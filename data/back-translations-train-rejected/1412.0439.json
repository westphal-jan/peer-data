{"id": "1412.0439", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2014", "title": "Fuzzy human motion analysis: A review", "abstract": "Human Motion Analysis (HMA) is currently one of the most popularly active research domains as such significant research interests are motivated by a number of real world applications such as video surveillance, sports analysis, healthcare monitoring and so on. However, most of these real world applications face high levels of uncertainties that can affect the operations of such applications. Hence, the fuzzy set theory has been applied and showed great success in the recent past. In this paper, we aim at reviewing the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. To the best of our knowledge, there is not found a single survey in the current literature that has discussed and reviewed fuzzy approaches towards the HMA. For ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA.", "histories": [["v1", "Mon, 1 Dec 2014 11:42:51 GMT  (6703kb)", "https://arxiv.org/abs/1412.0439v1", "Accepted in Pattern Recognition, first survey paper that discusses and reviews fuzzy approaches towards HMA"], ["v2", "Tue, 2 Dec 2014 18:19:13 GMT  (5727kb)", "http://arxiv.org/abs/1412.0439v2", "Accepted in Pattern Recognition, first survey paper that discusses and reviews fuzzy approaches towards HMA"]], "COMMENTS": "Accepted in Pattern Recognition, first survey paper that discusses and reviews fuzzy approaches towards HMA", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["chern hong lim", "ekta vats", "chee seng chan"], "accepted": false, "id": "1412.0439"}, "pdf": {"name": "1412.0439.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Chee Seng Chan"], "emails": ["ektavats_2608}@siswa.um.edu.my;"], "sections": [{"heading": null, "text": "ar Xiv: 141 2.04 39v2 [cs.CV] 2 Dec 201 4Human Motion Analysis (HMA) is currently one of the most popular areas of research, as such significant research interests are motivated by a number of real-world applications such as video surveillance, sports analysis, health monitoring, etc. However, most of these applications in the real world face a high level of uncertainty that can affect the operation of such applications. Therefore, fuzzy set theory has been applied and has shown great success in the recent past. In this paper, we aim to review the blurred set-oriented approaches to HMA and find out how the blurred amount can improve HMA by considering and outlining the future perspectives. To the best of knowledge, there is not a single survey in the current literature in which blurred approaches to HMA have been discussed and reviewed. To facilitate understanding, we classify human movement conceptually in three-level analysis: Mixed Level (Lozzy), Low-L (Lezzy) and Level (Lezzy)."}, {"heading": "1. Introduction", "text": "In recent years, however, with the advancement of video technologies and the availability of more complex computer algorithms that deal with the evolution of people, HMA has established itself in the public sphere. Video surveillance is one of the most important methods that play a role in public perception. [6, 8, 10] This is about capturing, tracking and recognizing people, understanding human behaviors that affect people. [7] Video surveillance is one of the most important methods that play a role in public perception."}, {"heading": "1.1. Motivation and contributions", "text": "In this paper, we focus primarily on the solutions that use the ambiguous approaches to HMA. This is in contrast to the past surveys listed in Tables 1 and 2, where stochastic solutions are the dominant approaches to HMA. To obtain the best results from our knowledge, it is not possible to find a single survey in the literature that shows the ambiguous approaches to future perspectives, which is in contrast to the past surveys listed in Tables 1 and 2."}, {"heading": "2. Low-level HMA", "text": "Human recognition is the first step in almost any vision impaired HMA system before the higher processing steps such as tracking and behavioral understanding can be performed. Technically, human recognition aims to locate and segment the regions that distinguish people from the rest of the image, a process that typically involves first segmentation of motion and then object classification."}, {"heading": "2.1. Motion segmentation", "text": "Motion segmentation is aimed at separating moving objects from natural scenes. Extracted motion regions are crucial for the next stage of processing, e.g. it loosens tracking complexity, taking into account only the pixels with changes. However, some critical situations in the real world such as lighting changes, dynamic scene movements (e.g. rain weather, undulating tree, rippling water, etc.), camera tremors and shadow effects pose a daunting task. In this section we will mainly review blurred approaches that have addressed the problem of subtracting the background from moving. Subtraction of the background is one of the popular motion segmentation algorithms that have received a lot of attention in the HMA system. This is due to the usefulness of its output, which is able to preserve the shape deformations that move in the background, as well as when extracting motion and contour information, the background of the moving object is clearly displayed in the background. [44] In general, the background is intended to differ from the background of the moving object."}, {"heading": "2.1.1. Fuzzy integral", "text": "Information fusion from a variety of sources is the simplest and most effective approach to increase classification confidence, as well as eliminating ambiguity and resolving conflicts in various decisions. Rationally in background modeling, combining multiple measurement criteria (also known as the characteristics or attributes) can strengthen the classification of the pixel as the background or foreground. However, the basic mathematical operators for aggregation such as the minimum, maximum, average, median \"and\" OR \"operators take clear decisions and use only a single feature that tends to lead to a false positive result [47]. In contrast, the blurred integrals take into account the meaning of any subset of criteria [48]. Generally, the fuzzy integrals is a nonlinear function defined in terms of the blurred measure, such as a belief or a plausibility measure [49] and is used in the aggregation stage."}, {"heading": "2.1.2. Type-2 Gaussian mixture model", "text": "The studies on background subtraction [56, 57] have shown that the Gaussian Mixture Model (GMM) is one of the most popular approaches used in modeling the dynamic background scene. It solves the constraint in the unimodal model (Single Gaussian), which is unable to handle the dynamic backgrounds such as waving tree and water waves. The expectation-maximizing algorithm is normally used in the initialization stage of GMM to estimate the parameters from a training sequence using the criterion maximum probability (ML). However, due to insufficient or noisy training data, the GMM may not be able to accurately reflect the underlying distribution of the observations. This is because accurate numbers must be used in the probability calculation and unfortunately, these parameters are limited by uncertainty. To take into account the uncertainty, the blurred set theory is blurred."}, {"heading": "2.1.3. Hybrid technique", "text": "Although the fuzzy approaches offer superior performance in subtraction in the background, most of these approaches have a common problem, namely the optimization of parameters in their algorithms. These parameters can be the intrinsic parameters, such as the interval values of the member function or the threshold for the inference step. Optimizing these parameters usually increases the overall performance of the system. However, such steps require human intervention [47, 51, 48]. For example, the trial and error process of determining a classification threshold is a tedious task, computationally expensive and subjective [65]. Fortunately, such limitations can be handled by using hybrid techniques, i.e. the combination of fuzzy approaches with machine learning methods. [66] Applied neural fuzzy framework to estimate image movement. The reverse propagation learning rule from a five-layer neural fuzzy network was used to adjust the best membership queries to the system, so that the speculative system can adapt itself to the most variable aspects of the system, and it is very adjacent to the speculative system."}, {"heading": "2.2. Object classification", "text": "The result of motion segmentation usually results in a rough estimate of the moving targets in a nature scene. These moving targets in a nature scene can be shadows, vehicle, flying bird, etc. Before further elaborating the region on the next level, it is very important to verify and refine the object of interest by eliminating the unintended objects. In this section we will discuss some blurred approaches that are advantageous for classifying human objects."}, {"heading": "2.2.1. Type-1 fuzzy inference system", "text": "The way in which they have behaved is not new; it is not new that they do what they do, but that they do what they do, and that they do it."}, {"heading": "2.2.2. Type-2 fuzzy inference system", "text": "To some extent, the overall performance of the system may be downgraded from [77, 78] due to the misclassification of the objects in the proposed Type 1 FIS. Taking this into account, the Type 2 FIS differs from the Type 1 FIS in terms of the Type 2 FIS ability to support higher levels of uncertainty in the real world. Consequently, the main focus in Type 2 Input Blurred Sets is the membership function used to represent the input data, where the membership function itself is a blurred group with an ordinary membership function. Consequently, the input data is first blurred in Type 2 Input Blurred Sets and then goes through the inference process, in which the rules may be similar to the Type 1 FIS. Prior to the demerger step, the Type 2 Blurred Input Blurred Sets are blurred sets that go into the Type 2 Blurred Input Type 2, and then go through the Blurred Input Process 2."}, {"heading": "3. Mid-level HMA", "text": "Once we have successfully located the human in the frame, the next step is to track human movements over time in order to be able to interpret them at a higher level. Tracking is a crucial step in the HMA, as it forms the basis for data preparation for HMA tasks such as action detection, detection of anomalies, etc. The aim of the tracking algorithm is to reliably track objects of interest such as the human body from an image sequence, and it can be categorized as model-based and non-model-based motion tracking."}, {"heading": "3.1. Model based tracking", "text": "In model-based Human Motion Tracking, human body models such as the stick figures, 2D and 3D motion description models are used to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91]. For detailed evaluations, the reader can refer to [20, 21, 24, 92].The bar model depicts the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], whereas the 2D models depict the human body using 2D bands or blobes [83, 86, 87]. 3D models are used to depict the human body structure in a more detailed way using cones, cylinders, spheres, ellipses, etc. [88, 89, 90, 91] However, tracking the human body in video sequences is not an easy task. The human body has a complex, non-rigid structure that is composed of a number of joints (e.g., the leg consists of a high number of joints) that move mutually."}, {"heading": "3.1.1. Fuzzy qualitative kinematics", "text": "A large number of studies in the model-based human motion tracking method used the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91]. Bregler et al. [94] demonstrated a comprehensive visual motion estimation technique using the kinematic chain in a complex video sequence, as shown in Figure 9. However, the sharp representation of the kinematic chain has a limitation. It suffers from the precision problem [95] and cumulative errors can directly affect the execution of tasks at a higher level. Therefore, a better strategy is needed to model the kinematic chain, and for this purpose fuzzy qualitative kinematics has been proposed. First, fuzzy qualitative reasoning [97, 98] is a form of fuzzy reasoning that can be defined as a fusion between fuzzy set theory [59] and qualitative kinematics [99]."}, {"heading": "3.1.2. Fuzzy voxel person", "text": "As already mentioned, the 3D models provide more useful information than the 2D models, since the features (height, centeredness, orientation, etc.) in 3D space are camera-independent. [16, 104] Inspired by this, they demonstrated a method of constructing a 3D human model in voxel (volume) space using the human silhouette images called voxel person (Figure 11). Due to the location of the cameras and the position of the object, the information collected using the voxel person model can sometimes be inaccurate and inaccurate. The razor-sharp technique works well if and only if there is a sufficient number of cameras. Unfortunately, however, due to the high cost and limited space, it is difficult to find more than a few cameras in the same area. Therefore, the blurred voxel person in [103] was used by using only a few cameras and minimal prior knowledge of the object."}, {"heading": "3.1.3. Fuzzy shape estimation", "text": "The regions extracted from the background subtraction algorithm are normally represented using different shape models, such as bands and blobs for 2D images, while cones, cylinders, spheres, ellipses, etc. for 3D images. Here, we mainly focus on blob representation. For a tracking system based on shape estimation, problems arise due to imperfect image segmentation techniques. This is due to the image irregularities, shadows, obfuscations, etc., which lead to the generation of multiple blobs for a single object. In addition, recovery from the overlapping regions is a major challenge when tracking multiple objects. To solve this, FIS was applied to update both the trajectories and the shape estimated for the targets with a series of image regions. These image regions are represented by the blobs extracted from each frame. Following the general steps of the FIS, hypocritical features were used to extract from the lobs and the target shape."}, {"heading": "3.2. Non-model based tracking", "text": "In non-model-based object tracking, the detected objects are represented by randomly distributed points rather than rigid shape models (e.g. stick figures, blobs, cylinders, etc.); the association between the points that contribute to motion tracking is based on the hypothesis that takes into account the properties and behavior of the object; this is a complex problem that needs to be formulated due to the presence of occlusions, false detections, new object entries, etc., which can lead to permanent tracking errors. Fuzzy approaches such as the Kalman filter, fuzzy particle filter, fuzzy optical flow, and fuzzy clustering are often used in non-model-based object tracking, explicitly taking into account the uncertainties to determine point correspondence between object movements."}, {"heading": "3.2.1. Fuzzy Kalman filter", "text": "The Kalman filter, the popular optimum estimator that can work recursively on the streams of noisy input data [107], is a popular choice for tracking a moving object. It has been successfully applied in several previous work on human motion tracking [91, 108, 109, 110, 111, 112]. There are three basic steps associated with Kalman filtering for human motion tracking: initialization, prediction, and correction [113]. Often, the complex dynamic trajectories are not feasible due to changes in the acceleration of human motion to be modeled by linear systems. Therefore, instead of the basic Kalman filters, the advanced Kalman filters are used, which are able to model the non-linear states. However, all these Kalman filter algorithms suffer from the divergence problem if the theoretical behavior of a filter and the actual modeling behavior of the Kalman do not match due to the calculation problem."}, {"heading": "3.2.2. Fuzzy particle filter", "text": "Similar to the Kalman filters, it has been suggested that particulate filters provide a good way to track the state of a dynamic HMA system. In general, if you have a model of how the system changes over time, and possible observations are made in particle states, the particle filters can be used for tracking. However, compared to the Kalman filters, the particle filters offer a better tracking mechanism as they provide multiple predictions or hypotheses (i.e. as many as the number of particles) to recover from the lost tracks, which helps overcome the problems associated with complex human movement. It should be noted that there is a compromise between system precision and computational costs in the particle filter frame, i.e. more particles improves system accuracy, but also the computational cost increases computational costs and vice versa."}, {"heading": "3.2.3. Fuzzy optical flow", "text": "The optical flux [127, 128] is another popular motion tracking algorithm. It is an efficient technique for approximating object motion in two consecutive video images by calculating the intensity fluctuations between them. However, eliminating the incoherent optical flux field is still a major challenge. This is because the incoherent regions can be treated as random noises in the optical flux field due to the sources of interference in a natural scene (e.g. dynamic background). To solve this problem, a blurred hostility index was introduced in [129, 130] which measures the degree of homogeneity or heterogeneity of the neighbourhood flux in the optical flux field. The more homogeneous the neighbourhood of a pixel is, the less hostile the pixel is to its neighbour. This implies that a denser neighbourhood has a more coherent optical flux region. In order to cope with the uncertain conditions in which one of the pixels quickly moves around it, the unstable conditions will be represented as the one of the x1."}, {"heading": "3.2.4. Fuzzy clustering", "text": "Clustering is an unsupervised machine learning solution that learns the blank data by autonomously grouping the similar data into the corresponding groups. Inspired by this, multi-object cluster tracking [133, 134] was introduced with the conviction that moving targets always produce a particular cluster of pixels with similar characteristics in the attribute space, and the distribution of these clusters changes little between successive frames. [132] A fast, fuzzy c-means (FCM) cluster tracking method was proposed, which offers a solution to the high complexity and computing costs associated with conventional multi-object tracking methods, as well as the hard cluster algorithms such as the k-medium, which causes failure in the case of severe occlusions and pervasive disturbances. FCM is also recognized as the soft cluster algorithm in which it uses data partitions to assign each sample to more than clusters with corresponding cluster values, which is the 13MA and the hard component algorithms]."}, {"heading": "4. High-level HMA", "text": "The ultimate goal of the HMA system is to understand human behavior. In this section, we will examine the feasibility of fuzzy approaches to achieve this, focusing on the following areas: (a) hand gesture recognition, (b) activity detection, (c) multi-angle invariant action detection, and (e) anomaly event detection."}, {"heading": "4.1. Hand gesture recognition", "text": "The application of gesture recognition is diverse [135] and extends from sign language to medical rehabilitation to virtual reality. The importance of gesture recognition lies in the construction of efficient and intelligent human-computer interaction applications [136] where the system can be controlled remotely for a specific task, i.e. without cursor movements or touch of the screen. In addition, successful commercial gesture recognition devices such as Kinect exist today: a vision-based motion sensor capable of deriving human activities. Unfortunately, in a gesture recognition system, the complex backgrounds, dynamic lighting conditions and sometimes the deformable forms of human limbs will lead to a high degree of uncertainty and ambiguity in the recognition of human gestures."}, {"heading": "4.1.1. Fuzzy clustering", "text": "Known clustering techniques include K-Means, GMM, Hierarchical Model and FCM. With probabilistic clustering algorithms (e.g. K-Means, GMM and Hierarchical Model), the mapping of data to each cluster takes place in a clear manner, i.e. each data element can belong to exactly one cluster. In contrast, the fuzzy clustering algorithm (e.g. FCM), soft computing, works in the sense that the data partition facilitates data allocation, where each data element can belong to more than one cluster and is associated with a set of member values. This solution works better in difficult environments such as complex backgrounds, dynamic light conditions and deformable hand shapes with real-time computing speeds [138, 139, 140, 141]. FCM, [138, 139] worked on a fast-reacting telerobotic gesture-based user interface."}, {"heading": "4.1.2. Hybrid technique", "text": "Some work [142, 143, 144] on the merging of blurred approaches with other machine learning solutions was reported in gesture recognition. [142] used the adaptive neuro-blurred inference system to recognize gestures in Arabic sign language. This work was motivated by the transformation of human knowledge into an FIS, but did not produce the precisely desired response due to heuristic or non-complex membership functions and the generation of blurred rules. [143] introduced a new approach to gesture recognition based on the idea of integrating the blurred ARTMAP [145] into the feature recognition network to enhance its performance, and the adaptive neuro-blurred inference system provided this flexibility by applying a learning process using training data. [143] introduced a new approach to gesture recognition based on the idea of integrating the blurred network from the xTM145 to the neural ARTM146."}, {"heading": "4.2. Activity recognition", "text": "Activity detection is an important task in HiL-HMA systems. The goal of activity detection is the autonomous analysis and interpretation of ongoing human activities and their context based on video data. For example, in surveillance systems to detect suspicious activity or in sports analysis to monitor athletes \"correct posture. Recently, blurred approaches such as Type 1 FIS, Blurred HMM and hybrid techniques have proven useful for human activity detection, with the ability to model uncertainty in characteristic data. Nevertheless, Fuzzy Vector Quantization (FVQ) and Qualitative Normalized Template (QNT) offer the ability to deal with the complex human activities that occur in our daily lives, such as running followed by running, followed by jumping or a hugging activity involving two or more people. In this section we will discuss the applications of these blurred approaches to activity detection."}, {"heading": "4.2.1. Type-1 fuzzy inference system", "text": "The FIS can be used efficiently to distinguish human movement patterns and to model human activities with their ability to detect the uncertainty and fusion of different features in the classification process. In the literature on activity detection, there is some work [147, 148] that used the FIS to classify different human activities. [147, 148] took into account the uncertainties of both spatial and temporal characteristics for efficient detection of human behavior. Their method is aimed at dealing with high levels of uncertainty and complexities that occur in the real world. [147] used the spatial and temporal geometrical characteristics to investigate the importance of spatial and temporal relationships, such as \"IsMoving,\" \"IsComingCloseTo,\" \"IsGoingAway,\" \"IsGoingAlong\" with the objective toprovide performing a qualitative interpretation of the behavior of an entity (e.g., a human function) in real-time [148]."}, {"heading": "4.2.2. Hybrid technique", "text": "Due to the requirements of developing improved video surveillance systems that can automatically understand human behavior and identify dangerous activities, a semantic system of human behavior analysis based on the hybridization of the neuro-fuzzy approach has been introduced. In their method, the kinematic data obtained from the tracking algorithm has been translated into several semantic terms that characterize the behavior of different actors in a scene. To achieve this, the semantic rules of behavior have been defined using the theory of time delay of neural networks and fuzzy logic to identify a human behavior that analyzes both temporal and contextual characteristics, meaning that they analyze how human activity changes over time, along with the contexts surrounding the human being. Their hybrid method outperformed other approaches and showed a high degree of scalability and robustness. Another paper [150] presented an unclear argument-based approach to the incorporation of football event identification and cognition."}, {"heading": "4.2.3. Fuzzy vector quantization", "text": "To learn the complex actions, [151] presented human movements as a combination of the smallest constructive unit of human motion patterns called dynems (Figure 13), which are the basic motion patterns of a continuous action. Dynems are defined in the hierarchy of action as the smallest constructive unit of human motion, while one level above is motion perceived as a sequence of dynems with clearly defined time limits and conceptual meaning. Dynems can be learned unsupervised and in [151] the FCM was chosen. Subsequently, the blurred vector quantization (FVQ) [152] was used as a function regulating the transition between the sharp and the soft decisions to map an input bearing vector into dynemic space. Finally, each movement was presented as a blurred motion model by calculating the arithmetic means of the composing postures of a movement in dynemic space."}, {"heading": "4.2.4. Qualitative normalized template", "text": "Using the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] created a generative action template, known as a qualitative normalized template (QNT), to perform the recognition of human actions. First, the training data representing a typical activity is obtained by tracking human anatomical landmarks in the image sequences. In their work, a quantization process was applied to handle the trade-offs between tracking precision and computational costs. Subsequently, the QNT, as shown in Figure 14, was constructed according to the fuzzy qualitative robot kinematics framework [95, 101]. An empirical comparison with the conventional hidden Markov model (HMM) and the fuzzy HMM using both KTH and Weizmannn data sets has shown the effectiveness of the proposed solution [96]."}, {"heading": "4.2.5. Fuzzy Hidden Markov Model", "text": "The Hidden Markov Model (HMM) [153] is the statistical Markov model in which the state is not directly visible, but the state-dependent performance is visible. HMM has been widely used in the detection of human actions [154, 155, 156, 157, 158]. This work has well demonstrated the modelling and detection of complex human activities using HMM. At the educational stage of HMM, the algorithm for maximizing expectation is adopted, but in conventional HMM, each observation vector is assigned to only one cluster. [159] pointed out that assignment of different observation vectors to the same cluster is possible, and when their observation probabilities become the same, the classification power may decrease as a result. Therefore, HMM was extended to blurred HMM, where during the training phase the distance from each observation vector to each cluster center is calculated and the inversion of the action as the degree of the detection of the M9 is carried out]."}, {"heading": "4.3. Style invariant action recognition", "text": "A robust action detection algorithm must be able to detect the actions performed by different people in different styles. Typically, different people have different styles of performing the same action, which can be categorized by physical differences (such as human appearance, height, posture, etc.) and dynamics differences (speed, movement patterns, etc.). [160] Several remarkable works have been written to model such deviations, incorporating the blurred approaches."}, {"heading": "4.3.1. Fuzzy vector quantization", "text": "[161] adopted the concept of FVQ and dynamics and proposed a new person-specific activity detection framework to deal with the stylistically invariant problem. [151] The method is essentially divided into two parts: firstly, the identity of the person is identified, and secondly, the activity is derived from the person-specific fuzzy motion model [151]. It was found that the different styles of performing actions have the ability to distinguish one person from the other. [162] Therefore, an activity-related biometric authentication system was developed using the information of different styles of different people. Improvements were made in calculating the cumulative fuzzy distances between the vectors and dynamics exceeding L1, L2 and Mahalanobis distances previously used in [151]."}, {"heading": "4.3.2. Fuzzy descriptor action model", "text": "An alternative approach was proposed in [160], where a fuzzy descriptor vector was used to represent human actions of different styles in a single underlying fuzzy action descriptor. Theoretically, the ordinary descriptor vector could only contain a single value in each dimension of the vector. In contrast, fuzzy descriptor allows the inclusion of a number of possible values in which these values contain the different measurements of the characteristic data obtained from the training data, which consist of an action performed by different persons in different styles."}, {"heading": "4.4. Multi-view action recognition", "text": "In the real world, humans are free to perform an action at any angle without restraint, head-on parallel to the camera, and most previous work treats it as a limitation or constraint in their system. This problem has received increasing attention in HMA research, and some of the remarkable work has been reported [28, 45, 46]. Moreover, blurred approaches such as FVQ and blurred qualitative reasoning are also applied to research into multiview action detection, which will be discussed in the following sections."}, {"heading": "4.4.1. Fuzzy vector quantization", "text": "[162, 163, 164] extended [151] to detect actions with multiple views. Similar to [151], FVQ was used to map each posture pattern with multiple views to create dynamic space with multiple views. This new representation of blurred multi-view movements is an invariant of motion speed and duration that generalizes over variations within a class and distinguishes between actions of different classes. In the detection step, invariant posture representation with Fourier vision was used to solve the problem of identifying the camera point before classifying actions. Nevertheless, they addressed the problem of interaction detection, i.e. detection of human actions involving two persons [165]."}, {"heading": "4.4.2. Fuzzy qualitative single camera framework", "text": "In most of the multiview action detection functions, there is an argument that performing vision-invariant human action detection using a multi-camera approach is not practicable in the real environment. [33, 46] The reasons for this are: First, such systems must be deployed in a narrow environment with many overlapping regions, which is very rare in public space. Second, the implementation and maintenance costs are very high due to the use of multiple cameras. [160] To solve this, a blurred action detection system for multi-vision within a single camera was proposed. Their work introduced the concept of learning the action at three predefined angles of view, which are oriented horizontally, diagonally and vertically, as in Figure 16. Learning is done by mapping the features extracted from the human silhouette onto the blurred quantity space. The dominant features are then identified from the blurred qualitative states and then tracked as a blurred step of the actioner [in the actioner]."}, {"heading": "4.5. Anomaly event detection", "text": "Detection of anomalies refers to the problem of finding patterns in the input data that do not match the expected behavior. In our daily lives, detection of anomalies is important in order to infer the abnormal behavior of a person, such as an action or activity that does not follow the routine or deviate from normal behavior [7, 166, 167]. For example, in the health sector, in order to prevent adverse events from occurring, such as the risk of patients falling over, and in monitoring systems to automatically detect criminal activity."}, {"heading": "4.5.1. Type-1 fuzzy inference system", "text": "As people gain more knowledge, they are able to make better decisions; similarly, if the FIS is equipped with sophisticated knowledge (i.e. blurred rules), it can deal with the problems of the real world in a better way.The FIS has been used in various work to detect anomalies such as the case of older people in [15, 16, 104] to address the shortcomings and inherent uncertainty associated with the modelling and conclusion of human activities.The work stressed that the non-interpretable probability value or ad hoc training of activity models in conventional approaches is impractical in the field of human action recognition.Therefore, a trustworthy (blurred membership level) that can be reliably used to reject unknown activities is more convenient. [16] proposed a novel, blurred rule method for monitoring the well-being of older people in conventional approaches."}, {"heading": "4.5.2. Fuzzy one class support vector machine", "text": "The fuzzy one class support vector machine (FOCSVM) is an efficient algorithm commonly used in fall detection systems to distinguish a fall from other activities such as walking, bending, sitting or lying down. [169] proposed a robust fall detection system using FOCSVM with novel 3D features. In their method, a voxel person was first calculated, then the video features derived from variation in a person's 3D angle and centric information were extracted from the sequences of voxel persons used to train the FOCSVM classifier. Compared to the conventional one-class support vector machine, FOCSVM achieved more accurate fall detection results with narrow decision limits under a training dataset with outliers. The success of the proposed method is evident from the experiments on the real video sequences, with fewer non-fall samples being misclassified by the classifier than falls with imperfect training data."}, {"heading": "4.5.3. Fuzzy clustering", "text": "In order to perform fall detection in multiple camera frames, indistinct cluster algorithms (e.g. FCM, Gustafson and Kessel clustering or Gath and Geva clustering) were used in [170] together with the indistinct K-nearest neighbor algorithms. In particular, invariant features of the Hu moment were calculated from the 2D silhouette images and the main components were analyzed to select the main components.The indistinct cluster algorithms were used to create the multi-prototype representing the action classes such as standing or walking, sitting or bending, lying down and lying forward."}, {"heading": "4.5.4. Hybrid technique", "text": "A hybrid model of FIS and Fuzzy Associative Memory (FAM) was incorporated into [172], which essentially receives an input and assigns a degree of affiliation to a set of rules. [172] considered the angles of human limbs as inputs to the FAM with three rules defining the abnormal types of motion. FAM then assigns a degree of affiliation to each rule and determines the abnormal or normal events based on a certain threshold. [173] also used the neural fuzzy network hybrid model, which compensates for the lack of learning of blurred approaches to recognizing human attitudes (e.g. standing, bending, sitting, and lying), and its system of simple fuzzy rules is capable of recognizing emergencies caused by accidental falls or when a person remains in a reclining posture for a period of time."}, {"heading": "5. Discussion", "text": "After reviewing a number of papers that use the fuzzy approaches in HMA, we identified some important factors that make fuzzy approaches successful in improving the overall performance of the system, and these are discussed in this section along with potential future work."}, {"heading": "5.1. Soft boundary", "text": "Human thinking is a mysterious phenomenon that scientists have attempted to simulate with machines in recent decades. Knowing that \"soft\" boundaries exist in human conceptualization [175], fuzzy set theory has become one of the most important methods of conceptualizing concepts. Generally, the fuzzy approach assigns \"soft\" boundaries, i.e. it performs \"soft labels\" in which a subject can be associated with a certain degree of certainty with many possible classes. Therefore, fuzzy representation is more advantageous than ordinary (crisp) representations, since it can represent not only the information given by a well-defined real interval, but also the knowledge embedded in the soft boundaries of the interval, thus eliminating or largely weakening the boundary interpretation problem achieved by describing a gradual rather than abrupt representation."}, {"heading": "5.2. Linguistic support", "text": "Another aspect of human behaviour is the way they interpret things in nature."}, {"heading": "5.3. Flexibility of the fuzzy system", "text": "This year it is more than ever before."}, {"heading": "5.4. Potential future works in fuzzy HMA", "text": "In fact, most people who are able to move, to move and to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move and to move, to move and to move, to move and to move."}, {"heading": "6. Conclusion", "text": "The studies show that the blurred approaches are able to deal with the uncertainty that was abundant in each level of the HMA system (LoL, MiL, and HiL), and some of the basic factors that gave this ability to the blurred approaches include the ability to perform soft labeling and the flexibility to adapt to different uncertainties. However, most of the reported work here did not use the standard HMA datasets as a starting point. However, the current datasets are usually too ideal to reflect real-world scenarios that are fraught with uncertainties. Generating the blurred dataset for HMA could be one of the potential future works, except for early detection of events and detection of actions as before."}, {"heading": "Acknowledgment", "text": "This research is supported by the Malaysian Ministry of Education's High Impact Research MoE Grant UM.C / 625 / 1 / HIR / MoE / FCSIT / 08, H-2200100-B0008."}], "references": [{"title": "Movement", "author": ["A.F. Bobick"], "venue": "activity and action: the role of knowledge in the perception of motion, Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences 352 (1358) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Decomposing biological motion: A framework for analysis and synthesis of human gait patterns", "author": ["N.F. Troje"], "venue": "Journal of Vision 2 (5) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Temporal and spatial factors in gait perception that influence gender recognition", "author": ["C.D. Barclay", "J.E. Cutting", "L.T. Kozlowski"], "venue": "Perception & Psychophysics 23 (2) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1978}, {"title": "Perception of human motion", "author": ["R. Blake", "M. Shiffrar"], "venue": "Annu. Rev. Psychol. 58 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Application of multimedia to the study of human movement", "author": ["C. Kirtley", "R. Smith"], "venue": "Multimedia Tools and Applications 14 (3) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "The evolution of video surveillance: an overview", "author": ["N. Haering", "P.L. Venetianer", "A. Lipton"], "venue": "Machine Vision and Applications 19 (5-6) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "A survey on visual surveillance of object motion and behaviors", "author": ["W. Hu", "T. Tan", "L. Wang", "S. Maybank"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 34 (3) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Intelligent visual surveillance: A survey", "author": ["I.S. Kim", "H.S. Choi", "K.M. Yi", "J.Y. Choi", "S.G. Kong"], "venue": "International Journal of Control, Automation and Systems 8 (5) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A survey on behavior analysis in video surveillance for homeland security applications", "author": ["T. Ko"], "venue": "in: 37th Applied Imagery Pattern Recognition Workshop", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Video-based abnormal human behavior recognition - a review", "author": ["O.P. Popoola", "K. Wang"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 42 (6) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey of content-based video retrieval", "author": ["P. Geetha", "V. Narayanan"], "venue": "Journal of Computer Science 4 (6) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Recognizing action at a distance", "author": ["A.A. Efros", "A.C. Berg", "G. Mori", "J. Malik"], "venue": "in: Proceedings. Ninth IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Monocular 3d reconstruction of human motion in long action sequences", "author": ["G. Loy", "M. Eriksson", "J. Sullivan", "S. Carlsson"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Action mach: Maximum average correlation height filter for action recognition", "author": ["M. Sullivan", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Recognizing falls from silhouettes", "author": ["D. Anderson", "J.M. Keller", "M. Skubic", "X. Chen", "Z. He"], "venue": "in: 28th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBS)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Modeling human activity from voxel person using fuzzy logic", "author": ["D. Anderson", "R.H. Luke", "J.M. Keller", "M. Skubic", "M.J. Rantz", "M.A. Aud"], "venue": "IEEE Transactions on Fuzzy Systems 17 (1) ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Multimodal human\u2013computer interaction: A survey", "author": ["A. Jaimes", "N. Sebe"], "venue": "Computer Vision and Image Understanding 108 (1) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Articulated and elastic non-rigid motion: A review", "author": ["J.K. Aggarwal", "Q. Cai", "W. Liao", "B. Sabata"], "venue": "in: Proceedings of the IEEE Workshop on Motion of Non-Rigid and Articulated Objects", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1994}, {"title": "Motion-based recognition a survey", "author": ["C. C\u00e9dras", "M. Shah"], "venue": "Image and Vision Computing 13 (2) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}, {"title": "Human motion analysis: A review", "author": ["J.K. Aggarwal", "Q. Cai"], "venue": "in: Proceedings of the IEEE Nonrigid and Articulated Motion Workshop", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "The visual analysis of human movement: A survey", "author": ["D.M. Gavrila"], "venue": "Computer Vision and Image Understanding 73 (1) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1999}, {"title": "Looking at people: Sensing for ubiquitous and wearable computing", "author": ["A. Pentland"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 22 (1) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "A survey of computer vision-based human motion capture", "author": ["T.B. Moeslund", "E. Granum"], "venue": "Computer Vision and Image Understanding 81 (3) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Recent developments in human motion analysis", "author": ["L. Wang", "W. Hu", "T. Tan"], "venue": "Pattern Recognition 36 (3) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "A survey of advances in vision-based human motion capture and analysis", "author": ["T.B. Moeslund", "A. Hilton", "V. Kr\u00fcger"], "venue": "Computer Vision and Image Understanding 104 (2) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Vision-based human motion analysis: An overview", "author": ["R. Poppe"], "venue": "Computer Vision and Image Understanding 108 (1) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Machine recognition of human activities: A survey", "author": ["P. Turaga", "R. Chellappa", "V.S. Subrahmanian", "O. Udrea"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 18 (11) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Advances in view-invariant human motion analysis: a review", "author": ["X. Ji", "H. Liu"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 40 (1) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "A survey on vision-based human action recognition", "author": ["R. Poppe"], "venue": "Image and Vision Computing 28 (6) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Understanding transit scenes: A survey on human behavior-recognition algorithms", "author": ["J. Candamo", "M. Shreve", "D.B. Goldgof", "D.B. Sapper", "R. Kasturi"], "venue": "IEEE Transactions on Intelligent Transportation Systems 11 (1) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Human activity analysis: A review", "author": ["J. Aggarwal", "M.S. Ryoo"], "venue": "ACM Computing Surveys 43 (3) ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey of vision-based methods for action representation", "author": ["D. Weinland", "R. Ronfard", "E. Boyer"], "venue": "segmentation and recognition, Computer Vision and Image Understanding 115 (2) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Human action recognition using multiple views: a comparative perspective on recent developments", "author": ["M.B. Holte", "C. Tran", "M.M. Trivedi", "T.B. Moeslund"], "venue": "in: Proceedings of the Joint ACM Workshop on Human Gesture and Behavior Understanding", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2011}, {"title": "A survey on human activity recognition using wearable sensors", "author": ["O.D. Lara", "M.A. Labrador"], "venue": "IEEE Communications Surveys & Tutorials 15 (3) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey of human motion analysis using depth imagery", "author": ["L. Chen", "H. Wei", "J. Ferryman"], "venue": "Pattern Recognition Letters 34 (15) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Human behavior analysis in video surveillance: A social signal processing perspective", "author": ["M. Cristani", "R. Raghavendra", "A. Del Bue", "V. Murino"], "venue": "Neurocomputing 100 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey of video datasets for human action and activity recognition", "author": ["J.M. Chaquet", "E.J. Carmona", "A. Fern\u00e1ndez-Caballero"], "venue": "Computer Vision and Image Understanding 117 (6) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Recognizing human actions: a local svm approach", "author": ["C. Schuldt", "I. Laptev", "B. Caputo"], "venue": "in: Proceedings of the International Conference on Pattern Recognition (ICPR), Vol. 3", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}, {"title": "Event-based analysis of video", "author": ["L. Zelnik-Manor", "M. Irani"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Vol. 2", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Actions as space-time shapes", "author": ["M. Blank", "L. Gorelick", "E. Shechtman", "M. Irani", "R. Basri"], "venue": "in: IEEE International Conference on Computer Vision (ICCV), Vol. 2", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2005}, {"title": "Representation of uncertainty in computer vision using fuzzy sets", "author": ["T.L. Huntsberger", "C. Rangarajan", "S.N. Jayaramamurthy"], "venue": "IEEE Transactions on Computers 100 (2) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1986}, {"title": "Fuzzy set theoretic approach to computer vision: An overview", "author": ["R. Krishnapuram", "J.M. Keller"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1992}, {"title": "Fuzzy sets in computer vision: An overview", "author": ["P. Sobrevilla", "E. Montseny"], "venue": "Mathware & Soft Computing 10 (3) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "The recognition of human movement using temporal templates", "author": ["A.F. Bobick", "J.W. Davis"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 23 (3) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2001}, {"title": "Free viewpoint action recognition using motion history volumes", "author": ["D. Weinland", "R. Ronfard", "E. Boyer"], "venue": "Computer Vision and Image Understanding 104 (2) ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2006}, {"title": "View and style-independent action manifolds for human activity recognition", "author": ["M. Lewandowski", "D. Makris", "J.-C. Nebel"], "venue": "in: European Conference on Computer Vision (ECCV)", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2010}, {"title": "Fusing color and texture features for background model", "author": ["H. Zhang", "D. Xu"], "venue": "in: Proceedings of the International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2006}, {"title": "Fuzzy integral for moving object detection", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2008}, {"title": "Information fusion in computer vision using the fuzzy integral", "author": ["H. Tahani", "J.M. Keller"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on 20 (3) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1990}, {"title": "On sugeno integral as an aggregation function", "author": ["J.-L. Marichal"], "venue": "Fuzzy Sets and Systems 114 (3) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2000}, {"title": "A fuzzy approach for background subtraction", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: IEEE International Conference on Image Processing 29  (ICIP)", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2008}, {"title": "Region based fuzzy background subtraction using choquet integral", "author": ["M. Balcilar", "A.C. Sonmez"], "venue": "in: Adaptive and Natural Computing Algorithms, Springer", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2013}, {"title": "An interpretation of fuzzy measures and the choquet integral as an integral with respect to a fuzzy measure", "author": ["T. Murofushi", "M. Sugeno"], "venue": "Fuzzy Sets and Systems 29 (2) ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1989}, {"title": "A new approach to time series modeling with fuzzy measures and the choquet integral", "author": ["M. Sugeno", "S.-H. Kwon"], "venue": "in: Proceedings of IEEE International Joint Conference of the Fourth IEEE International Conference on Fuzzy Systems and The Second International Fuzzy Engineering Symposium, Vol. 2", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1995}, {"title": "Decision modelling using the choquet integral", "author": ["Y. Narukawa", "T. Murofushi"], "venue": "in: Modeling Decisions for Artificial Intelligence, Springer", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2004}, {"title": "Background subtraction techniques: a review", "author": ["M. Piccardi"], "venue": "in: IEEE International Conference on Systems, Man and Cybernetics (SMC), Vol. 4", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2004}, {"title": "Robust techniques for background subtraction in urban traffic video", "author": ["S.-C.S. Cheung", "C. Kamath"], "venue": "in: Proceedings of SPIE, Vol. 5308", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2004}, {"title": "Type-2 fuzzy gaussian mixture models", "author": ["J. Zeng", "L. Xie", "Z.-Q. Liu"], "venue": "Pattern Recognition 41 (12) ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy sets", "author": ["L. Zadeh"], "venue": "Information and Control 8 (3) ", "citeRegEx": "59", "shortCiteRegEx": null, "year": 1965}, {"title": "Type-2 fuzzy sets made simple", "author": ["J.M. Mendel", "R.B. John"], "venue": "IEEE Transactions on Fuzzy Systems 10 (2) ", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2002}, {"title": "Type-2 fuzzy mixture of gaussians model: application to background modeling", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: Advances in Visual Computing, Springer", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy statistical modeling of dynamic backgrounds for moving object detection in infrared videos", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "in: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPRW)", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2009}, {"title": "F", "author": ["T. Bouwmans"], "venue": "El Baf, et al., Modeling of dynamic backgrounds by type-2 fuzzy gaussians mixture models, MASAUM Journal of of Basic and Applied Sciences 1 (2) ", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2009}, {"title": "A fuzzy background modeling approach for motion detection in dynamic backgrounds", "author": ["Z. Zhao", "T. Bouwmans", "X. Zhang", "Y. Fang"], "venue": "in: Multimedia and Signal Processing, Springer", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy running average and fuzzy background subtraction: concepts and application", "author": ["M.H. Sigari", "N. Mozayani", "H.R. Pourreza"], "venue": "International Journal of Computer Science and Network Security 8 (2) ", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2008}, {"title": "A neural fuzzy system for image motion estimation", "author": ["C. Lin", "I. Chung", "L. Sheu"], "venue": "Fuzzy Sets and Systems 114 (2) ", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2000}, {"title": "A fuzzy spatial coherence-based approach to background/foreground separation for moving object detection", "author": ["L. Maddalena", "A. Petrosino"], "venue": "Neural Computing and Applications 19 (2) ", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2010}, {"title": "Adaptive fuzzy apporach to background modeling using pso and klms", "author": ["Z. Li", "W. Liu", "Y. Zhang"], "venue": "in: 10th World Congress on Intelligent Control and Automation (WCICA)", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2012}, {"title": "A fuzzy system for background modeling in video sequences", "author": ["E. Calvo-Gallego", "P. Brox", "S. S\u00e1nchez-Solano"], "venue": "in: Fuzzy Logic and Applications, Springer", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2013}, {"title": "A novel fuzzy background subtraction method based on cellular automata for urban traffic applications", "author": ["M. Shakeri", "H. Deldari", "H. Foroughi", "A. Saberi", "A. Naseri"], "venue": "in: International Conference on Signal Processing (ICSP)", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2008}, {"title": "Interval type-2 fuzzy logic systems made simple", "author": ["J.M. Mendel", "R.I. John", "F. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 14 (6) ", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2006}, {"title": "An introduction to fuzzy logic applications in intelligent systems", "author": ["R.R. Yager", "L. Zadeh"], "venue": "Springer", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1992}, {"title": "Fuzzy logic", "author": ["L. Zadeh"], "venue": "Computer 21 (4) ", "citeRegEx": "73", "shortCiteRegEx": null, "year": 1988}, {"title": "Background subtraction and human detection in outdoor videos using fuzzy logic", "author": ["A. Mahapatra", "T.K. Mishra", "P.K. Sa", "B. Majhi"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2013}, {"title": "Human motion detection using fuzzy rule-base classification of moving blob regions", "author": ["J. See", "S. Lee", "M. Hanmandlu"], "venue": "in: Proc. Int. Conf. on Robotics, Vision, Information and Signal Processing 2005", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2005}, {"title": "Detection of human presence in a surveillance video using fuzzy approach", "author": ["A. Chowdhury", "S.S. Tripathy"], "venue": "in: International Conference on Signal Processing and Integrated Networks (SPIN)", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptive silouette extraction and human tracking in complex and dynamic environments", "author": ["X. Chen", "Z. He", "D. Anderson", "J. Keller", "M. Skubic"], "venue": "in: IEEE International Conference on Image Processing (ICIP)", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2006}, {"title": "Adaptive silhouette extraction in dynamic environments using fuzzy logic", "author": ["X. Chen", "Z. He", "J.M. Keller", "D. Anderson", "M. Skubic"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2006}, {"title": "An interval type-2 fuzzy logic system for human silhouette extraction in dynamic environments", "author": ["B. Yao", "H. Hagras", "D. Al Ghazzawi", "M.J. Alhaddad"], "venue": "in: Autonomous and Intelligent Systems, Springer", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2012}, {"title": "Interval type-2 fuzzy logic systems: theory and design", "author": ["Q. Liang", "J.M. Mendel"], "venue": "IEEE Transactions on Fuzzy Systems 8 (5) ", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2000}, {"title": "Type-2 fuzzy logic systems: type-reduction", "author": ["N.N. Karnik", "J.M. Mendel"], "venue": "in: IEEE International Conference on Systems, Man, and Cybernetics (SMC), Vol. 2", "citeRegEx": "81", "shortCiteRegEx": null, "year": 1998}, {"title": "Tracking human body motion based on a stick figure model", "author": ["Y. Guo", "G. Xu", "S. Tsuji"], "venue": "Journal of Visual Communication and Image Representation 5 (1) ", "citeRegEx": "82", "shortCiteRegEx": null, "year": 1994}, {"title": "First sight: A human body outline labeling system", "author": ["M.K. Leung", "Y.-H. Yang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 17 (4) ", "citeRegEx": "83", "shortCiteRegEx": null, "year": 1995}, {"title": "Posture estimation using structure and motion models", "author": ["Y. Iwai", "K. Ogaki", "M. Yachida"], "venue": "in: IEEE International Conference on Computer Vision (ICCV), Vol. 1", "citeRegEx": "84", "shortCiteRegEx": null, "year": 1999}, {"title": "Local and global skeleton fitting techniques for optical motion capture", "author": ["M.-C. Silaghi", "R. Pl\u00e4nkers", "R. Boulic", "P. Fua", "D. Thalmann"], "venue": "in: Modelling and Motion Capture Techniques for Virtual Environments, Springer", "citeRegEx": "85", "shortCiteRegEx": null, "year": 1998}, {"title": "Analyzing and recognizing walking figures in xyt", "author": ["S.A. Niyogi", "E.H. Adelson"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "86", "shortCiteRegEx": null, "year": 1994}, {"title": "Cardboard people: A parameterized model of articulated image motion", "author": ["S.X. Ju", "M.J. Black", "Y. Yacoob"], "venue": "in: Proceedings of the Second International Conference on Automatic Face and Gesture Recognition (FG)", "citeRegEx": "87", "shortCiteRegEx": null, "year": 1996}, {"title": "Towards model-based recognition of human movements in image sequences", "author": ["K. Rohr"], "venue": "CVGIP: Image understanding 59 (1) ", "citeRegEx": "88", "shortCiteRegEx": null, "year": 1994}, {"title": "Tracking of persons in monocular image sequences", "author": ["S. Wachter", "H.-H. Nagel"], "venue": "in: Proceedings of IEEE Nonrigid and Articulated Motion Workshop", "citeRegEx": "89", "shortCiteRegEx": null, "year": 1997}, {"title": "Model-based tracking of self-occluding articulated objects", "author": ["J.M. Rehg", "T. Kanade"], "venue": "in: Proceedings of International Conference on Computer Vision (ICCV)", "citeRegEx": "90", "shortCiteRegEx": null, "year": 1995}, {"title": "Model-based estimation of 3d human motion with occlusion based on active multi-viewpoint selection", "author": ["I.A. Kakadiaris", "D. Metaxas"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE", "citeRegEx": "91", "shortCiteRegEx": null, "year": 1996}, {"title": "A survey of computer vision-based human motion capture", "author": ["T.B. Moeslund", "E. Granum"], "venue": "Computer Vision and Image Understanding 81 (3) ", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2001}, {"title": "Kinematics-based tracking of human walking in monocular video sequences", "author": ["H. Ning", "T. Tan", "L. Wang", "W. Hu"], "venue": "Image and Vision Computing 22 (5) ", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2004}, {"title": "Twist based acquisition and tracking of animal and human kinematics", "author": ["C. Bregler", "J. Malik", "K. Pullen"], "venue": "International Journal of Computer Vision 56 (3) ", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2004}, {"title": "Fuzzy qualitative robot kinematics", "author": ["H. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 16 (6) ", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy qualitative human motion analysis", "author": ["C.S. Chan", "H. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 17 (4) ", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2009}, {"title": "Fuzzy qualitative simulation", "author": ["Q. Shen", "R. Leitch"], "venue": "IEEE Transactions on Systems, Man and Cybernetics 23 (4) ", "citeRegEx": "97", "shortCiteRegEx": null, "year": 1993}, {"title": "Recent advances in fuzzy qualitative reasoning", "author": ["C.S. Chan", "G.M. Coghill", "H. Liu"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 19 (03) ", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2011}, {"title": "Qualitative simulation", "author": ["B. Kuipers"], "venue": "Artificial Intelligence 29 (3) ", "citeRegEx": "99", "shortCiteRegEx": null, "year": 1986}, {"title": "Fuzzy qualitative trigonometry", "author": ["H. Liu", "G.M. Coghill", "D.P. Barnes"], "venue": "International Journal of Approximate Reasoning 51 (1) ", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2009}, {"title": "A fuzzy qualitative framework for connecting robot qualitative and quantitative representations", "author": ["H. Liu", "D.J. Brown", "G.M. Coghill"], "venue": "IEEE Transactions on Fuzzy Systems 16 (3) ", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2008}, {"title": "A fuzzy qualitative approach to human motion recognition", "author": ["C.S. Chan", "H. Liu", "D. Brown", "N. Kubota"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2008}, {"title": "J", "author": ["D. Anderson", "R.H. Luke III", "E.E. Stone"], "venue": "M. Keller, Fuzzy voxel object., in: IFSA/EUSFLAT Conf.", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2009}, {"title": "Linguistic summarization of video for fall detection using voxel person and fuzzy logic", "author": ["D. Anderson", "R.H. Luke", "J.M. Keller", "M. Skubic", "M. Rantz", "M. Aud"], "venue": "Computer Vision and Image Understanding 113 (1) ", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2009}, {"title": "Robust object tracking with fuzzy shape estimation", "author": ["J. Garc\u00eda", "J.M. Molina", "J.A. Besada", "J.I. Portillo", "J.R. Casar"], "venue": "in: Proceedings of the International Conference on Information Fusion, Vol. 1", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2002}, {"title": "Fuzzy region assignment for visual tracking", "author": ["J. Garcia", "M.A. Patricio", "A. Berlanga", "J.M. Molina"], "venue": "Soft Computing 15 (9) ", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2011}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Journal of Basic Engineering 82 (1) ", "citeRegEx": "107", "shortCiteRegEx": null, "year": 1960}, {"title": "Using the Kalman filter to track human interactive motion: modelling and initialization of the Kalman filter for translational motion", "author": ["M. Kohler"], "venue": "Citeseer", "citeRegEx": "108", "shortCiteRegEx": null, "year": 1997}, {"title": "Implementation and experimental results of a quaternion-based kalman filter for human body motion tracking", "author": ["X. Yun", "C. Aparicio", "E.R. Bachmann", "R.B. McGhee"], "venue": "in: Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2005}, {"title": "Design", "author": ["X. Yun", "E.R. Bachmann"], "venue": "implementation, and experimental results of a quaternion-based kalman filter for human body motion tracking, IEEE Transactions on Robotics 22 (6) ", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2006}, {"title": "An extended kalman filter for quaternion-based orientation estimation using marg sensors", "author": ["J.L. Marins", "X. Yun", "E.R. Bachmann", "R.B. McGhee", "M.J. Zyda"], "venue": "in: Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, Vol. 4", "citeRegEx": "111", "shortCiteRegEx": null, "year": 2001}, {"title": "History: The use of the kalman filter for human motion tracking in virtual reality", "author": ["G.F. Welch"], "venue": "Presence: Teleoperators and Virtual Environments 18 (1) ", "citeRegEx": "112", "shortCiteRegEx": null, "year": 2009}, {"title": "G", "author": ["G. Welch"], "venue": "Bishop, An introduction to the kalman filter ", "citeRegEx": "113", "shortCiteRegEx": null, "year": 1995}, {"title": "Fuzzy kalman filtering", "author": ["G. Chen", "Q. Xie", "L.S. Shieh"], "venue": "Information Sciences 109 (1) ", "citeRegEx": "114", "shortCiteRegEx": null, "year": 1998}, {"title": "Accurate differential global positioning system via fuzzy logic kalman filter sensor fusion technique", "author": ["K. Kobayashi", "K.C. Cheok", "K. Watanabe", "F. Munekata"], "venue": "IEEE Transactions on Industrial Electronics 45 (3) ", "citeRegEx": "115", "shortCiteRegEx": null, "year": 1998}, {"title": "Sensor fusion based on fuzzy kalman filtering for autonomous robot vehicle", "author": ["J. Sasiadek", "Q. Wang"], "venue": "in: Proceedings of the International Conference on Robotics and Automation (ICRA), Vol. 4", "citeRegEx": "116", "shortCiteRegEx": null, "year": 1999}, {"title": "Fuzzy adaptive kalman filtering for ins/gps data fusion", "author": ["J. Sasiadek", "Q. Wang", "M. Zeremba"], "venue": "in: Proceedings of the IEEE International Symposium on Intelligent Control", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2000}, {"title": "Sensor fusion based on fuzzy kalman filter", "author": ["J. Sasiadek", "J. Khe"], "venue": "in: Proceedings of the Second International Workshop on Robot Motion and Control", "citeRegEx": "118", "shortCiteRegEx": null, "year": 2001}, {"title": "Nonlinear state estimation using fuzzy kalman filter", "author": ["R. Senthil", "K. Janarthanan", "J. Prakash"], "venue": "Industrial & Engineering Chemistry Research 45 (25) ", "citeRegEx": "119", "shortCiteRegEx": null, "year": 2006}, {"title": "Autonomous novelty detection and object tracking in video streams using evolving clustering and takagi-sugeno type neuro-fuzzy system", "author": ["P. Angelov", "R. Ramezani", "X. Zhou"], "venue": "in: IEEE International Joint Conference on Neural Networks (IJCNN)", "citeRegEx": "120", "shortCiteRegEx": null, "year": 2008}, {"title": "An approach to online identification of takagi-sugeno fuzzy models", "author": ["P.P. Angelov", "D.P. Filev"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 34 (1) ", "citeRegEx": "121", "shortCiteRegEx": null, "year": 2004}, {"title": "Simpl_ets: a simplified method for learning evolving takagi-sugeno fuzzy models", "author": ["P. Angelov", "D. Filev"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "122", "shortCiteRegEx": null, "year": 2005}, {"title": "Fuzzy particle filtering for uncertain systems", "author": ["H. Wu", "F. Sun", "H. Liu"], "venue": "IEEE Transactions on Fuzzy Systems 16 (5) ", "citeRegEx": "123", "shortCiteRegEx": null, "year": 2008}, {"title": "Object tracking from image sequences using adaptive models in fuzzy particle filter", "author": ["C. Yoon", "M. Cheon", "M. Park"], "venue": "Information Sciences 253 ", "citeRegEx": "124", "shortCiteRegEx": null, "year": 2013}, {"title": "Fuzzy logic based particle filter for tracking a maneuverable target", "author": ["H. Kamel", "W. Badawy"], "venue": "in: 48th Midwest Symposium on Circuits and Systems", "citeRegEx": "125", "shortCiteRegEx": null, "year": 2005}, {"title": "Fuzzy adaptive particle filter for localization of a mobile robot", "author": ["Y.-J. Kim", "C.-H. Won", "J.-M. Pak", "M.-T. Lim"], "venue": "in: Knowledge-Based Intelligent Information and Engineering Systems, Springer", "citeRegEx": "126", "shortCiteRegEx": null, "year": 2007}, {"title": "Determining optical flow", "author": ["B.K. Horn", "B.G. Schunck"], "venue": "in: 1981 Technical Symposium East, International Society for Optics and Photonics", "citeRegEx": "127", "shortCiteRegEx": null, "year": 1981}, {"title": "The computation of optical flow", "author": ["S. Beauchemin", "J.L. Barron"], "venue": "ACM Computing Surveys 27 (3) ", "citeRegEx": "128", "shortCiteRegEx": null, "year": 1995}, {"title": "High-speed target tracking by fuzzy hostility-induced segmentation of optical flow field", "author": ["S. Bhattacharyya", "U. Maulik", "P. Dutta"], "venue": "Applied Soft Computing 9 (1) ", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2009}, {"title": "Target tracking using fuzzy hostility induced segmentation of optical flow field", "author": ["S. Bhattacharyya", "U. Maulik"], "venue": "in: Soft Computing for Image and Multimedia Data Processing, Springer", "citeRegEx": "130", "shortCiteRegEx": null, "year": 2013}, {"title": "Binary object extraction using bi-directional self-organizing neural network (bdsonn) architecture with fuzzy context sensitive thresholding", "author": ["S. Bhattacharyya", "P. Dutta", "U. Maulik"], "venue": "Pattern Analysis and Applications 10 (4) ", "citeRegEx": "131", "shortCiteRegEx": null, "year": 2007}, {"title": "A multi-object tracking system for surveillance video analysis", "author": ["D. Xie", "W. Hu", "T. Tan", "J. Peng"], "venue": "in: Proceedings of the 17th International Conference on Pattern Recognition (ICPR), Vol. 4", "citeRegEx": "132", "shortCiteRegEx": null, "year": 2004}, {"title": "Tracking non-rigid", "author": ["B. Heisele", "U. Kressel", "W. Ritter"], "venue": "moving objects based on color cluster flow, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "133", "shortCiteRegEx": null, "year": 1997}, {"title": "From cluster tracking to people counting", "author": ["A.E. Pece"], "venue": "in: IEEE Workshop on Performance Evaluation of Tracking and Surveillance (PETS)", "citeRegEx": "134", "shortCiteRegEx": null, "year": 2002}, {"title": "Automatic classification of single facial images", "author": ["M.J. Lyons", "J. Budynek", "S. Akamatsu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 21 (12) ", "citeRegEx": "135", "shortCiteRegEx": null, "year": 1999}, {"title": "Vision-based gesture recognition: A review", "author": ["Y. Wu", "T.S. Huang"], "venue": "in: Gesture-based communication in human-computer interaction, Springer", "citeRegEx": "136", "shortCiteRegEx": null, "year": 1999}, {"title": "Gesture recognition: A survey", "author": ["S. Mitra", "T. Acharya"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews 37 (3) ", "citeRegEx": "137", "shortCiteRegEx": null, "year": 2007}, {"title": "Real-time hand gesture telerobotic system using fuzzy c-means clustering", "author": ["J. Wachs", "U. Kartoun", "H. Stern", "Y. Edan"], "venue": "in: Proceedings of the 5th Biannual World Automation Congress, Vol. 13", "citeRegEx": "138", "shortCiteRegEx": null, "year": 2002}, {"title": "Cluster labeling and parameter estimation for the automated setup of a hand-gesture recognition system", "author": ["J.P. Wachs", "H. Stern", "Y. Edan"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans 35 (6) ", "citeRegEx": "139", "shortCiteRegEx": null, "year": 2005}, {"title": "Vision based hand gesture recognition using finite state machines and fuzzy logic", "author": ["R. Verma", "A. Dev"], "venue": "in: International Conference on Ultra Modern Telecommunications & Workshops (ICUMT)", "citeRegEx": "141", "shortCiteRegEx": null, "year": 2009}, {"title": "Recognition of gestures in arabic sign language using neuro-fuzzy systems", "author": ["O. Al-Jarrah", "A. Halawani"], "venue": "Artificial Intelligence 133 (1) ", "citeRegEx": "142", "shortCiteRegEx": null, "year": 2001}, {"title": "Hand gesture recognition using fuzzy neural network", "author": ["N.D. Binh", "T. Ejima"], "venue": "in: Proc. ICGST Conf. Graphics, Vision and Image Proces", "citeRegEx": "143", "shortCiteRegEx": null, "year": 2005}, {"title": "Human\u2013computer interaction for smart environment applications using fuzzy hand posture and gesture models", "author": ["A.R. V\u00e1rkonyi-K\u00f3czy", "B. Tusor"], "venue": "IEEE Transactions on Instrumentation and Measurement 60 (5) ", "citeRegEx": "144", "shortCiteRegEx": null, "year": 2011}, {"title": "Fuzzy artmap: A neural network architecture for incremental supervised learning of analog multidimensional maps", "author": ["G.A. Carpenter", "S. Grossberg", "N. Markuzon", "J.H. Reynolds", "D.B. Rosen"], "venue": "IEEE Transactions on Neural Networks 3 (5) ", "citeRegEx": "145", "shortCiteRegEx": null, "year": 1992}, {"title": "A novel feature recognition neural network and its application to character recognition", "author": ["B. Hussain", "M.R. Kabuka"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 16 (1) ", "citeRegEx": "146", "shortCiteRegEx": null, "year": 1994}, {"title": "A fuzzy spatio-temporal-based approach for activity recognition", "author": ["J.-M. Le Yaouanc", "J.-P. Poli"], "venue": "in: Advances in Conceptual Modeling, Springer", "citeRegEx": "147", "shortCiteRegEx": null, "year": 2012}, {"title": "A fuzzy logic-based system for the automation of human behavior recognition using machine vision in intelligent environments", "author": ["B. Yao", "H. Hagras", "M.J. Alhaddad", "D. Alghazzawi"], "venue": "Soft Computing ", "citeRegEx": "148", "shortCiteRegEx": null, "year": 2014}, {"title": "Combining neural networks and fuzzy systems for human behavior understanding", "author": ["G. Acampora", "P. Foggia", "A. Saggese", "M. Vento"], "venue": "in: IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance (AVSS)", "citeRegEx": "149", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy rule-based reasoning approach for event detection and annotation of broadcast soccer video", "author": ["M.-S. Hosseini", "A.-M. Eftekhari-Moghadam"], "venue": "Applied Soft Computing 13 (2) ", "citeRegEx": "150", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining fuzzy vector quantization with linear discriminant analysis for continuous human movement recognition", "author": ["N. Gkalelis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 18 (11) ", "citeRegEx": "151", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy vector quantization algorithms and their application in image compression", "author": ["N.B. Karayiannis", "P.-I. Pai"], "venue": "IEEE Transactions on Image Processing 4 (9) ", "citeRegEx": "152", "shortCiteRegEx": null, "year": 1995}, {"title": "Hidden Markov Models", "author": ["R.J. Elliott", "L. Aggoun", "J.B. Moore"], "venue": "Springer", "citeRegEx": "153", "shortCiteRegEx": null, "year": 1995}, {"title": "A state-based technique for the summarization and recognition of gesture", "author": ["A.F. Bobick", "A.D. Wilson"], "venue": "in: International Conference on Computer Vision (ICCV)", "citeRegEx": "154", "shortCiteRegEx": null, "year": 1995}, {"title": "Recognition of human body motion using phase space constraints", "author": ["L.W. Campbell", "A.F. Bobick"], "venue": "in: International Conference on Computer Vision (ICCV)", "citeRegEx": "155", "shortCiteRegEx": null, "year": 1995}, {"title": "A bayesian computer vision system for modeling human interactions", "author": ["N.M. Oliver", "B. Rosario", "A.P. Pentland"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 22 (8) ", "citeRegEx": "156", "shortCiteRegEx": null, "year": 2000}, {"title": "Parametric hidden markov models for gesture recognition", "author": ["A.D. Wilson", "A.F. Bobick"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 21 (9) ", "citeRegEx": "157", "shortCiteRegEx": null, "year": 1999}, {"title": "Recognizing human action in time-sequential images using hidden markov model", "author": ["J. Yamato", "J. Ohya", "K. Ishii"], "venue": "in: IEEE Conference on 32  Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "158", "shortCiteRegEx": null, "year": 1992}, {"title": "A novel fuzzy hmm approach for human action recognition in video", "author": ["K. Mozafari", "N.M. Charkari", "H.S. Boroujeni", "M. Behrouzifar"], "venue": "in: Knowledge Technology, Springer", "citeRegEx": "159", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy action recognition for multiple views within single camera", "author": ["C.H. Lim", "C.S. Chan"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "160", "shortCiteRegEx": null, "year": 2013}, {"title": "Person specific activity recognition using fuzzy learning and discriminant analysis", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "in: Proceedings of the 19th European Signal Processing Conference (EUSIPCO)", "citeRegEx": "161", "shortCiteRegEx": null, "year": 2011}, {"title": "Activity-based person identification using fuzzy representation and discriminant learning", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Information Forensics and Security 7 (2) ", "citeRegEx": "162", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-view human movement recognition based on fuzzy distances and linear discriminant analysis", "author": ["A. Iosifidis", "A. Tefas", "N. Nikolaidis", "I. Pitas"], "venue": "Computer Vision and Image Understanding 116 (3) ", "citeRegEx": "163", "shortCiteRegEx": null, "year": 2012}, {"title": "Minimum class variance extreme learning machine for human action recognition", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 23 (11) ", "citeRegEx": "164", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-view action recognition based on action volumes", "author": ["A. Iosifidis", "A. Tefas", "I. Pitas"], "venue": "fuzzy distances and cluster discriminant analysis, Signal Processing 93 (6) ", "citeRegEx": "165", "shortCiteRegEx": null, "year": 2012}, {"title": "Anomaly detection in extremely crowded scenes using spatio-temporal motion pattern models", "author": ["L. Kratz", "K. Nishino"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "166", "shortCiteRegEx": null, "year": 2009}, {"title": "Chaotic invariants of lagrangian particle trajectories for anomaly detection in crowded scenes", "author": ["S. Wu", "B.E. Moore", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "167", "shortCiteRegEx": null, "year": 2010}, {"title": "Extension of a soft-computing framework for activity analysis from linguistic summarizations of video", "author": ["D. Anderson", "R.H. Luke", "J.M. Keller", "M. Skubic"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "168", "shortCiteRegEx": null, "year": 2008}, {"title": "Fall detection in a smart room by using a fuzzy one class support vector machine and imperfect training data", "author": ["M. Yu", "S.M. Naqvi", "A. Rhuma", "J. Chambers"], "venue": "in: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "citeRegEx": "169", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-prototype fuzzy clustering with fuzzy k-nearest neighbor for off-line human action recognition", "author": ["R. Wongkhuenkaew", "S. Auephanwiriyakul", "N. Theera-Umpon"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "170", "shortCiteRegEx": null, "year": 2013}, {"title": "Fuzzy qualitative complex actions recognition", "author": ["C.S. Chan", "H. Liu", "W.K. Lai"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "171", "shortCiteRegEx": null, "year": 2010}, {"title": "Detecting pedestrian abnormal behavior based on fuzzy associative memory", "author": ["Z. Wang", "J. Zhang"], "venue": "in: Fourth International Conference on Natural Computation (ICNC), Vol. 6", "citeRegEx": "172", "shortCiteRegEx": null, "year": 2008}, {"title": "Human body posture classification by a neural fuzzy network and home care system application", "author": ["C.-F. Juang", "C.-M. Chang"], "venue": "EEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans 37 (6) ", "citeRegEx": "173", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning activity patterns using fuzzy self-organizing neural network", "author": ["W. Hu", "D. Xie", "T. Tan", "S. Maybank"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 34 (3) ", "citeRegEx": "174", "shortCiteRegEx": null, "year": 2004}, {"title": "Toward a theory of fuzzy information granulation and its centrality in human reasoning and fuzzy logic", "author": ["L.A. Zadeh"], "venue": "Fuzzy Sets and Systems 90 (2) ", "citeRegEx": "175", "shortCiteRegEx": null, "year": 1997}, {"title": "Computing with uncertainty", "author": ["J.C. Bezdek"], "venue": "IEEE Communications Magazine 30 (9) ", "citeRegEx": "176", "shortCiteRegEx": null, "year": 1992}, {"title": "Uncertainty representation using fuzzy measures", "author": ["R.R. Yager"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 32 (1) ", "citeRegEx": "177", "shortCiteRegEx": null, "year": 2002}, {"title": "Uncertainty bounds and their use in the design of interval type-2 fuzzy logic systems", "author": ["H. Wu", "J.M. Mendel"], "venue": "IEEE Transactions on Fuzzy Systems 10 (5) ", "citeRegEx": "178", "shortCiteRegEx": null, "year": 2002}, {"title": "Uncertainty measures for interval type-2 fuzzy sets", "author": ["D. Wu", "J.M. Mendel"], "venue": "Information Sciences 177 (23) ", "citeRegEx": "179", "shortCiteRegEx": null, "year": 2007}, {"title": "Type-2 fuzzy sets for handling uncertainty in pattern recognition", "author": ["J. Zeng", "Z.-Q. Liu"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "180", "shortCiteRegEx": null, "year": 2006}, {"title": "Fuzzy logic= computing with words", "author": ["L. Zadeh"], "venue": "IEEE Transactions on Fuzzy Systems 4 (2) ", "citeRegEx": "181", "shortCiteRegEx": null, "year": 1996}, {"title": "Outline of a new approach to the analysis of complex systems and decision processes", "author": ["L. Zadeh"], "venue": "IEEE Transactions on Systems, Man and Cybernetics (1) ", "citeRegEx": "182", "shortCiteRegEx": null, "year": 1973}, {"title": "Computing with words", "author": ["S.H. Rubin"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 29 (4) ", "citeRegEx": "183", "shortCiteRegEx": null, "year": 1999}, {"title": "A", "author": ["G. Trivino"], "venue": "van der Heide, Linguistic summarization of the human activity using skin conductivity and accelerometers, in: Proc. 12th Int. Conf. on Information Processing and Management of Uncertainty in Knowledge-based Systems (IPMU)", "citeRegEx": "184", "shortCiteRegEx": null, "year": 2008}, {"title": "Linguistic summaries of data using fuzzy logic", "author": ["J. Kacprzyk", "R.R. Yager"], "venue": "International Journal of General System 30 (2) ", "citeRegEx": "185", "shortCiteRegEx": null, "year": 2001}, {"title": "Linguistic description of adult skeletal age-at-death estimations from fuzzy integral acquired fuzzy sets", "author": ["D.T. Anderson", "J.M. Keller", "M. Anderson", "D.J. Wescott"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "186", "shortCiteRegEx": null, "year": 2011}, {"title": "Linguistic summarization of sensor data for eldercare", "author": ["A. Wilbik", "J.M. Keller", "G.L. Alexander"], "venue": "in: IEEE International Conference on Systems, Man, and Cybernetics (SMC)", "citeRegEx": "187", "shortCiteRegEx": null, "year": 2011}, {"title": "A fuzzy measure similarity between sets of linguistic summaries", "author": ["A. Wilbik", "J. Keller"], "venue": "IEEE Transactions on Fuzzy Systems 21 (1) ", "citeRegEx": "188", "shortCiteRegEx": null, "year": 2013}, {"title": "Generating fuzzy rules by learning from examples", "author": ["L.-X. Wang", "J.M. Mendel"], "venue": "IEEE Transactions on Systems, Man and Cybernetics 22 (6) ", "citeRegEx": "189", "shortCiteRegEx": null, "year": 1992}, {"title": "Fuzzy rule generation methods for high-level computer vision", "author": ["F.C.-H. Rhee", "R. Krishnapuram"], "venue": "Fuzzy Sets and Systems 60 (3) ", "citeRegEx": "190", "shortCiteRegEx": null, "year": 1993}, {"title": "A new approach to fuzzy rule generation: fuzzy extension matrix", "author": ["X. Wang", "Y. Wang", "X. Xu", "W. Ling", "D.S. Yeung"], "venue": "Fuzzy Sets and Systems 123 (3) ", "citeRegEx": "191", "shortCiteRegEx": null, "year": 2001}, {"title": "Fast clustering with application to fuzzy rule generation", "author": ["T.W. Cheng", "D. Goldgof", "L. Hall"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ), Vol. 4", "citeRegEx": "192", "shortCiteRegEx": null, "year": 1995}, {"title": "Generating the knowledge base of a fuzzy rule-based system by the genetic learning of the data base", "author": ["O. Cord\u00f3n", "F. Herrera", "P. Villar"], "venue": "IEEE 33  Transactions on Fuzzy Systems 9 (4) ", "citeRegEx": "193", "shortCiteRegEx": null, "year": 2001}, {"title": "Neuro-fuzzy rule generation: survey in soft computing framework", "author": ["S. Mitra", "Y. Hayashi"], "venue": "IEEE Transactions on Neural Networks 11 (3) ", "citeRegEx": "194", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning discriminative space\u2013time action parts from weakly labelled videos", "author": ["M. Sapienza", "F. Cuzzolin", "P.H. Torr"], "venue": "International Journal of Computer Vision ", "citeRegEx": "195", "shortCiteRegEx": null, "year": 2014}, {"title": "The pets04 surveillance ground-truth data sets", "author": ["R.B. Fisher"], "venue": "in: Proc. 6th IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS)", "citeRegEx": "196", "shortCiteRegEx": null, "year": 2004}, {"title": "Single/cross-camera multiple-person tracking by graph matching", "author": ["W. Nie", "A. Liu", "Y. Su", "H. Luan", "Z. Yang", "L. Cao", "R. Ji"], "venue": "Neurocomputing 139 ", "citeRegEx": "197", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing human action from a far field of view", "author": ["C.-C. Chen", "J. Aggarwal"], "venue": "in: Workshop on Motion and Video Computing", "citeRegEx": "198", "shortCiteRegEx": null, "year": 2009}, {"title": "Multi-max-margin support vector machine for multi-source human action recognition", "author": ["D. Wu", "L. Shao"], "venue": "Neurocomputing 127 ", "citeRegEx": "199", "shortCiteRegEx": null, "year": 2014}, {"title": "Human activity recognition based on r transform", "author": ["Y. Wang", "K. Huang", "T. Tan"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "200", "shortCiteRegEx": null, "year": 2007}, {"title": "Application of an incremental svm algorithm for on-line human recognition from video surveillance using texture and color features", "author": ["Y. Lu", "K. Boukharouba", "J. Boon\u00e6rt", "A. Fleury", "S. Lec\u0153uche"], "venue": "Neurocomputing 126 ", "citeRegEx": "201", "shortCiteRegEx": null, "year": 2014}, {"title": "Etiseo", "author": ["A.T. Nghiem", "F. Bremond", "M. Thonnat", "V. Valentin"], "venue": "performance evaluation for video surveillance systems, in: IEEE Conference on Advanced Video and Signal Based Surveillance (AVSS)", "citeRegEx": "202", "shortCiteRegEx": null, "year": 2007}, {"title": "F", "author": ["S.M. Simha", "D.P. Chau"], "venue": "Bremond, et al., Feature matching using co-inertia analysis for people tracking, in: The 9th International Conference on Computer Vision Theory and Applications (VISAPP)", "citeRegEx": "203", "shortCiteRegEx": null, "year": 2014}, {"title": "Human action recognition using distribution of oriented rectangular patches", "author": ["N. Ikizler", "P. Duygulu"], "venue": "in: Human Motion\u2013Understanding, Modeling, Capture and Animation, Springer", "citeRegEx": "204", "shortCiteRegEx": null, "year": 2007}, {"title": "Human activity recognition with metric learning", "author": ["D. Tran", "A. Sorokin"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "205", "shortCiteRegEx": null, "year": 2008}, {"title": "The complex action recognition via the correlated topic model, The Scientific World", "author": ["H.-b. Tu", "L.-m. Xia", "Z.-w. Wang"], "venue": null, "citeRegEx": "206", "shortCiteRegEx": "206", "year": 2014}, {"title": "Charting-based subspace learning for video-based human action classification", "author": ["V. John", "E. Trucco"], "venue": "Machine Vision and Applications 25 (1) ", "citeRegEx": "208", "shortCiteRegEx": null, "year": 2014}, {"title": "Vihasi: virtual human action silhouette data for the performance evaluation of silhouettebased action recognition methods", "author": ["H. Ragheb", "S. Velastin", "P. Remagnino", "T. Ellis"], "venue": "in: Second ACM/IEEE International Conference on Distributed Smart Cameras (ICDSC)", "citeRegEx": "209", "shortCiteRegEx": null, "year": 2008}, {"title": "Grassmann multimodal implicit feature selection", "author": ["L. Zhang", "D. Tao", "X. Liu", "L. Sun", "M. Song", "C. Chen"], "venue": "Multimedia Systems ", "citeRegEx": "210", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning realistic human actions from movies", "author": ["I. Laptev", "M. Marszalek", "C. Schmid", "B. Rozenfeld"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "211", "shortCiteRegEx": null, "year": 2008}, {"title": "Recognizing complex events in real movies by combining audio and video features", "author": ["J.-X. Du", "C.-M. Zhai", "Y.-L. Guo", "Y.-Y. Tang", "P.C. Chun Lung"], "venue": "Neurocomputing 137 ", "citeRegEx": "212", "shortCiteRegEx": null, "year": 2014}, {"title": "Actions in context", "author": ["M. Marszalek", "I. Laptev", "C. Schmid"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "213", "shortCiteRegEx": null, "year": 2009}, {"title": "Action recognition with improved trajectories", "author": ["H. Wang", "C. Schmid"], "venue": "in: International Conference on Computer Vision (ICCV)", "citeRegEx": "214", "shortCiteRegEx": null, "year": 2013}, {"title": "Action mach: Maximum average correlation height filter for action recognition", "author": ["M. Rodriguez", "J. Ahmed", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "215", "shortCiteRegEx": null, "year": 2008}, {"title": "Action recognition in videos acquired by a moving camera using motion decomposition of lagrangian particle trajectories", "author": ["S. Wu", "O. Oreifej", "M. Shah"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "216", "shortCiteRegEx": null, "year": 2011}, {"title": "Recognizing realistic actions from videos in the wild", "author": ["J. Liu", "J. Luo", "M. Shah"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "217", "shortCiteRegEx": null, "year": 2009}, {"title": "The i3dpost multi-view and 3d human action/interaction database", "author": ["N. Gkalelis", "H. Kim", "A. Hilton", "N. Nikolaidis", "I. Pitas"], "venue": "in: Conference for Visual Media Production (CVMP)", "citeRegEx": "218", "shortCiteRegEx": null, "year": 2009}, {"title": "A local 3-d motion descriptor for multi-view human action recognition from 4-d spatio-temporal interest points", "author": ["M.B. Holte", "B. Chakraborty", "J. Gonzalez", "T.B. Moeslund"], "venue": "IEEE Journal of Selected Topics in Signal Processing 6 (5) ", "citeRegEx": "219", "shortCiteRegEx": null, "year": 2012}, {"title": "Spatio-temporal relationship match: Video structure comparison for recognition of complex human activities", "author": ["M.S. Ryoo", "J.K. Aggarwal"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "220", "shortCiteRegEx": null, "year": 2009}, {"title": "Discriminative subvolume search for efficient action detection", "author": ["J. Yuan", "Z. Liu", "Y. Wu"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "222", "shortCiteRegEx": null, "year": 2009}, {"title": "Action recognition based on a bag of 3d points", "author": ["W. Li", "Z. Zhang", "Z. Liu"], "venue": "in: 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citeRegEx": "223", "shortCiteRegEx": null, "year": 2010}, {"title": "Effective 3d action recognition using eigenjoints", "author": ["X. Yang", "Y. Tian"], "venue": "Journal of Visual Communication and Image Representation 25 (1) ", "citeRegEx": "224", "shortCiteRegEx": null, "year": 2014}, {"title": "The behave video dataset: ground truthed video for multi-person behavior classification", "author": ["S. Blunsden", "R. Fisher"], "venue": "Annals of the BMVA 2010 (4) ", "citeRegEx": "225", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing human group action by layered model with multiple cues", "author": ["Z. Cheng", "L. Qin", "Q. Huang", "S. Yan", "Q. Tian"], "venue": "Neurocomputing 136 ", "citeRegEx": "226", "shortCiteRegEx": null, "year": 2014}, {"title": "Muhavi: A multicamera human action video dataset for the evaluation of action recognition methods", "author": ["S. Singh", "S.A. Velastin", "H. Ragheb"], "venue": "in: 2010 Seventh IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)", "citeRegEx": "227", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimizing human action recognition based on a cooperative coevolutionary algorithm", "author": ["A.A. Chaaraoui", "F. Fl\u00f3rez-Revuelta"], "venue": "Engineering Applications of Artificial Intelligence 31 ", "citeRegEx": "228", "shortCiteRegEx": null, "year": 2013}, {"title": "Modeling temporal structure of decomposable motion segments for activity classification", "author": ["J.C. Niebles", "C.-W. Chen", "L. Fei-Fei"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "229", "shortCiteRegEx": null, "year": 2010}, {"title": "High five: Recognising human interactions in tv shows", "author": ["A. Patron-Perez", "M. Marszalek", "A. Zisserman", "I. Reid"], "venue": "in: Proceedings of the British Machine Vision Conference (BMVC)", "citeRegEx": "230", "shortCiteRegEx": null, "year": 2010}, {"title": "N", "author": ["M. Mar\u00edn-Jim\u00e9nez", "R. Mu\u00f1oz-Salinas", "E. Yeguas-Bolivar"], "venue": "P. de la Blanca, Human interaction categorization by using audio-visual cues, Machine Vision and Applications 25 (1) ", "citeRegEx": "231", "shortCiteRegEx": null, "year": 2014}, {"title": "Hmdb: a large video database for human motion recognition", "author": ["H. Kuehne", "H. Jhuang", "E. Garrote", "T. Poggio", "T. Serre"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "232", "shortCiteRegEx": null, "year": 2011}, {"title": "Videoweb dataset for multi-camera activities and non-verbal communication", "author": ["G. Denina", "B. Bhanu", "H.T. Nguyen", "C. Ding", "A. Kamal", "C. Ravishankar", "A. Roy-Chowdhury", "A. Ivers", "B. Varda"], "venue": "in: Distributed Video Sensor Networks, Springer", "citeRegEx": "233", "shortCiteRegEx": null, "year": 2011}, {"title": "Detecting group activities with multi-camera context", "author": ["Z.-J. Zha", "H. Zhang", "M. Wang", "H. Luan", "T.-S. Chua"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 23 (5) ", "citeRegEx": "234", "shortCiteRegEx": null, "year": 2013}, {"title": "Ucf101: A dataset of 101 human actions classes from videos in the wild", "author": ["K. Soomro", "A.R. Zamir", "M. Shah"], "venue": "Tech. Rep. CRCV-TR-12-01, CRCV, University of Central Florida ", "citeRegEx": "235", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-view super vector for action recognition", "author": ["Z. Cai", "L. Wang", "X. Peng", "Y. Qiao"], "venue": "in: IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "236", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing 50 human action categories of web videos", "author": ["K.K. Reddy", "M. Shah"], "venue": "Machine Vision and Applications 24 (5) ", "citeRegEx": "237", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning multi-label scene classification", "author": ["M.R. Boutell", "J. Luo", "X. Shen", "C.M. Brown"], "venue": "Pattern recognition 37 (9) ", "citeRegEx": "238", "shortCiteRegEx": null, "year": 2004}, {"title": "Relative attributes", "author": ["D. Parikh", "K. Grauman"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "239", "shortCiteRegEx": null, "year": 2011}, {"title": "A fuzzy qualitative approach for scene classification", "author": ["C.H. Lim", "C.S. Chan"], "venue": "in: IEEE International Conference on Fuzzy Systems (FUZZ)", "citeRegEx": "240", "shortCiteRegEx": null, "year": 2012}, {"title": "Activity forecasting", "author": ["K.M. Kitani", "B.D. Ziebart", "J.A. Bagnell", "M. Hebert"], "venue": "in: European Conference on Computer Vision (ECCV), Springer", "citeRegEx": "241", "shortCiteRegEx": null, "year": 2012}, {"title": "Human activity prediction: Early recognition of ongoing activities from streaming videos", "author": ["M. Ryoo"], "venue": "in: IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "242", "shortCiteRegEx": null, "year": 2011}, {"title": "F", "author": ["M. Hoai"], "venue": "De la Torre, Max-margin early event detectors, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "243", "shortCiteRegEx": null, "year": 2012}, {"title": "Observing human-object interactions: Using spatial and functional compatibility for recognition", "author": ["A. Gupta", "A. Kembhavi", "L.S. Davis"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 31 (10) ", "citeRegEx": "244", "shortCiteRegEx": null, "year": 2009}, {"title": "Grouplet: A structured image representation for recognizing human and object interactions", "author": ["B. Yao", "L. Fei-Fei"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "245", "shortCiteRegEx": null, "year": 2010}, {"title": "Discriminative models for static human-object interactions", "author": ["C. Desai", "D. Ramanan", "C. Fowlkes"], "venue": "in: IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citeRegEx": "246", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing human actions from still images with latent poses", "author": ["W. Yang", "Y. Wang", "G. Mori"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "247", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognizing human actions in still images: a study of bag-of-features and part-based representations", "author": ["V. Delaitre", "I. Laptev", "J. Sivic"], "venue": "in: Proceedings of the British Machine Vision Conference (BMVC)", "citeRegEx": "248", "shortCiteRegEx": null, "year": 2010}, {"title": "Action recognition from a distributed representation of pose and appearance", "author": ["S. Maji", "L. Bourdev", "J. Malik"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "249", "shortCiteRegEx": null, "year": 2011}, {"title": "Weakly supervised learning of interactions between humans and objects", "author": ["A. Prest", "C. Schmid", "V. Ferrari"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 34 (3) ", "citeRegEx": "250", "shortCiteRegEx": null, "year": 2012}, {"title": "Recognizing human-object interactions in still images by modeling the mutual context of objects and human poses", "author": ["B. Yao", "L. Fei-Fei"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 34 (9) ", "citeRegEx": "251", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 95, "endOffset": 101}, {"referenceID": 1, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 95, "endOffset": 101}, {"referenceID": 2, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 114, "endOffset": 120}, {"referenceID": 3, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 114, "endOffset": 120}, {"referenceID": 4, "context": "For decades, it has been a popular research topic that crossovers many domains such as biology [1, 2], psychology [3, 4], multimedia [5] and so on.", "startOffset": 133, "endOffset": 136}, {"referenceID": 5, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 6, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 7, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 8, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 9, "context": "Amongst all, video surveillance is one of the most important real-time applications [6, 7, 8, 9, 10].", "startOffset": 84, "endOffset": 100}, {"referenceID": 10, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 57, "endOffset": 61}, {"referenceID": 11, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 79, "endOffset": 91}, {"referenceID": 12, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 79, "endOffset": 91}, {"referenceID": 13, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 79, "endOffset": 91}, {"referenceID": 14, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 115, "endOffset": 123}, {"referenceID": 15, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 115, "endOffset": 123}, {"referenceID": 16, "context": "Apart from that, HMA also contributed in video retrieval [11], sports analysis [12, 13, 14], healthcare monitoring [15, 16], human-computer interaction [17] and so on.", "startOffset": 152, "endOffset": 156}, {"referenceID": 17, "context": "One of the earliest surveys was [18], focused on various methods employed in the analysis of the human body motion, which is in non-rigid form.", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "[19] gave an overview on the motion extraction methods using the motion capture systems and focused on action recognition, individual body parts recognition, and body configuration estimation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] used the same taxonomy as in [19], but engaging different labels for the three classes, that is further dividing the classes into subclasses yielding a more comprehensive taxonomy.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] used the same taxonomy as in [19], but engaging different labels for the three classes, that is further dividing the classes into subclasses yielding a more comprehensive taxonomy.", "startOffset": 34, "endOffset": 38}, {"referenceID": 20, "context": "[21] gave an overview on the applications of visual analysis of human movements, and their taxonomy covered the 2D and 3D approaches with and without the explicit shape models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions", "startOffset": 8, "endOffset": 12}, {"referenceID": 38, "context": "The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions", "startOffset": 30, "endOffset": 38}, {"referenceID": 39, "context": "The KTH [38] and the Weizmann [39, 40] datasets were the most popular human actions", "startOffset": 30, "endOffset": 38}, {"referenceID": 17, "context": "[18] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] Alex Pentland Looking at people: sensing for ubiquitous and wearable computing Reviewed the state-of-the-art of \"looking at people\" focusing on person identification and surveillance monitoring.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] W.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "[25] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[32] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] O.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[35] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[36] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[37] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "1994 [18] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "1995 [19] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "1997 [20] X X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "1999 [21] X X X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 21, "context": "2000 [22] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "2001 [23] X X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 23, "context": "2003 [24] X X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 6, "context": "2004 [7] X X X X X", "startOffset": 5, "endOffset": 8}, {"referenceID": 24, "context": "2006 [25] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 25, "context": "2007 [26] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 26, "context": "2008 [27] X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "2010 [28] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 28, "context": "2010 [29] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 29, "context": "2010 [30] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 30, "context": "2011 [31] X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 31, "context": "2011 [32] X X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 32, "context": "2011 [33] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 33, "context": "2013 [34] X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 34, "context": "2013 [35] X X X X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 35, "context": "2013 [36] X X X X", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "2013 [37] X -", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "Please refer to [37] for a complete list of the currently available datasets in HMA.", "startOffset": 16, "endOffset": 20}, {"referenceID": 6, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 19, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 20, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 23, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 24, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 27, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 28, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 31, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 32, "context": "[7, 20, 21, 24, 25, 28, 29, 32, 33] moved ahead to survey on the representation and recognition of the human actions in multiple-views aspect.", "startOffset": 0, "endOffset": 35}, {"referenceID": 6, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 20, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 22, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 23, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 26, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 30, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 35, "context": "Last but not the least, [7, 21, 23, 24, 27, 31, 36] surveyed on the various applications of HMA such as the smart surveillance and advanced user interface for human-computer interaction.", "startOffset": 24, "endOffset": 51}, {"referenceID": 40, "context": "The nearest studies to ours are [41, 42, 43].", "startOffset": 32, "endOffset": 44}, {"referenceID": 41, "context": "The nearest studies to ours are [41, 42, 43].", "startOffset": 32, "endOffset": 44}, {"referenceID": 42, "context": "The nearest studies to ours are [41, 42, 43].", "startOffset": 32, "endOffset": 44}, {"referenceID": 40, "context": "[41] was the earliest survey that discussed the uncertainties in computer vision using the fuzzy sets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "Later, [42] gave a broad overview of the fuzzy set theory towards computer vision with applications in the areas of image modeling, preprocessing, segmentation, boundary detection, object/region recognition, and rule-based scene interpretation.", "startOffset": 7, "endOffset": 11}, {"referenceID": 42, "context": "Finally, [43] addressed various aspects of image processing and analysis problems where the theory of fuzzy set was applied.", "startOffset": 9, "endOffset": 13}, {"referenceID": 43, "context": "This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46].", "startOffset": 159, "endOffset": 171}, {"referenceID": 44, "context": "This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46].", "startOffset": 159, "endOffset": 171}, {"referenceID": 45, "context": "This is due to the usefulness of its output that is capable of preserving the shape information, as well as helps in extracting motion and contour information [44, 45, 46].", "startOffset": 159, "endOffset": 171}, {"referenceID": 46, "context": "However the basic mathematical operators used for aggregation such as the minimum, maximum, average, median, \u2018AND\u2019, and \u2018OR\u2019 operators provide crisp decisions and utilize only a single feature that tends to result in false positive [47].", "startOffset": 232, "endOffset": 236}, {"referenceID": 47, "context": "In contrast, the fuzzy integrals take into account the importance of the coalition of any subset of the criteria [48].", "startOffset": 113, "endOffset": 117}, {"referenceID": 47, "context": "Figure 3: Comparison between the Sugeno and the Choquet fuzzy integral methods for background subtraction [48].", "startOffset": 106, "endOffset": 110}, {"referenceID": 48, "context": "In general, the fuzzy integral is a non-linear function that is defined with respect to the fuzzy measure such as a belief or a plausibility measure [49], and is employed in the aggregation step.", "startOffset": 149, "endOffset": 153}, {"referenceID": 46, "context": "[47] proposed to use the Sugeno integral [50] to fuse color and texture features in their works for better classification of the pixel that", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[47] proposed to use the Sugeno integral [50] to fuse color and texture features in their works for better classification of the pixel that", "startOffset": 41, "endOffset": 45}, {"referenceID": 47, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 50, "endOffset": 62}, {"referenceID": 50, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 50, "endOffset": 62}, {"referenceID": 51, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 50, "endOffset": 62}, {"referenceID": 46, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 72, "endOffset": 76}, {"referenceID": 52, "context": "belongs to either background or foreground, while [48, 51, 52] improved [47] by replacing the Sugeno integral with the Choquet integral [53].", "startOffset": 136, "endOffset": 140}, {"referenceID": 53, "context": "The main reason is that the Choquet integral which was adapted for cardinal aggregation, was found to be more suitable than the Sugeno integral that assumed the measurement scale to be ordinal [54, 55].", "startOffset": 193, "endOffset": 201}, {"referenceID": 54, "context": "The main reason is that the Choquet integral which was adapted for cardinal aggregation, was found to be more suitable than the Sugeno integral that assumed the measurement scale to be ordinal [54, 55].", "startOffset": 193, "endOffset": 201}, {"referenceID": 55, "context": "The studies on the background subtraction [56, 57] have shown that the Gaussian Mixture Model (GMM) is one of the popular approaches used in modeling the dynamic background scene.", "startOffset": 42, "endOffset": 50}, {"referenceID": 56, "context": "The studies on the background subtraction [56, 57] have shown that the Gaussian Mixture Model (GMM) is one of the popular approaches used in modeling the dynamic background scene.", "startOffset": 42, "endOffset": 50}, {"referenceID": 57, "context": "The thick solid and dashed lines denote the lower and upper membership functions [58].", "startOffset": 81, "endOffset": 85}, {"referenceID": 58, "context": "However, there has been an argument that type-1 fuzzy set, which is an ordinary fuzzy set [59], has limited capability in modeling the uncertainty.", "startOffset": 90, "endOffset": 94}, {"referenceID": 59, "context": "Therefore, type-2 fuzzy sets [60] emerged from the type-1 fuzzy set by generalizing it to handle more uncertainty in the underlying fuzzy membership function.", "startOffset": 29, "endOffset": 33}, {"referenceID": 57, "context": "With the capability of type-2 fuzzy set to handle higher dimensions of uncertainty, it was adopted in [58] to represent the multivariate Gaussian with an uncertain mean vector or a covariance matrix.", "startOffset": 102, "endOffset": 106}, {"referenceID": 60, "context": "Several works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model.", "startOffset": 14, "endOffset": 26}, {"referenceID": 61, "context": "Several works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model.", "startOffset": 14, "endOffset": 26}, {"referenceID": 62, "context": "Several works [61, 62, 63] have been reported that utilized the type-2 fuzzy GMM to deal with insufficient or noisy data, and resulted in better background subtraction model.", "startOffset": 14, "endOffset": 26}, {"referenceID": 63, "context": "In the later stage, [64] made an improvement on these works with the inclusion of spatial-temporal constraints into the type-2 fuzzy GMM by using the Markov Random Field.", "startOffset": 20, "endOffset": 24}, {"referenceID": 46, "context": "However, such steps require human intervention [47, 51, 48].", "startOffset": 47, "endOffset": 59}, {"referenceID": 50, "context": "However, such steps require human intervention [47, 51, 48].", "startOffset": 47, "endOffset": 59}, {"referenceID": 47, "context": "However, such steps require human intervention [47, 51, 48].", "startOffset": 47, "endOffset": 59}, {"referenceID": 64, "context": "For example, the trial and error process to determine a classification threshold value is a tedious job, computationally expensive and subjective [65].", "startOffset": 146, "endOffset": 150}, {"referenceID": 65, "context": "[66] applied neural fuzzy framework to estimate the image motion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 66, "context": "Besides that, [67] introduced a spatial coherence variant incorporated with the self-organizing neural network to formulate a fuzzy model to enhance the robustness against false detection in the background subtraction algorithm.", "startOffset": 14, "endOffset": 18}, {"referenceID": 67, "context": "[68] used both the particle swarm optimization and the kernel least mean square to update the system parameters of a fuzzy model, and [69] employed a tuning process using the Marquardt-Levenberg algorithm within a fuzzy system to fine-tune the membership function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 68, "context": "[68] used both the particle swarm optimization and the kernel least mean square to update the system parameters of a fuzzy model, and [69] employed a tuning process using the Marquardt-Levenberg algorithm within a fuzzy system to fine-tune the membership function.", "startOffset": 134, "endOffset": 138}, {"referenceID": 69, "context": "In order to determine the appropriate threshold value for the classification task, [70] proposed a novel fuzzy-cellular method that helps in dynamically learning the optimal threshold value.", "startOffset": 83, "endOffset": 87}, {"referenceID": 70, "context": "Figure 5: Type-1 Fuzzy Inference System [71].", "startOffset": 40, "endOffset": 44}, {"referenceID": 71, "context": "The Type-1 Fuzzy Inference System (FIS) [72] is a complete fuzzy decision making system that utilizes the fuzzy set theory.", "startOffset": 40, "endOffset": 44}, {"referenceID": 72, "context": "The fuzzification step maps the crisp input data from a set of sensors (features or attributes) to the membership functions to generate the fuzzy input sets with linguistic support [73].", "startOffset": 181, "endOffset": 185}, {"referenceID": 73, "context": "(b) The fuzzy rules for the fuzzy input for three features (Distance, \u03c1; Angle, \u0398 and Cord to Arc Ratio, \u03b6), and its corresponding fuzzy output (VL=Very low, L=Low, M=Med, H=High, VH=Very High) [74].", "startOffset": 194, "endOffset": 198}, {"referenceID": 74, "context": "In human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76].", "startOffset": 135, "endOffset": 147}, {"referenceID": 73, "context": "In human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76].", "startOffset": 135, "endOffset": 147}, {"referenceID": 75, "context": "In human detection, the FIS is an effective and direct approach to distinguish between the human and non-human with different features [75, 74, 76].", "startOffset": 135, "endOffset": 147}, {"referenceID": 73, "context": "As an example, [74] extracted three features from the contours of the segmented region, such as the distance to the centroid, angle, and cord to arc ratio, and input them into the FIS.", "startOffset": 15, "endOffset": 19}, {"referenceID": 76, "context": "Besides that, [77, 78] studied in depth about the problems encountered in the human classification tasks, such as the situations where the unintended objects are attached to the classified human region.", "startOffset": 14, "endOffset": 22}, {"referenceID": 77, "context": "Besides that, [77, 78] studied in depth about the problems encountered in the human classification tasks, such as the situations where the unintended objects are attached to the classified human region.", "startOffset": 14, "endOffset": 22}, {"referenceID": 43, "context": "In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46].", "startOffset": 228, "endOffset": 240}, {"referenceID": 44, "context": "In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46].", "startOffset": 228, "endOffset": 240}, {"referenceID": 45, "context": "In general, silhouette is the binary representation of the segmented regions from the background subtraction techniques, where in HMA, human silhouette has proved its sufficiency to describe the activities captured by the video [44, 45, 46].", "startOffset": 228, "endOffset": 240}, {"referenceID": 76, "context": "In order to solve this, [77, 78] applied the FIS to perform an adaptive silhouette extraction in the complex and dynamic environments.", "startOffset": 24, "endOffset": 32}, {"referenceID": 77, "context": "In order to solve this, [77, 78] applied the FIS to perform an adaptive silhouette extraction in the complex and dynamic environments.", "startOffset": 24, "endOffset": 32}, {"referenceID": 76, "context": "To a certain extent, the overall performance of the system from [77, 78] may be degraded due to the misclassification of the objects in the proposed type-1 FIS.", "startOffset": 64, "endOffset": 72}, {"referenceID": 77, "context": "To a certain extent, the overall performance of the system from [77, 78] may be degraded due to the misclassification of the objects in the proposed type-1 FIS.", "startOffset": 64, "endOffset": 72}, {"referenceID": 78, "context": "Taking this into account, [79] employed the interval type-2 FIS [80] which is capable of handling higher uncertainty levels present in the real world dynamic environments.", "startOffset": 26, "endOffset": 30}, {"referenceID": 79, "context": "Taking this into account, [79] employed the interval type-2 FIS [80] which is capable of handling higher uncertainty levels present in the real world dynamic environments.", "startOffset": 64, "endOffset": 68}, {"referenceID": 70, "context": "Figure 7: Type-2 Fuzzy Inference System [71].", "startOffset": 40, "endOffset": 44}, {"referenceID": 77, "context": "(b) Extracted silhouette after using type-1 FIS to detach the book from the human, but degraded as a result [78, 77].", "startOffset": 108, "endOffset": 116}, {"referenceID": 76, "context": "(b) Extracted silhouette after using type-1 FIS to detach the book from the human, but degraded as a result [78, 77].", "startOffset": 108, "endOffset": 116}, {"referenceID": 76, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 27, "endOffset": 35}, {"referenceID": 77, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 27, "endOffset": 35}, {"referenceID": 78, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 37, "endOffset": 41}, {"referenceID": 80, "context": "Using the same features as [77, 78], [79] proposed to fuzzify the input feature values into the type-2 fuzzy sets using the singleton fuzzification method [81].", "startOffset": 155, "endOffset": 159}, {"referenceID": 46, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 47, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 50, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 51, "context": "[47, 48, 51, 52] Information fusion from a variety of sources us-", "startOffset": 0, "endOffset": 16}, {"referenceID": 60, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 61, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 62, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 63, "context": "[61, 62, 63, 64] The uncertainty in GMM is bounded with interval mean and standard deviation instead of the", "startOffset": 0, "endOffset": 16}, {"referenceID": 65, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 66, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 67, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 68, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 69, "context": "[66, 67, 68, 69, 70] Integration of the machine learning techniques", "startOffset": 0, "endOffset": 20}, {"referenceID": 73, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 74, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 75, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 76, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 77, "context": "[74, 75, 76, 77, 78] Type-1 FIS is able to model the uncertainty in the features data as the membership function, and per-", "startOffset": 0, "endOffset": 20}, {"referenceID": 78, "context": "[79] Type-2 fuzzy set offers the capability to support", "startOffset": 0, "endOffset": 4}, {"referenceID": 81, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 82, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 83, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 84, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 85, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 86, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 87, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 88, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 89, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 90, "context": "In the model based human motion tracking, the human body models such as the stick figures, 2D and 3D motion description models are adopted to model the complex, non-rigid structure of the human body [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 199, "endOffset": 239}, {"referenceID": 19, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 20, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 23, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 91, "context": "Readers can refer to [20, 21, 24, 92] for the detailed reviews.", "startOffset": 21, "endOffset": 37}, {"referenceID": 81, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 82, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 83, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 84, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 117, "endOffset": 133}, {"referenceID": 82, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 207, "endOffset": 219}, {"referenceID": 85, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 207, "endOffset": 219}, {"referenceID": 86, "context": "The stick figure model represents the human body as a combination of sticks or line segments connected by the joints [82, 83, 84, 85], while the 2D models represents the human body using 2D ribbons or blobs [83, 86, 87].", "startOffset": 207, "endOffset": 219}, {"referenceID": 87, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 88, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 89, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 90, "context": "[88, 89, 90, 91].", "startOffset": 0, "endOffset": 16}, {"referenceID": 92, "context": "3D models are able to handle such scenarios, but there are other factors that can affect the tracking performance such as the monotone clothes, cluttered background and changing brightness [93].", "startOffset": 189, "endOffset": 193}, {"referenceID": 81, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 82, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 83, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 84, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 85, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 86, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 87, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 88, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 89, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 90, "context": "A variety of works in the model based human motion tracking have employed the kinematic chain [82, 83, 84, 85, 86, 87, 88, 89, 90, 91].", "startOffset": 94, "endOffset": 134}, {"referenceID": 93, "context": "[94] demonstrated a comprehensive visual motion estimation technique using the kinematic chain in a complex video sequence, as depicted in Figure 9.", "startOffset": 0, "endOffset": 4}, {"referenceID": 94, "context": "It suffers from the precision problem [95] and the cumulative errors can directly affect the performance of the higher level tasks.", "startOffset": 38, "endOffset": 42}, {"referenceID": 96, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 47, "endOffset": 55}, {"referenceID": 97, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 47, "endOffset": 55}, {"referenceID": 58, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 154, "endOffset": 158}, {"referenceID": 98, "context": "To begin with, the fuzzy qualitative reasoning [97, 98] is a form of approximate reasoning that can be defined as the fusion between the fuzzy set theory [59] and the qualitative reasoning [99].", "startOffset": 189, "endOffset": 193}, {"referenceID": 93, "context": "Figure 9: (a) Kinematic chain defined by twist [94], and (b) The estimated kinematic chain on the human body while performing the walking action.", "startOffset": 47, "endOffset": 51}, {"referenceID": 95, "context": "(b) Element of the fuzzy quantity space for every variable (translation (X, Y), and orientation \u03b8) in the fuzzy qualitative unit circle is a finite and convex discretization of the real number line [96].", "startOffset": 198, "endOffset": 202}, {"referenceID": 99, "context": "For instance, [100] applied this in the Fuzzy Qualitative Trigonometry (Figure 10) where the ordinary Cartesian space and the unit circle are substituted with the combination of membership functions yielding the fuzzy qualitative coordinate and the fuzzy qualitative unit circle.", "startOffset": 14, "endOffset": 19}, {"referenceID": 94, "context": "Extension from this, a fuzzy qualitative representation of the robot kinematics [95, 101] was proposed.", "startOffset": 80, "endOffset": 89}, {"referenceID": 100, "context": "Extension from this, a fuzzy qualitative representation of the robot kinematics [95, 101] was proposed.", "startOffset": 80, "endOffset": 89}, {"referenceID": 99, "context": "The work presented a derivative extension to the Fuzzy Qualitative Trigonometry [100].", "startOffset": 80, "endOffset": 85}, {"referenceID": 101, "context": "Motivated by these approaches, [102] proposed a data quantization process based on the Fuzzy Qualitative Trigonometry to model the uncertainties during the kinematic chain tracking process; and subsequently constructed a generic activity representation model.", "startOffset": 31, "endOffset": 36}, {"referenceID": 102, "context": "Therefore, the fuzzy voxel person representation was proposed [103].", "startOffset": 62, "endOffset": 67}, {"referenceID": 15, "context": "Inspired by this, [16, 104] demonstrated a method to construct a 3D human model in voxel (volume element) space using the human silhouette images called the voxel person (Figure 11).", "startOffset": 18, "endOffset": 27}, {"referenceID": 103, "context": "Inspired by this, [16, 104] demonstrated a method to construct a 3D human model in voxel (volume element) space using the human silhouette images called the voxel person (Figure 11).", "startOffset": 18, "endOffset": 27}, {"referenceID": 102, "context": "Therefore, fuzzy voxel person was utilized in [103] by employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 46, "endOffset": 51}, {"referenceID": 102, "context": "Extreme body joints viewing conditions were taken into account and it was observed that the fuzzy acquired results were much better than the crisp approach, both qualitatively (as shown in Figure 12) as well as quantitatively [103].", "startOffset": 226, "endOffset": 231}, {"referenceID": 15, "context": "This concept of the fuzzy voxel person was incorporated in a number of works [16, 104].", "startOffset": 77, "endOffset": 86}, {"referenceID": 103, "context": "This concept of the fuzzy voxel person was incorporated in a number of works [16, 104].", "startOffset": 77, "endOffset": 86}, {"referenceID": 104, "context": "In order to solve this, [105, 106] applied FIS to update both the trajectories and the shape estimated for the targets with a set of image regions.", "startOffset": 24, "endOffset": 34}, {"referenceID": 105, "context": "In order to solve this, [105, 106] applied FIS to update both the trajectories and the shape estimated for the targets with a set of image regions.", "startOffset": 24, "endOffset": 34}, {"referenceID": 102, "context": "Red areas are the improved voxel person and the blue areas are the rest of the original crisp voxel person [103].", "startOffset": 107, "endOffset": 112}, {"referenceID": 106, "context": "Kalman filter, the popular optimal estimator capable of operating recursively on the streams of noisy input data [107], is a popular choice for tracking a moving object.", "startOffset": 113, "endOffset": 118}, {"referenceID": 90, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 107, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 108, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 109, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 110, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 111, "context": "It has been successfully applied in several previous works on the human motion tracking [91, 108, 109, 110, 111, 112].", "startOffset": 88, "endOffset": 117}, {"referenceID": 112, "context": "There are three basic steps involved in the Kalman filtering for human motion tracking: initialization, prediction and correction [113].", "startOffset": 130, "endOffset": 135}, {"referenceID": 113, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 114, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 115, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 116, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 117, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 118, "context": "In order to solve this, the FIS was adopted in the Kalman filtering [114, 115, 116, 117, 118, 119] to detect the bias of measurements and prevent the divergence.", "startOffset": 68, "endOffset": 98}, {"referenceID": 119, "context": "To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter.", "startOffset": 16, "endOffset": 21}, {"referenceID": 120, "context": "To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter.", "startOffset": 70, "endOffset": 80}, {"referenceID": 121, "context": "To this extent, [120] proposed the evolving Takagi-Sugeno fuzzy model [121, 122] which can be seen as the fuzzy weighted mixture of the Kalman filter for object tracking in the video streams, and the performance is better than the ordinary Kalman Filter.", "startOffset": 70, "endOffset": 80}, {"referenceID": 122, "context": "As a remedy to the above mentioned problems, a new sequential fuzzy simulation based particle filter was proposed in [123] to estimate the state of a dynamic system with noises described as fuzzy variables using the possibility theory.", "startOffset": 117, "endOffset": 122}, {"referenceID": 122, "context": "[123] found that their proposed fuzzy logic based particle filter outperforms the traditional particle filter even when the number of particles is small.", "startOffset": 0, "endOffset": 5}, {"referenceID": 123, "context": "Another variant of this work is [124], where an adaptive model is implemented in the fuzzy particle filter with the capability to adjust the number of particles by using the result from the measurement step, and improve the speed of an object tracking algorithm.", "startOffset": 32, "endOffset": 37}, {"referenceID": 95, "context": "Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100].", "startOffset": 17, "endOffset": 26}, {"referenceID": 101, "context": "Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100].", "startOffset": 17, "endOffset": 26}, {"referenceID": 99, "context": "Apart from that, [96, 102] handled the tradeoff between the system precision and the computational cost by employing data quantization process that utilizes the Fuzzy Quantity Space [100].", "startOffset": 182, "endOffset": 187}, {"referenceID": 124, "context": "Last but not the least, the FIS has also contributed in the particle filters [125, 126] and achieved better accuracy with lower computational cost.", "startOffset": 77, "endOffset": 87}, {"referenceID": 125, "context": "Last but not the least, the FIS has also contributed in the particle filters [125, 126] and achieved better accuracy with lower computational cost.", "startOffset": 77, "endOffset": 87}, {"referenceID": 126, "context": "Optical flow [127, 128] is another popular motion tracking algorithm.", "startOffset": 13, "endOffset": 23}, {"referenceID": 127, "context": "Optical flow [127, 128] is another popular motion tracking algorithm.", "startOffset": 13, "endOffset": 23}, {"referenceID": 128, "context": "Fuzzy hostility index was introduced in [129, 130] to overcome this issue and thus improving the time efficiency of the flow computation.", "startOffset": 40, "endOffset": 50}, {"referenceID": 129, "context": "Fuzzy hostility index was introduced in [129, 130] to overcome this issue and thus improving the time efficiency of the flow computation.", "startOffset": 40, "endOffset": 50}, {"referenceID": 130, "context": "The fuzzy hostility index [131] measures the amount of homogeneity or heterogeneity of the neighborhood pixel in the optical flow field.", "startOffset": 26, "endOffset": 31}, {"referenceID": 132, "context": "Inspired from this, multi-object cluster trackings [133, 134] were introduced with the belief that the moving targets always produce a particular cluster of pixels with similar characteristics in the feature space, and the distribution of these clusters changes only little between the consecutive frames.", "startOffset": 51, "endOffset": 61}, {"referenceID": 133, "context": "Inspired from this, multi-object cluster trackings [133, 134] were introduced with the belief that the moving targets always produce a particular cluster of pixels with similar characteristics in the feature space, and the distribution of these clusters changes only little between the consecutive frames.", "startOffset": 51, "endOffset": 61}, {"referenceID": 131, "context": "[132] proposed a fast fuzzy c-means (FCM) clustering tracking method which offers a solution towards the high complexity and the computational cost involved in the conventional methods on multi-object tracking, and also the hard clustering algorithms such as the k-means that causes failure in the case of severe occlusions and pervasive disturbances.", "startOffset": 0, "endOffset": 5}, {"referenceID": 131, "context": "In [132], the component quantization filtering was incorporated with FCM to provide faster processing speed.", "startOffset": 3, "endOffset": 8}, {"referenceID": 94, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 95, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 99, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 100, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 101, "context": "[95, 96, 100, 101, 102] Integration of the fuzzy set theory and the fuzzy qualitative reasoning in the kinematic chain representation provides a means of handling the uncertainty in a natural way.", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "[16, 103, 104] Fuzzy voxel person is able to model different types of uncertainties associated with the construction of the voxel person by using the membership functions, employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 0, "endOffset": 14}, {"referenceID": 102, "context": "[16, 103, 104] Fuzzy voxel person is able to model different types of uncertainties associated with the construction of the voxel person by using the membership functions, employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 0, "endOffset": 14}, {"referenceID": 103, "context": "[16, 103, 104] Fuzzy voxel person is able to model different types of uncertainties associated with the construction of the voxel person by using the membership functions, employing only a few cameras and a minimal prior knowledge about the object.", "startOffset": 0, "endOffset": 14}, {"referenceID": 104, "context": "[105, 106] FIS is applied to perform the fuzzy shape estimation to achieve a better tracking performance by taking into account the uncertainty in shape estimation.", "startOffset": 0, "endOffset": 10}, {"referenceID": 105, "context": "[105, 106] FIS is applied to perform the fuzzy shape estimation to achieve a better tracking performance by taking into account the uncertainty in shape estimation.", "startOffset": 0, "endOffset": 10}, {"referenceID": 6, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 7, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 8, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 19, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 20, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 113, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 114, "context": "[7, 8, 9, 20, 21, 114, 115] Fuzzy Kalman filters are capable of solving the divergence problem by incorporating the FIS, and are more robust against the streams of random noisy data inputs.", "startOffset": 0, "endOffset": 27}, {"referenceID": 95, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 101, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 122, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 123, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 124, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 125, "context": "[96, 102, 123, 124, 125, 126] The fuzzy particle filter effectively handles the system complexity by compromising the low number of particles that were used while retaining the tracking performance.", "startOffset": 0, "endOffset": 29}, {"referenceID": 128, "context": "[129, 130] Fuzzy hostility index is used in the optical flow to filter the incoherent optical flow field containing", "startOffset": 0, "endOffset": 10}, {"referenceID": 129, "context": "[129, 130] Fuzzy hostility index is used in the optical flow to filter the incoherent optical flow field containing", "startOffset": 0, "endOffset": 10}, {"referenceID": 131, "context": "[132] FCM tracking algorithm offers more meaningful", "startOffset": 0, "endOffset": 5}, {"referenceID": 134, "context": "The applications of gesture recognition are manifold [135], ranging from the sign language to medical rehabilitation and virtual reality.", "startOffset": 53, "endOffset": 58}, {"referenceID": 135, "context": "The importance of gesture recognition lies in building efficient and intelligent human-computer interaction applications [136] where one can control the system from a distance for a specific task, i.", "startOffset": 121, "endOffset": 126}, {"referenceID": 136, "context": "Also, \u201cpure\u201d gestures are seldom elicited, as people typically demonstrate \u201cblends\u201d of these gestures [137].", "startOffset": 102, "endOffset": 107}, {"referenceID": 137, "context": "This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].", "startOffset": 188, "endOffset": 208}, {"referenceID": 138, "context": "This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].", "startOffset": 188, "endOffset": 208}, {"referenceID": 139, "context": "This solution works better in the challenging environments such as the complex backgrounds, dynamic lighting conditions, and the deformable hand shapes with real-time computational speeds [138, 139, 140, 141].", "startOffset": 188, "endOffset": 208}, {"referenceID": 137, "context": "Using the FCM, [138, 139] worked on a fast respond telerobotic gesture-based user interface system.", "startOffset": 15, "endOffset": 25}, {"referenceID": 138, "context": "Using the FCM, [138, 139] worked on a fast respond telerobotic gesture-based user interface system.", "startOffset": 15, "endOffset": 25}, {"referenceID": 137, "context": "[140] further improved the work [138] in the skin segmentation problem using the color space to solve the skin color variation.", "startOffset": 32, "endOffset": 37}, {"referenceID": 139, "context": "In [141], the spatial information of hand gesture using the FCM was trained in order to determine the partitioning of the trajectory points into a number of clusters with the fuzzy pseudo-boundaries.", "startOffset": 3, "endOffset": 8}, {"referenceID": 140, "context": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition.", "startOffset": 12, "endOffset": 27}, {"referenceID": 141, "context": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition.", "startOffset": 12, "endOffset": 27}, {"referenceID": 142, "context": "A few works [142, 143, 144] on fusing the fuzzy approaches with machine learning solutions have been reported in the gesture recognition.", "startOffset": 12, "endOffset": 27}, {"referenceID": 140, "context": "[142] used the adaptive neuro-fuzzy inference system to recognize the gestures in Arabic sign language.", "startOffset": 0, "endOffset": 5}, {"referenceID": 141, "context": "[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146].", "startOffset": 0, "endOffset": 5}, {"referenceID": 143, "context": "[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146].", "startOffset": 112, "endOffset": 117}, {"referenceID": 144, "context": "[143] introduced a new approach towards gesture recognition based on the idea of incorporating the fuzzy ARTMAP [145] in the feature recognition neural network [146].", "startOffset": 160, "endOffset": 165}, {"referenceID": 142, "context": "Nonetheless, [144] presented an approach with several novelties and advantages as compared to other hybrid solutions.", "startOffset": 13, "endOffset": 18}, {"referenceID": 145, "context": "In the literature of activity recognition, there exists some works [147, 148] that employed the FIS to classify different human activities.", "startOffset": 67, "endOffset": 77}, {"referenceID": 146, "context": "In the literature of activity recognition, there exists some works [147, 148] that employed the FIS to classify different human activities.", "startOffset": 67, "endOffset": 77}, {"referenceID": 145, "context": "Both [147, 148] took into account the uncertainties in both the spatial and temporal features for efficient human behavior recognition.", "startOffset": 5, "endOffset": 15}, {"referenceID": 146, "context": "Both [147, 148] took into account the uncertainties in both the spatial and temporal features for efficient human behavior recognition.", "startOffset": 5, "endOffset": 15}, {"referenceID": 145, "context": "[147] used the spatial and temporal geometry features to study the importance of the spatiotemporal relations such as \u2018IsMoving\u2019, \u2018IsComingCloseTo\u2019, \u2018IsGoingAway\u2019, \u2018IsGoingAlong\u2019 with the objective to", "startOffset": 0, "endOffset": 5}, {"referenceID": 146, "context": "Another work [148] adopted the spatio-temporal features such as the silhouette slices and the movement speed in video sequences as the inputs to the FIS.", "startOffset": 13, "endOffset": 18}, {"referenceID": 147, "context": "Owing to the demands of the development of enhanced video surveillance systems that can automatically understand the human behaviors and identify dangerous activities, [149] introduced a semantic human behavioral analysis system based on the hybridization of the neuro-fuzzy approach.", "startOffset": 168, "endOffset": 173}, {"referenceID": 148, "context": "Another work [150] presented a fuzzy rule-based reasoning approach for event detection and annotation of broadcast soccer video, integrating the Decision Tree and the FIS.", "startOffset": 13, "endOffset": 18}, {"referenceID": 149, "context": "Figure 13: Movements of running (top) and walking (bottom) activities, as well as the associated dynemes which are learned from the FCM [151].", "startOffset": 136, "endOffset": 141}, {"referenceID": 149, "context": "In order to learn the complex actions, [151] represented the human movements as a combination of the smallest constructive unit of human motion patterns called the dyneme (Figure 13).", "startOffset": 39, "endOffset": 44}, {"referenceID": 149, "context": "Dyneme can be learned in an unsupervised manner and in [151], the FCM was chosen.", "startOffset": 55, "endOffset": 60}, {"referenceID": 150, "context": "Then, fuzzy vector quantization (FVQ) [152] as a function that regulates the transition between the crisp and the soft decisions was employed to map an input posture vector into the dyneme space.", "startOffset": 38, "endOffset": 43}, {"referenceID": 95, "context": "Figure 14: Visualization of the QNT model: each of the five activities (walking, running, jogging, one-hand waving (wave1) and two-hands waving(wave2)) from eight subjects (a)-(h) in the quantity space [96].", "startOffset": 202, "endOffset": 206}, {"referenceID": 94, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 60, "endOffset": 69}, {"referenceID": 100, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 60, "endOffset": 69}, {"referenceID": 95, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 84, "endOffset": 93}, {"referenceID": 101, "context": "Utilizing the concept of fuzzy qualitative robot kinematics [95, 101], Chan and Liu [96, 102] built a generative action template, called the Qualitative normalized template (QNT) to perform the human action recognition.", "startOffset": 84, "endOffset": 93}, {"referenceID": 94, "context": "Then, the QNT as illustrated in Figure 14 was constructed according to the fuzzy qualitative robot kinematics framework [95, 101].", "startOffset": 120, "endOffset": 129}, {"referenceID": 100, "context": "Then, the QNT as illustrated in Figure 14 was constructed according to the fuzzy qualitative robot kinematics framework [95, 101].", "startOffset": 120, "endOffset": 129}, {"referenceID": 95, "context": "An empirical comparison with the conventional hidden Markov model (HMM) and fuzzy HMM using both the KTH and the Weizmannn datasets has shown the effectiveness of the proposed solution [96].", "startOffset": 185, "endOffset": 189}, {"referenceID": 151, "context": "Hidden Markov model (HMM) [153] is the statistical Markov model with the state being not directly visible, but the output that is dependent on the state is visible.", "startOffset": 26, "endOffset": 31}, {"referenceID": 152, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 153, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 154, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 155, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 156, "context": "HMM have been widely employed in the human action recognition [154, 155, 156, 157, 158].", "startOffset": 62, "endOffset": 87}, {"referenceID": 157, "context": "[159] pointed out that assigning different observation vectors to the same cluster is possible and if their observation probabilities become the same, consequently, the classification performance may decrease.", "startOffset": 0, "endOffset": 5}, {"referenceID": 157, "context": "[159] utilized this concept for human action recognition and the experiment results demonstrate the effectiveness of the fuzzy HMM in human action recognition, with good recognition accuracy for the similar actions such as \u201cwalk\u201d and \u201crun\u201d.", "startOffset": 0, "endOffset": 5}, {"referenceID": 158, "context": ") [160].", "startOffset": 2, "endOffset": 7}, {"referenceID": 159, "context": "[161] adopted the concept of FVQ and the dyneme, and proposed a novel person specific activity recognition framework to cope with the style invariant problem.", "startOffset": 0, "endOffset": 5}, {"referenceID": 149, "context": "The method is mainly divided into two parts: firstly, the ID of the person is identified, and secondly, the activity is inferred from the person specific fuzzy motion model [151].", "startOffset": 173, "endOffset": 178}, {"referenceID": 160, "context": "Therefore, [162] developed an activity-related biometric authentication system by utilizing the information of different styles by different people.", "startOffset": 11, "endOffset": 16}, {"referenceID": 149, "context": "Improvement was made in the computation of the cumulative fuzzy distances between the vectors and the dynemes that outperforms L1, L2, and Mahalanobis distances which were used previously in [151].", "startOffset": 191, "endOffset": 196}, {"referenceID": 159, "context": "There is a limitation in [161, 162] where a large storage space is required to store the ID of different person and this makes the system impractical.", "startOffset": 25, "endOffset": 35}, {"referenceID": 160, "context": "There is a limitation in [161, 162] where a large storage space is required to store the ID of different person and this makes the system impractical.", "startOffset": 25, "endOffset": 35}, {"referenceID": 158, "context": "An alternative approach was proposed in [160], where a fuzzy descriptor vector was used to represent the human actions of different styles in a single underlying fuzzy action descriptor.", "startOffset": 40, "endOffset": 45}, {"referenceID": 27, "context": "This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46].", "startOffset": 116, "endOffset": 128}, {"referenceID": 44, "context": "This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46].", "startOffset": 116, "endOffset": 128}, {"referenceID": 45, "context": "This problem has received increasing attention in the HMA research and some of the notable works have been reported [28, 45, 46].", "startOffset": 116, "endOffset": 128}, {"referenceID": 161, "context": "Figure 15: (a) A converging eight-view camera setup and its capture volume, and (b) an eight-view video frame [163].", "startOffset": 110, "endOffset": 115}, {"referenceID": 160, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 0, "endOffset": 15}, {"referenceID": 161, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 0, "endOffset": 15}, {"referenceID": 162, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 0, "endOffset": 15}, {"referenceID": 149, "context": "[162, 163, 164] extended [151] to support multi-view action recognition.", "startOffset": 25, "endOffset": 30}, {"referenceID": 149, "context": "Similar to [151], FVQ was utilized to map every multi-view posture pattern to create the multi-view dyneme space.", "startOffset": 11, "endOffset": 16}, {"referenceID": 163, "context": "human action recognition involving two persons [165].", "startOffset": 47, "endOffset": 52}, {"referenceID": 32, "context": "In most of the multi-view action recognition works, there is an argument that performing view invariant human action recognition using multi-camera approach is not practical in real environment [33, 46].", "startOffset": 194, "endOffset": 202}, {"referenceID": 45, "context": "In most of the multi-view action recognition works, there is an argument that performing view invariant human action recognition using multi-camera approach is not practical in real environment [33, 46].", "startOffset": 194, "endOffset": 202}, {"referenceID": 158, "context": "In order to solve this, [160] proposed a fuzzy action recognition framework for multi-view within a single camera.", "startOffset": 24, "endOffset": 29}, {"referenceID": 158, "context": "The dominant features are then identified from the fuzzy qualitative states and represented as a fuzzy descriptor [160].", "startOffset": 114, "endOffset": 119}, {"referenceID": 158, "context": "In the action recognition step, the viewpoint of the person is first estimated and then proceeded with the action recognition by utilizing the viewpoint specific fuzzy descriptor action models [160].", "startOffset": 193, "endOffset": 198}, {"referenceID": 158, "context": "Figure 16: Predefined viewpoints from left to right: \u2018horizontal view\u2019, \u2018diagonal view\u2019 and \u2018vertical view\u2019 [160].", "startOffset": 108, "endOffset": 113}, {"referenceID": 6, "context": "In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167].", "startOffset": 198, "endOffset": 211}, {"referenceID": 164, "context": "In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167].", "startOffset": 198, "endOffset": 211}, {"referenceID": 165, "context": "In our daily life, anomaly detection is important to infer the abnormal behavior of a person, such as an action or an activity that is not following the routine or deviated from the normal behavior [7, 166, 167].", "startOffset": 198, "endOffset": 211}, {"referenceID": 14, "context": "FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities.", "startOffset": 105, "endOffset": 118}, {"referenceID": 15, "context": "FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities.", "startOffset": 105, "endOffset": 118}, {"referenceID": 103, "context": "FIS has been employed in various works for anomaly event detection such as the elderly fall detection in [15, 16, 104], to address the deficiencies and the inherent uncertainty related to modeling and inferring the human activities.", "startOffset": 105, "endOffset": 118}, {"referenceID": 15, "context": "[16] proposed a novel fuzzy rule based method for monitoring the wellness of the elderly people from the video.", "startOffset": 0, "endOffset": 4}, {"referenceID": 103, "context": "This work was an extension of [104] where the linguistic summarizations of the human states (three states: upright, on-the-ground and in-between) based on the voxel person and the FIS were extracted, extended using a hierarchy of the FIS and the linguistic summarization for the inference of the patients\u2019 activities.", "startOffset": 30, "endOffset": 35}, {"referenceID": 166, "context": "The answer is yes where, [168] extended the work to support the additional common elderly activities such as standing, walking, motionless-on-the-chair, and lying-motionless-on-the-couch, with the inclusion of the knowledge about the real world for the identification of the voxels that corresponds to the wall, floor, ceiling, or other static objects or surfaces.", "startOffset": 25, "endOffset": 30}, {"referenceID": 15, "context": "Figure 17: Rule table of the human states (Upright, In Between, On the Ground) with V=Very low, L=Low, M=Medium, and H=high which are used to infer the human activities [16].", "startOffset": 169, "endOffset": 173}, {"referenceID": 167, "context": "[169] proposed a robust fall detection system using FOCSVM with novel 3D features.", "startOffset": 0, "endOffset": 5}, {"referenceID": 168, "context": "FCM, Gustafson and Kessel Clustering, or Gath and Geva Clustering) along with the fuzzy K-nearest neighbor algorithms were employed in [170].", "startOffset": 135, "endOffset": 140}, {"referenceID": 170, "context": "A hybrid model of the FIS and the Fuzzy Associative Memory (FAM) was incorporated in [172], which basically receives an input and assigns a degree of belongingness to a set of rules.", "startOffset": 85, "endOffset": 90}, {"referenceID": 170, "context": "[172] considered the angles of human limbs as the inputs to the FAM with three rules defining the abnormal movement types.", "startOffset": 0, "endOffset": 5}, {"referenceID": 171, "context": "[173] also used the neural fuzzy network hybrid model, compensating the lacking of the learning ability of the fuzzy approaches to recognize human poses (e.", "startOffset": 0, "endOffset": 5}, {"referenceID": 172, "context": "Another paper [174] proposed fuzzy self-organizing neural network (fuzzy SOM) to learn the activity patterns for anomaly detection in visual surveillance.", "startOffset": 14, "endOffset": 19}, {"referenceID": 173, "context": "With the knowledge that \u201csoft\u201d boundaries exist in concepts formation of human beings [175], fuzzy set theory has emerged to become one of the most important methodology in capturing notions.", "startOffset": 86, "endOffset": 91}, {"referenceID": 174, "context": "For example, [176] in their review on computing with uncertainties emphasized on the fact that the integration of fuzzy models always improves the computer performance in pattern recognition problems.", "startOffset": 13, "endOffset": 18}, {"referenceID": 40, "context": "Similarly, [41, 177] presented a survey on how to effectively represent the uncertainty using the FIS.", "startOffset": 11, "endOffset": 20}, {"referenceID": 175, "context": "Similarly, [41, 177] presented a survey on how to effectively represent the uncertainty using the FIS.", "startOffset": 11, "endOffset": 20}, {"referenceID": 176, "context": "[178, 179] explained on how to design an interval type-2 FIS using the uncertainty bounds and introduced the measurement of uncertainty for interval type-2 fuzzy sets using the information such as centroid, cardinality, fuzziness, variance and skewness.", "startOffset": 0, "endOffset": 10}, {"referenceID": 177, "context": "[178, 179] explained on how to design an interval type-2 FIS using the uncertainty bounds and introduced the measurement of uncertainty for interval type-2 fuzzy sets using the information such as centroid, cardinality, fuzziness, variance and skewness.", "startOffset": 0, "endOffset": 10}, {"referenceID": 178, "context": "A comprehensive review on handling the uncertainty in pattern recognition using the type-2 fuzzy approach was provided by [180].", "startOffset": 122, "endOffset": 127}, {"referenceID": 137, "context": "[138, 139, 140, 141] FCM relaxes the learning and recognition of gesture by using soft computing technique.", "startOffset": 0, "endOffset": 20}, {"referenceID": 138, "context": "[138, 139, 140, 141] FCM relaxes the learning and recognition of gesture by using soft computing technique.", "startOffset": 0, "endOffset": 20}, {"referenceID": 139, "context": "[138, 139, 140, 141] FCM relaxes the learning and recognition of gesture by using soft computing technique.", "startOffset": 0, "endOffset": 20}, {"referenceID": 140, "context": "[142, 143, 144] Integration of the fuzzy approaches with machine learning algorithms help in learning the important", "startOffset": 0, "endOffset": 15}, {"referenceID": 141, "context": "[142, 143, 144] Integration of the fuzzy approaches with machine learning algorithms help in learning the important", "startOffset": 0, "endOffset": 15}, {"referenceID": 142, "context": "[142, 143, 144] Integration of the fuzzy approaches with machine learning algorithms help in learning the important", "startOffset": 0, "endOffset": 15}, {"referenceID": 145, "context": "[147, 148] FIS effectively distinguishes the human motion patterns and activity recognition with its flexibil-", "startOffset": 0, "endOffset": 10}, {"referenceID": 146, "context": "[147, 148] FIS effectively distinguishes the human motion patterns and activity recognition with its flexibil-", "startOffset": 0, "endOffset": 10}, {"referenceID": 147, "context": "[149, 150] Integration of fuzzy logic with machine learning techniques allows the generation of the optimum membership function and fuzzy rules to infer the human behavior.", "startOffset": 0, "endOffset": 10}, {"referenceID": 148, "context": "[149, 150] Integration of fuzzy logic with machine learning techniques allows the generation of the optimum membership function and fuzzy rules to infer the human behavior.", "startOffset": 0, "endOffset": 10}, {"referenceID": 149, "context": "[151] FVQ incorporated with FCM is used to model the human movements and provides the flexibility to support complex continuous actions.", "startOffset": 0, "endOffset": 5}, {"referenceID": 95, "context": "[96, 102, 171] QNT fuzzy motion template relaxes the complex-", "startOffset": 0, "endOffset": 14}, {"referenceID": 101, "context": "[96, 102, 171] QNT fuzzy motion template relaxes the complex-", "startOffset": 0, "endOffset": 14}, {"referenceID": 169, "context": "[96, 102, 171] QNT fuzzy motion template relaxes the complex-", "startOffset": 0, "endOffset": 14}, {"referenceID": 157, "context": "[159] Fuzzy HMM models apply soft computing in the training stage which effectively increases the per-", "startOffset": 0, "endOffset": 5}, {"referenceID": 159, "context": "[161, 162] Style invariant action recognition can be achieved by using person specific fuzzy movement model", "startOffset": 0, "endOffset": 10}, {"referenceID": 160, "context": "[161, 162] Style invariant action recognition can be achieved by using person specific fuzzy movement model", "startOffset": 0, "endOffset": 10}, {"referenceID": 158, "context": "[160] Fuzzy descriptor vector allows to accommodate a set of possible descriptor values in each vector di-", "startOffset": 0, "endOffset": 5}, {"referenceID": 160, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 161, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 162, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 163, "context": "[162, 163, 164, 165] Multi-view posture patterns are generated by uti-", "startOffset": 0, "endOffset": 20}, {"referenceID": 158, "context": "[160] Using fuzzy qualitative framework, action recog-", "startOffset": 0, "endOffset": 5}, {"referenceID": 14, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 15, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 103, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 166, "context": "[15, 16, 104, 168] FIS is flexible in customization where the knowl-", "startOffset": 0, "endOffset": 18}, {"referenceID": 167, "context": "[169] FOCSVM is used to reflect the importance of ev-", "startOffset": 0, "endOffset": 5}, {"referenceID": 168, "context": "[170] Fuzzy clustering algorithms (e.", "startOffset": 0, "endOffset": 5}, {"referenceID": 170, "context": "[172, 173, 174] Integration of the fuzzy approaches with machine learning algorithms allows the learning of optimum fuzzy membership functions and fuzzy rules that can adapt to newly encountered problems.", "startOffset": 0, "endOffset": 15}, {"referenceID": 171, "context": "[172, 173, 174] Integration of the fuzzy approaches with machine learning algorithms allows the learning of optimum fuzzy membership functions and fuzzy rules that can adapt to newly encountered problems.", "startOffset": 0, "endOffset": 15}, {"referenceID": 172, "context": "[172, 173, 174] Integration of the fuzzy approaches with machine learning algorithms allows the learning of optimum fuzzy membership functions and fuzzy rules that can adapt to newly encountered problems.", "startOffset": 0, "endOffset": 15}, {"referenceID": 179, "context": "This concept was initiated in [181] where words can be used in place of numbers for computing and reasoning (like done by humans), commonly known as computing with words (CWW).", "startOffset": 30, "endOffset": 35}, {"referenceID": 179, "context": "There are two major imperatives for CWW [181].", "startOffset": 40, "endOffset": 45}, {"referenceID": 180, "context": "The concept of linguistic support is rooted in several papers starting with [182] in which the concepts of a linguistic variable and the granulation were introduced.", "startOffset": 76, "endOffset": 81}, {"referenceID": 179, "context": "[181] threw light on the role played by the fuzzy logic in CWW and vice-versa.", "startOffset": 0, "endOffset": 5}, {"referenceID": 181, "context": "An interesting piece of work on CWW can be found in [183] where the author defined CWW as a symbolic generalization of the fuzzy logic.", "startOffset": 52, "endOffset": 57}, {"referenceID": 103, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 182, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 183, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 184, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 185, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 186, "context": "In the recent years, several papers have been published that utilizes the concept of linguistic summarization in the fuzzy system that are successfully applied in the real world applications [104, 184, 185, 186, 187, 188].", "startOffset": 191, "endOffset": 221}, {"referenceID": 187, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 188, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 189, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 190, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 191, "context": "Several works in the literature have reported efficient methods for the automatic generation of the fuzzy rules such as [189, 190, 191, 192, 193].", "startOffset": 120, "endOffset": 145}, {"referenceID": 187, "context": "For example, [189] proposed a method of generating the fuzzy rules by learning from examples, more specifically by the numerical data.", "startOffset": 13, "endOffset": 18}, {"referenceID": 188, "context": "Similarly, [190] presented an alternative method to generate the fuzzy rules automatically from the training data with their rules defined in the form of possibility, certainty, gradual, and unless rules.", "startOffset": 11, "endOffset": 16}, {"referenceID": 189, "context": "A new approach called the fuzzy extension matrix was proposed in [191] which incorporated the fuzzy entropy to search for the paths and generalized the concept of the crisp extension matrix.", "startOffset": 65, "endOffset": 70}, {"referenceID": 190, "context": "multi-stage random sampling) with its fast performance have also been adopted in the fuzzy rule generation such as the work by [192].", "startOffset": 127, "endOffset": 132}, {"referenceID": 192, "context": "[194] provided an exhaustive survey on the neuro-fuzzy rule generation algorithms, while [193] presented an approach to automatically learn the fuzzy rules by incorporating the genetic algorithm.", "startOffset": 0, "endOffset": 5}, {"referenceID": 191, "context": "[194] provided an exhaustive survey on the neuro-fuzzy rule generation algorithms, while [193] presented an approach to automatically learn the fuzzy rules by incorporating the genetic algorithm.", "startOffset": 89, "endOffset": 94}, {"referenceID": 234, "context": "However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses.", "startOffset": 9, "endOffset": 24}, {"referenceID": 235, "context": "However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses.", "startOffset": 9, "endOffset": 24}, {"referenceID": 236, "context": "However, [238, 239, 240] raised an argument that many situations in the real life are ambiguous, especially the human behavior with varied perceptions of the masses.", "startOffset": 9, "endOffset": 24}, {"referenceID": 237, "context": "Early event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243].", "startOffset": 291, "endOffset": 296}, {"referenceID": 238, "context": "Early event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243].", "startOffset": 327, "endOffset": 337}, {"referenceID": 239, "context": "Early event detection: Apart from that, fuzzy approaches being successful in handling the uncertainties in various real-time applications as highlighted in this survey, can be very well explored to be potentially applied in highly complex HMA applications such as human activity forecasting [241] and early detection of crimes [242, 243].", "startOffset": 327, "endOffset": 337}, {"referenceID": 37, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 9, "endOffset": 13}, {"referenceID": 101, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 14, "endOffset": 28}, {"referenceID": 95, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 14, "endOffset": 28}, {"referenceID": 162, "context": "KTH 2004 [38] [102, 96, 164] RA = 93.", "startOffset": 14, "endOffset": 28}, {"referenceID": 162, "context": "52 [164] RA = 96.", "startOffset": 3, "endOffset": 8}, {"referenceID": 193, "context": "76 [195]", "startOffset": 3, "endOffset": 8}, {"referenceID": 194, "context": "CAVIAR 2004 [196] TP = 91.", "startOffset": 12, "endOffset": 17}, {"referenceID": 195, "context": "90 [197]", "startOffset": 3, "endOffset": 8}, {"referenceID": 39, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 22, "endOffset": 26}, {"referenceID": 146, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 157, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 149, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 101, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 95, "context": "WEIZMANN Actions 2005 [40] [148, 159, 151, 102, 96] RA = 100.", "startOffset": 27, "endOffset": 51}, {"referenceID": 95, "context": "00 [96] RA = 100.", "startOffset": 3, "endOffset": 7}, {"referenceID": 196, "context": "00 [198]", "startOffset": 3, "endOffset": 8}, {"referenceID": 44, "context": "IXMAS 2006 [45] [163, 160] RA = 83.", "startOffset": 11, "endOffset": 15}, {"referenceID": 161, "context": "IXMAS 2006 [45] [163, 160] RA = 83.", "startOffset": 16, "endOffset": 26}, {"referenceID": 158, "context": "IXMAS 2006 [45] [163, 160] RA = 83.", "startOffset": 16, "endOffset": 26}, {"referenceID": 161, "context": "47 [163] RA = 95.", "startOffset": 3, "endOffset": 8}, {"referenceID": 197, "context": "54 [199]", "startOffset": 3, "endOffset": 8}, {"referenceID": 198, "context": "CASIA Action 2007 [200] RA = 99.", "startOffset": 18, "endOffset": 23}, {"referenceID": 199, "context": "90 [201]", "startOffset": 3, "endOffset": 8}, {"referenceID": 200, "context": "ETISEO 2007 [202] TP = 100.", "startOffset": 12, "endOffset": 17}, {"referenceID": 201, "context": "00 [203]", "startOffset": 3, "endOffset": 8}, {"referenceID": 202, "context": "UIUC - Complex action 2007 [204] [171] RA > 80.", "startOffset": 27, "endOffset": 32}, {"referenceID": 169, "context": "UIUC - Complex action 2007 [204] [171] RA > 80.", "startOffset": 33, "endOffset": 38}, {"referenceID": 169, "context": "00 [171] UIUC 2008 [205] RA = 93.", "startOffset": 3, "endOffset": 8}, {"referenceID": 203, "context": "00 [171] UIUC 2008 [205] RA = 93.", "startOffset": 19, "endOffset": 24}, {"referenceID": 204, "context": "30 [206]", "startOffset": 3, "endOffset": 8}, {"referenceID": 149, "context": "CMU MoCap 2008 [207] [151] RA = 98.", "startOffset": 21, "endOffset": 26}, {"referenceID": 149, "context": "90 [151] RA = 98.", "startOffset": 3, "endOffset": 8}, {"referenceID": 205, "context": "30 [208]", "startOffset": 3, "endOffset": 8}, {"referenceID": 206, "context": "ViHASi 2008 [209] RA = 72.", "startOffset": 12, "endOffset": 17}, {"referenceID": 207, "context": "00 [210]", "startOffset": 3, "endOffset": 8}, {"referenceID": 208, "context": "HOLLYWOOD 2008 [211] RA = 61.", "startOffset": 15, "endOffset": 20}, {"referenceID": 209, "context": "50 [212]", "startOffset": 3, "endOffset": 8}, {"referenceID": 210, "context": "HOLLYWOOD-2 2009 [213] RA = 64.", "startOffset": 17, "endOffset": 22}, {"referenceID": 211, "context": "30 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 212, "context": "UCF-Sports 2008 [215] [164] RA = 85.", "startOffset": 16, "endOffset": 21}, {"referenceID": 162, "context": "UCF-Sports 2008 [215] [164] RA = 85.", "startOffset": 22, "endOffset": 27}, {"referenceID": 162, "context": "77 [164] RA = 89.", "startOffset": 3, "endOffset": 8}, {"referenceID": 213, "context": "70 [216]", "startOffset": 3, "endOffset": 8}, {"referenceID": 214, "context": "UCF-11 Youtube 2009 [217] RA = 89.", "startOffset": 20, "endOffset": 25}, {"referenceID": 193, "context": "79 [195]", "startOffset": 3, "endOffset": 8}, {"referenceID": 215, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 13, "endOffset": 18}, {"referenceID": 161, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 19, "endOffset": 34}, {"referenceID": 163, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 19, "endOffset": 34}, {"referenceID": 162, "context": "i3DPost 2009 [218] [163, 165, 164] RA = 100.", "startOffset": 19, "endOffset": 34}, {"referenceID": 162, "context": "00 [164] RA = 98.", "startOffset": 3, "endOffset": 8}, {"referenceID": 216, "context": "44 [219]", "startOffset": 3, "endOffset": 8}, {"referenceID": 217, "context": "UT-Interaction 2009 [220] RA = 91.", "startOffset": 20, "endOffset": 25}, {"referenceID": 196, "context": "67 [221] UT-Tower 2009 [198] -", "startOffset": 23, "endOffset": 28}, {"referenceID": 218, "context": "MSR Action 2009 [222] MSR 3D Action 2010 [223] RA = 97.", "startOffset": 16, "endOffset": 21}, {"referenceID": 219, "context": "MSR Action 2009 [222] MSR 3D Action 2010 [223] RA = 97.", "startOffset": 41, "endOffset": 46}, {"referenceID": 220, "context": "80 [224]", "startOffset": 3, "endOffset": 8}, {"referenceID": 221, "context": "BEHAVE 2010 [225] RA = 65.", "startOffset": 12, "endOffset": 17}, {"referenceID": 222, "context": "50 [226]", "startOffset": 3, "endOffset": 8}, {"referenceID": 223, "context": "MuHAVi 2010 [227] RA = 100.", "startOffset": 12, "endOffset": 17}, {"referenceID": 224, "context": "00 [228]", "startOffset": 3, "endOffset": 8}, {"referenceID": 225, "context": "Olympic Sports 2010 [229] RA = 91.", "startOffset": 20, "endOffset": 25}, {"referenceID": 211, "context": "10 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 226, "context": "TV Human Interaction 2010 [230] RA = 46.", "startOffset": 26, "endOffset": 31}, {"referenceID": 227, "context": "00 [231]", "startOffset": 3, "endOffset": 8}, {"referenceID": 228, "context": "HMDB51 2011 [232] RA = 57.", "startOffset": 12, "endOffset": 17}, {"referenceID": 211, "context": "20 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 229, "context": "VideoWeb 2011 [233] RA = 72.", "startOffset": 14, "endOffset": 19}, {"referenceID": 230, "context": "00 [234]", "startOffset": 3, "endOffset": 8}, {"referenceID": 231, "context": "UCF-101 2012 [235] RA = 83.", "startOffset": 13, "endOffset": 18}, {"referenceID": 232, "context": "50 [236]", "startOffset": 3, "endOffset": 8}, {"referenceID": 233, "context": "UCF-50 2013 [237] RA = 91.", "startOffset": 12, "endOffset": 17}, {"referenceID": 211, "context": "20 [214]", "startOffset": 3, "endOffset": 8}, {"referenceID": 240, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 241, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 242, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 243, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 244, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 245, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 246, "context": "computer vision community [244, 245, 246, 247, 248, 249, 250], but as to our very best knowledge, none was found in the fuzzy domain.", "startOffset": 26, "endOffset": 61}, {"referenceID": 247, "context": "For example, [251] proposed a method to recognize the human-object interactions in still images by explicitly modeling the mutual context between the human poses and the objects, so that each can facilitate the recognition of the other.", "startOffset": 13, "endOffset": 18}], "year": 2014, "abstractText": "Human Motion Analysis (HMA) is currently one of the most popularly active research domains as such significant research interests are motivated by a number of real world applications such as video surveillance, sports analysis, healthcare monitoring and so on. However, most of these real world applications face high levels of uncertainties that can affect the operations of such applications. Hence, the fuzzy set theory has been applied and showed great success in the recent past. In this paper, we aim at reviewing the fuzzy set oriented approaches for HMA, individuating how the fuzzy set may improve the HMA, envisaging and delineating the future perspectives. To the best of our knowledge, there is not found a single survey in the current literature that has discussed and reviewed fuzzy approaches towards the HMA. For ease of understanding, we conceptually classify the human motion into three broad levels: Low-Level (LoL), Mid-Level (MiL), and High-Level (HiL) HMA.", "creator": "LaTeX with hyperref package"}}}