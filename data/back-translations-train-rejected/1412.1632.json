{"id": "1412.1632", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2014", "title": "Deep Learning for Answer Sentence Selection", "abstract": "Answer sentence selection is the task of identifying sentences that contain the answer to a given question. This is an important problem in its own right as well as in the larger context of open domain question answering. We propose a novel approach to solving this task via means of distributed representations, and learn to match questions with answers by considering their semantic encoding. This contrasts prior work on this task, which typically relies on classifiers with large numbers of hand-crafted syntactic and semantic features and various external resources. Our approach does not require any feature engineering nor does it involve specialist linguistic data, making this model easily applicable to a wide range of domains and languages. Experimental results on a standard benchmark dataset from TREC demonstrate that---despite its simplicity---our model matches state of the art performance on the answer sentence selection task.", "histories": [["v1", "Thu, 4 Dec 2014 11:53:02 GMT  (64kb)", "http://arxiv.org/abs/1412.1632v1", "9 pages, accepted by NIPS deep learning workshop"]], "COMMENTS": "9 pages, accepted by NIPS deep learning workshop", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lei yu", "karl moritz hermann", "phil blunsom", "stephen pulman"], "accepted": false, "id": "1412.1632"}, "pdf": {"name": "1412.1632.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for Answer Sentence Selection", "authors": ["Lei Yu Karl Moritz", "Hermann Phil Blunsom", "Stephen Pulman"], "emails": ["lei.yu@cs.ox.ac.uk", "phil.blunsom@cs.ox.ac.uk", "stephen.pulman@cs.ox.ac.uk", "kmh@google.com"], "sections": [{"heading": null, "text": "ar Xiv: 141 2.16 32v1 [cs.CL] 4 Dec 2"}, {"heading": "1 Introduction", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Related work", "text": "There are three types of work that are relevant to our approach. We first have the methods of distributional semantics and then the existing work in terms of selecting the answers. Finally, we find that working on the neural networks leads to questions of answering questions."}, {"heading": "3 Model description", "text": "The selection of the answer set can be regarded as a binary classification problem. Let's assume a set of questions q = q, each question q being associated with a list of answer sets {ai1, ai2, \u00b7 \u00b7, ziel}, along with their judgments {yi1, yi2, \u00b7 \u00b7, yim}, where yij = 1 if the answer is correct and yij = 0 otherwise. While this could be approached as a multiple marking task, we simply treat each data point as a triple (qi, aij, yij). Our task is therefore to learn a classifier about these triples so that he can predict the judgments of each additional QA pairing. Our solution to this problem is based on the assumption that correct answers have a high semantic similarity to questions. Unlike previous work where similarity was measured mainly with syntactic information and handmade semantic resources are used, we model questions and answers as vectors."}, {"heading": "3.1 Bag-of-words model", "text": "For word embedding, the sack-of-words model generates the vector representation of a sentence by adding up the embedding of all words in the sentence - after previously removing stopwords from the input. The vector is then normalized by the length of the sentence."}, {"heading": "3.2 Bigram model", "text": "In order to solve this problem, we also evaluate a sentence model based on a revolutionary neural network (CNN), which has the advantage that it is sensitive to word orders and able to capture features of n-grams regardless of their positions in sentences. Furthermore, the revolutionary network can learn to match the internal syntactic structure of sentences, eliminating dependence on external resources such as parse trees [13]. Finally, the convolution and pooling layers help us to grasp far-reaching dependencies that are common in questions. CNN-based models have proven effective in applications such as semantic role labeling [5], twitter sentimental predictions [13] and semantic parses [23]. Figure 1 illustrates the architecture of the CNN-based sentence model in one dimension."}, {"heading": "4 Experiments", "text": "We evaluated both models presented in this paper using a standard dataset for the selection of answers. We introduce the dataset briefly before describing our experimental setup. Finally, we report on our results and compare them with previous work."}, {"heading": "4.1 TREC Answer Selection Dataset", "text": "Wang et al. [20] created this dataset from the QA-Track data (8-13) of the Text REtrieval Conference (TREC), where candidates \"answers were automatically selected from the document pool of each question. Answer candidates were selected based on a combination of overlapping word count and sample matching, and then the correctness of candidates\" answers was manually assessed for parts of the dataset. Table 1 summarizes the dataset of the answer selection and describes the turn / developer / test split of the data. The TRAIN-ALL training set - which is significantly larger than any other part of the data - is loud because the answers were automatically labeled using sample matching. The task is to evaluate candidates \"answers based on their affiliation with the question and is therefore measured in Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR), with the answers in the MRR measurements larger than the answers in the MRR measurements, as all the results are correct in the MRR measurements."}, {"heading": "4.2 Experimental setup", "text": "We used word embeddings (d = 50) calculated using the neural language model of Collobert and Weston [5] and provided by Turian et al. [18]. Although our objective function would allow us to learn word embeddings directly, we determined these representations given the small size of the QA selection dataset. The other model weights were randomly initialized using a Gaussian distribution (\u00b5 = 0, \u03c3 = 0.01). All hyperparameters were optimized using the grid search on the MAP score of the development dataset. We use the AdaGrad algorithm [6] for training. A weakness of the distributed approach is that - unlike symbolic approaches - distributed representations are not very well equipped to handle cardinal numbers and correct nouns, especially taking into account the small datasets. As these are important artefacts in answering tasks, we mitigate the problem by using the second word answer together."}, {"heading": "4.3 Results", "text": "Table 2 summarizes the results of our models. As can be seen, the Bigram model improves the performance of both models by 10% - 15%. Wang et al. [20] reported that the training with the loud data set TRAIN-ALL negatively affected their models, except for our models in which the performance of the models increased. Table 3 includes the published results for this task and puts our best models in the context of the current state of the art. The table also contains three baseline models provided in [22]. The first model randomly assigns values to each answer. The second model counts the number of words that occur in each QA pair simultaneously, with a different version of this baseline weighting these word numbers by IDF values. As shown in Table 3, our best models (Bigram + number) perform better than all baselines and previous work on MAP and come very close to the best model YYet by comparing the results of our ixh selection with those of our task."}, {"heading": "5 Discussion", "text": "As explained in the background of this paper, most previous work has focused on syntactical analysis, with semantic aspects mainly being taken into account through a number of manually developed functions and external resources such as WordNet. Interestingly, however, the best performance pub-lished model is also the only piece of previous work that is primarily focused on semantics [22]. In their model, they combine a group of word matching functions with semantic properties derived from a wide range of linguistic resources such as WordNet, Polarity-inducing latent semantic analysis (PILSA) model to represent sentences used for classification. They combine a group of word matching functions with semantic properties derived from a wide range of linguistic resources including WordNet, Polarity-inducing latent semantic analysis (24) model and various vector space models.When considering the relevance of these models to relative simplicity, our models are highly relevant."}, {"heading": "6 Conclusion", "text": "This paper demonstrated the effectiveness of applying distribution set models to sentence selection. We projected questions and answers in vectors and learned a semantic matching function between QA pairs, and then combined this function with a simple, weighted QA co-occurence counter.We demonstrated that this approach significantly improves performance over the original count-based base model using a sack-of-words sentence model. By using a more complex sentence model based on a Convolutionary Neural Network via bigrams, we improved performance even further and reached the state of the art in the response selection task. Compared to previous work based on feature engineering and external handcoded semantic resources, our approach is much simpler and more flexible. As the selection of answers is comparable to text sets, we would like to investigate, for example, a convolutionary network-based sentence model with higher order n-programs and multiple character cards, as well as neural network recursive models."}, {"heading": "Acknowledgment", "text": "We thank Wen-tau Yih and Xuchen Yao for sharing the dataset to select solution sets. This work was supported by an Xerox Foundation Award and EPSRC grant number EP / K036580 / 1."}], "references": [{"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent"], "venue": "In Proceedings of NIPS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Question answering with subgraph embeddings", "author": ["Antoine Bordes", "Sumit Chopra", "Jason Weston"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Open question answering with weakly supervised embedding models", "author": ["Antoine Bordes", "Jason Weston", "Nicolas Usunier"], "venue": "In Proceedings of ECML,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A compositional distributional model of meaning", "author": ["Stephen Clark", "Bob Coecke", "Mehrnoosh Sadrzadeh"], "venue": "Proceedings of the Second Symposium on Quantum Interaction,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "A unified architecture for natural language processing: deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of ICML,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John C. Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Explorations in Automatic Thesaurus Discovery", "author": ["Gregory Grefenstette"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Tree edit models for recognizing textual entailments, paraphrases, and answers to questions", "author": ["Michael Heilman", "Noah A. Smith"], "venue": "In Proceedings of NAACL,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "The role of syntax in vector space models of compositional semantics", "author": ["Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proceedings of ACL,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Multilingual Distributed Representations without Word Alignment", "author": ["Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proceedings of ICLR,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Multilingual Models for Compositional Distributional Semantics", "author": ["Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proceedings of ACL,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "A neural network for factoid question answering over paragraphs", "author": ["Mohit Iyyer", "Jordan Boyd-Graber", "Leonardo Claudino", "Richard Socher", "Hal Daum\u00e9 III"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom"], "venue": "In Proceedings of ACL,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Finding predominant word senses in untagged text", "author": ["Diana McCarthy", "Rob Koeling", "Julie Weeds", "John A. Carroll"], "venue": "In Proceedings of ACL,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Automatic feature engineering for answer selection and extraction", "author": ["Aliaksei Severyn", "Alessandro Moschitti"], "venue": "In EMNLP,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Quasi-synchronous grammars: Alignment by soft projection of syntactic dependencies", "author": ["David A Smith", "Jason Eisner"], "venue": "In Proceedings of the Workshop on Statistical Machine Translation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Richard Socher", "Brody Huval", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In Proceedings of EMNLP-CoNLL,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Joseph P. Turian", "Lev-Arie Ratinov", "Yoshua Bengio"], "venue": "In Proceedings of ACL,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Probabilistic tree-edit models with structured latent variables for textual entailment and question answering", "author": ["Mengqiu Wang", "Christopher D Manning"], "venue": "In Proceedings of COLING,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "What is the jeopardy model? a quasisynchronous grammar for qa", "author": ["Mengqiu Wang", "Noah A Smith", "Teruko Mitamura"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Answer extraction as sequence tagging with tree edit distance", "author": ["Xuchen Yao", "Benjamin Van Durme", "Peter Clark"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Question answering using enhanced lexical semantic models", "author": ["Wen-tau Yih", "Ming-Wei Chang", "Christopher Meek", "Andrzej Pastusiak"], "venue": "In Proceedings of ACL,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Semantic parsing for single-relation question answering", "author": ["Wen-tau Yih", "Xiaodong He", "Christopher Meek"], "venue": "In Proceedings of ACL,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Polarity inducing latent semantic analysis", "author": ["Wen-tau Yih", "Geoffrey Zweig", "John C Platt"], "venue": "In Proceedings of EMNLP-CoNLL,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}], "referenceMentions": [{"referenceID": 19, "context": "This can be achieved with generative models that syntactically transform answers to questions [20, 19].", "startOffset": 94, "endOffset": 102}, {"referenceID": 18, "context": "This can be achieved with generative models that syntactically transform answers to questions [20, 19].", "startOffset": 94, "endOffset": 102}, {"referenceID": 7, "context": "Another option is discriminative models over features produced from minimal edit sequences between dependency parse trees [8, 21].", "startOffset": 122, "endOffset": 129}, {"referenceID": 20, "context": "Another option is discriminative models over features produced from minimal edit sequences between dependency parse trees [8, 21].", "startOffset": 122, "endOffset": 129}, {"referenceID": 21, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "At the same time, neural network-based distributional sentence models have achieved successes in many natural language processing tasks such as sentiment analysis [9, 13], paraphrase detection [17] and document classification [11, 10].", "startOffset": 163, "endOffset": 170}, {"referenceID": 12, "context": "At the same time, neural network-based distributional sentence models have achieved successes in many natural language processing tasks such as sentiment analysis [9, 13], paraphrase detection [17] and document classification [11, 10].", "startOffset": 163, "endOffset": 170}, {"referenceID": 16, "context": "At the same time, neural network-based distributional sentence models have achieved successes in many natural language processing tasks such as sentiment analysis [9, 13], paraphrase detection [17] and document classification [11, 10].", "startOffset": 193, "endOffset": 197}, {"referenceID": 10, "context": "At the same time, neural network-based distributional sentence models have achieved successes in many natural language processing tasks such as sentiment analysis [9, 13], paraphrase detection [17] and document classification [11, 10].", "startOffset": 226, "endOffset": 234}, {"referenceID": 9, "context": "At the same time, neural network-based distributional sentence models have achieved successes in many natural language processing tasks such as sentiment analysis [9, 13], paraphrase detection [17] and document classification [11, 10].", "startOffset": 226, "endOffset": 234}, {"referenceID": 11, "context": "Another line of work\u2014closely related to the model presented here\u2014is the application of recursive neural networks to factoid question answering over paragraphs [12].", "startOffset": 159, "endOffset": 163}, {"referenceID": 6, "context": "They have been proved to be successful in applications such as relation extraction [7] and word sense disambiguation [14].", "startOffset": 83, "endOffset": 86}, {"referenceID": 13, "context": "They have been proved to be successful in applications such as relation extraction [7] and word sense disambiguation [14].", "startOffset": 117, "endOffset": 121}, {"referenceID": 4, "context": "An alternative method for learning distributed representations comes in the form of neural language models, where the link to distributional data is somewhat more obscure [5, 1].", "startOffset": 171, "endOffset": 177}, {"referenceID": 0, "context": "An alternative method for learning distributed representations comes in the form of neural language models, where the link to distributional data is somewhat more obscure [5, 1].", "startOffset": 171, "endOffset": 177}, {"referenceID": 3, "context": "Popular ideas for this include exploiting category theory [4], using parse trees in conjunction with recursive autoencoders [17, 9], and convolutional neural networks [5, 13].", "startOffset": 58, "endOffset": 61}, {"referenceID": 16, "context": "Popular ideas for this include exploiting category theory [4], using parse trees in conjunction with recursive autoencoders [17, 9], and convolutional neural networks [5, 13].", "startOffset": 124, "endOffset": 131}, {"referenceID": 8, "context": "Popular ideas for this include exploiting category theory [4], using parse trees in conjunction with recursive autoencoders [17, 9], and convolutional neural networks [5, 13].", "startOffset": 124, "endOffset": 131}, {"referenceID": 4, "context": "Popular ideas for this include exploiting category theory [4], using parse trees in conjunction with recursive autoencoders [17, 9], and convolutional neural networks [5, 13].", "startOffset": 167, "endOffset": 174}, {"referenceID": 12, "context": "Popular ideas for this include exploiting category theory [4], using parse trees in conjunction with recursive autoencoders [17, 9], and convolutional neural networks [5, 13].", "startOffset": 167, "endOffset": 174}, {"referenceID": 10, "context": "More recently, sentence models constructed from parallel corpora [11] point to a new trend in compositional distributional semantics, where word- and sentence-level representations are learned given a joint semantic objective function.", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "[20] built a generative model to match the dependency trees of question answer pairs based on the soft alignment of a quasisynchronous grammar [16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[20] built a generative model to match the dependency trees of question answer pairs based on the soft alignment of a quasisynchronous grammar [16].", "startOffset": 143, "endOffset": 147}, {"referenceID": 18, "context": "Wang and Manning [19] proposed another probabilistic model based on Conditional Random Fields, which models alignment as a set of tree-edit operations of dependency trees.", "startOffset": 17, "endOffset": 21}, {"referenceID": 7, "context": "Heilman and Smith [8] used a tree kernel as a heuristic to search for the minimal edit sequences between parse trees.", "startOffset": 18, "endOffset": 21}, {"referenceID": 20, "context": "[21] extended Heilman and Smith\u2019s approach with the difference that they used dynamic programming to find the optimal tree edit sequences.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "synonym, antonym, hypernym) as explicit features, the focus of all of this work is primarily on syntactic information [22].", "startOffset": 118, "endOffset": 122}, {"referenceID": 21, "context": "[22] applied rich lexical semantics to their state-of-the-art QA matching models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "A variation of this idea can also be found in Severyn and Moschitti [15], who used an SVM with tree kernels to automatically learn features from shallow parse trees rather than relying on external resources, sacrificing semantic information for model simplicity.", "startOffset": 68, "endOffset": 72}, {"referenceID": 22, "context": "[23], who constructed models for single-relation question answering with a knowledge base of triples.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3, 2] used a type of siamese network for learning to project question and answer pairs into a joint space.", "startOffset": 0, "endOffset": 6}, {"referenceID": 1, "context": "[3, 2] used a type of siamese network for learning to project question and answer pairs into a joint space.", "startOffset": 0, "endOffset": 6}, {"referenceID": 11, "context": "[12] worked on the quiz bowl task, a question answering task that requires identifying an entity as described by a series of sentences.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3], given the vector representations of a question q and an answer a (both in R), the probability of the answer being correct is p(y = 1|q, a) = \u03c3(q Ma+ b), (1)", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Further, the convolutional network can learn to correspond to the internal syntactic structure of sentences, removing reliance on external resources such as parse trees [13].", "startOffset": 169, "endOffset": 173}, {"referenceID": 4, "context": "CNN-based models have been proved to be effective in applications such as semantic role labelling [5], twitter sentiment prediction [13] and semantic parsing [23].", "startOffset": 98, "endOffset": 101}, {"referenceID": 12, "context": "CNN-based models have been proved to be effective in applications such as semantic role labelling [5], twitter sentiment prediction [13] and semantic parsing [23].", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "CNN-based models have been proved to be effective in applications such as semantic role labelling [5], twitter sentiment prediction [13] and semantic parsing [23].", "startOffset": 158, "endOffset": 162}, {"referenceID": 19, "context": "[20] created this dataset from Text REtrieval Conference (TREC) QA track (8-13) data, with candidate answers automatically selected from each question\u2019s document pool.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "We used word embeddings (d = 50) that were computed using Collobert and Weston\u2019s neural language model [5] and provided by Turian et al.", "startOffset": 103, "endOffset": 106}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "We use the AdaGrad algorithm [6] for training.", "startOffset": 29, "endOffset": 32}, {"referenceID": 19, "context": "[20] reported that training with the noisy dataset TRAIN-ALL negatively impacted their models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The table also includes three baseline models provided in [22].", "startOffset": 58, "endOffset": 62}, {"referenceID": 21, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "lished model is also the only piece of prior work that is primarily focused on semantics [22].", "startOffset": 89, "endOffset": 93}, {"referenceID": 23, "context": "They combine a group of word matching features with semantic features obtained from a wide range of linguistic resources including WordNet, polarity-inducing latent semantic analysis (PILSA) model [24] and different vector space models.", "startOffset": 197, "endOffset": 201}], "year": 2014, "abstractText": "Answer sentence selection is the task of identifying sentences that contain the answer to a given question. This is an important problem in its own right as well as in the larger context of open domain question answering. We propose a novel approach to solving this task via means of distributed representations, and learn to match questions with answers by considering their semantic encoding. This contrasts prior work on this task, which typically relies on classifiers with large numbers of hand-crafted syntactic and semantic features and various external resources. Our approach does not require any feature engineering nor does it involve specialist linguistic data, making this model easily applicable to a wide range of domains and languages. Experimental results on a standard benchmark dataset from TREC demonstrate that\u2014despite its simplicity\u2014our model matches state of the art performance on the answer sentence selection task.", "creator": "LaTeX with hyperref package"}}}