{"id": "1412.2221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Dec-2014", "title": "Declarative Statistical Modeling with Datalog", "abstract": "Formalisms for specifying statistical models, such as probabilistic-programming languages, typically consist of two components: a specification of a stochastic process (the prior), and a specification of observations that restrict the probability space to a conditional subspace (the posterior). Use cases of such formalisms include the development of algorithms in machine learning and artificial intelligence. We propose and investigate a declarative framework for specifying statistical models on top of a database, through an appropriate extension of Datalog. By virtue of extending Datalog, our framework offers a natural integration with the database, and has a robust declarative semantics. Our Datalog extension provides convenient mechanisms to include numerical probability functions; in particular, conclusions of rules may contain values drawn from such functions. The semantics of a program is a probability distribution over the possible outcomes of the input database with respect to the program; these outcomes are minimal solutions with respect to a related program with existentially quantified variables in conclusions. Observations are naturally incorporated by means of integrity constraints over the extensional and intensional relations. We focus on programs that use discrete numerical distributions, but even then the space of possible outcomes may be uncountable (as a solution can be infinite). We define a probability measure over possible outcomes by applying the known concept of cylinder sets to a probabilistic chase procedure. We show that the resulting semantics is robust under different chases. We also identify conditions guaranteeing that all possible outcomes are finite (and then the probability space is discrete). We argue that the framework we propose retains the purely declarative nature of Datalog, and allows for natural specifications of statistical models.", "histories": [["v1", "Sat, 6 Dec 2014 11:04:14 GMT  (46kb)", "https://arxiv.org/abs/1412.2221v1", "14 pages, 4 figures"], ["v2", "Mon, 5 Jan 2015 19:49:24 GMT  (48kb)", "http://arxiv.org/abs/1412.2221v2", "14 pages, 4 figures"]], "COMMENTS": "14 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.DB cs.AI cs.PL", "authors": ["vince barany", "balder ten cate", "benny kimelfeld", "dan olteanu", "zografoula vagena"], "accepted": false, "id": "1412.2221"}, "pdf": {"name": "1412.2221.pdf", "metadata": {"source": "CRF", "title": "Declarative Statistical Modeling with Datalog", "authors": ["Vince Barany"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 141 2,22 21v2 [cs.DB] 5 Jan 201 5"}, {"heading": "1. INTRODUCTION", "text": "This year is the highest in the history of the country."}, {"heading": "2. PRELIMINARIES", "text": "In this section, we will give some preliminary definitions that we will use throughout the database. Schemes and instances of this kind will be more intensive. A (relational) schema is a collection of relation symbols in which each relation symbol R is associated with an arty, which is a natural number. An attribute of a ratio symbol R is any number in {1,..., arty (R), where R is an n-ary relationship in S and c1.., cn) An instance that we assume can be translated into real numbers. A fact above a scheme S is an expression of the form R (c1,.., cn) where R is an n-ary relationship in S and c1., cn) an instance I over S is a finite set of facts about S. We will call the set of all tuples (c1,., cn) that way."}, {"heading": "3. GENERATIVE DATALOG", "text": "A Datalog program without existential quantifiers specifies how to get a solution from an input EDB instance by generating the set of inferred IDB facts. In this section, we present generative Datalog programs that specify how to derive a distribution of possible results from an input EDB instance."}, {"heading": "3.1 Syntax", "text": "We first define the syntax of a generative datalog program, which we call the GDatalog [\u2206] program.Definition 3.1 (GDatalog [\u0445]). Let us pass a finite set of parameterized numerical distributions.1. A \u0394- term is a term of the form \u03b4 [p1,..., pk], which is a parameterized formula R (t1,.., tn) with parameterized numerical distributions, and p1,.., pk are variables and / or constants. 2. An \u2206 - atom in a scheme S is an atomic formula R (t1,.., tn) with R-S being an n-ary relationship, so that exactly one term ti (1 \u2264 i \u2264 n) is a term, and all other tj constants and / or variables in a scheme S. 3. A GDatalog [\u0394] rules a pair of common schemes E, and a first sentence I is the one."}, {"heading": "3.2 Possible Outcomes", "text": "To define the possible results of a GDatalog program, we associate a (3.5) fact with each GDatalog program. (3) The possible results of an input instance I w.r.t. G are then superseded by minimum solutions of I w.r.t. G. The schema I deviating terms are replaced by minimum solutions of I w.r.t. G. (4) Next, we describe I.P. deviating terms and minimum solutions of I w.r.t. G. (4) The schema I deviating terms extends to the following additional relation symbols: Whenever a rule in the form R contains (.) a minimum solution of the form R (.), [.], and i \u2264 Art.i (R) is the argument position at which the term in question occurs, then we add to I a corresponding relation symbol R.i, the arc of which is the arc (R) + parameter. These relation symbols R.i are called the distribution symbols of I."}, {"heading": "3.3 Finiteness and Weak Acyclicity", "text": "Our presentation focuses first on the case in which all possible results for the GDatalog program are finite. Before we move on to the definition of the semantics of such a GDatalog program, we present the concept of weak cyclicity for a GDatalog program as a natural syntactic property that guarantees the finiteness of all possible results, based on the concept of weak cyclicity for Datalog [18]. Let us consider any GDatalog program G = (E, I). A position of I is a pair (R, i), where R, I, and i is an attribute of R. The dependency graph of G is the directed graph that has the attributes of I as a node and the following edges: \u2022 A normal edge (R, i) \u2192 (S, j) is a pair (R, i), where R, I is an attribute of R. The dependence graph of G is the directed graph that has the attributes of I as a node, the following edges (S), the following edges (S), and a pair (S)."}, {"heading": "3.4 Probabilistic Semantics", "text": "Intuitively, we define the weight of a GDatalog (f) to be (J) a function that causes each instance (J) to have a probability distribution over a certain number of persons (I). Let G be a GDatalog (I), then let me have an input for G. Again, let's first consider the case in which an instance I have only limited possible results (i.e., we can have a discrete probability distribution over the possible results of I w.r.t. G. We denounce this probability distribution over PrG (I) is countable because we assume that all our numerical distributions are discrete. In this case, we can have a discrete probability distribution over the possible results of I w.r.t. G. We denounce this probability distribution over PrG, I. For a distribution of factors f = Rincii (a1, one, p) we define the weight of f (f), we denote the weight distribution of f (f)."}, {"heading": "4. CHASING GENERATIVE PROGRAMS", "text": "The hunt [3,28] is a classic procedure used for the consideration of Tupel-generating dependencies. (J) J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \"J\" J \""}, {"heading": "4.1 Proof of Theorems 3.8 and 3.9", "text": "By constructing, for each node of a tracking tree T, the weights of the edges emanating from the node in question are one to one. We can then assign a weight to each intermediate instance L (v), namely the product of the edge markers along the path from the root to v. This weight is well defined, since T is injective. We can then consider a random passage across the tree in which the probabilities are given by the edge markers. Then, for a node v, the weight of L (v) is equal to the probability of visiting v in this random world. From Theorem 4.3, we conclude that if all possible results are finite, T has no infinite paths, and furthermore, the random path defines a probability distribution over the labels of the leaves that are the possible results. This is exactly the probability distribution of theorem 3.8. Moreover, in the general case, the random path is a probability distribution of G (I) PrG, I (J) a probability distribution of the probability (the probability) between the labels (the labels), the probability (the 1) and the probability (the labels)."}, {"heading": "5. INFINITE POSSIBLE OUTCOMES", "text": "In the general case of a GDatalog program, the possible result can be infinite, and furthermore, the space of possible results can be infinite. Example 5.1. Let us now discuss examples showing what would happen if we extended our current definition of probability PrG, I (J) of possible results J to infinite possible results. Let us then look at the GDatalog program defined by the rule R (y) (y). Example 2.2: R (x, y), where it is a probability distribution with a parameter p and in such a way that the probability (z | p) is equal to 1 if z = 2p and 0 otherwise. Let us then look at I = {R (0, 1) the program has no finite possible result. In fact, I have exactly one infinite possible result: {R (0, 1).J (z) is equal to 1 if z = 2p and 0 otherwise."}, {"heading": "5.1 Generalization of Probabilistic Semantics", "text": "To generalize our framework, we must look at probability spaces across innumerable domains. (These are defined by measuring spaces defined as follows. (Let's be a series.) If F is a collection of subsets of H, then the closure of F \u00b2 among complementary and countable associations is an \"algebra,\" and it is said that F \u00b2 is an \"empty set,\" and that F \u00b2 is a closed space. (1) The closure of F \u00b2 among complementary and countable associations is an \"algebra,\" and it is said that F \u00b2 is a \"probability measurement,\" space is a threefold, \"F, zepte.\" (2) F is a set, called the example space. \"F \u00b2 F is an\" algebra about, \"and (3)."}, {"heading": "5.2 Measure Spaces by Infinite Chase", "text": "A maximum path of a persecution tree T is a path P that begins at the root and either ends in a leaf or is infinite. Note that the labels (instances) along a maximum path form a chain. A maximum path P of a persecution tree is fair if the premise of a rule in any intermediate instance on P is met by a swab, then the conclusion of the rule in an intermediate instance is on P. A persecution tree T is fair (or has the fairness property) if every maximum path is fair. Note that every finite persecution tree is fair. We will limit attention to fair persecution trees."}, {"heading": "5.3 Chase Measures", "text": "Our goal is to define a probability measurement defined by a random path over T, starting from the root. A measurement space for such a Markov chain is defined by means of a cylinder derivative [6]. Let v be a node of T. The v cylinder of T, referred to as CTv, is the subset of paths (T) that consists of all maximum paths containing a subset of paths (T) that forms a V cylinder shape of paths (T). The V cylinder group of T, referred to as CTv, is the subset of paths (T) that consist of all maximum paths containing a subset of paths (T) that forms a V cylinder shape for some nodes of V. We denote C (T) the set of all cylinders of T."}, {"heading": "5.4 Proof of Theorem 5.2", "text": "We can now prove that theorem 5.2. Let G be a GDatalog [\u2206] program, let me be an input for G, and let T be a fair trace tree for I w.r.t. G. Let \u00b5T = (\u0394G (I), FT, \u03c0T be the probability measurement for E G (I) associated with T, as defined in 5.5.Lemma 5.8. Let (I), which is generated from the sentences E G (I), FT), be generated by the sentences of the form F G (I), where F is finite.Proof. Let (I), F), which is generated from the sentences F G (I), FT \", FT.\" We will show that every F G (I) is in FT, and that every C is T in F. The second assertion is due to E, \"so we will prove that we are the first. So, let\" F G (I) be given."}, {"heading": "6. PROBABILISTIC-PROGRAMMING", "text": "DATALOGTo complete our framework, we define probabilisticing programming Datalog, PPDL (abbreviated J) (abbreviated J), where a program supplements a generative database program with constraints; these constraints unify the traditional integrity constraints of databases and the traditional observations of probabilistic programming. (Definition 6.1 (PPDL) is a finite set of parameterized numerical distributions. A PDL program is quadruple (E, I, II, IV, IV), where (E, I, II) is a GDatalog program and [P] is a finite set of logical constraints via E, I.1Example 6.2. Let's consider again Example 3.2. Let's assume that we have the EDB relationships ReportHAlarm and ReportBAlarm, which represent the reported domestic and business alarms. We get from the program a PDL by adding the following constraints to the program."}, {"heading": "In other words, \u00b5P,I is \u00b5G,I conditioned on \u03a6.", "text": "Example 6.4. Continuing with Example 6.2, the semantics of this program is the posterior probability distribution for the state of Example 3.2, under the conditions that the alarm is always turned on when it is reported. 1Restricting the language of the constraints to a fragment with traceability properties (or other qualities) is outside the scope of this paper. Then, various questions can be asked about the probability space defined, for example, for the probability of an earthquake (Napa, 1). Note that in case of denial, we could also formulate the condition that an alarm is turned off unless it is reported. We find that a traditional integrity constraint of input (e.g. there is no x, c1 and c2, so that both Home (x, c1) and Business (x, c2) can be considered as a constraint that is either probable 0 (and then the input is illegal) or probability 1 (and then the preceding problem, the micrometer problem, which is interesting for me)."}, {"heading": "7. EXTENSIONS AND FUTURE WORK", "text": "Our ultimate goal is to design a language for probabilistic programming that has the declarative and logical character of Datalog. To this end, enhancements are needed. In this section, we discuss some of the important future directions and challenges to pursue. We focus on the semantic aspects of expressiveness. (One obvious aspect for future work is practical implementation, such as appropriate sampling techniques.)"}, {"heading": "7.1 Unbounded Number of Parameters", "text": "It is often the case that the probability distributions have a large number of parameters. A simple example is the categorical distribution, where a single member of a finite domain of items must be selected, each element with its own probability. In this case, the domain can be very large, and furthermore, it can be dynamically determined by the database content and is unknown to the static program. To support such distributions, one can associate the distribution with a relation symbol in a scheme, and here we illustrate it in the case of a categorical distribution. Let R be a relation symbol. A categorical distribution over R is associated with two attributes that determine dynamic parameters: i and j of R, which represent a possible relation, and j represents their probability. In addition, the distribution is associated with a tuple g of the attributes of R, which we divide into groups with the semantics of SQL's GROBY."}, {"heading": "7.2 Multivariate Distributions", "text": "A natural and important extension is the support of multivariate distributions, the distributions with support in Rk for k > 1. Examples of popular such distributions are multinomial, Dirichlet and multivariate Gaussian distribution. If k is specified, our single distribution concept can be naturally replaced by several such terms. But if k is unlimited, such distribution should be supported as an overall operation that implies a set of facts (and not a single one).7.3 Continuous distributionA natural extension of our framework is the support of continuous probability distributions (e.g. continuous uniform, Pareto, Gaussian, Dirichlet etc.).This is a very important extension, since such distributions are extremely popular in the definition of statistical models. Syntactically, this extension is simple: we simply have to include these distributions in the overall classification of the classification of the classification of the classification of the classification of the classification of the U. Likewise, the extension of the probability tracing extends to an extension, although we are using the classification of the classification of the classification of the classification of the classification of the classification of the space."}, {"heading": "8. CONCLUDING REMARKS", "text": "We have proposed and examined a declarative framework for specifying statistical models in the context of a database, based on an extension of Datalog to include numerical distributions, which differs from traditional probabilistic programming languages not only in its close integration with a database, but also in its fully declarative rule-based language: the interpretation of a program is independent of transformations (such as reordering or duplication of rules) that preserve first-order semantics. We achieved this by treating a GDatalog program as a database program with existentially quantified variables in the conclusion, using the minimal solutions as an example of a (discrete or continuous) probability distribution. Using a suitable term of hunting that we introduced, we found that the resulting probability distributions are well-defined and robust, as part of efforts to expand the LogicBlox database [23] and support its database-based data management language of LogicBlox models [24]."}, {"heading": "Acknowledgments", "text": "We are grateful to Molham Aref, Todd J. Green, and Emir Pasalic for insightful discussions and feedback on this work. We also thank Michael Benedikt, Georg Gottlob, and Yannis Kassios for useful comments and suggestions. Finally, we are grateful to Kathleen Fisher and Suresh Jagannathan for including us in DARPA's PPAML initiative, which grew out of our efforts to develop a principled approach to translating probability programs into statistical solvers."}, {"heading": "9. REFERENCES", "text": "[1] S. Abiteboul, D. Deutch, and V. Vianu. Deduction with contradictions in Datalog 7 Theory. In ICDT, pp. 143-154, 2014. [2] S. Abiteboul, R. Hull, and V. Vianu. Foundations of Databases. 1995. [3] A. V. Aho, C. Beeri, and J. D. Ullman. The theory of joins in relational databases. ACM Trans. on Datab. Syst., (3): 297-314, 1979. [4] L. Antova, C. Koch, and D. Olteanu. From complete to incomplete incomplete information and back. In SIGMOD, pp. 713-724 Trans. on logical. [5] L. Antova, C. Koch, and D. Olteanu. Query language support for uncomplete information in the MayBMS system. In VLDB, pp. 1422-1425, 2007. [6] R. B. Ash and Doleans C. Proasability. Measure."}, {"heading": "A. ADDITIONAL PROOFS", "text": "So it is easy to show that if a datalog in our sense, then a datalog program D is weak acyclic, then there is a polynomial p () that is applied only to D), so for each input instance I and for each input instance I w.r.t. D, it is a solution J w.r.t. D, it is a solution J w.r.t. D, it is a solution J w.r.2 with J, and it is a solution J.P, and it is a solution J.P, and it is a solution J.P, and it is a solution J.P, and it is a solution J.P, and it is a solution."}], "references": [{"title": "Deduction with contradictions in Datalog", "author": ["S. Abiteboul", "D. Deutch", "V. Vianu"], "venue": "In ICDT,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "The theory of joins in relational databases", "author": ["A.V. Aho", "C. Beeri", "J.D. Ullman"], "venue": "ACM Trans. on Datab. Syst.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1979}, {"title": "From complete to incomplete information and back", "author": ["L. Antova", "C. Koch", "D. Olteanu"], "venue": "In SIGMOD,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Query language support for incomplete information in the MayBMS system", "author": ["L. Antova", "C. Koch", "D. Olteanu"], "venue": "In VLDB,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Doleans-Dade. Probability & Measure Theory", "author": ["C.R.B. Ash"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Probabilistic reasoning with answer sets", "author": ["C. Baral", "M. Gelfond", "N. Rushton"], "venue": "Theory Pract. Log. Program.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Probabilistic XML via markov chains", "author": ["M. Benedikt", "E. Kharlamov", "D. Olteanu", "P. Senellart"], "venue": "PVLDB, 3(1):770\u2013781,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Probabilistic similarity logic", "author": ["M. Br\u00f6cheler", "L. Mihalkova", "L. Getoor"], "venue": "In UAI, pages 73\u201382,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Simulation of database-valued Markov chains using SimSQL", "author": ["Z. Cai", "Z. Vagena", "L.L. Perez", "S. Arumugam", "P.J. Haas", "C.M. Jermaine"], "venue": "In SIGMOD,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Datalog+/-: A family of logical knowledge representation and query languages for new applications", "author": ["A. Cal\u0300\u0131", "G. Gottlob", "T. Lukasiewicz", "B. Marnette", "A. Pieris"], "venue": "In LICS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Querying parse trees of stochastic context-free grammars", "author": ["S. Cohen", "B. Kimelfeld"], "venue": "In Database Theory - ICDT 2010, 13th International Conference, Lausanne, Switzerland, March 23-25,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "On 12  probabilistic fixpoint and Markov chain query languages", "author": ["D. Deutch", "C. Koch", "T. Milo"], "venue": "In PODS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Markov Logic: An Interface Layer for Artificial Intelligence. Synthesis Lectures on AI and Machine Learning", "author": ["P. Domingos", "D. Lowd"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Disjunctive datalog", "author": ["T. Eiter", "G. Gottlob", "H. Mannila"], "venue": "ACM Trans. Database Syst.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}, {"title": "Recursive markov chains, stochastic grammars, and monotone systems of nonlinear equations", "author": ["K. Etessami", "M. Yannakakis"], "venue": "J. ACM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Data exchange: Semantics and query answering", "author": ["R. Fagin", "P.G. Kolaitis", "R.J. Miller", "L. Popa"], "venue": "In ICDT, volume 2572 of LNCS,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Probabilistic datalog: Implementing logical information retrieval for advanced applications", "author": ["N. Fuhr"], "venue": "JASIS, 51(2):95\u2013110,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "Peer data exchange", "author": ["A. Fuxman", "P.G. Kolaitis", "R.J. Miller", "W.C. Tan"], "venue": "ACM Trans. Datab. Syst.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "The principles and practice of probabilistic programming", "author": ["N.D. Goodman"], "venue": "In POPL,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Query answering under probabilistic uncertainty in Datalog+/ ontologies", "author": ["G. Gottlob", "T. Lukasiewicz", "M. Martinez", "G. Simari"], "venue": "Annals of Math.& AI,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "LogicBlox, platform and language: A tutorial", "author": ["T.J. Green", "M. Aref", "G. Karvounarakis"], "venue": "In Int Conf on Datalog in Academia and Industry,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "LogiQL: A Query Language for Smart Databases", "author": ["T. Halpin", "S. Rugaber"], "venue": "CRC Press,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "MCDB: a monte carlo approach to managing uncertain data", "author": ["R. Jampani", "F. Xu", "M. Wu", "L.L. Perez", "C.M. Jermaine", "P.J. Haas"], "venue": "In SIGMOD,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Probabilistic XML: models and complexity. In Advances in Probabilistic Databases for Uncertain Information Management, volume 304 of Studies in Fuzziness and Soft Computing, pages 39\u201366", "author": ["B. Kimelfeld", "P. Senellart"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "On the implementation of the probabilistic logic programming language ProbLog", "author": ["A. Kimmig", "B. Demoen", "L. De Raedt", "V. Santos Costa", "R. Rocha"], "venue": "Theory and Practice of Logic Programming,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Testing implications of data dependencies", "author": ["D. Maier", "A.O. Mendelzon", "Y. Sagiv"], "venue": "ACM Trans. on Datab. Syst.,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1979}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["V.K. Mansinghka", "D. Selsam", "Y.N. Perov"], "venue": "CoRR, abs/1404.0099,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Multi-label text classification with a mixture model trained by EM", "author": ["A.K. McCallum"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1999}, {"title": "BLOG: Probabilistic models with unknown objects", "author": ["B. Milch"], "venue": "In IJCAI,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2005}, {"title": "Text classification from labeled and unlabeled documents using EM", "author": ["K. Nigam", "A. McCallum", "S. Thrun", "T.M. Mitchell"], "venue": "Machine Learning,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2000}, {"title": "Tuffy: Scaling up statistical inference in markov logic networks using an RDBMS", "author": ["F. Niu", "C. R\u00e9", "A. Doan", "J.W. Shavlik"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "DeepDive: Web-scale knowledge-base construction using statistical learning and inference", "author": ["F. Niu", "C. Zhang", "C. Re", "J.W. Shavlik"], "venue": "In Proceedings of the Second International Workshop on Searching and Integrating New Web Data Sources, Istanbul,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "R2: an efficient MCMC sampler for probabilistic programs", "author": ["A.V. Nori", "C. Hur", "S.K. Rajamani", "S. Samuel"], "venue": "In AAAI,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Probabilistic reasoning in intelligent systems - networks of plausible inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1989}, {"title": "Figaro: An object-oriented probabilistic programming language", "author": ["A. Pfeffer"], "venue": "Technical report, Charles River Analytics,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "The independent choice logic and beyond", "author": ["D. Poole"], "venue": "In Probabilistic Inductive Logic Programming - Theory and Applications,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Applied Statistical Decision Theory", "author": ["H. Raiffa", "R. Schlaifer"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1961}, {"title": "PRISM: A language for symbolic-statistical modeling", "author": ["T. Sato", "Y. Kameya"], "venue": "In IJCAI,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1997}, {"title": "Probabilistic Databases", "author": ["D. Suciu", "D. Olteanu", "C. R\u00e9", "C. Koch"], "venue": "Synthesis Lectures on Data Management. Morgan & Claypool Publishers,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2011}, {"title": "Trio: a system for data, uncertainty, and lineage", "author": ["J. Widom"], "venue": "Managing and Mining Uncertain Data,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2008}], "referenceMentions": [{"referenceID": 19, "context": "An intensively studied concept in that area is that of Probabilistic Programming [21] (PP), where the idea is that the programming language allows for building general random procedures, while the system executes the program not in the standard programming sense, but rather by means of inference.", "startOffset": 81, "endOffset": 85}, {"referenceID": 27, "context": ", [29,31,37]) towards facilitating the development of algorithms based on machine learning.", "startOffset": 2, "endOffset": 12}, {"referenceID": 29, "context": ", [29,31,37]) towards facilitating the development of algorithms based on machine learning.", "startOffset": 2, "endOffset": 12}, {"referenceID": 35, "context": ", [29,31,37]) towards facilitating the development of algorithms based on machine learning.", "startOffset": 2, "endOffset": 12}, {"referenceID": 28, "context": "One common approach to this task assumes a generative process that produces random parameters for every class, and then uses these parameters to define a generator of random words in documents of the corresponding class [30, 32].", "startOffset": 220, "endOffset": 228}, {"referenceID": 30, "context": "One common approach to this task assumes a generative process that produces random parameters for every class, and then uses these parameters to define a generator of random words in documents of the corresponding class [30, 32].", "startOffset": 220, "endOffset": 228}, {"referenceID": 7, "context": "Latent Dirichlet Allocation [9] approaches this problem in a similar generative way as the above, with the addition that each document is associated with a distribution over topics.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "We use cylinder sets [6] to define a measure space based on a chase, and prove that this definition is robust, since one establishes the same probability measure no matter which chase is used.", "startOffset": 21, "endOffset": 24}, {"referenceID": 29, "context": ") The first category includes imperative probabilistic programming languages [43], such as BLOG [31], that can express probability distributions over logical structures, via generative stochastic models that can draw values at random from numerical distributions, and con-", "startOffset": 96, "endOffset": 100}, {"referenceID": 5, "context": "P-log [7] is a Prologbased language for specifying Bayesian networks.", "startOffset": 6, "endOffset": 9}, {"referenceID": 25, "context": "In the second step, a logic program, such as Prolog [27] or Datalog [1], is evaluated over the resulting random structure.", "startOffset": 52, "endOffset": 56}, {"referenceID": 0, "context": "In the second step, a logic program, such as Prolog [27] or Datalog [1], is evaluated over the resulting random structure.", "startOffset": 68, "endOffset": 71}, {"referenceID": 38, "context": "This approach has been taken by PRISM [40], the Independent Choice Logic [38], and to a large extent by probabilistic databases [41] and their semistructured counterparts [26].", "startOffset": 38, "endOffset": 42}, {"referenceID": 36, "context": "This approach has been taken by PRISM [40], the Independent Choice Logic [38], and to a large extent by probabilistic databases [41] and their semistructured counterparts [26].", "startOffset": 73, "endOffset": 77}, {"referenceID": 39, "context": "This approach has been taken by PRISM [40], the Independent Choice Logic [38], and to a large extent by probabilistic databases [41] and their semistructured counterparts [26].", "startOffset": 128, "endOffset": 132}, {"referenceID": 24, "context": "This approach has been taken by PRISM [40], the Independent Choice Logic [38], and to a large extent by probabilistic databases [41] and their semistructured counterparts [26].", "startOffset": 171, "endOffset": 175}, {"referenceID": 40, "context": "One step beyond the second category and closer to our work is taken by uncertainty-aware query languages for probabilistic data such as TriQL [42], I-SQL, and world-set algebra [4, 5].", "startOffset": 142, "endOffset": 146}, {"referenceID": 2, "context": "One step beyond the second category and closer to our work is taken by uncertainty-aware query languages for probabilistic data such as TriQL [42], I-SQL, and world-set algebra [4, 5].", "startOffset": 177, "endOffset": 183}, {"referenceID": 3, "context": "One step beyond the second category and closer to our work is taken by uncertainty-aware query languages for probabilistic data such as TriQL [42], I-SQL, and world-set algebra [4, 5].", "startOffset": 177, "endOffset": 183}, {"referenceID": 2, "context": "The latter two are natural analogs to SQL and relational algebra for the case of incomplete information and probabilistic data [4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 12, "context": "World-set algebra has been extended to (world-set) Datalog, fixpoint, and while-languages [14] to define Markov chains.", "startOffset": 90, "endOffset": 94}, {"referenceID": 23, "context": "MCDB [25] and SimSQL [11] propose SQL extensions (with for-loops and probability distributions) coupled with Monte Carlo simulations and parallel database techniques for stochastic analytics in the database.", "startOffset": 5, "endOffset": 9}, {"referenceID": 9, "context": "MCDB [25] and SimSQL [11] propose SQL extensions (with for-loops and probability distributions) coupled with Monte Carlo simulations and parallel database techniques for stochastic analytics in the database.", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "This category includes Markov Logic Networks (MLNs) [15, 33], where the logical rules are used as a compact and intuitive way of defining factors.", "startOffset": 52, "endOffset": 60}, {"referenceID": 31, "context": "This category includes Markov Logic Networks (MLNs) [15, 33], where the logical rules are used as a compact and intuitive way of defining factors.", "startOffset": 52, "endOffset": 60}, {"referenceID": 32, "context": "This approach is applied in DeepDive [34], where a database is used for storing relational data and extracted text, and database queries are used for defining the factors of a factor graph.", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": "A similar approach is taken by Probabilistic Soft Logic [10], where in each possible world every fact is associated with a weight (degree of truth).", "startOffset": 56, "endOffset": 60}, {"referenceID": 17, "context": "Further formalisms in this category are probabilistic Datalog [19], probabilistic Datalog+/- [22], and probabilistic logic programming (ProbLog) [27].", "startOffset": 62, "endOffset": 66}, {"referenceID": 20, "context": "Further formalisms in this category are probabilistic Datalog [19], probabilistic Datalog+/- [22], and probabilistic logic programming (ProbLog) [27].", "startOffset": 93, "endOffset": 97}, {"referenceID": 25, "context": "Further formalisms in this category are probabilistic Datalog [19], probabilistic Datalog+/- [22], and probabilistic logic programming (ProbLog) [27].", "startOffset": 145, "endOffset": 149}, {"referenceID": 15, "context": "Related formalisms are those of the Probabilistic Context-Free Grammar (PCFG) and the more general Recursive Markov Chain (RMC) [17], where the probabilistic specification is by means of a finite set of transition graphs that can call one another (in the sense of method call) in a possibly recursive fashion.", "startOffset": 128, "endOffset": 132}, {"referenceID": 6, "context": "In database research, PCFGs and RMCs have been explored in the context of probabilistic XML [8, 13].", "startOffset": 92, "endOffset": 99}, {"referenceID": 11, "context": "In database research, PCFGs and RMCs have been explored in the context of probabilistic XML [8, 13].", "startOffset": 92, "endOffset": 99}, {"referenceID": 10, "context": "In this work we use Datalog with the option of having existential variables in the head [12].", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "We initially focus on the discrete case; there, a probability space is a pair (\u03a9, \u03c0), where \u03a9 is a finite or countably infinite set, called the sample space, and \u03c0 : \u03a9 \u2192 [0, 1] is such that \u2211 o\u2208\u03a9 \u03c0(o) = 1.", "startOffset": 170, "endOffset": 176}, {"referenceID": 0, "context": "A parameterized probability distribution is a function \u03b4 : \u03a9 \u00d7 R \u2192 [0, 1], such that \u03b4(\u00b7,p) : \u03a9 \u2192 [0, 1] is a probability distribution for all p \u2208 R.", "startOffset": 67, "endOffset": 73}, {"referenceID": 0, "context": "A parameterized probability distribution is a function \u03b4 : \u03a9 \u00d7 R \u2192 [0, 1], such that \u03b4(\u00b7,p) : \u03a9 \u2192 [0, 1] is a probability distribution for all p \u2208 R.", "startOffset": 98, "endOffset": 104}, {"referenceID": 0, "context": "\u2022 Flip(x|p): \u03a9 is {0, 1}, and for a parameter p \u2208 [0, 1] we have Flip(1|p) = p and Flip(0|p) = 1\u2212 p.", "startOffset": 50, "endOffset": 56}, {"referenceID": 0, "context": "\u2022 Geo(x|p): \u03a9 = N, and for a parameter p \u2208 [0, 1] we have Geo(x|p) = (1\u2212 p)p.", "startOffset": 43, "endOffset": 49}, {"referenceID": 34, "context": "Our example is based on the burglar example of Pearl [36] that has been frequently used for illustrating probabilistic programming (e.", "startOffset": 53, "endOffset": 57}, {"referenceID": 33, "context": ", [35]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": "This draws on the notion of weak acyclicity for Datalog [18].", "startOffset": 56, "endOffset": 60}, {"referenceID": 39, "context": "We also highlight the fact that our framework can easily simulate the probabilistic database model of independent tuples [41] with probabilities mentioned in the database, using the Flip distribution, as follows.", "startOffset": 121, "endOffset": 125}, {"referenceID": 14, "context": "Finally, we note that a disjunctive Datalog rule [16], where the conclusion can be a disjunction of atoms, can be simulated by our model (with probabilities ignored): If the conclusion has n disjuncts, then we construct a distributional rule with a probability distribution over {1, .", "startOffset": 49, "endOffset": 53}, {"referenceID": 1, "context": "The chase [3,28] is a classic technique used for reasoning about tuple-generating dependencies and equalitygenerating dependencies.", "startOffset": 10, "endOffset": 16}, {"referenceID": 26, "context": "The chase [3,28] is a classic technique used for reasoning about tuple-generating dependencies and equalitygenerating dependencies.", "startOffset": 10, "endOffset": 16}, {"referenceID": 0, "context": "G is a possibly infinite tree, whose nodes are labeled by instances over E\u222aI and where each edge is labeled by a real number r \u2208 [0, 1] such that", "startOffset": 129, "endOffset": 135}, {"referenceID": 0, "context": "A probability measure space is a triple (\u03a9,F , \u03c0), where: (1) \u03a9 is a set, called the sample space, (2) F is a \u03c3-algebra over \u03a9, and (3) \u03c0 : F \u2192 [0, 1], called a probability measure, is such that \u03c0(\u03a9) = 1, and \u03c0(\u222aE) = \u2211 e\u2208E \u03c0(e) for every countable set E of pairwise-disjoint measurable sets.", "startOffset": 144, "endOffset": 150}, {"referenceID": 4, "context": "A measure space for such a Markov chain is defined by means of cylinderification [6].", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": "[6]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 37, "context": "Also, an interesting problem is to detect conditions under which the chase is a self conjugate [39], that is, the probability space \u03bcP,I is captured by a chase procedure without backtracking.", "startOffset": 95, "endOffset": 99}, {"referenceID": 0, "context": "We assume that fk[j] \u2208 [0, 1] for all k = 1, .", "startOffset": 23, "endOffset": 29}, {"referenceID": 2, "context": "The above specification for the categorical distribution is similar to the repair-key operation of the worldset algebra [4, 5].", "startOffset": 120, "endOffset": 126}, {"referenceID": 3, "context": "The above specification for the categorical distribution is similar to the repair-key operation of the worldset algebra [4, 5].", "startOffset": 120, "endOffset": 126}, {"referenceID": 21, "context": "This work is done as part of the effort to extend the LogicBlox database [23], and its Datalog-based data management language LogiQL [24], to support the specification of statistical models.", "startOffset": 73, "endOffset": 77}, {"referenceID": 22, "context": "This work is done as part of the effort to extend the LogicBlox database [23], and its Datalog-based data management language LogiQL [24], to support the specification of statistical models.", "startOffset": 133, "endOffset": 137}], "year": 2015, "abstractText": "Formalisms for specifying general statistical models, such as probabilistic-programming languages, typically consist of two components: a specification of a stochastic process (the prior), and a specification of observations that restrict the probability space to a conditional subspace (the posterior). Use cases of such formalisms include the development of algorithms in machine learning and artificial intelligence. We propose and investigate a declarative framework for specifying statistical models on top of a database, through an appropriate extension of Datalog. By virtue of extending Datalog, our framework offers a natural integration with the database, and has a robust declarative semantics (that is, semantic independence from the algorithmic evaluation of rules, and semantic invariance under logical program transformations). Our proposed Datalog extension provides convenient mechanisms to include common numerical probability functions; in particular, conclusions of rules may contain values drawn from such functions. The semantics of a program is a probability distribution over the possible outcomes of the input database with respect to the program; these possible outcomes are minimal solutions with respect to a related program that involves existentially quantified variables in conclusions. Observations are naturally incorporated by means of integrity constraints over the extensional and intensional relations. We focus on programs that use discrete numerical distributions, but even then the space of possible outcomes may be uncountable (as a solution can be infinite). We define a probability measure over possible outcomes by applying the known concept of cylinder sets to a probabilistic chase procedure. We show that the resulting semantics is robust under different chases. We also identify conditions guaranteeing that all possible outcomes are finite (and then the probability space is discrete). We argue that the framework we propose retains the purely declarative nature of Datalog, and allows for natural specifications of statistical models.", "creator": "LaTeX with hyperref package"}}}