{"id": "1412.2457", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2014", "title": "Weighted Polynomial Approximations: Limits for Learning and Pseudorandomness", "abstract": "Polynomial approximations to boolean functions have led to many positive results in computer science. In particular, polynomial approximations to the sign function underly algorithms for agnostically learning halfspaces, as well as pseudorandom generators for halfspaces. In this work, we investigate the limits of these techniques by proving inapproximability results for the sign function.", "histories": [["v1", "Mon, 8 Dec 2014 05:58:56 GMT  (26kb)", "http://arxiv.org/abs/1412.2457v1", "22 pages"]], "COMMENTS": "22 pages", "reviews": [], "SUBJECTS": "cs.CC cs.LG", "authors": ["mark bun", "thomas steinke"], "accepted": false, "id": "1412.2457"}, "pdf": {"name": "1412.2457.pdf", "metadata": {"source": "CRF", "title": "Weighted Polynomial Approximations: Limits for Learning and Pseudorandomness", "authors": ["Mark Bun", "Thomas Steinke"], "emails": ["mbun@seas.harvard.edu", "tsteinke@seas.harvard.edu"], "sections": [{"heading": null, "text": "We believe that the algorithm of \"polynomial regression\" by Kalai et al. (SIAM J. Comput. 2008) shows that semispaces in relation to logconcave distributions on Rn can be learned in the challenging agnostic learning model. The power of this algorithm is based on the fact that under logconcave distributions, semispaces can be estimated as well as desired by low-grade polynomials. We wonder whether this technique can be extended beyond logconcave distributions and find a negative result. We show that polynomials of each degree do not perform the character function within arbitrarily low errors for a large class of non-logconceived distributions on the real line, including those with densities proportional to exp (\u2212 x | 0.99). This impossibility extends to multivariate distributions."}, {"heading": "1 Introduction", "text": "Approximation theory is a classical area of mathematics that examines how well functions can be approached by simpler ones. It has found many applications in computer science. Most of these applications of approximation theory focus on the approximation of functions by polynomials within the uniform standard (or infinity standard).For example, the approximate degree that captures how well a Boolean function can be approximated by low-grade polynomials within the uniform standard is based on important lower limits in circuit complexity [Bei93, Bei94, She09], quantum query complexity [BBC + 01, AS04] and communication complexity [She08].It also underpins the state of art algorithms in learning theory [KKMS08, KS04], streaming [HNO08] and in spectral methods [SV14]. While it is imperative to study polynomial approximations under uniform polynomical scenarios, there are more natural ones in certain scenarios that we can study."}, {"heading": "1.1 Agnostically Learning Halfspaces", "text": "Halfspaces are a basic concept class in machine learning, both in theory and in practice. Their study goes back to the results of the perceptron algorithms of the 1950s. Halfspaces serve as building blocks in many applications, including the uplift and diffusion of core methods. Halfspaces can be learned in the PAC model and often need to be dealt with in practice. In this paper, we examine a challenging model of adversarial noise - the agnostic learning model by Kearns et al. [KSSH94] In this model, a learner has access to examples drawn from a distribution D to X \u00d7 \u00b1 1."}, {"heading": "1.1.1 Our Results", "text": "The question we must ask ourselves is whether we feel able to understand and understand the world, as the world in the world, in which the world and the world in the world, in which the world and the world in the world, in which the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world and the world, the world, the world and the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world and the world, the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world and the world, the world, the world, the world and the world, the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world, the world and the world, the world, the world and the world, the world, the world and the world, the world, the world, the world, the world and the world, the world, the world, the world and the world, the world, the world and the world, the world"}, {"heading": "1.1.2 Related Work", "text": "There is a rich literature on lower limits for agnostic learning. In the case of proper agnostic learning Feldman et. al [FGKP06] there was an optimal NP hardness result for even weakly agnostic learning half-spaces on Qn. Guruswami and Raghavendra [GR06] showed that the same is true for half-spaces on the Boolean hypercube. There was also a series of papers that provided a representation-independent hardness of learning half-spaces on the basis of cryptographic assumptions. Feldman et. al [FGKP06] and Klivans and Sherstov [KS09] showed that the security of certain public key encryptions requires schemes, it is difficult to learn even PAC thresholds and intersections of half-spaces. These results imply that it is difficult to learn a single half-space in hard space work, i.e. if one decides for the security of certain public key encrypted spaces, this half-space is difficult to intersect and it is fluctuating."}, {"heading": "1.2 Tail Bounds for Limited Independence", "text": "The famous Hoeffding bound [Hoe63] implies that if X-1} n is a uniform random variable and r-Rn is fixed, then for all T seeds 0-0, P-X-2, P-T2-2, P-R-22, the following question is asked: For which pseudo-andom X is the Hoeffing bound true? Specifically, we can construct a pseudo-andom X-2, so that P-X-r-T for all r-1, P-1, P-2, P-2, P-3, X-3, X-3, X-3, X-3, X-3, X-3, X-4, X-4, X-4, X-5, X-5, X-5, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-5, X-5, X-5, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-5, X-4, X-4, X-5, X-4, X-5, X-4, X-4, X-4, X-5, X-4, X-4, X-5, X-4, X-4, X-5, X-4, X-4, X-4, X-4, X-4, X-4, X-5, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-4, X-5, X-5, X-4, X-4, X-4, X-4, X-5, X-4, X-4, X-4, X-4, X-4, X-3, X-1, X-1, X-3, X-3, X-1, X-3, X-1, X-3, X-1, X-1, X-1, X-1, X-1, X-1"}, {"heading": "1.2.1 Our Results", "text": "In this paper we show that this is essentially narrow: Theorem 7. For T = c \u221a n log (1 / \u03b4) (c > 5), we have k (n, \u03b4, T) = q (logc (1 / \u03b4) for sufficiently large. The only previous lower limit is constant in our parameter regime. This lower limit results from the fact that a random variable X with support size s cannot give a tail-bound theory s. < 1 / s, and that there are k-wise independent distributions with support size s. We cannot have a tail-bound theory < 1 / s, and that there are k-wise independent distributions with support size s."}, {"heading": "2 Agnostically Learning Halfspaces", "text": "The class of log-concave distributions via Rn (defined below) is essentially the most comprehensive under which we know how to learn agnostic half-spaces. While many distributions used in machine learning are log-concave, such as the normal, laplace, beta, and dirichlet distributions, log-concave distributions do not capture everything. For example, log-normal distribution and exponential heavy-tail power distributions are not log-concave. The main motivating question in this section is whether we can relax the assumption of log-concave distributions to learn agnostic half-spaces. To this end, we show a negative result: For LSL distributions, agnostic learning of half-spaces requires new techniques."}, {"heading": "2.1 Background", "text": "Our starting point is the work of Kalai et al. [KKMS08]. Their results include the following: Theorem 8 ([KKMS08]). The concept class of semispaces over Rn is agnostically learnable in time poly (nO\u03b5 (1) under log-concave distributions. A log-concave distribution is an absolutely continuous probability distribution, so that the logarithm of the probability density function is concave. Thus, for example, the multivariate Gaussian standard distribution on Rn has the probability density function x 7 \u2192 e \u2212 | | x | 22 / 2 / (2\u03c0) n / 2. The natural logarithm for this is \u2212 | x | 22 / 2 \u2212 n / 2 \u00b7 log (2\u03c0), which is concave. The class of log-concave distributions also includes the Laplace distribution and other natural distributions. However, it does not contain any serious cold tailed distributions (such as - or equality distributions)."}, {"heading": "2.2 The L1 Regression Algorithm", "text": "The results of Kalai et al. are based on the so-called L1 regression algorithm, which is based on the ability to approximate the concept class concerned by a low-grade polynomial: Theorem 9 ([KKMS08]). Attach a distribution D to X \u00b7 {\u00b1 1} and a concept class C \u2022 f: X \u2192 {\u00b1 1}.5 Suppose that for all f \u00b7 C there is a polynomial algorithm p: X \u2192 R of the degree at most d, that Ex \u0445 DX (x) \u2212 f (x) |] \u2264 \u03b5, where DX represents the marginal distribution from D to X. Then the L1 regression algorithm gives a hypothesis h of such a thatP (x, y) that D [h), y), D (x), x, y, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, etc."}, {"heading": "2.3 On the Density of Polynomials", "text": "In this section, we give some clues as to why one might expect polynomial approximations to be insufficient to learn under LSL distributions. It turns out that under an LSL distribution w, polynomials cannot in fact be anywhere near dense in space C0 [w] of continuous functions that disappear to infinity when weighted by w. This is in stark contrast to the classic Weierstrass approximation theory, which claims that the polynomials in C0 are dense under the uniform weight. These kinds of results address Bernstein's approximation problem [Ber24], the exact statement of which is considered to be the following. 5Here X = Rn.Question 10: R \u2192 [0, 1] is a measurable function. Let C0 [w] denote the space of continuous functions f, for which lim | x | \u2192 f (x) w (x) = 0."}, {"heading": "2.4 Lower Bound for One Variable", "text": "Consider the LSL density function (x): The proof is based on the following Markov type inequality, which roughly means that a limited polynomia cannot have a large derivative."}, {"heading": "2.5 Extending the Lower Bound to Multivariate Distributions", "text": "It is easy to extend the lower limit of the previous section to product distributions with LSL limits. \"Theorem 17. Let X = (X1,.., Xn) be a random variable with a density fX (x) = 1 (x1) f (x2,.., xn). Suppose the density w specifies a univariate \u03b3-LSL distribution. Then there is such a one that for each polynomial p (x1,.) p (x1,.,., xn) p a univariate \u03b3-LSL distribution. That is, the linear threshold function sgn (x1) cannot be arbitrarily determined by polynomials. Proof. Let p (x1,.,.) p."}, {"heading": "3 Tail Bounds for Limited Independence", "text": "Our proof consists of three steps: \u00a7 3.1 First, we reformulate the question of tail boundaries for k-wise independent distributions using linear programming duality and symmetry, which reduces the problem to the detection of a lower boundary of univariate polynomials. We need to set a lower boundary for the degree of polynomial p: {0, 1, \u00b7 \u00b7 \u00b7 n} \u2192 R so that p (i) \u2265 0 for all i, p (i) \u2265 1 if | i \u2212 n / 2 | \u2265 T, and E [p (i)] \u2264 \u03b4 where i is drawn from the binomial distribution. \u00a7 3.2 We then transform the problem from a problem over polynomial with a discrete domain into one over polynomial with a continuous domain. This boils down to showing that E [p (i)] can only grow to a limited extent in terms of binomial distribution."}, {"heading": "3.1 Dual Formulation", "text": "Question 6 from the introduction is equivalent to finding the smallest k, for which the value of the following linear program is limited at most. (With the linear program formulation of question 6, question 6 is equivalent to finding the smallest k, for which the value of the following linear program is limited. (With the linear program formulation of question 6, question 6 is more than limited.) The linear program formulation of question 6 allows the smallest k, for which the value of the following linear program is limited at most. (With the linear program formulation of question 6, the linear formation of question 6 is more than limited. (With the linear program formulation of question 6, the linear formation of question 6 is more than otherwise.) The linear formulation of question 6 allows the linear formulas of question 6 more than otherwise. (With the linear program formulation of question 6, more than otherwise.)"}, {"heading": "3.2 A Continuous Version", "text": "In order to apply techniques from the theory of weighted polynomial approximations, we move to polynomials with a value of 1.0. We replace the binomial distribution according to which theorem 18 p is evaluated with a Gaussian distribution. Then, we define the probability density (x) = 1.0 q q e-x 2. We define the L standard in terms of weight w: 1.0 g \u00b2 l (S) = 1.0 \u2264 S | g (x). Now, we can give the continuous version of the problem: 6While our results show that this polynomial is asymptotically optimal, numerical experiments have shown that it is not exactly optimal. Theorem 19. Let us leave T = 1.0 / 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0 = 2.0."}, {"heading": "3.3 The Lower Bound", "text": "The following \"infinite-finite bandwidth q-inequality\" shows that the norm of the weighted polynomial on the real line is determined by its norm on a finite interval around the origin. We will apply this to the polynomial given to us in Theorem 19. Theorem 22. For each polynomial p of degree d and B > 1 there is a limit to its growth near the origin. We will apply this to the protocol (2eB) d exp. (\u2212 B2d) p."}, {"heading": "4 Further Work", "text": "Our negative results, of course, point to a number of directions for future work. Are semi-spaces agnostically learnable under LSL distributions? Our negative result does not even necessarily exclude the use of L1 regression for this task: The polynomial regression algorithm of Kalai et al. [KKMS08] is indeed quite flexible. Nothing is really specific to the basis of low-grade monomies, and the algorithm works equally well over any small, efficiently assessable \"attribute space.\" That is, if we can show that half-spaces are well approximated by linear combinations of features from a feature space F under a distribution D, then we can learn half-spaces agnostically proportional to | F |. Could one hope for such approximations? Wimmer [Wim10] and Feldman and Kothari [FK14] have shown how to use non-polynomial basic functions to obtain faster learning algorithms on the hyperalgorithms."}, {"heading": "5 Acknowledgements", "text": "We thank Varun Kanade, Scott Linderman, Raghu Meka, Jelani Nelson, Justin Thaler, Salil Vadhan, Les Valiant and several anonymous reviewers for helpful discussions and comments."}, {"heading": "A Upper Bound for Limited Independence", "text": "Theorem 5 follows from the following well-known [SSS95, BR94] problem, which we use for the completeness of the k relationship (= \"k\") k = = \"k\" (\"k\") k = \"k\" (\"k\") k \"(\" k \") k\" (\"k\") k \"(\" k \") k\" (\"k\") k \"(\" k \") k\" (\"k\") k \"(\" k \") k\" (\"k\") k \"(\" k \"k\" k \"k\" k \"k\" k \") k\" k \"(\" k \"k\" k \"k\" k \") k\" k \"(\" k \"k\" k \"k\" k \"k\" k \"k\" k \"k\" k \"k\" k \"k\" k \"k\" k \"k\" k \"k\") k \"k\" k \"(\" k \"k\" k \"k\" k \"k\" k \") k\" k \"(\" k \"k\" k \"k\" k \") k\" k \"(\" k \"k\" k \"k\" k \") k\" (\"k\" k \"k\" k \"k\") k \"k\" (\"k\" k \"k\" k \"k\") k \"k\" (\"k\" k \"k\" k) k \"k\") k \"(\" k \"k\") k \"k\" k \"k\" (\"k\") k \"k\" k \"k\" k \"k\" k \"k\") k (\"k\" k \"k\" k \") k\" k \"k (\" k \"k\" k \"k) k\" k \"k\" k \"k\" (\"k) k\" k (\"k\" k \"k\" k) k \"k\" k \"k (\") k (\"k\" k \"k\") k \"k\" k \"k (\" k \") k\" k \"k\") k \"k\" k (\"k\" k \"k\") (\"k\" k \") k\" k \"k\" k \"k\" k \"k\") (\"k\" k \"k\" k \") (\" k \"k\" k \"k\" k \")\" k \"k\" k \"k\" k \""}], "references": [{"title": "A fast and simple randomized parallel algorithm for the maximal independent set problem", "author": ["Noga Alon", "Laszlo Babai", "Alon Itai"], "venue": "Technical report,", "citeRegEx": "Alon et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Alon et al\\.", "year": 1985}, {"title": "Quantum lower bounds for the collision and the element distinctness problems", "author": ["Scott Aaronson", "Yaoyun Shi"], "venue": "J. ACM,", "citeRegEx": "Aaronson and Shi.,? \\Q2004\\E", "shortCiteRegEx": "Aaronson and Shi.", "year": 2004}, {"title": "Polylogarithmic independence can fool DNF formulas", "author": ["Louay M.J. Bazzi"], "venue": "SIAM J. Comput.,", "citeRegEx": "Bazzi.,? \\Q2009\\E", "shortCiteRegEx": "Bazzi.", "year": 2009}, {"title": "Quantum lower bounds by polynomials", "author": ["Robert Beals", "Harry Buhrman", "Richard Cleve", "Michele Mosca", "Ronald de Wolf"], "venue": "J. ACM,", "citeRegEx": "Beals et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Beals et al\\.", "year": 2001}, {"title": "The polynomial method in circuit complexity. In Structure in Complexity Theory Conference, pages 82\u201395", "author": ["Richard Beigel"], "venue": "IEEE Computer Society,", "citeRegEx": "Beigel.,? \\Q1993\\E", "shortCiteRegEx": "Beigel.", "year": 1993}, {"title": "Perceptrons, PP, and the polynomial hierarchy", "author": ["Richard Beigel"], "venue": "Computational Complexity,", "citeRegEx": "Beigel.,? \\Q1994\\E", "shortCiteRegEx": "Beigel.", "year": 1994}, {"title": "Le probl\u00e8me de l\u2019approximation des fonctions continues sur tout l\u2019axe", "author": ["S.N. Bernstein"], "venue": "re\u0301el et l\u2019une de ses applications. Bull. Math. Soc. France,", "citeRegEx": "Bernstein.,? \\Q1924\\E", "shortCiteRegEx": "Bernstein.", "year": 1924}, {"title": "Weakly learning DNF and characterizing statistical query learning using Fourier analysis", "author": ["Avrim Blum", "Merrick Furst", "Jeffrey Jackson", "Michael Kearns", "Yishay Mansour", "Steven Rudich"], "venue": "In Proceedings of the twenty-sixth annual ACM symposium on Theory of computing,", "citeRegEx": "Blum et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1994}, {"title": "\u00c9tude des coefficients de fourier des fonctions de lp(g)", "author": ["Aline Bonami"], "venue": "Annales de l\u2019institut Fourier,", "citeRegEx": "Bonami.,? \\Q1970\\E", "shortCiteRegEx": "Bonami.", "year": 1970}, {"title": "Polynomial regression under arbitrary product distributions", "author": ["Eric Blais", "Ryan O\u2019Donnell", "Karl Wimmer"], "venue": "Machine Learning,", "citeRegEx": "Blais et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Blais et al\\.", "year": 2010}, {"title": "Randomness-efficient oblivious sampling", "author": ["M. Bellare", "J. Rompel"], "venue": "In FOCS,", "citeRegEx": "Bellare and Rompel.,? \\Q1994\\E", "shortCiteRegEx": "Bellare and Rompel.", "year": 1994}, {"title": "Pseudorandom generators for regular branching programs", "author": ["Mark Braverman", "Anup Rao", "Ran Raz", "Amir Yehudayoff"], "venue": null, "citeRegEx": "Braverman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Braverman et al\\.", "year": 2010}, {"title": "The coin problem and pseudorandomness for branching programs", "author": ["Joshua Brody", "Elad Verbin"], "venue": "In FOCS,", "citeRegEx": "Brody and Verbin.,? \\Q2010\\E", "shortCiteRegEx": "Brody and Verbin.", "year": 2010}, {"title": "Bernstein\u2019s approximation problem", "author": ["Lennart Carleson"], "venue": "Proc. Amer. Math. Soc.,", "citeRegEx": "Carleson.,? \\Q1951\\E", "shortCiteRegEx": "Carleson.", "year": 1951}, {"title": "Introduction to Approximation Theory", "author": ["E.W. Cheney"], "venue": "AMS Chelsea Publishing Series. AMS Chelsea Pub.,", "citeRegEx": "Cheney.,? \\Q1982\\E", "shortCiteRegEx": "Cheney.", "year": 1982}, {"title": "Improved pseudorandom generators for depth 2 circuits", "author": ["Anindya De", "Omid Etesami", "Luca Trevisan", "Madhur Tulsiani"], "venue": "Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques,", "citeRegEx": "De et al\\.,? \\Q2010\\E", "shortCiteRegEx": "De et al\\.", "year": 2010}, {"title": "Approximate resilience, monotonicity, and the complexity of agnostic learning", "author": ["Dana Dachman-Soled", "Vitaly Feldman", "Li-Yang Tan", "Andrew Wan", "Karl Wimmer"], "venue": "CoRR, abs/1405.5268,", "citeRegEx": "Dachman.Soled et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dachman.Soled et al\\.", "year": 2014}, {"title": "Bounded independence fools halfspaces", "author": ["Ilias Diakonikolas", "Parikshit Gopalan", "Ragesh Jaiswal", "Rocco A. Servedio", "Emanuele Viola"], "venue": "In In Proc. 50th Annual Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Diakonikolas et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Diakonikolas et al\\.", "year": 2009}, {"title": "The complexity of learning halfspaces using generalized linear methods", "author": ["Amit Daniely", "Nati Linial", "Shai Shalev-Shwartz"], "venue": "CoRR, abs/1211.0616,", "citeRegEx": "Daniely et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2014}, {"title": "A regularity lemma, and low-weight approximators, for low-degree polynomial threshold functions", "author": ["Ilias Diakonikolas", "Rocco A. Servedio", "Li-Yang Tan", "Andrew Wan"], "venue": "In Proceedings of the 2010 IEEE 25th Annual Conference on Computational Complexity,", "citeRegEx": "Diakonikolas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Diakonikolas et al\\.", "year": 2010}, {"title": "Schwankung von polynomen zwischen gitterpunkten", "author": ["H. Ehlich", "K. Zeller"], "venue": "Mathematische Zeitschrift,", "citeRegEx": "Ehlich and Zeller.,? \\Q1964\\E", "shortCiteRegEx": "Ehlich and Zeller.", "year": 1964}, {"title": "New results for learning noisy parities and halfspaces", "author": ["Vitaly Feldman", "Parikshit Gopalan", "Subhash Khot", "Ponnuswami"], "venue": "In Proceedings of the 47th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Feldman et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2006}, {"title": "Agnostic learning of disjunctions on symmetric distributions", "author": ["Vitaly Feldman", "Pravesh Kothari"], "venue": "CoRR, abs/1405.6791,", "citeRegEx": "Feldman and Kothari.,? \\Q2014\\E", "shortCiteRegEx": "Feldman and Kothari.", "year": 2014}, {"title": "Lower bounds and hardness amplification for learning shallow monotone formulas", "author": ["V. Feldman", "H. Lee", "R. Servedio"], "venue": "Journal of Machine Learning Research - COLT Proceedings,", "citeRegEx": "Feldman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2011}, {"title": "Agnostically learning decision trees", "author": ["Parikshit Gopalan", "Adam Tauman Kalai", "Adam R. Klivans"], "venue": "In Cynthia Dwork, editor,", "citeRegEx": "Gopalan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gopalan et al\\.", "year": 2008}, {"title": "Pseudorandomness for concentration bounds and signed majorities", "author": ["Parikshit Gopalan", "Daniel Kane", "Raghu Meka"], "venue": "CoRR, abs/1411.4584,", "citeRegEx": "Gopalan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gopalan et al\\.", "year": 2014}, {"title": "Fooling functions of halfspaces under product distributions", "author": ["Parikshit Gopalan", "Ryan O\u2019Donnell", "Yi Wu", "David Zuckerman"], "venue": "In Proceedings of the 2010 IEEE 25th Annual Conference on Computational Complexity,", "citeRegEx": "Gopalan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gopalan et al\\.", "year": 2010}, {"title": "Hardness of learning halfspaces with noise", "author": ["V. Guruswami", "P. Raghavendra"], "venue": "In Proceedings of FOCS", "citeRegEx": "Guruswami and Raghavendra.,? \\Q2006\\E", "shortCiteRegEx": "Guruswami and Raghavendra.", "year": 2006}, {"title": "Sketching and streaming entropy via approximation theory", "author": ["Nicholas J.A. Harvey", "Jelani Nelson", "Krzysztof Onak"], "venue": "In FOCS,", "citeRegEx": "Harvey et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Harvey et al\\.", "year": 2008}, {"title": "Quasi-analytic class and closure of {tn} in the interval (\u2212\u221e,\u221e)", "author": ["S. Izumi", "T. Kawata"], "venue": "Tohoku Math. J.,", "citeRegEx": "Izumi and Kawata.,? \\Q1937\\E", "shortCiteRegEx": "Izumi and Kawata.", "year": 1937}, {"title": "Pseudorandomness for network algorithms", "author": ["Russell Impagliazzo", "Noam Nisan", "Avi Wigderson"], "venue": "In STOC,", "citeRegEx": "Impagliazzo et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Impagliazzo et al\\.", "year": 1994}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["M. Kearns"], "venue": "Journal of the ACM,", "citeRegEx": "Kearns.,? \\Q1998\\E", "shortCiteRegEx": "Kearns.", "year": 1998}, {"title": "Learning halfspaces under logconcave densities: Polynomial approximations and moment matching", "author": ["Daniel M. Kane", "Adam Klivans", "Raghu Meka"], "venue": "In COLT,", "citeRegEx": "Kane et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kane et al\\.", "year": 2013}, {"title": "Agnostically learning halfspaces", "author": ["Adam Tauman Kalai", "Adam R. Klivans", "Yishay Mansour", "Rocco A. Servedio"], "venue": "SIAM J. Comput.,", "citeRegEx": "Kalai et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kalai et al\\.", "year": 2008}, {"title": "Pseudorandom generators for group products", "author": ["Michal Kouck\u00fd", "Prajakta Nimbhorkar", "Pavel Pudl\u00e1k"], "venue": "In STOC,", "citeRegEx": "Kouck\u00fd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kouck\u00fd et al\\.", "year": 2011}, {"title": "Learning geometric concepts via gaussian surface area", "author": ["Adam R. Klivans", "Ryan O\u2019Donnell", "Rocco A. Servedio"], "venue": "In FOCS,", "citeRegEx": "Klivans et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Klivans et al\\.", "year": 2008}, {"title": "Learning DNF in time 2\u00f5(n 1/3)", "author": ["Adam R. Klivans", "Rocco A. Servedio"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Klivans and Servedio.,? \\Q2004\\E", "shortCiteRegEx": "Klivans and Servedio.", "year": 2004}, {"title": "Unconditional lower bounds for learning intersections of halfspaces", "author": ["Adam R Klivans", "Alexander A Sherstov"], "venue": "Machine Learning,", "citeRegEx": "Klivans and Sherstov.,? \\Q2007\\E", "shortCiteRegEx": "Klivans and Sherstov.", "year": 2007}, {"title": "Cryptographic hardness for learning intersections of halfspaces", "author": ["Adam R. Klivans", "Alexander A. Sherstov"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Klivans and Sherstov.,? \\Q2009\\E", "shortCiteRegEx": "Klivans and Sherstov.", "year": 2009}, {"title": "Lower bounds for agnostic learning via approximate rank", "author": ["Adam R. Klivans", "Alexander A. Sherstov"], "venue": "Computational Complexity,", "citeRegEx": "Klivans and Sherstov.,? \\Q2010\\E", "shortCiteRegEx": "Klivans and Sherstov.", "year": 2010}, {"title": "Toward efficient agnostic learning", "author": ["Michael Kearns", "Robert E. Schapire", "Linda M. Sellie", "Lisa Hellerstein"], "venue": "In Machine Learning,", "citeRegEx": "Kearns et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Kearns et al\\.", "year": 1994}, {"title": "On efficient agnostic learning of linear combinations of basis functions", "author": ["Wee Sun Lee", "Peter L. Bartlett", "Robert C. Williamson"], "venue": "In Proceedings of the Eighth Annual Conference on Computational Learning Theory, COLT", "citeRegEx": "Lee et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Lee et al\\.", "year": 1995}, {"title": "A survey of weighted polynomial approximation with exponential weights", "author": ["Doron Lubinsky"], "venue": "Surveys in Approximation Theory,", "citeRegEx": "Lubinsky.,? \\Q2007\\E", "shortCiteRegEx": "Lubinsky.", "year": 2007}, {"title": "Perceptrons: An Introduction to Computational Geometry", "author": ["Marvin Minsky", "Seymour Papert"], "venue": null, "citeRegEx": "Minsky and Papert.,? \\Q1972\\E", "shortCiteRegEx": "Minsky and Papert.", "year": 1972}, {"title": "Pseudorandom generators for polynomial threshold functions", "author": ["Raghu Meka", "David Zuckerman"], "venue": "In Proceedings of the Forty-second ACM Symposium on Theory of Computing,", "citeRegEx": "Meka and Zuckerman.,? \\Q2010\\E", "shortCiteRegEx": "Meka and Zuckerman.", "year": 2010}, {"title": "G\u00e9za Freud, orthogonal polynomials and Christoffel functions. A case study", "author": ["Paul Nevai"], "venue": "Journal of Approximation Theory,", "citeRegEx": "Nevai.,? \\Q1986\\E", "shortCiteRegEx": "Nevai.", "year": 1986}, {"title": "Small-bias probability spaces: Efficient constructions and applications", "author": ["Joseph Naor", "Moni Naor"], "venue": "SIAM J. Computing,", "citeRegEx": "Naor and Naor.,? \\Q1993\\E", "shortCiteRegEx": "Naor and Naor.", "year": 1993}, {"title": "On the degree of boolean functions as real polynomials", "author": ["N. Nisan", "M. Szegedy"], "venue": "Computational Complexity,", "citeRegEx": "Nisan and Szegedy.,? \\Q1994\\E", "shortCiteRegEx": "Nisan and Szegedy.", "year": 1994}, {"title": "Weighted polynomial inequalities", "author": ["Paul Nevai", "Vilmos Totik"], "venue": "Constructive Approximation,", "citeRegEx": "Nevai and Totik.,? \\Q1986\\E", "shortCiteRegEx": "Nevai and Totik.", "year": 1986}, {"title": "Sharp Nikolskii inequalities with exponential weights", "author": ["P. Nevai", "V. Totik"], "venue": "Analysis Mathematica,", "citeRegEx": "Nevai and Totik.,? \\Q1987\\E", "shortCiteRegEx": "Nevai and Totik.", "year": 1987}, {"title": "Analysis of Boolean Functions", "author": ["Ryan O\u2019Donnell"], "venue": null, "citeRegEx": "O.Donnell.,? \\Q2014\\E", "shortCiteRegEx": "O.Donnell.", "year": 2014}, {"title": "On the degree of polynomials that approximate symmetric boolean functions (preliminary version)", "author": ["Ramamohan Paturi"], "venue": null, "citeRegEx": "Paturi.,? \\Q1992\\E", "shortCiteRegEx": "Paturi.", "year": 1992}, {"title": "A comparison of uniform approximations on an interval and a finite subset thereof", "author": ["T.J. Rivlin", "E.W. Cheney"], "venue": "SIAM J. Numer. Anal.,", "citeRegEx": "Rivlin and Cheney.,? \\Q1966\\E", "shortCiteRegEx": "Rivlin and Cheney.", "year": 1966}, {"title": "Undirected connectivity in log-space", "author": ["Omer Reingold"], "venue": "J. ACM,", "citeRegEx": "Reingold.,? \\Q2008\\E", "shortCiteRegEx": "Reingold.", "year": 2008}, {"title": "Pseudorandomness for regular branching programs via fourier analysis", "author": ["Omer Reingold", "Thomas Steinke", "Salil Vadhan"], "venue": "In APPROX-RANDOM,", "citeRegEx": "Reingold et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Reingold et al\\.", "year": 2013}, {"title": "Communication lower bounds using dual polynomials", "author": ["Alexander A. Sherstov"], "venue": "Bulletin of the EATCS,", "citeRegEx": "Sherstov.,? \\Q2008\\E", "shortCiteRegEx": "Sherstov.", "year": 2008}, {"title": "Separating AC0 from depth-2 majority circuits", "author": ["Alexander A. Sherstov"], "venue": "SIAM J. Comput.,", "citeRegEx": "Sherstov.,? \\Q2009\\E", "shortCiteRegEx": "Sherstov.", "year": 2009}, {"title": "Chernoff\u2013Hoeffding bounds for applications with limited independence", "author": ["J. Schmidt", "A. Siegel", "A. Srinivasan"], "venue": "SIAM J. Discrete Mathematics,", "citeRegEx": "Schmidt et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 1995}, {"title": "Learning kernel-based halfspaces with the 0-1 loss", "author": ["S. Shalev-Shwartz", "O. Shamir", "K. Sridharan"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Faster algorithms via approximation theory", "author": ["Sushant Sachdeva", "Nisheeth K. Vishnoi"], "venue": "Foundations and Trends in Theoretical Computer Science,", "citeRegEx": "Sachdeva and Vishnoi.,? \\Q2014\\E", "shortCiteRegEx": "Sachdeva and Vishnoi.", "year": 2014}, {"title": "A theory of the learnable", "author": ["Leslie G. Valiant"], "venue": "Commun. ACM,", "citeRegEx": "Valiant.,? \\Q1984\\E", "shortCiteRegEx": "Valiant.", "year": 1984}, {"title": "Agnostically learning under permutation invariant distributions", "author": ["Karl Wimmer"], "venue": "In Proceedings of the 2010 IEEE 51st Annual Symposium on Foundations of Computer Science,", "citeRegEx": "Wimmer.,? \\Q2010\\E", "shortCiteRegEx": "Wimmer.", "year": 2010}], "referenceMentions": [], "year": 2014, "abstractText": "Polynomial approximations to boolean functions have led to many positive results in computer science. In particular, polynomial approximations to the sign function underly algorithms for agnostically learning halfspaces, as well as pseudorandom generators for halfspaces. In this work, we investigate the limits of these techniques by proving inapproximability results for the sign function. Firstly, the \u201cpolynomial regression\u201d algorithm of Kalai et al. (SIAM J. Comput. 2008) shows that halfspaces can be learned with respect to log-concave distributions on Rn in the challenging agnostic learning model. The power of this algorithm relies on the fact that under log-concave distributions, halfspaces can be approximated arbitrarily well by low-degree polynomials. We ask whether this technique can be extended beyond log-concave distributions, and establish a negative result. We show that polynomials of any degree cannot approximate the sign function to within arbitrarily low error for a large class of non-log-concave distributions on the real line, including those with densities proportional to exp(\u2212|x|0.99). This impossibility result extends to multivariate distributions, and thus gives a strong limitation on the power of the polynomial regression algorithm for halfspaces. Secondly, we investigate the derandomization of Chernoff-type concentration inequalities. Chernoff-type tail bounds on sums of independent random variables have pervasive applications in theoretical computer science. Schmidt et al. (SIAM J. Discrete Math. 1995) showed that these inequalities can be established for sums of random variables with only O(log(1/\u03b4))-wise independence, for a tail probability of \u03b4. We show that their results are tight up to constant factors. These results rely on techniques from weighted approximation theory, which studies how well functions on the real line can be approximated by polynomials under various distributions. We believe that these techniques will have further applications in other areas of theoretical computer science. Harvard University, School of Engineering and Applied Sciences. Supported by an NDSEG Fellowship and NSF grant CNS-1237235. Harvard University, School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616 and the Lord Rutherford Memorial Research Fellowship.", "creator": "LaTeX with hyperref package"}}}