{"id": "1412.4616", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Dec-2014", "title": "A Broadcast News Corpus for Evaluation and Tuning of German LVCSR Systems", "abstract": "Transcription of broadcast news is an interesting and challenging application for large-vocabulary continuous speech recognition (LVCSR). We present in detail the structure of a manually segmented and annotated corpus including over 160 hours of German broadcast news, and propose it as an evaluation framework of LVCSR systems. We show our own experimental results on the corpus, achieved with a state-of-the-art LVCSR decoder, measuring the effect of different feature sets and decoding parameters, and thereby demonstrate that real-time decoding of our test set is feasible on a desktop PC at 9.2% word error rate.", "histories": [["v1", "Mon, 15 Dec 2014 14:34:38 GMT  (32kb,D)", "http://arxiv.org/abs/1412.4616v1", "submitted to INTERSPEECH 2010 on May 3, 2010"]], "COMMENTS": "submitted to INTERSPEECH 2010 on May 3, 2010", "reviews": [], "SUBJECTS": "cs.CL cs.SD", "authors": ["felix weninger", "bj\\\"orn schuller", "florian eyben", "martin w\\\"ollmer", "gerhard rigoll"], "accepted": false, "id": "1412.4616"}, "pdf": {"name": "1412.4616.pdf", "metadata": {"source": "CRF", "title": "A Broadcast News Corpus for Evaluation and Tuning of German LVCSR Systems", "authors": ["Felix Weninger", "Bj\u00f6rn Schuller", "Florian Eyben", "Martin W\u00f6llmer", "Gerhard Rigoll"], "emails": ["weninger@tum.de", "schuller@tum.de", "eyben@tum.de", "woellmer@tum.de", "rigoll@tum.de"], "sections": [{"heading": null, "text": "Over the past decade, several languages other than English have been covered, including Arabic [3], French [4], German [5] and Mandarin [7]. The process of full transcription is usually divided into a full transcription system, but the audio signal is divided into speech and non-speech parts (e.g. music), and then the language parts are decoded by a speech recognition system. In this paper, we will not aim for a full transcription system."}, {"heading": "2. The Broadcast News Corpus", "text": "The program News (BCN) Corpus was recorded in the years 2000-01 at the University of Duisburg and consists of over 160 hours of German language programming, mainly radio broadcasts, but also news on television (Tagesschau). For the television parts, video is available as an additional modality, e.g. for audiovisual speech recognition, but was not taken into account in our experiments. Audio is sampled at 16 kHz with 16-bit PCM encoding. The audio files correspond to a program of several minutes in length. Segmentation and transcription is included in a flexible XML file format, which is shown in Figure 1. Firstly, each of the audio files is roughly divided into sections, which lead e.g. to jingles at the beginning of the program or voice parts. Each speaking part is divided into sections of different loudspeakers, which are listed at the beginning of the file."}, {"heading": "3. Feature Extraction", "text": "In order to measure how recognition performance affects the 75-dimensional characteristics of the PCP, we extracted three characteristics that we queried for training the PCS models. \"To reduce the number of parameters that we had to estimate for training, we reduced the number of parameters that we had to estimate for training.\" \"To reduce the number of parameters, we had to reduce the number of parameters that we had to estimate for training.\" \"To reduce the number of parameters that we had for acoustic models of the comparable dimensions, we applied to the 75-dimensional characteristics.\" \"To reduce the number of parameters, we have characteristics of the comparable dimensions that we applied.\" To measure the number of parameters that we had to estimate for training, we applied how recognition performance is affected by the 75-dimensional characteristics. \""}, {"heading": "6. Conclusions", "text": "Using a decoding system based on state-of-the-art LVCSR research and an LM vocabulary of 148K, we achieved a real-time word error rate of around 9% on a desktop PC. Various feature sets were evaluated, with PLP coefficients showing the best performance. In addition, we have extensively refined the decoding parameters and identified the beam widths and LM scale factors required to achieve different real-time factors. Comparing our results with previous work on message transcription, we conclude that our results are competitive, especially given that German is a significantly challenging language for LVCSR applications. Of course, comparisons with previous studies must be made very carefully, as our results were developed at a rapid pace based on manually segmented data and the capabilities of PC hardware."}, {"heading": "8. References", "text": "[1] P. Beyerlein, X. Aubert, R. Haeb-Umbach, M. Harris, D. Klakow, A. Wendemuth, S. Molau, H. Ney, M. Pitz, and A. Sixtus, \"Large vocabulary continuous speech recognition of broadcast news - the Philips / RWTH approach,\" Speech Communication, vol. P. 37, pp. 109-131, May 2002. [2] M. J. F. Gales, D. Kim, P. C. Woodland, H. Chan, D. Mrva, R. Sinha, and S. Tranter, \"Progress in the CU-HTK broadcast news transcription system, pp. [2] M. J. F. Gales, D. Rigoll Transactions on Audio, Speech and Language Processing, vol. 14, pp. 1513-1525, 2006. [3] L. Lamel, A. Messaoudi, and J.-L. Gauvain, and J.-L. Gauvain, Improved acoustic modeling data on Audio, Speech and Language Processing G. G. Processing, vol. 14, pp. 1513-1525, 2006."}], "references": [{"title": "Large vocabulary continuous speech recognition of broadcast news \u2013 the Philips/RWTH approach", "author": ["P. Beyerlein", "X. Aubert", "R. Haeb-Umbach", "M. Harris", "D. Klakow", "A. Wendemuth", "S. Molau", "H. Ney", "M. Pitz", "A. Sixtus"], "venue": "Speech Communication, vol. 37, pp. 109\u2013131, May 2002.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Progress in the CU-HTK broadcast news transcription system", "author": ["M.J.F. Gales", "D. Kim", "P.C. Woodland", "H. Chan", "D. Mrva", "R. Sinha", "S. Tranter"], "venue": "IEEE Transactions on Audio, Speech and Language Processing, vol. 14, no. 5, pp. 1513\u20131525, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Improved acoustic modeling for transcribing Arabic broadcast data", "author": ["L. Lamel", "A. Messaoudi", "J.-L. Gauvain"], "venue": "Proc. of Interspeech, Antwerp, Belgium, August 2007.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Where are we in transcribing French broadcast news?", "author": ["J.-L. Gauvain", "G. Adda", "M. Adda-Decker", "A. Allauzen", "V. Gendner", "L. Lamel", "H. Schwenk"], "venue": "in Proc. of Interspeech,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "The ALERT-System: Advanced broadcast speech recognition technology for selective dissemination of multimedia information", "author": ["G. Rigoll"], "venue": "Proc. of ASRU, Madonna di Campiglio Trento, Italy, December 2001.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "The 300k LIMSI German broadcast news transcription system", "author": ["K. McTait", "M. Adda-Decker"], "venue": "Proc. of Eurospeech, Geneva, Switzerland, September 2003.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "The ISL RT04 Mandarin broadcast news evaluation system", "author": ["H. Yu", "Y.-C. Tam", "T. Schaaf", "S. St\u00fcker", "Q. Jin", "M. Noamany", "T. Schultz"], "venue": "Proc. of EARS Rich Transcription Workshop (EARS RT), Palisades, NY, USA, November 2004.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "The CU-HTK broadcast news transcription system", "author": ["R. Sinha", "M.J.F. Gales", "D. Kim", "X. Liu", "K. Sim", "P.C. Woodland"], "venue": "Proc. of ICASSP, Toulouse, France, May 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "The LIMSI broadcast news transcription system", "author": ["J.-L. Gauvain", "L. Lamel", "G. Adda"], "venue": "Speech Communication, vol. 37, no. 1-2, pp. 98\u2013108, 2002.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "openEAR - introducing the Munich open-source Emotion and Affect Recognition toolkit", "author": ["F. Eyben", "M. W\u00f6llmer", "B. Schuller"], "venue": "Proc. of ACII, Amsterdam, Netherlands, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "The HTK book version", "author": ["S.J. Young", "G. Evermann", "M.J.F. Gales", "D. Kershaw", "G. Moore", "J.J. Odell", "D.G. Ollason", "D. Povey", "V. Valtchev", "P.C. Woodland"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Ducoder - the Duisburg University LVCSR stackdecoder", "author": ["D. Willett", "C. Neukirchen", "G. Rigoll"], "venue": "Proc. of ICASSP, Istanbul, Turkey, June 2000, pp. 1555\u20131558.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2000}, {"title": "Nonnegative matrix factorization as noise-robust feature extractor for speech recognition", "author": ["B. Schuller", "F. Weninger", "M. W\u00f6llmer", "Y. Sun", "G. Rigoll"], "venue": "Proc. of ICASSP, Dallas, TX, USA, March 2010, pp. 4562\u20134565.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 37, "endOffset": 43}, {"referenceID": 1, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 37, "endOffset": 43}, {"referenceID": 2, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 92, "endOffset": 95}, {"referenceID": 4, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 104, "endOffset": 110}, {"referenceID": 5, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 104, "endOffset": 110}, {"referenceID": 6, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 125, "endOffset": 131}, {"referenceID": 7, "context": "Various languages apart from English [1, 2] have been covered, including Arabic [3], French [4], German [5, 6], and Mandarin [7, 8].", "startOffset": 125, "endOffset": 131}, {"referenceID": 8, "context": "music), and then the speech parts are decoded by a speech recogniser [9].", "startOffset": 69, "endOffset": 72}, {"referenceID": 4, "context": "This corpus was originally created at Duisburg University in the context of the ALERT project, and used as a whole for training a broadcast news transcription system [5].", "startOffset": 166, "endOffset": 169}, {"referenceID": 5, "context": "German Spracherkennungsproblem = English speech recognition problem) [6].", "startOffset": 69, "endOffset": 72}, {"referenceID": 9, "context": "A baseline set contained Mel Frequency Cepstral Coefficients (MFCC) 1\u201312 and signal log-energy, and their first (\u03b4) and second order regression coefficients (\u03b4\u03b4), which were extracted using the openEAR feature extractor [10], and are identical to the features extracted by the HTK toolkit [11].", "startOffset": 220, "endOffset": 224}, {"referenceID": 10, "context": "A baseline set contained Mel Frequency Cepstral Coefficients (MFCC) 1\u201312 and signal log-energy, and their first (\u03b4) and second order regression coefficients (\u03b4\u03b4), which were extracted using the openEAR feature extractor [10], and are identical to the features extracted by the HTK toolkit [11].", "startOffset": 289, "endOffset": 293}, {"referenceID": 10, "context": "Finally, as a third feature set, we chose the Perceptual Linear Prediction (PLP) coefficients 1\u201312 along with log-energy and their \u03b4 and \u03b4\u03b4 coefficients, computed with HTK [11].", "startOffset": 172, "endOffset": 176}, {"referenceID": 4, "context": "In contrast to previous work on German broadcast data [5] using the \u201cDucoder\u201d stack decoder [12], we implemented a LVCSR system on top of HDecode [11].", "startOffset": 54, "endOffset": 57}, {"referenceID": 11, "context": "In contrast to previous work on German broadcast data [5] using the \u201cDucoder\u201d stack decoder [12], we implemented a LVCSR system on top of HDecode [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 10, "context": "In contrast to previous work on German broadcast data [5] using the \u201cDucoder\u201d stack decoder [12], we implemented a LVCSR system on top of HDecode [11].", "startOffset": 146, "endOffset": 150}, {"referenceID": 4, "context": "As has been shown in [5], using a domain-specific language model (LM) can vastly increase recognition rate.", "startOffset": 21, "endOffset": 24}, {"referenceID": 11, "context": "400 megabytes in ARPA format, hence the LM fits well into the memory of a state-of-the-art PC, and for our purpose no special effort to cope with memory requirements was needed, unlike in [12].", "startOffset": 188, "endOffset": 192}, {"referenceID": 10, "context": "Table 4 shows the perplexity \u2013 measured by the method described in [11] \u2013 of the transcription of the training, development, and test sets, and the BCN corpus as a whole, using the unigram, bigram, and trigram LM.", "startOffset": 67, "endOffset": 71}, {"referenceID": 5, "context": "As a final note concerning WER, it is noteworthy that sometimes calculation of WER for German speech takes into account equivalence classes for compound words [6].", "startOffset": 159, "endOffset": 162}, {"referenceID": 12, "context": "While both of these have been successfully used in whole-word recognition tasks [13], it will be an interesting research topic to assess their usefulness for German LVCSR.", "startOffset": 80, "endOffset": 84}], "year": 2014, "abstractText": "Transcription of broadcast news is an interesting and challenging application for large-vocabulary continuous speech recognition (LVCSR). We present in detail the structure of a manually segmented and annotated corpus including over 160 hours of German broadcast news, and propose it as an evaluation framework of LVCSR systems. We show our own experimental results on the corpus, achieved with a state-of-the-art LVCSR decoder, measuring the effect of different feature sets and decoding parameters, and thereby demonstrate that real-time decoding of our test set is feasible on a desktop PC at 9.2 % word error rate.", "creator": "LaTeX with hyperref package"}}}