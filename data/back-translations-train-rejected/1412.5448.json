{"id": "1412.5448", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Dec-2014", "title": "Extended Recommendation Framework: Generating the Text of a User Review as a Personalized Summary", "abstract": "We propose to augment rating based recommender systems by providing the user with additional information which might help him in his choice or in the understanding of the recommendation. We consider here as a new task, the generation of personalized reviews associated to items. We use an extractive summary formulation for generating these reviews. We also show that the two information sources, ratings and items could be used both for estimating ratings and for generating summaries, leading to improved performance for each system compared to the use of a single source. Besides these two contributions, we show how a personalized polarity classifier can integrate the rating and textual aspects. Overall, the proposed system offers the user three personalized hints for a recommendation: rating, text and polarity. We evaluate these three components on two datasets using appropriate measures for each task.", "histories": [["v1", "Wed, 17 Dec 2014 15:46:28 GMT  (1535kb,D)", "http://arxiv.org/abs/1412.5448v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["micka\\\"el poussevin", "vincent guigue", "patrick gallinari"], "accepted": false, "id": "1412.5448"}, "pdf": {"name": "1412.5448.pdf", "metadata": {"source": "CRF", "title": "Extended Recommendation Framework: Generating the Text of a User Review as a Personalized Summary", "authors": ["Micka\u00ebl Poussevin", "Vincent Guigue", "Patrick Gallinari"], "emails": ["mickael.poussevin@lip6.fr", "vincent.guigue@lip6.fr", "patrick.gallinari@lip6.fr"], "sections": [{"heading": "1. INTRODUCTION", "text": "The emergence of the participatory web has enabled users to predict their sensations on many different levels. Therefore, this idiosyncratic flood of data is growing rapidly and offers opportunities for multiple applications such as e-reputation management or recommendations. Today, many e-commerce sites are able to provide each individual element on their platform with a description of its characteristics, and the ratings of individual users explain their ratings. Our focus is on exploiting users. This is a multi-faceted task in which different sources of information about users and articles made available to the user could be viewed. Despite this diversity, the academic literature has focused on recommendations only a few specific tasks. The most popular is certainly predicting user preferences based on their previous rating profiles. These systems are usually relyPermission to create digital or hard copies of all or part of this work for the personal or classroom, is granted free of charge."}, {"heading": "2. MODELS", "text": "In this section, after introducing the notations used throughout the essay, we describe the three modules of our system one after the other. We begin by looking at the prediction of ratings [14]. Evaluation forecasters answer the following question: What rating will this user give to this article? We present a simple and efficient way to introduce text profiles that represent the user's writing style and taste in a hybrid formulation. We then show how ratings and ratings can be used in a new challenging task: What text will this user write about this article? We propose an extractive summary formulation of this task. We then describe how both ratings and text could be used in a personalized mood classifier."}, {"heading": "2.1 Notations", "text": "Similarly, lower case letters are used for scalars or vectors and uppercase letters are used for matrices. dui is the actual review text written by the user u for element i. It consists of two sentences: dui = {suik, 1 \u2264 k \u2264 \u043fui}. In this thesis, we consider documents to be bags of sentences. To simplify notation, suik is replaced by sui when there is no ambiguity. Thus, user ratings are quadrupled (u, i, rui, rui, dui). Recommendation systems use past information to calculate a rating for the user. To simplify notation, suik is replaced by sui when there is no ambiguity. Thus, user ratings are quadrupled (u, i, rui, dui, dui, dui). Recommendation systems use prior information to calculate a rating for the user."}, {"heading": "2.2 Hybrid recommender system with text profiles", "text": "The hybrid system described here uses both collaborative filtering methods to generate a rating as described in (2). The fourth predictor is a classic matrix factorization term. The novelty of our model comes from the fifth term (2), which takes the text profiles into account to refine the f prediction."}, {"heading": "2.3 Text generation model", "text": "The aim here is to generate a review text for each (u, i) recommendation. During the recommendation process, this text is an additional piece of information for users to take into account, it should arouse their interest and in principle resemble the one that user u \"may have written on point i. Each text is created as an extractive summary, with the extracted sentences u\" i coming from the ratings of other users (u \"6 = u\"). Selection of the sentence is made according to a criterion that has a similarity between the sentence and the textual user profile and a similarity between the actual rating ru \"i\" and the prediction made for (u \"i\"), r \"ui\" as described in Section 2.2. The former measure could take into account several dimensions such as vocabulary, sensory expression and even style, here it is mainly the vocabulary that is exploited, the latter measuring the proximity between user taste."}, {"heading": "2.4 Sentiment prediction model", "text": "We show here, as an example, how polarity information about an element can be generated by evaluating both the predicted user ratings and his textual profile. It will be shown that using both sources of information improves sentiment prediction performance compared to a standard text-based sentiment classification. Polarity classification [19] is the task of predicting whether a text dui (in this case a review) is positive or negative. We use the threshold rui ratings as a basis and follow a standard threshold classification [18]: ratings 1 or 2 are considered negative, while items 4 or 5 are rated positive. All texts rated 3 are ignored, as it is unclear whether thatData: u, i, S = (su \"i\" i \"i\" i \"u\") result: d \"i\" s \"s\" i \"s\" s \"i\" s \"s\" s \"s\" s \"s\" s \"s\"."}, {"heading": "3. EXPERIMENTS", "text": "All three modules, reviews, text, sensations, are evaluated independently as there is no global rating framework, but these individual reviews should together provide a quantitative assessment of the entire system.We use two real sets of user ratings collected by amazon.com [11] and ratebeer.com [14].Their characteristics are presented in Table 1, showing how records are pre-processed in 3.1. The benefits of including the text in the rating forecast for the recommendation system are then discussed in Section 3.2. The quality of the ratings generated is evaluated and analysed in Section 3.3. Finally, the performance of the mood classifier, which combines text and ratings, is described in Section 3.4."}, {"heading": "3.1 Data preprocessing", "text": "Ratings from different websites have different formats (rating scales, multiple ratings,...), they are then pre-processed into a uniform format. Ratings are scaled to an integer range of 1 to 5. In titled ratings, the title is considered as the first sentence of the review text. Each data set is randomly divided into three parts: Training, validation and test, each containing 80%, 10% and 10% of the values.As described in 2.2, two text presentations are each considered with a different dictionary: \u2022 for the autoencoder, we have selected the 5000 most common words, with one stop word removal step; the autoencoder input vector is then a binary vector of the dimension 5000. \u2022 for the raw representation, we have selected the 100,000 most common words, which appear in more than 10 documents (including stopwords) and used a binary vector representation.For the experiments, we look at several subsets of users, each of which is assigned to the number of different elements in most different databases."}, {"heading": "3.2 Recommender system evaluation", "text": "The metric used here is the mean square error (MSE) between valuation forecasts and actual ratings rui. The lower the MSE, the better the model is able to estimate the match between user taste and items. Results are referenced in Table 2.The models are referenced using the notations introduced in Section 2.2. The first column corresponds to a trivial system that predicts general bias, the second predicts user bias \u00b5u. Both give poor performance as expected. The third column corresponds to the Item bias \u00b5i baseline. It assumes that user taste is not relevant and that each item has its own intrinsic quality. Improvement in terms of \u00b5 and \u00b5u is important because MSE is halved. The fourth column corresponds to a non-negative matrix factoring basis that is referred to as the basis."}, {"heading": "3.3 Text generation evaluation", "text": "It is about the evaluation of the personalized review text generation. Since we use an extractive summary procedure, we use a classic loss, which is used for summaries. Thus, the quality of the prediction is evaluated with a retrievable number of sentences, which compare the generated text with the actual text of the user. As said, this is a rare case in which a generated summary can be compared with the actual text written by a user. As far as we know, the generation of candidate sentences has never been dealt with in this context and this is a novel task. ROUGE-n Metric is the ratio of n-grams of the actual text. (candidate) text is used here three metrics: ROUGE-2 and ROUGE-3. The higher quality of the candidate text is the quality of the candidate text."}, {"heading": "3.4 Sentiment classification evaluation", "text": "The performance of the various models that use the sentiment classification error as a yardstick is shown in Table 3. As they perform very poorly, the bias recommendation models (\u00b5 and \u00b5u) are not presented here. Item bias \u00b5i, second column, indicates a baseline that is enhanced by matrix factorization \u03b3u.\u03b3i, third column. Our hybrid models fA, fourth column, and fT, fifth column, exhibit lower classification errors than any other recommendation system. The first column, LL, is the linear support vector engine (SVM) baseline. It was learned from the training texts, and the regulation hyperparameter was selected on the basis of the validation set. Our implementation is based on liblinear (LL) [6]. Its performance is better than that of the recommendation systems, but it should be noted that they use the actual textual reference of the user information, while referring only to the earlier review systems."}, {"heading": "4. OVERALL GAINS", "text": "The metric depends on the task. Results are shown in Figure 3.For the mean square error metric, shown in Figure 3a, matrix factorization is used as the starting point, as it is the most common approach in literature. User retention fails greatly in generalizing two sets of data and has a negative gain: \u2212 69.07%. Itembias is closer to the baseline (\u2212 11.43%). Our hybrid models, which use text to discard user and item profiles, yield a gain of 5.71% for fA, 5.63% for fT. This shows an interest in integrating textual information into the recipient system."}, {"heading": "5. RELATED WORK", "text": "Since the paper deals with the topics of rating prediction, summary and mood classification, we briefly introduce them in the following sections and position ourselves in this context. Afterwards, we discuss current work that combines or provides different sources of information."}, {"heading": "5.1 Recommender systems", "text": "Three main families of recommendation algorithms have been developed [5]: content-based knowledge-based filtering and collaborative filtering [12]. Given the focus of this work on consumer reviews, we considered collaborative filtering. These systems are inherently user-centered, as they solve the problem of selecting items to be recommended to a user based on their previous actions. In the case of merchant websites, the goal is to encourage users to purchase new products, and the problem is usually viewed either as predicting a ranking of relevant articles for each user [4, 16] or as completing missing reviews [20, 12]. Here, we have focused on the latter approach to valuation issues: since we use data from third-party sources (amazon.com and ratebeer.com), we would not be able to dynamically evaluate the quality of a ranking."}, {"heading": "5.2 Text summarization for consumer reviews", "text": "Early reference books [10] on consumer ratings focused on a global summary of user ratings for each element. The motivation behind this work was to extract from all article review texts the feelings associated with a list of attributes, and the summary took the form of a rating or an appreciation of each feature. In contrast to this work, the emphasis here is on personalized article summaries for a target user. Given the difficulty of creating a comprehensive synthetic summary, we have turned this issue into a sentence or text selection procedure. Evaluating summaries is a challenge: how do we assess the quality of a summary when the basic truth is subjective? In our context, the summary texts are available and we have used them as a basic truth. We have used classical summary rating benchmarks [13]."}, {"heading": "5.3 Sentiment classification", "text": "Various latent text representations have been proposed within this framework: [17] proposed a generative model for the common representation of themes and feelings, and more recently several papers have considered the factorization of matrices or neural networks to develop robust systems for the recognition of feelings [8]. [21] go further and propose to learn two types of representation: a vector model is learned for the representation of words along with a latent transformation model that allows the representation of negation and quantifiers related to an expression. We have examined two types of representation for texts: dictionaries and a latent representation through the use of autoencoders as in [8]. [14] also use a latent representation for the representation of reviews, albeit in a probable environment rather than in a deterministic one such as here."}, {"heading": "5.4 Hybrid approaches", "text": "In the area of recommendations, a first hybrid model of [7] has been proposed: it is based on the manual marking of rating sets (topic and polarity) to identify relevant characteristics of the articles. Our approach does not require such manual marking. [14] However, recently an explanation for a recommendation system was introduced, proposing to extract some keywords from the rating texts to explain why a user likes or dislikes an element. This is probably the work whose spirit most closely coincides with ours, but the components of their system are not associated with any common variables."}, {"heading": "6. CONCLUSION", "text": "This article proposes an expanded framework for the recommendation task. The overall goal is to enrich classical recommendation systems with multiple dimensions. As an example, we will show how to create personalized ratings for each recommendation using extracted summaries. This is our main contribution. We will also show how ratings and texts can be used to create efficient personalized sentiment classifiers for each recommendation. Depending on the application, additional information could be provided to the user. In addition to generating additional information for the user, the different information sources can benefit from each other. This is particularly interesting as multiple sources are now effectively available on many online pages. Several new applications could be developed along the lines suggested here. From a modeling perspective, more sophisticated approaches can be developed."}, {"heading": "7. REFERENCES", "text": "[1] D Agarwal, BC Chen, and B Pang. Personalizedrecommendation of user comments via factor models. EMNLP '11, pp. 571-582, 2011. [2] M Amini and Nicolas Usunier. A contextual query review approach by term clustering for robust text summarization. DUC' 07, 2007. [3] John Blitzer, Mark Dredze, and Fernando Pereira. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. In Association for Computational Linguistics, 2007. [4] JS Breese, D Heckerman, and C Kadie. Empirical Analysis of Collaborative Algorithms for Collaborative Filtering. Technical Report, 1998. [5] Robin Burke. Hybrid recommender systems: Survey and experiments."}, {"heading": "A. RESULT TABLES FOR ROUGE-N METRICS", "text": "This appendix collects the result tables of ROUGEn metrics on all datasets, for all prediction methods and all models as described in Section 3.3. The performance of all datasets extracted from ratebeer.com and amazon.com, respectively, can be found in Tables A4 and A5, respectively. The full name is used instead of abbreviations in the first column of the table to name each generation procedure; the abbreviations were CT, 1S and XS for each Full Text, Single Sentence and Sentence in the text and in the histograms 2. The description of the size of the various datasets is available in 1, the datasets grow in the number of reviews (and users and items) from left to right. Greedily refers to our selection algorithm 1, which is presented in Section 2.3."}], "references": [{"title": "Personalized recommendation of user comments via factor models", "author": ["D Agarwal", "BC Chen", "B Pang"], "venue": "EMNLP\u201911, pages 571\u2013582", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "A contextual query expansion approach by term clustering for robust text summarization", "author": ["M Amini", "Nicolas Usunier"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification", "author": ["John Blitzer", "Mark Dredze", "Fernando Pereira"], "venue": "In Association for Computational Linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Empirical analysis of predictive algorithms for collaborative filtering", "author": ["JS Breese", "D Heckerman", "C Kadie"], "venue": "Technical report", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "Hybrid recommender systems: Survey and experiments. UMUAI\u201902", "author": ["Robin Burke"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Liblinear: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Beyond the Stars: Improving Rating Predictions using Review", "author": ["Gayatree Ganu", "N Elhadad", "A Marian"], "venue": "Text Content", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "In ICML\u201911,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu"], "venue": "KDD \u201904,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Opinion extraction and summarization on the web", "author": ["Minqing Hu", "Bing Liu"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Opinion spam and analysis", "author": ["Nitin Jindal", "Bing Liu"], "venue": "In Proceedings of the 2008 International Conference on Web Search and Data Mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Yehuda Koren", "Robert Bell", "Chris Volinsky"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin"], "venue": "In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Hidden factors and hidden topics: understanding rating dimensions with review text", "author": ["J McAuley", "J Leskovec"], "venue": "RecSys\u201913", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "author": ["JJ McAuley", "J Leskovec"], "venue": "WWW\u201913", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "A Collaborative Filtering Algorithm and Evaluation Metric That Accurately Model the User Experience", "author": ["Matthew R McLaughlin", "Jonathan L Herlocker"], "venue": "In SIGIR\u201904,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Topic sentiment mixture: modeling facets and opinions in weblogs", "author": ["Qiaozhu Mei", "Xu Ling", "Matthew Wondra", "Hang Su", "ChengXiang Zhai"], "venue": "In WWW\u201907,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Opinion mining and sentiment analysis", "author": ["B Pang", "L Lee"], "venue": "Foundations and trends in information retrieval, 1(2):91\u2013231", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Thumbs up?: sentiment classification using machine learning techniques", "author": ["Bo Pang", "Lillian Lee", "S Vaithyanathan"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Semantic compositionality through recursive matrix-vector spaces. In EMNLP\u201912, pages 1201\u20131211", "author": ["Richard Socher", "Brody Huval", "Christopher D Manning", "Andrew Y Ng"], "venue": "Association for Computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "To each his own: personalized content selection based on text comprehensibility", "author": ["Chenhao Tan", "Evgeniy Gabrilovich", "Bo Pang"], "venue": "In ICWDM\u201912,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "User-level sentiment analysis incorporating social networks", "author": ["Chenhao Tan", "Lillian Lee", "Jie Tang", "Long Jiang", "Ming Zhou", "Ping Li"], "venue": "In KDD\u201911,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis", "author": ["Yongfeng Zhang", "Guokun Lai", "Min Zhang", "Yi Zhang", "Yiqun Liu", "Shaoping Ma"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}], "referenceMentions": [{"referenceID": 11, "context": "on collaborative filtering [12] to predict missing values in a user/item/rating matrix.", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "[7] proposed to extract topics from consumer reviews in order to improve ratings predictions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "Recently, [14] proposed to learn a latent space common to both textual reviews and product ratings, they showed that rating prediction was improved by such hybrid recommender systems.", "startOffset": 10, "endOffset": 14}, {"referenceID": 0, "context": "Concerning the information provided to the user, some models exploit review texts for ranking comments that users may like [1] or for answering specific user queries [22].", "startOffset": 123, "endOffset": 126}, {"referenceID": 20, "context": "Concerning the information provided to the user, some models exploit review texts for ranking comments that users may like [1] or for answering specific user queries [22].", "startOffset": 166, "endOffset": 170}, {"referenceID": 1, "context": "Since pure text generation is a very challenging task [2], we adopt an extractive sumar X iv :1 41 2.", "startOffset": 54, "endOffset": 57}, {"referenceID": 13, "context": "We start by considering the prediction of ratings [14].", "startOffset": 50, "endOffset": 54}, {"referenceID": 7, "context": "We use the settings proposed in [8]: our dictionary is obtained after stopwords removal and selecting the most frequent 5000 words.", "startOffset": 32, "endOffset": 35}, {"referenceID": 13, "context": "As motivated in [14, 7], such a latent representation helps exploiting term co-occurrences and thus introduces some semantic.", "startOffset": 16, "endOffset": 23}, {"referenceID": 6, "context": "As motivated in [14, 7], such a latent representation helps exploiting term co-occurrences and thus introduces some semantic.", "startOffset": 16, "endOffset": 23}, {"referenceID": 18, "context": "Polarity classification [19] is the task of predicting whether a text dui (here of a review) is positive or negative.", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "We use as ground truth the ratings rui and follow a standard thresholding procedure [18]: reviews rated 1 or 2 are considered as negative, while items rated 4 or 5 are positive.", "startOffset": 84, "endOffset": 88}, {"referenceID": 10, "context": "com [11] and ratebeer.", "startOffset": 4, "endOffset": 8}, {"referenceID": 13, "context": "com [14].", "startOffset": 4, "endOffset": 8}, {"referenceID": 5, "context": "Our implementation relies on liblinear (LL) [6].", "startOffset": 44, "endOffset": 47}, {"referenceID": 4, "context": "Three main families of recommendation algorithms have been developed [5]: content-based knowledge-based, and collaborative filtering[12].", "startOffset": 69, "endOffset": 72}, {"referenceID": 11, "context": "Three main families of recommendation algorithms have been developed [5]: content-based knowledge-based, and collaborative filtering[12].", "startOffset": 132, "endOffset": 136}, {"referenceID": 3, "context": "For merchant websites the goal is to encourage users to buy new products and the problem is usually considered either as the prediction of a ranked list of relevant items for each user [4, 16] or as the completion of missing ratings [20, 12].", "startOffset": 185, "endOffset": 192}, {"referenceID": 15, "context": "For merchant websites the goal is to encourage users to buy new products and the problem is usually considered either as the prediction of a ranked list of relevant items for each user [4, 16] or as the completion of missing ratings [20, 12].", "startOffset": 185, "endOffset": 192}, {"referenceID": 11, "context": "For merchant websites the goal is to encourage users to buy new products and the problem is usually considered either as the prediction of a ranked list of relevant items for each user [4, 16] or as the completion of missing ratings [20, 12].", "startOffset": 233, "endOffset": 241}, {"referenceID": 9, "context": "Early reference work [10] on consumer reviews has focused on global summarization of user reviews for each item.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "We have used classical ROUGE-n summary evaluation measures [13].", "startOffset": 59, "endOffset": 63}, {"referenceID": 16, "context": "Different text latent representations have been proposed in this scope: [17] proposed a generative model to represent jointly topic and sentiments and recently, several works have considered matrix factorization or neural network, in an attempts to develop robust sentiment recognition systems [8].", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "Different text latent representations have been proposed in this scope: [17] proposed a generative model to represent jointly topic and sentiments and recently, several works have considered matrix factorization or neural network, in an attempts to develop robust sentiment recognition systems [8].", "startOffset": 294, "endOffset": 297}, {"referenceID": 19, "context": "[21] go further and propose to learn two types of representation: a vectorial model is learned for word representation together with a latent transformation model, which allows the representation of negation and quantifiers associated to an expression.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "We have investigated two kinds of representation for the texts: bag of words and a latent representation through the use of autoencoders as in [8].", "startOffset": 143, "endOffset": 146}, {"referenceID": 13, "context": "[14] also use a latent representation for representing reviews, although in a probabilistic setting instead in a deterministic one like we are doing here.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "In the field of recommendation, a first hybrid model was proposed by [7]: it is based on hand labeling of review sentences (topic and polarity) to identify relevant characteristics of the items.", "startOffset": 69, "endOffset": 72}, {"referenceID": 13, "context": "[14] pushes further the exploitation of texts, by using a joint latent representation for ratings and textual content with the objective of improving the rating accuracy.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Very recently, [24] has considered adding an explanation component to a recommender system.", "startOffset": 15, "endOffset": 19}, {"referenceID": 8, "context": "[9, 10] combined opinion mining and text summarization on product reviews with the goal of summarizing the qualities and defaults of the items.", "startOffset": 0, "endOffset": 7}, {"referenceID": 9, "context": "[9, 10] combined opinion mining and text summarization on product reviews with the goal of summarizing the qualities and defaults of the items.", "startOffset": 0, "endOffset": 7}, {"referenceID": 20, "context": "[22] proposed a system for delivering personalized answers to user queries on specific products.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] proposed a per-", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "For a long time, sentiment classification has ignored the user dimension and has focused for example on the conception of \u201duniversal\u201d sentiment classifiers able to deal with a large variety of topics [3].", "startOffset": 200, "endOffset": 203}, {"referenceID": 21, "context": "[23] for example exploited explicit relations in social graphs for improving opinion classifiers, but their work is only focused on this aspect.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] proposed to distinguish different rating behaviors and show that modeling the review authors in a scale ranging from connoisseur to expert offers a significant gain for an opinion classification task.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In another work, they integrate the textual data written by each user in the recommendation process [14].", "startOffset": 100, "endOffset": 104}], "year": 2014, "abstractText": "We propose to augment rating based recommender systems by providing the user with additional information which might help him in his choice or in the understanding of the recommendation. We consider here as a new task, the generation of personalized reviews associated to items. We use an extractive summary formulation for generating these reviews. We also show that the two information sources, ratings and items could be used both for estimating ratings and for generating summaries, leading to improved performance for each system compared to the use of a single source. Besides these two contributions, we show how a personalized polarity classifier can integrate the rating and textual aspects. Overall, the proposed system offers the user three personalized hints for a recommendation: rating, text and polarity. We evaluate these three components on two datasets using appropriate measures for each task.", "creator": "LaTeX with hyperref package"}}}