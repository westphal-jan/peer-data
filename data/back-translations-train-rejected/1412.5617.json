{"id": "1412.5617", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Dec-2014", "title": "Learning from Data with Heterogeneous Noise using SGD", "abstract": "We consider learning from data of variable quality that may be obtained from different heterogeneous sources. Addressing learning from heterogeneous data in its full generality is a challenging problem. In this paper, we adopt instead a model in which data is observed through heterogeneous noise, where the noise level reflects the quality of the data source. We study how to use stochastic gradient algorithms to learn in this model. Our study is motivated by two concrete examples where this problem arises naturally: learning with local differential privacy based on data from multiple sources with different privacy requirements, and learning from data with labels of variable quality.", "histories": [["v1", "Wed, 17 Dec 2014 21:15:06 GMT  (42kb,D)", "http://arxiv.org/abs/1412.5617v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["shuang song", "kamalika chaudhuri", "anand d sarwate"], "accepted": false, "id": "1412.5617"}, "pdf": {"name": "1412.5617.pdf", "metadata": {"source": "CRF", "title": "Learning from Data with Heterogeneous Noise using SGD", "authors": ["Shuang Song", "Kamalika Chaudhuri", "Anand D. Sarwate"], "emails": ["shs037@eng.ucsd.edu", "kamalika@cs.ucsd.edu", "asarwate@ece.rutgers.edu"], "sections": [{"heading": null, "text": "We show that for two sets of data with heterogeneous noise, the order in which they are used in standard SGD depends on the learning rate. We propose a method to change the learning rate depending on heterogeneity, and in two interesting cases show new limits of regret for our method. Experiments with real data show that our method performs better than with a single learning rate and only with the less noisy of the two sets when the noise level is low to moderate."}, {"heading": "1 Introduction", "text": "In many cases, we are dealing with a lot of data that we are able to collect and analyze a lot of different types of data, how they are able to collect a certain kind of data. (It is about the way in which the data comes from different sources) (It is about the way in which the data comes from different sources.) In this paper, we adopt a model in which the data is observed by heterogenetic noise, in which the noise reflects the quality of the data sources. We study how to use stochastic gradient algorithms to learn from heterogeneous qualities. (It is about the full generality, which is essentially the problem of domain adaptation - a challenge for which good and complete solutions are difficult to obtain.) Instead, we focus on the specific case of heterogenetic disorders and show how to use information to learn the quality of heterogeneous qualities."}, {"heading": "2 The Model", "text": "We look at the linear classification in the presence of noise. We get T-marked examples (x1, y1),.., (xT, yT) where xi-Rd and yi-Wf (w) and our goal is to find a hyperplane w that largely separates the examples labeled with \u2212 1 from those labeled with \u2212 1. A standard solution consists of the following convex optimization problem: w-Wf (w) = argmin w-Wf (w): = 2 x, y) = log (1 + e-jw > x) and the hinge loss' (w, x, y) = max (0, 1 \u2212 jw > x). Popular choices for \"include the logistic loss' (w, x, y) = log (1 + e \u2212 jw > x) and the hinge loss' (w, y) = max (0 \u2212 jw > x). Stochastic gradient deviation (GSD) is a precedent (S1), SD (S1)."}, {"heading": "2.1 The Heterogeneous Noise Model", "text": "We propose an abstract model of heterogeneous noise that can be specialized in two important scenarios: differentiated private learning and random classification noise. By heterogeneous noise, we mean that the distribution of noise can depend on the data points themselves. Formally, we assume that the learning algorithm can only access the designated data through an oracle G, which draws a fresh independent sample (x, y) from the underlying data distribution based on a w-Rd value and returns an unbiased gradient of the objective function f (w), based on the example (x, y): E [G (w)] = inconclusive sample (w, x, y), E [G (w), 2] \u2264 0 value. (3) The exact way in which G (w) is generated depends on the application."}, {"heading": "2.1.1 Local Differential Privacy", "text": "Local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012; Kasiviswanathan et al., 2008) is a strong notion of privacy motivated by differential privacy (Dwork et al., 2006b). An untrusted algorithm may access a disturbed version of a sensitive data set through a cleanup interface and must use that disturbed data to perform an estimate. The level of disturbance is controlled by a parameter that measures privacy. Definition 1 (Local differential privacy). Let D = (X1,., Xn) be a sensitive dataset in which each Xi-D model matches the data via individual i."}, {"heading": "2.1.2 Random Classification Noise", "text": "In the random classification noise model of Kearns (1998), the learning algorithm is presented on the basis of examples (x1, y-1),.., (xT, y-T) in which each y-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i (7) results in a linear classification scenario from data with random classification noise, which is an ambient loss function corresponding to a convex loss \":\" (w, x, y-i-i-i-i-i-w-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-ii-igem-i-i-i-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-ii-"}, {"heading": "3 Data order depends on learning rate", "text": "Suppose we have two oracles GC (for \"clean\") and GN (for \"noisy\"), which are based on DC, DN with noise levels of \"C,\" \"N\" (for \"clean\") and \"GN\" (for \"noisy\"). (...) Let us suppose that the answer depends on the learning rate. (...) We show a specific example of a convex optimization problem, which is with \"c / t,\" the optimal sequence when GC is used first, and the optimal sequence is that the GN is used first when c. \"(...) and the optimal sequence is that the GN is used first, and the optimal sequence is when c.\" (...)."}, {"heading": "4 Adapting the learning rate to the noise level", "text": "We are now examining whether the performance of SGD with different learning rates can be improved by applying different learning rates to oracles with different sound levels. (Suppose we have Oracle G1 and G2 with sound levels G1 and G2 based on two sets of data D1 and D2.) Unlike the previous section, we do not assume that there is any relationship between 1 and 2 - we analyze the error for using Oracle G1, followed by G2 and G2 to select a data order. Let T = D1 | T and \u03b22 = 1 \u2212 \u03b21 \u2212 \u03b21 adjust the fraction of data coming from G1 and G2 accordingly. We adjust the gradient updates to heterogeneous sounds by selecting the learning rate as a function of the sound level. Algorithm 1 shows a modified SGD for heterogeneous learning rates.Algorithm 1 with different learning algorithms: we implement the results of G2."}, {"heading": "4.1 Algorithm description", "text": "Our algorithm for selecting c1 and c2 is motivated by theorem 3. We propose an algorithm that selects c1 and c2 by minimizing the number B (c1, c2), which contains the highest terms in theorem 3: B (c1, c2) = 4\u0445 21\u03b2 2\u03bbc2 \u2212 1 c 2 1T (2\u03bbc1 \u2212 1) + 4\u0445 22 (1 \u2212 \u03b2 2\u03bbc2 \u2212 1) c 2 2T (2\u03bbc2 \u2212 1). (13) Given that we use c1, 2 and \u03b21, we use the values of c1 and c2, which minimize the values of c1 and c2 (c1, c2)."}, {"heading": "4.2 Regret Bounds", "text": "To express a regret about the performance of SGD with two learning rates, we need to include the optimal values of c1 and c2 in the right side of (13). Note that since c1 = c2 and c2 = 0 are a viable solution, our algorithm has a superior regret with respect to (13) than only a single learning rate is used, or only with clean data. In this section, we will consider two cases of interest, and derive simplified versions of regret for SGD with two learning rates for these cases. We will consider the two data requests (1, 2) = (1, 2) and (1, 2)."}, {"heading": "5 Experiments", "text": "Next, we illustrate our theoretical results by experimenting with real data. We consider the task of training as a regularized logistic regression classification for binary classification under local, differentiated privacy. For our experiments, we consider two real datasets - MNIST (with task 1 versus rest) and covertype (type 2 versus rest). The former consists of 60,000 samples in 784 dimensions, while the latter consists of 500,000 samples in 54 dimensions. We reduce the dimension of the MNIST dataset to 25 via random projections. To investigate the effects of heterogeneous disturbances, we divide the training data into subsets (DC, DN) to be accessed by oracles (GC, GN) with privacy parameters (C, N) each. We choose C > N, i.e. GN is more noisier than GC. To simulate typical practical situations where cleaner data is rare, we put the totality of the DC = 10% of the size of the data."}, {"heading": "6 Conclusion", "text": "In this paper, we propose a model to learn from heterogeneous noise that is suitable for studying stochastic gradient approaches to learning. In our model, data from different locations is accessed by different oracles that provide noisy versions of the gradient. Learning under local differential data protection and random classification noise are both examples of our model. We show that for two locations with different noise levels, processing data from one location followed by the other is better than randomly scanning the data, and the optimal order of data depends on the learning rate. We then provide a method for selecting the learning rates that depend on the noise level, and showed that these decisions achieve less remorse than using a common learning rate. We confirm these results by experimenting with two standard data sets and show that our method of selecting learning rates often brings improvements when the noise levels are moderate. In the case where a data set is much louder than the one we choose, the method is much louder than the one we use today."}, {"heading": "A Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Mathematical miscellany", "text": "For x \u2265 0 we have i = a ix \u2264 \u0445 b + 1 a ixdi = (b + 1) x + 1 \u2212 ax + 1 x + 1 (14) b = a ix \u2264 b a \u2212 1 ixdi = bx + 1 \u2212 (a \u2212 1) x + 1 x + 1 (15) For x < 0 and x 6 = \u2212 1 we have i = a ix \u2264 b a \u2212 1 ixdi = bx + 1 \u2212 (a \u2212 1) x + 1 x + 1 (16) b \u2211 i = a ix anymore b + 1 a ixdi = (b + 1) x + 1 \u2212 ax + 1 x + 1 + 1 + 1 (17) For x = \u2212 1 we have b \u0445 i = a ix \u0432i = a ix \u0445b \u2212 1 ixdi = a \u2212 1 (18) b = a \u00b2 integr + 1 = a ixdi = 1 (17)."}, {"heading": "A.2 Details from Section 2", "text": "The Proof. (From Theorem 1) Consider an oracle G based on a dataset D of size T. Given each sequence w1, w2,.., wT, the obfuscated version of the D output of G is the sequence of gradients G (w1),.., G (wT). Suppose that the oracle accesses the data in a (random) order specified by a permutation of G; for any x, x \"X, y,\" y \"(wT), we have (wt) = g.\" (xp), yp, \"yp.\""}, {"heading": "A.3 Proofs from Section 4", "text": "Remember that we have the oracles G1, G2 based on the data sets D1 and D2. Fractions of the data in each data set are \u03b21 = | D1 | | D1 | + | D2 | resp. \u03b22 = | D2 | | D1 | + | D2 |."}, {"heading": "A.3.1 Proof of Theorem 3", "text": "Theorem 3 is a side effect of the following lemmas. Lemma 4. (>) If we look at the SGD algorithm that follows algorithm 1. (...) Let us assume that the objective function is equally pronounced in both cases, and let us define W = (...) pronounced. (...) Let us assume that the objective function is not pronounced. (...) Let us assume that the objective function is not pronounced. (...) Let us assume that the objective function is not pronounced. (...) Let us assume that the objective function is pronounced. (...) Let us assume that the objective function is pronounced. (...) Let us assume that the objective function is not pronounced. (...) Let us assume that the objective function is not pronounced. (...) Let us assume that the objective function is not pronounced. (...) Let us assume that the objective function is not pronounced. (...)"}, {"heading": "A.3.2 Proof of Lemma 1", "text": "The proof. (From Lemma 1) Failure to put constant terms and k1 = 2\u03bbc1, k2 = 2\u03bbc2, we can paraphrase (13) as 1 / T timesQ (k1, k2) = \u03b2\u03b2\u03b2 \u2192 terms. Note that in this case k + \u03b2k2 -11 k 2 1k1 \u2212 1 + \u03b222. Leave x = k2 \u2212 1; then x \u2265 22 (1 \u2212 \u03b2k2 \u2212 11 \u2212 k2 \u2212 11 \u2212 k2, we can paraphrase (30) asQ (x) 21\u03b2 x 1 + 2 \u2212 2 (1 \u2212 \u03b2x1) (x + 1x 2). Leave x = k2 \u2212 1 \u2212 1; then x \u2265 1. Insert in k \u00b2 1 = 2, we can paraphrase (30) asQ (x)."}, {"heading": "A.3.3 Proof of Lemma 2", "text": "The Proof. (From Lemma 2) Let k2 =; then \u03b2\u03b22 = \u03b2\u03b22. (Beyond that, we can (30) asQ () = 4\u0445 21\u03b2 \u2212 1 + \u03b22 (1 \u2212 \u03b22) (\u2212 1 \u2212 \u03b2 \u2212 11) (\u2212 1 + 1 \u2212 1 + + 2) rewrite. (33) If we take the derivative, we obtain the following: Q \"() = \u2212 4\u0445 21\u03b2 \u2212 1 + 11 log (1 / \u03b21 \u2212 11) + 2 (1 \u2212 \u03b2 \u2212 11) (1 \u2212 1 \u2212 1 \u2212 11) (1 \u2212 1 (1 \u2212 1 \u2212 11) (1 \u2212 1 \u2212 1) (1 \u2212 1) (1 \u2212 2) (1 \u2212 1) (1 \u2212 1) (1 \u2212 11) (1 / \u03b21 \u2212 11) (1 / \u03b21 \u2212 11) protocol (1 / \u03b21 \u2212 1) (1 / \u03b21 \u2212 1) (1) (1), 1 (1), 1 (1), 1, (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1. (1), 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1."}], "references": [{"title": "Information-theoretic lower bounds on the oracle complexity of convex optimization", "author": ["A. Agarwal", "P.L. Bartlett", "P. Ravikumar", "M.J. Wainwright"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Agarwal et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2009}, {"title": "Private empirical risk minimization, revisited", "author": ["R. Bassily", "A. Thakurta", "A. Smith"], "venue": "In Proceedings of the IEEE Symposium on Foundations of Computer Science (FOCS", "citeRegEx": "Bassily et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bassily et al\\.", "year": 2014}, {"title": "Scaling up Machine Learning, Parallel and Distributed Approaches", "author": ["R. Bekkerman", "M. Bilenko", "J. Langford"], "venue": null, "citeRegEx": "Bekkerman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bekkerman et al\\.", "year": 2011}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["L. Bottou"], "venue": "Proceedings of COMPSTAT\u20192010,", "citeRegEx": "Bottou.,? \\Q2010\\E", "shortCiteRegEx": "Bottou.", "year": 2010}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chaudhuri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Learning from data of variable quality", "author": ["K. Crammer", "M. Kearns", "J. Wortman"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Crammer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2006}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["J. Duchi", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Duchi and Singer.,? \\Q2009\\E", "shortCiteRegEx": "Duchi and Singer.", "year": 2009}, {"title": "Privacy aware learning", "author": ["J. Duchi", "M. Jordan", "M. Wainwright"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Duchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2012}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["M. Kearns"], "venue": "Journal of the ACM,", "citeRegEx": "Kearns.,? \\Q2008\\E", "shortCiteRegEx": "Kearns.", "year": 2008}, {"title": "Making gradient descent optimal for strongly convex", "author": ["O. Shamir", "K. Sridharan"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Stochastic convex optimization", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridaran"], "venue": null, "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2012}, {"title": "Stochastic gradient descent with differen", "author": ["K. Chaudhuri", "Anand D. Sarwate"], "venue": null, "citeRegEx": "Song et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Song et al\\.", "year": 2009}, {"title": "A statistical framework for differential privacy", "author": ["S. Zhou"], "venue": "Journal of the American", "citeRegEx": "Wasserman and Zhou.,? \\Q2013\\E", "shortCiteRegEx": "Wasserman and Zhou.", "year": 2013}, {"title": "Dual averaging methods for regularized stochastic learning and online", "author": [], "venue": null, "citeRegEx": "Xiao.,? \\Q2009\\E", "shortCiteRegEx": "Xiao.", "year": 2009}], "referenceMentions": [{"referenceID": 3, "context": "We propose a model for variable data quality which is natural in the context of large-scale learning using stochastic gradient descent (SGD) and its variants (Bottou, 2010; Bekkerman et al., 2011).", "startOffset": 158, "endOffset": 196}, {"referenceID": 2, "context": "We propose a model for variable data quality which is natural in the context of large-scale learning using stochastic gradient descent (SGD) and its variants (Bottou, 2010; Bekkerman et al., 2011).", "startOffset": 158, "endOffset": 196}, {"referenceID": 3, "context": "To our knowledge, Crammer et al. (2006) were the first to provide a theoretical study of how to learn classifiers from data of variable quality.", "startOffset": 18, "endOffset": 40}, {"referenceID": 2, "context": "We propose a model for variable data quality which is natural in the context of large-scale learning using stochastic gradient descent (SGD) and its variants (Bottou, 2010; Bekkerman et al., 2011). We assume that the training data are accessed through an oracle which provides an unbiased but noisy estimate of the gradient of the objective. The noise comes from two sources: the random sampling of a data point, and additional noise due to the data quality. Our two motivating applications \u2013 learning with local differential privacy and learning from data of variable quality \u2013 can both be modeled as solving a regularized convex optimization problem using SGD. Learning from data with heterogeneous noise in this framework thus reduces to running SGD with noisy gradient estimates, where the magnitude of the added noise varies across iterations. Main results. In this paper we study noisy stochastic gradient methods when learning from multiple data sets with different noise levels. For simplicity we consider the case where there are two data sets, which we call Clean and Noisy. We process these data sets sequentially using SGD with learning rate O(1/t). In a future full version of this work we also analyze averaged gradient descent (AGD) with learning rate O(1/ \u221a t). We address some basic questions in this setup: In what order should we process the data? Suppose we use standard SGD on the union of Clean and Noisy. We show theoretically and empirically that the order in which we should process the datasets to get good performance depends on the learning rate of the algorithm: in some cases we should use the order (Clean,Noisy) and in others (Noisy,Clean). Can we use knowledge of the noise rates? We show that using separate learning rates that depend on the noise levels for the clean and noisy datasets improves the performance of SGD. We provide a heuristic for choosing these rates by optimizing an upper bound on the error for SGD that depends on the ratio of the noise levels. We analytically quantify the performance of our algorithm in two regimes of interest. For moderate noise levels, we demonstrate empirically that our algorithm outperforms using a single learning rate and using clean data only. Does using noisy data always help? The work of Crammer et al. (2006) suggests that if the noise level of noisy data is above some threshold, then noisy data will not help.", "startOffset": 173, "endOffset": 2296}, {"referenceID": 0, "context": "When the objective function is \u03bb-strongly convex, the learning rate used for SGD is O(1/\u03bbt) (Nemirovsky and Yudin, 1983; Agarwal et al., 2009; Rakhlin et al., 2012; Moulines and Bach, 2011), which leads to a regret of O(1/\u03bb2t) for smooth objectives.", "startOffset": 92, "endOffset": 189}, {"referenceID": 6, "context": "For non-smooth objectives, SGD with learning rate O(1/\u03bbt) followed by some form of averaging of the iterates achieves O(1/\u03bbt) (Nesterov and Vial, 2008; Nemirovski et al., 2009; Shalev-Shwartz et al., 2009; Xiao, 2010; Duchi and Singer, 2009).", "startOffset": 126, "endOffset": 241}, {"referenceID": 4, "context": "There is also a body of literature on differentially private classification by regularized convex optimization in the batch (Chaudhuri et al., 2011; Rubinstein et al., 2012; Kifer et al., 2012) as well as the online (Jain et al.", "startOffset": 124, "endOffset": 193}, {"referenceID": 7, "context": "In this paper, we consider classification with local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012), a stronger form of privacy than ordinary differential privacy.", "startOffset": 74, "endOffset": 120}, {"referenceID": 2, "context": "For simplicity we, like previous work Crammer et al. (2006), assume that the algorithms know the noise levels exactly.", "startOffset": 38, "endOffset": 60}, {"referenceID": 0, "context": "When the objective function is \u03bb-strongly convex, the learning rate used for SGD is O(1/\u03bbt) (Nemirovsky and Yudin, 1983; Agarwal et al., 2009; Rakhlin et al., 2012; Moulines and Bach, 2011), which leads to a regret of O(1/\u03bb2t) for smooth objectives. For non-smooth objectives, SGD with learning rate O(1/\u03bbt) followed by some form of averaging of the iterates achieves O(1/\u03bbt) (Nesterov and Vial, 2008; Nemirovski et al., 2009; Shalev-Shwartz et al., 2009; Xiao, 2010; Duchi and Singer, 2009). There is also a body of literature on differentially private classification by regularized convex optimization in the batch (Chaudhuri et al., 2011; Rubinstein et al., 2012; Kifer et al., 2012) as well as the online (Jain et al., 2012) setting. In this paper, we consider classification with local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012), a stronger form of privacy than ordinary differential privacy. Duchi et al. (2012) propose learning a classifier with local differential privacy using SGD, and Song et al.", "startOffset": 121, "endOffset": 943}, {"referenceID": 0, "context": "When the objective function is \u03bb-strongly convex, the learning rate used for SGD is O(1/\u03bbt) (Nemirovsky and Yudin, 1983; Agarwal et al., 2009; Rakhlin et al., 2012; Moulines and Bach, 2011), which leads to a regret of O(1/\u03bb2t) for smooth objectives. For non-smooth objectives, SGD with learning rate O(1/\u03bbt) followed by some form of averaging of the iterates achieves O(1/\u03bbt) (Nesterov and Vial, 2008; Nemirovski et al., 2009; Shalev-Shwartz et al., 2009; Xiao, 2010; Duchi and Singer, 2009). There is also a body of literature on differentially private classification by regularized convex optimization in the batch (Chaudhuri et al., 2011; Rubinstein et al., 2012; Kifer et al., 2012) as well as the online (Jain et al., 2012) setting. In this paper, we consider classification with local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012), a stronger form of privacy than ordinary differential privacy. Duchi et al. (2012) propose learning a classifier with local differential privacy using SGD, and Song et al. (2013) show empirically that using mini-batches significantly improves the performance of differentially private SGD.", "startOffset": 121, "endOffset": 1039}, {"referenceID": 0, "context": "When the objective function is \u03bb-strongly convex, the learning rate used for SGD is O(1/\u03bbt) (Nemirovsky and Yudin, 1983; Agarwal et al., 2009; Rakhlin et al., 2012; Moulines and Bach, 2011), which leads to a regret of O(1/\u03bb2t) for smooth objectives. For non-smooth objectives, SGD with learning rate O(1/\u03bbt) followed by some form of averaging of the iterates achieves O(1/\u03bbt) (Nesterov and Vial, 2008; Nemirovski et al., 2009; Shalev-Shwartz et al., 2009; Xiao, 2010; Duchi and Singer, 2009). There is also a body of literature on differentially private classification by regularized convex optimization in the batch (Chaudhuri et al., 2011; Rubinstein et al., 2012; Kifer et al., 2012) as well as the online (Jain et al., 2012) setting. In this paper, we consider classification with local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012), a stronger form of privacy than ordinary differential privacy. Duchi et al. (2012) propose learning a classifier with local differential privacy using SGD, and Song et al. (2013) show empirically that using mini-batches significantly improves the performance of differentially private SGD. Recent work by Bassily et al. (2014) provides an improved privacy analysis for non-local privacy.", "startOffset": 121, "endOffset": 1187}, {"referenceID": 0, "context": "When the objective function is \u03bb-strongly convex, the learning rate used for SGD is O(1/\u03bbt) (Nemirovsky and Yudin, 1983; Agarwal et al., 2009; Rakhlin et al., 2012; Moulines and Bach, 2011), which leads to a regret of O(1/\u03bb2t) for smooth objectives. For non-smooth objectives, SGD with learning rate O(1/\u03bbt) followed by some form of averaging of the iterates achieves O(1/\u03bbt) (Nesterov and Vial, 2008; Nemirovski et al., 2009; Shalev-Shwartz et al., 2009; Xiao, 2010; Duchi and Singer, 2009). There is also a body of literature on differentially private classification by regularized convex optimization in the batch (Chaudhuri et al., 2011; Rubinstein et al., 2012; Kifer et al., 2012) as well as the online (Jain et al., 2012) setting. In this paper, we consider classification with local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012), a stronger form of privacy than ordinary differential privacy. Duchi et al. (2012) propose learning a classifier with local differential privacy using SGD, and Song et al. (2013) show empirically that using mini-batches significantly improves the performance of differentially private SGD. Recent work by Bassily et al. (2014) provides an improved privacy analysis for non-local privacy. Our work is an extension of these papers to heterogeneous privacy requirements. Crammer et al. (2006) study classification when the labels in each data set are corrupted by RCN of different rates.", "startOffset": 121, "endOffset": 1350}, {"referenceID": 7, "context": "1 Local Differential Privacy Local differential privacy (Wasserman and Zhou, 2010; Duchi et al., 2012; Kasiviswanathan et al., 2008) is a strong notion of privacy motivated by differential privacy (Dwork et al.", "startOffset": 56, "endOffset": 132}, {"referenceID": 7, "context": "Duchi et al. (2012) showed that this mechanism provides -local privacy assuming analytic conditions on the loss function, bounded data, and that the oracle generates a fresh random sample at each invocation.", "startOffset": 0, "endOffset": 20}, {"referenceID": 8, "context": "2 Random Classification Noise In the random classification noise model of Kearns (1998), the learning algorithm is presented with labelled examples (x1, \u1ef91), .", "startOffset": 74, "endOffset": 88}, {"referenceID": 8, "context": "2 Random Classification Noise In the random classification noise model of Kearns (1998), the learning algorithm is presented with labelled examples (x1, \u1ef91), . . . , (xT , \u1ef9T ), where each \u1ef9i \u2208 {\u22121, 1} has been obtained by independently flipping the true label yi with some probability \u03c3. Natarajan et al. (2013) showed that solving", "startOffset": 74, "endOffset": 313}, {"referenceID": 5, "context": "In practice, we may wish to learn classifiers from multiple datasets with different amounts of classification noise (Crammer et al., 2006); for example, we may have a small dataset D1 labeled by domain experts, and a larger noisier dataset D2, labeled via crowdsourcing, with flip probabilities \u03c31 and \u03c32.", "startOffset": 116, "endOffset": 138}], "year": 2014, "abstractText": "We consider learning from data of variable quality that may be obtained from different heterogeneous sources. Addressing learning from heterogenous data in its full generality is a challenging problem. In this paper, we adopt instead a model in which data is observed through heterogeneous noise, where the noise level reflects the quality of the data source. We study how to use stochastic gradient algorithms to learn in this model. Our study is motivated by two concrete examples where this problem arises naturally: learning with local differential privacy based on data from multiple sources with different privacy requirements, and learning from data with labels of variable quality. The main contribution of this paper is to identify how heterogeneous noise impacts performance. We show that given two datasets with heterogeneous noise, the order in which to use them in standard SGD depends on the learning rate. We propose a method for changing the learning rate as a function of the heterogeneity, and prove new regret bounds for our method in two cases of interest. Experiments on real data show that our method performs better than using a single learning rate and using only the less noisy of the two datasets when the noise level is low to moderate.", "creator": "LaTeX with hyperref package"}}}