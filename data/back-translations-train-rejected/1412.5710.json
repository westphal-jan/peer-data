{"id": "1412.5710", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Dec-2014", "title": "Multiobjective Optimization of Classifiers by Means of 3-D Convex Hull Based Evolutionary Algorithm", "abstract": "Finding a good classifier is a multiobjective optimization problem with different error rates and the costs to be minimized. The receiver operating characteristic is widely used in the machine learning community to analyze the performance of parametric classifiers or sets of Pareto optimal classifiers. In order to directly compare two sets of classifiers the area (or volume) under the convex hull can be used as a scalar indicator for the performance of a set of classifiers in receiver operating characteristic space.", "histories": [["v1", "Thu, 18 Dec 2014 03:01:10 GMT  (4369kb)", "http://arxiv.org/abs/1412.5710v1", "32 pages, 26 figures"]], "COMMENTS": "32 pages, 26 figures", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["jiaqi zhao", "vitor basto fernandes", "licheng jiao", "iryna yevseyeva", "asep maulana", "rui li", "thomas b\\\"ack", "michael t m emmerich"], "accepted": false, "id": "1412.5710"}, "pdf": {"name": "1412.5710.pdf", "metadata": {"source": "CRF", "title": "Multiobjective Optimization of Classifiers by Means of 3-D Convex Hull Based Evolutionary Algorithms", "authors": ["Jiaqi Zhao", "Vitor Basto Fernandes", "Licheng Jiao", "Iryna Yevseyeva", "Asep Maulana", "Rui Li", "Thomas B\u00e4ck", "Michael T. M. Emmerich"], "emails": ["jiaqizhao88@126.com,", "lchjiao@mail.xidian.edu.cn)."], "sections": [{"heading": null, "text": "Finding a good classification is a multi-objective optimization problem with different error rates and costs to minimize. The receiver feature is often used in the machine learning community to analyze the performance of parametric classifiers or sets of Pareto classifiers. To directly compare two sets of classifiers, the area (or volume) under the convex skull has been defined as a scalar indicator of the performance of a number of classification problems in receiver operation properties. It has been proposed and successfully applied to maximize the convex ranges for binary classifications. The contribution of this paper is to expand these algorithms for dealing with higher-dimensional problem formulations. In particular, we discuss problems where parsimony (or classification complexity) is designated as the third and a multi-class classification with three different true classification rates is maximized."}, {"heading": "C. Convex Hull based EMOA", "text": "In the past, it was a case of being able to find a solution that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution, that was able to find a solution."}, {"heading": "A. Complexity as a third objective function", "text": "This year he has put himself in the position where he is capable of winning the aforementioned lrVo."}, {"heading": "C. ROCCH maximization and multiobjective optimization", "text": "The objectives of the extended ROCCH and the three-class ROCCH maximization are to find a group of classifiers that approximate the perfect point (0,0,0) for complex binary classifiers and (1,1,1) for three-class classifiers, respectively. However, the ROCCH maximization problems turn out to be minimizing problems of multi-objective optimization by multiplying each objective function by minus one, as in Equation. 7.minF (x) = (f1 (x), f2 (x)), which are subject to x (7). In Equation 7, x is a series of classifiers, ig is the solution space, i.e. the set of all possible classifiers, and F (x) is a vector function for the ROC distribution. In the theory of multi-objective optimization, dominance is an important concept that is defined x: Let's leave \u00b5 = (\u00b51, \u00b52, \u00b53), millier (=)."}, {"heading": "D. The motivation and ideas for 3-D ROCCH maximization", "text": "There are two key steps of each EMOAs problem that have been considered, one is how to classify the population and the other is how to select solutions that survive to the next generation; the other is how to divide the population into multiple levels and second is to design a selection scheme that is used to survive by the population at the same level; while dealing with the volume of 3-D ROCCH maximization problems, 3-D convexhull based on sorting without redundancy, the population is sorted, rapidly increasing diversity in the evolutionary process; a volume selection scheme is assumed to calculate the contribution to the volume of the 3-D ROCCH of each solution; based on our findings, the VUS-based selection strategy performs better than the 3-D ROCCH distance to deal with the specific feature of the ROCCH problem."}, {"heading": "V. EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS", "text": "In this section, the test functions of ZEJD and ZED are developed to test the performance of 3DCH-EMOA and several other EMOAs such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA / D [41]. To evaluate the performance of these algorithms VUS, Gini coefficient and time cost, the results of all algorithms are compared in this section."}, {"heading": "A. ZEJD Problem", "text": "In this section, three ZEJD (Zhao, Emmerich, Jiao, Deutz) problems (both) are solved to evaluate the performance of different types of EMOAs on ROCCH maximization problems. < < 2) The test problem is a simulation of the extended ROCCH distribution of complexity classifiers, which has several important properties. First, the points (1,0,0), (0,1,0) and (0,0,0,1) are contained in the Pareto front. Second, the Pareto front should be below the ROC surface of random classifiers described in Figure 3. Third, all solutions are located in the space of the unit cube. The aim of this test problem is to find the maximum value of the volume under the convex surface. The range of variation of each object is in [0,1], the problem of ZEJD1 is defined in Eq. 9, f1."}, {"heading": "B. ZED Problem", "text": "In this section, three ZED (Zhao, Emmerich, Deutz) problems are designed not to evaluate the performance of several types of EMOAs on ROCCH maximization problems. The test problem is a simulation of the 3-D ROC distribution of three-class classifiers, which has several important properties. First, the points (1,0,0), (0,1,0) and (0,1) are contained in the Pareto front. Second, the Pareto front should be above the surface of the random guess, which is in Fig. 5. Third, all solutions are located in the space of the unit Cube. The aim of this series of test problems is to find the maximum value of the volume under the convex hull. The range of variation of each object is [0,1], the problem of ZED1 is defined in Eq. 12.f1 = cos (x1)."}, {"heading": "C. Metrics", "text": "Three metrics are chosen to evaluate the performance of the different algorithms in the comparative experiment on the ZEJD and ZED problems. VUS metrics can directly evaluate the set solution, the better the set solution the greater the value of VUS. For complicity problems with binary classifiers and ZEJD problems, the smallest value of VUS is 0 with random classifiers and the largest value of VUS is 5 / 6. The Gini coefficient is often used as a measure of the statistical dispersion that is supposed to represent the income distribution of the inhabitants of a nation [34]. In this thesis, the Gini coefficient is used to evaluate the uniformity of the solution by calculating the statistical distribution of the individual solution segments. The Gini coefficient can describe the dispersion of neighboring individuals on the Pareto front."}, {"heading": "D. Experimental results and discussions", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "VI. SPAM PROBLEM", "text": "From a technical point of view, an anti-SPAM e-mail system consists of a set of Boolean filtering rules that collectively allow the detection of SPAM messages. Discovering the relative importance of these rules and assigning the corresponding values (weights) to each rule is a complex setup process. The need to frequently assign values to existing rules and set values for new rules in order to keep the anti-SPAM filter up-to-date requires the introduction of machine learning and optimization techniques."}, {"heading": "A. SPAM multiobjective problem formulation", "text": "This year it is so far that it will only take a year before it will be able to find a solution."}, {"heading": "VII. FEATURE SELECTION AND CLASSIFICATION", "text": "This year it is more than ever before in the history of the city."}, {"heading": "VIII. CONCLUSIONS AND FUTURE WORK", "text": "In order to evaluate the performance of several evolutionary multi-objective algorithms, two groups of test problems were developed: ZEJD and ZED. 3DCHEMOA is compared with other EMOAs, such as NSGA-II, GDE3, SPEA2, MOEA / D and SMS-EMOA for ZEJD and ZED test problems. 3DCH-EMOA always achieves the best results not only in convergence but also in diversity. 3DCH-EMOA showed a good ability to heal the dent in the 3-D ROC space, which is really important for ROCCH maximization problems. We also applied this algorithm to the area of SPAM filtering of optimization and feature selection. Extensive experimental studies compared the new proposed method with the state of the art."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was partially supported by China's National Basic Research Programme (973 Programme) (No. 2013CB329402), China's National Science Foundation (No. 61273317, 61271301, 61272279, 61001202, 61203303, 61003199 and 61003198), the Fund for Foreign Scholars in University Research and Teaching Programmes (No. B07048), the National Research Foundation for China's Doctoral Programme (No. 20100203120008), the Programme for Cheung Kong Scientists and Innovative Research Teams at Universities (No. IRT1170), the Basic Science Research Plan in Shaanxi Province of China (Programme No. 2014JM8301) and the Seventh Framework Programme of the European Union under Funding Agreements (No. 247619) on Nature Inspired Computation and its Applications (ICNaiations)."}], "references": [{"title": "An introduction to ROC analysis", "author": ["T. Fawcett"], "venue": "Pattern recognition letters, vol. 27, no. 8, pp. 861\u2013874, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Medical decision making", "author": ["H.C. Sox", "M.C. Higgins", "D.K. Owens"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Signal detection theory and ROC analysis", "author": ["J.P. Egan"], "venue": "1975.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1975}, {"title": "Measuring the accuracy of diagnostic systems", "author": ["J.A. Swets"], "venue": "Science, vol. 240, no. 4857, pp. 1285\u20131293, 1988.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1988}, {"title": "A novel selection evolutionary strategy for constrained optimization", "author": ["L. Jiao", "L. Li", "R. Shang", "F. Liu", "R. Stolkin"], "venue": "Information Sciences, vol. 239, no. 1, pp. 122 \u2013 141, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "An evolutionary multi-objective approach to sparse reconstruction", "author": ["L. Li", "X. Yao", "R. Stolkin", "M. Gong", "S. He"], "venue": "IEEE Transactions on Evolutionary Computation, vol. PP, no. 99, pp. 1\u20131, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Convex hull-based multi-objective genetic programming for maximizing receiver operator characteristic performance", "author": ["P. Wang", "M. Emmerich", "R. Li", "K. Tang", "T. B\u00e4ck", "X. Yao"], "venue": "IEEE Transactions on Evolutionary Computation, vol. PP, no. 99, pp. 1\u20131, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "A simplified extension of the area under the ROC to the multiclass domain", "author": ["T. Landgrebe", "R. Duin"], "venue": "Seventeenth annual symposium of the pattern recognition association of South Africa. Citeseer, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust classification for imprecise environments", "author": ["F. Provost", "T. Fawcett"], "venue": "Machine Learning, vol. 42, no. 3, pp. 203\u2013231, 2001.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "Using rule sets to maximize ROC performance", "author": ["T. Fawcett"], "venue": "Data Mining, 2001. ICDM 2001, Proceedings IEEE International Conference on. IEEE, 2001, pp. 131\u2013138.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "Prie: a system for generating rulelists to maximize ROC performance", "author": ["T. Fawcett"], "venue": "Data Mining and Knowledge Discovery, vol. 17, no. 2, pp. 207\u2013224, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Repairing concavities in ROC curves.", "author": ["P.A. Flach", "S. Wu"], "venue": "in IJCAI. Citeseer,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Optimal ROC curve for a combination of classifiers.", "author": ["M. Barreno", "A.A. C\u00e1rdenas", "J.D. Tygar"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "A multi-objective genetic programming approach to developing pareto optimal decision trees", "author": ["H. Zhao"], "venue": "Decision Support Systems, vol. 43, no. 3, pp. 809\u2013826, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-objective genetic programming for classification with unbalanced data", "author": ["U. Bhowan", "M. Zhang", "M. Johnston"], "venue": "AI 2009: Advances in Artificial Intelligence. Springer, 2009, pp. 370\u2013380.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Evolving diverse ensembles using genetic programming for classification with unbalanced data", "author": ["U. Bhowan", "M. Johnston", "M. Zhang", "X. Yao"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 17, no. 3, pp. 368\u2013386, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Multiobjective genetic programming for maximizing ROC performance", "author": ["P. Wang", "K. Tang", "T. Weise", "E. Tsang", "X. Yao"], "venue": "Neurocomputing, vol. 125, pp. 102\u2013118, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "UCI machine learning repository", "author": ["K. Bache", "M. Lichman"], "venue": "2013. [Online]. Available: http://archive.ics.uci.edu/ml", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Note on the location of optimal classifiers in n-dimensional ROC space", "author": ["A. Srinivasan", "A. Srinivasan"], "venue": "Tech. Rep., 1999.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "On reoptimizing multi-class classifiers", "author": ["C. Bourke", "K. Deng", "S.D. Scott", "R.E. Schapire", "N.V. Vinodchandran"], "venue": "Machine Learning, vol. 71, pp. 219\u2013242, 2008.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards maximizing the area under the ROC curve for multi-class classification problems.", "author": ["K. Tang", "R. Wang", "T. Chen"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Volume under the ROC surface for multi-class problems", "author": ["C. Ferri", "J. Hern\u00e1ndez-Orallo", "M.A. Salido"], "venue": "Machine Learning: ECML 2003. Springer, 2003, pp. 108\u2013120.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Efficient multiclass ROC approximation by decomposition via confusion matrix perturbation analysis", "author": ["T.C. Landgrebe", "R.P. Duin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 5, pp. 810\u2013822, 2008.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "The hypervolume under the ROC hypersurface of \u201cnear-guessing\u201d and \u201cnear-perfect\u201d observers in n-class classification tasks", "author": ["D.C. Edwards", "C.E. Metz", "R.M. Nishikawa"], "venue": "IEEE Transactions on Medical Imaging, vol. 24, no. 3, pp. 293\u2013299, 2005.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Well Trained PETs: Improving Probability Estimation Trees", "author": ["F. Provost", "P. Domingos"], "venue": "CeDER Working Paper IS-00-04, Stern School of Business, New York Univ.,2001.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "A simple generalisation of the area under the ROC curve for multiple class classification problems", "author": ["D.J. Hand", "R.J. Till"], "venue": "Machine Learning, vol. 45, no. 2, pp. 171\u2013186, 2001.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "Evolving neural networks with maximum auc for imbalanced data classification", "author": ["X. Lu", "K. Tang", "X. Yao"], "venue": "Hybrid Artificial Intelligence Systems. Springer, 2010, pp. 335\u2013342.  32  ARXIV, COMPUTER SCIENCE, DECEMBER, 2014", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Comparing three-class diagnostic tests by three-way ROC analysis", "author": ["S. Dreiseitl", "L. Ohno-Machado", "M. Binder"], "venue": "Medical Decision Making, vol. 20, no. 3, pp. 323\u2013331, 2000.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2000}, {"title": "Three-way rocs", "author": ["D. Mossman"], "venue": "Medical Decision Making, vol. 19, no. 1, pp. 78\u201389, 1999.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1999}, {"title": "The multi-objective differential evolution algorithm based on quick convex hull algorithms", "author": ["J. Shan-Fan", "S.-W. Xiong", "J. Zhuo-Wang"], "venue": "Natural Computation, 2009. ICNC\u201909. Fifth International Conference on, vol. 4. IEEE, 2009, pp. 469\u2013473.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex hull ranking algorithm for multi-objective evolutionary algorithms", "author": ["M. Davoodi Monfared", "A. Mohades", "J. Rezaei"], "venue": "Scientia Iranica, vol. 18, no. 6, pp. 1435\u20131442, 2011.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A new multi-objective evolutionary algorithm based on convex hull for binary classifier optimization", "author": ["M. Cococcioni", "P. Ducange", "B. Lazzerini", "F. Marcelloni"], "venue": "IEEE Congress on Evolutionary Computation, 2007. CEC 2007. IEEE, 2007, pp. 3150\u20133156.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-objective genetic fuzzy classifiers for imbalanced and cost-sensitive datasets", "author": ["P. Ducange", "B. Lazzerini", "F. Marcelloni"], "venue": "Soft Computing, vol. 14, no. 7, pp. 713\u2013728, 2010.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Relative deprivation and the gini coefficient", "author": ["S. Yitzhaki"], "venue": "The Quarterly Journal of Economics, pp. 321\u2013324, 1979.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1979}, {"title": "Muiltiobjective optimization using nondominated sorting in genetic algorithms", "author": ["N. Srinivas", "K. Deb"], "venue": "Evolutionary computation, vol. 2, no. 3, pp. 221\u2013248, 1994.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1994}, {"title": "A fast and elitist multiobjective genetic algorithm: NSGA-II", "author": ["K. Deb", "A. Pratap", "S. Agarwal", "T. Meyarivan"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182\u2013197, 2002.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2002}, {"title": "The quickhull algorithm for convex hulls", "author": ["C.B. Barber", "D.P. Dobkin", "H. Huhdanpaa"], "venue": "ACM Transactions on Mathematical Software (TOMS), vol. 22, no. 4, pp. 469\u2013483, 1996.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1996}, {"title": "SMS-EMOA: Multiobjective selection based on dominated hypervolume", "author": ["N. Beume", "B. Naujoks", "M. Emmerich"], "venue": "European Journal of Operational Research, vol. 181, no. 3, pp. 1653\u20131669, 2007.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "GDE3: The third evolution step of generalized differential evolution", "author": ["S. Kukkonen", "J. Lampinen"], "venue": "Evolutionary Computation, 2005. The 2005 IEEE Congress on, vol. 1. IEEE, 2005, pp. 443\u2013450.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2005}, {"title": "SPEA2: Improving the strength pareto evolutionary algorithm", "author": ["E. Zitzler", "M. Laumanns", "L. Thiele", "E. Zitzler", "E. Zitzler", "L. Thiele", "L. Thiele"], "venue": "TIK-Report 103, Department of Electrical Engineering, Swiss Federal Institute of Technology (ETH), 2001.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2001}, {"title": "MOEA/D: A multiobjective evolutionary algorithm based on decomposition", "author": ["Q. Zhang", "H. Li"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 11, no. 6, pp. 712\u2013731, 2007.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "The JMetal framework for multi-objective optimization: Design and architecture", "author": ["J. Durillo", "A. Nebro", "E. Alba"], "venue": "CEC 2010, Barcelona, Spain, July 2010, pp. 4138\u20134325.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}, {"title": "jMetal: A java framework for multi-objective optimization", "author": ["J.J. Durillo", "A.J. Nebro"], "venue": "Advances in Engineering Software, vol. 42, pp. 760\u2013771, 2011. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0965997811001219", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2011}, {"title": "Four Results on Randomized Incremental Constructions", "author": ["K.L. Clarkson", "K. Mehlhorn", "R. Seidel"], "venue": "Computational Geometry: Theory and Applications, vol. 3, pp. 185\u2013212, 1993.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1993}, {"title": "Anti-spam multiobjective genetic algorithms optimization analysis", "author": ["V. Basto-Fernandes", "I. Yevseyeva", "J.R.M\u00e9ndez"], "venue": "International Resource Management Journal, vol. 26, pp. 54\u201367, 2012.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimising anti-spam filters with evolutionary algorithms", "author": ["I. Yevseyeva", "V. Basto-Fernandes", "D. Ruano-Ord\u00e1s", "J.R. M\u00e9ndez"], "venue": "Expert Systems with Applications, vol. 40, no. 10, pp. 4010\u20134021, 2013.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Ockham\u2019s razor: A historical and philosophical analysis of Ockham\u2019s principle of parsimony", "author": ["R. Ariew"], "venue": "1976.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1976}, {"title": "The apache spamassassin project", "author": ["Internet"], "venue": "2006. [Online]. Available: http://spamassassin.apache.org/publiccorpus", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2006}, {"title": "A survey on feature selection methods", "author": ["G. Chandrashekar", "F. Sahin"], "venue": "Computers & Electrical Engineering, vol. 40, no. 1, pp. 16 \u2013 28, 2014, 40th-year commemorative issue.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2014}, {"title": "A survey of multiobjective evolutionary algorithms for data mining: Part I", "author": ["A. Mukhopadhyay", "U. Maulik", "S. Bandyopadhyay", "C. Coello Coello"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 18, no. 1, pp. 4\u201319, Feb 2014.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "C4.5: programs for machine learning", "author": ["J.R. Quinlan"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1993}, {"title": "The WEKA data mining software: An update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKDD Explorations, vol. 11, pp. 9\u201318, 2009.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2009}, {"title": "A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based approaches", "author": ["M. Galar", "A. Fernandez", "E. Barrenechea", "H. Bustince", "F. Herrera"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, vol. 42, no. 4, pp. 463\u2013484, July 2012.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2012}, {"title": "Training ensemble of diverse classifiers on feature subsets", "author": ["R. Gupta", "K. Audhkhasi", "S. Narayanan"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2014, pp. 2927\u20132931.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "The receiver operating characteristic (ROC) graph is a technique for visualizing, organizing and selecting classifiers based on their performance [1].", "startOffset": 146, "endOffset": 149}, {"referenceID": 1, "context": "Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].", "startOffset": 240, "endOffset": 243}, {"referenceID": 2, "context": "Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].", "startOffset": 262, "endOffset": 265}, {"referenceID": 3, "context": "Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].", "startOffset": 286, "endOffset": 289}, {"referenceID": 0, "context": "More recently, research has drawn attention to ROC convex hull (ROCCH) analysis that covers potentially optimal points for a given set of classifiers [1].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "Some evolutionary multiobjective optimization algorithms (EMOAs) [5] have been applied to machine learning and image processing areas [6].", "startOffset": 65, "endOffset": 68}, {"referenceID": 5, "context": "Some evolutionary multiobjective optimization algorithms (EMOAs) [5] have been applied to machine learning and image processing areas [6].", "startOffset": 134, "endOffset": 137}, {"referenceID": 6, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 35, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 187, "endOffset": 191}, {"referenceID": 39, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 199, "endOffset": 203}, {"referenceID": 40, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 212, "endOffset": 216}, {"referenceID": 37, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 231, "endOffset": 235}, {"referenceID": 7, "context": "A simplified ROC is estimated from a three-class classifier by only considering the rate of every correctly classified category [8], which ensures that good classifiers tend to result in better ROCCH than poorer ones.", "startOffset": 128, "endOffset": 131}, {"referenceID": 35, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 66, "endOffset": 70}, {"referenceID": 38, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 77, "endOffset": 81}, {"referenceID": 39, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 89, "endOffset": 93}, {"referenceID": 40, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 102, "endOffset": 106}, {"referenceID": 37, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 121, "endOffset": 125}, {"referenceID": 8, "context": "ROCCH maximization problems were first described in [9].", "startOffset": 52, "endOffset": 55}, {"referenceID": 0, "context": "One approach is to identify portions of the ROCCH to use iso-performance lines [1] that are translated from operating conditions of classifiers.", "startOffset": 79, "endOffset": 82}, {"referenceID": 9, "context": "In addition, a rule learning mechanism is described in [10] and in [11].", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "In addition, a rule learning mechanism is described in [10] and in [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "In [12], a method for detecting and repairing concavities in ROC curves is studied.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "The Neyman-Pearson lemma is introduced to the context of ROCCH in [13], which is the theoretical basis for finding the optimal combination of classifiers to maximize the ROCCH.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "This method not only focuses on repairing the concavity but it also improves the ROC curve, which is different with [12].", "startOffset": 116, "endOffset": 120}, {"referenceID": 10, "context": "More recently, ROCCER was proposed in [11].", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "In [14], non-dominated decision trees were developed, which are used to support the decision which classifier to choose.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "The Pareto front of multiobjective genetic programming is used to maximize the accuracy of each minority class with unbalanced data set in [15].", "startOffset": 139, "endOffset": 143}, {"referenceID": 15, "context": "Moreover, in [16], the technique of multiobjective optimization genetic programming is employed to evolve diverse ensembles to maximize the classification performance for unbalanced data.", "startOffset": 13, "endOffset": 17}, {"referenceID": 16, "context": "Some more evolutionary multiobjective optimization algorithms (EMOAs) have been combined with genetic programming to maximize ROC performance in [17].", "startOffset": 145, "endOffset": 149}, {"referenceID": 6, "context": "This is done in convex hull multiobjective genetic programming (CH-MOGP), which is proposed in [7].", "startOffset": 95, "endOffset": 98}, {"referenceID": 17, "context": "It has been compared to other state-of-the-art methods and showed the best performance for binary classifiers on the UCI benchmark [18].", "startOffset": 131, "endOffset": 135}, {"referenceID": 7, "context": "The area under the ROC convex hull (AUC) has become a standard performance evaluation criterion in binary pattern recognition problems and it has been widely used to compare different classifiers independently of priors of distribution and costs of misclassification [8].", "startOffset": 267, "endOffset": 270}, {"referenceID": 18, "context": "The ROC curve is extended to multi-class classification problems in [19].", "startOffset": 68, "endOffset": 72}, {"referenceID": 19, "context": ", [20]) that comprises the non-dominated boundary of the convex hull in n-dimensional ROC space.", "startOffset": 2, "endOffset": 6}, {"referenceID": 19, "context": "It has been shown that a multi-class classifier with good ROC hyper-surface can lead to classifiers suitable for various class distributions and misclassification costs via re-optimization of its output matrix [20].", "startOffset": 210, "endOffset": 214}, {"referenceID": 20, "context": "However, due to the increase of the dimensionality of the ROC space, achieving the optimal ROC hyper-surface is even more difficult than achieving the optimal ROC curve [21].", "startOffset": 169, "endOffset": 173}, {"referenceID": 21, "context": "A straightforward way to generalize AUC is the volume under the ROC (a surface in 3-D and a hyper-surface in n-D) surface (VUS) [22].", "startOffset": 128, "endOffset": 132}, {"referenceID": 22, "context": "Methods from computational geometry can be used to efficiently compute the VUS, but, as compared to the 2-D case, this is relatively complicated [23].", "startOffset": 145, "endOffset": 149}, {"referenceID": 23, "context": "Moreover, the VUS value of a \u201cnear guessing\u201d classifier is almost the same as a \u201cnear perfect\u201d classifier for more than two classes (see [24]).", "startOffset": 137, "endOffset": 141}, {"referenceID": 7, "context": "However, alternative definitions of VUS have been proposed where this problem does not occur [8].", "startOffset": 93, "endOffset": 96}, {"referenceID": 24, "context": "all strategy) in [25], turning the problem to a problem that considers a set of binary classifiers.", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "In [26], multi-class area under convex hull (MAUC) has been proposed as a simpler generalization of AUC for multi-class classification problems.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "MAUC has been widely used in recent work [21], [27].", "startOffset": 41, "endOffset": 45}, {"referenceID": 26, "context": "MAUC has been widely used in recent work [21], [27].", "startOffset": 47, "endOffset": 51}, {"referenceID": 7, "context": "This leads to a quadratically growing number of required comparisons in the number of classes [8].", "startOffset": 94, "endOffset": 97}, {"referenceID": 27, "context": "The VUS of three-class classifiers has been studied in [28] and [29].", "startOffset": 55, "endOffset": 59}, {"referenceID": 28, "context": "The VUS of three-class classifiers has been studied in [28] and [29].", "startOffset": 64, "endOffset": 68}, {"referenceID": 7, "context": "The simplified ROC is estimated from a multiclass classifier by only considering the rate of every correctly classified category [8], which ensures that good classifiers tend to result in better VUS than bad classifiers.", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "In this paper, we therefore focus on finding (sets of) classifiers with optimal VUS considering the simplified ROC proposed in [8].", "startOffset": 127, "endOffset": 130}, {"referenceID": 29, "context": "[30], [31]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[30], [31]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "In [32] a multiobjective evolutionary algorithm based on the properties of the convex hulls defined in the 2-D ROC space was proposed, which was applied to determine a set of fuzzy rule-based binary classifiers with different trade-offs between false positive rate (fpr) and true positive rate (tpr).", "startOffset": 3, "endOffset": 7}, {"referenceID": 32, "context": "NSGA-II was used to generate an approximation of a Pareto front composed of genetic fuzzy classifiers with different trade-offs among sensitivity, specificity, and interpretability in [33].", "startOffset": 184, "endOffset": 188}, {"referenceID": 16, "context": "discuss the optimization of binary classifiers based on receiver operator characteristic [17].", "startOffset": 89, "endOffset": 93}, {"referenceID": 7, "context": "The problem is simplified by only considering the diagonal elements of the matrix in [8].", "startOffset": 85, "endOffset": 88}, {"referenceID": 0, "context": "6 are surface functions which are named as iso-performance surface in ROC analysis theory [1].", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "The way to find a desired optimal classifier is similar to ROCCH for binary classifiers which is described in [1].", "startOffset": 110, "endOffset": 113}, {"referenceID": 33, "context": "The gini coefficient [34] is used to evaluate the uniformity of the solution of the test functions in this paper, and the details will be discussed later.", "startOffset": 21, "endOffset": 25}, {"referenceID": 6, "context": "\u03bd and \u03bc are incomparable if \u03bd and \u03bc do not dominate each other [7].", "startOffset": 63, "endOffset": 66}, {"referenceID": 16, "context": "The Pareto front is the set of all objective vectors of points in PS in objective space PF = {F (x) | x \u2208 PS} [17].", "startOffset": 110, "endOffset": 114}, {"referenceID": 6, "context": "A special approach based on ROCCH is proposed in [7] to solve the ROC maximization problem for binary classification.", "startOffset": 49, "endOffset": 52}, {"referenceID": 6, "context": "While in [7] binary classifiers were considered, here we consider complexity augmented binary classifiers and three-class classifiers and in the context of 3-D ROCCH multiobjective maximization.", "startOffset": 9, "endOffset": 12}, {"referenceID": 6, "context": "Firstly, 3-D convex hull (3DCH) based sorting without redundancy approach is used to rank the individuals into several priority levels as proposed in [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 6, "context": "Thirdly, a non-descending (\u03bc + 1) selection strategy is employed in this paper, rather than the approximate (\u03bc + \u03bc) scheme in CH-MOGP [7].", "startOffset": 134, "endOffset": 137}, {"referenceID": 36, "context": "The 3-D convex hull is built by the quickhull algorithm which is proposed in [37].", "startOffset": 77, "endOffset": 81}, {"referenceID": 6, "context": "Convex hull based sorting without redundancy strategy was first proposed in [7], which has a good performance to deal with binary classification problems.", "startOffset": 76, "endOffset": 79}, {"referenceID": 36, "context": "The 3-D quickhull algorithm [37] is adopted to build the convex hull with the candidate points set, which is widely used in 3-D convex hull related applications.", "startOffset": 28, "endOffset": 32}, {"referenceID": 36, "context": "Ensure: 3DCH based sorting without redundancy 1: Q = Qr +Qnr 2: T = Qnr \u222aR 3: F0 = 3D quickhull algorithm(T) [37] 4: Qnr = Qnr \u2212 F0 5: i=1 6: while Qnr = \u2205 do 7: T = Qnr \u222aR 8: Fi = 3D quickhull algorithm(T) 9: Qnr = Qnr \u2212 Fi 10: i = i+ 1 11: end while 12: Fi = Qr 13: return the ranked solution set F", "startOffset": 109, "endOffset": 113}, {"referenceID": 37, "context": "We hypothesize that the new VUS contribution indicator is a more efficient strategy to maximize the volume under the 3-D convex hull when compared to the hyper-volume based contribution [38] or crowding distance indicator [36].", "startOffset": 186, "endOffset": 190}, {"referenceID": 35, "context": "We hypothesize that the new VUS contribution indicator is a more efficient strategy to maximize the volume under the 3-D convex hull when compared to the hyper-volume based contribution [38] or crowding distance indicator [36].", "startOffset": 222, "endOffset": 226}, {"referenceID": 36, "context": "Algorithm 2 \u2206VUS(Qnr, R) Require: Qnr = \u2205 Qnr is the non-redundancy solution set R is a reference points set Ensure: \u2206VUS 1: m = sizeof(Qnr) 2: P = Qnr \u222aR 3: V olumeall = V US(P ) [37] 4: for all i=1:m do 5: qi \u2190 Qnr(i) 6: \u2206V USi = V olumeall \u2212 V US(P \u2212 {qi}) 7: end for 8: return \u2206VUS", "startOffset": 180, "endOffset": 184}, {"referenceID": 16, "context": "The scheme of a (\u03bc+ 1) evolutionary algorithm is adopted within 3DCHEMOA to maximize the ROC performance, rather than the (\u03bc+\u03bc) scheme used in CH-MOGP [17], which causes the algorithm to converge too quickly.", "startOffset": 151, "endOffset": 155}, {"referenceID": 35, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 186, "endOffset": 190}, {"referenceID": 38, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 197, "endOffset": 201}, {"referenceID": 37, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 212, "endOffset": 216}, {"referenceID": 39, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 224, "endOffset": 228}, {"referenceID": 40, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 237, "endOffset": 241}, {"referenceID": 0, "context": "The range of variation of each object is in [0,1], the problem of ZEJD1 is defined in Eq.", "startOffset": 44, "endOffset": 49}, {"referenceID": 0, "context": "where x1, x2, x3 are all in [0, 1] and f1, f2, f3 are all in [0, 1].", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "where x1, x2, x3 are all in [0, 1] and f1, f2, f3 are all in [0, 1].", "startOffset": 61, "endOffset": 67}, {"referenceID": 0, "context": "The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 63, "endOffset": 69}, {"referenceID": 0, "context": "The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 76, "endOffset": 82}, {"referenceID": 0, "context": "The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 89, "endOffset": 95}, {"referenceID": 0, "context": "The range of variation of each objective is in [0,1], the problem of ZED1 is defined in Eq.", "startOffset": 47, "endOffset": 52}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 24, "endOffset": 30}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 37, "endOffset": 43}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 53, "endOffset": 59}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 66, "endOffset": 72}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 79, "endOffset": 85}, {"referenceID": 0, "context": "The objectives of both ZED2 and ZED3 are f1, f2 and f3, all of the objectives are in [0, 1].", "startOffset": 85, "endOffset": 91}, {"referenceID": 33, "context": "The gini coefficient is commonly used as a measure of statistical dispersion intended to represent the income distribution of a nation\u2019s residents [34].", "startOffset": 147, "endOffset": 151}, {"referenceID": 41, "context": "All of the experiments are based on jMetal framework [42], [43].", "startOffset": 53, "endOffset": 57}, {"referenceID": 42, "context": "All of the experiments are based on jMetal framework [42], [43].", "startOffset": 59, "endOffset": 63}, {"referenceID": 43, "context": "The dynamic convex hulls algorithm [44] will be adapted in future work to reduce the computational complexity of the new method.", "startOffset": 35, "endOffset": 39}, {"referenceID": 44, "context": "SPAM multiobjective problem formulation SPAM filtering problem optimization has been addressed by the techniques surveyed in [45], [46].", "startOffset": 125, "endOffset": 129}, {"referenceID": 45, "context": "SPAM multiobjective problem formulation SPAM filtering problem optimization has been addressed by the techniques surveyed in [45], [46].", "startOffset": 131, "endOffset": 135}, {"referenceID": 45, "context": "In previous work on anti-SPAM filter optimization [46] it was observed that many rules were not participating in the classification process and some (with very small weights) only marginally influenced the classification results.", "startOffset": 50, "endOffset": 54}, {"referenceID": 46, "context": "This principle states, in one of its simplified formulations, that unnecessary assumptions for a theory (conclusion) should not be considered if they have no consequence for the conclusion [47].", "startOffset": 189, "endOffset": 193}, {"referenceID": 47, "context": "The SpamAssassin corpus used in our experiments is composed of 9349 email messages, 2398 SPAM and 6951 legitimate messages [49].", "startOffset": 123, "endOffset": 127}, {"referenceID": 47, "context": "2) Algorithms Involved: Five reference multiobjective algorithms were tested (NSGA-II, SPEA2, MOEA/D, SMS-EMOA and 3DCH-EMOA), for the three objectives anti-SPAM filtering problem formulation, using the SpamAssassin corpus [49] for SPAM classification quality assessment.", "startOffset": 223, "endOffset": 227}, {"referenceID": 42, "context": "Experiments were performed with jMetal [43], an optimization framework for the development of multiobjective metaheuristics in Java.", "startOffset": 39, "endOffset": 43}, {"referenceID": 48, "context": "Feature selection methods provide us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications [50].", "startOffset": 202, "endOffset": 206}, {"referenceID": 49, "context": "Evolutionary algorithms have proved to be particularly useful to discover significant and meaningful information in large quantities of raw noisy data [51].", "startOffset": 151, "endOffset": 155}, {"referenceID": 0, "context": "It is possible to construct a classifier with different classifiers trained by subsets of features in 3-D ROC space by means of randomization, which has computation complexity between them [1].", "startOffset": 189, "endOffset": 192}, {"referenceID": 17, "context": "1) Data sets: Twenty-four data sets are selected from UCI repository [18] and described in Table VIII.", "startOffset": 69, "endOffset": 73}, {"referenceID": 50, "context": "It is an algorithm used to generate a decision tree, proposed in [52], with an open source Java implementation (J48), available in the weka data mining tool [53].", "startOffset": 65, "endOffset": 69}, {"referenceID": 51, "context": "It is an algorithm used to generate a decision tree, proposed in [52], with an open source Java implementation (J48), available in the weka data mining tool [53].", "startOffset": 157, "endOffset": 161}, {"referenceID": 42, "context": "All experiments are based on jMetal [43] and Weka [53].", "startOffset": 36, "endOffset": 40}, {"referenceID": 51, "context": "All experiments are based on jMetal [43] and Weka [53].", "startOffset": 50, "endOffset": 54}, {"referenceID": 0, "context": "With the technique of iso-performance [1] we can obtain any classifiers on the surface of ROCCH.", "startOffset": 38, "endOffset": 41}, {"referenceID": 52, "context": "Ensemble learning is a powerful learning approach that combines multiple classifiers to build up more accurate classifier than each of the individual classifier [54].", "startOffset": 161, "endOffset": 165}, {"referenceID": 53, "context": "The performance of ensemble learning always rely on the diversity of feature subset selection [55].", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "It is possible to construct a classifier with two different classifiers with subsets of features in 3-D ROC space by means of randomization with the theory of iso-performance [1], which has computation complexity between the two classifiers.", "startOffset": 175, "endOffset": 178}, {"referenceID": 17, "context": "1) Data sets: Five data sets are selected from UCI repository [18] and described in Table X.", "startOffset": 62, "endOffset": 66}, {"referenceID": 50, "context": "5 [52] is used with J48 Java open source implementation of weka data mining tool [53].", "startOffset": 2, "endOffset": 6}, {"referenceID": 51, "context": "5 [52] is used with J48 Java open source implementation of weka data mining tool [53].", "startOffset": 81, "endOffset": 85}], "year": 2014, "abstractText": "Finding a good classifier is a multiobjective optimization problem with different error rates and the costs to be minimized. The receiver operating characteristic is widely used in the machine learning community to analyze the performance of parametric classifiers or sets of Pareto optimal classifiers. In order to directly compare two sets of classifiers the area (or volume) under the convex hull can be used as a scalar indicator for the performance of a set of classifiers in receiver operating characteristic space. Recently, the convex hull based multiobjective genetic programming algorithm was proposed and successfully applied to maximize the convex hull area for binary classification problems. The contribution of this paper is to extend this algorithm for dealing with higher dimensional problem formulations. In particular, we discuss problems where parsimony (or classifier complexity) is stated as a third objective and multi-class classification with three different true classification rates to be maximized. The design of the algorithm proposed in this paper is inspired by indicator-based evolutionary algorithms, where first a performance indicator for a solution set is established and then a selection operator is designed that complies with the performance indicator. In this case, the performance indicator will be the volume under the convex hull. The algorithm is tested and analyzed in a proof of concept study on different benchmarks that are designed for measuring its capability to capture relevant parts of a convex hull. Further benchmark and application studies on email classification and feature selection round up the analysis and assess robustness and usefulness of the new algorithm in real world settings.", "creator": "cairo 1.13.1 (http://cairographics.org)"}}}