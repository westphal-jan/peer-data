{"id": "1412.6153", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2014", "title": "Intelligent Indoor Mobile Robot Navigation Using Stereo Vision", "abstract": "Majority of the existing robot navigation systems, which facilitate the use of laser range finders, sonar sensors or artificial landmarks, has the ability to locate itself in an unknown environment and then build a map of the corresponding environment. Stereo vision, while still being a rapidly developing technique in the field of autonomous mobile robots, are currently less preferable due to its high implementation cost. This paper aims at describing an experimental approach for the building of a stereo vision system that helps the robots to avoid obstacles and navigate through indoor environments and at the same time remaining very much cost effective. This paper discusses the fusion techniques of stereo vision and ultrasound sensors which helps in the successful navigation through different types of complex environments. The data from the sensor enables the robot to create the two dimensional topological map of unknown environments and stereo vision systems models the three dimension model of the same environment.", "histories": [["v1", "Wed, 10 Sep 2014 20:01:45 GMT  (632kb)", "http://arxiv.org/abs/1412.6153v1", "9 pages, SIPIJ August 2014"]], "COMMENTS": "9 pages, SIPIJ August 2014", "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.CV", "authors": ["arjun b krishnan", "jayaram kollipara"], "accepted": false, "id": "1412.6153"}, "pdf": {"name": "1412.6153.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Arjun B Krishnan", "Jayaram Kollipara", "Amrita Vishwa Vidyapeetham"], "emails": ["abkrishna39@gmail.com", "kollipara.jayaram@gmail.com"], "sections": [{"heading": null, "text": "The majority of existing robot navigation systems, which allow the use of laser rangefinders, sonar sensors or artificial boundaries, have the ability to locate themselves in an unknown environment and then create a map of the corresponding environment. Stereo vision is still a rapidly evolving technology in the field of autonomous mobile robots, but is currently less preferable due to its high implementation costs. This paper aims to describe an experimental approach to building a stereo vision system that helps robots avoid obstacles and navigate indoors while remaining very cost-effective. This paper discusses the fusion technologies of stereo and ultrasonic sensors that help successfully navigate through various types of complex environments. Data from the sensor allows the robot to create the two-dimensional topological map of unknown environments, and stereo vision systems model the three-dimensional model of the ORYEGUGUGUINO, EGUGUGUGUGUINO, EGUGUGUGUGUINO, EGUGUGUGUGUGUGUINO, EGUGUGUGUGUGUGUGUGUGUGUGUGUINO, GUGUGUGUGUGUGUGUGUGUGUGUGUINO, GUGUGUGUGUGUGUGUGUGUINO, GUGUGUGUGUGUGUGUGUINO, GUGUGUGUGUGUGUGUGUINO, GUGUGUGUGUGUGUINO, GUGUGUUGUGUGUINO, GUGUGUGUGUAGINO, GUI, GUAGINOGUAGO, GUAGINOGUAGINO, GUAGINO, GUGUGUGUAGINOGUUAGINOGUUAGINO, GUGUAGO, GUAGINOGUAGINOGUAGINOUUAGO, GUAGO, GUAG"}, {"heading": "1. INTRODUCTION", "text": "Interest in implementing robotic systems for tasks such as indoor automation, driverless transportation and exploring the unknown environment has grown exponentially in the community of researchers and engineers. This project addresses the tasks of autonomous navigation and exploring the environment using stereo vision-based techniques. Other techniques include ultrasonic sensors, LIDAR, pre-installed maps, etc. For all of these reasons, Stereo-Vision has an advantage over other technologies due to its ability to provide three-dimensional information about what the environment looks like and to decide how to avoid obstacles to safe navigation through the environment. Currently available stereo cameras are very expensive and require special drivers and software to interface with processing platforms. This problem is solved in this project by creating stereo rigs using conventional webcams, making this technology cost-effective."}, {"heading": "2. RELATED WORKS", "text": "Several autonomous mobile robots equipped with stereo sensors and stereo system have been implemented in recent years and are used both in industry and in the domestic market. They serve humans in various areas such as tour guiding, food delivery, material transport during production processes, hospital automation and military surveillance. The robots Rhino [1] and Minerva [2] are famous examples of fully functional tour guide robots, which are used in museums and equipped with stereo sensors for navigation and map generation.The robot Jose [3] uses a trinocular vision-based system, which accurately maps the environment in all three dimensions. PR2 [4] is one of the most advanced home X-ray automation robots, which uses a combination of stereo sensor and laser rangefinder for operation.According to [5] there are two essential algorithms for each stereo system: stereo X-ray calibration algorithm and stereo X-ray paroscopy algorithms, which are used as X-ray paroscopic algorithms."}, {"heading": "3. STEREO VISION BASED OBSTACLE AVOIDANCE", "text": "Extracting the 3D position of objects from two or more simultaneous views of a scene is known as stereo vision. Stereo vision systems are reliable and efficient primary sensors for mobile robots and robotic manipulators to extract range information from the environment. Stereo vision systems can also be used as a tool for all image processing tasks such as color-based segmentation and function detection, making them the best imaging technique in the field of robotics. Ideally, the two image sensors in a stereo rig are perfectly aligned along a horizontal or vertical straight line that leads through the main points of both images. Perfect alignment while mounting the cameras at the same time is the main difficulty in realizing custom stereo rigs. In addition, cameras are prone to lens distortions and imaging-level distortions that result in the assumption of stereo pair rectification processes in the position to return distorted image projections to ordinary levels."}, {"heading": "3.1. The hardware for Stereo Vision System (SVS)", "text": "A stereo camera is a type of camera with two or more lenses and separate image sensors for each lens. Stereo systems are capable of simulating human binocular vision, thus providing the ability to capture three-dimensional images. Two 640x480 pixel CMOS web cameras with an interface to USB 2.0 High Speed (UVC) determine the depth range that can be reliably perceived. Choosing the baseline length of a stereo system is mainly application dependent, because a longer baseline length increases both the minimum and the maximum limits of the range, while a shorter baseline can reduce the limits [8]. Due to the similarity between the internal navigation of a robot and a human, the most suitable option for baseline length is the distance between the human eyes. As a result, a fixed distance of 63 mm between the stereoscopy and the stereo line has been selected."}, {"heading": "3.2. Algorithms and Software", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "3.3. Depth based Image segmentation for obstacle avoidance", "text": "The disparity maps generated by the above-mentioned algorithm play an important role in avoiding obstacles during navigation. Segmentation based on intensity levels is the same as segmentation based on depth. Disparity images are enhanced with 3x3 rectangular masks to fill small holes that exist in the disparity. A segmentation algorithm is used to detect near objects that have a high intensity range, and searches for connected areas that can form blobs within the segmented regions. The intensity range for segmentation is determined experimentally so that all obstacles within 20 cm to 40 cm are detected. The contours of these blobs are detected and Bounding Box coordinates are calculated for each blobe. The centers of the Bounding Boxes as well as the Bounding Boxes are marked on the image. The input image of the left camera is split into two halves recognized by the left of the camera, or the right."}, {"heading": "4. 3D RECONSTRUCTION", "text": "The three-dimensional reconstruction is the process of generating the model of the real world observed through multiple views. Generated disparity maps from each scene can be converted into corresponding point clouds with real X, Y and Z coordinates. The process of reconstructing 3D points requires certain parameters obtained from the calibration of stereo rig. An entity called the re-projection matrix is formed from the intrinsic and extrinsic parameters and it denotes the relationship between real coordinates and pixel coordinates. Re-projection matrix is formed during the calibration steps. The entries of the re-projection matrix are shown in Figure 6. (cx, cy) - is the main point of the camera. The point at which the image surface exactly coincides with the center of the lens. f - Focus length of the camera, as the cameras in the stereo rig are set to the same focal length."}, {"heading": "5. EXPERIMENTAL ROBOTIC PLATFORM", "text": "The experimental mobile robotic platform used in this project is a six-wheeled differential drive rover capable of carrying a portable personal computer. Three ultrasonic sensors are attached to the front of the robot. Vertical depth information on the operating surface is monitored by two infrared rangefinders, which prevent falling from an elevated surface. A three-axis digital compass module is used to determine the direction of motion of the robot. 45 rpm high-speed geared motors are used to power the four wheels, giving the robot a speed of 20 cm / sec. Optical encoders are attached to two freely rotating wheels that track the distance travelled. The optical encoder generates 400 pulses per revolution, giving a resolution of 0.90 degrees. The core elements of the embedded system of this robot are two 8-bit ATA-based microcontroller board 328."}, {"heading": "6. RESULTS", "text": "We successfully demonstrated a low-cost prototype of the stereo camera and robotics platform, comparable to commercially available alternatives, capable of processing five frames per second in a 1.6GHz Intel atomic processor board equipped with 2GB of RAM, which is adequate performance for safe indoor navigation for slow-moving robots. Near-flawless indoor navigation of the robot is ensured by the process of overlapping visual perception with other sensor information. Accurate 2D mapping of the environment based on ultrasonic data and 3D mapping using stereoscopy has been implemented. For sample data collected during a four-minute test run, 3D reconstruction takes 25 to 80ms per image, whereas 2D mapping takes less than 50ms of time. A sense of intelligence is given to the robot by recognizing objects that during this test run take four minutes to complete the 3D reconstruction process."}, {"heading": "7. DISCUSSION AND FUTURE WORK", "text": "The robot described in this paper is able to navigate through a completely unknown environment without manual control. It can be used to explore an unknown environment, such as collapsed buildings and inaccessible environments for soldiers during war. Vision-based navigation allows the robot to actively interact with the environment, although vision-based navigation systems have certain disadvantages compared to other techniques. Stereo vision fails when exposed to surfaces with fewer textures and features, such as monochrome walls and glass surfaces. The illumination level of the environment is another factor that significantly affects the performance of stereo vision. Choosing the processing platform is critical in the case of processor-intensive algorithms used in generating deviation maps."}], "references": [{"title": "The mobile robot Rhino,", "author": ["J. Buhmann", "W. Burgard", "A.B. Cremers", "D. Fox", "T. Hofmann", "F. Schneider", "J. Strikos", "S. Thrun"], "venue": "AI Magazine,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "MINERVA: A second generation mobile tour-guide robot,", "author": ["S. Thrun", "M. Bennewitz", "W. Burgard", "A.B. Cremers", "F. Dellaert", "D. Fox", "D. H\u00e4hnel", "C. Rosenberg", "N. Roy", "J. Schulte", "D. Schulz"], "venue": "in Proc. IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Using real-time stereo vision for mobile robot navigation,", "author": ["Don Murray", "Jim Little"], "venue": "Autonomous Robots,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "PR2 Remote Lab: An environment for remote development and experimentation,\" Robotics and Automation (ICRA)", "author": ["B. Pitzer", "S. Osentoski", "G. Jay", "C. Crick", "O.C. Jenkins"], "venue": "vol., no.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Binocular Stereo Vision Based Obstacle Avoidance Algorithm for Autonomous Mobile Robots,", "author": ["S. Kumar"], "venue": "Advance Computing Conference,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "A global matching framework for stereo computation,", "author": ["H. Tao", "H. Sawhney", "R. Kumar"], "venue": "In Proc. International Conference on Computer Vision,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Camera Calibration\", Emerging Topics in Computer Vision, Prentice Hall Professional", "author": ["Z. Zhang", "G. Medioni", "S.B. Kang"], "venue": "Technical Reference,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "A multiple-baseline stereo,", "author": ["M. O kutomi", "T . K"], "venue": "anade,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1993}, {"title": "Variation and extrema of human interpupillary distance,", "author": ["Dodgson", "N. A"], "venue": "Proceedings of SPIE: Stereoscopic Displays and Virtual Reality Systems XI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Random sample consensus: a paradigm for model fitting with application to image analysis and automated cartography", "author": ["M.A. Fischler", "R.C. Bolles"], "venue": "Communication of ACM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1981}, {"title": "Learning OpenCV: Computer Vision with the OpenCV Library,", "author": ["G. Bradski", "A. Kaehler"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Stereo vision based mapping and navigation for mobile robots,", "author": ["D. Murray", "C. Jennings"], "venue": "IEEE International Conference on Robotics and Automation,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "The robots Rhino [1] and Minerva [2] are famous examples of fully operational tour guide robots used in museums which a equipped with stereo vision along with sonar sensors for navigate and map building.", "startOffset": 17, "endOffset": 20}, {"referenceID": 1, "context": "The robots Rhino [1] and Minerva [2] are famous examples of fully operational tour guide robots used in museums which a equipped with stereo vision along with sonar sensors for navigate and map building.", "startOffset": 33, "endOffset": 36}, {"referenceID": 2, "context": "The robot Jose [3] uses a Trinocular vision based system that accurately map the environment in all three dimensions.", "startOffset": 15, "endOffset": 18}, {"referenceID": 3, "context": "PR2 [4] is one of the most developed home automation robot which uses a combination of stereo vision and laser range finders for operation", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "According to [5] there are two essential algorithms for every stereo vision systems: Stereo Calibration algorithm and Stereo Correspondence algorithm.", "startOffset": 13, "endOffset": 16}, {"referenceID": 5, "context": "A stereo correspondence algorithm based on global matching is described in [6] uses correspondence search based on block matching.", "startOffset": 75, "endOffset": 78}, {"referenceID": 6, "context": "Figure 1 shows the formation of disparity in stereo image pair using the Pinhole model [7] of two cameras.", "startOffset": 87, "endOffset": 90}, {"referenceID": 7, "context": "The choice of baseline length of a stereo rig is mainly application dependent because a longer baseline length increases both the minimum as well as a maximum bounds of the range while shorter baseline can decrease the bounds [8].", "startOffset": 226, "endOffset": 229}, {"referenceID": 8, "context": "2mm [9].", "startOffset": 4, "endOffset": 7}, {"referenceID": 9, "context": "OpenCV provides predefined functions to find these matrices using RANSAC algorithm [10] and hence calibrate cameras and the rig.", "startOffset": 83, "endOffset": 87}], "year": 2014, "abstractText": "Majority of the existing robot navigation systems, which facilitate the use of laser range finders, sonar sensors or artificial landmarks, has the ability to locate itself in an unknown environment and then build a map of the corresponding environment. Stereo vision, while still being a rapidly developing technique in the field of autonomous mobile robots, are currently less preferable due to its high implementation cost. This paper aims at describing an experimental approach for the building of a stereo vision system that helps the robots to avoid obstacles and navigate through indoor environments and at the same time remaining very much cost effective. This paper discusses the fusion techniques of stereo vision and ultrasound sensors which helps in the successful navigation through different types of complex environments. The data from the sensor enables the robot to create the two dimensional topological map of unknown environments and stereo vision systems models the three dimension model of the same environment.", "creator": "Microsoft\u00ae Word 2013"}}}