{"id": "1412.6815", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2014", "title": "Extraction of Salient Sentences from Labelled Documents", "abstract": "We present a hierarchical convolutional document model with an architecture designed to support introspection of the document structure. Using this model, we show how to use visualisation techniques from the computer vision literature to identify and extract topic-relevant sentences.", "histories": [["v1", "Sun, 21 Dec 2014 17:38:19 GMT  (190kb,D)", "https://arxiv.org/abs/1412.6815v1", "arXiv admin note: substantial text overlap witharXiv:1406.3830"], ["v2", "Sat, 28 Feb 2015 23:57:08 GMT  (238kb,D)", "http://arxiv.org/abs/1412.6815v2", "arXiv admin note: substantial text overlap witharXiv:1406.3830"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1406.3830", "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["misha denil", "alban demiraj", "nando de freitas"], "accepted": false, "id": "1412.6815"}, "pdf": {"name": "1412.6815.pdf", "metadata": {"source": "CRF", "title": "Extraction of Salient Sentences from Labelled Documents", "authors": ["Misha Denil", "Alban Demiraj", "Nando de Freitas"], "emails": ["misha.denil@cs.ox.ac.uk", "a.demiraj@oxfordalumni.org", "nandodefreitas@google.com"], "sections": [{"heading": null, "text": "We also introduce a new scalable evaluation technology for automatic sentence extraction systems that avoids time-consuming human annotation of validation data."}, {"heading": "1 Introduction", "text": "The idea of coding symbolic concepts with distributed representations has excited researchers for decades (Hinton, 1986; Bengio et al., 2003).In recent years, following the success of neural networks, this idea has resurfaced in many areas of natural language processing, such as language modeling (Mikolov et al., 2013), machine translation (Schwenk, 2012; Kalchbrenner & Blunsom, 2013a; Devlin et al., 2014; Cho et al., 2014; Sutskever et al., 2014; Hermann & Blunsom, 2014), answering questions (Bordes et al., 2014; Weston et al., 2014), dialogue systems (Kalchbrenner & Blunsom, 2013b), mood analysis (Socher et al., 2012; Hermann & Blunsom, 2013), and other tasks of natural language processing such as chunking and entity recognition."}, {"heading": "2 Model description", "text": "At the sentence level, we use a ConvNet to transform word embedding in each sentence into an embedding for the entire sentence. At the document level, we use a different ConvNet to transform sentence embedding from the first level into a single embedding vector that represents the entire document. At the sentence level, the model is trained by embedding the document in a Softmax classifier, and the model is trained by backprojecting both at the sentence and document level. At the sentence level, the filter banks that process different sentences are linked together so that each sentence has an embedding produced by the same ConvNet. The architecture of our model forces information to pass through a subsentence-based representation, an architecture inspired by Gulcehre & Bengio (2013), which shows that learning appropriate subsentences contributes to generalization."}, {"heading": "2.1 Embedding matrix", "text": "The input at each level of our model is an embedding matrix. At the sentence level, the columns of this matrix correspond to the embedding of words in the sentence to be processed, while at the document level, the columns correspond to the embedding generated by the sentence level of the model. At the sentence level, an embedding matrix is built for each sentence by concatenating embedding for each word it contains into the columns of a matrix. The words are drawn from a fixed vocabulary V, which we represent by means of a matrix of word embedding W-Rd-V-V. Each column of this matrix is a d-dimensional vector, which gives an embedding for a single word in the vocabulary. The word embedding vectors are parameters of the model and are optimized using the embedding matrix. 1Code implementing this model is provided after the verification process."}, {"heading": "2.2 Convolution", "text": "Each wave layer contains a filter bank F-Rd-wf-wf-nf, where wf and nf refer to the width and number of characteristic cards, respectively. The first dimension of each characteristic card f-Rd-wf corresponds to the number of dimensions in the embedding created by the layer below. The folding process in our model is one-dimensional. We align the first axis of each characteristic card with the embedding axis and unravel along the rows of the embedding matrix. At the record level, this corresponds to the entanglement across words and at the document level to the entanglement across sentences. Each characteristic card generates a 1d series of numbers, each value being achieved by applying the characteristic card at a different point along the set matrix. The results of different characteristic cards are then stacked to form a new matrix of latent representations, which is fed into the next layer as input. In all cases, we use \"full\" to achieve all features in the series."}, {"heading": "2.3 k-max pooling", "text": "Since different sets and documents have different lengths, not all embedding matrices are of the same width. This is not a problem for the shaft planes, as shafts can process input of any width, but it is problematic to use them as input for a fully connected or softmax level and at the interface between the set and document levels. The solution we use is k-max pooling, which is applied separately for each line of the embedding matrix. To apply k-max pooling to a single line, we keep the k-largest values along that line and discard the rest. Since k is a fixed parameter, it always produces a fixed-size output (if the input is less than k, we fill it with zeros). For example, applying 2-max pooling to [3, 1, 5, 2] yields [3, 5]. This method is also graphed in Figure 1."}, {"heading": "2.4 Full model", "text": "At the sentence level, we use a single revolutionary pipeline to process each sentence (i.e. the weights of the sentence models are bound across sentences).The document level of the model consists of the same type of folding and bundling primitives, but the weights are not shared with the sentence level models.An important feature of this archaeology is that it forces the model to create an intermediate representation for each sentence in the document. It is this representation that allows the extraction technique in Section 3 to identify prominent sentences. If we had simply applied coils to the entire document instead, we would not be able to unravel the contributions of individual sentences."}, {"heading": "3 Sentence extraction through visualisation", "text": "The first step in our selection process is to create a salinity map for the individual sentences that we use as a basis for each sentence. To generate the salinity map for a given document, we use the technique of Simonyan et al. (2013). To generate the salinity map for a given document, we use the technique of Simonyan et al. (2013) with a modified objective function.We first perform a prediction through the network to generate a prediction for the prediction.We generate the salinity map for a given document. (2013) We generate the technology of Simonyan et al. (2013)"}, {"heading": "4 Scalable evaluation", "text": "The sentence extraction scheme described in Section 3 yields very good results in terms of quality (see Figure 2 for several examples); however, because we lack labels for \"correct\" extractions, we do not have a gold standard to compare with. Instead, we propose a method of measuring the extraction quality that can easily be applied to marked 1: 1 documents. We propose to apply a simple \"reference model\" to complete documents and then compare the performance of the reference model to complete documents with its performance to documents created by extracting a small number of sentences. This assessment scheme is somewhat unorthodox, but has a very intuitive interpretation. If the extraction process chooses task-relevant sentences, it should be easy for the reference model to identify the name of the original document based on an extracted subset of sentences. On the other hand, selecting irrelevant sentences should confuse the reference model and reduce its accuracy."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Data preparation", "text": "We use the IMDB movie ratings dataset, originally introduced by Maas et al. (2011), to demonstrate our extraction techniques. This dataset contains a total of 100,000 movie ratings posted on IMDB. There are 50,000 unmarked ratings, and the remaining 50,000 marked ratings are divided into 25,000 rating trainings and 25,000 rating tests. Each of the marked ratings has a binary label, either positive or negative. In our experiments, we only use the marked part of that dataset. We pre-edit each review by first removing HTML markup and splitting the review into sentences, and then splitting each sentence into words. We use NLTK2 to perform these tasks. We also assign numbers to a generic NUMBER token, any symbol that is not in.?! SYMBOL and any word that appears less than 5 times in the training set to assign UNNOWN."}, {"heading": "5.2 Review Summarisation via Sentence extraction", "text": "The judgement-level model uses 10-dimensional word embedding interwoven with 6 playing cards of width 5, followed by a 4-max pooling layer and a tanh nonlinearity. The weights of this model are tied up via sentences in a document. The document-level model entangles its input with a bank of 15 playing cards of width 5, followed by 2-max pooling and a tanh nonlinearity. Finally, the result is fed into a softmax classifier that predicts whether the feeling of the review is positive or negative. We extract highlighted sentences from each of the review of the movie, followed by 2-max pooling and a tanh nonlinearity. The assessment, we also train a reference model with Nave Bayes on the full training set.2http: / www.nltk.org / i caught this movie on the sci-fi channel recently."}, {"heading": "6 Conclusion", "text": "In this paper, we presented a ConvNet model for documents with an architecture designed to support introspection of the document structure; we also demonstrated that we can use the visualization technology of Simonyan et al. (2013) to identify and extract task-specific, prominent sentences from documents; we demonstrated this technique by extracting sentimental sentences from film reviews; we also introduced a scalable evaluation method for automatic sentence extraction systems; by comparing the performance of a reference classifier in complete documents with its performance in documents created from extracted sentences, we can measure how much task-relevant information remains obtained through the extraction process.We compared our ConvNet extraction model with several methods of baseline extraction; our evaluation shows that our model extracts more task-relevant information than the basic methods, even if the total number of extracted sentences is very small."}, {"heading": "Acknowledgments", "text": "We would like to thank Phil Blunsom and Nal Kalchbrenner for many interesting discussions about ConvNets for NLP and for their contributions to an early version of this work."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "Technical report, University of Montreal,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "A Neural Probabilistic Language Model", "author": ["Bengio", "Yoshua", "Ducharme", "Rejean", "Vincent", "Pascal", "Jauvin", "Christian"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bengio et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Question answering with subgraph embeddings", "author": ["Bordes", "Antoine", "Chopra", "Sumit", "Weston", "Jason"], "venue": "CoRR, abs/1406.3676,", "citeRegEx": "Bordes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "From machine learning to machine reasoning: an essay", "author": ["Bottou", "L\u00e9on"], "venue": "Machine Learning,", "citeRegEx": "Bottou and L\u00e9on.,? \\Q2014\\E", "shortCiteRegEx": "Bottou and L\u00e9on.", "year": 2014}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine", "author": ["Cho", "Kyunghyun", "van Merrienboer", "Bart", "Gulcehre", "Caglar", "Bougares", "Fethi", "Schwenk", "Holger", "Bengio", "Yoshua"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Natural language processing (almost) from scratch", "author": ["R Collobert", "Weston", "Jason", "Bottou", "Leon", "Karlen", "Michael", "Kavukcuoglu", "Koray", "Kuksa", "Pabvel"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation", "author": ["Devlin", "Jacob", "Zbib", "Rabih", "Huang", "Zhongqiang", "Lamar", "Thomas", "Schwartz", "Richard", "Makhoul", "John"], "venue": "In Association for Computational Linguistics,", "citeRegEx": "Devlin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Devlin et al\\.", "year": 2014}, {"title": "Deep convolutional neural networks for sentiment analysis of short texts", "author": ["dos Santos", "Ciccero Noguelra", "Gatti", "Maira"], "venue": "In International Conference on Computational Linguistics,", "citeRegEx": "Santos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2014}, {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "author": ["Gulcehre", "Caglar", "Bengio", "Yoshua"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Gulcehre et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gulcehre et al\\.", "year": 2013}, {"title": "The role of syntax in vector space models of compositional semantics", "author": ["Hermann", "Karl Moritz", "Blunsom", "Phil"], "venue": "Proceedings of the ACL,", "citeRegEx": "Hermann et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2013}, {"title": "Multilingual Models for Compositional Distributional Semantics", "author": ["Hermann", "Karl Moritz", "Blunsom", "Phil"], "venue": "In Proceedings of ACL,", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Transforming Auto-encoders", "author": ["G E Hinton", "A Krizhevsky", "Wang", "S D"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Hinton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2011}, {"title": "Learning Distributed Representations of Concepts", "author": ["Hinton", "Geoffrey E"], "venue": "In Annual Conference of the Cognitive Science Society, pp", "citeRegEx": "Hinton and E.,? \\Q1986\\E", "shortCiteRegEx": "Hinton and E.", "year": 1986}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Hu", "Baotian", "Lu", "Zhengdong", "Li", "Hang", "Chen", "Qingcai"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2014}, {"title": "Recurrent Continuous Translation Models", "author": ["Kalchbrenner", "Nal", "Blunsom", "Phil"], "venue": "In Empirical Methods in Natural Language Processing,", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2013}, {"title": "Recurrent convolutional neural networks for discourse compositionality", "author": ["Kalchbrenner", "Nal", "Blunsom", "Phil"], "venue": "Proceedings of the 2013 Workshop on Continuous Vector Space Models and their Compositionality,", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2013}, {"title": "A Convolutional Neural Network for Modelling Sentences", "author": ["Kalchbrenner", "Nal", "Grefenstette", "Edward", "Blunsom", "Phil"], "venue": "In Association for Computational Linguistics,", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Learning Word Vectors for Sentiment Analysis", "author": ["Maas", "Andrew L", "Daly", "Raymond E", "Pham", "Peter T", "Huang", "Dan", "Ng", "Andrew Y", "Potts", "Christopher"], "venue": "In Proceedings of ACL,", "citeRegEx": "Maas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2011}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Mikolov", "Tomas", "Chen", "Kai", "Corrado", "Greg", "Dean", "Jeffrey"], "venue": "In NIPS,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Continuous Space Translation Models for Phrase-Based Statistical Machine Translation", "author": ["Schwenk", "Holger"], "venue": "In International Conference on Computational Linguistics,", "citeRegEx": "Schwenk and Holger.,? \\Q2012\\E", "shortCiteRegEx": "Schwenk and Holger.", "year": 2012}, {"title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps", "author": ["Simonyan", "Karen", "Vedaldi", "Andrea", "Zisserman", "Andrew"], "venue": "Technical report,", "citeRegEx": "Simonyan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2013}, {"title": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions", "author": ["Socher", "Richard", "Pennington", "Jeffrey", "Huang", "Eric H", "Ng", "Andrew Y", "Manning", "Christopher D"], "venue": "In Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Semantic Compositionality through Recursive Matrix-Vector Spaces", "author": ["Socher", "Richard", "Huval", "Brody", "Manning", "Christopher D", "Ng", "Andrew Y"], "venue": "In Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Socher et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc V. V"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Deep learning for answer sentence selection", "author": ["Yu", "Lei", "Hermann", "Karl Moritz", "Blunsom", "Phil", "Pulman", "Stephen"], "venue": "In NIPS Deep Learning Workshop,", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}, {"title": "Visualizing and Understanding Convolutional Networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "Technical report,", "citeRegEx": "Zeiler et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2012}, {"title": "Adaptive Deconvolutional Networks for Mid and High Level Feature Learning", "author": ["Zeiler", "Matthew D", "Taylor", "Graham W", "Fergus", "Rob"], "venue": "In International Conference on Computer Vision,", "citeRegEx": "Zeiler et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 1, "context": "The idea of encoding symbolic concepts with distributed representations has excited researchers for decades (Hinton, 1986; Bengio et al., 2003).", "startOffset": 108, "endOffset": 143}, {"referenceID": 18, "context": "In recent years this idea has re-emerged following the success of neural networks in many natural language processing domains such as language modelling (Mikolov et al., 2013), machine translation (Schwenk, 2012; Kalchbrenner & Blunsom, 2013a; Devlin et al.", "startOffset": 153, "endOffset": 175}, {"referenceID": 6, "context": ", 2013), machine translation (Schwenk, 2012; Kalchbrenner & Blunsom, 2013a; Devlin et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Sutskever et al., 2014; Hermann & Blunsom, 2014), question answering (Bordes et al.", "startOffset": 29, "endOffset": 186}, {"referenceID": 4, "context": ", 2013), machine translation (Schwenk, 2012; Kalchbrenner & Blunsom, 2013a; Devlin et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Sutskever et al., 2014; Hermann & Blunsom, 2014), question answering (Bordes et al.", "startOffset": 29, "endOffset": 186}, {"referenceID": 0, "context": ", 2013), machine translation (Schwenk, 2012; Kalchbrenner & Blunsom, 2013a; Devlin et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Sutskever et al., 2014; Hermann & Blunsom, 2014), question answering (Bordes et al.", "startOffset": 29, "endOffset": 186}, {"referenceID": 23, "context": ", 2013), machine translation (Schwenk, 2012; Kalchbrenner & Blunsom, 2013a; Devlin et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Sutskever et al., 2014; Hermann & Blunsom, 2014), question answering (Bordes et al.", "startOffset": 29, "endOffset": 186}, {"referenceID": 2, "context": ", 2014; Hermann & Blunsom, 2014), question answering (Bordes et al., 2014; Weston et al., 2014), dialogue systems (Kalchbrenner & Blunsom, 2013b), sentiment analysis (Socher et al.", "startOffset": 53, "endOffset": 95}, {"referenceID": 21, "context": ", 2014), dialogue systems (Kalchbrenner & Blunsom, 2013b), sentiment analysis (Socher et al., 2011; 2012; Hermann & Blunsom, 2013), and other natural language processing tasks such as chunking and named entity recognition (Collobert et al.", "startOffset": 78, "endOffset": 130}, {"referenceID": 5, "context": ", 2011; 2012; Hermann & Blunsom, 2013), and other natural language processing tasks such as chunking and named entity recognition (Collobert et al., 2011).", "startOffset": 130, "endOffset": 154}, {"referenceID": 5, "context": "Following their tremendous success in computer vision, there have recently been many successful applications of Convolutional neural networks (ConvNets for short) to NLP (Collobert et al., 2011; Kalchbrenner et al., 2014; Hermann & Blunsom, 2014; dos Santos & Gatti, 2014; Hu et al., 2014; Yu et al., 2014).", "startOffset": 170, "endOffset": 306}, {"referenceID": 16, "context": "Following their tremendous success in computer vision, there have recently been many successful applications of Convolutional neural networks (ConvNets for short) to NLP (Collobert et al., 2011; Kalchbrenner et al., 2014; Hermann & Blunsom, 2014; dos Santos & Gatti, 2014; Hu et al., 2014; Yu et al., 2014).", "startOffset": 170, "endOffset": 306}, {"referenceID": 13, "context": "Following their tremendous success in computer vision, there have recently been many successful applications of Convolutional neural networks (ConvNets for short) to NLP (Collobert et al., 2011; Kalchbrenner et al., 2014; Hermann & Blunsom, 2014; dos Santos & Gatti, 2014; Hu et al., 2014; Yu et al., 2014).", "startOffset": 170, "endOffset": 306}, {"referenceID": 24, "context": "Following their tremendous success in computer vision, there have recently been many successful applications of Convolutional neural networks (ConvNets for short) to NLP (Collobert et al., 2011; Kalchbrenner et al., 2014; Hermann & Blunsom, 2014; dos Santos & Gatti, 2014; Hu et al., 2014; Yu et al., 2014).", "startOffset": 170, "endOffset": 306}, {"referenceID": 10, "context": "This architecture is inspired by Gulcehre & Bengio (2013) who show that learning appropriate intermediate representations helps generalisation, and also by Hinton et al. (2011) who show that by forcing information to pass through carefully chosen bottlenecks it is possible to control the types of intermediate representations that are learned.", "startOffset": 156, "endOffset": 177}, {"referenceID": 10, "context": "This architecture is inspired by Gulcehre & Bengio (2013) who show that learning appropriate intermediate representations helps generalisation, and also by Hinton et al. (2011) who show that by forcing information to pass through carefully chosen bottlenecks it is possible to control the types of intermediate representations that are learned. Forcing the model to represent documents in terms of semantically relevant units is essential to the extraction application we introduce later in this paper. The fact that specific hidden units in our network are used to represent each sentence is what allows us to measure the relevance contribution from each sentence separately. Each level of our model in isolation is very similar to the DCNN of Kalchbrenner et al. (2014); the main difference is in how interactions between embedding dimensions are handled.", "startOffset": 156, "endOffset": 772}, {"referenceID": 5, "context": "Collobert et al. (2011)) and is also consistent with ConvNets for vision.", "startOffset": 0, "endOffset": 24}, {"referenceID": 5, "context": "Collobert et al. (2011)) and is also consistent with ConvNets for vision. Using a more standard form of convolution makes the model more compact (which is nice when adding more layers) but is not the focus of this paper. The main difference between our model and the DCNN is that we extend the model with a multi-level structure for modelling documents, where Kalchbrenner et al. (2014) considered only sentences.", "startOffset": 0, "endOffset": 387}, {"referenceID": 20, "context": "In fact this procedure is formally quite similar to the operations carried out in a deconvolutional net (Simonyan et al., 2013).", "startOffset": 104, "endOffset": 127}, {"referenceID": 20, "context": "In fact this procedure is formally quite similar to the operations carried out in a deconvolutional net (Simonyan et al., 2013). Visualisation through backpropogation is a generalisation of the deconvolutional approach, since one can backpropogate through nonconvolutional layers. The first step in our extraction procedure is to create a saliency map for the document by assigning an importance score to each sentence. To generate the saliency map for a given document, we adopt the technique of Simonyan et al. (2013) with a modified objective function.", "startOffset": 105, "endOffset": 520}, {"referenceID": 17, "context": "We use the IMDB movie review sentiment data set, which was originally introduced by Maas et al. (2011), to demonstrate our extraction technique.", "startOffset": 84, "endOffset": 103}, {"referenceID": 20, "context": "We have also shown that we can apply the visualisation technique of Simonyan et al. (2013) to identify and extract task-specific salient sentences from documents.", "startOffset": 68, "endOffset": 91}], "year": 2015, "abstractText": "We present a hierarchical convolutional document model with an architecture designed to support introspection of the document structure. Using this model, we show how to use visualisation techniques from the computer vision literature to identify and extract topic-relevant sentences. We also introduce a new scalable evaluation technique for automatic sentence extraction systems that avoids the need for time consuming human annotation of validation data.", "creator": "LaTeX with hyperref package"}}}