{"id": "1412.6885", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2014", "title": "Half-CNN: A General Framework for Whole-Image Regression", "abstract": "The Convolutional Neural Network (CNN) has achieved great success in image classification. The classification model can also be utilized at image or patch level for many other applications, such as object detection and segmentation. In this paper, we propose a whole-image CNN regression model, by removing the full connection layer and training the network with continuous feature maps. This is a generic regression framework that fits many applications. We demonstrate this method through two tasks: simultaneous face detection &amp; segmentation, and scene saliency prediction. The result is comparable with other models in the respective fields, using only a small scale network. Since the regression model is trained on corresponding image / feature map pairs, there are no requirements on uniform input size as opposed to the classification model. Our framework avoids classifier design, a process that may introduce too much manual intervention in model development. Yet, it is highly correlated to the classification network and offers some in-deep review of CNN structures.", "histories": [["v1", "Mon, 22 Dec 2014 06:43:58 GMT  (925kb)", "http://arxiv.org/abs/1412.6885v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jun yuan", "bingbing ni", "ashraf a kassim"], "accepted": false, "id": "1412.6885"}, "pdf": {"name": "1412.6885.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "In this article, we propose a holistic CNN regression model by removing the entire connectivity layer and building the network with continuous feature cards, which is a generic regression model that is suitable for many applications.We demonstrate this method using two tasks: simultaneous face recognition & segmentation and scene out prediction. The result is comparable to other models in each area, using only a small network.Since the regression model is trained on appropriate image / feature card pairs, unlike the classification model, there are no requirements for uniform input size. Our framework avoids classification design, a process that can introduce too many manual interventions into model development, but it is strongly correlated to the classification network and provides a thorough review of CNN structures."}, {"heading": "1. Introduction", "text": "In recent years, it has become clear that most of them are people who are not able to integrate themselves, and that they are not able to integrate themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \""}, {"heading": "2. Related Work", "text": "The classical models are extensively examined in [24]. CNN models have recently been developed in this area [25]. This paper uses folding to generate feature maps, and an SVM classifier to detect face windows. This approach is similar to the part-based model of object recognition [26]. Some other face recognition algorithms are typically implemented through segmentation [27, 28]; the idea is close to our frame. However, our network does not need to include specific knowledge of facial features, such as skin color, for recognition or segmentation task. Functions are fully learned in our network without manual manufacturing. Face recognition can also be combined with the simultaneous localization of face marks [29, 30, 31]. Part of our work is based on Y. Sun et al, where a CNN model is used to detect face marks."}, {"heading": "3. Implementation Details", "text": "This year, we have never seen anything like it."}, {"heading": "3.1. Size considerations in practice", "text": "The size of the Ground Truth Feature Map is typically related to the input image. However, since there are no fully connected layers in the regression frame, we can bypass the uniform requirement for the input size in typical classification CNNs. However, if the input sizes in the classification model are different, the images must be warped or cropped according to the filter size. Another aspect ratio is also a problem. However, our regression model can generally avoid these headers. Folding does not depend on the image size; however, the layer input must be correctly padded according to the filter size to ensure the correct downsampling factor after pooling. Theoretically, the input and output sizes of the folding blocks differ by a factor of 2 when pooling is used without up-sampling. If an up-sampling layer is present, the input and output sizes of the folding blocks are identical."}, {"heading": "4. Experiments", "text": "We use the above framework for two applications: for simultaneous face recognition and segmentation on the LFW face dataset [40], and for highlighting highlighting on the MIT dataset (version with 1003 images) [41]. Both networks are trained on the MatConvNet platform [42], a Matlab toolbox based on the famous CAFFE [13] CNN implementation."}, {"heading": "4.1. Face Detection & Segmentation", "text": "We use 5590 face images from the LFW dataset, with different viewing angles. All images are of identical size 250 x 250. We use 4151 images for training and the rest for testing. The detection window provided in [31] is used as the basic truth. We use a simple technique to generate the basic truth maps: a 2D Gaussian density function fits into the center of the detection window, with the diameter (6 and 6) being the window width and height. However, the size of the input images is supplemented by 256 \u00d7 256, as specified in Section 3, and a quadruple scan is applied to the generated feature maps. We use 3 folding blocks in this experiment. The first two blocks consist of 5 filters of size 11 x 11 and 7 \u00d7 7, each with maximum pooling and normalization. The following block consists of 5 filters of size 5 x 5, with maximum pooling features are the basic truth.For stability, 1"}, {"heading": "4.2. Saliency Prediction", "text": "The longest dimension of each image is 1024 pixels, and the other edge is between 405 and 1024 pixels. The aspect ratio is typically about 4: 3. The basic truth of the saliency prediction is already provided as feature maps, so this is an application that fits naturally with our regression framework. We use the images to 256 x 256 and use a down sampling factor of 4 for feature maps. We use the same network regulation parameters as in previous face recognition and segmentation experiments. We use 4 conversion blocks in this experiment: The first two blocks consist of 10 filters of size 7 x 7, with maximization and local normalization. The following two blocks consist of 10 filters of size 5 x 5, with max pooling and upsampling. Some experiment results are shown in Figure 5."}, {"heading": "5. Discussion", "text": "In fact, most people are able to decide for themselves what they want and what they don't want."}, {"heading": "6. Conclusion", "text": "We propose a CNN-based regression model trained on continuous characteristic maps. The regression network does not require a full connectivity layer and is insensitive to input sizes. We introduce an up-sampling technique for size compatibility and generate output characteristic maps through a linear combination on folding channels. We apply this framework to face recognition, segmentation and salinity forecasting, demonstrating its generalization capability in these tasks. Again, this general framework is closely related to the classification model and has the potential to be applied to a wide range of applications."}], "references": [{"title": "Video Google: a text retrieval approach to object matching in videos", "author": ["J. Sivic", "A. Zisserman"], "venue": "in Computer Vision,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Visual categorization with bags of keypoints", "author": ["C.B.G. Csurka", "C. Dance", "L. Fan"], "venue": "Workshop on Statistical Learning in Computer Vision, ECCV,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Improving the fisher kernel for large-scale image classification, in Computer Vision\u2013ECCV", "author": ["F. Perronnin", "J. S\u00e1nchez", "T. Mensink"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y LeCun"], "venue": "Neural computation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1989}, {"title": "The devil is in the details: an evaluation of recent feature encoding methods", "author": ["K Chatfield"], "venue": "British Machine Vision Conference,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Feature coding in image classification: a comprehensive study", "author": ["Y Huang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks, in Advances in Neural Information", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Processing Systems", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Distinctive Image Features from Scale- Invariant Keypoints", "author": ["D.G. Lowe"], "venue": "International Journal of Computer Vision,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J Deng"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "The pascal visual object classes (voc) challenge", "author": ["M Everingham"], "venue": "International journal of computer vision,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "CNN Features off-the-shelf: an Astounding Baseline for Recognition", "author": ["Razavian", "A.S"], "venue": "arXiv preprint arXiv:1403.6382,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets", "author": ["Chatfield", "K.K.a.S", "A. Vedaldi", "A. Zisserman"], "venue": "British Machine Vision Conference,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "author": ["Y Jia"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Pedestrian detection with convolutional neural networks", "author": ["M Szarvas"], "venue": "in Intelligent Vehicles Symposium,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R Girshick"], "venue": "arXiv preprint arXiv:1311.2524,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "New object-oriented segmentation algorithm based on the CNN paradigm", "author": ["G Grassi"], "venue": "Circuits and Systems II: Express Briefs, IEEE Transactions on,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "The elements of statistical learning: data mining, inference, and prediction", "author": ["T. Hastie", "R. Tibshirani", "J.H. Friedman"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Pattern recognition and machine learning. Vol. 1. 2006: springer New York", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Eigenfaces for recognition", "author": ["M. Turk", "A. Pentland"], "venue": "Journal of cognitive neuroscience,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Training support vector machines: an application to face detection", "author": ["E. Osuna", "R. Freund", "F. Girosi"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1997}, {"title": "Example-based learning for view-based human face detection", "author": ["Sung", "K.-K", "T. Poggio"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "Rapid object detection using a boosted cascade of simple features. in Computer Vision and Pattern Recognition", "author": ["P. Viola", "M. Jones"], "venue": "Proceedings of the 2001 IEEE Computer Society Conference on (Volume:1", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "A CNN-Based Face Detector with a Simple Feature Map and a Coarse-to-fine Classifier", "author": ["C Yin-Nong"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Object Detection with Discriminatively Trained Part-Based Models. IEEE Figure 7: Additional experiment results on simultaneous face detection & segmentation Figure 8: Additional experiment results on scene saliency prediction", "author": ["Felzenszwalb", "P.F"], "venue": "Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Face segmentation using skincolor map in videophone applications. Circuits and Systems for Video Technology", "author": ["D. Chai", "K.N. Ngan"], "venue": "IEEE Transactions on,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1999}, {"title": "Multi-source Multi-scale Counting in Extremely Dense Crowd Images", "author": ["H Idrees"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Active appearance models", "author": ["T.F. Cootes", "G.J. Edwards", "C.J. Taylor"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2001}, {"title": "Face detection, pose estimation, and landmark localization in the wild", "author": ["X. Zhu", "D. Ramanan"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Deep Convolutional Network Cascade for Facial Point Detection", "author": ["S. Yi", "W. Xiaogang", "T. Xiaoou"], "venue": "in Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Computational modelling of visual attention", "author": ["L. Itti", "C. Koch"], "venue": "Nature reviews neuroscience,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2001}, {"title": "Graph-based visual saliency. in Advances in neural information processing systems", "author": ["J. Harel", "C. Koch", "P. Perona"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}, {"title": "Learning visual saliency by combining feature maps in a nonlinear manner using AdaBoost", "author": ["Q. Zhao", "C. Koch"], "venue": "Journal of Vision,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Predicting human gaze beyond pixels", "author": ["J Xu"], "venue": "Journal of vision,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet", "author": ["M. K\u00fcmmerer", "L. Theis", "M. Bethge"], "venue": "arXiv preprint arXiv:1411.1045,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images. in Computer Vision and Pattern Recognition", "author": ["E. Vig", "M. Dorr", "D. Cox"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Saliency in images and video: a brief survey", "author": ["K. Duncan", "S. Sarkar"], "venue": "Computer Vision, IET,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Labeled faces in the wild: A database forstudying face recognition in unconstrained environments. in Workshop on Faces in'Real-Life'Images: Detection, Alignment, and Recognition", "author": ["Huang", "G.B"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2008}, {"title": "Learning to predict where humans look", "author": ["T Judd"], "venue": "Computer Vision,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "On the limited memory BFGS method for large scale optimization", "author": ["D.C. Liu", "J. Nocedal"], "venue": "Mathematical programming,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1989}, {"title": "Deep neural networks segment neuronal membranes in electron microscopy images. in Advances in neural information processing", "author": ["D Ciresan"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}, {"title": "Histograms of oriented gradients for human detection. in Computer Vision and Pattern Recognition", "author": ["N. Dalal", "B. Triggs"], "venue": "Proceedings of the 2005IEEE Computer Society Conference on (Volume:1", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2005}, {"title": "Regression Shrinkage and Selection via the Lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society.Series B (Methodological),", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1996}, {"title": "Regularization and Variable Selection via the Elastic Net", "author": ["H. Zou", "T. Hastie"], "venue": "Journal of the Royal Statistical Society.Series B (Statistical Methodology),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2005}, {"title": "A sparse sampling model for 3D face recognition", "author": ["Y. Jun", "A.A. Kassim"], "venue": "Image Processing (ICIP),", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2013}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Hinton", "G.E"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2012}, {"title": "Dropout Training as Adaptive Regularization", "author": ["S. Wager", "S. Wang", "P. Liang"], "venue": "ArXiv e-prints,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The image classification techniques have evolved vastly in recent years, from Bag-of-Visual-Words (BoVW) [1, 2], Fisher Vector (FV) Encoding [3], to the state-of-the-art Convolutional Neural Network (CNN) [4].", "startOffset": 105, "endOffset": 111}, {"referenceID": 1, "context": "The image classification techniques have evolved vastly in recent years, from Bag-of-Visual-Words (BoVW) [1, 2], Fisher Vector (FV) Encoding [3], to the state-of-the-art Convolutional Neural Network (CNN) [4].", "startOffset": 105, "endOffset": 111}, {"referenceID": 2, "context": "The image classification techniques have evolved vastly in recent years, from Bag-of-Visual-Words (BoVW) [1, 2], Fisher Vector (FV) Encoding [3], to the state-of-the-art Convolutional Neural Network (CNN) [4].", "startOffset": 141, "endOffset": 144}, {"referenceID": 3, "context": "The image classification techniques have evolved vastly in recent years, from Bag-of-Visual-Words (BoVW) [1, 2], Fisher Vector (FV) Encoding [3], to the state-of-the-art Convolutional Neural Network (CNN) [4].", "startOffset": 205, "endOffset": 208}, {"referenceID": 4, "context": "These techniques have been extensively studied in [5, 6].", "startOffset": 50, "endOffset": 56}, {"referenceID": 5, "context": "These techniques have been extensively studied in [5, 6].", "startOffset": 50, "endOffset": 56}, {"referenceID": 6, "context": "Each convolution block consists of a convolution layer with a non-linear activation, a pooling layer, and sometimes a local normalization layer [7].", "startOffset": 144, "endOffset": 147}, {"referenceID": 7, "context": "The key advance of CNN lies in its ability to learn adaptive features, as opposed to the hand-crafted features like SIFT [8] in BoVW and FV models.", "startOffset": 121, "endOffset": 124}, {"referenceID": 8, "context": "The CNN classification model achieves state-of-the-art performance on classification datasets such as ImageNet ILSVRC [9] and PASCAL VOC challenges [10].", "startOffset": 118, "endOffset": 121}, {"referenceID": 9, "context": "The CNN classification model achieves state-of-the-art performance on classification datasets such as ImageNet ILSVRC [9] and PASCAL VOC challenges [10].", "startOffset": 148, "endOffset": 152}, {"referenceID": 10, "context": "A comprehensive study can be found in [11].", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "The pre-trained ImageNet model [12, 13, 14] is also successful in generalizing to other image classification datasets.", "startOffset": 31, "endOffset": 43}, {"referenceID": 12, "context": "The pre-trained ImageNet model [12, 13, 14] is also successful in generalizing to other image classification datasets.", "startOffset": 31, "endOffset": 43}, {"referenceID": 13, "context": "The pre-trained ImageNet model [12, 13, 14] is also successful in generalizing to other image classification datasets.", "startOffset": 31, "endOffset": 43}, {"referenceID": 14, "context": "The CNN is also widely applied on non-classification tasks, such as object detection [15, 16] and segmentation [17, 16].", "startOffset": 85, "endOffset": 93}, {"referenceID": 15, "context": "The CNN is also widely applied on non-classification tasks, such as object detection [15, 16] and segmentation [17, 16].", "startOffset": 85, "endOffset": 93}, {"referenceID": 16, "context": "The CNN is also widely applied on non-classification tasks, such as object detection [15, 16] and segmentation [17, 16].", "startOffset": 111, "endOffset": 119}, {"referenceID": 15, "context": "The CNN is also widely applied on non-classification tasks, such as object detection [15, 16] and segmentation [17, 16].", "startOffset": 111, "endOffset": 119}, {"referenceID": 17, "context": "Regression and classification problems are highly correlated [18], and can be transferred to the other in many scenarios.", "startOffset": 61, "endOffset": 65}, {"referenceID": 18, "context": "For example, the softmax classifier is related to the softmax regression [19], and the SVM classifier is based on geometric regression.", "startOffset": 73, "endOffset": 77}, {"referenceID": 19, "context": "There are various models from the appearance to learning based models [20, 21, 22, 23].", "startOffset": 70, "endOffset": 86}, {"referenceID": 20, "context": "There are various models from the appearance to learning based models [20, 21, 22, 23].", "startOffset": 70, "endOffset": 86}, {"referenceID": 21, "context": "There are various models from the appearance to learning based models [20, 21, 22, 23].", "startOffset": 70, "endOffset": 86}, {"referenceID": 22, "context": "There are various models from the appearance to learning based models [20, 21, 22, 23].", "startOffset": 70, "endOffset": 86}, {"referenceID": 23, "context": "The CNN models are recently developed into this field [25].", "startOffset": 54, "endOffset": 58}, {"referenceID": 24, "context": "This approach is similar to the part-based model object detection [26].", "startOffset": 66, "endOffset": 70}, {"referenceID": 25, "context": "Some other face detection algorithms are implemented through segmentation [27, 28]; the idea is close to our framework.", "startOffset": 74, "endOffset": 82}, {"referenceID": 26, "context": "Some other face detection algorithms are implemented through segmentation [27, 28]; the idea is close to our framework.", "startOffset": 74, "endOffset": 82}, {"referenceID": 27, "context": "Face detection can also be combined with simultaneous face landmark localization [29, 30, 31].", "startOffset": 81, "endOffset": 93}, {"referenceID": 28, "context": "Face detection can also be combined with simultaneous face landmark localization [29, 30, 31].", "startOffset": 81, "endOffset": 93}, {"referenceID": 29, "context": "Face detection can also be combined with simultaneous face landmark localization [29, 30, 31].", "startOffset": 81, "endOffset": 93}, {"referenceID": 29, "context": "[31], where a CNN model is applied to detect face landmarks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "The work [31] can be considered as a bridge between the classification CNN model and our model.", "startOffset": 9, "endOffset": 13}, {"referenceID": 29, "context": "[31] also utilizes the spatial relationship of landmarks implicitly through a global-to-local refinement.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "The saliency prediction models evolved from Itti [32], GBVS [33], detection / segmentation models [34, 35], and to more recent CNN-based models [36, 37].", "startOffset": 49, "endOffset": 53}, {"referenceID": 31, "context": "The saliency prediction models evolved from Itti [32], GBVS [33], detection / segmentation models [34, 35], and to more recent CNN-based models [36, 37].", "startOffset": 60, "endOffset": 64}, {"referenceID": 32, "context": "The saliency prediction models evolved from Itti [32], GBVS [33], detection / segmentation models [34, 35], and to more recent CNN-based models [36, 37].", "startOffset": 98, "endOffset": 106}, {"referenceID": 33, "context": "The saliency prediction models evolved from Itti [32], GBVS [33], detection / segmentation models [34, 35], and to more recent CNN-based models [36, 37].", "startOffset": 98, "endOffset": 106}, {"referenceID": 34, "context": "The saliency prediction models evolved from Itti [32], GBVS [33], detection / segmentation models [34, 35], and to more recent CNN-based models [36, 37].", "startOffset": 144, "endOffset": 152}, {"referenceID": 35, "context": "The saliency prediction models evolved from Itti [32], GBVS [33], detection / segmentation models [34, 35], and to more recent CNN-based models [36, 37].", "startOffset": 144, "endOffset": 152}, {"referenceID": 36, "context": "An extensive study of classical models can be found in [38].", "startOffset": 55, "endOffset": 59}, {"referenceID": 32, "context": "The latter is also highly related to object detection and segmentation; some models explicitly use detection and segmentation techniques to give saliency predictions [34, 35].", "startOffset": 166, "endOffset": 174}, {"referenceID": 33, "context": "The latter is also highly related to object detection and segmentation; some models explicitly use detection and segmentation techniques to give saliency predictions [34, 35].", "startOffset": 166, "endOffset": 174}, {"referenceID": 35, "context": "The eDN [37] uses a large number of randomly initialized CNNs, picking those with good performance and aggregates their output feature maps to give predictions.", "startOffset": 8, "endOffset": 12}, {"referenceID": 34, "context": "The latter Deep Gaze I [36] uses ImageNet pre-trained network without the full connection layer, and learns a weight on linear combination of convolution channels.", "startOffset": 23, "endOffset": 27}, {"referenceID": 6, "context": "The convolution blocks follow structure of [7], and the output layer combines all the feature channels through a linear combination.", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "A normalization layer introduced in [7] can also be used after the pooling layer, with the local normalization function below:", "startOffset": 36, "endOffset": 39}, {"referenceID": 37, "context": "One is simultaneous face detection & segmentation on the LFW face dataset [40], the other is saliency prediction on the MIT dataset (1003 images version) [41].", "startOffset": 74, "endOffset": 78}, {"referenceID": 38, "context": "One is simultaneous face detection & segmentation on the LFW face dataset [40], the other is saliency prediction on the MIT dataset (1003 images version) [41].", "startOffset": 154, "endOffset": 158}, {"referenceID": 12, "context": "networks are both trained on the MatConvNet platform [42], a Matlab toolbox based on the famous CAFFE [13] CNN implementation.", "startOffset": 102, "endOffset": 106}, {"referenceID": 29, "context": "The detection window provided in [31] is used as the ground truth.", "startOffset": 33, "endOffset": 37}, {"referenceID": 29, "context": "We also tested our regression model on face landmark localization experiments, based on the work of [31].", "startOffset": 100, "endOffset": 104}, {"referenceID": 39, "context": "Since our regression network is small in scale, the L-BFGS [43] algorithm is used for fast convergence.", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "complicated segmentation tasks such as the PASCAL VOC challenge [10] and neuron membrane segmentation [44] in medical images, with the segmented object as the ground truth.", "startOffset": 64, "endOffset": 68}, {"referenceID": 40, "context": "complicated segmentation tasks such as the PASCAL VOC challenge [10] and neuron membrane segmentation [44] in medical images, with the segmented object as the ground truth.", "startOffset": 102, "endOffset": 106}, {"referenceID": 41, "context": "Also, our framework provides another view of classical features, such as SIFT and HoG [45].", "startOffset": 86, "endOffset": 90}, {"referenceID": 34, "context": "For example, the Deep Gaze I [36] uses ImageNet pre-trained models on", "startOffset": 29, "endOffset": 33}, {"referenceID": 42, "context": "such as the L1 norm, can offer some desired properties like sparsity [46, 47, 48, 49].", "startOffset": 69, "endOffset": 85}, {"referenceID": 43, "context": "such as the L1 norm, can offer some desired properties like sparsity [46, 47, 48, 49].", "startOffset": 69, "endOffset": 85}, {"referenceID": 44, "context": "such as the L1 norm, can offer some desired properties like sparsity [46, 47, 48, 49].", "startOffset": 69, "endOffset": 85}, {"referenceID": 17, "context": "effective degrees of freedom (DoF) of the network [18].", "startOffset": 50, "endOffset": 54}, {"referenceID": 45, "context": "The drop-out technique [50] is a famous way to prevent over-", "startOffset": 23, "endOffset": 27}, {"referenceID": 46, "context": "fitting in neural networks; it is proved to be an adaptive L2 regularization [51] on networks, which alleviates the testFigure 6: Comparison with classical saliency models, under the AUC and sAUC performance metric.", "startOffset": 77, "endOffset": 81}, {"referenceID": 10, "context": "Acquiring large data is sometimes not possible; data augmentation is often applied [11] to alleviate the requirement for training data.", "startOffset": 83, "endOffset": 87}], "year": 2014, "abstractText": "The Convolutional Neural Network (CNN) has achieved great success in image classification. The classification model can also be utilized at image or patch level for many other applications, such as object detection and segmentation. In this paper, we propose a whole-image CNN regression model, by removing the full connection layer and training the network with continuous feature maps. This is a generic regression framework that fits many applications. We demonstrate this method through two tasks: simultaneous face detection & segmentation, and scene saliency prediction. The result is comparable with other models in the respective fields, using only a small scale network. Since the regression model is trained on corresponding image / feature map pairs, there are no requirements on uniform input size as opposed to the classification model. Our framework avoids classifier design, a process that may introduce too much manual intervention in model development. Yet, it is highly correlated to the classification network and offers some in-deep review of CNN structures.", "creator": "Microsoft\u00ae Word 2010"}}}