{"id": "1412.7259", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Dec-2014", "title": "Unsupervised Feature Learning with C-SVDDNet", "abstract": "In this paper, we investigate the problem of learning feature representation from unlabeled data using a single-layer K-means network. A K-means network maps the input data into a feature representation by finding the nearest centroid for each input point, which has attracted researchers' great attention recently due to its simplicity, effectiveness, and scalability. However, one drawback of this feature mapping is that it tends to be unreliable when the training data contains noise. To address this issue, we propose a SVDD based feature learning algorithm that describes the density and distribution of each cluster from K-means with an SVDD ball for more robust feature representation. For this purpose, we present a new SVDD algorithm called C-SVDD that centers the SVDD ball towards the mode of local density of each cluster, and we show that the objective of C-SVDD can be solved very efficiently as a linear programming problem. Additionally, previous single-layer networks favor a large number of centroids but a crude pooling size, resulting in a representation that highlights the global aspects of the object. Here we explore an alternative network architecture with much smaller number of nodes but with much finer pooling size, hence emphasizing the local details of the object. The architecture is also extended with multiple receptive field scales and multiple pooling sizes. Extensive experiments on several popular object recognition benchmarks, such as MINST, NORB, CIFAR-10 and STL-10, shows that the proposed C-SVDDNet method yields comparable or better performance than that of the previous state of the art methods.", "histories": [["v1", "Tue, 23 Dec 2014 05:56:50 GMT  (1212kb,D)", "http://arxiv.org/abs/1412.7259v1", null], ["v2", "Mon, 12 Jan 2015 05:31:03 GMT  (1212kb,D)", "http://arxiv.org/abs/1412.7259v2", null], ["v3", "Fri, 29 May 2015 09:50:54 GMT  (2852kb,D)", "http://arxiv.org/abs/1412.7259v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["dong wang", "xiaoyang tan"], "accepted": false, "id": "1412.7259"}, "pdf": {"name": "1412.7259.pdf", "metadata": {"source": "CRF", "title": "C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning", "authors": ["Dong Wang", "Xiaoyang Tan"], "emails": ["(x.tan@nuaa.edu.cn)."], "sections": [{"heading": null, "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 TNN-SUBMISSION", "text": "Another reason for this development is the fact that it is able to establish itself in the region in which it is located, and that it is able to establish itself."}, {"heading": "II. PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Unsupervised Feature Learning", "text": "The goal of uncontrolled feature learning is to automatically detect useful hidden patterns / features in large data sets without relying on a reflex signal, and these learned patterns can be used to create representations that facilitate subsequent supervised learning (e.g. object classification).A typical pipeline for uncontrolled feature learning includes four steps. The first step is to train a set of local filters from the unlabeled training data.Then, we construct a set of feature maps for this by using the learned filters in the second step (e.g. through an image conversion).After applying a pooling operation on them in the third step, these feature maps are finally combined into a vector as a feature representation for the entered image. Local filters are a set of latent patterns found in the data and for this there are many basic algorithms (e.g. K-means, K-means, Gaussian Mixture Models (GMM), hierarchical codification [8], hierarchical codification]."}, {"heading": "B. K-means for Feature Mapping", "text": "It aims to minimize the sum of the distances between all data to their respective centers. Let X = {xi}, i = 1,..., n be the set of n d-dimensional points, C = {Ck}, k = 1,..., K be the set of K clusters, with the mean of clusters Ck. The K mean algorithm finds the clusters by solving the following objective function, J (C) = D-dimensional points, K = 1, K = 1, K = 2, K. \"After learning the clusters, they would be used to generate a feature mapping. So, if we have K clusters, the dimension of the resulting feature representation will be K. The easiest way for feature mapping is the so-called\" hard coding \"method, i.e., placing the winning cluster center on all others, as follows, fk.\""}, {"heading": "III. THE PROPOSED METHOD", "text": "After presenting the proposed architecture of the single-layer network, in this section we will explain the details of the proposed centered SVDD method for feature encoding and compare it with the K-mean \"triangle\" encoding method. We will then describe our SIFT-based post-pooling layer and discuss how to extend the method for extracting information on multiple levels."}, {"heading": "A. The architecture of the Single-layer Network", "text": "A typical single-layer network contains several components: an input image is first mapped into a series of feature cards using filter banks (or dictionary), which are then subjected to a pooling / subsampling operation to condense the information contained in the feature cards. Finally, the pooled feature cards are linked to a feature vector that serves as a representation for subsequent classification / cluster tasks. There are several design options in this process where the size of the filter bank and that of the pooling grids are the most important tradeoffs to make. Fig.2 There are two typical schemes of network architectures where Scheme A uses a large filter bank, but a rough pooling size, while Scheme B has a smaller filter bank, but a fine pooled pooling size. Generally, larger filter banks help each sample find its nearby representative points more accurately, but at the expense of a high-dimensional pooling architecture."}, {"heading": "4 TNN-SUBMISSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B. Using SVDD Ball to Cover Unequal Clusters", "text": "Suppose a dataset contains N data objects, {xi}, i = 1,..., n and a ball is described by its center a and radius R. The goal of SVDD (Support Vector Data Description, [11]) is to find a closed spherical boundary around the given data points. However, in order to avoid the influence of outliers, SVDD is actually facing a trade-off between two conflicting goals, i.e., minimizing the radius while covering as many data points as possible. This can be formulated as the following goal: SVDD, R, 2 + \u03bb N, i, i, i, i, s.t. xi \u2212 a, 2 \u2264 R2 +, i, 0, (3) where the gap variable, if the deviation of the i-th training data is outside the ball, and E.f."}, {"heading": "C. The C-SVDD Model", "text": "Although the SVDD ball provides a robust way to describe the cluster of data, an undesirable property of the ball = = = naive is that it may not correspond well with the distribution of data points in that cluster. As shown in Figure 5 (left), although the SVDD ball 5 covers the cluster C1 well, its center tends to the low density region. This should be avoided as it actually provides suboptimal estimates of the distribution of the data cluster. To solve this problem, inspired by the observation that the centers of the K means are always in the corresponding mode of their local density, it is proposed to move the SVDD ball to the centrification of the data so that it can better match the distribution of the data in a cluster. Our new objective function is then formulated asminR, with the two centers of the SVDD means in the corresponding mode of their local density."}, {"heading": "D. K-means Encoding vs. C-SVDD Encoding", "text": "To this end, it will be useful to have a brief discussion about the difference between two types of feature cards, i.e., K-Means based \"triangle\" encoding (E.q. 2) and our C-SVDD based one 1. For this purpose, a pilot experiment will be conducted. In particular, we will learn a very small dictionary containing only five atoms with five facial images by randomly scanning ZCA white patches from the faces and then using them for feature encoding. Fig.6 illustrates the facial images used for the dictionary (top) and the five learned atoms (leftmost). The feature cards of facial images encoded by the K-Mean coding method, and those encoded by the C-SVDD coding method, are shown respectively in Fig.6 (a) and Fig.6 (b), where each row corresponds to a dictionary."}, {"heading": "6 TNN-SUBMISSION", "text": "As Fig.7 (b) shows, the fourth atom actually represents a very small cluster. In fact, the radius of the C-SVDD sphere, which corresponds to the more informative atom, tends to be large, and a great advantage of our C-SVDD-based strategy is that it is able to exploit this property of the dictionary atoms for more effective feature encoding, as shown in the first three lines of Fig.6 (b), which partially explains the superior performance of the proposed C-SVDD method compared to its K-mean counterpart (cf. experimental results in Section IV)."}, {"heading": "E. Encoding Feature Maps with SIFT Representation", "text": "To encode the character cards, we use a variant of the SIFT representation. SIFT is a widely used descriptor in computer vision and helpful to suppress noise and improve the invariant properties of the final character representation. However, one problem with the SIFT-based representation is its high dimensionality. For example, if we extract 128-dimensional SIFT descriptors densely into 250 character cards with the size of 23 x 23 pixels, the dimension of the resulting representation vector will be as high as over 16M (250 x 23 x 23 x 128 = 16, 928,000). To solve this problem, we first divide each character card into m x m blocks and then extract an 8-bit gradient histogram from each block in the same way as SIFT. This results in a character representation with the dimensions m x m x 8 for each card, which significantly reduces the dimensionality while maintaining the following pattern classification for the task."}, {"heading": "F. Multi-scale Receptive Field Voting", "text": "Next, we expand our method of using multi-scale information for better feature learning through automatic learning. However, a multi-scale method is a way to describe the objects of interest in different context sizes, which would be useful because fixed-size patches are rarely good at characterizing an object - in fact, they can only capture local appearance information at that size. However, if the size is very small, information about edges could be captured, but the information about how they are converted into more meaningful patterns such as motifs, parts, poselets, and objects, while information about these entities at different levels is valuable, is not only discriminatory, but complementary to each other. Most popular manually designed feature descriptors, such as SIFT or HoG, address this problem to some extensive image gradients into edglets-like features, but it is still unclear how to assemble edglets in motifs using these methods."}, {"heading": "IV. EXPERIMENTS AND ANALYSIS", "text": "In order to evaluate the performance of the improved K-mean network, we conduct extensive experiments on four object data sets (MINST [2], NORB [24], CIFAR-10 [10], STL-10 [10]). Details of these data sets are listed below."}, {"heading": "8 TNN-SUBMISSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Experiment Settings", "text": "The whitening operation transforms the data linearly so that its covariance matrix becomes the sphere of unity, justifying the euclidean distance we use in the K-mean clustering procedure. Unless otherwise noted, the parameter settings listed in the table apply to all experiments. The influence of some important parameters, such as the number of filters, is examined in more detail in the following sections. By default, a value of 5 \u00d7 5 is set for the receptive field on a single scale across all data sets, as recommended in [10], while in a multi-scale version we use receptive fields on three scales, as in Table.I. For the C-SVDD ball, there is a regulation parameter that we must set, which allows us to control the amount of noise we are prepared to tolerate."}, {"heading": "B. Experimental results", "text": "This year, it has come to the point that it will only be once before there is such a process, in which there is such a process."}, {"heading": "10 TNN-SUBMISSION", "text": "In fact, most people who are able to live and work in the United States are not able to survive on their own, \"he said in an interview with The New York Times.\" I don't think we will be able to save the world, \"he said in an interview with The New York Times.\" I don't think we will be able to save the world, \"he said.\" I don't think we will be able to save the world. \"\" I don't think we will be able to save the world. \""}, {"heading": "C. The Influence of Parameters and Discussions", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "V. CONCLUSION", "text": "In this paper, we propose a simple single-layer neural network called C-SVDDNet for unattended feature learning. To this end, we present a new SVDD algorithm called C-SVDD that centers the SVDD ball in the way of the local density of each cluster. Furthermore, we show that the goal of CSVDD can be solved very efficiently as a linear programming problem. Another key component of C-SVDDNet is a postpooling layer that effectively encodes the pooling responses with a variant of SIFT descriptors that allows us to characterize the details of input without having to learn a large number of filters, enabling a \"lightweight\" design strategy for the network architecture."}, {"heading": "12 TNN-SUBMISSION", "text": "The network has multiple receptive field scales and multiple pooling parameters for better feature learning. Extensive experiments with several popular object recognition benchmarks show that the proposed C-SVDDNet performs comparably or better than previous state-of-the-art methods."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was supported by the National Science Foundation of China (61073112, 61035003, 61373060), Jiangsu Science Foundation (BK2012793), Qing Lan Project, Research Fund for the Doctoral Program (RFDP) (20123218110033)."}], "references": [{"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "arXiv preprint arXiv:1206.5538, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278\u20132324, 1998.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "What is the best multi-stage architecture for object recognition?", "author": ["K. Jarrett", "K. Kavukcuoglu", "M. Ranzato", "Y. LeCun"], "venue": "in Computer Vision,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Invariant scattering convolution networks", "author": ["J. Bruna", "S. Mallat"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 35, no. 8, pp. 1872\u20131886, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1872}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Q.V. Le", "M. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G.S. Corrado", "J. Dean", "A.Y. Ng"], "venue": "arXiv preprint arXiv:1112.6209, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning convolutional feature hierarchies for visual recognition.", "author": ["K. Kavukcuoglu", "P. Sermanet", "Y.-L. Boureau", "K. Gregor", "M. Mathieu", "Y. LeCun"], "venue": "in NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Hyperfeatures\u2013multilevel local coding for visual recognition", "author": ["A. Agarwal", "B. Triggs"], "venue": "Proc. Ninth European Conf. Computer Vision, 2006. Springer, 2006, pp. 30\u201343.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Geometry of the restricted boltzmann machine", "author": ["M.A. Cueto", "J. Morton", "B. Sturmfels"], "venue": "Algebraic Methods in Statistics and Probability,(eds. M. Viana and H. Wynn), AMS, Contemporary Mathematics, vol. 516, pp. 135\u2013153, 2010.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "H. Lee", "A.Y. Ng"], "venue": "Ann Arbor, vol. 1001, p. 48109, 2010.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Support vector data description", "author": ["D.M. Tax", "R.P. Duin"], "venue": "Machine learning, vol. 54, no. 1, pp. 45\u201366, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Fault detection based on svdd and cluster algorithm", "author": ["J. Xu", "J. Yao", "L. Ni"], "venue": "Electronics, Communications and Control (ICECC), 2011 International Conference on. IEEE, 2011, pp. 2050\u20132052.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009, pp. 609\u2013616.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep boltzmann machines", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "International Conference on Artificial Intelligence and Statistics, 2009, pp. 448\u2013455.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["D.G. Lowe"], "venue": "International journal of computer vision, vol. 60, no. 2, pp. 91\u2013110, 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Centering svdd for unsupervised feature representation in object classification", "author": ["D. Wang", "X. Tan"], "venue": "Neural Information Processing. Springer, 2013, pp. 376\u2013383.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Large-scale object recognition with cudaaccelerated hierarchical neural networks", "author": ["R. Uetz", "S. Behnke"], "venue": "Intelligent Computing and Intelligent Systems, 2009. ICIS 2009. IEEE International Conference on, vol. 1. IEEE, 2009, pp. 536\u2013541.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "The hierarchical beta process for convolutional factor analysis and deep learning", "author": ["B. Chen", "G. Polatkan", "G. Sapiro", "L. Carin", "D.B. Dunson"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, pp. 361\u2013368.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Unsupervised feature learning for rgb-d based object recognition", "author": ["L. Bo", "X. Ren", "D. Fox"], "venue": "Experimental Robotics. Springer, 2013, pp. 387\u2013402.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning image representations from the pixel level via hierarchical sparse coding", "author": ["K. Yu", "Y. Lin", "J. Lafferty"], "venue": "Proc. IEEE Computer Vision and Pattern Recognition (CVPR), 2011, pp. 1713\u20131720.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Image classification with the fisher vector: Theory and practice", "author": ["J. S\u00e1nchez", "F. Perronnin", "T. Mensink", "J. Verbeek"], "venue": "International journal of computer vision, vol. 105, no. 3, pp. 222\u2013245, 2013.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Pcanet: A simple deep learning baseline for image classification?", "author": ["T.-H. Chan", "K. Jia", "S. Gao", "J. Lu", "Z. Zeng", "Y. Ma"], "venue": "arXiv preprint arXiv:1404.3606,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "The devil is in the details: an evaluation of recent feature encoding methods", "author": ["K. Chatfield", "V. Lempitsky", "A. Vedaldi", "A. Zisserman"], "venue": "2011.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["Y. LeCun", "F.J. Huang", "L. Bottou"], "venue": "Proc. IEEE Computer Vision and Pattern Recognition (CVPR), vol. 2, 2004, pp. II\u201397.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2004}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "Proc. IEEE Computer Vision and Pattern Recognition (CVPR), 2012, pp. 3642\u20133649.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "CoRR, vol. abs/1312.4400, 2013. [Online]. Available: http://arxiv.org/abs/1312.4400", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1302.4389, 2013.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Regularization of neural networks using dropconnect", "author": ["L. Wan", "M. Zeiler", "S. Zhang", "Y.L. Cun", "R. Fergus"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML-13), 2013, pp. 1058\u20131066.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Deeply-supervised nets", "author": ["C.-Y. Lee", "S. Xie", "P. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "arXiv preprint arXiv:1409.5185, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "3d object recognition with deep belief nets.", "author": ["V. Nair", "G.E. Hinton"], "venue": "in NIPS,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Discriminative learning of sum-product networks.", "author": ["R. Gens", "P. Domingos"], "venue": "in NIPS,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Learning smooth pooling regions for visual recognition", "author": ["M. Malinowski", "M. Fritz"], "venue": "the British Machine Vision Conference, 2013.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "arXiv preprint arXiv:1301.3557, 2013.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving deep neural networks with probabilistic maxout units", "author": ["J.T. Springenberg", "M. Riedmiller"], "venue": "arXiv preprint arXiv:1312.6116, 2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Convolutional kernel networks", "author": ["J. Mairal", "P. Koniusz", "Z. Harchaoui", "C. Schmid"], "venue": "arXiv preprint arXiv:1406.3332, 2014.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Selecting receptive fields in deep networks.", "author": ["A. Coates", "A.Y. Ng"], "venue": "in NIPS,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Learning invariant representations with local transformations", "author": ["K. Sohn", "H. Lee"], "venue": "arXiv preprint arXiv:1206.6418, 2012.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep learning of invariant features via simulated fixations in video.", "author": ["W.Y. Zou", "A.Y. Ng", "S. Zhu", "K. Yu"], "venue": "in NIPS,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Committees of deep feedforward networks trained with few data", "author": ["B. Miclut"], "venue": "Pattern Recognition. Springer, 2014, pp. 736\u2013742.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "A representative method for this is the deep learning (DL) approach [1] with its goal to learn multiple layers of abstract representations from data.", "startOffset": 68, "endOffset": 71}, {"referenceID": 1, "context": "Among others, one typical DL method is the so called convolutional neural network (ConvNet), which consists of multiple trainable stages stacked on top of each other, followed by a supervised classifier [2] [3].", "startOffset": 203, "endOffset": 206}, {"referenceID": 2, "context": "Among others, one typical DL method is the so called convolutional neural network (ConvNet), which consists of multiple trainable stages stacked on top of each other, followed by a supervised classifier [2] [3].", "startOffset": 207, "endOffset": 210}, {"referenceID": 3, "context": "Many variations of ConvNet network have been proposed as well for different vision tasks [4] [5] [6] with great success.", "startOffset": 89, "endOffset": 92}, {"referenceID": 4, "context": "Many variations of ConvNet network have been proposed as well for different vision tasks [4] [5] [6] with great success.", "startOffset": 93, "endOffset": 96}, {"referenceID": 5, "context": "Many variations of ConvNet network have been proposed as well for different vision tasks [4] [5] [6] with great success.", "startOffset": 97, "endOffset": 100}, {"referenceID": 4, "context": "In these methods layers of representation are usually obtained by greedily training one layer at a time on the lower level [5] [7] [3], using an unsupervised learning algorithm.", "startOffset": 123, "endOffset": 126}, {"referenceID": 6, "context": "In these methods layers of representation are usually obtained by greedily training one layer at a time on the lower level [5] [7] [3], using an unsupervised learning algorithm.", "startOffset": 127, "endOffset": 130}, {"referenceID": 2, "context": "In these methods layers of representation are usually obtained by greedily training one layer at a time on the lower level [5] [7] [3], using an unsupervised learning algorithm.", "startOffset": 131, "endOffset": 134}, {"referenceID": 7, "context": "Neural network based singlelayer methods, such as autoencoder [8] and RBM (Restricted Boltzmann Machine, [9]), are widely used for this but they", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "Neural network based singlelayer methods, such as autoencoder [8] and RBM (Restricted Boltzmann Machine, [9]), are widely used for this but they", "startOffset": 105, "endOffset": 108}, {"referenceID": 9, "context": "[10] shows that the K-means based feature learning network is capable to achieve superior performance compared to sparse autoencoder, sparse RBM and GMM (Guassian Mixture Model).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "In this paper, we proposed a SVDD (Support Vector Data Description, [11], [12]) based method to address these issues.", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "In this paper, we proposed a SVDD (Support Vector Data Description, [11], [12]) based method to address these issues.", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "\u2019s series of controlled experiments on single layer unsupervised feature learning networks [10] is that compared to the choice of particular learning algorithm, the parameters that define the feature extraction pipeline, especially the number of features, have much more deep impact on the performance.", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": ", Convolutional Deep Belief Nets (CDBN) [13], Deep Boltzmann Machine [14] and Sparse Auto-encoder [10]).", "startOffset": 40, "endOffset": 44}, {"referenceID": 13, "context": ", Convolutional Deep Belief Nets (CDBN) [13], Deep Boltzmann Machine [14] and Sparse Auto-encoder [10]).", "startOffset": 69, "endOffset": 73}, {"referenceID": 9, "context": ", Convolutional Deep Belief Nets (CDBN) [13], Deep Boltzmann Machine [14] and Sparse Auto-encoder [10]).", "startOffset": 98, "endOffset": 102}, {"referenceID": 9, "context": "One major reason for this is that the existence of large number of basis vectors increases the chances that an input can be encoded properly by the network [10].", "startOffset": 156, "endOffset": 160}, {"referenceID": 14, "context": "Here we use a variant of SIFT-based encoder [15], which essentially projects the responses of a pooling operation into a low dimensional space while suppressing the noise and improving the invariant properties of the final feature representation.", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "A preliminary version of this work appeared in [16].", "startOffset": 47, "endOffset": 51}, {"referenceID": 7, "context": ", K-means, Gaussian Mixture Models (GMM), autoencoder [8], RBM [9], sparse coding) and their more sophisticated variants, such as Sparse Auto-encoder [10], Sparse RBM [10], Locally-connected Neural Pyramid (LCNP) [17], Conv.", "startOffset": 54, "endOffset": 57}, {"referenceID": 8, "context": ", K-means, Gaussian Mixture Models (GMM), autoencoder [8], RBM [9], sparse coding) and their more sophisticated variants, such as Sparse Auto-encoder [10], Sparse RBM [10], Locally-connected Neural Pyramid (LCNP) [17], Conv.", "startOffset": 63, "endOffset": 66}, {"referenceID": 9, "context": ", K-means, Gaussian Mixture Models (GMM), autoencoder [8], RBM [9], sparse coding) and their more sophisticated variants, such as Sparse Auto-encoder [10], Sparse RBM [10], Locally-connected Neural Pyramid (LCNP) [17], Conv.", "startOffset": 150, "endOffset": 154}, {"referenceID": 9, "context": ", K-means, Gaussian Mixture Models (GMM), autoencoder [8], RBM [9], sparse coding) and their more sophisticated variants, such as Sparse Auto-encoder [10], Sparse RBM [10], Locally-connected Neural Pyramid (LCNP) [17], Conv.", "startOffset": 167, "endOffset": 171}, {"referenceID": 16, "context": ", K-means, Gaussian Mixture Models (GMM), autoencoder [8], RBM [9], sparse coding) and their more sophisticated variants, such as Sparse Auto-encoder [10], Sparse RBM [10], Locally-connected Neural Pyramid (LCNP) [17], Conv.", "startOffset": 213, "endOffset": 217}, {"referenceID": 17, "context": "Sparse Factor Analysis (CSFA) [18], Hierarchical Matching Pursuit (HMP) [19], Hierarchical Sparse Coding (HSC) [20], Fisher vector [21], and so on.", "startOffset": 30, "endOffset": 34}, {"referenceID": 18, "context": "Sparse Factor Analysis (CSFA) [18], Hierarchical Matching Pursuit (HMP) [19], Hierarchical Sparse Coding (HSC) [20], Fisher vector [21], and so on.", "startOffset": 72, "endOffset": 76}, {"referenceID": 19, "context": "Sparse Factor Analysis (CSFA) [18], Hierarchical Matching Pursuit (HMP) [19], Hierarchical Sparse Coding (HSC) [20], Fisher vector [21], and so on.", "startOffset": 111, "endOffset": 115}, {"referenceID": 20, "context": "Sparse Factor Analysis (CSFA) [18], Hierarchical Matching Pursuit (HMP) [19], Hierarchical Sparse Coding (HSC) [20], Fisher vector [21], and so on.", "startOffset": 131, "endOffset": 135}, {"referenceID": 9, "context": "[10] shows through a series of controlled experiments that compared to how to obtain these filters, how many of them (the number of features) and how to use them (feature encoding) has more fundamental impact on the final performance of a network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "A better summary is the following \u201ctriangle\u201d encoding [10]:", "startOffset": 54, "endOffset": 58}, {"referenceID": 9, "context": "[10] shows that this strategy actually leads to comparable performance to, if not better than, those based on network methods.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "show that this kind of network is able to yield state of the art results on several challenging datasets [10].", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "On the other hand, other works use smaller filter banks but highlight the importance of detailed local information in constructing the representation, usually based on some complicated feature encoding strategy, as done in PCANet [22] or Fisher Vector [23].", "startOffset": 230, "endOffset": 234}, {"referenceID": 22, "context": "On the other hand, other works use smaller filter banks but highlight the importance of detailed local information in constructing the representation, usually based on some complicated feature encoding strategy, as done in PCANet [22] or Fisher Vector [23].", "startOffset": 252, "endOffset": 256}, {"referenceID": 9, "context": "Compared to [10], we use an improved feature encoding method named CSVDD (detailed in the next section) and adopt the architecture of relatively small dictionary.", "startOffset": 12, "endOffset": 16}, {"referenceID": 21, "context": "Different to [22] or [23], we learn filter banks for feature encoding but add a SIFT-based post-pooling processing procedure onto the network, which essentially projects the responses of a pooling operation into a more compact and robust representation space.", "startOffset": 13, "endOffset": 17}, {"referenceID": 22, "context": "Different to [22] or [23], we learn filter banks for feature encoding but add a SIFT-based post-pooling processing procedure onto the network, which essentially projects the responses of a pooling operation into a more compact and robust representation space.", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "The goal of SVDD (Support Vector Data Description, [11]) is to find a closed spherical boundary around the given data points.", "startOffset": 51, "endOffset": 55}, {"referenceID": 1, "context": "To evaluate the performance of the improved K-means network, we conduct extensive experiments on four object datasets (MINST [2], NORB [24], CIFAR-10 [10], STL-10 [10]).", "startOffset": 125, "endOffset": 128}, {"referenceID": 23, "context": "To evaluate the performance of the improved K-means network, we conduct extensive experiments on four object datasets (MINST [2], NORB [24], CIFAR-10 [10], STL-10 [10]).", "startOffset": 135, "endOffset": 139}, {"referenceID": 9, "context": "To evaluate the performance of the improved K-means network, we conduct extensive experiments on four object datasets (MINST [2], NORB [24], CIFAR-10 [10], STL-10 [10]).", "startOffset": 150, "endOffset": 154}, {"referenceID": 9, "context": "To evaluate the performance of the improved K-means network, we conduct extensive experiments on four object datasets (MINST [2], NORB [24], CIFAR-10 [10], STL-10 [10]).", "startOffset": 163, "endOffset": 167}, {"referenceID": 9, "context": "For single scale network the receptive field is set to be 5\u00d7 5 by default across all the datasets, as recommended in [10], while in multi-scale version, we use receptive fields in three scales, as shown in Table.", "startOffset": 117, "endOffset": 121}, {"referenceID": 9, "context": "Throughout the experiments, we use Coates\u2019 K-means \u201ctriangle\u201d encoding method [10] (c.", "startOffset": 78, "endOffset": 82}, {"referenceID": 9, "context": "In addition, we re-evaluate the baseline method [10] within the proposed network by replacing its component of C-SVDD with the Kmeans-based encoding, denoted as \u2018K-meansNet\u2019.", "startOffset": 48, "endOffset": 52}, {"referenceID": 13, "context": "Deep Boltzmann Machines [14] (2009) 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 12, "context": "95 Convolutional Deep Belief Networks [13] (2009) 0.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "82 Multi-column deep neural networks [25] (2012) 0.", "startOffset": 37, "endOffset": 41}, {"referenceID": 25, "context": "23 Network in Network [26] (2013) 0.", "startOffset": 22, "endOffset": 26}, {"referenceID": 26, "context": "47 Maxout Networks [27] (2013) 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 27, "context": "45 Regularization of neural networks [28] (2013) 0.", "startOffset": 37, "endOffset": 41}, {"referenceID": 21, "context": "21 PCANet [22] (2014) 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 28, "context": "62 Deeply-Supervised Nets [29] (2014) 0.", "startOffset": 26, "endOffset": 30}, {"referenceID": 23, "context": "ConvNet [24] (2004) 93.", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "4 Deep Boltzmann Machine [14] (2009) 92.", "startOffset": 25, "endOffset": 29}, {"referenceID": 29, "context": "8 Deep Belief Network [30] (2009) 95.", "startOffset": 22, "endOffset": 26}, {"referenceID": 2, "context": "0 optimized ConvNet [3] (2009) 94.", "startOffset": 20, "endOffset": 23}, {"referenceID": 16, "context": "4 Locally-connected Neural Pyramid (LCNP) [17] (2009) 97.", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "13 Sparse Auto-encoder [10] (2011) 96.", "startOffset": 23, "endOffset": 27}, {"referenceID": 9, "context": "9 Sparse RBM [10] (2011) 96.", "startOffset": 13, "endOffset": 17}, {"referenceID": 27, "context": "2 Regularization of neural networks [28] (2013) 96.", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "K-means (4000 features) [10] (2011) 97.", "startOffset": 24, "endOffset": 28}, {"referenceID": 30, "context": "Sum-Product Networks [31] (2012) 83.", "startOffset": 21, "endOffset": 25}, {"referenceID": 31, "context": "96 Learning smooth pooling [32] (2013) 80.", "startOffset": 27, "endOffset": 31}, {"referenceID": 26, "context": "02 Maxout Networks [27] (2013) 88.", "startOffset": 19, "endOffset": 23}, {"referenceID": 32, "context": "32 Stochastic Pooling [33] (2013) 84.", "startOffset": 22, "endOffset": 26}, {"referenceID": 33, "context": "87 Probabilistic Maxout Units [34] (2013) 88.", "startOffset": 30, "endOffset": 34}, {"referenceID": 21, "context": "65 PCANet [22] (2014) 78.", "startOffset": 10, "endOffset": 14}, {"referenceID": 34, "context": "67 Convolutional Kernel Networks [35] (2014) 82.", "startOffset": 33, "endOffset": 37}, {"referenceID": 9, "context": "K-means (4000 features) [10] (2011) 79.", "startOffset": 24, "endOffset": 28}, {"referenceID": 35, "context": "Selective Receptive Fields (3 Layers) [36] (2011) 60.", "startOffset": 38, "endOffset": 42}, {"referenceID": 36, "context": "Invariant RBM (TIRBM) [37] (2012) 58.", "startOffset": 22, "endOffset": 26}, {"referenceID": 37, "context": "70 Simulated visual fixation ConvNet [38] (2012) 61.", "startOffset": 37, "endOffset": 41}, {"referenceID": 30, "context": "Net (DSPN) [31] (2012) 62.", "startOffset": 11, "endOffset": 15}, {"referenceID": 18, "context": "0 Hierarchical Matching Pursuit (HMP) [19] (2013) 64.", "startOffset": 38, "endOffset": 42}, {"referenceID": 38, "context": "0 Deep Feedforward Networks [39] (2014) 68.", "startOffset": 28, "endOffset": 32}, {"referenceID": 35, "context": "K-means (4800 features) [36] (2011) 53.", "startOffset": 24, "endOffset": 28}, {"referenceID": 13, "context": "For example, only 95 among 10,000 test digits are misclassified by the Deep Boltzmann Machines [14], while Convolutional Deep Belief Networks [13] and Maxout Networks [27] respectively reduce this number to 82 and 45.", "startOffset": 95, "endOffset": 99}, {"referenceID": 12, "context": "For example, only 95 among 10,000 test digits are misclassified by the Deep Boltzmann Machines [14], while Convolutional Deep Belief Networks [13] and Maxout Networks [27] respectively reduce this number to 82 and 45.", "startOffset": 142, "endOffset": 146}, {"referenceID": 26, "context": "For example, only 95 among 10,000 test digits are misclassified by the Deep Boltzmann Machines [14], while Convolutional Deep Belief Networks [13] and Maxout Networks [27] respectively reduce this number to 82 and 45.", "startOffset": 167, "endOffset": 171}, {"referenceID": 9, "context": "Compared to the original K-means network [10], the proposed method reduces the error rate by 65%, with much smaller number of filters.", "startOffset": 41, "endOffset": 45}, {"referenceID": 23, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 120, "endOffset": 124}, {"referenceID": 2, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 125, "endOffset": 128}, {"referenceID": 13, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 134, "endOffset": 138}, {"referenceID": 29, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 144, "endOffset": 148}, {"referenceID": 16, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 190, "endOffset": 194}, {"referenceID": 9, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 226, "endOffset": 230}, {"referenceID": 9, "context": "9(b)) and many feature learning algorithms use this database as a benchmark to evaluate their scalability, such ConvNet [24] [3], DBM [14], DBN [30], Locally-connected Neural Pyramid (LCNP) [17] and many sparse coding methods [10] [10].", "startOffset": 231, "endOffset": 235}, {"referenceID": 9, "context": "It is previously shown that a fine-tuned K-means single-layer network [10] yields better performance than those aforementioned methods.", "startOffset": 70, "endOffset": 74}, {"referenceID": 9, "context": "However, we achieve the state of the art performance with only 400 atoms, about 10 times smaller than that used in [10].", "startOffset": 115, "endOffset": 119}, {"referenceID": 21, "context": "64%, which is comparable or superior to the performance of other multi-layer architecture systems, such as PCANet [22], Convolutional Kernel Networks [35] and [10].", "startOffset": 114, "endOffset": 118}, {"referenceID": 34, "context": "64%, which is comparable or superior to the performance of other multi-layer architecture systems, such as PCANet [22], Convolutional Kernel Networks [35] and [10].", "startOffset": 150, "endOffset": 154}, {"referenceID": 9, "context": "64%, which is comparable or superior to the performance of other multi-layer architecture systems, such as PCANet [22], Convolutional Kernel Networks [35] and [10].", "startOffset": 159, "endOffset": 163}, {"referenceID": 31, "context": "One possible explanation is that our compact SIFT encoding leads to more robust representation than others, such as Learning smooth pooling [32] and Sum-Product Networks [31].", "startOffset": 140, "endOffset": 144}, {"referenceID": 30, "context": "One possible explanation is that our compact SIFT encoding leads to more robust representation than others, such as Learning smooth pooling [32] and Sum-Product Networks [31].", "startOffset": 170, "endOffset": 174}, {"referenceID": 9, "context": "In consistence with [10], we report the average accuracy across 10 folds.", "startOffset": 20, "endOffset": 24}, {"referenceID": 36, "context": "Invariant RBM (TIRBM) [37], 60.", "startOffset": 22, "endOffset": 26}, {"referenceID": 35, "context": "10% of Selective Receptive Fields (SRF) [36], and 62.", "startOffset": 40, "endOffset": 44}, {"referenceID": 30, "context": "30% of Discriminative Sum-Product Networks (DSPN) [31].", "startOffset": 50, "endOffset": 54}, {"referenceID": 38, "context": "6% improvement in accuracy, exceeding the current best performer [39] on this challenging dataset.", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "For example, it is difficult for a GMM to learn a dictionary with over 800 atoms [10].", "startOffset": 81, "endOffset": 85}, {"referenceID": 35, "context": "11 show that using our C-SVDD encoding and the SIFT feature representation, the dictionary size reduces by 10 times (from 4,800 [36] to 500) while the performance improves by nearly 12% (from 53.", "startOffset": 128, "endOffset": 132}], "year": 2017, "abstractText": "In this paper, we investigate the problem of learning feature representation from unlabeled data using a single-layer K-means network. A K-means network maps the input data into a feature representation by finding the nearest centroid for each input point, which has attracted researchers\u2019 great attention recently due to its simplicity, effectiveness, and scalability. However, one drawback of this feature mapping is that it tends to be unreliable when the training data contains noise. To address this issue, we propose a SVDD based feature learning algorithm that describes the density and distribution of each cluster from Kmeans with an SVDD ball for more robust feature representation. For this purpose, we present a new SVDD algorithm called CSVDD that centers the SVDD ball towards the mode of local density of each cluster, and we show that the objective of CSVDD can be solved very efficiently as a linear programming problem. Additionally, previous single-layer networks favor a large number of centroids but a crude pooling size, resulting in a representation that highlights the global aspects of the object. Here we explore an alternative network architecture with much smaller number of nodes but with much finer pooling size, hence emphasizing the local details of the object. The architecture is also extended with multiple receptive field scales and multiple pooling sizes. Extensive experiments on several popular object recognition benchmarks, such as MINST, NORB, CIFAR-10 and STL-10, shows that the proposed C-SVDDNet method yields comparable or better performance than that of the previous state of the art methods.", "creator": "LaTeX with hyperref package"}}}