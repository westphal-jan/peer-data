{"id": "1412.7522", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Dec-2014", "title": "Learning Deep Temporal Representations for Brain Decoding", "abstract": "Functional magnetic resonance imaging produces high dimensional data, with a less then ideal number of labelled samples for brain decoding tasks. In this study, we propose a deep temporal convolutional neural network architecture for brain decoding task in order to reduce dimensionality of feature space along with improved classification performance. Temporal representations (filters) for each layer of the convolutional model are learned by leveraging unlabelled fMRI data in an unsupervised fashion by employing regularized autoencoders. Learned temporal representations in multiple levels capture the regularities in the temporal domain and are observed to be a rich bank of activation patterns which also exhibit similarities to the actual hemodynamic responses. Further spatial pooling layers in the convolutional architecture reduce the dimensionality without losing excessive information. By employing the proposed temporal convolutional architecture, raw input fMRI data is mapped to a non-linear, highly-expressive and low-dimensional feature space where the final classification is conducted. In addition, we propose a simple heuristic approach for hyper-parameter tuning when no validation data is available. Proposed method is tested on a ten class recognition memory experiment with nine subjects. The results support the efficiency and potential of the proposed model, compared to the baseline multi-voxel pattern analysis techniques.", "histories": [["v1", "Tue, 23 Dec 2014 20:53:09 GMT  (223kb,D)", "https://arxiv.org/abs/1412.7522v1", null], ["v2", "Wed, 24 Dec 2014 10:31:13 GMT  (244kb,D)", "http://arxiv.org/abs/1412.7522v2", null], ["v3", "Thu, 25 Dec 2014 07:43:42 GMT  (311kb,D)", "http://arxiv.org/abs/1412.7522v3", null], ["v4", "Mon, 12 Jan 2015 05:03:58 GMT  (311kb,D)", "http://arxiv.org/abs/1412.7522v4", "This paper has been withdrawn for a revision"]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["orhan firat", "emre aksan", "ilke oztekin", "fatos t yarman vural"], "accepted": false, "id": "1412.7522"}, "pdf": {"name": "1412.7522.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["BRAIN DECODING", "Orhan Firat", "Emre Aksan", "Fatos T. Yarman Vural"], "emails": ["orhan.firat@ceng.metu.edu.tr", "eaksan@ceng.metu.edu.tr", "vural@ceng.metu.edu.tr", "ioztekin@ku.edu.tr"], "sections": [{"heading": "1 INTRODUCTION", "text": "It is not as if it were a pure phantasm, but a pure phantasm, in which it is only a matter of understanding oneself. (...) It is not as if it were a pure phantasm. (...) It is as if it were a pure phantasm. (...) It is as if it were a pure phantasm. (...) It is as if it were a pure phantasm. (...) It is as if it were a phantasm. (...) It is as if it were a phantasm. (...) It is as if it were a phantasm. (...) It is as if it were a phantasm. (...) It is as if it were a phantasm. (...) It is as if it were a phantasm."}, {"heading": "2 UNSUPERVISED LEARNING OF TEMPORAL REPRESENTATIONS AND CONVOLUTIONAL ARCHITECTURE", "text": "In this section, we describe the proposed unsupervised learning architecture for deep temporal representations. The fMRI data consists of three-dimensional brain volumes over time (see Figure 1). Each pixel in these 2D images actually represents the intensity of a small volume of brain tissue (voxel) at a point in time when the intensity of a voxel at the site of the experiment can be directly referred to as Vji, where j = 1,., m and m are the total number of voxels in the experiment. A typical fMRI experiment consists of multiple runs in which the subjects are presented task-specific stimuli at predetermined times. Each of these stimuli corresponds to a class (class) and the data collected at that location is assigned."}, {"heading": "3 EXPERIMENTS ON FMRI DATA", "text": "The fMRI recording was performed during a recognition memory task on nine participants. Each participant was given a list of words belonging to a specific semantic category in the memory encoding phase within ten categories, namely fruits, vegetables, furniture, animals, herbs, clothing, body parts, chemical elements, colors and tools. After a delay phase in which the participant solves mathematical problems, a test probe is presented and the participant performs a yes / no answer indicating whether the word belongs to the current study list (e.g. see Oztekin & Badre (2011)). For the decoding task, we focused on the lateral region of the anterior temporal cortex with 1024 voxels (m). fMRI data consists of 2400 time points (s) in eight runs, using 240 class labels for the memory encoding phase and 240 class labels for the memory encoding phase."}, {"heading": "3.1 MODEL DETAILS", "text": "The proposed model is tested using fMRI experiments with various architectural options. Our main consideration was to reduce the final display dimensions with different pooling areas. To this end, we adjusted the pooling areas \u03b41 and \u03b42 to withdraw the number of dimensions comparable to the standard MVPA method (corresponding to the number of voxels m) and even lower. It is known that the hemorymic response function (HRF) reaches about 4-6 seconds after a stimulus and returns to the baseline after 10-12 seconds. (2004) Considering the experimental protocol TR as 2sec, a complete HRF with a window size of 6 samples could be captured."}, {"heading": "3.2 SELECTION OF HYPER-PARAMETERS WITHOUT A VALIDATION SET", "text": "An important avenue of CNNs and many other deep learning methods is the large number of hyperparameters \u03b2 = \u03b2 values that must be fully learned with each hyperparameter relationship Bengio et al. (2013). Without a correct cross-validation, as in our case, these hyperparameters are matched with trial-and-error mode, which we avoided in this study. As a heurist, it is expected that for the hyperparameters of the autoencoders in both levels k1, k2, \u03b2, \u03c1, \u03bb, we propose the following numerical quality assurance. It is obvious that the hidden representations of an autoencoder learn different regularities from the input, so the representation performance is increased and diversified, as the learned filters are decorrelated. We searched in a parameter search room for these hyperparameter combinations. For k1, the inverval values 9-25 and for k2, the interval parameters-4-01 for each of these parameters are equal to 0.3 and 0.3 for savings parameters."}, {"heading": "3.3 TESTING PROCEDURES AND COMPARISON", "text": "In order to be able to compare the proposed method with other MVPA methods, we use a k-nearest neighbor classifier for all methods. In order to make a fair comparison, we also use a one-step temporal Convolutionary Network to monitor the effects of depth. First, three different MVPA approaches are considered: The starting point is the raw MVPA method, in which the raw intensity values are fed directly to the classifier. To make a fair comparison, we also use temporal information in the classic MVPA method in two different ways. First, to take into account the temporal activation pattern in a handmade way, we intertwined the raw intensity values with a double gamma-HRF function, which we called the HRF-MVPA method. After intertwining with the temporal activation pattern of the MVPA sample, the MVPA matrix values are used in a similar way to the second phase of the MVPA matrix in the second phase."}, {"heading": "3.4 SIGNIFICANCE TESTS AND OVERFITTING ANALYSIS", "text": "The lower number of samples (as in our case) can lead to greater variability in the estimation. We performed simple but diagnostic tests to determine how accurate the proposed method is. Statistical significance measures the improbability of the observed classification accuracy in the face of the null hypothesis. However, Pereira et al. (2009) suggests a binomial test (see Alpaydin (2010) to estimate the significance of a classifier, provided that the samples are drawn independently. In our experiment, the experiments were clearly separated by irrelevant tasks between memory encoding and memory decoding of phases, making it plausible that the precondition holds. The null hypothesis was considered a random number, i.e. the classifier leads at the random level (10% for general, 50% for a one-against-all mode). The largest p value provided by the tests was 0.0004, and the zero hypothesis was rejected as a yardstick for all methods proposed."}, {"heading": "4 RESULTS", "text": "In this section, we present and analyze the performance results of the proposed approach. Experimental results are analyzed by looking at the final spatial dimensions of features (last column of Table I) in classifiers by comparing classification accuracies; the overall results are also presented in Table 1. For the classical and temporal MVPA approaches (first three rows of Table 1), the raw MVPA approach is used as the basic method, which is expected because we use time information; without adapting the HRF to the regularities of the data, it remains more manual; the T-MVPA method uses time information without HRF assumptions and improves performance by up to 8% for the rest of the participants; this is expected because we use time information without adapting the HRF to the regularities in the data; the T-MVPA method uses time information without HRF assumptions and improves performance compared to other MVPA methods."}, {"heading": "5 CONCLUSION", "text": "In this study, we considered a novel approach to decoding fMRI data using unattended feature learning and Convolutionary Neural Networks. By using unmarked data and using multi-layered temporal CNNs, we get to know several layers of time filters that represent the activation patterns of voxels under experimental conditions. By using deep temporal representations, we train powerful and robust brain decoding models that can trigger a slight deviation from conventional MVPA approaches, which generally rely on voxel intensity values as characteristics or can be created carefully by hand. As evidence of the performance of the proposed model, we conducted a recognition memory experiment on 9 subjects and observed significant performance improvements. The proposed model has potential for further improvements by incorporating spatial structures with spatial confusion and pooling or learning spatial-temporal filters as the overall work of the future should be."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors thank all Beyincik members for their insightful discussions on pre-processing fMRI data. This work is supported by the TUBITAK Project, 112E315."}], "references": [{"title": "Introduction to Machine Learning", "author": ["Alpaydin", "Ethem"], "venue": "ISBN 026201243X,", "citeRegEx": "Alpaydin and Ethem.,? \\Q2010\\E", "shortCiteRegEx": "Alpaydin and Ethem.", "year": 2010}, {"title": "Temporal and cross-subject probabilistic models for fmri prediction tasks", "author": ["Battle", "Alexis", "Chechik", "Gal", "Koller", "Daphne"], "venue": "In NIPS,", "citeRegEx": "Battle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Battle et al\\.", "year": 2006}, {"title": "Representation learning: A review and new perspectives", "author": ["Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pascal"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Deep neural networks rival the representation of primate it cortex for core visual object recognition", "author": ["Cadieu", "Charles F", "Hong", "Ha", "Yamins", "Daniel L K", "Pinto", "Nicolas", "Ardila", "Diego", "Solomon", "Ethan A", "Majaj", "Najib J", "DiCarlo", "James J"], "venue": "PLoS computational biology,", "citeRegEx": "Cadieu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cadieu et al\\.", "year": 2014}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["Erhan", "Dumitru", "Bengio", "Yoshua", "Courville", "Aaron", "Manzagol", "Pierre-Antoine", "Vincent", "Pascal", "Samy"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Erhan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2010}, {"title": "Functional mesh learning for pattern analysis of cognitive processes", "author": ["Firat", "Orhan", "Ozay", "Mete", "Onal", "Itir", "Oztekiny", "Ilke", "Vural", "Fatos T Yarman"], "venue": "In Cognitive Informatics & Cognitive Computing (ICCI* CC),", "citeRegEx": "Firat et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Firat et al\\.", "year": 2013}, {"title": "Multiclass fmri data decoding and visualization using supervised self-organizing maps", "author": ["Hausfeld", "Lars", "Valente", "Giancarlo", "Formisano", "Elia"], "venue": null, "citeRegEx": "Hausfeld et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hausfeld et al\\.", "year": 2014}, {"title": "Decoding neural representational spaces using multivariate pattern analysis", "author": ["Haxby", "James V", "Connolly", "Andrew C", "Guntupalli", "J. Swaroop"], "venue": "Annual Review of Neuroscience,", "citeRegEx": "Haxby et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Haxby et al\\.", "year": 2014}, {"title": "Decoding mental states from brain activity in humans", "author": ["Haynes", "John-Dylan", "Rees", "Geraint"], "venue": "Nature reviews. Neuroscience,", "citeRegEx": "Haynes et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Haynes et al\\.", "year": 2006}, {"title": "Restricted boltzmann machines for neuroimaging: An application in identifying intrinsic networks", "author": ["Hjelm", "R. Devon", "Calhoun", "Vince D", "Salakhutdinov", "Ruslan", "Allen", "Elena A", "Adali", "Tulay", "Plis", "Sergey M"], "venue": null, "citeRegEx": "Hjelm et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hjelm et al\\.", "year": 2014}, {"title": "Functional magnetic resonance imaging, volume 1. Sinauer Associates", "author": ["Huettel", "Scott A", "Song", "Allen W", "McCarthy", "Gregory"], "venue": null, "citeRegEx": "Huettel et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Huettel et al\\.", "year": 2004}, {"title": "Learning invariant features through topographic filter maps", "author": ["Kavukcuoglu", "Koray", "M Ranzato", "Fergus", "Rob", "LeCun", "Yann"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis", "author": ["Le", "Quoc V", "Zou", "Will Y", "Yeung", "Serena Y", "Ng", "Andrew Y"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Le et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Le et al\\.", "year": 2011}, {"title": "Predicting human brain activity associated with the meanings of nouns", "author": ["Mitchell", "Tom M", "Shinkareva", "Svetlana V", "Carlson", "Andrew", "Chang", "Kai-Min", "Malave", "Vicente L", "Mason", "Robert A", "Just", "Marcel Adam"], "venue": null, "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "A review of feature reduction techniques in neuroimaging", "author": ["Mwangi", "Benson", "Tian", "TianSiva", "Soares", "JairC"], "venue": "Neuroinformatics, 12(2):229\u2013244,", "citeRegEx": "Mwangi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mwangi et al\\.", "year": 2014}, {"title": "Advice for applying machine learning. Accessed: 04/01/2014", "author": ["Ng", "Andrew"], "venue": "URL http://see. stanford.edu/materials/aimlcs229/ML-advice.pdf", "citeRegEx": "Ng and Andrew.,? \\Q2014\\E", "shortCiteRegEx": "Ng and Andrew.", "year": 2014}, {"title": "Beyond mind-reading: multi-voxel pattern analysis of fMRI data", "author": ["Norman", "Kenneth A", "Polyn", "Sean M", "Detre", "Greg J", "Haxby", "James V"], "venue": "Trends in cognitive sciences,", "citeRegEx": "Norman et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Norman et al\\.", "year": 2006}, {"title": "Distributed Patterns of Brain Activity that Lead to Forgetting", "author": ["Oztekin", "Ilke", "Badre", "David"], "venue": "Frontiers in human neuroscience,", "citeRegEx": "Oztekin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Oztekin et al\\.", "year": 2011}, {"title": "Information mapping with pattern classifiers: a comparative study", "author": ["Pereira", "Francisco", "Botvinick", "Matthew"], "venue": null, "citeRegEx": "Pereira et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pereira et al\\.", "year": 2011}, {"title": "Machine learning classifiers and fmri: A tutorial overview", "author": ["Pereira", "Francisco", "Mitchell", "Tom", "Botvinick", "Matthew"], "venue": "NeuroImage, 45:S199 \u2013 S209,", "citeRegEx": "Pereira et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pereira et al\\.", "year": 2009}, {"title": "Deep learning for neuroimaging: a validation study", "author": ["Plis", "Sergey M", "Hjelm", "Devon", "Salakhutdinov", "Ruslan", "Allen", "Elena A", "Bockholt", "Henry Jeremy", "Long", "Jeffrey D", "Johnson", "Hans J", "Paulsen", "Jane", "Turner", "Jessica A", "Calhoun", "Vince D"], "venue": "Frontiers in Neuroscience,", "citeRegEx": "Plis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Plis et al\\.", "year": 2014}, {"title": "Self-taught learning: transfer learning from unlabeled data", "author": ["Raina", "Rajat", "Battle", "Alexis", "Lee", "Honglak", "Packer", "Benjamin", "Ng", "Andrew Y"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Raina et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Raina et al\\.", "year": 2007}, {"title": "Decoding subject-driven cognitive states with whole-brain connectivity patterns. Cerebral cortex (New York, N.Y", "author": ["W R Shirer", "S Ryali", "E Rykhlevskaia", "V Menon", "Greicius", "M D"], "venue": null, "citeRegEx": "Shirer et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Shirer et al\\.", "year": 1991}, {"title": "Kernel principal component analysis for dimensionality reduction in fmri-based diagnosis of adhd", "author": ["Sidhu", "Gagan S", "Asgarian", "Nasimeh", "Greiner", "Russell", "Brown", "Matthew R G"], "venue": "Frontiers in Systems Neuroscience,", "citeRegEx": "Sidhu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sidhu et al\\.", "year": 2012}, {"title": "Functional principal component analysis of fmri data", "author": ["Viviani", "Roberto", "Gr\u00f6n", "Georg", "Spitzer", "Manfred"], "venue": "Human brain mapping,", "citeRegEx": "Viviani et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Viviani et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 7, "context": "Brain decoding using functional magnetic resonance imaging (fMRI) is a challenging problem that has received much attention recently because of its non-invasive nature, see Haxby et al. (2014) for a review.", "startOffset": 173, "endOffset": 193}, {"referenceID": 17, "context": "great deal of effort spent to either reduce the dimensionality Viviani et al. (2005); Sidhu et al.", "startOffset": 63, "endOffset": 85}, {"referenceID": 17, "context": "(2005); Sidhu et al. (2012); Mwangi et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 11, "context": "(2012); Mwangi et al. (2014) or employ spatial/temporal structures Battle et al.", "startOffset": 8, "endOffset": 29}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al.", "startOffset": 45, "endOffset": 66}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al.", "startOffset": 45, "endOffset": 94}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation.", "startOffset": 45, "endOffset": 115}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al.", "startOffset": 45, "endOffset": 245}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al.", "startOffset": 45, "endOffset": 267}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al. (2012); Hausfeld et al.", "startOffset": 45, "endOffset": 289}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al. (2012); Hausfeld et al. (2014) to represent cognitive processes.", "startOffset": 45, "endOffset": 313}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al. (2012); Hausfeld et al. (2014) to represent cognitive processes. Another issue related to the low number of labelled samples is the labelling procedure which is strongly coupled with the experimental design. Within the time points acquired during an experiment, only few are assigned to corresponding class labels by considering timing of the stimulus. For example in a block design, a predetermined number of time points within a block are averaged to obtain a smoothed intensity value Mitchell et al. (2008) and assigned to a single class label.", "startOffset": 45, "endOffset": 792}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al. (2012); Hausfeld et al. (2014) to represent cognitive processes. Another issue related to the low number of labelled samples is the labelling procedure which is strongly coupled with the experimental design. Within the time points acquired during an experiment, only few are assigned to corresponding class labels by considering timing of the stimulus. For example in a block design, a predetermined number of time points within a block are averaged to obtain a smoothed intensity value Mitchell et al. (2008) and assigned to a single class label. Similarly, in an event related design, class labels are assigned to time points according to the prior knowledge of the peaks of hemo-dynamic response function (e.g. 2-3 time points after the stimulus) Norman et al. (2006); Oztekin & Badre (2011).", "startOffset": 45, "endOffset": 1053}, {"referenceID": 1, "context": "(2014) or employ spatial/temporal structures Battle et al. (2006); Pereira & Botvinick (2011); Firat et al. (2013) for a better representation. As a result, many brain decoding systems rely on cleverly hand-crafted features Norman et al. (2006); Haynes & Rees (2006); Shirer et al. (2012); Hausfeld et al. (2014) to represent cognitive processes. Another issue related to the low number of labelled samples is the labelling procedure which is strongly coupled with the experimental design. Within the time points acquired during an experiment, only few are assigned to corresponding class labels by considering timing of the stimulus. For example in a block design, a predetermined number of time points within a block are averaged to obtain a smoothed intensity value Mitchell et al. (2008) and assigned to a single class label. Similarly, in an event related design, class labels are assigned to time points according to the prior knowledge of the peaks of hemo-dynamic response function (e.g. 2-3 time points after the stimulus) Norman et al. (2006); Oztekin & Badre (2011). The rest of the unlabelled samples are generally thrown away and not used further in the decoding tasks.", "startOffset": 45, "endOffset": 1077}, {"referenceID": 20, "context": "Recent improvements in unsupervised feature learning and transfer learning points out the importance of employing unlabelled data for a better classification Raina et al. (2007); Erhan et al.", "startOffset": 158, "endOffset": 178}, {"referenceID": 3, "context": "(2007); Erhan et al. (2010), especially for the cases that we do not have enough labelled data.", "startOffset": 8, "endOffset": 28}, {"referenceID": 2, "context": "It is hypothesised that learning the data generating distribution p(x) by leveraging unlabelled data improves further discriminative tasks p(y|x), when p(x) and p(y|x) share some structure Bengio et al. (2013). We experimented this hypothesis by proposing that the discarded unlabelled samples of fMRI data still contain information and can be exploited in brain decoding tasks.", "startOffset": 189, "endOffset": 210}, {"referenceID": 12, "context": "Such approaches are common in computer vision Le et al. (2011) but have not been adapted for neuroimaging data, especially for brain decoding.", "startOffset": 46, "endOffset": 63}, {"referenceID": 12, "context": "Further, we integrate learned temporal representations into a deep temporal convolutional neural network (CNN) which have demonstrated many successes recently Krizhevsky et al. (2012). We employ the temporal representations to capture the temporal information by convolution following spatial pooling within CNN layers to reduce dimensionality.", "startOffset": 159, "endOffset": 184}, {"referenceID": 3, "context": "Although there exist few studies that employ and analyse deep learning methods for neuroimaging data Cadieu et al. (2014); Hjelm et al.", "startOffset": 101, "endOffset": 122}, {"referenceID": 3, "context": "Although there exist few studies that employ and analyse deep learning methods for neuroimaging data Cadieu et al. (2014); Hjelm et al. (2014); Plis et al.", "startOffset": 101, "endOffset": 143}, {"referenceID": 3, "context": "Although there exist few studies that employ and analyse deep learning methods for neuroimaging data Cadieu et al. (2014); Hjelm et al. (2014); Plis et al. (2014), we believe that the potential of deep learning should be further studied thoroughly for brain decoding tasks as well.", "startOffset": 101, "endOffset": 163}, {"referenceID": 11, "context": "For the aim of learning temporal filters in an unsupervised fashion, we employ sparse autoencoders Kavukcuoglu et al. (2009). An autoencoder is a neural network trained by back-propagation which attempts to reconstruct its input by setting the target values to be equal to the inputs, x \u2248 x\u0303.", "startOffset": 99, "endOffset": 125}, {"referenceID": 12, "context": "In a convolutional neural network, a general processing block is constructed by three consecutive operations; convolution, pooling and applying an element-wise non-linearity Krizhevsky et al. (2012). Further, these blocks can be repeated consecutively by feeding output of one block to the next one Le et al.", "startOffset": 174, "endOffset": 199}, {"referenceID": 12, "context": "In a convolutional neural network, a general processing block is constructed by three consecutive operations; convolution, pooling and applying an element-wise non-linearity Krizhevsky et al. (2012). Further, these blocks can be repeated consecutively by feeding output of one block to the next one Le et al. (2011). We construct our temporal convolutional model with two processing blocks as shown in Figure 2 with dashed boxes.", "startOffset": 174, "endOffset": 316}, {"referenceID": 12, "context": "In a convolutional neural network, a general processing block is constructed by three consecutive operations; convolution, pooling and applying an element-wise non-linearity Krizhevsky et al. (2012). Further, these blocks can be repeated consecutively by feeding output of one block to the next one Le et al. (2011). We construct our temporal convolutional model with two processing blocks as shown in Figure 2 with dashed boxes. To complete our first processing block, we determine a spatial pooling function \u03bc, a pooling range in a vicinity \u03b41 and point-wise non-linearity function \u03c3. Considering the capillary structure of the brain and point spread function of fMRI medium, it is expected that nearby voxels exhibit correlated activations Pereira & Botvinick (2011). Therefore for the choice of \u03bc we employ max pooling function on the columns of response matrices.", "startOffset": 174, "endOffset": 770}, {"referenceID": 10, "context": "It is well known that, hemo-dynamic response function (HRF) peaks around 4-6 seconds after a stimulus and returns to baseline after 10-12 seconds Huettel et al. (2004). Considering the experimental protocol TR as 2sec, a full HRF could be captured with a temporal window size of 6 samples.", "startOffset": 146, "endOffset": 168}, {"referenceID": 10, "context": "It is well known that, hemo-dynamic response function (HRF) peaks around 4-6 seconds after a stimulus and returns to baseline after 10-12 seconds Huettel et al. (2004). Considering the experimental protocol TR as 2sec, a full HRF could be captured with a temporal window size of 6 samples. Therefore the sampling window length for the first convolutional block \u03c41 (resp. input unit size for the first autoencoder, filter length), is set to 6. It is also common for CNNs that the higher level receptive fields get wider to capture more abstract regularities Krizhevsky et al. (2012), so we increased the second block temporal sampling window length \u03c42, to 9 samples (7-10 range give similar results).", "startOffset": 146, "endOffset": 582}, {"referenceID": 2, "context": "A major strait of CNNs and many other deep learning methods is the large number of hyperparameters to be tuned Bengio et al. (2013). Without a proper cross-validation set, as in our case, these hyper parameters are left to be tuned with trial and error fashion which we avoided in this study.", "startOffset": 111, "endOffset": 132}, {"referenceID": 19, "context": "Pereira et al. (2009) proposes Binomial test (see Alpaydin (2010)) to estimate the significance of a classifier provided that the samples are drawn independently.", "startOffset": 0, "endOffset": 22}, {"referenceID": 19, "context": "Pereira et al. (2009) proposes Binomial test (see Alpaydin (2010)) to estimate the significance of a classifier provided that the samples are drawn independently.", "startOffset": 0, "endOffset": 66}], "year": 2015, "abstractText": "Functional magnetic resonance imaging produces high dimensional data, with a less then ideal number of labelled samples for brain decoding tasks (predicting brain states). In this study, we propose a new deep temporal convolutional neural network architecture with spatial pooling for brain decoding which aims to reduce dimensionality of feature space along with improved classification performance. Temporal representations (filters) for each layer of the convolutional model are learned by leveraging unlabelled fMRI data in an unsupervised fashion with regularized autoencoders. Learned temporal representations in multiple levels capture the regularities in the temporal domain and are observed to be a rich bank of activation patterns which also exhibit similarities to the actual hemodynamic responses. Further, spatial pooling layers in the convolutional architecture reduce the dimensionality without losing excessive information. By employing the proposed temporal convolutional architecture with spatial pooling, raw input fMRI data is mapped to a non-linear, highly-expressive and low-dimensional feature space where the final classification is conducted. In addition, we propose a simple heuristic approach for hyper-parameter tuning when no validation data is available. Proposed method is tested on a ten class recognition memory experiment with nine subjects. The results support the efficiency and potential of the proposed model, compared to the baseline multi-voxel pattern analysis techniques.", "creator": "LaTeX with hyperref package"}}}