{"id": "1412.8147", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Dec-2014", "title": "Improving Persian Document Classification Using Semantic Relations between Words", "abstract": "With the increase of information, document classification as one of the methods of text mining, plays vital role in many management and organizing information. Document classification is the process of assigning a document to one or more predefined category labels. Document classification includes different parts such as text processing, term selection, term weighting and final classification. The accuracy of document classification is very important. Thus improvement in each part of classification should lead to better results and higher precision. Term weighting has a great impact on the accuracy of the classification. Most of the existing weighting methods exploit the statistical information of terms in documents and do not consider semantic relations between words. In this paper, an automated document classification system is presented that uses a novel term weighting method based on semantic relations between terms. To evaluate the proposed method, three standard Persian corpuses are used. Experiment results show 2 to 4 percent improvement in classification accuracy compared with the best previous designed system for Persian documents.", "histories": [["v1", "Sun, 28 Dec 2014 10:56:53 GMT  (404kb)", "http://arxiv.org/abs/1412.8147v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["saeed parseh", "ahmad baraani"], "accepted": false, "id": "1412.8147"}, "pdf": {"name": "1412.8147.pdf", "metadata": {"source": "CRF", "title": "Improving Persian Document Classification Using Semantic Relations between Words", "authors": ["Saeed Parseh", "Ahmad Baraani"], "emails": ["saeedparseh@gmail.com", "ahmadb@eng.ui.ac.ir"], "sections": [{"heading": null, "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city and in which it is a country."}, {"heading": "A. Document Preprocessing", "text": "The pre-processing phase prepares the document for the classification process. Typically, the following steps are taken to process the document: 1) tokenization, in which a document is treated as a string and then divided into a list of tokens. In fact, a model of document rendering is used. There are many different models of document rendering, the simplest being N-gram, in which words are rendered as strings of length N. The most popular and effective rendering is single words in which documents are represented by their words. 2) Removal of stopwords, where words frequently occur and the insignificant words must be removed. 3) Stemming word, in which a tribal algorithm is applied that converts different word forms into a similar canonical form. This step is the process of confusing tokens with their root form. In this paper, individual words are used as a model for document rendering, but some specific Persian language considerations must be considered as limits. The most important parameter is the recognition of the sentence."}, {"heading": "B. Term Selection", "text": "Each document in the training data set consists of a large number of relevant and irrelevant terms corresponding to its category. Thus, the second step in the training phase is the selection of the relevant terms. This step is called term selection (TS) or feature selection. The accuracy of the system depends to a large extent on the keywords selected to represent documents, also the arithmetic complexity depends on the number of keywords selected; the selection of a small subset of a category relative to keywords, or the selection of uninformative keywords not related to the domain of any category involved, can lead to a lack in the accuracy of the classification, even a very large number of keywords can make a classification algorithm time inefficient. In text classification terms should be able to distinguish between categories and selected terms for different categories, not overlap. Some conventional term selection methods are information gains, two tests and the frequency of documents based on a word selection mechanism [12] of a larger category, which is a larger category in a category."}, {"heading": "C. Term Weighting", "text": "The selected terms from the term selection phase can be represented by the vector space model [15]. Elements of this vector are the term weights, which can be calculated using different weighting schemes. The most commonly used method is Term Frequency-Inverse Document Frequency (tf _ idf), which stands for term frequency (tf) multiplied by the inverse document frequency (idf), where tf indicates the relative frequency of a term appearing in a document. tf _ idf Weight for each term is obtained by using (2) [16]. The weights resulting from tf _ idf are often normalized by cosine normalization, given by (3) [16].) (log (), (_ i jiji tN Ndttfdtidftf (2) | 1), (_ jds jsji ijdftfdtidf (3)."}, {"heading": "D. Classifier", "text": "This year, it has reached the point where it will be able to put itself at the top of the list."}, {"heading": "A. Training Data Set", "text": "In our experiments, we used three different sets of data: \"Hamshahri\" (version 2) [21], \"Persica\" [22] and \"Tabnak.\" The Hamshahri corpus is undoubtedly the largest collection of Persian texts, containing over 310,000 documents from 1996 to 2007 in the following subject categories: politics, urban news, economics, reports, editorials, literature, sciences, society, foreign news, sports, etc. Persica and Tabnak are other corpses with the same categories as Hamshahri. To evaluate the proposed method, three different sets of data in six categories are randomly selected from the above-mentioned corpus.The first set (D1) with 585 random documents, the second (D2) with 976 random documents, and the third (D3) with 1225 random documents."}, {"heading": "B. Evaluation Measures", "text": "Precision (8) and callback (9), measures are often used to evaluate classification tasks. They are defined as follows [16]: FPTP TPecision Pr (8) FNTP TPcall Re (9) Where TP is the number of documents correctly assigned to a category, FP is the number of documents wrongly assigned to a category and FN is the number of documents wrongly omitted in a category. There is a trade-off between precision and a system callback [16]. The F1 measure (10) is the harmonious mean for precision and callback that takes into account both the effects of precision and callback measurements."}, {"heading": "C. Equations", "text": "Experimental results are presented in this subsection. Experiments consist of evaluating the classification performance when using thesaurus and semantic weight using three sets of data with extended feature vectors mentioned in Table 1. In this case, the classification performance improves especially when accessible training data sets are not sufficiently comprehensive; i.e. the existing words are unable to distinguish one category from another. In this case, the use of an auxiliary knowledge resource such as a thesaurus can compensate for the inadequacy of existing information. In fact, some relevant features (words) extracted from the thesaurus are added to the existing feature vector obtained by processing the training documents belonging to the desired category. If semantic weight is used in the process of semantic weighting (the proposed method), efficiency measurements increase by 2 to 4 percent."}, {"heading": "D. Comparison With Other Works", "text": "In this section, the Persian classification system in this paper is compared with previous systems designed for Persian documents. To this end, we have selected three previous works that are similar to the system in this paper and have the best result. These works are mentioned in Section II. We refer to them according to System 1: The TC system designed by Maghsoodi and Homayounpour, with SVM and thesaurus.2) System 2: The TC system used by Parchami and thesaurus.3) System 3: The TC system designed by The Elahimanesh et al. [10] Using k-NN.2 and test on three sets of data, the results are shown. Since F1 Measure is a harmonious means of precision and recall, this measure has been selected for comparison relations."}], "references": [{"title": "New retrieval approaches using SMART", "author": ["C. Buckley", "A. Singhal", "M. Mitra"], "venue": "Proc. of the 4th Text Retrieval conference (TREC-4), Gaithersburg, 1996, pp. 25-48.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1996}, {"title": "Readings in information retrieval", "author": ["K.S. Jones", "P. Willett"], "venue": "San Francisco: Morgan Kaufmann Publishers,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Term-weighting approaches in automatic text retrieval", "author": ["G. Salton", "C. Buckley"], "venue": "Journal of Information Processing and management, vol. 24, 1988, pp. 513-523.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1988}, {"title": "A Semantic Term Weighting Scheme for Text Categorization", "author": ["O. Luo", "CH. Enhong", "X. Hui"], "venue": "Expert Systems with Applications, vol. 38, 2011, pp. 12708-12716.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Using Thesaurus to Improve Multiclass Text Classification", "author": ["N. Maghsoodi", "M. Homayounpoor"], "venue": "Computational Linguistics and Intelligent Text Processing, Springer Berlin Heidelberg, 2011, pp. 244-253.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Boosting for text classification with semantic features", "author": ["S. Bloehdorn", "A. Hotho"], "venue": "Workshop on Text-based Information Retrieval (TIR 2004) at the 27th German Conference on Artificial Intelligence, 2004, pp. 149\u2013166.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Wordnet improves text document clustering", "author": ["Hotho", "S. Staab", "G. Stumme"], "venue": "Proceedings of the Semantic Web Workshop at SIGIR, 2003, pp. 61\u201369.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Comparing KNN and FKNN algorithms in Farsi text classification based on information gain and document frequency feature selection", "author": ["M.E. Basiri", "S. Nemati", "N. Aqaee"], "venue": "Proceedings of the 13th International Computer Conference of Computer Society of Iran, 2008, pp. 383-406.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Classification of Persian textual documents using learning vector quantization", "author": ["M.T. Pilevar", "H. Feili", "M. Soltani"], "venue": "Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering, 2009, pp. 1-6.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Improving K-Nearest Neighbor Efficacy for Farsi Text Classification", "author": ["M.H. Elahimanesh", "B. Minaei", "H. Malekinezhad"], "venue": "The International Conference on Language Resources and Evaluation (LREC), 2012, pp. 1618-1621.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Persian text classification based on K-NN using wordnet", "author": ["M. Parchami", "B. Akhtar", "M. Dezfoulian"], "venue": "Advanced Research in Applied Artificial Intelligence, Springer Berlin Heidelberg, 2012, pp. 283-291.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "A theoretic and empirical research of cluster indexing for Mandarin Chinese full text document", "author": ["Y.L. Huang"], "venue": "Journal of Library and Information Science, vol. 24, 1998, pp. 1023\u20132125.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1998}, {"title": "Information gain and divergence-based feature selection for machine learning-based text categorization", "author": ["C. Lee", "G. Lee"], "venue": "Information Processing & Management, vol. 42, 2006, pp. 155\u2013165.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "A comparative study on feature selection in text categorization", "author": ["Y. Yang", "I.O. Pedersen"], "venue": "Proceedings of 14th International Conference on Machine Learning (ICML-97), San Francisco,1997, pp. 412\u2013420.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "A vector space model for automatic indexing", "author": ["G. Salton", "C. Yang", "A", "Wang"], "venue": "Communications of the ACM, vol. 18, 1975, pp. 613\u2013620.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1975}, {"title": "Machine learning automated text categorization", "author": ["F. Sebastiani"], "venue": "ACM Computing Surveys, vol. 34, 2002, pp. 1\u201347.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Expert network: Effective and efficient learning from human decisions in text categorization and retrieval", "author": ["Y. Yang"], "venue": "Proceedings of the International Conference on Research and Development in Information Retrieval (ACM SIGIR \u201994), NewYork, ACM Press, 1994, pp. 13\u201322.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1994}, {"title": "evaluation of statistical approaches to text categorization,", "author": ["Y. Yang", "\"An"], "venue": "Information Retrieval,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1999}, {"title": "Multi-Class Support Vector Machine", "author": ["Th. Joachims"], "venue": "Internet:www.cs.cornell.edu/people/tj/svm_light/svm_multiclass.html, Aug", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Hamshahri: A Standard Persian Text Collection", "author": ["AleAhmad", "H. Amiri", "E. Darrudi", "M. Rahgozar", "F. Oroumchian"], "venue": "Knowledge-Based Systems, vol. 22, 2009, pp. 382\u2013387.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Persica: A Persian corpus for multipurpose text mining and Natural language processing", "author": ["H. Eghbalzadeh", "B. Hosseini", "Sh. Khadivi", "A. Khodabakhsh"], "venue": "Sixth International Symposium on Telecommunications (IST), 2012, pp. 1207-1214.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Different approaches have been introduced for term weighting [1-3].", "startOffset": 61, "endOffset": 66}, {"referenceID": 1, "context": "Different approaches have been introduced for term weighting [1-3].", "startOffset": 61, "endOffset": 66}, {"referenceID": 2, "context": "Different approaches have been introduced for term weighting [1-3].", "startOffset": 61, "endOffset": 66}, {"referenceID": 3, "context": "Such an approach ignores the syntactic and semantic information in a document, such as word order, multi-word phrases, synonymy, polysemy, and other semantic relationships among words [4].", "startOffset": 184, "endOffset": 187}, {"referenceID": 4, "context": "Most of these methods use an existing ontology or thesaurus [5].", "startOffset": 60, "endOffset": 63}, {"referenceID": 5, "context": "Bloehdorn and Hotho represent documents using WordNet, the MeSH (Medical Subject Headings) Tree Structure Ontology [6].", "startOffset": 115, "endOffset": 118}, {"referenceID": 6, "context": "utilized a term ontology structured from WordNet to improve the BOW text representation [7].", "startOffset": 88, "endOffset": 91}, {"referenceID": 7, "context": "presented a comparison between KNN and fuzzy KNN approaches for Farsi text classification based on information gain and document frequency feature selection [8].", "startOffset": 157, "endOffset": 160}, {"referenceID": 8, "context": "provided a Farsi text classification system using the Learning Vector Quantization network [9].", "startOffset": 91, "endOffset": 94}, {"referenceID": 4, "context": "Maghsoodi and Homayounpour have used SVM classifier based on extending the feature vector applying words extracted from a thesaurus [5].", "startOffset": 132, "endOffset": 135}, {"referenceID": 9, "context": "improved the KNN text classifier by inserting a factor to the KNN formula for considering the effects of unbalanced training datasets and used of N-grams with lengths more than 3 characters in text preprocessing [10].", "startOffset": 212, "endOffset": 216}, {"referenceID": 10, "context": "proposed a method that uses WordNet to increase similarity of documents under the same category [11].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "Some conventional term selection methods are information gain, \u03c72 test and document frequency [12-14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 12, "context": "Some conventional term selection methods are information gain, \u03c72 test and document frequency [12-14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 13, "context": "Some conventional term selection methods are information gain, \u03c72 test and document frequency [12-14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 4, "context": "In other words, the degree that a term corresponds to a specific category is defined as term frequency times inverse category frequency (tf_icf), according to (1) [5]:", "startOffset": 163, "endOffset": 166}, {"referenceID": 4, "context": "According to [5] and our", "startOffset": 13, "endOffset": 16}, {"referenceID": 14, "context": "The selected terms from the term-selection phase can be represented by the vector space model [15].", "startOffset": 94, "endOffset": 98}, {"referenceID": 15, "context": "The tf_idf weight for each term can obtain using (2) [16].", "startOffset": 53, "endOffset": 57}, {"referenceID": 15, "context": "The weights resulting from tf_idf are often normalized by cosine normalization, given by (3) [16].", "startOffset": 93, "endOffset": 97}, {"referenceID": 15, "context": "Efficiency of this method on different corpuses has been proved [16].", "startOffset": 64, "endOffset": 68}, {"referenceID": 15, "context": "After obtaining feature vectors from the previous step, a machine learning method [16] or a statistical technique [17] is used as a classifier component.", "startOffset": 82, "endOffset": 86}, {"referenceID": 16, "context": "After obtaining feature vectors from the previous step, a machine learning method [16] or a statistical technique [17] is used as a classifier component.", "startOffset": 114, "endOffset": 118}, {"referenceID": 17, "context": "According to a study by [18], a support vector machine (SVM) outperforms other machine learning methods.", "startOffset": 24, "endOffset": 28}, {"referenceID": 18, "context": "Therefore, in the approach presented in this paper, SVM is applied as implemented in the SVM_multicalss [19] software.", "startOffset": 104, "endOffset": 108}, {"referenceID": 4, "context": "If a feature is added to the feature vector from the feature selection (features that exist in data set), the weighting process is done according to (6), a feature is selected from the thesaurus, (7) [5] is used for term weighting.", "startOffset": 200, "endOffset": 203}, {"referenceID": 19, "context": "In our experiments, we have used three corpuses: \"Hamshahri\" (version 2) [21], \"Persica\" [22] and \"Tabnak\".", "startOffset": 73, "endOffset": 77}, {"referenceID": 20, "context": "In our experiments, we have used three corpuses: \"Hamshahri\" (version 2) [21], \"Persica\" [22] and \"Tabnak\".", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "They are defined as follows [16]:", "startOffset": 28, "endOffset": 32}, {"referenceID": 15, "context": "There is a trade-off between precision and recall of a system [16].", "startOffset": 62, "endOffset": 66}, {"referenceID": 15, "context": "In this paper, average precision and recall measures are used and their equations are as follows [16]:", "startOffset": 97, "endOffset": 101}, {"referenceID": 4, "context": "1) System 1: The TC system designed by Maghsoodi and Homayounpour [5] using SVM and thesaurus.", "startOffset": 66, "endOffset": 69}, {"referenceID": 10, "context": "[11] using SVM and thesaurus.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] using k-NN.", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "With the increase of information, document classification as one of the methods of text mining, plays vital role in many management and organizing information. Document classification is the process of assigning a document to one or more predefined category labels. Document classification includes different parts such as text processing, term selection, term weighting and final classification. The accuracy of document classification is very important. Thus improvement in each part of classification should lead to better results and higher precision. Term weighting has a great impact on the accuracy of the classification. Most of the existing weighting methods exploit the statistical information of terms in documents and do not consider semantic relations between words. In this paper, an automated document classification system is presented that uses a novel term weighting method based on semantic relations between terms. To evaluate the proposed method, three standard Persian corpuses are used. Experiment results show 2 to 4 percent improvement in classification accuracy compared with the best previous designed system for Persian documents. Keywords-component; Document classification; Semantic weight; Accuracy; Term weightin.", "creator": null}}}