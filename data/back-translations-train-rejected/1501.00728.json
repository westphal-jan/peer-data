{"id": "1501.00728", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jan-2015", "title": "Differential Search Algorithm-based Parametric Optimization of Fuzzy Generalized Eigenvalue Proximal Support Vector Machine", "abstract": "Support Vector Machine (SVM) is an effective model for many classification problems. However, SVM needs the solution of a quadratic program which require specialized code. In addition, SVM has many parameters, which affects the performance of SVM classifier. Recently, the Generalized Eigenvalue Proximal SVM (GEPSVM) has been presented to solve the SVM complexity. In real world applications data may affected by error or noise, working with this data is a challenging problem. In this paper, an approach has been proposed to overcome this problem. This method is called DSA-GEPSVM. The main improvements are carried out based on the following: 1) a novel fuzzy values in the linear case. 2) A new Kernel function in the nonlinear case. 3) Differential Search Algorithm (DSA) is reformulated to find near optimal values of the GEPSVM parameters and its kernel parameters. The experimental results show that the proposed approach is able to find the suitable parameter values, and has higher classification accuracy compared with some other algorithms.", "histories": [["v1", "Sun, 4 Jan 2015 22:12:36 GMT  (964kb)", "http://arxiv.org/abs/1501.00728v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["m h marghny", "rasha m abd elaziz", "ahmed i taloba"], "accepted": false, "id": "1501.00728"}, "pdf": {"name": "1501.00728.pdf", "metadata": {"source": "META", "title": "Differential Search Algorithm-based Parametric Optimization of Fuzzy Generalized Eigenvalue Proximal Support Vector Machine", "authors": ["M. H. Marghny", "Rasha M. Abd El-Aziz", "Ahmed I. Taloba"], "emails": [], "sections": [{"heading": null, "text": "Many classification problems. However, SVM requires the solution of a quadratic program that requires specialized code. In addition, SVM has many parameters that affect the performance of the SVM classifier. Recently, the Generalized eigenvalue Proximal SVM (GEPSVM) was presented to solve the SVM complexity. In the real world, data can be affected by errors or noise, working with these data is a difficult problem. In this paper, an approach was proposed to solve this problem, called DSA-GEPSVM. The main improvements are based on the following: 1) novel blurred values values in the linear case. 2) A new kernel function in the nonlinear case. 3) The Differential Search Algorithm (DSA) is reformulated to find approximately optimal values of the GEPSVM parameters and their kernel parameters. The experimental results show that the proposed approach is capable of comparing the appropriate keyword classifier algorithms, finding more accurate classifier values, and some higher classifier algorithms."}, {"heading": "1. INTRODUCTION", "text": "It is indeed the case that we will be able to go in search of a solution that is capable, in which we are able to find a solution."}, {"heading": "2. GENERALIZED EIGENVALUE PSVM", "text": "This year it is more than ever before in the history of the city."}, {"heading": "3. DIFFERENTIAL SEARCH ALGORITHM (DSA)", "text": "The Differential Search Algorithm (DSA) is a newer and more efficient evolutionary algorithm. DSA is effectively used to solve numerical optimization problems. The main idea of the DSA algorithm was inspired by the migration of superorganisms that use brownian motion [28].Algorithms that use the principle of evolutionary computation are known as Evolutionary Algorithms (EA), which are suitable for finding the optimal (best) solution to many optimization problems. In the real world, the optimization process can have more than one solution, because finding the optimal solution between all of these solutions in a short time is a demanding task. If the search space is small, then finding the optimal solution takes a short time. Working with data whose search space is very large is a challenge for most researchers. If the problem with a large number of possible solutions is very large, then finding the optimal solution between all of these solutions is difficult."}, {"heading": "4. PROPOSED APPROACH", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Linear Fuzzy DSA-GEPSVM", "text": "The proposed approach introduces a technique for calculating fuzzy member values. If the data is affected by noise or outliers, the classification process will have an impact, so the data will require some pre-processing steps. We propose a method by adding a fuzzy value for those examples that have no change outside the center of the class and the remaining examples. Now, the new formulation of the problems is as follows: min (,) 0"}, {"heading": "4.2 Nonlinear DSA-GEPSVM", "text": "The choice of the kernel function increases the accuracy of the classification. In real applications, the choice of the kernel function depends on the dataset used. Here are some of the most popular cores. Polynomic function: A polynomial kernel is a common method of nonlinear modeling."}, {"heading": "4.3 Parameter Optimization using DSA", "text": "In this context, it should be noted that this is one of the greatest challenges in the history of the European Union."}, {"heading": "5. EXPERIMENTAL RESULTS", "text": "The proposed approach is equipped with a Core i3 processor capable of monitoring the entire system."}, {"heading": "6. CONCLUSIONS", "text": "It is well known that the MSPSVM regularization parameters and kernel parameters are important for the performance of the classifier, but it is difficult to select a core function and its parameters because they depend on data sets. To optimize these parameters, the DSA was used. We conducted experiments to evaluate the performance of the proposed approach with three different kernel functions: Poly, RBF and PolyRBF in the nonlinear classifier. Results were compared with those of other algorithms, and the results show sufficient evidence that the proposed approach has lower error rates for most data sets with other algorithms. We may also conclude that the PolyRBF kernel provides better results compared to other kernel functions, and we plan to expand the DSA-MSPSVM approach to deal with multiclase problems in linear and nonlinear cases, and to investigate the effects of kernel assets."}, {"heading": "7. REFERENCES", "text": "[1] M.H. Marghny, Rasha M. Abd El-Aziz, and Ahmed I.Taloba. An Effective Evolutionary Clustering Algorithm: Hepatitis C case study. International Journal of Computer Applications, 2011, 34 (6): 1-6. [2] M.H. Marghny, and Ahmed I. Taloba. Outlier Detection using Improved Genetic K-means. International Journal of Computer Applications, 2011, 28 (11): 1-6. [2] M.H. Marghny, and Ahmed I. Talobvi M. Abd El-Aziz, and Ahmed I. Taloba. Fast Efficient ClusteringAlgorithm for Balanced Data. International Journal of Advanced Computer Science and Applications (IJACSA), 2014, 5 (6): 123-129. [4] C.C. Aggarwal, and C.K Reddy. Data Clustering: Algorithms and Applications."}, {"heading": "8. APPENDIX", "text": "Pseudo-code: Differential search algorithm [28] Required:"}, {"heading": "N: Size of the population, where i = {1, 2, 3, \u2026, N}", "text": "D: Dimension of problemsG: Number of maximum generations1: Superorganism = > J (), where superorganism = [ArtificialOrganismi] 2: yi = Evaluate (ArtificialOrganismi) 3: for cycle = 1: G do4: Donor = SuperorganismRandom _ Shuffling (i) 5: Scale = randg [2.rand1]. (rand2 - rand3) 6: StopoverSite = Superorganism + Scale. (donor - Superorganism) 7: p1 = 0.3. Rand58: if rand6 < rand7 then9: if rand8 < p1 then10: r = rand (N, D) 11: for Counter1: N do12: r (Counter1,:)."}], "references": [{"title": "Rasha M", "author": ["M.H. Marghny"], "venue": "Abd El-Aziz, and Ahmed I. Taloba. An Effective Evolutionary Clustering Algorithm: Hepatitis C case study. International Journal of Computer Applications", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "and Ahmed I", "author": ["M.H. Marghny"], "venue": "Taloba. Outlier Detection using Improved Genetic K-means. International Journal of Computer Applications", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast Efficient Clustering Algorithm for Balanced Data", "author": ["Adel A. Sewisy", "M.H. Marghny", "Rasha M. Abd El-Aziz", "Ahmed I. Taloba"], "venue": "International Journal of Advanced Computer Science and Applications (IJACSA),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Data clustering: algorithms and applications", "author": ["C.C. Aggarwal", "C.K Reddy"], "venue": "Chapman and Hall/CRC Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Extracting logical classification rules with gene expression programming: International Journal of Computer Applications (0975 \u2013 8887) Volume 108 \u2013 No 19", "author": ["M.H. Marghny", "I.E. El-Semman"], "venue": "December 2014 44  microarray case study. Proceedings of the International Conference on Artificial Intelligence and Machine Learning (AIML 05), Cairo, Egypt", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Extracting fuzzy classification rules with gene expression programming", "author": ["M.H. Marghny", "I.E. El-Semman"], "venue": ". Proceedings of the International Conference on Artificial Intelligence and Machine Learning (AIML 05), Cairo, Egypt", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "A new parallel association rule mining algorithm on distributed shared memory system", "author": ["M.H. Marghny", "H.E. Refaat"], "venue": "International Journal of Business Intelligence and Data Mining", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast", "author": ["M.H. Marghny", "A.A. Shakour"], "venue": "Simple and Memory Efficient Algorithm for Mining Association Rules. International Review on Computers & Software", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Scalable Algorithm for Mining Association Rules", "author": ["M.H. Marghny", "A.A. Shakour"], "venue": "ICCST", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Support vector networks", "author": ["C. Cortes", "V.N. Vapnik"], "venue": "Machine Learning", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "Proximal support vector machine classifiers", "author": ["Glenn Fung", "Olvi L. Mangasarian"], "venue": "In Proceedings of the Seventh ACM SIGKDD International conference on knowledge discovery and data mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Multisurface proximal support vector machine classification via generalized eigenvalues", "author": ["Olvi L. Mangasarian", "Edward W. Wild"], "venue": "IEEE transaction on pattern analysis and machine intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Fuzzy Support Vector Machines for Pattern Classification", "author": ["S Abe", "T. Inoue"], "venue": "IEEE, 2001,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}, {"title": "Fuzzy support vector machines", "author": ["Chun-Fu Lin", "Sheng-De Wang"], "venue": "IEEE transactions on neural networks,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Fuzzy proximal support vector classification via generalized eigenvalues", "author": ["Jayadeva", "R. Khemchandani", "S. Chandra"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Fuzzy multi-category proximal support vector classification via generalized eigenvalues. Soft Computing \u2013 A Fusion of Foundations", "author": ["Jayadeva", "R. Khemchandani", "S. Chandra"], "venue": "Methodologies and Applications,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "A fuzzy support vector machine algorithm with dual membership based on hypersphere", "author": ["Ding Shifei", "Gu Yaxiang"], "venue": "Journal of computational information systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "A fuzzy twin support vector machine algorithm. International journal of application or innovation in engineering", "author": ["Li. Kai", "Hongyan Ma"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Fuzzy regularized generalized eigenvalue classifier with a novel membership function", "author": ["M.R. Guarracino", "A. Irpino", "R. Jasinevicius", "R. Verde"], "venue": "Information Sciences", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "A ga-based feature selection and parameters optimization for support  vector machines", "author": ["Huang. Cheng-Lung", "Chieh-Jen Wang"], "venue": "Expert systems with applications,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Parameter determination of support vector machine and feature selection using simulated annealing approach", "author": ["S. Lin", "Z. Lee", "S. Chen", "T. Tseng"], "venue": "Applied soft computing", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Particle swarm optimization for parameter determination and feature selection of support vector machines", "author": ["S. Lin", "K. Ying", "S. Chen", "Z. Lee"], "venue": "Expert systems with applications", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "A new parameter selection method for support vector machine based on the decision value", "author": ["L. Luo", "D. Huang", "H. Peng", "Q. Zhou", "G. Shao", "F. Yang"], "venue": "Convergence information technology", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Enhancing the classification accuracy by scatter-based ensemble approach", "author": ["S.C. Chen", "S.W. Linb", "S.Y. Chou"], "venue": "Applied soft computing", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Support vector machine with parameter optimization by a novel hybrid method and its application to fault diagnosis", "author": ["X. Zhang", "D. Qiu", "F. Chen"], "venue": "Neurocomputing", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding the nature of evolutionary search algorithms", "author": ["P. Civicioglu"], "venue": "Additional technical report for the project of 110Y309-Tubitak", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Differential search algorithm-based parametric optimization of electrochemical micromachining processes", "author": ["D. Goswami", "S. Chakraborty"], "venue": "International journal of industrial engineering computations", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm", "author": ["P. Civicioglu"], "venue": "Computers & Geosciences", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "An implementation of differential search algorithm (DSA) for inversion of surface wave data", "author": ["X. Song", "L. Li", "X. Zhang", "X. Shi", "J. Huang", "J. Cai", "S. Jin", "J. Ding"], "venue": "Journal of Applied Geophysics", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Survey on evolutionary computation tech techniques and its application in different fields", "author": ["R. Devi", "E. Barlaskar", "O. Devi", "S. Medhi", "R. Shimray"], "venue": "International Journal on Information Theory ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "A new optimal reactive power planning based on Differential Search Algorithm", "author": ["Y. Amrane", "M. Boudour", "M. Belazzoug"], "venue": "International Journal of Electrical Power & Energy Systems", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "A classification algorithm based on generalized eigenvalue problems", "author": ["M.R. Guarracino", "C. Cifarelli", "O. Seref", "PM. Pardalos"], "venue": "Optimization methods and software", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Multiclass generalized eigenvalue proximal support vector machines", "author": ["M.R. Guarracino", "A. Irpino", "R. Verde"], "venue": "Complex, Intelligent and Software Intensive Systems , IEEE Computer Society", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Improved generalized eigenvalue proximal support vector machine", "author": ["Y. Shao", "N. Deng", "W. Chen", "W. Zhen"], "venue": "IEEE signal processing letters", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust generalized eigenvalue classifier with ellipsoidal uncertainty", "author": ["P. Xanthopoulos", "M.R. Guarracino", "P.M. Pardalos"], "venue": "Ann Oper Res", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Solutions of Ill posed problems", "author": ["A.N. Tikhonov", "V.Y. Arsenin"], "venue": "New York: john wiley and sons", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1977}, {"title": "The symmetric eigenvalue problem", "author": ["B.N. Parlett"], "venue": "Philadelphia: SIAM", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1998}, {"title": "Improving the classification accuracy using support vector machines (SVMS) with new kernel", "author": ["A. Afifi"], "venue": "Journal of global research in computer science", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 92, "endOffset": 97}, {"referenceID": 1, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 92, "endOffset": 97}, {"referenceID": 2, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 92, "endOffset": 97}, {"referenceID": 3, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 92, "endOffset": 97}, {"referenceID": 4, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 123, "endOffset": 129}, {"referenceID": 5, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 123, "endOffset": 129}, {"referenceID": 6, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 204, "endOffset": 209}, {"referenceID": 7, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 204, "endOffset": 209}, {"referenceID": 8, "context": "This direction includes methods other than classical analysis, based on clustering analysis [1-4], classification analysis [5, 6], and solving problems of generalization, association and finding patterns [7-9].", "startOffset": 204, "endOffset": 209}, {"referenceID": 9, "context": "SVM which is an emerging data classification technique proposed by Vapnik in 1995 [10], and has been widely adopted in various fields of classification, nevertheless it suffers from complexity and parameters selection.", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": "A new method has been introduced in [11] by Olvi L.", "startOffset": 36, "endOffset": 40}, {"referenceID": 11, "context": "Mangasarian which is called the Generalized Eigenvalue Proximal Support Vector Machine (GEPSVM) [12].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "Experimental results in [12] showed the effectiveness of GEPSVM on some public datasets.", "startOffset": 24, "endOffset": 28}, {"referenceID": 12, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 13, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 14, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 15, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 16, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 17, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 18, "context": "There are many approaches have been proposed by researchers for this problem [13-19].", "startOffset": 77, "endOffset": 84}, {"referenceID": 19, "context": "Authors in [20-25] tried to find solution for SVM parameters.", "startOffset": 11, "endOffset": 18}, {"referenceID": 20, "context": "Authors in [20-25] tried to find solution for SVM parameters.", "startOffset": 11, "endOffset": 18}, {"referenceID": 21, "context": "Authors in [20-25] tried to find solution for SVM parameters.", "startOffset": 11, "endOffset": 18}, {"referenceID": 22, "context": "Authors in [20-25] tried to find solution for SVM parameters.", "startOffset": 11, "endOffset": 18}, {"referenceID": 23, "context": "Authors in [20-25] tried to find solution for SVM parameters.", "startOffset": 11, "endOffset": 18}, {"referenceID": 24, "context": "Authors in [20-25] tried to find solution for SVM parameters.", "startOffset": 11, "endOffset": 18}, {"referenceID": 25, "context": "For solving the problem of parameters selection, a new and powerful method which is called Differential Search Algorithm (DSA) [26-31] has been used.", "startOffset": 127, "endOffset": 134}, {"referenceID": 26, "context": "For solving the problem of parameters selection, a new and powerful method which is called Differential Search Algorithm (DSA) [26-31] has been used.", "startOffset": 127, "endOffset": 134}, {"referenceID": 27, "context": "For solving the problem of parameters selection, a new and powerful method which is called Differential Search Algorithm (DSA) [26-31] has been used.", "startOffset": 127, "endOffset": 134}, {"referenceID": 28, "context": "For solving the problem of parameters selection, a new and powerful method which is called Differential Search Algorithm (DSA) [26-31] has been used.", "startOffset": 127, "endOffset": 134}, {"referenceID": 29, "context": "For solving the problem of parameters selection, a new and powerful method which is called Differential Search Algorithm (DSA) [26-31] has been used.", "startOffset": 127, "endOffset": 134}, {"referenceID": 30, "context": "For solving the problem of parameters selection, a new and powerful method which is called Differential Search Algorithm (DSA) [26-31] has been used.", "startOffset": 127, "endOffset": 134}, {"referenceID": 11, "context": "Wild proposed the Generalized Eigenvalue Proximal Support Vector Machine GEPSVM [12] as a generalization of the SVM method.", "startOffset": 80, "endOffset": 84}, {"referenceID": 31, "context": "Due to the simplicity of GEPSVM, many researchers have refined it to improve the general performance of the classifier [32-35].", "startOffset": 119, "endOffset": 126}, {"referenceID": 32, "context": "Due to the simplicity of GEPSVM, many researchers have refined it to improve the general performance of the classifier [32-35].", "startOffset": 119, "endOffset": 126}, {"referenceID": 33, "context": "Due to the simplicity of GEPSVM, many researchers have refined it to improve the general performance of the classifier [32-35].", "startOffset": 119, "endOffset": 126}, {"referenceID": 34, "context": "Due to the simplicity of GEPSVM, many researchers have refined it to improve the general performance of the classifier [32-35].", "startOffset": 119, "endOffset": 126}, {"referenceID": 11, "context": "For this problem, a standard linear SVM is given by a plane halfway between the two parallel bounding planes that bound two disjoint half spaces each containing points mostly of class 1 or 2 [12].", "startOffset": 191, "endOffset": 195}, {"referenceID": 11, "context": "is the two-norm, and it has been assumed in [12] that w , \u03b3 \u2260 0 which implies to Bw \u2212 e \u03b3 \u2260 0.", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "As introduced in [12] the numerator of the minimization problem (2) is the sum of squares of two-norm distances in the (w, \u03b3)-space of points in the first class to the plane xw \u2212 \u03b3 = 0, while the denominator of (2) is the sum of squares of two norm distances in the (w, \u03b3) space of points in the second class to the same plane.", "startOffset": 17, "endOffset": 21}, {"referenceID": 35, "context": "Then Tikhonov regularization term is added [36] to reduce the norm of the problem variables w, \u03b3 that determine the proximal planes (1).", "startOffset": 43, "endOffset": 47}, {"referenceID": 36, "context": "As pointed out in [37], the objective function of (5) is known as the Rayleigh quotient, hence its solution can be obtained by solving a generalized eigenvalues problem.", "startOffset": 18, "endOffset": 22}, {"referenceID": 12, "context": "The works of many researches carried out by adding fuzzy values to the standard SVM [13, 14, 17, 18].", "startOffset": 84, "endOffset": 100}, {"referenceID": 13, "context": "The works of many researches carried out by adding fuzzy values to the standard SVM [13, 14, 17, 18].", "startOffset": 84, "endOffset": 100}, {"referenceID": 16, "context": "The works of many researches carried out by adding fuzzy values to the standard SVM [13, 14, 17, 18].", "startOffset": 84, "endOffset": 100}, {"referenceID": 17, "context": "The works of many researches carried out by adding fuzzy values to the standard SVM [13, 14, 17, 18].", "startOffset": 84, "endOffset": 100}, {"referenceID": 14, "context": "Many attempts for adding fuzzy to GEPSVM have been illustrated as in [15, 16, 19].", "startOffset": 69, "endOffset": 81}, {"referenceID": 15, "context": "Many attempts for adding fuzzy to GEPSVM have been illustrated as in [15, 16, 19].", "startOffset": 69, "endOffset": 81}, {"referenceID": 18, "context": "Many attempts for adding fuzzy to GEPSVM have been illustrated as in [15, 16, 19].", "startOffset": 69, "endOffset": 81}, {"referenceID": 14, "context": "A first attempt to obtain a fuzzy version of the GEPSVM classification is presented in [15, 16].", "startOffset": 87, "endOffset": 95}, {"referenceID": 15, "context": "A first attempt to obtain a fuzzy version of the GEPSVM classification is presented in [15, 16].", "startOffset": 87, "endOffset": 95}, {"referenceID": 14, "context": "In [15] the authors attempt to solve the following problem:", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "Another recently attempt of fuzzy GEPSVM can be found in [19] where the author proposed the following fuzzy function", "startOffset": 57, "endOffset": 61}, {"referenceID": 18, "context": "Where min (d(Ai,CA)) is the minimum distance of the point Ai from the centers in CA, max (d(Ai,CB)) is the maximum distance of the point Ai from the centers CB of the other class, and s is a parameter weighting the contribution of the exponential term to S ,for more detail see [19] .", "startOffset": 278, "endOffset": 282}, {"referenceID": 27, "context": "The main idea of the DSA algorithm was inspired form the migration of superorganisms making use of brownian like motion [28].", "startOffset": 120, "endOffset": 124}, {"referenceID": 27, "context": "EA includes the following techniques [28]: \uf0a7 Ant colony algorithm \uf0a7 Artificial Bee Colony (ABC) algorithm \uf0a7 Cultural algorithms \uf0a7 Differential evolution \uf0a7 Evolutionary algorithms \uf0a7 Evolutionary programming \uf0a7 Evolution strategy \uf0a7 Gene expression programming \uf0a7 Genetic algorithm \uf0a7 Genetic programming \uf0a7 Harmony search \uf0a7 Learnable Evolution Model \uf0a7 Particle swarm optimization \uf0a7 Self-organization such as self-organizing maps \uf0a7 Swarm intelligence The Differential Search Algorithm (DSA) is the most recent addition.", "startOffset": 37, "endOffset": 41}, {"referenceID": 27, "context": "There are a number of computational-intelligence algorithms that model the behaviors of the superorganisms [28-30].", "startOffset": 107, "endOffset": 114}, {"referenceID": 28, "context": "There are a number of computational-intelligence algorithms that model the behaviors of the superorganisms [28-30].", "startOffset": 107, "endOffset": 114}, {"referenceID": 29, "context": "There are a number of computational-intelligence algorithms that model the behaviors of the superorganisms [28-30].", "startOffset": 107, "endOffset": 114}, {"referenceID": 37, "context": "In [38] a new kernel has been introduced the author used the new kernel with the standard SVM, in the presented work we use the new kernel which is called PolyRBF witch is a hybrid between a polynomial kernel and a Gaussian RBF kernel.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "Then the process stops over on the suitable tested position for a temporary time during the migration, the members of the artificial that made such discovery immediately settle at the discovered position and continue their migration from this position [28].", "startOffset": 252, "endOffset": 256}, {"referenceID": 27, "context": "Where, N signifies number of elements in the superorganism (Size of the population), G represents number of maximum generation, and D indicates size of the problem [28-30].", "startOffset": 164, "endOffset": 171}, {"referenceID": 28, "context": "Where, N signifies number of elements in the superorganism (Size of the population), G represents number of maximum generation, and D indicates size of the problem [28-30].", "startOffset": 164, "endOffset": 171}, {"referenceID": 29, "context": "Where, N signifies number of elements in the superorganism (Size of the population), G represents number of maximum generation, and D indicates size of the problem [28-30].", "startOffset": 164, "endOffset": 171}, {"referenceID": 27, "context": "The method to find a stopover site at the remaining between the artificial- organisms may be described by a Brownian-like random walk model [28].", "startOffset": 140, "endOffset": 144}, {"referenceID": 27, "context": "The way of calculation R makes the respective artificial-superorganism to radically change direction in the habitat [28-30].", "startOffset": 116, "endOffset": 123}, {"referenceID": 28, "context": "The way of calculation R makes the respective artificial-superorganism to radically change direction in the habitat [28-30].", "startOffset": 116, "endOffset": 123}, {"referenceID": 29, "context": "The way of calculation R makes the respective artificial-superorganism to radically change direction in the habitat [28-30].", "startOffset": 116, "endOffset": 123}, {"referenceID": 27, "context": "The tested and the most appropriate values for these parameters were conducted by [28].", "startOffset": 82, "endOffset": 86}, {"referenceID": 11, "context": "[12] FSVM", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] FTSVM [18] IGEPSVM", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[13] FTSVM [18] IGEPSVM", "startOffset": 11, "endOffset": 15}, {"referenceID": 35, "context": "[36]", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "92 100 100 100 GA+SVM[20] 94.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "SA+SVM[21] 97.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "PSO+SVM[22] 97.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "CV-ACC[23] 96.", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "Chen [24] 96.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "GA+SVM[20] 94.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "SA+SVM[21] 97.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "PSO+SVM[22] 97.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "CV-ACC[23] 95.", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "Chen [24] 96.", "startOffset": 5, "endOffset": 9}], "year": 2014, "abstractText": "M. H. Marghny Computer Science Department, Faculty of Computers and Information, Assiut University, Egypt. Rasha M. Abd El-Aziz Computer Science Department, Faculty of Science, Assiut University, Egypt. Ahmed I. Taloba Computer Science Department, Faculty of Computers and Information, Assiut University, Egypt . ABSTRACT Support Vector Machine (SVM) is an effective model for many classification problems. However, SVM needs the solution of a quadratic program which require specialized code. In addition, SVM has many parameters, which affects the performance of SVM classifier. Recently, the Generalized Eigenvalue Proximal SVM (GEPSVM) has been presented to solve the SVM complexity. In real world applications data may affected by error or noise, working with this data is a challenging problem. In this paper, an approach has been proposed to overcome this problem. This method is called DSA-GEPSVM. The main improvements are carried out based on the following: 1) a novel fuzzy values in the linear case. 2) A new Kernel function in the nonlinear case. 3) Differential Search Algorithm (DSA) is reformulated to find near optimal values of the GEPSVM parameters and its kernel parameters. The experimental results show that the proposed approach is able to find the suitable parameter values, and has higher classification accuracy compared with some other algorithms.", "creator": "Microsoft\u00ae Office Word 2007"}}}