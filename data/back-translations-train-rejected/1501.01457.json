{"id": "1501.01457", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jan-2015", "title": "Comparison of Selection Methods in On-line Distributed Evolutionary Robotics", "abstract": "In this paper, we study the impact of selection methods in the context of on-line on-board distributed evolutionary algorithms. We propose a variant of the mEDEA algorithm in which we add a selection operator, and we apply it in a taskdriven scenario. We evaluate four selection methods that induce different intensity of selection pressure in a multi-robot navigation with obstacle avoidance task and a collective foraging task. Experiments show that a small intensity of selection pressure is sufficient to rapidly obtain good performances on the tasks at hand. We introduce different measures to compare the selection methods, and show that the higher the selection pressure, the better the performances obtained, especially for the more challenging food foraging task.", "histories": [["v1", "Wed, 7 Jan 2015 12:11:27 GMT  (1791kb)", "http://arxiv.org/abs/1501.01457v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.MA cs.NE cs.RO", "authors": ["i\\~naki fern\\'andez p\\'erez", "amine boumaza", "fran\\c{c}ois charpillet"], "accepted": false, "id": "1501.01457"}, "pdf": {"name": "1501.01457.pdf", "metadata": {"source": "CRF", "title": "Comparison of Selection Methods in On-line Distributed Evolutionary Robotics", "authors": ["I\u00f1aki Fern\u00e1ndez P\u00e9rez"], "emails": ["inaki.fernandez@loria.fr", "amine.boumaza@loria.fr", "francois.charpillet@loria.fr"], "sections": [{"heading": null, "text": "ar Xiv: 150 1st"}, {"heading": "1 Introduction", "text": "In this context, it has to be said that this is an instrument capable of meeting people's needs."}, {"heading": "2 Related Work", "text": "In the following, several distributed ER algorithms are reviewed and the selection mechanisms applied to ensure the desired intensity of selection pressure to drive development are discussed. A common feature of online distributed ER algorithms is that each agent has a controller at a time when he (the active controller) is being executed, and that he applies locally modified copies of this controller to other agents. In this sense, agents have only a partial view of the population in the swarm (a local repository). Fitness mapping or evaluation of individual chromosomes is performed by the agents themselves, and is therefore noisy, as different agents evaluate their active controllers in different conditions. Selection occurs when the active controller is to be replaced by a new one. PGTA (Probabilistic Gene Transfer Algorithm) is introduced, which is often referred to as the first implementation of a distributed ER algorithm."}, {"heading": "3 Algorithms", "text": "In this section, we describe the variant of mEDEA that we have used in our experiments (algorithm 1), which is managed by all the agents of the swarm in a distributed manner. At each time, each agent has a single controller that was randomly initiated at the beginning of evolution. The main difference between the two algorithms is that the algorithm switches between two phases, namely an evaluation phase in which the agent runs, evaluates and transfers his controller to nearby listeners, and a listening phase in which the agent does not move and listens to incoming chromosomes sent by nearby agents. Evaluation and the final Te and Tl hearing phases in which the various robots take place take place take place at different moments. As the various robots are desynchronized, the robots in the evaluation phase are able to propagate their genomes."}, {"heading": "4 Experiments", "text": "We compare these selection methods in a series of simulation experiments for two different tasks, fast forward navigation and collective foraging, two well-studied benchmarks in swarm robotics. All of our experiments were performed on the RoboRobo simulator ([4])."}, {"heading": "4.1 Description", "text": "In all experiments, a swarm of robotic agents is used in a compact environment with static obstacles. Agents also perceive other agents as obstacles. It is assumed that the samplers do not need replacements. All agents are morphologically homogeneous, i.e. they have the same physical properties, the sensors and motors, and they are identified only in the parameters of their respective controllers."}, {"heading": "4.2 Measures", "text": "In this context, the best fitness ever achieved by the swarm is not a reliable measure, as it reflects only \"good\" performance at one point in evolution. These measures summarize information about the swarm over several generations, are used only to evaluate and compare the selection methods, and are calculated once the evolution is complete. An illustrative description of these four measures is shown in Figure 2."}, {"heading": "4.3 Results and discussion", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "5 Conclusions", "text": "This type of algorithm raises several questions about the usefulness of selection pressure (partial population views, noisy fitness values, etc.) We compared four selection methods that cause different intensities of selection pressure for two tasks: obstacle avoidance navigation and collective foraging. Our experiments show that selection pressure greatly improves performance and that the intensity of the selection operator positively correlates with the performance of the swarm. Foraging and navigation can be considered relatively simple tasks, and we believe that more complex and challenging tasks involving deceptive fitness functions could provide further insights into selection and evolutionary dynamics in the distributed case."}], "references": [{"title": "Parallelism and evolutionary algorithms", "author": ["Enrique Alba", "Marco Tomassini"], "venue": "Evolutionary Computation, IEEE Transactions on,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Toward open-ended evolutionary robotics: evolving elementary robotic units able to self-assemble and self-reproduce", "author": ["Raffaele Bianco", "Stefano Nolfi"], "venue": "Connection Science,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Environment-driven Embodied Evolution in a Population of Autonomous Agents", "author": ["Nicolas Bredeche", "Jean-Marc Montanier"], "venue": "PPSN", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Roborobo! a fast robot simulator for swarm and collective robotics", "author": ["Nicolas Bredeche", "Jean-Marc Montanier", "Berend Weel", "Evert Haasdijk"], "venue": "CoRR, abs/1304.2888,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Self-adapting fitness evaluation times for on-line evolution of simulated robots", "author": ["Cristian M Dinu", "Plamen Dimitrov", "Berend Weel", "AE Eiben"], "venue": "In Proc. of GECCO\u201913,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Self-adaptive mutation in on-line, on-board evolutionary robotics", "author": ["AE Eiben", "Giorgos Karafotias", "Evert Haasdijk"], "venue": "In Fourth IEEE Int. Conf. on Self- Adaptive and Self-Organizing Systems Workshop (SASOW),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Introduction to Evolutionary Computing", "author": ["Agoston E. Eiben", "Jim E. Smith"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "An algorithm for distributed on-line, on-board evolutionary robotics", "author": ["Giorgos Karafotias", "Evert Haasdijk", "Agoston Endre Eiben"], "venue": "In Proc. of GECCO", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Evolutionary Robotics: The Biology, Intelligence, and Technology", "author": ["Stefano Nolfi", "Dario Floreano"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Monee: Using parental investment to combine open-ended and task-driven evolution", "author": ["Nikita Noskov", "Evert Haasdijk", "Berend Weel", "A.E. Eiben"], "venue": "In Esparcia-Alca\u0301zar, editor, App. of Evol. Comput.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Evolving communication in robotic swarms using on-line, on-board, distributed evolutionary algorithms", "author": ["LuisE. Pineda", "A.E. Eiben", "Marteen Steen"], "venue": "In Cecilia et al. Chio, editor, Applications of Evolutionary Computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "odneat: an algorithm for distributed online, onboard evolution of robot behaviours", "author": ["Fernando Silva", "Paulo Urbano", "Sancho Oliveira", "Anders Lyhne Christensen"], "venue": "In Artificial Life,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Evolving neural networks through augmenting topologies", "author": ["Kenneth O. Stanley", "Risto Miikkulainen"], "venue": "Evol. Comput.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Spatially structured evolutionary algorithms", "author": ["Marco Tomassini"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Embodied evolution: Distributing an evolutionary algorithm in a population of robots", "author": ["Richard A. Watson", "Sevan G. Ficici", "Jordan B. Pollack"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}], "referenceMentions": [{"referenceID": 8, "context": "Evolutionary robotics (ER) ([9]) aims to design robotic agents\u2019 behaviors using evolutionary algorithms (EA) ([7]).", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "Evolutionary robotics (ER) ([9]) aims to design robotic agents\u2019 behaviors using evolutionary algorithms (EA) ([7]).", "startOffset": 110, "endOffset": 113}, {"referenceID": 14, "context": "On the other hand, on-line evolution ([15]) takes a different approach in which behavior learning is performed during the actual execution of a task.", "startOffset": 38, "endOffset": 42}, {"referenceID": 6, "context": "These operators and their impact on evolutionary dynamics have been extensively studied in off-line contexts ([7]).", "startOffset": 110, "endOffset": 113}, {"referenceID": 4, "context": "Several authors have addressed on-line evolution of robotic agent controllers in different contexts: adaptation to dynamically changing environments ([5]), parameter tuning ([6]), evolution of self-assembly ([2]), communication ([11]), phototaxis and navigation ([8], [12]).", "startOffset": 150, "endOffset": 153}, {"referenceID": 5, "context": "Several authors have addressed on-line evolution of robotic agent controllers in different contexts: adaptation to dynamically changing environments ([5]), parameter tuning ([6]), evolution of self-assembly ([2]), communication ([11]), phototaxis and navigation ([8], [12]).", "startOffset": 174, "endOffset": 177}, {"referenceID": 1, "context": "Several authors have addressed on-line evolution of robotic agent controllers in different contexts: adaptation to dynamically changing environments ([5]), parameter tuning ([6]), evolution of self-assembly ([2]), communication ([11]), phototaxis and navigation ([8], [12]).", "startOffset": 208, "endOffset": 211}, {"referenceID": 10, "context": "Several authors have addressed on-line evolution of robotic agent controllers in different contexts: adaptation to dynamically changing environments ([5]), parameter tuning ([6]), evolution of self-assembly ([2]), communication ([11]), phototaxis and navigation ([8], [12]).", "startOffset": 229, "endOffset": 233}, {"referenceID": 7, "context": "Several authors have addressed on-line evolution of robotic agent controllers in different contexts: adaptation to dynamically changing environments ([5]), parameter tuning ([6]), evolution of self-assembly ([2]), communication ([11]), phototaxis and navigation ([8], [12]).", "startOffset": 263, "endOffset": 266}, {"referenceID": 11, "context": "Several authors have addressed on-line evolution of robotic agent controllers in different contexts: adaptation to dynamically changing environments ([5]), parameter tuning ([6]), evolution of self-assembly ([2]), communication ([11]), phototaxis and navigation ([8], [12]).", "startOffset": 268, "endOffset": 272}, {"referenceID": 14, "context": "PGTA (Probabilistic Gene Transfer Algorithm) introduced by [15], is commonly cited as the first implementation of a distributed on-line ER algorithm.", "startOffset": 59, "endOffset": 63}, {"referenceID": 11, "context": "[12] introduced odNEAT, an on-line distributed version of NEAT (Neuro-Evolution of Augmenting Topologies) ([13]), where each agent has one active chromosome that is transmitted to nearby agents.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[12] introduced odNEAT, an on-line distributed version of NEAT (Neuro-Evolution of Augmenting Topologies) ([13]), where each agent has one active chromosome that is transmitted to nearby agents.", "startOffset": 107, "endOffset": 111}, {"referenceID": 7, "context": "EDEA (Embodied Distributed Evolutionary Algorithm) ([8]), was applied to different swarm robotics tasks: phototaxis, navigation with obstacle avoidance and collective patrolling.", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "With mEDEA (minimal Environment-driven Distributed Evolutionary Algorithm), [3] address evolutionary adaptation with implicit fitness, i.", "startOffset": 76, "endOffset": 79}, {"referenceID": 9, "context": "[10] proposed MONEE (Multi-Objective aNd open-Ended Evolution), an extension to mEDEA adding a task-driven pressure as well as a mechanism (called market) for balancing the distribution of tasks among the population of agents, if several tasks are to be tackled.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "All our experiments were performed on the RoboRobo simulator ([4]).", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "([9]).", "startOffset": 1, "endOffset": 4}, {"referenceID": 2, "context": "As it is the case in ([3]), environmental pressure drives evolution toward behaviors that maximize mating opportunities and thus behaviors that explore the environment, increasing the swarm fitness.", "startOffset": 22, "endOffset": 25}, {"referenceID": 13, "context": "Comparisons with other approaches in which separated subpopulations are evolved, such as spatially structured EA\u2019s ([14]) and island models ([1]), could give further insights on the dynamics of this kind of evolution.", "startOffset": 116, "endOffset": 120}, {"referenceID": 0, "context": "Comparisons with other approaches in which separated subpopulations are evolved, such as spatially structured EA\u2019s ([14]) and island models ([1]), could give further insights on the dynamics of this kind of evolution.", "startOffset": 141, "endOffset": 144}], "year": 2015, "abstractText": "In this paper, we study the impact of selection methods in the context of on-line on-board distributed evolutionary algorithms. We propose a variant of the mEDEA algorithm in which we add a selection operator, and we apply it in a task-driven scenario. We evaluate four selection methods that induce different intensity of selection pressure in a multi-robot navigation with obstacle avoidance task and a collective foraging task. Experiments show that a small intensity of selection pressure is sufficient to rapidly obtain good performances on the tasks at hand. We introduce different measures to compare the selection methods, and show that the higher the selection pressure, the better the performances obtained, especially for the more challenging food foraging task.", "creator": "LaTeX with hyperref package"}}}