{"id": "1501.02484", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2015", "title": "Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart Devices", "abstract": "Smart devices with built-in sensors, computational capabilities, and network connectivity have become increasingly pervasive. The crowds of smart devices offer opportunities to collectively sense and perform computing tasks in an unprecedented scale. This paper presents Crowd-ML, a privacy-preserving machine learning framework for a crowd of smart devices, which can solve a wide range of learning problems for crowdsensing data with differential privacy guarantees. Crowd-ML endows a crowdsensing system with an ability to learn classifiers or predictors online from crowdsensing data privately with minimal computational overheads on devices and servers, suitable for a practical and large-scale employment of the framework. We analyze the performance and the scalability of Crowd-ML, and implement the system with off-the-shelf smartphones as a proof of concept. We demonstrate the advantages of Crowd-ML with real and simulated experiments under various conditions.", "histories": [["v1", "Sun, 11 Jan 2015 18:57:28 GMT  (681kb,D)", "http://arxiv.org/abs/1501.02484v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.DC cs.NI", "authors": ["jihun hamm", "adam champion", "guoxing chen", "mikhail belkin", "dong xuan"], "accepted": false, "id": "1501.02484"}, "pdf": {"name": "1501.02484.pdf", "metadata": {"source": "CRF", "title": "Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart Devices", "authors": ["Jihun Hamm", "Adam Champion", "Guoxing Chen", "Mikhail Belkin", "Dong Xuan"], "emails": [], "sections": [{"heading": null, "text": "I. INTRODUCTION"}, {"heading": "A. Crowdsensing", "text": "These devices feature built-in sensors (e.g. accelerometers, cameras, and microphones), programmable computing capabilities, and Internet connectivity via wireless or cellular networks, including stationary devices such as smart thermostats, and mobile devices such as smartphones or vehicle systems, as well as what is often referred to as the \"Internet of Things.\" Interconnectivity provides mass of smart devices with ways to collect and calculate these collectively on an unprecedented scale. Various applications of crowd sensing have been proposed, including personal health / fitness monitoring, ambient sensors, and road / traffic monitoring (see Section II-A), and the list is currently being expanded. Crowdsensing is primarily used to collect and analyze aggregate data from participants. More complex and useful tasks can be performed beyond the calculation of aggregate statistics by applying crowd-sensing algorithms to crowd-tracking routes."}, {"heading": "B. Privacy", "text": "Privacy is an important issue for crowdsensing applications. By guaranteeing the privacy of participants, a crowdsensing system can address a larger number of potential participants, which increases the benefits of such a system. However, many crowdsensing systems in literature do not use privacy-preserving mechanisms (see Section II-B), and existing mechanisms used in crowdsensing (see [1]) are often difficult to qualitatively compare between different systems or data types. In the last decade, differentiated privacy as a formal and quantifiable measure of data risk has gained popularity when data is published [2] - [4]. In short, differentiated privacy measures how much the result of a process changes due to the presence / absence of an individual subject in the original data. The measure provides a limit on the loss of privacy when data is published, regardless of the content of the data or any prior knowledge that an opponent may have used in crowdsensing (see the differentiated section II)."}, {"heading": "C. Proposed work", "text": "This paper presents Crowd-ML, a system for maintaining privacy that consists of a server and smart devices (see Figure 1). Crowd-ML is a distributed learning framework that enables the retrieval of data with formal processes."}, {"heading": "II. RELATED WORK", "text": "Crowd-ML integrates distributed learning algorithms and differentiated data protection mechanisms into a crowdsensing system. In this section, related work in the field of crowdsensing and learning systems as well as mechanisms to protect privacy are discussed."}, {"heading": "A. Crowdsensing and learning", "text": "There is a lot of crowdsensing work, and we focus on the system aspect of previous work with representative papers (we refer the reader to survey results [7] and [1]). Crowdsensing systems aim to achieve mass collection and extraction of environmental and human data, such as social interactions, movement patterns, and environmental impacts [8]. Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR. Data gathered through crowdsensing can also be used to detect high-grade patterns or to predict variables of interest using crowdsensing."}, {"heading": "B. Privacy-preserving mechanisms", "text": "In order to formally safeguard the privacy of general data types, several mechanisms have been proposed, such as k-anonymity [24] and secure multi-party computation [25], for data disclosure [26] and also for participatory collection [1]. Recently, differential privacy [2] - [4] has been addressed several weaknesses of k-anonymity [27] and has gained popularity as a quantifiable measure of data protection risk. Differential privacy has not generally been adopted in crowdsensing for data-preserving data analysis platforms [28], for disinfection of learned model parameters from data [29], and for the private preservation of data from distributed time series data [17]. Formal and formal data protection mechanisms have not generally been adopted in crowdsensing, but among crowdsensing systems that provide the best protection mechanisms in the previous section ([9] - [13] - [19] - [31], [31] [10]."}, {"heading": "III. CROWD-ML", "text": "In this section we describe our Crowd ML in detail: system, algorithms and privacy mechanisms."}, {"heading": "A. System and workflow", "text": "The goal of CrowdML is to learn a common method in the field of statistical learning [5]. Formally, we leave x-RD a feature vector from pre-processing sensory input such as audio, video, acceleration, etc., and y a target vector from pre-processing sensory input such as audio, video, acceleration, etc., and y a target vector that we can predict from x, such as user activity. For regression, y can be a real number and for classification a discrete label. (..., C) with C classes. We define data as N pairs of (feature vector, target vector vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vget)."}, {"heading": "B. Algorithms", "text": "The number of samples reaches the minibatch size b, the routine checks the current model parameters w from the server and calls device routine 2. Device routine 3 calculates the average course of the samples received from the server and w, checks the information from device routine 3 and sends the sanitized information to the server. Device routine 3 uses laplace noise and exponential mechanisms (in the next section) to clear the average course g, the number of incorrectly classified samples n and the label counts n-ky. Device routines 1-3 are performed independently and asynchronously by multiple devices. Server routine 1 sends current parameters w when the device is requested, and server routine 2 receives checkins (g-routine, n-ky) from devices when it is requested."}, {"heading": "C. Privacy mechanism", "text": "In crowdsensing systems, private user data has leaked in many ways: system administrators / analysts can intentionally violate privacy, or they can unintentionally leak private information when analyzing data. (2)) Init: set ns = 0, ne = 0, nky = 0, k = 1, K = 1, C = 1, E = 1, E = 1, E = 0, E = 0, K = 0, E = 0, E = 0, K = 0, K = 1, K = 1, K = 0, K = 0, K = 0, K = 1, K = 0, K = 0, K = 0, K = 0, K = 0, K = 0, K = 0, K = 0, K = 0, K =, K = 0, K =, K = 0, K =, 0, K =, K = 0, K =, 0, K =, K = 0, K =, 0, K =, K = 0, K =, 0, K =, 0, K =, K =, 0, K =, K =, 0, K =, 0, K =, K =, 0, K =, 0, K =, K =, 0, K =, 0, K =, K =, 0, K =, 0, K =, 0, K =, K =, 0, K =, 0, K =, K =, 0, K =, 0, K =, 0, K =, 0, K =, 0, K =, 0, K =, 0 =, K =, 0, 0, K =, 0 =, K =, 0, K =, 0, 0 =, K =, 0, 0 =, K =, 0 =, K =, 0, K =, 0, 0, K =, K =, 0, 0 =, 0 =, K =, 0, K =, 0, K =, 0, 0, K =, 0 =, K =, K =, 0 =, 0 =, 0, K =, K =, 0, K =, 0, 0, K =, 0, K =, 0, K =, 0, K =, K =, 0, K =, 0, 0 =, 0, K =, K =, K =, 0, 0,"}, {"heading": "1, ...,M, k = 1, ..., C", "text": "In fact, it is a matter of a way in which people are able, in which they are able to move, to move and to move. (...) In fact, it is a matter of a way in which people are able to move. (...) It is as if they are able to move. (...) It is as if they are able to move. (...) It is as if they are able to move. (...) It is as if they are able to hide. (...) It is as if they are able to move. (...)"}, {"heading": "IV. ANALYSIS", "text": "In this section, we analyze the trade-off between privacy and performance and the scalability of Crowd-ML. As discussed in Related Work, most existing crowdsensing systems use purely centralized or purely decentralized approaches, while Crowd-ML adopts a distributed approach. Crowd-ML's design achieves differentiated privacy with low performance loss (O (1 / b), moderate computing load due to its simple optimization method, and reduced communication load and delay (O (1 / b)), with b being the minibatch size."}, {"heading": "A. Privacy vs Performance", "text": "In fact, the more private we make the system, the less precise is the result of analysis / learning. From Theorem 1, Crowd-ML is -differentially private by disturbing the averaged gradients. The performance of an SGD-based learning can be compared by its rate of convergence to the optimal value / to the parameters E [l (t))."}, {"heading": "B. Scalability", "text": "Scalability is determined by calculation and communication loads and latencies on both sides of the device and server, but comparing these factors between centralized, crowd and decentralized learning approaches requires incremental learning approaches. (For all three approaches, we assume that the same pre-processing is performed on each device to calculate functions from raw sensory input or metadata.) On the device side, the incremented learning approach requires generating laplace noise per sample on the device. Crowd and decentralized approaches perform partial and complete learning on the device and require more processing. In particular, crowd-ML requires calculating one gradient per sample, vector summing (for averaging) per sample, and generating Laplace random noise per minibatch. A low-end smart device capable of running floating point updates requires less per sample, although a larger number of samples means a larger number of N samples."}, {"heading": "V. EVALUATION", "text": "In this section, we describe a prototype of Crowd-ML implemented on commercially available Android phones, and activities detection experiments on Android smartphones. We also conduct number and object recognition experiments under different conditions in simulated environments, and demonstrate the benefits of Crowd-ML analyzed in Section IVA. ImplementationWe implement a Crowd-ML prototype with three components: a web portal, commercially available smart devices, and a central server. On the device side, we implement Algorithm 1 on commercially available smartphones as an app running Android OS 4.3 +. Our prototype uses smartphones, but is easily ported to other smart device platforms. On the server side, we implement Algorithm 2 on a Lenovo ThinkCentre M82 machine with a quad-core 3.2 GHz Intel Core i5-3470 CPU and 4 GB RAM with Linux Ubuntu 14.04."}, {"heading": "B. Activity Recognition in Real Environments", "text": "In this experiment, we perform activity detection on smart devices. The purpose of this demonstration is to show that CrowdML works in a real environment = b, so we choose a simple task to detect three types of user activity (\"Still,\" \"On Foot\" and \"In Vehicle\"). We install a prototype Crowd ML application on 7 smartphones (Galaxy Nexus, Nexus S and Galaxy S3) running Android 4.3 or 4.4. The seven smartphones are performed by college students and faculty over a period of a few days. The devices \"triaxial accelerometers are sampled at 20 Hz. In this demonstration, we avoid manual activity label annotation to facilitate data collection, and instead use Google's activity detection service to obtain truth markers. Acceleration magnitudes | = a, a2x + a 2 y + a 2 z are continuously calculated over 3.2 s sliding windows."}, {"heading": "C. Digit/Object Recognition in Simulated Environments", "text": "To test the algorithms under complete control of the parameters, we perform a series of experiments on handwritten digital detection and visual object detection. As the two results are quite similar, we only describe the results of digital detection (object detection result is in Appendix D.) The task is to classify a test image as one of the 10 digital classes. Images from MNIST data are processed with PCA to have a reduced dimension of 50 and L1. In this experiment, we compare the performance of centralized, crowd-ML and decentralized learning approaches using the same data and classifiers (multiclass logistic regression), under other conditions such as privacy level, minibatch size b, and delays."}, {"heading": "VI. CONCLUSION", "text": "In this paper, we proposed Crowd-ML, a framework for machine learning for a variety of smart devices. Compared to other crowdsensing systems, Crowd-ML is a framework that combines sensors, learning and data protection mechanisms, and can build classifiers or predictors of interest from crowdsensing data using the computing power of intelligent devices. Algorithmically, Crowd-ML leverages recent advances in distributed and incremental learning and implements strong, differentiated private mechanisms. We analyzed Crowd-ML and demonstrated that Crowd-ML can surpass centralized approaches, while offering better privacy and scalability, and can also take advantage of larger shared data that decentralized approaches do not offer. We implemented a prototype of Crowd-ML and evaluated the framework with a simple activity detection task in a real environment, as well as larger experiments in simulated environments that demonstrate the benefits of crowd-based crowd design options."}, {"heading": "A. Proof of Theorem 1", "text": "In our algorithms, a device w receives from the server and transmits the averaged gradients g and other information. We assume that the sensitivity of an averaged gradient for logistic regression can easily be achieved by normalizing the data. There are C parameter vectors w1,..., wC for multi-class logistic regression. Let us leave the matrix of the gradient vectors according to the C parameter vectors beg = [g1 g2 \u00b7 \u00b7 gC] = x [P1 \u00b7 \u00b7 Py \u2212 1 \u00b7 PC] + \u03bb [w1 \u00b7 \u00b7 wC] = xM + \u03bb [w1 \u00b7 \u00b7 \u00b7 wC], where Pj = P (y = j | x; w) is the posterior probability and M is a row vector of the Pj's. Without loss of generality, we consider two minibatches D and D \u2032, which differ only in the first sample."}, {"heading": "B. Proof of Theorem 2", "text": "In addition to the averaged gradient, a device sends to the server the number of samples ns, the number of incorrectly classified samples ne, and the labeling counts nky. Disturbance by adding discrete Laplace noise corresponds to a random sample through exponential mechanism [44] with P (n) e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e-e e-e-e-e"}, {"heading": "C. Differential Privacy in Centralized Approach", "text": "For the sake of completeness, we also describe the - differential data protection mechanisms of the centralized approach. In the centralized approach, the data is sent directly to the server. Without a data protection mechanism, an adversary can potentially observe all the data. To prevent this, -differential data protection mechanisms can be enforced by taking the characteristics of (x) = x + z, P (z), E \u2212 x 2 | z |, (15) and also disrupting the labels. To disrupt the labels, we use an exponential mechanism to extract a noisy label containing a true label of p (y), y (y), y (y), y, y (16), in which we use the rating function d (y, y) = I [y = y] and the transmission stage of (y).Theorem 3 (feature and label) \u2022 The transmission of x and y by malfunction (15) and the exponential mechanism (y) is therefore the strongest of (y) and (y)."}, {"heading": "D. Experiments with Visual Object Recognition Task", "text": "We repeat the experiments in Section V-C for an object recognition task using the CIFAR-10 dataset, which consists of images of 10 object types (aircraft, car, bird, cat, deer, dog, frog, horse, ship, truck) collected from [45]. We use 50,000 training images and 10,000 test images of CIFAR10. To calculate the characteristics, we use a Convolutionary Neural Network 9 trained with ImageNet ILSVRC2010 dataset 10, which consists of 1.2 million images of 1000 categories. We apply CIFAR-10 images to the network and use the 4096-dimensional output of the last hidden layer of the network as characteristics. These characteristics are pre-processed with PCA to have a reduced dimension of 100, and are normalized to L1. We use the same setting in Section V-C to crowd-ML on this object recognition task. The results in Figures 9, 8 and 9 are very similar to the results in Figures 9."}], "references": [{"title": "A Survey on Privacy in Mobile Participatory Sensing Applications", "author": ["D. Christin", "A. Reinhardt", "S.S. Kanhere", "M. Hollick"], "venue": "J. Syst. Softw., vol. 84, pp. 1928\u20131946, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1928}, {"title": "Privacy-Preserving Data Mining on Vertically Partitioned Databases", "author": ["C. Dwork", "K. Nissim"], "venue": "Proc. CRYPTO. Springer, 2004. 9https://github.com/jetpacapp/DeepBeliefSDK 10http://www.image-net.org/challenges/LSVRC 0 0.5 1 1.5 2 2.5 x 10  5 0.4 0.5 0.6 0.7 0.8 0.9  1 Iteration  Test error Crowd\u2212ML (b=1,1\u2206) Crowd\u2212ML (b=1,10\u2206) Crowd\u2212ML (b=1,100\u2206) Crowd\u2212ML (b=1,1000\u2206) Crowd\u2212ML (b=20,1\u2206) Crowd\u2212ML (b=20,10\u2206) Crowd\u2212ML (b=20,100\u2206) Crowd\u2212ML (b=20,1000\u2206) Central (batch) Fig. 9: Impact of delays on Crowd-ML with privacy ( \u22121 = 0.1), varying minibatch sizes, and varying delays.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "Theory of Cryptography. Springer, 2006, pp. 265\u2013284.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "Automata, languages and programming. Springer, 2006, pp. 1\u201312.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "The nature of statistical learning theory", "author": ["V. Vapnik"], "venue": "springer,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "The annals of mathematical statistics, pp. 400\u2013407, 1951.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1951}, {"title": "A survey of mobile phone sensing", "author": ["N.D. Lane", "E. Miluzzo", "H. Lu", "D. Peebles", "T. Choudhury", "A.T. Campbell"], "venue": "Comm. Mag., vol. 48, pp. 140\u2013150, September 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Human-Centric Sensing", "author": ["M. Srivastava", "T. Abdelzaher", "B. Szymanski"], "venue": "Phil. Trans. R. Soc. A, vol. 370, pp. 176\u2013197, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Micro- Blog: Sharing and Querying Content Through Mobile Phones and Social Participation", "author": ["S. Gaonkar", "J. Li", "R.R. Choudhury", "L. Cox", "A. Schmidt"], "venue": "Proc. ACM MobiSys, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "PoolView: Stream Privacy for Grassroots Participatory Sensing", "author": ["R.K. Ganti", "N. Pham", "Y.-E. Tsai", "T.F. Abdelzaher"], "venue": "Proc. ACM SenSys, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "BikeNet: A Mobile Sensing System for Cyclist Experience Mapping", "author": ["S.B. Eisenman", "E. Miluzzo", "N.D. Lane", "R.A. Peterson", "G.-S. Ahn", "A.T. Campbell"], "venue": "ACM Trans. Sensor Networks, vol. 6, no. 1, 2009.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "PEIR, the Personal Environmental Impact Report, as a Platform for Participatory Sensing Systems Research", "author": ["M. Mun", "S. Reddy", "K. Shilton", "N. Yau", "J. Burke", "D. Estrin", "M. Hansen", "E. Howard", "R. West", "P. Boda"], "venue": "Proc. ACM MobiSys, 2009.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "How Long to Wait? Predicting Bus Arrival Time with Mobile Phone based Participatory Sensing", "author": ["P. Zhou", "Y. Zheng", "M. Li"], "venue": "Proc. ACM MobiSys, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey on human activity recognition using wearable sensors", "author": ["O.D. Lara", "M.A. Labrador"], "venue": "Communications Surveys & Tutorials, IEEE, vol. 15, no. 3, pp. 1192\u20131209, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "The Jigsaw Continuous Sensing Engine for Mobile Phone Applications", "author": ["H. Lu", "J. Yang", "Z. Liu", "N.D. Lane", "T. Choudhury", "A.T. Campbell"], "venue": "Proc. ACM SenSys, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Lifestreams: A Modular Sense-Making Toolset for Identifying Important Patterns from Everyday Life", "author": ["C.-K. Hsieh", "H. Tangmunarunkit", "F. Alquaddoomi", "J. Jenkins", "J. Kang", "C. Ketcham", "B. Longstaff", "J. Selsky", "B. Dawson", "D. Swendeman", "D. Estrin", "N. Ramanathan"], "venue": "Proc. ACM SenSys, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Soundsense: scalable sound sensing for people-centric applications on mobile phones", "author": ["H. Lu", "W. Pan", "N.D. Lane", "T. Choudhury", "A.T. Campbell"], "venue": "Proceedings of the 7th international conference on Mobile systems, applications, and services. ACM, 2009, pp. 165\u2013178.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Leveraging Graphical Models to Improve Accuracy and Reduce Privacy Risks of Mobile Sensing", "author": ["A. Parate", "M.-C. Chiu", "D. Ganesan", "B.M. Marlin"], "venue": "Proc. ACM MobiSys, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "ACE: Exploiting Correlation for Energy-Efficient and Continuous Context Sensing", "author": ["S. Nath"], "venue": "Proc. ACM MobiSys, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed delayed stochastic optimization.", "author": ["A. Agarwal", "J.C. Duchi"], "venue": "in Proc. NIPS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Optimal distributed online prediction", "author": ["O. Dekel", "R. Gilad-Bachrach", "O. Shamir", "L. Xiao"], "venue": "Proc. ICML, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Stochastic gradient descent with differentially private updates", "author": ["S. Song", "K. Chaudhuri", "A.D. Sarwate"], "venue": "Proc. IEEE GlobalSIP, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey of computational location privacy", "author": ["J. Krumm"], "venue": "Personal and Ubiquitous Computing, vol. 13, no. 6, pp. 391\u2013399, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "k-Anonymity: A Model for Protecting Privacy", "author": ["L. Sweeney"], "venue": "Int. J. Uncertainty, Fuzziness, Knowl. Syst., vol. 10, no. 5, pp. 557\u2013570, 2002.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Protocols for secure computations", "author": ["A.C. Yao"], "venue": "2013 IEEE Symp. Found. Comp. Sci. IEEE, 1982, pp. 160\u2013164.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Privacy-preserving data publishing: A survey of recent developments", "author": ["B. Fung", "K. Wang", "R. Chen", "P.S. Yu"], "venue": "ACM Comp. Surveys (CSUR), vol. 42, no. 4, p. 14, 2010.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Composition attacks and auxiliary information in data privacy", "author": ["S.R. Ganta", "S.P. Kasiviswanathan", "A. Smith"], "venue": "Proc. ACM SIGKDD. ACM, 2008, pp. 265\u2013273.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Privacy integrated queries: an extensible platform for privacy-preserving data analysis", "author": ["F.D. McSherry"], "venue": "Proc. ACM SIGMOD. ACM, 2009, pp. 19\u201330.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "JMLR, vol. 12, pp. 1069\u20131109, 2011.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Energy- Efficient Continuous Activity Recognition on Mobile Phones", "author": ["Z. Yan", "V. Subbaraju", "D. Chakraborty", "A. Misra", "K. Aherer"], "venue": "Proc. ISWC, 2012.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "A Public Domain Dataset for Human Activity Recognition Using Smartphones", "author": ["D. Anguita", "A. Ghio", "L. Oneto", "X. Parra", "J.L. Reyes-Ortiz"], "venue": "Proc. ESANN, 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Stochastic gradient descent tricks", "author": ["L. Bottou"], "venue": "Neural Networks: Tricks of the Trade. Springer, 2012, pp. 421\u2013436.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "Annal Math. Stat., pp. 400\u2013407, 1951.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1951}, {"title": "Online learning and stochastic approximations", "author": ["L. Bottou"], "venue": "On-line learning in neural networks, vol. 17, p. 9.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 0}, {"title": "Primal-dual subgradient methods for convex problems", "author": ["Y. Nesterov"], "venue": "Math. Program., vol. 120, no. 1, pp. 221\u2013259, Apr. 2009.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "A stochastic gradient method with an exponential convergence rate for finite training sets", "author": ["N.L. Roux", "M. Schmidt", "F.R. Bach"], "venue": "Proc. NIPS, 2012, pp. 2663\u20132671.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "COLT 2010, p. 257, 2010.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}, {"title": "No more pesky learning rates", "author": ["T. Schaul", "S. Zhang", "Y. LeCun"], "venue": "Proceedings of The 30th International Conference on Machine Learning, 2013, pp. 343\u2013351.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "A Discrete Analogue of the Laplace distribution", "author": ["S. Inusah", "T.J. Kozubowski"], "venue": "J. Stat. Plan. Inf., vol. 136, no. 3, pp. 1090\u20131102, 2006.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization, vol. 19, no. 4, pp. 1574\u20131609, 2009.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes", "author": ["O. Shamir", "T. Zhang"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML-13), S. Dasgupta and D. Mcallester, Eds., vol. 28, no. 1, 2013, pp. 71\u201379.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Better mini-batch algorithms via accelerated gradient methods", "author": ["A. Cotter", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "Advances in Neural Information Processing Systems, 2011, pp. 1647\u20131655.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Neural network learning: Theoretical foundations", "author": ["M. Anthony", "P.L. Bartlett"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1999}, {"title": "Mechanism design via differential privacy", "author": ["F. McSherry", "K. Talwar"], "venue": "Proc. IEEE FOCS, 2007.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Tech. Rep., 2009.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "However, many crowdsensing systems in the literature do not employ any privacy-preserving mechanism (see Section II-B), and existing mechanisms used in crowdsensing (see [1]) are often difficult to compare qualitatively across different systems or data types.", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "In the last decade, differential privacy has gained popularity as a formal and quantifiable measure of privacy risk in data publishing [2]\u2013[4].", "startOffset": 135, "endOffset": 138}, {"referenceID": 3, "context": "In the last decade, differential privacy has gained popularity as a formal and quantifiable measure of privacy risk in data publishing [2]\u2013[4].", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "Optimal parameters of a classifier or predictor are found by minimizing the risk function associated with a given task [5] (see Section III-A for details).", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "Specifically, the framework finds optimal parameters by incrementally minimizing the risk function using a variant of stochastic (sub)gradient descent (SGD) [6].", "startOffset": 157, "endOffset": 160}, {"referenceID": 6, "context": "There is a vast amount of work in crowdsensing, and we focus on the system aspect of previous work with representative papers (we refer the reader to survey papers [7] and [1]).", "startOffset": 164, "endOffset": 167}, {"referenceID": 0, "context": "There is a vast amount of work in crowdsensing, and we focus on the system aspect of previous work with representative papers (we refer the reader to survey papers [7] and [1]).", "startOffset": 172, "endOffset": 175}, {"referenceID": 7, "context": "Crowdsensing systems aim to achieve mass collection and mining of environmental and human-centric data such as social interactions, political issues of interest, exercise patterns, and people\u2019s impact on the environment [8].", "startOffset": 220, "endOffset": 223}, {"referenceID": 8, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 44, "endOffset": 47}, {"referenceID": 9, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "Applications of learning applied to crowdsensing include learning of bus waiting times [13] and recognizing user activities (see [14] for a review).", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "Applications of learning applied to crowdsensing include learning of bus waiting times [13] and recognizing user activities (see [14] for a review).", "startOffset": 129, "endOffset": 133}, {"referenceID": 14, "context": "Jigsaw [15] and Lifestreams [16] also use pattern recognition in sensed data from mobile devices.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "Jigsaw [15] and Lifestreams [16] also use pattern recognition in sensed data from mobile devices.", "startOffset": 28, "endOffset": 32}, {"referenceID": 16, "context": "For example, SoundSense [17] learns a classifier on a smartphone to recognized various audio events without communicating with the back-end.", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "Mixed centralized and decentralized approaches are also used in [18], [19], where a portion of computation is performed off-line on a server.", "startOffset": 64, "endOffset": 68}, {"referenceID": 18, "context": "Mixed centralized and decentralized approaches are also used in [18], [19], where a portion of computation is performed off-line on a server.", "startOffset": 70, "endOffset": 74}, {"referenceID": 17, "context": "CQue [18] provides a query interface for privacyaware probabilistic learning of users\u2019 contexts, and ACE [19] uses static association rules to learn users\u2019 contexts.", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "CQue [18] provides a query interface for privacyaware probabilistic learning of users\u2019 contexts, and ACE [19] uses static association rules to learn users\u2019 contexts.", "startOffset": 105, "endOffset": 109}, {"referenceID": 19, "context": "Crowd-ML also builds on recent advances in incremental distributed learning [20], [21], which show that a near-optimal convergence rate is achievable despite communication delays.", "startOffset": 76, "endOffset": 80}, {"referenceID": 20, "context": "Crowd-ML also builds on recent advances in incremental distributed learning [20], [21], which show that a near-optimal convergence rate is achievable despite communication delays.", "startOffset": 82, "endOffset": 86}, {"referenceID": 21, "context": "A privacy-preserving stochastic gradient descent method is presented briefly in [22].", "startOffset": 80, "endOffset": 84}, {"referenceID": 22, "context": "In particular, preserving privacy of users\u2019 locations has been studied by many researchers (see [23] for a survey).", "startOffset": 96, "endOffset": 100}, {"referenceID": 23, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 91, "endOffset": 95}, {"referenceID": 24, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 130, "endOffset": 134}, {"referenceID": 25, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 175, "endOffset": 179}, {"referenceID": 0, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 215, "endOffset": 218}, {"referenceID": 1, "context": "Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk.", "startOffset": 31, "endOffset": 34}, {"referenceID": 3, "context": "Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk.", "startOffset": 35, "endOffset": 38}, {"referenceID": 26, "context": "Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk.", "startOffset": 87, "endOffset": 91}, {"referenceID": 27, "context": "Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17].", "startOffset": 81, "endOffset": 85}, {"referenceID": 28, "context": "Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 16, "context": "Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17].", "startOffset": 221, "endOffset": 225}, {"referenceID": 8, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 63, "endOffset": 66}, {"referenceID": 12, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 67, "endOffset": 71}, {"referenceID": 14, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 73, "endOffset": 77}, {"referenceID": 18, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 78, "endOffset": 82}, {"referenceID": 29, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 84, "endOffset": 88}, {"referenceID": 30, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 90, "endOffset": 94}, {"referenceID": 9, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 102, "endOffset": 106}, {"referenceID": 11, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 108, "endOffset": 112}, {"referenceID": 17, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 114, "endOffset": 118}, {"referenceID": 9, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 161, "endOffset": 165}, {"referenceID": 4, "context": "A widerange of classifiers or predictors can be learned by minimizing an empirical risk associated with a given task, a common method in statistical learning [5].", "startOffset": 158, "endOffset": 161}, {"referenceID": 31, "context": ", regression, logistic regression, and Support Vector Machine (see [32] for more examples).", "startOffset": 67, "endOffset": 71}, {"referenceID": 32, "context": "In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34].", "startOffset": 59, "endOffset": 63}, {"referenceID": 31, "context": "In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34].", "startOffset": 160, "endOffset": 164}, {"referenceID": 33, "context": "In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34].", "startOffset": 166, "endOffset": 170}, {"referenceID": 34, "context": "Remark 3: In Server Routine 2, more recent update methods [35], [36] can be used in place of the simple update rule (3) without affecting differential privacy nor changing device routines.", "startOffset": 58, "endOffset": 62}, {"referenceID": 35, "context": "Remark 3: In Server Routine 2, more recent update methods [35], [36] can be used in place of the simple update rule (3) without affecting differential privacy nor changing device routines.", "startOffset": 64, "endOffset": 68}, {"referenceID": 36, "context": "Similarly, adaptive learning rates [37], [38] can be used in place of (5), which can provide a robustness to large gradients from outlying or malignant devices.", "startOffset": 35, "endOffset": 39}, {"referenceID": 37, "context": "Similarly, adaptive learning rates [37], [38] can be used in place of (5), which can provide a robustness to large gradients from outlying or malignant devices.", "startOffset": 41, "endOffset": 45}, {"referenceID": 2, "context": "A basic result from the definition of differential privacy is that a vector-valued function f with sensitivity S(f) can be made -differentially private [3] by adding an independent Laplace noise vector z1", "startOffset": 152, "endOffset": 155}, {"referenceID": 38, "context": "To sanitize ne and ny , we add \u2018discrete\u2019 Laplace noise [39] as follows:", "startOffset": 56, "endOffset": 60}, {"referenceID": 39, "context": "The performance of an SGD-based learning can be represented by its rate of convergence to the optimal value/parameters E[l(w(t))\u2212l(w\u2217)] at iteration t, which in turn depends on the properties of the loss l(\u00b7) (such as Lipschitzcontinuity and strong-convexity) and the step size \u03b7(t), with the best known rate being O(1/t) [40].", "startOffset": 322, "endOffset": 326}, {"referenceID": 40, "context": "When other conditions are the same, the convergence rate is roughly proportional E[l(w(t)) \u2212 l(w\u2217)] \u221d G to the amount of noise in the estimated gradient G = supt E[\u2016\u011d(t)\u2016] [41].", "startOffset": 172, "endOffset": 176}, {"referenceID": 42, "context": "For example, it is known from the VC-theory for binary classification problems that the upper-bound of the estimation error with a 1/M -times smaller sample size is \u221a M/ logM -times larger [43].", "startOffset": 189, "endOffset": 193}, {"referenceID": 41, "context": "3although a larger batch size means fewer updates given the same number of samples N , and too large a batch size can negatively affect the convergence rate (see [42] for discussion).", "startOffset": 162, "endOffset": 166}, {"referenceID": 19, "context": "Recent work in distributed incremental update [20], [21] also shows that a near-optimal convergence rate is achievable despite delays.", "startOffset": 46, "endOffset": 50}, {"referenceID": 20, "context": "Recent work in distributed incremental update [20], [21] also shows that a near-optimal convergence rate is achievable despite delays.", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "[21] shows that delayed incremental updates are scalable with M by adapting the minibatch size.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": ", \u011d(T ) is the same as the sensitivity of a single \u011d(t), and the -differential privacy follows from Proposition 1 of [3].", "startOffset": 117, "endOffset": 120}, {"referenceID": 43, "context": "Perturbation by adding discrete Laplace noise is equivalent to random sampling by exponential mechanism [44] with P (n\u0302e|ne) \u221d e\u2212 e 2 |n\u0302e\u2212ne|, n\u0302e \u2208 Z.", "startOffset": 104, "endOffset": 108}, {"referenceID": 43, "context": "As with multiple gradients, the sensitivity of multiples sets of (n\u0302e, n\u0302y) is the same as the sensitivity of a single set, and e-differential privacy follows from Theorem 6 of [44].", "startOffset": 177, "endOffset": 181}, {"referenceID": 38, "context": "and has zeromean and constant variance 2e \u2212 e/2 (1\u2212e\u2212 e/2)2 [39], the estimate of error rate converge almost surely to the true error rate with vanishing variances as T increases.", "startOffset": 60, "endOffset": 64}, {"referenceID": 2, "context": "From Proposition 1 of [3] and Theorem 6 of [44], respectively, we achieve x- and ydifferential privacy of data.", "startOffset": 22, "endOffset": 25}, {"referenceID": 43, "context": "From Proposition 1 of [3] and Theorem 6 of [44], respectively, we achieve x- and ydifferential privacy of data.", "startOffset": 43, "endOffset": 47}, {"referenceID": 44, "context": "We repeat the experiments in Section V-C for an object recognition task using CIFAR-10 dataset, which consists of images of 10 types of objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) collected by [45].", "startOffset": 228, "endOffset": 232}], "year": 2015, "abstractText": "Smart devices with built-in sensors, computational capabilities, and network connectivity have become increasingly pervasive. The crowds of smart devices offer opportunities to collectively sense and perform computing tasks in an unprecedented scale. This paper presents Crowd-ML, a privacy-preserving machine learning framework for a crowd of smart devices, which can solve a wide range of learning problems for crowdsensing data with differential privacy guarantees. Crowd-ML endows a crowdsensing system with an ability to learn classifiers or predictors online from crowdsensing data privately with minimal computational overheads on devices and servers, suitable for a practical and large-scale employment of the framework. We analyze the performance and the scalability of Crowd-ML, and implement the system with off-the-shelf smartphones as a proof of concept. We demonstrate the advantages of Crowd-ML with real and simulated experiments under various conditions.", "creator": "LaTeX with hyperref package"}}}