{"id": "1501.02560", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jan-2015", "title": "Belief Hierarchical Clustering", "abstract": "In the data mining field many clustering methods have been proposed, yet standard versions do not take into account uncertain databases. This paper deals with a new approach to cluster uncertain data by using a hierarchical clustering defined within the belief function framework. The main objective of the belief hierarchical clustering is to allow an object to belong to one or several clusters. To each belonging, a degree of belief is associated, and clusters are combined based on the pignistic properties. Experiments with real uncertain data show that our proposed method can be considered as a propitious tool.", "histories": [["v1", "Mon, 12 Jan 2015 07:55:41 GMT  (229kb,D)", "http://arxiv.org/abs/1501.02560v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["wiem maalel", "kuang zhou", "arnaud martin", "zied elouedi"], "accepted": false, "id": "1501.02560"}, "pdf": {"name": "1501.02560.pdf", "metadata": {"source": "CRF", "title": "Belief Hierarchical Clustering", "authors": ["Wiem Maalel", "Kuang Zhou", "Arnaud Martin", "Zied Elouedi"], "emails": ["Wiem.Maalel@gmail.com", "kzhoumath@163.com", "Arnaud.Martin@univ-rennes1.fr", "Zied.Elouedi@gmx.fr"], "sections": [{"heading": null, "text": "Keywords: clustering, hierarchical clustering, faith function, faith clustering"}, {"heading": "1 Introduction", "text": "Due to the increase of imperfect data, the decision-making process becomes more difficult. To accomplish this, data analysis is applied in various fields. Clustering is mostly used in data mining and aims to group a number of similar objects into clusters. In this context, there are many cluster algorithms that are divided into two main families: the first family includes the partitioning methods based on density, such as the kmeans algorithm [6], which is widely used thanks to its convergence speed. It divides the data into k clusters represented by its centers; the second family includes the hierarchical cluster methods, the hierarchical ascendant clusters (HAC), which consists of constructing clusters recursively by partitioning the objects in a bottom-up way. This process leads to good result visualizations, but it still has a non-linear complexity."}, {"heading": "2 Ascendant hierarchical clustering", "text": "This method consists of agglomerating the narrow clusters to finally have a cluster that contains all objects xj (where j = 1,.., N). Consider PK = {C1,..., CK} the set of clusters. IfK = N, C1 = x1,..., CN = xN. Then, in all the steps of clustering, we will move from a partition PK to a partition PK \u2212 1. The result is described by a hierarchical cluster tree (dendrogram), where the nodes represent successive mergers and the height of the nodes represent the value of the distance between two objects, which gives a concrete meaning at the level of the nodes inscribed as an \"indexed hierarchy.\" The latter is usually indexed by the values of the distances (or dissimilarity) between these elements."}, {"heading": "3 Basis on the theory of belief functions", "text": "In this section, we will briefly discuss the main concepts used in our method that underlies the theory of faith. [9] This is a finite quantity that reflects a state of partial knowledge that can be represented by a basic faith assignment defined as: m (A) > 0, 1) \u2022 A m (A) = 1 (4) The value m (A) is called the basic faith assignment (bbm) of A. The subset A-2 is defined as the central element when m (A) > 0. One of the important rules in faith theory is the conjunctive rule, which consists of the combination of two basic faith assignments m1 and m2, which are generated by two different \u00b7 \u00b7 \u00b7 reliable sources of information defined as follows: m1 \u00b2 m2 (C) = 4 m \u00b2 beta = C m1 (A) \u00b7 m \u00b2 (A) \u2022 B (A) \u2022 m \u00b2 (B), the two basic faith assignments A \u00b7 B (A) (A) (A) (A) m1 = 1 (A) m \u00b2 (B)."}, {"heading": "4 Belief hierarchical clustering", "text": "In order to find a way to develop a hierarchical clustering, we choose different levels: on the one hand the object level, on the other the cluster level. (...) At the beginning, for which we have both objects, we can define a mass function for each object, inspired by the k-next method, which is defined as follows: mI (xj) = a degree of faith is assigned. (...) We will define a mass function for each object defined by the k-next neighbors: mI (xj) = a degree of faith is assigned. (...) We will consider it as the Euclidean distance, and the frame of discretion is given by us. (...) Where we are 6 = j, we are two parameters that we can optimize. (...) D can be considered as the Euclidean distance, and the frame of discretion is given by us."}, {"heading": "5 Experimentations", "text": "This year, it will be able to put itself at the top of the group."}, {"heading": "6 Conclusion", "text": "Finally, we have introduced a new cluster method that uses the hierarchical paradigm to implement uncertainty in the belief functional framework. This method focuses on the fact that an object can belong to several clusters. It aims to merge clusters based on its pignistic probability. Our method has been proven using data sets and the corresponding results have clearly shown its efficiency. The complexity of the algorithms has proven to be the common problem of belief functioning theory."}], "references": [{"title": "Fcm: The fuzzy c-means clustering algorithm", "author": ["J.C. Bezdek", "R. Ehrlich", "W. Fulls"], "venue": "Computers and Geosciences 10(2-3), 191\u2013203", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1984}, {"title": "A k-Nearest Neighbor Classification Rule Based on Dempster-Shafer Theory", "author": ["T. Den\u0153ux"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans 25(5), 804\u2013813", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "EVCLUS: Evidential Clustering of Proximity Data", "author": ["T. Den\u0153ux", "M. Masson"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics 34(1), 95\u2013 109", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Clustering approach using belief function theory", "author": ["S. ben Hariz", "Z. Elouedi", "K. Mellouli"], "venue": "AIMSA. pp. 162\u2013171", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "The elements of statistical learning; data mining, inference and prediction", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman", "J. Franklin"], "venue": "Springer Verlag, New York", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Some methods for classification and analysis of multivariate observations", "author": ["J. MacQueen"], "venue": "In Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability 11", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1967}, {"title": "Clustering interval-valued proximity data using belief functions", "author": ["M. Masson", "T. Den\u0153ux"], "venue": "Pattern Recognition Letters 25, 163\u2013171", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Clustering belief functions based on attracting and conflicting metalevel evidence", "author": ["J. Schubert"], "venue": "Bouchon-Meunier, B., Foulloy, L., Yager, R. (eds.) Intelligent Systems for Information Processing: From Representation to Applications. Elsevier Science", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Mathematical Theory of evidence", "author": ["G. Shafer"], "venue": "Princeton Univ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1976}, {"title": "The Transferable Belief Model", "author": ["P. Smets", "R. Kennes"], "venue": "Artificial Intelligent 66, 191\u2013234", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}, {"title": "An Evidence-Theoric k-NN Rule with Parameter Optimization", "author": ["L.M. Zouhal", "T. Den\u0153ux"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics - Part C: Applications and Reviews 28(2), 263\u2013271", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 5, "context": "In this context, many clustering algorithms exist and are categorized into two main families: The first family involves the partitioning methods based on density such as kmeans algorithm [6] that is widely used thanks to its convergence speed.", "startOffset": 187, "endOffset": 190}, {"referenceID": 4, "context": "The second family includes the hierarchical clustering methods such as the top-down and the Hierarchical Ascendant Clustering (HAC) [5].", "startOffset": 132, "endOffset": 135}, {"referenceID": 0, "context": "Among them, the Fuzzy C-Means [1] which consists in assigning a membership to each data point ar X iv :1 50 1.", "startOffset": 30, "endOffset": 33}, {"referenceID": 2, "context": "Patently, Evidential cMeans (ECM) [3], [7] is deemed to be a very fateful method.", "startOffset": 34, "endOffset": 37}, {"referenceID": 6, "context": "Patently, Evidential cMeans (ECM) [3], [7] is deemed to be a very fateful method.", "startOffset": 39, "endOffset": 42}, {"referenceID": 3, "context": "Accordingly, the belief k-Modes method [4] is a popular method, which builds K groups characterized by uncertain attribute values and provides a classification of new instances.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "Schubert has also found a clustering algorithm [8] which uses the mass on the empty set to build a classifier.", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "In this Section, we briefly review the main concepts that will be used in our method that underlies the theory of belief functions [9] as interpreted in the Transferable Belief Model (TBM) [10].", "startOffset": 131, "endOffset": 134}, {"referenceID": 9, "context": "In this Section, we briefly review the main concepts that will be used in our method that underlies the theory of belief functions [9] as interpreted in the Transferable Belief Model (TBM) [10].", "startOffset": 189, "endOffset": 193}, {"referenceID": 0, "context": "\u03a9 is a finite set that reflects a state of partial knowledge that can be represented by a basis belief assignment defined as: m : 2 \u2192 [0, 1] \u2211", "startOffset": 134, "endOffset": 140}, {"referenceID": 9, "context": "In order to ensure the decision making, beliefs are transformed into probability measures recorded BetP, and defined as follows [10]:", "startOffset": 128, "endOffset": 132}, {"referenceID": 1, "context": "Hence, we define a mass function for each object xi, inspired from the k-nearest neighbors [2] method which is defined as follows:", "startOffset": 91, "endOffset": 94}, {"referenceID": 10, "context": "where i 6= j, \u03b1 and \u03b3 are two parameters we can optimize [11], d can be considered as the Euclidean distance, and the frame of discernment is given by \u03a9i = {x1, .", "startOffset": 57, "endOffset": 61}, {"referenceID": 6, "context": "a and analyzed in [7].", "startOffset": 18, "endOffset": 21}], "year": 2015, "abstractText": "In the data mining field many clustering methods have been proposed, yet standard versions do not take into account uncertain databases. This paper deals with a new approach to cluster uncertain data by using a hierarchical clustering defined within the belief function framework. The main objective of the belief hierarchical clustering is to allow an object to belong to one or several clusters. To each belonging, a degree of belief is associated, and clusters are combined based on the pignistic properties. Experiments with real uncertain data show that our proposed method can be considered as a propitious tool.", "creator": "LaTeX with hyperref package"}}}