{"id": "1501.03302", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jan-2015", "title": "Hard to Cheat: A Turing Test based on Answering Questions about Images", "abstract": "Progress in language and image understanding by machines has sparkled the interest of the research community in more open-ended, holistic tasks, and refueled an old AI dream of building intelligent machines. We discuss a few prominent challenges that characterize such holistic tasks and argue for \"question answering about images\" as a particular appealing instance of such a holistic task. In particular, we point out that it is a version of a Turing Test that is likely to be more robust to over-interpretations and contrast it with tasks like grounding and generation of descriptions. Finally, we discuss tools to measure progress in this field.", "histories": [["v1", "Wed, 14 Jan 2015 10:38:43 GMT  (168kb)", "https://arxiv.org/abs/1501.03302v1", "Also presented on: AAAI-15 Workshop: Beyond Turing the Turing Test"], ["v2", "Thu, 15 Jan 2015 10:18:54 GMT  (168kb)", "http://arxiv.org/abs/1501.03302v2", "Presented in AAAI-15 Workshop: Beyond the Turing Test"]], "COMMENTS": "Also presented on: AAAI-15 Workshop: Beyond Turing the Turing Test", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.CV cs.LG", "authors": ["mateusz malinowski", "mario fritz"], "accepted": false, "id": "1501.03302"}, "pdf": {"name": "1501.03302.pdf", "metadata": {"source": "CRF", "title": "Hard to Cheat: A Turing Test based on Answering Questions about Images", "authors": ["Mateusz Malinowski"], "emails": ["mmalinow@mpi-inf.mpg.de", "mfritz@mpi-inf.mpg.de"], "sections": [{"heading": null, "text": "ar Xiv: 150 1.03 302v 2 [cs.A I] 1 5Ja n20 15"}, {"heading": "Introduction", "text": "Advances in machine perception and understanding of language (e.g., Krizhevsky et al., 2012; Liang et al., 2013) have inspired researchers to work on holistic tasks that link the two modalities in a complex chain of perception, representation, and conclusion, such as grounding (Krishnamurthy et al., 2013), speech generation (Karpaththy and Fei-Fei, 2014; Donahue et al., 2014), retrieval (Karpathy et al., 2014; Malinowski and Fritz, 2014b), and answering questions about images (Malinowski and Fritz, 2014a, c). Recently, Malinowski and Fritz (2014a) have presented an approach to answering questions about images that resembles the famous Turing test (Turing, 1950), while Malinowski and Fritz (2014c) discuss some of the related challenges and problems further. Below, we will delve the data collection, the challenge, and the interpretation of these tasks, as well as others."}, {"heading": "Challenges", "text": "In this section, we have filtered out some prominent topics that require common thinking about language and visual inputs; we also argue that holistic architectures can benefit from common sense; finally, we discuss challenges in data collection and how the task differs from other known tasks; Vision and Language Scalability: Vision and language systems establish any internal representation in an external world that serves as a common reference point for machines and humans; and human conceptualization divides these perceptions into different instances, categories, and spatio-temporal concepts; architectures that aim to reproduce this space of human concepts must capture the same diversity and therefore apply it to thousands of concepts.Concept Ambiguity: As the number of categories grows, semantic boundaries become blurred, and therefore ambiguous."}, {"heading": "Evaluation of architectures", "text": "Measuring progress on holistic tasks requires identifying their objectives. For example, a suitable metric for \"answering questions about images\" should evaluate architectures based on the answers produced, but not on intermediate results such as recognitions or logical forms. For a Visual Turing Challenge, we are looking for a metric that fulfills several characteristics. Most importantly, automation: Assessing answers to such complex tasks as answering questions requires a fairly deep understanding of the natural language, concepts involved, and hidden intentions of the questioner. The ideal but impractical metric would be to assess each individual answer of each architecture individually. Therefore, we strive for an automatic approach so that we can evaluate different holistic architectures on a scale. Malinowski and Fritz (2014a) suggested limiting the response space in order to achieve this goal while fully evaluating the questions. Social consensus: The complex tasks we are interested in are inherently ambiguous."}, {"heading": "Summary", "text": "The aim of this paper is to stimulate discussion of challenges and benchmarking architectures on holistic tasks. We also argue that \"answering questions about images\" is a holistic task that offers several advantages over related tasks. Thus, it is probably less susceptible to \"fraud\" through over-interpretation than a traditional Turing test, the annotation process is comprehensible through crowd-sourced question and answer pairs, and the task does not impose artificial internal representation on the methods. Our recent efforts and results to establish a Visual Turing Test can be found on our website: www.d2.mpi-inf.mpg.de / visual-turing-challenge."}], "references": [{"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["J. Donahue", "L.A. Hendricks", "S. Guadarrama", "M. Rohrbach", "S. Venugopalan", "K. Saenko", "T. Darrell"], "venue": null, "citeRegEx": "Donahue et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Donahue et al\\.", "year": 2014}, {"title": "The pascal visual object classes (voc) challenge", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": null, "citeRegEx": "Everingham et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2010}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": null, "citeRegEx": "Karpathy and Fei.Fei,? \\Q2014\\E", "shortCiteRegEx": "Karpathy and Fei.Fei", "year": 2014}, {"title": "Deep fragment embeddings for bidirectional image sentence mapping", "author": ["A. Karpathy", "A. Joulin", "L. Fei-Fei"], "venue": null, "citeRegEx": "Karpathy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2014}, {"title": "Jointly learning to parse and perceive: Connecting natural language to the physical world. TACL", "author": ["J. Krishnamurthy", "T. Kollar"], "venue": null, "citeRegEx": "Krishnamurthy and Kollar,? \\Q2013\\E", "shortCiteRegEx": "Krishnamurthy and Kollar", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Space in language and cognition: Explorations in cognitive diversity, volume 5", "author": ["S.C. Levinson"], "venue": null, "citeRegEx": "Levinson,? \\Q2003\\E", "shortCiteRegEx": "Levinson", "year": 2003}, {"title": "Learning dependency-based compositional semantics", "author": ["P. Liang", "M.I. Jordan", "D. Klein"], "venue": "Computational Linguistics", "citeRegEx": "Liang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2013}, {"title": "A multi-world approach to question answering about real-world scenes based on uncertain input", "author": ["M. Malinowski", "M. Fritz"], "venue": null, "citeRegEx": "Malinowski and Fritz,? \\Q2014\\E", "shortCiteRegEx": "Malinowski and Fritz", "year": 2014}, {"title": "A pooling approach to modelling spatial relations for image retrieval and annotation", "author": ["M. Malinowski", "M. Fritz"], "venue": null, "citeRegEx": "Malinowski and Fritz,? \\Q2014\\E", "shortCiteRegEx": "Malinowski and Fritz", "year": 2014}, {"title": "Towards a visual turing challenge", "author": ["M. Malinowski", "M. Fritz"], "venue": "In Learning Semantics (NIPS workshop)", "citeRegEx": "Malinowski and Fritz,? \\Q2014\\E", "shortCiteRegEx": "Malinowski and Fritz", "year": 2014}, {"title": "Wordnet: a lexical database for english", "author": ["G.A. Miller"], "venue": null, "citeRegEx": "Miller,? \\Q1995\\E", "shortCiteRegEx": "Miller", "year": 1995}, {"title": "Computing machinery and intelligence. Mind, pages 433\u2013460", "author": ["A.M. Turing"], "venue": null, "citeRegEx": "Turing,? \\Q1950\\E", "shortCiteRegEx": "Turing", "year": 1950}, {"title": "Verbs semantics and lexical selection", "author": ["Z. Wu", "M. Palmer"], "venue": null, "citeRegEx": "Wu and Palmer,? \\Q1994\\E", "shortCiteRegEx": "Wu and Palmer", "year": 1994}], "referenceMentions": [{"referenceID": 5, "context": "(Krizhevsky et al., 2012; Liang et al., 2013)) has inspired researchers to work on holistic tasks that interlink both modalities together in a complex chain of perception, representation and inference.", "startOffset": 0, "endOffset": 45}, {"referenceID": 7, "context": "(Krizhevsky et al., 2012; Liang et al., 2013)) has inspired researchers to work on holistic tasks that interlink both modalities together in a complex chain of perception, representation and inference.", "startOffset": 0, "endOffset": 45}, {"referenceID": 4, "context": "Examples include: grounding (Krishnamurthy and Kollar, 2013), language generation (Karpathy and Fei-Fei, 2014; Donahue et al.", "startOffset": 28, "endOffset": 60}, {"referenceID": 2, "context": "Examples include: grounding (Krishnamurthy and Kollar, 2013), language generation (Karpathy and Fei-Fei, 2014; Donahue et al., 2014), retrieval (Karpathy et al.", "startOffset": 82, "endOffset": 132}, {"referenceID": 0, "context": "Examples include: grounding (Krishnamurthy and Kollar, 2013), language generation (Karpathy and Fei-Fei, 2014; Donahue et al., 2014), retrieval (Karpathy et al.", "startOffset": 82, "endOffset": 132}, {"referenceID": 3, "context": ", 2014), retrieval (Karpathy et al., 2014; Malinowski and Fritz, 2014b), and question answering about images (Malinowski and Fritz, 2014a,c).", "startOffset": 19, "endOffset": 71}, {"referenceID": 12, "context": "Recently, Malinowski and Fritz (2014a) have presented an approach for question answering about images that resembles the famous Turing Test (Turing, 1950), while Malinowski and Fritz (2014c) further discuss some of the associated challenges and issues.", "startOffset": 140, "endOffset": 154}, {"referenceID": 0, "context": "Examples include: grounding (Krishnamurthy and Kollar, 2013), language generation (Karpathy and Fei-Fei, 2014; Donahue et al., 2014), retrieval (Karpathy et al., 2014; Malinowski and Fritz, 2014b), and question answering about images (Malinowski and Fritz, 2014a,c). Recently, Malinowski and Fritz (2014a) have presented an approach for question answering about images that resembles the famous Turing Test (Turing, 1950), while Malinowski and Fritz (2014c) further discuss some of the associated challenges and issues.", "startOffset": 111, "endOffset": 306}, {"referenceID": 0, "context": "Examples include: grounding (Krishnamurthy and Kollar, 2013), language generation (Karpathy and Fei-Fei, 2014; Donahue et al., 2014), retrieval (Karpathy et al., 2014; Malinowski and Fritz, 2014b), and question answering about images (Malinowski and Fritz, 2014a,c). Recently, Malinowski and Fritz (2014a) have presented an approach for question answering about images that resembles the famous Turing Test (Turing, 1950), while Malinowski and Fritz (2014c) further discuss some of the associated challenges and issues.", "startOffset": 111, "endOffset": 458}, {"referenceID": 6, "context": "Depending on the cultural bias and the context, we may use object-centric or observer-centric or world-centric frames of reference (Levinson, 2003).", "startOffset": 131, "endOffset": 147}, {"referenceID": 4, "context": "In contrast to grounding (Krishnamurthy and Kollar, 2013), annotating images with question and answer pairs does not require a detailed annotations of whole scenes in terms of predicates representing objects and their relations.", "startOffset": 25, "endOffset": 57}, {"referenceID": 2, "context": "In contrast to language generation (Karpathy and Fei-Fei, 2014; Donahue et al., 2014), the output space of a question answering task is more restricted and hence evaluation of different architectures on the task is easier to formulate.", "startOffset": 35, "endOffset": 85}, {"referenceID": 0, "context": "In contrast to language generation (Karpathy and Fei-Fei, 2014; Donahue et al., 2014), the output space of a question answering task is more restricted and hence evaluation of different architectures on the task is easier to formulate.", "startOffset": 35, "endOffset": 85}, {"referenceID": 1, "context": "In contrast to typical computer vision tasks like object detection (Everingham et al., 2010), architectures are judged solely on right answers, not an internal representation.", "startOffset": 67, "endOffset": 92}, {"referenceID": 12, "context": "In contrast to the traditional Turing Test (Turing, 1950), \u201canswering questions about images\u201d is less prone to over-interpretations via associating a meaning to machine answers by the human interrogator.", "startOffset": 43, "endOffset": 57}, {"referenceID": 11, "context": "To deal with different interpretations of words, Malinowski and Fritz (2014a) define a WUPS scores using lexical databases (Miller, 1995) with Wu-Palmer similarity (Wu and Palmer, 1994).", "startOffset": 123, "endOffset": 137}, {"referenceID": 13, "context": "To deal with different interpretations of words, Malinowski and Fritz (2014a) define a WUPS scores using lexical databases (Miller, 1995) with Wu-Palmer similarity (Wu and Palmer, 1994).", "startOffset": 164, "endOffset": 185}, {"referenceID": 8, "context": "Malinowski and Fritz (2014a) proposed to restrict the answer space in order to achieve this goal, while leaving the questions unconstraint.", "startOffset": 0, "endOffset": 29}, {"referenceID": 8, "context": "Malinowski and Fritz (2014a) proposed to restrict the answer space in order to achieve this goal, while leaving the questions unconstraint. Social consensus: The complex tasks that we are interested in are inherently ambiguous. The ambiguities stem from many factors such as cultural bias, different frame of reference and fined grained categorization. This implies that multiple interpretations of a question are possible. To deal with different interpretations of words, Malinowski and Fritz (2014a) define a WUPS scores using lexical databases (Miller, 1995) with Wu-Palmer similarity (Wu and Palmer, 1994).", "startOffset": 0, "endOffset": 502}, {"referenceID": 8, "context": "Malinowski and Fritz (2014a) proposed to restrict the answer space in order to achieve this goal, while leaving the questions unconstraint. Social consensus: The complex tasks that we are interested in are inherently ambiguous. The ambiguities stem from many factors such as cultural bias, different frame of reference and fined grained categorization. This implies that multiple interpretations of a question are possible. To deal with different interpretations of words, Malinowski and Fritz (2014a) define a WUPS scores using lexical databases (Miller, 1995) with Wu-Palmer similarity (Wu and Palmer, 1994). To deal with different interpretations of a question, Malinowski and Fritz (2014c) suggest that the quality of answers should be measured according to the social consensus where the answers are evaluated against multiple groundtruths.", "startOffset": 0, "endOffset": 694}], "year": 2015, "abstractText": "Progress in language and image understanding by machines has sparkled the interest of the research community in more open-ended, holistic tasks, and refueled an old AI dream of building intelligent machines. We discuss a few prominent challenges that characterize such holistic tasks and argue for \u201cquestion answering about images\u201d as a particular appealing instance of such a holistic task. In particular, we point out that it is a version of a Turing Test that is likely to be more robust to over-interpretations and contrast it with tasks like grounding and generation of descriptions. Finally, we discuss tools to measure progress in this field.", "creator": "LaTeX with hyperref package"}}}