{"id": "1501.04282", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2015", "title": "Regularized maximum correntropy machine", "abstract": "In this paper we investigate the usage of regularized correntropy framework for learning of classifiers from noisy labels. The class label predictors learned by minimizing transitional loss functions are sensitive to the noisy and outlying labels of training samples, because the transitional loss functions are equally applied to all the samples. To solve this problem, we propose to learn the class label predictors by maximizing the correntropy between the predicted labels and the true labels of the training samples, under the regularized Maximum Correntropy Criteria (MCC) framework. Moreover, we regularize the predictor parameter to control the complexity of the predictor. The learning problem is formulated by an objective function considering the parameter regularization and MCC simultaneously. By optimizing the objective function alternately, we develop a novel predictor learning algorithm. The experiments on two chal- lenging pattern classification tasks show that it significantly outperforms the machines with transitional loss functions.", "histories": [["v1", "Sun, 18 Jan 2015 11:46:30 GMT  (34kb)", "http://arxiv.org/abs/1501.04282v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jim jing-yan wang", "yunji wang", "bing-yi jing", "xin gao"], "accepted": false, "id": "1501.04282"}, "pdf": {"name": "1501.04282.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Jing-Yan Wang", "Yunji Wang", "Bing-Yi Jing", "Xin Gao"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 1.04 282v 1 [cs.L G] 1In this paper, we examine the use of regulated correntropy frameworks for learning classifiers from loud labels. Class identification predictors, which are learned by minimizing transition loss functions, are sensitive to the loud and upstream labels of training samples, since the transition loss functions are applied equally to all samples. To solve this problem, we propose to learn class identification predictors by maximizing the correntropy between the predicted labels and the true labels of training samples within the framework of the regulated Maximum Correntropy Criteria (MCC). Furthermore, we regulate the predictor parameter to control the complexity of the predictor. The learning problem is formulated by an objective function that takes into account the regulation of parameters and MCC at the same time. By optimizing the objective function, we develop alternating a predictor complexity to control the learning algorithm."}, {"heading": "1. Introduction", "text": "Classification is a fundamental problem in the field of pattern recognition. An attempt is made to learn an effective predictor pattern in order to map the results of a training. (Suppose we have a training series that is used as an example of different training patterns. (Suppose we have a training series that is used as an example of different training patterns.) There will be a real learning pattern that is used as an example of the loss of the i-th training patterns. (Suppose we have a training series that is used as an example of the loss of the i-th training patterns.) In addition, we will also denounce the label indicator matrix as Y = [Yli]. (R \u00d7 N, and Yi = 1 if we learn dil, and we try the pre-L)."}, {"heading": "2. Regularized Maximum Correntropy Machine", "text": "In this section, we will introduce the classification engine that maximizes the correntropy between the predicted class labels and the real class labels, while keeping the solution as simple as possible."}, {"heading": "2.1. Objective Function", "text": "To design the predictors for the l-th predictor, we must first use the data sample x as x-inthe linear space and the kernel space as: x-x, (linear), K (\u00b7, x), (kernel), (1), where K (\u00b7, x) = [K (x1, x), \u00b7 \u00b7, K (xN, x)] and K (xi, xj) is a kernel function between xi and xj. Then a linear predictor f l (x) is developed to predict whether the sample belongs to the l-th class. (x)"}, {"heading": "2.2. Optimization", "text": "Due to the non-linear attribute of the core function g\u03c3 (x) in the objective function in (8), direct optimization is difficult. An attribute of the core function g\u03c3 (x) is that its derivative is also the same core function, and if we set its derivative to zero to search for the optimization of the object, it is not easy to obtain a near form solution. However, according to the property of the convex conjugate function, we have: sentence 1 There is a convex conjugate function of g\u03c3 (x), which is derived further from the theory of the convex conjugate function (x)."}, {"heading": "2.2.1. Expectation Step", "text": "In the expectation step of the EM algorithm, we calculated the auxiliary variable Matrix P directly by fixing the SVM variables. Obviously, according to Proposition 1, the maximum of (10) can be achieved at P = \u2212 g\u03c3 (F\u03b8 \u2212 Y), Pli = \u2212 g\u03c3 (w'l x i + bl \u2212 Yli). (11) Note that g\u03c3 (X) is the elementary Gaussian function. For fixed predictor parameters, the auxiliary variable \u2212 Pli can be regarded as the prediction result of the i-th study sample with respect to the l-th class. The better the l-th prediction result of the i-th sample corresponds to the correct designation Yli, the larger the \u2212 Pli becomes. Comment 5: It is interesting to see if there is any relationship between the auxiliary variables in P and the slip variables in SVM."}, {"heading": "2.2.2. Maximization Step", "text": "Im Maximierungsschnitt des EM-Algorithmus we solve the prediktorproblem (wl, bl, l, l, l, l). (wl, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l, l,"}, {"heading": "2.3. Algorithm", "text": "Algorithm 1 summarizes the learning procedure of the predictor parameters of Reg-MaxCEM. The E-step and M-step are repeated for T-times. Algorithm 1 RegMaxCEM Learning Algorithm.Input: Training set: D = {(xi, yi)} N i = 1; Initialize the auxiliary variables Matrix P 0 = \u2212 1L \u00b7 N; Present each sample xi as x-i as in (1); for t = 1, \u00b7 \u00b7, T doMaximization-Step: Update the predictor parameters successt = {(wtl, b t l)} L = 1 as in (17) and (18) as in P t \u2212 1. Expectation step: Update the auxiliary variable P t as in (11) by specifying the predictor parameters. End for output: predictor parameters prevantT = (wTl, b T) l = 1."}, {"heading": "3. Experiments", "text": "In the experiments, we will evaluate the proposed classification method based on two challenging pattern classification tasks - bacterial identification [21] and prediction of DNA binding sites in proteins [22]."}, {"heading": "3.1. Experiment I: Bacteria Identification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1. Dataset and Setup", "text": "The highly accurate identification of bacteria is very important for the diagnosis of cancers and bacterial infections. Recently, it was proposed to provide an effective platform for the detection of bacteria [21]. ENSaptamere is a sensor field with seven sensors, and each sensor is designed with a DNA element. For the experiment, we collected a total of 66 samples from 6 different bacteria, including S.tyohimurium, S.flexneri, E.coli (CAU 0111), S.sonnei, S.typhi and E.coli (ATCC 25922). The number of samples for each bacterium varies from 9 to 13. Given an unknown bacterial sample with its fluorescence reaction patterns of ENSaptamer, the task is to determine which bacteria it is. To this end, the seven fluorescence reactivity patterns of ENSaptamer against the sample have been classified."}, {"heading": "3.1.2. Results", "text": "We compare our proposed method with other loss function-based classifiers, including square loss, hinge loss, and logistical loss. 0-1 loss is the simplest loss function, but difficult to optimize, so it is not compared in the experiment. Diagrams of accuracy of different methods using both linear and kernel representations are illuminated in Figure 1. As shown in Figure 1, the predictor generated by maximizing correntropy is consistent and significant. To verify whether the improvements are statistically significant, we performed the paired t tests with respect to the accuracy of the proposed method and other comparative methods. The null hypothesis of the T test is that the accuracy of the proposed method and the methods compared is not significant."}, {"heading": "3.2. Experiment II: DNA-Binding Site Prediction", "text": "In order to understand the molecular mechanisms of protein-DNA interaction, it is very important to predict the DNA binding sites in proteins. In this experiment, we will evaluate the proposed method for predicting DNA binding sites [22]."}, {"heading": "3.2.1. Dataset and Setup", "text": "The PDNA-62 database for DNA-binding site prediction was randomly used in this experiment. This database contains a total of 8,163 sites in proteins, of which 1,215 are DNA-binding sites, while the remaining 6,948 sites are non-binding sites. To this end, we select 1,000 DNA-binding sites and 5,000 non-binding sites from the PDNA-62 database to construct our database for the experiment. In view of a candidate site, the goal of the DNA-binding site prediction is to predict whether or not it is a DNA-binding site. To this end, the evolutionary information, solvent-accessible surfaces and the protein backbone structural features are extracted from the site and then combined to construct the trait vector. The trait vector was further entered into the classifier to distinguish DNA-binding sites from the non-binding sites [22].To perform the experiment, we have the cross-validated 10."}, {"heading": "3.2.2. Results", "text": "The AUC values of the ROC curves are also shown in Table 3. Overall, the proposed methods significantly exceed the other methods, although there is some variability in prediction performance across different types of representation. In Table 3, we could see that the accuracy of the predictor is slightly increased by using the kernel representation instead of the linear representation. Regulated correntropy-based predictors provide much better results than other methods on both representations. An interesting result of the DNA-binding prediction on this dataset is that the predictor with the hinge loss function outperforms other two methods."}, {"heading": "4. Conclusion and Future Work", "text": "In this paper, we present a novel regulated prediction model for multi-class pattern recognition problems. The predictor is learned by maximizing correntropy between prediction results and actual class identifiers. By applying the MCC rule, we could treat different training samples differently, so that the noisy and remote training samples have less influence on predictor learning. Compared to existing prediction models with different loss functions, it is robust compared to the noisy and remote training samples. Experiments to identify bacteria and DNA-binding site prediction show that a good predictor can benefit a lot from a well-designed loss function based on MCC. The proposed method exceeded the predictor with other popularly used loss functions. In the future, we will investigate whether the regulated maximum correntropy framework can be used to regulate ranking score learning [23, 24, data representation with other popularly used loss functions], 40s, 40s, 40s, 40s, 40s, 40s, 429, 40s, 40s, 40s, 40s, 40s, 40s, 40s, 40s, 40s, 430, 40s, 40s, 40s, 40s, 40s, 40s, 40s, 40s, 4th, 40s, 40s, 40s, 40s, 40s, 40s, 40s, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th, 4th"}], "references": [{"title": "K-means clustering with bagging and mapreduce", "author": ["H. Li", "G.-Q. Wu", "X.-G. Hu", "J. Zhang", "L. Li", "X. Wu"], "venue": "in: System Sciences (HICSS), 2011 44th Hawaii International Conference on, IEEE", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Noise-robust semi-supervised learning via fast sparse coding", "author": ["Z. Lu", "L. Wang"], "venue": "Pattern Recognition 48 (2) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Online group feature selection from feature streams", "author": ["H. Li", "X. Wu", "Z. Li", "W. Ding"], "venue": "in: Twenty-Seventh AAAI Conference on Artificial Intelligence, AAAI", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Spatial temporal pyramid matching using temporal sparse representation for human motion retrieval", "author": ["L. Zhou", "Z. Lu", "H. Leung", "L. Shang"], "venue": "The Visual Computer 30 (6-8) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning descriptive visual representation by semantic regularized matrix factorization", "author": ["Z. Lu", "Y. Peng"], "venue": "in: IJCAI, AAAI Press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Region-based high-level semantics extraction with cedd", "author": ["Y. Zhou", "L. Li", "T. Zhao", "H. Zhang"], "venue": "in: Network Infrastructure and Digital Content, 2010 2nd IEEE International Conference on, IEEE", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Y", "author": ["Z. Lu"], "venue": "Peng, Unified constraint propagation on multi-view data., in: AAAI", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "l1-graph construction using structured sparsity", "author": ["G. Zhou", "Z. Lu", "Y. Peng"], "venue": "Neurocomputing 120 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Maximum Correntropy Criterion for Robust Face Recognition", "author": ["R. He", "W.-S. Zheng", "B.-G. Hu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (8) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Heterogeneous constraint propagation with constrained sparse representation", "author": ["Z. Lu", "Y. Peng"], "venue": "in: Proceedings of IEEE International Conference on Data Mining, IEEE Computer Society", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Exhaustive and efficient constraint propagation: A graphbased learning approach and its applications", "author": ["Z. Lu", "Y. Peng"], "venue": "International Journal of Computer Vision 103 (3) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "A Regularized Correntropy Framework for Robust Pattern Recognition", "author": ["R. He", "W.-S. Zheng", "B.-G. Hu", "X.-W. Kong"], "venue": "Vol. 23", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust Semi-supervised Learning Algorithm Based on Maximum Correntropy Criterion", "author": ["N.-H. Yang", "M.-M. Huang", "R. He", "X.-K. Wang"], "venue": "Journal of Software 23 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Robustness and regularization of support vector machines", "author": ["H. Xu", "C. Caramanis", "S. Mannor"], "venue": "The Journal of Machine Learning Research 10 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Robust feature extraction via information theoretic learning", "author": ["X.-T. Yuan", "B.-G. Hu"], "venue": "in: Proceedings of the 26th Annual International Conference on Machine Learning, ACM", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Image annotation by semantic sparse recoding of visual content", "author": ["Z. Lu", "Y. Peng"], "venue": "in: Proceedings of the 20th ACM international conference on Multimedia, ACM", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning descriptive visual representation for image classification and annotation", "author": ["Z. Lu", "L. Wang"], "venue": "Pattern Recognition 48 (2) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "A Graphene-Based Sensor Array for High-Precision and Adaptive 20  Target Identification with Ensemble Aptamers", "author": ["H. Pei", "J. Li", "M. Lv", "J. Wang", "J. Gao", "J. Lu", "Y. Li", "Q. Huang", "J. Hu", "C. Fan"], "venue": "Journal of the American Chemical Society 134 (33) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Predna: accurate prediction of dna-binding sites in proteins by integrating sequence and geometric structure information", "author": ["T. Li", "Q. Li", "S. Liu", "G. Fan", "Y. Zuo", "Y. Peng"], "venue": "Bioinformatics 29 (6) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Sparse structure regularized ranking", "author": ["J.J.-Y. Wang", "Y. Sun", "X. Gao"], "venue": "Multimedia Tools and Applications ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Generalized relevance models for automatic image annotation", "author": ["Z. Lu", "H.H. Ip"], "venue": "in: Advances in Multimedia Information Processing-PCM 2009, Springer Berlin Heidelberg", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Non-informative hierarchical bayesian inference for non-negative matrix factorization", "author": ["Q. Sun", "J. Lu", "Y. Wu", "H. Qiao", "X. Huang", "F. Hu"], "venue": "Signal Processing 108 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised image segmentation using an iterative entropy regularized likelihood learning algorithm", "author": ["Z. Lu"], "venue": "in: Advances in Neural Networks-ISNN 2006, Springer Berlin Heidelberg", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "Unsupervised learning of finite mixtures using entropy regularization and its application to image segmentation", "author": ["Z. Lu", "Y. Peng", "J. Xiao"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition, IEEE", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Spectral learning of latent semantics for action recognition", "author": ["Z. Lu", "Y. Peng", "H.H.-S. Ip"], "venue": "in: IEEE International Conference onComputer Vision (ICCV), IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Latent semantic learning with structured sparse representation for human action recognition", "author": ["Z. Lu", "Y. Peng"], "venue": "Pattern Recognition 46 (7) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Y", "author": ["Z. Lu"], "venue": "Peng, Latent semantic learning by efficient sparse coding with hypergraph regularization., in: AAAI", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "A regularized minimum cross-entropy algorithm on mixture of experts for curve detection", "author": ["Z. Lu"], "venue": "in: International Conference on Neural Networks and Brain, Vol. 2, IEEE", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2005}, {"title": "Action recognition based on learnt motion semantic vocabulary", "author": ["Q. Zhao", "Z. Lu", "H.H. Ip"], "venue": "in: Advances in Multimedia Information Processing-PCM 2010, Springer Berlin Heidelberg", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised image categorization using constrained entropy-regularized likelihood learning with pairwise constraints", "author": ["Z. Lu", "X. Lu", "Z. Ye"], "venue": "in: Advances in Neural Networks\u2013ISNN 2007, Springer Berlin Heidelberg", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Context awareness emergence for distributed binary pyroelectric sensors", "author": ["S. Qingquan", "H. Fei", "Q. Hao"], "venue": "in: Multisensor Fusion and Integration for Intelligent Systems (MFI), 2010 IEEE Conference on, IEEE", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "A fast raptor codes decoding strategy for real-time communication systems", "author": ["Y. Wu", "F. Hu", "Q. Sun", "K. Bao", "M. Guo"], "venue": "Network and Communication Technologies 2 (2) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "A multi-agent-based intelligent sensor and actuator network design for smart house and home automation", "author": ["Q. Sun", "W. Yu", "N. Kochurov", "Q. Hao", "F. Hu"], "venue": "Journal of Sensor and Actuator Networks 2 (3) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised multi-level nonnegative matrix factorization model: Binary data case", "author": ["Q. Sun", "P. Wu", "Y. Wu", "M. Guo", "J. Lu"], "venue": "Journal of Information Security 3 ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "Neuro-disorder patient monitoring via gait sensor networks", "author": ["F. Hu", "Q. Sun", "Q. Hao"], "venue": "Intelligent Sensor Networks: The Integration of Sensor Networks, Signal Processing and Machine Learning ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "Mobile targets scenario recognition via low-cost pyroelectric sensor network system: Towards an accurate context identification", "author": ["Q. Sun", "F. Hu", "Q. Hao"], "venue": "Proc. 2011 IEEE Students Tech. Sym ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "Spatial markov kernels for image categorization and annotation", "author": ["Z. Lu", "H.H. Ip"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 41 (4) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2011}, {"title": "Contextual kernel and spectral methods for learning the semantics of images", "author": ["Z. Lu", "H.H. Ip", "Y. Peng"], "venue": "IEEE Transactions on Image Processing 20 (6) ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Gaussian mixture learning via robust competitive agglomeration", "author": ["Z. Lu", "Y. Peng", "H.H. Ip"], "venue": "Pattern Recognition Letters 31 (7) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "An iterative entropy regularized likelihood learning algorithm for cluster analysis with the number of clusters automatically detected", "author": ["Z. Lu"], "venue": "in: International Conference on Neural Networks and Brain, Vol. 2, IEEE", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2005}, {"title": "A publishing framework for digitally augmented paper documents: towards cross-media information integration", "author": ["X. Lu", "Z. Lu"], "venue": "in: Advances in Multimedia Information Processing-PCM 2006, Springer Berlin Heidelberg", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2006}, {"title": "A semi-supervised learning algorithm on gaussian mixture with automatic model selection", "author": ["Z. Lu", "Y. Peng"], "venue": "Neural Processing Letters 27 (1) ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2008}, {"title": "Context-based multi-label image annotation", "author": ["Z. Lu", "H.H. Ip", "Q. He"], "venue": "in: Proceedings of the ACM International Conference on Image and Video Retrieval, ACM", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2009}, {"title": "Image categorization with spatial mismatch kernels", "author": ["Z. Lu", "H.H.-S. Ip"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition, IEEE", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "Characterizing honeypot-captured cyber attacks: Statistical framework and case study", "author": ["Z. Zhan", "M. Xu", "S. Xu"], "venue": "Information Forensics and Security, IEEE Transactions on 8 (11) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive epidemic dynamics in networks: Thresholds and control", "author": ["S. Xu", "W. Lu", "L. Xu", "Z. Zhan"], "venue": "ACM Trans. Auton. Adapt. Syst. 8 (4) ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "Cross-layer detection of malicious websites", "author": ["L. Xu", "Z. Zhan", "S. Xu", "K. Ye"], "venue": "in: CODASPY", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2013}, {"title": "An evasion and Counter-Evasion study in malicious websites detection", "author": ["L. Xu", "Z. Zhan", "S. Xu", "K. Ye"], "venue": "in: 2014 IEEE Conference on Communications and Network Security (CNS) ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}, {"title": "A stochastic model of multivirus dynamics", "author": ["S. Xu", "W. Lu", "Z. Zhan"], "venue": "Dependable and Secure Computing, IEEE Transactions on 9 (1) ", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2012}, {"title": "Trustworthy information: concepts and mechanisms", "author": ["S. Xu", "H. Qian", "F. Wang", "Z. Zhan", "E. Bertino", "R. Sandhu"], "venue": "in: Web-Age Information Management, Springer", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 1, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 2, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 3, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 4, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 5, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 6, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 7, "context": "It tries to learn an effective predictor to map the feature vector of a sample to its class label [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].", "startOffset": 98, "endOffset": 129}, {"referenceID": 8, "context": "Recently, regularized correntropy framework has been proposed for robust pattern recognition problems [11, 12, 13, 14].", "startOffset": 102, "endOffset": 118}, {"referenceID": 9, "context": "Recently, regularized correntropy framework has been proposed for robust pattern recognition problems [11, 12, 13, 14].", "startOffset": 102, "endOffset": 118}, {"referenceID": 10, "context": "Recently, regularized correntropy framework has been proposed for robust pattern recognition problems [11, 12, 13, 14].", "startOffset": 102, "endOffset": 118}, {"referenceID": 11, "context": "In [15], He et, al argued that the classical mean square error (MSE) criterion is sensitive to outliers, and intro-", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "[16] also proposed to use correntropy to compare predicted class labels and true labels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "To handle this problem, instead of minimizing a loss function to learn the predictor, we use the MCC [11] framework to learn the predictor by maximizing the correntropy between the predicted results and the true labels.", "startOffset": 101, "endOffset": 105}, {"referenceID": 8, "context": "For example, in [11], it is claimed that \u201cthe maximum correntropy criterion, .", "startOffset": 16, "endOffset": 20}, {"referenceID": 8, "context": "Please notice that in [11], MCC is used to measure the similarity between a test sample and its sparse linear representation of training samples, while in this work it is used to measure the similarity between the predicted class label and its true label.", "startOffset": 22, "endOffset": 26}, {"referenceID": 8, "context": "In our experiments, the \u03c3 value is calculated as \u03c3 = 1 2\u00d7L\u00d7N \u2211L l=1 \u2211N i=1 \u2016F\u03b8li \u2212 Yli\u2016 2 2 following [11].", "startOffset": 102, "endOffset": 106}, {"referenceID": 13, "context": "However, in support vector classification, this regularization term is either obtained by a \u201cmaximal margin\u201d regularization or obtained by a \u201cmaximal robustness\u201d regularization for certain type of feature noises [17].", "startOffset": 212, "endOffset": 216}, {"referenceID": 11, "context": "In fact, when the regularizer term is introduced, (8) is a case of the regularized correntropy framework [15].", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "This Proposition is taken from [18], which is further derived from the theory of convex conjugated functions.", "startOffset": 31, "endOffset": 35}, {"referenceID": 8, "context": "It is further discussed and used in many applications such as [11, 15, 19, 20].", "startOffset": 62, "endOffset": 78}, {"referenceID": 11, "context": "It is further discussed and used in many applications such as [11, 15, 19, 20].", "startOffset": 62, "endOffset": 78}, {"referenceID": 15, "context": "It is further discussed and used in many applications such as [11, 15, 19, 20].", "startOffset": 62, "endOffset": 78}, {"referenceID": 16, "context": "It is further discussed and used in many applications such as [11, 15, 19, 20].", "startOffset": 62, "endOffset": 78}, {"referenceID": 17, "context": "In the experiments, we will evaluate the proposed classification method on two challenging pattern classification tasks \u2014 bacteria identification [21] and prediction of DNA-binding sites in proteins [22].", "startOffset": 146, "endOffset": 150}, {"referenceID": 18, "context": "In the experiments, we will evaluate the proposed classification method on two challenging pattern classification tasks \u2014 bacteria identification [21] and prediction of DNA-binding sites in proteins [22].", "startOffset": 199, "endOffset": 203}, {"referenceID": 17, "context": "Recently, ensemble aptamers (ENSaptamers), which utilizes a small set of nonspecific DNA sequences, has been proposed to provide an effective platform for the detection of bacteria [21].", "startOffset": 181, "endOffset": 185}, {"referenceID": 18, "context": "In this experiment, we will evaluate the proposed method for prediction of DNA-binding sites [22].", "startOffset": 93, "endOffset": 97}, {"referenceID": 18, "context": "The feature vector was further inputted into the classifier to distinguish DNA-binding sites from the non-binding sites [22].", "startOffset": 120, "endOffset": 124}, {"referenceID": 19, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 133, "endOffset": 141}, {"referenceID": 20, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 133, "endOffset": 141}, {"referenceID": 21, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 22, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 23, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 24, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 25, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 26, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 27, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 28, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 29, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 163, "endOffset": 199}, {"referenceID": 30, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 315, "endOffset": 343}, {"referenceID": 31, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 315, "endOffset": 343}, {"referenceID": 32, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 315, "endOffset": 343}, {"referenceID": 33, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 315, "endOffset": 343}, {"referenceID": 34, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 315, "endOffset": 343}, {"referenceID": 35, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 315, "endOffset": 343}, {"referenceID": 36, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 37, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 38, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 39, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 40, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 41, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 41, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 42, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 43, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 361, "endOffset": 397}, {"referenceID": 44, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 429, "endOffset": 457}, {"referenceID": 45, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 429, "endOffset": 457}, {"referenceID": 46, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 429, "endOffset": 457}, {"referenceID": 47, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 429, "endOffset": 457}, {"referenceID": 48, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 429, "endOffset": 457}, {"referenceID": 49, "context": "In the future, we will investigate if the regularized maximum correntropy framework can be used to regularize ranking score learning [23, 24], data representation [25, 26, 27, 28, 29, 30, 31, 32, 33] Moreover, we also plan to extend the proposed regularized correntropy based classifier for wireless sensor network [34, 35, 36, 37, 38, 39, 40], computer vision [41, 42, 43, 44, 45, 46, 46, 47, 48], and computer network security [49, 50, 51, 52, 53, 54, 55].", "startOffset": 429, "endOffset": 457}], "year": 2015, "abstractText": "In this paper we investigate the usage of regularized correntropy framework for learning of classifiers from noisy labels. The class label predictors learned by minimizing transitional loss functions are sensitive to the noisy and outlying labels of training samples, because the transitional loss functions are equally applied to all the samples. To solve this problem, we propose to learn the class label predictors by maximizing the correntropy between the predicted labels and the true labels of the training samples, under the regularized Maximum Correntropy Criteria (MCC) framework. Moreover, we regularize the predictor parameter to control the complexity of the predictor. The learning problem is formulated by an objective function considering the parameter regularization and MCC simultaneously. By optimizing the objective function alternately, we develop a novel predictor learning algorithm. The experiments on two challenging pattern classification tasks show that it significantly outperforms the machines with transitional loss functions.", "creator": "LaTeX with hyperref package"}}}