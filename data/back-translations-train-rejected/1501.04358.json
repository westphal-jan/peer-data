{"id": "1501.04358", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2015", "title": "Does Learning Imply a Decrease in the Entropy of Behavior?", "abstract": "Shannon's information entropy measures of the uncertainty of an event's outcome. If learning about a system reflects a decrease in uncertainty, then a plausible intuition is that learning should be accompanied by a decrease in the entropy of the organism's actions and/or perceptual states. To address whether this intuition is valid, I examined an artificial organism -- a simple robot -- that learned to navigate in an arena and analyzed the entropy of the outcome variables action, state, and reward. Entropy did indeed decrease in the initial stages of learning, but two factors complicated the scenario: (1) the introduction of new options discovered during the learning process and (2) the shifting patterns of perceptual and environmental states resulting from changes to the robot's learned movement strategies. These factors lead to a subsequent increase in entropy as the agent learned. I end with a discussion of the utility of information-based characterizations of learning.", "histories": [["v1", "Sun, 18 Jan 2015 21:49:22 GMT  (520kb,D)", "https://arxiv.org/abs/1501.04358v1", "14 pages, 7 figures, 1 table"], ["v2", "Sun, 25 Jan 2015 01:13:52 GMT  (520kb,D)", "http://arxiv.org/abs/1501.04358v2", "14 pages, 7 figures, 1 table"], ["v3", "Thu, 19 Feb 2015 01:16:18 GMT  (520kb,D)", "http://arxiv.org/abs/1501.04358v3", "14 pages, 7 figures, 1 table"]], "COMMENTS": "14 pages, 7 figures, 1 table", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["paul e smaldino"], "accepted": false, "id": "1501.04358"}, "pdf": {"name": "1501.04358.pdf", "metadata": {"source": "CRF", "title": "Does Learning Imply a Decrease in the Entropy of Behavior?", "authors": ["Paul Smaldino"], "emails": ["paul.smaldino@gmail.com"], "sections": [{"heading": null, "text": "Keywords: information theory, robots, simulation, uncertainty, spatial learning, option generation0 Introductory annotationThis work is a lightly edited version of a paper I wrote in 2009 as the final project of a graduate course on Natural Computation and Self Organization in the Department of Physics at UC Davis. Since then, I have occasionally met people who have expressed interest in the ideas presented here, which has encouraged me to return to work and pour them into their current form. Xiv: 150 1.04 358v 3 [cs.R O] 19 FeThe paper considers a popular definition of learning as a decrease in uncertainty and asks whether the information tropy of an agent works or perceptual states decrease during a period of spatial learning. The method used to study the question involves a simulated robot borrowed from another study. Therefore, the model system is much more complicated than is absolutely necessary to investigate the research question."}, {"heading": "1 Introduction", "text": "For most organisms, the environment - which includes the other organisms that make up their predators, prey and competitors - is too complex and uncertain to prepare for any eventuality. Learning provides the solution to this uncertainty. Scenarios repeat, either accurately or roughly, and learning allows an individual to shape his reactions over time toward optimal (or at least better) solutions to the problems that concern him. In mathematical communication theory (Shannon, 1948), the being that reduces uncertainty is information, as reduction in entropy is measured. Put another way, information entropy is often equated with uncertainty in a variable. An outcome that is known with certainty has zero entropy. An event with many similarly probable results has maximum entropy."}, {"heading": "2 Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 The Model Organism and Its Environment", "text": "The model organism was a simulated mobile robot that learned to move in a prescribed space, which was more of a system inspired by the robotic Multi-Agent Development System (RoMADS; see Figure 1) developed by Dynamics of Learning Lab at UC Davis (Morrison, 2007).The robot and its environment are intentionally very simple to highlight the problems of pattern recognition that even exist in a simple system that is fully described. Admittedly, the current robot design has been used largely for convenience, but an advantage of such an arbitrary system reality is realized when it forces readers \"attention to the more general characteristics of learning and behavior and away from a particular naturalistic system. As this is the first study to use the current design, an arbitrarily selected system seems appropriate. Ecologically specific systems could be studied fruitfully in the future. That is, it can also be argued that even when highly falsified questions are considered, and ungracious models help us to understand them in the biology."}, {"heading": "2.2 Shannon Entropy", "text": "Each phase of the learning process was characterized by a policy that produced a unique pattern of behavior as the robot interacted with the environment. To better evaluate the behaviors generated under each policy, additional experiments were simulated during which the robot applied a pre-determined policy for 200 moves without additional learning, allowing me to obtain approximations of the frequency distributions for state, action, and reward within each policy, and the uncertainty inherent in these variables was then assessed by Shannon's Information Trophy (Shannon, 1948). Entropy for a variable X is given by H (X) = \u2212 p (x) = p (x) log2 p (x), where x is a realization of variable X from the alphabet X, and p (x) is the frequency of this realization. MATLAB scripts were written to calculate the entropy of the state, action, and reward variables for each policy."}, {"heading": "3 Results", "text": "In fact, it is the case that you are able to live in a country where most people are able to live in a country where they are able to move, to live, to live, to live and to live, where they are able to live, to live and to live."}, {"heading": "4 Discussion", "text": "In fact, it is the case that most people who are able to help themselves, to help themselves, to help themselves and to help others, to help themselves and to help themselves. (...) It is not that they are able to help themselves. (...) It is not that they can help themselves. (...) It is not that they are able to help themselves. (...) It is that they are not able to help themselves. (...) It is that they are able to help themselves. (...) It is that they are able to help themselves. (...) It is as if they do it. (...) It is not as if they do it. (...) It is as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, if they do it, if they do it as if they do it, if they do it, if they do it as if they do it, if they do it, if they do it, if they do it as if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it, if they do it."}, {"heading": "Acknowledgments", "text": "Thanks to Jim Crutchfield for an inspiring course and to Benny Brown for letting me play with his robot."}], "references": [{"title": "Exploration in a dark open field: A shift from directional to positional progression and a proposed model of acquiring spatial information", "author": ["R. Avni", "P. Zadicario", "D. Eilam"], "venue": "Behavioural Brain Research, 171:313\u2013323.", "citeRegEx": "Avni et al\\.,? 2006", "shortCiteRegEx": "Avni et al\\.", "year": 2006}, {"title": "Can unrealistic computer models illuminate theoretical biology? In Proceedings of the 1999 Genetic and Evolutionary Computation Conference Workshop, pages 20\u201323, Orlando, FL", "author": ["M.A. Bedau"], "venue": "GECC.", "citeRegEx": "Bedau,? 1999", "shortCiteRegEx": "Bedau", "year": 1999}, {"title": "Logical depth and physical complexity", "author": ["C.H. Bennett"], "venue": "Herken, R., editor, The universal Turing machine: A half-century survey, pages 227\u2013257. Oxford University Press.", "citeRegEx": "Bennett,? 1988", "shortCiteRegEx": "Bennett", "year": 1988}, {"title": "A model of spatial map formation in the hippocampus of the rat", "author": ["K.I. Blum", "L.F. Abbott"], "venue": "Neural Computation, 8:85\u201393.", "citeRegEx": "Blum and Abbott,? 1996", "shortCiteRegEx": "Blum and Abbott", "year": 1996}, {"title": "Places and landmarks: An arthropod perspective", "author": ["T. Collett", "J. Zeil"], "venue": "Healy, S., editor, Spatial representation in animals. Oxford University Press.", "citeRegEx": "Collett and Zeil,? 1998", "shortCiteRegEx": "Collett and Zeil", "year": 1998}, {"title": "Applications of the Morris water maze in the study of learning and memory", "author": ["R. D\u2019Hooge", "P.P. De Deyn"], "venue": "Brain Research Reviews,", "citeRegEx": "D.Hooge and Deyn,? \\Q2001\\E", "shortCiteRegEx": "D.Hooge and Deyn", "year": 2001}, {"title": "A goal-directed spatial navigation model using forward trajectory planning based on grid cells", "author": ["U.M. Erdem", "M. Hasselmo"], "venue": "European Journal of Neuroscience, 35:916\u2013931.", "citeRegEx": "Erdem and Hasselmo,? 2012", "shortCiteRegEx": "Erdem and Hasselmo", "year": 2012}, {"title": "A model of hippocampally dependent navigation, using the temporal difference learning rule", "author": ["D.J. Foster", "R.G.M. Morris", "P. Dayan"], "venue": "Hippocampus, 10:1\u201316.", "citeRegEx": "Foster et al\\.,? 2000", "shortCiteRegEx": "Foster et al\\.", "year": 2000}, {"title": "The organization of learning", "author": ["C. Gallistel"], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Gallistel,? 1990", "shortCiteRegEx": "Gallistel", "year": 1990}, {"title": "On intelligence", "author": ["J. Hawkins", "S. Blakeslee"], "venue": "St. Martin\u2019s Griffin, New York.", "citeRegEx": "Hawkins and Blakeslee,? 2005", "shortCiteRegEx": "Hawkins and Blakeslee", "year": 2005}, {"title": "Optimal foraging in semantic memory", "author": ["T.T. Hills", "M.N. Jones", "P.M. Todd"], "venue": "Psychological Review, 119:431\u2013440.", "citeRegEx": "Hills et al\\.,? 2012", "shortCiteRegEx": "Hills et al\\.", "year": 2012}, {"title": "Unskilled and unaware of it: How difficulties in recognizing one\u2019s own incompetence lead to inflated self-assessments", "author": ["J. Kruger", "D. Dunning"], "venue": "Journal of Personality and Social Psychology, 77:1121\u20131134.", "citeRegEx": "Kruger and Dunning,? 1999", "shortCiteRegEx": "Kruger and Dunning", "year": 1999}, {"title": "MASON: A multi-agent simulation environment", "author": ["S. Luke", "C. Cioffi-Revilla", "L. Panait", "K. Sullivan", "G. Balan"], "venue": "Simulation, 82:517\u2013527. http: //cs.gmu.edu/~eclab/projects/mason/.", "citeRegEx": "Luke et al\\.,? 2005", "shortCiteRegEx": "Luke et al\\.", "year": 2005}, {"title": "Information theory, inference, and learning algorithms", "author": ["D.J.C. MacKay"], "venue": "Cambridge University Press.", "citeRegEx": "MacKay,? 2003", "shortCiteRegEx": "MacKay", "year": 2003}, {"title": "The Robotic Multi-Agent Development System: Simulating the physical world", "author": ["R. Morrison"], "venue": "Available online at http://london.ucdavis.edu/~reu/ REU07/morrison.pdf.", "citeRegEx": "Morrison,? 2007", "shortCiteRegEx": "Morrison", "year": 2007}, {"title": "Place cells, grid cells, and the brain\u2019s spatial representation system", "author": ["E.I. Moser", "E. Kropff", "Moser", "M.-B."], "venue": "Annual Review of Neuroscience, 31:69\u201389.", "citeRegEx": "Moser et al\\.,? 2008", "shortCiteRegEx": "Moser et al\\.", "year": 2008}, {"title": "The role of the hippocampus in solving the morris water maze", "author": ["A.D. Redish", "D.S. Touretzky"], "venue": "Neural Computation, 10:73\u2013111.", "citeRegEx": "Redish and Touretzky,? 1998", "shortCiteRegEx": "Redish and Touretzky", "year": 1998}, {"title": "New hopes for a changing world", "author": ["B. Russell"], "venue": "Simon and Schuster, New York.", "citeRegEx": "Russell,? 1951", "shortCiteRegEx": "Russell", "year": 1951}, {"title": "A mathematical theory of communication", "author": ["C.E. Shannon"], "venue": "The Bell System Technical Journal, 27:379\u2013423.", "citeRegEx": "Shannon,? 1948", "shortCiteRegEx": "Shannon", "year": 1948}, {"title": "Measures of individual uncertainty for ecological models: Variance and entropy", "author": ["P.E. Smaldino"], "venue": "Ecological Modelling, 254:50\u201353. 14", "citeRegEx": "Smaldino,? 2013", "shortCiteRegEx": "Smaldino", "year": 2013}, {"title": "The origins of options", "author": ["P.E. Smaldino", "P.J. Richerson"], "venue": "Frontiers in Neuroscience, 6:50.", "citeRegEx": "Smaldino and Richerson,? 2012", "shortCiteRegEx": "Smaldino and Richerson", "year": 2012}, {"title": "Reinforcement learning", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "The MIT Press, Cambridge, MA.", "citeRegEx": "Sutton and Barto,? 1998", "shortCiteRegEx": "Sutton and Barto", "year": 1998}, {"title": "Dynamics of the hippocampal ensemble code for space", "author": ["M.A. Wilson", "B.L. McNaughton"], "venue": "Science, 261:1055\u20131058.", "citeRegEx": "Wilson and McNaughton,? 1993", "shortCiteRegEx": "Wilson and McNaughton", "year": 1993}, {"title": "False models as means to truer theories", "author": ["W.C. Wimsatt"], "venue": "Nitecki, M. H. and Hoffman, A., editors, Neutral models in biology, pages 23\u201355. Oxford University Press, New York. 15", "citeRegEx": "Wimsatt,? 1987", "shortCiteRegEx": "Wimsatt", "year": 1987}], "referenceMentions": [{"referenceID": 18, "context": "In the mathematical theory of communication (Shannon, 1948), the entity that reduces uncertainty is information, and information is measured as the reduction in entropy.", "startOffset": 44, "endOffset": 59}, {"referenceID": 13, "context": "On the other hand, if one knows the statistical properties of the language in question, minimizing entropy can be quite predictive of word and sentence structure (MacKay, 2003).", "startOffset": 162, "endOffset": 176}, {"referenceID": 0, "context": "Upon first encountering a new arena, a rodent moves in disorganized loops, exploring the space widely and with minimal structure to its path (Avni et al., 2006).", "startOffset": 141, "endOffset": 160}, {"referenceID": 8, "context": "Neuroscientists have discovered much about the underlying neural architecture of spatial learning (Gallistel, 1990; Wilson and McNaughton, 1993; Collett and Zeil, 1998; Moser et al., 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al.", "startOffset": 98, "endOffset": 188}, {"referenceID": 22, "context": "Neuroscientists have discovered much about the underlying neural architecture of spatial learning (Gallistel, 1990; Wilson and McNaughton, 1993; Collett and Zeil, 1998; Moser et al., 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al.", "startOffset": 98, "endOffset": 188}, {"referenceID": 4, "context": "Neuroscientists have discovered much about the underlying neural architecture of spatial learning (Gallistel, 1990; Wilson and McNaughton, 1993; Collett and Zeil, 1998; Moser et al., 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al.", "startOffset": 98, "endOffset": 188}, {"referenceID": 15, "context": "Neuroscientists have discovered much about the underlying neural architecture of spatial learning (Gallistel, 1990; Wilson and McNaughton, 1993; Collett and Zeil, 1998; Moser et al., 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al.", "startOffset": 98, "endOffset": 188}, {"referenceID": 3, "context": ", 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al., 2000; Erdem and Hasselmo, 2012).", "startOffset": 170, "endOffset": 268}, {"referenceID": 16, "context": ", 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al., 2000; Erdem and Hasselmo, 2012).", "startOffset": 170, "endOffset": 268}, {"referenceID": 7, "context": ", 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al., 2000; Erdem and Hasselmo, 2012).", "startOffset": 170, "endOffset": 268}, {"referenceID": 6, "context": ", 2008), and have proposed a number of models incorporating reinforcement learning and artificial neural nets to provide mechanistic explanations of the learning process (Blum and Abbott, 1996; Redish and Touretzky, 1998; Foster et al., 2000; Erdem and Hasselmo, 2012).", "startOffset": 170, "endOffset": 268}, {"referenceID": 14, "context": "The model organism was a simulated mobile robot that learned to move in a prescribed space, which was inspired by the Robotic Multi-Agent Development System (RoMADS; see Figure 1) developed by the Dynamics of Learning Lab at UC Davis (Morrison, 2007).", "startOffset": 234, "endOffset": 250}, {"referenceID": 23, "context": "That said, it can also be argued that even highly unrealistic models can help us to understand important questions in biology and behavior if they are carefully considered (Wimsatt, 1987; Bedau, 1999).", "startOffset": 172, "endOffset": 200}, {"referenceID": 1, "context": "That said, it can also be argued that even highly unrealistic models can help us to understand important questions in biology and behavior if they are carefully considered (Wimsatt, 1987; Bedau, 1999).", "startOffset": 172, "endOffset": 200}, {"referenceID": 12, "context": "The robot simulation was written in Java using the MASON simulation library (Luke et al., 2005).", "startOffset": 76, "endOffset": 95}, {"referenceID": 21, "context": "Learning was facilitated using an on-policy Monte Carlo control algorithm (Sutton and Barto, 1998).", "startOffset": 74, "endOffset": 98}, {"referenceID": 18, "context": "The inherent uncertainty in these variables was then assessed using Shannon\u2019s information entropy (Shannon, 1948).", "startOffset": 98, "endOffset": 113}, {"referenceID": 20, "context": "This highlights the importance of an ecological approach to the consideration of option generation in decision making (Smaldino and Richerson, 2012).", "startOffset": 118, "endOffset": 148}, {"referenceID": 21, "context": "sequences (such as temporal difference learning, (Sutton and Barto, 1998)) might be employed.", "startOffset": 49, "endOffset": 73}, {"referenceID": 19, "context": "Entropy characterizes the uncertainty pertaining to a set of possible outcomes for a given event, and may be usefully applied to simply cases of organismal uncertainty (Smaldino, 2013).", "startOffset": 168, "endOffset": 184}, {"referenceID": 9, "context": "However, learning in complex environments often consists of integrating and organizing information into semantic networks and action sequences (Hawkins and Blakeslee, 2005; Hills et al., 2012).", "startOffset": 143, "endOffset": 192}, {"referenceID": 10, "context": "However, learning in complex environments often consists of integrating and organizing information into semantic networks and action sequences (Hawkins and Blakeslee, 2005; Hills et al., 2012).", "startOffset": 143, "endOffset": 192}, {"referenceID": 2, "context": "From a computational perspective, such an idea may correspond to Bennett\u2019s (1988) concept of logical depth, in which the complexity of an algorithm is characterized by the time it takes to compute.", "startOffset": 65, "endOffset": 82}, {"referenceID": 11, "context": "Psychologists have long known that increased knowledge brings with it an increased awareness of the vast array of things one does not know (Kruger and Dunning, 1999).", "startOffset": 139, "endOffset": 165}, {"referenceID": 17, "context": "Bertrand Russell is well known for his quip that \u201cOne of the painful things about our time is that those who feel certainty are stupid, and those with any imagination and understanding are filled with doubt and indecision\u201d (Russell, 1951).", "startOffset": 223, "endOffset": 238}], "year": 2015, "abstractText": "Shannon\u2019s information entropy measures of the uncertainty of an event\u2019s outcome. If learning about a system reflects a decrease in uncertainty, then a plausible intuition is that learning should be accompanied by a decrease in the entropy of the organism\u2019s actions and/or perceptual states. To address whether this intuition is valid, I examined an artificial organism \u2013 a simple robot \u2013 that learned to navigate in an arena and analyzed the entropy of the outcome variables action, state, and reward. Entropy did indeed decrease in the initial stages of learning, but two factors complicated the scenario: (1) the introduction of new options discovered during the learning process and (2) the shifting patterns of perceptual and environmental states resulting from changes to the robot\u2019s learned movement strategies. These factors lead to a subsequent increase in entropy as the agent learned. I end with a discussion of the utility of information-based characterizations of learning.", "creator": "LaTeX with hyperref package"}}}