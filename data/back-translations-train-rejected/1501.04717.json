{"id": "1501.04717", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jan-2015", "title": "Robust Face Recognition by Constrained Part-based Alignment", "abstract": "Developing a reliable and practical face recognition system is a long-standing goal in computer vision research. Existing literature suggests that pixel-wise face alignment is the key to achieve high-accuracy face recognition. By assuming a human face as piece-wise planar surfaces, where each surface corresponds to a facial part, we develop in this paper a Constrained Part-based Alignment (CPA) algorithm for face recognition across pose and/or expression. Our proposed algorithm is based on a trainable CPA model, which learns appearance evidence of individual parts and a tree-structured shape configuration among different parts. Given a probe face, CPA simultaneously aligns all its parts by fitting them to the appearance evidence with consideration of the constraint from the tree-structured shape configuration. This objective is formulated as a norm minimization problem regularized by graph likelihoods. CPA can be easily integrated with many existing classifiers to perform part-based face recognition. Extensive experiments on benchmark face datasets show that CPA outperforms or is on par with existing methods for robust face recognition across pose, expression, and/or illumination changes.", "histories": [["v1", "Tue, 20 Jan 2015 06:05:01 GMT  (2948kb,D)", "http://arxiv.org/abs/1501.04717v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["yuting zhang", "kui jia", "yueming wang", "gang pan", "tsung-han chan", "yi ma"], "accepted": false, "id": "1501.04717"}, "pdf": {"name": "1501.04717.pdf", "metadata": {"source": "CRF", "title": "Robust Face Recognition by Constrained Part-based Alignment", "authors": ["Yuting Zhang", "Kui Jia", "Yueming Wang", "Gang Pan", "Tsung-Han Chan", "Yi Ma"], "emails": ["zyt@zju.edu.cn;", "gpan@zju.edu.cn)", "kuijia@gmail.com)", "ymingwang@gmail.com)", "thchan@ieee.org)", "mayi@shanghaitech.edu.cn)", "yima@uiuc.edu)"], "sections": [{"heading": null, "text": "An enormous amount of work has been done over the last three decades, but most of them can only work well in controlled scenarios. However, in practical scenarios, the performance of these existing methods is drastically degraded due to facial variations caused by illumination. [3], motivated by illumination of the facial model [4, 5], several carefully selected facial images of different illuminations are used as a gallery. Faced with a sample face of unknown illumination, facial images can be generated under this specific illumination in the gallery. If several galleries of this kind are not available, Zhang and G. Pan are explicit with the Department of Computer Science, Zhejiang University, Zhejiang University, Hangzhou images can be generated under this particular illumination."}, {"heading": "A. Tree-structured Shape Model", "text": "Let's (V, E) denote the tree, where V = {0, 1, 2,. & < < M} is the vertex set, and E is the set of directed edges. < V is composed of the nodes of the facial parts and a root node (the node \"0\") 5 corresponding to the holistic face. Each ith node is entered into the canonical form, whose variables correspond to the transformation parameters of the facial part. For the root node, we use this simplified case < 0 > = (0, 0) T, assuming the face at the global level, ltltltlt.M) is entered into the canonical form, which suggests (u, v) = constant < 0 > (v). We consider this simplified case in the following derivative of the tree-structured form as a child. To build a model on the tree, we first associate the difference of the transformation parameters of its two end points."}, {"heading": "B. Optimization", "text": "The main difficulty of the solution (7) stems from the non-contextuality of its limitations and deformations. < i > < i > < i > < i > < i > < i > < i > + e < i > + e < i >, i = 1,.. m, which combines the nonlinear operations of holistic deformation and partial deformations. < i >} mi = 1 in the image area. We choose the strategy of alternating optimization: we first update {x < i >} mi = 1, {e < i >} mi = 1, and then together we update the solution. & lti These two steps are applied alternately until the algorithms converge."}, {"heading": "A. Learning Part Dictionaries with Constraint from Known", "text": "It is not as if this is a way in which it is a way in which it is about optimizing the d-dimensional formations so that, after the partial deformation, each part of the image referred to as D < i > k < i > k > p = 1, i = 1,.m, for the partial deformations, so that, after the partial deformations, each part of the image referred to as D < i > p < i > 2, i > n; i > n] with d < i > k = dk."}, {"heading": "B. Learning the Tree-structured Shape Model Jointly with Part Dictionaries", "text": "To solve this revised problem, one can alternately update the sub-dictionaries by using the algorithms in Appendix C that use the variables (A < i >} mi = 1, {E < i >} mi (A < i >} mi (A < i >) mi (A < i >) mi (1, E < i >) mi = 1 of the Gaussian distributions with the updated {Tk)} nk = 1. Unfortunately, this approach seems to provide empirically degenerated solutions that correspond to a \"non-elastic\" shape model in which the Gaussian distributions model the deformation differences of the connected nodes in the tree."}, {"heading": "C. Learning Mixture of CPA Models", "text": "The presented CPA model can be expanded as a mixture of CPA models (mCPA) to cope with a wider range of poses and / or expression variations. Each component of the mCPA is parameterized in the same way as that of a standard CPA model, but may have a different number of faces because some face parts may be hidden under poses. For an mCPA model with c components, we use I\u03b9 {1, 2,..., m} the index of available parts for the umpteenth component. Accordingly, we also use {D < i > \u03b9} mi = 1 to denote the subdictionaries and Z\u03b9 = {z < 1 >, z < 2 >. < z < m > \u00b2 to denote the parameters of tree-structured shape models."}, {"heading": "D\u03b9 \u25e6 \u03c3\u03b9 \u25e6 T \u3008i\u3009(\u03bd\u030c\u03b9) = A\u3008i\u3009\u03b9 + E\u3008i\u3009\u03b9 for i \u2208 I\u03b9.", "text": "In fact, it is as if it is a reactionary project, which is a reactionary project, which is first and foremost a reactionary project."}, {"heading": "A. Face Recognition Across Pose and Expression with Different Illumination", "text": "In fact, most people who are able to recognize themselves and understand how they have behaved are maneuvering themselves into a situation where they are maneuvering themselves into a situation where they can no longer help themselves and others."}, {"heading": "B. Effectiveness of Part-based Recognition in CPA method", "text": "In fact, the fact is that most of them are able to move to another world, in which they are able, in which they are able to move, and in which they are able, in which they are able to move."}, {"heading": "C. Recognition with Synthetic Random Block Occlusion", "text": "In this section, we report on experiments to demonstrate the robustness of CPA against partial occlusion. As shown in Figure 10, we partially synthesized occluded facial images of the probe by adding block occlusion at random positions on a probe surface. Occluded blocks varied in size from 10% to 60% of 16."}, {"heading": "10% 20% 30% 40% 50% 60%", "text": "The method [3], i.e. \"holistic + holistic,\" was used as the starting point. Fig. 11a reports detection rates in front-view facial images with different occlusion ratios, and Fig. 11b reports those with different aspects at an occlusion ratio of 30%. Compared to [3], Fig. 11a and Fig. 11b show that our CPA method is more robust against partial occlusion. If a small part (10%) of the facial images is obscured, the detection rate of [3] falls below 90%. In contrast, the detection rates of CPA remain above 90% when occlusion rates increase from 0% to 30%. At the 30% occlusion rate, the detection rate of CPA is more than 45% higher than that of [3] for a pose change of within \u00b1 15%."}, {"heading": "D. Comparison with the State-of-the-art", "text": "In this section, we used the Multi-PIE Dataset to connect CPA to the state of the art. [1] See how the CPA facial recognition method is able to learn MDF models by using a large number of 3D face shapes, while training CPA models requires only two of them. [2] While LDA models were learned from the outset, MDF models can be equipped with different properties and classification systems for recognition. To compare the two methods we use, we used the same LDA classifier for both methods. [3] While LDA models were learned to expand the gallery in the CPA method, a single LDA model was learned from the MDF method for recognition."}, {"heading": "VII. CONCLUSION", "text": "In this thesis, we propose a method known as CPA for acroscopy and facial recognition, from which one can benefit through pixel-by-pixel precise alignment. The CPA model consists of evidence of the appearance of each part and a tree-structured form model for limiting part deformation, both of which can be learned automatically from training images. To align a test image, we adapt its parts to the evidence of appearance, taking into account the limitations of the learned tree structure. It seems that Zhu's method [25] can only work very well if the training and test images have the same illumination. In order to handle the illumination variation in our experiments, we normalize the image illumination with the non-local method (NLM) before estimation. This goal is formulated as a standard minimization problem regulated by graph similarity, which can be efficiently solved by a alternating optimization method."}, {"heading": "ACKNOWLEDGEMENT", "text": "Thanks to [34] for the friendly preparation of the test results in the MDF model, which is reported in Table VI."}, {"heading": "APPENDIX A LINEAR SYSTEM IN (15)", "text": "Leave Q = [q1, q2,. \u2212 j., qm] for Rd \u00b7 m, (15) the same as the linear equation arrangement: G < i > \u03bd < i > + \u03b7 (zipp., qm) for i = 1, 2,.., m, which can be written in a more standardized form W11 W12 \u00b7 \u00b7 \u00b7 W1m W21 W22 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 W2m............. Wm1 Wm2 \u00b7 \u00b7 \u00b7 Wmm. < 1 >. < 2 >... < m > = c1 c2... cm, (26) where ci-Rd is a column vector, and Wij-Rd \u00b7 d. Remember that E is the boundary set of the tree-structured model. In particular, if i is the parent of j, it applies (< < < j)."}, {"heading": "APPENDIX B SOLVING TRANSFORMATIONS IN (16) WITH FIXED PARTS", "text": "G is the 2-D similarity group defined in Rd (d = > > > < u >) as defined in (1). Initial values in (1) and (2) cannot be changed."}, {"heading": "APPENDIX C SOLUTION TO (19)", "text": "We solve (19) alternately the following two steps: < < i > < i > < i > < i > < i > < i > < i > < i > < i > < i > < i >, i >, i =, i >, i (A < i >), i (A < i >), i (A < i >, i >, i >, i >, i =, i (A < i >), i (A < i >, i >, i >, i >, i >, i >, i >, i >, i >, i (A < i >, i >, i >, i >, i >, i >, i (A < i >, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i >, i, i, i, i, i, i, i, < i, i, i >, i >, i >, i >, i, i >, i >, i, i >, i >, i >, i, i, i, < i < i, i >, i >, i, i >, i >, i >, i >, i >, i >, i >, i"}, {"heading": "APPENDIX D MAXIMUM A POSTERIORI WITH GAUSSIAN-WISHART PRIOR", "text": "The PDF of the Gaussian Wishart distribution is the conjugation before the Gaussian distribution, where \"conjugation\" means that the previous and corresponding posterior distribution is 0 +, Vaussian Wishart distribution 0 + 0, Vaussian Wishart distribution 0 + 0, Vaussian Wishart distribution 0 + 0, Vaussian Wishart distribution 0 + 0, Vaussian distribution 0 + 0, Vaussian Wishart distribution 0, where \"conjugation\" means that the previous and corresponding posterior distribution is 0, Vaussys distribution 0 + 0, Vaussys distribution 0 + 0, Vaussys distribution 0, Vaussys distribution 0, Vaussys distribution 0, Vaussys distribution 0, Vaussys distribution 0, Vaussys distribution 0, Vaussys distributions 0."}], "references": [{"title": "Face recognition: A literature survey", "author": ["W. Zhao", "R. Chellappa", "P.J. Phillips", "A. Rosenfeld"], "venue": "ACM Comput. Surv., vol. 35, no. 4, pp. 399\u2013458, Dec. 2003.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "Acquiring linear subspaces for face recognition under variable lighting", "author": ["K.-C. Lee", "J. Ho", "D. Kriegman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, no. 5, pp. 684 \u2013698, may 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Toward a practical face recognition system: Robust alignment and illumination by sparse representation", "author": ["A. Wagner", "J. Wright", "A. Ganesh", "Z. Zhou", "H. Mobahi", "Y. Ma"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, no. 2, pp. 372 \u2013386, feb. 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "What is the set of images of an object under all possible illumination conditions?", "author": ["P. Belhumeur", "D. Kriegman"], "venue": "International Journal of Computer Vision,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "From few to many: illumination cone models for face recognition under variable lighting and pose", "author": ["A. Georghiades", "P. Belhumeur", "D. Kriegman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, no. 6, pp. 643 \u2013660, jun 2001.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Total variation models for variable lighting face recognition", "author": ["T. Chen", "W. Yin", "X.S. Zhou", "D. Comaniciu", "T. Huang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 9, pp. 1519 \u20131524, sept. 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Appearance characterization of linear lambertian objects, generalized photometric stereo, and illumination-invariant face recognition", "author": ["S. Zhou", "G. Aggarwal", "R. Chellappa", "D. Jacobs"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 2, pp. 230 \u2013245, feb. 2007.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "View-based and modular eigenspaces for face recognition", "author": ["A. Pentland", "B. Moghaddam", "T. Starner"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 1994. Proceedings CVPR \u201994., jun 1994, pp. 84 \u201391.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1994}, {"title": "Face recognition under varying pose", "author": ["D. Beymer"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 1994. Proceedings CVPR \u201994., jun 1994, pp. 756 \u2013761.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "Tied factor analysis for face recognition across large pose differences", "author": ["S. Prince", "J. Warrell", "J. Elder", "F. Felisberti"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 6, pp. 970 \u2013984, june 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "A compressive sensing approach for expression-invariant face recognition", "author": ["P. Nagesh", "B. Li"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009., june 2009, pp. 1518 \u20131525.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Eigen lightfields and face recognition across pose", "author": ["R. Gross", "I. Matthews", "S. Baker"], "venue": "Fifth IEEE International Conference on Automatic Face and Gesture Recognition, 2002. Proceedings., may 2002, pp. 1 \u20137.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Locally linear regression for pose-invariant face recognition", "author": ["X. Chai", "S. Shan", "X. Chen", "W. Gao"], "venue": "IEEE  Transactions on Image Processing, vol. 16, no. 7, pp. 1716 \u20131725, july 2007.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning patch correspondences for improved viewpoint invariant face recognition", "author": ["A. Ashraf", "S. Lucey", "T. Chen"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2008. CVPR 2008., june 2008, pp. 1 \u20138.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "A deformation and lighting insensitive metric for face recognition based on dense correspondences", "author": ["A. Jorstad", "D. Jacobs", "A. Trouve"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011, june 2011, pp. 2353 \u20132360.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Energy normalization for poseinvariant face recognition based on MRF model image matching", "author": ["S. Arashloo", "J. Kittler"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 6, pp. 1274 \u20131280, june 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Wide-baseline stereo for face recognition with large pose variation", "author": ["C. Castillo", "D. Jacobs"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011, june 2011, pp. 537 \u2013544.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Active appearance models", "author": ["T. Cootes", "G. Edwards", "C. Taylor"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, no. 6, pp. 681 \u2013685, jun 2001.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2001}, {"title": "Active appearance models revisited", "author": ["I. Matthews", "S. Baker"], "venue": "International Journal of Computer Vision, vol. 60, no. 2, pp. 135\u2013164, 2004.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Face recognition by elastic bunch graph matching", "author": ["L. Wiskott", "J.-M. Fellous", "N. Kruger", "C. von der Malsburg"], "venue": "Proceedings., International Conference on Image Processing, 1997., vol. 1, oct 1997, pp. 129 \u2013132 vol.1.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "Feature detection and tracking with constrained local models", "author": ["D. Cristinacce", "T. Cootes"], "venue": "Proc. British Machine Vision Conference, vol. 3, 2006, pp. 929\u2013938.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Localizing parts of faces using a consensus of exemplars", "author": ["P. Belhumeur", "D. Jacobs", "D. Kriegman", "N. Kumar"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011, june 2011, pp. 545 \u2013552.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Deformable model fitting by regularized landmark mean-shift", "author": ["J. Saragih", "S. Lucey", "J. Cohn"], "venue": "International Journal of Computer Vision, vol. 91, pp. 200\u2013215, 2011.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Object detection with discriminatively trained part-based models", "author": ["P. Felzenszwalb", "R. Girshick", "D. McAllester", "D. Ramanan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 32, no. 9, pp. 1627 \u20131645, sept. 2010.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Face detection, pose estimation, and landmark localization in the wild", "author": ["X. Zhu", "D. Ramanan"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012, june 2012, pp. 2879 \u20132886.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Robust face recognition via sparse representation", "author": ["J. Wright", "A. Yang", "A. Ganesh", "S. Sastry", "Y. Ma"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 31, no. 2, pp. 210 \u2013227, feb. 2009.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Hierarchical ensemble of gabor fisher classifier for face recognition", "author": ["Y. Su", "S. Shan", "X. Chen", "W. Gao"], "venue": " 21 in Automatic Face and Gesture Recognition, 2006. FGR 2006. 7th International Conference on, 2006, pp. 6 pp.\u2013 96.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Partbased face recognition using near infrared images", "author": ["K. Pan", "S. Liao", "Z. Zhang", "S. Li", "P. Zhang"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR \u201907. IEEE Conference on, 2007, pp. 1\u20136.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}, {"title": "Maximizing all margins: Pushing face recognition with kernel plurality", "author": ["R. Kumar", "A. Banerjee", "B. Vemuri", "H. Pfister"], "venue": "2011 IEEE International Conference on Computer Vision (ICCV), 2011, pp. 2375\u20132382.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiobservation visual recognition via joint dynamic sparse representation", "author": ["H. Zhang", "N. Nasrabadi", "Y. Zhang", "T. Huang"], "venue": "2011 IEEE International Conference on Computer Vision (ICCV), 2011, pp. 595\u2013602.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Which parts of the face give out your identity?", "author": ["O. Ocegueda", "S. Shah", "I. Kakadiaris"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Multi-PIE", "author": ["R. Gross", "I. Matthews", "J. Cohn", "T. Kanade", "S. Baker"], "venue": "Image and Vision Computing, vol. 28, no. 5, pp. 807 \u2013 813, 2010, best of Automatic Face and Gesture Recognition 2008.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "The MUCT Landmarked Face Database", "author": ["S. Milborrow", "J. Morkel", "F. Nicolls"], "venue": "Pattern Recognition Association of South Africa, 2010, http://www.milbo.org/muct/.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Morphable displacement field based image matching for face recognition across pose", "author": ["S. Li", "X. Liu", "X. Chai", "H. Zhang", "S. Lao", "S. Shan"], "venue": "European Conference on Computer Vision (ECCV) 2012, ser. Lecture Notes in Computer Science, vol. 7572. Springer Berlin Heidelberg, 2012, pp. 102\u2013115.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Fully automatic pose-invariant face recognition via 3D pose normalization", "author": ["A. Asthana", "T. Marks", "M. Jones", "K. Tieu", "M. Rohith"], "venue": "IEEE International Conference on Computer Vision (ICCV), 2011, nov. 2011, pp. 937 \u2013944.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}, {"title": "Face recognition based on fitting a 3D morphable model", "author": ["V. Blanz", "T. Vetter"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 25, no. 9, pp. 1063 \u2013 1074, sept. 2003.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "Layered object models for image segmentation", "author": ["Y. Yang", "S. Hallman", "D. Ramanan", "C. Fowlkes"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, no. 9, pp. 1731 \u20131743, sept. 2012.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images", "author": ["Y. Peng", "A. Ganesh", "J. Wright", "W. Xu", "Y. Ma"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. PP, no. 99, p. 1, 2012.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices", "author": ["Z. Lin", "M. Chen", "Y. Ma"], "venue": "University of Illinois at Urbana- Champaign, Tech. Rep. UILU-ENG-09-2215, 2009.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "Rapid object detection using a boosted cascade of simple features", "author": ["P. Viola", "M. Jones"], "venue": "Proceedings of the  2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2001. CVPR 2001., vol. 1, 2001, pp. I\u2013511 \u2013 I\u2013518 vol.1.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2001}, {"title": "Face description with local binary patterns: Application to face recognition", "author": ["T. Ahonen", "A. Hadid", "M. Pietikainen"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 12, pp. 2037 \u20132041, dec. 2006.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2006}, {"title": "Eigenfaces vs. Fisherfaces: recognition using class specific linear projection", "author": ["P. Belhumeur", "J. Hespanha", "D. Kriegman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19, no. 7, pp. 711 \u2013720, jul 1997.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1997}, {"title": "Robust principal component analysis?", "author": ["E.J. Cand\u00e8s", "X. Li", "Y. Ma", "J. Wright"], "venue": "J. ACM,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2011}, {"title": "Approximating discrete probability distributions with dependence trees", "author": ["C. Chow", "C. Liu"], "venue": "IEEE Transactions on Information Theory, vol. 14, no. 3, pp. 462 \u2013 467, may 1968.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1968}, {"title": "Illumination invariant face recognition by non-local smoothing", "author": ["V. \u0160truc", "N. Pave\u0161ic"], "venue": "Biometric ID Management and Multimodal Communication, ser. Lecture Notes in Computer Science, J. Fierrez, J. Ortega- Garcia, A. Esposito, A. Drygajlo, and M. Faundez-Zanuy, Eds. Springer Berlin Heidelberg, 2009, vol. 5707, pp. 1\u20138.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "In more practical scenarios, performance of these existing methods degrades drastically due to face variations caused by illumination, pose, and/or expression changes [1].", "startOffset": 167, "endOffset": 170}, {"referenceID": 1, "context": "[2], Wagner et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3], motivated by the illumination cone model [4, 5], used multiple carefully chosen face images of varying illuminations per subject as gallery.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[3], motivated by the illumination cone model [4, 5], used multiple carefully chosen face images of varying illuminations per subject as gallery.", "startOffset": 46, "endOffset": 52}, {"referenceID": 4, "context": "[3], motivated by the illumination cone model [4, 5], used multiple carefully chosen face images of varying illuminations per subject as gallery.", "startOffset": 46, "endOffset": 52}, {"referenceID": 5, "context": "edu) alternative methods [6, 7] considered extracting illumination invariant features for face recognition.", "startOffset": 25, "endOffset": 31}, {"referenceID": 6, "context": "edu) alternative methods [6, 7] considered extracting illumination invariant features for face recognition.", "startOffset": 25, "endOffset": 31}, {"referenceID": 7, "context": "To address pose or expression variations, earlier approaches extend classic subspace or template based face recognition methods [8, 9].", "startOffset": 128, "endOffset": 134}, {"referenceID": 8, "context": "To address pose or expression variations, earlier approaches extend classic subspace or template based face recognition methods [8, 9].", "startOffset": 128, "endOffset": 134}, {"referenceID": 9, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 144, "endOffset": 156}, {"referenceID": 10, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 144, "endOffset": 156}, {"referenceID": 11, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 144, "endOffset": 156}, {"referenceID": 12, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 353, "endOffset": 373}, {"referenceID": 13, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 353, "endOffset": 373}, {"referenceID": 14, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 353, "endOffset": 373}, {"referenceID": 15, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 353, "endOffset": 373}, {"referenceID": 16, "context": "To recognize a probe face with pose or expression changes, they either identified an implicit identity feature/representation of the probe face [10, 11, 12], which is pose- and expression-invariant, or explicitly estimate global or local mappings of facial appearance so that a virtual face under the normal condition can be synthesized for recognition [13, 14, 15, 16, 17].", "startOffset": 353, "endOffset": 373}, {"referenceID": 17, "context": ", the Active Appearance Models (AAMs) [18, 19] and elastic graph matching (EGM) [20].", "startOffset": 38, "endOffset": 46}, {"referenceID": 18, "context": ", the Active Appearance Models (AAMs) [18, 19] and elastic graph matching (EGM) [20].", "startOffset": 38, "endOffset": 46}, {"referenceID": 19, "context": ", the Active Appearance Models (AAMs) [18, 19] and elastic graph matching (EGM) [20].", "startOffset": 80, "endOffset": 84}, {"referenceID": 20, "context": "To improve the localization accuracy, an explicit shape constraint for graph nodes was considered in the constrained local models (CLMs) [21].", "startOffset": 137, "endOffset": 141}, {"referenceID": 20, "context": "CLMs [21, 22, 23] are still based on densely-connected graph models, and their shape constraints are over-simplified so that the dependency among different graph nodes is ignored.", "startOffset": 5, "endOffset": 17}, {"referenceID": 21, "context": "CLMs [21, 22, 23] are still based on densely-connected graph models, and their shape constraints are over-simplified so that the dependency among different graph nodes is ignored.", "startOffset": 5, "endOffset": 17}, {"referenceID": 22, "context": "CLMs [21, 22, 23] are still based on densely-connected graph models, and their shape constraints are over-simplified so that the dependency among different graph nodes is ignored.", "startOffset": 5, "endOffset": 17}, {"referenceID": 23, "context": "Recently, deformable part-based models (DPMs) show their promise in many applications such as object detection [24] and facial landmark localization [25].", "startOffset": 111, "endOffset": 115}, {"referenceID": 24, "context": "Recently, deformable part-based models (DPMs) show their promise in many applications such as object detection [24] and facial landmark localization [25].", "startOffset": 149, "endOffset": 153}, {"referenceID": 24, "context": "In particular, Zhu and Ramanan [25] adopted a tree-structured part model, which encodes node dependency while admitting efficient solutions.", "startOffset": 31, "endOffset": 35}, {"referenceID": 24, "context": "Such a tree model was used by Zhu and Ramanan [25] for facial landmark localization.", "startOffset": 46, "endOffset": 50}, {"referenceID": 2, "context": "[3] recently leveraged sparsity optimization and a carefully prepared gallery set (multiple images of varying illuminations per subject), to align probe ar X iv :1 50 1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "Our method is partially motivated by the promise of piece-wise planar formulation and the explicit shape constraints used in CLMs [21, 22, 23] and DPMs [24, 25].", "startOffset": 130, "endOffset": 142}, {"referenceID": 21, "context": "Our method is partially motivated by the promise of piece-wise planar formulation and the explicit shape constraints used in CLMs [21, 22, 23] and DPMs [24, 25].", "startOffset": 130, "endOffset": 142}, {"referenceID": 22, "context": "Our method is partially motivated by the promise of piece-wise planar formulation and the explicit shape constraints used in CLMs [21, 22, 23] and DPMs [24, 25].", "startOffset": 130, "endOffset": 142}, {"referenceID": 23, "context": "Our method is partially motivated by the promise of piece-wise planar formulation and the explicit shape constraints used in CLMs [21, 22, 23] and DPMs [24, 25].", "startOffset": 152, "endOffset": 160}, {"referenceID": 24, "context": "Our method is partially motivated by the promise of piece-wise planar formulation and the explicit shape constraints used in CLMs [21, 22, 23] and DPMs [24, 25].", "startOffset": 152, "endOffset": 160}, {"referenceID": 2, "context": ", [3, 26].", "startOffset": 2, "endOffset": 9}, {"referenceID": 25, "context": ", [3, 26].", "startOffset": 2, "endOffset": 9}, {"referenceID": 26, "context": "Part-based face recognition methods [27, 28, 29, 30, 31] have shown improved performance over more standard approaches using holistic faces.", "startOffset": 36, "endOffset": 56}, {"referenceID": 27, "context": "Part-based face recognition methods [27, 28, 29, 30, 31] have shown improved performance over more standard approaches using holistic faces.", "startOffset": 36, "endOffset": 56}, {"referenceID": 28, "context": "Part-based face recognition methods [27, 28, 29, 30, 31] have shown improved performance over more standard approaches using holistic faces.", "startOffset": 36, "endOffset": 56}, {"referenceID": 29, "context": "Part-based face recognition methods [27, 28, 29, 30, 31] have shown improved performance over more standard approaches using holistic faces.", "startOffset": 36, "endOffset": 56}, {"referenceID": 30, "context": "Part-based face recognition methods [27, 28, 29, 30, 31] have shown improved performance over more standard approaches using holistic faces.", "startOffset": 36, "endOffset": 56}, {"referenceID": 31, "context": "In this paper, we present experiments on the Multi-PIE [32] and MUCT [33] datasets and show that our proposed CPA method can simultaneously and effectively handle illumination, pose, and/or expression variations.", "startOffset": 55, "endOffset": 59}, {"referenceID": 32, "context": "In this paper, we present experiments on the Multi-PIE [32] and MUCT [33] datasets and show that our proposed CPA method can simultaneously and effectively handle illumination, pose, and/or expression variations.", "startOffset": 69, "endOffset": 73}, {"referenceID": 33, "context": "\u2022 State-of-the-art pose-invariant face recognition method [34] relies on model learning using a large number of 3D face shapes, while training of our proposed CPA only requires 2D face images of a few subjects.", "startOffset": 58, "endOffset": 62}, {"referenceID": 33, "context": "[34].", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] learned local patch based mapping relations from nonfrontal pose to frontal pose by locally linear regression.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] estimated pixel-wise registration from non-neutral expression to neutral expression by optical flow.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Arashloo and Kittler [16] considered a Markov random field (MRF) model to regularize 2D displacements of local patches across different poses.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "For automatic face recognition across pose, given a probe face image, AAMs [18, 19] optimized localization of a set of facial landmarks to realize face alignment of pixel-level accuracy.", "startOffset": 75, "endOffset": 83}, {"referenceID": 18, "context": "For automatic face recognition across pose, given a probe face image, AAMs [18, 19] optimized localization of a set of facial landmarks to realize face alignment of pixel-level accuracy.", "startOffset": 75, "endOffset": 83}, {"referenceID": 34, "context": "However, the landmarks localized by AAMs are usually not accurate enough, and also the pixelwise correspondence induced by matched landmarks are not consistent enough across different poses and expressions [35].", "startOffset": 206, "endOffset": 210}, {"referenceID": 35, "context": "Among existing methods, maybe the most successful ones across pose and/or expression are based on 3D models [36, 35, 34].", "startOffset": 108, "endOffset": 120}, {"referenceID": 34, "context": "Among existing methods, maybe the most successful ones across pose and/or expression are based on 3D models [36, 35, 34].", "startOffset": 108, "endOffset": 120}, {"referenceID": 33, "context": "Among existing methods, maybe the most successful ones across pose and/or expression are based on 3D models [36, 35, 34].", "startOffset": 108, "endOffset": 120}, {"referenceID": 23, "context": "Deformable part models (DPM) have shown their success in object detection [24], facial landmark localization [25], and human pose estimation [37].", "startOffset": 74, "endOffset": 78}, {"referenceID": 24, "context": "Deformable part models (DPM) have shown their success in object detection [24], facial landmark localization [25], and human pose estimation [37].", "startOffset": 109, "endOffset": 113}, {"referenceID": 36, "context": "Deformable part models (DPM) have shown their success in object detection [24], facial landmark localization [25], and human pose estimation [37].", "startOffset": 141, "endOffset": 145}, {"referenceID": 23, "context": "Our use of part-based models is different from the DPM based methods [24, 25, 37].", "startOffset": 69, "endOffset": 81}, {"referenceID": 24, "context": "Our use of part-based models is different from the DPM based methods [24, 25, 37].", "startOffset": 69, "endOffset": 81}, {"referenceID": 36, "context": "Our use of part-based models is different from the DPM based methods [24, 25, 37].", "startOffset": 69, "endOffset": 81}, {"referenceID": 24, "context": "Compared with shape constraints in DPMs [25, 37], our proposed one models more complex relations with the part constellation and holds strict probabilistic properties that are beneficial to the model learning.", "startOffset": 40, "endOffset": 48}, {"referenceID": 36, "context": "Compared with shape constraints in DPMs [25, 37], our proposed one models more complex relations with the part constellation and holds strict probabilistic properties that are beneficial to the model learning.", "startOffset": 40, "endOffset": 48}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3]\u2019s method at Iteration 17 y D\u00b7x e", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "1 To pursue \u03bd, we consider techniques used in [26, 3].", "startOffset": 46, "endOffset": 53}, {"referenceID": 2, "context": "1 To pursue \u03bd, we consider techniques used in [26, 3].", "startOffset": 46, "endOffset": 53}, {"referenceID": 25, "context": "[26], Wagner et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3] assumed there exist multiple registered face images of varying illuminations per subject in the database.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] optimized a holistic similarity transformation by solving a `-norm minimization problem.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Extending techniques in [3] directly to part-based alignment gives the following objective", "startOffset": 24, "endOffset": 27}, {"referenceID": 2, "context": "The above direct extension of [3] essentially aligns the m parts independently.", "startOffset": 30, "endOffset": 33}, {"referenceID": 24, "context": "In particular, we are motivated by [25] to use a tree-structured shape model to constrain the difference of transformation parameters of different parts.", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "We note that CPA is not designed to produce a seamless face constituted by deformed individual parts, as AAMs [18, 19] can do.", "startOffset": 110, "endOffset": 118}, {"referenceID": 18, "context": "We note that CPA is not designed to produce a seamless face constituted by deformed individual parts, as AAMs [18, 19] can do.", "startOffset": 110, "endOffset": 118}, {"referenceID": 24, "context": "Similar tree-structured shape model and quadratic regularization term were also used in [25] for face detection and facial landmark localization.", "startOffset": 88, "endOffset": 92}, {"referenceID": 24, "context": "Compared to [25], our shape constraint is derived from a Bayesian network formulation, which not only interprets the underlying probabilistic properties of treestructured shape models, but also enables maximum a posteriori (MAP) estimation of the model parameters Z in the training stage of CPA.", "startOffset": 12, "endOffset": 16}, {"referenceID": 24, "context": "This scenario is different from [25], as their tree-structured shape model is integrated in a classification problem, which is strongly supervised.", "startOffset": 32, "endOffset": 36}, {"referenceID": 20, "context": "In fact, parametrization of AAMs and CLMs [21, 23] is also based on a joint Gaussian model, which seems to be similar to (6) derived from a tree model.", "startOffset": 42, "endOffset": 50}, {"referenceID": 22, "context": "In fact, parametrization of AAMs and CLMs [21, 23] is also based on a joint Gaussian model, which seems to be similar to (6) derived from a tree model.", "startOffset": 42, "endOffset": 50}, {"referenceID": 37, "context": "Similar iterative techniques have also been used in related works [38, 3], and showed good behaviors of convergence.", "startOffset": 66, "endOffset": 73}, {"referenceID": 2, "context": "Similar iterative techniques have also been used in related works [38, 3], and showed good behaviors of convergence.", "startOffset": 66, "endOffset": 73}, {"referenceID": 38, "context": "We solve the convex problem (8) by adapting the Augmented Lagrange Multiplier (ALM) method [39].", "startOffset": 91, "endOffset": 95}, {"referenceID": 38, "context": "Compared to exact ALM, inexact ALM shows better practical performance in terms of optimization efficiency [39].", "startOffset": 106, "endOffset": 110}, {"referenceID": 39, "context": "In practice, we rely on off-the-shelf face detectors [41, 25], which provide a rough bounding box of the face or the holistic pose and locations of facial parts [25].", "startOffset": 53, "endOffset": 61}, {"referenceID": 24, "context": "In practice, we rely on off-the-shelf face detectors [41, 25], which provide a rough bounding box of the face or the holistic pose and locations of facial parts [25].", "startOffset": 53, "endOffset": 61}, {"referenceID": 24, "context": "In practice, we rely on off-the-shelf face detectors [41, 25], which provide a rough bounding box of the face or the holistic pose and locations of facial parts [25].", "startOffset": 161, "endOffset": 165}, {"referenceID": 2, "context": "[3] to initialize the holistic transformation \u03c3.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "However, similar to the situation of holistic face alignment in [3], the presence of facial parts of multiple subjects in {D}i=1 makes (7) have many local minima, corresponding to aligning y to the facial parts of different subjects.", "startOffset": 64, "endOffset": 67}, {"referenceID": 25, "context": "For part-based face recognition, many existing methods such as SRC [26], LBP [42] and LDA [43] can be used at the part level, based on the pruned gallery.", "startOffset": 67, "endOffset": 71}, {"referenceID": 40, "context": "For part-based face recognition, many existing methods such as SRC [26], LBP [42] and LDA [43] can be used at the part level, based on the pruned gallery.", "startOffset": 77, "endOffset": 81}, {"referenceID": 41, "context": "For part-based face recognition, many existing methods such as SRC [26], LBP [42] and LDA [43] can be used at the part level, based on the pruned gallery.", "startOffset": 90, "endOffset": 94}, {"referenceID": 28, "context": "For obtaining better performance, we may adapt advanced aggregating schemes, such as the kernelized plurality voting [29], and joint recognition method for multiple observations, such as the joint dynamic sparse representation [30].", "startOffset": 117, "endOffset": 121}, {"referenceID": 29, "context": "For obtaining better performance, we may adapt advanced aggregating schemes, such as the kernelized plurality voting [29], and joint recognition method for multiple observations, such as the joint dynamic sparse representation [30].", "startOffset": 227, "endOffset": 231}, {"referenceID": 37, "context": "[38] to align a batch of linearly correlated images, such as frames in a video sequence or face images of a same subject.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "[38]\u2019s method at 20 iterations", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "by [38], in this paper, we leverage the very similar low-rank (matrices of part dictionaries without nuisances) and sparsity (error matrices modeling various variations) properties to align and form the part dictionaries.", "startOffset": 3, "endOffset": 7}, {"referenceID": 37, "context": "[38] to perform independent partbased alignment, the alignment process often converges to less meaningful solutions as shown in Fig.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3] in the case of aligning parts of a probe face to the gallery set, as we explained in Section III.", "startOffset": 0, "endOffset": 3}, {"referenceID": 37, "context": "[38], Cand\u00e8s et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[44], the penalty parameters {\u03bb}i=1 can be set as the reciprocal of the square root of E\u3008i\u3009\u2019s row number, denoted as \u03c9\u3008i\u3009.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "In this illustration, we use 60 images from the MUCT dataset [33] to learn the CPA model define in Fig.", "startOffset": 61, "endOffset": 65}, {"referenceID": 39, "context": "The above algorithms for CPA model learning require a careful initialization on \u03c3 and \u03bd\u030c, which can be done either by detectors [41, 25] or by manual annotations.", "startOffset": 128, "endOffset": 136}, {"referenceID": 24, "context": "The above algorithms for CPA model learning require a careful initialization on \u03c3 and \u03bd\u030c, which can be done either by detectors [41, 25] or by manual annotations.", "startOffset": 128, "endOffset": 136}, {"referenceID": 24, "context": "To learn the configuration of a tree, Zhu and Ramanan [25] used Chow and Liu [45] algorithm for the application of facial landmark localization.", "startOffset": 54, "endOffset": 58}, {"referenceID": 43, "context": "To learn the configuration of a tree, Zhu and Ramanan [25] used Chow and Liu [45] algorithm for the application of facial landmark localization.", "startOffset": 77, "endOffset": 81}, {"referenceID": 24, "context": "However, for a node with children, our tree-structured shape model (as well as Zhu and Ramanan [25]\u2019s shape model) assumes the independence between its part transformation and its part transformation differences with its children (refer to Section III-A), which is not an assumption for Chow-Liu algorithm.", "startOffset": 95, "endOffset": 99}, {"referenceID": 31, "context": "We used the CMU Multi-PIE [32] and MUCT [33] datasets to conduct our experiments.", "startOffset": 26, "endOffset": 30}, {"referenceID": 32, "context": "We used the CMU Multi-PIE [32] and MUCT [33] datasets to conduct our experiments.", "startOffset": 40, "endOffset": 44}, {"referenceID": 39, "context": "For practical experiments in Section VI-D that conduct fully automatic face recognition across pose, we used off-the-shelf face detector [41] and pose estimator [25] to initialize our method.", "startOffset": 137, "endOffset": 141}, {"referenceID": 24, "context": "For practical experiments in Section VI-D that conduct fully automatic face recognition across pose, we used off-the-shelf face detector [41] and pose estimator [25] to initialize our method.", "startOffset": 161, "endOffset": 165}, {"referenceID": 25, "context": "Our choice of off-the-shelf methods for face recognition across illumination is based on SRC [26], for which we used multiple gallery images of varying illuminations for each subject.", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "If using SRC [26] as a classifier, this alternative is essentially the same as in [3], which is", "startOffset": 13, "endOffset": 17}, {"referenceID": 2, "context": "If using SRC [26] as a classifier, this alternative is essentially the same as in [3], which is", "startOffset": 82, "endOffset": 85}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "1) Evaluation on the Multi-PIE Dataset : The CMU MultiPIE [32] is the largest publicly available dataset suitable for test of our CPA method.", "startOffset": 58, "endOffset": 62}, {"referenceID": 2, "context": ", the method in [3].", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "Representatives of these methods include Nearest Subspace (NS) [2], Linear Discriminate Analysis (LDA) [43], and Local Binary Pattern", "startOffset": 63, "endOffset": 66}, {"referenceID": 41, "context": "Representatives of these methods include Nearest Subspace (NS) [2], Linear Discriminate Analysis (LDA) [43], and Local Binary Pattern", "startOffset": 103, "endOffset": 107}, {"referenceID": 40, "context": "(LBP) [42].", "startOffset": 6, "endOffset": 10}, {"referenceID": 2, "context": "The method [3], i.", "startOffset": 11, "endOffset": 14}, {"referenceID": 2, "context": "Compared with [3], Fig.", "startOffset": 14, "endOffset": 17}, {"referenceID": 2, "context": "When a small portion (10%) of face images is occluded, recognition rate of [3] drops below 90%.", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "For the 30% occlusion ratio, recognition rate of CPA is more than 45% higher than that of [3] for pose change of within \u00b115\u25e6.", "startOffset": 90, "endOffset": 93}, {"referenceID": 33, "context": "In this section, we used the Multi-PIE dataset to compare CPA with the state-of-the-art Morphable Displacement Field (MDF) method [34] for face recognition across pose.", "startOffset": 130, "endOffset": 134}, {"referenceID": 33, "context": "[34], we used the last 137 subjects instead of the first 229 ones in Multi-PIE for testing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "We realize a fully automatic CPA method by initializing our algorithm using Viola and Jones [41]\u2019s face detector, followed by a coarse and holistic alignment using the method of Wagner et al.", "startOffset": 92, "endOffset": 96}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 33, "context": "[34].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "we consider two situations where poses of probe faces are either known in advance or estimated by Zhu and Ramanan [25]\u2019s method.", "startOffset": 114, "endOffset": 118}, {"referenceID": 39, "context": "Note that the fully automatic alignment works from coarse to fine granularity, say, sequentially uses Viola and Jones [41]\u2019s face detector, the method of Wagner et al.", "startOffset": 118, "endOffset": 122}, {"referenceID": 2, "context": "[3] for a holistic alignment, and partbased alignment by CPA.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "For larger degrees of pose change, performance of holistic alignment by [3] drops.", "startOffset": 72, "endOffset": 75}, {"referenceID": 24, "context": "\u2019s method [25] can work very well only when the training and test images are with the same illumination.", "startOffset": 10, "endOffset": 14}, {"referenceID": 44, "context": "To handle the illumination variation in our experiments, we normalized image illumination by the non-local means (NLM) based method [46] before pose estimation.", "startOffset": 132, "endOffset": 136}, {"referenceID": 33, "context": "Thanks to [34] for kindly producing the experimental results on the MDF model that are reported in Table VI.", "startOffset": 10, "endOffset": 14}], "year": 2015, "abstractText": "Developing a reliable and practical face recognition system is a long-standing goal in computer vision research. Existing literature suggests that pixel-wise face alignment is the key to achieve high-accuracy face recognition. By assuming a human face as piece-wise planar surfaces, where each surface corresponds to a facial part, we develop in this paper a Constrained Part-based Alignment (CPA) algorithm for face recognition across pose and/or expression. Our proposed algorithm is based on a trainable CPA model, which learns appearance evidence of individual parts and a tree-structured shape configuration among different parts. Given a probe face, CPA simultaneously aligns all its parts by fitting them to the appearance evidence with consideration of the constraint from the tree-structured shape configuration. This objective is formulated as a norm minimization problem regularized by graph likelihoods. CPA can be easily integrated with many existing classifiers to perform partbased face recognition. Extensive experiments on benchmark face datasets show that CPA outperforms or is on par with existing methods for robust face recognition across pose, expression, and/or illumination changes.", "creator": "LaTeX with hyperref package"}}}