{"id": "1501.05141", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2015", "title": "An Algebra to Merge Heterogeneous Classifiers", "abstract": "In distributed classification, each learner observes its environment and deduces a classifier. As a learner has only a local view of its environment, classifiers can be exchanged among the learners and integrated, or merged, to improve accuracy. However, the operation of merging is not defined for most classifiers. Furthermore, the classifiers that have to be merged may be of different types in settings such as ad-hoc networks in which several generations of sensors may be creating classifiers. We introduce decision spaces as a framework for merging possibly different classifiers. We formally study the merging operation as an algebra, and prove that it satisfies a desirable set of properties. The impact of time is discussed for the two main data mining settings. Firstly, decision spaces can naturally be used with non-stationary distributions, such as the data collected by sensor networks, as the impact of a model decays over time. Secondly, we introduce an approach for stationary distributions, such as homogeneous databases partitioned over different learners, which ensures that all models have the same impact. We also present a method that uses storage flexibly to achieve different types of decay for non-stationary distributions. Finally, we show that the algebraic approach developed for merging can also be used to analyze the behaviour of other operators.", "histories": [["v1", "Wed, 21 Jan 2015 11:42:58 GMT  (1076kb)", "https://arxiv.org/abs/1501.05141v1", "19 pages, 8 figures"], ["v2", "Thu, 22 Jan 2015 12:18:56 GMT  (1076kb)", "http://arxiv.org/abs/1501.05141v2", "19 pages, 8 figures"]], "COMMENTS": "19 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.DM cs.LG", "authors": ["philippe j giabbanelli", "joseph g peters"], "accepted": false, "id": "1501.05141"}, "pdf": {"name": "1501.05141.pdf", "metadata": {"source": "CRF", "title": "An Algebra to Merge Heterogeneous Classifiers", "authors": ["Philippe J. Giabbanellia", "Joseph G. Petersb"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 1.05 141v 2 [cs.D M] 22 Jan 2015In the distributed classification, each learner observes his or her environment and derives a classifier from it. Since a learner only has a local view of his or her environment, classifiers can be exchanged and integrated or merged between learners to improve accuracy. However, the operation of the merger is not defined for most classifiers. Furthermore, the classifiers that need to be merged can be of different types in environments such as ad hoc networks, where multiple generations of sensors can create classifiers. We introduce decision spaces as a framework for merging potentially different classifiers. We formally examine the merger process as algebra and prove that it fulfils a desirable set of characteristics. The effects of time are discussed for the two main data mining settings. First, of course, decision spaces can be used with non-stationary distributions, as the sensor network data collected from a model is not designed to affect the time divided."}, {"heading": "1. Introduction", "text": "A variety of classification systems, such as sensors and peer-to-peer networks, have been classified as classifying systems. These entities have observations from their local environments, for example as databases of observed tuples. Entities often have to adapt to future changes, but their local views may be too limited to make accurate predictions. Therefore, a global classification method that can be used to predict global trends may often be desirable. Entities could not calculate global classifiers by directly exchanging their datasets, due to safety concerns, or because the large amount of information could be overwhelmed, such as local storage or battery capacity. Therefore, the global classifier needs to be realized by combining the classifiers. The need to combine classifiers in other situations also results in the need to combine classifiers. Several examples illustrate the need to combine classifiers in Section 2 and others can be found."}, {"heading": "2. Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Combining maps", "text": "Consider the occurrence of a chronic disease in a city. For each part of the city, we want to know if the incidence is high enough to trigger specific action. Different groups provide maps of the disease, but these groups may not use the same spatial unit. One group may have divided the city into blocks, while another uses administrative boundaries. In addition, reports may have been published in different months, and administrative boundaries may have evolved. Therefore, we need to merge maps that report the incidence with different units. In particular, we do not have access to individual data (i.e., to the data points on which the maps are based), and we need to guarantee that all maps have the same impact in our composite image. The decision-room framework that we propose is able to cope with these requirements, and the algebra can be used to prove the properties of the composite map. Our framework can also cope with the situation in which monitoring would take place over a long period of time, and newer maps must have a higher impact if the composite map is in the composition's location to form the composition."}, {"heading": "2.2. Map algebras", "text": "In the early 1980s, Tomlin proposed treating maps as two-dimensional arrays and designing script-like languages to manipulate them in GIS. [26] These languages allow operations such as selecting areas (e.g. Schoolarea = Distance (SCHOOLS) < 300m) and combining selected areas using numerical operations. Mapping algebras are therefore specialized programming languages for the manipulation of grid cells, which now offer the possibility of processing maps within GIS using cellular automata or image processing techniques [7, 22]. While these algebras can be used to combine maps [9], there is no (mathematically proven) control over the effects that each map has on the final combination. [2]"}, {"heading": "2.3. Wireless sensor networks", "text": "Wireless sensor networks [2] are a natural application for our approach, but they can be found in applications such as forest fire detection, where temperature sensors measure the current temperature and rate of change. They are also used to study earthquake activity by measuring the strength and duration of seismic waves in the Earth's crust. Measurements are sent to collection nodes, which forward the data to a base station for processing. A typical sensor has a modest battery life, which can then be quickly emptied by the transceiver when large amounts of data are sent. Therefore, it is impracticable to forward all the collected data to the base station. However, sensors have the computing capacity to perform summaries, such as averages and standard deviations, which can then be sent to the base station. In our approach, any sensor can construct a classifier based on its local observations and send it as a summary."}, {"heading": "3. Background", "text": "In fact, most of them are able to play by the rules that they have set themselves in order to play by the rules."}, {"heading": "4. A framework: decision spaces", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Introducing the structure", "text": "Intuitively, a decision space is an m-dimensional space in which each dimension corresponds to one of the m-attributes. It contains a series of non-overlapping elements that, when encompassing the whole space, form a spatial division. \u00b7 A geometric interpretation of an element is a subspace defined by an m-polytopic. Therefore, the only requirement for the classifiers considered in this paper is that their elements must be polytopic, as is the case for SVMs with linear cores, decision trees, and rule sets. Our study of polytopes is a first step toward investigating the theoretical behavior of pure meta-learning processes. Further research could remove the limitation to polytopics to generalize our approach, such as SVMs with non-linear attributes and rule sets. [4] Informally, nonlinear cores can define shapes in terms of curves, while polytopic classes are used."}, {"heading": "4.2. Conversions", "text": "The constraints of a classifier's structure are used by a data mining algorithm to guide the search. < 3 A decision space is a frame and does not arise directly from a data mining algorithm, so its structure is less constrained than classification patterns such as decision trees. < 4 \u00b7 Any element of multiple types of classifiers can be converted into elements of a decision space without loss of information. < 4) To convert a classifier into a decision space, the only data required in addition to the classifier itself are the ranges of attributes for the dataset the classifier was trained to be derived in one pass across the dataset by scanning for the maximum and minimum values."}, {"heading": "5. Merge operator", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Preliminary definitions", "text": "The basic operation in the decision-making rooms is merging. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. (...) It is a matter of time until it comes to a solution. \"(...) It is a matter of time until it comes to a solution. (...)"}, {"heading": "5.2. Merging algorithm", "text": "The merge operator (X, Y) 7 \u2192 Z is algorithmically defined by algorithm 2 and illustrated in Figure 3. First, we apply the merge principle (1): All elements without intersections are added. Then, we apply principle (2): Any element x x x x x that is strictly contained in an element y x Y with the same value is deleted. Finally, principle (3) is applied as follows: (X, Y) 7 \u2192 Z1. Z new decision room 2. H 270 / / / Hash card: setting (y, y) of keys y and the corresponding values y \u00b2 3. for each element x 4. If we apply y such that x \u00b2 y and V (x) = V (y) then / / / If it is not a y that subsumes it with the same value, then we process it 5. if x \u00b2 y element is then / / / z value."}, {"heading": "21. Z \u2190 Z \u222a x", "text": "For each element that is in conflict, they are not subsumed by an element x with the same value. (Z) Z (Z) Z \"y\" y \"y\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"i.\" i. \"i\" i \"i\" i \"i.\" i \"i.\" i \"i\" i. \"i\" i. \"i.\" i. \"i\" i \"i.\" i \"i.\" i. \"i.\" i. \"i.\" i. \"i.\" i. \"i.\" i. \"i.\" i. \"i.\" i. \"i.\" i"}, {"heading": "5.3. Algebraic properties", "text": "The consequence is that there is a series of decisions that cannot be reconciled. (...) The consequence is a series of decisions that cannot be reconciled. (...) The consequence is a series of decisions that cannot be reconciled. (...) The consequence is a series of decisions that cannot be reconciled. (...) The consequence is a series of decisions that cannot be reconciled. (...) The consequence is a multitude of decisions that cannot be reconciled. (...) The consequence is a multitude of decisions that cannot be reconciled. (...) The consequence is a multitude of decisions that cannot be reconciled. (...) The consequence is a multitude of decisions that cannot be reconciled. (...) The consequence is a multitude of decisions that cannot be reconciled. (...) The consequence is a multitude of decisions that are made. (...)"}, {"heading": "6. The impact of merge order", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "6.1. m-ary merging", "text": "Consider a sentence {X1,.., Xm} of decision rooms. We expand algorithm 2 from a binary operator to a m-ary operator. Increasing the number of geometric objects that are intersected does not affect the operator, since the intersection set of geometric objects is associative. Therefore, the extension includes only the calculation of the value that is extended in definition 10.Definition. The value of the intersection set of m elements x1, x2, X2, Xm, Xm, based on their specialties, is a vectorV (x1, x2, x3, x4, x4, x5, x5, x5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5."}, {"heading": "6.2. Adjusting the bias", "text": "As explained earlier in this section, the merging of decision spaces over time only depends on the specifications, if each scheme has x and y values, then its effects disintegrate exponentially (V). In the previous section, we used additional memory to change the effects. In this subsection, we introduce an approach that is \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 M \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 Y is the class distribution vector V (xxxxxxm)."}, {"heading": "7. Developing an algebra", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1. Restriction operator", "text": "In a time-varying environment, the accuracy of predictions decreases over time, so new decision spaces must be created regularly. (A sequence of decision spaces carries information about changes in the environment over time, so techniques such as time series analysis could potentially be used. (While time series analysis looks at a sequence of fixed-size vectors, decision spaces can be of different sizes: for example, the values of attributes can evolve over time to cover a broader space.) A constraint operator can be used to simplify the decision spaces of a time series so that they all have the same size. We present this operator in Definition 12 and formally define it in Algorithm 3. Then we apply the algebraic approach in a similar way to the merging operator: we examine identity elements (Theorem 11), ideimpotence (Theorem 12), and associativity (Theorem 13).Definition 12).Definition 12. Definition 12. Definition X. Definition of a decision space X is only the constraint of decision space."}, {"heading": "7.2. Composite operators", "text": "When the merger operator creates an element z-Z = X-Y, z can be created from an x-X, a y-Y, or an x-X and a y-Y. The \"operator\" can be used to restrict the results of a merge in such a way that only elements z-Z are included that are created from both an x-X and a y-Y. This change has significant implications: an element derived from only one element is not as precise as an element derived from two, because in the latter case a consensus is achieved by a weighted formula. Therefore, this limited form of merging is less sensitive to noise and, as we know, all elements in Z are derived from exactly two elements, we can have the same confidence in the predictions of all elements in Z. A merge that provides the same confidence in the prediction of each element is obtained by the following composite operator."}, {"heading": "8. Conclusions", "text": "This year is the highest in the history of the country."}, {"heading": "Acknowledgements", "text": "We would like to thank Martin Ester, Binay Bhattacharya and Oliver Schulte for the helpful discussions, which were supported by the NSERC of Canada."}], "references": [{"title": "Wireless sensor networks: A survey", "author": ["I.F. Akyildiz", "W. Su", "Y. Sankarasubramaniam", "E. Cayirci"], "venue": "Computer Networks 38 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Hierarchical decision tree induction in distributed genomic databases", "author": ["A. Bar-Or", "D. Keren", "A. Schuster", "R. Wolff"], "venue": "IEEE Trans. Knowl. Data Eng. 17 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "A training algorithm for optimal margin classifiers", "author": ["B.E. Boser", "I.M. Guyon", "V.N. Vapnik"], "venue": "in: D. Haussler (Ed.), 5th Annual ACM Workshop on COLT, ACM Press, Pittsburgh, PA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1992}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine Learning 45 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Toward parallel and distributed learning by meta-learning - working notes", "author": ["P. Chan", "S.J. Stolfo"], "venue": "in: AAAI Workshop on Knowledge Discovery in Databases, AAAI", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1993}, {"title": "G", "author": ["J.P.C. Cordeiro"], "venue": "Camara, U.M. de Freitas, F. Almeida, Yet another map algebra, Geoinformatica 13 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Incremental rule learning and border examples selection from numerical data streams", "author": ["F.J. Ferrer-Troyano", "J.S. Aguilar-Ruiz", "J.C.R. Santos"], "venue": "J. UCS 11 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Map algebra extended with functors for temporal data", "author": ["A.U. Frank"], "venue": "Perspectives in Conceptual Modeling (Lecture Notes in Computer Science) 3770 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Separate-and-conquer rule learning", "author": ["J. F\u00fcrnkranz"], "venue": "Artificial Intelligence Review 13 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "A framework for measuring differences in data characteristics", "author": ["V. Ganti", "J. Gehrke", "R. Ramakrishnan", "W.Y. Loh"], "venue": "Journal of Computer and System Sciences 64 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Introduction to the special issue on meta-learning", "author": ["C. Giraud-Carrier", "R. Vilalta", "P. Brazdil"], "venue": "Machine Learning 54 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Decision tree learning on very large data sets", "author": ["L.O. Hall", "N. Chawla", "K.W. Bowyer"], "venue": "in: Proc. of the International Conference on Systems, Man, and Cybernetics, volume 3, IEEE", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "Knowledge Discovery with Support Vector Machines", "author": ["L.H. Hamel"], "venue": "Wiley-Interscience", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Data Mining: Concepts and Techniques", "author": ["J. Han", "M. Kamber"], "venue": "2nd edition, Morgan Kaufmann", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Multiple classifier combination: Lessons and the next steps", "author": ["T.K. Ho"], "venue": "Multiple classifier combination: Lessons and the next steps, World Scientific Publishing", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Combining pattern classifiers: methods and algorithms", "author": ["L.I. Kuncheva"], "venue": "John Wiley and Sons", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Confidence transformation for combining classifiers", "author": ["C.L. Liu", "H. Hao", "H. Sako"], "venue": "Pattern Anal Applic 7 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "Symbolic computation and automated reasoning", "author": ["A. Meier", "V. Sorge"], "venue": "Symbolic computation and automated reasoning, A. K. Peters, Ltd.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "Data Streams: Algorithms and Applications", "author": ["S. Muthukrishnan"], "venue": "volume 1:2, Now Publishers", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Vasa: An algebra for vague spatial data in databases", "author": ["A. Pauly", "M. Schneider"], "venue": "Information Systems 35 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Mapscript: a map algebra programming language incorporating neighborhood analysis", "author": ["D. Pullar"], "venue": "Geoinformatica 5 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Improved use of continuous attributes in c4.5", "author": ["J. Quinlan"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1996}, {"title": "Distributed prediction from vertically partitioned data", "author": ["D.B. Skillicorn", "S.M. McConnell"], "venue": "J. Parallel. Distrib. Comput. 68 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "A map algebra", "author": ["C.D. Tomlin"], "venue": "in: Proceedings of the 1983 Harvard Computer Graphics Conference,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1983}, {"title": "Arbiter meta-learning with dynamic selection of classifiers and its experimental investigation", "author": ["A. Tsymbal", "S. Puuronen", "V. Terziyan"], "venue": "in: J. Eder, I. Rozman, T. Welzer (Eds.), Advances in Databases and Information Systems, Third East European Conference, volume 1691 of Lecture Notes in Computer Science, Springer", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "A perspective view and survey of metalearning", "author": ["R. Vilalta", "Y. Drissi"], "venue": "Artificial Intelligence Review 18 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "Methods of combining multiple classifiers and their application to handwriting recognition", "author": ["L. Xu", "A. Krzyzak", "C.Y. Suen"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics 22 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1992}], "referenceMentions": [{"referenceID": 15, "context": "These ways have been grouped differently, but a key distinction can be found between fusion and selection ( [17], p.", "startOffset": 108, "endOffset": 112}, {"referenceID": 15, "context": "This is typically reflected in approaches that weight the outputs of the classifiers depending on the instance being classified [17].", "startOffset": 128, "endOffset": 132}, {"referenceID": 4, "context": ", pure meta-learning [6, 28, 12]), or requires access to the", "startOffset": 21, "endOffset": 32}, {"referenceID": 25, "context": ", pure meta-learning [6, 28, 12]), or requires access to the", "startOffset": 21, "endOffset": 32}, {"referenceID": 10, "context": ", pure meta-learning [6, 28, 12]), or requires access to the", "startOffset": 21, "endOffset": 32}, {"referenceID": 14, "context": "Most of the previously proposed solutions have been application-specific and were validated through experiments, leading researchers to suggest that questions about combining classifiers are (still) open \u201cbecause we do not yet have a scientific understanding of the classifier combination mechanisms\u201d [16].", "startOffset": 301, "endOffset": 305}, {"referenceID": 18, "context": "This can be a desirable behaviour in settings such as data streams [20], in which the distribution changes over time and the most recently received data is considered to be the most representative of current trends.", "startOffset": 67, "endOffset": 71}, {"referenceID": 23, "context": "In the early 1980s, Tomlin proposed to consider maps as two-dimensional arrays and to design script-like languages to manipulate them in GIS [26].", "startOffset": 141, "endOffset": 145}, {"referenceID": 5, "context": "Thus, map algebras are specialized programming languages for manipulating the cells of grids, which now offer the possibility to process maps within GIS using cellular automata or image-processing techniques [7, 22].", "startOffset": 208, "endOffset": 215}, {"referenceID": 20, "context": "Thus, map algebras are specialized programming languages for manipulating the cells of grids, which now offer the possibility to process maps within GIS using cellular automata or image-processing techniques [7, 22].", "startOffset": 208, "endOffset": 215}, {"referenceID": 7, "context": "While these algebras can be used to combine maps [9], there is no (mathematically proven) control of the impact that each map has on the final combination.", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "Wireless sensor networks [2] are a natural application for our approach.", "startOffset": 25, "endOffset": 28}, {"referenceID": 3, "context": "This richness may come at a cost in some classifiers: for example, a model derived using random forest classifiers [5] may be heavier than its training data, and would not be appropriate for wireless sensor networks.", "startOffset": 115, "endOffset": 118}, {"referenceID": 13, "context": ", to deduce an approximation of f given a set of instances, are [15, 14]", "startOffset": 64, "endOffset": 72}, {"referenceID": 12, "context": ", to deduce an approximation of f given a set of instances, are [15, 14]", "startOffset": 64, "endOffset": 72}, {"referenceID": 2, "context": "It is also possible to obtain non-linear classifications using the kernel method [4].", "startOffset": 81, "endOffset": 84}, {"referenceID": 21, "context": "A decision tree learner [23] applies a divide-andconquer technique to recursively split the data using the value of an attribute while maximizing a metric such as the information gain or Gini index.", "startOffset": 24, "endOffset": 28}, {"referenceID": 6, "context": "This is commonly referred to as a rule set [8].", "startOffset": 43, "endOffset": 46}, {"referenceID": 22, "context": "computation units, either by providing them with subsets of observations or subsets of attributes (vertical partitioning [24]).", "startOffset": 121, "endOffset": 125}, {"referenceID": 1, "context": "A number of researchers have focussed on merging decision trees: it was noted in [3] that \u201ca kind of decision tree induction [that is] efficient in a wide area system employs meta-learning, [in which] each computer induces a decision tree based on its local data and then the different models are merged to form the final tree\u201d.", "startOffset": 81, "endOffset": 84}, {"referenceID": 11, "context": "For example, it has been proposed [13] to transform decision trees into the sets of rules that they represent and to merge those sets.", "startOffset": 34, "endOffset": 38}, {"referenceID": 11, "context": "However, there are two potential problems with the design of the heuristic proposed in [13].", "startOffset": 87, "endOffset": 91}, {"referenceID": 24, "context": "For example, arbiter meta-learning [27] is a technique that merges classifiers in a hierarchical way.", "startOffset": 35, "endOffset": 39}, {"referenceID": 9, "context": "Ganti and colleagues [11] focused on a different problem: they examined how one could quantify the difference between two datasets by analyzing their models, which can be used to determine whether a model should be updated.", "startOffset": 21, "endOffset": 25}, {"referenceID": 2, "context": "Further research could remove the restriction to polytopes to generalize our approach to handle other classifiers such as SVMs with non-linear kernels [4].", "startOffset": 151, "endOffset": 154}, {"referenceID": 26, "context": "In Xu\u2019s categorization of the outputs used to combine classifiers, our requirement is the most universal (Type 1) [29].", "startOffset": 114, "endOffset": 118}, {"referenceID": 8, "context": "Intuitively, a cut in the space along the border of an element, either vertical or horizontal, should not cut any element [10].", "startOffset": 122, "endOffset": 126}, {"referenceID": 6, "context": "It can be an interval such as [8, 10], or a union of intervals.", "startOffset": 30, "endOffset": 37}, {"referenceID": 8, "context": "It can be an interval such as [8, 10], or a union of intervals.", "startOffset": 30, "endOffset": 37}, {"referenceID": 15, "context": "In these schemes, all classifiers contribute to the outcome of a given space space with weights based on their competence for that space [17].", "startOffset": 137, "endOffset": 141}, {"referenceID": 17, "context": "Therefore, (D,\u2297) is a unital, idempotent, and commutative magma (see [19] for a brief review of algebraic structures such as magmas).", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "Confidence transformations provide such a mechanism by transforming a class distribution vector into a measure representing its confidence [18].", "startOffset": 139, "endOffset": 143}, {"referenceID": 19, "context": "We can adopt the idea of an algebra for vague spatial data from [21] (which further highlights the connection of our approach with spatial algebras), by tagging each element of a decision space as being either guaranteed or conjectured.", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "The tag for elements resulting from the union, intersection, or difference of two elements can be determined by using the same tables as in [21].", "startOffset": 140, "endOffset": 144}], "year": 2015, "abstractText": "In distributed classification, each learner observes its environment and deduces a classifier. As a learner has only a local view of its environment, classifiers can be exchanged among the learners and integrated, or merged, to improve accuracy. However, the operation of merging is not defined for most classifiers. Furthermore, the classifiers that have to be merged may be of different types in settings such as ad-hoc networks in which several generations of sensors may be creating classifiers. We introduce decision spaces as a framework for merging possibly different classifiers. We formally study the merging operation as an algebra, and prove that it satisfies a desirable set of properties. The impact of time is discussed for the two main data mining settings. Firstly, decision spaces can naturally be used with non-stationary distributions, such as the data collected by sensor networks, as the impact of a model decays over time. Secondly, we introduce an approach for stationary distributions, such as homogeneous databases partitioned over different learners, which ensures that all models have the same impact. We also present a method that uses storage flexibly to achieve different types of decay for non-stationary distributions. Finally, we show that the algebraic approach developed for merging can also be used to analyze the behaviour of other operators.", "creator": "LaTeX with hyperref package"}}}