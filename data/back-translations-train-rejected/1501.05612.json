{"id": "1501.05612", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jan-2015", "title": "Features modeling with an $\\alpha$-stable distribution: Application to pattern recognition based on continuous belief functions", "abstract": "The aim of this paper is to show the interest in fitting features with an $\\alpha$-stable distribution to classify imperfect data. The supervised pattern recognition is thus based on the theory of continuous belief functions, which is a way to consider imprecision and uncertainty of data. The distributions of features are supposed to be unimodal and estimated by a single Gaussian and $\\alpha$-stable model. Experimental results are first obtained from synthetic data by combining two features of one dimension and by considering a vector of two features. Mass functions are calculated from plausibility functions by using the generalized Bayes theorem. The same study is applied to the automatic classification of three types of sea floor (rock, silt and sand) with features acquired by a mono-beam echo-sounder. We evaluate the quality of the $\\alpha$-stable model and the Gaussian model by analyzing qualitative results, using a Kolmogorov-Smirnov test (K-S test), and quantitative results with classification rates. The performances of the belief classifier are compared with a Bayesian approach.", "histories": [["v1", "Thu, 22 Jan 2015 19:55:58 GMT  (488kb,D)", "http://arxiv.org/abs/1501.05612v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["anthony fiche", "jean-christophe cexus", "arnaud martin", "ali khenchaf"], "accepted": false, "id": "1501.05612"}, "pdf": {"name": "1501.05612.pdf", "metadata": {"source": "CRF", "title": "Features modeling with an \u03b1-stable distribution: application to pattern recognition based on continuous belief functions", "authors": ["Anthony Fichea", "Jean-Christophe Cexusa", "Arnaud Martinb", "Ali Khenchafa"], "emails": [], "sections": [{"heading": null, "text": "Monitored pattern recognition is therefore based on the theory of continuous belief functions, which is a way of taking into account inaccuracy and uncertainty of data. Distributions of characteristics should be unimodal and estimated by a single Gaussian and \u03b1-stable model. Experimental results are first obtained from synthetic data by combining two characteristics of one dimension and taking into account a vector of two characteristics. Mass functions are calculated from plausibility functions using the generalized Bayes theorem. The same study is applied to the automatic classification of three types of seabed (rock, silt and sand) with characteristics captured by a mono-radiation echo sounder. We evaluate the quality of the \u03b1-stable model and the Gaussian model by analyzing qualitative results by comparing a Kolmogorov-Smirnov test (K-S test) and quantitative results with classification rates."}, {"heading": "1. Introduction", "text": "Choosing a model means that it is impossible to find a mode in which the probability density is symmetrical. The Gaussian model is a very efficient model that fits into many applications because it is very easy to use and saves computing time. However, as is the case for all distribution models, the Gaussian laws have some weaknesses and results that can be distorted in the end. In fact, since the Gaussian distribution belongs to a family of distributions called stable distributions, this family of distributions allows the representation of heavy tails and skewness. A distribution is said to have a heavy tail if the tail of the Gaussian distribution is lower than the tail. The property of skewness therefore means that it is impossible to find a mode in which the probability density is symmetrical."}, {"heading": "2. The \u03b1-stable distributions", "text": "Laplace and Poisson developed the theory of characteristic function by calculating the analytical expression of the Fourier transformation of a probability density function. Laplace found that the Fourier transformation of a Gaussian law is also a Gaussian law. Cauchy tried to calculate the Fourier transformation of a \"generalized Gaussian\" function with the expression fn (x) = 1\u03c0 + 0 exp (\u2212 ctn) cos (tx) dt, but he did not solve the problem. If the integer n is a real \u03b1, we define the family of \u03b1-stable distributions. Cauchy did not know at that time whether he had defined a probability density function. Janicki and Weron used the results of Polya and Bernstein to show that the multipourian distribution laws represent a stable form of probability density functions. Mathematician Paul Levy limited the data studied for central density by defining the stable function."}, {"heading": "2.1. Definition of stability", "text": "Mathematically, this definition means that a random variable X is stable and is called X \u0445 S \u03b1 (\u03b2, \u03b3, \u03b4) if there are two independent \u03b1-stable random variables for all (a, b), (R + + +), c + R + and d + R: aX1 + bX2 = cX + d, (1) with X1 and X2, which follow the same distribution as X. If Equation (1) defines the term stability, it does not indicate how an \u03b1-stable distribution should be parameterized. Therefore, we prefer to use the definition given by a characteristic function to refer to an \u03b1-stable distribution."}, {"heading": "2.2. Characteristic function", "text": "Several equivalent definitions have been proposed in the literature to parameterise an \u03b1-stable distribution in terms of its characteristic function [18, 19]. Zolotarev [19] proposed the following: \u03c6S \u03b1 (\u03b2, \u03b3, \u03b4) (t) = exp (jt\u03b4 \u2212 | \u03b3t | \u03b1 [1 + j\u03b2 tan (\u03c0\u03b1 2) character (t) (| t | 1 \u2212 \u03b1 \u2212 1)]) if \u03b1, 1, exp (jt\u03b4 character (t) log | t |])) if \u03b1 = 1, (2) if each feature has specific values: \u2022 \u03b1] 0, 2] is the characteristic exponent."}, {"heading": "2.3. The probability density function", "text": "The representation of an \u03b1-stable pdf, referred to as fS \u03b1 (\u03b2, \u03b3, \u03b4), results from the calculation of the Fourier transformation of its characteristic function: fS \u03b1 (\u03b2, \u03b3, \u03b4) (x) = \u0432 \u221e \u2212 \u221e \u03c6S \u03b1 (\u03b2, \u03b3, \u03b4) (t) exp (\u2212 jtx) dt. (3) However, this definition is problematic for two reasons: While the integral function is complex, its limits are infinite. Nolan [20] therefore proposed a way to represent normalized \u03b1-stable distributions (i.e. \u03b3 = 1 and \u03b4 = 0).The basic idea of Nolan [20] is to use variable modifications so that the integral has finite limits. Each parameter has an influence on the shape of the fS-\u03b1 (\u03b2, \u03b3, \u03b4) distributions. The curve shows a large peak when \u03b1 is close to 0, and a Gaussian shape \u03b1 when the scale is finite (\u03b2) of scale (the form of scale = 1) leads to the distribution of the (\u03b2) of the scale (finite) and (the scale of the scale = 1)."}, {"heading": "2.4. An overview of \u03b1-stable estimators", "text": "The estimators of the \u03b1-stable distributions are divided into three families: \u2022 the quantity methods of the sample [21, 22] \u2022 the characteristic functional methods of the sample [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30]. Fama and Roll [21] developed a method based on quantities. However, the algorithm proposed by Fama and Roll suffers from a small asymptotic bias in \u03b1 and \u03b3 and \u03b3] 0,6, 2] and \u03b2 = 0. McCulloch [22] extended the quantity method to the asymmetric case (i.e. \u03b2 = 0). The McCulloch estimator applies to the quantity of quantity. [23, 24] proposed a method based on transformations of the characteristic function. In [31] the author compared the performance of several estimators with the quantity."}, {"heading": "2.5. Multivariate stable distributions", "text": "It is possible to extend the \u03b1-stable distributions to the multivariate case. A random vector X-R is stable if there are stable distributions for all a-b-b-R + c, so that: aX1 + bX2 = cX + D, (4) where X1 and X2 are two independent and identically distributed random vectors following the same distribution as X.The characteristic function of a multivariate \u03b1-stable distribution, referred to as X-S-\u03b1, is d-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-multivarial value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-value-multivari"}, {"heading": "3. The belief functions", "text": "The final goal of this work is the classification of synthetic and real data according to the theory of belief functions. Data obtained from sensors are generally inaccurate and uncertain, as sounds can interfere with their acquisition. It is possible to take these limitations into account through the theory of belief functions. We will first develop the theory of belief functions within a separate framework, before characterizing them in real numbers."}, {"heading": "3.1. Discrete belief functions", "text": "This section outlines basic tools in relation to the theory of faith functions."}, {"heading": "3.1.1. Definitions", "text": "Discrete faith functions were introduced by Dempster [8] and formalized by Shafer [9], where he considers a discrete series of n exclusive events that Ci designates as a differentiating framework. (7) Faith functions can be interpreted as all assumptions about a problem. Faith functions are defined as 2 to [0,1]. The purpose of discrete faith functions is to ascribe a weight of faith to each element. Faith functions must follow normalization: \"A'm (A) = 1,\" (8), where the basic faith assignment (bba) is called. A focal element is a subset of A in which m\u044b (A) > 0 and multiple functions are constructed in one-to-one correspondence of bba: \"b\" (A) = \"b,\" b, \"b\" (9), \"b\" (A) = \"plausible\" (B), \"qm\" (B), \"B,\" (A), \"A\" (A), \"(A) (A) (b)."}, {"heading": "3.1.2. Combination rule", "text": "There are several rules of combination [36] in the literature, which deal differently with conflicts between sources. The most common rule is the conjunctive combination [37], in which the resulting mass of A is determined by: m\u044b (A) = \u2211 B1... Bn = A, \u2205 M-i = 1 m\u0435i (Bi), \u0432 A-2\u0432. (12) The mass of the empty quantity is determined by: m\u0432 (\u2205) = \u2211 B1... Bn = \u2205 M-i = 1 m\u0441i (Bi), \u00d1 A-2\u0432. (13) This rule allows us to remain in the open world. However, this is not practicable as calculations are difficult. It is possible to calculate the resulting mass using communality functions, in which each mass m\u0441i (i = 1,...) must be converted into Qi function: The calculation follows the communality (verse 1) as a result (9)."}, {"heading": "3.1.3. Pignistic probability", "text": "To make a decision, several operators exist in such a way that maximum credibility or maximum plausibility can be achieved, with the probability that the most commonly used operator is pignistic [38]. This name comes from pignus, a Latin bet. This operator approaches the pair (bel, pl) by evenly dividing a mass of focus elements on each individual Ci. This operator is defined by: betP (Ci) = \u2211 A \u0441\u043e, Ci \u0441\u0430\u0441\u0430\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e (A) | (1 \u2212 m\u0442 (\u2205)), (15) where | A | represents the cardinality of A. We choose the decision Ci by evaluating max1 \u2264 k \u2264 n betP (Ck)."}, {"heading": "3.2. Continuous belief functions", "text": "The basic description of continuous belief functions was performed by Shafer [9], then by Nguyen [39] and Strat [40]. Recently, Smets [41] expanded the definition of belief functions to the number of reals R = R = R = \u221e, + \u221e}, and masses are attributed only to intervals of R."}, {"heading": "3.2.1. Definitions", "text": "Consider I = {[x, y], (x, y], [x, y), (x, y), (x, y), (x, y, y) as a series of closed, half-open and open intervals of R. Fuel elements are closed intervals of R. The set mI (x, y) is a basic faith density associated with a specific pdf. If x > y, then mI (x, y) = 0. With these definitions it is possible to define the same functions as in individual cases. Since the interval [a, b] is a set of R with a \u2264 b, the previous functions can be defined as follows: belR ([a, b] = area x = x = max (a, x) mI (x, y) dydx (x, y), (17 qR) dydx (b), (16) plR ([a, b]) = x = \u00b2 (18)."}, {"heading": "3.2.2. Pignistic probability", "text": "The definition of pignistic probability for a < b is: Bet f ([a, b]) = for a function that defines a different function, is a function that defines a different function when it defines a different function. (19) It is possible to calculate pignistic probabilities to have basic faith densities. (19) Many basic faith densities, however, exist for the same pignistic probability. To solve this problem, we can use the consonant basic faith density. (19) A basic faith density is called \"consonant\" when focal elements are nested. Focal elements Iu can be called index u, so that Iu \"u\" u \"> u.\" This definition is used to apply the principle of least obligation, which is to choose the least informative faith function when a faith function is not fully defined and is only known to belong to a family of functions."}, {"heading": "3.3. Credal measure and index function", "text": "In [44], the authors propose a way to calculate faith functions from any probability density function. (24) The authors use an index function f and a specific index space I to define the set of focal elements F: f I: I \u2192 F, (23) y 7 \u2212 f I (y). (24) However, the authors introduce a positive measure in such a way that they describe non-contiguous sets. The pair (f I, ul) defines a faith function. For all A elements, they define subsets belonging to the Borel set: F A = \"y\" I (y) A, \"(25) F A =\" y \"I (y)\" y \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"(27) From these definitions, they calculate faith functions:\" f \"x\" i \"i.\""}, {"heading": "4. Continuous belief functions and \u03b1-stable distribution", "text": "In this section, we will model data distributions as a single \u03b1-stable distribution. However, we must introduce the concept of the plausibility function for an \u03b1-stable distribution. We will first describe how to calculate the plausibility function by knowing the pdf in R before extending to in R. Finally, we will explain how to construct our faith classifier."}, {"heading": "4.1. Link between pignistic probability function and plausibility function in R", "text": "The information that is available is the conditional pigmentation density = 0. We already know that Bet f [Ci] with Ci \u03b2 \u03b2 (\u03b2 \u03b2). The function Bet f [Ci] should be bell-shaped for all \u03b1-stable distributions (proven by Yamazato [46]). The plausibility function from a mass mR is simplified by an integral of the equation (22) between [x, + + \u00b2 of the integration of parts can (36): plR [Ci] (I) = 2 (x \u2212 \u00b5) Bet f (t) dt dt dt (37) Now let us consider a certain case in which symmetrical Bet f is a stable distribution (the parameter \u03b2 = 0)."}, {"heading": "4.3. Belief classifier", "text": "Consider a dataset of N samples from d sensors. For example, each characteristic of a vector x-Rd can be considered a piece of information from a sensor. Classification is divided into two steps. N-p (with p-p vectors) 0, 1 [) Samples are first randomly selected from the dataset for the learning base, so that X = x11. x-p-1...... x1d. x-p-d All columns of X belong to a class Ci with 1 \u2264 i-n. Probability density functions (Gaussian or \u03b1-stable models) are estimated from samples that belong to classes. The rest of the samples are used for the test base (N-p vectors). We use a validation test to determine whether samples belong to an estimated model. If the test is not valid, we set the classification up."}, {"heading": "5. Application to pattern recognition", "text": "The goal is to build a faith classifier and perform a classification of synthetic and real data by estimating the characteristics using a Gaussian and alpha-stable pdf. In [12], synthetic data is classified by modeling characteristics using Gaussian and alpha-stable mixture models. However, when the number of Gaussian distributions increases, the classification accuracies are significantly the same. Images from a side scan sonar are automatically classified by extracting Haralick characteristics [49, 50]. However, classification accuracies are roughly the same. In this section, we limit algorithms with a vector of characteristics in dimension d \u2264 2. In fact, the generalization of alpha stable by automatically classifying the probe is."}, {"heading": "5.1. Application to synthetic data generated by Gaussian distributions", "text": "In this subsection we show that the \u03b1-stable and Gaussian models exhibit the same behavior during classification when synthetic data is generated by Gaussian distributions.5.1.1. Representation of data.We have simulated three Gaussian pdfs in R \u00b7 R (see Table 1). Each distribution contains 3000 samples. A mesh between [\u2212 4, 4] \u00d7 [\u2212 4, 4] enables the level curves of pdf to be displayed (Figure 7)."}, {"heading": "5.1.2. Results", "text": "We have generated data and randomly divided samples into two groups: one third for the learning base and the rest for the test base. The learning base was used to estimate each mean and variance for the Gaussian distributions and each parameter \u03b1, \u03b2, \u03b3 and \u03b4 for the \u03b1-stable distributions [6, 25, 51]. We had to create a mesh between [\u2212 4, 4] \u00d7 [\u2212 4, 4] to calculate the plausibility functions in R2 using the \u03b1-stable model. Consequently, samples were selected which have features with dimensions within [\u2212 4, 4] The one-dimensional case. For each class Ci, we consider each feature as an information source. The estimated probability functions can be considered pignistic probability functions. For each pignistic probability function, we associate a mass function which is then combined with other mass functions. The K-S test is valid for the two zero hypotheses H1 and H2 samples (we can claim that samples from the same table 2)."}, {"heading": "5.2. Application to synthetic data generated by \u03b1-stable distributions", "text": "In this section we show the interest in modelling features in one and two dimensions with a single \u03b1-stable distribution."}, {"heading": "C1 0.1509 0.0873 0.1509 0.0873", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C1 0.0490 0.0650 0.1997 0.0836", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C3 0.1399 0.0870 0.1665 0.0841", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.1. Presentation of the data", "text": "Three classes of artificial data sets were generated from 2D \u03b1-stable distributions [33] (cf. Table 5 and [52] on the significance of \u03c3 and \u03b8) with 3000 samples. A network between [\u2212 4, 4] \u00d7 [\u2212 4, 4] enables the level curves of pdf to be displayed (Figure 11)."}, {"heading": "5.2.2. Results The one dimension case.", "text": "We can claim that the estimation with the Alpha-stable hypothesis is better than the Gaussian hypothesis (Figure 12). There is a difference between the mode of the Gaussian model and the mode of the Alpha-stable model. In fact, the mean calculated from samples for the Gaussian model does not correspond to the mode when the samples do not belong to a Gaussian law. Furthermore, the values of the PDFs are not identical to the real PDFs. The K-S test is not satisfied with the null components H1 for each class and component. Consequently, we stopped the classification step for the Gaussian model. However, the K-S test is valid for the null hypothesis H2 (Table 6). We can observe that the results obtained with the theory of faith functions are significantly the same as the results obtained with the Bayesian approach. This phenomenon can be explained by the fact that previous probabilities have been well estimated."}, {"heading": "C1 0.0683 0.1003", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C1 0.3694 0.0688", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C3 0.1154 0.0932", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.3. Application to real data from a mono-beam echo-sounder", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.3.1. Presentation of data", "text": "We used a dataset from a single-beam echo sounder provided by the Marine Hydrographic and Oce \u0301 anique Service (SHOM). Raw data represent an echo signal amplitude by time. In [16], the authors classify seven types of seabed by comparing the temporal hull of echo signal amplitude with a series of theoretical reference curves. In our application, raw data (Figure 19) was processed using the Quester Tangent Corporation (QTC) software [53] to identify some features normalized between [0.1] and [7338]. These data have already been used to navigate an autonomous underwater vehicle (AUV) [54]. The differentiation frame is: \"Mud, rock, sand.\" With 4853 samples of mud, 6017 of rock and 7338 of sand. \"The selection of features plays an important role in the classification, because the classification accuracy can be determined according to the characteristics of the constituent of the 56 characteristics."}, {"heading": "5.3.2. Results", "text": "We randomly select 5000 samples for the dataset. Half of the samples were used for the learning base, the rest for the test base. First, we consider characteristics in one dimension, i.e. two mass functions were calculated and combined to obtain a single mass function. One dimension case. We can observe that the assumption of the \u03b1-stable model can easily accommodate the data compared to the Gaussian model (Figure 21).The \u03b1-stable hypothesis applies to the K-S test, while the K-S test rejects the Gaussian hypothesis (Table 10).The approach using the theory of belief functions (classification accuracy of 82.68%) yields better results than the Bajesian approach (classification accuracy of 80.64%), but not significantly. This phenomenon can be explained by the fact that the estimated models and previous probabilities are well assessed. The two-dimensional case was extended by the use of a vector of two characteristics (classification accuracy of 80.64%), but not significantly."}, {"heading": "6. Conclusions", "text": "We have looked at the inaccuracy and uncertainty of the data used to model pdf, and the theory of faith functions provides a way to model these limitations. We have examined the basic definitions of this theory and shown a way to calculate plausibility functions when the knowledge of sensors is a pdf-stable. Finally, we validated our model by comparing it with the model studied by Caron et al. [43], where the pdf is a gaussian. Synthetic and real data were finally classified using the theory of faith functions. We have studied the learning basis, calculated plausibility functions, combined plausibility functions and calculated maximum pignistic probability to maintain classification accuracy. The K-S test shows that synthetic data can be modeled using an \u03b1-stable model. The proposed method works well for synthetic data. Considering two features improves the classification rate in the comparison of two features to the combination of GFs."}, {"heading": "Acknowledgements", "text": "The authors thank the Service Hydrographique et Oce'anique de la Marine (SHOM) for the data and G. Le Chenadec for his advice regarding the data."}], "references": [{"title": "Th\u00e9orie des erreurs : La loi de Gauss et les lois exceptionnelles", "author": ["P. L\u00e9vy"], "venue": "Bulletin de la Soci\u00e9t\u00e9 Math\u00e9matique de France. 52 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1924}, {"title": "SAR image denoising via Bayesian wavelet shrinkage based on heavy-tailed modeling", "author": ["A. Achim", "P. Tsakalides", "A. Bezerianos"], "venue": "IEEE Transactions on Geoscience and Remote Sensing. 41 (8) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Adaptive target detection in foliage-penetrating SAR images using alpha-stable models", "author": ["A. Banerjee", "P. Burlina", "R. Chellappa"], "venue": "IEEE Transactions on Image Processing. 8 (12) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Skewed \u03b1-stable distributions for modelling textures", "author": ["E.E. Kuruoglu", "J. Zerubia"], "venue": "Pattern Recognition Letters. 24 (1-3) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Financial applications of stable distributions", "author": ["J.H. McCulloch"], "venue": "Handbook of statistics, Statistical Method in Finance. 14 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "The behavior of stock-market prices", "author": ["E.F. Fama"], "venue": "Journal of business. 38 (1) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1965}, {"title": "Bayesian Data Fusion of Multi-View Synthetic Aperture Sonar Imagery for Seabed Classification", "author": ["D.P. Williams"], "venue": "IEEE Transactions on Image Processing. 18 (6) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Upper and Lower probabilities induced by a multivalued mapping", "author": ["A. Dempster"], "venue": "Annals of Mathematical Statistics. 38 (2) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1967}, {"title": "A mathematical theory of evidence", "author": ["G. Shafer"], "venue": "Princeton University Press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1976}, {"title": "Bayesian approach and continuous belief functions for classification", "author": ["A. Fiche", "A. Martin"], "venue": "in: Proceedings of the Rencontre francophone sur la Logique Floue et ses Applications,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of the Royal Statistical Society B. 39 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1977}, {"title": "Influence de l\u2019estimation des param\u00e8tres de texture pour la classification de donn\u00e9es complexes", "author": ["A. Fiche", "A. Martin", "J.C. Cexus", "A. Khenchaf"], "venue": "in: Proceedings of the Workshop Fouilles de donne\u0301es complexes,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Continuous belief functions and \u03b1-stable distributions", "author": ["A. Fiche", "A. Martin", "J.C. Cexus", "A. Khenchaf"], "venue": "in: Proceedings of the 13th International Conference on Information Fusion, Edinburgh, United Kingdom,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Mine classification based on raw sonar data: an approach combining Fourier descriptors", "author": ["I. Quidu", "J.P. Malkasse", "G. Burel", "P. Vilb\u00e9"], "venue": "statistical models and genetic algorithms, in: Proceedings OCEANS2000 MTS/IEEE, Providence, Rhode Island", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Martin,Multi-view fusion based on belief functions for seabed recognition", "author": ["A.H. Laanaya"], "venue": "in: Proceedings of the 12th International Conference on Information Fusion, Seattle,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Sea-bed identification using echo-sounder signals", "author": ["E. Pouliquen", "X. Lurton"], "venue": "in: Proceedings of the European Conference on Underwater Acoustics, Elsevier Applied Science, London and New York", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1992}, {"title": "Simulation and chaotic behavior of \u03b1-stable stochastic processes", "author": ["A. Janicki", "A. Weron"], "venue": "Marcel Dekker, New York", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1994}, {"title": "Stable non-gaussian random processes", "author": ["M.S. Taqqu", "G. Samorodnisky"], "venue": "Chapman and Hall", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1994}, {"title": "One-dimensional stable distributions", "author": ["V.M. Zolotarev"], "venue": "Translations of Mathematical Monographs Volume 65, American Mathematical Society", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1986}, {"title": "Numerical calculation of stable densities and distribution functions", "author": ["J.P. Nolan"], "venue": "Communications in Statistics-Stochastic Models. 13 (4) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "Parameter estimates for symmetric stable distributions", "author": ["E.F. Fama", "R. Roll"], "venue": "Journal of the American Statistical Association. 66 (334) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1971}, {"title": "Simple consistent estimators of the parameters of stable laws", "author": ["J.H. McCulloch"], "venue": "Journal of the American Statistical Association. 75 (372) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1980}, {"title": "Applied multivariate analysis", "author": ["S.J. Press"], "venue": "Holt, Rinehart and Winston New York", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1972}, {"title": "Estimation in univariate and multivariate stable distributions", "author": ["S.J. Press"], "venue": "Journal of the American Statistical Association. 67 (340) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1972}, {"title": "Regression-type estimation of the parameters of stable laws", "author": ["I.A. Koutrouvelis"], "venue": "Journal of the American Statistical Association. 75 (372) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1980}, {"title": "An iterative procedure for the estimation of the parameters of stable laws", "author": ["I.A. Koutrouvelis"], "venue": "Communications in Statistics-Simulation and Computation. 10 (1) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1981}, {"title": "Maximum likelihood estimates of symmetric stable distribution parameters", "author": ["B.W. Brorsen", "S.R. Yang"], "venue": "Communications in Statistics- Simulation and Computation. 19 (4) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1990}, {"title": "Linear regression with stable disturbances", "author": ["J.H. McCulloch"], "venue": "in: R. Adler, R. Feldman, M.S. Taqqu (Eds.), A practical guide to heavy tailed data, Birkh\u00e4user, Boston", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1998}, {"title": "Stable distributions in statistical inference", "author": ["W.H. Dumouchel"], "venue": "Ph.D. dissertation, Department of statistics, Yale University", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1971}, {"title": "Maximum likelihood estimation and diagnostics for stable distributions", "author": ["J.P. Nolan"], "venue": "in: O.E. Barndoff-Nielsen, T. Mikosh, S. Resnick (Eds.), L\u00e9vy processes: theory and applications, Birkh\u00e4user, Boston", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}, {"title": "Performance of the estimators of stable law parameters", "author": ["R. Weron"], "venue": "Technical Report HSC/95/01, Hugo Steinhaus Center, Wroclaw University of Technology", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1995}, {"title": "Estimation of stable-law parameters: A comparative study", "author": ["V. Akgiray", "C.G. Lamoureux"], "venue": "Journal of Business & Economic Statistics. 7 (1) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1989}, {"title": "A method for simulating stable random vectors", "author": ["R. Modarres", "J.P. Nolan"], "venue": "Computational Statistics. 9 (4) ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1994}, {"title": "Estimation of the bivariate stable spectral representation by the projection method", "author": ["J.H. McCulloch"], "venue": "Computational Economics. 16 (1) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2000}, {"title": "Estimation of stable spectral measures", "author": ["J.P. Nolan", "A.K. Panorska", "J.H. McCulloch"], "venue": "Mathematical and Computer Modelling. 34 (9-11) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2001}, {"title": "Combination of evidence in Dempster-Shafer theory", "author": ["K. Sentz", "S. Ferson"], "venue": "Technical Report", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2002}, {"title": "The combination of evidence in the transferable belief model, IEEE Transactions on Pattern Analysis and Machine Intelligence", "author": ["Ph. Smets"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1990}, {"title": "Constructing the pignistic probability function in a context of uncertainty", "author": ["Ph. Smets"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1990}, {"title": "On random sets and belief functions", "author": ["H.T. Nguyen"], "venue": "Journal of Mathematical Analysis and Applications. 65 (3), ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1978}, {"title": "Continuous belief functions for evidential reasoning", "author": ["T.M. Strat"], "venue": "in: Proceedings of the National Conference on Artificial Intelligence, Austin, Texas", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1984}, {"title": "Belief functions on real numbers, International Journal of Approximate Reasoning", "author": ["Ph. Smets"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2005}, {"title": "Ph", "author": ["B. Ristic"], "venue": "Smets, Target classification approach based on the belief function theory, IEEE Transactions on Aerospace and Electronic Systems. 42 (2) ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2005}, {"title": "Least Committed basic belief density induced by a multivariate Gaussian pdf", "author": ["F. Caron", "B. Ristic", "E. Duflos", "P. Vanheeghe"], "venue": "International Journal of Approximate Reasoning. 48 (2) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "Constructing of a consonant belief function induced by a multimodal probability density function, in: Proceedings of COGnitive systems with Interactive Sensors", "author": ["P.E. Dor\u00e9", "A. Martin", "A. Khenchaf"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2009}, {"title": "Continuous belief functions: singletons plausibility function in conjunctive and disjunctive combination operations of consonant bbds", "author": ["J.M. Vannobel"], "venue": "in: Proceedings of the Workshop on the Theory of Belief Function,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2010}, {"title": "Unimodality of infinitely divisible distribution functions of class L", "author": ["M. Yamazato"], "venue": "The Annals of Probability. 6 ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1978}, {"title": "Belief functions: The disjunctive rule of combination and the generalized Bayesian theorem, International Journal of Approximate Reasoning", "author": ["Ph. Smets"], "venue": null, "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1993}, {"title": "Ph", "author": ["F. Delmotte"], "venue": "Smets, Target identification based on the transferable belief model interpretation of Dempster\u2013Shafer model, IEEE Transactions on Systems, Man and Cybernetics. 34 (4) ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2004}, {"title": "Textural features for image classification", "author": ["R.M. Haralick", "K. Shanmugam", "I.H. Dinstein"], "venue": "IEEE Transactions on Systems, Man and Cybernetics. 3 (6) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1973}, {"title": "Statistical and structural approaches to texture", "author": ["R.M. Haralick"], "venue": "Proceedings of the IEEE. 67 (5) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1979}, {"title": "Simple consistent estimators of stable distribution parameters", "author": ["J.H. McCulloch"], "venue": "Communications in Statistics-Simulation and Computation. 15 (4) ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1986}, {"title": "Calculation of multidimensional stable densities", "author": ["J.P. Nolan", "B. Rajput"], "venue": "Communications in Statistics-Simulation and Computation. 24 (3) ", "citeRegEx": "52", "shortCiteRegEx": null, "year": 1995}, {"title": "Sea bottom classification from echo sounding data", "author": ["D. Caughey", "B. Prager", "J. Klymak"], "venue": "Quester Tangent Corporation, Marine Technology Center, British Columbia, V8L 3S1, Canada", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1994}, {"title": "Autonomous Underwater Vehicle sensors fusion by the theory of belief functions for Rapid Environment Assessment", "author": ["A. Martin", "J.C. Cexus", "G. Le Chenadec", "E. Cant\u00e9ro", "T. Landeau", "Y. Dupas", "R. Courtois"], "venue": "in: Proceedings of the 10th European Conference on Underwater Acoustics,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2010}, {"title": "Seabed segmentation using optimized statistics of sonar textures", "author": ["I. Karoui", "R. Fablet", "J.M. Boucher", "J.M. Augustin"], "venue": "IEEE Transactions on Geoscience and Remote Sensing. 47 (16) ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "The main property of stable laws introduced by L\u00e9vy [1] is that the sum of two independent stable random variables gives a stable random variable.", "startOffset": 52, "endOffset": 55}, {"referenceID": 1, "context": "\u03b1-stable distributions are used in different fields of research such as radar [2, 3], image processing [4] or finance [5, 6], .", "startOffset": 78, "endOffset": 84}, {"referenceID": 2, "context": "\u03b1-stable distributions are used in different fields of research such as radar [2, 3], image processing [4] or finance [5, 6], .", "startOffset": 78, "endOffset": 84}, {"referenceID": 3, "context": "\u03b1-stable distributions are used in different fields of research such as radar [2, 3], image processing [4] or finance [5, 6], .", "startOffset": 103, "endOffset": 106}, {"referenceID": 4, "context": "\u03b1-stable distributions are used in different fields of research such as radar [2, 3], image processing [4] or finance [5, 6], .", "startOffset": 118, "endOffset": 124}, {"referenceID": 5, "context": "\u03b1-stable distributions are used in different fields of research such as radar [2, 3], image processing [4] or finance [5, 6], .", "startOffset": 118, "endOffset": 124}, {"referenceID": 6, "context": "In [7], the author proposes to characterize the sea floor from a vector of features modeled by Gaussian mixture models (GMMs) using an Autonomous Underwater Vehicle (AUV).", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "We therefore favored the use of an approach based on the theory of belief functions [8, 9].", "startOffset": 84, "endOffset": 90}, {"referenceID": 8, "context": "We therefore favored the use of an approach based on the theory of belief functions [8, 9].", "startOffset": 84, "endOffset": 90}, {"referenceID": 9, "context": "In [10], the authors compared a Bayesian and belief classifier where data from sensors are modeled using GMMs estimated via an Expectation-Maximization (EM) algorithm [11].", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [10], the authors compared a Bayesian and belief classifier where data from sensors are modeled using GMMs estimated via an Expectation-Maximization (EM) algorithm [11].", "startOffset": 167, "endOffset": 171}, {"referenceID": 11, "context": "This work has been extended to data modeled by \u03b1-stable mixture models [12].", "startOffset": 71, "endOffset": 75}, {"referenceID": 12, "context": "This point has been dealt with in [13].", "startOffset": 34, "endOffset": 38}, {"referenceID": 13, "context": "SONAR has therefore been used for the detection of underwater mines [14].", "startOffset": 68, "endOffset": 72}, {"referenceID": 14, "context": "In [15], the author developed techniques to perform automatic classification of sediments on the seabed from sonar images.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "In [10], the authors classified sonar images by extracting features and modeling them with GMMs.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "In [16], the authors characterized the sea floor using data from a mono-beam echo-sounder.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "With the results of Polya and Bernstein, Janicki and Weron [17] demonstrated that the family of \u03b1-stable laws are probability density functions.", "startOffset": 59, "endOffset": 63}, {"referenceID": 0, "context": "The mathematician Paul L\u00e9vy studied the central limit theorem and showed, with the constraint of infinite variance, that the limit law is a stable law [1].", "startOffset": 151, "endOffset": 154}, {"referenceID": 17, "context": "Characteristic function Several equivalent definitions have been suggested in the literature to parameterize an \u03b1-stable distribution from its characteristic function [18, 19].", "startOffset": 167, "endOffset": 175}, {"referenceID": 18, "context": "Characteristic function Several equivalent definitions have been suggested in the literature to parameterize an \u03b1-stable distribution from its characteristic function [18, 19].", "startOffset": 167, "endOffset": 175}, {"referenceID": 18, "context": "Zolotarev [19] proposed the following:", "startOffset": 10, "endOffset": 14}, {"referenceID": 17, "context": "The advantage of this parameterization compared to [18] is that the values of the characterization and probability density functions are continuous for all parameters.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "In fact, the parameterization defined by [18] is discontinuous when \u03b1 = 1 and \u03b2 = 0.", "startOffset": 41, "endOffset": 45}, {"referenceID": 19, "context": "Nolan [20] therefore proposed a way to represent normalized \u03b1-stable distributions (i.", "startOffset": 6, "endOffset": 10}, {"referenceID": 19, "context": "The main idea of Nolan [20] is to use variable modifications so that the integral has finite bounds.", "startOffset": 23, "endOffset": 27}, {"referenceID": 20, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 142, "endOffset": 150}, {"referenceID": 21, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 142, "endOffset": 150}, {"referenceID": 22, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 196, "endOffset": 212}, {"referenceID": 23, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 196, "endOffset": 212}, {"referenceID": 24, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 196, "endOffset": 212}, {"referenceID": 25, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 196, "endOffset": 212}, {"referenceID": 26, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 249, "endOffset": 265}, {"referenceID": 27, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 249, "endOffset": 265}, {"referenceID": 28, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 249, "endOffset": 265}, {"referenceID": 29, "context": "An overview of \u03b1-stable estimators The estimators of \u03b1-stable distributions are decomposed into three families: \u2022 the sample quantile methods [21, 22] \u2022 the sample characteristic function methods [23, 24, 25, 26] \u2022 the Maximum Likelihood Estimation [27, 28, 29, 30].", "startOffset": 249, "endOffset": 265}, {"referenceID": 20, "context": "Fama and Roll [21] developed a method based on quantiles.", "startOffset": 14, "endOffset": 18}, {"referenceID": 21, "context": "McCulloch [22] extended the quantile method to the asymmetric case (i.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "Press [23, 24] proposed a method based on transformations of characteristic function.", "startOffset": 6, "endOffset": 14}, {"referenceID": 23, "context": "Press [23, 24] proposed a method based on transformations of characteristic function.", "startOffset": 6, "endOffset": 14}, {"referenceID": 30, "context": "In [31], the author compared the performances of several estimators.", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "Koutrouvelis [25] extended the Press method and proposed a regression method to estimate the parameters of \u03b1-stable distributions.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "He proposed a second version of his algorithm which is distinct that it is iterative [26].", "startOffset": 85, "endOffset": 89}, {"referenceID": 31, "context": "In [32], the authors proved that the method proposed by Koutrouvelis is better than both the quantile method and the Press method because it gives consistent and asymptotically unbiased estimates.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "The Maximum Likelihood Estimation (MLE) was first studied in the symmetric case [27, 28].", "startOffset": 80, "endOffset": 88}, {"referenceID": 27, "context": "The Maximum Likelihood Estimation (MLE) was first studied in the symmetric case [27, 28].", "startOffset": 80, "endOffset": 88}, {"referenceID": 28, "context": "Dumouchel [29] developed an approximate maximum likelihood method.", "startOffset": 10, "endOffset": 14}, {"referenceID": 29, "context": "Nolan [30] extended the MLE in general case.", "startOffset": 6, "endOffset": 10}, {"referenceID": 25, "context": "Consequently, we estimate a univariate \u03b1-stable distribution using the Koutrouvelis method [26].", "startOffset": 91, "endOffset": 95}, {"referenceID": 32, "context": "To avoid this problem, it is possible to consider a discrete spectral measure [33] which has the form: \u03c3(.", "startOffset": 78, "endOffset": 82}, {"referenceID": 33, "context": "There are two methods to estimate an \u03b1-stable random vector: \u2022 the PROJection method [34] (PROJ) \u2022 the Empirical Characteristic Function method [35] (ECF) These two algorithms have the same performances in terms of estimation and computation time.", "startOffset": 85, "endOffset": 89}, {"referenceID": 34, "context": "There are two methods to estimate an \u03b1-stable random vector: \u2022 the PROJection method [34] (PROJ) \u2022 the Empirical Characteristic Function method [35] (ECF) These two algorithms have the same performances in terms of estimation and computation time.", "startOffset": 144, "endOffset": 148}, {"referenceID": 7, "context": "Definitions Discrete belief functions were introduced by Dempster [8], and formalized by Shafer [9] where he considers a discrete set of n exclusive events Ci called the frame of discernment:", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "Definitions Discrete belief functions were introduced by Dempster [8], and formalized by Shafer [9] where he considers a discrete set of n exclusive events Ci called the frame of discernment:", "startOffset": 96, "endOffset": 99}, {"referenceID": 0, "context": "Belief functions are defined as 2 onto [0,1].", "startOffset": 39, "endOffset": 44}, {"referenceID": 35, "context": "There are several combination rules [36] in the literature which differently address conflicts between sources.", "startOffset": 36, "endOffset": 40}, {"referenceID": 36, "context": "The most common rule is the conjunctive combination [37] where the resultant mass of A is obtained by:", "startOffset": 52, "endOffset": 56}, {"referenceID": 8, "context": "The final mass is obtained by carrying out the inverse operation of Equation (11) [9].", "startOffset": 82, "endOffset": 85}, {"referenceID": 37, "context": "Pignistic probability To make a decision on \u0398, several operators exist such that maximum credibility or maximum plausibility with pignistic probability being the most commonly used operator [38].", "startOffset": 190, "endOffset": 194}, {"referenceID": 8, "context": "Continuous belief functions The basic description of continuous belief functions was accomplished by Shafer [9], then by Nguyen [39] and Strat [40].", "startOffset": 108, "endOffset": 111}, {"referenceID": 38, "context": "Continuous belief functions The basic description of continuous belief functions was accomplished by Shafer [9], then by Nguyen [39] and Strat [40].", "startOffset": 128, "endOffset": 132}, {"referenceID": 39, "context": "Continuous belief functions The basic description of continuous belief functions was accomplished by Shafer [9], then by Nguyen [39] and Strat [40].", "startOffset": 143, "endOffset": 147}, {"referenceID": 40, "context": "Recently, Smets [41] extended the definition of belief functions to the set of reals R = R \u222a {\u2212\u221e,+\u221e} and masses are only attributed to intervals of R.", "startOffset": 16, "endOffset": 20}, {"referenceID": 40, "context": "Many papers [41, 42, 43] deal with the particular case of continuous belief functions with nested focal elements.", "startOffset": 12, "endOffset": 24}, {"referenceID": 41, "context": "Many papers [41, 42, 43] deal with the particular case of continuous belief functions with nested focal elements.", "startOffset": 12, "endOffset": 24}, {"referenceID": 42, "context": "Many papers [41, 42, 43] deal with the particular case of continuous belief functions with nested focal elements.", "startOffset": 12, "endOffset": 24}, {"referenceID": 40, "context": "For example, Smets [41]", "startOffset": 19, "endOffset": 23}, {"referenceID": 43, "context": "In [44, 45], the authors propose a way to build belief functions with connected sets by using a credal measure and an index function.", "startOffset": 3, "endOffset": 11}, {"referenceID": 44, "context": "In [44, 45], the authors propose a way to build belief functions with connected sets by using a credal measure and an index function.", "startOffset": 3, "endOffset": 11}, {"referenceID": 43, "context": "Credal measure and index function In [44], the authors propose a way to calculate belief functions from any probability density function.", "startOffset": 37, "endOffset": 41}, {"referenceID": 45, "context": "The function Bet f [Ci] is supposed to be bell-shaped for all \u03b1-stable distributions (proved by Yamazato [46]).", "startOffset": 105, "endOffset": 109}, {"referenceID": 46, "context": "Several plausibility functions associated to the same feature can be combined by using the generalized Bayes theorem [47, 48] to calculate mass functions allocated to A of an interval I: mR[x](A) = \u220f", "startOffset": 117, "endOffset": 125}, {"referenceID": 47, "context": "Several plausibility functions associated to the same feature can be combined by using the generalized Bayes theorem [47, 48] to calculate mass functions allocated to A of an interval I: mR[x](A) = \u220f", "startOffset": 117, "endOffset": 125}, {"referenceID": 41, "context": "To validate our approach, we classify planes using kinematic data as in [42, 43] and compare the decision with the approach of Caron et al.", "startOffset": 72, "endOffset": 80}, {"referenceID": 42, "context": "To validate our approach, we classify planes using kinematic data as in [42, 43] and compare the decision with the approach of Caron et al.", "startOffset": 72, "endOffset": 80}, {"referenceID": 42, "context": "[43].", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "In [43], the authors calculate plausibility function in the Gaussian pdf situation of mode \u03b4 and matrix of covariance \u03a3.", "startOffset": 3, "endOffset": 7}, {"referenceID": 43, "context": "[44] to build belief functions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "We obtain d mass functions (one for each feature) at point x with the generalized Bayes theorem [47, 48] (Equation (42)).", "startOffset": 96, "endOffset": 104}, {"referenceID": 47, "context": "We obtain d mass functions (one for each feature) at point x with the generalized Bayes theorem [47, 48] (Equation (42)).", "startOffset": 96, "endOffset": 104}, {"referenceID": 43, "context": "For an \u03b1-stable probability density function, plausibility functions are calculated for each feature by using the approach of Dor\u00e9 et al [44] (section 3.", "startOffset": 137, "endOffset": 141}, {"referenceID": 11, "context": "In [12], synthetic data are classified by modeling features using Gaussian and \u03b1-stable mixture models.", "startOffset": 3, "endOffset": 7}, {"referenceID": 48, "context": "Images from a side-scan sonar are automatically classified by extracting Haralick features [49, 50].", "startOffset": 91, "endOffset": 99}, {"referenceID": 49, "context": "Images from a side-scan sonar are automatically classified by extracting Haralick features [49, 50].", "startOffset": 91, "endOffset": 99}, {"referenceID": 5, "context": "The learning base was used to estimate each mean and variance for the Gaussian distributions and each parameter \u03b1, \u03b2, \u03b3 and \u03b4 for the \u03b1-stable distributions [6, 25, 51].", "startOffset": 157, "endOffset": 168}, {"referenceID": 24, "context": "The learning base was used to estimate each mean and variance for the Gaussian distributions and each parameter \u03b1, \u03b2, \u03b3 and \u03b4 for the \u03b1-stable distributions [6, 25, 51].", "startOffset": 157, "endOffset": 168}, {"referenceID": 50, "context": "The learning base was used to estimate each mean and variance for the Gaussian distributions and each parameter \u03b1, \u03b2, \u03b3 and \u03b4 for the \u03b1-stable distributions [6, 25, 51].", "startOffset": 157, "endOffset": 168}, {"referenceID": 34, "context": "The learning base was used to estimate each mean and matrix of covariance for the Gaussian distributions (Figure 9) and each parameter \u03b1, \u03c3, \u03b8 and \u03b4 for the \u03b1-stable distributions [35] (Figure 10).", "startOffset": 180, "endOffset": 184}, {"referenceID": 32, "context": "Presentation of the data Three classes of artificial data sets were generated from 2D \u03b1-stable distributions [33] (c.", "startOffset": 109, "endOffset": 113}, {"referenceID": 51, "context": "Table 5 and [52] for the significance of \u03c3 and \u03b8) with 3000 samples.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "In [16], the authors classify seven types of sea floor by comparing the time envelope of echo signal amplitude with a set of theoretical references curves.", "startOffset": 3, "endOffset": 7}, {"referenceID": 52, "context": "In our application, raw data (Figure 19) were processed using the Quester Tangent Corporation (QTC) software [53] to 14", "startOffset": 109, "endOffset": 113}, {"referenceID": 0, "context": "obtain some features, which were normalized between [0,1].", "startOffset": 52, "endOffset": 57}, {"referenceID": 53, "context": "These data had already been used for the navigation of an Autonomous Underwater Vehicle (AUV) [54].", "startOffset": 94, "endOffset": 98}, {"referenceID": 54, "context": "In [55], the author gave an overview of methods based on features to classify data and choose features which discriminate all classes.", "startOffset": 3, "endOffset": 7}, {"referenceID": 42, "context": "[43] where the pdf is a Gaussian.", "startOffset": 0, "endOffset": 4}], "year": 2015, "abstractText": "The aim of this paper is to show the interest in fitting features with an \u03b1-stable distribution to classify imperfect data. The supervised pattern recognition is thus based on the theory of continuous belief functions, which is a way to consider imprecision and uncertainty of data. The distributions of features are supposed to be unimodal and estimated by a single Gaussian and \u03b1-stable model. Experimental results are first obtained from synthetic data by combining two features of one dimension and by considering a vector of two features. Mass functions are calculated from plausibility functions by using the generalized Bayes theorem. The same study is applied to the automatic classification of three types of sea floor (rock, silt and sand) with features acquired by a mono-beam echo-sounder. We evaluate the quality of the \u03b1-stable model and the Gaussian model by analyzing qualitative results, using a Kolmogorov-Smirnov test (K-S test), and quantitative results with classification rates. The performances of the belief classifier are compared with a Bayesian approach.", "creator": "LaTeX with hyperref package"}}}