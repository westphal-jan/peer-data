{"id": "1502.01823", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2015", "title": "Unsupervised Fusion Weight Learning in Multiple Classifier Systems", "abstract": "In this paper we present an unsupervised method to learn the weights with which the scores of multiple classifiers must be combined in classifier fusion settings. We also introduce a novel metric for ranking instances based on an index which depends upon the rank of weighted scores of test points among the weighted scores of training points. We show that the optimized index can be used for computing measures such as average precision. Unlike most classifier fusion methods where a single weight is learned to weigh all examples our method learns instance-specific weights. The problem is formulated as learning the weight which maximizes a clarity index; subsequently the index itself and the learned weights both are used separately to rank all the test points. Our method gives an unsupervised method of optimizing performance on actual test data, unlike the well known stacking-based methods where optimization is done over a labeled training set. Moreover, we show that our method is tolerant to noisy classifiers and can be used for selecting N-best classifiers.", "histories": [["v1", "Fri, 6 Feb 2015 08:28:57 GMT  (87kb,D)", "http://arxiv.org/abs/1502.01823v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["anurag kumar", "bhiksha raj"], "accepted": false, "id": "1502.01823"}, "pdf": {"name": "1502.01823.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Fusion Weight Learning in Multiple Classifier Systems", "authors": ["Anurag Kumar", "Bhiksha Raj"], "emails": ["alnu@andrew.cmu.edu", "bhiksha@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1. Classifier Fusion", "text": "This year is the highest in the history of the country."}, {"heading": "1.2. Related Work", "text": "In fact, it is as if most people who are able are able to determine for themselves what they want to do and what they want to do. It is not as if they are able to determine for themselves what they want to do. It is as if they are able to decide whether they want to do it or not. It is as if they want to do it. It is as if they do not do it. It is as if they do it, but it is as if they do it. It is as if they do it, as if they do it, as if they do it, as if they do it, as if they do it, as if they do something, as if they do it."}, {"heading": "2. The Proposed Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Problem Setting", "text": "We set up our problem within a call scenario in which the goal is to classify positive test instances from the target class against negative instances. Our goal will be to determine how the values produced by a collection of classifiers can be combined to optimize the ranking. Let p be an example instance and m be the number of classifiers used to predict results. Ci denotes the ith classifier. So, for each example instance, let's have p m outputs that represent the values xi = Ci (p), i = 1 \u00b7 \u00b7 m, where Ci (p) is the output of the classifier Ci on any feature vector of p. Let's have ~ x = [x1 x2 x3..... xm] T be the vector that represents the values of all m classifiers. Thus, all sample instances are represented by an m-dimensional score vector that is represented by one vector for each training."}, {"heading": "2.2. Relevance, Irrelevance and Clarity", "text": "In fact, it is in such a way that it will be able to be in a position to be in which it is in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position to be in a position in a position to be in a position to be in a position in a position to be in a position to be in a position in a position to be in a position to be in a position in a position to be in a position in a position to be in a position in a position to be in a position in a position to be in a position in a position to be in a position in a position to be in a position to be in a position in a position in a position to be in a position in a position to be in a position in a position to be in a position to be in a position in a position to be in a position to be in a position in a position in a position to be in a position in a position to be in a position in a position in a position in a position to be in a position in a position to be in a position in a position to be in a position in a position in a position to be in a position in a position in a position to be in a position in a position in a position to be in a position in a position in a position to be in a position to be in a position in a position to be in a position to be in a position in a position in a position in a position in a position in a position in a position to be in a position in a position in a position in a position to be in a position in a position in a position in a position in a position in a position to be in a position in a"}, {"heading": "2.3. Learning Weights", "text": "In fact, the fact is that most of us are able to go in search of a solution that enables them to go in search of a solution that they are able to find and that enables them to go in search of a solution; indeed, it is the case that they are able to find a solution for a solution that is able to find a solution that is able to find a solution for a solution that is able to find a solution for a solution that is able to find a solution for a solution that is able to find a solution that is able to find a solution, that is able to find a solution that is able to find a solution for a solution."}, {"heading": "2.4. Ranking Instances", "text": "The algorithms of the algorithms 1 result in the estimation of the fusion weights for each test instance, which can now be used to calculate the results and determine the order of the test instance in a number of ways. (The precedence order of the precedence order can simply be used to calculate the result for each test instance. (The order of precedence is the precedence order of the precedence order of the precedence order.) (The order of the order of the order of the order of the unmarked instances is a measure of the order of the unmarked instances. (As discussed above, for a positive instance we expect the raw clarity index to be negative; the narrower order is \u2212 1 the negative instance that the desired value RCL should be close to + 1.) After optimizing the value CL (~ xu, ~ wu) the best that can be achieved in both directions is stored."}, {"heading": "3. Experimental Results", "text": "We evaluate the performance of our method in the field of multicultural object categorization. We use the flower class [11], which is used in several works, such as [3] [10], to name a few. This dataset contains the blossoms of 17 different categories. The datasets are described in a total of 1360 points. The datasets are divided into each predefined column. 20 validation images and 20 test images. The datasets are also described in the details of characteristics based on characteristics. [11], which are based on vocabulary, shape vocabularies and textures."}, {"heading": "3.1. Selecting \u03b1", "text": "The sigmoid approximation of the indicator function according to Eq.4 has a key parameter \u03b1. Setting this value to a high value leads to a closer approximation to the actual indicator function, but this leads to several local optimas of the objective function (CL), which effectively increases the variance of the estimator. On the other hand, a low value of \u03b1 leads to a lower variance, but can result in a significant distortion. Consequently, the actual value chosen for \u03b1 can have a considerable influence on the result of the classifier. Figure 2 shows the varia in AP as a function of \u03b1 for three flower classes. As can be seen, there can be considerable variations in the performance with \u03b1. In all cases, the performance achieved with the best \u03b1 is significantly higher than that achieved with the average fusion. For subsequent experiments, we determine the \u03b1 used for each class by optimizing the performance on the specified validation sets in the data."}, {"heading": "3.2. Ranking by total score", "text": "Figure 3 shows the MAP performance across all 17 classes on the dataset. Figure 3 shows results across all three datasets. Figure 3 shows results across all three datasets. Figure 3 shows results obtained using three methods: Ranking results from the average fusion in this test (we see in the next section that this is not always the case). Raw clarity based scoring based scoring also outperforms average performance in two of the three sectors. To repeat the effect of weighted fusion in each case, we show the MAP values if provided by an oracle in Figure 4. This essentially means that the results are aligned with test data. Figure 4 and Figure 2 we make a note of the fact that proper matching can provide significant improvements."}, {"heading": "4. Conclusions and Discussion", "text": "The results indicate that the proposed merger method is indeed capable of achieving improved results over the average merger, demonstrating its promise to identify the most promising classification situations. Furthermore, the results showed that the proposed raw clarity-based ranking is a valid measure for ranking instances. In fact, it exceeded weighted scoring methods. For several flower classes in different groups, 2-5% absolute improvement in AP is observed, using RCL for ranking instances. It is interesting that this rating is primarily based on ranking and has no direct probability-based interpretation. In particular, however, it is shown that a score achieved through unattended optimization over the test data is able to provide improvements over the average merger, opening up the possibility of an unattended weight-learning method that can exceed the state of merger strategies."}], "references": [{"title": "A classifier ensemble based on fusion of support vector machines for classifying hyperspectral data", "author": ["X. Ceamanos", "B. Waske", "J.A. Benediktsson", "J. Chanussot", "M. Fauvel", "J. Sveinsson"], "venue": "Intl. Journal of Image and Data Fusion,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "An efficient boosting algorithm for combining preferences", "author": ["Y. Freund", "R. Iyer", "R.E. Schapire", "Y. Singer"], "venue": "The Journal of machine learning research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "On feature combination for multiclass object classification", "author": ["P. Gehler", "S. Nowozin"], "venue": "In Computer Vision,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Active learning for in-  teractive multimedia retrieval", "author": ["T.S. Huang", "C.K. Dagli", "S. Rajaram", "E.Y. Chang", "M.I. Mandel", "G.E. Poliner", "D.P. Ellis"], "venue": "Proc. of the IEEE,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Trainable classifier-fusion schemes: an application to pedestrian detection", "author": ["O.L. Junior", "D. Delgado", "V. Gon\u00e7alves", "U. Nunes"], "venue": "In Intelligent Transportation Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "A framework for classifier fusion: Is it still needed? In Advances in Pattern Recognition, pages 45\u201356", "author": ["J. Kittler"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Increasing experts for majority vote in ocr: Theoretical considerations and strategies", "author": ["L. Lam", "C.Y. Suen"], "venue": "In Proc. 4th Int. Workshop on Frontiers in Handwriting Recognition,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Sample-specific late fusion for visual category recognition", "author": ["D. Liu", "K.-T. Lai", "G. Ye", "M.-S. Chen", "S.-F. Chang"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Using correspondence analysis to combine classifiers", "author": ["C.J. Merz"], "venue": "Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Automated flower classification over a large number of classes", "author": ["M. Nilsback", "A. Zisserman"], "venue": "In Computer Vision, Graphics & Image Processing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "A visual vocabulary for flower classification", "author": ["M.-E. Nilsback", "A. Zisserman"], "venue": "In CVPR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "An overview of classifier fusion methods", "author": ["D. Ruta", "B. Gabrys"], "venue": "Computing and Information systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Classification in likelihood", "author": ["R. Singh", "B. Raj"], "venue": "spaces. Technometrics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Combining classifiers with meta decision trees", "author": ["L. Todorovski", "S. D\u017eeroski"], "venue": "Machine learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Stacked generalization", "author": ["D.H. Wolpert"], "venue": "Neural networks,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1992}, {"title": "Methods of combining multiple classifiers and their applications to handwriting recognition", "author": ["L. Xu", "A. Krzyzak", "C.Y. Suen"], "venue": "Systems, Man and Cybernetics, IEEE Trans. on,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Robust late fusion with rank minimization", "author": ["G. Ye", "D. Liu", "I.-H. Jhuo", "S.-F. Chang"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}], "referenceMentions": [{"referenceID": 1, "context": "Our method is based on the bipartite ranking loss [2][4].", "startOffset": 50, "endOffset": 53}, {"referenceID": 3, "context": "Our method is based on the bipartite ranking loss [2][4].", "startOffset": 53, "endOffset": 56}, {"referenceID": 5, "context": "Since the optimization is performed directly on test data, it minimizes generalization concerns that result from learning weights on held out validation data [6].", "startOffset": 158, "endOffset": 161}, {"referenceID": 0, "context": "Several works have studied the problem of classifier fusion [1] [5], [13] [7] [16] [12].", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "Several works have studied the problem of classifier fusion [1] [5], [13] [7] [16] [12].", "startOffset": 64, "endOffset": 67}, {"referenceID": 12, "context": "Several works have studied the problem of classifier fusion [1] [5], [13] [7] [16] [12].", "startOffset": 69, "endOffset": 73}, {"referenceID": 6, "context": "Several works have studied the problem of classifier fusion [1] [5], [13] [7] [16] [12].", "startOffset": 74, "endOffset": 77}, {"referenceID": 15, "context": "Several works have studied the problem of classifier fusion [1] [5], [13] [7] [16] [12].", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "Several works have studied the problem of classifier fusion [1] [5], [13] [7] [16] [12].", "startOffset": 83, "endOffset": 87}, {"referenceID": 14, "context": "A particularly popular formalism for combining outputs of classifiers is stacking [15].", "startOffset": 82, "endOffset": 86}, {"referenceID": 8, "context": "The outputs (say probabilities) of the base classifiers are treated as an input space to the stacking function, while the output space of the function remains the same as that of the base classifiers [9] [14].", "startOffset": 200, "endOffset": 203}, {"referenceID": 13, "context": "The outputs (say probabilities) of the base classifiers are treated as an input space to the stacking function, while the output space of the function remains the same as that of the base classifiers [9] [14].", "startOffset": 204, "endOffset": 208}, {"referenceID": 7, "context": "To the best of our knowledge, few recent works have actually looked into instance-specific weight learning [8] [17].", "startOffset": 107, "endOffset": 110}, {"referenceID": 16, "context": "To the best of our knowledge, few recent works have actually looked into instance-specific weight learning [8] [17].", "startOffset": 111, "endOffset": 115}, {"referenceID": 7, "context": "Some of the most promising results are reported in [8].", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "Another issue with [8] is that the weights learned for different test instances are not disjoint from each other.", "startOffset": 19, "endOffset": 22}, {"referenceID": 3, "context": "To formalize this intuition, we define two losses, the relevance loss and the irrelevance loss, and an index based on these losses [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 0, "context": "The range of the clarity index is [0, 1] and it is desired for it to be high for any unlabeled instance.", "startOffset": 34, "endOffset": 40}, {"referenceID": 10, "context": "We use the Oxford Flower dataset [11] which has been used in several works such as [3][11][10] to name a few.", "startOffset": 33, "endOffset": 37}, {"referenceID": 2, "context": "We use the Oxford Flower dataset [11] which has been used in several works such as [3][11][10] to name a few.", "startOffset": 83, "endOffset": 86}, {"referenceID": 10, "context": "We use the Oxford Flower dataset [11] which has been used in several works such as [3][11][10] to name a few.", "startOffset": 86, "endOffset": 90}, {"referenceID": 9, "context": "We use the Oxford Flower dataset [11] which has been used in several works such as [3][11][10] to name a few.", "startOffset": 90, "endOffset": 94}, {"referenceID": 10, "context": "[11] describes the details of features based on Colour Vocabulary, Shape Vocabulary and Texture Vocabulary.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] gives the details of features based on HSV, SIFT on the foreground internal regions, SIFT on the foreground boundary, and Histogram of Gradients.", "startOffset": 0, "endOffset": 4}], "year": 2015, "abstractText": "In this paper we present an unsupervised method to learn the weights with which the scores of multiple classifiers must be combined in classifier fusion settings. We also introduce a novel metric for ranking instances based on an index which depends upon the rank of weighted scores of test points among the weighted scores of training points. We show that the optimized index can be used for computing measures such as average precision. Unlike most classifier fusion methods where a single weight is learned to weigh all examples our method learns instance-specific weights. The problem is formulated as learning the weight which maximizes a clarity index; subsequently the index itself and the learned weights both are used separately to rank all the test points. Our method gives an unsupervised method of optimizing performance on actual test data, unlike the well known stacking-based methods where optimization is done over a labeled training set. Moreover, we show that our method is tolerant to noisy classifiers and can be used for selecting N\u2212 best classifiers.", "creator": "LaTeX with hyperref package"}}}