{"id": "1502.02125", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2015", "title": "Contextual Online Learning for Multimedia Content Aggregation", "abstract": "The last decade has witnessed a tremendous growth in the volume as well as the diversity of multimedia content generated by a multitude of sources (news agencies, social media, etc.). Faced with a variety of content choices, consumers are exhibiting diverse preferences for content; their preferences often depend on the context in which they consume content as well as various exogenous events. To satisfy the consumers' demand for such diverse content, multimedia content aggregators (CAs) have emerged which gather content from numerous multimedia sources. A key challenge for such systems is to accurately predict what type of content each of its consumers prefers in a certain context, and adapt these predictions to the evolving consumers' preferences, contexts and content characteristics. We propose a novel, distributed, online multimedia content aggregation framework, which gathers content generated by multiple heterogeneous producers to fulfill its consumers' demand for content. Since both the multimedia content characteristics and the consumers' preferences and contexts are unknown, the optimal content aggregation strategy is unknown a priori. Our proposed content aggregation algorithm is able to learn online what content to gather and how to match content and users by exploiting similarities between consumer types. We prove bounds for our proposed learning algorithms that guarantee both the accuracy of the predictions as well as the learning speed. Importantly, our algorithms operate efficiently even when feedback from consumers is missing or content and preferences evolve over time. Illustrative results highlight the merits of the proposed content aggregation system in a variety of settings.", "histories": [["v1", "Sat, 7 Feb 2015 11:14:10 GMT  (1173kb,D)", "https://arxiv.org/abs/1502.02125v1", "To appear in IEEE Transactions on Multimedia, 2015"], ["v2", "Tue, 24 Mar 2015 12:04:41 GMT  (5709kb,D)", "http://arxiv.org/abs/1502.02125v2", "To appear in IEEE Transactions on Multimedia, 2015"]], "COMMENTS": "To appear in IEEE Transactions on Multimedia, 2015", "reviews": [], "SUBJECTS": "cs.MM cs.LG cs.MA", "authors": ["cem tekin", "mihaela van der schaar"], "accepted": false, "id": "1502.02125"}, "pdf": {"name": "1502.02125.pdf", "metadata": {"source": "CRF", "title": "Contextual Online Learning for Multimedia Content Aggregation", "authors": ["Cem Tekin", "Mihaela van der Schaar"], "emails": ["pubs-permissions@ieee.org.", "cmtkn@ucla.edu,", "mihaela@ee.ucla.edu."], "sections": [{"heading": null, "text": "This year, it has reached the point where it will be able to leave the country without being able to leave it."}, {"heading": "II. RELATED WORK", "text": "Related work can be divided into two categories: related work on referral systems and related work on online learning methods, the so-called multi-armed bandits."}, {"heading": "A. Related work on recommender systems and content matching", "text": "In fact, most of them are able to survive on their own."}, {"heading": "B. Related Work on Multi-armed Bandits", "text": "Apart from distributed content recommendations, our learning framework can be applied to any problem that can be formulated as a decentralized contextual bandit problem. Contextual bandits have already been studied in [10], [11], [20] - [22] in a single agent setting, in which the agent sequentially selects from a series of alternatives with unknown rewards and the rewards depend on the context information provided to the agent at each step. In [5] a contextual bandit algorithm called LinUCB is proposed to recommend personalized news articles that is a variant of the UCB algorithm [23] designed for linear payouts. Numerical results on real Internet data are provided, but no theoretical results are derived about the resulting regret. The main difference between our work and contextual bandits of individual agents is that (i) a three-phase learning process with specific exploration and exploration problems is not required."}, {"heading": "III. PROBLEM FORMULATION", "text": "In fact, most people are able to move to another world in which they are in the position in which they find themselves."}, {"heading": "A. User and Content Characteristics", "text": "In this paper, we look at two types of user and content attributes in order to decide what timeframe will be used to use the proposed results. First, we look at the case when the user and content attributes are static, i.e., they do not change over time. In this case, for a user with context x, CA can determine the likelihood that the user likes content, we call this the relevance of content c.The second case we look at corresponds to the scenario when the characteristics of the user and content are dynamic. For online multimedia content, especially for social media, it is known that both the user and the content attributes are dynamic and noisy [24], hence the problem, the concept drifts [25]. Formally, a concept is the distribution of the problem, i.e. the common distribution of user and content attributes, at a certain point in time [26]."}, {"heading": "B. Optimal Content Matching with Complete Information", "text": "Our benchmark for evaluating the performance of learning algorithms is the optimal solution, which always suggests the content with the highest relevance value for CA i from the specified C context, corresponding to selecting the best matching action in Ki given xi (t). Next, we define the expected rewards of matching actions and the selection guidelines of the benchmark. For a matching action k-M-i, the relevance score is given as \u03c0k (x). The expected reward of CA i from selecting the action k (x), where c-k (x): = arg-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-maxc-benchmark (x)."}, {"heading": "C. The Regret of Learning", "text": "In this subsection, we define regret as the performance measure of the learning algorithm used by the CAs. Simply put, regret is the loss resulting from unknown system dynamics. Regret for a learning algorithm that selects the appropriate action / arm ai (t) at the time t for CA i is defined in terms of the best matching action k \u0445 i (x) given in (2), then the regret of CA i at the time T isRi (T): = T \u2211 t = 1 (B) (B) i (t))) (xi (t)))) \u2212 d i k \u0445 i (T))) \u2212 E [T \u2211 t = 1 (I (yi (t) = L) \u2212 diai (t)]]]]. (3) Regret indicates the convergence rate of the total expected reward of the learning algorithm to the value of the optimal solution of (2). Any algorithm whose regret is sublinear, i.e., total Ri = T (T) is average."}, {"heading": "IV. A DISTRIBUTED ONLINE CONTENT MATCHING ALGORITHM", "text": "Unlike previous online learning algorithms that exploit context information [10], [11], [20] - [22], [29], which take into account a single learning environment, the proposed algorithm helps a CA learn from the experience of other CA's. By using this mechanism, a CA is able to recommend content from multimedia sources that do not have a direct connection without knowing the IDs of such multimedia sources and their contents; it learns from these multimedia sources only through the other CAs that are associated with it. To analytically exploit the regret of this algorithm, we use the following assumption that the content attributes are static, we assume that each type of content has similar relevance for similar contexts; we assume that this is related to a Lipschitz condition.Assumption 1: There is L > 0, > 0 such."}, {"heading": "V. REGRET WHEN FEEDBACK IS MISSING", "text": "When we analyze the performance of DISCOM, we assume that users always give feedback: as or when they reject it. However, in most online content aggregation platforms, user feedback is not always available. If the user does not give feedback at this time, we assume that DISCOM does not update its counters, resulting in a greater number of training and explorations than if feedback is always available. The following theorem provides an upper limit on DISCOM's regrets for this case.Theorem 2: Let the DISCOM algorithm log with the parameters H1 (t) = t2GP / (3GP + d) maximizes the maximized + (T) maximized + (T) d \u2212 d \u2212 log t, H3 (t) t = 2GP / 3GP / (T) = 3GP / (T) + 3GP / (T) + (T) + 3GP / (T) (GP) + 3GP / T (T) 3GP + / T) (T)."}, {"heading": "VI. LEARNING UNDER DYNAMIC USER AND CONTENT CHARACTERISTICS", "text": "In this section, we assume that the following relation between the probabilities that a content will be labeled with similar contexts in two different periods of time, but will in any case exist in a different way than that there is a more active way than the speed of change in user and content characteristics. We call upon T's the stability parameters that capture the temporal dynamics of the mapping of content that is absent in Assumption 1. Such temporal variations are often referred to as concept drift. [31] If there is concept drift, a learner should also consider the past to take into account information that is absent in Assumption 1."}, {"heading": "VII. NUMERICAL RESULTS", "text": "In this section, we provide numerical results for our proposed DISCOM and DISCOM-W algorithms on real data sets."}, {"heading": "A. Datasets", "text": "The only factor that influences the overall reward are the user ratings. (ii) The context of the user (the two-dimensional vector), (iii) the click information of the user for a website / content is linked to the relevance of the content. (ii) The click numbers for a website / content are linked to the relevance of the content. (ii) The context of the user is determined by the user. (ii) The context contains T = 70,000 instances and 40 different types of content."}, {"heading": "B. Learning Algorithms", "text": "While DISCOM and DISCOM-W are the first distributed algorithms to perform content aggregation (see Table I), we compare their performance with the distributed versions of the centralized algorithms used in [5], [10], [22]. In the distributed implementation of these centralized algorithms, we assume that each CA runs an independent instance of the algorithms using its Ai algorithm, namely the contents of algorithm A with the distributed system of Ai that executes its own instance of Ai."}, {"heading": "C. Yahoo! Today Module Simulations", "text": "In YTM, each instance (user) has two contexts (x1, x2). [0, 1] 2. We simulate the algorithms in Section VII-B for three different contexts, in which the learning algorithms decide only on the basis of (i) the first context x1, (ii) the second context x2 and (iii) both contexts (x1, x2) of the user. DISCOM's mT parameter for these simulations is set to the optimal value found in Theorem 1 (for \u03b3 = 1), which is dT 1 / 4e for simulations with a single context, and dT 1 / 5e for simulations with both contexts. DISCOM is compared with the best DISM values for numerous z values from 1 / 4 to 1 / 2. Table IV compares the number of trainings and explorations required within the limits of regret."}, {"heading": "D. Music Dataset Simulations", "text": "Table VI compares the performance of DISCOM, LinUCB, Hybrid and CZ for the music record. The parameter values used for DISCOM for the result in Table VI are z = 1 / 8 and mT = 4. Results show that DISCOM achieves a 10% improvement over LinUCB, a 5% improvement over hybrid and a 28% improvement over CZ in terms of the average number of likes achieved for CA 1 users. In addition, the average number of likes received by DISCOM for high-type users (differential services) is even higher, 13%, 8% and 32%, respectively, than LinUCB, HE and CZ."}, {"heading": "E. Yahoo! Today Module with Drift Simulations", "text": "Table VII compares the performance of DISCOM-W with half window length (\u03c4h = 2500) and mT = 10, DISCOM (with mT set equal to dT 1 / 4e simulations with a single context dimension and dT 1 / 5e for simulation with two context dimensions), LinUCB, hybrid and CZ. For the results in the table, the z-parameter value of DISCOM and DISCOMW is set to the z value in which they achieve the highest number of clicks. Likewise, LinUCB, hybrid and CZ are also rated with their best parameter values. Results show the performance of DISCOM and DISCOM-W for differentiated services. DISCOM-W performs best in this dataset in terms of the average number of clicks, with about 23%, 11.3% and 51.6% improvement over the best of LinUCB, hybrid and CZ, for contexts, respectively, x2 (x2)."}, {"heading": "VIII. CONCLUSION", "text": "In this paper, we looked at novel online learning algorithms for content matching by a distributed group of CA. We characterized the relationship between user and content characteristics by a relevance point and proposed online learning algorithms that learn to match each user with the content with the highest relevance value. If user and content characteristics are static, the best matching between content and each user type can be learned perfectly, i.e., the average regret due to suboptimal matching is near zero. If user and content characteristics are dynamic, depending on the rate of change, an approximately optimal matching between content and each user type can be learned. In addition to our theoretical results, we validated the concept of distributed content matching on real data sets. An interesting future research direction is to examine the interaction between different CA when competing for the same pool of users. If content that a user sends to another CA, they should have a high probability of sending CA to another CA, or they should be used by another CA."}, {"heading": "APPENDIX A", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A BOUND ON DIVERGENT SERIES", "text": "For p > 0, p 6 = 1, T \u2211 t = 1 t \u2212 p \u2264 1 + (T 1 \u2212 p \u2212 1) / (1 \u2212 p). Proof: See [32]."}, {"heading": "APPENDIX B PROOF OF THEOREM 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Necessary Definitions and Notations", "text": "Leave \u03b2a: = \u2211 \u221e t = 1 1 / ta, and leave log (.) logarithm in base e. For each hypercube p-PT leave \u03c0c, p: = supx-p \u03c0c (x), \u03c0c, p: = infx-p \u03c0c (x), for c-C, and \u00b5ik, p: = supx-p \u00b5ik (x), \u00b5i k, p: = infx-p \u00b5 i k (x), for k-Ki. Let x-p be the context in the center (symmetry center) of the hypercube p. We define the optimal matching action of CA i for hypercube p as k-p (p): = arg maxk-p (x-p). If the hypercube p13is clearly out of context (center of symmetry) of the hypercube p. p."}, {"heading": "B. Bounding the Regret in Training, Exploration and Exploitation phases.", "text": "In the following lemmas we will address each of these terms individually (t). (t) The following question arises to us (t). (t) D \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i. (t)\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i. (t) i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i. (t) i\" i \"i\" i \"i\" i \"i\" i \"i. (t) i\" i \"i\" i \"i i\" i i \"i.\" i \"i\" i. \"i\" i. (t) i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i. \"i\" i \"i.\" i \"i\" i. (t) i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. (t) i \"i\" i \"i\" i \"i\" i \"i\" i. (t) i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. (t) i) i \"i\" i \"i\" i \"i\" i \"i. (t) i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. (t) i) i \"i. (t) i) i\" i \"i\" i \"i\" i \"i\" i. (t) i) i \"i\" i \"i\" i. (t) i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i) i \"i\" i \"i\""}, {"heading": "C. Proof of Theorem 1", "text": "The highest orders of repentance emanating from Lemmas 1, 2 and 3 are O \u0441d + z, O (T 1 \u2212 z / 2), O (T 1 \u2212 z / 2). We must optimize them with regard to the limitation that repentance is minimized when \u03bad + z = 1 \u2212 z / 2, which is achieved by z = 2\u03b3 / (3\u03b3 + d). The result is obtained from the summation of the boundaries in Lemmas 1, 2 and 3."}, {"heading": "APPENDIX C PROOF OF COROLLARY 1", "text": "From the proof of Lemma 2, for z = 2\u03b3 / (3\u03b3 + d) P (Vik (t), Wi (t)) \u2264 2t \u2212 2 + 2MCmax\u03b22t \u2212 \u03b3 / (3\u03b3 + d) for k-Lipi (t) (t), it follows that P (ai (t) and Lipi (t) (t), W i (t) \u2264 k-Li pi (t) (t) (Vik (t), Wi (t)) \u2264 2 | Ki | t2 + 2 | Ki | MCmax\u03b22 t\u03b3 / (3\u03b3 + d).The difference between the expected reward of an action within a hypercube and its expected reward at the center of the hypercube is at most Ld\u03b3 / 2 / (mT) \u2264 2 / (mT).Since mT = dT 1 / (3\u03b3 + d) e, ai (t) \u2212 Lipi (t) (t) (t) (this (ig) (3)."}, {"heading": "APPENDIX D PROOF OF THEOREM 2", "text": "For the time t to be an exploitation slot for CA i, it is necessary that Muti, pi (t) (t) (t), pi (t), pi (t), pi (t), pi (t) (t) =. Since the counters are only updated by DISCOM when feedback (t) is received, and since the control functions are the same as those used in the setting where feedback is always available, the regret due to sub-optimal and near-optimal matching actions will not be greater by time t with missing feedback than the regret due to sub-optimal and near-optimal matching actions in the case where users always provide feedback. Therefore, the limits given in Lemmas 2 and 3 will also apply in the case of missing feedback. Only the regret due to training and exploration increases, as further training and exploration are required before the counters exceed the values of the control functions, so that the estimates of the relevance evaluation are accurate enough."}, {"heading": "APPENDIX E PROOF OF THEOREM 3", "text": "The basic idea is to select \u03c4h in such a way that the regret due to the variation of the relevance over time and the regret due to the variation of the estimated relevance values due to the limited number of observations in each round is balanced out. The majority of the steps of this proof is similar to the proof of regret in theorem 1, hence some of the steps are omitted. Consider the number of time periods in each round through [\u03b7]. For all c-C steps, the content of the regret is in c, p: = sup x-p, t-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z-Z."}], "references": [{"title": "Contextual online learning for multimedia content aggregation", "author": ["C. Tekin", "M. van der Schaar"], "venue": "to appear in IEEE Trans. Multimedia, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Pricing and investment for online TV content platforms", "author": ["S. Ren", "M. van der Schaar"], "venue": "IEEE Trans. Multimedia, vol. 14, no. 6, pp. 1566\u2013 1578, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Advanced IPTV services personalization through context-aware content recommendation", "author": ["S. Song", "H. Moustafa", "H. Afifi"], "venue": "IEEE Trans. Multimedia, vol. 14, no. 6, pp. 1528\u20131537, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "A novel framework for semantic annotation and personalized retrieval of sports video", "author": ["C. Xu", "J. Wang", "H. Lu", "Y. Zhang"], "venue": "IEEE Trans. Multimedia, vol. 10, no. 3, pp. 421\u2013436, 2008.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["L. Li", "W. Chu", "J. Langford", "R.E. Schapire"], "venue": "Proc. 19th Int. Conf. World Wide Web, 2010, pp. 661\u2013670.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Analyzing video services in web 2.0: a global perspective", "author": ["M. Saxena", "U. Sharan", "S. Fahmy"], "venue": "Proc. 18th Int. Workshop Network and Operating Systems Support for Digital Audio and Video, 2008, pp. 39\u2013 44.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Adapting multimedia internet content for universal access", "author": ["R. Mohan", "J.R. Smith", "C.-S. Li"], "venue": "IEEE Trans. Multimedia, vol. 1, no. 1, pp. 104\u2013114, 1999.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "Building an integrated pan- European news distribution network", "author": ["M. Schranz", "S. Dustdar", "C. Platzer"], "venue": "Collaborative Networks and Their Breeding Environments. Springer US, 2005, pp. 587\u2013596.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "FStream: a decentralized and social music streamer", "author": ["A. Boutet", "K. Kloudas", "A.-M. Kermarrec"], "venue": "Proc. Int. Conf. Networked Systems (NETYS), pp. 253\u2013257.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 0}, {"title": "Contextual bandits with similarity information", "author": ["A. Slivkins"], "venue": "Proc. 24th Annual Conf. Learning Theory (COLT), vol. 19, June 2011, pp. 679\u2013702.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Contextual multi-armed bandits", "author": ["T. Lu", "D. P\u00e1l", "M. P\u00e1l"], "venue": "Proc. 13th Int. Conf. Artificial Intelligence and Statistics (AISTATS), vol. 9, May 2010, pp. 485\u2013492.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Linear bandits in high dimension and recommendation systems", "author": ["Y. Deshpande", "A. Montanari"], "venue": "Proc. 50th Annual Allerton Conf. Communication, Control and Computing, 2012, pp. 1750\u20131754.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "A fast bandit algorithm for recommendations to users with heterogeneous tastes", "author": ["P. Kohli", "M. Salek", "G. Stoddard"], "venue": "Proc. 27th Conf. Artificial Intelligence (AAAI), July 2013, pp. 1135\u20131141.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "A hidden Markov model for collaborative filtering", "author": ["N. Sahoo", "P.V. Singh", "T. Mukhopadhyay"], "venue": "MIS Quarterly, vol. 36, no. 4, pp. 1329\u20131356, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Amazon.com recommendations: Item-to-item collaborative filtering", "author": ["G. Linden", "B. Smith", "J. York"], "venue": "Internet Comput., vol. 7, no. 1, pp. 76\u201380, 2003.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2003}, {"title": "Collaborative filtering with the simple Bayesian classifier", "author": ["K. Miyahara", "M.J. Pazzani"], "venue": "PRICAI 2000 Topics in Artificial Intelligence. Springer, 2000, pp. 679\u2013689.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2000}, {"title": "Empowering cross-domain internet media with real-time topic learning from social streams", "author": ["S.D. Roy", "T. Mei", "W. Zeng", "S. Li"], "venue": "Proc. IEEE Int. Conf. Multimedia and Expo (ICME), 2012, pp. 49\u201354.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Towards cross-domain learning for social video popularity prediction", "author": ["S. Roy", "T. Mei", "W. Zeng", "S. Li"], "venue": "IEEE Trans. Multimedia, vol. 15, no. 6, pp. 1255\u20131267, Oct 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Hybrid-\u03b5greedy for mobile context-aware recommender system", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": "Advances in Knowledge Discovery and Data Mining. Springer, 2012, pp. 468\u2013479.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Online learning with prior knowledge", "author": ["E. Hazan", "N. Megiddo"], "venue": "Learning Theory. Springer, 2007, pp. 499\u2013513.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient optimal learning for contextual bandits", "author": ["M. Dudik", "D. Hsu", "S. Kale", "N. Karampatziakis", "J. Langford", "L. Reyzin", "T. Zhang"], "venue": "arXiv preprint arXiv:1106.2369, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Contextual bandits with linear payoff functions", "author": ["W. Chu", "L. Li", "L. Reyzin", "R.E. Schapire"], "venue": "Proc. 14th Int. Conf. Artificial Intelligence and Statistics (AISTATS), vol. 15, April 2011, pp. 208\u2013214.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning, vol. 47, p. 235256, 2002.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2002}, {"title": "Social multimedia: highlighting opportunities for search and mining of multimedia data in social media applications", "author": ["M. Naaman"], "venue": "Multimedia Tools and Applications, vol. 56, no. 1, pp. 9\u201334, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "The impact of diversity on online ensemble learning in the presence of concept drift", "author": ["L.L. Minku", "A.P. White", "X. Yao"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 22, no. 5, pp. 730\u2013742, 2010.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "A framework for generating data to simulate changing environments", "author": ["A. Narasimhamurthy", "L.I. Kuncheva"], "venue": "Proc. 25th IASTED Int. Multi-Conf.: Artificial Intelligence and Applications, February 2007, pp. 384\u2013389.  17", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient online exchange via fiat money", "author": ["M. van der Schaar", "J. Xu", "W. Zame"], "venue": "Economic Theory, vol. 54, no. 2, pp. 211\u2013248, 2013.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Bitcoin: A peer-to-peer electronic cash system", "author": ["S. Nakamoto"], "venue": "Consulted, vol. 1, no. 2012, p. 28, 2008.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "The epoch-greedy algorithm for contextual multi-armed bandits", "author": ["J. Langford", "T. Zhang"], "venue": "Proc. 20th Int. Conf. Neural Information Processing Systems (NIPS), vol. 20, 2007, pp. 1096\u20131103.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "On appropriate assumptions to mine data streams: Analysis and practice", "author": ["J. Gao", "W. Fan", "J. Han"], "venue": "Proc. 7th IEEE Int. Conf. Data Mining (ICDM), 2007, pp. 143\u2013152.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Integrating novel class detection with classification for concept-drifting data streams", "author": ["M.M. Masud", "J. Gao", "L. Khan", "J. Han", "B. Thuraisingham"], "venue": "Machine Learning and Knowledge Discovery in Databases. Springer, 2009, pp. 79\u201394.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 1, "context": "A plethora of multimedia applications (web-based TV [2], [3], personalized video retrieval [4], personalized news aggregation [5], etc.", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "A plethora of multimedia applications (web-based TV [2], [3], personalized video retrieval [4], personalized news aggregation [5], etc.", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "A plethora of multimedia applications (web-based TV [2], [3], personalized video retrieval [4], personalized news aggregation [5], etc.", "startOffset": 91, "endOffset": 94}, {"referenceID": 4, "context": "A plethora of multimedia applications (web-based TV [2], [3], personalized video retrieval [4], personalized news aggregation [5], etc.", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": ", Dailymotion, Metacafe [6]) that are responsible for mining the content of numerous multimedia sources in search of finding content which is interesting for the users.", "startOffset": 24, "endOffset": 27}, {"referenceID": 0, "context": "This online technical report is an extended version of the paper that appeared in IEEE Transactions on Multimedia [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 6, "context": "It may also represent the type of the device that the user is using [7] (e.", "startOffset": 68, "endOffset": 71}, {"referenceID": 7, "context": "[8]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "To jointly optimize the performance of the multimedia content aggregation system, we propose an online learning methodology that builds on contextual bandits [10], [11].", "startOffset": 158, "endOffset": 162}, {"referenceID": 10, "context": "To jointly optimize the performance of the multimedia content aggregation system, we propose an online learning methodology that builds on contextual bandits [10], [11].", "startOffset": 164, "endOffset": 168}, {"referenceID": 4, "context": "For instance, in [5], [12] a recommender system that learns the preferences of its users in an online way based on the ratings submitted by the users is provided.", "startOffset": 17, "endOffset": 20}, {"referenceID": 11, "context": "For instance, in [5], [12] a recommender system that learns the preferences of its users in an online way based on the ratings submitted by the users is provided.", "startOffset": 22, "endOffset": 26}, {"referenceID": 12, "context": "An online learning algorithm for a centralized recommender which updates its recommendations as both the preferences of the users and the characteristics of items change over time is proposed in [13].", "startOffset": 195, "endOffset": 199}, {"referenceID": 13, "context": "The general framework which exploits the similarities between the past users and the current user to recommend content to the current user is called collaborative filtering [14]\u2013[16].", "startOffset": 173, "endOffset": 177}, {"referenceID": 15, "context": "The general framework which exploits the similarities between the past users and the current user to recommend content to the current user is called collaborative filtering [14]\u2013[16].", "startOffset": 178, "endOffset": 182}, {"referenceID": 14, "context": "Groups of similar users can be created by various methods such as clustering [15], and then, the matching will be made based on the content matched with the past users that are in the same group.", "startOffset": 77, "endOffset": 81}, {"referenceID": 4, "context": "Our work [5], [12] [15] [14] [19] Distributed Yes No No No No Reward model H\u00f6lder Linear N/A N/A N/A Confidence bounds Yes No No No No Regret bound Yes Yes No No No Dynamic user Yes No Yes Yes Yes /content distribution", "startOffset": 9, "endOffset": 12}, {"referenceID": 11, "context": "Our work [5], [12] [15] [14] [19] Distributed Yes No No No No Reward model H\u00f6lder Linear N/A N/A N/A Confidence bounds Yes No No No No Regret bound Yes Yes No No No Dynamic user Yes No Yes Yes Yes /content distribution", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "Our work [5], [12] [15] [14] [19] Distributed Yes No No No No Reward model H\u00f6lder Linear N/A N/A N/A Confidence bounds Yes No No No No Regret bound Yes Yes No No No Dynamic user Yes No Yes Yes Yes /content distribution", "startOffset": 19, "endOffset": 23}, {"referenceID": 13, "context": "Our work [5], [12] [15] [14] [19] Distributed Yes No No No No Reward model H\u00f6lder Linear N/A N/A N/A Confidence bounds Yes No No No No Regret bound Yes Yes No No No Dynamic user Yes No Yes Yes Yes /content distribution", "startOffset": 24, "endOffset": 28}, {"referenceID": 18, "context": "Our work [5], [12] [15] [14] [19] Distributed Yes No No No No Reward model H\u00f6lder Linear N/A N/A N/A Confidence bounds Yes No No No No Regret bound Yes Yes No No No Dynamic user Yes No Yes Yes Yes /content distribution", "startOffset": 29, "endOffset": 33}, {"referenceID": 16, "context": "Another line of work [17], [18] uses social streams mined in one domain, e.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "Another line of work [17], [18] uses social streams mined in one domain, e.", "startOffset": 27, "endOffset": 31}, {"referenceID": 16, "context": "For example, in [17], Tweet streams are used to provide video recommendations in a commercial video search engine.", "startOffset": 16, "endOffset": 20}, {"referenceID": 6, "context": "A content adaptation method is proposed in [7] which enables the users with different types of contexts and devices to receive content that is in a suitable format to be accessed.", "startOffset": 43, "endOffset": 46}, {"referenceID": 17, "context": "Video popularity prediction is studied in [18], where the goal is to predict if a video will become popular in the multimedia domain, by detecting social trends in another social media domain (such as Twitter), and transferring this knowledge to the multimedia domain.", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "Contextual bandits have been studied before in [10], [11], [20]\u2013[22] in a single agent setting, where the agent sequentially chooses from a set of alternatives with unknown rewards, and the rewards depend on the context information provided to the agent at each time step.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "Contextual bandits have been studied before in [10], [11], [20]\u2013[22] in a single agent setting, where the agent sequentially chooses from a set of alternatives with unknown rewards, and the rewards depend on the context information provided to the agent at each time step.", "startOffset": 53, "endOffset": 57}, {"referenceID": 19, "context": "Contextual bandits have been studied before in [10], [11], [20]\u2013[22] in a single agent setting, where the agent sequentially chooses from a set of alternatives with unknown rewards, and the rewards depend on the context information provided to the agent at each time step.", "startOffset": 59, "endOffset": 63}, {"referenceID": 21, "context": "Contextual bandits have been studied before in [10], [11], [20]\u2013[22] in a single agent setting, where the agent sequentially chooses from a set of alternatives with unknown rewards, and the rewards depend on the context information provided to the agent at each time step.", "startOffset": 64, "endOffset": 68}, {"referenceID": 4, "context": "In [5], a contextual bandit algorithm named LinUCB is proposed for recommending personalized news articles, which is variant of the UCB algorithm [23] designed for linear payoffs.", "startOffset": 3, "endOffset": 6}, {"referenceID": 22, "context": "In [5], a contextual bandit algorithm named LinUCB is proposed for recommending personalized news articles, which is variant of the UCB algorithm [23] designed for linear payoffs.", "startOffset": 146, "endOffset": 150}, {"referenceID": 0, "context": "Let X = [0, 1] be the context space,5 where d is the dimension of the context space.", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "We assume that all these quantities are mapped into [0, 1].", "startOffset": 52, "endOffset": 58}, {"referenceID": 4, "context": "For instance, this mapping can be established by feature extraction methods such as the one given in [5].", "startOffset": 101, "endOffset": 104}, {"referenceID": 0, "context": "Another method is to represent each property of a user by a real number between [0, 1] (e.", "startOffset": 80, "endOffset": 86}, {"referenceID": 7, "context": "Consider a distributed set of news aggregators that operate in different countries (for instance a European news aggregator network as in [8]).", "startOffset": 138, "endOffset": 141}, {"referenceID": 23, "context": "For online multimedia content, especially for social media, it is known that both the user and the content characteristics are dynamic and noisy [24], hence the problem exhibits concept drift [25].", "startOffset": 145, "endOffset": 149}, {"referenceID": 24, "context": "For online multimedia content, especially for social media, it is known that both the user and the content characteristics are dynamic and noisy [24], hence the problem exhibits concept drift [25].", "startOffset": 192, "endOffset": 196}, {"referenceID": 25, "context": ", the joint distribution of the user and content characteristics, at a certain point of time [26].", "startOffset": 93, "endOffset": 97}, {"referenceID": 26, "context": "When the cost is payment, it can be money, tokens [27] or Bitcoins [28].", "startOffset": 50, "endOffset": 54}, {"referenceID": 27, "context": "When the cost is payment, it can be money, tokens [27] or Bitcoins [28].", "startOffset": 67, "endOffset": 71}, {"referenceID": 0, "context": "Since this cost is bounded, without loss of generality we assume that dj \u2208 [0, 1] for all i, j \u2208 M.", "startOffset": 75, "endOffset": 81}, {"referenceID": 0, "context": "In order make our model general, we also assume that there is a cost associated with recommending a type of content c \u2208 Ci, which is given by dc \u2208 [0, 1], for CA i.", "startOffset": 147, "endOffset": 153}, {"referenceID": 9, "context": "CA i\u2019s problem can be modeled as a contextual bandit problem [10], [21], [22], [29], where likes and costs translate into rewards.", "startOffset": 61, "endOffset": 65}, {"referenceID": 20, "context": "CA i\u2019s problem can be modeled as a contextual bandit problem [10], [21], [22], [29], where likes and costs translate into rewards.", "startOffset": 67, "endOffset": 71}, {"referenceID": 21, "context": "CA i\u2019s problem can be modeled as a contextual bandit problem [10], [21], [22], [29], where likes and costs translate into rewards.", "startOffset": 73, "endOffset": 77}, {"referenceID": 28, "context": "CA i\u2019s problem can be modeled as a contextual bandit problem [10], [21], [22], [29], where likes and costs translate into rewards.", "startOffset": 79, "endOffset": 83}, {"referenceID": 0, "context": "where dk \u2208 [0, 1] is the normalized cost of choosing action k for CA i.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "In the next section, we propose an online learning algorithm which achieves M: Set of all CAs Ci: Contents in the Content Network of CA i Cmax: maxi\u2208M |Ci| C: Set of all contents X = [0, 1]: Context space Y: Set of feedbacks a user can give xi(t): d-dimensional context of tth user of CA i yi(t): Feedback of the tth user of CA i Ki: Set of content matching actions of CA i \u03c0c(x): Relevance score of content c for context x dk: Cost of choosing matching action k for CA i \u03bck(x): Expected reward (static) of CA i from matching action k for context x k\u2217 i (x): Optimal matching action of CA i given context x (oracle benchmark) Ri(T ): Regret of CA i at time T \u03b2a := \u2211\u221e t=1 1/t a", "startOffset": 183, "endOffset": 189}, {"referenceID": 9, "context": "In contrast to prior online learning algorithms that exploit the context information [10], [11], [20]\u2013[22], [29], which consider a single learner setting, the proposed algorithm helps a CA to learn from the experience of other CAs.", "startOffset": 85, "endOffset": 89}, {"referenceID": 10, "context": "In contrast to prior online learning algorithms that exploit the context information [10], [11], [20]\u2013[22], [29], which consider a single learner setting, the proposed algorithm helps a CA to learn from the experience of other CAs.", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "In contrast to prior online learning algorithms that exploit the context information [10], [11], [20]\u2013[22], [29], which consider a single learner setting, the proposed algorithm helps a CA to learn from the experience of other CAs.", "startOffset": 97, "endOffset": 101}, {"referenceID": 21, "context": "In contrast to prior online learning algorithms that exploit the context information [10], [11], [20]\u2013[22], [29], which consider a single learner setting, the proposed algorithm helps a CA to learn from the experience of other CAs.", "startOffset": 102, "endOffset": 106}, {"referenceID": 28, "context": "In contrast to prior online learning algorithms that exploit the context information [10], [11], [20]\u2013[22], [29], which consider a single learner setting, the proposed algorithm helps a CA to learn from the experience of other CAs.", "startOffset": 108, "endOffset": 112}, {"referenceID": 0, "context": "DISCOM creates a partition of X = [0, 1] based on T .", "startOffset": 34, "endOffset": 40}, {"referenceID": 9, "context": ", [10]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 29, "context": "Such temporal variations are often referred to as concept drift [30], [31].", "startOffset": 64, "endOffset": 68}, {"referenceID": 30, "context": "Such temporal variations are often referred to as concept drift [30], [31].", "startOffset": 70, "endOffset": 74}, {"referenceID": 4, "context": "Yahoo! Today Module (YTM) [5]: The dataset contains news article webpage recommendations of Yahoo! Front Page.", "startOffset": 26, "endOffset": 29}, {"referenceID": 4, "context": "While DISCOM and DISCOM-W are the first distributed algorithms to perform content aggregation (see Table I), we compare their performance with distributed versions of the centralized algorithms proposed in [5], [10], [19], [22].", "startOffset": 206, "endOffset": 209}, {"referenceID": 9, "context": "While DISCOM and DISCOM-W are the first distributed algorithms to perform content aggregation (see Table I), we compare their performance with distributed versions of the centralized algorithms proposed in [5], [10], [19], [22].", "startOffset": 211, "endOffset": 215}, {"referenceID": 18, "context": "While DISCOM and DISCOM-W are the first distributed algorithms to perform content aggregation (see Table I), we compare their performance with distributed versions of the centralized algorithms proposed in [5], [10], [19], [22].", "startOffset": 217, "endOffset": 221}, {"referenceID": 21, "context": "While DISCOM and DISCOM-W are the first distributed algorithms to perform content aggregation (see Table I), we compare their performance with distributed versions of the centralized algorithms proposed in [5], [10], [19], [22].", "startOffset": 223, "endOffset": 227}, {"referenceID": 4, "context": "LinUCB [5], [22]: This algorithm computes an index for each matching action by assuming that the relevance score of a matching action for a user is a linear combination of the contexts of the user.", "startOffset": 7, "endOffset": 10}, {"referenceID": 21, "context": "LinUCB [5], [22]: This algorithm computes an index for each matching action by assuming that the relevance score of a matching action for a user is a linear combination of the contexts of the user.", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "Hybrid- [19]: This algorithm forms context-dependent sample mean rewards for the matching actions by considering the history of observations and decisions for groups of contexts that are similar to each other.", "startOffset": 8, "endOffset": 12}, {"referenceID": 9, "context": "Contextual zooming (CZ) [10]: This algorithm adaptively creates balls over the joint action and context space, calculates an index for each ball based on the history of selections of that ball, and at each time step selects a matching action according to the ball with the highest index that contains the current", "startOffset": 24, "endOffset": 28}, {"referenceID": 0, "context": "In YTM each instance (user) has two contexts (x1, x2) \u2208 [0, 1].", "startOffset": 56, "endOffset": 62}], "year": 2015, "abstractText": "The last decade has witnessed a tremendous growth in the volume as well as the diversity of multimedia content generated by a multitude of sources (news agencies, social media, etc.). Faced with a variety of content choices, consumers are exhibiting diverse preferences for content; their preferences often depend on the context in which they consume content as well as various exogenous events. To satisfy the consumers\u2019 demand for such diverse content, multimedia content aggregators (CAs) have emerged which gather content from numerous multimedia sources. A key challenge for such systems is to accurately predict what type of content each of its consumers prefers in a certain context, and adapt these predictions to the evolving consumers\u2019 preferences, contexts and content characteristics. We propose a novel, distributed, online multimedia content aggregation framework, which gathers content generated by multiple heterogeneous producers to fulfill its consumers\u2019 demand for content. Since both the multimedia content characteristics and the consumers\u2019 preferences and contexts are unknown, the optimal content aggregation strategy is unknown a priori. Our proposed content aggregation algorithm is able to learn online what content to gather and how to match content and users by exploiting similarities between consumer types. We prove bounds for our proposed learning algorithms that guarantee both the accuracy of the predictions as well as the learning speed. Importantly, our algorithms operate efficiently even when feedback from consumers is missing or content and preferences evolve over time. Illustrative results highlight the merits of the proposed content aggregation system in a variety of settings.", "creator": "LaTeX with hyperref package"}}}