{"id": "1502.02704", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2015", "title": "Learning Reductions that Really Work", "abstract": "We provide a summary of the mathematical and computational techniques that have enabled learning reductions to effectively address a wide class of problems, and show that this approach to solving machine learning problems can be broadly useful.", "histories": [["v1", "Mon, 9 Feb 2015 22:05:25 GMT  (60kb,D)", "http://arxiv.org/abs/1502.02704v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alina beygelzimer", "hal daum\\'e iii", "john langford", "paul mineiro"], "accepted": false, "id": "1502.02704"}, "pdf": {"name": "1502.02704.pdf", "metadata": {"source": "CRF", "title": "Learning Reductions that Really Work", "authors": ["Alina Beygelzimer", "John Langford"], "emails": ["beygel@yahoo-inc.com", "hal@umiacs.umd.edu", "jcl@microsoft.com", "pmineiro@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to move, to move and to move."}, {"heading": "1.1 Strawman one-against-all", "text": "A common approach to implementing a one-on-one classification for k classes is to create a script that processes the k times of the dataset, generates k intermediate datasets, and then executes a binary learning algorithm k times, creating k different model files. To evaluate the test time, another script then calls a test system for each example in a batch k times."}, {"heading": "1.2 Organization", "text": "Section 2 discusses the types of reduction theory that have been developed and found to be particularly useful. Section 3 discusses the programming interface that we have developed for learning reductions. Although programmability is a non-standard concern in machine learning applications, it is crucial to us. Creating a usable interface that is not computationally restrictive is critical to success. Section 4 discusses several problems for which the only known solution is derived via a reduction mechanism, and provides evidence that the reduction approach is useful for research.Section 5 shows experimental results for a particularly complex \"deep\" reduction for structured predictions, including comparisons with many other approaches. Together, these sections show that learning reductions are a useful approach to machine learning research."}, {"heading": "2 Reductions theory", "text": "There are several theories of natural learning reduction on a spectrum from simple to powerful, which we discuss in turn."}, {"heading": "2.1 Error reductions", "text": "When error is reduced, a low error rate on the problems created implies a low error rate on the original problem. If multiple underlying problems are created, we measure the average error rate over the underlying problems. Since it is easy to use a weight to indicate that one example is more important than the other, unequal averages are permissible. For example, a careful examination of the analysis shows how to improve the error transformation properties of the reduction: the first observation is that it helps to break bonds randomly rather than arbitrarily; the second observation is that a false negative only implies a 1 / k probability of making the correct multicalar forecast, whereas a false positive implies a 1 / 2 probability."}, {"heading": "2.2 Regret reductions", "text": "Here, a predictor's regret is the difference between his loss and the minimally achievable loss of the same problem. Unlike many other forms of learning theory, the minimum is above all predictions.A reduction that translates any optimal (i.e., no regret) regret into an optimal solution to the basic problems is called consistent. Consistency is a prerequisite for a good reduction. Unfortunately, error reductions are generally inconsistent. To see that a reduction is inconsistent against everything, we consider three classes with true conditional probabilities 12 \u2212 2\u043c, 1 4 + \u03b4, and 14 + \u03b4. The optimal binary prediction is always 0, resulting in a multicultural loss of 2 / 3. The corresponding multicultural regret is 16 \u2212 2\u043c, which is positive for any person. < 1 / 12.Strawman can be easily made consistent by reducing to quared loss regression instead of classification."}, {"heading": "2.3 Adaptive reductions", "text": "Adaptive reductions lead to learning problems that depend on solving other learning problems. In general, adaptivity is undesirable because conditionally defined problems are harder to form and easy to solve - they are less prone to parallelization and more prone to overadaptation due to propagation and multiplication of errors. However, in some cases, the most well-known reduction is adaptive. One such example is the logarithmic time multiclass prediction discussed in Section 4.4. All known unconditional log-time approaches lead to inconsistency in the presence of label noise [12]. The average regret of the base is still well defined as long as there is a partial sequence of basic problems, i.e. each base problem is defined in the face of a predictor for everything that occurs earlier in the sequence."}, {"heading": "2.4 Optimization oracle reductions", "text": "If the problem is to efficiently collect information, as in active learning (discussed in Section 4.3) or contextual bandit learning (discussed in Section 4.2), previous types of reductions are insufficient because they lack a way to quantify the progress made by reduction as examples of learning are used. Suppose we have access to an oracle that, when given a data set, provides a minimal loss predictive value from a class of H predictors with limited capacity. The form of the learning problem solved by the oracle may be binary classification, cost-sensitive classification, or some other reasonable primitive. Since many monitored learning algorithms resemble such an oracle, these reductions are immediately applicable. As the capacity of H is limited, tools from statistical learning theory can be used to argue about the regret of the predictor returned by the oracle."}, {"heading": "3 Interfaces for learning reductions", "text": "A good interface for learning reductions should be powerful, universally useful, easy to program, and eliminate systemic errors."}, {"heading": "3.1 The Wrong Way", "text": "The Strawman one-on-one approach illustrates the linkage of errors well. In particular, consider an implementation where an executable binary learning software treated as a black box is orchestrated so that it does the one-on-all approach via shell scripting. 1. Scripting implies a solution in a mixed language that is relatively difficult to maintain or understand. 2. The approach can easily fail on recursion. 3. For example, if another script calls the one-on-all training script several times, it is easy to imagine a problem where the stored models of one call override the stored models of another call. In a good programming approach, such errors should not be possible. 3. Transforming multi-class examples into binary examples is separated from transforming binary predictions into multiclass predictions, which increases the possibility of implementation bugs being significantly compared to an encoding or decoding approach."}, {"heading": "3.2 A Better Way", "text": "Our approach [40] eliminates all of the above interface errors, resulting in a system that is general, powerful and easily programmable, while bugs due to antimodal implementation. We need a basic learning algorithm that has two online interfaces: 1. Predict (example e, instance i) provides a prediction for the basic problem i and is guaranteed not to update the internal state. 2. Learn (example e, instance i) delivers the same result as Predict, but can update the internal state."}, {"heading": "4 Uniquely solved problems", "text": "Are reductions just a modular alternative that works in the same way as other direct methods? Or do they offer solutions to otherwise unsolved problems? To put it another way, are learning reductions a good first tool to develop solutions to new problems? We provide evidence that the answer is \"yes\" by examining a range of learning problems that have so far been effectively addressed only through reduction techniques. A common theme in all of these problems is computing efficiency. Often, there are well-known inefficient approaches to solving persistent problems. By taking a reduction approach, we can isolate optimization inefficiencies and eliminate other inefficiencies, often leading to exponential efficiency gains in practice."}, {"heading": "4.1 Efficient Contextual Bandit Learning", "text": "In contextual bandit learning, a learning algorithm must be applied to exploration data in order to learn a policy for acting in the world. A policy is functionally equivalent to a multi-class classifier that uses a trait vector x as input and produces an action a. Here, the term \"politics\" is used because the action is performed - perhaps a news story is displayed or a medical treatment is administered. Exploration data consists of quads (x, a, r, p) where x is a trait vector, a is an action, r is a reward, and p is the likelihood that the action a is on x.Efficient non-reduction techniques exist only in specific cases of this problem [35]. All known general adjustment techniques [10,28,56] use reduction approaches."}, {"heading": "4.2 Efficient Exploration in Contextual Bandits", "text": "In order to effectively conduct contextual bandit learning in the online environment, a good distribution of probabilities across actions must be created. There are approaches to this problem that are based on exponential weights [5], with a maturity that is linear in the size of the political sentence. Can this be done more efficiently? The answer is \"yes\" [1]. In particular, it is possible to reduce the problem to O (\u221a T) cases of cost-sensitive classification, each trained to find good but different solutions. This is an exponential improvement in computational complexity compared to the previous approach."}, {"heading": "4.3 Efficient Agnostic Selective Sampling", "text": "A learning algorithm that is able to choose which examples to label can be much more efficient than a learning algorithm that accepts passively randomly labeled examples. However, most such approaches collapse when strong assumptions about the nature of the problem are not metric. Canonical example is learning a threshold on the real line in the absence of any noise. A passive learning approach requires O (1 /) samples to achieve an error rate, while selective scanning requires only O (ln 1) samples by binary search. However, this exponential improvement is quite brittle - a small amount of label noise can provide an arbitrarily bad predictor. Inefficient approaches to address this brittleness state are statistically known [6, 30]. Is it possible to efficiently benefit from selective scanning in the agnostic environment? Two algorithms have been created [9,31] that generate active learning for important classification and practical learning on a binary basis."}, {"heading": "4.4 Logarithmic Time Classification", "text": "Most multi-level learning algorithms have linear time and space complexities in the number of classes in tests or training. Furthermore, many of these approaches tend to be inconsistent in the presence of noise - regardless of the amount of data available for label noise, predicting the wrong designation. It is easy to determine that logarithmic time classification can be possible because output only needs to be O (log k) bits to uniquely identify a class. Is it possible to perform a logarithmic time classification in a consistent and robust manner? Two reduction algorithms [12,16] provide a solution. The first shows that consistency and robustness can be achieved with a logarithmic time approach, while the second deals directly with learning the structure."}, {"heading": "5 Learning to search for structured prediction", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a region and in which it is a country."}, {"heading": "6 Summary and future directions", "text": "In working with learning reductions for several years, the greatest benefit seems to be associated with modularity, deeper reductions and computational efficiency. Modularity means that the additional code required for multiclass classification (for example) is small compared to the code required for binary classification. It also simplifies the use of a learning system, because (for example) learning rates apply to all learning algorithms. Modularity is1We have also tried to give CRF SGD the features calculated by POS and NERS. At POS, its accuracy has improved to 96.5 - on par with finding one's own skills - at essentially the same speed. On the other hand, its performance has declined."}], "references": [{"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["Alekh Agarwal", "Daniel Hsu", "Satyen Kale", "John Langford", "Lihong Li", "Robert E. Schapire"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Surrogate regret bounds for bipartite ranking via strongly proper losses", "author": ["Shivani Agarwal"], "venue": "Journal of Machine Learning Research", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Mohri,Preference-based learning to rank", "author": ["Nir Ailon", "Mehryar"], "venue": "Machine Learning Journal,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Reducing multiclass to binary: A unifying approach for margin classifiers", "author": ["Erin Allwein", "Robert Schapire", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "The non-stochastic multi-armed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM Journal on Computing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Convexity, classification and risk bounds", "author": ["Peter Bartlett", "Michael Jordan", "Jon McAuliffe"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Error limiting reductions between classification tasks", "author": ["Alina Beygelzimer", "Varsha Dani", "Tom Hayes", "John Langford", "Bianca Zadrozny"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "The Offset Tree for Learning with Partial Labels", "author": ["Alina Beygelzimer", "John Langford"], "venue": "KDD", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Multi-core structural SVM training", "author": ["Kai-Wei Chang", "Vivek Srikumar", "Dan Roth"], "venue": "In Proceedings of the European Conference on Machine Learning (ECML),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Incremental parsing with the perceptron algorithm", "author": ["Michael Collins", "Brian Roark"], "venue": "In Proceedings of the Conference of the Association for Computational Linguistics (ACL),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Ultraconservative online algorithms for multiclass problems", "author": ["Koby Crammer", "Yoram Singer"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Search-based structured prediction", "author": ["Hal Daum\u00e9 III", "John Langford", "Daniel Marcu"], "venue": "Machine Learning Journal,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Efficient programmable learning to search", "author": ["Hal Daum\u00e9 III", "John Langford", "St\u00e9phane Ross"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Learning as search optimization: Approximate large margin methods for structured prediction", "author": ["Hal Daum\u00e9 III", "Daniel Marcu"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Solving multiclass learning problems via error-correcting output codes", "author": ["Tom Dietterich", "G. Bakiri"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1995}, {"title": "Output space search for structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "HC-Search: A learning framework for search-based structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "On the Consistency of Ranking Algorithms", "author": ["John Duchi", "Lester Mackey", "Michael I. Jordan"], "venue": "International Conference on Machine Learning (ICML)", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Multiclass learning, boosting, and error-correcting codes", "author": ["Venkat Guruswami", "Amit Sahai"], "venue": "In Proceedings of the 12th Annual Conference on Computational Learning Theory (COLT),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "Algorithms for Active Learning, Ph.D", "author": ["Daniel Hsu"], "venue": "Thesis, University of California, San Diego,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "Structured perceptron with inexact search", "author": ["Liang Huang", "Suphan Fayong", "Yang Guo"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "The Error Coding Method and PICTs", "author": ["Gareth James", "Trevor Hastie"], "venue": "Journal of Computational and Graphical Statistics", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1998}, {"title": "Cutting-plane training of structural SVMs", "author": ["Thorsten Joachims", "Thomas Finley", "Chun-Nam Yu"], "venue": "Machine Learning Journal,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Efficient bandit algorithms for online multiclass prediction", "author": ["Sham M Kakade", "Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Online importance weight aware updates", "author": ["Nikos Karampatziakis", "John Langford"], "venue": "In UAI, pages 392\u2013399,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando Pereira"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2001}, {"title": "Sensitive error correcting output codes", "author": ["John Langford", "Alina Beygelzimer"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2005}, {"title": "Vowpal wabbit online learning project", "author": ["John Langford", "Lihong Li", "Alex Strehl"], "venue": "Technical report,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2007}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann Lecun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1998}, {"title": "On the Statistical Consistency of Plug-in Classifiers for Non-decomposable Performance Measures", "author": ["Harikrishna Narasimhany", "Rohit Vaishy", "Shivani Agarwal"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Updating Quasi-Newton Matrices with Limited Storage", "author": ["Jorge Nocedal"], "venue": "Mathematics of Computation", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1980}, {"title": "Boosting structured prediction for imitation learning", "author": ["Nathan Ratliff", "David Bradley", "J. Andrew Bagnell", "Joel Chestnutt"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2007}, {"title": "A comparison of algorithms for maximum entropy parameter estimation", "author": ["Robert Malouf"], "venue": "In Proceedings of CoNLL,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2002}, {"title": "Large margin online learning algorithms for scalable structured classification", "author": ["Ryan McDonald", "Koby Crammer", "Fernando Pereira"], "venue": "In NIPS Workshop on Learning with Structured Outputs,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2004}, {"title": "On the consistency of output code based learning algorithms for multiclass learning problems", "author": ["Harish Ramaswamy", "Balaji S.B", "Shivani Agarwal", "Robert Williamson"], "venue": "In Proceedings of the 27th Annual Conference on Learning Theory (COLT),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}, {"title": "A reduction of imitation learning and structured prediction to no-regret online learning", "author": ["Stephane Ross", "Geoff J. Gordon", "J. Andrew Bagnell"], "venue": "In Proceedings of the Workshop on Artificial Intelligence and Statistics (AI-Stats),", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2011}, {"title": "Boosting: Foundations and Algorithms", "author": ["Robert E. Schapire", "Yoav Freund"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "A reduction from apprenticeship learning to classification", "author": ["Umar Syed", "Robert E. Schapire"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2011}, {"title": "Max-margin Markov networks", "author": ["Ben Taskar", "Carlos Guestrin", "Daphne Koller"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2003}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["Ioannis Tsochantaridis", "Thomas Hofmann", "Thorsten Joachims", "Yasmine Altun"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2004}, {"title": "On learning linear ranking functions for beam search", "author": ["Yuehua Xu", "Alan Fern"], "venue": "In ICML,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2007}, {"title": "Discriminative learning of beam-search heuristics for planning", "author": ["Yuehua Xu", "Alan Fern", "Sung Wook Yoon"], "venue": "In IJCAI,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2007}, {"title": "Surrogate regret bounds for proper losses", "author": ["Mark Reid", "Robert Williamson"], "venue": "In ICML,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2009}, {"title": "Policy mining: Learning decision policies from fixed sets of data, Ph.D", "author": ["Bianca Zadrozny"], "venue": "Thesis, University of California, San Diego,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2003}], "referenceMentions": [{"referenceID": 3, "context": "For example, in the strawman one-against-all reduction, an average binary classification error rate of implies a multiclass error rate of at most (k \u2212 1) (see [4, 29]).", "startOffset": 159, "endOffset": 166}, {"referenceID": 20, "context": "For example, in the strawman one-against-all reduction, an average binary classification error rate of implies a multiclass error rate of at most (k \u2212 1) (see [4, 29]).", "startOffset": 159, "endOffset": 166}, {"referenceID": 15, "context": "Another example of an error reduction for multiclass classification is based on error-correcting output codes [23,29].", "startOffset": 110, "endOffset": 117}, {"referenceID": 20, "context": "Another example of an error reduction for multiclass classification is based on error-correcting output codes [23,29].", "startOffset": 110, "endOffset": 117}, {"referenceID": 30, "context": "Figure 2 illustrates the empirical superiority of reducing to regression rather than binary classification for the Mnist [41] data set.", "startOffset": 121, "endOffset": 125}, {"referenceID": 23, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 86, "endOffset": 93}, {"referenceID": 36, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 86, "endOffset": 93}, {"referenceID": 28, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 124, "endOffset": 132}, {"referenceID": 1, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 146, "endOffset": 152}, {"referenceID": 2, "context": "There are many known regret reductions for such problems as multiclass classification [33,47], costsensitive classification [12, 39], and ranking [2, 3].", "startOffset": 146, "endOffset": 152}, {"referenceID": 1, "context": "A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55].", "startOffset": 90, "endOffset": 100}, {"referenceID": 5, "context": "A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55].", "startOffset": 90, "endOffset": 100}, {"referenceID": 44, "context": "A surrogate regret bound quantifies the resulting regret in terms of the surrogate regret [2, 7, 55].", "startOffset": 90, "endOffset": 100}, {"referenceID": 19, "context": "In some cases, commonly used surrogate losses actually turn out to be inconsistent [27].", "startOffset": 83, "endOffset": 87}, {"referenceID": 38, "context": "Boosting [49] can be thought of as an adaptive reduction for converting any weak learner into a strong learner.", "startOffset": 9, "endOffset": 13}, {"referenceID": 38, "context": "Although linear separability with a positive margin implies weak learnability [49], linear separability is still a strong assumption.", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "Cleverly using this oracle can provide solutions to learning problems which are exponentially more efficient than simpler more explicit algorithms for choosing which information to gether [1, 9].", "startOffset": 188, "endOffset": 194}, {"referenceID": 29, "context": "2 A Better Way Our approach [40] eliminates all of the above interfacing bugs, resulting in a system which is general, performant, and easily programmed while eliminating bugs due to antimodular implementation.", "startOffset": 28, "endOffset": 32}, {"referenceID": 32, "context": "The interface certainly favors online base learning algorithms, but we have an implementation of LBFGS [43] that functions as an effective (if typically slow) base learning algorithm.", "startOffset": 103, "endOffset": 107}, {"referenceID": 25, "context": "Efficient non-reduction techniques exist only for special cases of this problem [35].", "startOffset": 80, "endOffset": 84}, {"referenceID": 7, "context": "All known techniques for the general setting [10,28,56] use reduction approaches.", "startOffset": 45, "endOffset": 55}, {"referenceID": 45, "context": "All known techniques for the general setting [10,28,56] use reduction approaches.", "startOffset": 45, "endOffset": 55}, {"referenceID": 4, "context": "There are approaches to this problem based on exponential weights [5] with a running time linear in the size of the policy set.", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "Can this be done in more efficiently? The answer turns out to be \u201cyes\u201d [1].", "startOffset": 71, "endOffset": 74}, {"referenceID": 21, "context": "Is it possible to benefit from selective sampling in the agnostic setting efficiently? Two algorithms have been created [9,31] which reduce active learning for binary classification to importance-weighted binary classification, creating practical algorithms.", "startOffset": 120, "endOffset": 126}, {"referenceID": 10, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 12, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 14, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 16, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 17, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 22, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 33, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 37, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 39, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 42, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 43, "context": ", [18,20,22,24,25,32,44,48,50,53,54]).", "startOffset": 2, "endOffset": 36}, {"referenceID": 12, "context": "We implemented a learning to search algorithm (based on [20, 48]) that operates via reduction to cost sensitive classification which is then further reduced to regression.", "startOffset": 56, "endOffset": 64}, {"referenceID": 37, "context": "We implemented a learning to search algorithm (based on [20, 48]) that operates via reduction to cost sensitive classification which is then further reduced to regression.", "startOffset": 56, "endOffset": 64}, {"referenceID": 13, "context": "This algorithm was then extensively tested against a suite of many structured learning algorithms which we report here (see [21] for full details).", "startOffset": 124, "endOffset": 128}, {"referenceID": 27, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 67, "endOffset": 71}, {"referenceID": 34, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 158, "endOffset": 165}, {"referenceID": 35, "context": "CRF++ The popular CRF++ toolkit [37] for conditional random fields [38], which implements both L-BFGS optimization for CRFs [45] as well as \u201cstructured MIRA\u201d [19,46].", "startOffset": 158, "endOffset": 165}, {"referenceID": 9, "context": "Structured Perceptron An implementation of the structured perceptron [17] due to [15].", "startOffset": 69, "endOffset": 73}, {"referenceID": 8, "context": "Structured Perceptron An implementation of the structured perceptron [17] due to [15].", "startOffset": 81, "endOffset": 85}, {"referenceID": 24, "context": "Structured SVM The cutting-plane implementation [34] of the structured SVMs [52] for \u201cHMM\u201d problems.", "startOffset": 48, "endOffset": 52}, {"referenceID": 41, "context": "Structured SVM The cutting-plane implementation [34] of the structured SVMs [52] for \u201cHMM\u201d problems.", "startOffset": 76, "endOffset": 80}, {"referenceID": 6, "context": "VW Search Our approach is implemented in the Vowpal Wabbit toolkit on top of a cost-sensitive classifier [8] that reduces to regression trained with an online rule incorporating AdaGrad [26],", "startOffset": 105, "endOffset": 108}, {"referenceID": 18, "context": "VW Search Our approach is implemented in the Vowpal Wabbit toolkit on top of a cost-sensitive classifier [8] that reduces to regression trained with an online rule incorporating AdaGrad [26],", "startOffset": 186, "endOffset": 190}, {"referenceID": 6, "context": "VW Classification An unstructured baseline that predicts each label independently, using oneagainst-all multiclass classification [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": "This is well illustrated for the learning to search results discussed in section 5, but has been observed with contextual bandit learning as well [1].", "startOffset": 146, "endOffset": 149}], "year": 2015, "abstractText": "We provide a summary of the mathematical and computational techniques that have enabled learning reductions to effectively address a wide class of problems, and show that this approach to solving machine learning problems can be broadly useful.", "creator": "LaTeX with hyperref package"}}}