{"id": "1502.03409", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2015", "title": "Large-Scale Deep Learning on the YFCC100M Dataset", "abstract": "We present a work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date. Recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers. We train our three-layer deep neural network on the Yahoo! Flickr Creative Commons 100M dataset. The dataset comprises approximately 99.2 million images and 800,000 user-created videos from Yahoo's Flickr image and video sharing platform. Training of our network takes eight days on 98 GPU nodes at the High Performance Computing Center at Lawrence Livermore National Laboratory. Encouraging preliminary results and future research directions are presented and discussed.", "histories": [["v1", "Wed, 11 Feb 2015 19:24:36 GMT  (2202kb,D)", "http://arxiv.org/abs/1502.03409v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["karl ni", "roger pearce", "kofi boakye", "brian van essen", "damian borth", "barry chen", "eric wang"], "accepted": false, "id": "1502.03409"}, "pdf": {"name": "1502.03409.pdf", "metadata": {"source": "CRF", "title": "LARGE-SCALE DEEP LEARNING ON THE YFCC100M DATASET", "authors": ["Karl Ni", "Roger Pearce", "Eric Wang", "Kofi Boakye", "Brian Van Essen", "Damian Borth", "Barry Chen", "Lawrence Livernmore"], "emails": [], "sections": [{"heading": null, "text": "Index Terms - Deep Learning, Autoencoder, High Performance Computing"}, {"heading": "1. INTRODUCTION", "text": "In this context, it should be noted that this project is a project, which is a project that is, first and foremost, a project that responds to the needs of people in developing countries."}, {"heading": "2. OVERVIEW OF THE YFCC100M DATASET", "text": "In late June 2014, Yahoo! published the Yahoo! Flickr Creative Commons (YFCC100M) dataset, which consists of 100 million Flickr-uploaded images and videos (99,206,564 images and 793,436 videos) along with their corresponding metadata, including title, description, camera type, tags and geotags, if available. All data is licensed by Creative Commons and is free pro-ar Xiv: 150 2.03 409v 1 [cs.L G] February 11, 2015vided to scientists for the promotion of multimedia research 1. In addition to the raw images, videos and metadata, Yahoo! in collaboration with ICSI and LLNL will use standard computer vision and audio capabilities using LLNL's Supercomputing Resources.Wang et al. [13] have used the data from YFCC100M to form systems that link images with more natural annotations found in captions used."}, {"heading": "3. ANALYSIS WITH LARGE SCALE NEURAL NETWORKS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Network Architecture", "text": "In fact, most of them are able to survive by themselves if they do not put themselves in a position to survive by themselves; most of them are not able to survive by themselves, and most of them are not able to survive by themselves."}, {"heading": "3.2. HPC Architecture", "text": "The edge cluster consists of 206 nodes with 12 core Intel Xeon EP X5660 at 2.8 GHz. Each node has 96 GB of DRAM and a Tesla M2050 (Fermi) NVIDIA GPU with 3 GB GDDR5. The training algorithm runs in parallel to the model as described in [2], with the nodes and GPUs processing each mini-batch across the system and distributing the model across the GPUs. MPI communicated via Mellanox QDR infiniband cards. GPU accelerators were used with CUDA 5.5 and MPI direct communication, and the operating system was a 2.6.32 kernel RHEL 6 distributed across the PU derivatives. The data set was stored in a Lustre file system with a peak bandwidth of 10 GB / s. Each mini-batch was stored into a multiple PHEL-6 memory using an occupied RHU memory structure and then transferred to a mini-series."}, {"heading": "4. PRELIMINARY RESULTS", "text": "We trained the network using all images from the YFCC100M dataset, pre-processed the images as in [2] and then scaled to 300 x 300 pixels by centering, then scaled to 300 pixels and finally cropped off. After training all three layers, we propagated 2 million images through the network to obtain activation values for visualization. Note that the test set in this document is significantly louder than the benchmark \"Faces In the Wild\" [16] and \"ImageNet\" [17] datasets taken into account in previous work such as [3]. In Fig. 5, we show the top 5 stimuli for some neurons. We observe that our network is capable of learning significant structures, identifying buildings, airplanes, text, cityscapes, and tower-like buildings."}, {"heading": "5. SUMMARY AND FUTURE WORK", "text": "The results discussed in this paper provide a snapshot of ongoing work at the Lawrence Livermore National Laboratory, which focuses primarily on expanding deep neural networks, which offer researchers enormous potential in both supervised and unsupervised computer vision tasks, from object detection and classification to unsupervised functioning. To date, we have seen highly encouraging results from the formation of our large three-layered neural parameter network on the YFCC100M dataset in an unsupervised manner. The results suggest that the network is capable of learning highly complex concepts such as city views, aircraft, buildings and text, all without labels or other instruction. That this structure is all the more remarkable given the noisiness of our test set (randomly taken from the YFCC100M dataset itself).Future work on our networks will focus on two main scales of learning (the enhancement of our high-level communication):"}, {"heading": "6. ACKNOWLEDGMENTS", "text": "We thank Adam Coates, Brody Huval and Andrew Ng for providing their COTS HPC Deep Learning software and helpful advice. This work was carried out under the auspices of the US Department of Energy by Lawrence Livermore National Laboratory under contract DE-AC52-07NA27344."}, {"heading": "7. REFERENCES", "text": "In fact, most of them are able to survive on their own if they are not able to survive on their own; most of them are able to survive on their own."}], "references": [{"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "Advances in neural information processing systems, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep learning with cots hpc", "author": ["A. Coates", "B. Huval", "T. Wang", "D.J. Wu", "A.Y. Ng", "B. Catanzaro."], "venue": "International Conference on Machine Learning, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Q.V. Le", "M. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G.S. Corrado", "J. Dean", "A.Y. Ng"], "venue": "International Conference on Machine Learning, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean."], "venue": "Proceedings of Workshop at ICLR, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Exploring convolutional neural network structures and optimization techniques for speech recognition", "author": ["O. Abdel-Hamid", "L. Deng", "D. Yu"], "venue": "Interspeech 2013, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep neural networks for acoustic modeling in speech recognition", "author": ["G. Hinton", "L. Deng", "D. Yu", "A.-R. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath", "G. Dahl", "B. Kingsbury"], "venue": "IEEE Signal Processing Magazine, vol. 29, no. 6, pp. 82\u201397, November 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Connectionist Speech Recognition: A Hybrid Approach", "author": ["H. Bourlard", "N. Morgan"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1993}, {"title": "Convolutional neural network committees for handwritten character classification", "author": ["D. Claudiu Ciresan", "U. Meier", "L.M. Gambardella", "J. Schmidhuber"], "venue": "International Conference on Document Analysis and Recognition, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Artificial neural networks as a classification method in the behavioural sciences", "author": ["D. Reby", "S. Lek", "I. Dimopoulos", "J. Joachim", "J. Lauga", "S. Aulagnier"], "venue": "Behavioural Processes, vol. 40, pp. 3543, 1997.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Large-scale object recognition with cuda-accelerated hierarchical neural networks", "author": ["R Uetz", "S. Behnke"], "venue": "IEEE International Conference on Intelligent Computing and Intelligent Systems, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Spatially coherent latent topic model for concurrent object segmentation and classification", "author": ["L. Cao", "L. Fei-Fei"], "venue": "Proceedings of International Conference on Computer vision, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Zero Shot Learning Through Cross-Modal Transfer", "author": ["R. Socher", "M. Ganjoo", "C.D. Manning", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems 26. 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "A poodle or a dog? Evaluating automatic image annotation using human descriptions at different levels of granularity", "author": ["J.K. Wang", "F. Yan", "A. Aker", "R. Gaizauskas"], "venue": "Proceedings of the Workshop on Vision and Language, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "im2gps: estimating geographic information from a single image", "author": ["James Hays", "Alexei A. Efros"], "venue": "Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "The Placing Task: A Large Scale Geo-Estimation Challenge for Social-Media Videos and Images", "author": ["J. Choi", "B. Thomee", "G. Friedland", "L. Cao", "K. Ni", "D. Borth", "B. Elizalde", "L. Gottlieb", "C. Carrano", "R. Pearce", "D. Poland"], "venue": "3rd ACM Multimedia Workshop On GeoTagging and Its Applications in Multimedia.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 0}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": ".", "citeRegEx": "16", "shortCiteRegEx": null, "year": 0}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L. Li", "K. Li", "L. Fei-fei"], "venue": "In CVPR, 2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "The field of deep learning via stacked neural networks has received renewed interest in the last decade [1, 2, 3].", "startOffset": 104, "endOffset": 113}, {"referenceID": 1, "context": "The field of deep learning via stacked neural networks has received renewed interest in the last decade [1, 2, 3].", "startOffset": 104, "endOffset": 113}, {"referenceID": 2, "context": "The field of deep learning via stacked neural networks has received renewed interest in the last decade [1, 2, 3].", "startOffset": 104, "endOffset": 113}, {"referenceID": 3, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 124, "endOffset": 133}, {"referenceID": 5, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 124, "endOffset": 133}, {"referenceID": 6, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 124, "endOffset": 133}, {"referenceID": 7, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 164, "endOffset": 170}, {"referenceID": 8, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 164, "endOffset": 170}, {"referenceID": 0, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 253, "endOffset": 262}, {"referenceID": 1, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 253, "endOffset": 262}, {"referenceID": 2, "context": "Neural networks have been shown to perform well in a wide variety of tasks, including text analysis [4], speech recognition [5, 6, 7], various classification tasks [8, 9], and most notably unsupervised and supervised feature learning on natural imagery [1, 2, 3].", "startOffset": 253, "endOffset": 262}, {"referenceID": 9, "context": "Deep neural networks applied to natural images have demonstrated state-of-the-art performance in supervised object recognition tasks [10, 1] as well as unsupervised neural networks [2, 3].", "startOffset": 133, "endOffset": 140}, {"referenceID": 0, "context": "Deep neural networks applied to natural images have demonstrated state-of-the-art performance in supervised object recognition tasks [10, 1] as well as unsupervised neural networks [2, 3].", "startOffset": 133, "endOffset": 140}, {"referenceID": 1, "context": "Deep neural networks applied to natural images have demonstrated state-of-the-art performance in supervised object recognition tasks [10, 1] as well as unsupervised neural networks [2, 3].", "startOffset": 181, "endOffset": 187}, {"referenceID": 2, "context": "Deep neural networks applied to natural images have demonstrated state-of-the-art performance in supervised object recognition tasks [10, 1] as well as unsupervised neural networks [2, 3].", "startOffset": 181, "endOffset": 187}, {"referenceID": 2, "context": "Motivated by this, [3] explored the application of deep neural networks in unsupervised deep learning and discovered that sufficiently large deep networks are capable of learning highly complex concept level features at the top level without labels.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "Spurred by this advancement, [2] set out to construct very large networks on the order of 10 to 10 parameters.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "[2] employed a high degree of model parallelism and was able to process 10 million YouTube thumbnails in a few days processing time on a medium sized cluster.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "via topic modeling [11] or natural language processing algorithms [12]).", "startOffset": 19, "endOffset": 23}, {"referenceID": 11, "context": "via topic modeling [11] or natural language processing algorithms [12]).", "startOffset": 66, "endOffset": 70}, {"referenceID": 1, "context": "In collaboration with the authors of [2], we have scaled a similar model and architecture to over 15 billion parameters on the Lawrence Livermore National Laboratory\u2019s (LLNL) Edge High Performance Computing (HPC) system.", "startOffset": 37, "endOffset": 40}, {"referenceID": 1, "context": "For example, the significantly greater number of GPUs and compute nodes used in our system versus [2] creates communication issues in MPI.", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "Finally, as in [2], data throughput presents a bottleneck to model training.", "startOffset": 15, "endOffset": 18}, {"referenceID": 12, "context": "[13] have used YFCC100M data to build systems that associate images with more natural annotations like those found in user-generated captions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Others are interested in using the YFCC100M imagery and audio to geolocate where the photo or video was taken [14].", "startOffset": 110, "endOffset": 114}, {"referenceID": 14, "context": "In fact, the 2014 MediaEval Placing Task is using YFCC100M as the source of benchmark data [15].", "startOffset": 91, "endOffset": 95}, {"referenceID": 2, "context": "We are interested in using YFCC100M as our sandbox dataset for learning image features using massive unsupervised neural networks, repeating the experiment by [3] on an order of magnitude more data and neural network parameters.", "startOffset": 159, "endOffset": 162}, {"referenceID": 2, "context": "In particular, we want to see what other \u201cgrandmother neurons\u201d [3] our network would automatically learn from YFCC100M.", "startOffset": 63, "endOffset": 66}, {"referenceID": 1, "context": "where as in [2],W is a weighting matrix, \u03b1 is a scaling value and x are the data points at the beginning of each layer.", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "Unlike [2], we do not presently include a pooling layer, as we believe the scale of the network and training data allows a similar translational invariance to be automatically learned.", "startOffset": 7, "endOffset": 10}, {"referenceID": 1, "context": "The training algorithm is model parallel as described in [2], with the nodes and GPUs processing each mini-batch across the system and distributing the model across the GPUs.", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "Images were preprocessed as in [2], and subsequently resized to 300 x 300 pixels by first centering, then scaling the smallest dimension to 300 pixels, and finally cropping.", "startOffset": 31, "endOffset": 34}, {"referenceID": 15, "context": "Note that in this paper, the test set is significantly noisier than the benchmark Labeled Faces In the Wild [16] and ImageNet [17] datasets considered in previous works such as [3].", "startOffset": 108, "endOffset": 112}, {"referenceID": 16, "context": "Note that in this paper, the test set is significantly noisier than the benchmark Labeled Faces In the Wild [16] and ImageNet [17] datasets considered in previous works such as [3].", "startOffset": 126, "endOffset": 130}, {"referenceID": 2, "context": "Note that in this paper, the test set is significantly noisier than the benchmark Labeled Faces In the Wild [16] and ImageNet [17] datasets considered in previous works such as [3].", "startOffset": 177, "endOffset": 180}, {"referenceID": 0, "context": "As was demonstrated in [1], network architecture has a significant impact on the performance of deep networks.", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "While the networks described in [3] were able to learn complex features in just three layers, our results suggest that extremely large datasets such as the YFCC100M can support (and possibly benefit from) deeper networks with improved high-level concept learning.", "startOffset": 32, "endOffset": 35}], "year": 2015, "abstractText": "We present a work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date. Recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers. We train our three-layer deep neural network on the Yahoo! Flickr Creative Commons 100M dataset. The dataset comprises approximately 99.2 million images and 800, 000 user-created videos from Yahoo\u2019s Flickr image and video sharing platform. Training of our network takes eight days on 98 GPU nodes at the High Performance Computing Center at Lawrence Livermore National Laboratory. Encouraging preliminary results and future research directions are presented and discussed.", "creator": "LaTeX with hyperref package"}}}