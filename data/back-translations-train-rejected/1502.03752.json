{"id": "1502.03752", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Feb-2015", "title": "A new hybrid metric for verifying parallel corpora of Arabic-English", "abstract": "This paper discusses a new metric that has been applied to verify the quality in translation between sentence pairs in parallel corpora of Arabic-English. This metric combines two techniques, one based on sentence length and the other based on compression code length. Experiments on sample test parallel Arabic-English corpora indicate the combination of these two techniques improves accuracy of the identification of satisfactory and unsatisfactory sentence pairs compared to sentence length and compression code length alone. The new method proposed in this research is effective at filtering noise and reducing mis-translations resulting in greatly improved quality.", "histories": [["v1", "Thu, 12 Feb 2015 17:49:45 GMT  (2371kb)", "http://arxiv.org/abs/1502.03752v1", "in CCSEA-2015"]], "COMMENTS": "in CCSEA-2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["saad alkahtani", "wei liu", "william j teahan"], "accepted": false, "id": "1502.03752"}, "pdf": {"name": "1502.03752.pdf", "metadata": {"source": "CRF", "title": "A NEW HYBRID METRIC FOR VERIFYING PARALLEL", "authors": ["Saad Alkahtani", "Wei Liu", "William J. Teahan"], "emails": ["s.alkahtani@bangor.ac.uk", "w.liu@bangor.ac.uk", "w.j.teahan@bangor.ac.uk"], "sections": [{"heading": null, "text": "It comes to a process in which it comes to a process in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, in which it comes to a process, and in which it comes to a process, and in which it comes to a process, in which it comes to a process, in which it comes to a process, and in which it comes to a process, and in which it comes to a process, in which it comes to a process, and in which it comes to a process, in which it comes to a process, and in which it comes to a process, and in which it comes to a process, in which it comes to a process, and in which it comes to a process, and in which it comes to a process in which"}, {"heading": "3.1. PPM Compression Code Length Metric", "text": "The prediction of Partial Matching (PPM) compression scheme, first proposed by Cleary and Witten in 1984 [4], predicts the next symbol or character from a fixed order context. Context models are adaptively updated as the text is processed sequentially using an online adaptive process. Moffat developed the text for both sides. [20] The main difference between PPMC and PPMD (and other variants PPPMA and PPMB) is the calculation of Howard's PPMD variant in 1993 based on the PPMC variant developed by Moffat."}, {"heading": "3.2. Code Length Ratio Distance Metric for Matching Sentences", "text": "The term code length refers to the size (in bytes) of the compressed output file generated by the PPM compression algorithm. When using PPM to compress Arabic or English text, the code length is a measure of the transverse entropy of the text, that is, the average size (in bytes) per character for the compressed output string. Theoretically, the transverse entropy is estimated as follows: = 1 log!,,,,!!! where the average number of bits to encode the text is and is the order of the model (e.g. 5 for the models used in this paper). Note that the length of the compression code, the number of bits required to encode the text string, is lossless, so that it can be expressed clearly,,,,, and, as, and, as, simply as,,,,, and, and, as, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and"}, {"heading": "3.3. Sentence Length Ratio Distance Metrics for Matching Sentences", "text": "Automatically generated bilingual corpora often have a large number of loud sentence pairs. Therefore, researchers have developed various methods to filter out loud sentences from parallel corpora [10]. However, for our experiments discussed in Section 4, we have found a new technique based on a combination of the compression code Length Ratio (CR) described above and the standard Sentence Length Ratio (SLR) described by M\u00fajdricza-Maydt [16] to achieve a high-quality corpus.The Sentence Length Ratio (SLR) for a pair of Arabic and English translation sentences can be calculated as follows:!,!!"}, {"heading": "4.1. Developing the Test Corpora", "text": "For our experimental evaluation, two parallel Arabic-English test corpus were created: A large corpus (Corpus A) was initially created containing fifty-eight million words collected by two online sources, Al Hayat (http: / / www.alhayat.com) and OPUS (http: / / opus.lingfil.uu.se) with the permission of the data holders. OPUS is an open-source parallel corpus that provides a large collection of translated texts from the Internet. All online data was collected automatically and as a result, the original texts are not of high quality. However, the main purpose of our research is to develop a more reliable collection based on this and other data with low-quality translations filtered out using our sentence comparison metrics. A second, much smaller test corpus (Corpus B) was created containing 10,000 translations judged as satisfactory and 2,000 translations as unsatisfactory for our basic and unsatisfactory test data."}, {"heading": "4.2. Compression Experiments", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "4.3. Analysing the quality of translations in the test corpora", "text": "This year it has come to the point that it has never come as far as this year."}], "references": [{"title": "Adaptive Models of Arabic Text", "author": ["K. Alhawiti"], "venue": "PhD Dissertation,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Estimating and Comparing Entropy across Written Natural Languages Using PPM Compression", "author": ["H. Behr F", "V. Fossum", "M. Mitzenmacher", "D. Xiao"], "venue": "Proceedings of Data Compression Conference,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "The Mathematics of Machine Translation: Parameter Estimation", "author": ["P. Brown", "S. Della Pieta", "V. Della Pieta", "R. Mercer"], "venue": "Computational Linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "Data Compression Using Adaptive Coding and Partial String Matching", "author": ["J.G. Cleary", "I.H. Witten"], "venue": "IEEE Transactions on Communications,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1984}, {"title": "Assisting Requirement Formalization by Means of Natural Language Translation", "author": ["A. Fantechi", "S. Gnesi", "M. Carenini", "M. Vanocchi", "P. Moreschini"], "venue": "Formal Methods in System Design,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1994}, {"title": "A Program for Aligning Sentences in Bilingual Corpora", "author": ["W.A. Gale"], "venue": "Annual Meeting,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1993}, {"title": "High-performance Bilingual Text Alignment Using Statistical and Dictionary Information", "author": ["M. Haruno", "T. Yamazaki"], "venue": "Proceedings of the 34th Annual Meeting of Association for Computational Linguistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1996}, {"title": "The Encyclopaedia of Languages and Linguistics", "author": ["W.J. Hutchins"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Text-translation Alignment", "author": ["M. Kay", "M. R\u00f6scheisen"], "venue": "Computational Linguistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "Automatic Filtering of Bilingual Corpora for Statistical Machine Translation", "author": ["S. Khadivi", "H. Ney"], "venue": "Natural Language Processing and Information Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Improving English-Russian Sentence Alignment through POS Tagging and Damerau-Levenshtein Distance", "author": ["A. Kutuzov"], "venue": "Association for Computational Linguistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Experiments with Compression-based Methods for English-Chinese Sentence Alignment", "author": ["W. Liu", "Z. Chang", "W. Teahan"], "venue": "2nd International Conference on Statistical Language and Speech Processing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Models of Translational Equivalence among Words", "author": ["I.D. Melamed"], "venue": "Computational Linguistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2000}, {"title": "Using Twitter to Collect a Multi-Dialectal Corpus of Arabic", "author": ["H. Mubarak", "K. Darwish", "N. Adly"], "venue": "EMNLP 2014 Workshop on Arabic Natural Language Processing", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "High-Precision Sentence Alignment by Bootstrapping from Wood Standard Annotations", "author": ["\u00c9. M\u00fajdricza-Maydt", "H. K\u00f6rkel-Qu", "S. Riezler", "S. Pad\u00f3"], "venue": "The Prague Bulletin of Mathematical Linguistics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Automatic Alignment in Corpora", "author": ["H. Papageorgiou", "L. Cranias", "S. Piperidis"], "venue": "Proceedings of 32nd Annual Meeting of Association of Computational Linguistic,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}, {"title": "A Mathematical Theory of Communication", "author": ["C.E. Shannon"], "venue": "Bell System Technical Journal,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1948}, {"title": "Using Cognates to Align Sentences in Bilingual Corpora", "author": ["M. Simard", "G.F. Foster", "P. Isabelle"], "venue": "Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1992}, {"title": "Modelling English Text", "author": ["W. Teahan"], "venue": "PhD Dissertation, University of Waikato,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Aligning a Parallel English-Chinese Corpus Statistically with Lexical Criteria", "author": ["D. Wu"], "venue": "Annual Meeting,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1994}, {"title": "Revisiting Sentence Alignment Algorithms for Alignment Visualization and Evaluation", "author": ["Q. Yu", "A. Max", "F. Yvon"], "venue": "LREC Workshop,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "The history of translation between natural languages can be traced back to the beginning of human culture, with its major mission being to expand the informativeness of one language, decrease the misunderstanding in dialogue, and even contribute to the growth of cultures [5].", "startOffset": 272, "endOffset": 275}, {"referenceID": 7, "context": "Early pioneering machine translation systems were developed in the 1950s and 1960s [8].", "startOffset": 83, "endOffset": 86}, {"referenceID": 13, "context": "Arabic is the primary language for over 380 million native Arabic speakers worldwide [15].", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "for a parallel bilingual corpus [13].", "startOffset": 32, "endOffset": 36}, {"referenceID": 5, "context": "Gale and Church [6] aligned parallel sentences in English-French and English-German corpora based on a sentence length metric that required calculating the character length of all sentences.", "startOffset": 16, "endOffset": 19}, {"referenceID": 5, "context": "Gale and Church\u2019s [6] overall accuracies were 97% for English-German and 94% for English-French.", "startOffset": 18, "endOffset": 21}, {"referenceID": 19, "context": "Wu [21] aligned English-Chinese corpora by using sentence length values and reached an accuracy of 95%.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "Kay and R\u00f6scheisen [9] developed a program that combined word and sentence alignment and calculated the word probabilities by using the dice co-efficient.", "startOffset": 19, "endOffset": 22}, {"referenceID": 6, "context": "Haruno and Yamazaki [7] used a similar method plus a bilingual dictionary for aligning English-Japanese corpora.", "startOffset": 20, "endOffset": 23}, {"referenceID": 15, "context": "Papageorgiou, Cranias, and Piperidis [17] used the sentence alignment metric based on the highest matching part of speech tags and matches restricted to nouns, adjectives and verbs, and reached 99% accuracy.", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "Simard, Foster and Isabelle [19] used cognate-based approaches and found that sentence length difference worked well for sentence alignment.", "startOffset": 28, "endOffset": 32}, {"referenceID": 12, "context": "However, Melamed [14] pointed out that because results were only reported for a relatively easy bilingual text, comparing two algorithms\u2019 performances in the literature is difficult.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "[3] calculated sentence length by using the number of words instead of the number of bytes or characters, which generated similar accuracies between 96% and 97%.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "In the last decade, there have been few new proposals for sentence alignment for parallel bilingual corpora [22].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "One disadvantage of existing sentence alignment algorithms is that it is less effective when linking corresponding sentences if they are one-to-many or many-to-one mutual translations [11].", "startOffset": 184, "endOffset": 188}, {"referenceID": 1, "context": "on natural languages indicates that all natural languages have similar cross entropies [2].", "startOffset": 87, "endOffset": 90}, {"referenceID": 16, "context": "According to Shannon\u2019s information theory [18], a derived hypothesis from this observation will be that all natural languages can be encoded into the same length of bit strings for the same information if redundant bits are excluded.", "startOffset": 42, "endOffset": 46}, {"referenceID": 11, "context": "Our work with using compression code length metrics for sentence alignment with ChineseEnglish corpora have shown they can be very effective [13].", "startOffset": 141, "endOffset": 145}, {"referenceID": 1, "context": "documents, paragraphs, sentences, clauses, phrases) should have similar code lengths [2].", "startOffset": 85, "endOffset": 88}, {"referenceID": 3, "context": "The Prediction by Partial Matching (PPM) compression scheme, first proposed by Cleary and Witten in 1984 [4], predicts the next symbol or character from a fixed order context.", "startOffset": 105, "endOffset": 108}, {"referenceID": 0, "context": "For both Arabic and English text [1, 9], experiments have shown that order 5 models (using fixed order contexts of length 5) perform best at compressing the text using the PPMD variant of the algorithm developed by Howard in 1993 based on the PPMC variant devised by Moffat [20].", "startOffset": 33, "endOffset": 39}, {"referenceID": 8, "context": "For both Arabic and English text [1, 9], experiments have shown that order 5 models (using fixed order contexts of length 5) perform best at compressing the text using the PPMD variant of the algorithm developed by Howard in 1993 based on the PPMC variant devised by Moffat [20].", "startOffset": 33, "endOffset": 39}, {"referenceID": 18, "context": "For both Arabic and English text [1, 9], experiments have shown that order 5 models (using fixed order contexts of length 5) perform best at compressing the text using the PPMD variant of the algorithm developed by Howard in 1993 based on the PPMC variant devised by Moffat [20].", "startOffset": 274, "endOffset": 278}, {"referenceID": 11, "context": "[13] have shown that CR is a more effective distance metric for sentence alignment of Chinese-English parallel corpora than a distance metric based on sentence length.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Consequently, researchers have devised various methods to filter noisy sentences from parallel corpora [10].", "startOffset": 103, "endOffset": 107}, {"referenceID": 14, "context": "However, for our experiments discussed in Section 4, we have found a new technique based on a combination of the compression Code Length Ratio (CR) described above and the standard Sentence Length Ratio (SLR) described by M\u00fajdricza-Maydt [16] is the most effective for Arabic-English sentence pairs in order to achieve a high-quality corpus as a result.", "startOffset": 238, "endOffset": 242}, {"referenceID": 11, "context": "This approach has been found to be very effective, for example, when using compression code length based metrics for sentence alignment between Chinese and English [13].", "startOffset": 164, "endOffset": 168}, {"referenceID": 18, "context": "Since compression code length is an effective method for measuring information (see [20] for several references), then we would expect that roughly 50% of the compression code lengths of sentences in one language to be longer than compression code lengths of sentences in the other language, and vice versa.", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "This approach is described in detail in [1].", "startOffset": 40, "endOffset": 43}, {"referenceID": 18, "context": "This indicates that the compression method being used for the Arabic text is probably not as well tuned as is the case for the English scheme (since the use of PPM for compressing English text has been fine-tuned over many years [20]).", "startOffset": 229, "endOffset": 233}, {"referenceID": 0, "context": "This problem was addressed in recent research on the compression of Arabic text [1] where it was found that using pre-processing techniques significantly improves PPM-based compression for Arabic in many cases by over 25%.", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "English sentences containing websites or abbreviations such as USA (United States of America), UNCTAD (United Nations Conference on Trade and Development Abbreviation) might also lead to mistranslations [10].", "startOffset": 203, "endOffset": 207}], "year": 2015, "abstractText": "This paper discusses a new metric that has been applied to verify the quality in translation between sentence pairs in parallel corpora of Arabic-English. This metric combines two techniques, one based on sentence length and the other based on compression code length. Experiments on sample test parallel Arabic-English corpora indicate the combination of these two techniques improves accuracy of the identification of satisfactory and unsatisfactory sentence pairs compared to sentence length and compression code length alone. The new method proposed in this research is effective at filtering noise and reducing mis-translations resulting in greatly improved quality.", "creator": "Word"}}}