{"id": "1502.04156", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2015", "title": "Towards Biologically Plausible Deep Learning", "abstract": "Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-Timing-Dependent Plasticity) can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.", "histories": [["v1", "Sat, 14 Feb 2015 01:11:25 GMT  (264kb,D)", "http://arxiv.org/abs/1502.04156v1", null], ["v2", "Wed, 25 Nov 2015 04:13:44 GMT  (264kb,D)", "http://arxiv.org/abs/1502.04156v2", null], ["v3", "Tue, 9 Aug 2016 01:57:09 GMT  (293kb,D)", "http://arxiv.org/abs/1502.04156v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yoshua bengio", "dong-hyun lee", "jorg bornschein", "thomas mesnard", "zhouhan lin"], "accepted": false, "id": "1502.04156"}, "pdf": {"name": "1502.04156.pdf", "metadata": {"source": "META", "title": "Towards Biologically Plausible Deep Learning", "authors": ["Yoshua Bengio", "Dong-Hyun Lee", "Jorg Bornschein"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city and in which it is a country, in which it is a country, in which it is a country and in which it is a country."}, {"heading": "2. STDP as Stochastic Gradient Descent", "text": "In fact, it is the result of experimental observations in biological neurons, the interpretation of which remains unclear as part of a learning process that could explain learning in deep networks. This paper aims to propose such an interpretation, based on the suggestion made by Hinton (2007), but to extend these ideas towards unattended generative modelling of data. What has been observed in STDP is that weights change when there is a pre-synaptic spike in the temporal environment of a synaptic spike. This change is positive when the post-synaptic spike-spike-spike-spike-spike-spike happens."}, {"heading": "3. Variational EM with Learned Approximate Inference", "text": "To use the advantage of the above statement, the dynamics of the neural network must be such that the neuronal activities move in the direction of better values of an objective function (q = q = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "4. Training a Deep Generative Model", "text": "There is strong biological evidence of a clear pattern of connectivity between cortical regions that distinguishes between \"q feedback\" and \"feedback\" connections (Douglas et al., 1989) at the level of the cortex micro-circuit (i.e., feedback and feedback connections do not end up in the same type of cells (q feedback). Furthermore, the Feedforward connec algorithm is 1 Variational MAP (or MCMC) SGD algorithm for gradually improving agreement between the values of the latent variable h and the observed data x. q (h | x) is a learned parametric initialization for h, p (h) is a parametric approach for the latent variables, and p (x | h) specifies how to generate x given h. Objective function J is defined in equation."}, {"heading": "5. Alternative Interpretations as Denoising Auto-Encoder", "text": "By looking at algorithm 1, one can observe that this algorithm forms p (x | h) and q (h | x) to complementary pairs of an auto-encoder (since the input of one is the target of the other and vice versa). Note that from this point of view, each of the two can act as an encoder and the other as a decoder for it, depending on whether we start from h or x. In the case of several latent layers, each of the two conditionalities q (h (k + 1) | h (k)) and p (h (k + 1) can form a symmetrical auto-encoder, i.e., either one can function as an encoder and the other as a corresponding decoder, since they are trained with the same (h (k), h (k + 1)) pairs (but with inverted roles of input and target)."}, {"heading": "5.1. Joint Denoising Auto-Encoder with Latent Variables", "text": "This suggests that a particular type of \"joint\" (k + 1) and such an ability (k + 1) is considered a \"visible\" variable that implicitly subordinates an underlying p (x, h) to p (x, h).The transition procedure for this common view (x, h) is as follows in the case of a single hidden layer: (x, h).The transition procedure (h) in which corruption can correspond to the stochastic quantization induced by neuronal non-linearity and the propagation process of spiking. In the case of a middle layer h (k) in a deeper model, the transition processor must take into account the fact that h (k) can be reconstructed either from above or below, with the probability of saying 12, h (k)."}, {"heading": "5.2. Latent Variables as Corruption", "text": "There is another interpretation of the training method, also as the denocialization of the auto-encoder, which has the advantage of generating a generative method identical to the inference method, except that x is decrypted. We return to the generative interpretation of the denocialization criterion for auto-encoders, but this time we consider the non-parametric process q \u0445 (h | x) as a kind of corruption of x that yields the h used as input for the reconstruction of the observed x via p (x | h). Under this interpretation, a valid generative procedure exists for each step in the first inference, i.e. in the sampling h from q (h | x) and the second sampling from p (x | h). To cite these steps generates x according to the Markov chain, whose stationary distribution is an estimator for the data generation of the distribution produced by the training x (Bengio et al., 2013)."}, {"heading": "6. Targetprop instead of Backprop", "text": "In algorithm 1 and the associated stochastic variants Eq. 8, it indicates that backward propagation (through a layer) still needs to be estimated when h (k) is on the right side of the conditional probability bar, e.g. to make h (k) more \"compatible\" with h (k \u2212 1). This gradient is also the basic building block in backward propagation for supervised learning: we need to go through a layer back-prop, for example, to make h (k) more \"compatible\" with h (k \u2212 1). This provides a kind of error signal that, in the case of unattended learning, comes from the sensors, and in the case of supervised learning, it comes from the layer that holds the observed \"target.\" Based on recent theoretical results on denoizing autocoders, we propose the following estimate (up to a scaling constant) of the required gradients related to the \"target propagation.\""}, {"heading": "7. Related Work", "text": "The main inspiration for the proposed framework is the biological implementation of reverse propagation proposed by Hinton (2007).In this conversation, Hinton suggests that STDP corresponds to a gradient update step with the gradient on the voltage potential corresponding to its temporal derivation.In order to obtain the supervised reverse propagation update in the proposed scenario, symmetrical weights and synchronization of the calculation steps with respect to feedback phases would be required.Our proposal extends these ideas to unsupervised learning, avoids the need for symmetrical weights and uses conclusions to obtain goals and a probable interpretation of the calculation, such as the optimization of a variable approach to thealgorithm 2. inference, training and generative procedures used in experiment 1, for a model with three map layers x, h1, h2. fi () is the feedback map from layer \u2212 1 to layer \u2212 1, the feedback layer \u2212 1 is layer \u2212 1."}, {"heading": "8. Experimental Validation", "text": "Figure 2 shows generated samples obtained after training at MNIST with algorithm 2 (derived from the considerations of Sec.s 4, 5 and 6).The network has two hid layers, h1 with 1000 softplus units and h2 with 100 sigmoid units (which can be considered biologically plausible (Glorot et al., 2011).We have trained for 20 epochs with size 100 minibatches to speed up the calculation using GPUs. Results can be reproduced from the code using the Parzen density estimator previously used for this data, we obtain a log probability of LL = 236 (using a standard deviation of 0.2 for the Parze density estimator, chosen with the validation theorem), which is approximately equal or better than for contractive autocoditors (Rifai et al al al., 2011) (LL = 121), deeper generative networks (Benastostic, 2014)."}, {"heading": "9. Future Work and Conclusion", "text": "The fact is that we will be able to hide, and that we will be able, we will be able to move to another world in which we are able, in which we are in."}, {"heading": "Acknowledgments", "text": "The authors thank Jyri Kivinen, Tim Lillicrap and Saizheng Zhang for feedback and discussion, NSERC, CIFAR, Samsung and Canada Research Chairs for funding and Compute Canada for computing resources."}], "references": [{"title": "What regularized auto-encoders learn from the data generating distribution", "author": ["Alain", "Guillaume", "Bengio", "Yoshua"], "venue": "In ICLR\u20192013. also arXiv report 1211.4246,", "citeRegEx": "Alain et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Alain et al\\.", "year": 2013}, {"title": "How auto-encoders could provide credit assignment in deep networks via target propagation", "author": ["Bengio", "Yoshua"], "venue": "Technical report,", "citeRegEx": "Bengio and Yoshua.,? \\Q2014\\E", "shortCiteRegEx": "Bengio and Yoshua.", "year": 2014}, {"title": "Generalized denoising auto-encoders as generative models", "author": ["Bengio", "Yoshua", "Yao", "Li", "Alain", "Guillaume", "Vincent", "Pascal"], "venue": "In NIPS\u20192013,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Deep generative stochastic networks trainable by backprop", "author": ["Bengio", "Yoshua", "Thibodeau-Laufer", "Eric", "Alain", "Guillaume", "Yosinski", "Jason"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Bengio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2014}, {"title": "Reweighted wakesleep", "author": ["Bornschein", "J\u00f6rg", "Bengio", "Yoshua"], "venue": "Technical report,", "citeRegEx": "Bornschein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bornschein et al\\.", "year": 2014}, {"title": "Variational MCMC", "author": ["de Freitas", "Nando", "H\u00f8jen-S\u00f8rensen", "Pedro", "Jordan", "Michael I", "Russell", "Stuart"], "venue": null, "citeRegEx": "Freitas et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Freitas et al\\.", "year": 2001}, {"title": "A canonical microcircuit for neocortex", "author": ["R.J. Douglas", "K.A. Martin", "D. Whitteridge"], "venue": "Neural Computation,", "citeRegEx": "Douglas et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Douglas et al\\.", "year": 1989}, {"title": "Distributed hierarchical processing in the primate cerebral cortex", "author": ["Felleman", "Daniel J", "Essen", "David C. Van"], "venue": "Cerebral Cortex,", "citeRegEx": "Felleman et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Felleman et al\\.", "year": 1991}, {"title": "A neuronal learning rule for sub-millisecond temporal coding", "author": ["W. Gerstner", "R. Kempter", "J.L. van Hemmen", "H. Wagner"], "venue": "Nature, 386:76\u201378,", "citeRegEx": "Gerstner et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Gerstner et al\\.", "year": 1996}, {"title": "Deep sparse rectifier neural networks", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "In AISTATS\u20192011,", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Measuring invariances in deep networks", "author": ["Goodfellow", "Ian", "Le", "Quoc", "Saxe", "Andrew", "Ng"], "venue": "In NIPS\u20192009,", "citeRegEx": "Goodfellow et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2009}, {"title": "Generative adversarial networks", "author": ["Goodfellow", "Ian J", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In NIPS\u20192014,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "How to do backpropagation in a brain", "author": ["Hinton", "Geoffrey E"], "venue": "Invited talk at the NIPS\u20192007 Deep Learning Workshop,", "citeRegEx": "Hinton and E.,? \\Q2007\\E", "shortCiteRegEx": "Hinton and E.", "year": 2007}, {"title": "The wake-sleep algorithm for unsupervised neural networks", "author": ["Hinton", "Geoffrey E", "Dayan", "Peter", "Frey", "Brendan J", "Neal", "Radford M"], "venue": "Science, 268:1558\u20131161,", "citeRegEx": "Hinton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1995}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Hinton", "Geoffrey E", "Osindero", "Simon", "Teh", "Yee Whye"], "venue": "Neural Computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Fast inference in sparse coding algorithms with applications to object recognition", "author": ["Kavukcuoglu", "Koray", "Ranzato", "Marc\u2019Aurelio", "LeCun", "Yann"], "venue": "Technical report, Computational and Biological Learning Lab, Courant Institute,", "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2008}, {"title": "Semi-supervised learning with deep generative models", "author": ["D.P. Kingma", "D.J. Rezende", "S. Mohamed", "M. Welling"], "venue": "In NIPS\u20192014,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Durk P", "Welling", "Max"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Backprop-free autoencoders. NIPS\u20192014", "author": ["Lee", "Dong-Hyun", "Bengio", "Yoshua"], "venue": "Deep Learning workshop,", "citeRegEx": "Lee et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Ensembles of spiking neurons with noise support optimal probabilistic inference in a dynamically changing environment", "author": ["Legenstein", "Robert", "Maass", "Wolfgang"], "venue": "PLOS Computational Biology,", "citeRegEx": "Legenstein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Legenstein et al\\.", "year": 2014}, {"title": "Random feedback weights support learning in deep neural networks", "author": ["Lillicrap", "Timothy P", "Cownden", "Daniel", "Tweed", "Douglas B", "Akerman", "Colin J"], "venue": null, "citeRegEx": "Lillicrap et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lillicrap et al\\.", "year": 2014}, {"title": "Action potentials propagating back into dendrites triggers changes in efficacy", "author": ["H. Markram", "B. Sakmann"], "venue": "Soc. Neurosci. Abs,", "citeRegEx": "Markram and Sakmann,? \\Q1995\\E", "shortCiteRegEx": "Markram and Sakmann", "year": 1995}, {"title": "A view of the EM algorithm that justifies incremental, sparse, and other variants", "author": ["R.M. Neal", "G.E. Hinton"], "venue": null, "citeRegEx": "Neal and Hinton,? \\Q1999\\E", "shortCiteRegEx": "Neal and Hinton", "year": 1999}, {"title": "Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons", "author": ["Pecevski", "Dejan", "Buesing", "Lars", "Maass", "Wolfgang"], "venue": "PLOS Computational Biology,", "citeRegEx": "Pecevski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pecevski et al\\.", "year": 2011}, {"title": "Efficient learning of sparse representations with an energybased model", "author": ["M. Ranzato", "C. Poultney", "S. Chopra", "Y. LeCun"], "venue": "In NIPS\u20192006,", "citeRegEx": "Ranzato et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2007}, {"title": "Contractive autoencoders: Explicit invariance during feature extraction", "author": ["Rifai", "Salah", "Vincent", "Pascal", "Muller", "Xavier", "Glorot", "Bengio", "Yoshua"], "venue": "In ICML\u20192011,", "citeRegEx": "Rifai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rifai et al\\.", "year": 2011}, {"title": "Deep Boltzmann machines", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "In AISTATS\u20192009,", "citeRegEx": "Salakhutdinov and Hinton,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov and Hinton", "year": 2009}, {"title": "Markov Chain Monte Carlo and Variational Inference: Bridging the Gap", "author": ["T. Salimans", "D.P. Kingma", "M. Welling"], "venue": null, "citeRegEx": "Salimans et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2014}, {"title": "Information processing in dynamical systems: Foundations of harmony theory", "author": ["Smolensky", "Paul"], "venue": "Parallel Distributed Processing,", "citeRegEx": "Smolensky and Paul.,? \\Q1986\\E", "shortCiteRegEx": "Smolensky and Paul.", "year": 1986}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Vincent", "Pascal", "Larochelle", "Hugo", "Bengio", "Yoshua", "Manzagol", "Pierre-Antoine"], "venue": "ICML", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["Welling", "Max", "Teh", "Yee-Whye"], "venue": "In ICML\u20192011,", "citeRegEx": "Welling et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Welling et al\\.", "year": 2011}, {"title": "Equivalence of backpropagation and contrastive Hebbian learning in a layered network", "author": ["Xie", "Xiaohui", "Seung", "H. Sebastian"], "venue": "Neural Computation,", "citeRegEx": "Xie et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 20, "context": "and with neurons not all being exactly the same, it could be difficult to match the right estimated derivatives this is known as the weight transport problem (Lillicrap et al., 2014) ar X iv :1 50 2.", "startOffset": 158, "endOffset": 182}, {"referenceID": 24, "context": "Note that back-propagation is used not just for classical supervised learning but also for many unsupervised learning algorithms, including all kinds of auto-encoders: sparse auto-encoders (Ranzato et al., 2007; Goodfellow et al., 2009), denoising auto-encoders (Vincent et al.", "startOffset": 189, "endOffset": 236}, {"referenceID": 10, "context": "Note that back-propagation is used not just for classical supervised learning but also for many unsupervised learning algorithms, including all kinds of auto-encoders: sparse auto-encoders (Ranzato et al., 2007; Goodfellow et al., 2009), denoising auto-encoders (Vincent et al.", "startOffset": 189, "endOffset": 236}, {"referenceID": 29, "context": ", 2009), denoising auto-encoders (Vincent et al., 2008), contractive auto-encoders (Rifai et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 25, "context": ", 2008), contractive auto-encoders (Rifai et al., 2011), and more recently, variational auto-encoders (Kingma & Welling, 2014).", "startOffset": 35, "endOffset": 55}, {"referenceID": 14, "context": "Other unsupervised learning algorithms exist which do not rely on back-propagation, such as the various Boltzmann machine learning algorithms (Hinton & Sejnowski, 1986; Smolensky, 1986; Hinton et al., 2006; Salakhutdinov & Hinton, 2009).", "startOffset": 142, "endOffset": 236}, {"referenceID": 18, "context": "6) is to show that one can estimate these gradients via an approximation that only involves ordinary neural computation and no explicit derivatives, following previous work on target propagation (Bengio, 2014; Lee et al., 2014).", "startOffset": 195, "endOffset": 227}, {"referenceID": 8, "context": "Spike-Timing-Dependent Plasticity or STDP is believed to be the main form of synaptic change in neurons (Markram & Sakmann, 1995; Gerstner et al., 1996) and it relates the expected change in synaptic weights to the timing difference between post-synaptic spikes and pre-synaptic spikes.", "startOffset": 104, "endOffset": 152}, {"referenceID": 8, "context": "Spike-Timing-Dependent Plasticity or STDP is believed to be the main form of synaptic change in neurons (Markram & Sakmann, 1995; Gerstner et al., 1996) and it relates the expected change in synaptic weights to the timing difference between post-synaptic spikes and pre-synaptic spikes. Although it is the result of experimental observations in biological neurons, its interpretation as part of a learning procedure that could explain learning in deep networks remains unclear. This paper aims at proposing such an interpretation, starting from the proposal made by Hinton (2007), but extending these ideas towards unsupervised generative modeling of the data.", "startOffset": 130, "endOffset": 580}, {"referenceID": 13, "context": "Variational bounds have been proposed to justify various learning algorithms for generative models (Hinton et al., 1995) (Sec.", "startOffset": 99, "endOffset": 120}, {"referenceID": 23, "context": ", via a Markov chain which may correspond to probabilistic inference with spiking neurons (Pecevski et al., 2011).", "startOffset": 90, "endOffset": 113}, {"referenceID": 5, "context": "Variational MCMC (de Freitas et al., 2001) can be used to approximate the posterior, e.g., as in the model from Salimans et al. (2014). However, a rejection step does not look very biologically plausible (both for the need of returning to a previous state and for the need to evaluate the joint likelihood, a global quantity).", "startOffset": 21, "endOffset": 135}, {"referenceID": 5, "context": "Variational MCMC (de Freitas et al., 2001) can be used to approximate the posterior, e.g., as in the model from Salimans et al. (2014). However, a rejection step does not look very biologically plausible (both for the need of returning to a previous state and for the need to evaluate the joint likelihood, a global quantity). On the other hand, a biased MCMC with no rejection step, such as the stochastic gradient Langevin MCMC of Welling & Teh (2011) can work very well in practice.", "startOffset": 21, "endOffset": 454}, {"referenceID": 6, "context": "There is strong biological evidence of a distinct pattern of connectivity between cortical areas that distinguishes between \u201cfeedforward\u201d and \u201cfeedback\u201d connections (Douglas et al., 1989) at the level of the microcircuit of cortex (i.", "startOffset": 165, "endOffset": 187}, {"referenceID": 2, "context": "See Theorem 1 from Bengio et al. (2013) for the generative interpretation of denoising auto-encoders: it basically states that one can sample from the model implicitly estimated by a denoising auto-encoder by simply alternating noise injection (corruption), encoding and decoding, these forming each step of a generative Markov chain.", "startOffset": 19, "endOffset": 40}, {"referenceID": 2, "context": "Iterating these steps generates x\u2019s according to the Markov chain whose stationary distribution is an estimator of the data generating distribution that produced the training x\u2019s (Bengio et al., 2013).", "startOffset": 179, "endOffset": 200}, {"referenceID": 18, "context": "Based on recent theoretical results on denoising autoencoders, we propose the following estimator (up to a scaling constant) of the required gradient, which is related to previous work on \u201ctarget propagation\u201d (Bengio, 2014; Lee et al., 2014) or targetprop for short.", "startOffset": 209, "endOffset": 241}, {"referenceID": 15, "context": "Another important inspiration is Predictive Sparse Decomposition (PSD) (Kavukcuoglu et al., 2008).", "startOffset": 71, "endOffset": 97}, {"referenceID": 13, "context": "that was started with the Wake-Sleep algorithm (Hinton et al., 1995) and which finds very interesting instantiations in the variational auto-encoder (Kingma & Welling, 2014; Kingma et al.", "startOffset": 47, "endOffset": 68}, {"referenceID": 16, "context": ", 1995) and which finds very interesting instantiations in the variational auto-encoder (Kingma & Welling, 2014; Kingma et al., 2014) and the reweighted wake-sleep algorithm (Bornschein & Bengio, 2014).", "startOffset": 88, "endOffset": 133}, {"referenceID": 13, "context": "that was started with the Wake-Sleep algorithm (Hinton et al., 1995) and which finds very interesting instantiations in the variational auto-encoder (Kingma & Welling, 2014; Kingma et al., 2014) and the reweighted wake-sleep algorithm (Bornschein & Bengio, 2014). Two important differences with the approach proposed here is that here we avoid back-propagation thanks to an inference step that approximates the posterior. In this spirit, see the recent work introducing MCMC inference for the variational auto-encoder Salimans et al. (2014).", "startOffset": 48, "endOffset": 541}, {"referenceID": 20, "context": "Addressing the weight transport problem (the weight symmetry constraint) was also done for the supervised case using feedback alignment (Lillicrap et al., 2014): even if the feedback weights do not exactly match the feedforward weights, the latter learn to align to the former and \u201cback-propagation\u201d (with the wrong feedback weights) still works.", "startOffset": 136, "endOffset": 160}, {"referenceID": 18, "context": "The proposal made here also owes a lot to the idea of target propagation introduced in Bengio (2014); Lee et al. (2014), to which it adds the idea that in order to find a target that is consistent with both the input and the final output target, it makes sense to perform iterative inference, reconciling the bottom-up and top-down pressures.", "startOffset": 102, "endOffset": 120}, {"referenceID": 9, "context": "den layers, h1 with 1000 softplus units and h2 with 100 sigmoid units (which can be considered biologically plausible (Glorot et al., 2011)).", "startOffset": 118, "endOffset": 139}, {"referenceID": 25, "context": "2 for the Parzen density estimator, chosen with the validation set), which is about the same or better as was obtained for contractive autoencoders (Rifai et al., 2011) (LL=121), deeper generative stochastic networks (Bengio et al.", "startOffset": 148, "endOffset": 168}, {"referenceID": 3, "context": ", 2011) (LL=121), deeper generative stochastic networks (Bengio et al., 2014) (LL=214) and generative adversarial networks (Goodfellow et al.", "startOffset": 56, "endOffset": 77}, {"referenceID": 11, "context": ", 2014) (LL=214) and generative adversarial networks (Goodfellow et al., 2014) (LL=225).", "startOffset": 53, "endOffset": 78}, {"referenceID": 18, "context": ", with stochastic binary units (Lee et al., 2014).", "startOffset": 31, "endOffset": 49}, {"referenceID": 18, "context": "As argued by Bengio (2014); Lee et al. (2014), departing from backpropagation could be useful not just for biological plausibility but from a machine learning point of view as well: by working on the \u201ctargets\u201d for the intermediate layers, we may avoid the kind of reliance on smoothness and derivatives that characterizes back-propagation, as these techniques can in principle work even with highly non-linear transformations for which gradients are often near 0, e.", "startOffset": 28, "endOffset": 46}], "year": 2015, "abstractText": "Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-TimingDependent Plasticity) can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.", "creator": "LaTeX with hyperref package"}}}