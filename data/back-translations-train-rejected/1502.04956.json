{"id": "1502.04956", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2015", "title": "The Linearization of Belief Propagation on Pairwise Markov Networks", "abstract": "Belief Propagation (BP) allows to approximate exact probabilistic inference in graphical models, such as Markov networks (also called Markov random fields, or undirected graphical models). However, no exact convergence guarantees for BP are known, in general. Recent work has proposed to approximate BP by linearizing the update equations around default values for the special case when all edges in the Markov network carry the same symmetric, doubly stochastic potential. This linearization has led to exact convergence guarantees, considerable speed-up, while maintaining high quality results in network-based classification (i.e. when we only care about the most likely label or class for each node and not the exact probabilities). The present paper generalizes our prior work on Linearized Belief Propagation (LinBP) with an approach that approximates Loopy Belief Propagation on any pairwise Markov network with the problem of solving a linear equation system.", "histories": [["v1", "Tue, 17 Feb 2015 16:49:23 GMT  (707kb,D)", "https://arxiv.org/abs/1502.04956v1", "14 pages, 7 figures"], ["v2", "Tue, 27 Dec 2016 15:01:40 GMT  (797kb,D)", "http://arxiv.org/abs/1502.04956v2", "Full version of AAAI 2017 paper with same title (23 pages, 9 figures)"]], "COMMENTS": "14 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.SI", "authors": ["wolfgang gatterbauer"], "accepted": false, "id": "1502.04956"}, "pdf": {"name": "1502.04956.pdf", "metadata": {"source": "CRF", "title": "The Linearization of Belief Propagation on Pairwise Markov Random Fields", "authors": ["Wolfgang Gatterbauer"], "emails": [], "sections": [{"heading": null, "text": "In fact, there is no guarantee that there will be such convergence at all, and there is no guarantee that there will be such convergence. (Sen et al.) It is not certain that there will be such convergence. (Sen et al.) It is not likely that there will be such convergence. (Sen et al.) While there will be such convergence, it is not likely that there will be such convergence. (Sen et al.) It is not likely that there will be such convergence. (Sen et al.) While there will be such convergence, there is such a convergence. (Sen et al.) It is not possible that there will be such a convergence. (Sen et al.)"}, {"heading": "Iterative updates and convergence", "text": "The complexity of inverting a matrix is cubic in the number of variables, which makes the direct application of Equation (4) difficult. Instead, we use Equation (3), which is an implicit definition of definitive beliefs, iterative. Starting from an arbitrary initialization of y (e.g., all values zero), we repeatedly compute the right side of the equations and update the values of y \u2212 until the process converges: 65Note that the BP update equations send a message over an edge that excludes information received from the other direction via the same edge: \"u\" N (s)\\ t \"in Equation (2). In a probabilistic scenario on tree-based graphs, this echoculature is required for correctness. In loopic graphs (without well-justified semantics), this term balances the message of a node."}, {"heading": "Computational complexity", "text": "We assume that the number of nodes and the maximum number of classes per node is only proportional to the number of edges: O (mk2max). However, the temporal complexity is identical to that of message delivery with division, which avoids redundant calculations and is faster than standard BP on high-node graphs (Koller and Friedman 2009). However, the ability to use existing highly optimized packages for efficient matrix vector multiplication is identical. 4 experiment questions will answer the following 3 questions: (1) What is the effect of convergence parameters on accuracy and number of iterations required? (2) How accurate is our alignment?"}, {"heading": "Recentering", "text": "The following Lemma provides the mathematical justification for our special choice of recentration: Lemma 10 (recentration) = K (recentration). Consider updated equation (1 Z-dimensional vector x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x x-x-x-x-x-x-x"}, {"heading": "Centered BP", "text": "By using the previous Lemma and concentrating only on the residuals, we can next convert the equations for the propagation of faith from the multiplication to the addition: Lemma 12 (centered BP). By centering the coupling matrix, faith and messages accordingly, we can convert the equations for the propagation of faith by: y s (j) x s (js) x s (js) x s (js) x s (js) x s (js) s (js) s (js) s (js) s (js) s (js) s (js) s (js) s (js) s (js) x s (js) s (js) s (js) s (js) js (js) js (js) js (s) js (s) js (s) js (s (s) js (js) js (s (s) js (js (s) js (js (s) js (s (js) js (js (js) js (s (js) js (s (s) js (s (js) js (s (s) js (s (js) js (js (s)) js (s (s (js (s)) js (s (s (s)) js (js (s (s)) js (s (s (s (s)) js (s (s (s (s) js (s)) js (s (s) js (s (s (s))) js (s (s (s (s) js (s (s) js (s) js) js (s (s (s)) js (s (s (s)) js (s) js (s (s (s)) js (s) js (s (s (s (s)) js (s (s) js (s (s (s) js) js) js (s (s) js (s (s) js (s (s)"}, {"heading": "Steady state messages", "text": "From Lemma 12 we can deduce a closed-form equation for the message in the permanent state of faith (Lemma 13 (Steady State Messages). After the convergence of the propagation of faith, the message propagation can be derived with respect to the continuous centered beliefs as: m, st, rst, and write instead: c, r, respectively. We begin by writing the messages in each of the two directions over the same margin (9). \u2212 To increase the readability of this evidence, we ignore the subscriptions in the subscriptions in the subscriptions in st, cst, k, rst, and write instead: c, r, or in the subscriptions in the subscriptions in the subscriptions. \u2212 t: m, st, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k"}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Belief Propagation (BP) is a widely used approximation for exact probabilistic inference in graphical models, such as Markov Random Fields (MRFs). In graphs with cycles, however, no exact convergence guarantees for BP are known, in general. For the case when all edges in the MRF carry the same symmetric, doubly stochastic potential, recent works have proposed to approximate BP by linearizing the update equations around default values, which was shown to work well for the problem of node classification. The present paper generalizes all prior work and derives an approach that approximates loopy BP on any pairwise MRF with the problem of solving a linear equation system. This approach combines exact convergence guarantees and a fast matrix implementation with the ability to model heterogenous networks. Experiments on synthetic graphs with planted edge potentials show that the linearization has comparable labeling accuracy as BP for graphs with weak potentials, while speeding-up inference by orders of magnitude.", "creator": "LaTeX with hyperref package"}}}