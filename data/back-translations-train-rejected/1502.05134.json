{"id": "1502.05134", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2015", "title": "Supervised cross-modal factor analysis for multiple modal data classification", "abstract": "In this paper we study the problem of learning from multiple modal data for purpose of document classification. In this problem, each document is composed two different modals of data, i.e., an image and a text. Cross-modal factor analysis (CFA) has been proposed to project the two different modals of data to a shared data space, so that the classification of a image or a text can be performed directly in this space. A disadvantage of CFA is that it has ignored the supervision information. In this paper, we improve CFA by incorporating the supervision information to represent and classify both image and text modals of documents. We project both image and text data to a shared data space by factor analysis, and then train a class label predictor in the shared space to use the class label information. The factor analysis parameter and the predictor parameter are learned jointly by solving one single objective function. With this objective function, we minimize the distance between the projections of image and text of the same document, and the classification error of the projection measured by hinge loss function. The objective function is optimized by an alternate optimization strategy in an iterative algorithm. Experiments in two different multiple modal document data sets show the advantage of the proposed algorithm over other CFA methods.", "histories": [["v1", "Wed, 18 Feb 2015 06:55:07 GMT  (91kb)", "http://arxiv.org/abs/1502.05134v1", null], ["v2", "Tue, 18 Aug 2015 05:20:59 GMT  (80kb)", "http://arxiv.org/abs/1502.05134v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jingbin wang", "yihua zhou", "kanghong duan", "jim jing-yan wang", "halima bensmail"], "accepted": false, "id": "1502.05134"}, "pdf": {"name": "1502.05134.pdf", "metadata": {"source": "CRF", "title": "Supervised cross-modal factor analysis", "authors": ["Jingbin Wang", "Haoxiang Wang", "Yujin Tu", "Kanghong Duan", "Zhenxin Zhan", "Srikanth Chekuri"], "emails": ["jingbinwang1@outlook.com", "wanghaoxiang1102@hotmail.com", "yujintu1@yahoo.com", "kanghongduan@outlook.com", "zhenxin.zhan.dr@gmail.com", "schekuria9@hotmail.com"], "sections": [{"heading": null, "text": "In fact, most people are able to move to another world in which they are able to live, in which they want to live."}, {"heading": "II. PROPOSED METHOD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Problem formulation", "text": "We assume that we have a training set of n documents D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D, D = D = D = D = D = D = D, D = D = D = D = D, D = D = D = D = D, D = D = D = D = D, D = D = D = D = D, D = D = D = D = D = D, D = D = D = D = D, D = D = D = D = D = D, D = D = D = D = D = D, D = D = D = D = D = D = D, D = D = D = D = D = D = D, D = D = D = D = D = D = D = D = D, D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D, D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D, D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D D = D = D = D D = D = D = D = D = D = D = D, D = D = D = D D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D D = D = D = D = D = D = D = D = D D D = D D = D = D D"}, {"heading": "B. Optimization", "text": "In order to solve the problem in (5), we write the Lagrange function as follows: L = 12 = 12 = W = 22 + C1n = 1 (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1) (1 (1) (1) (1) (1 (1) (1) (1 (1) (1) (1) (1 (1) (1 (1) (1 (1) (1 (1) (1 (1) (1) (1 (1) (1) (1 (1) (1 (1) (1) (1) (1 (1) (1 (1) (1) (1 (1) (1) (1 (1) (1 (1) (1) ("}, {"heading": "C. Algorithm", "text": "Based on the optimization results, we can design an iterative algorithm as algorithm 1. Iterations are repeated T times, and the T-th time of each iteration the variables \u0441tI, \u0394t T, \u03b1 t i | n i = 1 and \u03b3ti | n i = 1 are updated alternately. Finally, the predictor parameters W are calculated from the updated variables."}, {"heading": "III. EXPERIMENTS", "text": "In this section we will experimentally examine the proposed algorithm. Algorithm 1 Iterative learning algorithm of monitored crossmodal factor analyses.Input: A training set of n documents {(I1, Ti), \u00b7 \u00b7, (In, Tn)} and the corresponding class label vector set {y1, \u00b7 \u00b7 \u00b7, yn}; Input: Tradeoff parameters C1, C2 and maximum iteration number T; Initialize ormal transformation matrices in (10); Fix matrices in (1), \u00b7 \u00b7, T do Fix matrices in (1), \u00b7 T do Fix matrices in (1) and update T matrices in (15); Update prediction in (I) and T matrices by applying SVD to Zt in (10); Fix matrices in (n i = 1) and T matrices in (T)."}, {"heading": "A. Experiment setup", "text": "1) Datasets: In this experiment, we used two different datasets of documents composed of images and text. The first dataset is the TVGraz Database [17], a multimodal database of object categories composed of textual and visual characteristics. Documents belong to 10 of 256 classes of Caltech-256. 1,000 websites are retrieved for each of the 10 classes, and 2,058 image-text pairs are collected. As most classes of the Wikipedia article database contain very few documents, we select only the 10 classes with the most documents in that dataset. The second dataset is the Wikipedia database selected from the Wikipedia article database, and Wikipedia article database contains documents from 30 classes. As most classes of the Wikipedia article database contain very few documents, we select only the 10 classes with the most documents. In addition, each marked article has more than one image and sections, so we will divide each section and each document containing several documents."}, {"heading": "B. Results", "text": "1) Comparison to unsupervised CFA: We first compared the proposed supervised version of CFA with unsupervised CFA methods on the problem of image-text classification. We considered the original CFA method [11] and its core version (CFAker) as objective representation methods and used an SVM as classifier. The suggested classification rates of the 10-fold cross-validations of the compared methods are shown in Fig. 1. However, it is clear that the proposed SupCFA completely exceeds the two unsupervised CFA methods. Indeed, the low quartile of the SupCFA classification rates is higher than the upper quarters of the compared methods. This is not at all surprising, since the SupCFA is the only method that can examine the monitoring information to improve the discriminatory capability of cross-modal factor analysis."}, {"heading": "IV. CONCLUSIONS AND FUTURE WORKS", "text": "The proposed method not only projects data of different modalities onto a common data space such as CFA, but also attempts to learn a predictor for predicting the class labels from that data space. Furthermore, learning of projection and class labeling parameters is learned within a single objective function. By jointly optimizing this objective function in terms of both projection and class labeling parameters, the class labeling information is used to unify the learning of CFA parameters. Experiments show that the monitored CFA exceeds both linear and kernel versions of CFA without taking class labeling information into account. Our method can also be used in other applications such as imaging [18], malware detection [19], [20], [21] and bioinformatics [22], [23], [24]."}], "references": [{"title": "A generic neural network for multi-modal sensorimotor learning", "author": ["F. Carenzi", "P. Bendahan", "V. Roschin", "A. Frolov", "P. Gorce", "M. Maier"], "venue": "Neurocomputing, vol. 58-60, pp. 525\u2013533, 2004.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "An advanced multi-modal method for human authentication featuring biometrics data and tokenised random numbers", "author": ["A. Lumini", "L. Nanni"], "venue": "Neurocomputing, vol. 69, no. 13-15, pp. 1706\u20131710, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Dynamic sampling-based interpolation algorithm for representation of clickable moving object in collaborative video annotation", "author": ["K.-S. Lee", "A. Nurzid Rosli", "I. Ariesthea Supandi", "G.-S. Jo"], "venue": "Neurocomputing, vol. 146, pp. 291\u2013300, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Classification of geological structure using ground penetrating radar and laplace transform artificial neural networks", "author": ["P. Szymczyk", "M. Szymczyk"], "venue": "Neurocomputing, vol. 148, pp. 354\u2013362, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Text classification with self-organizing maps: Some lessons learned", "author": ["D. Merkl"], "venue": "Neurocomputing, vol. 21, no. 1-3, pp. 61\u201377, 1998.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1998}, {"title": "Boosting na\u0131\u0308ve bayes text classification using uncertainty-based selective sampling", "author": ["H.-J. Kim", "J.-U. Kim", "Y.-G. Ra"], "venue": "Neurocomputing, vol. 67, no. 1-4 SUPPL., pp. 403\u2013410, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Multimodal representation, indexing, automated annotation and retrieval of image collections via non-negative matrix factorization", "author": ["J. Caicedo", "J. BenAbdallah", "F. Gonz\u00e1lez", "O. Nasraoui"], "venue": "Neurocomputing, vol. 76, no. 1, pp. 50\u201360, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Hypergraph-based multi-example ranking with sparse representation for transductive learning image retrieval", "author": ["C. Hong", "J. Zhu"], "venue": "Neurocomputing, vol. 101, pp. 94\u2013103, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "On the role of correlation and abstraction in cross-modal multimedia retrieval", "author": ["J. Costa Pereira", "E. Coviello", "G. Doyle", "N. Rasiwasia", "G. Lanckriet", "R. Levy", "N. Vasconcelos"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 36, no. 3, pp. 521\u2013535, March 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Continuum regression for cross-modal multimedia retrieval", "author": ["Y. Chen", "L. Wang", "W. Wang", "Z. Zhang"], "venue": "2012 19th IEEE International Conference on Image Processing (ICIP 2012), 2012, pp. 1949 \u2013 52.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Multimedia content processing through cross-modal association", "author": ["D. Li", "N. Dimitrova", "M. Li", "I.K. Sethi"], "venue": "Proceedings of the eleventh ACM international conference on Multimedia. ACM, 2003, pp. 604\u2013611.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Kernel cross-modal factor analysis for multimodal information fusion", "author": ["Y. Wang", "L. Guan", "A.N. Venetsanopoulos"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 2384\u20132387.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Singular value decomposition based minutiae matching method for finger vein recognition", "author": ["F. Liu", "G. Yang", "Y. Yin", "S. Wang"], "venue": "Neurocomputing, vol. 145, pp. 75\u201389, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Denoising of 3d magnetic resonance images by using higher-order singular value decomposition", "author": ["X. Zhang", "Z. Xu", "N. Jia", "W. Yang", "Q. Feng", "W. Chen", "Y. Feng"], "venue": "Medical Image Analysis, vol. 19, no. 1, pp. 75\u201386, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Finite time dual neural networks with a tunable activation function for solving quadratic programming problems and its application", "author": ["P. Miao", "Y. Shen", "X. Xia"], "venue": "Neurocomputing, vol. 143, pp. 80\u201389, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "A dynamic programming heuristic for the quadratic knapsack problem", "author": ["F. Fomeni", "A. Letchford"], "venue": "INFORMS Journal on Computing, vol. 26, no. 1, pp. 173\u2013182, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Tvgraz: Multi-modal learning of object categories by combining textual and visual features", "author": ["I. Khan", "A. Saffari", "H. Bischof"], "venue": "AAPR Workshop, 2009, pp. 213\u2013224.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "An effective image representation method using kernel classification", "author": ["H. Wang", "J. Wang"], "venue": "2014 IEEE 26th International Conference on Tools with Artificial Intelligence (ICTAI 2014), 2014, pp. 853\u2013858.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "An evasion and counter-evasion study in malicious websites detection", "author": ["L. Xu", "Z. Zhan", "S. Xu", "K. Ye"], "venue": "2014 IEEE Conference on Communications and Network Security (CNS), 2014, pp. 265\u2013273.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Characterizing honeypot-captured cyber attacks: Statistical framework and case study", "author": ["Z. Zhan", "M. Xu", "S. Xu"], "venue": "IEEE Transactions on Information Forensics and Security, vol. 8, no. 11, pp. 1775\u20131789, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Cross-layer detection of malicious websites", "author": ["L. Xu", "Z. Zhan", "S. Xu", "K. Ye"], "venue": "Proceedings of the third ACM conference on Data and application security and privacy, 2013, pp. 141\u2013152.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Computational modeling of magnetic nanoparticle targeting to stent surface under high gradient field", "author": ["S. Wang", "Y. Zhou", "J. Tan", "J. Xu", "J. Yang", "Y. Liu"], "venue": "Computational mechanics, vol. 53, no. 3, pp. 403\u2013412, 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Structure design of vascular stents", "author": ["Y. Liu", "J. Yang", "Y. Zhou", "J. Hu"], "venue": "Multiscale Simulations and Mechanics of Biological Materials, pp. 301\u2013 317, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Biomarker binding on an antibody-functionalized biosensor surface: The influence of surface properties, electric field, and coating density", "author": ["Y. Zhou", "W. Hu", "B. Peng", "Y. Liu"], "venue": "The Journal of Physical Chemistry C, vol. 118, no. 26, pp. 14 586\u201314 594, 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION In this paper, we deal with the problem of learning from multiple modal data [1], [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 1, "context": "INTRODUCTION In this paper, we deal with the problem of learning from multiple modal data [1], [2].", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "Traditional data representation, classification and retrieval problems usually focus on single modal data [3], [4].", "startOffset": 106, "endOffset": 109}, {"referenceID": 3, "context": "Traditional data representation, classification and retrieval problems usually focus on single modal data [3], [4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "For example, for the problem of text classification, we usually only consider using a data set of text to train a classifier [5], [6].", "startOffset": 125, "endOffset": 128}, {"referenceID": 5, "context": "For example, for the problem of text classification, we usually only consider using a data set of text to train a classifier [5], [6].", "startOffset": 130, "endOffset": 133}, {"referenceID": 6, "context": "While for the problem of image representation, only the images are considered to learn the representation parameters [7], [8].", "startOffset": 117, "endOffset": 120}, {"referenceID": 7, "context": "While for the problem of image representation, only the images are considered to learn the representation parameters [7], [8].", "startOffset": 122, "endOffset": 125}, {"referenceID": 8, "context": "Learning from these multiple modal data has attracted much attention from both machine learning and multimedia information processing communities [9], [10].", "startOffset": 146, "endOffset": 149}, {"referenceID": 9, "context": "Learning from these multiple modal data has attracted much attention from both machine learning and multimedia information processing communities [9], [10].", "startOffset": 151, "endOffset": 155}, {"referenceID": 10, "context": "Recently, cross-modal factor analysis (CFA) has been proposed to project different modal of data to a shared feature space so that classification or retrieval can be performed cross data modal [11].", "startOffset": 193, "endOffset": 197}, {"referenceID": 11, "context": "CFA is further extended to its kernel version in [12].", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "The orthonormal transformation matrices are optimized by fixing class label predictor parameter matrix and solving a singular value decomposition (SVD) problem [13], [14].", "startOffset": 160, "endOffset": 164}, {"referenceID": 13, "context": "The orthonormal transformation matrices are optimized by fixing class label predictor parameter matrix and solving a singular value decomposition (SVD) problem [13], [14].", "startOffset": 166, "endOffset": 170}, {"referenceID": 14, "context": "[15], [16] The rest parts of this paper are organized as follows: in section II we introduce the proposed supervised CFA (SupCFA), in section III the proposed method is evaluated experimentally, and in section IV, the paper is concluded.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[15], [16] The rest parts of this paper are organized as follows: in section II we introduce the proposed supervised CFA (SupCFA), in section III the proposed method is evaluated experimentally, and in section IV, the paper is concluded.", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "The first data set is the TVGraz database [17], which is a multimodal database of object categories composed of textual and visual features.", "startOffset": 42, "endOffset": 46}, {"referenceID": 10, "context": "We considered the original CFA method [11] and its kernel version (CFAker) [12] as data representation methods, and used a SVM as a classifier.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "We considered the original CFA method [11] and its kernel version (CFAker) [12] as data representation methods, and used a SVM as a classifier.", "startOffset": 75, "endOffset": 79}], "year": 2017, "abstractText": "In this paper we study the problem of learning from multiple modal data for purpose of document classification. In this problem, each document is composed two different modals of data, i.e., an image and a text. Cross-modal factor analysis (CFA) has been proposed to project the two different modals of data to a shared data space, so that the classification of a image or a text can be performed directly in this space. A disadvantage of CFA is that it has ignored the supervision information. In this paper, we improve CFA by incorporating the supervision information to represent and classify both image and text modals of documents. We project both image and text data to a shared data space by factor analysis, and then train a class label predictor in the shared space to use the class label information. The factor analysis parameter and the predictor parameter are learned jointly by solving one single objective function. With this objective function, we minimize the distance between the projections of image and text of the same document, and the classification error of the projection measured by hinge loss function. The objective function is optimized by an alternate optimization strategy in an iterative algorithm. Experiments in two different multiple modal document data sets show the advantage of the proposed algorithm over other CFA methods.", "creator": "LaTeX with hyperref package"}}}