{"id": "1502.05213", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2015", "title": "F0 Modeling In Hmm-Based Speech Synthesis System Using Deep Belief Network", "abstract": "In recent years multilayer perceptrons (MLPs) with many hid- den layers Deep Neural Network (DNN) has performed sur- prisingly well in many speech tasks, i.e. speech recognition, speaker verification, speech synthesis etc. Although in the context of F0 modeling these techniques has not been ex- ploited properly. In this paper, Deep Belief Network (DBN), a class of DNN family has been employed and applied to model the F0 contour of synthesized speech which was generated by HMM-based speech synthesis system. The experiment was done on Bengali language. Several DBN-DNN architectures ranging from four to seven hidden layers and up to 200 hid- den units per hidden layer was presented and evaluated. The results were compared against clustering tree techniques pop- ularly found in statistical parametric speech synthesis. We show that from textual inputs DBN-DNN learns a high level structure which in turn improves F0 contour in terms of ob- jective and subjective tests.", "histories": [["v1", "Wed, 18 Feb 2015 13:15:13 GMT  (219kb)", "http://arxiv.org/abs/1502.05213v1", "OCOCOSDA 2014"]], "COMMENTS": "OCOCOSDA 2014", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["sankar mukherjee", "shyamal kumar das mandal"], "accepted": false, "id": "1502.05213"}, "pdf": {"name": "1502.05213.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["sankar1535@gmail.com", "sdasmandal@cet.iitkgp.ernet.in"], "sections": [{"heading": null, "text": "ar Xiv: 150 2.05 213v 1 [cs.L G] 18 FeIndex Terms - F0 Modeling, DBN, Speech Synthesis, Bengali."}, {"heading": "1. INTRODUCTION", "text": "This year is the highest in the history of the country."}, {"heading": "2. ARCHITECTURE OF DEEP BELIEF NETWORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Restricted Boltzmann Machines", "text": "RBM is a special type of Markov random variable having a layer of (Bernoulli) stochastic hidden units and a layer of (Bernoulli or Gaussian) stochastic visible or observable units. There are no visible or hidden units, but all visible units are connected to all hidden units. The weights between the connections of the visible units v and hidden units h define a probability distribution over the visible units v \u2212 \u2212 v via an energy function [11]. Depending on the visible unit (i.e. Bernoulli or Gaussian) there are two types of energy functions (i.e. Bernoulli (visible) -Bernoulli (hidden) -Bernoulli (hidden) -Bernoulli (hidden) - and Gaussian (hidden) configuration (v, h). Gaussian expectations (i.e. Bernoulli or Gaussian) there are two types of energy functions (i.e. Bernoulli) -Bernoulli (hidden) -Bernoulli (i.e.) -Bernoulli (hidden) -Bernoulli (Bernoulli) -models are (i.e.)"}, {"heading": "2.2. Deep Belief Network", "text": "In this model, each layer captures the correlations between the activities of hidden features in the underlying layer; the top two layers of the DBN form an undirected bilateral graph; the lower layers form a directional graph with a top-down direction to generate the visible units. Given the training samples of the visible units, it is difficult to estimate the model parameters of a DBN directly under the highest probability criterion, due to the complex model structure with several hidden layers. Therefore, a greedy learning algorithm was proposed and popularly used to train the DBN layer by layer [1]. After learning Bernoulli-Bernoulli-Bernoulli-RBM, the activation probabilities of its hidden units were treated as the data to train the Bernoulli-Bernoulli-Bernoulli-RBM one layer higher."}, {"heading": "3. PROPOSED F0 MODELING APPROACH", "text": "As shown in Figure 1, a database of language and corresponding text sets was used as a training corpus. CRBLPspeech corpus [14] is used here for the entire experiment and consists of a male voice at the age of 27. STRAIGHT [15], a high-quality analysis and synthesis algorithm, was used to estimate the spectrum and F0 contours at a frame rate of 10 ms. Continuous F0 contour was formed from the step described in [16], which led to approximation of the original F0 consonants, consisting of third-order polynomial segments. For input of the neural network, a number of textual features was extracted from the raw text. Table 1 illustrates the characteristics eligible for this work. The phoneme consists of 30 consonants and 16 vowels. Max syllable length 6 and max 10 syllable values were taken into account, and the cognitive help of the coding language was sufficient to recreate these features from the ocoding language."}, {"heading": "3.1. DBN Training", "text": "The input into the DBN was binary, i.e. we used Bernoulli-Bernoulli-RBM. 7000 sets are selected from the corpus to train the DBN. Each DBN layer was pre-trained for 50 epochs as an RBM with a mini-charge of size 10. Average gradients were calculated on the mini-batches and parameters were updated with a learning rate of 0.002 and a pulse of 0.95."}, {"heading": "3.2. DNN Training", "text": "DNN is pre-trained by the DBN, which means that the weights of the DNN are initialized by the trained DBN. To refine the DNN 1000 records (with the exception of the previous 7000), they are taken from the CRBLP corpus and phonetically aligned with the HTK toolkit (5-state HMM). Finally, the phonetic limits are corrected manually. Of the 1000 records, 500 are selected to train, 200 for cross-validation, 300 for testing the DNN. The output of the DNN are log-F0 values corresponding to each phoneme state. This is because records are segmented with 5-state HMMs, which result in 5 states for each phoneme or each observation, which is approximately 1 / 5 of the phoneme. F0 values corresponding to each state were calculated from the continued F0 satisfaction with the enduring information generated by HTK. These F0 values act like the output of DNN."}, {"heading": "3.3. Synthesis Stage", "text": "Figure 2 shows the synthesis process of the proposed system. It consists of two main parts - the generation of the head and the duration and the prediction of the F0 values. At the synthesis time, the same characteristics were extracted for each phoneme and transferred to the DNN. Using previously trained weights DNN then forecast the F0 values. From the HTS phoneme duration model, the duration of each state was extracted. On the basis of the F0 values, a cubic spline interpolation with the duration information was performed so that the resulting F0 has the same length."}, {"heading": "4. RESULTS AND EVALUATION", "text": "In order to compare the proposed model with the Multi-Space Probability Distribution Model (MSD-HMM) F0 included in the HTS Synthesis Motor Toolkit [17], a Bengal HTS [18] system is constructed using HTS 2.2 with a 34th order MGC coefficient, a time window of 10 ms, a shift of 5 ms and a frequency wrapping factor of 0.53."}, {"heading": "4.1. Objective Evaluation and Model Selection", "text": "Two types of metrics have been calculated for objective evaluation, i.e. crosscorrelation (XCORR) and root mean square error (RMSE). Several DNN architectures have been constructed and their performance is evaluated using these two metrics. Figure 3 illustrates the different RMSE and XCORR values of the predicted F0 values on the test set (300 sets). Figure 3 shows that XCORR improves as the hidden layer size in the test set increases, but the performance of RMSE decreases. Therefore, we choose DBN-DNN (120U-7L), which provides the best performance according to the two metrics (RMSE 17 and XCORR 0.64). Table 2 shows the objective test results performed on the test set between MSD-HMM and DBN-DNN. DBN-DNN (120U-7L) is selected for subjective evaluation."}, {"heading": "4.2. Subjective Evaluation", "text": "For the subjective measurement, ABX is performed with 5 subjects (3 male, 2 female), all of whom are not language experts and are native Bengali speakers. In this experiment, the 50 test sets are synthesized using DBN-DNN (120U-7L) and MSD-HMM. Subjects are asked to choose their preferred set. Figure 4 shows that 82% of the subjects have a preference for one of the two systems and the majority (54% vs 46%) prefer a proposed system, which is statistically significant at p < 0.001."}, {"heading": "5. CONCLUSION & FUTURE WORKS", "text": "In this thesis, we used Deep Belief Network (DBN) to model the F0 contour of synthesized language generated by the HMM-based speech synthesis system. DBN acted as a high-grade character extractor from the raw input text. Neural network is trained for each phoneme, i.e. for input of textual features of the neural network (phoneme identity, number of syllables, etc.) and for output normalized log-F0 values are used. Although the entire experiment is conducted in Bengali language, it can be applied to all languages. Objective metrics and subjective tests indicate that the proposed model has a greater preference than the MSD-HMM-based model found in many standard text-to-speech synthesis systems."}, {"heading": "6. REFERENCES", "text": "[1] Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh, \"A deep learning algorithm for deep belief nets,\" Neural computation, vol. 18, no. 7, pp. 1527-1554, 2006. [2] Volodymyr Mnih and Geoffrey E Hinton, \"Learning to detect roads in high-resolution aerial images,\" in Computer Vision-ECCV 2010, pp. 210-223. Springer, 2010. [3] Ronan Collobert and Jason Weston, \"A unified architecture for natural language processing: Deep neural networks with multitask learning,\" in Proceedings of the 25th international conference on Machine learning (ICML). [4] Li Deng, Michael L Seltzer, Dong Yu, Alex Acero, Abdel-rahman Mohamed, and Geoffrey E. \""}], "references": [{"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning to detect roads in high-resolution aerial images", "author": ["Volodymyr Mnih", "Geoffrey E Hinton"], "venue": "Computer Vision\u2013ECCV 2010, pp. 210\u2013223. Springer, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston"], "venue": "Proceedings of the 25th international conference on Machine learning (ICML). ACM, 2008, pp. 160\u2013167.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Binary coding of speech spectrograms using a deep autoencoder", "author": ["Li Deng", "Michael L Seltzer", "Dong Yu", "Alex Acero", "Abdel-rahman Mohamed", "Geoffrey E Hinton"], "venue": "INTERSPEECH. Citeseer, 2010, pp. 1692\u2013 1695.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["George E Dahl", "Dong Yu", "Li Deng", "Alex Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "A deep neural network for acoustic-articulatory speech inversion", "author": ["Benigno Uria", "Steve Renals", "Korin Richmond"], "venue": "NIPS Workshop on Deep Learning Unsupervised Feature Learning, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["Heiga Zen", "Andrew Senior", "Mike Schuster"], "venue": "ICASSP, 2013, pp. 7962\u20137966.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Multidistribution deep belief network for speech synthesis", "author": ["Shiyin Kang", "Xiaojun Qian", "Helen Meng"], "venue": "International Conference on Acoustics, Speech and  Signal Processing (ICASSP). IEEE, 2013, pp. 8012\u2013 8016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Modeling spectral envelopes using restricted boltzmann machines and deep belief networks for statistical parametric speech synthesis", "author": ["Z-H Ling", "Li Deng", "Dong Yu"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 21, no. 10, pp. 2129\u20132139, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "F0 contour prediction with a deep belief network-gaussian process hybrid model", "author": ["Raul Fernandez", "Asaf Rendel", "Bhuvana Ramabhadran", "Ron Hoory"], "venue": "International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2013, pp. 6885\u20136889.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Exponential family harmoniums with an application to information retrieval", "author": ["Max Welling", "Michal Rosen-Zvi", "Geoffrey E Hinton"], "venue": "Advances in neural information processing systems, 2004, pp. 1481\u20131488.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["Geoffrey E Hinton"], "venue": "Neural computation, vol. 14, no. 8, pp. 1771\u20131800, 2002.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning deep generative models, Ph.D", "author": ["Ruslan Salakhutdinov"], "venue": "thesis, University of Toronto,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Development of annotated bangla speech corpora, spoken language technologies for under-resourced language", "author": ["Sultana Dil Afroza Alam Firoj", "Habib S.M. Murtoza", "Khan Mumit"], "venue": "Proceedings of (SLTU10). Penang, Malasia, 2010, vol. 1, pp. 35 \u2013 41.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Speech representation and transformation using adaptive interpolation of weighted spectrum: vocoder revisited", "author": ["Hideki Kawahara"], "venue": "International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1997, vol. 2, pp. 1303\u20131306.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1997}, {"title": "A method for automatic extraction of model parameters from fundamental frequency contours of speech", "author": ["Shuichi Narusawa", "Nobuaki Minematsu", "Keikichi Hirose", "Hiroya Fujisaki"], "venue": "International Conference on Acoustics, Speech, and Signal Processing (ICASSP). IEEE, 2002, vol. 1, pp. I\u2013509.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "A bengali hmm based speech synthesis system", "author": ["Sankar Mukherjee", "Shyamal Kumar Das Mandal"], "venue": "International Conference on Speech Database and Assessments (Oriental COCOSDA), 2012, pp. 225\u2013259.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "The training of DBN as described in [1] is to first initialize the weights of each layer greedily in a purely unsupervised way and then fine-tune all the weights jointly to further improve the likelihood.", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "DBN-DNN (DNN pre-trained by DBN and fine-tune by labeled data) is successfully applied in speech, audio, image and text data [2] [3].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "DBN-DNN (DNN pre-trained by DBN and fine-tune by labeled data) is successfully applied in speech, audio, image and text data [2] [3].", "startOffset": 129, "endOffset": 132}, {"referenceID": 3, "context": "In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN).", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN).", "startOffset": 132, "endOffset": 135}, {"referenceID": 5, "context": "In recent years, DBNs have been successfully applied to modeling speech signals, such as spectrogram coding [4], speech recognition [5], and acousticarticulatory inversion mapping [6], where they mainly act as the pre-training methods for a deep autoencoder or a deep neural network (DNN).", "startOffset": 180, "endOffset": 183}, {"referenceID": 6, "context": "In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].", "startOffset": 92, "endOffset": 95}, {"referenceID": 7, "context": "In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].", "startOffset": 96, "endOffset": 99}, {"referenceID": 8, "context": "In statistical parametric speech synthesis domain DBNs have also been studied very recently [7] [8] [9].", "startOffset": 100, "endOffset": 103}, {"referenceID": 7, "context": "Use of DBN to model F0 contour [8] [10] was not new.", "startOffset": 31, "endOffset": 34}, {"referenceID": 9, "context": "Use of DBN to model F0 contour [8] [10] was not new.", "startOffset": 35, "endOffset": 39}, {"referenceID": 9, "context": "But in [10] DBN was used as feature extractor for Gaussian Process Regression which is a non-parametric model.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "other aspect was rather than discontinues F0 contour [8] we train the DNN with continues F0 contour which adds simplicity to the model.", "startOffset": 53, "endOffset": 56}, {"referenceID": 10, "context": "The weights between the connections of the visible units v and hidden units h define a probability distribution over the visible units v via an energy function [11].", "startOffset": 160, "endOffset": 164}, {"referenceID": 11, "context": "But, Emodel(vi, hj) is computationally very expensive to compute so the contrastive divergence (CD) algorithm [12] to the gradient is used where Edata(vi, hj) is replaced by running the Gibbs sampler initialized at the data for one full step.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "Therefore, a greedy learning algorithm has been proposed and popularly applied to train the DBN in a layer-by-layer manner [1].", "startOffset": 123, "endOffset": 126}, {"referenceID": 0, "context": "It has been proved that this greedy learning algorithm can improve the lower bound on the log-likelihood of the training samples by adding each new hidden layer [1] [13].", "startOffset": 161, "endOffset": 164}, {"referenceID": 12, "context": "It has been proved that this greedy learning algorithm can improve the lower bound on the log-likelihood of the training samples by adding each new hidden layer [1] [13].", "startOffset": 165, "endOffset": 169}, {"referenceID": 12, "context": "AIS-based partition function estimation with approximate inference [13] used to estimate the lower bound on the log-probability.", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "speech corpus [14] is employed here for the whole experiment and it consists of one male voice of age 27.", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "STRAIGHT [15], a high-quality analysis and synthesis algorithm, was adopted to estimate the spectrum and F0 contours with 10-ms frame rate.", "startOffset": 9, "endOffset": 13}, {"referenceID": 15, "context": "Continues F0 contour was formed using step described in [16] which resulted an approximation of original F0 contour consisting of third order polynomial segments.", "startOffset": 56, "endOffset": 60}, {"referenceID": 9, "context": "of syllable in current word [10]", "startOffset": 28, "endOffset": 32}, {"referenceID": 11, "context": "Phoneme position in syllable [Forward/Backward] 6 * 2 = [12]", "startOffset": 56, "endOffset": 60}, {"referenceID": 16, "context": "of phonemes in syllable [Previous/Current/Next] 6 * 3 = [18]", "startOffset": 56, "endOffset": 60}, {"referenceID": 5, "context": "Vowel position in syllable [Forward] [6]", "startOffset": 37, "endOffset": 40}, {"referenceID": 15, "context": "Vowel identity in the syllable [16] Total 220", "startOffset": 31, "endOffset": 35}, {"referenceID": 16, "context": "In order to compare the proposed model against the clustering tree with multi-space probability distribution (MSD-HMM) F0 model included in the HTS synthesis engine toolkit [17], a Bengali-HTS [18] system is constructed.", "startOffset": 193, "endOffset": 197}], "year": 2015, "abstractText": "In recent years multilayer perceptrons (MLPs) with many hidden layers Deep Neural Network (DNN) has performed surprisingly well in many speech tasks, i.e. speech recognition, speaker verification, speech synthesis etc. Although in the context of F0 modeling these techniques has not been exploited properly. In this paper, Deep Belief Network (DBN), a class of DNN family has been employed and applied to model the F0 contour of synthesized speech which was generated by HMM-based speech synthesis system. The experiment was done on Bengali language. Several DBN-DNN architectures ranging from four to seven hidden layers and up to 200 hidden units per hidden layer was presented and evaluated. The results were compared against clustering tree techniques popularly found in statistical parametric speech synthesis. We show that from textual inputs DBN-DNN learns a high level structure which in turn improves F0 contour in terms of objective and subjective tests.", "creator": "LaTeX with hyperref package"}}}