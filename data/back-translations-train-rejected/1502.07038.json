{"id": "1502.07038", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2015", "title": "Web-scale Surface and Syntactic n-gram Features for Dependency Parsing", "abstract": "We develop novel first- and second-order features for dependency parsing based on the Google Syntactic Ngrams corpus, a collection of subtree counts of parsed sentences from scanned books. We also extend previous work on surface $n$-gram features from Web1T to the Google Books corpus and from first-order to second-order, comparing and analysing performance over newswire and web treebanks.", "histories": [["v1", "Wed, 25 Feb 2015 03:27:38 GMT  (30kb,D)", "http://arxiv.org/abs/1502.07038v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dominick ng", "mohit bansal", "james r curran"], "accepted": false, "id": "1502.07038"}, "pdf": {"name": "1502.07038.pdf", "metadata": {"source": "CRF", "title": "Web-scale Surface and Syntactic n-gram Features for Dependency Parsing", "authors": ["Dominick Ng", "Mohit Bansal", "James R. Curran"], "emails": ["@-lab,", "dominick.ng@sydney.edu.au", "james.r.curran@sydney.edu.au", "mbansal@ttic.edu"], "sections": [{"heading": null, "text": "We are developing novel first and second order functionality for dependency analysis based on the Google Syntactic Ngrams Corpus, a collection of sub-tree counts of analyzed sentences from scanned books. We are also extending previous work on superficial n-gram features from Web1T to Google Books Corpus and from first to second order, and comparing and analyzing performance across newswire and web tree banks. Both surface and syntactic n-grams lead to significant and complementary gains in analytical accuracy across domains. Our best system combines the two functionality sets, achieving up to 0.8% absolute UAS improvements in messaging wire and 1.4% in web text."}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "4 Experimental Setup", "text": "As with Bansal and Klein (2011) and Pitler (2012), we transform Penn Treebank into dependencies by using pennant converters 3 (Johansson and Nugues, 2007) (henceforth LTH) and generating POS tags with MXPOST (Ratnaparkhi, 1996). We used Sections 02-21 of the WSJ for training, 22 for development, and 23 for final testing. We used MSTParser (McDonald and Pereira, 2006), trained with the parameters order: 2, training-k: 5, iters: 10, and loss-type: nopunc. We leave marked attach3 http: / / nlp.cl.thse software / WAS in compliance with the values, but do not comply with the WAS / WAS."}, {"heading": "5 Results", "text": "Table 2 summarizes our results on the WSJ development and test datasets, as well as the SANCL 2012 test datasets. All of our features are very similar: Each feature in isolation provides an average improvement in UAS of about 0.5% over the base saver of the WSJ development and test phases. In the non-domain web treebank, surface and syntactic features improve over the baseline by about 0.8-1.0% over the test phases. All of our results are also statistically significant improvements over the base bank. While our syntactic n gram numbers are calculated using Stanford dependencies and almost certainly contain significant parser and OCR errors, they still provide a significant performance improvement in LTH parsing. In addition, the Syntactical Ngram dataset is derived from a wide variety of genres, but helps capture message wire and web text parameters, the best results are performed on top of both TH and TH synchronization systems, which are also used in Google's second row synchronization systems."}, {"heading": "6 Analysis", "text": "This year it is as far as never before in the history of the city, where it is as far as never before that it is a place where it is a place, it is a place."}, {"heading": "6.1 Future Work", "text": "A combination of features from all the sources used in this paper would be interesting for further study, especially since these features seem to be very complementary. We could also explore more of the notes on POS and head modifiers in the Google Books ngram corpus to develop features that strike a balance between surface and syntactic n-gram characteristics. Google Books corpora and syntactic ngrams both deliver frequencies by date, and it would be interesting to examine how well features extracted from different date ranges would work - especially for texts from roughly the same ages. Redesigning Web1T to reduce it to a comparable corpus the size of Google Books would also provide better insight into how many n-gram noises are."}, {"heading": "7 Related Work", "text": "In addition to Bansal and Klein (2011), other feature-based approaches have been used to improve dependency analysis, including Pitler (2012), which uses Brown clusters and point-by-point mutual information on the counting of n-gram surfaces to specifically address PP and coordination errors. Chen et al. (2013) describe a novel method of generating meta-traits that work to highlight important characteristic types used by the parser. Chen et al. (2009) generate sub-tree-based traits that are similar to ours. However, they use the domain-internal BLLIP message wire corpus to generate their sub-tree counts, while the syntactic gram corpus is outside the domain and is an order of magnitude larger. They also use the same underlying parser to generate the BLLIP subtree counts and as the last test time pars, while syntactical parameters are systematically compared with a shift diagram of STLIP only during scanning."}, {"heading": "8 Conclusion", "text": "We developed dependency analysis capabilities based on sub-tree counts of 345 billion words read from scanned English books. We expanded existing work on interface n-grams from the first order to the second, and investigated the usefulness of web text and scanned books as sources for interface n-grams. Our individual feature sets all work similarly, offering significant improvements in analytical accuracy of about 0.5% in messaging wire and up to 1.0% on average across web tree domains. They also complement each other as our best system combines interface and syntactic n-gram capabilities to achieve improvements in UAS of 1.3% in messaging wire and 1.6% in web text. We hope that our work will encourage further efforts to unify different sources of unmarked and automatically read data for dependency analysis, taking into account the relative strengths and weaknesses of each source."}], "references": [{"title": "Web-Scale Features for Full-Scale Parsing", "author": ["Mohit Bansal", "Dan Klein."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 693\u2013702.", "citeRegEx": "Bansal and Klein.,? 2011", "shortCiteRegEx": "Bansal and Klein.", "year": 2011}, {"title": "Improving Dependency Parsing with Subtrees from Auto-Parsed Data", "author": ["Wenliang Chen", "Jun\u2019ichi Kazama", "Kiyotaka Uchimoto", "Kentaro Torisawa"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "SemiSupervised Feature Transformation for Dependency Parsing", "author": ["Wenliang Chen", "Min Zhang", "Yue Zhang."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303\u20131313.", "citeRegEx": "Chen et al\\.,? 2013", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "A Dataset of Syntactic-Ngrams over Time from a Very Large Corpus of English Books", "author": ["Yoav Goldberg", "Jon Orwant."], "venue": "Proceedings of the 2nd Joint Conference on Lexical and Computational Semantics, pages 241\u2013247.", "citeRegEx": "Goldberg and Orwant.,? 2013", "shortCiteRegEx": "Goldberg and Orwant.", "year": 2013}, {"title": "Extended Constituent-to-dependency Conversion for English", "author": ["Richard Johansson", "Pierre Nugues."], "venue": "Proceedings of the 16th Nordic Conference of Computational Linguistics, pages 105\u2013112.", "citeRegEx": "Johansson and Nugues.,? 2007", "shortCiteRegEx": "Johansson and Nugues.", "year": 2007}, {"title": "Online Learning of Approximate Dependency Parsing Algorithms", "author": ["Ryan McDonald", "Fernando Pereira."], "venue": "Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 81\u201388.", "citeRegEx": "McDonald and Pereira.,? 2006", "shortCiteRegEx": "McDonald and Pereira.", "year": 2006}, {"title": "Using the Web as an Implicit Training Set: Application to Structural Ambiguity Resolution", "author": ["Preslav Nakov", "Marti Hearst."], "venue": "Proceedings of the 2005 Human Language Technology Conference and Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Nakov and Hearst.,? 2005", "shortCiteRegEx": "Nakov and Hearst.", "year": 2005}, {"title": "Overview of the 2012 Shared Task on Parsing the Web", "author": ["Slav Petrov", "Ryan McDonald."], "venue": "Notes of the First Workshop on the Syntactic Analysis of NonCanonical Language.", "citeRegEx": "Petrov and McDonald.,? 2012", "shortCiteRegEx": "Petrov and McDonald.", "year": 2012}, {"title": "Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations", "author": ["Emily Pitler."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 768\u2013776.", "citeRegEx": "Pitler.,? 2012", "shortCiteRegEx": "Pitler.", "year": 2012}, {"title": "Using Web-scale N-grams to Improve Base NP Parsing Performance", "author": ["Emily Pitler", "Shane Bergsma", "Dekang Lin", "Kenneth Church."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, pages 886\u2013894.", "citeRegEx": "Pitler et al\\.,? 2010", "shortCiteRegEx": "Pitler et al\\.", "year": 2010}, {"title": "A Maximum Entropy Model for Part-of-Speech Tagging", "author": ["Adwait Ratnaparkhi."], "venue": "Proceedings of the 1996 Conference on Empirical Methods in Natural Language Processing, pages 133\u2013142.", "citeRegEx": "Ratnaparkhi.,? 1996", "shortCiteRegEx": "Ratnaparkhi.", "year": 1996}, {"title": "Exploiting the WWW as a corpus to resolve PP attachment ambiguities", "author": ["Martin Volk."], "venue": "Proceedings of the Corpus Linguistics 2001 Conference, pages 601\u2013 606.", "citeRegEx": "Volk.,? 2001", "shortCiteRegEx": "Volk.", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Features from n-gram counts over resources like Web1T (Brants and Franz, 2006) have proven to be useful proxies for syntax (Bansal and Klein, 2011; Pitler, 2012), but they enforce linear word order, and are unable to distinguish between syntactic and non-syntactic co-occurrences.", "startOffset": 123, "endOffset": 161}, {"referenceID": 8, "context": "Features from n-gram counts over resources like Web1T (Brants and Franz, 2006) have proven to be useful proxies for syntax (Bansal and Klein, 2011; Pitler, 2012), but they enforce linear word order, and are unable to distinguish between syntactic and non-syntactic co-occurrences.", "startOffset": 123, "endOffset": 161}, {"referenceID": 5, "context": "In this paper we develop new features for the graph-based MSTParser (McDonald and Pereira, 2006) from the Google Syntactic Ngrams corpus", "startOffset": 68, "endOffset": 96}, {"referenceID": 3, "context": "(Goldberg and Orwant, 2013), a collection of Stanford dependency subtree counts.", "startOffset": 0, "endOffset": 27}, {"referenceID": 7, "context": "formance of our syntactic n-gram features against the surface n-gram features of Bansal and Klein (2011) in-domain on newswire and out-of-domain on the English Web Treebank (Petrov and McDonald, 2012) across CoNLL-style (LTH) dependencies.", "startOffset": 173, "endOffset": 200}, {"referenceID": 0, "context": "formance of our syntactic n-gram features against the surface n-gram features of Bansal and Klein (2011) in-domain on newswire and out-of-domain on the English Web Treebank (Petrov and McDonald, 2012) across CoNLL-style (LTH) dependencies.", "startOffset": 81, "endOffset": 105}, {"referenceID": 3, "context": "The Google Syntactic Ngrams English (2013) corpus1 contains counts of dependency tree fragments over a 345 billion word selection of the Google Books data, parsed with a beam-search shift-reduce parser and Stanford dependencies (Goldberg and Orwant, 2013).", "startOffset": 228, "endOffset": 255}, {"referenceID": 0, "context": "We also develop paraphrase-style features like those of Bansal and Klein (2011) based on the most frequently occurring words and POS tags before, in between, and after each head-argument ambiguity (see Section 3.", "startOffset": 56, "endOffset": 80}, {"referenceID": 0, "context": "We extract Bansal and Klein (2011)\u2019s affinity and paraphrase-style first-order features from the Google Books English Ngrams corpus, and compare their", "startOffset": 11, "endOffset": 35}, {"referenceID": 8, "context": "Pitler et al. (2010) has documented a number of sources of noise in the corpus, including duplicate sentences (such as legal disclaimers and boilerplate text), dispropor-", "startOffset": 0, "endOffset": 21}, {"referenceID": 6, "context": "Affinity features rely on the intuition that frequently co-occurring words in large unlabeled text collections are likely to be in a syntactic relationship (Nakov and Hearst, 2005; Bansal and Klein, 2011).", "startOffset": 156, "endOffset": 204}, {"referenceID": 0, "context": "Affinity features rely on the intuition that frequently co-occurring words in large unlabeled text collections are likely to be in a syntactic relationship (Nakov and Hearst, 2005; Bansal and Klein, 2011).", "startOffset": 156, "endOffset": 204}, {"referenceID": 6, "context": "Nakov and Hearst (2005) propose several static patterns to resolve a variety of nominal and prepositional attachment ambiguities.", "startOffset": 0, "endOffset": 24}, {"referenceID": 0, "context": "In Bansal and Klein (2011), paraphrase features are generated for all full-parse attachment ambiguities from the surface n-gram corpus.", "startOffset": 3, "endOffset": 27}, {"referenceID": 4, "context": "As with Bansal and Klein (2011) and Pitler (2012), we convert the Penn Treebank to dependencies using pennconverter3 (Johansson and Nugues, 2007) (henceforth LTH) and generate POS tags with MXPOST (Ratnaparkhi, 1996).", "startOffset": 117, "endOffset": 145}, {"referenceID": 10, "context": "As with Bansal and Klein (2011) and Pitler (2012), we convert the Penn Treebank to dependencies using pennconverter3 (Johansson and Nugues, 2007) (henceforth LTH) and generate POS tags with MXPOST (Ratnaparkhi, 1996).", "startOffset": 197, "endOffset": 216}, {"referenceID": 7, "context": "The test sections of the answers, newsgroups, and reviews sections of the English Web Treebank as per the SANCL 2012 Shared Task (Petrov and McDonald, 2012) were converted to LTH and used for out-of-domain evaluation.", "startOffset": 129, "endOffset": 156}, {"referenceID": 5, "context": "We used MSTParser (McDonald and Pereira, 2006), trained with the parameters order:2, training-k:5, iters:10, and loss-type:nopunc.", "startOffset": 18, "endOffset": 46}, {"referenceID": 0, "context": "As with Bansal and Klein (2011) and Pitler (2012), we convert the Penn Treebank to dependencies using pennconverter3 (Johansson and Nugues, 2007) (henceforth LTH) and generate POS tags with MXPOST (Ratnaparkhi, 1996).", "startOffset": 8, "endOffset": 32}, {"referenceID": 0, "context": "As with Bansal and Klein (2011) and Pitler (2012), we convert the Penn Treebank to dependencies using pennconverter3 (Johansson and Nugues, 2007) (henceforth LTH) and generate POS tags with MXPOST (Ratnaparkhi, 1996).", "startOffset": 8, "endOffset": 50}, {"referenceID": 3, "context": "that we have discussed as helping resolve these issues, it is unsurprising that syntactic n-gram features using the counts from the Goldberg and Orwant (2013) parser are less effective.", "startOffset": 132, "endOffset": 159}, {"referenceID": 3, "context": "Additionally, a post-hoc analysis of the types of errors present in the corpus is impossible due to the exclusion of the full parse trees, though Goldberg and Orwant (2013) note that this data would almost certainly be computationally prohibitive to process.", "startOffset": 146, "endOffset": 173}, {"referenceID": 11, "context": "Surface n-gram counts from large web corpora have been used to address NP and PP attachment errors (Volk, 2001; Nakov and Hearst, 2005) Aside from Bansal and Klein (2011), other feature-based approaches to improving dependency parsing in-", "startOffset": 99, "endOffset": 135}, {"referenceID": 6, "context": "Surface n-gram counts from large web corpora have been used to address NP and PP attachment errors (Volk, 2001; Nakov and Hearst, 2005) Aside from Bansal and Klein (2011), other feature-based approaches to improving dependency parsing in-", "startOffset": 99, "endOffset": 135}, {"referenceID": 0, "context": "Surface n-gram counts from large web corpora have been used to address NP and PP attachment errors (Volk, 2001; Nakov and Hearst, 2005) Aside from Bansal and Klein (2011), other feature-based approaches to improving dependency parsing in-", "startOffset": 147, "endOffset": 171}, {"referenceID": 6, "context": "clude Pitler (2012), who exploits Brown clusters and point-wise mutual information of surface n-gram counts to specifically address PP and coordination errors.", "startOffset": 6, "endOffset": 20}, {"referenceID": 1, "context": "Chen et al. (2013) describe a novel way of generating meta-features that work to emphasise important feature types used by the parser.", "startOffset": 0, "endOffset": 19}], "year": 2015, "abstractText": "We develop novel firstand second-order features for dependency parsing based on the Google Syntactic Ngrams corpus, a collection of subtree counts of parsed sentences from scanned books. We also extend previous work on surface n-gram features from Web1T to the Google Books corpus and from first-order to second-order, comparing and analysing performance over newswire and web treebanks. Surface and syntactic n-grams both produce substantial and complementary gains in parsing accuracy across domains. Our best system combines the two feature sets, achieving up to 0.8% absolute UAS improvements on newswire and 1.4% on web text.", "creator": "LaTeX with hyperref package"}}}