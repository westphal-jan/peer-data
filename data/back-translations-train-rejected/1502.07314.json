{"id": "1502.07314", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2015", "title": "Path Finding under Uncertainty through Probabilistic Inference", "abstract": "We introduce a new approach to solving path-finding problems under uncertainty by representing them as probabilistic models and applying domain-independent inference algorithms to the models. This approach separates problem representation from the inference algorithm and provides a framework for efficient learning of path-finding policies. We evaluate the new approach on the Canadian Traveler Problem, which we formulate as a probabilistic model, and show how probabilistic inference allows high performance stochastic policies to be obtained for this problem.", "histories": [["v1", "Wed, 25 Feb 2015 19:21:04 GMT  (124kb,D)", "https://arxiv.org/abs/1502.07314v1", null], ["v2", "Sat, 2 May 2015 21:53:39 GMT  (130kb,D)", "http://arxiv.org/abs/1502.07314v2", null], ["v3", "Mon, 8 Jun 2015 05:02:53 GMT  (130kb,D)", "http://arxiv.org/abs/1502.07314v3", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david tolpin", "brooks paige", "jan willem van de meent", "frank wood"], "accepted": false, "id": "1502.07314"}, "pdf": {"name": "1502.07314.pdf", "metadata": {"source": "CRF", "title": "Path Finding under Uncertainty through Probabilistic Inference", "authors": ["David Tolpin", "Brooks Paige", "Jan Willem van de Meent", "Frank Wood"], "emails": ["dtolpin@robots.ox.ac.uk", "brooks@robots.ox.ac.uk", "jwvdm@robots.ox.ac.uk", "fwood@robots.ox.ac.uk"], "sections": [{"heading": "Introduction", "text": "In most cases, the optimal policy cannot be precisely identified, and approximations are used to label the policy either explicitly or as an implicit feature of the planning algorithm."}, {"heading": "Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probabilistic Programming", "text": "Probabilistic programs are regular programs that are augmented by two constructs (Gordon et al. 2014): \u2022 The ability to draw random values from probability distributions. \u2022 The ability to condition the values calculated in the programs on probability distributions. A probabilistic program implicitly defines a probability distribution over the results of the program. Formally, we define a probabilistic program as a handsome deterministic calculation P with the following properties: \u2022 Initially, P does not expect any arguments.ar Xiv: 150 2.07 314v 3 [cs.A] 8 Jun 201 5 \u2022 On each call, P returns either a distribution F, a distribution and a value (G, y), a value z or a value. \u2022 On return F, P expects a value x drawn from F as an argument to continue. \u2022 On return (G, y) or z, P is called again without arguments. \u2022 On return of P, the ability of the algorithms is denounced."}, {"heading": "Canadian Traveller Problem", "text": "There are several variants of CTP (Bar-Noy and Slider 1991; Nikolova and Karger 2008; Bnaya, Felner and Shimony 2009); here we look at the stochastic version. In stochastic CTP we get \u2022 undirected weighted graph G = (V, E). \u2022 The initial and final location nodes s and t. \u2022 Edge weights w: E \u2192 R. \u2022 Traversability probabilities: po: E \u2192 (0, 1]. The actual state of each edge is determined for each case of problems, but is only known when one of the peripheral points is reached. The goal is to find a policy that minimizes the expected travel distance from s to t. The travel distance is the sum of the weights of all the edges traversed during the journey, where the actual problem is compared in each direction, is a high number of opposites (SPY)."}, {"heading": "Duality between Path Finding and", "text": "This link has been noted before (Shimony and Charniak 1991) and has been used to search for the maximum a-posteriori probability (MAP) in graphical models using a best-first search algorithm. Here, we expand the analogy further and establish a bilateral correspondence between the distribution defined by a probabilistic model and learning the optimal policy in a path-finding problem. We proceed in two steps. First, we establish a link between an MAP mapping and the shortest path. Then, on the basis of this analogy, we explain how the optimal policy in a generative model can be translated into the output distribution of a probabilistic program and vice versa."}, {"heading": "Stochastic Policy Learning through", "text": "Probabilistic InferenceWe have shown that they need to derive the optimal policy to solve the problem."}, {"heading": "Case Study: Canadian Traveller Problem", "text": "In fact, it is so that it is a matter of a way in which people are able to determine themselves what they want and what they do not want. (...) In fact, it is so that they are able to determine themselves. (...) It is as if they were able to determine themselves. (...) It is as if they were able to determine themselves. (...) \"It is as if they were able to determine themselves. (...)\" (...) \"(...)\" (...) \"(...)\" (...) \"(...)\" (...) \"((...)\" (... \")\" (... \"()\" (() \"() (()\" () () (() \"() () (() () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () ()) () () () () () ()) () () () () () ()) () () () () () () () () ()) () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ("}, {"heading": "Discussion", "text": "The main contributions of the paper are: \u2022 Discovering the bilateral correspondence between probabilistic conclusions and political learning for pathfinding. \u2022 A new approach to political learning based on established correspondence. \u2022 A realization of the approach to the Canadian Traveler problem, where improved strategies were consistently learned through probabilistic program conclusions. \u2022 The proposed approach can be extended to many different planning problems, both in known path-finding applications and in other areas where political learning takes place under uncertainty; Partially observable Markov decision-making processes and generalized multi-armed bandit settings are just two examples. At the same time, exposure of probabilistic programming tools to different domains and new applications is a challenge. These tools were initially developed with specific applications in mind and our limited experience shows that probabilistic programming paradigms are well tailored to new applications and major problems."}], "references": [{"title": "and Schieber", "author": ["A. Bar-Noy"], "venue": "B.", "citeRegEx": "Bar.Noy and Schieber 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "R", "author": ["A.M. Becker", "Ziff"], "venue": "M.", "citeRegEx": "Becker and Ziff 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "S", "author": ["Z. Bnaya", "A. Felner", "Shimony"], "venue": "E.", "citeRegEx": "Bnaya. Felner. and Shimony 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Geffner", "author": ["B. Bonet"], "venue": "H.", "citeRegEx": "Bonet and Geffner 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "A survey of Monte Carlo tree search methods", "author": ["Browne"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on 4(1):1\u201343", "citeRegEx": "Browne,? \\Q2012\\E", "shortCiteRegEx": "Browne", "year": 2012}, {"title": "M", "author": ["P. Eyerich", "T. Keller", "Helmert"], "venue": "2010. High-quality policies for the Canadian traveler\u2019s problem. In Proc. of the Twenty-Fourth AAAI Conference on Artificial Intelligence, Atlanta, Georgia, USA, July 11-15,", "citeRegEx": "Eyerich. Keller. and Helmert 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "S", "author": ["Fried, D.", "Shimony"], "venue": "E.; Benbassat, A.; and Wenner, C.", "citeRegEx": "Fried et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "J", "author": ["N.D. Goodman", "V.K. Mansinghka", "D.M. Roy", "K. Bonawitz", "Tenenbaum"], "venue": "B.", "citeRegEx": "Goodman et al. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "S", "author": ["A.D. Gordon", "T.A. Henzinger", "A.V. Nori", "Rajamani"], "venue": "K.", "citeRegEx": "Gordon et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "New admissible heuristics for domain-independent planning", "author": ["Bonet Haslum", "P. Geffner 2005] Haslum", "B. Bonet", "H. Geffner"], "venue": "In Proceedings, The Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intel-", "citeRegEx": "Haslum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Haslum et al\\.", "year": 2005}, {"title": "S", "author": ["N. Hay", "S.J. Russell", "D. Tolpin", "Shimony"], "venue": "E.", "citeRegEx": "Hay et al. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "and Szepesv\u00e1ri", "author": ["L. Kocsis"], "venue": "C.", "citeRegEx": "Kocsis and Szepesv\u00e1ri 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Y", "author": ["V.K. Mansinghka", "D. Selsam", "Perov"], "venue": "N.", "citeRegEx": "Mansinghka. Selsam. and Perov 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "D", "author": ["E. Nikolova", "Karger"], "venue": "R.", "citeRegEx": "Nikolova and Karger 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Asynchronous anytime sequential Monte Carlo", "author": ["Paige"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Paige,? \\Q2014\\E", "shortCiteRegEx": "Paige", "year": 2014}, {"title": "and Yannakakis", "author": ["C.H. Papadimitriou"], "venue": "M.", "citeRegEx": "Papadimitriou and Yannakakis 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "and Wefald", "author": ["S. Russell"], "venue": "E.", "citeRegEx": "Russell and Wefald 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "and Charniak", "author": ["S.E. Shimony"], "venue": "E.", "citeRegEx": "Shimony and Charniak 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "M", "author": ["Sun, X.", "Druzdzel"], "venue": "J.; and Yuan, C.", "citeRegEx": "Sun. Druzdzel. and Yuan 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "A", "author": ["R.S. Sutton", "Barto"], "venue": "G.", "citeRegEx": "Sutton and Barto 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "Optimistic planning in markov decision processes using a generative model", "author": ["Kedenburg Sz\u00f6r\u00e9nyi", "B. Munos 2014] Sz\u00f6r\u00e9nyi", "G. Kedenburg", "R. Munos"], "venue": null, "citeRegEx": "Sz\u00f6r\u00e9nyi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sz\u00f6r\u00e9nyi et al\\.", "year": 2014}, {"title": "N", "author": ["D. Wingate", "A. Stuhlm\u00fcller", "Goodman"], "venue": "D.", "citeRegEx": "Wingate. Stuhlm\u00fcller. and Goodman 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "A new approach to probabilistic programming inference", "author": ["van de Meent Wood", "F. Mansinghka 2014] Wood", "J.W. van de Meent", "V. Mansinghka"], "venue": "In Artificial Intelligence and Statistics", "citeRegEx": "Wood et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wood et al\\.", "year": 2014}], "referenceMentions": [], "year": 2015, "abstractText": "We introduce a new approach to solving path-finding problems under uncertainty by representing them as probabilistic models and applying domain-independent inference algorithms to the models. This approach separates problem representation from the inference algorithm and provides a framework for efficient learning of path-finding policies. We evaluate the new approach on the Canadian Traveller Problem, which we formulate as a probabilistic model, and show how probabilistic inference allows high performance stochastic policies to be obtained for this problem.", "creator": "LaTeX with hyperref package"}}}