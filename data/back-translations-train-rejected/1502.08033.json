{"id": "1502.08033", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2015", "title": "SciRecSys: A Recommendation System for Scientific Publication by Discovering Keyword Relationships", "abstract": "In this work, we propose a new approach for discovering various relationships among keywords over the scientific publications based on a Markov Chain model. It is an important problem since keywords are the basic elements for representing abstract objects such as documents, user profiles, topics and many things else. Our model is very effective since it combines four important factors in scientific publications: content, publicity, impact and randomness. Particularly, a recommendation system (called SciRecSys) has been presented to support users to efficiently find out relevant articles.", "histories": [["v1", "Fri, 27 Feb 2015 19:35:24 GMT  (45kb,D)", "http://arxiv.org/abs/1502.08033v1", null]], "reviews": [], "SUBJECTS": "cs.DL cs.CL cs.IR", "authors": ["vu le anh", "vo hoang hai", "hung nghiep tran", "jason j jung"], "accepted": false, "id": "1502.08033"}, "pdf": {"name": "1502.08033.pdf", "metadata": {"source": "CRF", "title": "SciRecSys: a Recommendation System for Scientific Publication by Discovering Keyword Relationships", "authors": ["Vu Le Anh", "Hai Vo Hoang", "Hung Nghiep Tran", "Jason J. Jung", "Nguyen Tat Thanh"], "emails": ["lavu@ntt.edu.vn,", "vohoanghai2@gmail.com,", "nghiepth@uit.edu.vn,", "j2jung@gmail.com", "vohoanghai2@gmail.com."], "sections": [{"heading": null, "text": "Keywords: Keyword ranking, Keyword similarity, Keyword inference, Scientific Recommendation System, Bibliographical corpus"}, {"heading": "1 Introduction", "text": "Keyword-based search engines (Google, Bing Search and Yahoo) have emerged and dominate the Internet. The success of these search engines is based on the study of keyword relationships and keyword indexes. The task of measuring keyword relationships is the basic operation for building the related network of abstract objects that are applied in many problems and applications, such as document clustering, synonym extraction, plagiarism detection problem, taxonomy, search engine optimization, referral system, etc. In this work we focus on two problems. First, we study the rank, inference and similarity of keywords to scientific publications under the assumption that the keywords belong to a virtual ontology of keywords. The follow-up relationship will help us to find parents, children, the similarity relationship will help us find siblings of a particular keyword and the rank of keywords will determine how important they are. Second, we apply this relationship in our scientific referral system, Recoys Sciences."}, {"heading": "2 Related works", "text": "The similarity of keywords is often used as a crucial feature to reveal the relationship between objects and many methods of measuring similarity. A basis for similarity measurements is the use of distance functions such as square Euclidean distance, cosmic similarity, Jaccard coefficient, Pearsons correlation coefficient and relative entropy. Anna Huang et al. [6] has compared and analyzed the effectiveness of these measurements in text cluster problems, presents a document as a m-dimensional vector for the frequency of terms and uses a weighting scheme to measure their meaning by frequencies tf / idf. Singthongchai et al. [12] make keyword search more practical by calculating the similarity of keywords by combining Jaccards, N-gram and vector space. Probability models for similarity measurements have been studied in the language [4,3] Iagan et al."}, {"heading": "3 Backgrounds", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Basic definitions", "text": "Suppose K (p) K is the set of keywords that belong to p. P (A) = {q) P | A \u00b2 K (q)} is the set of papers that contains A. We assume that K (p) 6 = \u2205 P (A) 6 = \u2205.A pair (A, R) is referred to as a ranking system when: (i) A = {a1,..., an} is a finite set, and (ii) R is a non-negative function onA (i.e., R: A \u2192 [0, + \u2264). A ranking order on A can be represented as R = (a1), and (ii) R is a non-negative function onA (i.e., R: two events on A (i.e.), A (i.e., A) and S (ii)."}, {"heading": "3.2 Relationships of keywords based on the occurrences", "text": "Let us introduce two standardized rankings: Rc (A) = | P (A) | K, based on the events. Rc (c stands for counting) is based on the counting of the documents containing the given keyword.Rc (A) = | P (A) = 1 | P | B (P) | (A) K (P) (2) Rp (p stands for probability) is based on the probability of occurrence of the given keyword in the papers. Rp (A) = 1 | P | p \u00b2 P \u00b2 P (A) 1 | K (p) | (A \u00b2 K) (3) 1 | P | is the probability of selecting a paper from the corpus. 1 | K (p) | P is the probability of selecting the keyword A from the paper p, which contains | K (p) | keywords.We propose the following formulas for measuring the sequence and similarity of two keywords A, B based on occurrence: Ic (A) (A) (A) (A) (A) (A) (A) (A) (A | B (P) (P)."}, {"heading": "4 Relationships of keywords based on graph of keywords", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Markov Chain model of the reading process", "text": "We propose a Markov model to simulate the reading process, which can combine four factors: content, publicity, impact and randomness. We assume that the reading topic (keyword) A in any work p at any time (A, q). S = {(A, p). K \u00b7 P | A (A, K). (Same work - any topic.) The reader is interested in current work and randomly selects a topic in the same work with the probability 1. Thus p = q.Pr (Disruption probability) Pr (Disruption probability) Pr (4, following actions: - A1. Same work - any topic. The reader is interested in current work and randomly selects a topic in the same work with the same probability. Pr (Disruption probability) Pr (Disruption probability)."}, {"heading": "5. k = k + 1 stop = true", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. Foreach \u03b8 \u2208 S do", "text": "7. pr (\u03b8) (k) = 0 8. Foreach-Pr-S do Pr (\u03b8) (k) + = Pr-S do Pr-1 (k-1) Pr-S do Pr. 9. if-Pr-S do Pr (\u03b8) (k) \u2212 Pr-S do Pr (\u03b8) (k) | > then stop = wrong 10. to stop point 11. foreach-\u03b8-S do Pr (\u03b8) = Pr (k) (\u03b8)"}, {"heading": "12. end", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2 Ranking, Inference and Similarity of keywords", "text": "The rank of keyword A based on the transition graph, Rg (A) (g stands for graph), is equal to the probability that the user reads keyword A. We have: Rg (A) = 1: 1 (A) Pr (s) (\u03b8 = (A, p) 1: 2 (10) Let n0 be a positive integer. For each sequence s = 1: 2 (s), Pr (s) is the probability that s occurs in the Sn0 model of the Markov chain. F'Sn0, we denote Pr (F) = 1: 2 (s) FPr (s). For each keyword A, letP g (A) = 1: 2 (s)."}, {"heading": "5 SciRecSys - Recommendation System", "text": "In this paper, we want to present three scenarios using SciRecSys.Universal ranking vs. q-based ranking. (i) All results are sorted according to only one universal ranking, {Rgu (p)} p-P or (ii) The order of results depends on A with the keyword based ranking, {RgA (p)} p-P (A). We suggest that Rgu (p) is equal to the probability that the user reads p-papers. (ii) The order of results depends on A with the keyword based ranking, {RgA (p)} p-P (A). We suggest that RgA (p) is equal to the probability that the user reads p-papers."}, {"heading": "6 Experiments", "text": "We collect data from DBLP6 and Microsoft Academic Search7 (MAS) to conduct experiments. We select three sets of data for experiments in three different areas: (i) D1 are the publications of ICRA - International Conference on Robotics and Automation; (ii) D2 are the publications of ICDE - International Conference on Data Engineering (iii) D3 are the publications of GI Annual Meeting - Germany Conference in Computer Science. ICRA and ICDE conferences are one of the best known and largest in their field. They are selected for rich publications and citations."}, {"heading": "6.1 Experiments for rank scores", "text": "We conduct the experiments for three different rankings Rc, Rp and Rg. Values on {\u03b1i} 4i = 1 are selected to test different contexts, the rankings are scaled at the same speed for convenience, and for each of the two rankings we examine: (i) the rank correlation coefficient of the Spearman (designated \u03c1ij) for the monotonous check; (ii) the value differences: \u0445 ij (A) = Ri (A) \u2212 Rj (A),% \u0445 ij (A) = \u0445 ij (A) Rj (A). Here are some interesting observations: 6 http: / / dblp.uni-trier.de access December 2013 7 http: / / academic.research.microsoft.com / access to December 2013 - The rankings are monotonous, but quite different from each other."}, {"heading": "6.2 Experiments for Inference and Similarity", "text": "In this case, it is as if we are able to orient ourselves in a different direction than in a different direction, that is, in the direction in which we are. - It is as if we are able to orient ourselves in a different direction. - It is as if we are able to orient ourselves in a different direction. - It is as if we are able to orient ourselves in a different direction. - It is as if we are able to orient ourselves in a different direction. - It is as if we want to orient ourselves in a different direction. - It is as if we want to orient ourselves in a different direction. - It is as if we want to orient ourselves in a different direction. - It is as if we want to orient ourselves in a different direction. - It is as if we want to orient ourselves in a different direction."}, {"heading": "6.3 SciRecSys Recommendation System", "text": "We compare universal rankings Rgu (p) and local rankings R g A (p) and conduct experimental models for recommending keywords. We get some interesting results: - The universal ranking prefers the most popular papers, whereas the local ranking prefers that the papers are not only popular, but also focus on a small group of topics. See Tab. 6 (a). The top recommendations returned by Universal Ranking show a large number of quoting / quoting papers. While the top recommendations returned by Local Ranking have less quoting / quoting papers, their keywords are more specific. The average number of keywords in each recommended article of the Local Ranking and Universal Ranking is 2.25 and 6.75, respectively, with the exception of the most cited paper with ID = 395393. These numbers in D2 are 3.00 and 10.12. We note that the average number of keywords in a paper is about 2 and 3 for these two sets."}, {"heading": "7 Conclusion and future works", "text": "The proposed Markov chain model combines four main factors of the problem: content, publicity, impact and randomness. Stationary probability of states in the model helps us to evaluate and measure the conclusion and similarity of keywords. We have proposed the SciRecSys recommendation system for efficient navigation of scientific publications. By applying the relationships between keywords, we have proposed solutions for ranking results of a particular keyword, related keywords and recommended essays. Experiments have shown that our methods can reflect the quality of our ranking and measurement system and overcome the missing occurrence problem. Furthermore, our approach can effectively exploit the latent information of the citation network.As a future work, we plan to conduct experiments with large data sets to improve the quality of our ranking and measurement system, ii) investigate how to link sequence relationships by stationary probability graphs with a given ranking system, combining key systems, iverbatim problems in connection with events, and iverbatim problems with time systems."}], "references": [{"title": "A general model for mutual ranking systems", "author": ["V.L. Anh", "H.V. Hoang", "K.L. Trung", "H.L. Trung", "J.J. Jung"], "venue": "Nguyen, N.T., Attachoo, B., Trawinski, B., Somboonviwat, K. (eds.) Proceedings of the 6th Asian Conference on Intelligent Information and Database Systems (ACIIDS 2014), Bangkok, Thailand, April 7-9. Lecture Notes in Computer Science, vol. 8397, pp. 211\u2013220. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Measuring semantic similarity between words using web search engines", "author": ["D. Bollegala", "Y. Matsuo", "M. Ishizuka"], "venue": "Williamson, C.L., Zurko, M.E., Patel-Schneider, P.F., Shenoy, P.J. (eds.) Proceedings of the 16th International Conference on World Wide Web (WWW 2007), Banff, Alberta, Canada, May 8-12. pp. 757\u2013766. ACM", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Comprehensive survey on distance/similarity measures between probability density functions", "author": ["S.H. Cha"], "venue": "International Journal of Mathematical Models and Methods in Applied Sciences 1(4), 300\u2013307", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Similarity-based models of word cooccurrence probabilities", "author": ["I. Dagan", "L. Lee", "F.C.N. Pereira"], "venue": "Machine Learning 34(1-3), 43\u201369", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1999}, {"title": "Random-walk computation of similarities between nodes of a graph with application to collaborative recommendation", "author": ["F. Fouss", "A. Pirotte", "J.M. Renders", "M. Saerens"], "venue": "IEEE Transactions on Knowledge and Data Engineering 19(3), 355\u2013369", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Similarity measures for text document clustering", "author": ["A. Huang"], "venue": "Proceedings of 6th In New Zealand Computer Science Research Student Conference, Christchurch, New Zealand. pp. 49\u201356", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "The perron-frobenius theorem and the ranking of football teams", "author": ["J.P. Keener"], "venue": "SIAM review 35(1), 80\u201393", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1993}, {"title": "Mpagerank: The stability of web graph", "author": ["L.T. Kien", "L.T. Hieu", "T.L. Hung", "L.A. Vu"], "venue": "Vietnam Journal of Mathematics 37(4), 475\u2013489", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Content-based recommender systems: State of the art and trends", "author": ["P. Lops", "M. de Gemmis", "G. Semeraro"], "venue": "Ricci, F., Rokach, L., Shapira, B., Kantor, P. (eds.) Recommender Systems Handbook, chap. 3, pp. 73\u2013105. Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Ontology-based semantic similarity: A new feature-based approach", "author": ["D. S\u00e1nchez", "M. Batet", "D. Isern", "A. Valls"], "venue": "Expert Systems with Applications 39(9), 7718\u20137728", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Oss: A semantic similarity function based on hierarchical ontologies", "author": ["V. Schickel-Zuber", "B. Faltings"], "venue": "Veloso, M.M. (ed.) Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI 2007), Hyderabad, India, January 6-12. pp. 551\u2013556", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "A method for measuring keywords similarity by applying jaccard\u2019s, n-gram and vector space", "author": ["J. Singthongchai", "S. Niwattanakul"], "venue": "Lecture Notes on Information Theory 1(4), 159\u2013164", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "[6] has compared and analyzed the effectiveness of these measures in text clustering problem.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[12] make keywords search more practical by calculating keyword similarity by combining Jaccard\u2019s, N-Gram and Vector Space.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Probabilistic models for similarity measure has been studied in language speech [4,3].", "startOffset": 80, "endOffset": 85}, {"referenceID": 2, "context": "Probabilistic models for similarity measure has been studied in language speech [4,3].", "startOffset": 80, "endOffset": 85}, {"referenceID": 3, "context": "have proposed a bigram similarity model and used the relative entropy to compute the similarity of keywords [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 2, "context": "Sung-Hyuk Cha has conducted a comprehensive survey on probability density functions for similarity measures [3].", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "Ontology-based methods are also exploited to measure the similarity of keywords [2,11,10].", "startOffset": 80, "endOffset": 89}, {"referenceID": 10, "context": "Ontology-based methods are also exploited to measure the similarity of keywords [2,11,10].", "startOffset": 80, "endOffset": 89}, {"referenceID": 9, "context": "Ontology-based methods are also exploited to measure the similarity of keywords [2,11,10].", "startOffset": 80, "endOffset": 89}, {"referenceID": 1, "context": "[2] use the Wordnet database - ontology of words to measure keywords\u2019 relatedness by extracting lexico-syntactic patterns that indicate various aspects of semantic similarity and modifying four popular co-occurrence measures, including Jaccard, Overlap (Simpson), Dice, and Pointwise mutual information (PMI).", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Vincent Schickel-Zuber and Boi Falting [11] present a novel similarity measure for hierarchical ontologies called Ontology Structure based Similarity (OSS) that allows similarities to be asymmetric.", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "[10] presents an ontology-based method relying on the exploitation of taxonomic features available in an ontology.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Markov Chain model which properties are studied in [7,8] is used for computing the similarity and ranking [5,1].", "startOffset": 51, "endOffset": 56}, {"referenceID": 7, "context": "Markov Chain model which properties are studied in [7,8] is used for computing the similarity and ranking [5,1].", "startOffset": 51, "endOffset": 56}, {"referenceID": 4, "context": "Markov Chain model which properties are studied in [7,8] is used for computing the similarity and ranking [5,1].", "startOffset": 106, "endOffset": 111}, {"referenceID": 0, "context": "Markov Chain model which properties are studied in [7,8] is used for computing the similarity and ranking [5,1].", "startOffset": 106, "endOffset": 111}, {"referenceID": 4, "context": "[5] use a stochastic random-walk model to compute similarities between nodes of a graph for recommendation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1] introduce an N-star model, and demonstrate it in ranking conference and journal problems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] do a thorough review on state-of-the-art and trends of contentbased recommender systems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Since a state \u03b8 can jump to any state (and itself too) by apply action A4, the Markov Chain is irreducible and aperiodic (see more [7,8]).", "startOffset": 131, "endOffset": 136}, {"referenceID": 7, "context": "Since a state \u03b8 can jump to any state (and itself too) by apply action A4, the Markov Chain is irreducible and aperiodic (see more [7,8]).", "startOffset": 131, "endOffset": 136}, {"referenceID": 6, "context": "The Perron-Frobenius theorem [7] states that there exists a unique stationary score {Pr(\u03b8)}\u03b8\u2208S .", "startOffset": 29, "endOffset": 32}], "year": 2015, "abstractText": "In this work, we propose a new approach for discovering various relationships among keywords over the scientific publications based on a Markov Chain model. It is an important problem since keywords are the basic elements for representing abstract objects such as documents, user profiles, topics and many things else. Our model is very effective since it combines four important factors in scientific publications: content, publicity, impact and randomness. Particularly, a recommendation system (called SciRecSys) has been presented to support users to efficiently find out relevant articles.", "creator": "Hung Nghiep Tran"}}}