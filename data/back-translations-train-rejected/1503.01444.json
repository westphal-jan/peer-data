{"id": "1503.01444", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2015", "title": "Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and Applications", "abstract": "Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint in rank minimization. Our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.", "histories": [["v1", "Wed, 4 Mar 2015 20:14:35 GMT  (1300kb,D)", "https://arxiv.org/abs/1503.01444v1", null], ["v2", "Thu, 13 Aug 2015 12:51:08 GMT  (2622kb,D)", "http://arxiv.org/abs/1503.01444v2", "Accepted in Transactions on Pattern Analysis and Machine Intelligence (TPAMI). To appear"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["tae-hyun oh", "yu-wing tai", "jean-charles bazin", "hyeongwoo kim", "in so kweon"], "accepted": false, "id": "1503.01444"}, "pdf": {"name": "1503.01444.pdf", "metadata": {"source": "CRF", "title": "Partial Sum Minimization of Singular Values in Robust PCA: Algorithm and Applications", "authors": ["Tae-Hyun Oh", "Jean-Charles Bazin"], "emails": ["thoh.kaist.ac.kr@gmail.com,", "yuwing@gmail.com,", "woo.kim@kaist.ac.kr,", "iskweon77@kaist.ac.kr", "jean-charles.bazin@inf.ethz.ch"], "sections": [{"heading": null, "text": "Index Terms - Robust main component analysis, rank minimization, sparse and low decomposition, truncated nuclear standard, method of multipliers in alternating directions."}, {"heading": "1 INTRODUCTION", "text": "VArious low-level vision applications, including HighDynamic Range (HDR) [35], [36], photometric stereo [3], [23], batch image alignment [38] and factorization-based structure from motion [5], [41], can be formulated as a low-rank matrix recovery problem [48] are widely used to find the best approximation of an underlying low-rank structure of data, such as Principal Component Analysis (PCA). However, many of these approaches are error-prone due to the presence of outliers of the low-rank matrix while rejecting outliers, a rank minimization based outliers, a rank minimization based component (RPCA)."}, {"heading": "2 RELATED WORKS", "text": "In fact, we are able to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to find ourselves in another world, to find ourselves in another world, to find ourselves in another world, to find ourselves in another world. \""}, {"heading": "3 PARTIAL SUM MINIMIZATION BY THE PSVT OPERATOR", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Derivation of Partial Sum of Singular Values", "text": "Our subtotal formula in Equation (3) is derived from the following objective function: argmin A, E | rank (A) \u2212 N | + \u03bb \u27e9 E-0, s.t. O = A + E. (4) Equation (4) aims to use a low-rank A matrix near target rank N and a sparse error matrix E. Since the above objective function is also a NP-hard problem, we relax it with an alternative representation to deal with it effectively. Relaxation is similar to the method presented by Cande Woods et al. [9]. We should also interpret target rank N correctly. We relax it with a projection operator to implement a rank N matrix in a matrix interpretation. Relaxation results in the PSSV target function, which is the first term in the equation. (4), the matrix matrix can be derived as follows:"}, {"heading": "3.1.1 From rank constraint to projection", "text": "In this section we show the relationship between the target group N and the target group 1: 1. (5) We first present a ranking in which the ranking order is 1: 1. (7) Let UDV and rank (A).Let UDV be, then there are matrices C and V1: r, where U1: r and V1: r are the matrices corresponding to the r largest singular values. (7) Let UDV be the SVD of A. Suppose C = U 1: r and B: r, where U1: r and V1: r are the matrices corresponding to the r largest singular values. (C and B satisfy rank (CAB) = r, which represents the proof.The constant r can be represented in the matrix form with Lemma 1."}, {"heading": "3.1.2 Why the partial sum of singular values?", "text": "Minimizing the nuclear standard may favor a solution that has a lower nuclear standard, but the singular values in the residual ranges (singular values above the target rank N. Let's leave N = 1 here) may still be large, as shown in Figures 1- (a) and 2- (a). This distortion affects the accuracy of the estimated low-ranking subspace. The phenomenon of distortion by a convex surrogate is common and could be corrected by non-convex relaxation [46]. An additional problem is that if the basic truth exhibits a large deviation, but a sparse distribution within the subspace of truth, some strains can be considered outliers to reduce the singular values within the target range, as shown in Figure) and at the minimum point of the nuclear standard in Figure 2- (a)."}, {"heading": "3.2 Optimization by ADMM", "text": "To solve these kinds of problems, Lin et al. [31] proposed an ADMM method (or called them imprecise extended Lagrange multipliers, iALM).The extended Lagrange function of Eq. (3) is formulated by the following formulations: L\u03bc (A, E, Z) = \"A-p = N + N-E-1 (10) + < Z, O-A-E > + \u03bc2-O-A-E-2F,\" where \u03bc is a positive scalar, Z-Rm \u00b7 n is an estimate of the Lagrange multiplier, and < \u00b7 F denotes the Frobenius standard, and < \u00b7, \u00b7 > represents the internal product engineer. Direct minimization of the Lagrange function could be particularly challenging."}, {"heading": "A\u2217 =argmin", "text": "A L\u03bck (A, EZk) = argmin A\u03bc \u2212 1k \u0441\u0441p = N + 12 \u0441\u043d\u0435\u0435 A \u2212 O \u2212 Ek Zk \u2212 1k Zk) Facility Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities Facilities"}, {"heading": "E\u2217 =argmin", "text": "E L\u03bck (Ak + 1, E, Zk) = argmin E\u03bb\u03bc \u2212 1k, E-1 + 12, E-E \u2212 (O \u2212 Ak + 1 + \u03bc \u2212 1k Zk), 2 F, (12) where k indicates the iteration index (see Alg. 1)."}, {"heading": "3.3 Solving A\u2217", "text": "To minimize Eq (11), we define the partial single value Thresholding (PSVT) Operator PN = 1q (PSVT) Operator (PSVT) = 1q Operator (PSVT) = 1q Operator (PSVT) = 1q Operator (PSVT) = 1q Operator (PSVT). Before defining the PSVT, we first present von Neumann's lemma (PSVY) (see details in de Sa \u0301 et al. [14]). Lemma 3 (von Neumann [14]). For all matrices B, Z \u00b2 Rm \u00b7 n and vectors of singular values (\u00b7 l), the following equation applies: max {UZV, B \u00b2 U \u00b2 Um, V \u00b2 Un \u00b2 Un} (Z). (Z)"}, {"heading": "3.4 Solving E\u2217", "text": "As suggested by Hale et al. [22], the solution of the partial problem in Equation (12) can be obtained as follows: S\u03c4 [Y] = argmin X1 2-X-Y-2F + \u03c4-X-1, (22) where S\u03c4 [x] = character (x) max (| x | -\u03c4, 0) is the soft threshold operator [17], [22] and x-R. This operator can be extended by elementary application to vectors and matrices. Soft threshold method (shrinkage) proves to be very effective in minimizing the l1 standard and the proximity term and guarantees that the solution is the global minimum for the equations of the same shape as Equation (22) (e.g. Equation (12) [17], [22]."}, {"heading": "3.5 Updating A\u2217 and E\u2217", "text": "For each iteration k, Ak and Ek can be updated with the operators S\u03c4 [\u00b7] and PN, \u03c4 [\u00b7] as follows: Ak + 1 = PN, \u03bc \u2212 1k [O \u2212 Ek + \u03bck \u2212 1Zk], Ek + 1 = S\u03bb\u03bc \u2212 1k [O \u2212 Ak + 1 + \u03bck \u2212 1Zk]. (23) The iterations are terminated when the equality condition is met (in all experiments). This method is called imprecise ALM [31] and is designed for computational efficiency. We summarize the overall algorithm in Alg. \u2212 1 (For further details see the report by Lin et al. (31)."}, {"heading": "3.6 Convergence Analysis", "text": "To the best of our knowledge, the general convergence characteristic of ADMM, which alternates between non-convex (solvingA) and convex (solvingA) functions, has not yet been answered. ADMM for non-convex problems can be considered a local optimization method aimed at converging to a point with a better objective value [4]. In our problem, each sub-problem has a closed solution and the objective value decreases with respect to the variables optimized in each sub-problematication2. Our empirical convergence tests show that it does not mean a monotonous decrease in the lagrange function, which is not necessarily monotonous due to the dual update.that our ADMM-based algorithm exhibits strong convergence behavior (see Sec. 4.1). Although the global optimal solution is not guaranteed, all our experiments have shown that our algorithms converge to a solution that comes very close to the standard number of observations."}, {"heading": "4 EXPERIMENT RESULTS", "text": "We compare the performance of the proposed method with the RPCA (nuclear standard) [9] using synthetic data sets and real-world application examples. In all experiments, we use the standard parameters recommended by Cande and al. [9] for both their approach and ours, i.e. \u03bb = 1 / \u221a max (m, n) and \u03c1 = 1.5, unless explicitly stated otherwise. The code of the proposed method is available on our project website 3."}, {"heading": "4.1 Synthetic Dataset", "text": "We compare our method (PSSV) with the RPCA (Nuclear Standard) based on synthetic data by evaluating the success ratio and convergence behavior. To synthesize a ground-truth-lowrank matrix, we perform a linear combination of N arbitrary orthogonal base vectors. The weight vector used to encircle each column vector of the AGT is randomly selected from the uniform distribution U [0, 1]. To create sparse outliers, we select m-n-r entries from the AGT, where r indicates the corruption ratio. Greater r means more outlier entries. The selected entries are corrupted by random noise from U [0, 1]."}, {"heading": "4.1.1 Comparison of Success Ratio", "text": "We check the robustness of the RPCA (nuclear standard) and the proposed method (PSSV) in terms of the number of observations, the data dimension and the corruption ratio. We examine the performance by counting the number of successes. If the recovered A-group has an NRMSE smaller than 0.01, we look at the estimate of A and E. We compare the success ratio with different column size n (i.e. the number of observations) and row size m (i.e. the data dimension). The magnitude in Fig. 3 shows the success. http: / / thoh.kaist.ac.krPercentage. A larger blue area indicates a more robust performance of the algorithm. We also conduct experiments in which we vary m = 10 000 and n and r. The comparison between RPCA and our method with rank 1,2,3,5 and -10 limitations shows greater corruption than Fig."}, {"heading": "4.1.2 Rank Deficiency", "text": "Our objective function minimizes the rank from A to the target rank. Therefore, the rank of the result from A to Z should not be lower than the target rank. In practice, the rank insufficiency is decisive for the quality of the final solution in some applications (e.g. photometric stereo). We measure the ratio of N (A) + E (similar to the inverse value of the condition number) for the rank N limitation case. We test only for rank N = 3 as a typical example of photometric stereo. If the ratio of E is less than 0.01, we consider that the recovered matrix has a rank lower than N. In Fig. 6, the red regions mean that the rank of the recovered matrix is lower than the rank of N = 3 as a typical example of photometric stereo. Experiments empirically confirm that the rank of E obtained by our method is limited."}, {"heading": "4.1.3 Sensitivity to Initialization", "text": "Since the proposed objective function is not convex, the convergent solution may vary depending on the initialization. To investigate the sensitivity of optimization versus initialization, we performed 1000 experiments with random initialization on a rank-3 matrixO-R10000-50 with 5% outliers. The distribution of NRMSE is shown in Fig. 7. While the convergence of the nonconvex problem to an optimum is difficult to guarantee, most solutions are distributed concentrically in regions close to the basic truth solution with small errors."}, {"heading": "4.1.4 Comparisons with other low-rank approximations", "text": "We provide additional comparisons with the singular value of the projection (SVP) with small scales (WNNM). The formulations are summarized in Table 1. SVP and WNNM are reformulated on the basis of the RPCA framework for a fair comparison. MF methods impose a hard constraint on the target-to-rank ratio of the data matrix (O = UV) by factoring it into a product of rank-N-base (U) and coefficient (V). Among the existing MF-based methods, we compare with the state-of-the-art methods of LMaFit. [48] and Eriksson et al. [18], with the recommended standard parameters. Since the method of Eriksson et al. can only treat small size examples, we conduct separate experiments for small and large scales."}, {"heading": "4.1.5 Incorrect Setting of Target Rank", "text": "Our method uses the target rank from the problem definition. If the target rank is set incorrectly, of course, the question arises as to the behaviour of our method. For the sake of completeness, we have used an incorrect target rank in Fig. 9.We have looked at the situation in which the rank is known but is ambiguous within a certain limit (e.g. the truth rank is 3, but ambiguous within the precedence order - {2,3,4}). The data construction is similar to the experiments carried out in Fig. 4.1.4, i.e. well-sampled and under-sampled data cases. The ranking 3 matrices O-R3000 \u00d7 100 are used for the experiment. Fig. 9 shows that MF-based methods are prone to incorrect target ranking. Interestingly, for the data under-sampled on9 5 10 15 20 30 30 30 30 30 \u2212 8 \u2212 10 iterationT erm inat ion crit erio nRPCA, r = 4r = PCA 1. = 3. (R = 3)."}, {"heading": "4.1.6 Convergence Behavior", "text": "In order to investigate the convergence behaviour of both the RPCA [31] and our method, we record the development of the relative errors in the figures of Fig. 10- (a) and (b). We randomly generate 5000 x 40 matrices for the ranges 2, 3, 4 cases, and the average value of the studies is calculated. We use the MATLAB implementation of the RPCA provided by Wright et al. [44] We perform our method to convergence and find that it terminates with the RPCA at similar moments as shown in Fig. 10- (a). In addition, our method takes the same amount of time as the inaccurate ALM-based RPCA [31]. Fig. 10- (b) also shows that our method offers a higher accuracy than the RPCA and a gradual convergence under the same criterion."}, {"heading": "4.1.7 Lambda (\u03bb) parameter", "text": "For the sake of completeness, we will show in this section how the choice of \u03bb can influence the solution of both RPCA and ours. Note that it is not possible to match the optimal \u03bb to the balance of the core norm and scanty unless the ground truth solution is known as from Chandrasekaran et al. [10]. Therefore, the results provided here are for reference only. Fig. 11 shows normalized MSE at variations where \u03bb = L / \u221a max (m, n) varies. Results show that our method consistently produces fewer errors than RPCA under other size settings. Fig. 12: Illustration of the observed intensity values for (a) saturation range, (b) moving object and (c) consistent cases. Fixed lines indicate the ideal relationship between intensity and exposure, and dotted lines denote the observed intensities. (a) (b) (d) (e) (comparison of a group and c) (a comparison between the results of the three (b) and (c)."}, {"heading": "4.2 Real-world Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 High Dynamic Range (HDR) Imaging", "text": "We apply the proposed method for modeling a background scene and a ghost-free HDR composition."}, {"heading": "4.2.2 Motion Detection by Temporal Edge", "text": "RPCA-based background modeling for surveillance purposes requires a large number of observations to estimate background and moving objects under global lighting changes, a requirement that is not suitable for the online monitoring algorithm. Using some images as input, RPCA may fail to detect moving regions due to the limited number of observations. In this case, we find that edge images make moving object boundaries sparser and rarely overlap. We stack a few edge images (obtained from the Sobel Operator) in video sequence as slit vectors of a matrix O-Rm \u00b7 n = [vec (O1) | \u00b7 \u00b7 | vec (On)]. Without moving objects, the edge pixels on the background texture are static, so that the matrix O should be essentially rank-1. Since moving object regions are not consistent with background boundaries, the regions may show the same as modeling A."}, {"heading": "4.2.3 Outlier Rejection for Photometric Stereo", "text": "The mentioned for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green for the green."}, {"heading": "4.2.4 Batch Image Alignment", "text": "In view of several images of an interesting object (e.g. the face), the task of image alignment in the stack is to align them with a fixed canonical template [6], [38]. In this problem, we are looking for a transformational gi for each image Ii in order to make the images correlate linearly. We note the set of transformations: g = {g1,.., gn} in which n is the number of images and write O-g = [vec (I1), Ii to make the images correlate linearly. In contrast to the formulation of Peng et al. [38], we mathematically look at the PSSV as follows: argmin A, E, g-A-p = N + E-1, s.t. O-g = A + E. (24) We applied our approach to the header dataset al. (see Fig. 20- (a) [38]."}, {"heading": "4.2.5 Image Recovery", "text": "Images of natural scenes follow natural statistics [25]. As Hu et al. [24] have shown, image scene information is dominated by the top 20 singular values, which is a low rank. Hu et al. [24] proposed a matrix completion method using the abbreviated nuclear standard (TNN) introduced in Sec. 2. We formulate the matrix completion asargmin A, B, A = B, P\u03a9 (B) = P\u03a9 (O), (25) where P\u03a9 (\u00b7) is the orthogonal projection operator setting [P\u03a9 (X)] i, j = [X] i, j for (i, j) \u03a9 and 0 otherwise. Although the auxiliary variable B appears unnecessary, it makes the affine constraint (the projection operator) the efficient PSVT operator applicable in the ADMM algorithm."}, {"heading": "5 DISCUSSIONS AND CONCLUSION", "text": "In this paper, we have re-examined the minimization method in the RPCA for basic visual problems. If the target value is known, we show that by modifying the objective function from the nuclear standard to the PSSV, we can achieve better control over the target value of the low-level solution, even if the number of observations is limited. An attractive advantage of our solution is that it can easily be used in existing algorithms, e.g. ADMM [31], and the efficient computational properties are still maintained. [37] The universality and effectiveness of our approach are supported by numerous and extensive experiments using both synthetic examples and several real-world applications that exceed the conventional core objective function. We do not consider scalability problems of our method in this paper, but the most recent approach is proposed by Oh et al. [37] make it possible to accelerate the application of our method. An interesting direction of future work is the mathematical analysis of the properties of our partial sum function, which is comparable to the standard."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank reviewers and co-editors for their valuable comments and Steve Seitz and Dan Goldman for the photometric stereo dataset. The work was supported by the Korean government-funded grant from the National Research Foundation of Korea (NRF) (MSIP) (No. 2010-0028680). So Kweon is the corresponding author."}], "references": [{"title": "Nonconvex analysis", "author": ["A. Bagirov", "N. Karmitsa", "M. Makela"], "venue": "Introduction to Nonsmooth Optimization, pages 61\u2013116. Springer International Publishing", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J.-F. Cai", "E.J. Cand\u00e8s", "Z. Shen"], "venue": "SIAM Journal on Optimization, 20(4):1956\u2013 1982", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "An appropriate subdifferential for quasiconvex functions", "author": ["A. Daniilidis", "N. Hadjisavvas", "J.-E. Martinez-Legaz"], "venue": "SIAM Journal on Optimization, 12(2):407\u2013420", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices", "author": ["Z. Lin", "M. Chen", "Y. Ma"], "venue": "Technical Report UILU-ENG-09-2215, UIUC", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Partial sum minimization of singular values in robust PCA: Algorithm and applications", "author": ["T.-H. Oh", "Y.-W. Tai", "J.-C. Bazin", "H. Kim", "I.S. Kweon"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "On the moreau\u2013yosida regularization of the vector k-norm related functions", "author": ["B. Wu", "C. Ding", "D. Sun", "K.-C. Toh"], "venue": "SIAM Journal on Optimization, 24(2):766\u2013794", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 2, "context": "1 INTRODUCTION VArious low-level vision applications, including High Dynamic Range (HDR) [35], [36], photometric stereo [3], [23], batch image alignment [38] and factorization-based structure from motion [5], [41], can be formulated as a low-rank matrix recovery problem.", "startOffset": 120, "endOffset": 123}, {"referenceID": 4, "context": "1 INTRODUCTION VArious low-level vision applications, including High Dynamic Range (HDR) [35], [36], photometric stereo [3], [23], batch image alignment [38] and factorization-based structure from motion [5], [41], can be formulated as a low-rank matrix recovery problem.", "startOffset": 204, "endOffset": 207}, {"referenceID": 0, "context": "[1] proved that convex approximation by nuclear norm can still achieve bounded and stable results even under small noise measurements.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[7] revisited the relationship between nuclear norm regularization and bilinear MF model [2], and proposed a rank continuation heuristic to avoid local minima.", "startOffset": 89, "endOffset": 92}, {"referenceID": 3, "context": "The ADMM for non-convex problems can be considered as a local optimization method, which aims to converge to a point with better objective value [4].", "startOffset": 145, "endOffset": 148}, {"referenceID": 0, "context": "The color magnitude represents the success ratio [0,1].", "startOffset": 49, "endOffset": 54}, {"referenceID": 0, "context": "The color magnitude represents the success ratio [0,1].", "startOffset": 49, "endOffset": 54}, {"referenceID": 0, "context": "The color magnitude represents the success ratio [0,1].", "startOffset": 49, "endOffset": 54}, {"referenceID": 0, "context": "The weight vector used to span each column vector of AGT is randomly sampled from the uniform distribution U [0, 1].", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "The selected entries are corrupted by random noise from U [0, 1].", "startOffset": 58, "endOffset": 64}, {"referenceID": 5, "context": "face), the batch image alignment task aims to align them to a fixed canonical template [6], [38].", "startOffset": 87, "endOffset": 90}], "year": 2015, "abstractText": "Robust Principal Component Analysis (RPCA) via rank minimization is a powerful tool for recovering underlying low-rank structure of clean data corrupted with sparse noise/outliers. In many low-level vision problems, not only it is known that the underlying structure of clean data is low-rank, but the exact rank of clean data is also known. Yet, when applying conventional rank minimization for those problems, the objective function is formulated in a way that does not fully utilize a priori target rank information about the problems. This observation motivates us to investigate whether there is a better alternative solution when using rank minimization. In this paper, instead of minimizing the nuclear norm, we propose to minimize the partial sum of singular values, which implicitly encourages the target rank constraint. Our experimental analyses show that, when the number of samples is deficient, our approach leads to a higher success rate than conventional rank minimization, while the solutions obtained by the two approaches are almost identical when the number of samples is more than sufficient. We apply our approach to various low-level vision problems, e.g. high dynamic range imaging, motion edge detection, photometric stereo, image alignment and recovery, and show that our results outperform those obtained by the conventional nuclear norm rank minimization method.", "creator": "LaTeX with hyperref package"}}}