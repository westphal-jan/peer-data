{"id": "1503.02578", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Mar-2015", "title": "Modeling State-Conditional Observation Distribution using Weighted Stereo Samples for Factorial Speech Processing Models", "abstract": "This paper investigates the role of factorial speech processing models in noise-robust automatic speech recognition tasks. Factorial models can embed non-stationary noise models using Markov chains as one of its source chain. The paper proposes a modeling scheme for modeling state-conditional observation distribution of factorial models based on weighted stereo samples. This scheme is an extension to previous single pass retraining for ideal model compensation and here we used it to construct ideal state-conditional observation distributions. Experiments of this paper over the set A of the Aurora 2 dataset shows that by considering noise models with multiple states, system performance can be improved especially in low SNR conditions up to 4% absolute word recognition performance. In addition to its power in accurate representation of state-conditional observation distribution, it has an important advantage over previous methods by providing the opportunity to independently select feature spaces for both source and corrupted features. This opens a new window for seeking better feature spaces appropriate for noise-robust tasks independent from clean speech feature space.", "histories": [["v1", "Mon, 9 Mar 2015 17:40:08 GMT  (731kb)", "http://arxiv.org/abs/1503.02578v1", null], ["v2", "Wed, 5 Oct 2016 12:05:10 GMT  (882kb)", "http://arxiv.org/abs/1503.02578v2", "Updated version of the first submission. Several clarifications are added to previous version. One experiment is added to the experiments, Circuits Syst Signal Process, Apr. 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.SD", "authors": ["mahdi khademian", "mohammad mehdi homayounpour"], "accepted": false, "id": "1503.02578"}, "pdf": {"name": "1503.02578.pdf", "metadata": {"source": "CRF", "title": "Modeling State-Conditional Observation Distribution using Weighted Stereo Samples for Factorial Speech Processing Models", "authors": ["Mahdi Khademian", "Mohammad Mehdi Homayounpour"], "emails": [], "sections": [{"heading": null, "text": "This paper examines the role of factorial speech processing models in noise-stable automatic speech recognition tasks. Factorial models can embed non-stationary sound models using Markov chains as one of their source chains. It proposes a modeling scheme for modelling the state-conditioned observation distribution of factorial models based on weighted stereo samples, which is an extension of previous single-pass retraining for ideal model compensation and has been used here to construct ideal state-conditioned observation distributions. Experiments in this paper on the set A of the Aurora 2 dataset show that taking multiple states into account can improve system performance by up to 4% absolute word recognition performance, especially under low SNR conditions. In addition to its performance in accurately representing the state-conditioned observation distribution, it has an important advantage over earlier methods by offering the possibility of selecting feature spaces for both the source and for corrupt features."}, {"heading": "1. Introduction", "text": "I \"n\" tlcnlhsrcsrteeteeteersrrsrrsrteeaeVnlrrsrrteeoiiiiiiiiiiiiiteeeegtlrsrsrsrteeeeeeVnlrrsrsrsrteeoiiiiiiiiiiiiiiiteeeeegtlrsrrsrsrsrsrsrrsrrrsrteeteeteeeteeteersrsrrrsrrrsrrsrsrteeteeteeteeteersrsrsrsrrsrsrrsrsrsrteeteeteeteeteeteeteeteeteeteeteeteeteeteeteersrsrsrsrsrsrsrsrsrsrsrrsrsrsrsrsrsrsreteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteersrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsreteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteete"}, {"heading": "2. Background", "text": "Model-based noise-intensive ASR methods take into account the following relationship between speech and sound signals in an assumed environment to produce distorted speech signals (3), [15]: (2))"}, {"heading": "2.1. State-conditional observation distribution", "text": "The interaction model (or the mismatch function) is not used directly in inferences of factor models. Instead, the source functions are marginalized as follows: (,,,, (,) (,,) (,) (,) (,) (,) (), (), \"(),\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \"\", \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\" \",\", \"\", \"\" \",\", \",\" \",\" \"\", \"\", \",\" \"\", \"\", \",\" \"\" \",\", \"\" \"\", \"\", \"\" \",\" \",\" \"\" \"\", \"\" \",\" \",\" \"\" \",\" \",\" \"\" \"\", \"\" \"\" \",\" \"\" \""}, {"heading": "2.1.1. VTS based SCOD models", "text": "For VTS-based methods, the incongruence function is approximated by the first-order Taylor series (0, 0, 0) + (0, 0). For example, for the incongruence function of (3) in the form of (0, 0, 0) + (0) + ("}, {"heading": "2.1.2. DPMC based SCOD models", "text": "Data-driven PMC methods use forward sampling to generate state-conditioned trait samples for SCOD modeling. First, source states are specified, i.e., =. Then conditional traits are generated based on defined states and the use of source models. Now, traits observed by using an appropriate in-match function are extracted from source traits (,,,,,). These samples can represent empirical SCODs as follows: (, =) = 1 (,) 1 (10), the number of samples being and the Dirac delta function. In this step, the parametric model of SCOD can be trained by using state-conditional samples."}, {"heading": "2.2. Inference", "text": "In fact, it is the case that each country is a country in which it is not a country, but a country in which it is a country, \"he said.\" But it is not the case that it is a country in which it is a country, \"he said.\" But it is not the case that it is a country in which it is a country in which it is a country. \""}, {"heading": "3. The proposed method", "text": "The proposed method solves the problem of modelling the state-induced observation distribution in a way that differs from previous methods based on interaction models or incongruence functions. It models the state-induced observation distribution based on samples where the samples are not generated by pre-sampling and the use of incongruence functions as in the data-driven PMC methods. The sample of the corrupt feature distribution starts with source signals in the time domain. In the first step, segments of source signals are combined by the freely assumed environment model (such as (1)) to generate the corrupt language in the time domain. Then, the corresponding features are extracted from these time domain signals."}, {"heading": "3.1. Empirical distribution", "text": "Since we have no limitation on the source states, the samples of (19) are taken from unconditional observation distributions and not from SCOD. Therefore, these samples cannot be used directly for SCOD modeling. Particle weights are calculated in each source space as follows: () () () () () () () () () () () () () () () ()) () () () () () () () () () () and () () () () (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (, (), (, (), (, (), (, (), (, (), (, (), (, (,), (, (,), (, (,), (, (), (), (, (,), (), (, (), (, (), (, (,), (), (, (,), (), (), (, (), (), (, (), (), (, (), (), (, (), (), (, (), (, (), (), (, (), (), (, (), (, (), (, (), (), (, (), (, (), (), (, (), (, (, (), (), (), (), (), (, (), (, (), (, (), (, (), (, (, (), (), (), (), (, (, (, (, (), (, (), (, (), (, (, (), (, (, (, (), (), (), (, (), (, (, (, (), (, (, (, (, (), (, (, (), (), (, (), (, (), (,"}, {"heading": "3.2. Parametric distribution", "text": "The empirical distribution cannot be used directly in the application for recognition and we need a parametric model of the SCOD. (Parameter estimation of individual Gaussian models can be done by weighted probability estimators [23] as: argmax"}, {"heading": "4. Experiments", "text": "The Aurora 2 task [24] for detecting expressions of digital series corrupted by additive and convolutive sounds is selected to evaluate the effectiveness of the proposed method for dealing with multi-state noise models in SCOD models. This task has three sets of tests A, B and C and our method is rated with set A. Set A is designed to test the robustness of additive noise detection methods taking into account this point that the sound information could be used during the training phase, and in our experiment we assume that we have sound distributions and signals prior to the test. In this test set, four sounds are artificially applied to 8440 clean expressions, which are used during the training phase for multiple condition scenarios, the same noise states and signals prior to the test."}, {"heading": "4.1. Source modeling", "text": "In fact, the proposed method for SCOD modeling allows us to independently select the characteristics of the source and the observed characteristics, but for comparing the performance of the ideal SCOD models with other methods, we limit ourselves to the Cepstral coefficients (MFCC) with a specific configuration supported by the derivative functions. Since the second order derivatives do not offer significant improvements in the experiments, we only use the first order of the Cepstral coefficients (MFCC) with a specific configuration."}, {"heading": "4.2. Modeling state-conditional observation distributions", "text": "In IDPMC-SCOD modeling, generated samples are extracted from source state GMMs, while in VTS models, SCOD models are conditioned to source state and GMM components of the language state. Therefore, IDPMC-SCOD models are conditioned to common speech and noise saturation, while VTS-SCOD models are conditioned additionally to components of each language state. In addition, VTS-based SCOD models are trained by two alpha values (see (4). At the first effect of phase difference, all four types of Set-A noise are ignored by setting the alpha value to zero. Then, the second alpha value is set to 2.5, which gives the best results in [17] experiments. In the proposed method, different SCOD models are trained for each sound type by introducing all four types of Set-A noise by using the ambient model of (1), except that we ignore the effect of channel distortion."}, {"heading": "4.3. Results", "text": "In the first experiment, the performance of the compensated system (single noise state factor model) is compared on the basis of IDPMC and VTS-based SCODs for two selected alpha values. Figure 3 shows the average word recognition accuracy for four sounds of set A against different SNRs for two selected alpha values, as shown in [17] when selecting alpha for invalid constant 2.5 (invalid in terms of its support quantity, which is [\u2212 1, 1]), yields a better result than their ignoring, both in VTS and IDPMC SCOD models, but with less effect in the IDPMC case. Furthermore, we have observed that IDPMC-based SCOD models provide a higher detection rate than VTS-based models. Therefore, Alpha is set to 2.5 for further experiments. Now, the proposed method of forming ideal SCOD modelling for individual noise states and SCOD-based noise states in the SCOD multiple VD."}, {"heading": "5. Conclusion", "text": "This paper proposes a modeling method based on weighted \"stereo\" samples to create a state-conditioned observation distribution to be used in factorial language processing models. In fact, the idea behind this method is similar to the retraining scheme for model compensation presented in [10]. We present this method in addition to its support for non-stationary noise with different formulations. As shown in our experiments, the use of multiple noise states increases detection accuracy, especially under low SNR conditions. Due to the use of \"stereo\" data, the proposed method cannot be used directly in many real-world applications, as this data is not always available. However, similar to the ideal compensated models in retrained systems with only one pass, we are able to train ideal SCOD models here to evaluate the capabilities of other useful modeling techniques. The purpose of presenting this method is to find a way to improve the overall modelling of the number of noise factors in our systems in order to evaluate whether it is appropriate to increase the noise level of the system."}, {"heading": "Appendix A", "text": "The extension of the EM algorithm for modelling the mixture of Gaussians based on weighted samples (= 31) In the E-step of the EM algorithm for weighted particles, particle weights have no effect on the responsibility equations of the particles. By considering particle weights as the replicating order of the particles (similar to (21), this replication has no effect on the responsibilities of the particles. Therefore, particle weights are calculated without taking into account the parameters specified in the E-step of the standard EM algorithm for GMMs:"}], "references": [{"title": "Developments and directions in speech recognition and understanding, Part 1 [DSP Education", "author": ["J. Baker", "L. Deng", "J. Glass", "S. Khudanpur", "C. Lee", "N. Morgan", "D. O\u2019Shaughnessy"], "venue": "IEEE Signal Process. Mag., vol. 26, no. 3, pp. 75 \u201380, May 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Factorial Models for Noise Robust Speech Recognition", "author": ["J.R. Hershey", "S.J. Rennie", "J. Le Roux"], "venue": "Techniques for Noise Robustness in Automatic Speech Recognition, T. Virtanen, R. Singh, and B. Raj, Eds. John Wiley & Sons, Ltd, 2012, pp. 311\u2013345.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "ALGONQUIN: Iterating Laplace\u2019s method to remove multiple types of acoustic distortion for robust speech recognition", "author": ["B.J. Frey", "L. Deng", "A. Acero", "T. Kristjansson"], "venue": "presented at the EUROSPEECH 2001, 2001, pp. 901\u2013904.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "Factorial Hidden Markov Models for Speech Recognition: Preliminary Experiments", "author": ["B. Logan", "P.J. Moreno"], "venue": "Cambridge Research Laboratory, Cambridge, Massachusetts, 1997.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Factorial models and refiltering for speech separation and denoising", "author": ["S.T. Roweis"], "venue": "Eighth European Conference on Speech Communication and Technology, 2003.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Super-human multi-talker speech recognition: A graphical modeling approach", "author": ["J.R. Hershey", "S.J. Rennie", "P.A. Olsen", "T.T. Kristjansson"], "venue": "Comput. Speech Lang., vol. 24, no. 1, pp. 45\u201366, Jan. 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Single-Channel Multitalker Speech Recognition", "author": ["S.J. Rennie", "J.R. Hershey", "P.A. Olsen"], "venue": "IEEE Signal Process. Mag., vol. 27, no. 6, pp. 66\u201380, Nov. 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "An Overview of Noise-Robust Automatic Speech Recognition", "author": ["J. Li", "L. Deng", "Y. Gong", "R. Haeb-Umbach"], "venue": "IEEEACM Trans. Audio Speech Lang. Process., vol. 22, no. 4, pp. 745\u2013777, Apr. 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Model-Based Techniques for Noise Robust Speech Recognition", "author": ["M.J.F. Gales"], "venue": "Ph.D. Thesis, University of Cambridge, 1995.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "Statistical models for noise-robust speech recognition", "author": ["R.C. Van Dalen"], "venue": "Ph.D. Thesis, Cambridge, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Factorial Hidden Markov Models", "author": ["Z. Ghahramani", "M.I. Jordan"], "venue": "Mach. Learn., vol. 29, no. 2, pp. 245\u2013 273, 1997.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1997}, {"title": "Dynamic bayesian networks: representation, inference and learning", "author": ["K.P. Murphy"], "venue": "Ph.D. Thesis, University of California, 2002.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "The HTK book", "author": ["S. Young", "G. Evermann", "D. Kershaw", "G. Moore", "J. Odell", "D. Ollason", "V. Valtchev", "P. Woodland"], "venue": "Camb. Univ. Eng. Dep., vol. 3, 2002.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Enhancement of log Mel power spectra of speech using a phase-sensitive model of the acoustic environment and sequential estimation of the corrupting noise", "author": ["L. Deng", "J. Droppo", "A. Acero"], "venue": "IEEE Trans. Speech Audio Process., vol. 12, no. 2, pp. 133 \u2013 143, Mar. 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "An analytic derivation of a phase-sensitive observation model for noise robust speech recognition", "author": ["V. Leutnant", "R. Haeb-Umbach"], "venue": "INTERSPEECH, 2009, pp. 2395\u20132398.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "A unified framework of HMM adaptation with joint compensation of additive and convolutive distortions", "author": ["J. Li", "L. Deng", "D. Yu", "Y. Gong", "A. Acero"], "venue": "Comput. Speech Lang., vol. 23, no. 3, pp. 389\u2013405, Jul. 2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Single-Channel Speech Separation Using Soft Mask Filtering", "author": ["M.H. Radfar", "R.M. Dansereau"], "venue": "IEEE Trans. Audio Speech Lang. Process., vol. 15, no. 8, pp. 2299 \u20132310, Nov. 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Robust continuous speech recognition using parallel model combination", "author": ["M.J.F. Gales", "S.J. Young"], "venue": "IEEE Trans. Speech Audio Process., vol. 4, no. 5, pp. 352\u2013359, Sep. 1996.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1996}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proc. IEEE, vol. 77, no. 2, pp. 257\u2013286, 1989.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1989}, {"title": "Stereo-Based Stochastic Mapping for Robust Speech Recognition", "author": ["M. Afify", "X. Cui", "Y. Gao"], "venue": "IEEE Trans. Audio Speech Lang. Process., vol. 17, no. 7, pp. 1325\u20131334, Sep. 2009.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Introduction to Monte Carlo Methods", "author": ["D.J.C. Mackay"], "venue": "Learning in Graphical Models, vol. 89, M. I. Jordan, Ed. Springer Netherlands, 1998, pp. 175\u2013204.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "Maximum weighted likelihood estimation", "author": ["S.X. Wang"], "venue": "Ph.D. Thesis, University of British Columbia, Vancouver, Canada, 2001.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "The Aurora experimental framework for the performance evaluation of speech recognition systems under noisy conditions", "author": ["H.G. Hirsch", "D. Pearce"], "venue": "ASR2000-Automatic Speech Recognition: Challenges for the new Millenium ISCA Tutorial and Research Workshop (ITRW), 2000.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "VOICEBOX: Speech Processing Toolbox for MATLAB", "author": ["M. Brookes"], "venue": "Imperial College, Exhibition Road,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1997}, {"title": "Fast state discovery for HMM model selection and learning", "author": ["S.M. Siddiqi", "G.J. Gordon", "A.W. Moore"], "venue": "International Conference on Artificial Intelligence and Statistics, 2007, pp. 492\u2013499.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Some Applications of Matrix Derivatives in Multivariate Analysis", "author": ["P.S. Dwyer"], "venue": "J. Am. Stat. Assoc., vol. 62, no. 318, pp. 607\u2013625, Jun. 1967.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1967}], "referenceMentions": [{"referenceID": 0, "context": "Despite long term efforts and great successes in automatic speech recognition (ASR) systems, rapid degradation of performance in the presence of noise and other competing sources remains the Achilles Heel of these systems [1].", "startOffset": 222, "endOffset": 225}, {"referenceID": 1, "context": "While some feature enhancement and model adaptation techniques loosely use noise source characteristics to increase performance of speech recognition systems, model based methods try to use as much as information they can acquire from noise sources [2].", "startOffset": 249, "endOffset": 252}, {"referenceID": 2, "context": "Factorial speech processing models [3]\u2013[5] are extension of Hidden Markov Models (HMM) which model audio sources and the way that these sources are combined in a generative manner.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": "Factorial speech processing models [3]\u2013[5] are extension of Hidden Markov Models (HMM) which model audio sources and the way that these sources are combined in a generative manner.", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": "Recent researches achieve higher performance even than human in the multi-talker speech recognition challenge by use of factorial models of speech processing in some specific conditions [6], [7].", "startOffset": 186, "endOffset": 189}, {"referenceID": 6, "context": "Recent researches achieve higher performance even than human in the multi-talker speech recognition challenge by use of factorial models of speech processing in some specific conditions [6], [7].", "startOffset": 191, "endOffset": 194}, {"referenceID": 7, "context": "Despite their successes in the mentioned challenge and their modeling power, factorial models are not widely used for real noise-robust speech processing applications [8]; their computational demand for inference and difficulties in representing their central conditional probability distribution (CPD) are the two main reasons for this lack of use [2].", "startOffset": 167, "endOffset": 170}, {"referenceID": 1, "context": "Despite their successes in the mentioned challenge and their modeling power, factorial models are not widely used for real noise-robust speech processing applications [8]; their computational demand for inference and difficulties in representing their central conditional probability distribution (CPD) are the two main reasons for this lack of use [2].", "startOffset": 349, "endOffset": 352}, {"referenceID": 1, "context": "The second one is the interaction model, [2]; CPD of the observed signal features conditioned on features of its corresponding sources, p(yt|xt , nt) in Figure 1.", "startOffset": 41, "endOffset": 44}, {"referenceID": 8, "context": "This CPD in its deterministic form is called mismatch function [10], [11].", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "This CPD in its deterministic form is called mismatch function [10], [11].", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "On the one hand, multiple state sequence increases computational complexity of inference (which is also required for learning) to O(TS) in which T is inference window or lag, K is number of underlying chain, and S is maximum number of states in the chains [12], [13].", "startOffset": 256, "endOffset": 260}, {"referenceID": 11, "context": "On the one hand, multiple state sequence increases computational complexity of inference (which is also required for learning) to O(TS) in which T is inference window or lag, K is number of underlying chain, and S is maximum number of states in the chains [12], [13].", "startOffset": 262, "endOffset": 266}, {"referenceID": 1, "context": "On the other hand, accurate modeling of probabilistic relationship between the observed features and their sources is not always possible in speech recognition applications [2].", "startOffset": 173, "endOffset": 176}, {"referenceID": 8, "context": "This paper focuses on the second challenge of factorial models by incorporating the idea of single-pass retraining [10], [14] for ideal SCOD modeling to be used in factorial speech processing models.", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "This paper focuses on the second challenge of factorial models by incorporating the idea of single-pass retraining [10], [14] for ideal SCOD modeling to be used in factorial speech processing models.", "startOffset": 121, "endOffset": 125}, {"referenceID": 2, "context": "In the model based noise-robust ASR methods, the following relation is considered between speech and noise signals in an assumed environment for generation of distorted speech signals [3], [15]:", "startOffset": 184, "endOffset": 187}, {"referenceID": 13, "context": "In the model based noise-robust ASR methods, the following relation is considered between speech and noise signals in an assumed environment for generation of distorted speech signals [3], [15]:", "startOffset": 189, "endOffset": 193}, {"referenceID": 9, "context": "By applying filterbank, taking logarithm and use of truncated DCT matrix, the following interaction model is derived for MFCC features [11]:", "startOffset": 135, "endOffset": 139}, {"referenceID": 14, "context": "This residual reflects the effects of the phase difference of (2) and by considering uniform distribution for phase difference, \u03b1 in this residual becomes stochastic; its properties is investigated in [16].", "startOffset": 201, "endOffset": 205}, {"referenceID": 7, "context": "The interaction model is usually approximated by removing the residual [8] or considering its \u03b1 as constant; same value for all frequency bins [17].", "startOffset": 71, "endOffset": 74}, {"referenceID": 15, "context": "The interaction model is usually approximated by removing the residual [8] or considering its \u03b1 as constant; same value for all frequency bins [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 1, "context": "Two examples are max and soft-max approximation for log-power-spectral features [2], [18].", "startOffset": 80, "endOffset": 83}, {"referenceID": 16, "context": "Two examples are max and soft-max approximation for log-power-spectral features [2], [18].", "startOffset": 85, "endOffset": 89}, {"referenceID": 17, "context": "Parallel model combination (PMC) is an example of this group [19].", "startOffset": 61, "endOffset": 65}, {"referenceID": 15, "context": "A successful and complete VTS based compensation is presented in [17].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "Developed methods in this set are known as variations of data-driven PMC [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 9, "context": "This is the reason for naming this kind of robust speech recognition, \u201cmodel compensation\u201d [11].", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "Detail derivation of these expressions for single state noise models can be found in [11], [17]; extending them for multiple noise sates is straightforward.", "startOffset": 85, "endOffset": 89}, {"referenceID": 15, "context": "Detail derivation of these expressions for single state noise models can be found in [11], [17]; extending them for multiple noise sates is straightforward.", "startOffset": 91, "endOffset": 95}, {"referenceID": 8, "context": "This model may consist of single Gaussian or multiple Gaussians where the method is named DPMC or IDPMC respectively [10], [11].", "startOffset": 117, "endOffset": 121}, {"referenceID": 9, "context": "This model may consist of single Gaussian or multiple Gaussians where the method is named DPMC or IDPMC respectively [10], [11].", "startOffset": 123, "endOffset": 127}, {"referenceID": 18, "context": "It is noteworthy that the role of SCOD in inference here is similar to the observation model in HMMs; like bi(ot) according to notations of [20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 5, "context": "For more details on the two chain models or general cases of using the algorithm, the reader is referred to [6] or [9, Ch.", "startOffset": 108, "endOffset": 111}, {"referenceID": 10, "context": "8], [12] respectively.", "startOffset": 4, "endOffset": 8}, {"referenceID": 7, "context": "These feature vectors are known as stereo features [8], [21].", "startOffset": 51, "endOffset": 54}, {"referenceID": 19, "context": "These feature vectors are known as stereo features [8], [21].", "startOffset": 56, "endOffset": 60}, {"referenceID": 20, "context": "We use importance sampling scheme [22] to correct bias occurred by non-conditional samples for modeling the SCOD using particle weights which indicates association of particle weights to states.", "startOffset": 34, "endOffset": 38}, {"referenceID": 21, "context": "Parameter estimation of single Gaussian models can be done by maximum weighted likelihood estimators [23] as:", "startOffset": 101, "endOffset": 105}, {"referenceID": 22, "context": "The Aurora 2 task [24] for recognizing utterances of digit series corrupted by additive and convolutive noises is selected for evaluating the effectiveness of the proposed method for handling noise models with multiple noise states in SCOD modeling in factorial models.", "startOffset": 18, "endOffset": 22}, {"referenceID": 22, "context": "Source modeling Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25].", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "Source modeling Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25].", "startOffset": 150, "endOffset": 154}, {"referenceID": 23, "context": "Source modeling Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25].", "startOffset": 245, "endOffset": 249}, {"referenceID": 24, "context": "Noise models of the second set are created by STACS tool [26] and noise modeling is done for each noise separately.", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "5 which provides the best results in [17] experiments.", "startOffset": 37, "endOffset": 41}, {"referenceID": 15, "context": "As mentioned in [17] selecting alpha to invalid constant 2.", "startOffset": 16, "endOffset": 20}, {"referenceID": 8, "context": "In fact the idea behind this method is similar to single pass retraining scheme presented in [10] for model compensation.", "startOffset": 93, "endOffset": 97}, {"referenceID": 25, "context": "For estimating \u03a3k , according to [27] the derivative takes the following form: \u2202g \u2202\u03a3k \u2044 = \u2212 1 2 \u2211 wl\u03b3l(k)[\u03a3k \u22121 \u2212 \u03a3k (yl \u2212 \u03bck)(yl \u2212 \u03bck) \u03a3k ] l=1 (34)", "startOffset": 33, "endOffset": 37}], "year": 2015, "abstractText": "This paper investigates the role of factorial speech processing models in noise-robust automatic speech recognition tasks. Factorial models can embed non-stationary noise models using Markov chains as one of its source chain. The paper proposes a modeling scheme for modeling state-conditional observation distribution of factorial models based on weighted stereo samples. This scheme is an extension to previous single pass retraining for ideal model compensation and here we used it to construct ideal state-conditional observation distributions. Experiments of this paper over the set A of the Aurora 2 dataset shows that by considering noise models with multiple states, system performance can be improved especially in low SNR conditions up to 4% absolute word recognition performance. In addition to its power in accurate representation of state-conditional observation distribution, it has an important advantage over previous methods by providing the opportunity to independently select feature spaces for both source and corrupted features. This opens a new window for seeking better feature spaces appropriate for noise-robust tasks independent from clean speech feature space.", "creator": "Microsoft\u00ae Word 2013"}}}