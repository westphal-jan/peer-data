{"id": "1503.02626", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Mar-2015", "title": "On the Intrinsic Limits to Representationally-Adaptive Machine-Learning", "abstract": "Online learning is a familiar problem setting within Machine-Learning in which data is presented serially in time to a learning agent, requiring it to progressively adapt within the constraints of the learning algorithm. More sophisticated variants may involve concepts such as transfer-learning which increase this adaptive capability, enhancing the learner's cognitive capacities in a manner that can begin to imitate the open-ended learning capabilities of human beings.", "histories": [["v1", "Mon, 9 Mar 2015 19:17:49 GMT  (19kb)", "http://arxiv.org/abs/1503.02626v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david windridge"], "accepted": false, "id": "1503.02626"}, "pdf": {"name": "1503.02626.pdf", "metadata": {"source": "CRF", "title": "On the Intrinsic Limits to Representationally-Adaptive Machine-Learning", "authors": ["David Windridge"], "emails": ["d.windridge@mdx.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 150 3.02 626v 1 [cs.A I] Online learning is a familiar problem within machine learning, where data is presented serially to a learning agent over time, requiring him to gradually adapt to the limitations of the learning algorithm. More sophisticated variants may include concepts such as transfer learning, which increase this adaptability and improve the learner's cognitive abilities in a way that can begin to imitate the limitless learning abilities of humans. However, we will argue in this paper that a full realization of this notion requires that, in addition to the ability to adapt to new data, autonomous online learning ultimately has the ability to update its own representational abilities in relation to the data. Therefore, we will ask about the philosophical limitations of this process and argue that only fully embodied learners with a priori perceptual and behavioral connection are capable of exhibiting the full range of human cognitive abilities."}, {"heading": "1 Introduction", "text": "In the following, we will rewrite the conceptual limits inherent in the notion of unlimited machine learning - a key criterion for human thinking and intelligence - and propose a strategy for building autonomous actors capable of working on this extremity of their abilities."}, {"heading": "1.1 Conceptual Limits to OpenEnded Learning", "text": "In Putnam's classic philosophical thought experiment, \"Brain in the Vat,\" a brain is wired to a supercomputer that simulates all aspects of the real world, and communicates this in the form of electrical signals that the wires send down in response to input signals from the brain in the form of nerve impulses. Therefore, the thought experiment aims to address notions of radical skepticism; could such a brain be justified in having true beliefs? (and would these be beliefs about objects that exist within the simulated world or about the input / output characteristics of electrical signals) A variant of this thought experiment (actually a subset of this thought experiment) could be the notion of a brain in a vat that is transmitted from birth only through its optical nerves to a video camera before which in a temporal sequence all natural scenes of the world pass (the refined question being, \"Would such a brain represent the world in the same way as a typical human being able to move freely in a problem)."}, {"heading": "2 Limits to Standard Ap-", "text": "It is a standard form of machine learning induction, in which data is presented serially in time and in which learning usually takes place one instance at a time (i.e. it is the opposite of offline techniques or batch techniques, learning), but it is also inherently predictive in predicting the label values of data that are not yet presented to the system. Therefore, such a system is inherently adaptable; the degree of adaptation to new data will vary from online learners to online learners (advanced variants may include terms such as transfer learning ([4, 5]), abnormal recognition ([6]) and active learning ([7, 8]). However, despite this tendency towards increasing adaptability, we assume that the majority of existing approaches typically assume an underlying consistency in the representative characteristics of the data; the data stream presented to an online learner is generally fixed in terms of a group of defined characteristics, or in terms of a defined class of particular characteristics)."}, {"heading": "3 Identity Retention in Online", "text": "In fact, most people who are able to survive themselves are also able to survive themselves. (...) It is not so that they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is not as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) (...) (...) (...) (...) () (...) () (...) () (...) () (). () It is as if they are able to survive themselves. (...) () () (...) () () (...) () () ()) (...) ()"}, {"heading": "3.1 The Kantian Perspective on Cognitive Agency", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "4 Perception-Action Learning", "text": "This year, the time has come for a realignment, in which there will be a realignment."}, {"heading": "5 The Biophilosophical Per-", "text": "In fact, it is such that most people who are able, are able, themselves to determine what they want and what they want to do, are able to determine themselves. This also applies to the way in which they act, in which they act, in which they act, in which they act, in which they act, in which they act, in which they act, in which they act, in which they think, in which they think, in which they think, in which they think, in which they think, in which they act, in which they act, in which they act, in which they act, in which they act, in which they act, in which they act, in which they think, in which they think, in which they think, in which they think, they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they act, in which they act, in which they think, in which they act, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, in which they think, they think, in which they think, in which they think, they think, they think, they think, in which they think, they think, in which they think, they think, they think, in which they think, they think, in which they think, they think, in which they think, they think, they think, in which they think, in which they think, they think, in which they think, in which they think, they think, they think, they think, in fact, in which they think, in fact, in which they think."}, {"heading": "6 Conclusion", "text": "It is as if it was an attempt that did not exist. It is as if it had been an attempt that did not exist. It is as if it had been an attempt. It is as if it had been an attempt. It is as if it had been an attempt. It is as if it had been an attempt. It is as if it had been an attempt."}], "references": [{"title": "Philosophical investigations : the German text with a revised English translation by Ludwig Wittgenstein", "author": ["L. Wittgenstein"], "venue": "Oxford : Blackwell,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Online learning with kernels a new approach for sparsity control based on a coherence criterion", "author": ["J.-B. Pothin", "C. Richard"], "venue": "Machine Learning for Signal Processing, 2006. Proceedings of the 2006 16th IEEE Signal Processing Society Workshop on, Sept 2006, pp. 241\u2013245.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Online learning with kernels", "author": ["J. Kivinen", "A. Smola", "R. Williamson"], "venue": "Signal Processing, IEEE Transactions on, vol. 52, no. 8, pp. 2165\u2013 2176, Aug 2004.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 22, no. 10, pp. 1345\u2013 1359, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Transfer learning for reinforcement learning domains: A survey", "author": ["M.E. Taylor", "P. Stone"], "venue": "The Journal of Machine Learning Research, vol. 10, pp. 1633\u20131685, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Anomaly detection: A survey", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM Computing Surveys (CSUR), vol. 41, no. 3, p. 15, 2009.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin, Madison, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Rademacher complexities and bounding the excess risk in active learning", "author": ["V. Koltchinskii"], "venue": "The Journal of Machine Learning Research, vol. 11, pp. 2457\u20132485, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Online learning for latent dirichlet allocation", "author": ["M. Hoffman", "D.M. Blei", "F. Bach"], "venue": "Advances in Neural Information Processing Systems, vol. 23, pp. 856\u2013864, 2010.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Minimum description length principle", "author": ["J. Rissanen"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Language, Thought, and Other Biological Categories: New Foundations for Realism", "author": ["R.G. Millikan"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1987}, {"title": "Adaptive manifold learning", "author": ["Z. Zhang", "J. Wang", "H. Zha"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 34, no. 2, pp. 253\u2013265, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Detecting influential observations in kernel pca", "author": ["M. Debruyne", "M. Hubert", "J. Van Horebeek"], "venue": "Computational Statistics & Data Analysis, vol. 54, no. 12, pp. 3007\u20133019, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Real-time 3d visual slam with a hand-held rgb-d camera", "author": ["N. Engelhard", "F. Endres", "J. Hess", "J. Sturm", "W. Burgard"], "venue": "Proc. of the RGB- D Workshop on 3D Perception in Robotics at the European Robotics Forum, Vasteras, Sweden, vol. 2011, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Scale drift-aware large scale monocular slam", "author": ["H. Strasdat", "J. Montiel", "A. Davison"], "venue": "Proceedings of Robotics: Science and Systems (RSS), vol. 2, no. 3, 2010, p. 5.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Active slam and loop prediction with the segmented map using simplified models", "author": ["N. Fairfield", "D. Wettergreen"], "venue": "Field and Service Robotics: Results of the 7th International Conference, vol. 62. Springer, 2010, p. 173.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "The reflex arc concept in psychology", "author": ["J. Dewey"], "venue": "The Psychological Review, no. 3, pp. 356\u2013 370, 1896.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1896}, {"title": "What memory is for", "author": ["A. Glenberg"], "venue": "Behavioral and Brain Sciences, vol. 20, no. 1, pp. 1\u201355, 1997.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Philosophy in the Flesh : The Embodied Mind and Its Challenge to Western Thought", "author": ["G. Lakoff", "M. Johnson"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1999}, {"title": "The ecological approach to visual perception", "author": ["J.J. Gibson"], "venue": "Boston: Houghton-Mifflin,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1979}, {"title": "Affordances: Clarifying and evolving a concept", "author": ["J. McGrenere", "W. Ho"], "venue": "Proceedings of Graphics Interface 2000, Montreal, Canada, 2000, pp. 179\u2013186.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "Visual feedback control of hand movements", "author": ["J. Saunders", "D.C. Knill"], "venue": "J. of Neuroscience, vol. 24, no. 13, pp. 3223\u20133234, 2004.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "Bayesian model for reaching and grasping peripheral and occluded targets", "author": ["E.J. Schlicht", "P.R. Schrater"], "venue": "Journal of Vision, vol. 3, no. 9, p. 261, 2003.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Characterizing driver intention via hierarchical perception-action modeling", "author": ["D. Windridge", "A. Shaukat", "E. Hollnagel"], "venue": "Human-Machine Systems, IEEE Transactions on, vol. 43, no. 1, pp. 17\u201331, 2013.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Intelligence without representation", "author": ["R.A. Brooks"], "venue": "Artificial Intelligence, vol. 47, pp. 139\u2013 159, 1991.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1991}, {"title": "Schema abstraction in a multiple-trace memory model", "author": ["D.L. Hintzman"], "venue": "Psychological review, vol. 93, no. 4, pp. 411\u2013428, 1986.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1986}, {"title": "Autonomous development of a grounded object ontology by a learning robot", "author": ["J. Modayil", "B. Kuipers"], "venue": "Proceedings of the national conference on Artificial intelligence, vol. 22, no. 2. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2007, p. 1095.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1999}, {"title": "Perception-action learning as an epistemologically-consistent model for self-updating cognitive representation", "author": ["D. Windridge", "J. Kittler"], "venue": "Brain Inspired Cognitive Systems 2008. Springer, 2010, pp. 95\u2013134.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Cognitive development as optimisation", "author": ["J.G. Wolff"], "venue": "Computational Models of Learning, L. Bolc, Ed. Heidelberg: Springer-Verlag, 1987, pp. 161\u2013205. 11", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1987}, {"title": "What Computers Can\u2019t Do", "author": ["H. Dreyfus"], "venue": "New York: Harper and Row,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1972}, {"title": "Meaningful information, sensor evolution, and the temporal horizon of embodied organisms", "author": ["C.L. Nehaniv", "D. Polani", "K. Dautenhahn", "R. te Boekhorst", "L. Canamero"], "venue": "Artificial Life VIII, B. Standish, Abbass, Ed. MIT Press, 2002, pp. 345\u2013349.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2002}, {"title": "Some philosophical problems from the standpoint of artificial intelligence,\u201dMachine", "author": ["J. McCarthy", "P. Hayes"], "venue": "Intelligence, no", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1969}, {"title": "The symbol grounding problem", "author": ["S. Harnad"], "venue": "Physica D, no. 42, pp. 335\u2013346, 1990.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1990}, {"title": "Organization of architectures for cognitive vision systems", "author": ["G. Granlund"], "venue": "Proceedings of Workshop on Cognitive Vision, Schloss Dagstuhl, Germany, 2003.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2003}, {"title": "Exploratory learning structures in artificial cognitive systems", "author": ["M. Felsberg", "J. Wiklund", "G. Granlund"], "venue": "Image and Vision Computing, vol. 27, no. 11, pp. 1671\u20131687, 2009.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "Epistemic constraints on autonomous symbolic representation in natural and artificial agents", "author": ["D. Windridge", "J. Kittler"], "venue": "Studies in Computational Intelligence: Applications of Computational Intelligence in Biology. Springer Berlin Heidelberg, 2008, vol. 122, pp. 395\u2013422.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "A framework for hierarchical perception-action learning utilizing fuzzy reasoning", "author": ["D. Windridge", "M. Felsberg", "A. Shaukat"], "venue": "Cybernetics, IEEE Transactions on, vol. 43, no. 1, pp. 155\u2013 169, Feb 2013.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "A linear-complexity reparameterisation strategy for the hierarchical bootstrapping of capabilities within perception\u2013action architectures", "author": ["M. Shevchenko", "D. Windridge", "J. Kittler"], "venue": "Image and Vision Computing, vol. 27, no. 11, pp. 1702\u20131714, 2009.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "Genetic Epistemology", "author": ["J. Piaget"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1970}, {"title": "An introduction to artificial life.", "author": ["M. Sipper"], "venue": "Explorations in Artificial Life (special issue of AI Expert),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1995}, {"title": "The theory of human problem solving; reprinted in collins & smith (eds.)", "author": ["A. Newell", "H. Simon"], "venue": "Readings in Cognitive Science, section 1.3., 1976.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1976}, {"title": "Vision: A Computational Approach", "author": ["D. Marr"], "venue": "San Fr.: Freeman & Co.,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1982}, {"title": "How logic emerges from the dynamics of information", "author": ["P. G\u00e4rdenfors"], "venue": "Logic and Information Flow, pp. 49\u201377, 1994.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1994}, {"title": "Bootstrap learning a perceptually grounded object ontology", "author": ["J. Modayil"], "venue": "2005, retr. 9/5/2005 http://www.cs.utexas.edu/users/modayil/modayilproposal.pdf. 12", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Any such relational, non-essentialist notion of representation ([1]) has clear implications for artificial implementations of cognitive learning, which we shall explore in this paper.", "startOffset": 64, "endOffset": 67}, {"referenceID": 1, "context": "Online learning ([2, 3]) is a standard form of machinelearning induction in which data is presented serially in time, and in which learning generally takes place one instance at a time (it is thus the opposite of offline, or batch, learning).", "startOffset": 17, "endOffset": 23}, {"referenceID": 2, "context": "Online learning ([2, 3]) is a standard form of machinelearning induction in which data is presented serially in time, and in which learning generally takes place one instance at a time (it is thus the opposite of offline, or batch, learning).", "startOffset": 17, "endOffset": 23}, {"referenceID": 3, "context": "Such a system is thus inherently adaptive; the degree of adaptation to new data will vary from on-line learner to on-line learner (sophisticated variants may incorporate notions such as transfer learning ([4, 5]), anomaly detection ([6]), and active learning ([7, 8])).", "startOffset": 205, "endOffset": 211}, {"referenceID": 4, "context": "Such a system is thus inherently adaptive; the degree of adaptation to new data will vary from on-line learner to on-line learner (sophisticated variants may incorporate notions such as transfer learning ([4, 5]), anomaly detection ([6]), and active learning ([7, 8])).", "startOffset": 205, "endOffset": 211}, {"referenceID": 5, "context": "Such a system is thus inherently adaptive; the degree of adaptation to new data will vary from on-line learner to on-line learner (sophisticated variants may incorporate notions such as transfer learning ([4, 5]), anomaly detection ([6]), and active learning ([7, 8])).", "startOffset": 233, "endOffset": 236}, {"referenceID": 6, "context": "Such a system is thus inherently adaptive; the degree of adaptation to new data will vary from on-line learner to on-line learner (sophisticated variants may incorporate notions such as transfer learning ([4, 5]), anomaly detection ([6]), and active learning ([7, 8])).", "startOffset": 260, "endOffset": 266}, {"referenceID": 7, "context": "Such a system is thus inherently adaptive; the degree of adaptation to new data will vary from on-line learner to on-line learner (sophisticated variants may incorporate notions such as transfer learning ([4, 5]), anomaly detection ([6]), and active learning ([7, 8])).", "startOffset": 260, "endOffset": 266}, {"referenceID": 8, "context": "Techniques exist that partially address these limitations, such as in online learners that incorporate Dirichlet processes to spawn novel states in relation to the requirements of the data ([9]), which are thus capable of expanding their representational characteristics to a certain extent.", "startOffset": 190, "endOffset": 193}, {"referenceID": 9, "context": "g an MDL ([10]) or Occam\u2019s Razor -like criterion).", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "A motivation for this efficiency of representation criterion can be found in Biosemantics ([11]) humans have adapted over millions of years for efficiency of their representative capability (in terms of either the overall neuronal budget or the total energy of processing).", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "for example, manifold learning techniques ([12]) and non-linear dimensionality reduction techniques ([13]).", "startOffset": 43, "endOffset": 47}, {"referenceID": 12, "context": "for example, manifold learning techniques ([12]) and non-linear dimensionality reduction techniques ([13]).", "startOffset": 101, "endOffset": 105}, {"referenceID": 13, "context": "For instance, to give perhaps the simplest instance of this problem, in Simultaneous Location and Mapping (SLAM) robotics ([14, 15]), the robotic agent\u2019s model of the world necessarily depends upon its calculation of its own position and orientation in the world (i.", "startOffset": 123, "endOffset": 131}, {"referenceID": 14, "context": "For instance, to give perhaps the simplest instance of this problem, in Simultaneous Location and Mapping (SLAM) robotics ([14, 15]), the robotic agent\u2019s model of the world necessarily depends upon its calculation of its own position and orientation in the world (i.", "startOffset": 123, "endOffset": 131}, {"referenceID": 15, "context": "A SLAM agent will therefore position itself in the world (perhaps using active learning ([16]) in order to minimize model ambiguity) by leveraging its own, uncertain model of the world.", "startOffset": 89, "endOffset": 93}, {"referenceID": 16, "context": "We can thus consider the world model as being mapped on to a grid of motor impulses such that, in a sense, the agent\u2019s active capabilities provide the metric for its perceptual data (cf also ([17, 18, 19])).", "startOffset": 192, "endOffset": 204}, {"referenceID": 17, "context": "We can thus consider the world model as being mapped on to a grid of motor impulses such that, in a sense, the agent\u2019s active capabilities provide the metric for its perceptual data (cf also ([17, 18, 19])).", "startOffset": 192, "endOffset": 204}, {"referenceID": 18, "context": "We can thus consider the world model as being mapped on to a grid of motor impulses such that, in a sense, the agent\u2019s active capabilities provide the metric for its perceptual data (cf also ([17, 18, 19])).", "startOffset": 192, "endOffset": 204}, {"referenceID": 19, "context": "Falsification of a world model is, by comparison, straightforward in a standard autonomous robotic system, in that a world model typically constitutes a set of proposed haptic affordances ([20, 21]) gathered at-a-distance by a vision system.", "startOffset": 189, "endOffset": 197}, {"referenceID": 20, "context": "Falsification of a world model is, by comparison, straightforward in a standard autonomous robotic system, in that a world model typically constitutes a set of proposed haptic affordances ([20, 21]) gathered at-a-distance by a vision system.", "startOffset": 189, "endOffset": 197}, {"referenceID": 21, "context": "Thus, the visual model typically denotes a set of object hypotheses that may be verified via haptic contact ([22, 23]).", "startOffset": 109, "endOffset": 117}, {"referenceID": 22, "context": "Thus, the visual model typically denotes a set of object hypotheses that may be verified via haptic contact ([22, 23]).", "startOffset": 109, "endOffset": 117}, {"referenceID": 23, "context": "we are concerned with our proximity to other road users, to the curb and so on) ([25]).", "startOffset": 81, "endOffset": 85}, {"referenceID": 24, "context": "In robotics, when goals and sub-goals are explicitly delineated at each level, this is known as a subsumption hierarchy ([26]).", "startOffset": 121, "endOffset": 125}, {"referenceID": 25, "context": "Thus, for instance, an embodied autonomous robotic agent might, following active experimentation, spontaneously conceive a high-level concept of affordance, or schema ([27]), such as that of container.", "startOffset": 168, "endOffset": 172}, {"referenceID": 26, "context": "motor babbling ([28])), or via activity driven by lower-level action imperatives, that the previously defined concept \u2018object\u2019 yields an exception that allows for objects to be placed coextantly in the same location as another object (the original concept \u2018object\u2019 assumes that objects placed on top of each other do not then co-exist in the same location).", "startOffset": 16, "endOffset": 20}, {"referenceID": 27, "context": "(For an example of this approach utilizing first-order logic induction see ([29])).", "startOffset": 76, "endOffset": 80}, {"referenceID": 28, "context": "This particular representational enhancement can represent an enormous compression ([30]); a pixel-based representation has a parametric magnitude of P (with P and n being the intensity resolution and number of pixels, respectively), while an object-based representation typically has a parametric magnitude of \u223c n, o << n, where o is the number of objects.", "startOffset": 84, "endOffset": 88}, {"referenceID": 29, "context": "Perception-Action learning is a novel paradigm in robotics that aims to address significant deficits in traditional approaches to embodied computer vision ([31]).", "startOffset": 156, "endOffset": 160}, {"referenceID": 30, "context": "However, it is apparent that there exists in this approach, a very wide disparity between the visual parameterization of the agent\u2019s domain and its action capabilities within it ([32]).", "startOffset": 179, "endOffset": 183}, {"referenceID": 31, "context": "This disparity leads directly to the classical problems of framing ([33]) and symbol grounding ([34]) (note that this observation is not limited purely to vision based approaches - alternative modalities such as LIDAR and SONAR would also exhibit the same issues).", "startOffset": 68, "endOffset": 72}, {"referenceID": 32, "context": "This disparity leads directly to the classical problems of framing ([33]) and symbol grounding ([34]) (note that this observation is not limited purely to vision based approaches - alternative modalities such as LIDAR and SONAR would also exhibit the same issues).", "startOffset": 96, "endOffset": 100}, {"referenceID": 33, "context": "Perception-Action (P-A) learning aims to overcome these issues by adopting as its motto, \u2018action precedes perception\u2019 ([35, 36]).", "startOffset": 119, "endOffset": 127}, {"referenceID": 34, "context": "Perception-Action (P-A) learning aims to overcome these issues by adopting as its motto, \u2018action precedes perception\u2019 ([35, 36]).", "startOffset": 119, "endOffset": 127}, {"referenceID": 27, "context": "such that each hypothesizable action has a unique, discriminable outcome) [29, 37, 38].", "startOffset": 74, "endOffset": 86}, {"referenceID": 35, "context": "such that each hypothesizable action has a unique, discriminable outcome) [29, 37, 38].", "startOffset": 74, "endOffset": 86}, {"referenceID": 36, "context": "such that each hypothesizable action has a unique, discriminable outcome) [29, 37, 38].", "startOffset": 74, "endOffset": 86}, {"referenceID": 37, "context": "Of course, this P-A motor-babbling activity can take place in any P-A manifold, of whatever level of abstraction; we may thus, by combining the idea of P-A learning with the notion of hierarchical representation presented above, conceive of the notion of a hierarchical Perception-Action learner ([39]), in which a vertical representation hierarchy is progressively constructed for which randomized exploratory motor activity at the highest level of the corresponding motor hierarchy would rapidly converge on an ideal representation of the agent\u2019s world in terms of its affordance potentialities.", "startOffset": 297, "endOffset": 301}, {"referenceID": 10, "context": "Biosemantics, as a sub-branch of Biophilosophy, was proposed by Millikan ([11]) as an attempt to subsume certain philosophical questions of representation and perception within the purview of biology, and in particular, the contingencies that arise from consistency with respect to natural selection.", "startOffset": 74, "endOffset": 78}, {"referenceID": 38, "context": "In practical terms, this means that the organism must be able to discriminate those entities (food, predators, mates etc), that are key to its survival and reproduction ([40]).", "startOffset": 170, "endOffset": 174}, {"referenceID": 39, "context": "However, this describes a biological entity with a fixed, evolved representational framework (whether in a natural or simulated environment ([41])).", "startOffset": 141, "endOffset": 145}, {"referenceID": 40, "context": "In a sense, in a Perception-Action learning agent, \u201cthe environment has become it own representation\u201d, ([42]), which naturally represents a very significant compression of the information that an agent needs to retain.", "startOffset": 104, "endOffset": 108}, {"referenceID": 32, "context": "This relates to the issue of symbol grounding, a seminal problem in the conceptual underpinning of the classical approach to machine learning ([34]).", "startOffset": 143, "endOffset": 147}, {"referenceID": 41, "context": "In hierarchical P-A learning the problem is eliminated by virtue of the fact that representations are abstracted from the bottom-up ([43, 44, 45, 35]).", "startOffset": 133, "endOffset": 149}, {"referenceID": 42, "context": "In hierarchical P-A learning the problem is eliminated by virtue of the fact that representations are abstracted from the bottom-up ([43, 44, 45, 35]).", "startOffset": 133, "endOffset": 149}, {"referenceID": 43, "context": "In hierarchical P-A learning the problem is eliminated by virtue of the fact that representations are abstracted from the bottom-up ([43, 44, 45, 35]).", "startOffset": 133, "endOffset": 149}, {"referenceID": 33, "context": "In hierarchical P-A learning the problem is eliminated by virtue of the fact that representations are abstracted from the bottom-up ([43, 44, 45, 35]).", "startOffset": 133, "endOffset": 149}], "year": 2015, "abstractText": "Online learning is a familiar problem setting within Machine-Learning in which data is presented serially in time to a learning agent, requiring it to progressively adapt within the constraints of the learning algorithm. More sophisticated variants may involve concepts such as transfer-learning which increase this adaptive capability, enhancing the learner\u2019s cognitive capacities in a manner that can begin to imitate the open-ended learning capabilities of human beings. We shall argue in this paper, however, that a full realization of this notion requires that, in addition to the capacity to adapt to novel data, autonomous online learning must ultimately incorporate the capacity to update its own representational capabilities in relation to the data. We therefore enquire about the philosophical limits of this process, and argue that only fully embodied learners exhibiting an a priori perception-action link in order to ground representational adaptations are capable of exhibiting the full range of human cognitive capability. keywords: philosophy of machine learning, perception-action learning, online learning", "creator": "LaTeX with hyperref package"}}}