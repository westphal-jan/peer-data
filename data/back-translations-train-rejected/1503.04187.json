{"id": "1503.04187", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Mar-2015", "title": "A Minimal Active Inference Agent", "abstract": "Research on the so-called \"free-energy principle'' (FEP) in cognitive neuroscience is becoming increasingly high-profile. To date, introductions to this theory have proved difficult for many readers to follow, but it depends mainly upon two relatively simple ideas: firstly that normative or teleological values can be expressed as probability distributions (active inference), and secondly that approximate Bayesian reasoning can be effectively performed by gradient descent on model parameters (the free-energy principle). The notion of active inference is of great interest for a number of disciplines including cognitive science and artificial intelligence, as well as cognitive neuroscience, and deserves to be more widely known.", "histories": [["v1", "Fri, 13 Mar 2015 18:58:25 GMT  (360kb)", "http://arxiv.org/abs/1503.04187v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["simon mcgregor", "manuel baltieri", "christopher l buckley"], "accepted": false, "id": "1503.04187"}, "pdf": {"name": "1503.04187.pdf", "metadata": {"source": "CRF", "title": "A Minimal Active Inference Agent", "authors": ["Simon McGregor", "Manuel Baltieri", "Christopher L. Buckley"], "emails": ["s.mcgregor@sussex.ac.uk,", "m.baltieri@sussex.ac.uk,", "c.l.buckley@sussex.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 150 3.04 187v 1 [cs.A I] 1 3M arThis paper attempts to provide readers with a range of scientific backgrounds with an accessible introduction to active conclusions and informative free energy. In this paper we present an agent-based model in which an agent attempts to make predictions about his position in a discredited one-dimensional world using FEP methods."}, {"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want to do and what they want to do."}, {"heading": "2 The Free Energy Formalism", "text": "Following the work of Dayan et al. [12] on the Helmholtz machine, we define two densities that constitute the free energy concept to be optimized: \u2022 a generative density p (1), which represents the common probability of world states and sensory input s based on a probable predictive model m by the agent or the brain \u2022 a recognition density q (1), which encodes the agent's (or brain) beliefs about the causes of the phenomenon with a series of brain states b, which comprehensively describe these beliefs. IFE is then defined as: F (s, b) = \u03b6 q (B) ln q (3) p (1) The optimization of this term then requires that a brain (agent) is able to \u2022 change its perception by using the inner states b to change its beliefs q (b) and thus improve its ability to explain the causes of the world by making them more dependent on each other, or by aligning them with the different energy forms."}, {"heading": "2.1 Perception", "text": "F (s, b) = D (q (Canadian | b) | | p (Canadian | s, m)) \u2212 ln p (s | m) (2), where D (q (Canadian | b) | | p (Canadian | s, m) is the Kullback Leibler (KL) divergence between the recognition density (q (Canadian | b) and the actual back of the world states (p (Canadian | s); \u2212 ln p (Canadian | m) is the surprise of the sensory input that the brain cannot directly evaluate. Changing the group of brain states b allows the back of the world states to approximate the brain's views of the world. Ideally, if the two coincide, free energy would be equal to surprise (the KL divergence would be zero, Appendix [A.2]) and would thus be able to interpret this otherwise hidden concept to the brain."}, {"heading": "2.2 Action", "text": "An alternative form instead shows how the free energy depends on the sensory input, which can be considered dependent on a representing the series of actions a system can perform in a given environment, and then returns s (a).F (s, b) = D (g (economic input) | | p (economic input)) \u2212 < ln p (s (a) | economic input, m) > q (3) with D (q (economic input) | | p (economic input), KL divergence between the recognition density q (economic belief about the causes / world states) and the previous (belief) p (economic input) of the world states. < ln p (s (a) | economic input, m) > q is the expectation of sensations s (a) under the density q. In this formulation we can see how the free energy is expressed by an optimal density (action)."}, {"heading": "3 A discretized approach to the FEP", "text": "In this paper, we consider a discrete representation of our state variables, specifically \"Q,\" \"Q\" and \"B,\" respectively as world and internal states in time ti + 1. In their discrete version, information-free energy (IFE) becomes a quantity that describes an action a and a sensation s to two possible internal states b and b, \"based on a generative and recognizable density attributed to the agent by the theorist. Identification density describes the internal\" encoding \"of external world states, while generative density is the\" predictive model \"of physical dynamics.\" Most active inference papers use a continuous spatial definition of information-free energy F [17, 14, 13] but in this paper, we consider a discrete-pace version: F (b, s, a) = implicit proceeding of physical dynamics. \""}, {"heading": "3.1 Practical IFE Minimisation", "text": "The value of IFE minimization as a computational model of active inference, either for machine learning or in neuroscience models, depends on how realistic the proposed mechanisms for minimizing IFE are. In general, IFE minimization is mathematically not much more tractable than the sum required to perform an exact Bavarian inference, because it includes a sum (or, in the ongoing case, integral) of all possible world states. Of course, it is conceivable that the brain can implicitly calculate this integral using physical means that are computationally expensive to simulate. However, IFE minimization is much easier to calculate when certain conditions are met, how agent-environmental dynamics work and how the agent represents world states. These conditions, together with additional approximations, allow the IFE minimization to form a tractable computational approach to active inference [15, 16] and it is argued to provide a neural function [13]."}, {"heading": "3.2 Unifying Beliefs and Desires", "text": "We have shown why minimizing F (b1, b0, s0, a0) in relation to b1 is an approximate Bayesian filtering, and why minimizing F (b *, b0, s0, a0) in relation to a0 is an optimal control. In a context of machine learning, it will often be convenient to maintain a distinction between belief and intention, and the computational costs of maintaining the distinction are low, because the function F (and its derivatives) can be characterized by any argument. However, the formulation of free energy in neuroscience postulates a different mechanism. The same IFE term is used to provide a gradient term that is applied to the dynamics of both the inner state and the action [13]."}, {"heading": "4 A Minimal Free-Energy Agent", "text": "This section outlines in detail how the active inference formalism works for a \"minimal\" abstract model of active agency. Agents are modeled as organisms that inhabit a single discrete space (a \"cell\") in a one-dimensional discrete world of time and are sensitive to a chemical that occurs in their environment; the world has periodic boundary conditions (i.e. it \"wraps itself around the edges\"), and each cell contains a concentration of the chemical; the concentration of the chemical follows a gradient in the environment, being highest in a \"source cell\" and lowest in the cell farthest from the source; if the reader wants, this can be imagined as the result of a diffusion process; the agent's interactions with its environment are extremely low: it has a 1-bit sensor that fires with a probability that is the furthest from the cell's concentration of the chemical, the one that is accumulator, and the other one that is trying to move in a Bit or Bit direction."}, {"heading": "4.1 Definitions", "text": "We begin by describing the simulation framework for our agents and the environments they inhabit; the dynamics of the agent-environment are modeled in discrete increments of time; the agent is presented as a system with an internal \"brain state\" b; after sending an action a, the agent receives sensory input s and updates his brain to a new state b \u00b2; he then sends out a new action a \u00b2, and the cycle begins again. Sometimes, it is worth thinking about how the dynamic of the agent progresses when fed an arbitrary series of sensory inputs by an experimenter who resembles Descartes \"malignant demon,\" but in general we are interested in the coupled dynamics of an agent and its \"natural\" environment; the environment is presented as a system with a state in which the dynamics of the system change depending on its current state and the action of the agent."}, {"heading": "4.2 Formulation", "text": "In our case, the environment is modeled so that it would have a length of n = 16 cells and its state is therefore only from the position of the agent b = = = previous position of the agent b = = previous position of the agent b = = = previous position of the agent b = = = previous position of the agent b = = = previous position of the agent is described as follows: The brain state of the agent b \u00b2 is a vector of real numbers b \u00b2 1, \u00b7 \u00b7, b \u00b2 n and we use a softmax encoding: q (namib \u00b2) = the internal beliefs of the agent about his position at the time t + 1 is described as follows: The brain state of the agent b \u00b2 is a vector of real numbers b \u00b2 1, \u00b7, b \u00b2 n and we use a softmax encoding: q (namib \u00b2) = the internal perception of the agent about his position at the time t \u00b2 s. \""}, {"heading": "5 Results", "text": "An example of the dynamics of a simulated agent is shown in Figure 2. The trajectory of the agent over time, and its subjective security in relation to its position, can be seen in the figure. The objective of the agent is to occupy locations in the direction of the lower graph that exhibit a higher deliberate probability than other locations (the intention distribution is shown on the right side of the figure).The only ecological indication of its location is its sensor reading, which probably detects the local concentration of a chemical.The spatial gradient of the chemical concentration is shown on the left side of the graph. It can be seen that the agent is effective in simultaneous online estimation of its position, with a short period of confusion. It is worth noting that the \"physics\" of the agent-environment system is very simple, the agent's task is not completely trivial."}, {"heading": "5.1 Inferential Quality and Task Performance", "text": "Although the quality of the drug's conclusions decreases markedly with the deterioration of IFE optimization, it is not immediately clear what effect this should have on its performance. Figure 5 shows the typical position profile (over 500 time steps) for agents using weak, moderate, and strong optimization techniques (characterized by 20, 50, or 100 downward steps between time steps).Agents were instructed to maintain their location around a specific target, and initialized in equally random localisations.In fact, the statistical behavior of a weakly minimizing agent appears to be re-tagged.This is interesting because it suggests that accurate localization is not particularly important for optimal positioning control in this simple task. According to embodied / situated cognition theories, many tasks can be accomplished by directly evaluating simple sensor imotor correlations without the need for high verifiability; this phenomenon clearly demonstrates."}, {"heading": "6 Discussion", "text": "The IFE principle promises exciting new action and perception within the same powerful framework. However, the influence of these ideas has been hampered by the complexity of the current format, and the central force of the original format is the potential to unify both action and perception within a single theoretical framework."}, {"heading": "6.1 Learning Without Reinforcement: Where Does The Intelligence Come From?", "text": "One of the most disappointing aspects of the active follow-up is that it offers almost no mechanistic explanation for a particular pattern of intelligent behavior. Actively, the sensorimotor behavior of the agent results from the already existing structure of its sensory expectations. All of the agent's intelligence is encoded in the mechanism that generates these expectations, about which the active follow-up itself has little or nothing to say. For machine learning or robotic applications, this is not a viable alternative to conventional paradigms such as enhanced learning or supervised learning. The challenges faced by robot control lie precisely in understanding how certain desired external behaviors translate into sensory and motor patterns; in order to build a robot according to principles of active inference, it is necessary to define exactly what the robot has to expect. It seems likely that the active follow-up is strong enough that a principle reinforcement learning task can be formulated as a built-in expectation, but only to explain the internal signal parameter, which can be associated with an internal signal model."}, {"heading": "A Background", "text": "A.1 Kronecker delta Named after Leopold Kronecker, the Kronecker delta is a function of two variables normally represented as \u03b4xy: \u03b4xy = {1 if x = y 0 otherwise (12) A.2 Kullback-Leibler (KL) divergenceAs a measure of the difference between two probability densities (e.g. q (x) and p (x))), the Kullback-Leibler divergence of Solomon Kullback and Richard Leibler is defined in [26] as follows: D (q (x) | p (x))) = ig q (x) = q (x) log q (x) dx (13) important properties: \u2022 D (q (x) | p (x) 6 = D (p (x) | q (x)))))) (the divergence is not symmetrical) \u2022 D (q (x) | p (x) = ig returns a natural density of 0 \u2022 D (x) | p (x) = 0 = (converge (x) (x), if the divergence (x) (x) is required) (p)."}, {"heading": "B Calculating IFE and its Gradient", "text": "B.1 IFEWe define the IFE F asF (b), b), b), b), b), b), a), p (b), p (b), p (b), p (b), p (b), p (b), p (), p (), p (), p (), p (), p (b), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (, p, p, p, p (, p, p, p, p, p, p, p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (), p (, p (), p (), p (), p (, p (), p (), p (), p (, p (), p (), p (), p (, p (), p (, p (), p (), p (), p (, p (), p (), p (, p (), p (, p (, p (), p (, p (), p (, p (), p (, p (, p (), p (), p (, p (, p (), p (, p (), p (, p (, p (), p (, p (), p (, p (), p (,"}], "references": [{"title": "Philosophy of science: Theories of almost everything", "author": ["P.M. Binder"], "venue": "Nature", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Anthropic bias: Observation selection effects in science and philosophy", "author": ["Nick Bostrom"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Superminds: People Harness Hypercomputation, and More", "author": ["Selmer Bringsjord", "Michael John Zenzen"], "venue": "Norwell, MA, USA: Kluwer Academic Publishers,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Cambrian intelligence: the early history of the new AI", "author": ["Rodney A Brooks"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "The Anthropic Principle and its Implications for Biological Evolution [and Discussion]", "author": ["B. Carter", "W.H. McCrea"], "venue": "Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1983}, {"title": "Simplicity: a unifying principle in cognitive science?", "author": ["Nick Chater", "Paul Vit\u00e1nyi"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Natural Intensions", "author": ["Ron Chrisley"], "venue": "Adaptation and Representation", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Clustering by compression", "author": ["Rudi Cilibrasi", "Paul MB Vit\u00e1nyi"], "venue": "Information Theory, IEEE Transactions on 51.4", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Whatever next? Predictive brains, situated agents, and the future of cognitive science", "author": ["A. Clark"], "venue": "BEHAVIORAL AND BRAIN SCIENCES", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Being there: Putting brain, body, and world together again", "author": ["Andy Clark"], "venue": "MIT press,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Every good regulator of a system must be a model of that system", "author": ["Roger C. Conant", "Ross W. Ashby"], "venue": "In: International Journal of Systems Science", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1970}, {"title": "The Helmholtz machine", "author": ["P. Dayan", "G.E. Hinton", "R.M. Neal"], "venue": "Neural Computation", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "The free-energy principle: a unified brain theory?", "author": ["Karl Friston"], "venue": "Nature Reviews Neuroscience", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "A free energy principle for the brain", "author": ["Karl Friston", "James Kilner", "Lee Harrison"], "venue": "Journal of Physiology-Paris", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Variational free energy and the Laplace approximation", "author": ["Karl Friston"], "venue": "(Jan", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Hierarchical Models in the Brain.", "author": ["Karl J. Friston"], "venue": "PLoS Computational Biology", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Reinforcement learning or active inference?", "author": ["Karl J Friston", "Jean Daunizeau", "Stefan J Kiebel"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Reinforcement Learning or Active Inference?", "author": ["Karl J. Friston", "Jean Daunizeau", "Stefan J. Kiebel"], "venue": "Ed. by Olaf Sporns. issn: 1932-6203.doi: 10.1371/journal.pone.0006421. url: http://dx.plos.org/10.1371/journal.pone", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Active inference and agency: optimal control without cost functions.", "author": ["Karl J. Friston", "Spyridon Samothrakis", "P. Read Montague"], "venue": "Biological Cybernetics", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Perceptions as Hypotheses: Saccades as Experiments", "author": ["Karl J. Friston"], "venue": "doi: 10.3389/fpsyg.2012.00151. url: http://www.frontiersin.org/Perception\\_Science/10.3389/fpsyg.2012.00151/abstract", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "\u00dcber formal unentscheidbare S\u00e4tze der Principia Mathematica und verwandter Systeme I", "author": ["Kurt G\u00f6del"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1931}, {"title": "Open problems in universal induction & intelligence", "author": ["Marcus Hutter"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Universal Algorithmic Intelligence: A Mathematical Top\u2192Down Approach", "author": ["Marcus Hutter"], "venue": "Artificial General Intelligence", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Probability theory: the logic of science", "author": ["Edwin T Jaynes"], "venue": "Cambridge university press,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Justification as truth-finding efficiency: how Ockham\u2019s Razor works", "author": ["Kevin T Kelly"], "venue": "Minds and Machines", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2004}, {"title": "On Information and Sufficiency", "author": ["Kullback", "R.A. Leibler"], "venue": "The Annals of Mathematical Statistics", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1951}, {"title": "Vitanyi. An Introduction to Kolmogorov Complexity and Its Applications. 3rd ed", "author": ["Ming Li", "Paul M.B"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}, {"title": "Minds, machines and G\u00f6del", "author": ["John R Lucas"], "venue": "Philosophy", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1961}, {"title": "Algorithmic Information Theory and Novelty Generation", "author": ["Simon McGregor"], "venue": "Proceedings of the 4th Internation Joint Workshop on Computational Creativity", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "Stationary algorithmic probability", "author": ["Markus M\u00fcller"], "venue": "Theoretical Computer Science", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "The Emperor\u2019s New Mind", "author": ["Roger Penrose"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1989}, {"title": "A philosophical treatise of universal induction", "author": ["Samuel Rathmanner", "Marcus Hutter"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}, {"title": "Algorithmic Theories of Everything", "author": ["J. Schmidhuber"], "venue": "Tech. rep. IDSIA- 20-00,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2000}, {"title": "Discovering neural nets with low Kolmogorov complexity and high generalization capability", "author": ["J\u00fcrgen Schmidhuber"], "venue": "In:Neural Networks", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1997}, {"title": "The Speed Prior: a new simplicity measure yielding near-optimal computable predictions", "author": ["J\u00fcrgen Schmidhuber"], "venue": "Computational Learning Theory. Springer", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2002}, {"title": "Minds, brains, and programs", "author": ["John R Searle"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1980}, {"title": "The Foundations of Solomonoff Prediction", "author": ["Tom Florian Sterkenburg"], "venue": "MA thesis. University of Utrecht,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "On computable numbers, with an application to the Entscheidungsproblem", "author": ["Alan Mathison Turing"], "venue": "J. of Math", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1936}, {"title": "Solomonoff Induction: A Solution to the Problem of the Priors?", "author": ["Aron Vallinder"], "venue": "MA thesis. Lund University,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Physical limits of inference", "author": ["David H Wolpert"], "venue": "Physica D: Nonlinear Phenomena", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2008}], "referenceMentions": [{"referenceID": 12, "context": "Furthermore one of the central strengths of the formalism is its potential to unite an understanding off action and perception within a single unified framework [13].", "startOffset": 161, "endOffset": 165}, {"referenceID": 12, "context": "The foundational premise of the IFE principle is that adaptive agents are defined by their ability occupy only a limited repertoire of physical states [13].", "startOffset": 151, "endOffset": 155}, {"referenceID": 13, "context": "Thus, the very fact that a living system maintains its organisation in the face of environmental perturbation supposedly justifies adverting to the \u201cfree-energy principle\u201d [14].", "startOffset": 172, "endOffset": 176}, {"referenceID": 12, "context": "In this sense, active inference blurs the distinction between a prediction and an intention; both are treated as conceptions-of-thefuture, with the main difference being in what physical variables change most when the reality turns out to be different from the expectation [13].", "startOffset": 273, "endOffset": 277}, {"referenceID": 8, "context": "Recent discussions of active inference have tended to occur within the context of a neuroscientific theory known as the predictive coding hypothesis [9].", "startOffset": 149, "endOffset": 152}, {"referenceID": 15, "context": "Within this hierarchical predictive coding model for active inference [16], efferent (motor) signals are treated similarly to other signals.", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "The workings of this process can be a little difficult to understand at first; the idea is that the neural architecture imposes certain specific patterns of expectances on instantaneous kinesthetic sensations [13].", "startOffset": 209, "endOffset": 213}, {"referenceID": 11, "context": "[12] on the Helmholtz machine, we define 2 densities that will constitute the free energy term to be optimised:", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Most active inference papers use a continuous-space definition of the informational free energy F [17, 14, 13], but in this paper we will consider a discretespace version:", "startOffset": 98, "endOffset": 110}, {"referenceID": 13, "context": "Most active inference papers use a continuous-space definition of the informational free energy F [17, 14, 13], but in this paper we will consider a discretespace version:", "startOffset": 98, "endOffset": 110}, {"referenceID": 12, "context": "Most active inference papers use a continuous-space definition of the informational free energy F [17, 14, 13], but in this paper we will consider a discretespace version:", "startOffset": 98, "endOffset": 110}, {"referenceID": 12, "context": "IFE has several interesting properties, corresponding to different rearrangements of the formula, which give rise to different interpretations [13] as we described in the previous section.", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "Note that the second statement draws a distinction between belief P (\u03c81 | b1) and desire P (\u03c8 | b) which does not reflect the original maths of the active inference framework [18].", "startOffset": 175, "endOffset": 179}, {"referenceID": 14, "context": "These conditions, along with additional approximations, allow IFE minimisation to form a tractable computational approach to active inference [15, 16] and are argued [13] to provide an elegant model of neural function.", "startOffset": 142, "endOffset": 150}, {"referenceID": 15, "context": "These conditions, along with additional approximations, allow IFE minimisation to form a tractable computational approach to active inference [15, 16] and are argued [13] to provide an elegant model of neural function.", "startOffset": 142, "endOffset": 150}, {"referenceID": 12, "context": "These conditions, along with additional approximations, allow IFE minimisation to form a tractable computational approach to active inference [15, 16] and are argued [13] to provide an elegant model of neural function.", "startOffset": 166, "endOffset": 170}, {"referenceID": 12, "context": "The same IFE term is used to provide a gradient term which is applied to the dynamics of both internal state and action [13].", "startOffset": 120, "endOffset": 124}, {"referenceID": 17, "context": "Active inference simulations such as [18] usually assume a differential equation model in which brain state variables follow a negative IFE gradient in", "startOffset": 37, "endOffset": 41}, {"referenceID": 18, "context": "Furthermore while central strength of the original formalism is it potential to unify both action and perception within a single theoretical framework yet to date agent based approaches have largely been absence except see [19, 17].", "startOffset": 223, "endOffset": 231}, {"referenceID": 16, "context": "Furthermore while central strength of the original formalism is it potential to unify both action and perception within a single theoretical framework yet to date agent based approaches have largely been absence except see [19, 17].", "startOffset": 223, "endOffset": 231}, {"referenceID": 10, "context": "Friston\u2019s argument about minimising entropy is very similar to the argument presented in \u201cEvery Good Regulator of a System Must Be a Model of That System\u201d, [11].", "startOffset": 156, "endOffset": 160}, {"referenceID": 19, "context": "There is no reason in principle why an agent proceeding according to active inference should not have expectations regarding its information gain as well as its sensory input, and recent research by Friston and colleagues [20] explicitly models infotaxis by exactly such a method.", "startOffset": 222, "endOffset": 226}], "year": 2015, "abstractText": "Research on the so-called \u201cfree-energy principle\u201d (FEP) in cognitive neuroscience is becoming increasingly high-profile. To date, introductions to this theory have proved difficult for many readers to follow, but it depends mainly upon two relatively simple ideas: firstly that normative or teleological values can be expressed as probability distributions (active inference), and secondly that approximate Bayesian reasoning can be effectively performed by gradient descent on model parameters (the freeenergy principle). The notion of active inference is of great interest for a number of disciplines including cognitive science and artificial intelligence, as well as cognitive neuroscience, and deserves to be more widely known. This paper attempts to provide an accessible introduction to active inference and informational free-energy, for readers from a range of scientific backgrounds. In this work introduce an agent-based model with an agent trying to make predictions about its position in a one-dimensional discretized world using methods from the FEP.", "creator": "LaTeX with hyperref package"}}}