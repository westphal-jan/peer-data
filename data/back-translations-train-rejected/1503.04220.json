{"id": "1503.04220", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Mar-2015", "title": "Fuzzy Mixed Integer Optimization Model for Regression Approach", "abstract": "Mixed Integer Optimization has been a topic of active research in past decades. It has been used to solve Statistical problems of classification and regression involving massive data. However, there is an inherent degree of vagueness present in huge real life data. This impreciseness is handled by Fuzzy Sets. In this Paper, Fuzzy Mixed Integer Optimization Method (FMIOM) is used to find solution to Regression problem. The methodology exploits discrete character of problem. In this way large scale problems are solved within practical limits. The data points are separated into different polyhedral regions and each region has its own distinct regression coefficients. In this attempt, an attention is drawn to Statistics and Data Mining community that Integer Optimization can be significantly used to revisit different Statistical problems. Computational experimentations with generated and real data sets show that FMIOM is comparable to and often outperforms current leading methods. The results illustrate potential for significant impact of Fuzzy Integer Optimization methods on Computational Statistics and Data Mining.", "histories": [["v1", "Fri, 13 Mar 2015 21:10:38 GMT  (232kb)", "http://arxiv.org/abs/1503.04220v1", "Conference Paper"]], "COMMENTS": "Conference Paper", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["arindam chaudhuri", "dipak chatterjee"], "accepted": false, "id": "1503.04220"}, "pdf": {"name": "1503.04220.pdf", "metadata": {"source": "CRF", "title": "Fuzzy Mixed Integer Optimization Model for Regression Approach", "authors": ["Arindam Chaudhari", "Dipak Chatterjee"], "emails": ["arindam_chau@yahoo.co.in"], "sections": [{"heading": null, "text": "This year, it is more than ever before in the history of the city, where it has gone down in history as never before."}, {"heading": "II. GEOMETRY OF REGRESSION APPROACH", "text": "In the classical regression setting, we have n data points niRyRxyx i d iii,......., 1,,), (=,,,,. We intend to find a linear relationship between ix and iy, i.e., ixy ii, \"\u03b2, where the coefficients dR, \u03b2 are found by minimizing the coefficients dR, \u03b2 = \u2212 ni ii xy 1 2\" (\u03b2 or \u2211 = \u2212 ni ii xy 1 \"| \u03b2. In this process k points are assigned to K groups where K are user-defined parameters. In addition, the optimization model is further improved to identify and eliminate outliers in the dataset (Figure 2). In contrast, traditional regression models are grouped into K groups where K are user-defined optimization parameters."}, {"heading": "III. FMIOM FOR REGRESSION", "text": "In this section, we present the FMIOM approach to regression. We start with the Mixed Integer Optimization Method (MIOM) to assign points to groups, which is impractical due to dimensionality problems. First, we assign points to clusters, then we assign groups represented by polyhedral regions cP to clusters. Finally, we introduce the regression algorithm to automatically determine non-linear transformations of explanatory variables to improve the predictive power of the method."}, {"heading": "A. Assigning Points to Groups", "text": "The training iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"}, {"heading": "B. Clustering Algorithm", "text": "Nearest Prototype) 1, (> \u2212 kNPk clustering algorithmdefined on dR [4] in), (yx space is used to findL clusters."}, {"heading": "C. Assigning Points to Groups: Practical Approach", "text": "Continuing the clustering algorithm of the previous section, we can find K clusters, define them as our final groups, and find the best k coefficient for each group by solving separate linear regression problems. \u2212 Another central point in the regression models is the presence of outlier models. MIOM presents the next outlier potential by eliminating points in clusters that tend to weaken the adjustment of the predictor coefficients. \u2212 LLLCl = cluster l and denote) (il assxi'cluster), the optimization problems (1), we define the following binary variables for} 0 ikjar Kk."}, {"heading": "D. Assigning Groups to Polyhedral Regions", "text": "We identify K-point groups that solve optimization problems (3). In this section, we determine a geometric representation of group k by a polyhedron kP. It is possible that convex skulls of K-groups overlap and therefore we are not able to define disjunct areas of group kP that contain all points of group kP. Therefore, our approach is based on separating groups with the aim of minimizing injury. We first outline how we define the group kto group rkr <,. We consider the following two fuzzy linear optimization problems: imizemin group kp."}, {"heading": "E. Non linear Data Transformations", "text": "In order to improve the predictive power of FMIOM, we extend explanatory variables by non-linear transformations. In particular, we consider transformations xx log, 2 and x 1. We extend each d-dimensional vector ', 1,),..., (diii xxx = with djx xxji jiji,......., 1, 1, log,,,, 2, = and apply FMIOM to resulting d4-dimensional vectors, but the increased dimension slows down the computation time. For this reason, a simple heuristic method is used to select which transformation of which variable should be included in the dataset."}, {"heading": "F. Regression Algorithm", "text": "The regression algorithm consists of the following steps: (a) Nonlinear transformation: Extension of the original data set with nonlinear transformations using the method described in section III (E); (b) Pre-processing: Use a fuzzy clustering algorithm to find nL < < Assign clusters of data points; (c) Assign clusters to groups: Solve optimization problems (3) to determine which points belong to which group, while potential outliers are eliminated; (d) Assign groups to polyhedral regions: Solve linear optimization problems (5) and (6) for all group pairs and define polyhedra as an equation (7). (e) Recalculation of \u03b2: Once polyheder kPairs are identified, we recalculate 4-4-4-4-0-4-4-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-4-4-0-0-0-0-0-0-0-0-4-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-4-0-0-0-0-0-0-4-0-0-0-4-0-0-4-0-0-0-4-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-4-"}, {"heading": "IV. COMPUTATIONAL RESULTS AND DISCUSSIONS", "text": "This year it is more than ever before in the history of the city."}, {"heading": "V. CONCLUSION", "text": "The FMIOM presents a new approach to solving the regression problem. The methodology takes advantage of the discrete nature of the problem and includes clustering to reduce dimensionality, nonlinear transformations to improve predictive power, mixed integer optimization to group points, and elimination of outlier data for representation groups by polyhedral regions, solving large-scale problems within practical limits. Data points are divided into different polyhedral regions, each region having its own distinct regression coefficients. Results from real data sets are encouraging because FMIOM has surpassed other techniques such as LLSR and ANN. We hope that these encouraging results will motivate statistics, data mining, and machine learning to re-examine integer optimization as a practical tool in statistical computation."}], "references": [{"title": "Mathematical Programming in Statistics", "author": ["T.S. Arthanari", "Y. Dodge"], "venue": "Wiley Classics Library Edition, Wiley Interscience, New York", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Optimal Decision Trees", "author": ["K.P. Bennett", "J.A. Blue"], "venue": "Mathematical Report 214, Department of Mathematical Sciences, Rensselaer Polytechnic Institute, Troy, New York", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1984}, {"title": "Computational Study of families of Mixed Integer Quadratic Programming Problems", "author": ["D. Bienstock"], "venue": "Mathematical Programming, vol. 74, pp. 121\u2013140", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Pattern Recognition with Fuzzy Objective Function Algorithms", "author": ["J.C. Bezdek"], "venue": "Plenum Press, New York", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1986}, {"title": "Classification and Regression Trees", "author": ["L. Breiman", "J. Friedman", "R. Olshen", "C. Stone"], "venue": "Wadsworth International, Belmont, California", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1984}, {"title": "Multivariate Adaptive Regression Splines", "author": ["J. Friedman"], "venue": "Annals of Statistics, vol. 19, no. 1, pp. 1\u201367", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1991}, {"title": "Greedy Function Approximation: A Gradient Boosting  Machine", "author": ["J. Friedman"], "venue": " hhtp://wwwstat.stanford.edu/~jhf/ftp/trebst.ps", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "Technical Report 989", "author": ["H. Kim", "W.Y. Loh", "CRUISE User Manual"], "venue": "Department of Statistics, University of Wisconsin, Madison", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Linear and Nonlinear separation of Patterns by Linear Programming", "author": ["O.L. Mangasarian"], "venue": "Operations Research, vol. 13, no. 3, pp. 444\u2013452", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1965}, {"title": "Programs for Machine Learning", "author": ["R. Quinlan"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1993}, {"title": "Everything old is new again: A fresh look at historical approaches in Machine Learning", "author": ["R. Rifkin"], "venue": "PhD Thesis, Electrical Engineering, Computer Science and Operations Research, Massachusetts Institute of Technology, Cambridge", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Robust Regression and Outlier Detection", "author": ["P.J. Rousseeuw", "A.M. Leroy"], "venue": "Wiley, New York", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1987}, {"title": "Modern Regression Methods", "author": ["T.P. Ryan"], "venue": "Wiley Series in Probability and Statistics, John Wiley and Sons, New York", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "The Nature of Statistical Learning Theory", "author": ["V. Vapnik"], "venue": "Springer Verlag, New York", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1999}, {"title": "Fuzzy Logic and its Applications", "author": ["L.A. Zadeh"], "venue": "Academic Press, New York", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1965}, {"title": "The concept of a linguistic variable and its application to approximate reasoning\u2013I", "author": ["L.A. Zadeh"], "venue": "Information Science, vol. 8, pp. 199\u2013249", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1975}, {"title": "The concept of a linguistic variable and its application to approximate reasoning\u2013II", "author": ["L.A. Zadeh"], "venue": "Information Science, vol. 8, pp. 301\u2013357", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1975}, {"title": "The concept of a linguistic variable and its application to approximate reasoning\u2013III", "author": ["L.A. Zadeh"], "venue": "Information Science, vol. 8, pp. 43\u201380", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1976}], "referenceMentions": [{"referenceID": 1, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 10, "endOffset": 13}, {"referenceID": 4, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 15, "endOffset": 18}, {"referenceID": 7, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 20, "endOffset": 23}, {"referenceID": 8, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 25, "endOffset": 28}, {"referenceID": 5, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 78, "endOffset": 81}, {"referenceID": 8, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 116, "endOffset": 119}, {"referenceID": 10, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 121, "endOffset": 125}, {"referenceID": 13, "context": "0, CRUISE [2], [5], [8], [9], Multivariate Adaptive Regression Splines (MARS) [6] and Support Vector Machines (SVM) [9], [11], [14].", "startOffset": 127, "endOffset": 131}, {"referenceID": 0, "context": "While Continuous Optimization methods have been widely used in Statistics and have significant impact in last 30 years [1], Integer Optimization has limited impact in Statistical Computing.", "startOffset": 119, "endOffset": 122}, {"referenceID": 0, "context": "While statisticians have recognized that problems like classification and regression can be formulated as Integer Optimization problems [1], the belief was formed in early 1970s that these methods are not tractable in practical computational settings.", "startOffset": 136, "endOffset": 139}, {"referenceID": 14, "context": "Fuzzy theory was originally developed by Zadeh [15] to deal with problems involving linguistic terms [16], [17], [18] and have been successfully applied to various applications in Engineering and Science.", "startOffset": 47, "endOffset": 51}, {"referenceID": 15, "context": "Fuzzy theory was originally developed by Zadeh [15] to deal with problems involving linguistic terms [16], [17], [18] and have been successfully applied to various applications in Engineering and Science.", "startOffset": 101, "endOffset": 105}, {"referenceID": 16, "context": "Fuzzy theory was originally developed by Zadeh [15] to deal with problems involving linguistic terms [16], [17], [18] and have been successfully applied to various applications in Engineering and Science.", "startOffset": 107, "endOffset": 111}, {"referenceID": 17, "context": "Fuzzy theory was originally developed by Zadeh [15] to deal with problems involving linguistic terms [16], [17], [18] and have been successfully applied to various applications in Engineering and Science.", "startOffset": 113, "endOffset": 117}, {"referenceID": 11, "context": "In contrast, traditional regression models deal with outliers after slopes have been determined by examining which points contribute most to total prediction error [12], [13].", "startOffset": 164, "endOffset": 168}, {"referenceID": 12, "context": "In contrast, traditional regression models deal with outliers after slopes have been determined by examining which points contribute most to total prediction error [12], [13].", "startOffset": 170, "endOffset": 174}, {"referenceID": 3, "context": "Nearest Prototype ) 1 , ( > \u2212 k NP k clustering algorithm defined on d R [4] in ) , ( y x space is used to find L clusters.", "startOffset": 73, "endOffset": 76}, {"referenceID": 6, "context": "Boston, Abalone and Auto data and Friedman\u2019s [7] generated data sets.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "The FMIOM for regression can be tailored by implicitly branching on integer variables [3].", "startOffset": 86, "endOffset": 89}], "year": 2010, "abstractText": "Mixed Integer Optimization has been a topic of active research in past decades. It has been used to solve Statistical problems of classification and regression involving massive data. However, there is an inherent degree of vagueness present in huge real life data. This impreciseness is handled by Fuzzy Sets. In this Paper, Fuzzy Mixed Integer Optimization Method (FMIOM) is used to find solution to Regression problem. The methodology exploits discrete character of problem. In this way large scale problems are solved within practical limits. The data points are separated into different polyhedral regions and each region has its own distinct regression coefficients. In this attempt, an attention is drawn to Statistics and Data Mining community that Integer Optimization can be significantly used to revisit different Statistical problems. Computational experimentations with generated and real data sets show that FMIOM is comparable to and often outperforms current leading methods. The results illustrate potential for significant impact of Fuzzy Integer Optimization methods on Computational Statistics and Data Mining. Keywords\u2013Mixed Integer Optimization; Fuzzy Sets; Regression; Polyhedral Regions", "creator": "PScript5.dll Version 5.2"}}}