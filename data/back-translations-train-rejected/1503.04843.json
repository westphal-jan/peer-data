{"id": "1503.04843", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2015", "title": "More General Queries and Less Generalization Error in Adaptive Data Analysis", "abstract": "Adaptivity is an important feature of data analysis---typically the choice of questions asked about a dataset depends on previous interactions with the same dataset. However, generalization error is typically bounded in a non-adaptive model, where all questions are specified before the dataset is drawn. Recent work by Dwork et al. (STOC '15) and Hardt and Ullman (FOCS '14) initiated the formal study of this problem, and gave the first upper and lower bounds on the achievable generalization error for adaptive data analysis.", "histories": [["v1", "Mon, 16 Mar 2015 20:48:42 GMT  (23kb,D)", "http://arxiv.org/abs/1503.04843v1", null], ["v2", "Tue, 10 Nov 2015 02:01:05 GMT  (0kb,I)", "http://arxiv.org/abs/1503.04843v2", "This paper was merged with another manuscript and is now subsumed byarXiv:1511.02513"]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["raef bassily", "adam smith", "thomas steinke", "jonathan ullman"], "accepted": false, "id": "1503.04843"}, "pdf": {"name": "1503.04843.pdf", "metadata": {"source": "CRF", "title": "More General Queries and Less Generalization Error in Adaptive Data Analysis", "authors": ["Raef Bassily", "Adam Smith", "Thomas Steinke", "Jonathan Ullman"], "emails": ["bassily@psu.edu", "asmith@psu.edu", "tsteinke@seas.harvard.edu", "jullman@cs.columbia.edu"], "sections": [{"heading": null, "text": "Suppose there is an unknown distribution P and a number of n independent samples x is drawn by P. We are looking for an algorithm that \"precisely\" answers a sequence of adaptively selected \"queries\" about the unknown distribution P. How many samples n do we need to draw from the distribution, depending on the type of queries, the number of queries and the desired degree of accuracy? In this paper, we are making two new contributions to solving this question: 1. We are specifying limits on the number of samples n that are needed to answer statistical queries that improve beyond the limits of Dwork et al.2. We are proving the first limits on the number of samples needed to answer more general families of queries, including arbitrary queries with low sensitivity and the important class of convex risk queries needed to minimize queries. As in Dwork et al., our algorithms are based on a link between differential privacy and generalizations."}, {"heading": "1 Introduction 1", "text": "1.1 Overview of results..............................................................................................................................."}, {"heading": "2 Preliminaries 5", "text": "..................................................................................................................................."}, {"heading": "3 From Privacy to Accuracy for Adaptive Queries 8", "text": "3.1 Different privacy implies low expectations of error......................................................................................................................................"}, {"heading": "4 From Function Approximation to Optimization Queries 15", "text": "4.1 Adaptive Minimization Oracle..................... 15 4.2 Strengthening the probability of success.................."}, {"heading": "5 Applications 17", "text": "5.1 Low sensitivity and statistical queries.............................................................................................................................................................................................................................................................."}, {"heading": "1 Introduction", "text": "A common problem in empirical research is testing the significance of multiple \"hypotheses\" on a finite sample of data from some population groups. An observation is considered significant when it is unlikely to have occurred by chance alone, and a \"false discovery\" occurs when the analyst erroneously declares an observation to be significant. Unfortunately, false discovery has been identified as a major problem in the scientific community (see e.g. [Ioa05]. This problem persists despite decades of research by statisticians on methods to prevent false discovery, such as the widespread Bonferroni correction [Bon36, Dun61] and the Benjamini-Hochberg method [BH95]. False discovery is often attributed to the misuse of statistics. However, an alternative explanation is that the prevalence of false discovery results from inherent adaptivity in the process of data analysis - the choice of hypotheses to test depends on previous interactions with the data (see Io06, for example [Io06]."}, {"heading": "1.1 Overview of Results", "text": "Following on from this previous work, we formalize the problem of adaptive data analysis as follows: There is a distribution P over a limited universe X and an oracle O that P does not know but does not know samples of P. Using its sample, the oracle must answer questions about P. However, here a query q maps a distribution P to a really evaluated answer, and we assume that the questions come from some families. The oracle's answer to a question q is absolutely accurate when there is a high probability. Important is the goal of the oracle to provide answers that are \"generalizing\" to the underlying distribution, rather than giving answers specific to the sample. We model adaptability by allowing the analyst to make a sequence of queries q1, q2, qk. Q to the oracle, who has answers a1, a2, ak."}, {"heading": "1.2 Overview of Techniques", "text": "Following Dwork et al. [DFH + 15], the most important technique we use is a connection between differential privacy and generalization. Intuitively, differential privacy guarantees that the distribution of the results given by the oracle does not depend \"too much\" on one of the samples that existed. Differential privacy can also be seen as a strong guarantee of stability that behaves well under adaptive data analysis. Thus, this work fits into the rich palette of machine learning work that combines algorithmic stability and generalization (cf. [BE02, SS10]). We show that a differential private algorithm provides answers to adaptive questions that come close to the empirical value of the answers that encompass the underlying distribution. In particular, for the low sensitivity class, we obtain the following theorem.Theorem 1.1 (Main \"Transfer Theorem\")."}, {"heading": "1.3 Related Work in Differential Privacy", "text": "For statistical queries, the optimal mechanisms are the well-known Gaussian mechanism (slightly refined by [SU15]) when k is small, and the Private Multiplicative Weights Mechanism [HR10] when k is large. For arbitrary queries with low sensitivity, the Laplace mechanism is again optimal when k is small, and for large k we can use the median mechanism [RR10]. When looking at arbitrary queries over any finite range, the optimal algorithm is the exponential mechanism [MT07]. The first efficient, differentiated private algorithms for the important special case of convex minimization queries over an infinite range were given by Dwork and Lei [DL09] and by Chaudhuri, Monteleone and Sarwate [CMS11], resulting in a long series of subsequent queries over an infinite range."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Queries", "text": "Given a distribution P over X or a sample x = (x1, \u00b7 \u00b7, xn), we are only able to answer questions about P or x from any family. We will work with multiple families of questions. \u2022 Statistical queries: These questions are specified by a predicate q (xi). The error of an answer a to a statistical query q (0,1), and (modified notation) is defined in relation to P or x. (P) = an answer to a statistical query q in relation to P or x is specified in relation to beerrx (q, a) = a \u2212 q (x) and errP (q, a) = a \u2212 q (P). \u2022 Sensitive queries: For an answer a [0,1], n N, these questions are specified by a function q (x)."}, {"heading": "2.2 Oracles for Adaptive Queries", "text": "Our goal is to design an oracle O that answers the questions on P. only using independent samples. \u03b2 \u03b2 Q,. \u03b2, xn \u2190 R P. Our focus is on the case in which the samples are selected adaptively and adversarially. Specifically, O is a state-based algorithm that takes a collection of samples x1,.., xn \u0445 X, a query q from a specific family Q as input and returns an answer a. We demand that this condition applies to each query in an adaptively selected order q1,. qk. Formally, we define the precision game between a state-based opponent q (P) in a sense appropriate to the family of queries. Furthermore, we demand that this condition applies to each query in an adaptively selected order q1. We define the precision game between a state-based opponent and a state-based opponent A in Figure 2.Definition 2.1 (Accuracy)."}, {"heading": "2.3 Differential Privacy", "text": "Informal, an algorithm is differentiated private if it is randomized and the distribution of its results does not depend \"much\" on one element of its input sample. We say that two samples x, x, x and X n are neighbors if they differ exactly on an entry, and designate this relationship by x, x and x. \"Definition 2.6 (Differential Privacy) Letter M: X n \u2192 R is a randomized algorithm. We say that M is for each x x\" and each R, P [M (x) and R] \u2264 e\u03b5 \u00b7 P [M (x) \u0432R] + v. A useful fact about differential privacy is that it is robust for post-processing. Lemma 2.7 ([DMNS06])) If M: X n \u2192 R is \"differentiated\" and f: R, then it may also be private (automatic)."}, {"heading": "3 From Privacy to Accuracy for Adaptive Queries", "text": "We begin by showing that differentiated private algorithms that respond to adaptive queries with low sensitivity and are precise in terms of sample size are accurate in terms of population."}, {"heading": "3.1 Differential Privacy Implies Low Expected Error", "text": "We start with the following key dilemma, which examines the expectation of q (x) against q (P), when q (q) may depend on x in a differentiated private relationship. (...) Let us leave M: X (...) n (...). (...) Let us leave M: X (...) n (...). (...) Let us leave P to be a distribution on X and let us leave x (...) n (...). The proof goes through a hybrid argument. (...) Let us leave x (...) r n independent of x (...). (...) - Ex, M (...). (...) | q (...) x (...) x (...) x (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (.... (...). (...). (.... (...). (...). (.... (...). (...). (...). (...). (.... (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (. (...). (.).). (...). (.). (. (.).). (. (. (.).). (.).).). (.). (. (...). (.). (. (.). (.).). (.). (.). (. (...). (. (.).). (.).). (.). (.). (.).). (.). (...). (. (.).). (.). (...). (. (. (.).). (. (.).).). (...). ("}, {"heading": "3.2 Amplifying the Success Probability", "text": "There is only an average error guarantee where we have a high confidence threshold limited to error. - Of Markov's Inequality (Fact 2.5), the maximum error rate is limited with at least constant probability. - And we will increase this probability by \"serial repetition.\" - Since O has a constant probability of giving good answers to all questions, the number of times a new sample is required, which is given by O (log) with an inaccurate answer, a new sample is drawn and a new instance of O is started. - Since O has a constant probability of giving good answers to all questions, the number of times a new sample of O (log) is required. - The challenge is to construct a suitable censor C that can detect when the oracle uses only a small number of samples."}, {"heading": "3.2.1 The Bounded Censor Algorithm", "text": "This construction is inspired by the sparse vector algorithm [DNR + 09, HR10, DNPR10, RR10] and the analysis is inspired by [Rot14].Theorem 3.7. The bound censor algorithm C (\u03b1, n, c, k) in Figure 5 is a bundled c-bounded censor for k sensitivity \"queries with thresholds\" in X assumption 8 (n) 2\u03b12 (log (2 / \u03b2) + (c + 1) \u00b7 Log (k + 1) \u00b7 Log (k + 1))).In the common scenario where we have a bundled censor (1 / n), the bound censor C requires only n (log (1 / \u03b2) + c \u00b7 logk).When C is called in theorem, we have c = O (1 / \u03b2)."}, {"heading": "4 From Function Approximation to Optimization Queries", "text": "We are now extending our results for low-sensitivity requests to more general minimization requests."}, {"heading": "4.1 Oracles for Adaptive Minimization Queries", "text": "By analogy with Theorem 3.2, we can show that an oracle that responds to its input and also differentiates gives private answers that apply to the entire distribution.Theorem 4.1. Suppose that the oracle O is adaptive for k queries from Q'Qmin (the family of -sensitive convex minimization queries from X).3Then O is adaptive for k queries from X.Proof.Suppose for the sake of the contradiction that O is not exact for k for k minimization queries from X. 3Then O is exact for x exact queries from X for population queries from X.Proof.Suppose for the sake of the contradiction that O is not adaptive for k queries from X."}, {"heading": "4.2 Amplifying the Success Probability", "text": "Similar to Theorem 3,6, we can increase the probability of success of an algorithm for minimization queries. Theorem 4,7. Suppose that 1. O is an \u03b2 / 2 sound c'bounded censor for k + c sensitivity - \u0445 queries with threshold \u03b1 for n'samples in X, where c = dlog2 (4 / \u03b2). Then F O, C (\u03b1, \u03b2) -exactly in relation to the basic population for k adaptively selected queries from Q specified n \u2032 + n \u00b7 c samples in X. The proof is almost identical to Theorem 3,6. The only difference is that the query for a Ps -sensitive loss function Lj (\u03b1, \u03b2) in relation to the basic population for k adaptively selected queries from Q specified n \u2032 + n samples in X. The proof is almost identical to Theorem 3,6."}, {"heading": "5 Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Low-Sensitivity and Statistical Queries", "text": "Conclusion 5.1 (Theorem 3.9 and [DMNS06, SU15]): There is an oracle O which is (\u03b1, \u03b2) -exact in relation to the population for k-adaptive selected queries from Q, where \u2206 = O (1 / n) is given per query. Conclusion 5.2 (Theorem 3.9 and [RRR10]): There is an oracle O which is (\u03b1, \u03b2) -exact in relation to the population (1 / \u03b2) \u03b12 The oracle runs in time poly (n, log | X |, log (1 / \u03b2)) per query. Consequently 5.2 (Theorem 3.9 and [RRR10]) there is an oracle O which is (\u03b1, \u03b2) -exact in relation to the population in relation to k-adaptive selected queries."}, {"heading": "5.2 Optimization Queries", "text": "The results of Section 4 can be combined with existing differentiated private algorithms to minimize \"empirical risk\" (i.e. the loss in relation to sample x) to obtain algorithms to respond to adaptive sequences of minimization queries."}, {"heading": "5.2.1 Minimization Over Arbitrary Finite Sets", "text": "Conclusion 5.4 (Theorem 4.8 and [MT07]): Let us have a finite theorem of at most D. Let Q-Qmin be the theorem of sensitivity 1 / n loss functions limited between 0 and C. Then there is an oracle O that (\u03b1, \u03b2) -exactly in relation to the population for k adaptively selected queries from Qmin givenn \u2265 O log (DC / \u03b1) \u00b7 \u221a k \u00b7 log (1 / \u03b1) \u00b7 log (1 / \u03b2) \u03b12 samples from X. The runtime of the oracle is dominated by O (k + log (1 / \u03b2) \u00b7 D) evaluations of the loss function."}, {"heading": "5.2.2 Convex Minimization", "text": "We specify the limits for convex minimization queries for some of the most common parameter regimes in applications. (In the first two corollaries, we will consider 1-lipschitz4 loss functions over a limited domain. (Corollary 5.5 (theorem 4,8 and [BST14])) Let us specify a closed, convex subset of Rd so that max\u03b8 2 \u2264 1. LetQ-Qmin be the set of convex 1-lipschitz loss functions that are 1 / n sensitive.) Then there is an oracle O that is (\u03b1, \u03b2) -exact in relation to the population. (Let the population for k adaptively selected queries of Q givenn = O-Qmin be the set of convex 1-lipschitz functions that are 1 / n sensitive.) The runtime of the oracle is dominated by k \u00b7 n2 evaluations of gradient 4A-loss function L."}, {"heading": "Acknowledgements", "text": "We would like to thank Aaron Roth, who suggested the technique we used to prove Theorem 3.7, as well as Mark Bun, Moritz Hardt and Salil Vadhan for helpful discussions."}], "references": [{"title": "Stability and generalization", "author": ["Olivier Bousquet", "Andr\u00e9 Elisseeff"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bousquet and Elisseeff.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Elisseeff.", "year": 2002}, {"title": "Controlling the false discovery rate: a practical and powerful approach to multiple testing", "author": ["Yoav Benjamini", "Yosef Hochberg"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Benjamini and Hochberg.,? \\Q1995\\E", "shortCiteRegEx": "Benjamini and Hochberg.", "year": 1995}, {"title": "Bonferroni. Teoria statistica delle classi e calcolo delle probabilita", "author": ["Carlo Emilio"], "venue": "Pubbl. d. R. Ist. Super. di Sci. Econom. e Commerciali di Firenze.,", "citeRegEx": "Emilio,? \\Q1936\\E", "shortCiteRegEx": "Emilio", "year": 1936}, {"title": "Private empirical risk minimization: Efficient algorithms and tight error bounds", "author": ["Raef Bassily", "Adam Smith", "Abhradeep Thakurta"], "venue": "In FOCS,", "citeRegEx": "Bassily et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bassily et al\\.", "year": 2014}, {"title": "Fingerprinting codes and the price of approximate differential privacy", "author": ["Mark Bun", "Jonathan Ullman", "Salil P. Vadhan"], "venue": "In STOC,", "citeRegEx": "Bun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bun et al\\.", "year": 2014}, {"title": "Differentially private empirical risk minimization", "author": ["Kamalika Chaudhuri", "Claire Monteleoni", "Anand D. Sarwate"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chaudhuri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In STOC. ACM,", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Differential privacy and robust statistics. In STOC, pages 371\u2013380", "author": ["Cynthia Dwork", "Jing Lei"], "venue": "ACM, May 31\u2013June", "citeRegEx": "Dwork and Lei.,? \\Q2009\\E", "shortCiteRegEx": "Dwork and Lei.", "year": 2009}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Differential privacy under continual observation", "author": ["Cynthia Dwork", "Moni Naor", "Toniann Pitassi", "Guy N. Rothblum"], "venue": "In Symposium on Theory of Computing (STOC),", "citeRegEx": "Dwork et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2010}, {"title": "On the complexity of differentially private data release: efficient algorithms and hardness results", "author": ["Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": "In STOC,", "citeRegEx": "Dwork et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2009}, {"title": "Multiple comparisons among means", "author": ["Olive Jean Dunn"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Dunn.,? \\Q1961\\E", "shortCiteRegEx": "Dunn.", "year": 1961}, {"title": "The garden of forking paths: Why multiple comparisons can be a problem, even when there is no \u201cfishing expedition", "author": ["Andrew Gelman", "Eric Loken"], "venue": "or \u201cphacking\u201d and the research hypothesis was posited ahead of time. Manuscript.,", "citeRegEx": "Gelman and Loken.,? \\Q2013\\E", "shortCiteRegEx": "Gelman and Loken.", "year": 2013}, {"title": "A multiplicative weights mechanism for privacypreserving data analysis", "author": ["Moritz Hardt", "Guy Rothblum"], "venue": "In Proc. 51st Foundations of Computer Science (FOCS),", "citeRegEx": "Hardt and Rothblum.,? \\Q2010\\E", "shortCiteRegEx": "Hardt and Rothblum.", "year": 2010}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["Moritz Hardt", "Jonathan Ullman"], "venue": "In FOCS. IEEE, October", "citeRegEx": "Hardt and Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Hardt and Ullman.", "year": 2014}, {"title": "Why most published research findings are false", "author": ["John P.A. Ioannidis"], "venue": "PLoS Medicine,", "citeRegEx": "Ioannidis.,? \\Q2005\\E", "shortCiteRegEx": "Ioannidis.", "year": 2005}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael J. Kearns"], "venue": "In STOC, pages 392\u2013401", "citeRegEx": "Kearns.,? \\Q1993\\E", "shortCiteRegEx": "Kearns.", "year": 1993}, {"title": "On the method of bounded differences", "author": ["Colin McDiarmid"], "venue": "Surveys in combinatorics,", "citeRegEx": "McDiarmid.,? \\Q1989\\E", "shortCiteRegEx": "McDiarmid.", "year": 1989}, {"title": "Mechanism design via differential privacy", "author": ["Frank McSherry", "Kunal Talwar"], "venue": "In FOCS,", "citeRegEx": "McSherry and Talwar.,? \\Q2007\\E", "shortCiteRegEx": "McSherry and Talwar.", "year": 2007}, {"title": "Interactive privacy via the median mechanism", "author": ["Aaron Roth", "Tim Roughgarden"], "venue": "In STOC, pages 765\u2013774", "citeRegEx": "Roth and Roughgarden.,? \\Q2010\\E", "shortCiteRegEx": "Roth and Roughgarden.", "year": 2010}, {"title": "Learnability, stability and uniform convergence", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2010}, {"title": "Interactive fingerprinting codes and the hardness of preventing false discovery", "author": ["Thomas Steinke", "Jonathan Ullman"], "venue": "CoRR, abs/1410.1228,", "citeRegEx": "Steinke and Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Steinke and Ullman.", "year": 2014}, {"title": "Between pure and approximate differential privacy", "author": ["Thomas Steinke", "Jonathan Ullman"], "venue": "CoRR, abs/1501.06095,", "citeRegEx": "Steinke and Ullman.,? \\Q2015\\E", "shortCiteRegEx": "Steinke and Ullman.", "year": 2015}, {"title": "Answering n2+o(1) counting queries with differential privacy is hard", "author": ["Jonathan Ullman"], "venue": "In STOC, pages 361\u2013370", "citeRegEx": "Ullman.,? \\Q2013\\E", "shortCiteRegEx": "Ullman.", "year": 2013}, {"title": "Private multiplicative weights beyond linear queries", "author": ["Jonathan Ullman"], "venue": "In PODS. ACM, May 31\u2013June", "citeRegEx": "Ullman.,? \\Q2015\\E", "shortCiteRegEx": "Ullman.", "year": 2015}], "referenceMentions": [], "year": 2015, "abstractText": "Adaptivity is an important feature of data analysis\u2014typically the choice of questions asked about a dataset depends on previous interactions with the same dataset. However, generalization error is typically bounded in a non-adaptive model, where all questions are specified before the dataset is drawn. Recent work by Dwork et al. (STOC \u201915) and Hardt and Ullman (FOCS \u201914) initiated the formal study of this problem, and gave the first upper and lower bounds on the achievable generalization error for adaptive data analysis. Specifically, suppose there is an unknown distribution P and a set of n independent samples x is drawn from P . We seek an algorithm that, given x as input, \u201caccurately\u201d answers a sequence of adaptively chosen \u201cqueries\u201d about the unknown distribution P . How many samples n must we draw from the distribution, as a function of the type of queries, the number of queries, and the desired level of accuracy? In this work we make two new contributions towards resolving this question: 1. We give upper bounds on the number of samples n that are needed to answer statistical queries that improve over the bounds of Dwork et al. 2. We prove the first upper bounds on the number of samples required to answer more general families of queries. These include arbitrary low-sensitivity queries and the important class of convex risk minimization queries. As in Dwork et al., our algorithms are based on a connection between differential privacy and generalization error, but we feel that our analysis is simpler and more modular, which may be useful for studying these questions in the future. \u2217Pennsylvania State University, Department of Computer Science and Engineering. {bassily,asmith}@psu.edu \u2020Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. tsteinke@seas.harvard.edu \u2021Columbia University Department of Computer Science. Supported by a Junior Fellowship from the Simons Society of Fellows. jullman@cs.columbia.edu ar X iv :1 50 3. 04 84 3v 1 [ cs .L G ] 1 6 M ar 2 01 5", "creator": "LaTeX with hyperref package"}}}