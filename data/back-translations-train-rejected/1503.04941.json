{"id": "1503.04941", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2015", "title": "How the symbol grounding of living organisms can be realized in artificial agents", "abstract": "A system with artificial intelligence usually relies on symbol manipulation, at least partly and implicitly. However, the interpretation of the symbols - what they represent and what they are about - is ultimately left to humans, as designers and users of the system. How symbols can acquire meaning for the system itself, independent of external interpretation, is an unsolved problem. Some grounding of symbols can be obtained by embodiment, that is, by causally connecting symbols (or sub-symbolic variables) to the physical environment, such as in a robot with sensors and effectors. However, a causal connection as such does not produce representation and aboutness of the kind that symbols have for humans. Here I present a theory that explains how humans and other living organisms have acquired the capability to have symbols and sub-symbolic variables that represent, refer to, and are about something else. The theory shows how reference can be to physical objects, but also to abstract objects, and even how it can be misguided (errors in reference) or be about non-existing objects. I subsequently abstract the primary components of the theory from their biological context, and discuss how and under what conditions the theory could be implemented in artificial agents. A major component of the theory is the strong nonlinearity associated with (potentially unlimited) self-reproduction. The latter is likely not acceptable in artificial systems. It remains unclear if goals other than those inherently serving self-reproduction can have aboutness and if such goals could be stabilized.", "histories": [["v1", "Tue, 17 Mar 2015 08:00:49 GMT  (128kb)", "http://arxiv.org/abs/1503.04941v1", "11 pages, 3 figures"]], "COMMENTS": "11 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.AI cs.NE cs.RO", "authors": ["j h van hateren"], "accepted": false, "id": "1503.04941"}, "pdf": {"name": "1503.04941.pdf", "metadata": {"source": "CRF", "title": "How the Symbol Grounding of Living Organisms Can Be Realized in Artificial Agents", "authors": ["J. H. van Hateren"], "emails": ["J.H.VAN.HATEREN@RUG.NL"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own by searching for another path that will take them to another world, in which they will then find themselves in another world, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves."}, {"heading": "2. Biological Symbol Grounding", "text": "To understand how absurdity is likely to have arisen in organic evolution, three key concepts must be taken into account: the first is that the basic Darwinian theory of differential reproduction (organisms equipped for more effective reproduction than others that seem to be naturally selected) has an extent that depends on the organism establishing an internal model of its reproductive capacity; the second is that the specific, stochastic role of this internal model establishes an indirect link between internal and external variables; it constitutes a causal link, thus generating an original form of absurdity; and the third is that communication between organisms can reduce the ambiguity resulting from the combination of such internal variables into abstract symbols."}, {"heading": "2.1 Extending Basic Darwinian Evolution", "text": "In fact, most of them will be able to move to another world, where they will be able to move to another world, where they will be able to move to another world, where they will be able to move to where they are."}, {"heading": "2.2 Details of Aboutness", "text": "In fact, it is not that this is a mere diversion manoeuvre, but a diversion manoeuvre, which is about putting oneself in check. (...) It is not that it is a mere diversion manoeuvre. (...) It is not that it is a diversion manoeuvre. (...) It is not that it is a diversion manoeuvre. (...) It is not that it is a diversion manoeuvre. (...) It is not that it is a distraction manoeuvre. (...) It is not that it is a distraction manoeuvre. (...) It is a distraction manoeuvre. (...) It is a distraction manoeuvre. (...) It is a distraction manoeuvre. (...) It is a distraction manoeuvre. (...) It is a distraction manoeuvre."}, {"heading": "2.3 Stabilization of Symbols", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3. Discussion and Conclusion", "text": "In fact, it is such that most of them will be able to move to another world, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they are living, that they are living, that they are living, that they are living, that they are that they are, that they are living, that they are, that they are, that they are living, that they are, that they are, that they are living, that they are, that they are, that they are, that they are, that they are, that they are living, that they are, that they live, that they are, that they are, that they are, that they are, that they live, that they are, that they are living, that they are, that they are living, that they are, that they are, that they are living, that they are, that they are, that they are living, that they are, that they are, that they are living, that they are living, that they are, that they are, that they are living, that they are living, that they are living, that they are, that they are, that they are, that they are living, that they are living, that they are living, that they are, that they are, that they are, that they are, that they are"}], "references": [{"title": "Symbol Grounding Problem and causal theory of reference. New Ideas in Psychology, doi:10.1016/j.newideapsych.2015.01.006 Bongard", "author": ["K. Bielecka"], "venue": "J. C", "citeRegEx": "Bielecka,? \\Q2015\\E", "shortCiteRegEx": "Bielecka", "year": 2015}, {"title": "The superintelligent will: motivation and instrumental rationality in advanced artificial agents", "author": ["N. Bostrom"], "venue": "Minds & Machines,", "citeRegEx": "Bostrom,? \\Q2012\\E", "shortCiteRegEx": "Bostrom", "year": 2012}, {"title": "Intelligence without representation", "author": ["R.A. Brooks"], "venue": "Artificial Intelligence,", "citeRegEx": "Brooks,? \\Q1991\\E", "shortCiteRegEx": "Brooks", "year": 1991}, {"title": "Multimodal distributional semantics", "author": ["E. Bruni", "N.K. Tran", "M. Baroni"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Bruni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bruni et al\\.", "year": 2014}, {"title": "The grounding and sharing of symbols", "author": ["A. Cangelosi"], "venue": "Pragmatics & Cognition,", "citeRegEx": "Cangelosi,? \\Q2006\\E", "shortCiteRegEx": "Cangelosi", "year": 2006}, {"title": "Symbol grounding \u2013 the emperor's new theory of meaning", "author": ["M.H. Christiansen", "N. Chater"], "venue": "In Proceedings of the 15th Annual Conference of the Cognitive Science Society (pp. 155-160)", "citeRegEx": "Christiansen and Chater,? \\Q1993\\E", "shortCiteRegEx": "Christiansen and Chater", "year": 1993}, {"title": "A short review of symbol grounding in robotic and intelligent systems", "author": ["S. Coradeschi", "A. Loutfi", "B. Wrede"], "venue": "Ku\u0308nstliche Intelligenz,", "citeRegEx": "Coradeschi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Coradeschi et al\\.", "year": 2013}, {"title": "Evolution of adaptive behaviour in robots by means of Darwinian selection", "author": ["D. Floreano", "L. Keller"], "venue": "PLoS Biology,", "citeRegEx": "Floreano and Keller,? \\Q2010\\E", "shortCiteRegEx": "Floreano and Keller", "year": 2010}, {"title": "The symbol grounding problem", "author": ["A. Harnad"], "venue": "Physica D,", "citeRegEx": "Harnad,? \\Q1990\\E", "shortCiteRegEx": "Harnad", "year": 1990}, {"title": "Automatic design and manufacture of robotic lifeforms", "author": ["H. Lipson", "J.B. Pollack"], "venue": null, "citeRegEx": "Lipson and Pollack,? \\Q2000\\E", "shortCiteRegEx": "Lipson and Pollack", "year": 2000}, {"title": "Computer science as empirical inquiry", "author": ["A. Newell", "H.A. Simon"], "venue": "Symbols and search. Communications of the ACM,", "citeRegEx": "Newell and Simon,? \\Q1976\\E", "shortCiteRegEx": "Newell and Simon", "year": 1976}, {"title": "Meaning in artificial agents: the symbol grounding problem revisited", "author": ["D. Rodr\u00edguez", "J. Hermosillo", "B. Lara"], "venue": "Mind & Machines,", "citeRegEx": "Rodr\u00edguez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rodr\u00edguez et al\\.", "year": 2012}, {"title": "Minds, brains, and programs", "author": ["J.R. Searle"], "venue": "The Behavioral and Brain Sciences,", "citeRegEx": "Searle,? \\Q1980\\E", "shortCiteRegEx": "Searle", "year": 1980}, {"title": "The symbol grounding problem has been solved. So what's next", "author": ["L. Steels"], "venue": null, "citeRegEx": "Steels,? \\Q2008\\E", "shortCiteRegEx": "Steels", "year": 2008}, {"title": "Symbol grounding: A new look at an old idea", "author": ["R. Sun"], "venue": "Philosophical Psychology,", "citeRegEx": "Sun,? \\Q2000\\E", "shortCiteRegEx": "Sun", "year": 2000}, {"title": "Solving the symbol grounding problem: a critical review of fifteen years of research", "author": ["M. Taddeo", "L. Floridi"], "venue": "Journal of Experimental & Theoretical Artificial Intelligence,", "citeRegEx": "Taddeo and Floridi,? \\Q2005\\E", "shortCiteRegEx": "Taddeo and Floridi", "year": 2005}, {"title": "A new criterion for demarcating life from non-life", "author": ["J.H. van Hateren"], "venue": "Origins of Life and Evolution of Biospheres,", "citeRegEx": "Hateren,? \\Q2013\\E", "shortCiteRegEx": "Hateren", "year": 2013}, {"title": "The origin of agency, consciousness, and free will", "author": ["J.H. van Hateren"], "venue": "Phenomenology and the Cognitive Sciences,", "citeRegEx": "Hateren,? \\Q2014\\E", "shortCiteRegEx": "Hateren", "year": 2014}, {"title": "Active causation and the origin of meaning", "author": ["J.H. van Hateren"], "venue": "Biological Cybernetics,", "citeRegEx": "Hateren,? \\Q2015\\E", "shortCiteRegEx": "Hateren", "year": 2015}, {"title": "The physical symbol grounding problem", "author": ["P. Vogt"], "venue": "Cognitive Systems Research,", "citeRegEx": "Vogt,? \\Q2002\\E", "shortCiteRegEx": "Vogt", "year": 2002}, {"title": "Rethinking grounding", "author": ["T. Ziemke"], "venue": null, "citeRegEx": "Ziemke,? \\Q1999\\E", "shortCiteRegEx": "Ziemke", "year": 1999}], "referenceMentions": [{"referenceID": 10, "context": "Newell and Simon (1976) conjectured that information processing by a physical symbol system is all that is needed for producing general intelligent action of the kind humans produce.", "startOffset": 0, "endOffset": 24}, {"referenceID": 10, "context": "Newell and Simon (1976) conjectured that information processing by a physical symbol system is all that is needed for producing general intelligent action of the kind humans produce. Physical symbols, such as present in the physical patterns within a computing machine, can be regarded as forming a formal system. Searle (1980) questioned the sufficiency of formal systems for producing some of the major characteristics that symbols, and combinations of symbols, have for humans.", "startOffset": 0, "endOffset": 328}, {"referenceID": 11, "context": "\u201cSymbol grounding\u201d as defined by Harnad (1990) is focused on physical reference, which does not specifically aim to solve the general problem of aboutness (Rodr\u00edguez et al., 2012).", "startOffset": 155, "endOffset": 179}, {"referenceID": 6, "context": "Although many solutions have been proposed, often by combining symbolic with connectionist processing, none appear to really solve the problem of aboutness (for reviews see Ziemke, 1999; Taddeo & Floridi, 2005; Rodriguez et al., 2012; Coradeschi et al., 2013; Bielecka, 2015).", "startOffset": 156, "endOffset": 275}, {"referenceID": 0, "context": "Although many solutions have been proposed, often by combining symbolic with connectionist processing, none appear to really solve the problem of aboutness (for reviews see Ziemke, 1999; Taddeo & Floridi, 2005; Rodriguez et al., 2012; Coradeschi et al., 2013; Bielecka, 2015).", "startOffset": 156, "endOffset": 275}, {"referenceID": 13, "context": "Therefore, communication will drive synchronization and stabilization of symbols (Steels, 2008).", "startOffset": 81, "endOffset": 95}, {"referenceID": 19, "context": "As will be clear from the above summary, the latter parts of the theory \u2013 defining and stabilizing symbols through physical and social grounding (Vogt, 2002; Cangelosi, 2006; Coradeschi et al., 2013) and organizing them in a symbolic system \u2013 may be complex, but do not require anything that goes beyond existing robotic technology.", "startOffset": 145, "endOffset": 199}, {"referenceID": 4, "context": "As will be clear from the above summary, the latter parts of the theory \u2013 defining and stabilizing symbols through physical and social grounding (Vogt, 2002; Cangelosi, 2006; Coradeschi et al., 2013) and organizing them in a symbolic system \u2013 may be complex, but do not require anything that goes beyond existing robotic technology.", "startOffset": 145, "endOffset": 199}, {"referenceID": 6, "context": "As will be clear from the above summary, the latter parts of the theory \u2013 defining and stabilizing symbols through physical and social grounding (Vogt, 2002; Cangelosi, 2006; Coradeschi et al., 2013) and organizing them in a symbolic system \u2013 may be complex, but do not require anything that goes beyond existing robotic technology.", "startOffset": 145, "endOffset": 199}, {"referenceID": 4, "context": "As will be clear from the above summary, the latter parts of the theory \u2013 defining and stabilizing symbols through physical and social grounding (Vogt, 2002; Cangelosi, 2006; Coradeschi et al., 2013) and organizing them in a symbolic system \u2013 may be complex, but do not require anything that goes beyond existing robotic technology. Indeed, Steels (2008) has shown that letting robots communicate about colored samples can produce a consistent and stable framework for the meaning of the symbols used.", "startOffset": 158, "endOffset": 355}], "year": 2015, "abstractText": "A system with artificial intelligence usually relies on symbol manipulation, at least partly and implicitly. However, the interpretation of the symbols \u2013 what they represent and what they are about \u2013 is ultimately left to humans, as designers and users of the system. How symbols can acquire meaning for the system itself, independent of external interpretation, is an unsolved problem. Some grounding of symbols can be obtained by embodiment, that is, by causally connecting symbols (or sub-symbolic variables) to the physical environment, such as in a robot with sensors and effectors. However, a causal connection as such does not produce representation and aboutness of the kind that symbols have for humans. Here I present a theory that explains how humans and other living organisms have acquired the capability to have symbols and sub-symbolic variables that represent, refer to, and are about something else. The theory shows how reference can be to physical objects, but also to abstract objects, and even how it can be misguided (errors in reference) or be about non-existing objects. I subsequently abstract the primary components of the theory from their biological context, and discuss how and under what conditions the theory could be implemented in artificial agents. A major component of the theory is the strong nonlinearity associated with (potentially unlimited) self-reproduction. The latter is likely not acceptable in artificial systems. It remains unclear if goals other than those inherently serving selfreproduction can have aboutness and if such goals could be stabilized.", "creator": "PDFCreator Version 1.5.0"}}}