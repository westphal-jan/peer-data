{"id": "1503.05018", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2015", "title": "Ultra-Fast Shapelets for Time Series Classification", "abstract": "Time series shapelets are discriminative subsequences and their similarity to a time series can be used for time series classification. Since the discovery of time series shapelets is costly in terms of time, the applicability on long or multivariate time series is difficult. In this work we propose Ultra-Fast Shapelets that uses a number of random shapelets. It is shown that Ultra-Fast Shapelets yield the same prediction quality as current state-of-the-art shapelet-based time series classifiers that carefully select the shapelets by being by up to three orders of magnitudes. Since this method allows a ultra-fast shapelet discovery, using shapelets for long multivariate time series classification becomes feasible.", "histories": [["v1", "Tue, 17 Mar 2015 12:41:30 GMT  (489kb,D)", "http://arxiv.org/abs/1503.05018v1", "Preprint submitted to Journal of Data &amp; Knowledge Engineering January 24, 2015"]], "COMMENTS": "Preprint submitted to Journal of Data &amp; Knowledge Engineering January 24, 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["martin wistuba", "josif grabocka", "lars schmidt-thieme"], "accepted": false, "id": "1503.05018"}, "pdf": {"name": "1503.05018.pdf", "metadata": {"source": "CRF", "title": "Ultra-Fast Shapelets for Time Series Classification", "authors": ["Martin Wistuba", "Josif Grabocka", "Lars Schmidt-Thieme"], "emails": ["wistuba@ismll.uni-hildesheim.de", "josif@ismll.uni-hildesheim.de", "schmidt-thieme@ismll.uni-hildesheim.de"], "sections": [{"heading": null, "text": "Time series forms are discriminatory subsequences and their similarity to time series can be used to classify time series. As the discovery of time series forms is time-consuming, it is difficult to apply them to long or multivariate time series. In this paper, we propose Ultra-Fast Shapelets that use a number of random shapelets. It turns out that Ultra-Fast Shapelets provide the same predictive quality as current form series classifiers that carefully select the shapelets by being up to three orders of magnitude larger. As this method enables ultra-fast shape finding, the use of shapelets for long multivariate time series classifications becomes practicable. A method for using shapelets for multivariate time series is proposed and Ultra-Fast Shapelets are proving successful in comparison to state-of-the-art multivariate time series classifiers."}, {"heading": "1. Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2. Related Work", "text": "The idea is that we will all be able to be able to be able to be able to be able to be, and that we will be able to be able to play by the rules that we have set ourselves."}, {"heading": "3. Baselines", "text": "As will be shown later, Ultra-Fast Shapelets (UFS) is comparable to all other shapelet-based classifiers, but takes less time to extract the shapelets. UFS is compared with three different methods to extract shapelets from univariate data, and the reader will notice that the number of hyperparameters required for UFS is very small in comparison."}, {"heading": "3.1. Exhaustive Search (ES)", "text": "The Extensive Search (ES) [2, 6, 1] takes into account each sub-sequence in the training data and classifies it by means of a scoring function. As discussed in Section 4.2, this corresponds to a variable ranking. The scoring function is usually the gain of information, but other quality measures such as Kruskal-Wallis, F statistics and the median of mood have already been taken into account. As the consideration of all candidates for larger data sets is not feasible, the candidates are reduced by taking into account only partial sequences of certain lengths, by selecting a minimum and maximum length, sometimes a step size larger than one. Since the length of the best sub-sequence length is unknown, these are obviously very sensitive hyperparameters. Another hyperparameter is the number of shapelets to be selected. This is also an important hyperparameter, as a too low setting could lead to not taking into account important features and setting them too high, causing too much noise for simple classifiers such as Nearest Neighbor."}, {"heading": "3.2. Fast Shapelets (FS)", "text": "Since the exhaustive search for shapelets is very slow, there is a need for a faster method of extracting shapelets. Therefore, an approximate method has been introduced, so-called Fast Shapelets (FS) [5]. The idea is to reduce the dimension of the data by estimating the SAX representation [19] and looking for characteristics that are likely to be useful in the reduced space. Therefore, only a few candidates remain when mapping the reduced space to the original space. The final characteristics are estimated by means of variable order. Fast Shapelets is the fastest published method of shape finding, which we know to provide comparable classification accuracy. As with the exhaustive search, there are hyperparameters to restrict the search space by sub-sequence lengths. However, it is also possible to simply capture them all.Three new hyperparameters are required for dimensionality reduction, i.e. window length, alpha height and word length that may be less sensitive."}, {"heading": "3.3. Learning Shapelets (LS)", "text": "Instead of restricting the pool of possible candidates to those that can be found in the training data and simply searching through them, Grabocka et al. [9] propose to consider the shapelets as parameters that are also optimized in terms of loss. Therefore, shapelets are not found on the basis of an approximate measure to be useful for a model, but directly optimized for it. This means that it has an advantage because the method does not consider a limited number of candidates, but can select any shapelets. Disadvantages of this method are that its accuracy depends heavily on the original shapelets and that not every classification model can be used. The number of hyperparameters corresponds to the exhaustive search, but it will be shown that the runtime may be shorter. In the following sections, this method is referred to as Learning Shapelets (LS)."}, {"heading": "3.4. Symbolic Representation for Multivariate Timeseries", "text": "Symbolic Representation for Multivariate Timeseries (SMTS) [18] is not based on shapelets, but has its own way of generating characteristics. The idea is to represent time series as histograms of symbols in which a symbol represents a leaf of a decision tree. Raw data is transformed in such a way that the transformed data for each point in time j of the time series Ti contains an instance (j, ti, 1, j,..., ti, j, ti, 2, j \u2212 ti, 1, j,.., ti, m, j \u2212 ti, m \u2212 1, j) with the caption yi. A random forest is trained on the transformed data and its leaves are considered as symbols. The number of occurrences of a symbol in the raw data is counted and these symbol histograms are used for the final classification step using random forests."}, {"heading": "4. Ultra-Fast Shapelets for Univariate and Multivariate Time Series", "text": "Shapelets are often defined as discriminatory subsequences and extracted using a monitored measure of quality. This process corresponds to a selection of feature subgroups [20], which is mathematically very expensive as there are usually many possible Shapelet candidates. In Section 4.2 it is shown that most Shapelet discovery methods are nothing more than feature selection algorithms. An alternative method that is faster and based on feature samples is presented in Section 4.3. Subsequently, Section 4.4 introduces a way to generate features from multivariate time series using subsequences. Finally, Section 4.5 shows how derivatives of time series can be integrated into the proposed concept of ultra-fast shapelets."}, {"heading": "4.1. Notation", "text": "A univariate time series T = (t1,.., tm) is a sequence of m data points, ti \u0441R, where m is called the length of the time series.For notatorial and illustrative reasons, it is assumed that the length of each time series is the same, although the methods presented handle time series of different lengths. A multivariate time series T = (t1,..., tm) is a sequence of m vectors ti = (ti, 1,...., ti, s).Rs with s data streams in which the time series Tj = (t1, j,.., tm, j) as streams. A data set for univariate or multivariate time series classification is a pair T = ((T1,.., Tn) T, Y), in which Y = (y1,.,., yn) and the class of time series Ti is a pair T = ((T1,..,., Tn)."}, {"heading": "4.2. Shapelet Discovery as Feature Subset Selection", "text": "This section describes the relationship between shapelet discovery and attribute selection, which applies only to methods that select subsequences as shapelets that occur in the training data, which is common in many methods [2, 5, 8, 6, 1]. For a better understanding, the shapelet transformation is described in Section 4.2.1 and the shapelet discovery in Section 4.2.2."}, {"heading": "4.2.1. Shapelet Transformation for Univariate Time Series", "text": "The term Shapelet transformation was introduced by Lines et al. [8]. Shapelet transformation is a feature extraction process that uses and extracts shapelets that are discriminatory subsequences. This idea is used for the univariate classification of time series at the latest since Ye et al. [1]. The extracted shapelets are used to express the original time series data set T = ((((T1,.., Tn) T, Y) as transformed data set D = (X, Y), X-Rn-p, which can be performed in four steps (see Figure 2): 1. Candidate Extraction: From all time series T1,..., Tn subsequences C1,....., Cq are selected as candidates. Different methods exist for selecting candidates. Typically, all subsequences of a certain length [2, 6, 1] or that meet another informed criterion [5] are presented as subsequence."}, {"heading": "4.2.2. Shapelet Discovery is Variable Ranking", "text": "The last section has shown how the shapelet transformation can be applied to univariate time series. Now, the relationship between shapelet discovery and feature selection is discussed by reciting the definition used for a shapelet here. Definition 1. There is a univariate time series data set T and a scoring function s, which classifies a sequence of a time series T to T. Subsequently, a shapelet S is defined as a sequence of a time series T to T, which is one of the highest rated subsequences in terms of the scoring function. In the literature, this type of feature subset selection is called variable ranking and is a filtering method [20]. Filter methods have the advantage that they are computationally fast and scalable, but have the disadvantages of selecting redundant features and ignoring dependencies between features and the classifier. However, although the variable ranking is still slow to evaluate the number of attributes before selecting the number O, the number of the number of attributes can still be selected."}, {"heading": "4.3. Shapelet Discovery as Feature Sampling", "text": "It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. It is. (...) It is. (...) It is. (...) It is. (... It is. (...) It is. (...) It is. It is. It is. (...) It is. It is. (.... (...) It is. It is. (...) It is. It is. (.... It is. It is. It is. (...). It is. It is. (.... It is. It is. (...). It is. It is. It is. (.... It is. It is. (...). It is. It is. It is. (.... It is. It is. (...). It is. It is. It is. It is. It is. (.... It is. It is. It is. (). It is. (). It is. It is. It is. (). It is. It is. It is. (). It is. (). It is. (). It is. (.... It is. It is. (). It is. It is. It is. It is. It is. It is."}, {"heading": "4.4. Generalized Ultra-Fast Shapelets", "text": "This section describes how Ultra-Fast Shapelets can be generalized in such a way that the implementation can be used for univariate and multivariate time series classification. The proposal is to transform multivariate time series using shapelets in a manner similar to that described for the univariate case. In the first step, shapelets are randomly selected from each of the s streams, so that sets of shapelets S1,.. \u2212 Ss are extracted. Ignoring temporal relations between the streams, the raw data is transformed into a data set D, so that the features on each stream are generated and then summarized as in the univariate case. Formally, using the sets Si of size ps, the datasets D = (X, Y), X-R n \u00b7 pis computed, where xi, j = minDist (Sj \u2212 f) the features in each stream as in the univariate case are then summarized and summarized."}, {"heading": "4.5. Considering Derivatives of Time Series", "text": "In the next section, Ultra-Fast Shapelets will be compared with other state-of-the-art methods for multivariate time series classification. To ensure fair comparison, the same classification model and the same features will be used. As SMTS [18] uses not only the raw time series, but also its derivative, it will now explain how derivatives for Ultra-Fast Shapelets can be used. The derivative of a time series T = (t1,..., tm) is defined as \u0432 T = (0, t2 \u2212 t1,.., tm \u2212 1). The leading 0 ensures that the derivative has the same length as its time series. Using derivatives from the time series is easy for Ultra-Fast Shapelets. For each stream Ti of a time series T, a new stream Ti is added, which is the derivative of Ti. The original dataset is now twice as large, but no adjustment to the algorithm of a series 7 m is made."}, {"heading": "5. Experiments", "text": "Section 3 summarizes the baselines to complete this work in itself. Section 5.1 provides a detailed description of the experimental setup and explains which hyperparameters are used and how they were found for each algorithm. One contention is that scanning shapelets is generally a scalable method to extract features for the classification of time series, which is also accurate, by performing experiments on 52 universal datasets in different areas such as speech recognition, activity detection, medicine, image classification, etc. These datasets are downloaded from [21, 22] and have different properties such as number of training instances, classes, and length (see Table 1). Section 5.2 compares Ultra-Fast Shapelets (UFS) with various formula-based classifiers and demonstrates their ability to compete with each other. Furthermore, the runtime of data streams is compared with data streams and it is shown that Ultra-Fast Shapelets (UFS) are indefinite."}, {"heading": "5.1. Experimental Setup", "text": "In fact, the number of candidates to be evaluated is less than the number of people to be evaluated; in fact, the number of people to be evaluated who are able to be evaluated may be higher than the number of people to be evaluated, higher than the number of people to be evaluated, higher than the number of people to be evaluated."}, {"heading": "5.2. Univariate Datasets", "text": "To support the claim that Ultra-Fast Shapelets are comparable in terms of accuracy but faster than modern shapelet-based classifiers, experiments are conducted on 52 univariate time series datasets and compared with three different methods of shapelet discovery using different classifiers. Ultra-Fast Shapelets (UFS) using Random Forest (RF) and a linear SVM (SVM) are compared with the comprehensive search of shapelets (ES) using RF and SVM, with Fast Shapelets (FS) and Learning Shapelets (LS). These four form-based methods are compared based on classification errors in Section 5.2.1 and runtime in Section 5.2.2. The experiments show that UFS is as good as state-of-the-art shapelets (FS) and Learning Shapelets (LS). These four methods are compared based on runtime errors in Section 5.2.1 and Section 5.2."}, {"heading": "5.2.1. Classification Accuracy", "text": "This section presents the results of an empirical comparison of 52 datasets of different domains for different methods of form finding. Detailed results for each dataset are presented in Table 2.The different methods can be divided into two groups depending on the type of classifier used. Methods using a linear SVM (SVM), ES (SVM), LS) provide better results than those using a nonlinear, tree-based classifier. Tree-based classifiers are only better in 9 datasets than the SVM, which confirms the results by Hills et al. [2] Overall, FS is the worst classifier, which is not surprising because it is an approximation of ES. Comparing UFS with ES by classifier is almost similar in performance using an SVM. ES has better prediction quality on 10 datasets, UFS on 15. UFS using a random forest shows better performance on 19 datasets."}, {"heading": "5.2.2. Runtime Analysis", "text": "This section shows that Ultra-Fast Shapelets (UFS) is not only as accurate as state-of-the-art methods, but also significantly faster, finally making it possible to apply them to multivariate time series datasets. Therefore, the four shapelet-based methods are compared empirically and theoretically. Based on empirical runtime analysis, Table 4 provides the measured runtime in seconds averaged over 10 replications for each method on 52 datasets. Subsequence lengths that are considered are suggested by the authors, which means that only UFS and Fast Shapelets (FS) consider all candidates, while exhaustive search (ES) and Learning Shapelets (LS) consider only a subset of them. Knowing this is obviously an advantage for ES and LS. Nevertheless, FS and UFS are significantly faster than the data series."}, {"heading": "5.3. Hyperparameter Sensitivity", "text": "This section is dedicated to two questions: i) Ultra-Fast Shapelets, which are sensitive to the hyperparameters, and it is easy to find an optimal solution, and ii) Ultra-Fast Shapelets is better because it uses more functions than the baselines use. Figure 8 shows the accuracy and time needed for Ultra-Fast Shapelets (UFS)."}, {"heading": "5.4. Multivariate Datasets", "text": "The 15 multivariate datasets used to evaluate Ultra-Fast Shapelets cover various areas such as character recognition (AUSLAN), handwriting recognition (CharacterTrajectories, PenDigits), motion (CMU S16), gesture (uWaveGestureLibrary) and speech recognition (ArabicDigits, JapaneseVowels). Detailed characteristics of the datasets are shown in Table 5."}, {"heading": "6. Conclusions", "text": "We proposed an ultrafast method of shapelet extraction motivated by knowledge of redundant sub-sequences. Since shapelet discovery by most authors is nothing more than a time-consuming selection of characteristics, it was not surprising that our method, Ultra-Fast shapelets, reduces runtime by orders of magnitude and is, to our knowledge, the fastest Shapelet discovery method published to date. In addition, the ultra-fast shapelet discovery method enabled us to apply shapelet-based classifiers to long universal datasets as well as multivariate time series. We compared UFS to 52 univariate datasets from 15 datasets from different areas of Ultra-Fast Forest characteristics and demonstrated empirically that it is competitive in terms of accuracy. Furthermore, a comparison with state-of-the-art methods for classifying multivariate time series on 15 datasets from different areas of Ultra-Fast Forest characteristics was better compared to Fast Forest characteristics."}, {"heading": "7. Acknowledgements", "text": "Partly co-financed by the Seventh Framework Programme of the European Commission as part of the REDUCTION project (# 288254) www.reduction-project.eu"}], "references": [{"title": "Time Series Shapelets: A New Primitive for Data Mining", "author": ["L. Ye", "E. Keogh"], "venue": "in: Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201909, ACM, New York, NY, USA", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Classification of time series by shapelet transformation", "author": ["J. Hills", "J. Lines", "E. Baranauskas", "J. Mapp", "A. Bagnall"], "venue": "Data Mining and Knowledge Discovery 28 (4) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Clustering Time Series Using Unsupervised-Shapelets", "author": ["J. Zakaria", "A. Mueen", "E. Keogh"], "venue": "in: Proceedings of the 2012 IEEE 12th International Conference on Data Mining, ICDM \u201912, IEEE Computer Society, Washington, DC, USA", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Z", "author": ["M.F. Ghalwash"], "venue": "Obradovic, Early classification of multivariate temporal observations by extraction of interpretable shapelets., BMC Bioinformatics 13 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "T", "author": ["E.J. Keogh"], "venue": "Rakthanmanon, Fast Shapelets: A Scalable Algorithm for Discovering Time Series Shapelets., in: SDM, SIAM", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Logical-shapelets: An Expressive Primitive for Time Series Classification", "author": ["A. Mueen", "E. Keogh", "N. Young"], "venue": "in: Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201911, ACM, New York, NY, USA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient Pattern-Based Time Series Classification on GPU", "author": ["K.-W. Chang", "B. Deka", "W.-M.W. Hwu", "D. Roth"], "venue": "2013 IEEE 13th International Conference on Data Mining 0 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "A Shapelet Transform for Time Series Classification", "author": ["J. Lines", "L.M. Davis", "J. Hills", "A. Bagnall"], "venue": "in: Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201912, ACM, New York, NY, USA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning Time-Series Shapelets", "author": ["J. Grabocka", "N. Schilling", "M. Wistuba", "L. Schmidt-Thieme"], "venue": "in: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "N", "author": ["B. Hartmann"], "venue": "Link, Gesture recognition with inertial sensors and optimized DTW prototypes., in: SMC, IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Human Gait Recognition and Classification Using Time Series Shapelets, 2012", "author": ["S. T", "P.B. Sivakumar"], "venue": "International Conference on Advances in Computing and Communications", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Fast Time Series Classification Based on Infrequent Shapelets", "author": ["Q. He", "Z. Dong", "F. Zhuang", "T. Shang", "Z. Shi"], "venue": "in: ICMLA (1)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "L", "author": ["D. Gordon", "D. Hendler"], "venue": "Rokach, Fast randomized model generation for shapelet-based time series classification ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "B", "author": ["C. Li", "L. Khan"], "venue": "Prabhakaran, Real-time classification of variable length multi-attribute motions., Knowl. Inf. Syst. 10 (2) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Classification of multivariate time series using locality preserving projections", "author": ["X. Weng", "J. Shen"], "venue": "Knowledge-Based Systems 21 (7) ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Accelerometer-based gesture recognition via dynamic-time warping", "author": ["A. Akl", "S. Valaee"], "venue": "affinity propagation, & compressive sensing, in: ICASSP\u201910", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "uWave: Accelerometer-based Personalized Gesture Recognition and Its Applications", "author": ["J. Liu", "L. Zhong", "J. Wickramasuriya", "V. Vasudevan"], "venue": "Pervasive Mob. Comput. 5 (6) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning a symbolic representation for multivariate time series classification", "author": ["M. Baydogan", "G. Runger"], "venue": "Data Mining and Knowledge Discovery ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Experiencing SAX: A Novel Symbolic Representation of Time Series", "author": ["J. Lin", "E. Keogh", "L. Wei", "S. Lonardi"], "venue": "Data Min. Knowl. Discov. 15 (2) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "An Introduction to Variable and Feature Selection", "author": ["I. Guyon", "A. Elisseeff"], "venue": "J. Mach. Learn. Res. 3 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Shapelet based time series classification: https://www.uea.ac.uk/computing/machinelearning/shapelets", "author": ["T. Bagnall"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "The UCR time series classification/clustering homepage: http://www.cs.ucr.edu/ eamonn/time series data", "author": ["E. Keogh"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Multivariate Time Series Classification with Learned Discretization: http://www.mustafabaydogan.com/multivariate-time-series-discretization-for-classification.html (2014). URL http://www.mustafabaydogan.com/multivariate-time-series-discretization-for-classification", "author": ["M. Baydogan"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "A Bag-of-Features Framework to Classify Time Series", "author": ["M.G. Baydogan", "G. Runger", "E. Tuv"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 35 (11) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "One popular method is to identify shapelets [1].", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "Many methods try to find shapelets and apply Shapelet Transformation [2].", "startOffset": 69, "endOffset": 72}, {"referenceID": 2, "context": "The idea of shapelets was mainly applied for univariate time series classification but also for time series clustering [3] and early classification of multivariate time series [4].", "startOffset": 119, "endOffset": 122}, {"referenceID": 3, "context": "The idea of shapelets was mainly applied for univariate time series classification but also for time series clustering [3] and early classification of multivariate time series [4].", "startOffset": 176, "endOffset": 179}, {"referenceID": 4, "context": "Hence, there are various methods of pruning the candidate space [5], improving the scoring function that defines how good a shapelet is [6, 1] or by parallelization [7].", "startOffset": 64, "endOffset": 67}, {"referenceID": 5, "context": "Hence, there are various methods of pruning the candidate space [5], improving the scoring function that defines how good a shapelet is [6, 1] or by parallelization [7].", "startOffset": 136, "endOffset": 142}, {"referenceID": 0, "context": "Hence, there are various methods of pruning the candidate space [5], improving the scoring function that defines how good a shapelet is [6, 1] or by parallelization [7].", "startOffset": 136, "endOffset": 142}, {"referenceID": 6, "context": "Hence, there are various methods of pruning the candidate space [5], improving the scoring function that defines how good a shapelet is [6, 1] or by parallelization [7].", "startOffset": 165, "endOffset": 168}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Also other measures like F-Stat, Kruskall-Wallis and Mood\u2019s median were considered [2, 8].", "startOffset": 83, "endOffset": 89}, {"referenceID": 7, "context": "Also other measures like F-Stat, Kruskall-Wallis and Mood\u2019s median were considered [2, 8].", "startOffset": 83, "endOffset": 89}, {"referenceID": 1, "context": "It is possible to use the extracted subsequences to transform the data and use an arbitrary classifier [2].", "startOffset": 103, "endOffset": 106}, {"referenceID": 8, "context": "[9] try to learn optimal shapelets with respect to the target and report statistically significant improvements in accuracy compared to other shapelet-based classifiers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Shapelets have been used in many applications such as medicine [4], gesture [10] and gait recognition [11] and even time series clustering [3].", "startOffset": 63, "endOffset": 66}, {"referenceID": 9, "context": "Shapelets have been used in many applications such as medicine [4], gesture [10] and gait recognition [11] and even time series clustering [3].", "startOffset": 76, "endOffset": 80}, {"referenceID": 10, "context": "Shapelets have been used in many applications such as medicine [4], gesture [10] and gait recognition [11] and even time series clustering [3].", "startOffset": 102, "endOffset": 106}, {"referenceID": 2, "context": "Shapelets have been used in many applications such as medicine [4], gesture [10] and gait recognition [11] and even time series clustering [3].", "startOffset": 139, "endOffset": 142}, {"referenceID": 0, "context": "On the one hand, there are smart implementations using early abandon of distance computation and entropy pruning for the information gain heuristic [1].", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "On the other hand, ideas to trade time for speed and reuse computations and to prune the search space [6] as well as pruning candidates by searching possibly interesting candidates on the SAX representation [5] or using infrequent shapelets [12] are applied.", "startOffset": 102, "endOffset": 105}, {"referenceID": 4, "context": "On the other hand, ideas to trade time for speed and reuse computations and to prune the search space [6] as well as pruning candidates by searching possibly interesting candidates on the SAX representation [5] or using infrequent shapelets [12] are applied.", "startOffset": 207, "endOffset": 210}, {"referenceID": 11, "context": "On the other hand, ideas to trade time for speed and reuse computations and to prune the search space [6] as well as pruning candidates by searching possibly interesting candidates on the SAX representation [5] or using infrequent shapelets [12] are applied.", "startOffset": 241, "endOffset": 245}, {"referenceID": 12, "context": "[13] learn a decision tree using random subsequences.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4].", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "This overcomes the problem of time series with varying lengths [14, 15].", "startOffset": 63, "endOffset": 71}, {"referenceID": 14, "context": "This overcomes the problem of time series with varying lengths [14, 15].", "startOffset": 63, "endOffset": 71}, {"referenceID": 15, "context": "For example dynamic time warping was applied on multivariate time series in the context of accelerometer-based gesture recognition [16, 17].", "startOffset": 131, "endOffset": 139}, {"referenceID": 16, "context": "For example dynamic time warping was applied on multivariate time series in the context of accelerometer-based gesture recognition [16, 17].", "startOffset": 131, "endOffset": 139}, {"referenceID": 17, "context": "[18] use a symbolic representation for multivariate time series.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "This is similar to SAX [19] but in contrast, the symbols are not fixed but learned in a supervised way using random forests.", "startOffset": 23, "endOffset": 27}, {"referenceID": 1, "context": "Exhaustive Search (ES) The exhaustive search (ES) [2, 6, 1] considers every subsequence in the training data and ranks it using a scoring function s.", "startOffset": 50, "endOffset": 59}, {"referenceID": 5, "context": "Exhaustive Search (ES) The exhaustive search (ES) [2, 6, 1] considers every subsequence in the training data and ranks it using a scoring function s.", "startOffset": 50, "endOffset": 59}, {"referenceID": 0, "context": "Exhaustive Search (ES) The exhaustive search (ES) [2, 6, 1] considers every subsequence in the training data and ranks it using a scoring function s.", "startOffset": 50, "endOffset": 59}, {"referenceID": 4, "context": "Hence, an approximative method, so called Fast Shapelets (FS) [5], was introduced.", "startOffset": 62, "endOffset": 65}, {"referenceID": 18, "context": "The idea is reduce the dimension of the data by estimating the SAX representation [19] and searching on the reduced space for features that are likely to be useful.", "startOffset": 82, "endOffset": 86}, {"referenceID": 8, "context": "[9] propose to consider the shapelets to be parameters that are optimized regarding the loss as well.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "Symbolic Representation for Multivariate Timeseries Symbolic Representation for Multivariate Timeseries (SMTS) [18] is not based on shapelets but has its own way of generating features.", "startOffset": 111, "endOffset": 115}, {"referenceID": 19, "context": "This process corresponds to a feature subset selection [20] that is computational very expensive as there usually exist many possible shapelet candidates.", "startOffset": 55, "endOffset": 59}, {"referenceID": 1, "context": "This relationship holds only for those methods that choose subsequences as shapelets that occur in the training data which is common in many methods [2, 5, 8, 6, 1].", "startOffset": 149, "endOffset": 164}, {"referenceID": 4, "context": "This relationship holds only for those methods that choose subsequences as shapelets that occur in the training data which is common in many methods [2, 5, 8, 6, 1].", "startOffset": 149, "endOffset": 164}, {"referenceID": 7, "context": "This relationship holds only for those methods that choose subsequences as shapelets that occur in the training data which is common in many methods [2, 5, 8, 6, 1].", "startOffset": 149, "endOffset": 164}, {"referenceID": 5, "context": "This relationship holds only for those methods that choose subsequences as shapelets that occur in the training data which is common in many methods [2, 5, 8, 6, 1].", "startOffset": 149, "endOffset": 164}, {"referenceID": 0, "context": "This relationship holds only for those methods that choose subsequences as shapelets that occur in the training data which is common in many methods [2, 5, 8, 6, 1].", "startOffset": 149, "endOffset": 164}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Typically, all subsequences of a specific length [2, 6, 1] or that fulfill another informed criterion [5] are chosen.", "startOffset": 49, "endOffset": 58}, {"referenceID": 5, "context": "Typically, all subsequences of a specific length [2, 6, 1] or that fulfill another informed criterion [5] are chosen.", "startOffset": 49, "endOffset": 58}, {"referenceID": 0, "context": "Typically, all subsequences of a specific length [2, 6, 1] or that fulfill another informed criterion [5] are chosen.", "startOffset": 49, "endOffset": 58}, {"referenceID": 4, "context": "Typically, all subsequences of a specific length [2, 6, 1] or that fulfill another informed criterion [5] are chosen.", "startOffset": 102, "endOffset": 105}, {"referenceID": 19, "context": "In the literature this kind of feature subset selection is called variable ranking and is a filter method [20].", "startOffset": 106, "endOffset": 110}, {"referenceID": 1, "context": "This figure also shows the shapelets found using the variable ranking method which are considered to be useful for classification [2].", "startOffset": 130, "endOffset": 133}, {"referenceID": 17, "context": "Since SMTS [18] is not only using the raw time series but also the derivative of it, it is now explained how derivatives can be used for Ultra-Fast Shapelets.", "startOffset": 11, "endOffset": 15}, {"referenceID": 20, "context": "from [21, 22] and have different properties such as number of training instances, classes and length (see Table 1).", "startOffset": 5, "endOffset": 13}, {"referenceID": 21, "context": "from [21, 22] and have different properties such as number of training instances, classes and length (see Table 1).", "startOffset": 5, "endOffset": 13}, {"referenceID": 22, "context": "4, UFS is compared to state-of-the-art classifiers for multivariate time series on 15 datasets from different domains such as speech, gesture, motion, handwriting and sign language recogniton provided by [23].", "startOffset": 204, "endOffset": 208}, {"referenceID": 23, "context": "The results of SMTS, nearest neighbor with dynamic time warping distance without a warping window (NNDTW) and a multivariate extension of TSBF [24] (MTSBF) were taken from Baydogan et al.", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The datasets are provided by the UCR time series database [22] and by Bagnall et al.", "startOffset": 58, "endOffset": 62}, {"referenceID": 20, "context": "[21].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Table 1 contains few statistics about the datasets, further information can be found on the corresponding websites [21, 22].", "startOffset": 115, "endOffset": 123}, {"referenceID": 21, "context": "Table 1 contains few statistics about the datasets, further information can be found on the corresponding websites [21, 22].", "startOffset": 115, "endOffset": 123}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "LS [9] reports a runtime of O ( ipnm ) where i is the number of iterations used until the algorithm converges and p is the number of shapelets that have to be found.", "startOffset": 3, "endOffset": 6}], "year": 2015, "abstractText": "Time series shapelets are discriminative subsequences and their similarity to a time series can be used for time series classification. Since the discovery of time series shapelets is costly in terms of time, the applicability on long or multivariate time series is difficult. In this work we propose Ultra-Fast Shapelets that uses a number of random shapelets. It is shown that Ultra-Fast Shapelets yield the same prediction quality as current state-of-theart shapelet-based time series classifiers that carefully select the shapelets by being by up to three orders of magnitudes. Since this method allows a ultra-fast shapelet discovery, using shapelets for long multivariate time series classification becomes feasible. A method for using shapelets for multivariate time series is proposed and Ultra-Fast Shapelets is proven to be successful in comparison to state-of-the-art multivariate time series classifiers on 15 multivariate time series datasets from various domains. Finally, time series derivatives that have proven to be useful for other time series classifiers are investigated for the shapelet-based classifiers. It is shown that they have a positive impact and that they are easy to integrate with a simple preprocessing step, without the need of adapting the shapelet discovery algorithm.", "creator": "LaTeX with hyperref package"}}}