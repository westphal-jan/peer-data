{"id": "1503.05615", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Mar-2015", "title": "Learning to Search for Dependencies", "abstract": "We create a transition-based dependency parser using a general purpose learning to search system. The result is a fast and accurate parser for many languages. Compared to other transition-based dependency parsing approaches, our parser provides similar statistical and computational performance with best-known approaches while avoiding various downsides including randomization, extra feature requirements, and custom learning algorithms. We show that it is possible to implement a dependency parser with an open-source learning to search library in about 300 lines of C++ code, while existing systems often requires several thousands of lines.", "histories": [["v1", "Wed, 18 Mar 2015 23:33:17 GMT  (42kb,D)", "http://arxiv.org/abs/1503.05615v1", null], ["v2", "Thu, 7 May 2015 22:12:11 GMT  (48kb,D)", "http://arxiv.org/abs/1503.05615v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["kai-wei chang", "he he", "hal daum\\'e iii", "john langford"], "accepted": false, "id": "1503.05615"}, "pdf": {"name": "1503.05615.pdf", "metadata": {"source": "META", "title": "Learning to Search for Dependencies", "authors": ["Kai-Wei Chang", "He He", "Hal Daum\u00e9 III", "John Langford"], "emails": ["kchang10@illinois.edu", "hhe@cs.umd.edu", "hal@cs.umd.edu", "jcl@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "Dependence parsing is a well-known problem with a long evolutionary history that leads to many solutions. (McDonald et al., 2005; Nivre, 2003; Koo et al., 2008; Goldberg and Elhadad, 2010; Goldberg et al., 2014) Virtually all of these solutions use various problem-specific adaptations of machine learning algorithms or problematic adaptations of traits. In this paper, we try to answer the following question: Is it possible to use a general-purpose learning algorithm with only basic traits to effectively solve dependencies? To be universal, the system needs to solve a wide range of other problems as well. To achieve this goal, we have investigated how learning to find a search system (L2S) (thumb \u0301 III et al., 2014) that has been used to solve about half a dozen other structured prediction problems."}, {"heading": "2 Learning to Search", "text": "However, this family includes a number of specific algorithms, including incremental structured perception (Collins and Roark, 2004; Huang et al., 2012), SEARN (Daume \u0301 III et al., 2009), DAGGER (Ross et al., 2011), 2Inconsistency is a subtle problem that is often not properly addressed, even in machine learning. Inconsistency is important when the truth is loud. A simple illustrative example of inconsistency occurs when the reduction of the 3-class classification to binary classification is done using a one-on-all approach (1 vs {2}, 3 vs {2}, and 3 vs {2}). If the class label is inherently unsafe, probability 1 and 0.3 for the label 2 and 3 that prefers learned binary classification."}, {"heading": "3 Dependency Parsing by Learning to Search", "text": "A transition-based dependency parser takes a sequence of actions and analyzes a set from left to right, maintaining a stack S, a buffer B, and a series of dependency arcs A, A, and A. The stack maintains partial parses, the buffer stores the words that need to be analyzed, and A holds the arcs that can be considered been4Technically, in a mixture that is almost always defined as \"reference\" for the first epoch and \"learned\" for subsequent epochs. Configuration of the parser at each level can be defined by a triple (S, B, A). For the simplicity of notation, we use the leftmost word in the buffer, using s1 and s2 to denote the top and second top words in the stack. A dependency arc (wh, wm) is a directed border that represents the leftmost word in the stack."}, {"heading": "4 Experimental Results", "text": "While most work is compared to MaltParser or MSTParser, which are actually weak baselines, we compare two recent strong baselines: the greedy transition-based dynamic oracle parser (Goldberg and Nivre, 2013) and the Stanford neural network parser (Chen and Manning, 2014)."}, {"heading": "4.1 Datasets", "text": "We conduct experiments with the English Penn Treebank (PTB) datasets (Marcus et al., 1993) and the CoNLL-X datasets (Buchholz and Marsi, 2006) for 9 other languages, including Arabic, Bulgarian, Chinese, Danish, Dutch, Japanese, Portuguese, Slovenian, and Swedish. For the PTB, we convert the constituency trees into dependencies according to the header rules of Yamada and Matsumoto (2006). We follow the standard split: Sections 2 to 21 for education, Section 22 for development, and Section 23 for testing. The POS tags in the evaluation data are assigned by the Stanford POS tagger (Toutanova et al., 2003), which has an accuracy of 97.2% on the PTB test set. For CoNLL-X, we use the Giventrain / Test splits and reserve the last 10% of the training data for development if necessary."}, {"heading": "4.2 Setup and Parameters", "text": "For L2S, the rollin policy is a mixture of the current (learned) policy and the reference (dynamic oracle) TB policy. The probability of executing the reference policy decreases with each round. Specifically, we set it to 1 \u2212 (1 \u2212 \u03b1) t, where t is the number of rounds and \u03b1 is set to 10 \u2212 5 in all experiments. It has been shown (Ross and Bagnell, 2014; Chang et al., 2015) that if the reference policy is optimal, it is preferable to roll out with the reference. Therefore, we roll out the dynamic oracle (Goldberg and Nivre, 2013).Our base learning algorithm is a simple neural network with a hidden layer size of 5 and we do not use word or POS tag embedding. We find the Follow the Regularized Leader Proximal Sximal (FTRL) online learning algorithm particularly effective with learning neural network and parameter use."}, {"heading": "4.3 Results", "text": "Compared to DYNA, our parser has the same transition system and oracle, but more than 8Enabled by -saveIntermediate. 9Available at https: / / github.com / syllog1sm / redshift 10 We note that the neural network parser at Stanford performs particularly poorly in Arabic, Portuguese and Slovenian. One reason for this is that these languages do not have a \"ROOT\" label in the dataset and this is currently not handled well by the software. Compared to SNN, we use much less hidden units and parameters for tuning."}, {"heading": "5 The Value of Strong Base Learners", "text": "As mentioned in Section 3, a key advantage of the L2S framework is that we can use the performance of our parser in training with the following basic teachers: \u2022 SGD: a learner with SGD update rules \u2022 Default: the standard base classifier. This is an improved SGD-like update rule using an adaptive metric (Duchi et al., 2011; McMahan and Streeter, 2010), important invariant updates (Karampatziakis and Langford, 2011) and normalized updates (Ross et al., 2013). \u2022 NN: a single-layer neural network with 5 hidden nodes. \u2022 NN + FTRL: a neural network learner with subsequent management regulation. This is the base learner we use in our parsing system.Table 6 shows that the performance of our TB database can be improved by 7% using various parameters."}, {"heading": "6 Related Work", "text": "However, most of the early work focuses on decoding or feature engineering instead of the core learning algorithm. Their approach is essentially a special case of our algorithm: the basic learner is a multi-class perceptron, and there is no rollout to assign costs to the actions. In this work, we combine dynamic oracles to learn and explore the search space in a more principled way by learning searching: by cost-sensitive classification, we evaluate the end result of each non-optimal action rather than treating it as equally poor.There are a number of papers that use the L2S approach to solve various other structured prediction problems, such as sequence labeling of programs (Doppa et al., 2014), correlation resolution (Ma Pyet, a general system in which this dependence or our interaction (s) is structured."}, {"heading": "7 Conclusion and Discussion", "text": "We show that it is now much easier to implement a powerful dependency saver. In addition, we offer a wide range of advanced optimization methods from which we can choose during training. Experimental results show that we consistently achieve better performance in 10 languages. An interesting direction for future work is to expand the current system beyond the greedy search. In addition, there is a great deal of scope to speed up training time by intelligently choosing where to introduce it."}], "references": [{"title": "Conll-x shared task on multilingual dependency parsing", "author": ["Sabine Buchholz", "Erwin Marsi."], "venue": "Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 149\u2013164. Association for Computational Linguistics.", "citeRegEx": "Buchholz and Marsi.,? 2006", "shortCiteRegEx": "Buchholz and Marsi.", "year": 2006}, {"title": "Learning to search better than your teacher", "author": ["Kai-Wei Chang", "Akshay Krishnamurthy", "Alekh Agarwal", "Hal Daum\u00e9 III", "John Langford."], "venue": "arXiv:1502.02206.", "citeRegEx": "Chang et al\\.,? 2015", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Danqi Chen", "Christopher Manning."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 740\u2013750.", "citeRegEx": "Chen and Manning.,? 2014", "shortCiteRegEx": "Chen and Manning.", "year": 2014}, {"title": "Incremental parsing with the perceptron algorithm", "author": ["Michael Collins", "Brian Roark."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL).", "citeRegEx": "Collins and Roark.,? 2004", "shortCiteRegEx": "Collins and Roark.", "year": 2004}, {"title": "Learning as search optimization: Approximate large margin methods for structured prediction", "author": ["Hal Daum\u00e9 III", "Daniel Marcu."], "venue": "Proceedings of the International Conference on Machine Learning (ICML).", "citeRegEx": "III and Marcu.,? 2005", "shortCiteRegEx": "III and Marcu.", "year": 2005}, {"title": "Search-based structured prediction", "author": ["Hal Daum\u00e9 III", "John Langford", "Daniel Marcu."], "venue": "Machine Learning Journal.", "citeRegEx": "III et al\\.,? 2009", "shortCiteRegEx": "III et al\\.", "year": 2009}, {"title": "Efficient programmable learning to search", "author": ["Hal Daum\u00e9 III", "John Langford", "St\u00e9phane Ross."], "venue": "arXiv:1406.1837.", "citeRegEx": "III et al\\.,? 2014", "shortCiteRegEx": "III et al\\.", "year": 2014}, {"title": "Output space search for structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli."], "venue": "Proceedings of the International Conference on Machine Learning (ICML).", "citeRegEx": "Doppa et al\\.,? 2012", "shortCiteRegEx": "Doppa et al\\.", "year": 2012}, {"title": "HC-Search: A learning framework for search-based structured prediction", "author": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli."], "venue": "Journal of Artificial Intelligence Research (JAIR), 50.", "citeRegEx": "Doppa et al\\.,? 2014", "shortCiteRegEx": "Doppa et al\\.", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John C. Duchi", "Elad Hazan", "Yoram Singer."], "venue": "Journal of Machine Learning Research, 12:2121\u20132159.", "citeRegEx": "Duchi et al\\.,? 2011", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "An efficient algorithm for easy-first non-directional dependency parsing", "author": ["Yoav Goldberg", "Michael Elhadad."], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Goldberg and Elhadad.,? 2010", "shortCiteRegEx": "Goldberg and Elhadad.", "year": 2010}, {"title": "Training deterministic parsers with non-deterministic oracles", "author": ["Yoav Goldberg", "Joakim Nivre."], "venue": "Transactions of the ACL, 1.", "citeRegEx": "Goldberg and Nivre.,? 2013", "shortCiteRegEx": "Goldberg and Nivre.", "year": 2013}, {"title": "A tabular method for dynamic oracles in transition-based parsing", "author": ["Yoav Goldberg", "Francesco Sartorio", "Giorgio Satta."], "venue": "Transactions of the ACL, 2.", "citeRegEx": "Goldberg et al\\.,? 2014", "shortCiteRegEx": "Goldberg et al\\.", "year": 2014}, {"title": "Probabilistic programming", "author": ["Andrew D. Gordon", "Thomas A. Henzinger", "Aditya V. Nori", "Sriram K. Rajamani."], "venue": "Proceedings of the on Future of Software Engineering.", "citeRegEx": "Gordon et al\\.,? 2014", "shortCiteRegEx": "Gordon et al\\.", "year": 2014}, {"title": "Dynamic feature selection for dependency parsing", "author": ["He He", "Hal Daum\u00e9 III", "Jason Eisner."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "He et al\\.,? 2013", "shortCiteRegEx": "He et al\\.", "year": 2013}, {"title": "Structured perceptron with inexact search", "author": ["Liang Huang", "Suphan Fayong", "Yang Guo."], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Huang et al\\.,? 2012", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Online importance weight aware updates", "author": ["Nikos Karampatziakis", "John Langford."], "venue": "UAI 2011, Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence, Barcelona, Spain, July 14-17, 2011, pages 392\u2013399.", "citeRegEx": "Karampatziakis and Langford.,? 2011", "shortCiteRegEx": "Karampatziakis and Langford.", "year": 2011}, {"title": "Simple semi-supervised dependency parsing", "author": ["Terry Koo", "Xavier Carreras", "Michael Collins."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL).", "citeRegEx": "Koo et al\\.,? 2008", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "Dynamic programming algorithms for transition-based dependency parsers", "author": ["Marco Kuhlmann", "Carlos G\u00f3mez-Rodr\u0131\u0301guez", "Giorgio Satta"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-", "citeRegEx": "Kuhlmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kuhlmann et al\\.", "year": 2011}, {"title": "Building a large annotated corpus of English: The Penn Treebank", "author": ["M.P. Marcus", "M.A. Marcinkiewicz", "B. Santorini."], "venue": "Computational linguistics, 19(2):330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Factorie: Probabilistic programming via imperatively defined factor graphs", "author": ["Andrew McCallum", "Karl Schultz", "Sameer Singh."], "venue": "Advances in Neural Information Processing Systems (NIPS).", "citeRegEx": "McCallum et al\\.,? 2009", "shortCiteRegEx": "McCallum et al\\.", "year": 2009}, {"title": "Online large-margin training of dependency parsers", "author": ["Ryan McDonald", "Koby Crammer", "Fernando Pereira."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL).", "citeRegEx": "McDonald et al\\.,? 2005", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Adaptive bound optimization for online convex optimization", "author": ["H. Brendan McMahan", "Matthew J. Streeter."], "venue": "COLT 2010 - The 23rd Conference on Learning Theory, Haifa, Israel, June 27-29, 2010, pages 244\u2013256.", "citeRegEx": "McMahan and Streeter.,? 2010", "shortCiteRegEx": "McMahan and Streeter.", "year": 2010}, {"title": "An efficient algorithm for projective dependency parsing", "author": ["Joakim Nivre."], "venue": "International Workshop on Parsing Technologies (IWPT), pages 149\u2013160.", "citeRegEx": "Nivre.,? 2003", "shortCiteRegEx": "Nivre.", "year": 2003}, {"title": "Incrementality in deterministic dependency parsing", "author": ["Joakim Nivre."], "venue": "Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together.", "citeRegEx": "Nivre.,? 2004", "shortCiteRegEx": "Nivre.", "year": 2004}, {"title": "Boosting structured prediction for imitation learning", "author": ["Nathan Ratliff", "David Bradley", "J. Andrew Bagnell", "Joel Chestnutt."], "venue": "Advances in Neural Information Processing Systems (NIPS).", "citeRegEx": "Ratliff et al\\.,? 2007", "shortCiteRegEx": "Ratliff et al\\.", "year": 2007}, {"title": "Reinforcement and imitation learning via interactive no-regret learning", "author": ["St\u00e9phane Ross", "J. Andrew Bagnell."], "venue": "arXiv:1406.5979.", "citeRegEx": "Ross and Bagnell.,? 2014", "shortCiteRegEx": "Ross and Bagnell.", "year": 2014}, {"title": "A reduction of imitation learning and structured prediction to no-regret online learning", "author": ["St\u00e9phane Ross", "Geoff J. Gordon", "J. Andrew Bagnell."], "venue": "Proceedings of the Workshop on Artificial Intelligence and Statistics (AIStats).", "citeRegEx": "Ross et al\\.,? 2011", "shortCiteRegEx": "Ross et al\\.", "year": 2011}, {"title": "Normalized online learning", "author": ["St\u00e9phane Ross", "Paul Mineiro", "John Langford."], "venue": "Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence, Bellevue, WA, USA, August 11-15, 2013.", "citeRegEx": "Ross et al\\.,? 2013", "shortCiteRegEx": "Ross et al\\.", "year": 2013}, {"title": "A reduction from apprenticeship learning to classification", "author": ["Umar Syed", "Robert E. Schapire."], "venue": "Advances in Neural Information Processing Systems (NIPS).", "citeRegEx": "Syed and Schapire.,? 2011", "shortCiteRegEx": "Syed and Schapire.", "year": 2011}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["Kristina Toutanova", "Dan Klein", "Christopher D. Manning", "Yoram Singer."], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Toutanova et al\\.,? 2003", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "Feature hashing for large scale multitask learning", "author": ["Kilian Weinberger", "Anirban Dasbupta", "John Langford", "Alex Smola", "Josh Attenberg."], "venue": "Proceedings of the International Conference on Machine Learning (ICML).", "citeRegEx": "Weinberger et al\\.,? 2009", "shortCiteRegEx": "Weinberger et al\\.", "year": 2009}, {"title": "On learning linear ranking functions for beam search", "author": ["Yuehua Xu", "Alan Fern."], "venue": "ICML, pages 1047\u20131054.", "citeRegEx": "Xu and Fern.,? 2007", "shortCiteRegEx": "Xu and Fern.", "year": 2007}, {"title": "Discriminative learning of beam-search heuristics for planning", "author": ["Yuehua Xu", "Alan Fern", "Sung Wook Yoon."], "venue": "IJCAI, pages 2041\u20132046.", "citeRegEx": "Xu et al\\.,? 2007", "shortCiteRegEx": "Xu et al\\.", "year": 2007}, {"title": "Statistical dependency analysis with support Vector Machines", "author": ["Hiroyasu Yamada", "Yuji Matsumoto."], "venue": "International Workshop on Parsing Technologies (IWPT).", "citeRegEx": "Yamada and Matsumoto.,? 2006", "shortCiteRegEx": "Yamada and Matsumoto.", "year": 2006}, {"title": "Transition-based dependency parsing with rich non-local features", "author": ["Yue Zhang", "Joakim Nivre."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL), pages 188\u2013193. Association for Computational Linguistics.", "citeRegEx": "Zhang and Nivre.,? 2011", "shortCiteRegEx": "Zhang and Nivre.", "year": 2011}], "referenceMentions": [{"referenceID": 21, "context": "Dependency parsing is a well-known problem with a long history of development resulting in many solutions (McDonald et al., 2005; Nivre, 2003; Koo et al., 2008; Goldberg and Elhadad, 2010; Goldberg et al., 2014).", "startOffset": 106, "endOffset": 211}, {"referenceID": 23, "context": "Dependency parsing is a well-known problem with a long history of development resulting in many solutions (McDonald et al., 2005; Nivre, 2003; Koo et al., 2008; Goldberg and Elhadad, 2010; Goldberg et al., 2014).", "startOffset": 106, "endOffset": 211}, {"referenceID": 17, "context": "Dependency parsing is a well-known problem with a long history of development resulting in many solutions (McDonald et al., 2005; Nivre, 2003; Koo et al., 2008; Goldberg and Elhadad, 2010; Goldberg et al., 2014).", "startOffset": 106, "endOffset": 211}, {"referenceID": 10, "context": "Dependency parsing is a well-known problem with a long history of development resulting in many solutions (McDonald et al., 2005; Nivre, 2003; Koo et al., 2008; Goldberg and Elhadad, 2010; Goldberg et al., 2014).", "startOffset": 106, "endOffset": 211}, {"referenceID": 12, "context": "Dependency parsing is a well-known problem with a long history of development resulting in many solutions (McDonald et al., 2005; Nivre, 2003; Koo et al., 2008; Goldberg and Elhadad, 2010; Goldberg et al., 2014).", "startOffset": 106, "endOffset": 211}, {"referenceID": 11, "context": "L2S (ours) \u223c300 Stanford \u223c3K RedShift \u223c2K (Goldberg and Nivre, 2013) \u223c4K Malt Parser \u223c10K", "startOffset": 42, "endOffset": 68}, {"referenceID": 11, "context": "Several authors have investigated transition-based parser approaches (Goldberg and Nivre, 2013; Zhang and Nivre, 2011; Chen and Manning, 2014; Kuhlmann et al., 2011) achieving success with custom learning algorithms or custom features.", "startOffset": 69, "endOffset": 165}, {"referenceID": 35, "context": "Several authors have investigated transition-based parser approaches (Goldberg and Nivre, 2013; Zhang and Nivre, 2011; Chen and Manning, 2014; Kuhlmann et al., 2011) achieving success with custom learning algorithms or custom features.", "startOffset": 69, "endOffset": 165}, {"referenceID": 2, "context": "Several authors have investigated transition-based parser approaches (Goldberg and Nivre, 2013; Zhang and Nivre, 2011; Chen and Manning, 2014; Kuhlmann et al., 2011) achieving success with custom learning algorithms or custom features.", "startOffset": 69, "endOffset": 165}, {"referenceID": 18, "context": "Several authors have investigated transition-based parser approaches (Goldberg and Nivre, 2013; Zhang and Nivre, 2011; Chen and Manning, 2014; Kuhlmann et al., 2011) achieving success with custom learning algorithms or custom features.", "startOffset": 69, "endOffset": 165}, {"referenceID": 11, "context": "Aside from the overall transition-based dependency parsing structure, the L2S parser uses a dynamic oracle (Goldberg and Nivre, 2013) and a single-hidden-layer neural network \u201cfor free\u201d (enabled by a simple flag), as opposed to a system built from scratch to use neural networks (Chen and Manning, 2014).", "startOffset": 107, "endOffset": 133}, {"referenceID": 2, "context": "Aside from the overall transition-based dependency parsing structure, the L2S parser uses a dynamic oracle (Goldberg and Nivre, 2013) and a single-hidden-layer neural network \u201cfor free\u201d (enabled by a simple flag), as opposed to a system built from scratch to use neural networks (Chen and Manning, 2014).", "startOffset": 279, "endOffset": 303}, {"referenceID": 11, "context": "We do not randomize 5 times and take the best result as in (Goldberg and Nivre, 2013).", "startOffset": 59, "endOffset": 85}, {"referenceID": 27, "context": "Regret analysis of learning to search (Daum\u00e9 III et al., 2009; Ross et al., 2011; Ross and Bagnell, 2014; Chang et al., 2015) suggests how to settle various details:", "startOffset": 38, "endOffset": 125}, {"referenceID": 26, "context": "Regret analysis of learning to search (Daum\u00e9 III et al., 2009; Ross et al., 2011; Ross and Bagnell, 2014; Chang et al., 2015) suggests how to settle various details:", "startOffset": 38, "endOffset": 125}, {"referenceID": 1, "context": "Regret analysis of learning to search (Daum\u00e9 III et al., 2009; Ross et al., 2011; Ross and Bagnell, 2014; Chang et al., 2015) suggests how to settle various details:", "startOffset": 38, "endOffset": 125}, {"referenceID": 3, "context": "This family includes a number of specific algorithms including the incremental structured perceptron (Collins and Roark, 2004; Huang et al., 2012), SEARN (Daum\u00e9 III et al.", "startOffset": 101, "endOffset": 146}, {"referenceID": 15, "context": "This family includes a number of specific algorithms including the incremental structured perceptron (Collins and Roark, 2004; Huang et al., 2012), SEARN (Daum\u00e9 III et al.", "startOffset": 101, "endOffset": 146}, {"referenceID": 27, "context": ", 2009), DAGGER (Ross et al., 2011),", "startOffset": 16, "endOffset": 35}, {"referenceID": 26, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al.", "startOffset": 10, "endOffset": 34}, {"referenceID": 32, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al., 2007; Ratliff et al., 2007; Syed and Schapire, 2011; Doppa et al., 2012; Doppa et al., 2014).", "startOffset": 47, "endOffset": 197}, {"referenceID": 33, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al., 2007; Ratliff et al., 2007; Syed and Schapire, 2011; Doppa et al., 2012; Doppa et al., 2014).", "startOffset": 47, "endOffset": 197}, {"referenceID": 25, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al., 2007; Ratliff et al., 2007; Syed and Schapire, 2011; Doppa et al., 2012; Doppa et al., 2014).", "startOffset": 47, "endOffset": 197}, {"referenceID": 29, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al., 2007; Ratliff et al., 2007; Syed and Schapire, 2011; Doppa et al., 2012; Doppa et al., 2014).", "startOffset": 47, "endOffset": 197}, {"referenceID": 7, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al., 2007; Ratliff et al., 2007; Syed and Schapire, 2011; Doppa et al., 2012; Doppa et al., 2014).", "startOffset": 47, "endOffset": 197}, {"referenceID": 8, "context": "AGGREVATE (Ross and Bagnell, 2014), and others (Daum\u00e9 III and Marcu, 2005; Xu and Fern, 2007; Xu et al., 2007; Ratliff et al., 2007; Syed and Schapire, 2011; Doppa et al., 2012; Doppa et al., 2014).", "startOffset": 47, "endOffset": 197}, {"referenceID": 18, "context": "We consider an arc-hybrid transition system (Kuhlmann et al., 2011)5.", "startOffset": 44, "endOffset": 67}, {"referenceID": 23, "context": "The learning to search framework is also suitable for other transition-based dependency parsing systems, such as arc-eager (Nivre, 2003) or arc-standard (Nivre, 2004) transition systems.", "startOffset": 123, "endOffset": 136}, {"referenceID": 24, "context": "The learning to search framework is also suitable for other transition-based dependency parsing systems, such as arc-eager (Nivre, 2003) or arc-standard (Nivre, 2004) transition systems.", "startOffset": 153, "endOffset": 166}, {"referenceID": 11, "context": "Thanks to recent work (Goldberg and Nivre, 2013), we know how to compute a \u201cdynamic oracle\u201d reference policy that is optimal.", "startOffset": 22, "endOffset": 48}, {"referenceID": 11, "context": "\u2022 GETGOLDACTION implements the dynamic oracle described in (Goldberg and Nivre, 2013).", "startOffset": 59, "endOffset": 85}, {"referenceID": 31, "context": "A feature hashing technique (Weinberger et al., 2009) is employed to provide a fast feature lookup.", "startOffset": 28, "endOffset": 53}, {"referenceID": 11, "context": "While most work compares with MaltParser or MSTParser, which are indeed weak baselines, we compare with two recent strong baselines: the greedy transition-based parser with dynamic oracle (Goldberg and Nivre, 2013) and the Stanford neural network parser (Chen and Manning, 2014).", "startOffset": 188, "endOffset": 214}, {"referenceID": 2, "context": "While most work compares with MaltParser or MSTParser, which are indeed weak baselines, we compare with two recent strong baselines: the greedy transition-based parser with dynamic oracle (Goldberg and Nivre, 2013) and the Stanford neural network parser (Chen and Manning, 2014).", "startOffset": 254, "endOffset": 278}, {"referenceID": 19, "context": "We conduct experiments on the English Penn Treebank (PTB) (Marcus et al., 1993) and the CoNLL-X (Buchholz and Marsi, 2006) datasets for 9 other languages, including Arabic, Bulgarian, Chinese, Danish, Dutch, Japanese, Portuguese, Slovene and Swedish.", "startOffset": 58, "endOffset": 79}, {"referenceID": 0, "context": ", 1993) and the CoNLL-X (Buchholz and Marsi, 2006) datasets for 9 other languages, including Arabic, Bulgarian, Chinese, Danish, Dutch, Japanese, Portuguese, Slovene and Swedish.", "startOffset": 24, "endOffset": 50}, {"referenceID": 30, "context": "The POS tags in the evaluation data is assigned by the Stanford POS tagger (Toutanova et al., 2003), which has an accuracy of 97.", "startOffset": 75, "endOffset": 99}, {"referenceID": 0, "context": ", 1993) and the CoNLL-X (Buchholz and Marsi, 2006) datasets for 9 other languages, including Arabic, Bulgarian, Chinese, Danish, Dutch, Japanese, Portuguese, Slovene and Swedish. For PTB, we convert the constituency trees to dependencies by the head rules of Yamada and Matsumoto (2006). We follow the standard split: sections 2 to 21 for training, section 22 for development and section 23 for testing.", "startOffset": 25, "endOffset": 287}, {"referenceID": 26, "context": "It has been shown (Ross and Bagnell, 2014; Chang et al., 2015) that when the reference policy is optimal, it is preferable to roll out with the reference.", "startOffset": 18, "endOffset": 62}, {"referenceID": 1, "context": "It has been shown (Ross and Bagnell, 2014; Chang et al., 2015) that when the reference policy is optimal, it is preferable to roll out with the reference.", "startOffset": 18, "endOffset": 62}, {"referenceID": 11, "context": "Therefore, we roll out with the dynamic oracle (Goldberg and Nivre, 2013).", "startOffset": 47, "endOffset": 73}, {"referenceID": 11, "context": "We compare with the recent transition-based parser with dynamic oracles (DYNA) (Goldberg and Nivre, 2013), and the Stanford neural network parser (SNN) (Chen and Manning, 2014).", "startOffset": 79, "endOffset": 105}, {"referenceID": 2, "context": "We compare with the recent transition-based parser with dynamic oracles (DYNA) (Goldberg and Nivre, 2013), and the Stanford neural network parser (SNN) (Chen and Manning, 2014).", "startOffset": 152, "endOffset": 176}, {"referenceID": 2, "context": "parameter values as suggested in (Chen and Manning, 2014), which are also the default settings of the software.", "startOffset": 33, "endOffset": 57}, {"referenceID": 9, "context": "This is an improved SGD-style update rule using an adaptive metric (Duchi et al., 2011; McMahan and Streeter, 2010), importance invariant updates (Karampatziakis and Langford, 2011), and normalized updates (Ross et al.", "startOffset": 67, "endOffset": 115}, {"referenceID": 22, "context": "This is an improved SGD-style update rule using an adaptive metric (Duchi et al., 2011; McMahan and Streeter, 2010), importance invariant updates (Karampatziakis and Langford, 2011), and normalized updates (Ross et al.", "startOffset": 67, "endOffset": 115}, {"referenceID": 16, "context": ", 2011; McMahan and Streeter, 2010), importance invariant updates (Karampatziakis and Langford, 2011), and normalized updates (Ross et al.", "startOffset": 66, "endOffset": 101}, {"referenceID": 28, "context": ", 2011; McMahan and Streeter, 2010), importance invariant updates (Karampatziakis and Langford, 2011), and normalized updates (Ross et al., 2013).", "startOffset": 126, "endOffset": 145}, {"referenceID": 11, "context": "Goldberg and Nivre (2013) first proposed dynamic oracles under the framework of imitation learning.", "startOffset": 0, "endOffset": 26}, {"referenceID": 8, "context": "There are a number of works that use the L2S approach to solve various other structured prediction problems, for example, sequence labeling (Doppa et al., 2014), coreference resolution (Ma et al.", "startOffset": 140, "endOffset": 160}, {"referenceID": 14, "context": ", 204), graph-based dependency parsing (He et al., 2013).", "startOffset": 39, "endOffset": 56}, {"referenceID": 20, "context": ", (McCallum et al., 2009; Gordon et al., 2014)), however, instead of relying on a new programming language, ours is implemented in C++ and Python, thus is easily accessible.", "startOffset": 2, "endOffset": 46}, {"referenceID": 13, "context": ", (McCallum et al., 2009; Gordon et al., 2014)), however, instead of relying on a new programming language, ours is implemented in C++ and Python, thus is easily accessible.", "startOffset": 2, "endOffset": 46}], "year": 2017, "abstractText": "We create a transition-based dependency parser using a general purpose learning to search system. The result is a fast and accurate parser for many languages. Compared to other transition-based dependency parsing approaches, our parser provides similar statistical and computational performance with best-known approaches while avoiding various downsides including randomization, extra feature requirements, and custom learning algorithms. We show that it is possible to implement a dependency parser with an open-source learning to search library in about 300 lines of C++ code, while existing systems often requires several thousands of lines.", "creator": "LaTeX with hyperref package"}}}