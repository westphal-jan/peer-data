{"id": "1503.06046", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2015", "title": "Deep Transform: Cocktail Party Source Separation via Probabilistic Re-Synthesis", "abstract": "In cocktail party listening scenarios, the human brain is able to separate competing speech signals. However, the signal processing implemented by the brain to perform cocktail party listening is not well understood. Here, we trained two separate convolutive autoencoder deep neural networks (DNN) to separate monaural and binaural mixtures of two concurrent speech streams. We then used these DNNs as convolutive deep transform (CDT) devices to perform probabilistic re-synthesis. The CDTs operated directly in the time-domain. Our simulations demonstrate that very simple neural networks are capable of exploiting monaural and binaural information available in a cocktail party listening scenario.", "histories": [["v1", "Fri, 20 Mar 2015 12:00:44 GMT  (5232kb)", "http://arxiv.org/abs/1503.06046v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG cs.NE", "authors": ["andrew j r simpson"], "accepted": false, "id": "1503.06046"}, "pdf": {"name": "1503.06046.pdf", "metadata": {"source": "CRF", "title": "Deep Transform: Cocktail Party Source Separation via Probabilistic Re-Synthesis", "authors": ["Andrew J.R. Simpson"], "emails": ["Andrew.Simpson@Surrey.ac.uk"], "sections": [{"heading": null, "text": "In fact, most of them are able to determine for themselves what they want and what they don't want."}], "references": [{"title": "The cocktail party problem", "author": ["JH McDermott"], "venue": "Curr. Biol", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Perceptual Organization of Sound Begins in the Auditory Periphery", "author": ["D Pressnitzer", "M Sayles", "C Micheyl", "IM Winter"], "venue": "Curr. Biol", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Emergence of neural encoding of auditory objects while listening to competing speakers", "author": ["N Ding", "JZ Simon"], "venue": "Proc. Natl. Acad. Sci. USA", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Perceptual Restoration of Missing Speech Sounds", "author": ["Warren", "Richard M"], "venue": "Science", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1970}, {"title": "Deep Transform: Error Correction via Probabilistic Re-Synthesis\u201d, arxiv.org", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Deep Transform: Time-Domain Audio Error Correction via Probabilistic Re-Synthesis\u201d, arxiv.org abs/1502.05849", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Learning deep architectures for AI", "author": ["Y Bengio"], "venue": "Foundations and Trends in Machine Learning", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "A Free Database of Head-Related Impulse Response Measurements in the Horizontal Plane with Multiple Distances", "author": ["H Wierstorf", "M Geier", "A Raake", "S Spors"], "venue": "In Proc. 130th Conv. Audio Eng. Soc", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Abstract Learning via Demodulation in a Deep Neural Network\u201d, arxiv.org", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Performance measurement in blind audio source separation", "author": ["E Vincent", "R Gribonval", "C F\u00e9votte"], "venue": "IEEE Trans. on Audio, Speech and Language Processing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "In cocktail party listening, a listener must selectively attend to a voice within a background of competing speech noise [1].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "The fact that selective representations of speech emerge at a relatively early stage of the auditory pathway [2], [3] suggests that relatively simple bottom-up processes are involved.", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "The fact that selective representations of speech emerge at a relatively early stage of the auditory pathway [2], [3] suggests that relatively simple bottom-up processes are involved.", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "In addition, a role of synthesis is implied by the well known phenomenon of \u2018phoneme restoration\u2019 [4].", "startOffset": 98, "endOffset": 101}, {"referenceID": 4, "context": "This may be interpreted as re-synthesis [5], [6].", "startOffset": 40, "endOffset": 43}, {"referenceID": 5, "context": "This may be interpreted as re-synthesis [5], [6].", "startOffset": 45, "endOffset": 48}, {"referenceID": 6, "context": "One way to perform this abstract transformation is known as an autoencoder [7] or deep transform (DT) [5], [6].", "startOffset": 75, "endOffset": 78}, {"referenceID": 4, "context": "One way to perform this abstract transformation is known as an autoencoder [7] or deep transform (DT) [5], [6].", "startOffset": 102, "endOffset": 105}, {"referenceID": 5, "context": "One way to perform this abstract transformation is known as an autoencoder [7] or deep transform (DT) [5], [6].", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "From the point of view of the autoencoder which is trained on the speech of a single speaker, source separation may be viewed as error correction wherein the speech of the competing speaker is treated as error [5].", "startOffset": 210, "endOffset": 213}, {"referenceID": 7, "context": "The HRIR was obtained from a dummy head [8], recorded at 1m.", "startOffset": 40, "endOffset": 43}, {"referenceID": 0, "context": "This allowed the use of a signmoidal output function mapped to the range [0,1].", "startOffset": 73, "endOffset": 78}, {"referenceID": 8, "context": "Both the DNNs employed the biased-sigmoid activation function [9] throughout with zero bias for the output layer.", "startOffset": 62, "endOffset": 65}, {"referenceID": 4, "context": ", a convolutive deep transform \u2013 CDT - [5], [6]).", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": ", a convolutive deep transform \u2013 CDT - [5], [6]).", "startOffset": 44, "endOffset": 47}, {"referenceID": 9, "context": "Separation quality (for the test data) was measured using the BSS-EVAL toolbox [10] and is quantified in terms of signal-to-distortion ratio (SDR), signal-to-artefact ratio (SAR) and signal-to-interference ratio (SIR).", "startOffset": 79, "endOffset": 83}, {"referenceID": 9, "context": "Signal-to-distortion ratio (SDR, red), signal-to-interference (SIR, green), signal-to-artefact ration (SAR, blue), computed from the 10second test audio using the BSS-EVAL toolkit [10].", "startOffset": 180, "endOffset": 184}, {"referenceID": 5, "context": "We have demonstrated that CDT probabilistic re-synthesis [6] may be applied to the problem of source separation directly in the time domain.", "startOffset": 57, "endOffset": 60}], "year": 2015, "abstractText": "In cocktail party listening scenarios, the human brain is able to separate competing speech signals. However, the signal processing implemented by the brain to perform cocktail party listening is not well understood. Here, we trained two separate convolutive autoencoder deep neural networks (DNN) to separate monaural and binaural mixtures of two concurrent speech streams. We then used these DNNs as convolutive deep transform (CDT) devices to perform probabilistic re-synthesis. The CDTs operated directly in the time-domain. Our simulations demonstrate that very simple neural networks are capable of exploiting monaural and binaural information available in a cocktail party listening scenario.", "creator": "PDFCreator Version 1.7.1"}}}