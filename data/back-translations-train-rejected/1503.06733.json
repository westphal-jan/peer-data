{"id": "1503.06733", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2015", "title": "Yara Parser: A Fast and Accurate Dependency Parser", "abstract": "Dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition. We introduce the Yara Parser, a fast and accurate open-source dependency parser based on the arc-eager algorithm and beam search. It achieves an unlabeled accuracy of 93.32 on the standard WSJ test set which ranks it among the top dependency parsers. At its fastest, Yara can parse about 4000 sentences per second when in greedy mode (1 beam). When optimizing for accuracy (using 64 beams and Brown cluster features), Yara can parse 45 sentences per second. The parser can be trained on any syntactic dependency treebank and different options are provided in order to make it more flexible and tunable for specific tasks. It is released with the Apache version 2.0 license and can be used for both commercial and academic purposes. The parser can be found at", "histories": [["v1", "Mon, 23 Mar 2015 17:20:54 GMT  (255kb,D)", "http://arxiv.org/abs/1503.06733v1", null], ["v2", "Tue, 24 Mar 2015 18:45:13 GMT  (757kb,D)", "http://arxiv.org/abs/1503.06733v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mohammad sadegh rasooli", "joel tetreault"], "accepted": false, "id": "1503.06733"}, "pdf": {"name": "1503.06733.pdf", "metadata": {"source": "CRF", "title": "Yara Parser: A Fast and Accurate Dependency Parser", "authors": ["Mohammad Sadegh Rasooli", "Joel Tetreault"], "emails": ["rasooli@cs.columbia.edu", "tetreaul@yahoo-inc.com"], "sections": [{"heading": null, "text": "We introduce the Yara Parser, a fast and precise open source dependency parser based on the arc-eager algorithm and beam search. It achieves an undescribed accuracy of 93.32 on the standard WSJ test set, which ranks it among the top dependency savers. Yara is fastest at about 4000 records per second in greedy mode (1 beam). In accuracy optimization (using 64 beam types and Brown cluster features), Yara can analyze 45 records per second. Yara can be trained on any syntactic dependency tree base, and various options are available to make it more flexible and usable for specific tasks. It is released under the Apache Version 2.0 license and can be used for both commercial and academic purposes. The parser is available at https: / / github.com / yahoo / Yarsera.Content"}, {"heading": "1 Introduction 2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Using Yara in Practice 2", "text": "The question whether the woman is a woman or a woman has not yet been answered."}, {"heading": "3 Yara Technical Details 7", "text": "3.1 Arc-Eager algorithm........................................................................................................................"}, {"heading": "4 Experiments 9", "text": "4.1 Parsing WSJ Data..................................................... 9 4.2 Parsing Non-Projective Languages: Persian..........................................."}, {"heading": "5 Conclusion and Future Work 11", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction", "text": "Dependency trees are one of the most important representations used in syntactical analysis of sentences. They show explicit syntactic dependencies between words in sentences [K\u00fcbler et al., 2009]. Many dependency parsers have been published in the last ten years. Among them, graph-based and transition-based analyses are two main approaches for analyzing dependencies. In graph-based models, the parser aims to find the most likely tree out of all possible trees, often using maximum tree algorithms in conjunction with dynamic programming. On the other hand, in transition models, a tree is converted into a series of incremental actions and the parser decides to perform an action depending on the current configuration of the subtree. Graph-based parsers can achieve state-of-the-art performance with the guarantee of restoring the best possible analyses, but usually at the expense of speed."}, {"heading": "2 Using Yara in Practice", "text": "In this section, we give a brief overview of the training of the parser, both from the command line and as an API. Finally, we introduce a simple NLP pipeline that can parse text files. All technical details for the parser are in \u00a7 3. The default settings for Yara should be the best in practice in terms of accuracy (except for the number of training iterations that depend on the data and feature settings)."}, {"heading": "2.1 Data format", "text": "Yara uses the CoNLL 2006 dependency format1 for both training and testing. The CoNLL format is a tabular format in which each word (and its information) takes one line in a sentence and sentences are separated by a blank line. Each line is divided into the following tabular columns: 1) number of words (starting with one), 2) word form, 3) word puzzle, 4) coarse-grained POS tag, 5) fine-grained POS tag (Part-of-Speech), 6) disordered set of syntactical and / or morphological features separated by a vertical bar (|) or underscore if not present, 7) header of the current token (an integer indicating the head number where 0 indicates root mark), 8) dependency label, 9) projective header (underscore if not present) and 10) projective dependency labels (if not present)."}, {"heading": "2.2 Training and Model Selection", "text": "The jar file in the package can be used directly to form a model with the following command line (executed from the project root): \"java -jar jar / YaraParser.jar train -train-file [train-file] -dev [dev-file] -model [model-file] 1http: / / ilk.uvt.nl / conll / # dataformat-punc [punc-file] where [train-file] and [dev-file] -model [model-file] 1http: / / ilk.uvt.nl / conll / # dataformat-punc [punc-file] where [train-file] and [dev-file] are CoNLL-files for training and development data and [model-file] and [model-file-dester] is.\""}, {"heading": "2.2.1 Punctuation Files", "text": "Most punctuation symbols and their incoming slurs are ignored in most dependency assessments, and most parsers do so by using hard-coded rules for sentence attachments. Yara instead allows the user to specify which punctuation marks POS tags are important for his task by specifying a path for a sentence file ([Punc file]) with the option -punc (e.g. -punc punc _ files / wsj.puncs). If no file is provided, Yara uses WSJ punctuation marks. The sentence file contains a list of punctuation marks POS tags, one per line. The Yara Git repository provides sentence files for WSJ data and Google universal POS tags [Petrov et al., 2011]."}, {"heading": "2.2.2 Some Examples", "text": "Here we offer examples of training Yara with different settings. Essentially, we select these examples where we think would be useful in practice. Training with Brown Cluster This can be done using the -cluster option. \"java -jar jar / YaraParser.jar train -train-file [train-file] -dev [dev-file] -model [model-file] -punc [punc-file] -cluster [cluster-file] -model This can be done using the basic and beam: 1 options.\" java -jar jar / YaraParser.jar train train train-file -punc [train-file] -dev [train-file] -dev-file [dev-file] -model -dev. \"punc _ model\".punc _ file: 1 based on changing the number of iterations This can be done using the iter option."}, {"heading": "2.3 Test and Evaluation", "text": "The test file can be either a CoNLL file or a POS-tagged file. Output is done as a file in CoNLL format.Parsing a CoNLL file \"java -jar jar / YaraParser.jar parse _ conll -input [test-file] -out [output-file] -model [model-file] Parsing a tagged file The tagged file is a simple file in which words and tags are separated by a delimiter (default is underscore).The user can use the option -delim [delimiter] (e.g. -deloo /) to change the delimiter. Output is done in CoNLL format\" java -jar jar / YaraParser.jar parse _ tagged -input [output-file] -model-file # httrevaluation Both [gold-file] and [parsed-file] should be shown in CoNLL format \"Yevar-jar-jar-training.\""}, {"heading": "2.4 Parsing a Partial Tree", "text": "Yara can parse sub-trees in which some gold dependencies are provided, and is expected to return a dependency tree that matches the sub-dependencies. Unknown dependencies are represented as a header in CoNLL format with \"-1.\" Figure 1 shows an example of a sub-parse tree before and after restricted parsing. 2https: / / github.com / yahoo / YaraParser / tree / master / sample _ data \"java -jar YaraParser.jar parse _ partial -input [test-file] -out [output-file] -model [model-file]"}, {"heading": "2.5 Yara Pipeline", "text": "We also offer a simple pipeline for using Yara in real-world applications. The pipeline benefits from the OpenNLP3 tokenizer and sentence delimiter, as well as our own POS tagger4, so the user needs to download a specific sentence delimiter and word tokenizer model from the OpenNLP website depending on the target language. It is also possible to train a new sentence delimiter and word tokenizer model with OpenNLP5. The number of threads can be changed using the nt: [# nt] option (e.g. nt: 10), the pipeline can be downloaded from https: / / github.com / rasoolims / YaraPipeline. \"java -jar jar / YaraPipeline.jar -input [output file] -parse _ model [output file] -pos _ model [output file] -pos _ model [pos-model] -tokenizer _ model-set-model _"}, {"heading": "2.6 Pipeline API usage", "text": "It is possible to use the Yara API directly, but the pipeline provides an easier way to do this with different levels of information, allowing the user to specify the number of threads to parse: numberOfThreads."}, {"heading": "2.6.1 Importing libraries", "text": "The user should first import YaraPipeline.java libraries into the code as in Listing 1. Class YaraPipeline.java contains static methods for parsing a sentence, and ParseResult contains information about words, POS tags, dependency labels and heads, as well as normalized tagging scores and parsing scores. Info contains all information about parsing settings and models for the parser, POS tagger, tokenizer, and sentence boundary detector."}, {"heading": "2.6.2 Parsing Raw Text File", "text": "In this case, we need all models for parsing, tagging, tokenizing, and recognizing record boundaries. Listing 2 shows one such case where the parser parses the results in CoNLL format to the [output _ file].3http: / / opennlp.apache.org / index.html 4https: / / github.com / rasoolims / SemiSupervisedPosTagger 5For more information, refer to the OpenNLP manual at https: / opennlp.apache.org / documentation / 1.5.3 / manual / opennlp.html. 6https: / / github.com / yahoo / YaraParser / blob / master / src / YaraParser / API _ UsageExample.java1 / / should r e a l i l e-path in brackets (e."}, {"heading": "2.6.3 Parsing Raw Text", "text": "Similar to parsing a file, we can parse raw text. Listing 3.1 / / shows that r e a l f i l e path in parentheses s (e.g. [parse _ model]) 2 In f o i n f o 2 = new In fo (\"[parse _ model],\" \"[pos _ model],\" \"[tokenizer _ model],\" \"[satz _ model],\" nummerOfThreads); 3 St r ing someText = \"some text...\"; 4 St r ing conl lOutputText2 = YaraPipe l ine. parseText (someText, i n f o 1); Listing 3: Code for parsing raw text"}, {"heading": "2.6.4 Parsing a Sentence", "text": "In cases where the user uses his own sentence separator, it is possible to add sentences as shown in Listing 4.1 / / in parentheses s (e.g. [parse _ model]) 2 In f o i n f o 3 = new In fo (\"[parse _ model],\" \"[pos _ model],\" [tokenizer _ model], \"numberOfThreads) 2 In f o i n f o 3 =\" any sentence. \"; 4 ParseResult parseResu l t3 = YaraPipe l ine. parseSentence (any sentence, i n f o 1); 5 St r ing conl lOutputText3 = parseResu l t3. getConllOutput (); Listing 4: Code for parsing a sentence"}, {"heading": "2.6.5 Parsing a Tokenized Sentence", "text": "Listing 5 shows an example of cases where the user only wants to use the parser and POS tagger to analyze a prefabricated sentence. 1 / / r e a l f i l e path in brackets s (e. g. [parse _ model]) 2 In f o i n f o 4 = new In fo (\"[parse _ model],\" \"[pos _ model],\" nummerOfThreads); 3 St r ing [] someWords4 = {\"some,\" words, \".,\".}; 4 ParseResult parseResu l t4 = YaraPipe l ine. parseTokenizedSentence (someWords4, i n f o 1); 5 St r ing conl lOutputText4 = parseResu l t4. getConllOutput (); Listing 5: Code for parsing a linked sentence"}, {"heading": "2.6.6 Parsing a Tagged Sentence", "text": "List 6 shows an example of cases where the user only wants to use Yara to parse pre-selected records (e.g. [parse _ model]) 2 In f o i n f o 5 = new In fo (\"[parse _ model],\" numberOfThreads); 3 St r ing [] someWords5 = {\"some,\" \"words,\"..}; 4 St r ing [] someTags5 = {\"tag1,\" tag2, \"\" tag3 \"}; 5 ParseResult parseResu l t5 = YaraPipe l ine. parseTaggedSentence (someWords5, someTags5, i n f o 1); 6 St r ing conl lOutputText5 = parseResu l t5. getConllOutput (); Listing 6: Code for parsing tagged records"}, {"heading": "3 Yara Technical Details", "text": "Yara is a transition-based dependency parser based on the arc-eager algorithm [Nivre, 2004], which uses beam detection training and decoding [Zhang and Clark, 2008] to avoid local errors in parser decisions, and the properties of the parser are roughly the same as [Zhang and Nivre, 2011] with additional Brown clusters [Brown et al., 1992] features. 7 Yara also includes several flexible parameters and options that allow users to easily adjust it depending on language and task. Generally, there are 128 possible combinations of settings in addition to tuning the number of iterations, Brown cluster functions and beam width. 8"}, {"heading": "3.1 Arc-Eager Algorithm", "text": "As in the arc-zealous algorithm, Yara has the following actions: \u2022 Left-arc (LA): The first word in the buffer becomes the head of the top word in the stack. \u2022 Right-arc (RA): The top word in the stack becomes the head of the first word in the buffer. \u2022 Reduce (R): The top word in the stack is popped. \u2022 Shift (SH): The first word in the buffer is pressed onto the stack. Depending on the position of the root, the constraints on initialization and actions vary. Figure 2 shows the transitions used to parse the sentence \"I want to parse a sentence.\" Unshift Action The original algorithm does not guarantee that a tree will be printed and therefore, in some cases, when the root is positioned at the beginning of the sentence, the parser decides to link all remaining words in the stack to the root."}, {"heading": "3.2 Online Learning", "text": "Most currently monitored parsers use online learning algorithms. Online learners are fast, efficient and very accurate. We use average structured Perceptron [Collins, 2002], which is also used in previous similar parsers [Zhang and Clark, 2008, Zhang and Nivre, 2011, Choi and Palmer, 2011]. We use different [Koo et al., 2008, Honnibal and Johnson, 2014]. 8We use the best performance setting as the default setting for Yara. 9This problem occurs less in beam search and is more common in greedy parsing. Technical methods to speed up the parser, such as the mean trick introduced by [thumb III, 2006, Figure 2.3]. In addition, all features except the properties of a lexical pair are converted into long-term integer values to avoid frequent hash collisions and reduce memory consumption."}, {"heading": "3.3 Beam Search and Update Methods", "text": "Early transition-based parsers such as the malt parser [Nivre et al., 2006] were greedy and were trained in batch mode, doing this by converting each tree into a series of independent actions. This has proven less effective than a global search. Given our feature setting, it is impossible to use dynamic programming to get the exact result. Instead, we use beam search as an approximate value. 10 Therefore, unlike batch learning, the same procedure is used for training and decrypting the parser. Yara supports beam search and its default beam size is 64. There are several ways to update the classification weights with beam learning. A very trivial way is to get the best scoring result from the beam search, as predicting and updating the weights compared to gold. This is known as a \"late update,\" but it does not result in good performance [Huang et al., 2012]. A more attractive beam search method is achieved until the prediction of the beam state is reached."}, {"heading": "3.4 Dynamic and Static Oracles", "text": "In other words, different search paths can lead to the same parse tree. Most standard parsers such as Zpar [Zhang and Nivre, 2011] define some manual rules for restoring a gold oracle in order to give it to the learner. This is known as static oracle. The other way is to let the oracle be dynamic and let the learner choose between the oracles [Goldberg and Nivre, 2013]. Yara supports both static and dynamic oracles. In the case of dynamic oracles, only zero-cost explorations are allowed. In [Goldberg and Nivre, 2013] the gold oracle can be randomly selected, but we have also provided another option for selecting the best-rated oracle as a selected oracle. The latter way is known as latent structured perception."}, {"heading": "3.5 Other Properties", "text": "In fact, we will be able to put ourselves at the forefront in the way we have done in the past: in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it. \""}, {"heading": "4 Experiments", "text": "In this section we show how Yara performs with two different datasets and compare its performance with other leading parsers. We also graphically show the trade-off between beam width and accuracy, as well as the number of iterations. For all experiments we use version 0.2 of Yara."}, {"heading": "4.1 Parsing WSJ Data", "text": "As in [Zhang and Nivre, 2011], we first converted the WSJ data [Marcus et al., 1993] with Penn2Malt11. Next, automatic POS tags are generated for the entire dataset with version 0.2 of our POS tagger12, by performing 10-way jack knifing on the training data. The tagger is a third-order 20-bar tagger trained with the maximum injury strategy with the same settings as in [Collins, 2002], along with additional Brown clustering functionality [Liang, 2005].13 It achieved POS tagging accuracy of 97.14, 97.18 and 97.37 on the move, development and test files accordingly. Table 1 shows the results on WSJ data by varying the beam size and using Brown clusters in certain size ranges."}, {"heading": "4.2 Parsing Non-Projective Languages: Persian", "text": "We use version 1.1 of the Persian Dependency Treebank (PerDT) [Rasooli et al., 2013] 14 and mark it with the same setting as the WSJ data. We have symbolized Mizan corpus15 and added it to our training data to create 1000 Brown clusters.16 The training data contains 22% non-projective trees. We use Mate parser (v3.6.1) [Bohnet, 2010] as a high-precision, non-projective parsing tool to compare with Yara. Table 4 shows the performance of the two parsers. There is a 1.35% gap in14http: / / www.dadegan.ir / catalog / perdt 15http: / / www.dadegan.ir / catalog / mizan 16The definition of the Brown cluster in this data is loose because there are multi-word gaps in the tree population."}, {"heading": "5 Conclusion and Future Work", "text": "We presented an introduction to our open source dependency parser. We showed that the parser is very fast and accurate, and can also be used for non-projective languages with a very low performance loss. We believe that, given its performance and flexible license, our parser can be useful for various downstream tasks. One of our future plans is to expand this parser to include non-projection and to use continuous value display functions such as word embedding to improve the accuracy of the parser."}, {"heading": "Acknowledgements", "text": "We would like to thank the open source team at Yahoo Labs for allowing us to release the parser with a very flexible license, especially Dev Glass for creating the first version of the code. We would like to thank Amanda Stent, Kapil Thadani, Idan Szpektor and Yuval Pinter and other colleagues at Yahoo Labs for their support and fruitful ideas. Finally, we would like to thank Michael Collins and Matthew Honnibal for their feedback."}], "references": [{"title": "Going to the roots of dependency parsing", "author": ["Ballesteros", "Nivre", "M. 2013] Ballesteros", "J. Nivre"], "venue": "Computational Linguistics,", "citeRegEx": "Ballesteros et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2013}, {"title": "A transition-based system for joint partof-speech tagging and labeled non-projective dependency parsing", "author": ["Bohnet", "Nivre", "B. 2012] Bohnet", "J. Nivre"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Bohnet et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bohnet et al\\.", "year": 2012}, {"title": "Class-based n-gram models of natural language", "author": ["Brown et al", "P.F. 1992] Brown", "P.V. Desouza", "R.L. Mercer", "V.J.D. Pietra", "J.C. Lai"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1992\\E", "shortCiteRegEx": "al. et al\\.", "year": 1992}, {"title": "Transition-based dependency parsing with selectional branching", "author": ["Choi", "McCallum", "J.D. 2013] Choi", "A. McCallum"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),", "citeRegEx": "Choi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2013}, {"title": "Getting the most out of transition-based dependency parsing", "author": ["Choi", "Palmer", "J.D. 2011] Choi", "M. Palmer"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Choi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2011}, {"title": "Incremental parsing with the perceptron algorithm. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL\u201904)", "author": ["Collins", "Roark", "M. 2004] Collins", "B. Roark"], "venue": "Main Volume,", "citeRegEx": "Collins et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2004}, {"title": "Practical Structured Learning Techniques for Natural Language Processing", "author": ["III Daum\u00e9", "III H. 2006] Daum\u00e9"], "venue": "PhD thesis,", "citeRegEx": "Daum\u00e9 and Daum\u00e9,? \\Q2006\\E", "shortCiteRegEx": "Daum\u00e9 and Daum\u00e9", "year": 2006}, {"title": "Unsupervised search-based structured prediction", "author": ["III Daum\u00e9", "III H. 2009] Daum\u00e9"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Daum\u00e9 and Daum\u00e9,? \\Q2009\\E", "shortCiteRegEx": "Daum\u00e9 and Daum\u00e9", "year": 2009}, {"title": "Training deterministic parsers with nondeterministic oracles", "author": ["Goldberg", "Nivre", "Y. 2013] Goldberg", "J. Nivre"], "venue": null, "citeRegEx": "Goldberg et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2013}, {"title": "Joint incremental disfluency detection and dependency parsing", "author": ["Honnibal", "Johnson", "M. 2014] Honnibal", "M. Johnson"], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "Honnibal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Honnibal et al\\.", "year": 2014}, {"title": "Structured perceptron with inexact search", "author": ["Huang et al", "L. 2012] Huang", "S. Fayong", "Y. Guo"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Dynamic programming for linear-time incremental parsing", "author": ["Huang", "Sagae", "L. 2010] Huang", "K. Sagae"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Huang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2010}, {"title": "Simple semi-supervised dependency parsing", "author": ["Koo et al", "T. 2008] Koo", "X. Carreras", "M. Collins"], "venue": "In Proceedings of ACL-08: HLT,", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Efficient third-order dependency parsers", "author": ["Koo", "Collins", "T. 2010] Koo", "M. Collins"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Koo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2010}, {"title": "Fourth-order dependency parsing", "author": ["Ma", "Zhao", "X. 2012] Ma", "H. Zhao"], "venue": "In Proceedings of COLING 2012: Posters,", "citeRegEx": "Ma et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2012}, {"title": "Building a large annotated corpus of English: The Penn treebank", "author": ["Marcus et al", "M.P. 1993] Marcus", "M.A. Marcinkiewicz", "B. Santorini"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1993\\E", "shortCiteRegEx": "al. et al\\.", "year": 1993}, {"title": "Turning on the turbo: Fast third-order non-projective turbo parsers", "author": ["Martins et al", "A. 2013] Martins", "M. Almeida", "N.A. Smith"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Non-projective dependency parsing using spanning tree algorithms", "author": ["McDonald et al", "R. 2005] McDonald", "F. Pereira", "K. Ribarov", "J. Haji\u010d"], "venue": "In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "Online learning of approximate dependency parsing algorithms", "author": ["McDonald", "Pereira", "R.T. 2006] McDonald", "F.C. Pereira"], "venue": "In Proceedings of the 11th Conference of the European Chapter of the Association", "citeRegEx": "McDonald et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2006}, {"title": "Arc-eager parsing with the tree constraint", "author": ["Nivre", "Fern\u00e1ndez-Gonz\u00e1lez", "J. 2014] Nivre", "D. Fern\u00e1ndez-Gonz\u00e1lez"], "venue": "Computational linguistics,", "citeRegEx": "Nivre et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2014}, {"title": "Maltparser: A data-driven parser-generator for dependency parsing", "author": ["Nivre et al", "J. 2006] Nivre", "J. Hall", "J. Nilsson"], "venue": "In Proceedings of LREC,", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "A universal part-of-speech tagset", "author": ["Petrov et al", "S. 2011] Petrov", "D. Das", "R. McDonald"], "venue": "arXiv preprint arXiv:1104.2086", "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Branch and bound algorithm for dependency parsing with non-local features. Transactions of the Association for Computational Linguistics, 1:37\u201348", "author": ["Qian", "Liu", "X. 2013] Qian", "Y. Liu"], "venue": null, "citeRegEx": "Qian et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Qian et al\\.", "year": 2013}, {"title": "Fast unsupervised dependency parsing with arc-standard transitions", "author": ["Rasooli", "Faili", "M.S. 2012] Rasooli", "H. Faili"], "venue": "In Proceedings of the Joint Workshop on Unsupervised and Semi-Supervised Learning in NLP,", "citeRegEx": "Rasooli et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2012}, {"title": "Development of a Persian syntactic dependency treebank", "author": ["Rasooli et al", "M.S. 2013] Rasooli", "M. Kouhestani", "A. Moloodi"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Joint parsing and disfluency detection in linear time", "author": ["Rasooli", "Tetreault", "M.S. 2013] Rasooli", "J. Tetreault"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Rasooli et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2013}, {"title": "Non-monotonic parsing of fluent umm I mean disfluent sentences", "author": ["Rasooli", "Tetreault", "M.S. 2014] Rasooli", "J. Tetreault"], "venue": "In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Rasooli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2014}, {"title": "Parser combination by reparsing", "author": ["Sagae", "Lavie", "K. 2006] Sagae", "A. Lavie"], "venue": "In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,", "citeRegEx": "Sagae et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Sagae et al\\.", "year": 2006}, {"title": "Latent structured perceptrons for largescale learning with hidden information", "author": ["Sun et al", "X. 2013] Sun", "T. Matsuzaki", "W. Li"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Punctuation prediction with transition-based parsing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "author": ["Zhang et al", "D. 2013a] Zhang", "S. Wu", "N. Yang", "M. Li"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Online learning for inexact hypergraph search", "author": ["Zhang et al", "H. 2013b] Zhang", "L. Huang", "K. Zhao", "R. McDonald"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Generalized higher-order dependency parsing with cube pruning", "author": ["Zhang", "McDonald", "H. 2012] Zhang", "R. McDonald"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "Enforcing structural diversity in cube-pruned dependency parsing", "author": ["Zhang", "McDonald", "H. 2014] Zhang", "R. McDonald"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing", "author": ["Zhang", "Clark", "Y. 2008] Zhang", "S. Clark"], "venue": "In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Zhang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2008}, {"title": "Transition-based dependency parsing with rich non-local features", "author": ["Zhang", "Nivre", "Y. 2011] Zhang", "J. Nivre"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Zhang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 25, "context": "1 of the Persian dependency treebank (PerDT) [Rasooli et al., 2013]14 and tagged it with the same setting as WSJ data.", "startOffset": 45, "endOffset": 67}], "year": 2017, "abstractText": "Dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition. We introduce the Yara Parser, a fast and accurate open-source dependency parser based on the arc-eager algorithm and beam search. It achieves an unlabeled accuracy of 93.32 on the standard WSJ test set which ranks it among the top dependency parsers. At its fastest, Yara can parse about 4000 sentences per second when in greedy mode (1 beam). When optimizing for accuracy (using 64 beams and Brown cluster features), Yara can parse 45 sentences per second. The parser can be trained on any syntactic dependency treebank and different options are provided in order to make it more flexible and tunable for specific tasks. It is released with the Apache version 2.0 license and can be used for both commercial and academic purposes. The parser can be found at https: //github.com/yahoo/YaraParser.", "creator": "LaTeX with hyperref package"}}}