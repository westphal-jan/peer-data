{"id": "1503.06962", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2015", "title": "Probabilistic Binary-Mask Cocktail-Party Source Separation in a Convolutional Deep Neural Network", "abstract": "Separation of competing speech is a key challenge in signal processing and a feat routinely performed by the human auditory brain. A long standing benchmark of the spectrogram approach to source separation is known as the ideal binary mask. Here, we train a convolutional deep neural network, on a two-speaker cocktail party problem, to make probabilistic predictions about binary masks. Our results approach ideal binary mask performance, illustrating that relatively simple deep neural networks are capable of robust binary mask prediction. We also illustrate the trade-off between prediction statistics and separation quality.", "histories": [["v1", "Tue, 24 Mar 2015 09:34:51 GMT  (3354kb)", "http://arxiv.org/abs/1503.06962v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG cs.NE", "authors": ["andrew j r simpson"], "accepted": false, "id": "1503.06962"}, "pdf": {"name": "1503.06962.pdf", "metadata": {"source": "META", "title": "Probabilistic Binary-Mask Cocktail-Party Source Separation in a Convolutional Deep Neural Network_arxiv", "authors": ["Andrew J.R. Simpson"], "emails": ["Andrew.Simpson@Surrey.ac.uk"], "sections": [{"heading": null, "text": "In fact, we are building a revolutionary, deep neural network that is capable of making a robust prediction. We are also illustrating the trade between the prediction statistics and the delimitation of the quality of the product. - Deep learning, convolution, source separation. - The work in source separation has focused on the so-called cocktail problem."}, {"heading": "II. METHOD", "text": "We look at a typical cocktail party listening scenario with a male and a female voice speaking the mask at the same time. Speakers were recorded separately (in mono), each reading from different stories. The two speech signals were adjusted to be of the same average intensity. To produce a mixture representative of a monaural cocktail party listening scenario, the monaural speech from each speaker was combined linearly to produce a monaural mixing signal (see Fig. 1).The mix and the original speech signals were decimated to a sample rate of 4 kHz. The original speech signals and mixes were converted into spectrograms that used the Shorttime Fourier Transform (STFT) with a window size of 128 samples, overlap intervals of 1 sample and a Hanning window. These provided spectrograms with 65 frequency bins which were retained for each phase component of the mask and were later removed."}, {"heading": "III. RESULTS", "text": "Fig. 1 shows spectrograms that illustrate the stages of mixing and separation for a brief excerpt (~ 3 seconds) of the test data; the spectrograms for the source's voice signals are shown above; the middle panel shows the mixed spectrogram and shows the overlap of the two competing voice signals in the time-frequency space; at the bottom of Fig. 1, the separate and newly synthesized audio signals for the male and female voice are shown (\u03b1 = 0.99); the separate spectrograms are relatively faithful to the original sources but show some points where there is discontinuity in the scores, some missing energy and other small distortions; Fig. 2 shows the various objective quality metrics of source separation (SDR / SIR / SAR) calculated over the entire 10-second test data as a function of the confidence level SAR (\u03b1) between 0.001 and 0.99."}, {"heading": "IV. DISCUSSION AND CONCLUSION", "text": "In this context, it should be noted that the case concerns a case where the cause of the origin of the disease lies in nature, the cause of the origin of the disease must be sought in nature."}, {"heading": "ACKNOWLEDGMENT", "text": "The AJRS was supported by funding EP / L027119 / 1 from the UK Engineering and Physical Sciences Research Council (EPSRC)."}], "references": [{"title": "The cocktail party problem", "author": ["JH McDermott"], "venue": "Curr. Biol", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Perceptual Organization of Sound Begins in the Auditory Periphery", "author": ["D Pressnitzer", "M Sayles", "C Micheyl", "IM Winter"], "venue": "Curr. Biol", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Emergence of neural encoding of auditory objects while listening to competing speakers", "author": ["N Ding", "JZ Simon"], "venue": "Proc. Natl. Acad. Sci. USA", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Deep neural networks for single channel source separation", "author": ["E Grais", "M Sen", "H Erdogan"], "venue": "in Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Deep learning for monaural speech separation", "author": ["PS Huang", "M Kim", "M Hasegawa-Johnson", "P Smaragdis"], "venue": "in Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Abstract Learning via Demodulation in a Deep Neural Network\u201d, arxiv.org", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Performance measurement in blind audio source separation", "author": ["E Vincent", "R Gribonval", "C F\u00e9votte"], "venue": "IEEE Trans. on Audio, Speech and Language Processing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Deep Transform: Time-Domain Cocktail Party Source Separation via Probabilistic Re-Synthesis\u201d, arxiv.org abs/1502.06046", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Deep Transform: Error Correction via Probabilistic Re-Synthesis\u201d, arxiv.org abs/1502.04617", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Over-Sampling in a Deep Neural Network\u201d, arxiv.org", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Selective Adaptation to \u201cOddball\u201d Sounds by the Human Auditory System", "author": ["AJR Simpson", "NS Harper", "JD Reiss", "D McAlpine"], "venue": "J Neurosci", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Much work in source separation has focused on the socalled cocktail party problem [1], where a listener must selectively attend to speech within a background of competing speech noise.", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "spectro-temporal representations for concurrent streams of speech [2], [3].", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "spectro-temporal representations for concurrent streams of speech [2], [3].", "startOffset": 71, "endOffset": 74}, {"referenceID": 3, "context": "to assign each time-frequency element (of the mixture spectrogram) to a particular source [4], [5].", "startOffset": 90, "endOffset": 93}, {"referenceID": 4, "context": "to assign each time-frequency element (of the mixture spectrogram) to a particular source [4], [5].", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "The ideal binary mask relies on the fact that concurrent speech features relatively little overlap in time-frequency space and serves as common benchmark in spectrogram-based source separation [4], [5].", "startOffset": 193, "endOffset": 196}, {"referenceID": 4, "context": "The ideal binary mask relies on the fact that concurrent speech features relatively little overlap in time-frequency space and serves as common benchmark in spectrogram-based source separation [4], [5].", "startOffset": 198, "endOffset": 201}, {"referenceID": 5, "context": "employed the biased-sigmoid activation function [6] throughout with zero bias for the output layer.", "startOffset": 48, "endOffset": 51}, {"referenceID": 6, "context": "Separation quality (for the test data) was measured using the BSS-EVAL toolbox [7] and is quantified in terms of signal-to-distortion ratio (SDR), signalto-artefact ratio (SAR) and signal-to-interference ratio (SIR).", "startOffset": 79, "endOffset": 82}, {"referenceID": 6, "context": "Mean signal-todistortion ratio (SDR, red), signal-to-interference (SIR, green), signal-to-artefact ration (SAR, blue), computed from the 10-second test audio using the BSS-EVAL toolkit [7].", "startOffset": 185, "endOffset": 188}, {"referenceID": 7, "context": "reported for the same test audio using a time-domain convolutional deep transform (CDT) with probabilistic resynthesis approach [8].", "startOffset": 128, "endOffset": 131}, {"referenceID": 7, "context": "Essentially, the STFT we employ constitutes a layer of abstraction featuring both a filter and a demodulation stage [8], [9], and the inverse", "startOffset": 116, "endOffset": 119}, {"referenceID": 8, "context": "Essentially, the STFT we employ constitutes a layer of abstraction featuring both a filter and a demodulation stage [8], [9], and the inverse", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "In addition, this model is more constrained, hence is easier to train than the respective autoencoder [8] and, we note in passing, that (unlike the autoencoder based approach reported previously) the present model showed no sign of bias towards either the male or female voice.", "startOffset": 102, "endOffset": 105}, {"referenceID": 3, "context": "The performance reported here also appears superior to previous methods based on non-negative matrix factorization (NMF) which incorporated deep neural networks as part of the NMF pipeline [4], [5].", "startOffset": 189, "endOffset": 192}, {"referenceID": 4, "context": "The performance reported here also appears superior to previous methods based on non-negative matrix factorization (NMF) which incorporated deep neural networks as part of the NMF pipeline [4], [5].", "startOffset": 194, "endOffset": 197}, {"referenceID": 3, "context": "combination of 1) a relatively large scale network (larger than those reported in [4], [5]) and 2) the probabilistic convolution featured here.", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "combination of 1) a relatively large scale network (larger than those reported in [4], [5]) and 2) the probabilistic convolution featured here.", "startOffset": 87, "endOffset": 90}, {"referenceID": 9, "context": "It may also be the case that this relation of scale to sampling rate accounts for some performance gains in terms of mitigated aliasing [10].", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "(adaptation) rate demonstrated in the human auditory perceptual system [11].", "startOffset": 71, "endOffset": 75}], "year": 2015, "abstractText": "Separation of competing speech is a key challenge in signal processing and a feat routinely performed by the human auditory brain. A long standing benchmark of the spectrogram approach to source separation is known as the ideal binary mask. Here, we train a convolutional deep neural network, on a twospeaker cocktail party problem, to make probabilistic predictions about binary masks. Our results approach ideal binary mask performance, illustrating that relatively simple deep neural networks are capable of robust binary mask prediction. We also illustrate the trade-off between prediction statistics and separation quality.", "creator": "PDFCreator Version 1.7.1"}}}