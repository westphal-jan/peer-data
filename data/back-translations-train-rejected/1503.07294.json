{"id": "1503.07294", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2015", "title": "Using Latent Semantic Analysis to Identify Quality in Use (QU) Indicators from User Reviews", "abstract": "The paper describes a novel approach to categorize users' reviews according to the three Quality in Use (QU) indicators defined in ISO: effectiveness, efficiency and freedom from risk. With the tremendous amount of reviews published each day, there is a need to automatically summarize user reviews to inform us if any of the software able to meet requirement of a company according to the quality requirements. We implemented the method of Latent Semantic Analysis (LSA) and its subspace to predict QU indicators. We build a reduced dimensionality universal semantic space from Information System journals and Amazon reviews. Next, we projected set of indicators' measurement scales into the universal semantic space and represent them as subspace. In the subspace, we can map similar measurement scales to the unseen reviews and predict the QU indicators. Our preliminary study able to obtain the average of F-measure, 0.3627.", "histories": [["v1", "Wed, 25 Mar 2015 06:42:05 GMT  (363kb)", "http://arxiv.org/abs/1503.07294v1", "4 Figures in The International Conference on Artificial Intelligence and Pattern Recognition (AIPR2014),2014"]], "COMMENTS": "4 Figures in The International Conference on Artificial Intelligence and Pattern Recognition (AIPR2014),2014", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR", "authors": ["wendy tan wei syn", "bong chih how", "issa atoum"], "accepted": false, "id": "1503.07294"}, "pdf": {"name": "1503.07294.pdf", "metadata": {"source": "CRF", "title": "Using Latent Semantic Analysis to Identify Quality in Use (QU) Indicators from User Reviews", "authors": ["Wendy Tan", "Wei Syn", "Bong Chih How", "Issa Atoum"], "emails": ["@inproceedings{article2014,", "wendytws@siswa.unimas.my,", "chbong@fit.unimas.my,", "Issa.Atoum@gmail.com"], "sections": [{"heading": null, "text": "The article describes a novel approach to categorizing user ratings based on the three quality indicators defined in the ISO: effectiveness, efficiency, and risk-free. Given the enormous number of ratings published each day, there is a need to automatically aggregate user ratings to inform us whether any of the software is capable of meeting a company's quality requirements. We implemented the method of Latent Semantic Analysis (LSA) and its sub-space to predict QU indicators. We create a reduced universal semantic space in the form of information system journals and Amazon ratings. Next, we projected a set of measurement scales of indicators into universal semantic space and present them as subspace. In subspace, we can assign similar measurement scales to invisible ratings and predict QU indicators."}, {"heading": "1 INTRODUCTION", "text": "Due to advances in Internet technology, they write reviews on online sites such as Amazon and CNet after they have used certain products and services, making the Internet a medium for communicating with other people of similar interest. Ratings have a huge impact on the business and social spheres. For businesses, a company is one that can know how end-users perceive their products from a social perspective: ratings can actually influence other people's decisions and opinions about certain products. The International Standard Organization's (ISO) Quality in Use (QU) model is the validated measurement method for measuring the quality of software or products related to the outcome after the user has interacted with the products [2]. Indicators of the QU model are effectiveness, efficiency and freedom from risk, satisfaction and context coverage [2]."}, {"heading": "2 PROBLEMS", "text": "Most textmining methods in user ratings are based on features that determine polarity (positive, neutral, or negative); there is more information that can emerge from the ratings, such as the QU indicators that determine whether ICT products can contribute to an organization's goals; and human interpretation of ratings can lead to bias and confusion, as each of us has its own interpretations, so the interpretation of ratings will eventually depend subjectively on the individual context; so we want to find an approach to recognizing QU indicators from ratings without introducing bias."}, {"heading": "3 RESEARCH GOAL", "text": "This study is intended to propose an approach to the recognition of the three QU indicators expressed by users in assessments: effectiveness, efficiency and risk-free of products. These are the characteristics of the international standard for measuring product quality."}, {"heading": "4 BACKGROUND", "text": "Personal satisfaction, business success and human security depend on high-quality software and systems [2]. It is important that product quality characteristics can be measured on the basis of validated measurement methods derived from ISO / IEC 9126: 1991. This international standard defines a QU model that consists of five characteristics that relate to \"the result of interaction when using a product in an articular application context.\" [2] The QU model is a model that \"represents the degree to which a product or system can be used by certain users to meet their needs in order to achieve certain objectives.\" [2] Examples of the objectives are effectiveness, efficiency, risk-free and satisfaction. In order to make it short, in this study we focus on three characteristics: effectiveness, efficiency and risk-free as QU indicators. The definitions for the three selected QU indicators are confirmed by the ISO measurement indicators in accordance with project ISO 1.2411 [1-2]."}, {"heading": "5 OUR METHOD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Latent Semantic Analysis Universal Space and Subspace", "text": "In fact, most of us are able to set out in search of new paths to follow."}, {"heading": "6 DATA", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Paragraph and Amazon Reviews to Build Universal Space", "text": "To create a universal semantic space, we used 95084 Amazon reviews for the \"software\" category from Jure Leskovec's SNAP project [3]. We also used paragraphs from journals manually extracted from Larsen's Human Behavior Project [4]. (5.6) (5.4) (5.3) (5.5)"}, {"heading": "6.2 Measurement Scales from Human Behavior Project", "text": "To reinforce the context of the three indicators of QU: effectiveness, efficiency and risk-free, we carefully select a set of closely related behavioral variables of the Human Behavior Project based on the key words of the indicators (effectiveness, efficiency, risk (similar to risk-free)).The following table shows the total number of measurement scales for each category."}, {"heading": "6.3 Annotated Reviews", "text": "In this study, we used a collection of annotated review sets from 1947 from the works of Atoum and Bong [1]. To our knowledge, there are no data sets for software quality, so a gold standard is required. The gold standard is a set of software review sets that are crawled off the web and classified by the annotators, which (at the end of the annotation process) have the topic of sentence quality in use, sentence polarity and the indication of keywords on the topic. First, a series of reviews from software websites Amazon.com and CNet.com. These reviews are filtered. Then, the top 10% reviews from each review category are selected. Next, the reviews are broken down into sentences. Finally, the sets of annotators for marking and annotation.Before we conduct the experiments, we label each of the measured and annotated reviews with the three risk indicators: QU Efficiency, QU Efficiency."}, {"heading": "7 EXPERIMENTS", "text": "In this section, we explain the steps of predicting QU indicators based on ratings. First, we build a universal semantic space with different data sets: i) paragraphs from the Information System Journal, ii) ratings, and iii) combination of (i) and (ii) above. We want to investigate how different universal semantic space can affect overall performance. Second, we have created a subspace for each built universal semantic space by projecting measurement scales and testing evaluations based on common term weights scaled and truncated in universal semantic space. By using this subspace, we can find similar measurement scales based on cosmic similarity between the vectors presented in subspace. We filter the returned results and get the predicted indicators of the final review. We repeat each step for each review and report on precision."}, {"heading": "8 EVALUATION", "text": "In order to obtain the predicted QU indicators, we obtain the six most similar measurement scales for each assessment set. Based on our study, this is the best optimal number to achieve the best accuracy. Next, we go through several filter steps based on the results we have received to determine the best QU indicators for verification. Overall views of the filter steps are illustrated by the following pseudo-code: From the returned list of measurement scales, sorted by their similarity value, we must check the deviation of the similarity value between them. If the deviation exceeds 0.2, we opt for the QU indicators with the highest similarity value. If the deviation is less than 0.2, we deduce the most similar QU indicators by deriving the majority vote count of the indicators from our result. If there is a similar number of majority votes received, we consider the QU indicators received to be the highest similarity with the QU indicators."}, {"heading": "9 RESULTS AND DISCUSSION", "text": "The following figure shows that the F measure in predicting the three indicators using three sub-spaces composed of different corpus, as explained in Section 6.Figure 2, shows that the overall best performance is the use of the journal paragraphs (Experiment 1). The overall average of the F measurement is 0.3627. Although the combination of both paragraphs and Amazon slightly increases the accuracy of effectiveness, the accuracy of the other two indicators has decreased due to the presence of noise when both resources are combined. However, the following example illustrates correctly predicted sentences that agreed with experts. We can see above that the items and ratings do not have many overlapping words, but they can be recognized as similar. This shows that our methods are able to find similar documents in word usage. However, there are several cases where our approach has not been able to detect the correct indicators. Careful analysis in Table 6 shows that two sentences necessarily have a similar meaning due to different category and do not have a similar interpretation."}, {"heading": "10 FUTURE WORKS", "text": "Although our study is encouraging at this point, the following future work is planned: 1. we intend to obtain more measuring elements to be projected into the semantic space in order to better capture the QU characteristics in reviews. So far, some reviews could not be identified due to the lack of measuring elements.2. another approach to improving performance is to improve semantic space by training with more vocabulary. Based on the results, rich semantic space can contribute to improving overall performance. 3. we would need to pre-edit the reviews in detail before analyzing them by the LSA, as the noise in the reviews could affect performance.4. In semantic space, words with higher frequency will dominate the overall retrieval process. Log entropy works better than TFIDF, but it still cannot solve the main problem if the words are given incorrect priority."}, {"heading": "11 RELATED WORKS", "text": "Atoum and Bong proposed a framework for recognizing QU from reviews, using the latent dirichlet allocation method to generate multiple keywords; they also used semi-supervised learning to calculate the polarity of sentences [1]. Wang et al. Works related to opinion-forming, currently most methods are based on traits. Their proposed feature-based vector model includes traits as well as the reviewer's opinion on the traits; they also take into account the relationship between words and punctuation. [7] In terms of locating related documents or classifying documents, some of the known methods are kNN classification, naive bayes, vector spatial model, neural networks, etc."}, {"heading": "12 CONCLUSION", "text": "Finally, we proposed an approach to identifying quality characteristics from assessments using latent semantic analysis (LSA). We adapted a number of measurement elements from the Human Behavior Project to determine whether assessments correspond to QU characteristics. We proposed the method of universal semantic space and subspace. We enriched the universal semantic space with assessments and QU indicators to map the context of our measurement scales and build a subspace to map similar assessments and measurement scales based on their semantic meaning. The reported results showed that QU indicators can be predicted in assessments with an average F-measure of 0.3627. Several constraints made this work even where there are different interpretations between our measurement scales and commented assessments, ambiguous usage."}, {"heading": "13. ACKNOWLEDGEMENT", "text": "We would like to thank the Universiti Malaysia Sarawak and MOHE, who financed this project through the ERGS / ICT07 (01) / 1018 / 2013 (15) scholarship. We would also like to express our sincere gratitude to Kai Larsen, Director of the Human Behavior Project at the University of Colorado Boulder, for enabling us to use the behavioral variables in the study."}], "references": [{"title": "A Framework to Predict Software \u201cQuality in Use\u201d from Software Reviews", "author": ["I. Atoum", "Bong", "C. H", "January"], "venue": "In Proceedings of the First International Conference on Advanced Data and Information Engineering", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Hidden factors and hidden topics: understanding rating dimensions with review text", "author": ["J. McAuley", "J. Leskovec"], "venue": "RecSys", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Inter-Nomological Network. Retrieved from http://inn.colorado.edu", "author": ["Larsen", "Kai R"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Mathematical foundations behind latent semantic analysis", "author": ["D.I. Martin", "M.W. Berry"], "venue": "Handbook of latent semantic analysis,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Introduction to information retrieval", "author": ["C.D. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": "(Vol. 1,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Feature-based Sentiment Analysis Approach for Product Reviews", "author": ["H. Wang", "L. Liu", "W. Song", "J. Lu"], "venue": "Journal of Software,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "According to Atoum and Bong, the reason that drives users to use a product is if the product is perceived able to achieve particular goals such as effectiveness and efficiency [1].", "startOffset": 176, "endOffset": 179}, {"referenceID": 2, "context": "As the formal definition of the three QU indicators from ISO document is rather brief, we reinforced the indicators with expert validated measurement scales from Human Behavioral Project [4].", "startOffset": 187, "endOffset": 190}, {"referenceID": 3, "context": "As explained by Martin and Berry [5], to create the vector space model, we form typeby-document matrix A from the documents.", "startOffset": 33, "endOffset": 36}, {"referenceID": 3, "context": "Orthogonal matrix contain [5]:", "startOffset": 26, "endOffset": 29}, {"referenceID": 3, "context": "SVD can represent types and documents simultaneously that able to capture the underlying semantic meaning by manipulating the number of dimensions [5].", "startOffset": 147, "endOffset": 150}, {"referenceID": 3, "context": "which reduce the dimension from r to k [5].", "startOffset": 39, "endOffset": 42}, {"referenceID": 3, "context": "In this way, noises are removed and it captures the important semantic structure of types of documents [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "We treat query as document to be projected in the space which also known as \u201cpseudodocument\u201d [5], hereby it can be represented by,", "startOffset": 93, "endOffset": 96}, {"referenceID": 3, "context": "According to the findings presented by Martin and Berry [5], the best optimal choice for number of dimension, K is between 100 and 300.", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "In order to build a universal semantic space, we adopted 95084 Amazon reviews for category \u201csoftware\u201d from SNAP project by Jure Leskovec [3].", "startOffset": 137, "endOffset": 140}, {"referenceID": 2, "context": "Besides that, we also used collection of paragraphs from journals that manually extracted under Human Behavior Project by Larsen [4].", "startOffset": 129, "endOffset": 132}, {"referenceID": 0, "context": "In this study, we have employed a collection of 1947 annotated review sentences from the works of Atoum and Bong [1].", "startOffset": 113, "endOffset": 116}, {"referenceID": 0, "context": "START READ scores and labelled indicators from returned LSA results SORT results based on highest to lowest similarity score (R1) READ highest score R1[0]:score and second highest score R1[1]:score from the sorted list R1 COUNT variance = R1[0]:score \u2013 R1[1]:score IF variance >0.", "startOffset": 188, "endOffset": 191}, {"referenceID": 0, "context": "START READ scores and labelled indicators from returned LSA results SORT results based on highest to lowest similarity score (R1) READ highest score R1[0]:score and second highest score R1[1]:score from the sorted list R1 COUNT variance = R1[0]:score \u2013 R1[1]:score IF variance >0.", "startOffset": 255, "endOffset": 258}, {"referenceID": 4, "context": "Next, we calculate precision, recall and F-measure based on the following formulas adapted from information retrieval proposed by Manning, Raghavan and Sch\u00fctze [6]:", "startOffset": 160, "endOffset": 163}, {"referenceID": 0, "context": "They also used semi-supervised learning to calculate polarity of sentences [1].", "startOffset": 75, "endOffset": 78}, {"referenceID": 5, "context": "[7] In terms of finding related documents or document classification works, some of the well-known methods are kNN classification, Na\u00efve bayes, vector space model, neural networks and etc.", "startOffset": 0, "endOffset": 3}], "year": 2015, "abstractText": "The paper describes a novel approach to categorize users\u2019 reviews according to the three Quality in Use (QU) indicators defined in ISO: effectiveness, efficiency and freedom from risk. With the tremendous amount of reviews published each day, there is a need to automatically summarize user reviews to inform us if any of the software able to meet requirement of a company according to the quality requirements. We implemented the method of Latent Semantic Analysis (LSA) and its subspace to predict QU indicators. We build a reduced dimensionality universal semantic space from Information System journals and Amazon reviews. Next, we projected set of indicators\u2019 measurement scales into the universal semantic space and represent them as subspace. In the subspace, we can map similar measurement scales to the unseen reviews and predict the QU indicators. Our preliminary study able to obtain the average of Fmeasure, 0.3627.", "creator": "Microsoft\u00ae Word 2013"}}}