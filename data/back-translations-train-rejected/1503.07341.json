{"id": "1503.07341", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2015", "title": "An Experiment on Using Bayesian Networks for Process Mining", "abstract": "Process mining is a technique that performs an automatic analysis of business processes from a log of events with the promise of understanding how processes are executed in an organisation.", "histories": [["v1", "Wed, 25 Mar 2015 11:34:31 GMT  (1772kb,D)", "http://arxiv.org/abs/1503.07341v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["catarina moreira"], "accepted": false, "id": "1503.07341"}, "pdf": {"name": "1503.07341.pdf", "metadata": {"source": "CRF", "title": "An Experiment on Using Bayesian Networks for Process Mining", "authors": ["Catarina Moreira"], "emails": [], "sections": [{"heading": null, "text": "Process Mining is a technique that performs automatic analysis of business processes based on events with the promise of understanding how processes in an organization are executed. Several models have been proposed to solve this problem, but here we propose a different approach to deal with uncertainty. By uncertainty we mean estimating the likelihood of a sequence of tasks occurring in a business process, since only a subset of tasks can be observed. In this sense, this work proposes a new approach to performing process mining using Bayean networks, which can take into account the likelihood that a task exists or does not exist in the business process. Furthermore, Bayesian networks are able to automatically analyze these probabilities through mechanisms such as maximum probability estimation and EM clustering. Experiments conducted via a case study of credit applications suggest that Bayesian networks are adequate structures for process mining and allow for in-depth analysis of the business process model that can be used to answer questions about this process."}, {"heading": "1 Introduction", "text": "In fact, most of them will be able to move to another world, in which they will be able to escape rather than to another world."}, {"heading": "2 Markov Chains", "text": "A Markov chain is defined by a state space Val (X) and a model that defines a next-state distribution via Val (X) for each state x-Val (X). Specifically, the transition model \u03c4 determines for each state pair x, x-x the probability of passing from state x to state x (Koller & Friedman 2009). In the Markov chain, the transition probability matrix must be stochastical, i.e. each row of the matrix must be added to one. Matrix 1 represents the transition matrix of the Markov chain in Figure 1.Ptransition = 0,9 0,075 0,025 0,15 0,8 0,50.25 0,25 0,5 (1) Suppose that you are in state B at the time n. To calculate the evolution of the system for n + 1, you only need to perform a matrix multiplication between the current state and the transition probability matrix (PsiB)."}, {"heading": "3 Bayesian Networks", "text": "Bavarian networks are directional acyclic graphs in which each node represents a different random variable from a particular domain and each edge represents a direct influence from the source node to the target node (Pearl 1997).The graph represents independence relations between variables and each node, linked to a conditional probability table (CPT) that determines a distribution over the values of a node, with any possible common allocation of values from its parents.The complete common distribution of a Bavarian network in which X is the list of variables results from (Russell & Norvig 2009): Prc (X1,.., Xn) = n \u00b2 i = 1 Pr (Xi | Parents (Xi)) (4) The formula for calculating classical exact conclusions on Bavarian networks is based on the complete articulation (Equation 4)."}, {"heading": "3.1 Example of Application", "text": "If we look at the Bayesian network in Figure 2. Let us assume that we want to determine the probability of rain = = = = = = = = = We know that the grass is wet. | To make such a conclusion on a Bayesian network, we can use the equation 5 as follows: Pr (R = T | W = T) = \u03b1 Pr (R = T) = 0.2 \u00b7 [Pr (S = T) \u00b7 Pr (W = T | S = s, R = T = T) (6) Pr (R = T | W = T) = \u03b1 Pr (R = T) = 0.2 \u00b7 F (S = T) Pr (W = T = T = T = T = T = T) (R = S = s) (6) Pr (R = T | W = T) = 0.2 \u00b7 W = 0.2 [0.01 \u00b7 0.99 + 0.8 \u00d7 0.8] = 0.1677 = = F = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = F = = = = = = = = = = 0.2 = = = = = = T = T = T = Pr (R = T = T = Pr = T = T = S = S = S = S = s = S = s = S = S = s = S = S = S = s = S = s = S = S = s = S = s = S = s = S = S = s = S = s = s = T = S = s = S = s = s = T = S = s = s = s = T = T = T = = = = = = T = T = = = = T = = = = = = T = = = = T = = = = = = T = = = = = = = = = = T = = = = = = T = = = = = = = = = = = = = T = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "3.2 Learning in Bayesian Networks", "text": "There are two main approaches to building a Bayesian network: one is to construct the network by hand and use an expert's knowledge to estimate the conditional probability tables; the second is to use statistical models to automatically learn these probabilities (Koller & Friedman 2009); the manual estimation of conditional probabilities with an expert's knowledge is problematic for several reasons: in some situations, the network is so large that it is almost impossible for the expert to reliably assign probabilities to the random variables; and, in many situations, the distribution of data varies by application and over time, making it impossible for an expert to reliably estimate the probabilities associated with the Bayesian network's random variables; and statistical models provide a mechanism to automatically learn a model that replicates the probability distribution of some populations."}, {"heading": "3.2.1 Maximum Likelihood Estimation in Bayesian Networks", "text": "The Maximum Probability Estimation is a statistical method that assumes that the data follow a Gaussian probability distribution (then the mean and variance of the probability distribution is estimated by knowing only a partial sample of the dataset (Bishop 2007). Suppose that we have a Bavarian network, as shown in Figure 3. This network is parameterized by a parameter vector that determines the parameters for the conditional probability distribution of the mesh. Training examples in Figure 3 consist of a multiple of the form < x [m], y [m] >, where x is an instance of the random variable X, y is an instance of the random variable Y, and m is the mth training example for size M. The probability function is given by: L (Profile: D) = M \u00b2 m = 1 Pr = 1 Pr (x [m], y [m]: 1 Pr [m], y [m], y [],] we can give a distributive probability distribution in a Bayesian network."}, {"heading": "3.3 SamIam", "text": "Developed by the Automated Reasoning Group at the University of California1.SamIam, which consists of a graphical interface and an argumentation engine, the graphical interface provides an easy way to model the Bayesian network by specifying random variables as nodes, causal connections as edges, and the respective conditional probabilities, while the reasoning motor can perform classic inferences over the plotted Bayesian network, with parameters determined by the learning mechanisms."}, {"heading": "4 Bayesian Networks for Process mining", "text": "Probabilistic graphical models, such as Bayean networks, are normally used for probabilistic conclusions, i.e. to make requests to the model and obtain answers in the form of probability values. In the field of process mining, Bayean networks can represent activities as nodes (i.e. random variables), and the edges between activities can be considered as transitions between these tasks. From this structure, one can automatically learn the probability tables by using EM clusters, just as they are used in the work of Bobek et al. (2013), which developed a Bayesian network to recommend business processes (Section 3.2.1). If the protocol is incomplete, a Bayesian network can also automatically learn and estimate the probability tables by using EM clusters, just as it is used in the work of Bobek et al. (2013), which developed a Bayesian network to recommend business processes (Section 3.2.1) of the Petri literature to be learned from business protocols or events in 2012."}, {"heading": "4.1 Defining the Strucuture", "text": "Another advantage of Bayesian Networks is that they allow the direct representation of business process diagrams by capturing the direct dependencies between tasks. However, they do not allow explicit representation of cycles, since Bayesian Networks are aligned to acyclic graphs. To represent a cycle in a Bayesian Network, we would have to create many instances of the same node that are insoluble to draw conclusions, since the consequential problem is NP-Complete (Figures 10 and 11). In this work, to eliminate cycles from the log of events, we used a heuristics that selects the most likely transitions between nodes. For example, that there is a transition from nodes A \u2192 B that have occurred 900 times. Let's also assume that there is a transition from nodes B."}, {"heading": "4.2 SamIam: Designing a Bayesian Network", "text": "SamIam provides an intuitive interface for constructing the Bayesian network. There are two modes in SamIam: the query mode (for learning and for conclusions) and the editing mode (for network structure and definition of conditional probabilities). When SamIam is started, the editing mode appears by default. Figure 20 describes the interface of the general editing mode. The interface allows the creation / removal of nodes and the creation / removal of edges between nodes. Additionally, for each created node, one must specify a configuration window that can be accessed when the node is double-clicked. In this window, one must specify a unique identifier for the node and a name that can be displayed in the SamIam interface. Additionally, one must specify which states of the nodes can have. For the scope of this work, we will have only binary random variables, so that each node will have two random variables exactly, one representing the other one and the other."}, {"heading": "4.3 Learning", "text": "This year it has come to the point where it will be able to put itself at the top to save the world, \"he said in an interview with\" Welt am Sonntag. \""}, {"heading": "5 Case Study: Loan Application", "text": "The event log that we use in this work is from a Dutch financial institute 2. The event log represents a credit application from a global financial organization in which a customer requests a certain amount of money. The process consists of three different sub-processes; the first letter of each task corresponds to an identifier of the sub-process to which it belongs; the tasks that begin with letter A correspond to the states of the application; the tasks that begin with letter O correspond to offers that belong to the application; and the tasks that begin with letter W correspond to the part of work that belongs to the application; the general scenario is as follows: There is a website that allows credit applications to be submitted; a customer selects a certain amount of money and then submits his request; then the application performs some automatic tasks and verifies whether an application is eligible; if it is eligible, the customer receives an offer by post; after this offer is received, it is evaluated; in the case of missing information, the offer goes back to the customer and is evaluated again."}, {"heading": "5.1 Converting the Log of Events into a SamIam Bayesian Nework", "text": "In this thesis, a Java program was created that entered the log of events in csv format and returned a Bayesian network in a special file format that was readable by the SamIam toolkit. It analyzed each line of the log and grouped all activities belonging to the same instance (had the same case).The program automatically generated a graph in a matrix form representation and calculated the frequency of connections between the notes. In light of this matrix form representation, another Java program was created to turn the this2http: / / www.win.nl / bpi / 2012 / challengematrix into a network file. Numbers 28 and 29 show an example of a network file that is readable."}, {"heading": "5.2 Converting the Log of Events into a Markov Chain", "text": "As already mentioned, we also developed a Markov chain using a script in Python with the same training set from which the Bayesian network was generated. Transition probabilities of the Markov chain were calculated simply by counting the number of events in each event sequence and then normalizing to obtain a probability value. Figure 35 shows the calculated Markov network."}, {"heading": "5.3 Results", "text": "After defining the structure of the Bayesian network for the loan application, we created a training set in which we randomly selected 70% of the cases in the event log as the training set and then used the remaining 30% as the test set to validate our model. The training set was given to SamIam as input to learn the conditional probability tables. To test the application, a MatLab program was developed to perform probabilistic conclusions. Essentially, the MatLab program received the SamIam network file as input and returned a Bayesian network structure from which we were able to calculate full common probability distributions and boundary probabilities. Another Java program received the test set as input and was able to validate the model. Validation was performed as follows: We calculated the probability of some events occurring in the test set, and then compared this value to the probability of the LE8 given in the LEE network, where the ELE was the most likely to show the LE8 results."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Probability Test Set Training Set ERROR %", "text": "Another experiment was to compare the proposed Bayesian network with a Markov chain. We trained a Markov chain in the same way as we did for the Bayesian network. To validate both approaches, we used the test theorem and calculated the probability of each sequence occurring in a Bayesian network and in a Markov chain. Ultimately, these probabilities were weighted by the number of occurrences of each sequence in the test theorem. The results are discriminated against in Table 10.Table 10, which shows that the probabilities calculated in a Bayesian network are almost identical to those calculated by the Markov chain. Individually, the probabilities of calculating the sequences in the test theorem showed no margin of error higher than 4.13%, which is statistically insignificant compared to the total amount of data tested. Furthermore, the total error ratio between the proposed Bayesian network and the Markov network was significant by 2674%."}, {"heading": "Processes Process Encoding Processes Process Encoding", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Chain Occ. Test Set BN MC ERROR %", "text": "means that the Bayesian networks have a similar performance as a Markov chain. From this one can conclude that Bayesian networks are also good approaches to modelling business processes, with the advantage of being able to represent uncertainty (calculation probabilities of tasks that we do not know if they have occurred)."}, {"heading": "5.4 Queries", "text": "As mentioned above, one of Bayesian Networks \"capabilities for process mining is its ability to deal with uncertainty, enabling the analysis of tasks that are not known. For example, for the Bayesian Loan Application Network, one may be interested in analyzing the likelihood of a successful end to the business process by knowing only that a few tasks have been observed. Combining this capability with SamIam's graphical capabilities, a quick analysis of business processes and risk management will be beneficial. Figure 36 shows the likelihood of some nodes of the Bayesian Network Loan Application being rejected, if only it is known that the application has been rejected, that is, the node A DECLINED has been observed. From this analysis, one can conclude that the majority of rejected applications have a high probability of reaching the state A PREACCEPT. Moreover, if an application is rejected, then the nodes A ACTIVATED and A CANCELLED will never be ated.Another example is given by Figure 37, if a high probability is reached that the CEPT task will be achieved."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we propose the use of Bayesian networks as a new approach to represent business processes that are automatically extracted from event logs. In a first step, we extracted the relationships between nodes from the event log and then used this protocol to train and validate the proposed Bayesian networks. Experiments conducted via a case study on loan application suggest that Bayesian networks perform the same performance as Markov chains, i.e. are good models for making accurate predictions of events in the context of process mining. Furthermore, it is interesting for future work to use the capabilities of these structures to deal with uncertainties. More specifically, Bayesian networks allow the reconstruction of a flow by taking only incomplete observations into account in the business process.As for future work, it would be interesting to expand the capabilities of Bayean networks to learn from incomplete event logs."}], "references": [{"title": "Mining process performance from event logs: The bpi challenge 2012 case study, in \u2018Proceedings of the 8th International Workshop on Business Process Intelligence", "author": ["A. Adriansyah", "J. Buijs"], "venue": null, "citeRegEx": "Adriansyah and Buijs,? \\Q2012\\E", "shortCiteRegEx": "Adriansyah and Buijs", "year": 2012}, {"title": "Process mining-driven optimization of a consumer loan approvals process: The bpic 2012 challenge, in \u2018Proceedings of the 8th International Workshop on Business Process Intelligence", "author": ["A.D. Bautista", "L. Wangikar", "S.M.K. Akbar"], "venue": null, "citeRegEx": "Bautista et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bautista et al\\.", "year": 2012}, {"title": "Pattern Recognition and Machine Learning, Springer", "author": ["C. Bishop"], "venue": null, "citeRegEx": "Bishop,? \\Q2007\\E", "shortCiteRegEx": "Bishop", "year": 2007}, {"title": "Application of bayesian networks to recommendations in business process modeling, in \u2018Proceedings of the Central Europe Workshop", "author": ["S. Bobek", "M. Baran", "K. Kluza", "G. Nalepa"], "venue": null, "citeRegEx": "Bobek et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bobek et al\\.", "year": 2013}, {"title": "Process mining applied to the bpi challenge 2012: Divide and conquer while discerning resources, in \u2018Proceedings of the 8th International Workshop on Business Process Intelligence", "author": ["J.C. Bose", "W. van der Aalst"], "venue": null, "citeRegEx": "Bose and Aalst,? \\Q2012\\E", "shortCiteRegEx": "Bose and Aalst", "year": 2012}, {"title": "Discovering models of software processes from event-based data", "author": ["J. Cook", "A. Wolf"], "venue": "Journal of ACM Transactions on Software Engineering and Methodology", "citeRegEx": "Cook and Wolf,? \\Q1998\\E", "shortCiteRegEx": "Cook and Wolf", "year": 1998}, {"title": "Approaching process mining with sequence clustering: Experiments and findings, in \u2018In", "author": ["D. Ferreira", "M. Zacarias", "M. Malheiros", "P. Ferreira"], "venue": "Proceedings of the 5th International Conference on Business Process Management\u2019", "citeRegEx": "Ferreira et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ferreira et al\\.", "year": 2007}, {"title": "Analyzing application process for a personal loan or overdraft of dutch financial institute with process mining techniques, in \u2018Proceedings of the 8th International Workshop on Business Process Intelligence", "author": ["C.J. Kang", "C.K. Shin", "E.S. Lee", "J.H. Kim", "M.A. An"], "venue": null, "citeRegEx": "Kang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kang et al\\.", "year": 2012}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "Koller and Friedman,? \\Q2009\\E", "shortCiteRegEx": "Koller and Friedman", "year": 2009}, {"title": "Machine Learning: A Probabilistic Perspective", "author": ["K. Murphy"], "venue": null, "citeRegEx": "Murphy,? \\Q2012\\E", "shortCiteRegEx": "Murphy", "year": 2012}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1997\\E", "shortCiteRegEx": "Pearl", "year": 1997}, {"title": "Causality: Models, Reasoning and Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q2009\\E", "shortCiteRegEx": "Pearl", "year": 2009}, {"title": "Business process analysis in healthcare environments: A methodology based on process mining", "author": ["A. Rebuge", "D. Ferreira"], "venue": "Journal of Information Systems: Management and Engineering of Process-Aware Information Systems", "citeRegEx": "Rebuge and Ferreira,? \\Q2012\\E", "shortCiteRegEx": "Rebuge and Ferreira", "year": 2012}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S. Russell", "P. Norvig"], "venue": null, "citeRegEx": "Russell and Norvig,? \\Q2009\\E", "shortCiteRegEx": "Russell and Norvig", "year": 2009}, {"title": "Causation, Prediction and Search", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": null, "citeRegEx": "Spirtes et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Spirtes et al\\.", "year": 2001}, {"title": "A review of business process mining: state-of-the-art and future trends", "author": ["A. Tiwari", "C. Turner", "B. Majeed"], "venue": "Journal of Business Process Management", "citeRegEx": "Tiwari et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Tiwari et al\\.", "year": 2008}, {"title": "The application of petri nets to workflow management", "author": ["W. van der Aalst"], "venue": "Journal of Circuit Systems and Computers", "citeRegEx": "Aalst,? \\Q1998\\E", "shortCiteRegEx": "Aalst", "year": 1998}, {"title": "Process mining and security: Detecting anomalous process executions and checking process conformance", "author": ["W. van der Aalst", "A.K. de Medeiros"], "venue": "Journal of Electronic Notes in Theoretical Computer Science", "citeRegEx": "Aalst and Medeiros,? \\Q2005\\E", "shortCiteRegEx": "Aalst and Medeiros", "year": 2005}, {"title": "Workflow mining: Discovering process models from event logs", "author": ["W. van der Aalst", "T. Weijters", "L. Maruster"], "venue": "Journal of IEEE Transactions on Knowledge and Data Engineering 16,", "citeRegEx": "Aalst et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Aalst et al\\.", "year": 2004}, {"title": "Process Mining: Discovery, Conformance and Enhancement of Business Processes, Springer", "author": ["W. van der"], "venue": null, "citeRegEx": "der,? \\Q2011\\E", "shortCiteRegEx": "der", "year": 2011}, {"title": "Business Process Management: Concepts, Languages, Architectures, Springer", "author": ["M. Weske"], "venue": null, "citeRegEx": "Weske,? \\Q2012\\E", "shortCiteRegEx": "Weske", "year": 2012}], "referenceMentions": [{"referenceID": 20, "context": "This graphical representation describes dependencies between activities that need to be executed together in order to fulfil a business target (Weske 2012).", "startOffset": 143, "endOffset": 155}, {"referenceID": 15, "context": "However, Markov Chains and Petri Nets are the models that are most used in the literature of process mining (Tiwari et al. 2008).", "startOffset": 108, "endOffset": 128}, {"referenceID": 14, "context": "A Bayesian Networks can be defined as an acyclic directed graph in which each node represents a random variable and each edge represents a direct influence from the source node to the target node (conditional dependencies) (Spirtes et al. 2001).", "startOffset": 223, "endOffset": 244}, {"referenceID": 11, "context": "Therefore, it is possible to perform special analysis that will enable the computation of the probability of some task of the business process occurring, given that we do not know which tasks have already been performed (Pearl 2009).", "startOffset": 220, "endOffset": 232}, {"referenceID": 10, "context": "Bayesian Networks are directed acyclic graphs in which each node represents a different random variable from a specific domain and each edge represents a direct influence from the source node to the target node (Pearl 1997).", "startOffset": 211, "endOffset": 223}, {"referenceID": 9, "context": "The data are considered fully observed if on each of the training instances there is a full instantiation to all the random variables of our sample space (Murphy 2012).", "startOffset": 154, "endOffset": 167}, {"referenceID": 2, "context": "The mean and the variance of the probability distribution can be estimated by only knowing a partial sample of the dataset (Bishop 2007).", "startOffset": 123, "endOffset": 136}, {"referenceID": 20, "context": "In the literature, business processes that are learnt from event logs are usually represented by either Markov Chains or Petri Nets (Weske 2012).", "startOffset": 132, "endOffset": 144}, {"referenceID": 3, "context": "If the log is incomplete, then a Bayesian Network can also automatically learn and estimate the probability tables through the usage of EM Clustering, just like used in the work of Bobek et al. (2013), who developed a Bayesian Network to recommend business processes.", "startOffset": 181, "endOffset": 201}, {"referenceID": 2, "context": "1) if the log of events is complete or using the EM Clustering algorithm if the log of events is incomplete (Bishop 2007).", "startOffset": 108, "endOffset": 121}], "year": 2015, "abstractText": "Process mining is a technique that performs an automatic analysis of business processes from a log of events with the promise of understanding how processes are executed in an organisation. Several models have been proposed to address this problem, however, here we propose a different approach to deal with uncertainty. By uncertainty, we mean estimating the probability of some sequence of tasks occurring in a business process, given that only a subset of tasks may be observable. In this sense, this work proposes a new approach to perform process mining using Bayesian Networks. These structures can take into account the probability of a task being present or absent in the business process. Moreover, Bayesian Networks are able to automatically learn these probabilities through mechanisms such as the maximum likelihood estimate and EM clustering. Experiments made over a Loan Application Case study suggest that Bayesian Networks are adequate structures for process mining and enable a deep analysis of the business process model that can be used to answer queries about that process.", "creator": "LaTeX with hyperref package"}}}