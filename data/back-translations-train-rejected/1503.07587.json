{"id": "1503.07587", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2015", "title": "Universal Psychometrics Tasks: difficulty, composition and decomposition", "abstract": "This note revisits the concepts of task and difficulty. The notion of cognitive task and its use for the evaluation of intelligent systems is still replete with issues. The view of tasks as MDP in the context of reinforcement learning has been especially useful for the formalisation of learning tasks. However, this alternate interaction does not accommodate well for some other tasks that are usual in artificial intelligence and, most especially, in animal and human evaluation. In particular, we want to have a more general account of episodes, rewards and responses, and, most especially, the computational complexity of the algorithm behind an agent solving a task. This is crucial for the determination of the difficulty of a task as the (logarithm of the) number of computational steps required to acquire an acceptable policy for the task, which includes the exploration of policies and their verification. We introduce a notion of asynchronous-time stochastic tasks. Based on this interpretation, we can see what task difficulty is, what instance difficulty is (relative to a task) and also what task compositions and decompositions are.", "histories": [["v1", "Thu, 26 Mar 2015 00:34:34 GMT  (92kb,D)", "http://arxiv.org/abs/1503.07587v1", "30 pages"]], "COMMENTS": "30 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jose hernandez-orallo"], "accepted": false, "id": "1503.07587"}, "pdf": {"name": "1503.07587.pdf", "metadata": {"source": "CRF", "title": "Universal Psychometrics Tasks: difficulty, composition and decomposition", "authors": ["Jos\u00e9 Hern\u00e1ndez-Orallo"], "emails": ["jorallo@dsic.upv.es"], "sections": [{"heading": null, "text": "The concept of cognitive task and its use for the evaluation of intelligent systems is still fraught with problems. Considering tasks as MDP in the context of reinforcement learning has been particularly useful for formalizing learning tasks. However, this mutual interaction is not well suited to some other tasks common in artificial intelligence and especially in animal and human evaluation. In particular, we would like to have a more general representation of episodes, rewards and reactions, and especially the computational complexity of the algorithm behind an agent solving a task, which is crucial for determining the difficulty of a task than the (logarithm of) number of computational steps required to develop an acceptable policy for the task, which includes the exploration of strategies and their verification. We introduce an idea of asynchronous temporal stochastic tasks. Based on this interpretation, we can see which task is difficult, which instance of difficulty (a relative difficulty to a task), which compositions, which tasks are which and which tasks."}, {"heading": "1 Introduction", "text": "In fact, most people who are in a position to decide for themselves what they want and what they want to do are left to their own devices, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \""}, {"heading": "2 Tasks, trials and responses", "text": "Cognitive evaluation is done through instruments called cognitive tests, which consist of cognitive tasks. Consequently, we need to have a clear view of what a task is and how it can be compared. [25] Tasks are defined as interactive processes with asynchronous time, where the final response is not necessarily a function of reward. However, tasks are still based on transitional functions, and - partly for this reason - there is no clear handling of idle times to define an appropriate notion of arithmetic steps. Furthermore, it is unclear what happens when repeatedly tested on the same agent, and also whether or not the agent has undergone an earlier training phase. Despite some additional notation loads, we will try to explain all this explicitly in this paper."}, {"heading": "2.1 Example", "text": "What do Talon the dolphin in the Florida Keys [40] and Ana the sea lion in Valencia [1] have in common? Both were tested for their ability to evaluate relative quantity, a task normally referred to as \"relative numeracy,\" \"relative numeracy,\" or \"relative quantity evaluation.\" Talon the bottlenose dolphin, for example, was repeatedly tested with two different quantities, as shown in fig. 1, and received a reward when the lesser amount was selected. Apart from the cetaceans, many other studies on \"relative numeracy\" were conducted in the field of comparative psychology, including angels, bears, capuchin monkeys, squirrel monkeys, cats, chimpanzees, coyotes, gorillas, hyenas, orangutans, pigeons, salamanders, sea lions, and elephants (see e.g. the links to some of these studies)."}, {"heading": "2.2 Features of a task", "text": "In fact, it is not that we would be able to survive ourselves, and that we would be able to survive ourselves. (...) It is not that we would be able to survive ourselves. (...) It is not that we would be able to survive ourselves. (...) It is not that we would be able to survive ourselves. (...) It is not that we would be able to survive ourselves. (...) It is not that we would be able to survive ourselves. (...) It is not that we would be able to survive ourselves. (...)... (...)... (...)... (...)... (...)... (...)... (...)... (...) \"(...)\" (...) (...) \"(... (...)\" (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) ()) (...)"}, {"heading": "2.3 Asynchronous-time Stochastic Tasks", "text": "In fact, most of them will be able to move to another world in which they are able to live, in which they want to live."}, {"heading": "2.4 Trials and results", "text": "We consider tests consisting of tasks (also called environments), which are usually referred to by \u00b5, and are performed by agents (also called policies or subjects), usually referred to by \u03c0.The expected value of the answer, return or result of \u03c0 in \u00b5 for a time limit. However, if the agent goes into a non-holding loop and does not respond, this is usually omitted since it is understood that it is part of the description of the task that there are many tasks in which the task can be repeated. R always gives values between 0 and 1 and we assume that it is always defined. If the agent goes into a non-holding loop and does not respond anymore, this is not perceived externally and may even lead to some non-zero R tasks (from the previous actions or because of the nature of the task). Now, we must extend the notation of R (\u03c0, \u00b5) to consider multiple instances of the same task. Each attempt of a subject on a task study is an [R is an expected episode 7 or R is an episode]."}, {"heading": "2.5 Examples", "text": "In Fig. 1, we saw an example of the task \"relative countability\" \u00b5num. This can be regarded as a stochastic task class in which the agent sees two rectangular grids (representing plates) in which we have some black spots on it. The action is only the selection to the left or right. However, if the choice is correct, the agent receives an answer (and reward) of 1. Otherwise, he receives 0.For this task (\u00b5num in Table 1), we have 4 \u00b7 4 \"cells,\" with the number of points in each panel ranging uniformly from 1 to 16. The size of each point is uniformly distributed between 0.2 and 1, where 1 is the diameter of the cell. In the case of the two panels would have exactly the same number of points, the pair would be discarded and a new one would be generated. Using different scores is used to prevent the subjects from being selected exclusively (or mostly) by their overall representation."}, {"heading": "3 Task difficulty", "text": "The first thing we need to clarify about the difficulty is whether we apply it to the generation of politics or the application of policy.The generation phase can be innate (through programming or nature) or acquired (through training or learning).In comparative psychology and artificial intelligence, it is common to have these two phases. It is very important to determine which phase we are referring to when talking about difficulties. For example, when we evaluate an animal's ability to perform a task that involves counting, we want to know whether the animal can attain this ability. If we evaluate the ability to perform calculations (e.g. addition), we clearly assume that the system already has the algorithm for addition, and we only investigate how well they work. This is clearly the case in many specific task assessments, such as driving, playing, etc. The confusion arises because in both cases we evaluate the performance of the task in the same way."}, {"heading": "3.1 Agent resources, acceptability and interaction in asynchronous environments", "text": "The first thing we need is the length of a policy. The length of an object x, denoted by L (x), expresses the length of a string using a binary code for the object. This function can be applied to tasks and agents. However, there is one important thing we need to consider here. If a program has the ability to modify itself, as happens with self-renewal agents, then it is like analyzing how memory develops, so we will look at the program as it was before the evaluation. The second thing we need is the calculation steps that are taken by a policy. In synchronous environments, one option can be all the steps that are taken for all time cycles, but this clearly depends on the resolution of the discrete time."}, {"heading": "3.2 Difficulty as minimum resources", "text": "These are general expressions whose aim is to understand what a function of difficulty is. However, in many tasks we can use a more practical (and specific) function of difficulty, and now we are ready to link difficulties to resources. This is common in algorithmic information theory, but here we have to evaluate the complexity of policy measures (the agents) and not the problems (the tasks) as the length of the shortest acceptable policy: K [3], 7 [4] and [5], which we have to consider as a task. (5] The use of the notation K and the structure of the definition make it clear that this can be understood as a version of the Kolmogorov complexity for tasks, where instead we are talking about the shortest program we are talking about the solution that the task.K."}, {"heading": "4 Task instances, task composition and decomposition", "text": "This year it is so far that it only takes a few days to get there, to get to the point where an agreement can be reached."}, {"heading": "4.1 Instance difficulty as rareness", "text": "Instead of considering all the policies, we can consider the best policy. Insight comes when we see that the best policy can change with variable values of LS. This leads to the view that the relative difficulty of an instance in relation to a problem is simply the problem for which its random behavior is fixed. This can be achieved with the underlying model, by putting a solid instance to the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance of the instance."}, {"heading": "4.2 Task composition and decomposition", "text": "The question now is how to reconcile several tasks. For example, if we can include answers from Table 1 in the same test using micropunctures and micropunctures, does it make sense to aggregate the results? The first problem is that aggregating multiple answers that are not appropriate does not make sense (perhaps for one of the answers they go from 0 to 0.1, while for the other they go from 0.5 to 1, with very different task distributions from 1). An alternative to normalization is to use a tolerance level for the tasks, which gives another justification for eq. 1 where A was introduced. Given two tolerance levels for each task, we can see if this leads to similar or different difficulties for each task. If the difficulties are very different, then the task is dominated by the simple one. In the previous example, micropunception is much easier than the micropunception. By using different tolerance levels, we can determine whether we want to have both tasks or not."}, {"heading": "4.3 Agent response curves", "text": "One of the benefits of the difficulty is the analysis of the agents according to how they behave in relation to the difficulty of the problem. (This can be done with the so-called agent-response curves introduced in [25] following the notion of item-response curves in psychometry. Let's briefly see how these curves can be defined for tasks or task instances, unless M is a set of tasks or task instances where M is a set of tasks or task instances, and pM is a distribution that with this definition, task classes are stochastic tasks (but not all stochastic tasks can be considered as classes). We also consider a difficulty function h (about tasks, or about task instances relative to the overall task).We can group those of the same difficulty:"}, {"heading": "5 Difficulty as Levin search with stochastic verification", "text": "This depends on how many alternative algorithms we have to try before we find the right one and how much time we need to discard the bad ones and confirm the right one. It boils down to a measure of difficulty depending on how many options need to be examined, and the time it takes each of them to find a higher limit on the number of arithmetic steps to find the best acceptable policy on a problem, i.e., their difficulty is led to the length of the policy and the logarithms of their computing time through their combination of computing time that ultimately led to the function Kt. (7) As we argued, this is given by the realization that a policy of length L (\u03c0) we have to try about 2L (\u03c0) algorithms when we encompass programs from small to large (this is basically what Levin is looking for a universal entity that we are gradually increasing)."}, {"heading": "5.1 Levin universal search for stochastic tasks and/or policies", "text": "Levin's universal search has very interesting properties, since any inversion problem can be optimally solved (except for a multiplicative constant) [44, pp. 577-580]. It is related (and with roughly similar properties) to the SIMPLE search algorithm in [44, pp. 579], but with the advantage that executing programs does not require threads or tracks to resume the previously examined program execution (at the expense of repeating a portion of previous execution). It is important how it times the length of a program with its execution (and verification).The traditional Levin's universal search is defined as follows: 12There are some variants and adaptations of the Levin search for interactive scenarios and MDPs [33, 52, 53, 51]. Here, our goal is not to find a search that is useful for designing intelligent agents, but to find some expressions that help us improve our definition of tasks."}, {"heading": "5.2 \u2018PAC\u2019 verification for stochastic tasks", "text": "The second thing is that it can be unreasonable for stochastic systems to expect a maximum or perfect result. In fact, by using any statistical test as to whether we have reached the maximum value, we cannot have a degree of certainty (not even the slightest degree of certainty) that we have this maximum value, since our average value will never exceed the maximum value necessary for statistical significance. We could think about using a slack parameter. In the face of a series of n runs, we can calculate the average r value and the standard deviation of the results. For example, we can make the default error susceptible by just SE = and set a limit on it. However, when we do this, we see that it depends on the order of magnitude, a stochastic process between 0 and 1 will be higher than when it goes between 0.4 and 0.6."}, {"heading": "5.3 Interpretation and use", "text": "Does the approximation in Equations 15 and 16 work properly? To get more insight into how it works, we will see some figurative examples and see the resulting values to see the effects of B in the new difficulty formula. This is shown in Table 4 (all cases take r * = 1 into account). As we see from the results, there are cases where B can be large and have an impact on the log (F). Although the use of B entails an additional complication of the concept of difficulty, it does not add significant additional costs to its calculation, since we have to perform the optimal policy for S many times. Nevertheless, the most difficult part of estimating the difficulty is finding the optimal policy. The previous sections can be analyzed in terms of whether they lead to limited difficulty functions. It seems that for the target case (Section 5.2) we have the choice of whether r * = 1, the difficulty function is unlimited, but the repetition function is unlimited."}, {"heading": "6 Conclusions", "text": "As we have mentioned in this paper, the concept of task is widely used in AI evaluation, in cognition, and also in human evaluation. However, a general formalization, its arrangement, and especially its difficulty has not been approached here with serious determination. Of course, with this resolution of being in general, we have left some other more convenient approaches, such as MDP and other formalizations in AI. Our main goal was the difficulty, as we have seen that this is central to many of the other issues. Difficulty, however, is seen as a computational step of a Levin search, but this search needs to be modified to analyze stochastic behavior. Nevertheless, we have been able to find an expression in terms of the best policy for the task. These ideas are an evolution and continuation of early notions of task and difficulty in [25] and [21] in terms of the task. There have been some early approaches where the role of Kt for various types of optimization or inference problems has been explored."}], "references": [{"title": "Relative quantity judgments in south american sea lions (otaria flavescens)", "author": ["Jos\u00e9 Z Abramson", "Victoria Hern\u00e1ndez-Lloreda", "Josep Call", "Fernando Colmenares"], "venue": "Animal cognition,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Can we measure the difficulty of an optimization problem", "author": ["T. Alpcan", "T. Everitt", "M. Hutter"], "venue": "IEEE Information Theory Workshop (ITW),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Deep machine learning - a new frontier in artificial intelligence research", "author": ["I. Arel", "D.C. Rose", "T.P. Karnowski"], "venue": "Computational Intelligence Magazine, IEEE, 5(4):13\u201318,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolution for automatic assessment of the difficulty of sokoban boards", "author": ["D. Ashlock", "J. Schonfeld"], "venue": "Evolutionary Computation (CEC), 2010 IEEE Congress on, pages 1\u20138. IEEE,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "The development of arithmetic concepts and skills: Constructive adaptive expertise", "author": ["Arthur J Baroody", "Ann Dowker"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "An empirical exploration of the difficulty function", "author": ["J.G.W. Bentley", "P.G. Bishop", "M. van der Meulen"], "venue": "In Computer Safety, Reliability, and Security,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Do artificial ants march in step? ordered asynchronous processes and modularity in biological systems", "author": ["David Cornforth", "David G Green", "David Newth", "Michael Kirley"], "venue": "In Proceedings of the eighth international conference on Artificial life,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "IQ tests are not for machines, yet", "author": ["D.L. Dowe", "J. Hern\u00e1ndez-Orallo"], "venue": "Intelligence, 40(2):77\u201381,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "How universal can an intelligence test be", "author": ["D.L. Dowe", "J. Hern\u00e1ndez-Orallo"], "venue": "Adaptive Behavior,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Compression and intelligence: social environments and communication", "author": ["D.L. Dowe", "J. Hern\u00e1ndez-Orallo", "P.K. Das"], "venue": "J. Schmidhuber, K.R. Th\u00f3risson, and M. Looks, editors, Artificial General Intelligence, volume 6830, pages 204\u2013211. LNAI series, Springer,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A guided tour of asynchronous cellular automata", "author": ["Nazim Fates"], "venue": "In Cellular Automata and Discrete Complex Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Toward a formal characterization of real-world general intelligence", "author": ["B. Goertzel"], "venue": "The Third Conference on Artificial General Intelligence (AGI 2010), pages 19\u201324. Citeseer,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Toward a roadmap for human-level artificial general intelligence: Embedding hlai systems in broad, approachable, physical or virtual contexts", "author": ["B. Goertzel", "I. Arel", "M. Scheutz"], "venue": "Artificial General Intelligence Roadmap Initiative,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Beyond the Turing Test", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "J. Logic, Language & Information, 9(4):447\u2013466,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "A computational definition of \u2018consilience", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "Philosophica, 61:901\u2013920,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2000}, {"title": "Computational measures of information gain and reinforcement in inference processes", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "AI Communications, 13(1):49\u201350,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "Constructive reinforcement learning", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "International Journal of Intelligent Systems, 15(3):241\u2013264,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2000}, {"title": "On the computational measurement of intelligence factors", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "A. Meystel, editor, Performance metrics for intelligent systems workshop, pages 1\u20138. National Institute of Standards and Technology, Gaithersburg, MD, U.S.A.,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2000}, {"title": "A (hopefully) non-biased universal environment class for measuring intelligence of biological and artificial systems", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "M. Hutter et al., editor, Artificial General Intelligence, 3rd Intl Conf, pages 182\u2013183. Atlantis Press, Extended report at http://users.dsic.upv.es/proy/anynt/unbiased.pdf,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "On environment difficulty and discriminating power", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "Autonomous Agents and Multi-Agent Systems, pages 1\u201353,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Measuring universal intelligence: Towards an anytime intelligence test", "author": ["J. Hern\u00e1ndez-Orallo", "D.L. Dowe"], "venue": "Artificial Intelligence, 174(18):1508 \u2013 1539,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "On potential cognitive abilities in the machine kingdom", "author": ["J. Hern\u00e1ndez-Orallo", "D.L. Dowe"], "venue": "Minds and Machines, 23:179\u2013210,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "On more realistic environment distributions for defining, evaluating and developing intelligence", "author": ["J. Hern\u00e1ndez-Orallo", "D.L. Dowe", "S. Espa\u00f1a-Cubillo", "M.V. Hern\u00e1ndez-Lloreda", "J. Insa-Cabrera"], "venue": "J. Schmidhuber, K.R. Th\u00f3risson, and M. Looks, editors, Artificial General Intelligence, volume 6830, pages 82\u201391. LNAI, Springer,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Universal psychometrics: Measuring cognitive abilities in the machine kingdom", "author": ["J. Hern\u00e1ndez-Orallo", "D.L. Dowe", "M.V. Hern\u00e1ndez-Lloreda"], "venue": "Cognitive Systems Research, 27:5074,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Explanatory and creative alternatives to the MDL priciple", "author": ["J. Hern\u00e1ndez-Orallo", "I. Gar\u0107\u0131a-Varea"], "venue": "Foundations of Science, 5(2):185\u2013207,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "Turing machines and recursive Turing Tests", "author": ["J. Hern\u00e1ndez-Orallo", "J. Insa-Cabrera", "D.L. Dowe", "B. Hibbard"], "venue": "V. Muller and A. Ayesh, editors, AISB/IACAP 2012 Symposium \u201cRevisiting Turing and his Test\u201d, pages 28\u201333. The Society for the Study of Artificial Intelligence and the Simulation of Behaviour,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Turing Tests with Turing machines", "author": ["J. Hern\u00e1ndez-Orallo", "J. Insa-Cabrera", "D.L. Dowe", "B. Hibbard"], "venue": "Andrei Voronkov, editor, Turing-100, volume 10, pages 140\u2013156. EPiC Series,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "A formal definition of intelligence based on an intensional variant of Kolmogorov complexity", "author": ["J. Hern\u00e1ndez-Orallo", "N. Minaya-Collado"], "venue": "Proc. Intl Symposium of Engineering of Intelligent Systems (EIS\u201998), pages 146\u2013163. ICSC Press,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1998}, {"title": "Universal and cognitive notions of part", "author": ["Jos\u00e9 Hern\u00e1ndez-Orallo"], "venue": "Proceedings of 4th Systems Science European Congress,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1999}, {"title": "AI evaluation: past, present and future", "author": ["Jos\u00e9 Hern\u00e1ndez-Orallo"], "venue": "arXiv preprint arXiv:1408.6908,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Bias and no free lunch in formal measures of intelligence", "author": ["B. Hibbard"], "venue": "Journal of Artificial General Intelligence, 1(1):54\u201361,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "The fastest and shortest algorithm for all well-defined problems", "author": ["M. Hutter"], "venue": "International Journal of Foundations of Computer Science, 13(03):431\u2013443,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability", "author": ["M. Hutter"], "venue": "Springer,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2005}, {"title": "On measuring social intelligence: Experiments on competition and cooperation", "author": ["J. Insa-Cabrera", "J.L. Benacloch-Ayuso", "J. Hern\u00e1ndez-Orallo"], "venue": "J. Bach, B. Goertzel, and M. Ikl\u00e9, editors, AGI, volume 7716 of Lecture Notes in Computer Science, pages 126\u2013135. Springer,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}, {"title": "Comparing humans and AI agents", "author": ["J. Insa-Cabrera", "D.L. Dowe", "S. Espa\u00f1a-Cubillo", "M.V. Hern\u00e1ndez-Lloreda", "J. Hern\u00e1ndez-Orallo"], "venue": "J. Schmidhuber, K.R. Th\u00f3risson, and M. Looks, editors, Artificial General Intelligence, volume 6830, pages 122\u2013132. LNAI, Springer,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Evaluating a reinforcement learning algorithm with a general intelligence test", "author": ["J. Insa-Cabrera", "D.L. Dowe", "J. Hern\u00e1ndez-Orallo"], "venue": "J.A. Moreno J.A. Lozano, J.A. Gamez, editor, Current Topics in Artificial Intelligence. CAEPIA 2011. LNAI Series 7023, Springer,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2011}, {"title": "Definition and properties to assess multi-agent environments as social intelligence tests", "author": ["J. Insa-Cabrera", "J. Hern\u00e1ndez-Orallo"], "venue": "arXiv preprint, http://arxiv.org/abs/1408.6350,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Hern\u00e1ndez-Lloreda. The anynt project intelligence test : Lambda - one", "author": ["J. Insa-Cabrera", "J. Hern\u00e1ndez-Orallo", "D.L. Dowe", "S. Espa na", "M.V"], "venue": "AISB/IACAP 2012 Symposium \u201cRevisiting Turing and his Test\u201d,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}, {"title": "Understanding of the concept of numerically \u2018less\u2019 by bottlenose dolphins (tursiops truncatus)", "author": ["Kelly Jaakkola", "Wendi Fellner", "Linda Erb", "Mandy Rodriguez", "Emily Guarino"], "venue": "Journal of Comparative Psychology,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2005}, {"title": "Universal intelligence: A definition of machine intelligence", "author": ["S. Legg", "M. Hutter"], "venue": "Minds and Machines, 17(4):391\u2013444,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "An approximation of the universal intelligence measure", "author": ["S. Legg", "J. Veness"], "venue": "Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence, pages 236\u2013249. Springer,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Universal sequential search problems", "author": ["L.A. Levin"], "venue": "Problems of Information Transmission, 9(3):265\u2013266,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1973}, {"title": "An introduction to Kolmogorov complexity and its applications (3rd ed.)", "author": ["M. Li", "P. Vit\u00e1nyi"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2008}, {"title": "Task complexity: A review and conceptualization framework", "author": ["Peng Liu", "Zhizhong Li"], "venue": "International Journal of Industrial Ergonomics,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2012}, {"title": "The Turing ratio: Metrics for open-ended tasks", "author": ["H. Masum", "S. Christensen", "F. Oppacher"], "venue": "GECCO, pages 973\u2013980. Citeseer,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2002}, {"title": "Minimal history, a theory of plausible explanation", "author": ["J.E. Mayfield"], "venue": "Complexity, 12(4):48\u201353,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2007}, {"title": "Putting the elephant back in the herd: elephant relative quantity judgments match those of other species", "author": ["Bonnie M Perdue", "Catherine F Talbot", "Adam M Stone", "Michael J Beran"], "venue": "Animal cognition,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2012}, {"title": "Accelerating progress in artificial general intelligence: Choosing a benchmark for natural world interaction", "author": ["B. Rohrer"], "venue": "J. of Artificial General Intelligence, 2(1):1\u201328,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2010}, {"title": "A computer program capable of passing IQ tests", "author": ["P. Sanghi", "D.L. Dowe"], "venue": "4th Intl. Conf. on Cognitive Science (ICCS\u201903), Sydney, pages 570\u2013575,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2003}, {"title": "Metalearning", "author": ["T. Schaul", "J. Schmidhuber"], "venue": "Scholarpedia, 5(6):4650,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimal ordered problem solver", "author": ["J. Schmidhuber"], "venue": "Machine Learning, 54(3):211\u2013254,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2004}, {"title": "G\u00f6del machines: Fully self-referential optimal universal self-improvers", "author": ["J. Schmidhuber"], "venue": "Artificial general intelligence, pages 199\u2013226. Springer,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2007}, {"title": "Tutorial on structured continuous-time Markov processes", "author": ["Christian R Shelton", "Gianfranco Ciardo"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2014}, {"title": "PAC model-free reinforcement learning", "author": ["A.L. Strehl", "L. Li", "E. Wiewiora", "J. Langford", "M.L. Littman"], "venue": "Proc. of the 23rd Intl Conf on Machine learning, ICML \u201906, pages 881\u2013888, New York,", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2006}, {"title": "American Council on Education for college freshmen: Manual of Instructions", "author": ["L.L. Thurstone", "T.G. Thurstone"], "venue": "Cooperative Test Division, Educational Testing Service,", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1947}, {"title": "Intelligent machinery, a heretical theory", "author": ["A.M. Turing"], "venue": "The Turing Test: Verbal Behavior as the Hallmark of Intelligence, page 105,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1948}, {"title": "A theory of the learnable", "author": ["L.G. Valiant"], "venue": "Communications of the ACM, 27(11):1134\u20131142,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1984}, {"title": "Probably Approximately Correct: Nature\u00d5s Algorithms for Learning and Prospering in a Complex World", "author": ["Leslie Valiant"], "venue": "Basic Books,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2013}, {"title": "A Monte Carlo AIXI Approximation", "author": ["J. Veness", "K.S. Ng", "M. Hutter", "D. Silver"], "venue": "Journal of Artificial Intelligence Research, JAIR, 40:95\u2013142,", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2011}, {"title": "Normalized information distance", "author": ["Paul MB Vit\u00e1nyi", "Frank J Balbach", "Rudi L Cilibrasi", "Ming Li"], "venue": "In Information theory and statistical learning,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2009}, {"title": "Bears \u2018count\u2019 too: quantity estimation and comparison in black bears, ursus americanus", "author": ["Jennifer Vonk", "Michael J Beran"], "venue": "Animal behaviour,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2012}, {"title": "Q-learning", "author": ["C.J.C.H. Watkins", "P. Dayan"], "venue": "Machine learning, 8(3):279\u2013292,", "citeRegEx": "63", "shortCiteRegEx": null, "year": 1992}], "referenceMentions": [{"referenceID": 23, "context": "In the context of universal psychometrics [25], defined as the evaluation of cognitive features of humans, non-human animals, computers, hybrids and collectives thereof, the notion of \u2018cognitive task\u2019 was introduced and formalised, but several issues still require further development, such as the associated concepts of task difficulty and task breadth (or alternative concepts such as composition and decomposition).", "startOffset": 42, "endOffset": 46}, {"referenceID": 55, "context": "With this representation, the straightforward idea of difficulty as search effort is used, whatever the kind of search is (\u201cintellectual\u201d, \u201cevolutionary\u201d or \u201ccultural\u201d, as Turing distinguished [57]).", "startOffset": 193, "endOffset": 197}, {"referenceID": 41, "context": "This is in accordance with Levin\u2019s universal search [43, 44], the notion of information gain [17] and the interpretation of the \u201cminimal process for creating [something] from nothing\u201d [47].", "startOffset": 52, "endOffset": 60}, {"referenceID": 42, "context": "This is in accordance with Levin\u2019s universal search [43, 44], the notion of information gain [17] and the interpretation of the \u201cminimal process for creating [something] from nothing\u201d [47].", "startOffset": 52, "endOffset": 60}, {"referenceID": 15, "context": "This is in accordance with Levin\u2019s universal search [43, 44], the notion of information gain [17] and the interpretation of the \u201cminimal process for creating [something] from nothing\u201d [47].", "startOffset": 93, "endOffset": 97}, {"referenceID": 45, "context": "This is in accordance with Levin\u2019s universal search [43, 44], the notion of information gain [17] and the interpretation of the \u201cminimal process for creating [something] from nothing\u201d [47].", "startOffset": 184, "endOffset": 188}, {"referenceID": 23, "context": "In [25], tasks are defined as interactive processes with asynchronous time where the final response is not necessarily a function of rewards.", "startOffset": 3, "endOffset": 7}, {"referenceID": 38, "context": "What do Talon the dolphin in Florida Keys [40] and Ana the sea lion in Valencia [1] have in common? Both have been tested about their ability to judge relative quantity, a task that is usually referred to as \u201crelative numerousness\u201d, \u201crelative numerosity\u201d or \u201crelative quantity judgment\u201d.", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "What do Talon the dolphin in Florida Keys [40] and Ana the sea lion in Valencia [1] have in common? Both have been tested about their ability to judge relative quantity, a task that is usually referred to as \u201crelative numerousness\u201d, \u201crelative numerosity\u201d or \u201crelative quantity judgment\u201d.", "startOffset": 80, "endOffset": 83}, {"referenceID": 0, "context": ", [1, 48, 62], to links to some of these studies).", "startOffset": 2, "endOffset": 13}, {"referenceID": 46, "context": ", [1, 48, 62], to links to some of these studies).", "startOffset": 2, "endOffset": 13}, {"referenceID": 60, "context": ", [1, 48, 62], to links to some of these studies).", "startOffset": 2, "endOffset": 13}, {"referenceID": 52, "context": "Note that there is a long tradition of discrete time in AI, especially in reinforcement learning, although the use of continuous time environments has also been studied in the areas of intelligent control and also in various kinds of reinforcement learning [54].", "startOffset": 257, "endOffset": 261}, {"referenceID": 52, "context": "Apart from its need in these types of tasks, there are additional reasons for using asynchronous time in reinforcement learning [54], and artificial life [8, 12].", "startOffset": 128, "endOffset": 132}, {"referenceID": 6, "context": "Apart from its need in these types of tasks, there are additional reasons for using asynchronous time in reinforcement learning [54], and artificial life [8, 12].", "startOffset": 154, "endOffset": 161}, {"referenceID": 10, "context": "Apart from its need in these types of tasks, there are additional reasons for using asynchronous time in reinforcement learning [54], and artificial life [8, 12].", "startOffset": 154, "endOffset": 161}, {"referenceID": 23, "context": "This is similar to the way rewards were defined in [25], an internal thing given to the agent, whereas the score or response for the episode was an external thing not necessarily given to the agent.", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": ", deep learning [3]), many repetitions (e.", "startOffset": 16, "endOffset": 19}, {"referenceID": 61, "context": ", Q-learning [63]) or large \u03c4 (e.", "startOffset": 13, "endOffset": 17}, {"referenceID": 58, "context": ", AIXI [60]).", "startOffset": 7, "endOffset": 11}, {"referenceID": 43, "context": "The difficulty of solving a stochastic task can be assessed by [45] (1) looking at the complexity of the task (this is known as a structuralist approach), (2) looking at the complexity of the policy (or the resources that are required by the subject) or (3) looking at the interaction between task and subject.", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": "To avoid this problem another option is to calculate the maximum, as done in [22] with the so-called Kt.", "startOffset": 77, "endOffset": 81}, {"referenceID": 41, "context": ", [43] or [44]), is to define:", "startOffset": 2, "endOffset": 6}, {"referenceID": 42, "context": ", [43] or [44]), is to define:", "startOffset": 10, "endOffset": 14}, {"referenceID": 32, "context": "5In a way, this strategy is like an AIXI-like algorithm [34].", "startOffset": 56, "endOffset": 60}, {"referenceID": 15, "context": "in [17].", "startOffset": 3, "endOffset": 7}, {"referenceID": 58, "context": "6In a way, this strategy is like an AIXItl-like algorithm [60].", "startOffset": 58, "endOffset": 62}, {"referenceID": 41, "context": "Anyway, the use of Kt is related to Levin\u2019s universal search [43, 44], as if we measure the computational steps that are required to find the algorithm that minimises Kt we have to go approximately through 2 programs with their corresponding execution steps of S.", "startOffset": 61, "endOffset": 69}, {"referenceID": 42, "context": "Anyway, the use of Kt is related to Levin\u2019s universal search [43, 44], as if we measure the computational steps that are required to find the algorithm that minimises Kt we have to go approximately through 2 programs with their corresponding execution steps of S.", "startOffset": 61, "endOffset": 69}, {"referenceID": 5, "context": "Some other approaches also link the difficulty of an instance or problem to the \u201cprobability of failure\u201d [7] or to the \u201cprobability-of-failure and mean time-to-solution\u201d [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 3, "context": "Some other approaches also link the difficulty of an instance or problem to the \u201cprobability of failure\u201d [7] or to the \u201cprobability-of-failure and mean time-to-solution\u201d [4].", "startOffset": 170, "endOffset": 173}, {"referenceID": 5, "context": "The probability of failure can be defined in terms of one policy (so we would have again a notion of difficulty dependent to the best policy solving the task), but another perspective is \u201cthe likelihood that a randomly chosen program will fail for any given input value\u201d [7].", "startOffset": 271, "endOffset": 274}, {"referenceID": 0, "context": "\u03b50\u2208[0,1] (4)", "startOffset": 3, "endOffset": 8}, {"referenceID": 14, "context": "This is closely related to concepts such as consilience, coherence and intensionality [16, 26, 30, 18, 17].", "startOffset": 86, "endOffset": 106}, {"referenceID": 24, "context": "This is closely related to concepts such as consilience, coherence and intensionality [16, 26, 30, 18, 17].", "startOffset": 86, "endOffset": 106}, {"referenceID": 28, "context": "This is closely related to concepts such as consilience, coherence and intensionality [16, 26, 30, 18, 17].", "startOffset": 86, "endOffset": 106}, {"referenceID": 16, "context": "This is closely related to concepts such as consilience, coherence and intensionality [16, 26, 30, 18, 17].", "startOffset": 86, "endOffset": 106}, {"referenceID": 15, "context": "This is closely related to concepts such as consilience, coherence and intensionality [16, 26, 30, 18, 17].", "startOffset": 86, "endOffset": 106}, {"referenceID": 54, "context": "For instance, in a task where the agent has to guess the following symbol in a letter series, such as the task \u03bcCtest in Table 1 or Thurstone\u2019s letter series [56], we may wonder why the series aaaaaaa seems easier than aacaeag.", "startOffset": 158, "endOffset": 162}, {"referenceID": 48, "context": "This is exactly what the program passing IQ tests from [50] did, using some predefined rules for some common sequences.", "startOffset": 55, "endOffset": 59}, {"referenceID": 27, "context": "As we mentioned above, there is a connection between the logarithm of the steps required by Levin\u2019s search and Kt, the measure of instance difficulty that was used in the C-test [29, 15].", "startOffset": 178, "endOffset": 186}, {"referenceID": 13, "context": "As we mentioned above, there is a connection between the logarithm of the steps required by Levin\u2019s search and Kt, the measure of instance difficulty that was used in the C-test [29, 15].", "startOffset": 178, "endOffset": 186}, {"referenceID": 0, "context": "In particular, the composition of tasks \u03bc1 and \u03bc2 with weight \u03b1 \u2208 [0, 1], denoted by \u03b1\u03bc1\u2295 (1\u2212\u03b1)\u03bc2, is defined by a stochastic choice, using a biased coin (e.", "startOffset": 66, "endOffset": 72}, {"referenceID": 59, "context": "These ideas and properties can be related to concepts such as (normalised) information distance [6, 61], especially the similarity of two tasks, with the appropriate caution, as here we are talking about interactive tasks and we are using the complexity of the policies and not the complexity of the description of the tasks.", "startOffset": 96, "endOffset": 103}, {"referenceID": 4, "context": ", [5]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 12, "context": "There have been several (informal) approaches or expressions of relevance of task breadth [14, 49] or the notion of intellectual breadth (though applied to an agent [13] and not to a task).", "startOffset": 90, "endOffset": 98}, {"referenceID": 47, "context": "There have been several (informal) approaches or expressions of relevance of task breadth [14, 49] or the notion of intellectual breadth (though applied to an agent [13] and not to a task).", "startOffset": 90, "endOffset": 98}, {"referenceID": 11, "context": "There have been several (informal) approaches or expressions of relevance of task breadth [14, 49] or the notion of intellectual breadth (though applied to an agent [13] and not to a task).", "startOffset": 165, "endOffset": 169}, {"referenceID": 44, "context": "Some of them are relative to other tasks or to humans, such as the one suggested (but not fully developed) with the Turing Ratio [46].", "startOffset": 129, "endOffset": 133}, {"referenceID": 23, "context": "This can be done with the so-called agent response curves, introduced in [25] following the notion of item response curves in psychometrics.", "startOffset": 73, "endOffset": 77}, {"referenceID": 45, "context": "11[47] says \u201cthis allows time to be measured in bits\u201d, but I think that this is misleading, as there is more information involved.", "startOffset": 2, "endOffset": 6}, {"referenceID": 55, "context": "We must also bear in mind that we are focussing on a view of difficulty when the policy is found by search (be it \u201cintellectual\u201d, \u201cevolutionary\u201d or \u201ccultural\u201d, as Turing distinguished [57]).", "startOffset": 184, "endOffset": 188}, {"referenceID": 31, "context": "12There are some variants and adaptations of Levin search for interactive scenarios and MDPs [33, 52, 34, 53, 51].", "startOffset": 93, "endOffset": 113}, {"referenceID": 50, "context": "12There are some variants and adaptations of Levin search for interactive scenarios and MDPs [33, 52, 34, 53, 51].", "startOffset": 93, "endOffset": 113}, {"referenceID": 32, "context": "12There are some variants and adaptations of Levin search for interactive scenarios and MDPs [33, 52, 34, 53, 51].", "startOffset": 93, "endOffset": 113}, {"referenceID": 51, "context": "12There are some variants and adaptations of Levin search for interactive scenarios and MDPs [33, 52, 34, 53, 51].", "startOffset": 93, "endOffset": 113}, {"referenceID": 49, "context": "12There are some variants and adaptations of Levin search for interactive scenarios and MDPs [33, 52, 34, 53, 51].", "startOffset": 93, "endOffset": 113}, {"referenceID": 27, "context": "This is related to unquestionability, as whether there are competing programs of similar complexity is relevant, as in [29, 15].", "startOffset": 119, "endOffset": 127}, {"referenceID": 13, "context": "This is related to unquestionability, as whether there are competing programs of similar complexity is relevant, as in [29, 15].", "startOffset": 119, "endOffset": 127}, {"referenceID": 23, "context": "These ideas are an evolution and continuation of early notions of task and difficulty in [25] and [21] respectively.", "startOffset": 89, "endOffset": 93}, {"referenceID": 19, "context": "These ideas are an evolution and continuation of early notions of task and difficulty in [25] and [21] respectively.", "startOffset": 98, "endOffset": 102}, {"referenceID": 14, "context": "There have been some early approaches where the role of Kt has been explored for different kinds of optimisation or inference problems [16, 26, 30, 18, 17].", "startOffset": 135, "endOffset": 155}, {"referenceID": 24, "context": "There have been some early approaches where the role of Kt has been explored for different kinds of optimisation or inference problems [16, 26, 30, 18, 17].", "startOffset": 135, "endOffset": 155}, {"referenceID": 28, "context": "There have been some early approaches where the role of Kt has been explored for different kinds of optimisation or inference problems [16, 26, 30, 18, 17].", "startOffset": 135, "endOffset": 155}, {"referenceID": 16, "context": "There have been some early approaches where the role of Kt has been explored for different kinds of optimisation or inference problems [16, 26, 30, 18, 17].", "startOffset": 135, "endOffset": 155}, {"referenceID": 15, "context": "There have been some early approaches where the role of Kt has been explored for different kinds of optimisation or inference problems [16, 26, 30, 18, 17].", "startOffset": 135, "endOffset": 155}, {"referenceID": 17, "context": "The disposition and arrangement of tasks was discussed in [19], as well as the notion of task or agent breadth [46, 14, 49], and the distinction between specific and general [31].", "startOffset": 58, "endOffset": 62}, {"referenceID": 44, "context": "The disposition and arrangement of tasks was discussed in [19], as well as the notion of task or agent breadth [46, 14, 49], and the distinction between specific and general [31].", "startOffset": 111, "endOffset": 123}, {"referenceID": 12, "context": "The disposition and arrangement of tasks was discussed in [19], as well as the notion of task or agent breadth [46, 14, 49], and the distinction between specific and general [31].", "startOffset": 111, "endOffset": 123}, {"referenceID": 47, "context": "The disposition and arrangement of tasks was discussed in [19], as well as the notion of task or agent breadth [46, 14, 49], and the distinction between specific and general [31].", "startOffset": 111, "endOffset": 123}, {"referenceID": 29, "context": "The disposition and arrangement of tasks was discussed in [19], as well as the notion of task or agent breadth [46, 14, 49], and the distinction between specific and general [31].", "startOffset": 174, "endOffset": 178}, {"referenceID": 39, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 30, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 20, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 18, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 35, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 22, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 9, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 25, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 26, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 33, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 34, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 37, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 7, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 40, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 8, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 21, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 36, "context": "The notions introduced in this paper, and the expression for difficulty can be useful to reunderstand some of the recent contributions in the evaluation of intelligence [41, 32, 22, 20, 37, 24, 11, 27, 28, 35, 36, 39, 9, 42, 10, 23, 38].", "startOffset": 169, "endOffset": 236}, {"referenceID": 15, "context": "However, some works have incorporated it as well in other inference problems, such as induction and optimisation, using Levin\u2019s Kt [17, 47, 2].", "startOffset": 131, "endOffset": 142}, {"referenceID": 45, "context": "However, some works have incorporated it as well in other inference problems, such as induction and optimisation, using Levin\u2019s Kt [17, 47, 2].", "startOffset": 131, "endOffset": 142}, {"referenceID": 1, "context": "However, some works have incorporated it as well in other inference problems, such as induction and optimisation, using Levin\u2019s Kt [17, 47, 2].", "startOffset": 131, "endOffset": 142}, {"referenceID": 53, "context": "Also, while our use of \u2018PAC\u2019 is just superficially related to PAC learning, we may have a closer look as this, in particular in the context of PAC reinforcement learning [55].", "startOffset": 170, "endOffset": 174}], "year": 2015, "abstractText": "This note revisits the concepts of task and difficulty. The notion of cognitive task and its use for the evaluation of intelligent systems is still replete with issues. The view of tasks as MDP in the context of reinforcement learning has been especially useful for the formalisation of learning tasks. However, this alternate interaction does not accommodate well for some other tasks that are usual in artificial intelligence and, most especially, in animal and human evaluation. In particular, we want to have a more general account of episodes, rewards and responses, and, most especially, the computational complexity of the algorithm behind an agent solving a task. This is crucial for the determination of the difficulty of a task as the (logarithm of the) number of computational steps required to acquire an acceptable policy for the task, which includes the exploration of policies and their verification. We introduce a notion of asynchronous-time stochastic tasks. Based on this interpretation, we can see what task difficulty is, what instance difficulty is (relative to a task) and also what task compositions and decompositions are.", "creator": "LaTeX with hyperref package"}}}