{"id": "1503.07715", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2014", "title": "The Computational Theory of Intelligence: Data Aggregation", "abstract": "In this paper, we will expound upon the concepts proffered in [1], where we proposed an information theoretic approach to intelligence in the computational sense. We will examine data and meme aggregation, and study the effect of limited resources on the resulting meme amplitudes.", "histories": [["v1", "Wed, 24 Dec 2014 07:47:46 GMT  (8kb)", "http://arxiv.org/abs/1503.07715v1", "Published in IJMNTA"]], "COMMENTS": "Published in IJMNTA", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["daniel kovach"], "accepted": false, "id": "1503.07715"}, "pdf": {"name": "1503.07715.pdf", "metadata": {"source": "CRF", "title": "The Computational Theory of Intelligence: Data Aggregation", "authors": ["Daniel Kovach"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 3.07 715v 1 [cs.A I] 2 4"}, {"heading": "1 Introduction", "text": "In this paper we will deepen this discussion and offer some new insights. We discussed how intelligence can be thought of as an entropy-minimizing process, but this entropy-minimizing process comes at a cost. Remember [5, 7] that whenever a system is brought from a state of higher entropy to a state of lower entropy, there is always a certain amount of energy involved in this transition, and an increase in the entropy of the rest of the environment that is greater or equal to entropy loss. [7] The negative change in entropy requires a certain amount of work. The central concept of this paper concerns how smaller concepts aggregate into larger and more complex structures, a process that is a function of the complexity of each element and the energy available to the system. The complexity of the components will delegate the degree of freedom that is available."}, {"heading": "2 Creating Structure", "text": "In practically all facets of nature, more complicated structures are formed by less complicated structures, after the addition of a certain amount of energy. Suppose that set C contains I components, each of which has a certain amount of degrees of freedom J, as expressed in the notation: cij, i, i, 0,.., I, j, 0,... J. A carbon atom, for example, has four valence electrons available for the formation of bonds. Note that cij, c need not be homogeneous, since (in our example from chemistry) a carbon atom is free to form bonds with other elements and molecules. We will call the aggregation of these components a meme, a term coined by Richard Dawkins in The Selfish Genes, [6]. Let us further assume that with each of these degrees of freedom, j, a certain amount of energy is required to participate in the formation of a more complicated structure, and all degrees of freedom cannot be linear."}, {"heading": "2.1 Applications to Data Mining", "text": "In order to make sense of a dataset, we need to determine the elements that are correlated and therefore have minimal entropy relative to the others, some of which will participate, some of which will have no relevance at all, and some of which may contain no information at all, as is the case with sparse datasets. It is an active field of research to sift out data with a higher information content for classification or clustering, and processes such as PCA or Cholesky transformation are used to reduce the amount of attribute vectors for classification and to find a basis for transformation, which has a clearly defined interpretation in linear algebra, although we argue that information content can be another potential approach. It is not uncommon to deal with datasets in such a way that each element is characterized by thousands or hundreds of thousands of feature vectors or more."}, {"heading": "3 Meme Amplitude", "text": "Now that we have determined the total energy required for a meme to reach the next state, let's talk about the transition from one state to another. In this case, we can talk about relative energy, He or the initial energy less. Let's further assume that this He can be described by a function, y, which we can also call the meme amplitude. Let's consider some considerations for y \"(t). The rate of change in y (t) is almost certainly proportional to y (t) itself, since the rate of change in the energy of the system should be proportional to the one it already has. If we take into account a constant of proportionality that we will call affinity A, then we have the well-known y\" = Er \"as the starting limit, but bearing in mind that\" E \"is a limit to bitterness, we have the familiar logistical equation that we should conclude."}, {"heading": "3.1 Solutions", "text": "Equation 2 is well researched, and its solutions fall into a broad class of functions known as sigmoid functions, known for their characteristic \"S\" shape [11], whose applications range from their use as cumulative distribution functions in probability and statistics to activation functions in artificial neural networks. Due to the first boundary condition, we limit the solution to t \u2265 0, which cuts off the left side of this \"S\" shape, or translate the entire curve so that the lower Aymptote is reasonably close to t = 0."}, {"heading": "3.1.1 Growth Rate", "text": "As the A curve increases, the curve becomes steeper and the time to reach the memamplitude decreases. We use the term aggressively to refer to the large A curve. If the A curve is drastically large, the sigmoid curve approaches a step function. A also depends on the energy supplied to the system, EA, and will itself have its own boundary conditions, since the dynamics described by 2 often collapse for EA-E. Carbon, for example, forms graphite at (relatively) low energies, but at higher energies diamonds. This is a function of the amount of valence electrons used in the binding process (3 or 4 for graphite and diamond, respectively). A similar analogy can be made for data and the computational effort we are willing to put into the algorithm of entropic self-organization."}, {"heading": "3.1.2 Amplitude", "text": "The meme amplitude is certainly not limited to a single meme amplitude, at least not in the general case. Once the transition He \u2192 \u2206 E is made, we are free to successively apply the logic to determine the next successive meme amplitude, etc. We will call the repeated demonstration of meme amplitude growth over 2 the hierarchical aggregation paradigm."}, {"heading": "3.1.3 Extrema", "text": "Although the solutions for 2 monotonously increase, some subtle nuances in their curvature offer useful insights. Consider the second derivative, which can be easily derived from 2y \u2032 = (A-E) 2y (E-2y) (E-E-2y) (E-y) (3). The second rate of change occurs at the roots of this equation, the y = 0, 12-E, E-E. The first and last are clearly the asymmetries when the energy decreases. It is the middle root that is of interest. Finally, if sustainable growth is to take place, there must be a transition in the sign of growth rate. This happens at y = 12-E."}, {"heading": "3.2 Stability and Sustainability", "text": "Although affinity is often considered constant to facilitate calculations and estimates, it can actually be a function of the applied energy and be valid in a kind of threshold. If the applied energy level is outside this threshold, the model collapses. Furthermore, once the affinity has been established, we can be used as an indicator of stability that the transition to the next energy level will occur. If we ignore the differences between the model 2 and the observed data, we can get an idea of whether this transition will occur, or whether the model will return to its previous energy state, or even to a subsequent one. If we remove the threshold state, Equation 2 will simply be comesy \u2032 = Ay (4), whose solutions are exponential to the positives A. However, unlimited growth is untenable and leads to unpredictable behavior. If we observe the behavior described in 4 as opposed to 2."}, {"heading": "3.3 Bubbles", "text": "Our discussion in Section 3.2 has many applications and is particularly important for society over the last five years. We can cite examples of real estate, financial markets and population growth. Indeed, this math can be used to identify sustained growth or bubbles, periods of exceptional inflation growth followed by abject collapse. Consider, for example, the well-studied behavior in the growth of bacterial colonies. There is an initial lag period when the RNA of the bacteria begins to copy, followed by an explosion of exponential growth, the so-called growth phase, followed by a brief period of stability before the bacteria deplete their resources, resulting in a purposeful decay."}, {"heading": "3.3.1 Determining Bubbles", "text": "It may be difficult to determine whether a given dataset is an emerging bubble or the initial stages of a stable transition, although by applying two observations discussed in this paper we can gain insights. Firstly, if we are able to calculate the affinity constant and activation energy, and we notice a discrepancy in the dynamics of the system and what was predicted on the basis of these constants, then we may have reason to believe that a bubble may form. Bubbles are caused by disproportionately excessive growth or by extransient factors distorting the dynamics of the system, but such factors are not permanent and finally, the true dynamics of the system will prevail. At this point, the system will fall into its natural energy state, which corresponds to our calculations and which is capable of supporting the system.Secondly, we consider the rate of change. Finally, we may not rely on the subtle inner workings of the system to calculate the necessary parameters."}, {"heading": "3.3.2 Outliers", "text": "The difficulty of calculating the activation energy of large and complex systems should be emphasized. Finally, there can be a number of factors influencing the overall dynamics of the model, and they can be highly nonlinear."}, {"heading": "4 Competing Memes", "text": "To repeat the logic of section 3, we must introduce the interaction matrix \u03b1ij, which represents the effect that meme i has on meme j. Among the mechanisms underlying these \u03b1ij's are resource allocation and direct competition. Thus, in the presence of N memes, 2 become comesdyidt = Ai-N-j\u03b1ijyj (5), in which the constant \"egg\" can be absorbed into the interaction matrix without having a functional effect on the resulting solutions [1]. Therefore, 5 become comesdyidt = Aiyi (1 \u2212 N-j\u03b1ijyj) (6), which is recognized as the Lotka-Volterra equation, commonly referred to as the \"competitive equation.\""}, {"heading": "5 Conclusion", "text": "In essence, the subject of this paper could be summarized as follows: how data merge into more complex memes, how this is caused by the presence of multiple memes, and under what conditions this transition parameter may not be stable. We have also looked at some practical examples of these principles in the source code. There is still a lot of room for future improvement. First, we can improve our understanding of affinity parameter A. We can also apply this knowledge to other areas of study to effectively calculate predictable amplitude transitions, burgeoning growth, or bubble formation. Furthermore, we would also like to examine the most basic layers of meme aggregation and creation, the basic components of how they evolve into systems, and how these systems can aggregate hierarchically, as meme amplitude growth is described."}], "references": [{"title": "Extinction in Nonautonomous T-periodic Competitive Lotka- Volterra System.", "author": ["S. Ahmad"], "venue": "Applied Mathematics and Computation", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "On the Nonautonomous Volterra-Lotka Competition Equations.", "author": ["Ahmad", "Shair"], "venue": "Proceedings of the American Mathematical Society", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1993}, {"title": "Stable Periodic Solution of a Discrete Periodic Lotka\u2013Volterra Competition System.", "author": ["Y. Chen"], "venue": "Journal of Mathematical Analysis and Applications", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Input Variable Selection for Feature Extraction in Classification Problems.", "author": ["Choi", "Sang-Il", "Jiyong Oh", "Chong-Ho Choi", "Chunghoon Kim"], "venue": "Signal Processing", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "The Computational Theory of Intelligence", "author": ["Kovach", "Daniel J", "Jr."], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "The Selfish Gene", "author": ["Dawkins", "Richard"], "venue": "Oxford: Oxford UP,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "An Introduction to Thermal Physics", "author": ["Schroeder", "Daniel V"], "venue": "San Francisco, CA: Addison Wesley,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Hill Climbing Algorithm", "author": ["Kovach", "Daniel J", "Jr."], "venue": "Kovach Technologies. N.p., n.d. Web", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Partial Permanence and Extinction in an Nspecies Nonautonomous Lotka\u2013Volterra Competitive System.", "author": ["J. Li", "J. Yan"], "venue": "Computers & Mathematics with Applications", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Differential Equations", "author": ["Farkas", "Mikl\u00f3s"], "venue": "Amsterdam: North-Holland Pub.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1977}, {"title": "A Necessary and Sufficient Condition for Permanence of a Lotka\u2013Volterra Discrete System with Delays.", "author": ["Y. Saito"], "venue": "Journal of Mathematical Analysis and Applications", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Generalized Stochastic Delay Lotka-Volterra Systems.", "author": ["Yin", "Juliang", "Xuerong Mao", "Fuke Wu"], "venue": "Stochastic Models", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Periodic Solution for a Two-Species Nonautonomous Competition Lotka\u2013Volterra Patch System with Time Delay,.", "author": ["Z. Zhang"], "venue": "Journal of Mathematical Analysis and Applications", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}], "referenceMentions": [{"referenceID": 4, "context": "Abstract In this paper, we will expound upon the concepts proffered in [5], where we proposed an information theoretic approach to intelligence in the computational sense.", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "In the previous paper [5], we laid the groundwork for what was referred to as computational intelligence (CI).", "startOffset": 22, "endOffset": 25}, {"referenceID": 4, "context": "Recall from [5, 7] that whenever a system is taken from a state of higher entropy to a state of lower entropy, there is always some amount of energy involved in this transition, and an increase in the entropy of the rest of the environment greater than or equal to that of the entropy loss [7].", "startOffset": 12, "endOffset": 18}, {"referenceID": 6, "context": "Recall from [5, 7] that whenever a system is taken from a state of higher entropy to a state of lower entropy, there is always some amount of energy involved in this transition, and an increase in the entropy of the rest of the environment greater than or equal to that of the entropy loss [7].", "startOffset": 12, "endOffset": 18}, {"referenceID": 6, "context": "Recall from [5, 7] that whenever a system is taken from a state of higher entropy to a state of lower entropy, there is always some amount of energy involved in this transition, and an increase in the entropy of the rest of the environment greater than or equal to that of the entropy loss [7].", "startOffset": 290, "endOffset": 293}, {"referenceID": 5, "context": "We shall call the aggregation of these constituents a meme, a term coined by Richard Dawkins in The Selfish Gene, [6].", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "It is not uncommon to deal with data sets such that each element is characterized by thousands or hundreds of thousands or feature vectors or more, [4].", "startOffset": 148, "endOffset": 151}, {"referenceID": 4, "context": "Under our framework here, using entropic self organization [5] the entropy contribution of redundant data would be very small, and that of random data", "startOffset": 59, "endOffset": 62}, {"referenceID": 9, "context": "1 Solutions Equation 2 has been well studied, and its solutions fall into a broad class of functions known as sigmoid functions known for their characteristic \u2019S\u2019 shape [11], and who\u2019s applications range from their use as cumulative distribution functions in probability and statistics to activation functions in artificial neural networks.", "startOffset": 169, "endOffset": 173}, {"referenceID": 0, "context": "where the constant\u25b3Ei can be absorbed into the interaction matrix without a functional effect on the resulting solutions [1].", "startOffset": 121, "endOffset": 124}, {"referenceID": 0, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 1, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 2, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 8, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 10, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 11, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 12, "context": "This is another very well studied class of differential equations for which results can be found in [1, 2, 3, 10, 12, 13, 14] just to name a few.", "startOffset": 100, "endOffset": 125}, {"referenceID": 4, "context": "In this paper , we discussed some ramifications of the original principal detailed in [5].", "startOffset": 86, "endOffset": 89}], "year": 2015, "abstractText": "In this paper, we will expound upon the concepts proffered in [5], where we proposed an information theoretic approach to intelligence in the computational sense. We will examine data and meme aggregation, and study the effect of limited resources on the resulting meme amplitudes.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}