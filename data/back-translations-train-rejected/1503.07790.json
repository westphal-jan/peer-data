{"id": "1503.07790", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2015", "title": "Transductive Multi-label Zero-shot Learning", "abstract": "Zero-shot learning has received increasing interest as a means to alleviate the often prohibitive expense of annotating training data for large scale recognition problems. These methods have achieved great success via learning intermediate semantic representations in the form of attributes and more recently, semantic word vectors. However, they have thus far been constrained to the single-label case, in contrast to the growing popularity and importance of more realistic multi-label data. In this paper, for the first time, we investigate and formalise a general framework for multi-label zero-shot learning, addressing the unique challenge therein: how to exploit multi-label correlation at test time with no training data for those classes? In particular, we propose (1) a multi-output deep regression model to project an image into a semantic word space, which explicitly exploits the correlations in the intermediate semantic layer of word vectors; (2) a novel zero-shot learning algorithm for multi-label data that exploits the unique compositionality property of semantic word vector representations; and (3) a transductive learning strategy to enable the regression model learned from seen classes to generalise well to unseen classes. Our zero-shot learning experiments on a number of standard multi-label datasets demonstrate that our method outperforms a variety of baselines.", "histories": [["v1", "Thu, 26 Mar 2015 17:12:34 GMT  (323kb,D)", "http://arxiv.org/abs/1503.07790v1", "12 pages, 6 figures, Accepted to BMVC 2014 (oral)"]], "COMMENTS": "12 pages, 6 figures, Accepted to BMVC 2014 (oral)", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["yanwei fu", "yongxin yang", "tim hospedales", "tao xiang", "shaogang gong"], "accepted": false, "id": "1503.07790"}, "pdf": {"name": "1503.07790.pdf", "metadata": {"source": "CRF", "title": "Transductive Multi-label Zero-shot Learning", "authors": ["Yanwei Fu", "Yongxin Yang", "Timothy Hospedales", "Tao Xiang", "Shaogang Gong"], "emails": ["y.fu@qmul.ac.uk", "yongxin.yang@qmul.ac.uk", "t.hospedales@qmul.ac.uk", "t.xiang@qmul.ac.uk", "s.gong@qmul.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are a kind of self-realization that is able to put themselves in the center. (...) It is as if they are able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...)"}, {"heading": "2 Related Work", "text": "In fact, it is a purely mental game, in which the aim is to find a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "3 Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Problem setup", "text": "Suppose we have two sets of data - source / auxiliary data set and target / test. The auxiliary data set S = {XS, YS, LS, WS} has nS training instances and the test set T = {XT, YT, LT, WT} has nT test instances. We use S = {1, \u00b7, nS} and U = {nS + 1, \u00b7 \u00b7 \u00b7, nT + nS} to denote the auxiliary and test record instances index set. XS = {x1, \u00b7, xnS} and XT = {xnS + 1, \u00b7 \u00b7, xnS + nT} are the raw data of all auxiliary data sets and test instances respectively. YS = [y1, \u00b7, ynS] and YT = [xynS + 1, \u00b7, ynS + nT] are the sectarian intermediate representations of each auxiliary data set and of our auxiliary \u00b7 \u00b7 nS + nT} are the raw data of all auxiliary data sets or test instances. YS = [y1, \u00b7 \u00b7, \u00b7, ynS = 1, ynS = 1."}, {"heading": "4 FU ET AL: TRANSDUCTIVE MULTI-LABEL ZERO-SHOT LEARNING", "text": "The possible text labels for each instance in LS and LT are called WS = {w1, \u00b7 \u00b7, wmS} or WT = {wmS + 1, \u00b7 \u00b7, wmS + mT}, where mS and mT are the total number of classes / labels in each record. If a markup space of mT binary labels is given, an instance xi can be tagged with any of the possible 2mT markup subsets, li = 0.1} 2mT, where li j = 1 means that instance i has the label j, and li j = 0 the opposite. When naming the power sets of text labels WS and WT as P (WS) and P (WT), we need to find the optimal class label column vector li for the i th test instance in the Power Set Space P (WT) for the multi-mark classification. At the training time, XS, YS, WS, WS, WT, WT and only their class XT and WT labels are predicted."}, {"heading": "3.2 Learning a semantic word space", "text": "The semantic representations YS and YT are the projection of each instance into a linguistic word vector space V. The semantic word vector space is learned by using the state-of-the-art language model of the skip program [22, 23] on all English Wikipedia articles1. Space V represents almost the entire available English vocabulary and is therefore potentially much more effective than human commentators in measuring subtle similarities and differences between any two text markups. Moreover, V encodes the syntactic and semantic regularities in language [23], enabling vector-oriented thinking due to its property of \"compositionality,\" which enables the critical ability to synthesize the exhaustive set of test label combinations P (WT). Note that cosmic distance is used in space V due to its robustness to noise labeling (22, 23]."}, {"heading": "3.3 Multi-output deep regression", "text": "We design a Multi-Output Deep Regression (Mul-DR) model f: X \u2192 V to predict the semantic representation of YT-V from images XT-X, where X is the space of raw pixel intensity values. Our Mul-DR is inspired by the recent success of deep revolutionary neural network functions (CNN) [18, 29] and the importance of modeling correlations within semantic representation. The Mul-DR model is a neural network consisting of nine layers: layer 1-5 are revolutionary layers; layer 6-8 are fully connected layers; layer 9 is the linear mapping layer with 100 least square regressors. Two key components contribute to the effectiveness of Mul-DR. The first component (layer 1-7) provides state-of-the-art feature extraction for many computer vision tasks [27]."}, {"heading": "3.4 Zero-shot multi-label prediction", "text": "In view of the fact that this is a \"label-label,\" it is possible to have a \"label-label\" label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-label-"}, {"heading": "3.5 Generalisation of multi-output deep regression", "text": "As described above, our framework consists of two key steps: applying the multi-output deep regression model q (Mul-DR) to obtain the estimated semantic representation Y-T, followed by applying either DMP or TraMP to predict LT. However, there is an unsolved problem, that is, our Mul-DR is learned from the auxiliary data with a different set of labels from the target / test data. Therefore, this projection model is not guaranteed to project a test image near its ground truth label vector in the semantic word space. For example, if our Mul-DR is learned to project images of cat and dog onto the word vector representation of \"cat\" and \"dog\" (v (\"cat\" dog \"), it cannot project exactly an image with a person and a chair onto its word vector representation of v (\" person \") x."}, {"heading": "4 Experiments", "text": "Datasets Two popular multi-label datasets - Natural Scene [33] and IAPRTC-12 [12] are used to evaluate our framework. Natural Scene consists of 2000 natural scene images, in which each image can be labeled as any combination of desert, mountain, sea, sunset and trees, and over 22% of the entire dataset is labeled multi-sided. For multi-label zero-shot learning on Natural Scene, we use a multi-class single-label dataset - Scene dataset [24] (a total of 2688 images) as an auxiliary dataset labeled with a non-overlapping set of labels such as road, coast and highway. IAPRTC-12 consists of 20,000 images and a total of 275 different labels. The labels are hierarchically divided into 6 main branches: humans, animals, food, nature, humans and others. Our experiments consider the subset of landscape-to be both the most common branches of this data set (about 9500 and 9500)."}, {"heading": "4.1 Experimental setup", "text": "Evaluation Measurands (a) Hamming Loss: it measures the percentage of mismatches between estimated and actual labels; (b) MicroF1 [16]: it measures both the micro-precision and micro-recall microaverage with equal importance; (c) Ranking Loss: it measures the number of label pairs that are misordered by comparing their confidence values with the labels of truth; (d) Average Precision: it measures the range below precision recall curves in the face of a league table of classes. These four criteria evaluate very different aspects of multi-label classification. Normally, very few algorithms can achieve the best performance on all metrics. High values are preferred for MicroF1 and AP and vice versa for the evaluation of labels (ranking and hamming loss)."}, {"heading": "4.2 Results", "text": "It is only a matter of time before that happens, that it happens."}, {"heading": "5 Conclusion and future work", "text": "It is somewhat surprising that it is possible to exploit the label correlation at test point in the zero-shot case - since there is no set of examples to learn random statistics in the conventional way. We achieve this by introducing new strategies to exploit the compositivity of the semantic word space and by transductively exploiting the unmarked test data. In addition to the proposed tailor-made multi-label algorithms - DMP and TraMP - our strategy could potentially help other existing multi-label algorithms to generalize the multi-label zero-shot learning problem. Finally, we find that many of the Power-Set P prototypes actually have an extremely low chance of occurring in the test dataset. They should not be viewed in the same way as the other more likely prototypes."}], "references": [{"title": "Recognition by components - a theory of human image understanding", "author": ["I. Biederman"], "venue": "Psychological Review,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1987}, {"title": "LIBSVM: a library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Cumulative attribute space for age and crowd density estimation", "author": ["Ke Chen", "Shaogang Gong", "Tao Xiang", "Chen Chang Loy"], "venue": "In CVPR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Learning with augmented class by exploiting unlabeled data", "author": ["Qing Da", "Yang Yu", "Zhi-Hua Zhou"], "venue": "In AAAI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "A kernel method for multi-labelled classification", "author": ["Andre Elisseeff", "Jason Weston"], "venue": "In NIPS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Learning visual attributes", "author": ["V. Ferrari", "A. Zisserman"], "venue": "In NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Devise: A deep visual-semantic embedding model andrea", "author": ["Andrea Frome", "Greg S. Corrado", "Jon Shlens", "Samy Bengio", "Jeffrey Dean", "Marc Aurelio Ranzato", "Tomas Mikolov"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Attribute learning for understanding unstructured social activity", "author": ["Yanwei Fu", "Timothy M. Hospedales", "Tao Xiang", "Shaogang Gong"], "venue": "In ECCV,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Learning multimodal latent attributes", "author": ["Yanwei Fu", "Timothy M. Hospedales", "Tao Xiang", "Shaogang Gong"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Transductive multi-view embedding for zero-shot recognition and annotation", "author": ["Yanwei Fu", "Timothy M. Hospedales", "Tao Xiang", "Zhengyong Fu", "Shaogang Gong"], "venue": "In ECCV,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Interestingness prediction by robust learning to rank", "author": ["Yanwei Fu", "Timothy M. Hospedales", "Tao Xiang", "Shaogang Gong", "Yuan Yao"], "venue": "In ECCV,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Analysis and Evaluation of Visual Information Systems Performance", "author": ["Michael Grubinger"], "venue": "PhD thesis, School of Computer Science and Mathematics, Faculty of Health,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Efficient max-margin multi-label classification with applications to zero-shot learning", "author": ["Bharath Hariharan", "S.V. Vishwanathan", "Manik Varma"], "venue": "Mach. Learn.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome Friedman"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Improving word representations via global context and multiple word prototypes", "author": ["Eric H. Huang", "Richard Socher", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In ACL,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Correlated label propagation with application to multi-label learning", "author": ["Feng Kang", "Rong Jin", "Rahul Sukthankar"], "venue": "In CVPR,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Transductive multilabel learning via label set propagation", "author": ["Xiangnan Kong", "M.K. Ng", "Zhi-Hua Zhou"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "venue": "In NIPS,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Learning to detect unseen object classes by between-class attribute transfer", "author": ["Christoph H. Lampert", "Hannes Nickisch", "Stefan Harmeling"], "venue": "In CVPR,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Attribute-based classification for zero-shot visual object categorization", "author": ["Christoph H. Lampert", "Hannes Nickisch", "Stefan Harmeling"], "venue": "IEEE TPAMI,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Re-id: Hunting attributes in the wild", "author": ["Ryan Layne", "Timothy M. Hospedales", "Shaogang Gong"], "venue": "In BMVC,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Efficient estimation of word representation in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In Proceedings of Workshop at ICLR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In NIPS,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "author": ["Aude Oliva", "Antonio Torralba"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Zero-shot learning with semantic output codes", "author": ["Mark Palatucci", "Geoffrey Hinton", "Dean Pomerleau", "Tom M. Mitchell"], "venue": "In NIPS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "A pac-bayesian bound for lifelong learning", "author": ["Anastasia Pentina", "Christoph H. Lampert"], "venue": "In ICML,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Cnn features off-theshelf : an astounding baseline for recognition", "author": ["Ali Sharif Razavian", "Josephine Sullivan", "Stefan Carlsson"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Evaluating knowledge transfer and zero-shot learning in a large-scale setting", "author": ["Marcus Rohrbach", "Michael Stark", "Bernt Schiele"], "venue": "In CVPR,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Pierre Sermanet", "David Eigen", "Xiang Zhang", "Michael Mathieu", "Rob Fergus", "Yann LeCun"], "venue": "In ICLR,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Augmented attribute representations", "author": ["Viktoriia Sharmanska", "Novi Quadrianto", "Christoph H. Lampert"], "venue": "In ECCV,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Zero-shot learning through cross-modal transfer", "author": ["Richard Socher", "Milind Ganjoo", "Hamsa Sridhar", "Osbert Bastani", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In NIPS,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Multi-label classification with unlabeled data: An inductive approach", "author": ["Le Wu", "Min-Ling Zhang"], "venue": "In ACML, pages 197\u2013212,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Ml-knn: A lazy learning approach to multi-label learning", "author": ["Min-Ling Zhang", "Zhi-Hua Zhou"], "venue": "Pattern Recognition,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2007}, {"title": "A review on multi-label learning algorithms", "author": ["Min-Ling Zhang", "Zhi-Hua Zhou"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2013}, {"title": "Hybrid decision tree", "author": ["Zhi-Hua Zhou", "Zhao-Qian Chen"], "venue": "Knowledge-Based Systems,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "There are around 30,000 human-distinguishable basic object classes [1] and many more subordinate ones.", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "This has recently been explored at large scale on ImageNet [7, 28].", "startOffset": 59, "endOffset": 66}, {"referenceID": 27, "context": "This has recently been explored at large scale on ImageNet [7, 28].", "startOffset": 59, "endOffset": 66}, {"referenceID": 21, "context": "This knowledge transfer is achieved using an intermediate semantic representation in the form of the skip-gram word vectors [22, 23] learned from linguistic knowledge bases.", "startOffset": 124, "endOffset": 132}, {"referenceID": 22, "context": "This knowledge transfer is achieved using an intermediate semantic representation in the form of the skip-gram word vectors [22, 23] learned from linguistic knowledge bases.", "startOffset": 124, "endOffset": 132}, {"referenceID": 26, "context": "Mul-DR is a 9 layer neural network that exploits the widely used convolutional neural network (CNN) layers [27], and includes two multi-output regression layers as the final layers.", "startOffset": 107, "endOffset": 111}, {"referenceID": 21, "context": "It learns from auxiliary data the explicit and direct mapping from raw image pixels to a linguistic representation defined by the skip-gram language model [22, 23].", "startOffset": 155, "endOffset": 163}, {"referenceID": 22, "context": "It learns from auxiliary data the explicit and direct mapping from raw image pixels to a linguistic representation defined by the skip-gram language model [22, 23].", "startOffset": 155, "endOffset": 163}, {"referenceID": 12, "context": "With this synthetic dataset, we are able to extend conventional multi-label algorithms [13, 17, 32, 34], to propose two new multi-label algorithms \u2013 direct multi-label zero-shot prediction (DMP) and transductive multi-label zero-shot prediction (TraMP).", "startOffset": 87, "endOffset": 103}, {"referenceID": 16, "context": "With this synthetic dataset, we are able to extend conventional multi-label algorithms [13, 17, 32, 34], to propose two new multi-label algorithms \u2013 direct multi-label zero-shot prediction (DMP) and transductive multi-label zero-shot prediction (TraMP).", "startOffset": 87, "endOffset": 103}, {"referenceID": 31, "context": "With this synthetic dataset, we are able to extend conventional multi-label algorithms [13, 17, 32, 34], to propose two new multi-label algorithms \u2013 direct multi-label zero-shot prediction (DMP) and transductive multi-label zero-shot prediction (TraMP).", "startOffset": 87, "endOffset": 103}, {"referenceID": 33, "context": "With this synthetic dataset, we are able to extend conventional multi-label algorithms [13, 17, 32, 34], to propose two new multi-label algorithms \u2013 direct multi-label zero-shot prediction (DMP) and transductive multi-label zero-shot prediction (TraMP).", "startOffset": 87, "endOffset": 103}, {"referenceID": 31, "context": "Multi-label classification Multi-label classification has been widely studied \u2013 for a review of the field please see [32, 34].", "startOffset": 117, "endOffset": 125}, {"referenceID": 33, "context": "Multi-label classification Multi-label classification has been widely studied \u2013 for a review of the field please see [32, 34].", "startOffset": 117, "endOffset": 125}, {"referenceID": 16, "context": "[17] studied transductive multi-label learning with a small set of training instances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] explored the label correlations of auxiliary data via a multi-label max-margin formulation and bet-", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 142, "endOffset": 164}, {"referenceID": 5, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 142, "endOffset": 164}, {"referenceID": 9, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 142, "endOffset": 164}, {"referenceID": 10, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 142, "endOffset": 164}, {"referenceID": 18, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 142, "endOffset": 164}, {"referenceID": 24, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 142, "endOffset": 164}, {"referenceID": 7, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 180, "endOffset": 194}, {"referenceID": 8, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 180, "endOffset": 194}, {"referenceID": 20, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 180, "endOffset": 194}, {"referenceID": 29, "context": "Zero-shot learning Multi-class single label zero-shot learning has now been widely studied using attribute-based intermediate semantic layers [3, 6, 10, 11, 19, 25] or data-driven [8, 9, 21, 30] representations.", "startOffset": 180, "endOffset": 194}, {"referenceID": 30, "context": "[31] first employed a linguistic model [15] as the intermediate semantic representation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[31] first employed a linguistic model [15] as the intermediate semantic representation.", "startOffset": 39, "endOffset": 43}, {"referenceID": 22, "context": "However, this does not model the syntactic and semantic regularities in language [23] which allows vector-oriented reasoning.", "startOffset": 81, "endOffset": 85}, {"referenceID": 21, "context": "For this purpose, we employ the skip-gram language model to learn the word space, which has shown to be able to capture such syntactic regularities [22, 23].", "startOffset": 148, "endOffset": 156}, {"referenceID": 22, "context": "For this purpose, we employ the skip-gram language model to learn the word space, which has shown to be able to capture such syntactic regularities [22, 23].", "startOffset": 148, "endOffset": 156}, {"referenceID": 6, "context": "[7] also used the skip-gram language model.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Additionally, zero-shot learning can be taken as the generalisation of class-incremental learning (C-IL) [4, 35] or life-long learning [26].", "startOffset": 105, "endOffset": 112}, {"referenceID": 34, "context": "Additionally, zero-shot learning can be taken as the generalisation of class-incremental learning (C-IL) [4, 35] or life-long learning [26].", "startOffset": 105, "endOffset": 112}, {"referenceID": 25, "context": "Additionally, zero-shot learning can be taken as the generalisation of class-incremental learning (C-IL) [4, 35] or life-long learning [26].", "startOffset": 135, "endOffset": 139}, {"referenceID": 22, "context": "YS = [ y1, \u00b7 \u00b7 \u00b7 ,ynS ] and YT = [ ynS+1, \u00b7 \u00b7 \u00b7 ,ynS+nT ] are the intermediate semantic representations of each auxiliary and test instance \u2013 in our case yi is a 100 dimensional continuous word vector for instance i in the skip-gram language model [23] space.", "startOffset": 248, "endOffset": 252}, {"referenceID": 21, "context": "The semantic word vector space is learned by using the state-of-the-art skip-gram language model [22, 23] on all English Wikipedia articles1.", "startOffset": 97, "endOffset": 105}, {"referenceID": 22, "context": "The semantic word vector space is learned by using the state-of-the-art skip-gram language model [22, 23] on all English Wikipedia articles1.", "startOffset": 97, "endOffset": 105}, {"referenceID": 22, "context": "Furthermore, V encodes the syntactic and semantic regularities in language [23] which allows vector-oriented reasoning by its \u2018compositionality\u2019 property.", "startOffset": 75, "endOffset": 79}, {"referenceID": 21, "context": "Note that cosine distance is used in the space V because of its robustness against noise [22, 23].", "startOffset": 89, "endOffset": 97}, {"referenceID": 22, "context": "Note that cosine distance is used in the space V because of its robustness against noise [22, 23].", "startOffset": 89, "endOffset": 97}, {"referenceID": 17, "context": "Our Mul-DR is inspired by the recent success of the deep convolutional neural network (CNN) features [18, 29] as well as the importance of modelling correlations within the semantic representation.", "startOffset": 101, "endOffset": 109}, {"referenceID": 28, "context": "Our Mul-DR is inspired by the recent success of the deep convolutional neural network (CNN) features [18, 29] as well as the importance of modelling correlations within the semantic representation.", "startOffset": 101, "endOffset": 109}, {"referenceID": 26, "context": "The first component (layers 1-7) provides state-of-the-art feature extraction for many computer vision tasks [27].", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "2 million labelled instances are used to train this component [29].", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "Different from [18, 29], where the 8-th layer is an output layer for classification, the 8-th layer in our model is a fully connected layer of 1024 neurons with Rectified Linear Units (ReLUs) activation functions.", "startOffset": 15, "endOffset": 23}, {"referenceID": 28, "context": "Different from [18, 29], where the 8-th layer is an output layer for classification, the 8-th layer in our model is a fully connected layer of 1024 neurons with Rectified Linear Units (ReLUs) activation functions.", "startOffset": 15, "endOffset": 23}, {"referenceID": 28, "context": "The parameters of the first components are pre-trained using ImageNet [29] while the parameters of the second component are trained by gradient descendent with auxiliary data XS and YS.", "startOffset": 70, "endOffset": 74}, {"referenceID": 13, "context": "A straightforward solution is to decompose the multi-label classification problem into multiple independent binary classification problems which is equivalent [14] to directly solving Eq (1) by: L\u0302T = [ [v(WT )] v(WT ) ]\u2020 [v(WT )] \u00b7 \u0176T (2)", "startOffset": 159, "endOffset": 163}, {"referenceID": 18, "context": "In a way, this can be considered as an extension of the \u2018Direct Attribute Prediction (DAP)\u2019 [19] to the case of multi-label and continuous representation.", "startOffset": 92, "endOffset": 96}, {"referenceID": 4, "context": "However, this does not exploit the multi-label correlations and thus has very limited expressive power [5, 33].", "startOffset": 103, "endOffset": 110}, {"referenceID": 32, "context": "However, this does not exploit the multi-label correlations and thus has very limited expressive power [5, 33].", "startOffset": 103, "endOffset": 110}, {"referenceID": 16, "context": "We therefore propose TramMP, which can be viewed as an extension the TRAM model in [17] for zero-shot learning, or a semi-supervised generalisation of Eq (3).", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "closed form solution [17], L\u0302T =\u2212A\u22121 UUAULLP.", "startOffset": 21, "endOffset": 25}, {"referenceID": 8, "context": "We therefore take a simple SSL strategy and perform one step of selftraining [9] to refine each prototype of P,", "startOffset": 77, "endOffset": 80}, {"referenceID": 32, "context": "4 Experiments Datasets Two popular multi-label datasets \u2013 Natural Scene [33] and IAPRTC-12 [12] are used to evaluate our framework.", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "4 Experiments Datasets Two popular multi-label datasets \u2013 Natural Scene [33] and IAPRTC-12 [12] are used to evaluate our framework.", "startOffset": 91, "endOffset": 95}, {"referenceID": 23, "context": "For multi-label zero-shot learning on Natural Scene, we use a multi-class single label dataset \u2013 Scene dataset [24] (totally 2688 images) as the auxiliary dataset which have been labelled with a non-overlapping set of labels such as street, coast and highway.", "startOffset": 111, "endOffset": 115}, {"referenceID": 15, "context": "Evaluation metrics (a) Hamming Loss: it measures the percentage of mismatches between estimated and ground-truth labels; (b) MicroF1 [16]: it evaluates both micro average of Precision (Micro-Precision) and micro average of Recall (Micro-Recall) with equal importance; (c) Ranking Loss: given the ranked list of predicted labels, it measures the number of label pairs that are incorrectly ordered by comparing their confidence scores with the ground-truth labels; (d) Average precision: given a ranked list of classes, it measures the area under precision-recall curve.", "startOffset": 133, "endOffset": 137}, {"referenceID": 1, "context": "(1) SVR+exDAP: Support Vector Regression (SVR)4 [2] is used to learn f :X \u2192V and infer the representation of each test instance.", "startOffset": 48, "endOffset": 51}, {"referenceID": 18, "context": "Using exDAP (Eq (2)) is a straightforward generalisation of [19, 20] to multilabel zero-shot learning.", "startOffset": 60, "endOffset": 68}, {"referenceID": 19, "context": "Using exDAP (Eq (2)) is a straightforward generalisation of [19, 20] to multilabel zero-shot learning.", "startOffset": 60, "endOffset": 68}, {"referenceID": 6, "context": "(3) DeViSE+DMP: We use DeViSE [7] to learn the visual-semantic embedding into which the power set P is projected.", "startOffset": 30, "endOffset": 33}, {"referenceID": 6, "context": "Thus it corresponds to the extension of [7] to multi-label zero-shot learning problems.", "startOffset": 40, "endOffset": 43}, {"referenceID": 18, "context": "It is evident that our Mul-DR significantly improve the results on conventional SVR [19, 20] regression model (Mul-DR+DMP>SVR+DMP, Mul-DR+exDAP>SVR+exDAP).", "startOffset": 84, "endOffset": 92}, {"referenceID": 19, "context": "It is evident that our Mul-DR significantly improve the results on conventional SVR [19, 20] regression model (Mul-DR+DMP>SVR+DMP, Mul-DR+exDAP>SVR+exDAP).", "startOffset": 84, "endOffset": 92}, {"referenceID": 6, "context": "This is because that SVR treats each of the 100 semantic word space dimensions independently, whilst our multi-output regression model, as well as the DeViSE model [7] capture the correlations between different dimensions.", "startOffset": 164, "endOffset": 167}, {"referenceID": 6, "context": "Comparing to the DeViSE model [7] (MulDR+DMP vs.", "startOffset": 30, "endOffset": 33}], "year": 2015, "abstractText": "Zero-shot learning has received increasing interest as a means to alleviate the often prohibitive expense of annotating training data for large scale recognition problems. These methods have achieved great success via learning intermediate semantic representations in the form of attributes and more recently, semantic word vectors. However, they have thus far been constrained to the single-label case, in contrast to the growing popularity and importance of more realistic multi-label data. In this paper, for the first time, we investigate and formalise a general framework for multi-label zero-shot learning, addressing the unique challenge therein: how to exploit multi-label correlation at test time with no training data for those classes? In particular, we propose (1) a multi-output deep regression model to project an image into a semantic word space, which explicitly exploits the correlations in the intermediate semantic layer of word vectors; (2) a novel zero-shot learning algorithm for multi-label data that exploits the unique compositionality property of semantic word vector representations; and (3) a transductive learning strategy to enable the regression model learned from seen classes to generalise well to unseen classes. Our zero-shot learning experiments on a number of standard multi-label datasets demonstrate that our method outperforms a variety of baselines.", "creator": "LaTeX with hyperref package"}}}