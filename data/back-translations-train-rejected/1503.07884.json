{"id": "1503.07884", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2015", "title": "Transductive Multi-class and Multi-label Zero-shot Learning", "abstract": "Recently, zero-shot learning (ZSL) has received increasing interest. The key idea underpinning existing ZSL approaches is to exploit knowledge transfer via an intermediate-level semantic representation which is assumed to be shared between the auxiliary and target datasets, and is used to bridge between these domains for knowledge transfer. The semantic representation used in existing approaches varies from visual attributes to semantic word vectors and semantic relatedness. However, the overall pipeline is similar: a projection mapping low-level features to the semantic representation is learned from the auxiliary dataset by either classification or regression models and applied directly to map each instance into the same semantic representation space where a zero-shot classifier is used to recognise the unseen target class instances with a single known 'prototype' of each target class. In this paper we discuss two related lines of work improving the conventional approach: exploiting transductive learning ZSL, and generalising ZSL to the multi-label case.", "histories": [["v1", "Thu, 26 Mar 2015 20:07:37 GMT  (3272kb,D)", "http://arxiv.org/abs/1503.07884v1", "4 pages, 4 figures, ECCV 2014 Workshop on Parts and Attributes"]], "COMMENTS": "4 pages, 4 figures, ECCV 2014 Workshop on Parts and Attributes", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["yanwei fu", "yongxin yang", "timothy m hospedales", "tao xiang", "shaogang gong"], "accepted": false, "id": "1503.07884"}, "pdf": {"name": "1503.07884.pdf", "metadata": {"source": "CRF", "title": "Transductive Multi-class and Multi-label Zero-shot Learning", "authors": ["Yanwei Fu", "Yongxin Yang", "Timothy M. Hospedales", "Tao Xiang", "Shaogang Gong", "Y. Fu", "Y. Yang", "T. Hospedales", "T. Xiang", "S. Gong"], "emails": ["s.gong}@qmul.ac.uk"], "sections": [{"heading": null, "text": "In fact, it is a \"reactionary act,\" which is a \"reactionary action,\" which is an attempt \"directed against the reactionary forces.\""}, {"heading": "1 Transductive multi-class zero-shot learning", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "2 Transductive multi-label zero-shot learning", "text": "For example, an image on Flickr often contains multiple objects with an overloaded background and therefore requires more than one label to describe its contents, and different labels are often correlated (e.g. cows often appear on grass).To better predict these labels, the label correlation needs to be modeled: for n labels, there are 2n possible multi-label combinations and sufficient training samples for each combination to learn the correlations of labels is impossible. However, more basic are the existing ZSL multi-class algorithms that cannot model such correlations, as there are no labeled examples available in this environment. We propose a novel framework for multi-label zero-shot-learning. However, given an auxiliary dataset that contains labeled images, and a target dataset multilabeled dataset multilabeled dataset multilabeled data models, we suggest a multi-label learning model for zero-shot-learning."}], "references": [{"title": "Label-embedding for attribute-based classification", "author": ["Z. Akata", "F. Perronnin", "Z. Harchaoui", "C. Schmid"], "venue": "In CVPR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Describing objects by their attributes", "author": ["A. Farhadi", "I. Endres", "D. Hoiem", "D. Forsyth"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Devise: A deep visual-semantic embedding model andrea", "author": ["A. Frome", "G.S. Corrado", "J. Shlens", "S. Bengio", "J. Dean", "M. Ranzato", "T. Mikolov"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Multi-view video summarization", "author": ["Y. Fu", "Y. Guo", "Y. Zhu", "F. Liu", "C. Song", "Z.-H. Zhou"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Attribute learning for understanding unstructured social activity", "author": ["Y. Fu", "T. Hospedales", "T. Xiang", "S. Gong"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Transductive multi-view embedding for zero-shot recognition and annotation", "author": ["Y. Fu", "T.M. Hospedales", "T. Xiang", "Z. Fu", "S. Gong"], "venue": "In ECCV,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Learning multi-modal latent attributes", "author": ["Y. Fu", "T.M. Hospedales", "T. Xiang", "S. Gong"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Transductive multi-view zero-shot recognition and annotation", "author": ["Y. Fu", "T.M. Hospedales", "T. Xiang", "S. Gong"], "venue": "Submitted to IEEE TPAMI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Transductive multi-label zero-shot learning", "author": ["Y. Fu", "Y. Yang", "T. Hospedales", "T. Xiang", "S. Gong"], "venue": "In BMVC,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "A multi-view embedding space for modeling internet", "author": ["Y. Gong", "Q. Ke", "M. Isard", "S. Lazebnik"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Learning to detect unseen object classes by between-class attribute transfer", "author": ["C.H. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Attribute-based classification for zero-shot visual object categorization", "author": ["C.H. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "IEEE TPAMI,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Recognizing human actions by attributes", "author": ["J. Liu", "B. Kuipers", "S. Savarese"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Efficient estimation of word representation in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "In Proceedings of Workshop at ICLR,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "In NIPS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Transfer learning in a transductive setting", "author": ["M. Rohrbach", "S. Ebert", "B. Schiele"], "venue": "In NIPS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Evaluating knowledge transfer and zeroshot learning in a large-scale setting", "author": ["M. Rohrbach", "M. Stark", "B. Schiele"], "venue": "In CVPR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "What helps where\u2013and why semantic relatedness for knowledge transfer", "author": ["M. Rohrbach", "M. Stark", "G. Szarvas", "I. Gurevych", "B. Schiele"], "venue": "In CVPR,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Zero-shot learning through cross-modal transfer", "author": ["R. Socher", "M. Ganjoo", "H. Sridhar", "O. Bastani", "C.D. Manning", "A.Y. Ng"], "venue": "In NIPS,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "A unified probabilistic approach modeling relationships between attributes and objects", "author": ["X. Wang", "Q. Ji"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Designing categorylevel attributes for discriminative visual recognition", "author": ["F.X. Yu", "L. Cao", "R.S. Feris", "J.R. Smith", "S.-F. Chang"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}], "referenceMentions": [{"referenceID": 10, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 86, "endOffset": 97}, {"referenceID": 1, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 86, "endOffset": 97}, {"referenceID": 12, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 86, "endOffset": 97}, {"referenceID": 6, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 86, "endOffset": 97}, {"referenceID": 2, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 123, "endOffset": 129}, {"referenceID": 18, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 123, "endOffset": 129}, {"referenceID": 16, "context": "The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17].", "startOffset": 155, "endOffset": 159}, {"referenceID": 15, "context": "This problem has never been explicitly identified although a partial solution exists [16].", "startOffset": 85, "endOffset": 89}, {"referenceID": 10, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 44, "endOffset": 55}, {"referenceID": 1, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 44, "endOffset": 55}, {"referenceID": 12, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 44, "endOffset": 55}, {"referenceID": 6, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 44, "endOffset": 55}, {"referenceID": 13, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 117, "endOffset": 126}, {"referenceID": 2, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 117, "endOffset": 126}, {"referenceID": 18, "context": "In particular, while both visual attributes [11,2,13,7] and linguistic semantic representations such as word vectors [14,3,19] have been independently exploited successfully, multiple semantic \u2018views\u2019 have not been exploited.", "startOffset": 117, "endOffset": 126}, {"referenceID": 7, "context": "In our work [8,6], we propose to solve the projection domain shift problem using a transductive multi-view embedding framework.", "startOffset": 12, "endOffset": 17}, {"referenceID": 5, "context": "In our work [8,6], we propose to solve the projection domain shift problem using a transductive multi-view embedding framework.", "startOffset": 12, "endOffset": 17}, {"referenceID": 9, "context": "We introduce a multi-view semantic space alignment process to correlate different semantic views and the low-level feature view by projecting them onto a latent embedding space learned using multi-view Canonical Correlation Analysis (CCA) [10].", "startOffset": 239, "endOffset": 243}, {"referenceID": 5, "context": "To this end, we introduce novel transductive multi-view Bayesian label propagation (TMV-BLP) algorithm for recognition in [6] which combines multiple graphs by Bayesian model averaging in the embedding space.", "startOffset": 122, "endOffset": 125}, {"referenceID": 7, "context": "In our journal version [8], we further introduce a novel transductive multi-view hypergraph label propagation (TMV-HLP) algorithm for recognition.", "startOffset": 23, "endOffset": 26}, {"referenceID": 10, "context": "Approach AwA (H [11]) AwA (O) AwA (O,D) USAA CUB (O) CUB (F) DAP 40.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "5([11]) / 41.", "startOffset": 2, "endOffset": 6}, {"referenceID": 11, "context": "4([12]) / 38.", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": "2([7,5]) / 35.", "startOffset": 2, "endOffset": 7}, {"referenceID": 4, "context": "2([7,5]) / 35.", "startOffset": 2, "endOffset": 7}, {"referenceID": 10, "context": "8([11]) / 42.", "startOffset": 2, "endOffset": 6}, {"referenceID": 11, "context": "2([12]) \u2013 \u2013 \u2013 \u2013 \u2013 M2LATM [7] 41.", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": "2([12]) \u2013 \u2013 \u2013 \u2013 \u2013 M2LATM [7] 41.", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "9 \u2013 \u2013 ALE/HLE/AHLE [1] 37.", "startOffset": 19, "endOffset": 22}, {"referenceID": 17, "context": "0 Mo/Ma/O/D [18] 27.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "7 \u2013 \u2013 \u2013 \u2013 \u2013 PST [16] 42.", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "2* [20] 43.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "4 \u2013 \u2013 \u2013 \u2013 \u2013 [21] 48.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "3** \u2013 \u2013 \u2013 \u2013 \u2013 TMV-BLP[6] 47.", "startOffset": 21, "endOffset": 24}, {"referenceID": 7, "context": "8 \u2013 \u2013 TMV-HLP [8] 49.", "startOffset": 14, "endOffset": 17}, {"referenceID": 17, "context": "Mo, Ma, O and D represent the highest results in the mined object class-attribute associations, mined attributes, objectness as attributes and direct similarity methods used in [18] respectively.", "startOffset": 177, "endOffset": 181}, {"referenceID": 8, "context": "We propose a novel framework for multi-label zero-shot learning [9].", "startOffset": 64, "endOffset": 67}, {"referenceID": 14, "context": "Zero-shot transfer is achieved using an intermediate semantic representation in the form of the skip-gram word vectors [15]", "startOffset": 119, "endOffset": 123}, {"referenceID": 14, "context": "It learns from auxiliary data the mapping from raw image pixels to a linguistic representation defined by the skip-gram language model [15].", "startOffset": 135, "endOffset": 139}, {"referenceID": 8, "context": "For more details, please read our paper [9].", "startOffset": 40, "endOffset": 43}], "year": 2015, "abstractText": "Recently, zero-shot learning (ZSL) has received increasing interest. The key idea underpinning existing ZSL approaches is to exploit knowledge transfer via an intermediate-level semantic representation which is assumed to be shared between the auxiliary and target datasets, and is used to bridge between these domains for knowledge transfer. The semantic representation used in existing approaches varies from visual attributes [11,2,13,7] to semantic word vectors [3,19] and semantic relatedness [17]. However, the overall pipeline is similar: a projection mapping low-level features to the semantic representation is learned from the auxiliary dataset by either classification or regression models and applied directly to map each instance into the same semantic representation space where a zero-shot classifier is used to recognise the unseen target class instances with a single known \u2018prototype\u2019 of each target class. In this paper we discuss two related lines of work improving the conventional approach: exploiting transductive learning ZSL, and generalising ZSL to the multi-label case.", "creator": "LaTeX with hyperref package"}}}