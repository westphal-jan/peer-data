{"id": "1503.07989", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Mar-2015", "title": "Discriminative Bayesian Dictionary Learning for Classification", "abstract": "We propose a Bayesian approach to learn discriminative dictionaries for sparse representation of data. The proposed approach infers probability distributions over the atoms of a discriminative dictionary using a Beta Process. It also computes sets of Bernoulli distributions that associate class labels to the learned dictionary atoms. This association signifies the selection probabilities of the dictionary atoms in the expansion of class-specific data. Furthermore, the non-parametric character of the proposed approach allows it to infer the correct size of the dictionary. We exploit the aforementioned Bernoulli distributions in separately learning a linear classifier. The classifier uses the same hierarchical Bayesian model as the dictionary, which we present along the analytical inference solution for Gibbs sampling. For classification, a test instance is first sparsely encoded over the learned dictionary and the codes are fed to the classifier. We performed experiments for face and action recognition; and object and scene-category classification using five public datasets and compared the results with state-of-the-art discriminative sparse representation approaches. Experiments show that the proposed Bayesian approach consistently outperforms the existing approaches.", "histories": [["v1", "Fri, 27 Mar 2015 08:36:15 GMT  (1156kb,D)", "http://arxiv.org/abs/1503.07989v1", "15 pages"]], "COMMENTS": "15 pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["naveed akhtar", "faisal shafait", "ajmal mian"], "accepted": false, "id": "1503.07989"}, "pdf": {"name": "1503.07989.pdf", "metadata": {"source": "CRF", "title": "Discriminative Bayesian Dictionary Learning for Classification", "authors": ["Naveed Akhtar", "Faisal Shafait", "Ajmal Mian"], "emails": ["naveed.akhtar@research.uwa.edu.au,", "ajmal.mian}@uwa.edu.au."], "sections": [{"heading": null, "text": "It is indeed the case that most people who work for equality between women and men must put themselves and themselves at the centre; it is not that they pursue the same goals as men, but it is that they pursue the same goals that they pursue."}, {"heading": "II. RELATED WORK", "text": "This year is the highest in the history of the country."}, {"heading": "III. PROBLEM FORMULATION AND BACKGROUND", "text": "Let us solve the following problems: Let us solve the problem of optimisation: Let us solve the optimisation problems: Let us solve the optimisation problems. (...) Let us solve the optimisation problems. (...) Let us solve the problem. (...) Let us create a dictionary of data describing the optimisation problems of data. (...) Let us specify the term matrix of data. (...) Let us specify the term matrix of data. (...) Let us specify the term matrix of data. (...) Let us apply the term matrix of data. (...) Let us apply the term matrix of data. (...) Let us apply the term matrix of data. (...) Let us apply the term matrix of data. (...) Let us use the term matrix of data. (...) Let us use the term matrix of data. (...) Let us use the term matrix of data. (...) Let us use the term matrix of data."}, {"heading": "IV. PROPOSED APPROACH", "text": "For the cth class, the vectors are scanned using separate drawings with the same base. That is, the matrix factorization is determined by a series of C probability vectors \u03c0c (1,..., C), rather than by a single vector, but the derived dictionary is divided by all classes. An element of the above set, i.e. \u03c0c (R) | K (K), controls the probability of selecting the dictionary atoms for a single class. This promotes the discriminatory capabilities of the derivative dictionary. 5 (a) AR database [1] (b) Extended YaleB database [2] Fig. Examples of how recognition accuracy is affected by the derivative dictionaries are used for half of the derivative dictionaries and for half of the dictionaries."}, {"heading": "A. The Model", "text": "It is not as if it is a model applied by the beta process, since it only allows the code to be binary. To overcome this limitation, we allow the hadamard / element-wise product, zci. \"R\".K is the binary vector and sci. \"R\".K is a weight vector before N (scik. \"0, 1 / 2 cso) on the kth component the weight vector and sci.\" K \"is a weight vector before N (scik.\") on the kth component the weight vector scik. \""}, {"heading": "C. Classification", "text": "Let us not detract from the discriminatory skills of the learned dictatorial class. We follow the common methodology [9], [7] for the grading that we need to learn. (7] We assume that the grading is already achieved through the joint optimization of W and E into the existing techniques (see Eq. 3). The main difference between the grading approach of this work and that of the existing techniques is in the learning process of W. Wherea's discrimination in the joint optimization of W and E in the existing techniques. (see Eq. 3), which is possible in the inference of the proposed approach to optimize a classification separately from the dictatorial learning process without affecting the discriminatory abilities of the learned dictatorial grading Let's."}, {"heading": "V. EXPERIMENTS", "text": "We evaluated the proposed approach on two face data sets: the Extended YaleB [2] and the AR database [1], a dataset for object categories: Caltech-101 [3], a dataset for scene9 categorization: Fifteen scene categories [4], and an action dataset: UCF sports actions [5]. These datasets are widely used in the literature to evaluate the sparse representation classification techniques. We compare the performance of the proposed approach with SRC [8], the two variants of LabelConsistent K-SVD [9] (i.e. LC-KSVD1, LC-KSVD2), the discriminatory K-SVD algorithm (D-KSVD) [7], the two variants of LabelConsistent K-SVD [9] (i.e. LC-KSVD, LC-KSVD1, LC-SVD2), the experimental results of SVD."}, {"heading": "A. Extended YaleB", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "B. AR Database", "text": "This database contains more than 4,000 color face images of 126 people. There are 26 images per person taken during two different sessions. Compared to Extended YaleB, the images in the AR database have greater variations in terms of facial expressions, disguise and lighting conditions. However, samples from the AR database are randomly selected 20 samples for training and the rest for the exam. The 165 x 120 pixel images were projected onto a 540-dimensional vector using a random projection matrix."}, {"heading": "C. Caltech-101", "text": "In fact: The number of samples per class varies from 31 to 800, and the pictures within a certain class are of importance, as they can be seen in the illustration. In the illustration of the database, it can be seen how it was created in the sequence of the illustrations. In the sequence of the illustrations, it can be seen that the illustrations in the sequence of the illustrations are very different. In the sequence of the illustrations, the illustrations are very different. In the sequence of the illustrations, the illustrations are very different. In the sequence of the illustrations, the illustrations of the illustrations are very different. In the sequence of the illustrations, the illustrations of the illustrations are very different. In the illustrations, the illustrations of the illustrations are the illustrations of the illustrations are the illustrations of the illustrations are the illustrations very different. In the illustrations, the illustrations of the illustrations are the illustrations of the illustrations are the illustrations of the illustrations are the illustrations very different."}, {"heading": "D. Fifteen Scene Category", "text": "The dataset of the Fifteen Scene Categories [4] contains 200 to 400 images per category for fifteen different scenarios, including scenes from kitchens, living rooms, and the countryside, etc. In our experiments, we used the spatial pyramid characteristics of the images published by Jiang et al. [9]. In these data, each feature descriptor is a 3000-dimensional vector. Using these characteristics, we conducted experiments by randomly selecting 100 training instances per class and considering the remaining as test steps. The classification accuracy of the proposed approach is compared with the existing approaches in Table V. The reported averages are calculated over ten experiments.The error tolerance for SRC was set at 10 \u2212 6 and the parameter settings proposed by Jiang et al. [9] for LC-KSVD1, LCKSVD2, and D-KSVD.The parameters of DL-COPAR were used as proposed in the original work of the 11 Database [11]."}, {"heading": "E. UCF Sports Action", "text": "This database includes video sequences collected from various broadcast sports channels (e.g. ESPN and BBC) [5]. The videos contain 10 categories of sports actions, including: kicking, golfing, diving, riding, skateboarding, running, swinging, high bar swinging, lifting, and walking. Examples from this data set are shown in Figure 8. Under the joint evaluation protocol, we performed a quintuple cross-validation over the data set, using four folds in training and the remaining folds for testing. The results, calculated as an average of the five experiments, are summarized in Table VI. For D-KSVD, LC-KSVD1, and LC-KSVD2, we followed the parameter settings [9]. Again, the value of 10 \u2212 6 (along with similarly small values) resulted in the best accuracy for SRC.12 The table also includes the results for some specific action detection methods, Qui [33] [SDL-11] and the SAR-11 results."}, {"heading": "VI. DISCUSSION", "text": "In our experiments, we chose the values of K, ao and bo in light of the theoretical results presented in section IV-B. By defining K > N, we ensure that K is very large. The results remain mainly insensitive to other similarly large values of this parameter. The values of ao and bo used in our experiments ensure that 0 < ao, bo < | Ic |. We used large values for \u03bb o in our experiments, as this parameter represents the precision of the distribution of white noise in the samples. The data sets used in our experiments are mainly clean in terms of white noise. Therefore, we achieved the best performance with \u03bb o \u2265 106. In the case of noise data, this parameter can be adjusted accordingly. \u2212 For UCF sports action parameters dataset o = 109, the best results were obtained because fewer number of training samples per class were available. It should be noted that the value of growth increases as a result of Bayean inference with cleaner training parameters."}, {"heading": "VII. CONCLUSION", "text": "The proposed approach uses a beta process to derive a discriminatory dictionary and sentences from Bernoulli distributions that match the dictionary atoms to the class names of the training data. Consequence also results in the correct dictionary size being calculated. To learn the discriminatory dictionary, we have presented a hierarchical model that shows the corresponding inference equations for sampling dictionaries. The proposed model is also used in learning a linear classifier that eventually classifies the sparse codes of a test instance."}, {"heading": "ACKNOWLEDGMENT", "text": "This research was supported by ARC Grant DP110102399."}], "references": [{"title": "From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose", "author": ["A. Georghiades", "P. Belhumeur", "D. Kriegman"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Learning Generative Visual Models from Few Training Samples: An Incremental Bayesian Approach Tested on 101 Object Categories", "author": ["L. FeiFei", "R. Fergus", "P. Perona"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern Recognition Workshop Generative Model Based Vision,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Beyond bag of features: spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "In Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "A spatio-temporal maximum average correlation height filter for action recognition", "author": ["M. Rodriguez", "J. Ahmed", "M. Shah"], "venue": "In Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation", "author": ["M. Aharon", "M. Elad", "A. Bruckstein"], "venue": "IEEE Trans. Signal Processing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Discriminative K-SVD for Dictionary Learning in Face Recognition", "author": ["Q. Zhang", "B. Li"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Robust Face Recognition via Sparse Representation", "author": ["J. Wright", "M. Yang", "A. Ganesh", "S. Sastry", "Y. Ma"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Label Consistent K-SVD: Learning a Discriminative Dictionary for Recognition", "author": ["Z. Jiang", "Z. Lin", "L.S. Davis"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol.35,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Sparse Representation Based Fisher Discrimination Dictionary Learning for Image Classification", "author": ["M. Yang", "L. Zhang", "X. Feng", "D. Zhang"], "venue": "International Journal of Computer Vision, vol.109,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "A Classification-oriented Dictionary Learning Model: Explicitly Learning the Particularity and Commonality Across Categories", "author": ["D. Wang", "S. Kong"], "venue": "Pattern Recognition, vol.47,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Classification and Clustering via Dictionary Learning with Structured Incoherence and Shared Features", "author": ["I. Ramirez", "P. Sprechmann", "G. Sapiro"], "venue": "In Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Latent Dictionary Learning for Sparse Representation based Classification, In", "author": ["M. Yang", "D. Dai", "L. Shen", "L.V. Gool"], "venue": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Learning Discriminative Dictionary for Group Sparse Representation", "author": ["Y. Sun", "Q. Liu", "J. Tang", "D. Tao"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Locality Constrained Linear Coding for Image Classification", "author": ["J. Wang", "J. Yang", "K. Yu", "F. Lv", "T.Huang", "Y. Gong"], "venue": "In Proc. IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries", "author": ["M. Elad", "M. Aharon"], "venue": "IEEE Transactions on Image Processing, vol.15,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "Sparse Representation for Color Image Restoration", "author": ["J. Mairal", "M. Elad", "G. Sapiro"], "venue": "IEEE Transactions on Image Processing, vol.17,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Sparse Spatio-spectral Representation for Hyperspectral Image Super Resolution", "author": ["N. Akhtar", "F. Shafait", "A. Mian"], "venue": "Proc. European Conf. on Computer Vision,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Compressed sensing", "author": ["D. Donoho"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Morphological component analysis: An adaptive thresholding strategy", "author": ["J. Bobin", "J.L. Starck", "J.M. Fadili", "Y. Moudden", "D.L. Donoho"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2006}, {"title": "Gabor feature based sparse representation for face recognition with gabor occlusion dictionary", "author": ["M. Yang", "L. Zhang"], "venue": "In Proc. Computer Vision?ECCV", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Robust sparse coding for face recognition", "author": ["M. Yang", "D. Zhang", "J. Yang"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Metaface learning for sparse representation based face recognition", "author": ["M. Yang", "L. Zhang", "J. Yang", "D. Zhang"], "venue": "In Proc. IEEE International Conference on Image Processing,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Sparse representation for signal classification", "author": ["K. Huang", "S. Aviyente"], "venue": "In Advances in Neural Information Processing systems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Supervised translation-invariant sparse coding", "author": ["J. Yang", "K. Yu", "T. Huang"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Sparse Representation for Image Classification: Learning discriminative and reconstructive non-parametric dictionaries", "author": ["F. Rodriguez", "G. Sapiro"], "venue": "Minnesota Univ. Minneapolis,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Task driven dictionary learning", "author": ["J. Mairal", "F. Bach", "J. Ponce"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Linear spatial pyramid matching using sparse coding for image classification", "author": ["J. Yang", "K. Yu", "Y. Gong", "T. Huang"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Sparse dictionary-based representation and recognition of action attributes", "author": ["Q. Qiu", "Z. Jiang", "R. Chellappa"], "venue": "In Proc. IEEE International Conference on Computer Vision pp", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "Learning sparse representations for human action recognition", "author": ["G. Tanaya", "R.K. Ward"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Sparse modeling of human actions from motion imagery", "author": ["A. Castrodad", "G. Sapiro"], "venue": "International journal of computer vision,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "SVM-KNN: Discriminative nearest neighbor classification for visual category recognition", "author": ["H. Zhang", "A. Berg", "M. Maire", "J. Malik"], "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "In Proc. IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2007}, {"title": "Caltech-256 object category dataset, CIT Technical report", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2007}, {"title": "Action bank: A high-level representation of activity in video", "author": ["S. Sadanand", "J.J. Corso"], "venue": "In Proc. IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "An algorithm for machine calculation of complex Fourier series", "author": ["J.W. Cooley", "J.W. Tukey"], "venue": "Mathematics of Computation,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1965}, {"title": "A wavelet tour of signal processing, 2nd Edition, Sandiago", "author": ["S. Mallat"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1999}, {"title": "Compression of facial images using the K-SVD algorithm", "author": ["O. Bryt", "M. Elad"], "venue": "Journal of Visual Communication and Image Representation, vol.19,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2008}, {"title": "Non-parametric Bayesian dictionary learning for sparse image representations, In Advances in neural information processing", "author": ["M. Zhou", "H. Chen", "L. Ren", "G. Sapiro", "L. Carin", "J.W. Paisley"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2009}, {"title": "Joint learning and dictionary construction for pattern recognition", "author": ["D.S. Pham", "S. Venkatesh"], "venue": "In Proc. IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2008}, {"title": "Method of optimal directions for frame design", "author": ["K. Engan", "S.O. Aase", "J.H. Husoy"], "venue": "In Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1999}, {"title": "Discriminative learned dictionaries for local image analysis", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro", "A. Zisserman"], "venue": "IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2008}, {"title": "Dictionary learning and sparse coding for unsupervised clustering", "author": ["P. Sprechmann", "G. Sapiro"], "venue": "In Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2010}, {"title": "Learning Active Basis Model for Object Detection and Recognition", "author": ["Y.N. Wu", "Z. Si", "H. Gong", "S.C. Zhu"], "venue": "Int. Journal of Computer Vision, vol. 90,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2010}, {"title": "Max-Margin Dictionary Learning for Multiclass Image Categorization", "author": ["X.C. Lian", "Z. Li", "B.L. Lu", "L. Zhang"], "venue": "In Computer Vision (ECCV 2010),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2010}, {"title": "Submodular Dictionary Learning for Sparse Coding", "author": ["Z. Jiang"], "venue": "In Proc. IEEE Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2012}, {"title": "Algorithms for simultaneous sparse approximation: part I: Greedy pursuit", "author": ["J.A. Tropp", "A.C. Gilbert", "M.J. Strauss"], "venue": "Signal Process.,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2006}, {"title": "Extended SRC: Undersampled Face Recognition via Intraclass Variant Dictionary", "author": ["W. Deng", "J. Hu", "J. Guo"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2012}, {"title": "Learning inter-related visual dictionary for object recognition", "author": ["N. Zhou", "J.P. Fan"], "venue": "In Proc. IEEE Conf. on Computer Vision and Pattern Recognition", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2012}, {"title": "Multi-level Discriminative Dictionary Learning towards Hierarchical Visual Categorization", "author": ["L. Shen", "S. Wang", "G. Sun", "S. Jiang", "Q. Huang"], "venue": "In Proc. IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2013}, {"title": "Nonparametric factor analysis with beta process prior", "author": ["J. Paisley", "L. Carin"], "venue": "In Proc. Int. Conf. on Machine Learning,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2009}, {"title": "Sparse and redundant representation: From theory to applications in signal and image", "author": ["M. Elad"], "venue": null, "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2010}, {"title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2006}, {"title": "Orthogonal matching pursuit for sparse signal recovery with noise", "author": ["T.T. Cai", "Lei Wang"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2011}, {"title": "Online learning for matrix factorization and sparse coding", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2010}, {"title": "Regression shrinkage and selection via Lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 1996}, {"title": "Distinctive Image Features from Scale-Invariant Keypoints", "author": ["D.G. Lowe"], "venue": "International Journal of Computer Vision,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2004}, {"title": "Futuristic greedy approach to sparse unmixing of hypersperctral data", "author": ["N. Akhtar", "F. Shafait", "A. Mian"], "venue": "IEEE Transactions on Geoscience and Remote Sensing,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2015}], "referenceMentions": [{"referenceID": 14, "context": "With its inspirational roots in human vision system [16], [17], this technique has been successfully employed in image restoration [18], [19], [20], compressive sensing [21], [22] and morphological component analysis [23].", "startOffset": 131, "endOffset": 135}, {"referenceID": 15, "context": "With its inspirational roots in human vision system [16], [17], this technique has been successfully employed in image restoration [18], [19], [20], compressive sensing [21], [22] and morphological component analysis [23].", "startOffset": 137, "endOffset": 141}, {"referenceID": 16, "context": "With its inspirational roots in human vision system [16], [17], this technique has been successfully employed in image restoration [18], [19], [20], compressive sensing [21], [22] and morphological component analysis [23].", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "With its inspirational roots in human vision system [16], [17], this technique has been successfully employed in image restoration [18], [19], [20], compressive sensing [21], [22] and morphological component analysis [23].", "startOffset": 175, "endOffset": 179}, {"referenceID": 18, "context": "With its inspirational roots in human vision system [16], [17], this technique has been successfully employed in image restoration [18], [19], [20], compressive sensing [21], [22] and morphological component analysis [23].", "startOffset": 217, "endOffset": 221}, {"referenceID": 7, "context": "More recently, sparse representation based approaches have also shown promising results in face recognition and gender classification [9], [8], [10], [13], [24],", "startOffset": 134, "endOffset": 137}, {"referenceID": 6, "context": "More recently, sparse representation based approaches have also shown promising results in face recognition and gender classification [9], [8], [10], [13], [24],", "startOffset": 139, "endOffset": 142}, {"referenceID": 8, "context": "More recently, sparse representation based approaches have also shown promising results in face recognition and gender classification [9], [8], [10], [13], [24],", "startOffset": 144, "endOffset": 148}, {"referenceID": 11, "context": "More recently, sparse representation based approaches have also shown promising results in face recognition and gender classification [9], [8], [10], [13], [24],", "startOffset": 150, "endOffset": 154}, {"referenceID": 19, "context": "More recently, sparse representation based approaches have also shown promising results in face recognition and gender classification [9], [8], [10], [13], [24],", "startOffset": 156, "endOffset": 160}, {"referenceID": 20, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 6, "endOffset": 10}, {"referenceID": 12, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 57, "endOffset": 61}, {"referenceID": 23, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 63, "endOffset": 67}, {"referenceID": 24, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 69, "endOffset": 73}, {"referenceID": 25, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 75, "endOffset": 79}, {"referenceID": 7, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 121, "endOffset": 124}, {"referenceID": 9, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 126, "endOffset": 130}, {"referenceID": 26, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 132, "endOffset": 136}, {"referenceID": 27, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 166, "endOffset": 170}, {"referenceID": 28, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 172, "endOffset": 176}, {"referenceID": 29, "context": "[25], [26], texture and handwritten digit classification [14], [29], [30], [31], natural image and object classification [9], [11], [32] and human action recognition [33], [34], [35], [36].", "startOffset": 184, "endOffset": 188}, {"referenceID": 6, "context": "sparse linear combination of the other samples from the same class, in a lower dimensional manifold [8].", "startOffset": 100, "endOffset": 103}, {"referenceID": 34, "context": "fast Fourier transform [41] or wavelets [42]) as a generic dictionary to represent data from different domains/classes.", "startOffset": 23, "endOffset": 27}, {"referenceID": 35, "context": "fast Fourier transform [41] or wavelets [42]) as a generic dictionary to represent data from different domains/classes.", "startOffset": 40, "endOffset": 44}, {"referenceID": 4, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 55, "endOffset": 59}, {"referenceID": 14, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 61, "endOffset": 65}, {"referenceID": 36, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 67, "endOffset": 71}, {"referenceID": 37, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 73, "endOffset": 77}, {"referenceID": 38, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 79, "endOffset": 83}, {"referenceID": 8, "context": "However, research in the last decade ( [6], [9], [10], [11], [18], [43], [44], [45]) has provided strong evidence in favor of learning dictionaries using the domain/class-specific training data, especially for classification and recognition tasks [10] where class label information of the training data can be exploited in the supervised learning of a dictionary.", "startOffset": 247, "endOffset": 251}, {"referenceID": 4, "context": "K-SVD [6], Method of Optimal Directions [46]) aim at learning faithful signal representations, supervised sparse representation additionally strives for making the dictionaries discriminative.", "startOffset": 6, "endOffset": 9}, {"referenceID": 39, "context": "K-SVD [6], Method of Optimal Directions [46]) aim at learning faithful signal representations, supervised sparse representation additionally strives for making the dictionaries discriminative.", "startOffset": 40, "endOffset": 44}, {"referenceID": 6, "context": "[8] constructed a discriminative dictionary by directly using the training data as the dictionary atoms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "In order to learn a discriminative dictionary, existing approaches either force subsets of the dictionary atoms to represent data from only specific classes [12], [26], [47] or", "startOffset": 157, "endOffset": 161}, {"referenceID": 21, "context": "In order to learn a discriminative dictionary, existing approaches either force subsets of the dictionary atoms to represent data from only specific classes [12], [26], [47] or", "startOffset": 163, "endOffset": 167}, {"referenceID": 40, "context": "In order to learn a discriminative dictionary, existing approaches either force subsets of the dictionary atoms to represent data from only specific classes [12], [26], [47] or", "startOffset": 169, "endOffset": 173}, {"referenceID": 5, "context": "they associate the complete dictionary to all the classes and constrain their sparse coefficient to be discriminative [7], [9], [28].", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "they associate the complete dictionary to all the classes and constrain their sparse coefficient to be discriminative [7], [9], [28].", "startOffset": 123, "endOffset": 126}, {"referenceID": 9, "context": "A third category of techniques learns exclusive sets of class specific and common dictionary atoms to separate the common and particular features of the data from different classes [11], [54].", "startOffset": 181, "endOffset": 185}, {"referenceID": 47, "context": "A third category of techniques learns exclusive sets of class specific and common dictionary atoms to separate the common and particular features of the data from different classes [11], [54].", "startOffset": 187, "endOffset": 191}, {"referenceID": 11, "context": "However, adaptively building this association is still an open research problem [13].", "startOffset": 80, "endOffset": 84}, {"referenceID": 49, "context": "sparse representation technique that infers a discriminative dictionary using a Beta Process [56].", "startOffset": 93, "endOffset": 97}, {"referenceID": 0, "context": "Our approach has been tested on two face-databases [1], [2], an object-database [3], an action-database [5] and a scene-database [4].", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "Our approach has been tested on two face-databases [1], [2], an object-database [3], an action-database [5] and a scene-database [4].", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "Our approach has been tested on two face-databases [1], [2], an object-database [3], an action-database [5] and a scene-database [4].", "startOffset": 104, "endOffset": 107}, {"referenceID": 2, "context": "Our approach has been tested on two face-databases [1], [2], an object-database [3], an action-database [5] and a scene-database [4].", "startOffset": 129, "endOffset": 132}, {"referenceID": 21, "context": "In the first category, the learned dictionary atoms have direct correspondence to the labels of the classes [26], [47], [12], [48], [35], [49], [36].", "startOffset": 108, "endOffset": 112}, {"referenceID": 40, "context": "In the first category, the learned dictionary atoms have direct correspondence to the labels of the classes [26], [47], [12], [48], [35], [49], [36].", "startOffset": 114, "endOffset": 118}, {"referenceID": 10, "context": "In the first category, the learned dictionary atoms have direct correspondence to the labels of the classes [26], [47], [12], [48], [35], [49], [36].", "startOffset": 120, "endOffset": 124}, {"referenceID": 41, "context": "In the first category, the learned dictionary atoms have direct correspondence to the labels of the classes [26], [47], [12], [48], [35], [49], [36].", "startOffset": 126, "endOffset": 130}, {"referenceID": 42, "context": "In the first category, the learned dictionary atoms have direct correspondence to the labels of the classes [26], [47], [12], [48], [35], [49], [36].", "startOffset": 138, "endOffset": 142}, {"referenceID": 29, "context": "In the first category, the learned dictionary atoms have direct correspondence to the labels of the classes [26], [47], [12], [48], [35], [49], [36].", "startOffset": 144, "endOffset": 148}, {"referenceID": 21, "context": "[26] proposed an SRC like framework for face recognition, where the atoms of the dictionary are learned from the training data instead of directly using the training data as the dictionary.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[47] used a discriminative penalty term in the KSVD model [6], achieving state-of-the-art results on texture segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[47] used a discriminative penalty term in the KSVD model [6], achieving state-of-the-art results on texture segmentation.", "startOffset": 58, "endOffset": 61}, {"referenceID": 41, "context": "Sprechmann and Sapiro [48] also proposed to learn dictionaries and sparse codes for clustering.", "startOffset": 22, "endOffset": 26}, {"referenceID": 29, "context": "In [36], Castrodad and Sapiro computed class-specific dictionaries for actions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 42, "context": "Active basis models are learned from the training images of each class and applied to object detection and recognition in [49].", "startOffset": 122, "endOffset": 126}, {"referenceID": 10, "context": "[12] have used an incoherence promoting term for the dictionary atoms in their learning model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 20, "endOffset": 23}, {"referenceID": 5, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 31, "endOffset": 34}, {"referenceID": 23, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 36, "endOffset": 40}, {"referenceID": 24, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 42, "endOffset": 46}, {"referenceID": 38, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 48, "endOffset": 52}, {"referenceID": 25, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 54, "endOffset": 58}, {"referenceID": 43, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 60, "endOffset": 64}, {"referenceID": 27, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 66, "endOffset": 70}, {"referenceID": 44, "context": "be discriminative ( [9], [28], [7], [29], [30], [45], [31], [50], [33], [51] ).", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "[9] proposed a dictionary learning model that encourages the sparse representation coefficients of the same class to be similar.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "A similar approach is taken by Rodriguez and Sapiro [30] where the authors solve for a simultaneous sparse approximation problem [52] while learning the coefficients.", "startOffset": 52, "endOffset": 56}, {"referenceID": 45, "context": "A similar approach is taken by Rodriguez and Sapiro [30] where the authors solve for a simultaneous sparse approximation problem [52] while learning the coefficients.", "startOffset": 129, "endOffset": 133}, {"referenceID": 38, "context": "Pham and Venkatesh [45] and Mairal et al.", "startOffset": 19, "endOffset": 23}, {"referenceID": 5, "context": "Zhang and Li [7] enhanced the K-SVD algorithm [6] to learn a linear classifier along the dictionary.", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "Zhang and Li [7] enhanced the K-SVD algorithm [6] to learn a linear classifier along the dictionary.", "startOffset": 46, "endOffset": 49}, {"referenceID": 25, "context": "A task driven dictionary learning framework has also been proposed [31].", "startOffset": 67, "endOffset": 71}, {"referenceID": 46, "context": "[53] extended the SRC algorithm by appending an intra-class face variation dictionary to the training data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 47, "context": "Zhou and Fan [54] employ a Fisher-like regularizer on the representation coefficients while learning a hybrid dictionary.", "startOffset": 13, "endOffset": 17}, {"referenceID": 9, "context": "Wang and Kong [11] learned a hybrid dictionary to separate the common and particular features of the data.", "startOffset": 14, "endOffset": 18}, {"referenceID": 48, "context": "[55] proposed to learn a multi-level dictionary for hierarchical visual categorization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "However, it is often non-trivial to decide on how to balance between the shared and the class-specific parts of the hybrid dictionary [10], [13].", "startOffset": 134, "endOffset": 138}, {"referenceID": 11, "context": "However, it is often non-trivial to decide on how to balance between the shared and the class-specific parts of the hybrid dictionary [10], [13].", "startOffset": 140, "endOffset": 144}, {"referenceID": 50, "context": "Generally, p is chosen to be 0 or 1 for sparsity [57].", "startOffset": 49, "endOffset": 53}, {"referenceID": 7, "context": "Nevertheless, we can still exploit this factorization in classification tasks by using the sparse codes of the data as features [9], for which, a classifier can be obtained as", "startOffset": 128, "endOffset": 131}, {"referenceID": 5, "context": "Considering this, existing approaches [7], [45], [29], [28] proposed to jointly optimize a classifier with the dictionary while learning the sparse representation.", "startOffset": 38, "endOffset": 41}, {"referenceID": 38, "context": "Considering this, existing approaches [7], [45], [29], [28] proposed to jointly optimize a classifier with the dictionary while learning the sparse representation.", "startOffset": 43, "endOffset": 47}, {"referenceID": 23, "context": "Considering this, existing approaches [7], [45], [29], [28] proposed to jointly optimize a classifier with the dictionary while learning the sparse representation.", "startOffset": 49, "endOffset": 53}, {"referenceID": 7, "context": "[9] built further on this concept and encouraged explicit correspondence between the dictionary atoms and the class-labels.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "More precisely, the following optimization problem is solved by the LabelConsistent K-SVD (LC-KSVD2) algorithm [9]:", "startOffset": 111, "endOffset": 114}, {"referenceID": 7, "context": "It is worth noting that in Label-Consistent K-SVD algorithm [9], the relationship between class-specific subsets of dictionary atoms and class labels is pre-defined.", "startOffset": 60, "endOffset": 63}, {"referenceID": 5, "context": "SVD (D-KSVD) algorithm [7].", "startOffset": 23, "endOffset": 26}, {"referenceID": 5, "context": "2, we illustrate the behavior of recognition accuracy under varying dictionary sizes for [7] and [9] for two face databases.", "startOffset": 89, "endOffset": 92}, {"referenceID": 7, "context": "2, we illustrate the behavior of recognition accuracy under varying dictionary sizes for [7] and [9] for two face databases.", "startOffset": 97, "endOffset": 100}, {"referenceID": 49, "context": "Paisley and Carin [56] developed a Beta Process for nonparametric factor analysis, which was later used by Zhou et al.", "startOffset": 18, "endOffset": 22}, {"referenceID": 37, "context": "[44] in successful image restoration and compressive sensing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "(5), the number of non-zero components in a column of Z is a random number drawn from Poisson(ao/bo) [56].", "startOffset": 101, "endOffset": 105}, {"referenceID": 0, "context": "(a) AR database [1] (b) Extended YaleB database [2]", "startOffset": 48, "endOffset": 51}, {"referenceID": 7, "context": "All other parameters are kept constant at optimal values reported in [9].", "startOffset": 69, "endOffset": 72}, {"referenceID": 49, "context": "3Paisley and Carin [56] derived variational Bayesian algorithm [58] for their model.", "startOffset": 19, "endOffset": 23}, {"referenceID": 37, "context": "[44] that Gibbs sampling is an equally effective strategy in data representation using the same model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "K-SVD [6]), we derive expressions for the Gibbs sampler for our approach.", "startOffset": 6, "endOffset": 9}, {"referenceID": 4, "context": "This process is analogous to the atom-by-atom dictionary update step of K-SVD [6], however the sparse codes remain fixed during our dictionary update.", "startOffset": 78, "endOffset": 81}, {"referenceID": 49, "context": "4We follow [56] closely in the proof, however, our analysis also takes into account the class labels of the data, whereas no such data discrimination is assumed in [56].", "startOffset": 11, "endOffset": 15}, {"referenceID": 49, "context": "4We follow [56] closely in the proof, however, our analysis also takes into account the class labels of the data, whereas no such data discrimination is assumed in [56].", "startOffset": 164, "endOffset": 168}, {"referenceID": 7, "context": "We follow the common methodology [9], [7] for classification that first encodes y over the inferred dictionary such that y = \u03a6\u03b1\u0302 + , and then computes ` = W\u03b1\u0302, where W \u2208 RC\u00d7|K| contains model parameters of a multi-class linear classifier.", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "We follow the common methodology [9], [7] for classification that first encodes y over the inferred dictionary such that y = \u03a6\u03b1\u0302 + , and then computes ` = W\u03b1\u0302, where W \u2208 RC\u00d7|K| contains model parameters of a multi-class linear classifier.", "startOffset": 38, "endOffset": 41}, {"referenceID": 0, "context": "4: Illustration of the discriminative character of the inferred dictionary: From top, the four rows present results on AR database [1], Extended YaleB [2], Caltech-101 [3] and Fifteen Scene categories [4], respectively.", "startOffset": 151, "endOffset": 154}, {"referenceID": 1, "context": "4: Illustration of the discriminative character of the inferred dictionary: From top, the four rows present results on AR database [1], Extended YaleB [2], Caltech-101 [3] and Fifteen Scene categories [4], respectively.", "startOffset": 168, "endOffset": 171}, {"referenceID": 2, "context": "4: Illustration of the discriminative character of the inferred dictionary: From top, the four rows present results on AR database [1], Extended YaleB [2], Caltech-101 [3] and Fifteen Scene categories [4], respectively.", "startOffset": 201, "endOffset": 204}, {"referenceID": 5, "context": "[7], [9]) the coupling between W and \u03a6 is kept probabilistic in our approach.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[7], [9]) the coupling between W and \u03a6 is kept probabilistic in our approach.", "startOffset": 5, "endOffset": 8}, {"referenceID": 52, "context": "Our view point also makes Orthogonal Matching Pursuit (OMP) [60] a", "startOffset": 60, "endOffset": 64}, {"referenceID": 52, "context": "We sparsely encode xi over the initial dictionary using OMP [60].", "startOffset": 60, "endOffset": 64}, {"referenceID": 0, "context": "We have evaluated the proposed approach on two face data sets: the Extended YaleB [2] and the AR database [1], a data set for object categories: Caltech-101 [3], a data set for scene", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "We have evaluated the proposed approach on two face data sets: the Extended YaleB [2] and the AR database [1], a data set for object categories: Caltech-101 [3], a data set for scene", "startOffset": 157, "endOffset": 160}, {"referenceID": 2, "context": "categorization: Fifteen scene categories [4], and an action data", "startOffset": 41, "endOffset": 44}, {"referenceID": 3, "context": "set: UCF sports actions [5].", "startOffset": 24, "endOffset": 27}, {"referenceID": 6, "context": "We compare the performance of the proposed approach with SRC [8], the two variants of LabelConsistent K-SVD [9] (i.", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "We compare the performance of the proposed approach with SRC [8], the two variants of LabelConsistent K-SVD [9] (i.", "startOffset": 108, "endOffset": 111}, {"referenceID": 5, "context": "LC-KSVD1, LC-KSVD2), the Discriminative K-SVD algorithm (D-KSVD) [7], the Fisher Discrimination Dictionary Learning algorithm (FDDL) [10] and the Dictionary Learning based on separating the Commonalities and the Particularities of the data (DL-COPAR) [11].", "startOffset": 65, "endOffset": 68}, {"referenceID": 8, "context": "LC-KSVD1, LC-KSVD2), the Discriminative K-SVD algorithm (D-KSVD) [7], the Fisher Discrimination Dictionary Learning algorithm (FDDL) [10] and the Dictionary Learning based on separating the Commonalities and the Particularities of the data (DL-COPAR) [11].", "startOffset": 133, "endOffset": 137}, {"referenceID": 9, "context": "LC-KSVD1, LC-KSVD2), the Discriminative K-SVD algorithm (D-KSVD) [7], the Fisher Discrimination Dictionary Learning algorithm (FDDL) [10] and the Dictionary Learning based on separating the Commonalities and the Particularities of the data (DL-COPAR) [11].", "startOffset": 251, "endOffset": 255}, {"referenceID": 4, "context": "In our comparisons, we also include results of unsupervised sparse representation based classification that uses K-SVD [6] as the dictionary learning technique and separately computes a multi-class linear classifier using Eq.", "startOffset": 119, "endOffset": 122}, {"referenceID": 54, "context": "To implement SRC, we used the LASSO [63] solver of the SPAMS toolbox [62].", "startOffset": 36, "endOffset": 40}, {"referenceID": 53, "context": "To implement SRC, we used the LASSO [63] solver of the SPAMS toolbox [62].", "startOffset": 69, "endOffset": 73}, {"referenceID": 7, "context": "[9] for LC-KSVD2 algorithm and solved Eq.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Furthermore, \u03bb o was set to 10 6 for all the datasets except for Fifteen Scene Categories [4],", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "Extended YaleB [2] contains 2,414 frontal face images of 38 different people, each having about 64 samples.", "startOffset": 15, "endOffset": 18}, {"referenceID": 6, "context": "In our experiments, we used the random face feature descriptor [8], where a cropped 192 \u00d7 168 pixels image was projected onto a 504-dimensional vector.", "startOffset": 63, "endOffset": 66}, {"referenceID": 0, "context": "(a) Extended YaleB [2]", "startOffset": 19, "endOffset": 22}, {"referenceID": 13, "context": "The results for Locality-constrained Linear Coding (LLC) [15] is directly taken from [9], where the accuracy is computed using 70 local bases.", "startOffset": 57, "endOffset": 61}, {"referenceID": 7, "context": "The results for Locality-constrained Linear Coding (LLC) [15] is directly taken from [9], where the accuracy is computed using 70 local bases.", "startOffset": 85, "endOffset": 88}, {"referenceID": 7, "context": "[9], the sparsity threshold for K-SVD, LC-KSVD1, LC-KSVD2 and D-KSVD was set to 30 in our experiments.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Furthermore, as in [9], we used \u03c5 = 4.", "startOffset": 19, "endOffset": 22}, {"referenceID": 7, "context": "This value is set to 570 in [9] for all of the four methods.", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "Following [8], we set the residual error tolerance to 0.", "startOffset": 10, "endOffset": 13}, {"referenceID": 8, "context": "For FDDL, we followed [10] for the optimized parameter settings.", "startOffset": 22, "endOffset": 26}, {"referenceID": 9, "context": "For the parameter settings of DL-COPAR we followed the original work [11].", "startOffset": 69, "endOffset": 73}, {"referenceID": 0, "context": "TABLE I: Recognition accuracy with Random-Face features on the Extended YaleB database [2].", "startOffset": 87, "endOffset": 90}, {"referenceID": 13, "context": "LLC [15] 90.", "startOffset": 4, "endOffset": 8}, {"referenceID": 4, "context": "7 K-SVD [6] 93.", "startOffset": 8, "endOffset": 11}, {"referenceID": 7, "context": "37 LC-KSVD1 [9] 93.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "36 D-KSVD [7] 94.", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "38 DL-COPAR [11] 94.", "startOffset": 12, "endOffset": 16}, {"referenceID": 7, "context": "55 LC-KSVD2 [9] 95.", "startOffset": 12, "endOffset": 15}, {"referenceID": 8, "context": "FDDL [10] 96.", "startOffset": 5, "endOffset": 9}, {"referenceID": 6, "context": "SRC [8] 96.", "startOffset": 4, "endOffset": 7}, {"referenceID": 13, "context": "We report the average recognition accuracy of our experiments in Table II, which also includes the accuracy of LLC [15] reported in [9].", "startOffset": 115, "endOffset": 119}, {"referenceID": 7, "context": "We report the average recognition accuracy of our experiments in Table II, which also includes the accuracy of LLC [15] reported in [9].", "startOffset": 132, "endOffset": 135}, {"referenceID": 5, "context": "In our experiments, we set the sparsity threshold for K-SVD, LC-KSVD1, LC-KSVD2 and D-KSVD to 50 as compared to 10 and 30 which was used in [7] and [9], respectively.", "startOffset": 140, "endOffset": 143}, {"referenceID": 7, "context": "In our experiments, we set the sparsity threshold for K-SVD, LC-KSVD1, LC-KSVD2 and D-KSVD to 50 as compared to 10 and 30 which was used in [7] and [9], respectively.", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "These large values (compared to 500 used in [7], [9]) resulted in better accuracies at the", "startOffset": 44, "endOffset": 47}, {"referenceID": 7, "context": "These large values (compared to 500 used in [7], [9]) resulted in better accuracies at the", "startOffset": 49, "endOffset": 52}, {"referenceID": 13, "context": "LLC [15] 88.", "startOffset": 4, "endOffset": 8}, {"referenceID": 9, "context": "7 DL-COPAR [11] 93.", "startOffset": 11, "endOffset": 15}, {"referenceID": 7, "context": "80 LC-KSVD1 [9] 93.", "startOffset": 12, "endOffset": 15}, {"referenceID": 4, "context": "37 K-SVD [6] 94.", "startOffset": 9, "endOffset": 12}, {"referenceID": 7, "context": "99 LC-KSVD2 [9] 95.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "41 D-KSVD [7] 95.", "startOffset": 10, "endOffset": 13}, {"referenceID": 8, "context": "38 FDDL [10] 96.", "startOffset": 8, "endOffset": 12}, {"referenceID": 6, "context": "03 SRC [8] 96.", "startOffset": 7, "endOffset": 10}, {"referenceID": 1, "context": "6: Examples from Caltech-101 database [3].", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "The Caltech-101 database [3] comprises 9, 144 samples from 102 classes.", "startOffset": 25, "endOffset": 28}, {"referenceID": 55, "context": "To use the database, first the SIFT descriptors [64] were extracted from 16 \u00d7 16 image patches, which were densely sampled with a 6-pixels step size for the grid.", "startOffset": 48, "endOffset": 52}, {"referenceID": 31, "context": "Then, based on the extracted features, spatial pyramid features [38] were extracted with 2\u00d72 grids, where l = 0, 1, 2.", "startOffset": 64, "endOffset": 68}, {"referenceID": 1, "context": "TABLE III: Classification results using Spatial Pyramid Features on the Caltech-101 dataset [3].", "startOffset": 92, "endOffset": 95}, {"referenceID": 30, "context": "[37] 46.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[38] - - 56.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[39] 44.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] 51.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "4 SRC [8] 49.", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": "9 DL-COPAR [11] 49.", "startOffset": 11, "endOffset": 15}, {"referenceID": 4, "context": "9 K-SVD [6] 51.", "startOffset": 8, "endOffset": 11}, {"referenceID": 8, "context": "3 FDDL [10] 52.", "startOffset": 7, "endOffset": 11}, {"referenceID": 5, "context": "1 D-KSVD [7] 52.", "startOffset": 9, "endOffset": 12}, {"referenceID": 7, "context": "1 LC-KSVD1 [9] 53.", "startOffset": 11, "endOffset": 14}, {"referenceID": 7, "context": "5 LC-KSVD2 [9] 53.", "startOffset": 11, "endOffset": 14}, {"referenceID": 7, "context": "[9] also suggested the same parameter settings.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "We used the parameter settings for object categorization given in [10] for FDDL.", "startOffset": 66, "endOffset": 70}, {"referenceID": 9, "context": "For DL-COPAR, the selected number of classspecific atoms were kept the same as the number of training instances per class, whereas the number of shared atoms were fixed to 314, as in the original work [11].", "startOffset": 201, "endOffset": 205}, {"referenceID": 7, "context": "Moreover, our approach is able to handle a batch of large training data more efficiently than LC-KSVD [9] and D-KSVD [7].", "startOffset": 102, "endOffset": 105}, {"referenceID": 5, "context": "Moreover, our approach is able to handle a batch of large training data more efficiently than LC-KSVD [9] and D-KSVD [7].", "startOffset": 117, "endOffset": 120}, {"referenceID": 5, "context": "96 D-KSVD [7] 3196 19.", "startOffset": 10, "endOffset": 13}, {"referenceID": 7, "context": "90 LC-KSVD1 [9] 5434 19.", "startOffset": 12, "endOffset": 15}, {"referenceID": 7, "context": "65 LC-KSVD2 [9] 5434 19.", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": "7: Examples images from eight different categories in Fifteen Scene Categories dataset [4].", "startOffset": 87, "endOffset": 90}, {"referenceID": 2, "context": "The Fifteen Scene Category dataset [4] has 200 to 400 images per category for fifteen different kinds of scenes.", "startOffset": 35, "endOffset": 38}, {"referenceID": 7, "context": "[9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] for LC-KSVD1, LCKSVD2 and D-KSVD.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Parameters of DL-COPAR were set as suggested in the original work [11] for the same database.", "startOffset": 66, "endOffset": 70}, {"referenceID": 3, "context": "ESPN and BBC) [5].", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "For D-KSVD, LC-KSVD1 and LC-KSVD2 we followed [9] for the parameter settings.", "startOffset": 46, "endOffset": 49}, {"referenceID": 2, "context": "TABLE V: Classification accuracy on Fifteen Scene Category dataset [4] using Spatial Pyramid Features.", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "K-SVD [6] 93.", "startOffset": 6, "endOffset": 9}, {"referenceID": 7, "context": "14 LC-KSVD1 [9] 94.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "17 D-KSVD [7] 96.", "startOffset": 10, "endOffset": 13}, {"referenceID": 6, "context": "12 SRC [8] 96.", "startOffset": 7, "endOffset": 10}, {"referenceID": 9, "context": "09 DL-COPAR [11] 96.", "startOffset": 12, "endOffset": 16}, {"referenceID": 7, "context": "22 LC-KSVD2 [9] 97.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "8: Examples from UCF Sports action dataset [5].", "startOffset": 43, "endOffset": 46}, {"referenceID": 27, "context": "[33] and action back feature with SVM [40].", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[33] and action back feature with SVM [40].", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "These results are taken directly from [13] along the results of DLSI [12], DL-COPAR [11] and FDDL [10]5.", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": "These results are taken directly from [13] along the results of DLSI [12], DL-COPAR [11] and FDDL [10]5.", "startOffset": 69, "endOffset": 73}, {"referenceID": 9, "context": "These results are taken directly from [13] along the results of DLSI [12], DL-COPAR [11] and FDDL [10]5.", "startOffset": 84, "endOffset": 88}, {"referenceID": 8, "context": "These results are taken directly from [13] along the results of DLSI [12], DL-COPAR [11] and FDDL [10]5.", "startOffset": 98, "endOffset": 102}, {"referenceID": 33, "context": "Following [40], we also performed leave-one-out cross validation on this database for the proposed approach.", "startOffset": 10, "endOffset": 14}, {"referenceID": 33, "context": "7% better than the state-of-the-art results claimed in [40].", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "5The results of DL-COPAR [11] and FDDL [10] are taken directly from the literature because the optimized parameter values for these algorithms are not previously reported for this dataset.", "startOffset": 25, "endOffset": 29}, {"referenceID": 8, "context": "5The results of DL-COPAR [11] and FDDL [10] are taken directly from the literature because the optimized parameter values for these algorithms are not previously reported for this dataset.", "startOffset": 39, "endOffset": 43}, {"referenceID": 3, "context": "TABLE VI: Classification rates on UCF Sports Action dataset [5]", "startOffset": 60, "endOffset": 63}, {"referenceID": 27, "context": "[33] 83.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "6 LC-KSVD2 [9] 91.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "5 D-KSVD [7] 89.", "startOffset": 9, "endOffset": 12}, {"referenceID": 10, "context": "1 DLSI [12] 92.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "1 LC-KSVD1 [9] 89.", "startOffset": 11, "endOffset": 14}, {"referenceID": 6, "context": "6 SRC [8] 92.", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": "7 DL-COPAR [11] 90.", "startOffset": 11, "endOffset": 15}, {"referenceID": 8, "context": "7 FDDL [10] 93.", "startOffset": 7, "endOffset": 11}, {"referenceID": 33, "context": "6 Sadanand [40] 90.", "startOffset": 11, "endOffset": 15}, {"referenceID": 11, "context": "7 LDL [13] 95.", "startOffset": 6, "endOffset": 10}, {"referenceID": 3, "context": "In our experiments, while sparse coding a test instance over the learned dictionary, we consistently used the sparsity threshold of 50 for all the datasets except for the UCF [5], for which this parameter was set to 40 because of the smaller dictionary resulting from less training samples.", "startOffset": 175, "endOffset": 178}, {"referenceID": 56, "context": "For instance, while classifying the spectral signatures of minerals on pixel and sub-pixel level in remote-sensing hyperspectral images, the relative smoothness of spectral signatures [65] can be incorporated in the inferred discriminative bases.", "startOffset": 184, "endOffset": 188}], "year": 2015, "abstractText": "We propose a Bayesian approach to learn discriminative dictionaries for sparse representation of data. The proposed approach infers probability distributions over the atoms of a discriminative dictionary using a Beta Process. It also computes sets of Bernoulli distributions that associate class labels to the learned dictionary atoms. This association signifies the selection probabilities of the dictionary atoms in the expansion of class-specific data. Furthermore, the non-parametric character of the proposed approach allows it to infer the correct size of the dictionary. We exploit the aforementioned Bernoulli distributions in separately learning a linear classifier. The classifier uses the same hierarchical Bayesian model as the dictionary, which we present along the analytical inference solution for Gibbs sampling. For classification, a test instance is first sparsely encoded over the learned dictionary and the codes are fed to the classifier. We performed experiments for face and action recognition; and object and scene-category classification using five public datasets and compared the results with state-of-the-art discriminative sparse representation approaches. Experiments show that the proposed Bayesian approach consistently outperforms the existing approaches.", "creator": "LaTeX with hyperref package"}}}