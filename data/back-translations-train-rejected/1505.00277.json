{"id": "1505.00277", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-May-2015", "title": "Grounded Discovery of Coordinate Term Relationships between Software Entities", "abstract": "We present an approach for the detection of coordinate-term relationships between entities from the software domain, that refer to Java classes. Usually, relations are found by examining corpus statistics associated with text entities. In some technical domains, however, we have access to additional information about the real-world objects named by the entities, suggesting that coupling information about the \"grounded\" entities with corpus statistics might lead to improved methods for relation discovery. To this end, we develop a similarity measure for Java classes using distributional information about how they are used in software, which we combine with corpus statistics on the distribution of contexts in which the classes appear in text. Using our approach, cross-validation accuracy on this dataset can be improved dramatically, from around 60% to 88%. Human labeling results show that our classifier has an F1 score of 86% over the top 1000 predicted pairs.", "histories": [["v1", "Fri, 1 May 2015 20:40:00 GMT  (1946kb,D)", "http://arxiv.org/abs/1505.00277v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG cs.SE", "authors": ["dana movshovitz-attias", "william w cohen"], "accepted": false, "id": "1505.00277"}, "pdf": {"name": "1505.00277.pdf", "metadata": {"source": "CRF", "title": "Grounded Discovery of Coordinate Term Relationships between Software Entities", "authors": ["Dana Movshovitz-Attias", "William W. Cohen"], "emails": ["dma@cs.cmu.edu", "wcohen@cs.cmu.edu"], "sections": [{"heading": null, "text": "In some technical areas, however, we have access to additional information about the real-world objects named by the entities, which suggests that coupling information about the \"grounded\" entities with corpus statistics could lead to improved ways of discovering relationships. To this end, we are developing a similarity measurement for Java classes based on distribution information about their use in software, which we combine with corpus statistics about the distribution of the contexts in which the classes appear in the text. Using our approach, the accuracy of cross-validation of this data set can be dramatically improved, from about 60% to 88%. Results from human labeling show that our classifier has an F1 value of 86% above the top 1000 predicted pairs."}, {"heading": "1 Introduction", "text": "In fact, it is such that most people who see themselves in a position to understand themselves and understand themselves are able to understand themselves and to understand what they are doing, and that they are able to understand the world in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2 Related Work", "text": "The first approach is based on the insight that certain lexical patterns indicate a semantic relationship with high precision, as first observed by Hearst [16]. The second approach, however, is based on the assumption that words that appear in a similar context are likely to be semantically similar. In contrast to pattern-based classifiers, context-based similarity approaches tend to be higher in memory. [7, 32, 33, 36] In this paper, we seek to identify samples that work with high precision in language."}, {"heading": "3 Coordinate Term Discovery", "text": "In this section, we describe a high-level coordinate classification pipeline as illustrated in Figure 2. All of the following steps are described in detail in the following sections. Given a text corpus from the software domain (StackOverflow) and a code repository (Java Standard Libraries), our goal is to predict a coordinate relationship for < X, Y >, with X and Y potentially pointing to Java classes. Next, we try a basic approach to designating the pair < X, Y > based on corpus distribution similarity. Since closely related classes often have morphological proximity, we use the string similarity of X and Y. Next, we assign the noun X to an underlying class implementation from the code repository, called X \u2032."}, {"heading": "3.1 Baseline: Corpus Distributional Similarity.", "text": "As a starting point, we calculate the distributional similarity of the nouns < X, Y >, assuming that words with a similar context are likely to be semantically similar. Our implementation follows Pereira et al. [33] We calculate the empirical context distribution for noun X (3.1) pX = f (c, X) / n c (c, X), where f (c, X) is the frequency of occurrence of noun X in context c. We then measure the similarity of the nouns X and Y using relative entropy or Kullback-Leibler class (3.2), where f (c, X) is the frequency of occurrence of noun X (z) pY (z) pY (z).Since this measure is not symmetrical, we finally consider the distributional similarity of X and Y as D (pY)."}, {"heading": "4 Experimental Settings", "text": "In fact, it is a very rare disease, which is a very rare disease, which is usually a very rare disease."}, {"heading": "5 Results", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "6 Conclusions", "text": "We have an approach to the grounded discovery of conceptual relationships between text units representing Java classes. Using a simple concatenation method, we have mapped text units to an underlying class type implementation from the Java standard libraries. [With this code-based grounding, we extract information about the class's usage pattern and its position in the Java class and namespace hierarchies.] Our experimental evaluation shows that there is only a corpus-based similarity for the coordinate term prediction task, which reaches an accuracy of about 58%. However, adding information based on the entity implementation software dramatically improves accuracy to 88%. Our classification has an F1 score of 86% according to human labeling. We have shown that our predictions can be used to build an interesting code taxonomy that is divided from the functional connections, common user spaces, and implementation patterns."}], "references": [{"title": "Improving identifier informativeness using part of speech information", "author": ["Dave Binkley", "Matthew Hearn", "Dawn Lawrie"], "venue": "In Proc. of the Working Conference on Mining Software Repositories. ACM,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Fast unfolding of communities in large networks", "author": ["Vincent D Blondel", "Jean-Loup Guillaume", "Renaud Lambiotte", "Etienne Lefebvre"], "venue": "Journal of Statistical Mechanics: Theory and Experiment,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Reading between the lines: Learning to map highlevel instructions to commands", "author": ["SRK Branavan", "Luke S Zettlemoyer", "Regina Barzilay"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. ACL,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Toward an architecture for never-ending language learning", "author": ["Andrew Carlson", "Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R Hruschka Jr.", "Tom M Mitchell"], "venue": "In AAAI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Libsvm: a library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "A comparison of string distance metrics for name-matching tasks", "author": ["William W Cohen", "Pradeep D Ravikumar", "Stephen E Fienberg"], "venue": "IIWeb,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "From distributional to semantic similarity", "author": ["James Richard Curran"], "venue": "PhD thesis, University of Edinburgh. College of Science and Engineering. School of Informatics.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Identifying relations for open information extraction", "author": ["Anthony Fader", "Stephen Soderland", "Oren Etzioni"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing. ACL,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Liblinear: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang- Rui Wang", "Chih-Jen Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Javert: fully automatic mining of general temporal properties from dynamic traces", "author": ["Mark Gabel", "Zhendong Su"], "venue": "In Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "A statistical semantic parser that integrates syntax and semantics", "author": ["Ruifang Ge", "Raymond J Mooney"], "venue": "In Computational Natural Language Learning", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Learning semantic constraints for the automatic discovery of part-whole relations", "author": ["Roxana Girju", "Adriana Badulescu", "Dan Moldovan"], "venue": "In North American Chapter of the Association for Computational Linguistics on Human Language Technology. ACL,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Situated language understanding as filtering perceived affordances", "author": ["Peter Gorniak", "Deb Roy"], "venue": "Cognitive Science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Code completion from abbreviated input", "author": ["Sangmok Han", "David R Wallace", "Robert C Miller"], "venue": "In Automated Software Engineering", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Automatic acquisition of hyponyms  from large text corpora", "author": ["Marti A Hearst"], "venue": "In Proceedings of the 14th conference on Computational linguistics. ACL,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Code template inference using language models", "author": ["Ferosh Jacob", "Robert Tairas"], "venue": "In Southeast Regional Conference", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Learning language semantics from ambiguous supervision", "author": ["Rohit J Kate", "Raymond J Mooney"], "venue": "In AAAI,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Jointly learning to parse and perceive: Connecting natural language to the physical world", "author": ["Jayant Krishnamurthy", "Thomas Kollar"], "venue": "TACL,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Weakly supervised training of semantic parsers", "author": ["Jayant Krishnamurthy", "Tom M Mitchell"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Ni Lao", "Tom Mitchell", "William W Cohen"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Whats in a name? a study of identifiers", "author": ["Dawn Lawrie", "Christopher Morrell", "Henry Feild", "David Binkley"], "venue": "ICPC", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Learning semantic correspondences with less supervision", "author": ["Percy Liang", "Michael I Jordan", "Dan Klein"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Identifying synonyms among distributionally similar words", "author": ["Dekang Lin", "Shaojun Zhao", "Lijuan Qin", "Ming Zhou"], "venue": "In IJCAI,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Entity linking at web scale", "author": ["Thomas Lin", "Oren Etzioni"], "venue": "In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction. ACL,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "A machine learning for language toolkit", "author": ["Andrew Kachites McCallum. Mallet"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2002}, {"title": "Wordnet: A lexical database for english", "author": ["George A Miller"], "venue": "Communications of the ACM,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1995}, {"title": "Parsing entire discourses as very long strings: Capturing topic continuity in grounded language learning", "author": ["Thang Luong Minh", "Michael C Frank", "Mark Johnson"], "venue": "TACL,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Natural language models for predicting programming comments", "author": ["Dana Movshovitz-Attias", "William W. Cohen"], "venue": "In Association for Computational Linguistics,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Maltparser: A data-driven parser-generator for dependency parsing", "author": ["Joakim Nivre", "Johan Hall", "Jens Nilsson"], "venue": "In Proceedings of LREC,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2006}, {"title": "Structured statistical syntax tree prediction", "author": ["Cyrus Omar"], "venue": "In Proceedings of the 2013 companion publication for conference on Systems, programming, & applications: software for humanity. ACM,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Clustering by committee", "author": ["Patrick Andre Pantel"], "venue": "PhD  thesis, Department of Computing Science, University of Alberta,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2003}, {"title": "Distributional clustering of english words", "author": ["Fernando Pereira", "Naftali Tishby", "Lillian Lee"], "venue": "In ACL,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1993}, {"title": "Building statistical language models of code", "author": ["Peter Schulam", "Roni Rosenfeld", "Premkumar Devanbu"], "venue": "In Proc. DAPSE. IEEE,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2013}, {"title": "A computational study of crosssituational techniques for learning word-to-meaning", "author": ["Jeffrey Mark Siskind"], "venue": "mappings. Cognition,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1996}, {"title": "Learning syntactic patterns for automatic hypernym discovery", "author": ["Rion Snow", "Daniel Jurafsky", "Andrew Y Ng"], "venue": "In NIPS,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2004}, {"title": "Semantic taxonomy induction from heterogenous evidence", "author": ["Rion Snow", "Daniel Jurafsky", "Andrew Y Ng"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "Coupled temporal scoping of relational facts", "author": ["Partha Pratim Talukdar", "Derry Wijaya", "Tom Mitchell"], "venue": "In Proceedings of the fifth ACM international conference on Web search and data mining. ACM,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["Kristina Toutanova", "Dan Klein", "Christopher D Manning", "Yoram Singer"], "venue": "In Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology. Association for Computational Linguistics,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2003}, {"title": "Combining independent modules to solve multiple-choice synonym and analogy problems", "author": ["Peter Turney", "Michael L Littman", "Jeffrey Bigham", "Victor Shnayder"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2003}, {"title": "Extracting paraphrases of technical terms from noisy parallel software corpora", "author": ["Xiaoyin Wang", "David Lo", "Jing Jiang", "Lu Zhang", "Hong Mei"], "venue": "In Proceedings of the ACL-IJCNLP. ACL,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "Automatically assessing the post quality in online discussions on software", "author": ["Markus Weimer", "Iryna Gurevych", "Max M\u00fchlh\u00e4user"], "venue": "In Proceedings of the 45th Annual Meeting of the ACL. ACL,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2007}, {"title": "Textrunner: open information extraction on the web", "author": ["Alexander Yates", "Michael Cafarella", "Michele Banko", "Oren Etzioni", "Matthew Broadhead", "Stephen Soderland"], "venue": "In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations. ACL,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2007}, {"title": "On the integration of grounding language and learning objects", "author": ["Chen Yu", "Dana H Ballard"], "venue": "In AAAI,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2004}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["Luke S Zettlemoyer", "Michael Collins"], "venue": "Uncertainty in Artificial Intelligence,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2005}], "referenceMentions": [{"referenceID": 41, "context": "It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].", "startOffset": 108, "endOffset": 112}, {"referenceID": 7, "context": "It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].", "startOffset": 121, "endOffset": 124}, {"referenceID": 3, "context": "It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].", "startOffset": 135, "endOffset": 138}, {"referenceID": 36, "context": "It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].", "startOffset": 228, "endOffset": 232}, {"referenceID": 18, "context": "It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].", "startOffset": 251, "endOffset": 255}, {"referenceID": 23, "context": "It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].", "startOffset": 275, "endOffset": 279}, {"referenceID": 25, "context": "According to the WordNet glossary, X and Y are defined as coordinate terms if they share a common hypernym [10, 27].", "startOffset": 107, "endOffset": 115}, {"referenceID": 35, "context": "[37]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Semantic similarity relations are normally discovered by comparing corpus statistics associated with the entities: for instance, two entities X and Y that usually appear in similar contexts are likely to be semantically similar [7, 32, 33].", "startOffset": 228, "endOffset": 239}, {"referenceID": 30, "context": "Semantic similarity relations are normally discovered by comparing corpus statistics associated with the entities: for instance, two entities X and Y that usually appear in similar contexts are likely to be semantically similar [7, 32, 33].", "startOffset": 228, "endOffset": 239}, {"referenceID": 31, "context": "Semantic similarity relations are normally discovered by comparing corpus statistics associated with the entities: for instance, two entities X and Y that usually appear in similar contexts are likely to be semantically similar [7, 32, 33].", "startOffset": 228, "endOffset": 239}, {"referenceID": 2, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 209, "endOffset": 221}, {"referenceID": 27, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 209, "endOffset": 221}, {"referenceID": 39, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 209, "endOffset": 221}, {"referenceID": 40, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 209, "endOffset": 221}, {"referenceID": 0, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 324, "endOffset": 337}, {"referenceID": 13, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 324, "endOffset": 337}, {"referenceID": 15, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 324, "endOffset": 337}, {"referenceID": 32, "context": "Understanding software entity relations will allow the construction of a domain specific taxonomy and knowledge base, which can enable higher reasoning capabilities in NLP applications for the software domain [3,29,41,42] and improve a variety of code assisting applications, including code refactoring and token completion [1, 15,17,34].", "startOffset": 324, "endOffset": 337}, {"referenceID": 14, "context": "The first is based on the insight that certain lexical patterns indicate a semantic relationship with high-precision, as initially observed by Hearst [16].", "startOffset": 150, "endOffset": 154}, {"referenceID": 11, "context": "been introduced for meronyms [13], synonyms [24], and general analogy relations [40].", "startOffset": 29, "endOffset": 33}, {"referenceID": 22, "context": "been introduced for meronyms [13], synonyms [24], and general analogy relations [40].", "startOffset": 44, "endOffset": 48}, {"referenceID": 38, "context": "been introduced for meronyms [13], synonyms [24], and general analogy relations [40].", "startOffset": 80, "endOffset": 84}, {"referenceID": 6, "context": "[7, 32, 33, 36].", "startOffset": 0, "endOffset": 15}, {"referenceID": 30, "context": "[7, 32, 33, 36].", "startOffset": 0, "endOffset": 15}, {"referenceID": 31, "context": "[7, 32, 33, 36].", "startOffset": 0, "endOffset": 15}, {"referenceID": 34, "context": "[7, 32, 33, 36].", "startOffset": 0, "endOffset": 15}, {"referenceID": 12, "context": "The aim of grounded language learning methods is to learn a mapping between natural language (words and sentences) and the observed world [14, 35, 44], where more recent work includes grounding language to the physical world [19], and grounding of entire discourses [28].", "startOffset": 138, "endOffset": 150}, {"referenceID": 33, "context": "The aim of grounded language learning methods is to learn a mapping between natural language (words and sentences) and the observed world [14, 35, 44], where more recent work includes grounding language to the physical world [19], and grounding of entire discourses [28].", "startOffset": 138, "endOffset": 150}, {"referenceID": 42, "context": "The aim of grounded language learning methods is to learn a mapping between natural language (words and sentences) and the observed world [14, 35, 44], where more recent work includes grounding language to the physical world [19], and grounding of entire discourses [28].", "startOffset": 138, "endOffset": 150}, {"referenceID": 17, "context": "The aim of grounded language learning methods is to learn a mapping between natural language (words and sentences) and the observed world [14, 35, 44], where more recent work includes grounding language to the physical world [19], and grounding of entire discourses [28].", "startOffset": 225, "endOffset": 229}, {"referenceID": 26, "context": "The aim of grounded language learning methods is to learn a mapping between natural language (words and sentences) and the observed world [14, 35, 44], where more recent work includes grounding language to the physical world [19], and grounding of entire discourses [28].", "startOffset": 266, "endOffset": 270}, {"referenceID": 10, "context": "Early work in this field relied on supervised aligned sentence-tomeaning data [12, 45].", "startOffset": 78, "endOffset": 86}, {"referenceID": 43, "context": "Early work in this field relied on supervised aligned sentence-tomeaning data [12, 45].", "startOffset": 78, "endOffset": 86}, {"referenceID": 16, "context": "However, in later work the supervision constraint has been gradually relaxed [18,23].", "startOffset": 77, "endOffset": 84}, {"referenceID": 21, "context": "However, in later work the supervision constraint has been gradually relaxed [18,23].", "startOffset": 77, "endOffset": 84}, {"referenceID": 13, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 119, "endOffset": 132}, {"referenceID": 15, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 119, "endOffset": 132}, {"referenceID": 27, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 119, "endOffset": 132}, {"referenceID": 32, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 119, "endOffset": 132}, {"referenceID": 0, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 166, "endOffset": 172}, {"referenceID": 20, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 166, "endOffset": 172}, {"referenceID": 9, "context": "NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11].", "startOffset": 207, "endOffset": 211}, {"referenceID": 29, "context": "This has been complemented by work from the programming language research community for structured prediction of code syntax trees [31].", "startOffset": 131, "endOffset": 135}, {"referenceID": 31, "context": "[33].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "[33]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "The words X and Y are defined as coordinate terms if they have the same hypernym in a given taxonomy, meaning they have at least one common ancestor in this taxonomy [36].", "startOffset": 166, "endOffset": 170}, {"referenceID": 24, "context": "Mallet statistical NLP package [26].", "startOffset": 31, "endOffset": 35}, {"referenceID": 37, "context": "Next, the text was POS tagged with the Stanford POS tagger [39] and parsed with the MaltParser [30].", "startOffset": 59, "endOffset": 63}, {"referenceID": 28, "context": "Next, the text was POS tagged with the Stanford POS tagger [39] and parsed with the MaltParser [30].", "startOffset": 95, "endOffset": 99}, {"referenceID": 4, "context": "We follow the classification pipeline described in Figure 2, using the LibLinear SVM classifier [5, 9] with the following features:", "startOffset": 96, "endOffset": 102}, {"referenceID": 8, "context": "We follow the classification pipeline described in Figure 2, using the LibLinear SVM classifier [5, 9] with the following features:", "startOffset": 96, "endOffset": 102}, {"referenceID": 3, "context": "In Figure 3 we provide an additional analysis based on manual human labeling of samples from the Coord-PMI dataset, following a procedure similar to prior researchers exploring semi-supervised methods for relation discovery [4, 21].", "startOffset": 224, "endOffset": 231}, {"referenceID": 19, "context": "In Figure 3 we provide an additional analysis based on manual human labeling of samples from the Coord-PMI dataset, following a procedure similar to prior researchers exploring semi-supervised methods for relation discovery [4, 21].", "startOffset": 224, "endOffset": 231}, {"referenceID": 1, "context": "Graph edges are colored using the Louvain method [2] for community detection and an entity label\u2019s size is determined by its betweenness centrality degree.", "startOffset": 49, "endOffset": 52}], "year": 2015, "abstractText": "We present an approach for the detection of coordinateterm relationships between entities from the software domain, that refer to Java classes. Usually, relations are found by examining corpus statistics associated with text entities. In some technical domains, however, we have access to additional information about the real-world objects named by the entities, suggesting that coupling information about the \u201cgrounded\u201d entities with corpus statistics might lead to improved methods for relation discovery. To this end, we develop a similarity measure for Java classes using distributional information about how they are used in software, which we combine with corpus statistics on the distribution of contexts in which the classes appear in text. Using our approach, cross-validation accuracy on this dataset can be improved dramatically, from around 60% to 88%. Human labeling results show that our classifier has an F1 score of 86% over the top 1000 predicted pairs.", "creator": "LaTeX with hyperref package"}}}