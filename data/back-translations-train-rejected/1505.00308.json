{"id": "1505.00308", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2015", "title": "Multi-Object Classification and Unsupervised Scene Understanding Using Deep Learning Features and Latent Tree Probabilistic Models", "abstract": "Deep learning has shown state-of-art classification performance on datasets such as ImageNet, which contain a single object in each image. However, multi-object classification is far more challenging. We present a unified framework which leverages the strengths of multiple machine learning methods, viz deep learning, probabilistic models and kernel methods to obtain state-of-art performance on Microsoft COCO, consisting of non-iconic images. We incorporate contextual information in natural images through a conditional latent tree probabilistic model (CLTM), where the object co-occurrences are conditioned on the extracted fc7 features from pre-trained Imagenet CNN as input. We learn the CLTM tree structure using conditional pairwise probabilities for object co-occurrences, estimated through kernel methods, and we learn its node and edge potentials by training a new 3-layer neural network, which takes fc7 features as input. Object classification is carried out via inference on the learnt conditional tree model, and we obtain significant gain in precision-recall and F-measures on MS-COCO, especially for difficult object categories. Moreover, the latent variables in the CLTM capture scene information: the images with top activations for a latent node have common themes such as being a grasslands or a food scene, and on on. In addition, we show that a simple k-means clustering of the inferred latent nodes alone significantly improves scene classification performance on the MIT-Indoor dataset, without the need for any retraining, and without using scene labels during training. Thus, we present a unified framework for multi-object classification and unsupervised scene understanding.", "histories": [["v1", "Sat, 2 May 2015 03:23:46 GMT  (3153kb)", "http://arxiv.org/abs/1505.00308v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["tejaswi nimmagadda", "anima anandkumar"], "accepted": false, "id": "1505.00308"}, "pdf": {"name": "1505.00308.pdf", "metadata": {"source": "CRF", "title": "Multi-Object Classification and Unsupervised Scene Understanding Using Deep Learning Features and Latent Tree Probabilistic Models", "authors": ["Tejaswi Nimmagadda"], "emails": ["nimmagas@uci.edu", "a.anandkumar@uci.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 5.00 308v 1 [cs.C V] 2M ayDeep Learning has demonstrated state-of-the-art classification on datasets such as ImageNet, which contain a single object in each image. However, the classification of multi-objects is much more difficult. We present a unified framework that uses the strengths of multiple machine learning methods, namely deep learning, probabilistic models and core methods, to obtain a state-of-the-art performance on Microsoft COCO, consisting of non-iconic images. We incorporate contextual information into natural images through a conditional latent tree probability model (CLTM), in which the common appearance of the object is conditioned on the basis of the extracted fc7 features from pre-trained Imagenet CNN."}, {"heading": "1 Introduction", "text": "In this context, it should be noted that this is an attempt to get to grips with the causes of the crisis, both in the United States and in the United States."}, {"heading": "1.1 Summary of Results", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they are"}, {"heading": "1.2 Related Work", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2 Overview of The Model And Algorithm", "text": "In fact, it is as if most of us are able to play by the rules that they have imposed on themselves. (...) In fact, it is as if they are able to play by the rules. (...) It is not as if they play by the rules, that they play by the rules. (...) It is as if they play by the rules. (...) It is as if they play by the rules. \"(...) It is as if they play by the rules.\" (...) It is as if they play by the rules. \"(...) It is as if they play by the rules.\" (...) It is as if they play by the rules. \"(...) It is as if they play by the rules.\" (...) It is as if they play by the rules."}, {"heading": "3 Conditional Latent Tree Model", "text": "We designate predefined training sets as D = {(x1, y1), \u00b7 \u00b7 \u00b7 (xn, yn)} and xi-R4096, yi-R4096, yi-R4096, yi-R (1, 2, \u00b7 \u00b7, n). We designate extracted tree structure from T = (Z, E), where Z indicates the quantity of observed and latent nodes and E the edge. Once we recover the structure, we use conditioned latent tree model to model P (Z | X). Condition on input X, we model the distribution of Z using the methods used under Eqn.P (Z | X) and E designates edge."}, {"heading": "3.1 Learning Latent Tree Structure", "text": "Algorithm 2 CondDistanceMatrixRequire: Input data-set D = {(x1, y1), \u00b7 \u00b7, (xn, yn)} 1: Compute Gram matrix Kn \u00b7 n using hyper-parameter \u03b3 2: for i = 1 TO i = n do 3: G = (K + \u03bbI) \u2212 1 \u00b7 K (:, i) 4: for all pairs (k, t) where k, t (1, 2, \u00b7 \u00b7, L) do 5: E [Yk'Yt | X = xi] = [y1k'y1t, y2k y2t, \u00b7 \u00b7, ynk ynt] G 6: Sk, t = | det (E'Yt | X = xi]) | 7: Compute Di [k, t] where Di [k't, t] = \u2212 log (Sk, t'provincent St, t) 8: return DL \u00d7 L = n'applied."}, {"heading": "4 Learning CLTM Using Neural Networks", "text": "Energy-based learning provides a uniform framework for many probabilistic and non-probabilistic approaches to structured output tasks [16], especially for non-probabilistic training of graphical models and other structured models. Furthermore, the absence of the normalization condition allows more flexibility in the design of learning machines. Most probabilistic models can be considered as special types of energy-based models in which the energy function fulfills certain normalization conditions and in which the loss function optimized by learning has a certain form."}, {"heading": "4.1 Inference", "text": "Consider the observed variable X and the output variable Y. Define an energy function E (X, Y) that is minimized when X and Yare compatible.The most compatible Y variable for an observed X can be expressed as Y * = argminY E (Y, X).The energy function can be expressed as a factor graph, i.e. the sum of energy functions (node and edge potentials) that depend on input covariables x.Efficient sequencing methods for factor diagrams can be used to find the optimal configuration Y *. In the following equation, we define the energy function used to model loss functions.E (x, z, zipieren.E) = action.K, Z\u03c6k (x, \u03b8) zk + \u2211 (k, t)."}, {"heading": "4.2 Training Energy Based Models using Neural Networks", "text": "The formation of an energy-based model (EBM) consists in finding an energy function that produces the best Y for each X. The search for the best energy function is carried out within a family of energy functions indexed by a parameter W. The architecture of the EBM is the internal structure of the parameterized energy function E (W, Y, X). In the case of neural networks, the family of energy functions is the set of neural network architectures and weight values. For a given neural network architecture, weights are learned by backpropagating the weight through a loss function [16]. In the case of structures with latent variables h, we use negative limit value losses (2) for training. L = E [E (W, x, y, h) | y, x] \u2212 E [E (W, y, x, h) | x] (2) And the gradient is evaluated under Eqn."}, {"heading": "5 Experiments", "text": "In this section, we show experimental results of (a) simultaneously classifying an image into multiple object categories and (b) identifying scenes from which images were created. To evaluate our model, we use the non-iconic MS COCO image dataset [20]. This dataset contains 83K training images with images labeled with 80 different object classes. The validation set contains 40K images. We use an independent classifier trained on the basis of a neural network with three layers (indep. classifier) as the starting point, and compare precision retrieval measures with our proposed conditional latent tree model. ImplementationTo avoid overfitting, we use our conditional latent tree model as a standalone layer on a neural network. The layer takes as input a set of scores \u03c6 (x, W) and Rn. These scores correspond to the node potentials of the energy function. In order to avoid overadjusting our effect, we put together the potentials below that are marginal."}, {"heading": "5.1 Structure Recovery", "text": "We use 40k randomly selected images from the training set to learn the tree structure using the distance-based method suggested in Section 3. We have the recovered tree structure in relation to 80 different objects and 22 hidden nodes in 6 appendices. From the learned tree structure we can see that hidden nodes take on the role of splitting the tree by scene category. Thus, the nodes connected to the hidden nodes h19, h22, h9 and h17 contain objects from the kitchen, bathroom, wildlife or living room. Likewise, all objects that occur in outdoor traffic scenes group around the observed node car. Note that most training images contain less than 3 cases of different object categories."}, {"heading": "5.2 Classification Performance on MS COCO", "text": "Table 1 shows the comparison of precision, recall and F measurement between three-layer neural network independent classifier and conditional latent tree model learned from 1.2 and 3-layer feed neural networks, respectively. In the case of three-layer neural network independent classifier, we use a threshold of 0.5 to make binary decisions for different object designations. For CLTM, we use the MAP configuration to make binary decisions. Note that CLTM significantly improves F measurement for indoor objects. Fig.2 shows the comparison of F measurement for each object category between baseline and CLTM trained using a three-layer neural network. Overall, the F measurement with our model is 7 percent compared to 3-layer neural network. Note that the F measurement gain for indoor objects is more significant. For difficult objects such as a skateboard, laptop, measurement gain, laptop, and wine glass is 27 percent, 19 percent, and 19 percent."}, {"heading": "5.3 Qualitative Analysis", "text": "In this section, we examine the image class that triggered the highest activation of the node potentials for different latent nodes. Figure 5 shows the top 12 images from the test set that led to the highest activation of different latent nodes. It is observed that different latent nodes effectively capture different semantic information that is common in images with adjacent object classes. For example, the top 12 images of latent nodes h9, h12, h4, h21, h3 and h5 led to an image class that appears in scenes of forest, dining table, kitchen, living room, traffic and fruit category."}, {"heading": "5.4 Scene Classification on MIT-Indoor Dataset", "text": "The hidden nodes in the CLTM model collect scene-relevant information that can be used to perform scene classification tasks. In this section, we demonstrate the scene classification capabilities of the CLTM model. We use 529 images from the MIT indoor dataset, which belong to 4 different scenes: kitchen, bathroom, living room, and bedroom. We use k-means for output of the CLTM model and a 3-layer neural network classifier for cluster images. We then optimally adapt these clusters to scenes to evaluate the misclassification rate. Note that we have never trained our model based on scene designations and only use them to validate performance. In our experiments, we use marginal probabilities of observed and hidden nodes of CLTM, marginal probabilities of hidden nodes of CLTM, and probabilities of individual classes resulting from 3-layer neural networks that are used on the input table to show remarkable 2 distinct misclassification rates."}, {"heading": "6 Conclusion and Future Work", "text": "In summary, the proposed structure restoration method allows us to restore the structure of a latent tree. This tree has a natural hierarchy of related objects that are placed in different scenes according to their common appearance. We use neural networks of different architectures to train conditional latent tree models. We evaluate CLTM on MS COCO data sets and there is a significant gain in precision, retrieval and F measurement compared to 3-layer classifiers of neural networks. Latent nodes capture different semantic information to distinguish high-grade information from images. Such information is used for scene labeling tasks in an unattended manner. In the future, we plan to model both spatial knowledge and co-event and apply the model to object localization tasks using CNN (such as RCNN)."}], "references": [{"title": "Network flows. In Optimization, pages 211\u2013369", "author": ["R. Ahuja", "T. Magnanti", "J. Orlin"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1989}, {"title": "Conditional random field autoencoders for unsupervised structured prediction", "author": ["W. Ammar", "C. Dyer", "N.A. Smith"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Learning deep structured models", "author": ["L.-C. Chen", "A.G. Schwing", "A.L. Yuille", "R. Urtasun"], "venue": "arXiv preprint arXiv:1407.2538,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Learning latent tree graphical models", "author": ["M.J. Choi", "V.Y.F. Tan", "A. Anandkumar", "A.S. Willsky"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Context models and out-of-context objects", "author": ["M.J. Choi", "A. Torralba", "A.S. Willsky"], "venue": "Pattern Recognition Letters,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "A tree-based context model for object recognition", "author": ["M.J. Choi", "A. Torralba", "A.S. Willsky"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "On the nystr&#246;m method for approximating a gram matrix for improved kernel-based learning", "author": ["P. Drineas", "M.W. Mahoney"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "The pascal visual object classes (voc) challenge", "author": ["M. Everingham", "L. Gool", "C.K. Williams", "J. Winn", "A. Zisserman"], "venue": "Int. J. Comput. Vision,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Learning a tree of metrics with disjoint visual features", "author": ["K. Grauman", "F. Sha", "S.J. Hwang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Integrated structure and parameters learning in latent tree graphical models", "author": ["F. Huang", "N.U. N", "A. Anandkumar"], "venue": "ArXiv 1406.4566,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Object bank: A high-level image representation for scene classification &amp; semantic feature sparsification", "author": ["L. jia Li", "H. Su", "L. Fei-fei", "E.P. Xing"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "arXiv preprint arXiv:1412.2306,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Loss functions for discriminative training of energy-based models", "author": ["Y. Lecun", "F. Jie", "Jhuangfu"], "venue": "Proc. of the 10-th International Workshop on Artificial Intelligence and Statistics (AIStats05,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "\u03b8-mrf: Capturing spatial and semantic structure in the parameters for scene understanding", "author": ["C. Li", "A. Saxena", "T. Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Towards total scene understanding: Classification, annotation and segmentation in an automatic framework", "author": ["L.-J. Li", "R. Socher", "L. Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Building and using a semantivisual image hierarchy", "author": ["L.-J. Li", "C. Wang", "Y. Lim", "D.M. Blei", "L. Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Microsoft COCO: common objects in context", "author": ["T. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "CoRR, abs/1405.0312,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Kernel embeddings of conditional distributions: A unified kernel framework for nonparametric inference in graphical models", "author": ["L. Song", "K. Fukumizu", "A. Gretton"], "venue": "IEEE Signal Process. Mag.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Joint training of a convolutional network and a graphical model for human pose estimation", "author": ["J.J. Tompson", "A. Jain", "Y. LeCun", "C. Bregler"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Show and tell: A neural image caption generator", "author": ["O. Vinyals", "A. Toshev", "S. Bengio", "D. Erhan"], "venue": "arXiv preprint arXiv:1411.4555,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "How transferable are features in deep neural networks", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "CoRR, abs/1411.1792,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Improving object detection with deep convolutional networks via bayesian optimization and structured prediction", "author": ["Y. Zhang", "K. Sohn", "R. Villegas", "G. Pan", "H. Lee"], "venue": "arXiv preprint arXiv:1504.03293,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Object detectors emerge in deep scene cnns", "author": ["B. Zhou", "A. Khosla", "A. Lapedriza", "A. Oliva", "A. Torralba"], "venue": "arXiv preprint arXiv:1412.6856,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Learning deep features for scene recognition using places database", "author": ["B. Zhou", "A. Lapedriza", "J. Xiao", "A. Torralba", "A. Oliva"], "venue": "In Advances in Neural Information Processing Systems, pages 487\u2013495,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}], "referenceMentions": [{"referenceID": 21, "context": "ILSVRC [22]), or binary classification, which makes binary decisions for each label independently (e.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "PASCAL VOC [8]).", "startOffset": 11, "endOffset": 14}, {"referenceID": 25, "context": "It is known that deep learning produces transferable features, which can be used to learn new tasks, which differ from tasks on which the neural networks were trained [26, 21].", "startOffset": 167, "endOffset": 175}, {"referenceID": 20, "context": "It is known that deep learning produces transferable features, which can be used to learn new tasks, which differ from tasks on which the neural networks were trained [26, 21].", "startOffset": 167, "endOffset": 175}, {"referenceID": 14, "context": "We extract features using pre-trained ImageNet CNN [15] from Caffe [12], and use it as input to the conditional latent tree model (CLTM), a type of conditional random field (CRF).", "startOffset": 51, "endOffset": 55}, {"referenceID": 11, "context": "We extract features using pre-trained ImageNet CNN [15] from Caffe [12], and use it as input to the conditional latent tree model (CLTM), a type of conditional random field (CRF).", "startOffset": 67, "endOffset": 71}, {"referenceID": 3, "context": "The tree dependency structure for this model is recovered using distance based methods [4], which requires pairwise conditional probabilities of object co-occurrences, conditioned on the input features.", "startOffset": 87, "endOffset": 90}, {"referenceID": 22, "context": "We employ the kernel conditional embedding framework [23] to compute these pairwise measures.", "startOffset": 53, "endOffset": 57}, {"referenceID": 19, "context": "We test performance of multi-object classification on a non-iconic image set Microsoft COCO [20] and we test its unsupervised scene learning capabilities on the MIT Indoor dataset [13].", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "We test performance of multi-object classification on a non-iconic image set Microsoft COCO [20] and we test its unsupervised scene learning capabilities on the MIT Indoor dataset [13].", "startOffset": 180, "endOffset": 184}, {"referenceID": 0, "context": "For validation, we match these clusters to ground truth scene categories using maximum weight matching [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 6, "context": "While general non-parametric methods are computationally expensive, and not scalable to large datasets, we employ kernel methods only to estimate pairwise conditional probabilities, which can be carried out efficiently using randomized matrix techniques [7].", "startOffset": 254, "endOffset": 257}, {"referenceID": 10, "context": "Our tree structure estimation is scalable to large datasets using recent advances in parallel techniques for structure estimation [11].", "startOffset": 130, "endOffset": 134}, {"referenceID": 5, "context": "[6, 5] learn contextual relations between co-occurring objects using a tree structure graphical model to capture dependencies among different objects.", "startOffset": 0, "endOffset": 6}, {"referenceID": 4, "context": "[6, 5] learn contextual relations between co-occurring objects using a tree structure graphical model to capture dependencies among different objects.", "startOffset": 0, "endOffset": 6}, {"referenceID": 9, "context": "In many settings, the hierarchical structure representing the contextual relations between different objects is fixed and is based on semantic similarity [10], or may rely on text, in addition to image information [19].", "startOffset": 154, "endOffset": 158}, {"referenceID": 18, "context": "In many settings, the hierarchical structure representing the contextual relations between different objects is fixed and is based on semantic similarity [10], or may rely on text, in addition to image information [19].", "startOffset": 214, "endOffset": 218}, {"referenceID": 25, "context": "[26, 9, 21].", "startOffset": 0, "endOffset": 11}, {"referenceID": 8, "context": "[26, 9, 21].", "startOffset": 0, "endOffset": 11}, {"referenceID": 20, "context": "[26, 9, 21].", "startOffset": 0, "endOffset": 11}, {"referenceID": 8, "context": "[9] term this as supervised pre-training and employ them to train regional convolutional neural networks (R-CNN) for object localization.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "While [9] employ independent SVM classifiers for each class, we believe that incorporating our probabilistic framework for multi-object localization can significantly improve performance.", "startOffset": 6, "endOffset": 9}, {"referenceID": 26, "context": "Recently, [27] propose improving object detection using Bayesian optimization for fine grained search and a structured loss function that aims at both classification and localization.", "startOffset": 10, "endOffset": 14}, {"referenceID": 28, "context": "[29, 28] introduce the places dataset and use CNNs for scene classification.", "startOffset": 0, "endOffset": 8}, {"referenceID": 27, "context": "[29, 28] introduce the places dataset and use CNNs for scene classification.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "[18] propose a hierarchical generative model that performs multiple tasks in a coherent manner.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] also consider the use of context by taking into account the spatial location of the regions of interest.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "While there is a large body of such works which use contextual information (see for instance [17]), they mostly do not incorporate latent variables in their modeling.", "startOffset": 93, "endOffset": 97}, {"referenceID": 1, "context": "For example, [2] propose to combine CRF and auto-encoder frameworks for unsupervised learning.", "startOffset": 13, "endOffset": 16}, {"referenceID": 23, "context": "Markov random fields are employed for pose estimation to encode the spatial relationships between joint locations in [24].", "startOffset": 117, "endOffset": 121}, {"referenceID": 2, "context": "[3] propose a joint framework for deep learning and probabilistic models.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "Finally, while many works have used MS-COCO for captioning and joint image-text related tasks [14, 25], there have been no attempts to improve multi-object classification over standard deep learning techniques, using images alone on MS-COCO and not the text data, to the best of our knowledge.", "startOffset": 94, "endOffset": 102}, {"referenceID": 24, "context": "Finally, while many works have used MS-COCO for captioning and joint image-text related tasks [14, 25], there have been no attempts to improve multi-object classification over standard deep learning techniques, using images alone on MS-COCO and not the text data, to the best of our knowledge.", "startOffset": 94, "endOffset": 102}, {"referenceID": 14, "context": "We consider pre-trained ImageNet [15] as a fixed feature extractor by considering the fc7 layer (4096-D vector) as the feature vector for a given input image.", "startOffset": 33, "endOffset": 37}, {"referenceID": 25, "context": "It is also demonstrated in [26] that such feature vectors can be effectively used for different tasks with different labels.", "startOffset": 27, "endOffset": 31}, {"referenceID": 3, "context": "3: Extract tree structure using [4] T \u2190 CLRG(D) 4: Training a NN with randomly initialized weights W: 5: repeat 6: randomly select a mini-batch M .", "startOffset": 32, "endOffset": 35}, {"referenceID": 6, "context": "So, we restrict using kernel methods to only evaluate pairwise conditional probabilities, and here, we can use randomized matrix methods to efficiently scale the computations [7].", "startOffset": 175, "endOffset": 178}, {"referenceID": 3, "context": "is estimated through CL grouping algorithm from [4].", "startOffset": 48, "endOffset": 51}, {"referenceID": 3, "context": "Although the method in [4] is serial, we note that recently there have been parallel versions of this method in [11].", "startOffset": 23, "endOffset": 26}, {"referenceID": 10, "context": "Although the method in [4] is serial, we note that recently there have been parallel versions of this method in [11].", "startOffset": 112, "endOffset": 116}, {"referenceID": 3, "context": "The estimated distance matrix is then used by distance-based methods for structure recovery [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 22, "context": "Kernel Embedding of Conditional Distribution The kernel conditional embedding framework, described in [23] gives us methods for modeling conditional and joint distributions.", "startOffset": 102, "endOffset": 106}, {"referenceID": 3, "context": "Among the available approaches for latent tree learning, we use the information distance based algorithm CLGrouping [4] which has provable computational efficiency guarantees.", "startOffset": 116, "endOffset": 119}, {"referenceID": 15, "context": "Energy-based learning provides a unified framework for many probabilistic and non-probabilistic approaches to structured output tasks [16], particularly for non-probabilistic training of graphical models and other structured models.", "startOffset": 134, "endOffset": 138}, {"referenceID": 15, "context": "For a given neural network architecture, weights are learned by backpropagating the gradient through some loss function [16].", "startOffset": 120, "endOffset": 124}, {"referenceID": 19, "context": "We use the non-iconic image data-set MS COCO [20] to evaluate our model.", "startOffset": 45, "endOffset": 49}], "year": 2015, "abstractText": "Deep learning has shown state-of-art classification performance on datasets such as ImageNet, which contain a single object in each image. However, multi-object classification is far more challenging. We present a unified framework which leverages the strengths of multiple machine learning methods, viz deep learning, probabilistic models and kernel methods to obtain state-of-art performance on Microsoft COCO, consisting of non-iconic images. We incorporate contextual information in natural images through a conditional latent tree probabilistic model (CLTM), where the object co-occurrences are conditioned on the extracted fc7 features from pre-trained Imagenet CNN as input. We learn the CLTM tree structure using conditional pairwise probabilities for object co-occurrences, estimated through kernel methods, and we learn its node and edge potentials by training a new 3-layer neural network, which takes fc7 features as input. Object classification is carried out via inference on the learnt conditional tree model, and we obtain significant gain in precision-recall and F-measures on MS-COCO, especially for difficult object categories. Moreover, the latent variables in the CLTM capture scene information: the images with top activations for a latent node have common themes such as being a grasslands or a food scene, and on on. In addition, we show that a simple k-means clustering of the inferred latent nodes alone significantly improves scene classification performance on the MIT-Indoor dataset, without the need for any retraining, and without using scene labels during training. Thus, we present a unified framework for multi-object classification and unsupervised scene understanding.", "creator": "LaTeX with hyperref package"}}}