{"id": "1505.00855", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2015", "title": "Large-scale Classification of Fine-Art Paintings: Learning The Right Metric on The Right Feature", "abstract": "In the past few years, the number of fine-art collections that are digitized and publicly available has been growing rapidly. With the availability of such large collections of digitized artworks comes the need to develop multimedia systems to archive and retrieve this pool of data. Measuring the visual similarity between artistic items is an essential step for such multimedia systems, which can benefit more high-level multimedia tasks. In order to model this similarity between paintings, we should extract the appropriate visual features for paintings and find out the best approach to learn the similarity metric based on these features. We investigate a comprehensive list of visual features and metric learning approaches to learn an optimized similarity measure between paintings. We develop a machine that is able to make aesthetic-related semantic-level judgments, such as predicting a painting's style, genre, and artist, as well as providing similarity measures optimized based on the knowledge available in the domain of art historical interpretation. Our experiments show the value of using this similarity measure for the aforementioned prediction tasks.", "histories": [["v1", "Tue, 5 May 2015 01:25:26 GMT  (1438kb,D)", "http://arxiv.org/abs/1505.00855v1", "21 pages"]], "COMMENTS": "21 pages", "reviews": [], "SUBJECTS": "cs.CV cs.IR cs.LG cs.MM", "authors": ["babak saleh", "ahmed elgammal"], "accepted": false, "id": "1505.00855"}, "pdf": {"name": "1505.00855.pdf", "metadata": {"source": "CRF", "title": "Large-scale Classification of Fine-Art Paintings: Learning The Right Metric on The Right Feature", "authors": ["Babak Saleh", "Ahmed Elgammal"], "emails": ["babaks@cs.rutgers.edu", "elgammal@cs.rutgers.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want to do and what they want to do."}, {"heading": "2 Related Work", "text": "In the field of painting, computers have been used for a variety of tasks. In addition, image processing techniques have been used to provide art historians with pigment analysis, statistical quantification of brush strokes, etc. We refer the reader to comprehensive surveys on this topic. Several studies deal with the question of which features should be used in the paintings. Most research into the classification of paintings uses low-level features that include the color, texture and edges."}, {"heading": "3 Methodology", "text": "In this section, we explain the methodology we use to find the most appropriate combination of visual characteristics and indicators that produce accurate similarity measurements. We acquire these indicators to mimic the ability of an art historian to categorize paintings based on their style, genre and the artist who created them. In the first step, we extract visual characteristics from the image. These visual characteristics range from low (e.g. edges) to high (e.g. objects in painting). More importantly, the next step is to learn to adapt these characteristics to various classification tasks by learning the corresponding indicators. Based on the indicators we have learned, we are able to project paintings from a high-dimensional space with raw visual information into a meaningful space with much smaller dimensions. In addition, learning a classification in this low-dimensional space for large collections can be easily scaled. In the rest of this section, we will explain our collection and what to do in front of this section."}, {"heading": "3.1 Dataset and Proposed Tasks", "text": "To collect our visual art collection, we used the publicly available data set \"Wikiart paintings\" 4, which to our knowledge is the largest online public collection of digitized artworks. This collection includes 81,449 fineart paintings by 1,119 artists from fifteen centuries to contemporary artists. These paintings come from 27 different styles (Abstract, Byzantium, Baroque, etc.) and 45 different genres (Interior, Landscape, etc.) Previous works [26, 9] used different resources and made smaller collections with limited variability in style, genre, and artist. The work of [4] is closest to our work in terms of data collection methods, but the number of images in their collection is half of below. We aim to automatically classify paintings based on their style, genre, and artist, using visual features that are automatically extracted using computer vision algorithms. \"Each of these tasks has its own challenges and major limitations. For example, http / 4 / there are larger limitations."}, {"heading": "3.2 Classification Methodology", "text": "To classify paintings based on their style, genre or artist, we followed three methods. Metric Learning: First, as shown in Figure 1, we extract visual features from images of paintings. For each of these prediction tasks, we learn a similarity metric that is optimized for them, i.e., we project the raw visual features into the new optimized space and learn classifiers for the corresponding prediction task. To this end, we learn a projector to a corresponding feature that is optimized for the corresponding task. After learning the metric, we project the raw visual features into the new optimized space and learn classifiers for the corresponding prediction task. To this end, we learn a set of one-on-all SVM classifiers for each of the designations in Table 1 for each of the tasks. While our initial strategy focuses on classification on combinations of a metric and builds a visual feature, the next two methods we merge, which we followed different metrics."}, {"heading": "3.3 Visual Features", "text": "Visual features in computer vision literature are either constructed and extracted in an unattended manner (e.g. HOG, GIST) or learned based on the optimization of a particular task, typically categorizing objects or scenes (e.g. CNN-based features).This results in high-dimensional feature vectors that may not be necessary to correspond to designable (semantic) properties of an image. Based on the ability to find a meaning, visual features can be categorized into low and high levels. Low-level features are visual descriptors that have no explicit meaning for each dimension of them, while high-level visual features are designed to capture some concepts (usually objects).For this work, we examined some state-of-the-art representatives of these two categories: Low-level features are visual descriptors that have no explicit meaning for each dimension of them, while high-level visual features are designed to capture some of the characteristics (in general)."}, {"heading": "3.4 Metric Learning", "text": "The purpose of Metric Learning is to find some pairs of real rated functions dM (x, x) that are not negative, symmetrical, obeys the triangular inequality and yields zero if and only if x and x \"is the same point. Training such a function in a general form can be considered as the following optimization problem: min M l (M, D) + 2) This optimization has two sides, first it tries to minimize the amount of loss l (M, D) by trying to adjust the model by the regulatory term R (M). The first term shows the accuracy of the trained metrics and secondly its ability to minimize over new data and avoids overmatching. Based on the forced constraints, the resulting metric may be linear or non-linear and depending on the amount of labels used for training."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Setting", "text": "We have followed the initial implementation of Oliva and Torralba to obtain a 512-dimensional feature vector. For Classeme and Picodes, we have followed the implementation of Bergamo et al. [29], which has resulted in 2659-dimensional classeme features and 2048-dimensional picodes. We have used the implementation of Vedaldi and Lenc [30] to create 1000-dimensional feature vectors of the last layer of CNN.Object-based representations of the images produce feature vectors that are much higher in dimensional picodes features."}, {"heading": "4.2 Classification Experiments", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "5 Conclusion and Future Works", "text": "In this essay, we examined the applicability of metric learning approaches and the performance of various visual characteristics in order to learn similarity in a collection of paintings of visual arts. We implemented significant metrics for measuring similarity between paintings. These metrics are learned under supervision to place paintings from a concept close to each other and far from others. In this work, we used three concepts: style, genre and artist. We used these acquired metrics to transform raw visual characteristics into another space so that we can significantly improve performance for three important tasks of classification of style, genre and artist. We conducted our comparative experiments with the largest publicly available dataset of paintings of visual arts to evaluate the performance for the above tasks. We conclude: - Classeme characteristics show the superior performance for all three tasks of style, genre or artist classification. We performed our comparative experiments with the largest publicly available dataset of visual arts to evaluate the performance for the above tasks. We concluded: - Classeme characteristics show the superior performance for all three tasks of style, genre or artist classification. - This superior performance is independent of the metric representation of the individual types of metric information we have learned. - In this case, the metric performance is independent of the metric representation of the three tasks."}], "references": [{"title": "Csift: A sift descriptor with color invariant characteristics", "author": ["A.E. Abdel-Hakim", "A.A. Farag"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Visual thinking", "author": ["R. Arnheim"], "venue": "Univ of California Press,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1969}, {"title": "Towards automated classification of fine-art painting style: A comparative study", "author": ["R.S. Arora", "A.M. Elgammal"], "venue": "ICPR,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Classification of artistic styles using binarized features derived from a deep neural network", "author": ["Y. Bar", "N. Levy", "L. Wolf"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Computer Vision and Image Analysis of Art: Proceedings of the SPIE Electronic Imaging Symposium, San Jose Convention Center, 18-22 January 2010", "author": ["A. Bentkowska-Kafel", "J. Coddington"], "venue": "PROCEEDINGS OF SPIE.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Automatic extraction of brushstroke orientation from paintings", "author": ["I.E. Berezhnoy", "E.O. Postma", "H.J. van den Herik"], "venue": "Machine Vision and Applications,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Classemes and other classifier-based features for efficient object categorization", "author": ["A. Bergamo", "L. Torresani"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, page 1,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Picodes: Learning a compact code for novel-category recognition", "author": ["A. Bergamo", "L. Torresani", "A.W. Fitzgibbon"], "venue": "Advances in Neural Information Processing Systems, pages 2088\u20132096,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Artistic image classification: An analysis on the printart database", "author": ["G. Carneiro", "N.P. da Silva", "A.D. Bue", "J.P. Costeira"], "venue": "In ECCV,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "International Conference on Computer Vision & Pattern Recognition, volume 2, pages 886\u2013893, June", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Information-theoretic metric learning", "author": ["J.V. Davis", "B. Kulis", "P. Jain", "S. Sra", "I.S. Dhillon"], "venue": "ICML,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Foundations of Art and Design", "author": ["L. Fichner-Rathus"], "venue": "Clark Baxter,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Neighbourhood components analysis", "author": ["J. Goldberger", "S. Roweis", "G. Hinton", "R. Salakhutdinov"], "venue": "NIPS,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Image processing for artist identification", "author": ["C.R. Johnson", "E. Hendriks", "I.J. Berezhnoy", "E. Brevdo", "S.M. Hughes", "I. Daubechies", "J. Li", "E. Postma", "J.Z. Wang"], "venue": "Signal Processing Magazine, IEEE, 25(4):37\u201348,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Studying digital imagery of ancient paintings by mixtures of stochastic models", "author": ["J. Li", "J.Z. Wang"], "venue": "Image Processing, IEEE Transactions on, 13(3):340\u2013353,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "Rhythmic brushstrokes distinguish van gogh from his contemporaries: Findings via automated brushstroke extraction", "author": ["J. Li", "L. Yao", "E. Hendriks", "J.Z. Wang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "The classification of style in fine-art painting", "author": ["T.E. Lombardi"], "venue": "ETD Collection for Pace University. Paper AAI3189084.,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["D.G. Lowe"], "venue": "Int. J. Comput. Vision,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "A digital technique for art authentication", "author": ["S. Lyu", "D. Rockmore", "H. Farid"], "venue": "Proceedings of the National Academy of Sciences of the United States of America, 101(49):17006\u201317010,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "author": ["A. Oliva", "A. Torralba"], "venue": "IJCV,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Detection of forgery in paintings using supervised learning", "author": ["G. Polatkan", "S. Jafarpour", "A. Brasoveanu", "S. Hughes", "I. Daubechies"], "venue": "16th IEEE International Conference on Image Processing (ICIP),", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Hierarchical classification of paintings using face- and brush stroke models", "author": ["R. Sablatnig", "P. Kammerer", "E. Zolda"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Knowledge discovery of artistic influences: A metric learning approach", "author": ["B. Saleh", "K. Abe", "A. Elgammal"], "venue": "ICCC,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Positive semidefinite metric learning using boosting-like algorithms", "author": ["C. Shen", "J. Kim", "L. Wang", "A. van den Hengel"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Computer vision and computer graphics analysis of paintings and drawings: An introduction to the literature", "author": ["D.G. Stork"], "venue": "Computer Analysis of Images and Patterns, pages 9\u201324. Springer,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Efficient object category recognition using classemes", "author": ["L. Torresani", "M. Szummer", "A. Fitzgibbon"], "venue": "ECCV,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Matconvnet \u2013 convolutional neural networks for matlab", "author": ["A. Vedaldi", "K. Lenc"], "venue": "CoRR, abs/1412.4564,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Metric learning for kernel regression", "author": ["K. Weinberger", "G. Tesauro"], "venue": "Eleventh international conference on artificial intelligence and statistics, pages 608\u2013615,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "JMLR,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 1, "context": "Learning and judging such complex visual concepts is an impressive ability of human perception [2].", "startOffset": 95, "endOffset": 98}, {"referenceID": 11, "context": "To this might be added physical attributes, like brush strokes as well as subject matter and other descriptive concepts [13].", "startOffset": 120, "endOffset": 124}, {"referenceID": 17, "context": "[19, 20]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 18, "context": "[19, 20]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "[24].", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "We refer the reader to [28, 5] for comprehensive surveys on this subject.", "startOffset": 23, "endOffset": 30}, {"referenceID": 4, "context": "We refer the reader to [28, 5] for comprehensive surveys on this subject.", "startOffset": 23, "endOffset": 30}, {"referenceID": 18, "context": "For example Lombardi [20] has presented a study of the performance of these types of features for the task of artist classification among a small set of artists using several supervised and unsupervised learning methodologies.", "startOffset": 21, "endOffset": 25}, {"referenceID": 23, "context": "[25, 18, 22, 15, 6, 19]).", "startOffset": 0, "endOffset": 23}, {"referenceID": 16, "context": "[25, 18, 22, 15, 6, 19]).", "startOffset": 0, "endOffset": 23}, {"referenceID": 20, "context": "[25, 18, 22, 15, 6, 19]).", "startOffset": 0, "endOffset": 23}, {"referenceID": 13, "context": "[25, 18, 22, 15, 6, 19]).", "startOffset": 0, "endOffset": 23}, {"referenceID": 5, "context": "[25, 18, 22, 15, 6, 19]).", "startOffset": 0, "endOffset": 23}, {"referenceID": 17, "context": "[25, 18, 22, 15, 6, 19]).", "startOffset": 0, "endOffset": 23}, {"referenceID": 19, "context": "Researchers also investigated the use of features based on local edge orientation histograms, such as SIFT [21] and HOG [10].", "startOffset": 107, "endOffset": 111}, {"referenceID": 9, "context": "Researchers also investigated the use of features based on local edge orientation histograms, such as SIFT [21] and HOG [10].", "startOffset": 120, "endOffset": 124}, {"referenceID": 2, "context": "[3] presented a comparative study for the task of style classification, which evaluated low-level features, such as SIFT and Color SIFT [1], versus semanticlevel features, namely Classemes [29], which encodes object presence in the image.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[3] presented a comparative study for the task of style classification, which evaluated low-level features, such as SIFT and Color SIFT [1], versus semanticlevel features, namely Classemes [29], which encodes object presence in the image.", "startOffset": 136, "endOffset": 139}, {"referenceID": 27, "context": "[3] presented a comparative study for the task of style classification, which evaluated low-level features, such as SIFT and Color SIFT [1], versus semanticlevel features, namely Classemes [29], which encodes object presence in the image.", "startOffset": 189, "endOffset": 193}, {"referenceID": 8, "context": "Carneiro et al [9] also concluded that low-level texture and color features are not effective because of inconsistent color and texture patterns that describe the visual classes in paintings.", "startOffset": 15, "endOffset": 18}, {"referenceID": 24, "context": "More recently, Saleh et al [26] used metric learning approaches for finding influence paths between painters based on their paintings.", "startOffset": 27, "endOffset": 31}, {"referenceID": 24, "context": "Moreover, The dataset of [26] has only 1710 images from 66 artists, while we conducted our experiments on 81,449 images painted by 1119 artists.", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "Bar et al [4] proposed an approach for style classification based on features obtained from a convolution neural network pre-trained on an image categorization task.", "startOffset": 10, "endOffset": 13}, {"referenceID": 24, "context": ") Previous work [26, 9] used different resources and made smaller collections with limited variability in terms of style, genre and artists.", "startOffset": 16, "endOffset": 23}, {"referenceID": 8, "context": ") Previous work [26, 9] used different resources and made smaller collections with limited variability in terms of style, genre and artists.", "startOffset": 16, "endOffset": 23}, {"referenceID": 3, "context": "The work of [4] is the closest to our work in terms of data collection procedure, but the number of images in their collection is half of ours.", "startOffset": 12, "endOffset": 15}, {"referenceID": 21, "context": "For this work, we investigated some state-of-the-art representatives of these two categories: Low-level Features: On one hand, in order to capture low-level visual information we extracted GIST features [23], which are holistic features that are designed for scene categorization.", "startOffset": 203, "endOffset": 207}, {"referenceID": 27, "context": "Learned Semantic-level Features: On the other hand, for the purpose of semantic representation of the images, we extracted three object-based representation of the images: Classeme [29], Picodes [8], and CNN-based features [16].", "startOffset": 181, "endOffset": 185}, {"referenceID": 7, "context": "Learned Semantic-level Features: On the other hand, for the purpose of semantic representation of the images, we extracted three object-based representation of the images: Classeme [29], Picodes [8], and CNN-based features [16].", "startOffset": 195, "endOffset": 198}, {"referenceID": 14, "context": "Learned Semantic-level Features: On the other hand, for the purpose of semantic representation of the images, we extracted three object-based representation of the images: Classeme [29], Picodes [8], and CNN-based features [16].", "startOffset": 223, "endOffset": 227}, {"referenceID": 6, "context": "We followed the implementation of [7] and for each image extracted a 2659 dimensional real-valued Classeme feature vector and a 2048 dimensional binary-value Picodes feature.", "startOffset": 34, "endOffset": 37}, {"referenceID": 15, "context": "Convolutional Neural Networks(CNN) [17] showed a remarkable performance for the task of large-scale image categorization [16].", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "Convolutional Neural Networks(CNN) [17] showed a remarkable performance for the task of large-scale image categorization [16].", "startOffset": 121, "endOffset": 125}, {"referenceID": 3, "context": "Bar et al [4] showed that a combination of the", "startOffset": 10, "endOffset": 13}, {"referenceID": 14, "context": "Following this observation we used the last layer of a pre-trained CNN [16] (1000 dimensional real-valued vectors) as another feature vector.", "startOffset": 71, "endOffset": 75}, {"referenceID": 12, "context": "Neighborhood Component Analysis (NCA) The objective function of NCA [14] is related to analyzing the nearest neighbors.", "startOffset": 68, "endOffset": 72}, {"referenceID": 30, "context": "Large Margin Nearest Neighbors (LMNN) LMNN [32] is an approach for learning a Mahalanobis distance, which is widely used because of its global optimum solution and superior performance in practice.", "startOffset": 43, "endOffset": 47}, {"referenceID": 30, "context": "Due to the popularity of LMNN, different variations of it have been introduced, including a non-linear version called gb-LMNN [32] which we used in our experiments", "startOffset": 126, "endOffset": 130}, {"referenceID": 25, "context": "Shen et al [27] use this fact and instead of learning M , finds a set of weaker metrics that can be combined and give the final metric.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "Davis et al [11] introduce the measure of LogDet divergence regularization between two matrices M,M \u2032(can be interpreted as metrics).", "startOffset": 12, "endOffset": 16}, {"referenceID": 29, "context": "Metric Learning for Kernel Regression (MLKR) Similar to NCA objective function, which minimizes the classification error; Weinberger and Tesauro [31] learn a metric by optimizing the leave-one-out error for the task of kernel regression.", "startOffset": 145, "endOffset": 149}, {"referenceID": 21, "context": "We followed the original implementation of Oliva and Torralba [23] to get a 512 dimensional feature vector.", "startOffset": 62, "endOffset": 66}, {"referenceID": 27, "context": "For Classeme and Picodes we used the implementation of Bergamo et al [29], resulting in 2659 dimensional Classeme features and 2048 dimensional Picodes features.", "startOffset": 69, "endOffset": 73}, {"referenceID": 28, "context": "We used the implementation of Vedaldi and Lenc [30] to extract 1000 dimensional feature vectors of the last layer of CNN.", "startOffset": 47, "endOffset": 51}, {"referenceID": 30, "context": "Metric Learning We used implementation of [32] to learn LMNN metric(both version of linear and non-linear) and MLKR 5.", "startOffset": 42, "endOffset": 46}, {"referenceID": 25, "context": "For the BoostMetric we slightly adjusted the implementation of [27].", "startOffset": 63, "endOffset": 67}, {"referenceID": 3, "context": "The work of Bar et al [4] is the most similar to ours and we compare our final results of these experiments with their reported performance.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "[4] only performed the task", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "However [4] extract a 3882 dimensional feature vector to their best reported performance.", "startOffset": 8, "endOffset": 11}], "year": 2015, "abstractText": "In the past few years, the number of fine-art collections that are digitized and publicly available has been growing rapidly. With the availability of such large collections of digitized artworks comes the need to develop multimedia systems to archive and retrieve this pool of data. Measuring the visual similarity between artistic items is an essential step for such multimedia systems, which can benefit more high-level multimedia tasks. In order to model this similarity between paintings, we should extract the appropriate visual features for paintings and find out the best approach to learn the similarity metric based on these features. We investigate a comprehensive list of visual features and metric learning approaches to learn an optimized similarity measure between paintings. We develop a machine that is able to make aesthetic-related semantic-level judgments, such as predicting a painting\u2019s style, genre, and artist, as well as providing similarity measures optimized based on the knowledge available in the domain of art historical interpretation. Our experiments show the value of using this similarity measure for the aforementioned prediction tasks.", "creator": "LaTeX with hyperref package"}}}