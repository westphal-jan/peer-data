{"id": "1505.01221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2015", "title": "The Configurable SAT Solver Challenge (CSSC)", "abstract": "It is well known that different solution strategies work well for different types of instances of hard combinatorial problems. As a consequence, most solvers for the propositional satisfiability problem (SAT) expose parameters that allow them to be customized to a particular family of instances. In the international SAT competition series, these parameters are ignored: solvers are run using a single default parameter setting (supplied by the authors) for all benchmark instances in a given track. While this competition format rewards solvers with robust default settings, it does not reflect the situation faced by a practitioner who only cares about performance on one particular application and can invest some time into tuning solver parameters for this application. The new Configurable SAT Solver Competition (CSSC) compares solvers in this latter setting, scoring each solver by the performance it achieved after a fully automated configuration step. This article describes the CSSC in more detail, and reports the results obtained in its two instantiations so far, CSSC 2013 and 2014.", "histories": [["v1", "Tue, 5 May 2015 23:39:24 GMT  (1203kb,D)", "http://arxiv.org/abs/1505.01221v1", null], ["v2", "Tue, 2 Aug 2016 08:48:53 GMT  (5750kb,D)", "http://arxiv.org/abs/1505.01221v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["frank hutter", "marius lindauer", "adrian balint", "sam bayless", "holger hoos", "kevin leyton-brown"], "accepted": false, "id": "1505.01221"}, "pdf": {"name": "1505.01221.pdf", "metadata": {"source": "CRF", "title": "The Configurable SAT Solver Challenge (CSSC)", "authors": ["Frank Hutter", "Marius Lindauer", "Adrian Balint", "Sam Bayless", "Holger Hoos", "Kevin Leyton-Brown"], "emails": ["fh@cs.uni-freiburg.de", "lindauer@cs.uni-freiburg.de", "adrian.balint@uni-ulm.de", "sbayless@cs.ubc.ca", "hoos@cs.ubc.ca", "kevinlb@cs.ubc.ca"], "sections": [{"heading": null, "text": "Different solving strategies for different types of hard combinatorial problems are known to work well. As a result, these parameters are ignored by most solvers of the Propositional Satifiability Problem (SAT): solvers are executed with a single default parameter setting (provided by the authors) for all benchmark instances in a particular track. While this competition format rewards solvers with robust defaults, it does not reflect the situation faced by a user who only cares about the performance of a particular application and can invest some time in matching solver parameters for that application. The new Configurable SAT Solver Competition (CSSC) compares solvers in this latter setting and evaluates each solver based on the performance achieved after a fully automated configuration step."}, {"heading": "1. Introduction", "text": "This year it has come to the point where there is such a process, in which there is such a process."}, {"heading": "2. Design Criteria for the CSSC", "text": "We organized the CSSC 2013 and 2014 in coordination with the international SAT competition and presented it in the 2013 and 2014 competition phases at SAT conferences (as well as in the 2014 FLoC Olympic Games, in which all SAT competitions participated); we coordinated the submission deadlines with the SAT contest to minimize the effort for participants who could submit their solver using standard parameters; and then opened their parameter rooms to the CSSC. We designed the CSSC to stay close to the established SAT competition; in particular, we used the same general categories: industry, crafts and chance, and in 2014 also random situations; and we also used the same input and output formats to ensure the SAT contest to verify the veracity of the solution approaches."}, {"heading": "2.1. Controlled Execution of Solver Runs", "text": "Since all configuration processes were fully automated, they had to be robust against any kind of solution errors (segmentation errors, unsupported parameter combinations, wrong results, infinite loops, etc.) We handled all such conditions in a generic wrapper script that Olivier Roussel's runsolver tool [71] used to limit runtime and memory, and counted all errors or boundary violations as timeouts at the maximum runtime of 300 seconds. We also kept track of the extensive runtime data we collected in our configuration runs and made them available on the competition website."}, {"heading": "2.2. Choice of Configuration Pipeline", "text": "In order to avoid prejudice arising from our choice of algorithm configuration method, we have independently used all three state-of-the-art runtime optimization methods (ParamILS, GGA, and SMAC, as described in detail in Section 3). We have evaluated the configurations resulting from all configuration runs on the entire training data set and selected the configuration with the best training performance. Subsequently, we have executed only this configuration on the test set to determine the performance of the configured solver. Unless expressly stated otherwise, all performance data we report in this article refer to this optimized configuration on previously invisible test instances from the respective benchmark set."}, {"heading": "2.3. Choice of Benchmarks", "text": "Typically, we chose benchmark families that were neither too simple (since acceleration is less interesting for simple instances) nor too hard (so that solvers can solve a large portion of the instances within the available computing budgets); we aimed for benchmark sets, at least 20-40% of which could be solved within the maximum runtime of a current machine through the standard configuration of a SAT solver that would perform reasonably well in the SAT competition; we also aimed for benchmark sets with a sufficient number of instances to protect against overtuning; in practice, the smallest data sets we used had 500 instances: 250 for training and 250 for testing."}, {"heading": "3. Automated Algorithm Configuration Procedures", "text": "& & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & &"}, {"heading": "4. The Configurable SAT Solver Challenge 2013", "text": "The first CSSC (http: / / www.cs.ubc.ca / labs / beta / Projects / CSSC2013 /) took place in 2013. It contained three tracks similar to those of the SAT competition: Industrial SAT + UNSAT, Crafted SAT + UNSAT and Random SAT + UNSAT. Table 1 lists the benchmark families we used in each of these tracks, all of which are described in detail in Appendix A. Within each track, we used the same number of test instances for each benchmark family, giving us equal weighting of each in our analysis."}, {"heading": "4.1. Participating Solvers and Their Parameters", "text": "This year, it is only a matter of time before a solution is found."}, {"heading": "4.2. Configuration Pipeline", "text": "Since our budget for each configuration procedure was two CPU days to five cores for each scenario, conducting the contest required 990 CPU days per configuration approach. We ran this contest on the QDR partition of the Compute Canada Westgrid Cluster Orcinus. Each node in this cluster was provided with 24 GB of memory and two 6-core, 2.66 GHz Intel Xeon X5650 CPUs, each with 12 MB L2 cache, and we ran Red Hat Enterprise Linux Server 5.5 (Kernel 2.6.18, glibc 2.5). Unfortunately, in this first edition of the CSSC, we were unable to run a GGA, due to the fact that it required multiple cores for effective runtime minimization, and the respective multi-core jobs we submitted to the Orcinus Cluster were queued for months without starting the configuration."}, {"heading": "4.3. Results", "text": "For each of the three tracks of CSSC 2013, we configured each of the eleven submitted solvers for each of the benchmark families within the track and aggregated the results across each test instance. We show the winners in Table 3 and discuss the results for each track in the following sections. Further details, tables and illustrations are included in an accompanying technical report [42]."}, {"heading": "4.3.1. Results of the Industrial SAT+UNSAT Track", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "4.3.2. Results of the crafted SAT+UNSAT Track", "text": "The created SAT + UNSAT track consisted of the two created benchmarks, which are detailed in Appendix A.2: Graph Isomorphism (GI) and Low Autocorrelation Binary Sequence (LABS).Figure 2 illustrates the improvements made by configuring the algorithm for the most powerful solver clasp-3.0.4-p8 of these benchmarks. Particularly significant were the improvements in the GI instances, where the algorithm configuration increased the number of timeouts from 42 to 6. Table 5 summarizes the results we achieved for all solvers among these benchmarks, and shows that the configuration also significantly improved the performance of many other solvers. Furthermore, the table aggregates the results of both benchmark families to achieve overall results for the created SAT + UNSAT track. While Forl-nodrup showed the best standard performance and benefited significantly from the configuration (# Timeouts improved from 135 to # 13.04-3p), even improved from 13.04-3p."}, {"heading": "4.3.3. Results of the Random SAT+UNSAT Track", "text": "The Random SAT + UNSAT Track consisted of three random benchmarks described in detail in Appendix A.3: 5sat500, K3 and unif-k5. The instances in 5sat500 were all satisfactory, those in unif-k5 were all unsatisfactory and those in K3 were mixed. Table 6 summarizes the results for these benchmarks. It shows that the unif-k5 benchmark set was very simple for complete solvers (although the configuration still yielded up to four times the speed), that the K3 benchmark was quite simple even for the best solvers, and that only the SLS solvers were able to handle the 5sat500 benchmark, with the configuration representing a large performance difference.Again, our overall results show that the rankings differed considerably between the standard and configured versions of the solvers: the three solvers with the best standard performance ranked 4th to 6th in the CSSC and vice versa."}, {"heading": "4.4. Hors-Concours Solver Riss3gExt", "text": "This year, it is closer than ever before to being able to unite."}, {"heading": "5. The Configurable SAT Solver Challenge 2014", "text": "The second CSSC (http: / / aclib.net / cssc2014 /) was held in 2014. Compared to the first CSSC in 2013, we improved the competition design in several ways: \u2022 We used a different computing cluster4, which enabled us to execute GGA as one of the configuration methods.3Personal communication with Riss3gExt's developer Norbert Manthey. 4We conducted this competition on the META cluster of the University of Freiburg, whose computing nodes contained 64GB of RAM and two 2.60GHz Intel Xeon E5-2650v2 8-core CPUs, each with 20MB L2 cache, on the Ubuntu 14.04 LTS, 64 bit. \u2022 We added a random SAT track to compare stochastic local search solutions. \u2022 We dropped the (too simple) SWV benchmark family and introduced four new benchmark families, which resulted in a total of three benchmark families in each of the four tracks, each of which we should summarize in a larger space, each of which we should decide on the number of authors."}, {"heading": "5.1. Participating Solvers", "text": "This year it is more than ever before in the history of the city."}, {"heading": "5.2. Configuration Pipeline", "text": "In CSSC 2014, we used the ParamILS, GGA, and SMAC configurators. For each benchmark and solver, we used GGA and SMAC on the complete configuration space of the solver, which could contain any combination of numerical and categorical parameters. We also used all configurators on a discredited version of the configuration space (which was automatically created unless provided by the solver authors), resulting in a total of five configuration approaches: ParamILS - discredited, GGA, GGA-discredited, SMAC -discredited, and SMAC. GGA could not handle the complex conditions of some solvers, so we only implemented ParamILS and the two SMAC variants for these solvers. Due to the cost of operating a third configurator on almost every scenario, we reduced the budget for each configuration approach from two days to two CPU variants."}, {"heading": "5.3. Results", "text": "For each of the four CSSC 2014 tracks, we have configured the solvers submitted for each of the three benchmark families from that track, and aggregated results for each test instance. We show the winners for each track in Table 9 and discuss the results in the following sections. Further details, tables and illustrations are included in an accompanying technical report [47]."}, {"heading": "5.3.1. Results of the Industrial SAT+UNSAT Track", "text": "In fact, it is not the case that we would be able to find a solution that would allow us to solve the problems, \"he told the Deutsche Presse-Agentur in an interview with the\" Frankfurter Allgemeine Zeitung \"(Friday)."}, {"heading": "5.3.2. Results of the crafted SAT+UNSAT Track", "text": "This year, it has come to the point where it only takes one year to get to the next round."}, {"heading": "5.3.3. Results of the Random SAT+UNSAT Track", "text": "The Random SAT + UNSAT Track consisted of three random benchmarks described in detail in Appendix A.3. The instances in unif-k5 are all unsatisfactory, while the other two sets contain both satisfactory and unsatisfactory instances. Figure 6 illustrates the improvements achieved by configuring these benchmarks for the most powerful solver clasp-3.0.4-p8. Clasp-3.0.4-p8 benefited most from the configuration on benchmark 3cnf, where it reduced the number of timeouts from 18 to 0. For the other benchmarks, it has already solved all instances in its standard parameter configuration, but the configuration helped reduce its average runtime by factors 3 (K3) and 2 (unif-k5). Table 12 summarizes the results of all solvers for these benchmarks."}, {"heading": "5.3.4. Results of the Random SAT Track", "text": "The random SAT track consisted of the three benchmarks listed in Appendix A.3: 3sat1k, 5sat500 and 7sat90. Figure 7 illustrates the improvements achieved with these benchmarks for the most powerful solver ProbSAT. ProbSAT benefited most from the configuration on the benchmark 5sat500: its default did not solve a single instance in the maximum runtime of 300 seconds, while its configured version solved all instances in an average runtime of less than 2 seconds! Since timeouts in 300s result in a PAR 10 score of 3000, the PAR 10 speedup factor on this benchmark was 1,500, the largest we have observed in the CSSC. On the other two scenarios, the configuration was also very advantageous, reducing the number of timeouts on ProbSAT from 24 to 0 (7sat90) and on SATS from 10 to 4 (3sat1k)."}, {"heading": "6. Post-Competition Analyses", "text": "While the previous sections focused on the results of the respective contests, we will now discuss several analyses that we have subsequently carried out to investigate overarching phenomena and general patterns. The results for CSSC 2014 Random SAT track10 \u2212 2 10 \u2212 1 1 10 100Default in sec.10 \u2212 210 \u2212 1110100C o n fi g u red i n se c.2x2x10x100x300timeouttim eout (a) 3sat1k PAR-10: 132 \u2192 5310 \u2212 2 10 \u2212 1 10 100Default in sec.10 \u2212 1110100C o n figures in c.2x10x300x300timeouttim eout (b) 5sat500 \u2212 2 CSAR-10 \u2212 1 100 Default in sec.10 \u2212 10 \u2212 1 Sagid in sec.10 \u2212 210 SAR-103000 o o n figures in c.2x10x100x300x300timeouttim eout (b) 5sat500 \u2212 10 \u2212 10 \u2212 1 Sagid in sec.10 \u2212 1010 \u2212 1010 \u2212 1010 SAR \u2212 1111."}, {"heading": "6.1. Overall Configurability of Solvers", "text": "Some solvers consistently benefited more from the configuration than others. Here, we quantify the configurability of a solver based on a preset benchmark by the PAR-10 acceleration factor that its configured version achieved over its standard version, calculated based on instances solved by at least one of the two. Then, we examine the relationship between configurability and the number of parameters to determine whether solvers with many parameters consistently benefited from the configuration compared to solvers with few parameters. 55 Of course, it is easy to construct examples where a solver is highly configurable with a single parameter (for example, let the parameter have a poor default configuration) or where a solver has many parameters but does not benefit at all from the configuration (for example, a solver might expose many parameters that are not actually used at all)."}, {"heading": "6.2. Impact of Configuration Budget", "text": "In an extreme case, if we let this budget go toward zero, the configuration pipeline returns the solver specifications (and we are back to default SAT competition). For small, not zero budgets, we can expect solvers with few parameters to benefit more from the configuration, as their configuration spaces are easier to find. On the other hand, if we increase the time budget, solvers with larger parameter spaces will probably benefit more than those with smaller parameter spaces (since larger portions of their configuration space can be searched due to additional time)."}, {"heading": "6.3. Results with a Single Configurator", "text": "While the CSSC was looking at the performance of the SAT solvers, not the performance of the configurators, we were asked whether our complex configuration pipeline was necessary or whether a single configurator would have produced similar or identical results. In fact, our pipeline would have used five configuration approaches (ParamILS-discredited, GGA-discredited, GGA-discredited, SMAC-discredited, and SMAC) if one of these approaches alone had produced the same results. To determine whether this was the case, we evaluated the solar performance we would have observed if we had used each configuration approach in isolation. For each configuration scenario and approach, we calculated the PAR-10 deceleration factor above the CSSC result, as the PAR-10 configuration is split by each configuration."}, {"heading": "7. Conclusion", "text": "In this article we described the design of the configurable SAT Solver Challenge (CSSC) and the details of the CSSC 2013 and CSSC 2014. We highlighted two important insights we gained from this competition. 1. Automated algorithm configuration has indeed significantly improved performance by producing average accelerations of orders of magnitude. 2. Some solvers have benefited more from automated configuration than others, resulting in significantly different algorithm rankings after configuration than before."}, {"heading": "Acknowledgements", "text": "Many thanks to Kevin Tierney for his generous help in running GGA, including the addition of new features, his suggestion of parameter settings and his conversion script for reading the pcs format. We also thank the solver developers for proofreading the description of their solvers and their parameters. We thank Compute Canada (CSSC 2013) and the German Research Foundation (DFG; CSSC 2014) for the computing resources needed to conduct the competition. F. Hutter and M. Lindauer thank the DFG for funding this research as part of the Emmy Noether Fellowship HU 1900 / 2-1. H. Hoos grants the NSERC Discovery Grant."}, {"heading": "Appendix A. Benchmark Sets Used", "text": "In 2014, we also included a category of satisfactory random instances from the SAT races. For each of these categories, we used different benchmark sets, each of which resulted in a training set for algorithm configuration and a disjoint test set.For each category, in order to balance all benchmarks equally, we used the same number of test instances from each benchmark; these test sets were consistently randomly sampled from the respective complete test sets. All benchmarks are summarized in Tables 1 and 7 in the main text."}, {"heading": "Appendix A.1. Industrial Benchmark Sets", "text": "SWV. This set of SAT-encoded software verification instances consists of 604 instances originally created with the static checker CALYSTO [4], which was used to verify five programs: the spam filter Dspam, the SAT solver HyperSAT, the Wine Windows OS emulator, the gzip archiver and a component of xinetd (a secure version of inetd). We used the same training / test split as Hutter et al. (2007), which contained 302 training instances and 302 testing instances. We used this benchmark set in the CSSC of 2013. (In 2014 we used it only for preliminary testing, as it is quite simple for modern solvers.) Hardware Verification (IBM), which contains 302 training instances and 302 testing instances."}, {"heading": "Appendix A.2. Crafted Benchmark Sets", "text": "Graph Isomorphism (GI) These instances were first used in the 2013 SAT Competition [66] and generated by encoding the graph isomorphism problem to SAT according to the procedure described by Torn (2013). Faced with two graphs G1 and G2 with n vertices and m edges (for which the isomorphism problem is to be solved), the generator generates a SAT formula with n2 variables and O (n) + O (n3) + O (n4) clauses. Consequently, the generated instances can contain a large number of clauses. The 2 064 SAT instances in this set were generated from different types of graphs. We divide the instances equally into 1 032 training instances and 1 032 test instances that we used in both the 2013 and 2014 CSSCSCSCs."}, {"heading": "Appendix A.3. Random Benchmark Sets", "text": "This is a set of 600 randomly generated 3-SAT instances at the phase transition (variable ratio clause of about 4.26), comprising both satisfactory and unsatisfactory instances; the set consists of 100 instances each containing 200 variables (853 clauses), 225 variables (960 clauses), 250 variables (1066 clauses), 275 variables (1172 clauses), and 325 variables (1385 clauses); these 600 instances were generated by Lin Xu using the random instancer from the SAT competition and were previously described by Bayless et al."}, {"heading": "Appendix A.4. Instance Features Used for these Benchmark Sets", "text": "As described in Appendix B.3, SMAC can use instance functions to guide its search. Such instance functions were mainly studied in the work on SATzilla for algorithm selection [68, 82] and in machine learning models for predicting algorithm runtime [48]. These functions range from simple summary statistics, such as the number of variables or clauses in an instance, to the results of short, runtime-limited probes with local search solvers. In the context of algorithm configuration, we can afford slightly more expensive functions than in algorithm selection, as we only need them on the training instances (not on the test instances) and can calculate them once offline. Nevertheless, we kept the cost of function determination low in order not to significantly increase the time required for algorithm configuration. For the instance sets, in which we already had available instance functions from previous work, we used these functions to calculate the ATZ SATM, specifically SATZ 11500, which we used for SATS 11500."}, {"heading": "Appendix B. Configuration Procedures", "text": "This appendix describes the configuration procedures we use in detail. Configurators typically perform the following steps: (1) execute the target algorithm on one or more instances with one or more configurations for a limited period of time; (2) measure the resulting performance metric; and (3) decide on the next execution of the target algorithm. In addition to the key question of which configuration to try next, configurators must also decide how many runs and which instances to use for each evaluation, and after which time unsuccessful runs must be terminated. ParamILS, SMAC, and GGA differ in how they initiate these components."}, {"heading": "Appendix B.1. ParamILS: Local Search in Configuration Space", "text": "ParamILS is an algorithm that is reflected in the strategy of how many runs are to be evaluated. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves. - Most of them are able to identify themselves."}, {"heading": "Appendix B.2. GGA: Gender-based Genetic Algorithm", "text": "This year is the highest in the history of the country."}, {"heading": "Appendix B.3. SMAC: Sequential Model-based Algorithm Configuration", "text": "Unlike the model-free configurators ParamILS and GGA, SMAC [45] is a sequential model-based algorithm configuration method, which means that it uses predictive models of algorithm performance [48] to guide its search for good configurations. More specifically, it uses previously observed < configuration, performance > pairs < \u03b8, f (\u03b8) > to learn a random forest of regression trees (see, e.g. [22]) expressing a function f: as."}], "references": [{"title": "A gender-based genetic algorithm for the automatic configuration of algorithms", "author": ["C. Ans\u00f3tegui", "M. Sellmann", "K. Tierney"], "venue": "Proceedings of the Fifteenth International Conference on Principles and Practice of Constraint Programming (CP\u201909),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Predicting learnt clauses quality in modern SAT solvers", "author": ["G. Audemard", "L. Simon"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Structural abstraction of software verification conditions", "author": ["D. Babi\u0107", "A. Hu"], "venue": "Proceedings of the international conference on Computer Aided Verification (CAV\u201907),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Exploiting shared structure in software verification conditions", "author": ["D. Babi\u0107", "A.J. Hu"], "venue": "Proceedings of the International Conference on Hardware and Software: Verification and Testing (HVC\u201908),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Spear theorem prover. Solver description, SAT competition", "author": ["D. Babi\u0107", "F. Hutter"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Proceedings of SAT Competition 2013: Solver and Benchmark Descriptions, volume B- 2013-1 of Department of Computer Science Series of Publications B. University of Helsinki", "author": ["A. Balint", "A. Belov", "M. Heule", "M. J\u00e4rvisalo"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Choosing probability distributions for stochastic local search and the role of make versus break", "author": ["A. Balint", "U. Sch\u00f6ning"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Using CSP look-back techniques to solve real-world SAT instances", "author": ["R.J. Bayardo Jr.", "R. Schrag"], "venue": "Proceedings of the Fourteenth National Conference on Artificial Intelligence", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "Evaluating instance generators by configuration", "author": ["S. Bayless", "D. Tompkins", "H. Hoos"], "venue": "Proceedings of the Eighth International Conference on Learning and Intelligent Optimization (LION\u201914), Lecture Notes in Computer Science. Springer-Verlag", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Hard SAT instances based on factoring", "author": ["J. Bebel", "H. Yuen"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Proceedings of SAT Competition 2014: Solver and Benchmark Descriptions, volume B- 2014-2 of Department of Computer Science Series of Publications B. University of Helsinki", "author": ["A. Belov", "D. Diepold", "M. Heule", "M. J\u00e4rvisalo"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "The sat4j library, release 2.2, system description", "author": ["D.L. Berre", "A. Parrain"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "The AIGER and-inverter graph (AIG) format. Available at fmv.jku.at/aiger", "author": ["A. Biere"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Lingeling, Plingeling and Treengeling entering the SAT competition", "author": ["A. Biere"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Yet another local search solver and Lingeling and friends entering the SAT competition", "author": ["A. Biere"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Benchmarks from the 2008 hardware model checking competition (HWMCC\u201908)", "author": ["A. Biere", "A. Cimatti", "K.L. Claessen", "T. Jussila", "K. McMillan", "F. Somenzi"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Symbolic model checking using SAT procedures instead of BDDs", "author": ["A. Biere", "A. Cimatti", "E. Clarke", "M. Fujita", "Y. Zhu"], "venue": "In Proceedings of Design Automation Conference (DAC\u201999),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1999}, {"title": "Detecting cardinality constraints in CNF", "author": ["A. Biere", "D. Le Berre", "E. Lonca", "N. Manthey"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Automated testing and debugging of SAT and QBF solvers", "author": ["R. Brummayer", "F. Lonsing", "A. Biere"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs", "author": ["C. Cadar", "D. Dunbar", "D.R. Engler"], "venue": "In Proceedings of the 8th USENIX conference on Operating systems design and implementation (OSDI\u201908),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "A tool for checking ANSI-C programs. In Tools and Algorithms for the Construction and Analysis of Systems", "author": ["E. Clarke", "D. Kroening", "F. Lerda"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "The complexity of theorem proving procedures", "author": ["S. Cook"], "venue": "Proceedings of the Third Annual ACM Symposium on the Theory of Computing", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1971}, {"title": "Experimental results on the application of satisfiability algorithms to scheduling problems", "author": ["J. Crawford", "A. Baker"], "venue": "In Proceedings of the national conference on Artificial Intelligence (AAAI\u201994),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1994}, {"title": "gNovelty+GC: Weight-Enhanced Diversification on Stochastic Local Search for SAT", "author": ["Duong", "T.-T", "Pham", "D.-N"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "An extensible sat-solver", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "Proceedings of the Sixth International Conference on Theory and Applications of Satisfiability Testing (SAT\u201903),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2003}, {"title": "The first learning track of the international planning competition", "author": ["A. Fern", "R. Khardon", "P. Tadepalli"], "venue": "Machine Learning,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Conflict-driven answer set solving: From theory to practice", "author": ["M. Gebser", "B. Kaufmann", "T. Schaub"], "venue": "Artificial Intelligence,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Toward leaner binary-clause reasoning in a satisfiability solver", "author": ["A.V. Gelder"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2005}, {"title": "Heavy-tailed phenomena in satisfiability and constraint satisfaction problems", "author": ["C. Gomes", "B. Selman", "N. Crato", "H. Kautz"], "venue": "Journal of Automated Reasoning.,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2000}, {"title": "Simpsat 1.0 for sat challenge", "author": ["Han", "C.-S"], "venue": "Proceedings of SAT Challenge", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2012}, {"title": "When Boolean satisfiability meets Gaussian elimination in a simplex way", "author": ["Han", "C.-S", "Jiang", "J.-H"], "venue": "Computer Aided Verification,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "On-the-fly clause improvement", "author": ["H. Han", "F. Somenzi"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Efficient CNF simplification based on binary implication graphs", "author": ["M.J. Heule", "M. Jrvisalo", "A. Biere"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}, {"title": "Stochastic Local Search: Foundations & Applications", "author": ["H. Hoos", "T. Sttzle"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2004}, {"title": "Programming by optimization", "author": ["H.H. Hoos"], "venue": "Commun. ACM,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Boosting verification by automatic tuning of decision procedures", "author": ["F. Hutter", "D. Babi\u0107", "H. Hoos", "A. Hu"], "venue": "Formal Methods in Computer Aided Design (FMCAD\u201907),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2007}, {"title": "Results of the Configurable SAT Solver Challenge", "author": ["F. Hutter", "A. Balint", "S. Bayless", "H. Hoos", "K. Leyton-Brown"], "venue": "Technical Report 276,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Tradeoffs in the empirical evaluation of competing algorithm designs", "author": ["F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "Annals of Mathematics and Artificial Intelligenc (AMAI), Special Issue on Learning and Intelligent Optimization,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2010}, {"title": "Bayesian optimization with censored response data", "author": ["F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "In NIPS workshop on Bayesian Optimization,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2011}, {"title": "Sequential modelbased optimization for general algorithm configuration", "author": ["F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "Proceedings of the Fifth International Conference on Learning and Intelligent Optimization (LION\u201911),", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2011}, {"title": "ParamILS: An automatic algorithm configuration framework", "author": ["F. Hutter", "H. Hoos", "K. Leyton-Brown", "T. St\u00fctzle"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2009}, {"title": "Results of the Configurable SAT Solver Challenge", "author": ["F. Hutter", "M. Lindauer", "S. Bayless", "H. Hoos", "K. Leyton-Brown"], "venue": "Technical Report 277,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}, {"title": "Algorithm runtime prediction: Methods and evaluation", "author": ["F. Hutter", "L. Xu", "H. Hoos", "K. Leyton-Brown"], "venue": "Artificial Intelligence,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2014}, {"title": "The international SAT solver competitions", "author": ["M. J\u00e4rvisalo", "D.L. Berre", "O. Roussel", "L. Simon"], "venue": "AI Magazine,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "Blocked clause elimination", "author": ["M. J\u00e4rvisalo", "A. Biere", "M.J. Heule"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2010}, {"title": "Pushing the envelope: Planning, propositional logic, and stochastic search", "author": ["H. Kautz", "B. Selman"], "venue": "Proceedings of the Thirteenth National Conference on Artificial Intelligence and the Eighth Innovative Applications of Artificial Intelligence Conference,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1996}, {"title": "Unifying SAT-based and graph-based planning", "author": ["H. Kautz", "B. Selman"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2014}, {"title": "SATenstein: Automatically building local search sat solvers from components", "author": ["A. KhudaBukhsh", "L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": null, "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2009}, {"title": "The irace package, iterated race for automatic algorithm configuration", "author": ["M. L\u00f3pez-Ib\u00e1\u00f1ez", "J. Dubois-Lacoste", "T. St\u00fctzle", "M. Birattari"], "venue": "Technical report,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2011}, {"title": "Iterated local search. In Handbook of Metaheuristics (pp. 321\u2013353)", "author": ["H. Louren\u00e7o", "O. Martin", "T. St\u00fctzle"], "venue": null, "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2003}, {"title": "Focused random walk with configuration checking and break minimum for satisfiability", "author": ["C. Luo", "S. Cai", "W. Wu", "K. Su"], "venue": "Proceedings of the Ninth International Conference on Principles and Practice of Constraint Programming (CP\u201913),", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2012}, {"title": "Double configuration checking in stochastic local search for satisfiability", "author": ["C. Luo", "S. Cai", "W. Wu", "K. Su"], "venue": "Proceedings of the Twenty-eighth National Conference on Artificial Intelligence", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2014}, {"title": "Probing-based preprocessing techniques for propositional satisfiability", "author": ["I. Lynce", "J.P. Marques-Silva"], "venue": "IEEE International Conference on Tools with Artificial Intelligence,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2003}, {"title": "Coprocessor 2.0\u2013a flexible CNF simplifier", "author": ["N. Manthey"], "venue": null, "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2012}, {"title": "The SAT solver RISS3G at SC", "author": ["N. Manthey"], "venue": null, "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2013}, {"title": "Automated reencoding of Boolean formulas", "author": ["N. Manthey", "M.J. Heule", "A. Biere"], "venue": null, "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2013}, {"title": "Formula simplifications as DRAT derivations", "author": ["N. Manthey", "T. Philipp"], "venue": "KI 2014: Advances in Artificial Intelligence,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2014}, {"title": "Too many rooks", "author": ["N. Manthey", "P. Steinke"], "venue": null, "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2014}, {"title": "2013a). Sat encoded graph isomorphism benchmark description", "author": ["F. Mugrauer", "A. Balint"], "venue": null, "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2013}, {"title": "Sat encoded low autocorrelation binary sequence (labs) benchmark description", "author": ["F. Mugrauer", "A. Balint"], "venue": null, "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2013}, {"title": "Understanding random sat: Beyond the clauses-to-variables ratio", "author": ["E. Nudelman", "K. Leyton-Brown", "H.H. Hoos", "A. Devkar", "Y. Shoham"], "venue": "Proceedings of the Tenth International Conference on Principles and Practice of Constraint Programming (CP\u201904),", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2004}, {"title": "Minisat hack 999ed, minisat hack 1430ed and swdia5by", "author": ["C. Oh"], "venue": null, "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2014}, {"title": "A survey of recent advances in SAT-based formal verification", "author": ["M. Prasad", "A. Biere", "A. Gupta"], "venue": "International Journal on Software Tools for Technology Transfer,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2005}, {"title": "Controlling a solver execution with the runsolver tool", "author": ["O. Roussel"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2011}, {"title": "Fast downward SMAC", "author": ["J. Seipp", "S. Sievers", "F. Hutter"], "venue": "Planner abstract,", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2014}, {"title": "The sat2002 competition report", "author": ["L. Simon", "D.L. Berre", "E. Hirsch"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2005}, {"title": "Extending SAT solvers to cryptographic problems", "author": ["M. Soos", "K. Nohl", "C. Castelluccia"], "venue": null, "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2009}, {"title": "Combinational test generation using satisfiability", "author": ["P. Stephan", "R. Brayton", "A. Sangiovanni-Vencentelli"], "venue": "IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 1996}, {"title": "Auto- WEKA: combined selection and hyperparameter optimization of classification algorithms", "author": ["C. Thornton", "F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD\u201913),", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 2013}, {"title": "Captain jack: New variable selection heuristics in local search for sat", "author": ["D. Tompkins", "A. Balint", "H. Hoos"], "venue": null, "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2009}, {"title": "On the resolution complexity of graph non-isomorphism", "author": ["J. Torn"], "venue": "Theory and Applications of Satisfiability Testing SAT 2013,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2013}, {"title": "Another look at graph coloring via propositional satisfiability", "author": ["A. van Gelder"], "venue": "In Proceedings of Computational Symposium on Graph Coloring and Generalizations (COLOR-02),", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2002}, {"title": "SATzilla: Portfolio-based algorithm selection for SAT", "author": ["L. Xu", "F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 2008}], "referenceMentions": [{"referenceID": 21, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 196, "endOffset": 208}, {"referenceID": 62, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 196, "endOffset": 208}, {"referenceID": 20, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 196, "endOffset": 208}, {"referenceID": 67, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 231, "endOffset": 239}, {"referenceID": 19, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 231, "endOffset": 239}, {"referenceID": 45, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 253, "endOffset": 261}, {"referenceID": 46, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 253, "endOffset": 261}, {"referenceID": 22, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 274, "endOffset": 278}, {"referenceID": 71, "context": "It is relevant both for theory (having been the first problem proven to be NP-hard [27]) and for practice (having important applications in many fields, such as hardware and software verification [19, 70, 26], test-case generation [77, 24], AI planning [51, 52], scheduling [28], and graph colouring [81]).", "startOffset": 300, "endOffset": 304}, {"referenceID": 43, "context": "The SAT community has a long history of regularly assessing the state of the art via competitions [49].", "startOffset": 98, "endOffset": 102}, {"referenceID": 65, "context": "2002 [74], and the event has been growing over time: in 2014, it had a record participation of 58 solvers by 79 authors in 11 tracks [13].", "startOffset": 5, "endOffset": 9}, {"referenceID": 10, "context": "2002 [74], and the event has been growing over time: in 2014, it had a record participation of 58 solvers by 79 authors in 11 tracks [13].", "startOffset": 133, "endOffset": 137}, {"referenceID": 2, "context": "In practical applications of SAT, solvers can typically be adjusted to perform well for the specific type of instances at hand, such as software verification instances generated by a particular static checker on a particular software system [3], or a particular family of bounded model checking instances [83].", "startOffset": 241, "endOffset": 244}, {"referenceID": 35, "context": "Solvers typically come with robust default parameter settings meant to provide good all-round performance, but it is widely known that adjusting parameter settings to particular target instance classes can yield orders-of-magnitude speedups [41, 53, 79].", "startOffset": 241, "endOffset": 253}, {"referenceID": 47, "context": "Solvers typically come with robust default parameter settings meant to provide good all-round performance, but it is widely known that adjusting parameter settings to particular target instance classes can yield orders-of-magnitude speedups [41, 53, 79].", "startOffset": 241, "endOffset": 253}, {"referenceID": 69, "context": "Solvers typically come with robust default parameter settings meant to provide good all-round performance, but it is widely known that adjusting parameter settings to particular target instance classes can yield orders-of-magnitude speedups [41, 53, 79].", "startOffset": 241, "endOffset": 253}, {"referenceID": 64, "context": "(In fact, the 2014 IPC learning track for non-portfolio solvers was won by FastDownward-SMAC [73], a system that employs a similar combination of general algorithm configuration and a highly parameterized solver framework as we do in the CSSC.", "startOffset": 93, "endOffset": 97}, {"referenceID": 28, "context": "We based this choice partly on the fact that many solvers have runtime distributions with rather long tails (or even heavy tails [34]), and that practitioners often use many instances and relatively short runtimes to benchmark solvers for a new application domain.", "startOffset": 129, "endOffset": 133}, {"referenceID": 37, "context": "There is also evidence that SAT competition results would remain quite similar if based on shorter runtimes, but not if based on fewer instances [43].", "startOffset": 145, "endOffset": 149}, {"referenceID": 63, "context": "We handled all such conditions in a generic wrapper script that used Olivier Roussel\u2019s runsolver tool [71] to limit runtime and memory, and counted any errors or limit violations as timeouts at the maximum runtime of 300 seconds.", "startOffset": 102, "endOffset": 106}, {"referenceID": 40, "context": "In recent years, the AI community has developed several dedicated systems for this general algorithm configuration problem [46, 1, 55, 45].", "startOffset": 123, "endOffset": 138}, {"referenceID": 0, "context": "In recent years, the AI community has developed several dedicated systems for this general algorithm configuration problem [46, 1, 55, 45].", "startOffset": 123, "endOffset": 138}, {"referenceID": 48, "context": "In recent years, the AI community has developed several dedicated systems for this general algorithm configuration problem [46, 1, 55, 45].", "startOffset": 123, "endOffset": 138}, {"referenceID": 39, "context": "In recent years, the AI community has developed several dedicated systems for this general algorithm configuration problem [46, 1, 55, 45].", "startOffset": 123, "endOffset": 138}, {"referenceID": 35, "context": "[41] configured the algorithm Spear [5] on formal verification instances, achieving a 500-fold speedup on software verification instances generated with the static checker Calysto [3] and a 4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[41] configured the algorithm Spear [5] on formal verification instances, achieving a 500-fold speedup on software verification instances generated with the static checker Calysto [3] and a 4.", "startOffset": 36, "endOffset": 39}, {"referenceID": 2, "context": "[41] configured the algorithm Spear [5] on formal verification instances, achieving a 500-fold speedup on software verification instances generated with the static checker Calysto [3] and a 4.", "startOffset": 180, "endOffset": 183}, {"referenceID": 47, "context": "Algorithm configuration has also enabled the development of general frameworks for stochastic local search SAT solvers that can be automatically instantiated to yield state-of-the-art performance on new types of instances; examples for such frameworks are SATenstein [53] and Captain Jack [79].", "startOffset": 267, "endOffset": 271}, {"referenceID": 69, "context": "Algorithm configuration has also enabled the development of general frameworks for stochastic local search SAT solvers that can be automatically instantiated to yield state-of-the-art performance on new types of instances; examples for such frameworks are SATenstein [53] and Captain Jack [79].", "startOffset": 289, "endOffset": 293}, {"referenceID": 40, "context": "While all of these applications used the local-search based algorithm configuration method ParamILS [46], in the CSSC we wanted to avoid bias that could", "startOffset": 100, "endOffset": 104}, {"referenceID": 40, "context": "1An alternative definition considers the optimization of expected performance across a distribution of instances rather than average performance across a set of instances [46].", "startOffset": 171, "endOffset": 175}, {"referenceID": 0, "context": "arise from commitment to one particular algorithm configuration method and thus used all three existing general algorithm configuration methods for runtime optimization: ParamILS , GGA [1], and SMAC [45].", "startOffset": 185, "endOffset": 188}, {"referenceID": 39, "context": "arise from commitment to one particular algorithm configuration method and thus used all three existing general algorithm configuration methods for runtime optimization: ParamILS , GGA [1], and SMAC [45].", "startOffset": 199, "endOffset": 203}, {"referenceID": 7, "context": "The eleven submitted solvers ranged from complete solvers based on conflict-directed clause learning (CDCL; [10]) to stochastic local search (SLS; [39]) solvers.", "startOffset": 108, "endOffset": 112}, {"referenceID": 33, "context": "The eleven submitted solvers ranged from complete solvers based on conflict-directed clause learning (CDCL; [10]) to stochastic local search (SLS; [39]) solvers.", "startOffset": 147, "endOffset": 151}, {"referenceID": 48, "context": "2We did not use the iterated racing method I/F-Race [55], since it does not effectively support runtime optimization and its authors thus discourage its use for this purpose (personal communication with Manuel L\u00f3pez-Ib\u00e1\u00f1ez and Thomas St\u00fctzle).", "startOffset": 52, "endOffset": 56}, {"referenceID": 3, "context": "0k 182k\u00b1 206k [4] IBM 383 302 96.", "startOffset": 14, "endOffset": 17}, {"referenceID": 18, "context": "3k [23] BMC 807 302 446k\u00b1 992k 1.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "70m [18] GI 1032 351 11.", "startOffset": 4, "endOffset": 8}, {"referenceID": 58, "context": "03m [66, 80] LABS 350 351 75.", "startOffset": 4, "endOffset": 12}, {"referenceID": 70, "context": "03m [66, 80] LABS 350 351 75.", "startOffset": 4, "endOffset": 12}, {"referenceID": 59, "context": "7k 154k\u00b1 153k [67] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 5sat500 250 250 500\u00b1 0 10000\u00b1 0 [79]", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "7k 154k\u00b1 153k [67] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 5sat500 250 250 500\u00b1 0 10000\u00b1 0 [79]", "startOffset": 48, "endOffset": 52}, {"referenceID": 69, "context": "7k 154k\u00b1 153k [67] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 5sat500 250 250 500\u00b1 0 10000\u00b1 0 [79]", "startOffset": 117, "endOffset": 121}, {"referenceID": 23, "context": "subset Gnovelty+GCa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+GCwa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+PCL 5 0 0 0 20 000 \u2013 \u2013 [29] Simpsat 5 0 0 0 2 400 \u2013 \u2013 [35] Sat4j 10 0 0 4 2\u00d7 10 \u2013 \u2013 [14] Solver43 12 0 0 0 5\u00d7 10 \u2013 \u2013 [6] Forl-nodrup 44 0 0 0 3\u00d7 10 \u2013 \u2013 [76] Clasp-2.", "startOffset": 36, "endOffset": 40}, {"referenceID": 23, "context": "subset Gnovelty+GCa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+GCwa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+PCL 5 0 0 0 20 000 \u2013 \u2013 [29] Simpsat 5 0 0 0 2 400 \u2013 \u2013 [35] Sat4j 10 0 0 4 2\u00d7 10 \u2013 \u2013 [14] Solver43 12 0 0 0 5\u00d7 10 \u2013 \u2013 [6] Forl-nodrup 44 0 0 0 3\u00d7 10 \u2013 \u2013 [76] Clasp-2.", "startOffset": 71, "endOffset": 75}, {"referenceID": 23, "context": "subset Gnovelty+GCa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+GCwa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+PCL 5 0 0 0 20 000 \u2013 \u2013 [29] Simpsat 5 0 0 0 2 400 \u2013 \u2013 [35] Sat4j 10 0 0 4 2\u00d7 10 \u2013 \u2013 [14] Solver43 12 0 0 0 5\u00d7 10 \u2013 \u2013 [6] Forl-nodrup 44 0 0 0 3\u00d7 10 \u2013 \u2013 [76] Clasp-2.", "startOffset": 108, "endOffset": 112}, {"referenceID": 29, "context": "subset Gnovelty+GCa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+GCwa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+PCL 5 0 0 0 20 000 \u2013 \u2013 [29] Simpsat 5 0 0 0 2 400 \u2013 \u2013 [35] Sat4j 10 0 0 4 2\u00d7 10 \u2013 \u2013 [14] Solver43 12 0 0 0 5\u00d7 10 \u2013 \u2013 [6] Forl-nodrup 44 0 0 0 3\u00d7 10 \u2013 \u2013 [76] Clasp-2.", "startOffset": 139, "endOffset": 143}, {"referenceID": 11, "context": "subset Gnovelty+GCa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+GCwa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+PCL 5 0 0 0 20 000 \u2013 \u2013 [29] Simpsat 5 0 0 0 2 400 \u2013 \u2013 [35] Sat4j 10 0 0 4 2\u00d7 10 \u2013 \u2013 [14] Solver43 12 0 0 0 5\u00d7 10 \u2013 \u2013 [6] Forl-nodrup 44 0 0 0 3\u00d7 10 \u2013 \u2013 [76] Clasp-2.", "startOffset": 169, "endOffset": 173}, {"referenceID": 66, "context": "subset Gnovelty+GCa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+GCwa 2 0 0 0 110 \u2013 \u2013 [29] Gnovelty+PCL 5 0 0 0 20 000 \u2013 \u2013 [29] Simpsat 5 0 0 0 2 400 \u2013 \u2013 [35] Sat4j 10 0 0 4 2\u00d7 10 \u2013 \u2013 [14] Solver43 12 0 0 0 5\u00d7 10 \u2013 \u2013 [6] Forl-nodrup 44 0 0 0 3\u00d7 10 \u2013 \u2013 [76] Clasp-2.", "startOffset": 237, "endOffset": 241}, {"referenceID": 26, "context": "3 42 34 7 60 \u221e 10 \u2013 [32] Riss3g 125 0 0 107 2\u00d7 10 \u2013 \u2013 [61] Riss3gExt 193 0 0 168 2\u00d7 10 \u2013 \u2013 [61] Lingeling 102 139 0 0 1\u00d7 10 1\u00d7 10 2\u00d7 10 [16]", "startOffset": 20, "endOffset": 24}, {"referenceID": 54, "context": "3 42 34 7 60 \u221e 10 \u2013 [32] Riss3g 125 0 0 107 2\u00d7 10 \u2013 \u2013 [61] Riss3gExt 193 0 0 168 2\u00d7 10 \u2013 \u2013 [61] Lingeling 102 139 0 0 1\u00d7 10 1\u00d7 10 2\u00d7 10 [16]", "startOffset": 54, "endOffset": 58}, {"referenceID": 54, "context": "3 42 34 7 60 \u221e 10 \u2013 [32] Riss3g 125 0 0 107 2\u00d7 10 \u2013 \u2013 [61] Riss3gExt 193 0 0 168 2\u00d7 10 \u2013 \u2013 [61] Lingeling 102 139 0 0 1\u00d7 10 1\u00d7 10 2\u00d7 10 [16]", "startOffset": 91, "endOffset": 95}, {"referenceID": 13, "context": "3 42 34 7 60 \u221e 10 \u2013 [32] Riss3g 125 0 0 107 2\u00d7 10 \u2013 \u2013 [61] Riss3gExt 193 0 0 168 2\u00d7 10 \u2013 \u2013 [61] Lingeling 102 139 0 0 1\u00d7 10 1\u00d7 10 2\u00d7 10 [16]", "startOffset": 136, "endOffset": 140}, {"referenceID": 23, "context": "Gnovelty+GCa and Gnovelty+GCwa [29] are closely related SLS solvers.", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "Gnovelty+PCL [29] is an SLS solver with five parameters: one binary parameter (determining whether the stagnation path is dynamic or static) and four numerical parameters: the length of the stagnation path, the size of the time window storing stagnation paths, the probability of smoothing stagnation weights, and the probability of smoothing clause weights.", "startOffset": 13, "endOffset": 17}, {"referenceID": 29, "context": "Simpsat [35] is a CDCL solver based on Cryptominisat [75], which adds additional strategies for explicitly handling XOR constraints [36].", "startOffset": 8, "endOffset": 12}, {"referenceID": 30, "context": "Simpsat [35] is a CDCL solver based on Cryptominisat [75], which adds additional strategies for explicitly handling XOR constraints [36].", "startOffset": 132, "endOffset": 136}, {"referenceID": 11, "context": "Sat4j [14] is full-featured library of solvers for Boolean satisfiability and optimization problems.", "startOffset": 6, "endOffset": 10}, {"referenceID": 66, "context": "Forl-nodrup [76] is a CDCL solver with 44 parameters.", "startOffset": 12, "endOffset": 16}, {"referenceID": 26, "context": "3 [32] is a solver for the more general answer set programming (ASP) problem, but it can also solve SAT, MAXSAT and PB problems.", "startOffset": 2, "endOffset": 6}, {"referenceID": 54, "context": "Riss3g [61] is a CDCL solver with 125 parameters.", "startOffset": 7, "endOffset": 11}, {"referenceID": 24, "context": "These include 6 numerical parameters from MiniSAT [30], 10 numerical parameters from Glucose [2], 17 mostly numerical Riss3G parameters, and 92 parameters controlling preprocessing/inprocessing performed by the integrated Coprocessor [60].", "startOffset": 50, "endOffset": 54}, {"referenceID": 1, "context": "These include 6 numerical parameters from MiniSAT [30], 10 numerical parameters from Glucose [2], 17 mostly numerical Riss3G parameters, and 92 parameters controlling preprocessing/inprocessing performed by the integrated Coprocessor [60].", "startOffset": 93, "endOffset": 96}, {"referenceID": 53, "context": "These include 6 numerical parameters from MiniSAT [30], 10 numerical parameters from Glucose [2], 17 mostly numerical Riss3G parameters, and 92 parameters controlling preprocessing/inprocessing performed by the integrated Coprocessor [60].", "startOffset": 234, "endOffset": 238}, {"referenceID": 13, "context": "parameters resemble those in Lingeling [16], emphasizing blocked clause elimination [50], bounded variable addition [63], and probing [59].", "startOffset": 39, "endOffset": 43}, {"referenceID": 44, "context": "parameters resemble those in Lingeling [16], emphasizing blocked clause elimination [50], bounded variable addition [63], and probing [59].", "startOffset": 84, "endOffset": 88}, {"referenceID": 55, "context": "parameters resemble those in Lingeling [16], emphasizing blocked clause elimination [50], bounded variable addition [63], and probing [59].", "startOffset": 116, "endOffset": 120}, {"referenceID": 52, "context": "parameters resemble those in Lingeling [16], emphasizing blocked clause elimination [50], bounded variable addition [63], and probing [59].", "startOffset": 134, "endOffset": 138}, {"referenceID": 54, "context": "Riss3gExt [61] is an experimental extension of Riss3g .", "startOffset": 10, "endOffset": 14}, {"referenceID": 13, "context": "Lingeling [16] is a CDCL solver with 241 parameters (making it the solver with the largest configuration space in the CSSC 2013).", "startOffset": 10, "endOffset": 14}, {"referenceID": 36, "context": "Additional details, tables, and figures are provided in an accompanying technical report [42].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "1: Bounded Model Checking 2008 (BMC) [15], Circuit Fuzz [23], Hardware Verification (IBM) [83], and SWV [4].", "startOffset": 37, "endOffset": 41}, {"referenceID": 18, "context": "1: Bounded Model Checking 2008 (BMC) [15], Circuit Fuzz [23], Hardware Verification (IBM) [83], and SWV [4].", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "1: Bounded Model Checking 2008 (BMC) [15], Circuit Fuzz [23], Hardware Verification (IBM) [83], and SWV [4].", "startOffset": 104, "endOffset": 107}, {"referenceID": 18, "context": "3k [23] BMC 604 302 424k\u00b1 843k 1.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "30m [18] GI 1032 351 11.", "startOffset": 4, "endOffset": 8}, {"referenceID": 58, "context": "03m [66, 80] LABS 350 351 75.", "startOffset": 4, "endOffset": 12}, {"referenceID": 70, "context": "03m [66, 80] LABS 350 351 75.", "startOffset": 4, "endOffset": 12}, {"referenceID": 59, "context": "7k 154k\u00b1 153k [67] N-Rooks 484 351 38.", "startOffset": 14, "endOffset": 18}, {"referenceID": 57, "context": "4k 125k\u00b1 126k [65] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] 3cnf 500 250 350\u00b1 0 1493\u00b1 0 [12] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 3sat1k 250 250 500\u00b1 0 10000\u00b1 0 [79] 5sat500 250 250 1000\u00b1 0 4260\u00b1 0 [79] 7sat90 250 250 90\u00b1 0 7650\u00b1 0 [79]", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "4k 125k\u00b1 126k [65] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] 3cnf 500 250 350\u00b1 0 1493\u00b1 0 [12] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 3sat1k 250 250 500\u00b1 0 10000\u00b1 0 [79] 5sat500 250 250 1000\u00b1 0 4260\u00b1 0 [79] 7sat90 250 250 90\u00b1 0 7650\u00b1 0 [79]", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "4k 125k\u00b1 126k [65] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] 3cnf 500 250 350\u00b1 0 1493\u00b1 0 [12] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 3sat1k 250 250 500\u00b1 0 10000\u00b1 0 [79] 5sat500 250 250 1000\u00b1 0 4260\u00b1 0 [79] 7sat90 250 250 90\u00b1 0 7650\u00b1 0 [79]", "startOffset": 81, "endOffset": 85}, {"referenceID": 69, "context": "4k 125k\u00b1 126k [65] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] 3cnf 500 250 350\u00b1 0 1493\u00b1 0 [12] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 3sat1k 250 250 500\u00b1 0 10000\u00b1 0 [79] 5sat500 250 250 1000\u00b1 0 4260\u00b1 0 [79] 7sat90 250 250 90\u00b1 0 7650\u00b1 0 [79]", "startOffset": 149, "endOffset": 153}, {"referenceID": 69, "context": "4k 125k\u00b1 126k [65] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] 3cnf 500 250 350\u00b1 0 1493\u00b1 0 [12] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 3sat1k 250 250 500\u00b1 0 10000\u00b1 0 [79] 5sat500 250 250 1000\u00b1 0 4260\u00b1 0 [79] 7sat90 250 250 90\u00b1 0 7650\u00b1 0 [79]", "startOffset": 186, "endOffset": 190}, {"referenceID": 69, "context": "4k 125k\u00b1 126k [65] K3 300 250 262\u00b1 43 1116\u00b1 182 [11] 3cnf 500 250 350\u00b1 0 1493\u00b1 0 [12] unif-k5 300 250 50\u00b1 0 1056\u00b1 0 \u2013 3sat1k 250 250 500\u00b1 0 10000\u00b1 0 [79] 5sat500 250 250 1000\u00b1 0 4260\u00b1 0 [79] 7sat90 250 250 90\u00b1 0 7650\u00b1 0 [79]", "startOffset": 220, "endOffset": 224}, {"referenceID": 31, "context": "Indeed, after the competition, Riss3gExt \u2019s developer found a bug in it (in onthe-fly clause improvement [37]) that caused some satisfiable instances to be incorrectly labeled as unsatisfiable.", "startOffset": 105, "endOffset": 109}, {"referenceID": 51, "context": "discretized original DCCASat+march-rw 1 0 0 0 9 9 Random [58] CSCCSat2014 3 0 0 0 567 567 Random SAT [57, 58] ProbSAT 5 1 3 4 1\u00d7 105 \u221e Random SAT [9] Minisat-HACK-999ED 10 0 0 3 8\u00d7 105 8\u00d7 105 All categories [69] YalSAT 16 10 0 0 5\u00d7 106 2\u00d7 1072 Crafted&Random SAT [17] Cryptominisat 14 15 7 2 3\u00d7 1024 \u221e Industrial & Crafted [75] Clasp-3.", "startOffset": 57, "endOffset": 61}, {"referenceID": 50, "context": "discretized original DCCASat+march-rw 1 0 0 0 9 9 Random [58] CSCCSat2014 3 0 0 0 567 567 Random SAT [57, 58] ProbSAT 5 1 3 4 1\u00d7 105 \u221e Random SAT [9] Minisat-HACK-999ED 10 0 0 3 8\u00d7 105 8\u00d7 105 All categories [69] YalSAT 16 10 0 0 5\u00d7 106 2\u00d7 1072 Crafted&Random SAT [17] Cryptominisat 14 15 7 2 3\u00d7 1024 \u221e Industrial & Crafted [75] Clasp-3.", "startOffset": 101, "endOffset": 109}, {"referenceID": 51, "context": "discretized original DCCASat+march-rw 1 0 0 0 9 9 Random [58] CSCCSat2014 3 0 0 0 567 567 Random SAT [57, 58] ProbSAT 5 1 3 4 1\u00d7 105 \u221e Random SAT [9] Minisat-HACK-999ED 10 0 0 3 8\u00d7 105 8\u00d7 105 All categories [69] YalSAT 16 10 0 0 5\u00d7 106 2\u00d7 1072 Crafted&Random SAT [17] Cryptominisat 14 15 7 2 3\u00d7 1024 \u221e Industrial & Crafted [75] Clasp-3.", "startOffset": 101, "endOffset": 109}, {"referenceID": 6, "context": "discretized original DCCASat+march-rw 1 0 0 0 9 9 Random [58] CSCCSat2014 3 0 0 0 567 567 Random SAT [57, 58] ProbSAT 5 1 3 4 1\u00d7 105 \u221e Random SAT [9] Minisat-HACK-999ED 10 0 0 3 8\u00d7 105 8\u00d7 105 All categories [69] YalSAT 16 10 0 0 5\u00d7 106 2\u00d7 1072 Crafted&Random SAT [17] Cryptominisat 14 15 7 2 3\u00d7 1024 \u221e Industrial & Crafted [75] Clasp-3.", "startOffset": 146, "endOffset": 149}, {"referenceID": 61, "context": "discretized original DCCASat+march-rw 1 0 0 0 9 9 Random [58] CSCCSat2014 3 0 0 0 567 567 Random SAT [57, 58] ProbSAT 5 1 3 4 1\u00d7 105 \u221e Random SAT [9] Minisat-HACK-999ED 10 0 0 3 8\u00d7 105 8\u00d7 105 All categories [69] YalSAT 16 10 0 0 5\u00d7 106 2\u00d7 1072 Crafted&Random SAT [17] Cryptominisat 14 15 7 2 3\u00d7 1024 \u221e Industrial & Crafted [75] Clasp-3.", "startOffset": 207, "endOffset": 211}, {"referenceID": 14, "context": "discretized original DCCASat+march-rw 1 0 0 0 9 9 Random [58] CSCCSat2014 3 0 0 0 567 567 Random SAT [57, 58] ProbSAT 5 1 3 4 1\u00d7 105 \u221e Random SAT [9] Minisat-HACK-999ED 10 0 0 3 8\u00d7 105 8\u00d7 105 All categories [69] YalSAT 16 10 0 0 5\u00d7 106 2\u00d7 1072 Crafted&Random SAT [17] Cryptominisat 14 15 7 2 3\u00d7 1024 \u221e Industrial & Crafted [75] Clasp-3.", "startOffset": 263, "endOffset": 267}, {"referenceID": 26, "context": "4-p8 38 30 7 55 1\u00d7 1049 \u221e All categories [32] Riss-4.", "startOffset": 41, "endOffset": 45}, {"referenceID": 14, "context": "27 214 0 0 160 5\u00d7 1086 5\u00d7 1086 All but Random SAT [62] SparrowToRiss 170 36 16 176 1\u00d7 10112 \u221e All categories [8] Lingeling 137 186 0 0 1\u00d7 1053 2\u00b7101341 All categories [17]", "startOffset": 167, "endOffset": 171}, {"referenceID": 51, "context": "DCCASat+march-rw [58] combines the SLS solver DCCASat with the CDCL solver march-rw.", "startOffset": 17, "endOffset": 21}, {"referenceID": 50, "context": "CSCCSat2014 [57, 58] is an SLS solver based on configuration checking and dynamic local search methods.", "startOffset": 12, "endOffset": 20}, {"referenceID": 51, "context": "CSCCSat2014 [57, 58] is an SLS solver based on configuration checking and dynamic local search methods.", "startOffset": 12, "endOffset": 20}, {"referenceID": 6, "context": "ProbSAT [9] is a simple SLS solver based on probability distributions that are built from simple features, such as the make and break of variables [9].", "startOffset": 8, "endOffset": 11}, {"referenceID": 6, "context": "ProbSAT [9] is a simple SLS solver based on probability distributions that are built from simple features, such as the make and break of variables [9].", "startOffset": 147, "endOffset": 150}, {"referenceID": 61, "context": "Minisat-HACK-999ED [69] is a CDCL solver; it was submitted to all tracks.", "startOffset": 19, "endOffset": 23}, {"referenceID": 14, "context": "YalSAT [17] is an SLS solver; it was submitted to the tracks crafted SAT+UNSAT and Random SAT .", "startOffset": 7, "endOffset": 11}, {"referenceID": 26, "context": "4-p8 [32] is a solver for the more general answer set programming (ASP) problem, but it can also solve SAT, MAXSAT and PB problems.", "startOffset": 5, "endOffset": 9}, {"referenceID": 30, "context": "In particular, it added many new preprocessing and inprocessing techniques, including XOR handling (via Gaussian elimination [36]), and extracting cardinality constraints [20].", "startOffset": 125, "endOffset": 129}, {"referenceID": 17, "context": "In particular, it added many new preprocessing and inprocessing techniques, including XOR handling (via Gaussian elimination [36]), and extracting cardinality constraints [20].", "startOffset": 171, "endOffset": 175}, {"referenceID": 27, "context": "The simplification parameters comprise about 20 Boolean switches for preprocessing techniques and about 100 in-processor parameters, prominently including blocked clause elimination, bounded variable addition, equivalance elimination [33], numerical limits, probing, symmetry breaking, unhiding [38], Gaussian elimination, covered literal elimination [64], and even some stochastic local search.", "startOffset": 234, "endOffset": 238}, {"referenceID": 32, "context": "The simplification parameters comprise about 20 Boolean switches for preprocessing techniques and about 100 in-processor parameters, prominently including blocked clause elimination, bounded variable addition, equivalance elimination [33], numerical limits, probing, symmetry breaking, unhiding [38], Gaussian elimination, covered literal elimination [64], and even some stochastic local search.", "startOffset": 295, "endOffset": 299}, {"referenceID": 56, "context": "The simplification parameters comprise about 20 Boolean switches for preprocessing techniques and about 100 in-processor parameters, prominently including blocked clause elimination, bounded variable addition, equivalance elimination [33], numerical limits, probing, symmetry breaking, unhiding [38], Gaussian elimination, covered literal elimination [64], and even some stochastic local search.", "startOffset": 351, "endOffset": 355}, {"referenceID": 14, "context": "Lingeling [17] is a successor to the 2013 version; it was submitted to the tracks Industrial SAT+UNSAT and crafted SAT+UNSAT .", "startOffset": 10, "endOffset": 14}, {"referenceID": 41, "context": "Additional details, tables, and figures are provided in an accompanying technical report [47].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "1: BMC [15], Circuit Fuzz [23], and IBM [83].", "startOffset": 7, "endOffset": 11}, {"referenceID": 18, "context": "1: BMC [15], Circuit Fuzz [23], and IBM [83].", "startOffset": 26, "endOffset": 30}, {"referenceID": 41, "context": "Full results can be found in the accompanying technical report [47].", "startOffset": 63, "endOffset": 67}, {"referenceID": 34, "context": "Rather, they promote the design paradigm of Programming by Optimization (PbO) [40], which aims to avoid premature design choices and to rather actively develop promising alternatives for parts of the design that enable an automated customization to achieve peak performance on particular benchmarks of interest.", "startOffset": 78, "endOffset": 82}, {"referenceID": 68, "context": "Another interesting application domain is automatic machine learning, where algorithm configuration can adapt flexible machine learning frameworks to each new dataset at hand [78].", "startOffset": 175, "endOffset": 179}], "year": 2017, "abstractText": "It is well known that different solution strategies work well for different types of instances of hard combinatorial problems. As a consequence, most solvers for the propositional satisfiability problem (SAT) expose parameters that allow them to be customized to a particular family of instances. In the international SAT competition series, these parameters are ignored: solvers are run using a single default parameter setting (supplied by the authors) for all benchmark instances in a given track. While this competition format rewards solvers with robust default settings, it does not reflect the situation faced by a practitioner who only cares about performance on one particular application and can invest some time into tuning solver parameters for this application. The new Configurable SAT Solver Competition (CSSC) compares solvers in this latter setting, scoring each solver by the performance it achieved after a fully automated configuration step. This article describes the CSSC in more detail, and reports the results obtained in its two instantiations so far, CSSC 2013 and 2014.", "creator": "LaTeX with hyperref package"}}}