{"id": "1505.01621", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2015", "title": "Blind Compressive Sensing Framework for Collaborative Filtering", "abstract": "Existing works based on latent factor models have focused on representing the rating matrix as a product of user and item latent factor matrices, both being dense. Latent (factor) vectors define the degree to which a trait is possessed by an item or the affinity of user towards that trait. A dense user matrix is a reasonable assumption as each user will like/dislike a trait to certain extent. However, any item will possess only a few of the attributes and never all. Hence, the item matrix should ideally have a sparse structure rather than a dense one as formulated in earlier works. Therefore we propose to factor the ratings matrix into a dense user matrix and a sparse item matrix which leads us to the Blind Compressed Sensing (BCS) framework. We derive an efficient algorithm for solving the BCS problem based on Majorization Minimization (MM) technique. Our proposed approach is able to achieve significantly higher accuracy and shorter run times as compared to existing approaches.", "histories": [["v1", "Thu, 7 May 2015 08:19:05 GMT  (301kb)", "http://arxiv.org/abs/1505.01621v1", "5 pages"]], "COMMENTS": "5 pages", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["anupriya gogna", "angshul majumdar"], "accepted": false, "id": "1505.01621"}, "pdf": {"name": "1505.01621.pdf", "metadata": {"source": "CRF", "title": "Blind Compressive Sensing Framework for Collaborative Filtering", "authors": ["Anupriya Gogna", "Angshul Majumdar"], "emails": ["anupriyag@iiitd.ac.in", "angshul@iiitd.ac.in"], "sections": [{"heading": null, "text": "Latent (factor) vectors define the degree to which a feature is possessed by an item or the affinity of the user to that feature. A dense user matrix is a reasonable assumption, since each user will like / reject a feature to some degree. However, each item will have only a few of the attributes and never all of them. Therefore, the item matrix should ideally have a sparse structure and not a dense one as formulated in previous work. Therefore, we propose to integrate the valuation matrix into a dense user matrix and a sparse item matrix that leads us to the Blind Compressed Sensing (BCS) Framework. We derive an efficient algorithm for solving the BCS problem based on Majorization Minimization Technology (MM). Our proposed approach is capable of achieving significantly higher accuracy and shorter runtimes compared to existing approaches."}, {"heading": "Keywords", "text": "Blind compressive sampling, collaborative filtering, latent factor model, matrix factorization, recommendation system."}, {"heading": "1. INTRODUCTION", "text": "This year, it will be able to solve and fix the problems mentioned."}, {"heading": "2. PROPOSED FORMULATION AND ALGORITHM", "text": "In this section, we discuss our novel proposal for a formulation based on latent factors to design an effective recommendation system."}, {"heading": "2.1 Problem Formulation", "text": "This year it is more than ever before that it is a reactionary, reactionary, reactionary and reactionary party."}, {"heading": "2.2 Algorithm Design", "text": "D \"i\" s \"i\" s \"i.\" D \"W\" s tis \"i.\" S \"W\" s tis \"i.\" W \"s\" i \"t.\" W \"t\" s \"i\" t. \"W\" s \"i\" t. \"W\" i \"t\" t. \"W\" i \"t\" i \"t.\" W \"i\" t \"i\" t. \"W\" i \"t\" i \"t.\" W \"i\" t \"i\" t \"t.\" W \"i\" t. \"W\" i \"t\" i \"t.\" W \"i\" t \"t.\" W \"i\" t. \"t.\" W \"i\" s \"s\" s \"s\" s \"s\" s \"t.\" t \"i\" t \"t\" t. \"W\" i \"s\" t. \"t\" t \"i\" s \"t.\" W \"s\" t. \"W\" t. \"t.\""}, {"heading": "3. EXPERIMENTAL SETUP AND RSULTS", "text": "We conducted experiment on the movielens 100K and 1M datasets (http: / / grouplens.org / datasets / movielens /). The 100K dataset consists of 100,000 ratings (rating of 1-5) given by 943 users on 1682 movies. 1M dataset consists of ratings on 3952 movies by 6040 users. Both datasets are divided into test and training data to perform cross-validation. We performed three, five and ten-fold cross-validation to vary the ratio of the sizes of test and training data. For \"n\" fold cross-validation the entire dataset is divided into n blocks. \"n-1\" blocks are combined to form the training data and the nth set is taken as a test set. Simulations are performed on the system with i7-3770S CPU @ 3.10GHz with 8GB RAM. For our algorithm (CS-F), the value of 1K is achieved in the efficiency parameter 11U."}, {"heading": "Algorithm MAE-3 Fold MAE-5 Fold MAE-10 Fold", "text": "BCS-CF 0.7417 0.7215 0.7140MC-SB 0.7454 0.7323 0.7279APG 0.8573 0.8847 0.9187OptSpace 0.7629 0.7450 0.7323BCS-J 0.7527 0.7430 0.7414SGD 0.8002 0.7432 0.7312Table 1. MAE for 1M dataset"}, {"heading": "Algorithm MAE-3 Fold MAE-5 Fold MAE-10 Fold", "text": "BCS-CF 0.6835 0.6762 0.6712MC-SB 0.6999 0.6943 0.6897APG 1.0178 0.9782 0.9352OptSpace 0.6907 0.6844BCS-J 0.6967 0.6858SGD 0.6988 0.6936 0.6907Table 1 gives the MAE values of all algorithms for 3, 5 and 10-fold cross validation. Results are averaged values for 100 independent runs of each test pair. It is evident from all three sets of data that our algorithm performs better than the other two techniques compared. Our algorithm provides an improvement in recovery accuracy from about 3% (for 10-fold validation) to 8% (for 3-fold cross validation) via SGD."}, {"heading": "4. CONCLUSION", "text": "In this paper, we propose a novel formulation based on a latent factor model for collaborative filtering, but the basic formulation remains the same, i.e. the assessment matrix can be incorporated into two matrices - a latent factor matrix for the user and a latent factor matrix for the item. However, all previous studies assumed that these two matrices are dense. We argue that this is not the case; the latent factor matrix for the user is dense, but the latent factor matrix for the item should be sparing. This is because all users are likely to have an affinity for all different factors, but it is not possible for the items to possess all factors at the same time. We show that our proposed formulation naturally fits into the recently proposed blind compression system. BCS is an up-to-date framework and there are no efficient algorithms to solve the BCS problem. In this paper, we propose a majority algorithm to solve the problem of minimization algorithm."}, {"heading": "5. REFERENCES", "text": "In recent years, the number of those who are able to shoot up has increased significantly. [1] In recent years, the number of those who are able to shoot up has increased, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, skyrocketed, and skyrocketed. \""}], "references": [{"title": "A survey of collaborative filtering techniques", "author": ["Xiaoyuan Su", "TaghiMKhoshgoftaar"], "venue": "Advances in artificial intelligence, vol. 2009, pp. 4, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Improving memory-based collaborative filtering via similarity updating and prediction modulation", "author": ["Buhwan Jeong", "Jaewook Lee", "Hyunbo Cho"], "venue": "Information Sciences, vol. 180, no. 5, pp. 602\u2013612, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl"], "venue": "Proceedings of the 10th international conference on World Wide Web. ACM, 2001, pp. 285\u2013295.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "Latent semantic models for collaborative filtering", "author": ["Thomas Hofmann"], "venue": "ACM Transactions on Information Systems (TOIS), vol. 22, no. 1, pp. 89\u2013115, 2004.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["Gediminas Adomavicius", "Alexander Tuzhilin"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 17, no. 6, pp. 734\u2013749, 2005.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Scalable collaborative filtering with jointly derived neighborhood interpolation weights", "author": ["Robert M Bell", "Yehuda Koren"], "venue": "Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE, 2007, pp. 43\u201352.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Yehuda Koren", "Robert Bell", "Chris Volinsky"], "venue": "Computer, vol. 42, no. 8, pp. 30\u201337, 2009.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Blind compressed sensing,\u201dInformation", "author": ["Sivan Gleichman", "Yonina C Eldar"], "venue": "Theory, IEEE Transactions on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Blind compressive sensing dynamic mri", "author": ["Sajan Goud Lingala", "Mathews Jacob"], "venue": "Medical Imaging, IEEE Transactions on, vol. 32, no. 6, pp. 1132\u20131145, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Sparsity and incoherence in compressive sampling", "author": ["Emmanuel Candes", "Justin Romberg"], "venue": "Inverse problems, vol. 23, no. 3, pp. 969, 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Majorization\u2013minimization algorithms for wavelet based image restoration", "author": ["M \u0301ario AT Figueiredo", "Jos \u0301e M Bioucas-Dias", "Robert D Nowak"], "venue": "Image Processing, IEEE Transactions on, vol. 16, no. 12, pp. 2980\u20132991, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems", "author": ["Kim-Chuan Toh", "Sangwoon Yun"], "venue": "Pacific Journal of Optimization, vol. 6, no. 615-640, pp. 15, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Matrix recovery using split bregman", "author": ["Anupriya Gogna", "Ankita Shukla", "Angshul Majumdar"], "venue": "arXiv preprint arXiv:1312.6872, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Matrix completion from a few entries", "author": ["Raghunandan H Keshavan", "Andrea Montanari", "Sewoong Oh"], "venue": "Information Theory, IEEE Transactions on, vol. 56, no. 6, pp. 2980\u20132998, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Collaborative filtering (CF) [1] is the most popular approach for design of RS.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "Memory based models [2] [3] are heuristic methods which use the available rating data to find users similar to the target user and a weighted average of ratings by similar users is used as to predict rating for the target user.", "startOffset": 20, "endOffset": 23}, {"referenceID": 2, "context": "Memory based models [2] [3] are heuristic methods which use the available rating data to find users similar to the target user and a weighted average of ratings by similar users is used as to predict rating for the target user.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "On the other hand (latent factor) model based techniques [4] fundamentally represent the available information in the form of a lower dimensional structure under the proposition that the overall rating matrix can be represented by a relatively small number of independent variables or factors (Latent factor model).", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "They have been shown to outperform their memory based counterparts, in terms of Quality of Prediction (QoP) and coverage [5].", "startOffset": 121, "endOffset": 124}, {"referenceID": 5, "context": "html) and Alternating Least Squares (ALS) [6] are commonly employed to solve the above problem.", "startOffset": 42, "endOffset": 45}, {"referenceID": 6, "context": "In our formulation, we estimate the baseline offline from the available dataset using method outlined in [7] by solving the following convex optimization framework.", "startOffset": 105, "endOffset": 108}, {"referenceID": 7, "context": "Our formulation follows the Blind Compressive Sensing framework [8] [9] given in (7).", "startOffset": 64, "endOffset": 67}, {"referenceID": 8, "context": "Our formulation follows the Blind Compressive Sensing framework [8] [9] given in (7).", "startOffset": 68, "endOffset": 71}, {"referenceID": 10, "context": "2 Algorithm Design To efficiently solve our formulation and recover the complete rating matrix, we propose an algorithm following the Majorization Minimization (MM) approach [11].", "startOffset": 174, "endOffset": 178}, {"referenceID": 6, "context": "The results of our formulation is compared against the results obtained using SGD formulation proposed in [7], Accelerated Proximal Gradient based matrix completion (APG) algorithm [13], Matrix completion using Split bregman (MCSB) [14] and optSpace [15].", "startOffset": 106, "endOffset": 109}, {"referenceID": 11, "context": "The results of our formulation is compared against the results obtained using SGD formulation proposed in [7], Accelerated Proximal Gradient based matrix completion (APG) algorithm [13], Matrix completion using Split bregman (MCSB) [14] and optSpace [15].", "startOffset": 181, "endOffset": 185}, {"referenceID": 12, "context": "The results of our formulation is compared against the results obtained using SGD formulation proposed in [7], Accelerated Proximal Gradient based matrix completion (APG) algorithm [13], Matrix completion using Split bregman (MCSB) [14] and optSpace [15].", "startOffset": 232, "endOffset": 236}, {"referenceID": 13, "context": "The results of our formulation is compared against the results obtained using SGD formulation proposed in [7], Accelerated Proximal Gradient based matrix completion (APG) algorithm [13], Matrix completion using Split bregman (MCSB) [14] and optSpace [15].", "startOffset": 250, "endOffset": 254}, {"referenceID": 8, "context": "We also compare our results against the BCS algorithm (BCSJ) put forth in [9] to show the efficiency of our algorithm.", "startOffset": 74, "endOffset": 77}], "year": 2015, "abstractText": "Existing works based on latent factor models have focused on representing the rating matrix as a product of user and item latent factor matrices, both being dense. Latent (factor) vectors define the degree to which a trait is possessed by an item or the affinity of user towards that trait. A dense user matrix is a reasonable assumption as each user will like/dislike a trait to certain extent. However, any item will possess only a few of the attributes and never all. Hence, the item matrix should ideally have a sparse structure rather than a dense one as formulated in earlier works. Therefore we propose to factor the ratings matrix into a dense user matrix and a sparse item matrix which leads us to the Blind Compressed Sensing (BCS) framework. We derive an efficient algorithm for solving the BCS problem based on Majorization Minimization (MM) technique. Our proposed approach is able to achieve significantly higher accuracy and shorter run times as compared to existing approaches.", "creator": "Microsoft\u00ae Word 2013"}}}