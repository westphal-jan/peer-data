{"id": "1505.01658", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2015", "title": "A Survey of Predictive Modelling under Imbalanced Distributions", "abstract": "Many real world data mining applications involve obtaining predictive models using data sets with strongly imbalanced distributions of the target variable. Frequently, the least common values of this target variable are associated with events that are highly relevant for end users (e.g. fraud detection, unusual returns on stock markets, anticipation of catastrophes, etc.). Moreover, the events may have different costs and benefits, which when associated with the rarity of some of them on the available training data creates serious problems to predictive modelling techniques. This paper presents a survey of existing techniques for handling these important applications of predictive analytics. Although most of the existing work addresses classification tasks (nominal target variables), we also describe methods designed to handle similar problems within regression tasks (numeric target variables). In this survey we discuss the main challenges raised by imbalanced distributions, describe the main approaches to these problems, propose a taxonomy of these methods and refer to some related problems within predictive modelling.", "histories": [["v1", "Thu, 7 May 2015 10:44:57 GMT  (1348kb,D)", "https://arxiv.org/abs/1505.01658v1", null], ["v2", "Wed, 13 May 2015 17:13:11 GMT  (1348kb,D)", "http://arxiv.org/abs/1505.01658v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["paula branco", "luis torgo", "rita ribeiro"], "accepted": false, "id": "1505.01658"}, "pdf": {"name": "1505.01658.pdf", "metadata": {"source": "CRF", "title": "A Survey of Predictive Modelling under Imbalanced Distributions", "authors": ["Paula Branco", "Rita P. Ribeiro"], "emails": ["paobranco@gmail.com,", "ltorgo@dcc.fc.up.pt,", "rpribeiro@dcc.fc.up.pt"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able are able to determine for themselves what they want to do and what they want to do, and most of them are not able to move."}, {"heading": "2 Problem Definition", "text": "As we have already mentioned, the problem of unbalanced data distribution occurs in the context of > prediction tasks, where the goal is to get a good approximation of the unknown function Y = f (X1, X2, \u00b7 \u00b7 \u00b7, Xp), which maps the values of a set of p predictor variables into the values of a target variable. These approximations to the function are made using a training dataset D = {< xi, yi >} ni = 1. At the heart of the problem of unbalanced distribution is the fact that the user attaches greater importance to the performance of the approach achieved on a subset of the value range of the target variable Y. Let us express these user preference bias by an importance or relevance function \u03c6 (), which maps the values of the target variables into a range of importance, with 1 maximum meaning and 0 minimal relevance of the target variables."}, {"heading": "3 Performance Metrics for Imbalanced Domains", "text": "The main problem with unbalanced data sets is that they are often associated with a user bias toward performance in cases that are poorly represented in the available sample of data. Standard evaluation criteria tend to focus the evaluation of models on the most common cases, which runs counter to user preferences in these tasks. Indeed, the use of common metrics in unbalanced domains can lead to suboptimal classification models (He and Garcia, 2009; Wei\u00df, 2004; Kubat and Matwin, 1997) and could lead to misleading conclusions as these measures are insensitive to distorted domains (Ranawana and Palade, 2006; Daskalaki et al., 2006). In this sense, the selection of appropriate evaluation metrics plays a key role in the task of correctly handling data imbalances."}, {"heading": "3.1 Metrics for Classification Tasks", "text": "The confusion matrix for a two-class problem represents the results obtained from a particular classifier (see Table 2).This table provides for each class the in-positions that were correctly classified, i.e. the number of true positives (TP) and true negatives (TN), and the instances that were wrongly classified, i.e. the number of false positives (FP) and false negatives (FN).Accuracy (cf. Equation 2) and its complementary error rate are the most commonly used metrics for learning system performance in classification problems. For two-class problems, accuracy can be defined as Accuracy = TP + TN + TP + FP (2) taking into account a user preference bias toward the minority (positive) class examples, because the effects of the least represented but more important examples are reduced when we consider a problem where only 1% of the minority class belong."}, {"heading": "3.2 Metrics for Regression Tasks", "text": "These metrics are commonly used in regression, such as Mean Squared Error (MSE) and Mean Absolute Deviation (MAD) (cf. Equations 14 and 15), but are not adequate for these specific problems. These metrics assume a uniform relevance of the target variables domain and evaluate only the magnitude of the numerical error. Although the magnitude of the numerical error is important, for tasks with an unbalanced distribution of the target variables the metric must also be sensitive to the error position within the target domain, because, as in the classification tasks, users of these domains are often distorted to performance on poorly represented values. A simple solution, such as the introduction of weights, would not neglect this target because it is variable in the target domain."}, {"heading": "4 Modelling Strategies for Handling Imbalanced", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "4.1 Data Pre-processing", "text": "Pre-processing strategies consist of methods of using the available data set in a way that is more consistent with the user's preference distortions, which means that rather than applying a learning algorithm directly to the training data provided, we will initially somehow pre-process that data according to the user's objectives. Any standard learning algorithm can be applied to the pre-processed data set. Existing approaches to pre-processing data can be grouped into three main types: \u2022 Re-sampling: changing the data distribution of the data set, forcing the learner to focus on the least represented examples; \u2022 Active learning: actively selecting the best (most valuable) samples to learn, leaving the learner with less information to improve the performance of the learner; \u2022 Data space weighting: modifying the distribution of the data set using information about misclassification costs, so that the learned model avoids game-playing errors from Table 3 to graphical bibliography."}, {"heading": "4.1.1 Re-sampling", "text": "The application of re-sampling strategies to achieve a more balanced distribution of data is an effective solution to the imbalance problem (Emsrooks et al., 2004; Batuwita and Palade, 2010a; Ferna \u0301 ndez et al., 2008, 2010).Strategy type (Section) Main ReferencesRe-sampling (4.1.1) Random Under / Over-Sampling Chawla et al. (2002); Bunmond and Holte (2003) Estabrooks et al. (2004); Seiffert et al. (2010); Chen et al al. (2004); Wang and Yao et al. (2009); Chang et al. (2003); Tao et al. (2006); Torgo et al. (2013) Distance Based Chyi (2003); Mani and Zhang (2003) Data Cleaning Based Kubat and Matwin and Matwin (1997); Laurika."}, {"heading": "4.1.2 Active Learning", "text": "Active learning is a semi-supervised strategy in which the learning algorithm is able to obtain information interactively from the user. Although this method is traditionally used with unmarked data, it can also be used when all class markers are known. In this case, the active learning strategy offers the opportunity to actively select the best, i.e. most informative examples from which to learn. Several approaches have been proposed for unbalanced areas based on active learning (Ertekin et al., 2007b, a; Zhu and Hovy, 2007; Ertekin, 2013). These approaches focus on SVM learning systems and are based on the fact that for this type of learner, the most informative examples are those closest to the hyperplanner. This property is used to determine generative learning processes by selecting the most informative examples, i.e., the selection of examples closer to the hyperplanner."}, {"heading": "4.1.3 Weighting the Data Space", "text": "The strategy of data space weighting is one way of implementing cost-sensitive learning. In fact, the costs of misclassification are applied to the given data set with the aim of selecting the best distribution of training courses. Essentially, this method is based on the fact that changing the original distribution of samples by multiplying each case by a factor corresponding to its importance (relative cost) enables any standard learner to achieve the expected cost minimization on the original distribution. Although it is a simple technique and easy to apply, it also has some disadvantages. There is a risk of model revision and it is also possible that the real cost values are not available, which may entail the additional difficulty of researching effective cost structures. This approach has a strong theoretical basis, building on the translation theorem derived from Zadrozny et al. (2003) and other examples."}, {"heading": "4.2 Special-purpose Learning Methods", "text": "In fact, most of them are able to survive if they do not play by the rules. (...) Most of them are able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...)"}, {"heading": "4.3 Prediction Post-processing", "text": "To address unbalanced domains at the post-processing level, we will consider two main types of solutions: \u2022 Threshold Method: uses the ranking of a score that expresses the degree to which an example is a member of a class to produce multiple learners by varying the threshold for class membership; \u2022 Cost-sensitive post-processing: associates costs with predictive errors and minimizes expected costs. Table 5 summarizes the key bibliographic references of post-processing strategies."}, {"heading": "4.3.1 Threshold Method", "text": "Some classifiers are referred to as soft classifiers because they provide a score that expresses the degree to which an example is a member of a class. Indeed, this score can be used as a threshold to generate other classifiers, and this task can be accomplished by varying the threshold for an example belonging to a class White (2004). A study of this method (Maloof, 2003) concluded that the operations of shifting the decision threshold, applying a sampling strategy, and adjusting the cost matrix of classifiers produce the same performance."}, {"heading": "4.3.2 Cost-sensitive Post-processing", "text": "This type of strategy has been researched mainly for classification tasks and aims to modify only the model forecasts to make them cost-sensitive (e.g. Domingos (1999); Sinha and May (2004)), which means that these approaches could potentially be applicable to unbalanced data distributions. However, to our knowledge, these methods have never been applied or evaluated to these tasks. Regression has not progressed in assessing these solutions in unbalanced areas (Bansal et al., 2008; Zhao et al., 2011), a problem that has not yet been explored with a few limited solutions, nor has progress been made in assessing these solutions in unbalanced areas. However, one interesting proposal mentioned reframing (Herna \u0301 ndez-Orallo, 2012, 2014)."}, {"heading": "4.4 Hybrid Methods", "text": "In recent years, several methods have appeared in the research literature combining some of the basic approaches described in the previous sections. Due to their characteristics, these methods can be considered hybrid methods for handling unequal distributions. They attempt to exploit some of the main advantages of the approaches we described earlier. Existing hybrid approaches combine the use of re-sampling strategies with special learning algorithms. Table 6 summarizes the most important bibliographic references to these strategies."}, {"heading": "4.4.1 Re-sampling and Special-purpose Learning Methods", "text": "This year it is more than ever before."}, {"heading": "5 Related Problems", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able, in which they are able to integrate themselves, in which they are able, in which they are able, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they"}, {"heading": "6 Conclusions", "text": "In this paper, we propose a formulation of the problem of modeling using unbalanced data sets that includes both classification and regression tasks. We present an overview of the state of the art for obtaining and evaluating predictive models for both classification and regression tasks. We propose a new taxonomy for the existing approaches they use in: (i) data pre-processing, (ii) specialized learning methods, and (iii) post-processing prediction methods.Most existing solutions for modeling under unbalanced distributions focus on classification tasks. This fact is also present in previous surveys of this important area of research. In this paper, we propose the first survey that also addresses existing approaches to unbalanced data sets within regression problems.Finally, we describe some problems that are strongly related to unbalanced data distributions, and highlight work that examines the relationship of these other problems to unbalanced data sets."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Many real world data mining applications involve obtaining predictive models using data sets with strongly imbalanced distributions of the target variable. Frequently, the least common values of this target variable are associated with events that are highly relevant for end users (e.g. fraud detection, unusual returns on stock markets, anticipation of catastrophes, etc.). Moreover, the events may have different costs and benefits, which when associated with the rarity of some of them on the available training data creates serious problems to predictive modelling techniques. This paper presents a survey of existing techniques for handling these important applications of predictive analytics. Although most of the existing work addresses classification tasks (nominal target variables), we also describe methods designed to handle similar problems within regression tasks (numeric target variables). In this survey we discuss the main challenges raised by imbalanced distributions, describe the main approaches to these problems, propose a taxonomy of these methods and refer to some related problems within predictive modelling.", "creator": "LaTeX with hyperref package"}}}