{"id": "1505.01757", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2015", "title": "Contextual Analysis for Middle Eastern Languages with Hidden Markov Models", "abstract": "Displaying a document in Middle Eastern languages requires contextual analysis due to different presentational forms for each character of the alphabet. The words of the document will be formed by the joining of the correct positional glyphs representing corresponding presentational forms of the characters. A set of rules defines the joining of the glyphs. As usual, these rules vary from language to language and are subject to interpretation by the software developers.", "histories": [["v1", "Thu, 7 May 2015 16:03:02 GMT  (209kb,D)", "http://arxiv.org/abs/1505.01757v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["kazem taghva"], "accepted": false, "id": "1505.01757"}, "pdf": {"name": "1505.01757.pdf", "metadata": {"source": "CRF", "title": "Contextual Analysis for Middle Eastern Languages with Hidden Markov Models", "authors": ["Kazem Taghva"], "emails": ["kazem.taghva@unlv.edu"], "sections": [{"heading": null, "text": "In this paper, we propose an approach to machine learning for contextual analysis based on the first-order Hidden Markov model. We design and build a model for the Farsi language to showcase this technology; the Farsi model achieves an accuracy of 94% with a short list of 89 Farsi words consisting of 2780 Farsi characters; the experiment can easily be extended to many languages, including Arabic, Urdu and Sindhi. Furthermore, the advantage of this approach is that the same software can be used to perform contextual analysis without encoding complex rules for each specific language. Of particular interest is that languages with fewer speakers can have a greater representation on the Web, as they are usually ignored by software developers due to a lack of financial incentives.Keywords: Unicode, Contextual Analysis, Hidden Markov Models, Big Data, Middle Eastern Languages, Farsi, Arabic"}, {"heading": "1 Introduction", "text": "One of the main objectives of Unicode is to provide a setting that allows non-English documents to be easily created and displayed on modern electronic devices such as laptops and mobile phones. Consequently, this encryption has led to the development of many software tools for text editing, font design, storage and management of data in foreign languages. For commercial reasons, languages with a high speaking population and large economies have made much faster progress in Unicode-based technologies. On the other hand, less-spoken languages such as Pushtu are paid scant attention. According to [11], about 40 to 60 million people speak Pushtu worldwide. Many Unicode-based technologies are based on proprietary and patented methods and are therefore not available to general open source software developers. For example, BIT [9] does not disclose its contextual analysis algorithm for Farsi [10]. Many software developers need to develop new methods to mimic these commercial technologies."}, {"heading": "2 Background", "text": "In 2002, the Center for Intelligent Information Retrieval at the University of Massachusetts, Amherst, held a workshop on challenges in information gathering and language model [7]. The premise of this workshop was to promote the use of Language Model technology for different natural languages, the goal being to use the same software for indexing and retrieval regardless of language. It was noted that by using training materials such as document collections, we can automatically build retrieval engines for all languages. This report was one of the reasons why we decided to launch a few projects in Farsi and Arabic [16]. Consequently, these projects led to developments of the two widely used Farsi and Arabic Stemmers [15]. One of the difficulties we had was the lack of technologies for entering and viewing Farsi and Arabic documents."}, {"heading": "2.1 Keyboard Applet", "text": "The applet shows a Farsi keyboard image with the ability to type in characters from both the keyboard and the mouse. Figure 1 shows the keyboard applet used to define our search and retrieve test queries. Typically, the input data is displayed using the pre-installed wisteria images, but if a character is not pre-installed, it can be generated in no time at all. Mostly, these generated characters are \"compound\" characters. Farsi (and other Arabic script languages) can use \"compound\" characters that are a combination of two or more separated characters. For example, the right character of A \u00d3Q k is the Farsi word for \"date\" (i.e. the fruit), a combination of letters that represent a combination of two or more separated characters."}, {"heading": "3 Hidden Markov Model", "text": "This year it has come to the point where it is a kind of pus bag that is able to retaliate, \"he said in an interview with the Deutsche Presse-Agentur.\" We have no idea yet, \"he said,\" but we have no idea yet what it will be like. \"Indeed,\" We have no idea yet what it will be like. \"And indeed:\" We have no idea yet what it will be like. \""}, {"heading": "4 Farsi Hidden Markov Model", "text": "The Farsi HMM is very similar to the example of the HMM described in the previous section. HMM has a state for each representation of the Farsi alphabet. HMM also has a vocabulary of size 32, one for each character in the Farsi alphabet. A simple calculation shows that the Farsi HMM should have 128 states and 32 vocabularies. HMM has less than 128 states, as some of the characters do not have 4 representations. For example, there are only two letters: Viterbi AlgorithmData: Given K states and M vocabularies, and a sequence of vocabularies Y = w1w2. wn \u2212 1wn Result: The most likely state sequence R = r1r2 \u00b7 rn \u2212 1rn that we maximize the above probability, Function Viterbi (V, S, \u0430, Y, A, B)."}, {"heading": "5 Training and Testing of HMM", "text": "We trained the HMM with 89 words (2780 characters) selected from the list of common words from the newspaper Kayhan, published in 2005. There are over 10,000 words in this collection. We limited the training to this short list to save time. The list of these words is shown in Figure 5.The test data is a small number of words randomly selected from a small dictionary, shown in Figure 5.This list contains 32 words (350 characters).The training file contains word pairs separated by a vertical bar. The first word is the isolated form and the second word is the correct representation of the word. We read the file one line at a time and submit the two words for the training as shown in the rubric code below: f = File.open (. \"/ Training Data\") fersi.train ([\"], [\"]) f.each do - line - seq1, seq2 = line.chomp.split (s /) / ferded."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we have presented a machine learning approach to the contextual analysis of written languages. It is shown that an ergodic HMM can easily be trained to automatically decode the representation of written languages. Although the work is based on Farsi, it can easily be extended to other languages of the Middle East. Further education and research in this area can improve character accuracy. A successful contextual analysis program may have to include a list of exceptional words that do not fall within the normal combination of letters. It is also important to note that most of the Arabic and Farsi setting technologies, such as ArabTex [8] or FarsiTex [5], have problems with context analysis, mainly due to the fact that it is virtually impossible to develop an algorithm that provides 100% accuracy for tasks related to natural languages. Finally, a higher order HMM can also improve context analysis."}], "references": [{"title": "Compositional Morphology for Word Representations and Language Modelling", "author": ["Jan A. Botha", "Phil Blunsom"], "venue": "In Proceedings of the 31st International Conference on Machine Learning (ICML),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Element sets: A minimal basis for an XML query engine", "author": ["Tim Bray"], "venue": "In QL,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Peter F. Brown", "Vincent J. Della Pietra", "Stephen A. Della Pietra", "Robert L. Mercer"], "venue": "Comput. Linguist.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "Extended viterbi algorithm for second order hidden markov process", "author": ["Y.H.Y. He"], "venue": "In Proceedings 9th International Conference on Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1988}, {"title": "Challenges in information retrieval and language modeling: Report of a workshop held at the center for intelligent information retrieval, university of massachusetts amherst,  september", "author": ["Allan James"], "venue": "SIGIR Forum,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Design and implementation of a bilingual information entrance and edit environment. technical report, Iran", "author": ["Fallah Moshfeghi", "Kourosh Shadsari"], "venue": "Telecommunication Research Center,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "A new algorithm for contextual analysis of farsi characters and its implementation in java", "author": ["Kourosh Fallah Moshfeghi"], "venue": "In 17th International Unicode Conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "A Grammar of Pashto a Descriptive Study of the Dialect of Kandahar, Afghanistan", "author": ["Herbert Penzl", "Ismail Sloan"], "venue": "Ishi Press International,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "National iranian standard isiri 6219, information technology persian information interchange and display mechanism, using unicode", "author": ["Roozbeh Pournader"], "venue": "In Technical Report,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["Lawrence R. Rabiner"], "venue": "In PROCEEDINGS OF THE IEEE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1989}, {"title": "Readings in speech recognition. chapter A Tutorial on Hidden Markov Models and Selected Applications in Speech Recogni- 8  tion, pages 267\u2013296", "author": ["Lawrence R. Rabiner"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1990}, {"title": "A stemming algorithm for the farsi language", "author": ["Kazem Taghva", "Russell Beckley", "Mohammad Sadeh"], "venue": "In International Symposium on Information Technology: Coding and Computing (ITCC 2005),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Language model-based retieval for farsi documents", "author": ["Kazem Taghva", "Jeffrey S. Coombs", "Ray Pereda", "Thomas A. Nartker"], "venue": "In International Conference on Information Technology: Coding and Computing (ITCC\u201904),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Arabic stemming without A root dictionary", "author": ["Kazem Taghva", "Rania Elkhoury", "Jeffrey S. Coombs"], "venue": "In International Symposium on Information Technology: Coding and Computing (ITCC 2005),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Malreddy. Post processing with first- and secondorder hidden markov models", "author": ["Kazem Taghva", "Srijana Poudel", "Spandana"], "venue": "In DRR,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Farsi searching and display technologies", "author": ["Kazem Taghva", "Ron Young", "Jeff Coombs", "Russell Beckley", "Mohammad Sadeh"], "venue": "In SDIUT,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Probability bracket notation: Markov state chain projector, hidden markov models and dynamic bayesian networks", "author": ["Xing M. Wang"], "venue": "CoRR, abs/1212.3817,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}], "referenceMentions": [{"referenceID": 7, "context": "According to [11], approximately 40 to 60 million people speak Pushtu worldwide.", "startOffset": 13, "endOffset": 17}, {"referenceID": 5, "context": "For example, BIT [9] does not reveal its contextual analysis algorithm for Farsi[10].", "startOffset": 17, "endOffset": 20}, {"referenceID": 6, "context": "For example, BIT [9] does not reveal its contextual analysis algorithm for Farsi[10].", "startOffset": 80, "endOffset": 84}, {"referenceID": 6, "context": "The new contextual analysis for Farsi developed by Moshfeghi in Iran Telecommunication Research Center is an example of these kinds of efforts[10].", "startOffset": 142, "endOffset": 146}, {"referenceID": 1, "context": "Tim Bray [2] writes:", "startOffset": 9, "endOffset": 12}, {"referenceID": 2, "context": "The language translation technologies heavily use Hidden Markov Models to improve translation accuracy [3] [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 0, "context": "The language translation technologies heavily use Hidden Markov Models to improve translation accuracy [3] [1].", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "In 2002, the Center for Intelligent Information Retrieval at the University of Massachusetts, Amherst, held a workshop on Challenges in Information Retrieval and Language Model [7].", "startOffset": 177, "endOffset": 180}, {"referenceID": 12, "context": "This report was one of the reasons that we decided to start a couple of projects on Farsi and Arabic [16] [19].", "startOffset": 101, "endOffset": 105}, {"referenceID": 15, "context": "This report was one of the reasons that we decided to start a couple of projects on Farsi and Arabic [16] [19].", "startOffset": 106, "endOffset": 110}, {"referenceID": 11, "context": "Consequently, these projects led to developments of the two widely used Farsi and Arabic Stemmers [15][17].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "Consequently, these projects led to developments of the two widely used Farsi and Arabic Stemmers [15][17].", "startOffset": 102, "endOffset": 106}, {"referenceID": 15, "context": "One of the difficulties we had was the lack of technologies for input and display of Farsi and Arabic documents[19].", "startOffset": 111, "endOffset": 115}, {"referenceID": 8, "context": "The keyboard layout is based on the ISIRI 2901:1994 standard layout as documented in an email by Pournader [12].", "startOffset": 107, "endOffset": 111}, {"referenceID": 9, "context": "An HMM is a finite state automaton with probabilistic transitions and symbol emissions [13][14].", "startOffset": 87, "endOffset": 91}, {"referenceID": 10, "context": "An HMM is a finite state automaton with probabilistic transitions and symbol emissions [13][14].", "startOffset": 91, "endOffset": 95}, {"referenceID": 16, "context": "As an example, consider the widely used HMM [21] that decodes weather states based on a friend\u2019s activities.", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "The solution is given by the Viterbi algorithm that finds an optimal path using dynamic programming [14].", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "The algorithm 1 is a modification of the pseudo code from [21].", "startOffset": 58, "endOffset": 62}, {"referenceID": 3, "context": "For example, it is shown that the second order HMM improves the hand written character recognition [6].", "startOffset": 99, "endOffset": 102}, {"referenceID": 14, "context": "It may also worth mentioning that the second order HMM does not improve error detection and correction for post processing of printed documents [18].", "startOffset": 144, "endOffset": 148}], "year": 2015, "abstractText": "Displaying a document in Middle Eastern languages requires contextual analysis due to different presentational forms for each character of the alphabet. The words of the document will be formed by the joining of the correct positional glyphs representing corresponding presentational forms of the characters. A set of rules defines the joining of the glyphs. As usual, these rules vary from language to language and are subject to interpretation by the software developers. In this paper, we propose a machine learning approach for contextual analysis based on the first order Hidden Markov Model. We will design and build a model for the Farsi language to exhibit this technology. The Farsi model achieves 94 % accuracy with the training based on a short list of 89 Farsi vocabularies consisting of 2780 Farsi characters. The experiment can be easily extended to many languages including Arabic, Urdu, and Sindhi. Furthermore, the advantage of this approach is that the same software can be used to perform contextual analysis without coding complex rules for each specific language. Of particular interest is that the languages with fewer speakers can have greater representation on the web, since they are typically ignored by software developers due to lack of financial incentives.", "creator": "LaTeX with hyperref package"}}}