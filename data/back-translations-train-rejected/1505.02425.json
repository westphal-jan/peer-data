{"id": "1505.02425", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2015", "title": "Fast Rhetorical Structure Theory Discourse Parsing", "abstract": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing. Most of the recent work on RST parsing has focused on implementing new types of features or learning algorithms in order to improve accuracy, with relatively little focus on efficiency, robustness, or practical use. Also, most implementations are not widely available. Here, we describe an RST segmentation and parsing system that adapts models and feature sets from various previous work, as described below. Its accuracy is near state-of-the-art, and it was developed to be fast, robust, and practical. For example, it can process short documents such as news articles or essays in less than a second.", "histories": [["v1", "Sun, 10 May 2015 19:26:31 GMT  (18kb)", "http://arxiv.org/abs/1505.02425v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["michael heilman", "kenji sagae"], "accepted": false, "id": "1505.02425"}, "pdf": {"name": "1505.02425.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["mheilman@ets.org", "sagae@ict.usc.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 5.02 425v 1 [cs.C L] 10 May 201 5Fast Rhetorical Structure Theory Discourse ParsingMichael Heilman Educational Testing ServicePrinceton, NJ, USA mheilman @ ets.orgKenji Sagae Institute for Creative Technologies University of Southern California Los Angeles, CA, USA sagae @ ict.usc.edu"}, {"heading": "1 Introduction", "text": "In recent years, there has been a great deal of research on discourse sparsing, in particular RST discourse sparsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a). Most of the recent work on RST parsing has focused on implementing new types of features or learning algorithms to improve accuracy, with relatively little emphasis on efficiency, robustness, or practical application. In addition, most implementations are not generally available.At this point, we describe an RST segmentation and analysis system that adapts models and feature sets from various previous work as described below. Its accuracy is state-of-the-art, and is designed to be fast, robust, and practical."}, {"heading": "2 Tasks and Data", "text": "We address two tasks in this work: discourse segmentation and discourse analysis. Discourse segmentation is the task of taking a sequence of word and punctuation marks as input and identifying boundaries at which new discourse units begin. Discourse analysis is the task of taking a sequence of discourse units and identifying relationships between them. In our case, these relationships form a tree.For both, we follow the conventions encoded in the RST Discourse Treebank (Carlson et al., 2002). Here, we give a brief overview of the corpus. See Carlson et al. (2001) for more information. The treebank uses a representation in which discourse is presented as a tree, with labels on nodes indicating relationships between siblings. Most RST relationships have a core that expresses the core content, and a satellite that provides additional information to the core. Probably the simplest example is the \"mapping\" relationship: attributed to text (e.g., we are quoted as the satellite system)."}, {"heading": "3 Discourse Segmenter Description", "text": "In this section, we describe and evaluate the discourse segmentation component of the system. Our discourse segmentator is essentially a re-implementation of the base system by Xuan Bach et al. (2012). We are not implementing their newly bound model, which is more complex to implement and probably less efficient, and we use the ZPar parser (Zhang and Clark, 2011) for automatic syntactic parsing."}, {"heading": "3.1 Segmenter Model and Features", "text": "Following Xuan Bach et al. (2012), we model RST as a tagging problem. Specifically, the system predicts for each token in a sentence whether that token is the beginning of a new EDU or the continuation of an EDU. For this task, we use a conditional random field (Lafferty et al., 2001) with a DIN EN 2 regulation using the CRF + + implementation (https: / / crfpp.googlecode.com). In addition, we assume that a new sentence always starts a new EDU, regardless of the CRF output.The CRF uses simple word and POS features as well as syntactic features. The word and POS features are as follows (note that by \"word\" we mean a word or character): \u2022 the rundown form of the current word \u2022 the part-of-speech (POS) of the current word (POS features) of the current word (e.g. the parent feature)."}, {"heading": "3.2 Segmenter Evaluation", "text": "Following Xuan Bach et al. (2012), we evaluate segmentation performance using the gold standard EDUs from the RST Treebank test set, using the F1 score for the day that indicates the beginning of a new EDU (\"B-EDU\"). As new sets start new EDUs, we exclude the first day in the output (always \"B-EDU\") for each sentence. For comparison, we include previous results, including human match, reported by Xuan Bach et al. (2012) using the Stanford Parser syntax (Klein and Manning, 2003a) (the paper does not clearly indicate which analysis model was used). \"CRFSeg\" results are for the Hernault et al. (2010) system. We are unsure what causes the differences in the hypothesis that we are at least observing the major differences in partition size synchronously."}, {"heading": "4 Discourse Parser Description", "text": "In this section, we describe our RST parser. It borrows extensively from previous work, in particular Sagae (2009).11Please note that we do not include Sagae (2009) in our assessments, as only performance within a sentence is shown in this essay."}, {"heading": "4.1 Shift-Reduce Approach", "text": "According to Sagae (2009) and Ji and Eisenstein (2014), we use a shift-reducing \"arc standard\" for the analysis of the RST discourse."}, {"heading": "4.2 Parsing Model", "text": "The parser maintains two primary data structures: a queue containing the EDUs of the document that have not yet been processed, and a stack of RST sub-trees that are ultimately merged into a complete tree. First, the stack is empty and all EDUs are put in the queue. Until a complete tree is found or no actions can be performed, the parser iteratively selects whether to perform or reduce layer actions. First, the layer action creates a new sub-tree for the next EDU in the queue. Reduce actions generate new sub-trees from the sub-trees at the top of the stack. Second, there are several types of reduction actions. First, there are unary or binary versions of reduction actions, depending on whether the top 1 or 2 elements of the stack are included as children in the sub-tree to be created. Second, there are versions for each of the non-terminal labels on the top of the stack (e.g., \"Break together the relationships\")."}, {"heading": "4.3 Parsing Features", "text": "To select the next layer or reduce the queue, the analysis model takes into account a variety of lexical, syntactical and positional features adapted to various previous work on the analysis of the RST discourse, such as that of Sagae (2009) and the systems with which we compare in paragraph 5. Characteristics are as follows: \u2022 the previous action (e.g. \"binary reduction to satellite: mapping\") \u2022 the non-terminal symbols of the n-th subtree on the stack (n = 0, 1, 2) and their combinations \u2022 the non-terminal symbols of the children of the n-th subtree on the stack (n = 0, 1, 2) \u2022 the depressed words (and POS tags) for the tokens in the header EDU for the n-th subtree on the stack (n = 0, 1) and the first EDU on the stack (n = 1, 3), the first synchronization for the first part of the EDU-group (3), the first part of the synchronization"}, {"heading": "5 Parsing Experiments", "text": "Following (Marcu, 2000, pp. 143-144) and other recent work, we evaluate our system according to the F1 score for labeled and unlabeled spans of discourse units in the RST Treebank Test Set. This rating is consistent with the evaluation program for evaluation groups commonly used for constituency analysis (http: / / nlp.cs.nyu.edu / evalb /). For comparison with previous results, we use gold standard discourse segmentations (but automatic syntactic parses from ZPar).We report F1 values for compliance with the gold standard on unlabeled EDU spans (\"span\"), spans labeled only with nuclearity (\"nuclear\"), and fully labeled spans containing relationship information (\"Relation\").We first optimized the differences between the two models (1 regularization parameter for searching for the grid J0P and J0P synchronization parameters)."}, {"heading": "5.1 The effect of automatic syntax parsing", "text": "To show the effect of automatic parsing, we report on the performance of the development set (\u00a7 2), using either gold standard syntax trees from Penn Treebank or the automatic syntax trees from our retrained ZPar model (\u00a7 2) for computational functions. F1 values are presented in Table 3 (note that we report the results using the optimal settings from the grid search on the development set). It appears that the performance difference between using the automatic syntax instead of the gold standard syntax is about 1 to 2 points of the F1 value."}, {"heading": "5.2 Parsing Speed", "text": "In this section we evaluate the speed of the parser. Most previous work on RST parsing does not report runtime experiments, and most systems are not generally available or easy to replicate.Our parser uses a displacement-reducing parsing algorithm that has a runtime that is linear in the number of EDUs in the worst case. For comparison, Li et al. (2014b) uses a square, maximum-time approach to parsing trees. Joty et al. (2013) also uses a polynominal runtime algorithm. Other linear time parsers have been developed (Feng and Hirst, 2014; Ji and Eisenstein, 2014). However, the function calculation can also be a performance-dependent bottleneck. Feng and Hirst (2014) also report an average analysis time of 10.71 seconds for RST treebank test sets (and 5.52 seconds for a variant)."}, {"heading": "6 Conclusion", "text": "In this paper, we introduced a fast discourse segmentator and parser that achieves near-state-of-the-art accuracy and processes Penn Treebank documents in less than a second, which is about an order of magnitude faster than the most recent results from Feng and Hirst (2014)."}, {"heading": "Acknowledgments", "text": "We would like to thank Dan Blanchard, Xinhao Wang and Keelan Evanini for their feedback on this work and Dan Blanchard, Diane Napolitano, Nitin Madnani, Aoife Cahill, Chong Min Lee, Michael Flor and Keisuke Sakaguchi for their initial help and feedback on the implementation."}], "references": [{"title": "Building a discourse-tagged corpus in the framework of rhetorical structure theory", "author": ["Lynn Carlson", "Daniel Marcu", "Mary Ellen Okurowski."], "venue": "Proceedings of the Second SIGdial Workshop on Discourse and Dialogue - Volume 16, SIGDIAL \u201901, pages 1\u201310,", "citeRegEx": "Carlson et al\\.,? 2001", "shortCiteRegEx": "Carlson et al\\.", "year": 2001}, {"title": "A maximum-entropy-inspired parser", "author": ["Eugene Charniak."], "venue": "1st Meeting of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Charniak.,? 2000", "shortCiteRegEx": "Charniak.", "year": 2000}, {"title": "A lineartime bottom-up discourse parser with constraints and post-editing", "author": ["Vanessa Wei Feng", "Graeme Hirst."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 511\u2013521, Baltimore,", "citeRegEx": "Feng and Hirst.,? 2014", "shortCiteRegEx": "Feng and Hirst.", "year": 2014}, {"title": "A sequential model for discourse segmentation", "author": ["Hugo Hernault", "Danushka Bollegala", "Mitsuru Ishizuka."], "venue": "Proceedings of the 11th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing\u201910, pages 315\u2013326,", "citeRegEx": "Hernault et al\\.,? 2010", "shortCiteRegEx": "Hernault et al\\.", "year": 2010}, {"title": "Representation learning for text-level discourse parsing", "author": ["Yangfeng Ji", "Jacob Eisenstein."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13\u201324, Baltimore, Maryland, June. Association", "citeRegEx": "Ji and Eisenstein.,? 2014", "shortCiteRegEx": "Ji and Eisenstein.", "year": 2014}, {"title": "Discriminative reranking of discourse parses using tree kernels", "author": ["Shafiq Joty", "Alessandro Moschitti."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2049\u20132060, Doha, Qatar, October. Association", "citeRegEx": "Joty and Moschitti.,? 2014", "shortCiteRegEx": "Joty and Moschitti.", "year": 2014}, {"title": "A novel discriminative framework for sentence-level discourse analysis", "author": ["Shafiq Joty", "Giuseppe Carenini", "Raymond Ng."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Lan-", "citeRegEx": "Joty et al\\.,? 2012", "shortCiteRegEx": "Joty et al\\.", "year": 2012}, {"title": "Combining intra- and multisentential rhetorical parsing for document-level discourse analysis", "author": ["Shafiq Joty", "Giuseppe Carenini", "Raymond Ng", "Yashar Mehdad."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Joty et al\\.,? 2013", "shortCiteRegEx": "Joty et al\\.", "year": 2013}, {"title": "Accurate unlexicalized parsing", "author": ["Dan Klein", "Christopher D. Manning."], "venue": "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 423\u2013430, Sapporo, Japan, July. Association for Computational Linguistics.", "citeRegEx": "Klein and Manning.,? 2003a", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "Fast exact inference with a factored model for natural language parsing", "author": ["Dan Klein", "Christopher D Manning."], "venue": "S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15, pages 3\u201310. MIT Press.", "citeRegEx": "Klein and Manning.,? 2003b", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando C.N. Pereira."], "venue": "Proceedings of the 18th International Conference", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Recursive deep models for discourse parsing", "author": ["Jiwei Li", "Rumeng Li", "Eduard Hovy."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2061\u2013 2069, Doha, Qatar, October. Association for Compu-", "citeRegEx": "Li et al\\.,? 2014a", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Text-level discourse dependency parsing", "author": ["Sujian Li", "Liang Wang", "Ziqiang Cao", "Wenjie Li."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 25\u201335, Baltimore, Maryland, June. As-", "citeRegEx": "Li et al\\.,? 2014b", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "The Theory and Practice of Discourse Parsing and Summarization", "author": ["Daniel Marcu."], "venue": "MIT Press.", "citeRegEx": "Marcu.,? 2000", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Mitchell P. Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."], "venue": "Computational Linguistics, 19(2):313\u2013330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Maltparser: A language-independent system for data-driven dependency parsing", "author": ["J.J. Hall J. Nilsson A. Chanev G. Eryigit S. Kbler S. Marinov Nivre", "E. Marsi."], "venue": "13(2):95\u2013135.", "citeRegEx": "Nivre and Marsi.,? 2007", "shortCiteRegEx": "Nivre and Marsi.", "year": 2007}, {"title": "A classifier-based parser with linear run-time complexity", "author": ["Kenji Sagae", "Alon Lavie."], "venue": "Proceedings of the Ninth International Workshop on Parsing Technology, pages 125\u2013132, Vancouver, British Columbia, October. Association for Computational", "citeRegEx": "Sagae and Lavie.,? 2005", "shortCiteRegEx": "Sagae and Lavie.", "year": 2005}, {"title": "Analysis of discourse structure with syntactic dependencies and data-driven shift-reduce parsing", "author": ["Kenji Sagae."], "venue": "Proceedings of the 11th International Conference on Parsing Technologies (IWPT\u201909), pages 81\u201384, Paris, France, October. Association for Com-", "citeRegEx": "Sagae.,? 2009", "shortCiteRegEx": "Sagae.", "year": 2009}, {"title": "Sentence level discourse parsing using syntactic and lexical information", "author": ["Radu Soricut", "Daniel Marcu."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technol-", "citeRegEx": "Soricut and Marcu.,? 2003", "shortCiteRegEx": "Soricut and Marcu.", "year": 2003}, {"title": "A reranking model for discourse segmentation using subtree features", "author": ["Ngo Xuan Bach", "Nguyen Le Minh", "Akira Shimazu."], "venue": "Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 160\u2013168, Seoul, South", "citeRegEx": "Bach et al\\.,? 2012", "shortCiteRegEx": "Bach et al\\.", "year": 2012}, {"title": "Syntactic processing using the generalized perceptron and beam search", "author": ["Yue Zhang", "Stephen Clark."], "venue": "Computational Linguistics, 37(1).", "citeRegEx": "Zhang and Clark.,? 2011", "shortCiteRegEx": "Zhang and Clark.", "year": 2011}], "referenceMentions": [{"referenceID": 2, "context": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a).", "startOffset": 111, "endOffset": 220}, {"referenceID": 12, "context": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a).", "startOffset": 111, "endOffset": 220}, {"referenceID": 4, "context": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a).", "startOffset": 111, "endOffset": 220}, {"referenceID": 5, "context": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a).", "startOffset": 111, "endOffset": 220}, {"referenceID": 11, "context": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a).", "startOffset": 111, "endOffset": 220}, {"referenceID": 0, "context": "For both, we follow the conventions encoded in the RST Discourse Treebank (Carlson et al., 2002). Here, we give a brief overview of the corpus. See Carlson et al. (2001) for more information.", "startOffset": 75, "endOffset": 170}, {"referenceID": 14, "context": "The texts in the RST treebank are a subset of those in the Penn Treebank (Marcus et al., 1993).", "startOffset": 73, "endOffset": 94}, {"referenceID": 20, "context": "For this reason, we retrained the syntactic parser used in our system, ZPar (Zhang and Clark, 2011), on the subset of the Penn Treebank WSJ sections 2 to 21 texts not present in the RST treebank.", "startOffset": 76, "endOffset": 99}, {"referenceID": 20, "context": "We do not implement their reranked model, which is more complex to implement and probably less efficient, and we use the ZPar parser (Zhang and Clark, 2011) for automatic syntactic parsing.", "startOffset": 133, "endOffset": 156}, {"referenceID": 19, "context": "Our discourse segmenter is essentially a reimplementation of the baseline system from Xuan Bach et al. (2012). We do not implement their reranked model, which is more complex to implement and probably less efficient, and we use the ZPar parser (Zhang and Clark, 2011) for automatic syntactic parsing.", "startOffset": 91, "endOffset": 110}, {"referenceID": 10, "context": "For this task, we use a conditional random field (Lafferty et al., 2001) model with l2 regularization, using the CRF++ implementation (https://crfpp.", "startOffset": 49, "endOffset": 72}, {"referenceID": 18, "context": "Following Xuan Bach et al. (2012), we model RST as a tagging problem.", "startOffset": 15, "endOffset": 34}, {"referenceID": 19, "context": "Following Xuan Bach et al. (2012), we evaluate segmentation performance using the gold standard EDUs from the RST treebank test set, using the F1 score for the tag indicating the beginning of a new EDU (\u201cB-EDU\u201d).", "startOffset": 15, "endOffset": 34}, {"referenceID": 8, "context": "(2012), using syntax from the Stanford Parser (Klein and Manning, 2003a) (it is not clear from the paper what parsing model was used).", "startOffset": 46, "endOffset": 72}, {"referenceID": 16, "context": "For comparison, we include previous results, including humanhuman agreement, reported by Xuan Bach et al. (2012), using syntax from the Stanford Parser (Klein and Manning, 2003a) (it is not clear from the paper what parsing model was used).", "startOffset": 94, "endOffset": 113}, {"referenceID": 3, "context": "The \u201cCRFSeg\u201d results are for the system from Hernault et al. (2010).", "startOffset": 45, "endOffset": 68}, {"referenceID": 17, "context": "borrows extensively from previous work, especially Sagae (2009).1", "startOffset": 51, "endOffset": 64}, {"referenceID": 17, "context": "Note that we do not include Sagae (2009) in our evaluations since only within-sentence parsing performance was reported in that paper.", "startOffset": 28, "endOffset": 41}, {"referenceID": 16, "context": "Following Sagae (2009) and Ji and Eisenstein (2014), we use an \u201carc standard\u201d shift-reduce approach to RST discourse parsing.", "startOffset": 10, "endOffset": 23}, {"referenceID": 4, "context": "Following Sagae (2009) and Ji and Eisenstein (2014), we use an \u201carc standard\u201d shift-reduce approach to RST discourse parsing.", "startOffset": 27, "endOffset": 52}, {"referenceID": 16, "context": "Additionally, we binarize trees as described by Sagae and Lavie (2005).", "startOffset": 48, "endOffset": 71}, {"referenceID": 16, "context": "Following Sagae (2009) and Ji and Eisenstein (2014), we treat the problem of selecting the best parsing action given the current parsing state (i.", "startOffset": 10, "endOffset": 23}, {"referenceID": 4, "context": "Following Sagae (2009) and Ji and Eisenstein (2014), we treat the problem of selecting the best parsing action given the current parsing state (i.", "startOffset": 27, "endOffset": 52}, {"referenceID": 17, "context": "To select the next shift or reduce action, the parsing model considers a variety of lexical, syntactic, and positional features adapted from various previous work on RST discourse parsing, such as that of Sagae (2009) and the systems we compare to in \u00a75.", "startOffset": 205, "endOffset": 218}, {"referenceID": 18, "context": "\u2022 syntactic dominance features between pairs of the top 3 stack items and 1st queue item, similar to (Soricut and Marcu, 2003)", "startOffset": 101, "endOffset": 126}, {"referenceID": 5, "context": "1 Li et al. (2014a) Stanford 84.", "startOffset": 2, "endOffset": 20}, {"referenceID": 2, "context": "6 Joty et al. (2013) Charniak (retrained) 82.", "startOffset": 2, "endOffset": 21}, {"referenceID": 1, "context": "(2013) Charniak (retrained) 82.5 68.4 55.7 Joty and Moschitti (2014) Charniak (retrained) \u2013 \u2013 57.", "startOffset": 7, "endOffset": 69}, {"referenceID": 1, "context": "(2013) Charniak (retrained) 82.5 68.4 55.7 Joty and Moschitti (2014) Charniak (retrained) \u2013 \u2013 57.3 Feng and Hirst (2014) Stanford 85.", "startOffset": 7, "endOffset": 121}, {"referenceID": 1, "context": "(2013) Charniak (retrained) 82.5 68.4 55.7 Joty and Moschitti (2014) Charniak (retrained) \u2013 \u2013 57.3 Feng and Hirst (2014) Stanford 85.7 71.0 58.2 Li et al. (2014b) Penn Treebank 82.", "startOffset": 7, "endOffset": 163}, {"referenceID": 1, "context": "(2013) Charniak (retrained) 82.5 68.4 55.7 Joty and Moschitti (2014) Charniak (retrained) \u2013 \u2013 57.3 Feng and Hirst (2014) Stanford 85.7 71.0 58.2 Li et al. (2014b) Penn Treebank 82.9 73.0 60.6 Ji and Eisenstein (2014) MALT 81.", "startOffset": 7, "endOffset": 217}, {"referenceID": 9, "context": "\u201csyntax\u201d indicates the source of POS tags and syntactic parse trees: \u201cStanford\u201d refers to the Stanford parser (Klein and Manning, 2003b), \u201cMALT\u201d refers to Nivre and Marsi (2007), and \u201cCharniak\u201d refers to Charniak (2000).", "startOffset": 110, "endOffset": 136}, {"referenceID": 7, "context": "\u201csyntax\u201d indicates the source of POS tags and syntactic parse trees: \u201cStanford\u201d refers to the Stanford parser (Klein and Manning, 2003b), \u201cMALT\u201d refers to Nivre and Marsi (2007), and \u201cCharniak\u201d refers to Charniak (2000).", "startOffset": 111, "endOffset": 178}, {"referenceID": 1, "context": "\u201csyntax\u201d indicates the source of POS tags and syntactic parse trees: \u201cStanford\u201d refers to the Stanford parser (Klein and Manning, 2003b), \u201cMALT\u201d refers to Nivre and Marsi (2007), and \u201cCharniak\u201d refers to Charniak (2000).", "startOffset": 184, "endOffset": 220}, {"referenceID": 3, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al.", "startOffset": 45, "endOffset": 70}, {"referenceID": 2, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al.", "startOffset": 108, "endOffset": 130}, {"referenceID": 2, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al. (2014b), Joty and Moschitti (2014), Li et al.", "startOffset": 108, "endOffset": 149}, {"referenceID": 2, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al. (2014b), Joty and Moschitti (2014), Li et al.", "startOffset": 108, "endOffset": 176}, {"referenceID": 2, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al. (2014b), Joty and Moschitti (2014), Li et al. (2014a), and Joty and Moschitti (2014).", "startOffset": 108, "endOffset": 195}, {"referenceID": 2, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al. (2014b), Joty and Moschitti (2014), Li et al. (2014a), and Joty and Moschitti (2014).2 The results are shown in Table 2.", "startOffset": 108, "endOffset": 226}, {"referenceID": 2, "context": "We compare to recently reported results from Ji and Eisenstein (2014) (their DPLP general +features model), Feng and Hirst (2014), Li et al. (2014b), Joty and Moschitti (2014), Li et al. (2014a), and Joty and Moschitti (2014).2 The results are shown in Table 2. The human agreement statistics were originally reported by Ji and Eisenstein (2014). For each system, the table indicates the source of POS tags and syntactic parse trees (\u201cPenn Treebank\u201d means", "startOffset": 108, "endOffset": 346}, {"referenceID": 1, "context": "(2012) that the Charniak (2000) parser was used, with a model trained on a subset of the Penn Treebank that did not include the RST treebank test set.", "startOffset": 16, "endOffset": 32}, {"referenceID": 2, "context": "Other linear time parsers have been developed (Feng and Hirst, 2014; Ji and Eisenstein, 2014).", "startOffset": 46, "endOffset": 93}, {"referenceID": 4, "context": "Other linear time parsers have been developed (Feng and Hirst, 2014; Ji and Eisenstein, 2014).", "startOffset": 46, "endOffset": 93}, {"referenceID": 7, "context": "For comparison, Li et al. (2014b) employ a quadratic time maximum spanning tree parsing approach.", "startOffset": 16, "endOffset": 34}, {"referenceID": 4, "context": "The approach from Joty et al. (2013) also uses a polynominal runtime algorithm.", "startOffset": 18, "endOffset": 37}, {"referenceID": 2, "context": "Feng and Hirst (2014) report an average parsing time of 10.", "startOffset": 0, "endOffset": 22}, {"referenceID": 2, "context": "The parser achieves near state-of-the-art accuracy and processes Penn Treebank documents in less than a second, which is about an order of magnitude faster than recent results reported by Feng and Hirst (2014).", "startOffset": 188, "endOffset": 210}], "year": 2015, "abstractText": "In recent years, There has been a variety of research on discourse parsing, particularly RST discourse parsing (Feng and Hirst, 2014; Li et al., 2014b; Ji and Eisenstein, 2014; Joty and Moschitti, 2014; Li et al., 2014a). Most of the recent work on RST parsing has focused on implementing new types of features or learning algorithms in order to improve accuracy, with relatively little focus on efficiency, robustness, or practical use. Also, most implementations are not widely available. Here, we describe an RST segmentation and parsing system that adapts models and feature sets from various previous work, as described below. Its accuracy is near state-of-the-art, and it was developed to be fast, robust, and practical. For example, it can process short documents such as news articles or essays in less than a second. The system is written in Python and is publicly available at https://github. com/EducationalTestingService/ discourse-parsing.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}