{"id": "1505.02433", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2015", "title": "Probabilistic Belief Embedding for Knowledge Base Completion", "abstract": "This paper contributes a novel embedding model which measures the probability of each belief $\\langle h,r,t,m\\rangle$ in a large-scale knowledge repository via simultaneously learning distributed representations for entities ($h$ and $t$), relations ($r$), and the words in relation mentions ($m$). It facilitates knowledge completion by means of simple vector operations to discover new beliefs. Given an imperfect belief, we can not only infer the missing entities, predict the unknown relations, but also tell the plausibility of the belief, just leveraging the learnt embeddings of remaining evidences. To demonstrate the scalability and the effectiveness of our model, we conduct experiments on several large-scale repositories which contain millions of beliefs from WordNet, Freebase and NELL, and compare it with other cutting-edge approaches via competing the performances assessed by the tasks of entity inference, relation prediction and triplet classification with respective metrics. Extensive experimental results show that the proposed model outperforms the state-of-the-arts with significant improvements.", "histories": [["v1", "Sun, 10 May 2015 20:22:47 GMT  (472kb,D)", "https://arxiv.org/abs/1505.02433v1", "arXiv admin note: text overlap witharXiv:1503.08155"], ["v2", "Mon, 18 May 2015 02:19:39 GMT  (476kb,D)", "http://arxiv.org/abs/1505.02433v2", "arXiv admin note: text overlap witharXiv:1503.08155"], ["v3", "Tue, 19 May 2015 14:56:16 GMT  (477kb,D)", "http://arxiv.org/abs/1505.02433v3", "arXiv admin note: text overlap witharXiv:1503.08155"], ["v4", "Fri, 22 May 2015 16:58:33 GMT  (238kb,D)", "http://arxiv.org/abs/1505.02433v4", "arXiv admin note: text overlap witharXiv:1503.08155"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1503.08155", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["miao fan", "qiang zhou", "rew abel", "thomas fang zheng", "ralph grishman"], "accepted": false, "id": "1505.02433"}, "pdf": {"name": "1505.02433.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Belief Embedding for Knowledge Base Completion", "authors": ["Miao Fan", "Qiang Zhou", "Andrew Abel", "Thomas Fang Zheng", "Ralph Grishman"], "emails": ["fanmiao.cslt.thu@gmail.com"], "sections": [{"heading": null, "text": "This paper contributes a novel embedding model that measures the probability of each candidate for faith < h, r, t, m > in a large store of knowledge by simultaneously learning distributed representations of entities (h and t), relationships (r), and even words in relation (m). It facilitates completion of knowledge through simple vector operations to discover new beliefs. To demonstrate the scalability and effectiveness of our model, we conduct experiments on several large entities containing hundreds of thousands of beliefs from WordNet, Freebase, and NELL, and compare the results of a number of tasks, entity conclusions, relationship predictions, and triplet classifications with innovative approaches. Extensive experimental results show that the proposed model outperforms other significant improvements in methods."}, {"heading": "1 Introduction", "text": "It is still not clear if and to what extent it is indeed a complete knowledge that has attracted much attention in recent years due to the explosive growth in the number of websites. WordNet (Miller, 1995) and Freebase (Bollacker et al., 2007; Bollacker et al., 2008) follow the RDF format, which represents every faith as a triplet, i.e. < head entity, relation, tail entity. NELL et al., 2010a), each triplet extends with a relation indicating the corresponding relationship. <"}, {"heading": "2 Related Work", "text": "It is therefore a naive model that exploits the presence of information from the head and tail without taking into account the relationship between them. It defines a scoring function, and this model obviously cannot distinguish between a pair of entities that include different relationships between the entities. Therefore, unstructuring is commonly considered to be the baseline. (SE) uses a pair of matrices (Wrh, Wrt) to characterize a relationship between the entities. Unstructuring a relationship between entities is generally considered to be the basis. (Wrh, 2011) uses a pair of matrices (Wrh, Wrt) to characterize a relationship between the entities."}, {"heading": "3 Model", "text": "It is assumed that Pr (h, r, m) for the conditional probability of inferring the head h (h, m) of Pr (h, m) jointly of Pr (h, t), Pr (t), Pr (t, t), Pr (t), r (t), r (t), r (t), r (t), Pr (t), r (t), r (r), r (r), e (t), e (t), e), e (t), e (t), r (r), e (r), e (h), e (h), e (h), e (h), e (h), e (h), e (h), e (t), e (t), e (h), e (h)."}, {"heading": "4 Algorithm", "text": "In order to find the optimal solutions to the equation (4) and (5), we can use Stochastic Gradient Descent (SGD) to update the embedding of units, relationships and words of mentions in an iterative manner. However, it is mathematically complex to recalculate the normalization terms in Pr (h | r, t), Pr (r | h, t), Pr (h | h, t) and Pr (r | m) according to the definitions of the equation (8), (9), (10) and (12). For example, if we directly calculate the value of Pr (h, t) for just one faith, tens of thousands of expD (h, r, t) need to be re-evaluated as there are tens of thousands of candidate units h \u2032 in Eh. Inspired by the work of Mikolov et al."}, {"heading": "5 Experiment", "text": "In addition to accessing the efficient SGD algorithm, the learned embedding by PBE can contribute to greater effectiveness in several subtasks of knowledge completion, such as entity conclusions, relationship predictions and triplet classifications."}, {"heading": "5.1 Dataset", "text": "To demonstrate the broad adaptability and significant effectiveness of our approach, we are preparing three sets of data as shown in Table 1, i.e. NELL50K, WN-100K, FB-500K from the repositories of NELL (Carlson et al., 2010b), WordNet (Miller, 1995), and Freebase (Bollacker et al., 2007; Bollacker et al., 2008). NELL (Mitchell et al., 2015), designed and maintained by Carnegie Mellon University, is an outstanding system that runs 24 hours a day and never stops learning the beliefs on the Web. We use a relatively small set of NELL-50K containing approximately 50,000 confidence-weighted beliefs from NELL. Each belief in NELL-50K has a relationship m in addition to a triplet < h, r, t >."}, {"heading": "5.2 Entity inference", "text": "One of the advantages of knowledge embedding is that simple vector operations can be applied to entity conclusions that contribute to completing knowledge graphs. In the face of a destroyed triplet, such as < h, r,? > or <?, r, t >, the subtask must use entity and relation embedding to calculate arg-maxh-Eh-Pr (h | h, t). Meanwhile, arg-maxt-Et-Pr (t | h, r) will help us find the original name of the data set (FB15K) in order to follow the naming conventions in our paper. Related studies on this data set can be looked up from the https: / / www.hds.utc.fr / everest / doku.php? id = en: transebest tail entity given the header unit h and relation r."}, {"heading": "5.2.1 Metric", "text": "The plausibility of each candidate triplet is first calculated by various scoring functions, such as Pr (h | r, t) in PBE, and then sorted in ascending order. Finally, we locate the basic truth triplet and record its rank. This whole process proceeds in the same way when we replace the tail entity, so that we can get the mean results. We use two metrics, namely Mean Rank and Mean Hit @ 10 (the percentage of basic truth triplets that rank in the top 10) to measure performance. However, the results measured using these metrics are relatively raw, as the method above tends to generate false negative triplets. In other words, some of the candidates rank higher than the basic truth triplets just because they also appear in training."}, {"heading": "5.2.2 Performance", "text": "We compare PBE with the TransH (Wang et al., 2014b), TransM (Fan et al., 2014b), TransE (Bordes et al., 2013) and TransE (Bordes et al., 2013) evaluated in Section 2, which are based on NELL-50K, WN-100K and FB-500K data sets. We match the parameters of each previous model based on the validation rate and select the combination of parameters leading to the best performance. Tables 2, 3 and 4 show that PBE exceeds the previous arts in almost all metrics. Overall, it achieves significant improvements (relative increments) for all three data sets, with NELL-50K: {Mean Rank Raw: {Mean Rank Raw: {Mean Rank Raw: 4.9%, Hit @ 10 Raw: 4.2%, Mean RankFilter: 3.7%, Hit @ 10 Filter: 8.3%, Mean Raw {Mean Rw: 10.5%, Hit @ 20.5%, Hit @ 20.5%: Hit @"}, {"heading": "5.3 Relation prediction", "text": "The scenario of this sub-task is as follows: If you assume two entities and the text specifies the semantic relations between them, i.e. < h,?, t, m >, this sub-task calculates the arg maxr-R Pr (r | h, t) Pr (r | m) to predict the best relationships."}, {"heading": "5.3.1 Metric", "text": "We compare the performance between our models and other state-of-the-art approaches with the following metrics: Average Rank: Each candidate relationship gets a score calculated by Equation (7). We sort them in ascending order and compare them with the corresponding basic-truth belief. For each belief in the test set, we get the rank of the correct relationship. The average rank is to some extent an aggregative indicator to judge the overall performance in relation extraction of an approach. Hit @ 10: In addition to the average rank, industry scientists care more about the accuracy of extraction when selecting the top-10 relationships. This metric shows the percentage of beliefs we predict as the correct relationship in Top10.Hit @ 1: It is a stricter metric that can be referenced by an automatic system because it shows the accuracy when only the first predicted relationship is selected from the sorted list."}, {"heading": "5.3.2 Performance", "text": "Table 5 illustrates the results of relationship forecasting experiments with all three sets of data. We find that text within the NELL-50K does much to predict correct relationships, and all results show that the PBE performs best compared to recent approaches, with relative increases being NELL-50K: {Mean Rank: 59.7%, Hit @ 10: 10.0%, Hit @ 1: 30.0%, WN-100K: {Mean Rank: 41.1%, Hit @ 10: 0.1%, Hit @ 1: 276.2%, and FB-500K: {Mean Rank: 95.7%, Hit @ 10: 148.2%, Hit @ 1: 327.6%}."}, {"heading": "5.4 Triplet classification", "text": "The triplet classification is another task proposed by Socher et al. (Socher et al., 2013), which focuses on the search for a relationship-specific threshold \u03c3r in order to determine whether a triplet < h, r, t > is plausible. If the probability of a test triplet (h, r, t) predicted by Pr (h | r, t) Pr (r | h, t) Pr (t | h, r) is below the relationship-specific threshold \u03c3r, it is predicted to be positive, otherwise negative."}, {"heading": "5.4.1 Metric", "text": "We use classification accuracy to measure the performance between the competing methods. Specifically, we sum up the accuracy of each triplet < h, r, t > by comparing the probability of the triplet and the relationship-specific threshold \u03c3r, which can be sought by maximizing the classification accuracy of the validation triplets belonging to the relationship r."}, {"heading": "5.4.2 Performance", "text": "Compared to several recent approaches, i.e. TransH (Wang et al., 2014b), TransM (Fan et al., 2014b) and TransE (Bordes et al., 2013), the proposed PBE approach still performs better than the improvements shown in NELL-50K: {accuracy: 7.9% ECU}, WN-100K: {accuracy: 5.6% ECU} and FB-500K: {accuracy: 5.6% ECU} as shown in Table 6."}, {"heading": "6 Conclusion", "text": "This paper proposed an elegant probabilistic model to address the problem of embedding beliefs containing both structured knowledge and unstructured free texts by first measuring the probability of a given belief < h, r, t, m >. In order to efficiently learn the embeddings for each entity, relationship and word in mentions, we also applied the technique of negative sampling to transform the original model and represent the algorithm based on stochastic gradient descent in order to find the optimal solution. Extensive experiments to complete knowledge, including inference, kinship prediction and triplet classification, showed that our approach achieves significant improvements when tested with three large-scale repositories compared to other state-of-the-art methods."}, {"heading": "Acknowledgement", "text": "The paper is dedicated to all members of CSLT8 and Proteus Group 9. It was supported by the National Program on Key Basic Research Project (973 Program) under Grant 2013CB329304 and the National Science Foundation of China (NSFC) under Grant No. 61373075 when the first author was a doctoral student at Tsinghua University and New York University."}], "references": [{"title": "Freebase: A shared database of structured general human knowledge", "author": ["Robert Cook", "Patrick Tufts"], "venue": "In AAAI,", "citeRegEx": "Bollacker et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2007}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of the 2008 ACM SIGMOD international", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Learning structured embeddings of knowledge bases", "author": ["Jason Weston", "Ronan Collobert", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bordes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2011}, {"title": "Translating embeddings for modeling multi-relational data", "author": ["Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "A semantic matching energy function for learning with multirelational data", "author": ["Xavier Glorot", "Jason Weston", "Yoshua Bengio"], "venue": "Machine Learning,", "citeRegEx": "Bordes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "Toward an architecture for never-ending language learning", "author": ["Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka Jr.", "Tom M. Mitchell"], "venue": "In Proceedings of the Twenty-Fourth", "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Toward an architecture for never-ending language learning", "author": ["Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka Jr.", "Tom M. Mitchell"], "venue": "In Proceedings of the Twenty-Fourth Conference", "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "http://cslt.riit.tsinghua.edu.cn/ http://nlp.cs.nyu.edu/index.shtml", "author": ["Fan et al.2014a] Miao Fan", "Deli Zhao", "Qiang Zhou", "Zhiyuan Liu", "Thomas Fang Zheng", "Edward Y"], "venue": null, "citeRegEx": "Fan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2014}, {"title": "Distant supervision for relation extraction with matrix completion", "author": ["Chang."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 839\u2013849, Baltimore, Maryland, June.", "citeRegEx": "Chang.,? 2014a", "shortCiteRegEx": "Chang.", "year": 2014}, {"title": "Transition-based knowledge graph embedding with relational mapping properties", "author": ["Fan et al.2014b] Miao Fan", "Qiang Zhou", "Emily Chang", "Thomas Fang Zheng"], "venue": "In Proceedings of the 28th Pacific Asia Conference on Language,", "citeRegEx": "Fan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2014}, {"title": "Jointly embedding relations and mentions for knowledge population", "author": ["Fan et al.2015a] Miao Fan", "Kai Cao", "Yifan He", "Ralph Grishman"], "venue": "arXiv preprint arXiv:1504.01683", "citeRegEx": "Fan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2015}, {"title": "Learning embedding representations for knowledge inference on imperfect and incomplete repositories. arXiv preprint arXiv:1503.08155", "author": ["Fan et al.2015b] Miao Fan", "Qiang Zhou", "Thomas Fang Zheng"], "venue": null, "citeRegEx": "Fan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2015}, {"title": "Information extraction: Techniques and challenges. In International Summer School on Information Extraction: A Multidisciplinary Approach to an Emerging Information Technology, SCIE", "author": ["Ralph Grishman"], "venue": null, "citeRegEx": "Grishman.,? \\Q1997\\E", "shortCiteRegEx": "Grishman.", "year": 1997}, {"title": "A latent factor model for highly multi-relational data", "author": ["Nicolas Le Roux", "Antoine Bordes", "Guillaume Obozinski"], "venue": "In NIPS,", "citeRegEx": "Jenatton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2012}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: a lexical database for english", "author": ["George A. Miller"], "venue": "Communications of the ACM,", "citeRegEx": "Miller.,? \\Q1995\\E", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Danqi Chen", "Christopher D Manning", "Andrew Ng"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Modelling relational data using bayesian clustered tensor factorization", "author": ["Ruslan Salakhutdinov", "Joshua B Tenenbaum"], "venue": "In NIPS,", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "Knowledge graph and text jointly embedding", "author": ["Wang et al.2014a] Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Knowledge graph embedding by translating on hyperplanes", "author": ["Wang et al.2014b] Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Knowledge base completion via search-based question answering", "author": ["West et al.2014] Robert West", "Evgeniy Gabrilovich", "Kevin Murphy", "Shaohua Sun", "Rahul Gupta", "Dekang Lin"], "venue": null, "citeRegEx": "West et al\\.,? \\Q2014\\E", "shortCiteRegEx": "West et al\\.", "year": 2014}, {"title": "Connecting language and knowledge bases with embedding models for relation extraction", "author": ["Weston et al.2013] Jason Weston", "Antoine Bordes", "Oksana Yakhnenko", "Nicolas Usunier"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods", "citeRegEx": "Weston et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "Information extraction (Sarawagi, 2008; Grishman, 1997), the study of extracting structured beliefs from unstructured online texts to populate knowledge bases, has drawn much attention in recent years because of the explosive growth in the number of web pages.", "startOffset": 23, "endOffset": 55}, {"referenceID": 15, "context": "WordNet (Miller, 1995) and Freebase (Bollacker et al.", "startOffset": 8, "endOffset": 22}, {"referenceID": 0, "context": "WordNet (Miller, 1995) and Freebase (Bollacker et al., 2007; Bollacker et al., 2008) follow the RDF format that represents each belief as a triplet, i.", "startOffset": 36, "endOffset": 84}, {"referenceID": 1, "context": "WordNet (Miller, 1995) and Freebase (Bollacker et al., 2007; Bollacker et al., 2008) follow the RDF format that represents each belief as a triplet, i.", "startOffset": 36, "endOffset": 84}, {"referenceID": 21, "context": "Although colossal quantities of beliefs have been gathered, state-of-the-art work (West et al., 2014) reports that our knowledge bases are far from complete.", "startOffset": 82, "endOffset": 101}, {"referenceID": 16, "context": "completion have benefited significantly from a paradigm known as Distantly Supervised Relation Extraction (Mintz et al., 2009) (DSRE), which bridges the gap between structured knowledge bases and unstructured free texts.", "startOffset": 106, "endOffset": 126}, {"referenceID": 7, "context": "However state-of-the-art research (Fan et al., 2014a) points out that DSRE still suffers from the problem of sparse and noisy features. Although Fan et al. (2014a) fix the issue to some extent by making use of low-dimensional matrix factorization, their approach was identified as unable to handle large-scale datasets.", "startOffset": 35, "endOffset": 164}, {"referenceID": 2, "context": "Fortunately, knowledge embedding techniques (Bordes et al., 2011; Bordes et al., 2014) enable us to encode the high-dimensional sparse features into low-dimensional distributed representations.", "startOffset": 44, "endOffset": 86}, {"referenceID": 4, "context": "Fortunately, knowledge embedding techniques (Bordes et al., 2011; Bordes et al., 2014) enable us to encode the high-dimensional sparse features into low-dimensional distributed representations.", "startOffset": 44, "endOffset": 86}, {"referenceID": 3, "context": "A simple but effective model is TransE (Bordes et al., 2013), which trains a vector representation for each entity and relation in large-scale knowledge bases without considering any text information.", "startOffset": 39, "endOffset": 60}, {"referenceID": 22, "context": "(Weston et al., 2013), Wang et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 3, "context": "Unstructured (Bordes et al., 2013) is a naive model which exploits the occurrence information of the head and the tail entities without considering the relation between them.", "startOffset": 13, "endOffset": 34}, {"referenceID": 2, "context": "Distance Model (SE) (Bordes et al., 2011) uses a pair of matrices (Wrh,Wrt), to characterize a relation r.", "startOffset": 20, "endOffset": 41}, {"referenceID": 17, "context": "(Socher et al., 2013), the separating matrices Wrh and Wrt weaken the capability of capturing correlations between entities and corresponding relations, despite the model taking the relations into consideration.", "startOffset": 0, "endOffset": 21}, {"referenceID": 17, "context": "(Socher et al., 2013) thus aims to alleviate the shortcomings of the Distance Model by means of the non-linearity of a single layer neural network", "startOffset": 0, "endOffset": 21}, {"referenceID": 18, "context": "Bilinear Model (Sutskever et al., 2009; Jenatton et al., 2012) is another model that tries to fix the issue of weak interaction between the head and tail entities caused by the Distance Model with a relation-specific bilinear form: fr(h, t) = hWrt.", "startOffset": 15, "endOffset": 62}, {"referenceID": 13, "context": "Bilinear Model (Sutskever et al., 2009; Jenatton et al., 2012) is another model that tries to fix the issue of weak interaction between the head and tail entities caused by the Distance Model with a relation-specific bilinear form: fr(h, t) = hWrt.", "startOffset": 15, "endOffset": 62}, {"referenceID": 17, "context": "Neural Tensor Network (NTN) (Socher et al., 2013) designs a general scoring function: fr(h, t) = u T r g(h Wrt + Wrhh + Wrtt + br), which combines the Single Layer and Bilinear", "startOffset": 28, "endOffset": 49}, {"referenceID": 3, "context": "TransE (Bordes et al., 2013) is a canonical model different from all the other prior arts, which embeds relations into the same vector space as entities by regarding the relation r as a translation from h to t, i.", "startOffset": 7, "endOffset": 28}, {"referenceID": 2, "context": "This kind of symbolic representation, whilst being very efficient for storing, is not flexible enough for statistical learning approaches (Bordes et al., 2011).", "startOffset": 138, "endOffset": 159}, {"referenceID": 14, "context": "(Mikolov et al., 2013), we have developed an efficient approach that adopts the negative sampling technique to approximate the conditional probability functions, i.", "startOffset": 0, "endOffset": 22}, {"referenceID": 15, "context": ", 2010b), WordNet (Miller, 1995) and Freebase (Bollacker et al.", "startOffset": 18, "endOffset": 32}, {"referenceID": 0, "context": ", 2010b), WordNet (Miller, 1995) and Freebase (Bollacker et al., 2007; Bollacker et al., 2008) respectively.", "startOffset": 46, "endOffset": 94}, {"referenceID": 1, "context": ", 2010b), WordNet (Miller, 1995) and Freebase (Bollacker et al., 2007; Bollacker et al., 2008) respectively.", "startOffset": 46, "endOffset": 94}, {"referenceID": 3, "context": "(Bordes et al., 2013).", "startOffset": 0, "endOffset": 21}, {"referenceID": 3, "context": ", 2014b), TransE (Bordes et al., 2013) mentioned in Section 2 evaluated on NELL-50K, WN-100K and FB-500K datasets.", "startOffset": 17, "endOffset": 38}, {"referenceID": 17, "context": "(Socher et al., 2013) which focuses on searching a relation-specific threshold \u03c3r to identify whether a triplet \u3008h, r, t\u3009 is plausible.", "startOffset": 0, "endOffset": 21}, {"referenceID": 3, "context": ", 2014b) and TransE (Bordes et al., 2013), the proposed PBE approach still outperforms them with the improvements that NELL-50K: {Accuracy: 7.", "startOffset": 20, "endOffset": 41}], "year": 2015, "abstractText": "This paper contributes a novel embedding model which measures the probability of each candidate belief \u3008h, r, t,m\u3009 in a large-scale knowledge repository via simultaneously learning distributed representations for entities (h and t), relations (r), and even the words in relation mentions (m). It facilitates knowledge completion by means of simple vector operations to discover new beliefs. Given an imperfect belief, we can not only infer the missing entities, predict the unknown relations, but also tell the plausibility of that belief, just by exploiting the learnt embeddings of available evidence. To demonstrate the scalability and the effectiveness of our model, we conduct experiments on several large-scale repositories which contain hundreds of thousands of beliefs from WordNet, Freebase and NELL, and compare the results of a number of tasks, entity inference, relation prediction and triplet classification, with cutting-edge approaches. Extensive experimental results show that the proposed model outperforms other state-of-the-art methods, with significant improvements identified.", "creator": "LaTeX with hyperref package"}}}