{"id": "1505.02973", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2015", "title": "Comparing methods for Twitter Sentiment Analysis", "abstract": "This work extends the set of works which deal with the popular problem of sentiment analysis in Twitter. It investigates the most popular document (\"tweet\") representation methods which feed sentiment evaluation mechanisms. In particular, we study the bag-of-words, n-grams and n-gram graphs approaches and for each of them we evaluate the performance of a lexicon-based and 7 learning-based classification algorithms (namely SVM, Na\\\"ive Bayesian Networks, Logistic Regression, Multilayer Perceptrons, Best-First Trees, Functional Trees and C4.5) as well as their combinations, using a set of 4451 manually annotated tweets. The results demonstrate the superiority of learning-based methods and in particular of n-gram graphs approaches for predicting the sentiment of tweets. They also show that the combinatory approach has impressive effects on n-grams, raising the confidence up to 83.15% on the 5-Grams, using majority vote and a balanced dataset (equal number of positive, negative and neutral tweets for training). In the n-gram graph cases the improvement was small to none, reaching 94.52% on the 4-gram graphs, using Orthodromic distance and a threshold of 0.001.", "histories": [["v1", "Tue, 12 May 2015 12:05:19 GMT  (471kb)", "http://arxiv.org/abs/1505.02973v1", "5 pages, 1 figure, 6th Conference on Knowledge Discovery and Information Retrieval 2014, Rome, Italy"]], "COMMENTS": "5 pages, 1 figure, 6th Conference on Knowledge Discovery and Information Retrieval 2014, Rome, Italy", "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.SI", "authors": ["evangelos psomakelis", "konstantinos tserpes", "dimosthenis anagnostopoulos", "theodora varvarigou"], "accepted": false, "id": "1505.02973"}, "pdf": {"name": "1505.02973.pdf", "metadata": {"source": "CRF", "title": "Comparing methods for Twitter Sentiment Analysis", "authors": ["Evangelos Psomakelis", "Konstantinos Tserpes", "Theodora Varvarigou"], "emails": ["vpsomak@hua.gr", "tserpes@hua.gr", "dimosthe@hua.gr", "dora@telecom.ntua.gr"], "sections": [{"heading": null, "text": "The results demonstrate the superiority of learning-based methods and, in particular, n-gram charts to predict the mood of tweets. They also show that the combinatorial approach has impressive effects on n-grams by increasing confidence to 83.15% of 5-gram tweets by using majority votes and a balanced dataset (the same number of positive, negative and neutral tweets for training)."}, {"heading": "Categories and Subject Descriptors", "text": "H.3.1 Content Analysis and Indexing"}, {"heading": "General Terms", "text": ""}, {"heading": "Keywords", "text": "Sentiment Analysis, Document Polarity Classification, Lexicon & Learning Based, Bag of Words, Ngrams, Ngrams."}, {"heading": "1. INTRODUCTION", "text": "Identifying the mood in the content of online social networks can be considered the \"Holy Grail\" for scientists in the information retrieval, data mining and machine learning fields. On the one hand, there is the challenge of the venture itself, which is often a moving goal: changing application requirements (topics of interest, media, available resources, etc.) and sentiment analysis solutions by nature cannot handle these changes. On the other hand, there is the high demand, with a large number of organizations and individuals who lay their hands on mechanisms that automatically use the volume of user-generated data and help them to evaluate public opinion in relation to topics of interest (products, services, people, concepts, etc.) In this context, Twitter has the most prominent playground for sentism analysis with companies and scientists alike trying to tap the enthusiasm of its users for sharing opinions online. It is no coincidence that numerous works have proposed methods for implementing such mechanisms, such as [14] [20]."}, {"heading": "2. PROBLEM FORMULATION", "text": "The work adopts and broadens the definition of [16] for the sentiment-polarity problem, according to which:... \"in the face of an idiosyncratic text that assumes that the general opinion is a single subject or object, the opinion is classified as falling under one of two opposing sentiment polarities or localizing its position on the continuum between these two polarities.\" The latter leaves room for the definition of three classes instead of the typical two (binary polarity problem). The third class refers to those text texts that do not express positive or negative feelings, i.e. they are neutral. In this context, the problem of sentiment analysis at the document level [4] is addressed. In this problem, documents (as opposed to sentences or characteristics) are contradicted with respect to a particular topic. In the case of Twitter, the document is referred to as a \"tweet\" and it has a very specific form: a text message that automatically identifies the purpose of a tweet consisting of 140 words."}, {"heading": "3. RELATED WORK", "text": "In fact, most of them will be able to play by the rules that they need for their work, and they will be able to play by the rules that they need for their work. In fact, they will be able to play by the rules that they have imposed on themselves."}, {"heading": "4. EXPERIMENTS", "text": "These tweets were manually evaluated by a number of researchers, depending on how they felt about their topic. Thus, each tweet was assigned to a positive, neutral or negative category, which helps us train the machine learning algorithms we use. After this categorization, there were 1,203 positive tweets, 1,313 neutral tweets, and 1,935 negative tweets. This slight tendency toward negativity affected some of the algorithms that cause either increased or decreased accuracy. To increase the effectiveness of categorization at a later stage of the experiments, the tweets had to be pre-processed. At this stage, pre-processing consisted of special characters that do not value the polarization of feelings, such as the \"#\" character of each tweet was converted to lowercase letters and each web address."}, {"heading": "5. CONCLUSIONS", "text": "The results demonstrated the superiority of n-gram charts in recording the mood expressed in a document and specifically in tweets, as well as the improvements that various combinations of NLP methods and machine learning algorithms can make to the confidence rate of some mood analysis techniques. Innovation in this work focuses on carefully assessing the efficiency of various mood analysis mechanisms using manually annotated data sets, as well as demonstrating the ability to combine methods and create new techniques to improve the quality of results."}, {"heading": "6. ACKNOWLEDGMENTS", "text": "This work was supported by the Consensus project (http: / / www.consensus-project.eu) and partly funded by the EU's Seventh Framework Programme ICT-2013.5.4: ICT for Governance and Policy Modeling under contract number 611688."}, {"heading": "7. REFERENCES", "text": "[1] Agarwal, A. et al. 2011. Sentiment Analysis of TwitterData. Proceedings of the Workshop on Languages in Social Media (Stroudsburg, PA, USA, 2011), 30-38. [2] Aisopos, F. et al. 2012. Content vs. context for sentimentanalysis: a comparative analysis over microblogs. 23rd ACM Conference on Hypertext and Social Media, HT '12, Milwaukee, WI, USA, June 25-28, 2012 (2012), 187-196. [3] Baccianella, S. et al. 2010. SentiWordNet 3.0: Anhanced Lexical Resource for Sentiment and Opinion Mining. (May 2010). [4] Bing, L. 2011. Web Data Mining - Exploring Hyperlinks, Contents, and Usage Data. Springer. Cavnar, W.B. and Trenkle, J.M. 1994."}], "references": [{"title": "Sentiment Analysis of Twitter Data", "author": ["A Agarwal"], "venue": "Proceedings of the Workshop on Languages in Social Media (Stroudsburg, PA,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Content vs. context for sentiment analysis: a comparative analysis over microblogs", "author": ["F Aisopos"], "venue": "23rd ACM Conference on Hypertext and Social Media, HT \u201912,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining", "author": ["S Baccianella"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Web Data Mining - Exploring Hyperlinks, Contents, and Usage", "author": ["L. Bing"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "N-gram-based text categorization", "author": ["W.B. Cavnar", "J.M. Trenkle"], "venue": "Ann Arbor MI. 48113,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1994}, {"title": "A Study Using n-gram Features for Text Categorization", "author": ["J. F\u00fcrnkranz"], "venue": "Austrian Institute for Artificial Intelligence", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Summarization system evaluation revisited: N-gram graphs", "author": ["G Giannakopoulos"], "venue": "TSLP. 5,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Twitter sentiment classification using distant supervision", "author": ["A Go"], "venue": "CS224N Project Report,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Large-scale sentiment analysis for news and blogs. ICWSM\u201907", "author": ["N Godbole"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Comparing and Combining Sentiment Analysis Methods", "author": ["P Gon\u00e7alves"], "venue": "Proceedings of the First ACM Conference on Online Social Networks (New York, NY,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Estimating Continuous Distributions in Bayesian Classifiers", "author": ["G.H. John", "P. Langley"], "venue": "Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (San Francisco, CA,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Sentiment analysis using support vector machines with diverse information sources", "author": ["T. Mullen", "N. Collier"], "venue": "In Proceedings of Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Twitter as a Corpus for Sentiment Analysis and Opinion Mining", "author": ["A. Pak", "P. Paroubek"], "venue": "Proceedings of the International Conference on Language Resources and Evaluation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Thumbs up? Sentiment Classification Using Machine Learning Techniques", "author": ["B Pang"], "venue": "emnlp2002 (Philadelphia, Pennsylvania,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Opinion Mining and Sentiment Analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and Trends\u00ae in Information Retrieval", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Improved Use of Continuous Attributes in C4.5", "author": ["J.R. Quinlan"], "venue": "J. Artif. Int. Res", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Comparison between SVM and Logistic Regression: Which One is Better to Discriminate", "author": ["Salazar", "D.A"], "venue": "Revista Colombiana de Estadi\u0301stica. 35,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Best-first decision tree learning. University of Waikato", "author": ["H. Shi"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Lexicon-Based Methods for Sentiment Analysis", "author": ["M Taboada"], "venue": "Computational Linguistics. 37,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews", "author": ["P. Turney"], "venue": "(Philadelphia, Pennsylvania,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2002}, {"title": "Recognizing Contextual Polarity in Phrase-level Sentiment Analysis", "author": ["T Wilson"], "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (Stroudsburg, PA,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}], "referenceMentions": [{"referenceID": 12, "context": "[14], [8], [1], [20].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[14], [8], [1], [20].", "startOffset": 6, "endOffset": 9}, {"referenceID": 0, "context": "[14], [8], [1], [20].", "startOffset": 11, "endOffset": 14}, {"referenceID": 18, "context": "[14], [8], [1], [20].", "startOffset": 16, "endOffset": 20}, {"referenceID": 14, "context": "work adopts and extends the definition of [16] for the sentiment polarity problem, according to which: \".", "startOffset": 42, "endOffset": 46}, {"referenceID": 3, "context": "In this context the problem of document-level sentiment analysis [4] is addressed.", "startOffset": 65, "endOffset": 68}, {"referenceID": 1, "context": "Formally and according to [2] it is:", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "The Bag of Words [9] may be classified as the simplest method.", "startOffset": 17, "endOffset": 20}, {"referenceID": 20, "context": "by a dictionary that correlates each word with a numerical value, showing its sentiment polarity [22].", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "The lack of contextual information though makes this correlation inaccurate in the case of \u201cthwarted expectations\u201d as explained by both [15] and [21].", "startOffset": 136, "endOffset": 140}, {"referenceID": 19, "context": "The lack of contextual information though makes this correlation inaccurate in the case of \u201cthwarted expectations\u201d as explained by both [15] and [21].", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "The N-Grams are pretty similar to the bag of words with one big difference; The text is split in pseudowords of equal length [16].", "startOffset": 125, "endOffset": 129}, {"referenceID": 4, "context": "Commonly, 2-Grams, 3-Grams and 4Grams are used and other variations are largely rare [5, 6].", "startOffset": 85, "endOffset": 91}, {"referenceID": 5, "context": "Commonly, 2-Grams, 3-Grams and 4Grams are used and other variations are largely rare [5, 6].", "startOffset": 85, "endOffset": 91}, {"referenceID": 1, "context": "Using a dictionary in this case is not useful, because only a small -and in many cases random- set of pseudowords correspond to real words [2].", "startOffset": 139, "endOffset": 142}, {"referenceID": 6, "context": "The graph denotes the position of each N-Gram in the sentence and its relation with its neighbors [7].", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "The merged graph contains all the N-Grams of the individual training graphs, all their edges and an average weight on each edge [2].", "startOffset": 128, "endOffset": 131}, {"referenceID": 15, "context": "5, which is based on the ID3 algorithm, is using the Information Gain theory, which in turn is based on the Entropy theory, in order to perform the less possible splits, creating the smallest possible tree [17].", "startOffset": 206, "endOffset": 210}, {"referenceID": 10, "context": "On the other hand, Na\u00efve Bayesian Networks use a probabilistic model in order to maximize their accuracy with no consideration to the size of the produced tree [12].", "startOffset": 160, "endOffset": 164}, {"referenceID": 17, "context": "Best-First Trees decides the \u201cbest\u201d point to split the tree by a more arbitrary function, specified by the user in order to minimize the impurity between each new split [19].", "startOffset": 169, "endOffset": 173}, {"referenceID": 16, "context": "The Logistic Regression is using various logistic functions in order to calculate a function with a graphical representation that has the minimum distance from each of the training data points in the multidimensional space [18].", "startOffset": 223, "endOffset": 227}, {"referenceID": 11, "context": "The Support Vector Machines use other mathematical functions, such as the minimum square function, in order to create another function with a similar graphical representation [13].", "startOffset": 175, "endOffset": 179}, {"referenceID": 9, "context": "From a high level perspective, a similar work has been conducted and reported in [10].", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "0 [3] was employed.", "startOffset": 2, "endOffset": 5}, {"referenceID": 1, "context": "Each new graph that is tested is compared with each one of these three graphs, using three different similarity functions [2].", "startOffset": 122, "endOffset": 125}], "year": 2014, "abstractText": "This work extends the set of works which deal with the popular problem of sentiment analysis in Twitter. It investigates the most popular document (\"tweet\") representation methods which feed sentiment evaluation mechanisms. In particular, we study the bagof-words, n-grams and n-gram graphs approaches and for each of them we evaluate the performance of a lexicon-based and 7 learning-based classification algorithms (namely SVM, Na\u00efve Bayesian Networks, Logistic Regression, Multilayer Perceptrons, Best-First Trees, Functional Trees and C4.5) as well as their combinations, using a set of 4451 manually annotated tweets. The results demonstrate the superiority of learning-based methods and in particular of n-gram graphs approaches for predicting the sentiment of tweets. They also show that the combinatory approach has impressive effects on n-grams, raising the confidence up to 83.15% on the 5-Grams, using majority vote and a balanced dataset (equal number of positive, negative and neutral tweets for training). In the n-gram graph cases the improvement was small to none, reaching 94.52% on the 4-gram graphs, using Orthodromic distance and a threshold of 0.001.", "creator": "Microsoft\u00ae Office Word 2007"}}}