{"id": "1505.03540", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2015", "title": "Brain Tumor Segmentation with Deep Neural Networks", "abstract": "In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.", "histories": [["v1", "Wed, 13 May 2015 20:06:21 GMT  (949kb,D)", "http://arxiv.org/abs/1505.03540v1", null], ["v2", "Mon, 5 Oct 2015 17:37:02 GMT  (1683kb,D)", "http://arxiv.org/abs/1505.03540v2", null], ["v3", "Fri, 20 May 2016 06:30:23 GMT  (2872kb,D)", "http://arxiv.org/abs/1505.03540v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["mohammad havaei", "axel davy", "david warde-farley", "antoine biard", "aaron courville", "yoshua bengio", "chris pal", "pierre-marc jodoin", "hugo larochelle"], "accepted": false, "id": "1505.03540"}, "pdf": {"name": "1505.03540.pdf", "metadata": {"source": "CRF", "title": "Brain Tumor Segmentation with Deep Neural Networks", "authors": ["Mohammad Havaei", "Axel Davy", "David Warde-Farley", "Antoine Biard", "Aaron Courville", "Yoshua Bengio", "Chris Pal", "Pierre-Marc Jodoin", "Hugo Larochelle"], "emails": [], "sections": [{"heading": null, "text": "We present a novel CNN architecture that differs from that traditionally used in computer vision. Our CNN takes advantage of both local features and more global contextual features at the same time. Unlike most traditional applications of CNN, our networks use a final layer that represents a revolutionary implementation of a fully interconnected layer that allows for 40-fold acceleration. We also describe a two-phase training process that allows us to solve difficulties related to the imbalance of tumor markings. Finally, we examine a cascade architecture in which Xiv: 150 5.03 540v 1 [csthe output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test dataset have our architecture is better over the now published state-of-the-art while being over 30 times faster."}, {"heading": "1 Introduction", "text": "This year, we have reached a point where it can only take one year to reach an agreement."}, {"heading": "2 Related work", "text": "As noted by Menze et al. [32], a typical model of brain tumor segmentation 37 can be found given that the segmentation of brain tumors has grown exponentially in recent decades. [32] This observation not only underscores the need for automatic image segmentation tools, but also shows that research in this area still involves advanced work. Methods for segmentation of brain tumors (especially those related to MRI) can be roughly divided into two categories: those based on generative models and those based on discriminatory models [32, 6, 2]. Generative models rely heavily on domain-specific prior knowledge of the occurrence of healthy and tumor tissue. The appearance of the brain is a challenge for characterization, and existing generative models generally identify a tumor as a form or signal that differs from a normal (or average) brain template based on 3D brain models [9]."}, {"heading": "3 Our Convolutional Neural Network Approach", "text": "In fact, it is the case that we are in a position to play by the rules that have been laid down in recent years."}, {"heading": "3.1 The Architectures", "text": "Our previous description of CNNs points to a simple architecture that corresponds to a single stack of multiple curved layers. This configuration is the most commonly implemented architecture in the computer vision literature, but one could imagine other architectures that would be more suitable for the task at hand. In this paper, we are examining a variety of architectures by using concatenation of feature cards from different layers as a further operation in composing CNNs. This operation allows us to construct architectures with multiple computational pathways that can each serve a different purpose. We will now describe the two types of architectures that we are examining in this paper."}, {"heading": "3.1.1 Two-pathway architecture", "text": "This architecture consists of two flows: one path with smaller 7 x 7 receptive fields and another one with larger 13 x 13 receptive fields. We call these flows the local path or global path. The motivation for this architectural decision is that we want the prediction of the name of a pixel to be influenced by two aspects: the visual details of the region around this pixel and its larger \"context,\" i.e., where the patch is located in the brain. The complete architecture and its details are presented in Figure 2. We call this architecture TwoPathCNN. To allow the summary of the top hidden layers of both paths, we use two layers for the local path with 3 x 3 cores for the second layer. While this implies that the effective receptive field of characteristics in the top layer of each path is the same, the parameterization of the global path is more direct and flexible models in the same area."}, {"heading": "3.1.2 Cascaded architectures", "text": "One disadvantage of the CNNs described so far is that they predict each segmentation label separately from each other \u2022 This is effectively modelling the direct dependencies between spatially narrow labels, in contrast to a large number of segmentation methods in the literature, which often suggest a common model of segmentation labels. One approach is to define a conditional random field (CRF) over the labels and perform a center field display that generates complete segmentation. In this case, the final label at a particular position is effectively influenced by the beliefs about what the label is close to that position. On the other hand, the conclusion in such common segmentation methods is typically more expensive than simple segmentation. This is an important aspect to consider when using automatic segmentation of brain tumors."}, {"heading": "3.2 Training", "text": "In practice, we implement this approach by developing a model for distributing smaller education protocols with appropriate dynamics that improves the segmentation strategy, is a natural training criterion to maximize the likelihood of all labels in our training set while minimizing the negative log probability within each brain. (To do this, we follow a stochastic gradient descent approach by repeatedly selecting Yij labels from a random subset of patches within each brain, calculating the average negative log probability for this mini batch of patches, and executing a gradient descent level at the CNNs level. i.e. performing updates based on only a small subset of patches allows us to avoid processing an entire brain for each update, while providing reliable updates for learning."}, {"heading": "4 Implementation details", "text": "Our implementation is based on the Pylearn2 library [18]. Pylearn2 is an open source machine learning library specializing in deep learning algorithms, and it also supports the use of GPUs that can significantly speed up the execution of deep learning algorithms. Since CNN's are able to learn useful features from scratch, we have applied minimal preprocessing, using the same preprocessing as Tustison et al., the winner of the 2013 BRATS challenge [32]. Pre-processing follows three steps: First, removing the highest and lowest intensities; then, applying an N4ITK presetting correction [3] to T1 and T1C modalities; the data is then subtracted within each input channel by default value and divided by the standard deviation of the channel. As with post-processing, a simple method based on the skulls may appear, the skulls based on the associated component could be implemented."}, {"heading": "5 Experiments and Results", "text": "The results of the study show that the individual countries are not only a country, but also a whole series of countries in which people are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance"}, {"heading": "5.2 Cascaded architectures", "text": "We will now discuss our experiments with the three cascaded architectures, namely InputCascadeCNN, LocalCascadeCNN and MFCascadeCNN *. Table 2 provides the quantitative results for each architecture. Figure 5 also provides visual examples of the segmentation generated by each architecture.However, we find that the MFCascadeCNN model produces smoother boundaries between classes. We hypothesize that since the neurons in the Softmax output layer are directly linked to the previous results within each receptive field, these parameters are more likely to learn that the center pixel label should have a similar designation for its environment.As for the LocalCascadeCNN architecture, while it has resulted in fewer false positives in the full tumor category, it does not improve performance in other categories (i.e. tumor nucleus and extended tumor).Overall, the best performance is achieved by the InputCascadeCNN * model. It improves the dip measurement in all tumor regions."}, {"heading": "6 Conclusion", "text": "The results of the BRATS 2013 online assessment system confirm that our best model has enabled us to improve both the accuracy and speed of the state-of-the-art method presented in MICCAI 2013. High performance is achieved through a novel two-way architecture (which can model both local details and the global context), as well as by modelling local label dependencies by stacking two CNN. Training is based on a two-phase process that allows us to train CNNs efficiently when the distribution of labels is unbalanced. Thanks to the voluminous nature of the models and the efficient GPU implementation, the resulting segmentation system is very fast. The time needed to segment an entire brain with one of these CNN architectures varies between 25 seconds and 3 minutes, making them practical segmentation methods."}], "references": [{"title": "Road scene segmentation from a single image", "author": ["Jose M. Alvarez", "Theo Gevers", "Yann LeCun", "Antonio M. Lopez"], "venue": "In Proceedings of the 12th European Conference on Computer Vision - Volume Part VII,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Glioma dynamics and computational models: A review of segmentation, registration, and in silico growth algorithms and their clinical applications", "author": ["E.D. Angelini", "E.O. Clatz", "E. Konukoglu", "L. Capelle", "H. Duffau"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Advanced normalization tools (ants)", "author": ["Brian B Avants", "Nick Tustison", "Gang Song"], "venue": "Insight J,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization", "author": ["S. Bauer", "L-P Nolte", "M. Reyes"], "venue": "InMICCAI, volume 6893, pages 354\u2013361,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "segmentation of brain tumor images based on integrated hierarchical classification and regularization", "author": ["S. Bauer", "R. Wiest", "M. Reyes"], "venue": "proc of BRATS- MICCAI,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey of mri-based medical image analysis for brain tumor studies", "author": ["S. Bauer", "R. Wiest", "L.P. Nolte", "M. Reyes"], "venue": "Physics in medicine and biology, 58 (13):97\u2013129,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Practical recommendations for gradient-based training of deep architectures", "author": ["Yoshua Bengio"], "venue": "In Neural Networks: Tricks of the Trade,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Representation learning: A review and new perspectives", "author": ["Yoshua Bengio", "Aaron Courville", "Pascal Vincent"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Automatic tumor segmentation using knowledge-based clustering", "author": ["M. Clark", "L. Hall", "D. Goldgof", "R.P. Velthuizen", "F. Murtagh", "M.L. Silbiger"], "venue": "IEEE Trans. Med. Imaging, 17(2):187\u2013201,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "3d variational brain tumor segmentation using a high dimensional feature set", "author": ["D. Cobzas", "N. Birkbeck", "M. Schmidt", "M. J\u00e4gersand", "A. Murtha"], "venue": "ICCV, pages 1\u20138,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Brain tumor segmentation with deep neural networks", "author": ["A. Davy", "M. Havaei", "D. Warde-Farley", "A. Biard", "L. Tran", "P-M. Jodoin", "A. Courville", "H. Larochelle", "C Pal", "Y. Bengio"], "venue": "proc of BRATS-MICCAI,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Fully automatic brain tumor segmentation from multiple mr sequences using hidden markov fields and variational em", "author": ["S. Doyle", "F. Vasseur", "M. Dojat", "F. Forbes"], "venue": "proc of BRATS-MICCAI,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning hierarchical features for scene labeling", "author": ["Clement Farabet", "Camille Couprie", "Laurent Najman", "Yann LeCun"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1915}, {"title": "Multimodal Brain Tumor Segmentation (BRATS", "author": ["Keyvan Farahani", "Bjoern Menze", "Mauricio Reyes"], "venue": "URL http://martinos.org/qtim/ miccai2013/", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ICML,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Pylearn2: a machine learning research", "author": ["Ian J. Goodfellow", "David Warde-Farley", "Pascal Lamblin", "Vincent Dumoulin", "Mehdi Mirza", "Razvan Pascanu", "James Bergstra", "Fr\u00e9d\u00e9ric Bastien", "Yoshua Bengio"], "venue": "library. arXiv preprint arXiv:1308.4214,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Extremely randomized trees based brain tumor segmentation", "author": ["M. Gotz", "C. Weber", "J. Blocher", "B. Stieltjes", "H-P Meinzer", "K. Maier-Hein"], "venue": "in proc of BRATS Challenge - MICCAI,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Tumor-cut: Segmentation of brain tumors on contrast enhanced mr images for radiosurgery applications", "author": ["A. Hamamci", "N. Kucuk", "K. Karaman", "K. Engin", "G. Unal"], "venue": "IEEE trans. Medical Imaging, 31(3):790\u2013804,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Simultaneous detection and segmentation", "author": ["Bharath Hariharan", "Pablo Arbel\u00e1ez", "Ross Girshick", "Jitendra Malik"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Efficient interactive brain tumor segmentation as within-brain knn classification", "author": ["M. Havaei", "P-M Jodoin", "H. Larochelle"], "venue": "International Conference on Pattern Recognition (ICPR),", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep and wide multiscale recursive networks for robust image labeling", "author": ["G.B. Huang", "V. Jain"], "venue": "arXiv preprint arXiv:1310.0354,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "What is the best multi-stage architecture for object recognition", "author": ["Kevin Jarrett", "Koray Kavukcuoglu", "M Ranzato", "Yann LeCun"], "venue": "In Computer Vision,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "3d brain tumor segmentation in mri using fuzzy classification, symmetry analysis and spatially constrained deformable models", "author": ["H. Khotanlou", "O. Colliot", "J. Atif", "I. Bloch"], "venue": "Fuzzy Sets Syst., 160(10):1457\u20131473,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "ilastik for multi-modal brain tumor segmentation", "author": ["J. Kleesiek", "A. Biller", "G. Urban", "U. Kothe", "M. Bendszus", "F.A. Hamprecht"], "venue": "proc of BRATS-MICCAI,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "NIPS.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Multimodal brain tumor image segmentation using glistr", "author": ["D. Kwon", "H. Akbari", "X. Da", "B. Gaonkar", "C. Davatzikos"], "venue": "in proc of BRATS Challenge - MICCAI,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Gradientbased learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1998}, {"title": "Segmenting brain tumor with conditional random fields and support vector machines", "author": ["C-\u0307H. Lee", "M. Schmidt", "A. Murtha", "A. Bistritz", "J. S", "R. Greiner"], "venue": "In in Proc of Workshop on Computer Vision for Biomedical Image Applications,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2005}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Jonathan Long", "Evan Shelhamer", "Trevor Darrell"], "venue": "CVPR (to appear),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "The multimodal brain tumor image segmentation benchmark (brats)", "author": ["B. Menze", "M. Reyes", "K.V. Leemput"], "venue": "IEEE Trans. on Medical Imaging (accepted), September", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Ants and \u00e1rboles", "author": ["C. Durst N.Tustison", "M. Wintermark", "B. Avants"], "venue": "In in proc of BRATS Challenge - MICCAI,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2013}, {"title": "Joint tumor segmentation and dense deformable registration of brain mr images", "author": ["S. Parisot", "H. Duffau", "S. Chemouny", "N. Paragios"], "venue": "MICCAI, volume 7511, pages 651\u2013658,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Recurrent convolutional neural networks for scene labeling", "author": ["Pedro Pinheiro", "Ronan Collobert"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "3d variational brain tumor segmentation using dirichlet priors on a clustered feature set", "author": ["K. Popuri", "D. Cobzas", "A. Murtha", "M. J\u00e4gersand"], "venue": "Int. J. Computer Assisted Radiology and Surgery, 7(4):493\u2013506,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "A brain tumor segmentation framework based on outlier detection", "author": ["M. Prastawa", "E. Bullit", "S. Ho", "G. Gerig"], "venue": "Medical Image Anaylsis, 8(3):275\u2013283,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2004}, {"title": "Robust estimation for brain tumor segmentation. In Medical Image Computing and Computer-Assisted Intervention-MICCAI", "author": ["Marcel Prastawa", "Elizabeth Bullitt", "Sean Ho", "Guido Gerig"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2003}, {"title": "Learning representations by back-propagating errors", "author": ["David E Rumelhart", "Geoffrey E Hinton", "Ronald J Williams"], "venue": "Cognitive modeling,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1988}, {"title": "Segmenting brain tumors using alignment-based features", "author": ["M. Schmidt", "I. Levner", "R. Greiner", "A. Murtha", "A. Bistritz"], "venue": "Int. Conf on Machine Learning and Applications, pages 6\u2013pp,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2005}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research, 15:1929\u20131958,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "Hierarchical probabilistic gabor and mrf segmentation of brain tumours in mri volumes", "author": ["N. Subbanna", "D. Precup", "L. Collins", "T. Arbel"], "venue": "in proc of MICCAI, volume 8149, pages 751\u2013758,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Iterative multilevel mrf leveraging context and voxel information for brain tumour segmentation in mri", "author": ["N. Subbanna", "D. Precup", "T. Arbel"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "Multi-modal brain tumor segmentation using deep convolutional neural networks", "author": ["G. Urban", "M. Bendszus", "F. Hamprecht", "J. Kleesiek"], "venue": "proc of BRATS-MICCAI,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "A generalized mean field algorithm for variational inference in exponential families", "author": ["Eric P Xing", "Michael I Jordan", "Stuart Russell"], "venue": "In Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2002}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D Zeiler", "Rob Fergus"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2014}, {"title": "Segmentation of brain tumor tissues with convolutional neural networks", "author": ["D. Zikic", "Y. Ioannou", "M. Brown", "A. Criminisi"], "venue": "proc of BRATS-MICCAI,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 30, "context": "Such methods have proven somewhat successful in previous brain tumor segmentation challenges [32].", "startOffset": 93, "endOffset": 97}, {"referenceID": 7, "context": "Deep neural networks have been shown to excel at learning such feature hierarchies [8].", "startOffset": 83, "endOffset": 86}, {"referenceID": 27, "context": "Although CNNs first appeared over two decades ago [29], they have recently become a mainstay of the computer vision community due to their record-shattering performance in the ImageNet LargeScale Visual Recognition Challenge [27].", "startOffset": 50, "endOffset": 54}, {"referenceID": 25, "context": "Although CNNs first appeared over two decades ago [29], they have recently become a mainstay of the computer vision community due to their record-shattering performance in the ImageNet LargeScale Visual Recognition Challenge [27].", "startOffset": 225, "endOffset": 229}, {"referenceID": 0, "context": "While CNNs have also been successfully applied to segmentation problems [1, 31, 21], most of the previous work has focused on non-medical tasks and many involve architectures that are not well suited to medical imagery or brain tumor segmentation in particular.", "startOffset": 72, "endOffset": 83}, {"referenceID": 29, "context": "While CNNs have also been successfully applied to segmentation problems [1, 31, 21], most of the previous work has focused on non-medical tasks and many involve architectures that are not well suited to medical imagery or brain tumor segmentation in particular.", "startOffset": 72, "endOffset": 83}, {"referenceID": 19, "context": "While CNNs have also been successfully applied to segmentation problems [1, 31, 21], most of the previous work has focused on non-medical tasks and many involve architectures that are not well suited to medical imagery or brain tumor segmentation in particular.", "startOffset": 72, "endOffset": 83}, {"referenceID": 15, "context": "Our architectures exploit the most recent advances in CNN design and training techniques, such as Maxout [17] hidden units and Dropout [41] regularization.", "startOffset": 105, "endOffset": 109}, {"referenceID": 39, "context": "Our architectures exploit the most recent advances in CNN design and training techniques, such as Maxout [17] hidden units and Dropout [41] regularization.", "startOffset": 135, "endOffset": 139}, {"referenceID": 30, "context": "[32], the number of publications devoted to automated brain tumor segmentation has grown exponentially in the last several decades.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "Brain tumor segmentation methods (especially those devoted to MRI) can be roughly divided in two categories: those based on generative models and those based on discriminative models [32, 6, 2].", "startOffset": 183, "endOffset": 193}, {"referenceID": 5, "context": "Brain tumor segmentation methods (especially those devoted to MRI) can be roughly divided in two categories: those based on generative models and those based on discriminative models [32, 6, 2].", "startOffset": 183, "endOffset": 193}, {"referenceID": 1, "context": "Brain tumor segmentation methods (especially those devoted to MRI) can be roughly divided in two categories: those based on generative models and those based on discriminative models [32, 6, 2].", "startOffset": 183, "endOffset": 193}, {"referenceID": 8, "context": "Tissue appearance is challenging to characterize, and existing generative models usually identify a tumor as being a shape or a signal which deviates from a normal (or average) brain [9].", "startOffset": 183, "endOffset": 186}, {"referenceID": 11, "context": "Typically, these methods rely on anatomical models obtained after aligning the 3D MR image on an atlas or a template computed from several healthy brains [12].", "startOffset": 154, "endOffset": 158}, {"referenceID": 35, "context": "[37].", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[38] also register brain images onto an atlas in order to get a probability map for abnormalities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Many other active-contour methods along the same lines have been proposed [25, 10, 36], all of which depend on left-right brain symmetry features and/or alignment-based features.", "startOffset": 74, "endOffset": 86}, {"referenceID": 9, "context": "Many other active-contour methods along the same lines have been proposed [25, 10, 36], all of which depend on left-right brain symmetry features and/or alignment-based features.", "startOffset": 74, "endOffset": 86}, {"referenceID": 34, "context": "Many other active-contour methods along the same lines have been proposed [25, 10, 36], all of which depend on left-right brain symmetry features and/or alignment-based features.", "startOffset": 74, "endOffset": 86}, {"referenceID": 26, "context": "some methods perform registration and tumor segmentation at the same time [28, 34].", "startOffset": 74, "endOffset": 82}, {"referenceID": 32, "context": "some methods perform registration and tumor segmentation at the same time [28, 34].", "startOffset": 74, "endOffset": 82}, {"referenceID": 20, "context": "These features may be raw input pixels values [22, 20], texture features such as Gabor filterbanks [42, 43], or alignment-based features such as inter-image gradient, region shape difference, and symmetry analysis [33].", "startOffset": 46, "endOffset": 54}, {"referenceID": 18, "context": "These features may be raw input pixels values [22, 20], texture features such as Gabor filterbanks [42, 43], or alignment-based features such as inter-image gradient, region shape difference, and symmetry analysis [33].", "startOffset": 46, "endOffset": 54}, {"referenceID": 40, "context": "These features may be raw input pixels values [22, 20], texture features such as Gabor filterbanks [42, 43], or alignment-based features such as inter-image gradient, region shape difference, and symmetry analysis [33].", "startOffset": 99, "endOffset": 107}, {"referenceID": 41, "context": "These features may be raw input pixels values [22, 20], texture features such as Gabor filterbanks [42, 43], or alignment-based features such as inter-image gradient, region shape difference, and symmetry analysis [33].", "startOffset": 99, "endOffset": 107}, {"referenceID": 31, "context": "These features may be raw input pixels values [22, 20], texture features such as Gabor filterbanks [42, 43], or alignment-based features such as inter-image gradient, region shape difference, and symmetry analysis [33].", "startOffset": 214, "endOffset": 218}, {"referenceID": 3, "context": "Classical discriminative learning techniques such as SVMs [4, 40, 30] and decision forests [5] have also been used.", "startOffset": 58, "endOffset": 69}, {"referenceID": 38, "context": "Classical discriminative learning techniques such as SVMs [4, 40, 30] and decision forests [5] have also been used.", "startOffset": 58, "endOffset": 69}, {"referenceID": 28, "context": "Classical discriminative learning techniques such as SVMs [4, 40, 30] and decision forests [5] have also been used.", "startOffset": 58, "endOffset": 69}, {"referenceID": 4, "context": "Classical discriminative learning techniques such as SVMs [4, 40, 30] and decision forests [5] have also been used.", "startOffset": 91, "endOffset": 94}, {"referenceID": 30, "context": "Results from the 2012, 2013 and 2014 editions of the MICCAI-BRATS Challenge suggest that methods relying on random forests are among the most accurate [32, 19, 26].", "startOffset": 151, "endOffset": 163}, {"referenceID": 17, "context": "Results from the 2012, 2013 and 2014 editions of the MICCAI-BRATS Challenge suggest that methods relying on random forests are among the most accurate [32, 19, 26].", "startOffset": 151, "endOffset": 163}, {"referenceID": 24, "context": "Results from the 2012, 2013 and 2014 editions of the MICCAI-BRATS Challenge suggest that methods relying on random forests are among the most accurate [32, 19, 26].", "startOffset": 151, "endOffset": 163}, {"referenceID": 10, "context": "[11], Zikic et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[47], Urban et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[44]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "All three methods divide the 3D MR images into 2D [11, 47] or 3D patches [44] and train a CNN to predict its center pixel class.", "startOffset": 50, "endOffset": 58}, {"referenceID": 45, "context": "All three methods divide the 3D MR images into 2D [11, 47] or 3D patches [44] and train a CNN to predict its center pixel class.", "startOffset": 50, "endOffset": 58}, {"referenceID": 42, "context": "All three methods divide the 3D MR images into 2D [11, 47] or 3D patches [44] and train a CNN to predict its center pixel class.", "startOffset": 73, "endOffset": 77}, {"referenceID": 42, "context": "[44] as well as Zikic et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[47] implemented a fairly common CNN, consisting of a series of convolutional layers, a non-linear activation function between each layer and a softmax output layer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] using a two-pathway architecture, which we use here as a building block.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "The work in Pinheiro and Collobert [35] uses a basic CNN to make predictions for each pixel and further improves the predictions by using them as extra information in the input of a second CNN model.", "startOffset": 35, "endOffset": 39}, {"referenceID": 12, "context": "Other work [13] involves several distinct CNNs processing the image at different resolutions.", "startOffset": 11, "endOffset": 15}, {"referenceID": 29, "context": "Like our work, other recent work has exploited convolution operations in the final layer of a network to extend traditional CNN architectures for semantic scene segmentation [31].", "startOffset": 174, "endOffset": 178}, {"referenceID": 21, "context": "However, some notable recent work by Huang and Jain [23] has used CNNs to predict the boundaries of neural tissue in electron microscopy images.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Like most CNN-based segmentation models [35, 13], our method predicts the class of a pixel by processing the M \u00d7M patch centered on that pixel.", "startOffset": 40, "endOffset": 48}, {"referenceID": 12, "context": "Like most CNN-based segmentation models [35, 13], our method predicts the class of a pixel by processing the M \u00d7M patch centered on that pixel.", "startOffset": 40, "endOffset": 48}, {"referenceID": 37, "context": "These parameters are adapted via stochastic gradient descent on a surrogate loss function related to the misclassification error, with gradients computed efficiently via the backpropagation algorithm [39].", "startOffset": 200, "endOffset": 204}, {"referenceID": 22, "context": "There are multiple choices for this non-linearity, such as the sigmoid, hyperbolic tangent and rectified linear functions [24], [16].", "startOffset": 122, "endOffset": 126}, {"referenceID": 14, "context": "There are multiple choices for this non-linearity, such as the sigmoid, hyperbolic tangent and rectified linear functions [24], [16].", "startOffset": 128, "endOffset": 132}, {"referenceID": 15, "context": "[17] proposed a Maxout non-linearity, which has been shown to be particularly effective at modeling useful features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "This subsampling procedure has been found beneficial in other applications [27].", "startOffset": 75, "endOffset": 79}, {"referenceID": 43, "context": "This architecture is interesting, as it is similar to the computations made by one pass of mean-field inference [45] in a CRF whose pairwise potential functions are the weights in the output kernels.", "startOffset": 112, "endOffset": 116}, {"referenceID": 25, "context": "To further improve optimization, we implemented a so-called momentum strategy which has been shown successful in the past [27].", "startOffset": 122, "endOffset": 126}, {"referenceID": 39, "context": "Moreover, we used Dropout [41], a recent regularization method that works by stochastically adding noise in the computation of the hidden layers of the CNN.", "startOffset": 26, "endOffset": 30}, {"referenceID": 39, "context": "[41].", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Our implementation is based on the Pylearn2 library [18].", "startOffset": 52, "endOffset": 56}, {"referenceID": 30, "context": ", the winner of the 2013 BRATS challenge [32].", "startOffset": 41, "endOffset": 45}, {"referenceID": 2, "context": "Then, we apply an N4ITK bias correction [3] to T1 and T1C modalities.", "startOffset": 40, "endOffset": 43}, {"referenceID": 6, "context": "Hyper-parameters were tuned using grid search and cross-validation on a validation set (see Bengio [7]).", "startOffset": 99, "endOffset": 102}, {"referenceID": 25, "context": "[27], we applied data augmentation by flipping the input images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "Unlike what was reported by Zeiler and Fergus [46], it did not improve the overall accuracy of our model.", "startOffset": 46, "endOffset": 50}, {"referenceID": 13, "context": "Quantitative evaluation of the models performance on the test set is achieved by uploading the segmentation results to the online BRATS evaluation system [14].", "startOffset": 154, "endOffset": 158}, {"referenceID": 30, "context": "[32], tumor regions are defined as:", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "This includes methods from the 2013 BRATS challenge published in [32] as well as anonymized unpublished methods for which no reference is available.", "startOffset": 65, "endOffset": 69}, {"referenceID": 30, "context": "Table 3 shows how our implemented architectures compare with currently published state-of-the-art methods as mentioned in [32]4.", "startOffset": 122, "endOffset": 126}, {"referenceID": 30, "context": "method takes 100 minutes to compute predictions per brain as reported in [32], while the InputCascadeCNN* takes 3 minutes, thanks to the fully convolutional architecture and the GPU implementation, which is over 30 times faster than the winner of the challenge.", "startOffset": 73, "endOffset": 77}, {"referenceID": 41, "context": "[43] published competitive results on the BRATS 2013 dataset, reporting dice measures of 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "However, as mentioned in [43], their method takes 70 minutes to process a subject, which is about 23 times slower than our method.", "startOffset": 25, "endOffset": 29}, {"referenceID": 42, "context": "[44] used an average of two 3D convolutional networks with dice measures of 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "As for [47], they do not report results on BRATS 2013 test dataset.", "startOffset": 7, "endOffset": 11}], "year": 2015, "abstractText": "In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we\u2019ve found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which 1 ar X iv :1 50 5. 03 54 0v 1 [ cs .C V ] 1 3 M ay 2 01 5 the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test dataset reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.", "creator": "LaTeX with hyperref package"}}}