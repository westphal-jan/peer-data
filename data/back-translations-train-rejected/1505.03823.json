{"id": "1505.03823", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2015", "title": "Distant Supervision for Entity Linking", "abstract": "Entity linking is an indispensable operation of populating knowledge repositories for information extraction. It studies on aligning a textual entity mention to its corresponding disambiguated entry in a knowledge repository. In this paper, we propose a new paradigm named distantly supervised entity linking (DSEL), in the sense that the disambiguated entities that belong to a huge knowledge repository (Freebase) are automatically aligned to the corresponding descriptive webpages (Wiki pages). In this way, a large scale of weakly labeled data can be generated without manual annotation and fed to a classifier for linking more newly discovered entities. Compared with traditional paradigms based on solo knowledge base, DSEL benefits more via jointly leveraging the respective advantages of Freebase and Wikipedia. Specifically, the proposed paradigm facilitates bridging the disambiguated labels (Freebase) of entities and their textual descriptions (Wikipedia) for Web-scale entities. Experiments conducted on a dataset of 140,000 items and 60,000 features achieve a baseline F1-measure of 0.517. Furthermore, we analyze the feature performance and improve the F1-measure to 0.545.", "histories": [["v1", "Thu, 14 May 2015 18:15:49 GMT  (478kb,D)", "https://arxiv.org/abs/1505.03823v1", null], ["v2", "Tue, 19 May 2015 14:45:19 GMT  (499kb,D)", "http://arxiv.org/abs/1505.03823v2", null], ["v3", "Wed, 5 Aug 2015 01:25:26 GMT  (478kb,D)", "http://arxiv.org/abs/1505.03823v3", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["miao fan", "qiang zhou", "thomas fang zheng"], "accepted": false, "id": "1505.03823"}, "pdf": {"name": "1505.03823.pdf", "metadata": {"source": "CRF", "title": "Distant Supervision for Entity Linking", "authors": ["Miao Fan", "Qiang Zhou", "Thomas Fang Zheng"], "emails": ["fanmiao.cslt.thu@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to survive by going in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves, most of them are able to go in search of themselves."}, {"heading": "2 Paradigm", "text": "Manual annotations cost a lot and can only cover a certain category, such as personal names (Christen, 2006), so we look forward to exploring a paradigm that could automatically generate large amounts of open categorical training records without manual annotation.Based on the data set, we aim to build a handy classifier and generalize it to include more explicit entity mentions in free texts.Freebase contains 43 million unique entities divided into 76 categorities.Each entity is assigned by a unique machine identifier (MID).These MIDs are the natural labels for the newly identified entity mentions, to which links in free text link. However, 6Auto-labeling via crowd sourcing can of course cause disruption, so we consider the data sets to be labeled weak."}, {"heading": "3 Feature", "text": "For each unit in Freebase, we find its topical equivalent wiki page and extract the contextual features of its mention at the sentence level. Generally, we simultaneously select K (K = 1, 2, 3) open-class words (Van Petten and Kutas, 1991), namely nouns, verbs, adjectives, and adverbs, before and after the specified unit. If we ignore the order of these words, we can get the word sequence function while the word sequence function. In addition, we use Stanford NLP core7 and add the part-of-speech tagging function, which can help make these contextual words unambiguous. Therefore, for each K window surrounding the unit, we can extract four types of different features, i.e., bag of words (BOW), word sequence (WS), bag of words plus part-of-speech tagging (BOW + POS), and part-speech sequence."}, {"heading": "4 Implementation", "text": "Since we have already created a training dataset based on the proposed remote monitoring paradigm, an intuitive idea is to feed a specific classifier for each ambiguous name with its unique MIDs and associated feature vectors. However, Table 2 shows that there are at least 5.5 million names that represent more than one unit (MID) in Freebase. Therefore, it is unfeasible to build 5.5 million specific classifiers. To train a general classifier that is not limited to one particular name, we adopt a strategy that merges these specific classifiers. Specifically, we transform MIDs into characteristics and use 1 / 2 to indicate whether the contextual features of the freebase match or not."}, {"heading": "5 Experiments", "text": "In this section, we report on the experimental results following the procedures described in Section 4. To evaluate the performance of various characteristics, we use three widely used metrics (Meij et al., 2013), namely precision, recall and F1 measurement."}, {"heading": "5.1 Dataset", "text": "We randomly select 20,000 ambiguous names (collections) in Freebase. Approximately 82,000 sentences containing at least one mention are extracted from the theme-equivalent wiki pages. For each collection, 80% of the sentences are randomly selected for the creation of the training set, and 20% of the remaining sentences are used for prolonged evaluation. Following the procedures for building training patterns described in Section 4, we receive a data set of approximately 140,000 articles and 60,000 features."}, {"heading": "5.2 Evaluation metrics", "text": "Precision and recall are widely used measures for evaluating different rank-based approaches to linking units. F1 measurement synthetically measures precision and recall by calculating the harmonic mean of these values. Suppose C stands for the entire collection set for testing. Ci, j represents the set of top-j predictions with higher probabilities in the i-th collection. Gi stands for the set of gold standards of the i-th collection. # (S) is the function that counts the entries in set S. Then the formulas for calculating precision, recall and F1 measurement are as follows: Precision = \u2211 i-j # (Ci, j-Gi) # (Ci, j-Gi) # (C), F1 measurement = 2 \u00d7 Recall Precision + Recall Precision."}, {"heading": "5.3 Feature comparison", "text": "For each type of trait, we perform an experiment and adjust the parameters for the logistics classifier using a 5x cross-validation. We then use extensive testing using the remaining 20% rates. Figure 4 and Figure 5 show the accuracy recall curves for the twelve lexical traits, and Table 3 shows the average comparison of each trait with the F1 measure. We find that the traits of the WS class generally exceed the traits of the BOWclass, and the contextual traits of the short distance (K = 1) are more effective than the traits of the long distance (K = 2, 3)."}, {"heading": "6 Conclusion and Future Work", "text": "As far as we know, this is the first attempt to solve the task of linking entities based on the idea of remote monitoring. We are using a heuristic alignment assumption, i.e. the topic-equivalent pages, to bridge the gap between Freebase and Wikipedia and are using these two knowledge bases together to automatically produce training data without manual annotation. Furthermore, we propose a strategy that converts labels into traits and feeds them to a general classifier instead of creating an individualized classifier for each ambiguous name for millions of entities.For future work, we believe that this new paradigm leaves several questions open: \u2022 In addition to the entities (MIDs) that have already been stored in knowledge repositories (freebases), new entity instances (NIL) with the same name must be discovered. Therefore, another study could focus on expanding the paradigm to include identifying unknown entities that are also intended for many other entities in different languages, although the proposed strategy is also high."}, {"heading": "Acknowledgements", "text": "This work is mainly supported by the National Program on Key Basic Research Project (973 Program) under grant number 2013CB329304, National Science Foundation of China (NSFC) under grant number 61373075. Thanks to Yulong Gu, Yingnan Xiao and anonymous reviewers for their insightful comments."}], "references": [{"title": "Freebase: A shared database of structured general human knowledge", "author": ["Robert Cook", "Patrick Tufts"], "venue": "In Proceedings of the national conference on Artificial Intelligence,", "citeRegEx": "Bollacker et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2007}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of the 2008 ACM SIGMOD international", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Using encyclopedic knowledge for named entity disambiguation", "author": ["Bunescu", "Pasca2006] Razvan C Bunescu", "Marius Pasca"], "venue": "In EACL,", "citeRegEx": "Bunescu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bunescu et al\\.", "year": 2006}, {"title": "A comparison of personal name matching: Techniques and practical issues", "author": ["Peter Christen"], "venue": "In Data Mining Workshops,", "citeRegEx": "Christen.,? \\Q2006\\E", "shortCiteRegEx": "Christen.", "year": 2006}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["Craven et al.1999] Mark Craven", "Johan Kumlien"], "venue": "In ISMB,", "citeRegEx": "Craven and Kumlien,? \\Q1999\\E", "shortCiteRegEx": "Craven and Kumlien", "year": 1999}, {"title": "Large-scale named entity disambiguation based on wikipedia data", "author": ["Silviu Cucerzan"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Cucerzan.,? \\Q2007\\E", "shortCiteRegEx": "Cucerzan.", "year": 2007}, {"title": "Liblinear: A library for large linear classification", "author": ["Fan et al.2008] Rong-En Fan", "Kai-Wei Chang", "ChoJui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Distant supervision for relation extraction with matrix completion", "author": ["Fan et al.2014] Miao Fan", "Deli Zhao", "Qiang Zhou", "Zhiyuan Liu", "Thomas Fang Zheng", "Edward Y Chang"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Fan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2014}, {"title": "Evaluating entity linking with wikipedia", "author": ["Hachey et al.2013] Ben Hachey", "Will Radford", "Joel Nothman", "Matthew Honnibal", "James R Curran"], "venue": "Artificial intelligence,", "citeRegEx": "Hachey et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hachey et al\\.", "year": 2013}, {"title": "The rise of crowdsourcing", "author": ["Jeff Howe"], "venue": "Wired magazine,", "citeRegEx": "Howe.,? \\Q2006\\E", "shortCiteRegEx": "Howe.", "year": 2006}, {"title": "Knowledge base population: Successful approaches and challenges", "author": ["Ji", "Grishman2011] Heng Ji", "Ralph Grishman"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-", "citeRegEx": "Ji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2011}, {"title": "Overview of the tac 2010 knowledge base population track", "author": ["Ji et al.2010] Heng Ji", "Ralph Grishman", "Hoa Trang Dang", "Kira Griffitt", "Joe Ellis"], "venue": "In Third Text Analysis Conference (TAC", "citeRegEx": "Ji et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2010}, {"title": "Overview of the tac 2009 knowledge base population track", "author": ["McNamee", "Dang2009] Paul McNamee", "Hoa Trang Dang"], "venue": "In Text Analysis Conference (TAC),", "citeRegEx": "McNamee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "McNamee et al\\.", "year": 2009}, {"title": "Entity linking and retrieval", "author": ["Meij et al.2013] Edgar Meij", "Krisztian Balog", "Daan Odijk"], "venue": "In Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Meij et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Meij et al\\.", "year": 2013}, {"title": "Wikify!: linking documents to encyclopedic knowledge", "author": ["Mihalcea", "Csomai2007] Rada Mihalcea", "Andras Csomai"], "venue": "In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,", "citeRegEx": "Mihalcea et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2007}, {"title": "Learning to link with wikipedia", "author": ["Milne", "Witten2008] David Milne", "Ian H Witten"], "venue": "In Proceedings of the 17th ACM conference on Information and knowledge management,", "citeRegEx": "Milne et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Milne et al\\.", "year": 2008}, {"title": "A survey of named entity recognition and classification", "author": ["Nadeau", "Sekine2007] David Nadeau", "Satoshi Sekine"], "venue": "Lingvisticae Investigationes,", "citeRegEx": "Nadeau et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nadeau et al\\.", "year": 2007}, {"title": "Supervised noun phrase coreference research: The first fifteen years", "author": ["Vincent Ng"], "venue": "In Proceedings of the 48th annual meeting of the association for computational linguistics,", "citeRegEx": "Ng.,? \\Q2010\\E", "shortCiteRegEx": "Ng.", "year": 2010}, {"title": "Entity linking: Finding extracted entities in a knowledge base. In Multi-source, multilingual information extraction and summarization", "author": ["Rao et al.2013] Delip Rao", "Paul McNamee", "Mark Dredze"], "venue": null, "citeRegEx": "Rao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rao et al\\.", "year": 2013}, {"title": "Local and global algorithms for disambiguation to wikipedia", "author": ["Ratinov et al.2011] Lev Ratinov", "Dan Roth", "Doug Downey", "Mike Anderson"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:", "citeRegEx": "Ratinov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ratinov et al\\.", "year": 2011}, {"title": "Influences of semantic and syntactic context on open-and closed-class words", "author": ["Van Petten", "Kutas1991] Cyma Van Petten", "Marta Kutas"], "venue": "Memory & Cognition,", "citeRegEx": "Petten et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Petten et al\\.", "year": 1991}, {"title": "Entity disambiguation with freebase", "author": ["Zheng et al.2012] Zhicheng Zheng", "Xiance Si", "Fangtao Li", "Edward Y Chang", "Xiaoyan Zhu"], "venue": "In Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intel-", "citeRegEx": "Zheng et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 17, "context": "\u2022 Coreference Resolution (Ng, 2010): Some entities may have alias or abbreviations.", "startOffset": 25, "endOffset": 35}, {"referenceID": 0, "context": "base (Bollacker et al., 2007) which is a huge1, public2, collaborative3(Bollacker et al.", "startOffset": 5, "endOffset": 29}, {"referenceID": 1, "context": ", 2007) which is a huge1, public2, collaborative3(Bollacker et al., 2008) and online knowledge base with billions of triples and millions of disambiguated entities, and is primarily maintained by Google Inc.", "startOffset": 49, "endOffset": 73}, {"referenceID": 18, "context": "\u2022 Entity Linking (Rao et al., 2013): It concerns about the study of aligning a textual entity mention to the corresponding disambiguated entry in a knowledge repository.", "startOffset": 17, "endOffset": 35}, {"referenceID": 5, "context": "(2013) elucidate that most of the literatures (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al.", "startOffset": 46, "endOffset": 160}, {"referenceID": 19, "context": "(2013) elucidate that most of the literatures (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007; Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al.", "startOffset": 46, "endOffset": 160}, {"referenceID": 11, "context": ", 2011) and the entity linking tracks4 in TAC-KBP (McNamee and Dang, 2009; Ji et al., 2010) concentrate on linking ambiguous entities to the entries in Wikipedia, whereas our ultimate goal is to populate the structured knowledge repository, e.", "startOffset": 50, "endOffset": 91}, {"referenceID": 21, "context": "However, to the best of our knowledge, few works (Zheng et al., 2012) concern about disambiguating named entities using Freebase which contains much more entries but less text information for each entry than Wikipedia.", "startOffset": 49, "endOffset": 69}, {"referenceID": 8, "context": "Overall, Hachey et al. (2013) and Zheng et al.", "startOffset": 9, "endOffset": 30}, {"referenceID": 8, "context": "Overall, Hachey et al. (2013) and Zheng et al. (2012) represent two research directions leveraging Wikipedia and Freebase, respectively.", "startOffset": 9, "endOffset": 54}, {"referenceID": 7, "context": "Inspired by the idea of weak labeling (Fan et al., 2014; Craven et al., 1999), we contribute a new paradigm called distantly supervised entity linking (DSEL) without manual annotation in this paper.", "startOffset": 38, "endOffset": 77}, {"referenceID": 6, "context": ", liblinear (Fan et al., 2008) to self-learn the weights among the high-dimensional sparse and noisy features.", "startOffset": 12, "endOffset": 30}, {"referenceID": 3, "context": ", person names (Christen, 2006) as well.", "startOffset": 15, "endOffset": 31}, {"referenceID": 9, "context": "Fortunately, every entity in Freebase maintains a list of links to its topic equivalent webpages via crowd sourcing (Howe, 2006) as shown in Figure 2.", "startOffset": 116, "endOffset": 128}, {"referenceID": 6, "context": ", Liblinear (Fan et al., 2008), to rapidly self-learn the weights among the high-dimensional sparse and noisy features.", "startOffset": 12, "endOffset": 30}, {"referenceID": 13, "context": "To evaluate the performance of different features, we adopt three widely used metrics (Meij et al., 2013), namely precision, recall and F1-measure.", "startOffset": 86, "endOffset": 105}], "year": 2015, "abstractText": "Entity linking is an indispensable operation of populating knowledge repositories for information extraction. It studies on aligning a textual entity mention to its corresponding disambiguated entry in a knowledge repository. In this paper, we propose a new paradigm named distantly supervised entity linking (DSEL), in the sense that the disambiguated entities that belong to a huge knowledge repository (Freebase) are automatically aligned to the corresponding descriptive webpages (Wiki pages). In this way, a large scale of weakly labeled data can be generated without manual annotation and fed to a classifier for linking more newly discovered entities. Compared with traditional paradigms based on solo knowledge base, DSEL benefits more via jointly leveraging the respective advantages of Freebase and Wikipedia. Specifically, the proposed paradigm facilitates bridging the disambiguated labels (Freebase) of entities and their textual descriptions (Wikipedia) for Web-scale entities. Experiments conducted on a dataset of 140,000 items and 60,000 features achieve a baseline F1measure of 0.517. Furthermore, we analyze the feature performance and improve the F1-measure to 0.545.", "creator": "LaTeX with hyperref package"}}}