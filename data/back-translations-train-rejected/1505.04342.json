{"id": "1505.04342", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2015", "title": "Sifting Robotic from Organic Text: A Natural Language Approach for Detecting Automation on Twitter", "abstract": "Twitter, a popular social media outlet, has evolved into a vast source of linguistic data, rich with opinion, sentiment, and discussion. Due to the increasing popularity of Twitter, its perceived potential for exerting social influence has led to the rise of a diverse community of automatons, commonly referred to as bots. These inorganic and semi-organic Twitter entities can range from the benevolent (e.g., weather-update bots, help-wanted-alert bots) to the malevolent (e.g., spamming messages, advertisements, or radical opinions). Existing detection algorithms typically leverage meta-data (time between tweets, number of followers, etc.) to identify robotic accounts. Here, we present a powerful classification scheme that exclusively uses the natural language text from organic users to provide a criterion for identifying accounts posting automated messages. Since the classifier operates on text alone, it is flexible and may be applied to any textual data beyond the Twitter-sphere.", "histories": [["v1", "Sun, 17 May 2015 01:22:00 GMT  (603kb,D)", "https://arxiv.org/abs/1505.04342v1", null], ["v2", "Tue, 19 May 2015 13:32:43 GMT  (603kb,D)", "http://arxiv.org/abs/1505.04342v2", null], ["v3", "Tue, 2 Jun 2015 16:14:38 GMT  (603kb,D)", "http://arxiv.org/abs/1505.04342v3", null], ["v4", "Wed, 11 Nov 2015 23:02:05 GMT  (5696kb,D)", "http://arxiv.org/abs/1505.04342v4", null], ["v5", "Wed, 24 Feb 2016 07:42:59 GMT  (8619kb,D)", "http://arxiv.org/abs/1505.04342v5", null], ["v6", "Tue, 14 Jun 2016 13:44:56 GMT  (8619kb,D)", "http://arxiv.org/abs/1505.04342v6", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["eric m clark", "jake ryland williams", "chris a jones", "richard a galbraith", "christopher m danforth", "peter sheridan dodds"], "accepted": false, "id": "1505.04342"}, "pdf": {"name": "1505.04342.pdf", "metadata": {"source": "CRF", "title": "Sifting Robotic from Organic Text: A Natural Language Approach for Detecting Automation on Twitter", "authors": ["Eric M. Clark", "Jake Ryland Williams", "Chris A. Jones", "Richard A. Galbraith", "Christopher M. Danforth", "Peter Sheridan Dodds"], "emails": ["eclark@uvm.edu"], "sections": [{"heading": null, "text": "In recent years, it has become clear that the number of people who are able to outdo themselves, to compete, is a system, \"he said.\" We have to be aware that this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, \"he said,\" this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a system, this is a"}, {"heading": "II. DATA HANDLING", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Data-Collection", "text": "We filtered a 1% sample of Twitter's Streaming API (the Schorle feed) for tweets containing geo-spatial metadata from April to July 2014. Since about 1% of tweets contained GPS-localized spatial coordinates, our sample represents almost all tweets from users that enable geotagging, allowing for much more complete coverage of the user account. From this sample, we collected all the geo-tweets of the most active 1000 users for classification as human or robotic, and call this the geo-tweet dataset."}, {"heading": "B. Social HoneyPots", "text": "To put our classification in the context of recent work, we applied our algorithm to another group of accounts collected as part of the Social HoneyPot Experiment [11], which required a more sophisticated approach to finding automated accounts on Twitter by creating a network of fake accounts (called devils [12]) that tweeted among themselves about trending topics to induce robotic interactions, and the experiment was analyzed and compiled into a data set that included tweets from \"legitimate users\" and those classified as \"content polluders.\" We found that the users in that data set were not hand-coded. Accounts that followed the Devil HoneyPot Accounts were considered robots. Their organic users were compiled from a random sample of Twitter and classified as organic only because those accounts were not blocked by Twitter at the time. Therefore, the full HoneyPot performance chart can only serve as the performance scheme of this data set."}, {"heading": "C. Human Classification of Geo-Tweets", "text": "All tweets collected by each user were checked until the evaluator noticed the presence of automation. If no sub-sample of tweets appeared to be algorithmically generated, the user was classified as human. Results were merged and conflicting entries resolved to create a definitive list of user identifications and encodings. See Figure 1 for histograms and violin charts summarizing the distributions of each user class. We found that any form of perceived automation was sufficient to make the account automated. See SI for examples of each of these types of tweets from each user class and a more thorough description of the annotation process."}, {"heading": "D. Types of Users", "text": "We consider organic content, i.e. from human accounts, as those that have not tweeted in an algorithmic way. We focused on three distinct classes of automated twittering: Robots: Tweets from these accounts rely on a strictly limited vocabulary. The messages follow a very structured pattern, many of which lie in Formula 3 automated updates. Examples include Weather Condition Update Accounts, Police Scanner Update Accounts, Help Wanted Update Accounts, etc. Cyborgs: the most covert of the three, these automated machines display human behavior and messages through loosely structured, generic, automated messages, and borrowed content copied from other sources. As many malicious cyborgs on Twitter try to market an idea or product, a high proportion of their tweets contain URLs, analogous to spam campaigns being investigated on Facebook. [13] Messages range from backdoor advertising for goods and services [14] to those that attempt to influence social opinion or even political conversations like these [15] puppets."}, {"heading": "III. METHODS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Classification Algorithm", "text": "The classifier, C, takes samples of tweets from each user, \u00b5, different number, s, to determine whether the user is a person posting strictly organic content, or algorithmically automated tweets: C: \u00b5s \u2192 {0, 1} = {Organic, Automaton}. Although we have divided each automaton into three different classes, the classifier is easier to detect and separate organic content from automated ones. To classify a user's tweets, we measure three different linguistic attributes: 1. Average dissimilarity of tweets, 2. Word Introduction Rate Decay Parameter, 3. Average number of URLs (hyperlinks) per tweet."}, {"heading": "B. Average Pairwise Tweet Dissimilarity", "text": "Purely organic accounts have tweets that vary widely on average; the length of a tweet, t, is defined as the number of characters in the tweet and is referred to as | t |. Each tweet is cleaned by truncating several whitespace characters, and the metric is performed on a case-by-case basis. A sample of tweets by a particular user is called T s\u00b5. In a tweet pair by a specific user, ti, tj, T s\u00b5 is given the pair of tweet dissimilarity, D (ti, tj), by subtracting the length of the longest common subsequence of both tweets, | LCS (ti, tj) | and then weighted by the sum of the lengths of both tweets: D (ti, tj) = | ti, tj, tj, tj (ti, tj), tj, tj (ti, tj)."}, {"heading": "C. Word Introduction Decay Rate", "text": "Because social robots automate messages, they have a limited and crystalline vocabulary compared to organic accounts. Even cyborgs masking their automations with borrowed content cannot fully mimic the speed at which organic users insert unique words into their text. Introduction rate is a measure of the number of unique words introduced from a particular text sample. [17] The speed at which unique words are introduced naturally decays over time and differs noticeably between automated and organic text. By testing many random word exchanges in a text, we define mn as the average number of words between the ninth and n + 1. Initial unique word types. Beginning with [17], the word insertion decay rate, \u03b1 (n), is given as \u03b1 (n) = 1 / mn \u00b2 n \u00b2 for each user."}, {"heading": "D. Average URLs per Tweet", "text": "Hyperlinks (URLs) help automatons spread spam and malware [10, 20, 21]. A high percentage of spammers \"tweets tend to contain some kind of URL compared to organic individuals, making the average URLs per tweet a valuable attribute for bot classification algorithms [8, 22, 23]. For each user, the average URLrate is measured by the total number of occurrences of the substring\" http: \"within tweets and then divided by the total number of tweets written by the user in the sample of size s: \u00b5surl = # occurrences of\" http: '# Sampled Tweets."}, {"heading": "E. Cross Validation Experiment", "text": "We perform a 10-fold cross-validation procedure based on the 2014 Geo-Tweet dataset to measure the accuracy of the use of each linguistic feature to classify organic accounts. We divided people into 10 equal-sized groups. Subsequently, 10 trials are conducted in which 9 of the 10 groups are used to train the algorithm to classify the final group.During the calibration phase, we measure each of the three features for each human encoded account in the training set. We collect tweets from each user sequentially from a random starting position in time. We capture the arithmetic mean and the standard deviation of organic attributes to classify the remaining group.The classifier distinguishes the human from the automaton by using a different threshold, n, from the average attribute value calculated from the training set. For each attribute, we classify each user as an automaton, if its characteristic differs from the average for each positive window, and the positive for each one is calculated further than the average for each positive window."}, {"heading": "IV. RESULTS AND DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Geo-Tweet Classification Validation", "text": "The ROC curves of the 10-fold cross-validation experiment for different tweet containers in Figure 3 show that accuracy increases as a function of the number of tweets. Although the accuracy of the classifier increases with the number of tweets collected, in Figure 4 we see that within 50 tweets the accuracy of the average of 10 random attempts is only slightly higher than for a user sample of 500 tweets. Although this is very beneficial for our task (isolating people), we find that larger samples achieve greater yields when isolating spammers who tweet random outbursts of automation instead. 5"}, {"heading": "B. HoneyPot External Validation", "text": "The results are visualized using an ROC curve in Figure 5. The average optimal threshold for the full English user record (blue curve) had a high true positive rate (correctly classified vending machines: 86%), but also a high false positive rate (wrongly classified people: 22%). The Honeypot dataset relied on Twitter's spam detection protocols to identify its randomly collected \"legitimate users.\" Some forms of automation (weather bots, help bots) are permitted by Twitter. Other cyborgs that post borrowed organic content can deceive Twitter's automation criterion. This malformation of the training set significantly reduces the classifier's ability to distinguish people from vending machines, as the classifier gets the wrong information about what constitutes a human being. To see this, a random sample of 1,000 English honeypot users was hand-coded to increase the previous threshold by 4%."}, {"heading": "C. Calibrated Classifier Performance", "text": "We have created the threshold window of the final calibrated classifier based on the results of the calibration experiment. We calculate the optimal parameters of the 10-fold cross-validation of the Geo-Tweet dataset from each of the 10 calibration attempts for Tweet containers in the range of 25 to 500 tweets. We also calculate the optimal parameter windows, opt and their standard deviations. The standard deviations serve as tuning parameters to increase the sensitivity of the classifier by increasing the feature cutoff window (s). The results of applying the calibrated classifier to the 6full set of 1,000 users using 400 tweet bags are shown in Figure 6. The feature cutoff window (black lines) estimates whether the content of the user is organic or automated. Human feature sets (True Negatives: 716) are densely distributed with a False Rate of 4.79%, which is classified as robots."}, {"heading": "V. CONCLUSION", "text": "Through a flexible and transparent classification scheme, we have demonstrated the potential to use linguistic traits as a means of classifying automated activity on Twitter. Since these traits do not use the metadata provided by Twitter, our classification scheme can also be applied outside the Twittersphere. Future work may expand this analysis to include additional traits with an analogue classification scheme. URLs can also be analysed more deeply to identify organic versus SPAM-related hyperlinks. We point to the potential of future research to differentiate between each subclass of automated accounts. We have shaped our taxonomy according to the different modes of text production. Our efforts have focused primarily on separating from any form of automation of organic human content, identifying three distinct classes of these types of automated accounts. However, boundaries (e.g. cyborg spammers, robotic cyborg cyborg classes, potential cyborg classes, etc.) are likely to exist together with others."}, {"heading": "VI. ACKNOWLEDGMENTS", "text": "The authors would like to acknowledge the Vermont Advanced Computing Core, which provided high performance computing resources that contributed to the research outcomes. EMC and JRW were supported by the UVM Complex Systems Center, PSD. http: / / www.cmd.org / PSD were also supported by MITRE Corporation and the NSF Conference. # 1447634. CJ is partially supported by the National Institute of Health (NIH) Research wards R01DA014028 & R01HD075669, and by the Center of Biomedical Research Excellence Award P20GM1036447 from the National Institute of General Medical Sciences. [1] V.S. Subrahmanian, A. Azaria, S. Durst, V. Kagan, A. Galstyan, K. Lerman, L. Zhu, E. Ferrara, A. Flammini, and F. Menczer, arXiv: 1601.05140 (2016), http: / / Jaxidf."}], "references": [{"title": "and F", "author": ["V.S. Subrahmanian", "A. Azaria", "S. Durst", "V. Kagan", "A. Galstyan", "K. Lerman", "L. Zhu", "E. Ferrara", "A. Flammini"], "venue": "Menczer, arXiv arXiv:1601.05140, ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Can evil data scientists fool us all with the world\u2019s best spam", "author": ["D. Harris"], "venue": "goo.gl/psEguf ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "and V", "author": ["A. Sadilek", "H.A. Kautz"], "venue": "Silenzio, in ICWSM ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Journal of health economics 31", "author": ["A. Wagstaff", "A.J. Culyer"], "venue": "406 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "PloS one 8", "author": ["L. Mitchell", "M.R. Frank", "K.D. Harris", "P.S. Dodds", "C.M. Danforth"], "venue": "e64417 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "and A", "author": ["E. Ferrara", "O. Varol", "C. Davis", "F. Menczer"], "venue": "Flammini, CoRR abs/1407.5225 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "in In Collaboration", "author": ["F. Benevenuto", "G. Magno", "T. Rodrigues", "V. Almeida"], "venue": "Electronic messaging, Anti- Abuse and Spam Conference (CEAS ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "and S", "author": ["Z. Chu", "S. Gianvecchio", "H. Wang"], "venue": "Jajodia, in Proceedings of the 26th Annual Computer Security Applications Conference ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "and V", "author": ["K. Thomas", "C. Grier", "D. Song"], "venue": "Paxson, in Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "and J", "author": ["K. Lee", "B.D. Eoff"], "venue": "Caverlee, in In AAAI Int?l Conference on Weblogs and Social Media (ICWSM ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "in ICWSM", "author": ["K. Lee", "B.D. Eoff", "J. Caverlee"], "venue": "edited by W. W. Cohen and S. Gosling ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "and B", "author": ["H. Gao", "J. Hu", "C. Wilson", "Z. Li", "Y. Chen"], "venue": "Y. Zhao, in Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Tobacco control 23", "author": ["J. Huang", "R. Kornfield", "G. Szczypka", "S.L. Emery"], "venue": "iii26 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "and V", "author": ["K. Thomas", "C. Grier"], "venue": "Paxson, in Presented as part of the 5th USENIX Workshop on Large-Scale Exploits and Emergent Threats ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "in Machine Learning and Knowledge Discovery in Databases", "author": ["X. Wu", "Z. Feng", "W. Fan", "J. Gao", "Y. Yu"], "venue": "edited by H. Blockeel, K. Kersting, S. Nijssen, and F. elezn ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Text mixing shapes the anatomy of rank-frequency distributions: A modern Zipfian mechanics for natural language", "author": ["J.R. Williams", "J.P. Bagrow", "C.M. Danforth", "P.S. Dodds"], "venue": "Physical Review E (in press) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Detecting automation of twitter accounts: Are you a human", "author": ["Z. Chu", "S. Gianvecchio", "H. Wang", "S. Jajodia"], "venue": "bot, or cyborg?, Dependable and Secure Computing, IEEE Transactions on v9, n6 pp 811-824 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Using sentiment to detect bots on Twitter: Are humans more opinionated than bots", "author": ["J.P. Dickerson", "V. Kagan", "H. Wang", "VS. Subrahmanian"], "venue": "Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on 620\u2013627 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "and K", "author": ["G. Brown", "T. Howe", "M. Ihbe", "A. Prakash"], "venue": "Borders, in Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "and S", "author": ["K. Lee", "J. Caverlee"], "venue": "Webb, in Proceedings of the 19th International Conference on World Wide Web ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "and S", "author": ["K. Lee", "J. Caverlee"], "venue": "Webb, in Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "PloS one 8", "author": ["D.A. Broniatowski", "M.J. Paul", "M. Dredze"], "venue": "e83672 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "C Jones", "author": ["E.M. Clark"], "venue": "J.R. Williams, A.N. Kurti, M.C. Norotsky, C.M. Danforth, and P.S. Dodds, arXiv arXiv:1508.01843, ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "As Twitter has evolved from a simple microblogging social media interface into a mainstream source of communication for the discussion of current events, politics, consumer goods/services, it has become increasingly enticing for parties to gameify the system by creating automated software to send messages to organic (human) accounts as a means for personal gain and for influence manipulation [1, 2].", "startOffset": 395, "endOffset": 401}, {"referenceID": 1, "context": "As Twitter has evolved from a simple microblogging social media interface into a mainstream source of communication for the discussion of current events, politics, consumer goods/services, it has become increasingly enticing for parties to gameify the system by creating automated software to send messages to organic (human) accounts as a means for personal gain and for influence manipulation [1, 2].", "startOffset": 395, "endOffset": 401}, {"referenceID": 2, "context": "Nevertheless, data from Twitter is becoming a source of interest in public health and economic research in monitoring the spread of disease [3, 4] and gaining insight into public health trends [5].", "startOffset": 140, "endOffset": 146}, {"referenceID": 3, "context": "Nevertheless, data from Twitter is becoming a source of interest in public health and economic research in monitoring the spread of disease [3, 4] and gaining insight into public health trends [5].", "startOffset": 140, "endOffset": 146}, {"referenceID": 4, "context": "Nevertheless, data from Twitter is becoming a source of interest in public health and economic research in monitoring the spread of disease [3, 4] and gaining insight into public health trends [5].", "startOffset": 193, "endOffset": 196}, {"referenceID": 5, "context": "In related work [6\u20139], researchers have built classification algorithms using metadata idiosyncratic to Twitter, including the number of followers, posting frequency, account age, number of user mentions/replies, username", "startOffset": 16, "endOffset": 21}, {"referenceID": 6, "context": "In related work [6\u20139], researchers have built classification algorithms using metadata idiosyncratic to Twitter, including the number of followers, posting frequency, account age, number of user mentions/replies, username", "startOffset": 16, "endOffset": 21}, {"referenceID": 7, "context": "In related work [6\u20139], researchers have built classification algorithms using metadata idiosyncratic to Twitter, including the number of followers, posting frequency, account age, number of user mentions/replies, username", "startOffset": 16, "endOffset": 21}, {"referenceID": 5, "context": "However, relying on metadata can be problematic: sophisticated spam algorithms now emulate the daily cycle of human activity and author borrowed content to appear human [6].", "startOffset": 169, "endOffset": 172}, {"referenceID": 8, "context": "Another problematic spam tactic is the renting of accounts of legitimate users (called sponsored accounts), to introduce short bursts of spam and hide under the user\u2019s organic metadata to mask the attack [10].", "startOffset": 204, "endOffset": 208}, {"referenceID": 16, "context": "A content based classifier proposed by [18] measures the entropy between Twitter time intervals along with user meta data to classify Twitter accounts, and requires a comparable number of tweets (\u2265 60) for adequate classification accuracy as our proposed method.", "startOffset": 39, "endOffset": 43}, {"referenceID": 17, "context": "SentiBot, another content based classifier [19], utilizes latent Dirichlet allocation (LDA) for topical categorization combined with sentiment analysis techniques to classify individuals as either bots or humans.", "startOffset": 43, "endOffset": 47}, {"referenceID": 9, "context": "To place our classifier in the context of recent work, we applied our algorithm to another set of accounts collected from the Social HoneyPot Experiment [11].", "startOffset": 153, "endOffset": 157}, {"referenceID": 10, "context": "This work exacted a more elaborate approach to find automated accounts on Twitter by creating a network of fake accounts (called Devils [12]) that would tweet about trending topics amongst themselves in order to tempt robotic interactions.", "startOffset": 136, "endOffset": 140}, {"referenceID": 11, "context": "Since many malicious cyborgs on Twitter try to market an idea or product, a high proportion of their tweets contain URLs, analogous to spam campaigns studied on Facebook [13].", "startOffset": 170, "endOffset": 174}, {"referenceID": 12, "context": "Messages range from the backdoor advertising of goods and services [14] to those trying to influence social opinion or even censor political conversations [15].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "Messages range from the backdoor advertising of goods and services [14] to those trying to influence social opinion or even censor political conversations [15].", "startOffset": 155, "endOffset": 159}, {"referenceID": 14, "context": "These accounts act like puppets from a central algorithmic puppeteer to push their product on organic users while trying to appear like an organic user [16].", "startOffset": 152, "endOffset": 156}, {"referenceID": 9, "context": "Included in this category are \u2018malicious promoter\u2019 accounts [11] that are radically promoting a business or an idea systematically.", "startOffset": 60, "endOffset": 64}, {"referenceID": 15, "context": "over time from a given sample of text [17].", "startOffset": 38, "endOffset": 42}, {"referenceID": 15, "context": "From [17], the word introduction decay rate, \u03b1(n), is given as", "startOffset": 5, "endOffset": 9}, {"referenceID": 15, "context": "For each user, the scaling exponent of the word introduction decay rate, \u03b1, is approximated by performing standard linear regression on the last third of the logtransformed tail of the average gap size distribution as a function of word introduction number, n [17].", "startOffset": 260, "endOffset": 264}, {"referenceID": 8, "context": "Hyperlinks (URLs) help automatons spread spam and malware [10, 20, 21] .", "startOffset": 58, "endOffset": 70}, {"referenceID": 18, "context": "Hyperlinks (URLs) help automatons spread spam and malware [10, 20, 21] .", "startOffset": 58, "endOffset": 70}, {"referenceID": 7, "context": "A high fraction of tweets from spammers tend to contain some type of URL in comparison to organic individuals, making the average URLs per tweet a valuable attribute for bot classification algorithms [8, 22, 23].", "startOffset": 200, "endOffset": 211}, {"referenceID": 19, "context": "A high fraction of tweets from spammers tend to contain some type of URL in comparison to organic individuals, making the average URLs per tweet a valuable attribute for bot classification algorithms [8, 22, 23].", "startOffset": 200, "endOffset": 211}, {"referenceID": 20, "context": "A high fraction of tweets from spammers tend to contain some type of URL in comparison to organic individuals, making the average URLs per tweet a valuable attribute for bot classification algorithms [8, 22, 23].", "startOffset": 200, "endOffset": 211}, {"referenceID": 9, "context": "The classifier was tested on the Social Honeypot Twitter-bot dataset provided by [11].", "startOffset": 81, "endOffset": 85}, {"referenceID": 3, "context": "This is particularly important, since Twitter has become a possible outlet for health economics [4] research including monitoring patient satisfaction and modeling disease spread [3, 24].", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "This is particularly important, since Twitter has become a possible outlet for health economics [4] research including monitoring patient satisfaction and modeling disease spread [3, 24].", "startOffset": 179, "endOffset": 186}, {"referenceID": 21, "context": "This is particularly important, since Twitter has become a possible outlet for health economics [4] research including monitoring patient satisfaction and modeling disease spread [3, 24].", "startOffset": 179, "endOffset": 186}, {"referenceID": 22, "context": "Monitoring excessive social media marketing of electronic nicotine delivery systems (also known as e-cigarettes), discussed in [25, 26], makes classifying organic and automated activity relevant for research that can benefit policy-makers regarding public health agendas.", "startOffset": 127, "endOffset": 135}, {"referenceID": 0, "context": "[1] V.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] F.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Z.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[23] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[24] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[25] E.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "of [16].", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "Eric M. Clark, 2, 3, 4, 5, \u2217 Jake Ryland Williams, 2, 3, 4 Chris A. Jones, 6, 7 Richard A. Galbraith, 9 Christopher M. Danforth, 2, 3, 4 and Peter Sheridan Dodds 2, 3, 4 Department of Mathematics & Statistics Vermont Complex Systems Center Vermont Advanced Computing Core Computational Story Lab Department of Surgery Global Health Economics Unit of the Vermont Center for Clinical and Translational Science Vermont Center for Behavior and Health Department of Medicine Vermont Center for Clinical and Translational Science (Dated: June 15, 2016)", "creator": "LaTeX with hyperref package"}}}