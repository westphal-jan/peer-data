{"id": "1505.04657", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-May-2015", "title": "Mining User Opinions in Mobile App Reviews: A Keyword-based Approach", "abstract": "To improve user satisfaction, mobile app developers are interested in relevant user opinions such as complaints or suggestions. An important source for such opinions is user reviews on online app markets. However, manual review analysis for useful opinions is often challenging due to the large amount and the noisy-nature of user reviews. To address this problem, we propose M.A.R.K, a keyword-based framework for semiautomated review analysis. The key task of M.A.R.K is to analyze reviews for keywords of potential interest which developers can use to search for useful opinions. We have developed several techniques for that task including: 1) keyword extracting with customized regularization algorithms; 2) keyword grouping with distributed representation; and 3) keyword ranking with ratings and frequencies analysis. Our empirical evaluation and case studies show that M.A.R.K can identify keywords of high interest and provide developers with useful user opinions.", "histories": [["v1", "Mon, 18 May 2015 14:25:03 GMT  (692kb,D)", "http://arxiv.org/abs/1505.04657v1", null], ["v2", "Mon, 26 Oct 2015 02:23:32 GMT  (2333kb,D)", "http://arxiv.org/abs/1505.04657v2", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["phong minh vu", "tam the nguyen", "hung viet pham", "tung thanh nguyen"], "accepted": false, "id": "1505.04657"}, "pdf": {"name": "1505.04657.pdf", "metadata": {"source": "CRF", "title": "Mining User Opinions in Mobile App Reviews: A Keyword-based Approach", "authors": ["Phong Minh Vu", "Tam The Nguyen", "Hung Viet Pham", "Tung Thanh Nguyen"], "emails": ["phong.vu@aggiemail.usu.edu", "tam.nguyen@aggiemail.usu.edu", "hung.pham@aggiemail.usu.edu", "tung.nguyen@usu.edu"], "sections": [{"heading": null, "text": "In fact, most of them are able to determine for themselves what they want to do and what they want to do."}, {"heading": "II. SYSTEM OVERVIEW", "text": "Figure 2 illustrates the system architecture of M.A.R.K. In general, M.A.R.K. consists of three main components: Keyword Extractor, Keyword Analyzers and Further Analysis & Visualization. Keyword Extractor extracts raw ratings from designated app stores1 and extracts keywords from them. Then, the keyword data is stored in a common database, which Keyword Analyzers (Keyword Dividing, Keywords Expanding, Keyword Ranking) can retrieve for further analysis. The results of these processes are a keyword group or multiple keyword clusters, which in turn can be used as input to search for relevant ratings or detect discrepancies in their trends. Details of each technique are discussed further in the following sections."}, {"heading": "III. DATA COLLECTION AND PREPROCESSING", "text": "In this section, we describe how M.A.R.K. processes and stores raw data for our following analysis: (i) by pointing out the problems we have encountered in collecting words from reviews: too many misspelled words, acronyms and teen code; too many reviews in other languages instead of English; not all parts of a sentence contain interesting information; (ii) by suggesting pre-processing of 1Google Play, Apple App Store, Amazon, Microsoft to solve the above problems and gather information we need for later analysis."}, {"heading": "A. Data Collecting", "text": "Most App Markets offer user ratings to developers and third parties. Although the information provided may vary from one to the other, most of them include: \u2022 Text: the user's text rating. \u2022 Rating: The user's opinion of the app ranges from 1 to 5, with 5 being the best and 1 the worst. \u2022 Creation time: the time it takes to create this rating. In our work, we need this information for each rating, but M.A.R.K Framework still combs through all the other information provided by each App Market and stores it for each future use. Most markets limit the number of reviews that can be retrieved from their API (for example, Google Play API limits ratings to 500 each), so our crawler needs to work continuously to acquire all ratings for a specific time."}, {"heading": "B. Reviews Preprocessing and Keywords Extraction", "text": "In fact, it is as if most of us are able to survive ourselves, and they do not. (...) It is not as if they are able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves."}, {"heading": "IV. KEYWORD ANALYSIS", "text": "In this section, we describe our approach to analyzing keywords from reviews in order to derive user feedback from them. (i) The section includes: (i) the use of ratings and the frequency of keywords to rate them and find the most popular keywords that users frequently mention in their concerns; (iii) the extension of a keyword set to a broader sentence; (iv) the search for ratings that are relevant to a keyword could be the bestA. Finding keywords of interest In this section, we suggest a technique to rate keywords based on their importance. Our assumption is that developers and users often express their concerns about keywords related to that concern. However, the number of concerns extracted from user app reviews could be many, and all of them could be time consuming, so they should be prioritized so that developers can address the most important ones."}, {"heading": "B. Dividing keywords into groups", "text": "In this section, we explain our grouping technology using the vector-space-distributed representation of words. We define the problem as follows: Definition 2: Faced with a keyword sentence S, a similarity could not be expressed by a single keyword alone, as for the battery consumption problem mentioned above. As a result, developers must find sets of keywords that describe each problem. In such a sentence, all keywords must have a common semantic meaning or relationship. As explained in Section III-B4, simple statistical models do not describe such information. However, the representations distributed in vector space can explicitly encode many linguistic regularities, patterns, and context information, so that they have many degrees, including semantic meanings."}, {"heading": "C. Expanding keywords into bigger set", "text": "As a counter-analysis to grouping a known set of keywords into several subsets, in this section we propose a technique to expand a small set of keywords into a larger and more comprehensive one. We define this problem below: Definition 3: Given a vocabulary of keywords V, a keyword set S, a measure of similarity, a threshold \u03b1, we add any keyword to S. So u = mean (S), \u00f6ff (u, v) > = \u03b1.As I said, the concern could be described by many keywords, at some point the developers have in mind what keywords they really want to look at but do not know whether their set of keywords is sufficient or not. This leads back to the problem of finding keywords that have a similar meaning or close relationship, but in this case the developers already know part of what they are looking for. Our solution to this problem is to search for words that correspond semantically to the original set of similar words to some degree."}, {"heading": "D. Searching reviews based on keyword set", "text": "Finally, since we have a set of keywords that can describe a concern, developers need an effective way to search for the ratings that contain those keywords. We propose a verification technology from a given set of keywords that classifies the ratings based on their relevance to the whole. We formulate this problem as follows: Definition 4: Given a collection of ratings R, a keyword S, a measurement of relevance, we can return all ratings R in descending order of use (r, S). On the other hand, it is not certain that all keywords contribute equally to the main concern. Some keywords could refer to multiple concerns at once, such as \"usage,\" could describe both the user's opinions about data usage or even storage usage. On the other hand, if people mention \"runoff,\" they will most likely refer only to the battery issue."}, {"heading": "V. TREND AND ABNORMALITIES DISCOVERY", "text": "In this section, we describe our method for detecting abnormalities in the trend of a topic of concern defined by a set of keywords based on sudden changes in its time series. Time series of keywords are the series of incidents of certain words working overtime. Figure 6 (a) shows a time series of battery issues. If users mention a set of keywords in their reviews more than usual over a period of time, they may have experienced some difficulties related to the topic of those keywords. Previous studies [1] [4] have shown that at some point a new release could cause the change in the occurrence of words or ratings of an app. For example, if a release introduces a new flawed main feature of the app, users are expected to complain more about this feature than if it was still in order. Therefore, we could analyze the time series that give developers a better understanding of current trends in users \"opinions, so they can address emerging issues in a timely manner."}, {"heading": "VI. EMPIRICAL EVALUATION AND CASE STUDIES", "text": "In this section, we present and discuss our empirical assessments and case studies with M.A.R.K. based on a sample of more than 2 million reviews collected by Google Play. In our empirical assessment, we focus on the accuracy of M.A.R.K. in its keyword extraction tasks. Our case studies evaluate the accuracy and usefulness of M.A.R.K. in its keyword-based analytics tasks, i.e. identifying the most negative keywords, clustering those keywords, expanding user-provided keywords, retrieving relevant ratings, tracking breakout trends of specific keywords."}, {"heading": "A. Data collection", "text": "We searched 2 million reviews of 95 apps (Table VIII) on Google Play from January 2015 to early May 2015 using an open source Google Play crawler8. The apps to be searched in this study were based on the number of download times and the manual inspection of their review rates. Since Google limits the total number of new reviews that can be downloaded each time to 500 reviews, we had to continuously search the reviews of the selected apps to get access to the most up-to-date ones. However, on average, we have more than twenty thousand reviews for each app, and this number varies between them because some apps have more active users than others."}, {"heading": "B. Keyword Extractor", "text": "1) Non-English Ratings Classifier: In order to evaluate our classifier and find suitable bi-grammar and uni-grammar thresholds, we manually mark 400 ratings to verify classification accuracy. These ratings are randomly taken from our data set and labelled as 245 / 145 English Ratings / Non-English Ratings. At the beginning of the evaluation, we perform a greedy test with both thresholds from 0.0 to 1.0, in increments of 0.01 to find the best accuracy. In the end, we found that bi-grammar threshold and uni-grammar threshold are best at 0.39 and 0.64, respectively, with accuracy reaching 86.5%. Table IX shows some of the calculated values for some of our examples, with the top half being accepted English ratings and the bottom half being non-English entries. Finally, we applied these thresholds to the entire data set and discovered 239,980 non-English ratings contributing to our data sets."}, {"heading": "C. Keywords Analyzer", "text": "In fact, most people who are able to survive themselves are not able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think we will be able to do what we are doing. \""}, {"heading": "VII. RELATED WORK", "text": "There are a number of empirical and exploratory studies on the importance of app reviews in app development processes [15], Vasa et al. have conducted an exploratory study on how users enter their reviews in app stores and what could influence the way they write reviews. Later, Hoon et al. [16] we analyzed nearly 8 million reviews on Apple AppStore to discover several statistical features that suggest that there are developers who are constantly paying attention to changes in users \"expectations in order to customize their apps. They have examined various aspects of user reviews such as time of publication, topics and multiple characteristics, including quality and constructiveness, to determine their impact on app.Other than reviews, price and rating of apps can also have an impact on the people who offer their feedback."}, {"heading": "VIII. CONCLUSION", "text": "In this work, we proposed M.A.R.K as a semi-automatic framework for collecting and reducing user feedback from App Markets using a keyword-based approach. We developed and applied several automated, tailor-made techniques for our main tasks, including: extracting keywords from pipe reviews, ranking, grouping these reviews based on their semantic meaning, searching for the most relevant reviews for a number of keywords, visualizing their occurrence over time with reports of unusual patterns. From our observations of the difficulties in processing pipe reviews, we proposed an original technique to classify non-English reviews and developed a tailor-made stemmer to normalize their keywords. Our reviews show that the classifier is able to correctly label and use reviews in our test set, we found 11.39% non-English in our 2 million Google Play reviews, our more tailor-fit for-purpose app."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors would like to thank Dr. Young-Woo Kwon, Anand Ashok Bora, Sima Mehri Kotchaki and Jiin Kim from Utah State University, who supported us in our evaluation process, and especially Mr. Ty Nguyen, Dr. Tam Vu and Dr. Thang Dinh for their contributions to our work."}, {"heading": "C. Cosine Similarity", "text": "Similarities = cos (\u03b8) = A \u00b7 B, A, B, B (7) \u2022 A, B: two vectors of attributes. \u2022 cos (\u03b8): cosine similarity"}, {"heading": "D. Term Frequency - Document Frequency", "text": "tf.idf = N1 + log (nt) (8) \u2022 N: term frequency \u2022 nt: document frequencyE. Simple moving mean i \u2212 1 j = i \u2212 w Vjw (9) \u2022 \u00b5i: simple moving average on day i \u2022 w: moving window size in days \u2022 Vj: observable value on time series on day j\u03c3 = \u221a 1 N \u2211 i = 1 (Vi \u2212 \u00b5i) 2 (10) \u2022 \u03c3: standard deviation of time series to simple moving average \u2022 N: length of time series in days"}], "references": [{"title": "Arminer: Mining informative reviews for developers from mobile app marketplace", "author": ["N. Chen", "J. Lin", "S.C.H. Hoi", "X. Xiao", "B. Zhang"], "venue": "Proceedings of the 36th International Conference on Software Engineering, ser. ICSE 2014. New York, NY, USA: ACM, 2014, pp. 767\u2013778. [Online]. Available: http://doi.acm.org/10.1145/ 2568225.2568263", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "CoRR, vol. abs/1301.3781, 2013. [Online]. Available: http://arxiv.org/abs/1301.3781", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Some methods for classification and analysis of multivariate observations", "author": ["J. MacQueen"], "venue": "Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, vol. 1, no. 14. Oakland, CA, USA., 1967, pp. 281\u2013297.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1967}, {"title": "Why people hate your app: Making sense of user feedback in a mobile app store", "author": ["B. Fu", "J. Lin", "L. Li", "C. Faloutsos", "J. Hong", "N. Sadeh"], "venue": "Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD \u201913. New York, NY, USA: ACM, 2013, pp. 1276\u20131284. [Online]. Available: http://doi.acm.org/10.1145/2487575.2488202", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Snowball stemmer", "author": ["M. Porter", "R. Boulton"], "venue": "2001.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55\u201360. [Online]. Available: http://www.aclweb.org/anthology/P/P14/P14-5010", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Featurerich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, ser. NAACL \u201903. Stroudsburg, PA, USA: Association for Computational Linguistics, 2003, pp. 173\u2013180. [Online]. Available: http://dx.doi.org/10.3115/1073445.1073478", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res., vol. 3, pp. 993\u20131022, Mar. 2003. [Online]. Available: http://dl.acm.org/citation.cfm?id=944919.944937", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Statistical language models based on neural networks", "author": ["T. Mikolov"], "venue": "Presentation at Google, Mountain View, 2nd April, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Oehlert, A first course in design and analysis of experiments", "author": ["W. G"], "venue": "WH Freeman New York,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Probability and statistics for engineers and scientists", "author": ["R.E. Walpole", "R.H. Myers", "S.L. Myers", "K. Ye"], "venue": "Macmillan New York,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "CoRR, vol. abs/1310.4546, 2013. [Online]. Available: http://arxiv.org/abs/1310. 4546", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Introduction to information retrieval", "author": ["C.D. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": "Cambridge university press Cambridge,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "The scientist and engineer\u2019s guide to digital signal processing", "author": ["S.W. Smith"], "venue": "1997.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "A preliminary analysis of mobile app user reviews", "author": ["R. Vasa", "L. Hoon", "K. Mouzakis", "A. Noguchi"], "venue": "Proceedings of the 24th Australian Computer-Human Interaction Conference, ser. OzCHI \u201912. New York, NY, USA: ACM, 2012, pp. 241\u2013244. [Online]. Available: http://doi.acm.org/10.1145/2414536.2414577", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "An analysis of the mobile app review landscape: Trends and implications", "author": ["L. Hoon", "R. Vasa", "J.-G. Schneider", "J. Grundy"], "venue": "Tech. rep., Faculty of Information and Communication Technologies, Swinburne University of Technology, Melbourne, Australia, Tech. Rep., 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "User feedback in the appstore: An empirical study", "author": ["D. Pagano", "W. Maalej"], "venue": "Requirements Engineering Conference (RE), 2013 21st IEEE International, July 2013, pp. 125\u2013134.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "What do mobile app users complain about? a study on free ios apps", "author": ["H. Khalid", "E. Shihab", "M. Nagappan", "A. Hassan"], "venue": "2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "What are you complaining about?: a study of online reviews of mobile applications", "author": ["C. Iacob", "V. Veerappa", "R. Harrison"], "venue": "Proceedings of the 27th International BCS Human Computer Interaction Conference. British Computer Society, 2013, p. 29.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "The impact of api change- and faultproneness on the user ratings of android apps", "author": ["G. Bavota", "M. Linares-Vasquez", "C. Bernal-Cardenas", "M. Di Penta", "R. Oliveto", "D. Poshyvanyk"], "venue": "Software Engineering, IEEE Transactions on, vol. 41, no. 4, pp. 384\u2013407, April 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Identifying spam in the ios app store", "author": ["R. Chandy", "H. Gu"], "venue": "Proceedings of the 2Nd Joint WICOW/AIRWeb Workshop on Web Quality, ser. WebQuality \u201912. New York, NY, USA: ACM, 2012, pp. 56\u201359. [Online]. Available: http://doi.acm.org/10.1145/2184305. 2184317", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Analysis of user comments: An approach for software requirements evolution", "author": ["L. Galvis Carreno", "K. Winbladh"], "venue": "Software Engineering (ICSE), 2013 35th International Conference on, May 2013, pp. 582\u2013 591.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "How do users like this feature? a fine grained sentiment analysis of app reviews", "author": ["E. Guzman", "W. Maalej"], "venue": "Requirements Engineering Conference (RE), 2014 IEEE 22nd International. IEEE, 2014, pp. 153\u2013162.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Sentiment strength detection in short informal text", "author": ["M. Thelwall", "K. Buckley", "G. Paltoglou", "D. Cai", "A. Kappas"], "venue": "Journal of the American Society for Information Science and Technology, vol. 61, no. 12, pp. 2544\u20132558, 2010.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Retrieving and analyzing mobile apps feature requests from online reviews", "author": ["C. Iacob", "R. Harrison"], "venue": "Proceedings of the 10th Working Conference on Mining Software Repositories, ser. MSR \u201913. Piscataway, NJ, USA: IEEE Press, 2013, pp. 41\u201344. [Online]. Available: http://dl.acm.org/citation.cfm?id=2487085.2487094", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Text classification from labeled and unlabeled documents using em", "author": ["K. Nigam", "A.K. McCallum", "S. Thrun", "T. Mitchell"], "venue": "Machine learning, vol. 39, no. 2-3, pp. 103\u2013134, 2000.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2000}, {"title": "A recommender system of buggy app checkers for app store moderators", "author": ["M. Gomez", "R. Rouvoy", "M. Monperrus", "L. Seinturier"], "venue": "Ph.D. dissertation, Inria Lille, 2014.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "do not contain useful opinions [1].", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "This clustering task is based on Word2Vec, a distributed, vector-based representation of words [2].", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "K divides a group of keywords into smaller sub-groups of related ones by applying K-mean [3], a similarity-based clustering algorithm on the vectors representing those keywords.", "startOffset": 89, "endOffset": 92}, {"referenceID": 0, "context": "Prior works [1], [4] suggest that there are sudden changes that often happen when a new version of an app is released, which contain some defects or issues that make many users unsatisfied.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "Prior works [1], [4] suggest that there are sudden changes that often happen when a new version of an app is released, which contain some defects or issues that make many users unsatisfied.", "startOffset": 17, "endOffset": 20}, {"referenceID": 3, "context": "[4] will not suffice.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "In this kind of problem, Snowball Stemmer [5] is often used.", "startOffset": 42, "endOffset": 45}, {"referenceID": 5, "context": "Lemmatization tools such as Stanford Lemmatizer [6] may works well but it is too slow since it will try to lemmatize all words, not just Nouns and Verbs.", "startOffset": 48, "endOffset": 51}, {"referenceID": 6, "context": "Our Stemmer uses the WSJ-trained Stanford Part of Speech (PoS) tagger [7] to find PoS for each word in each sentence.", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "Simple statistical models such as topic modeling [8] can capture topics based on the frequency of a word in different documents, however, it is not intended to capture semantic regularities of words.", "startOffset": 49, "endOffset": 52}, {"referenceID": 8, "context": "Recent studies on vector-space distributed representation of words had suggested that words can have multiple degrees of similarity [9].", "startOffset": 132, "endOffset": 135}, {"referenceID": 9, "context": "This technique is relatively faster and simpler than the commonly used Skewness [10] or Pearson Correlation [11] which are widely used.", "startOffset": 80, "endOffset": 84}, {"referenceID": 10, "context": "This technique is relatively faster and simpler than the commonly used Skewness [10] or Pearson Correlation [11] which are widely used.", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "However, the vector-space distributed representations can explicitly encode many linguistic regularities, patterns and context information in many degrees, including semantic meanings [12].", "startOffset": 184, "endOffset": 188}, {"referenceID": 1, "context": "To learn those vectors, we use Word2Vec tool [2] for its scalability to expand to billions of words, opens up an opportunity for future analysis tasks of hundreds of millions reviews from multiple app stores.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "Therefore, in this work we choose K-mean Clustering Algorithm [3] to cluster the keywords into common concerns.", "startOffset": 62, "endOffset": 65}, {"referenceID": 12, "context": "We estimate such similarity using Cosine Similarity [13].", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "idf) [13] scoring.", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": "From the prior studies [1] [4], we know that sometime a new release could cause the change in occurrence of words or reviews of an app.", "startOffset": 23, "endOffset": 26}, {"referenceID": 3, "context": "From the prior studies [1] [4], we know that sometime a new release could cause the change in occurrence of words or reviews of an app.", "startOffset": 27, "endOffset": 30}, {"referenceID": 13, "context": "There are several techniques to smooth the time-series and filter out short-term noise, but the most commonly used is Simple Moving Average [14] for its simple and sufficient nature.", "startOffset": 140, "endOffset": 144}, {"referenceID": 3, "context": "2) Keywords Expanding: In this case study, we choose some words from the topics found by Wiscom [4] to expand.", "startOffset": 96, "endOffset": 99}, {"referenceID": 3, "context": "KEYWORD EXPANDING RESULTS FOR SEVERAL POPULAR TOPICS FROM WISCOM [4].", "startOffset": 65, "endOffset": 68}, {"referenceID": 14, "context": "In [15], Vasa et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "[16] analyzed nearly 8 millions reviews on Apple AppStore to discover several statistical characteristics to suggest developers constantly watching for the changes in user\u2019s expectations to adapt their apps.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "suggest that there are at least 12 types of complaints about iOS apps [18].", "startOffset": 70, "endOffset": 74}, {"referenceID": 18, "context": "Other than reviews, price and rating of apps can also affect how people provide their feedbacks, as suggested in [19] by Iacob et al.", "startOffset": 113, "endOffset": 117}, {"referenceID": 19, "context": "[20] studied the relationship between API changes and their faulty level with app ratings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[22] who proposed a classification model for spamming reviews on Apple AppStore using a simple latent model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] extract changes or additional requirements for new versions automatically using information retrieval techniques.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "More to the mining techniques, in [24], Guzman et al.", "startOffset": 34, "endOffset": 38}, {"referenceID": 7, "context": "extracts features from app reviews in form of collocations and summarizes them with Latent Dirichlet Allocation (LDA) [8] and their sentiment.", "startOffset": 118, "endOffset": 121}, {"referenceID": 23, "context": "In their work, they score the sentiment of reviews by using SentiStrength [25], which is a lexical sentiment approach.", "startOffset": 74, "endOffset": 78}, {"referenceID": 3, "context": "Another work, which is more closely related to our work, is Wiscom [4].", "startOffset": 67, "endOffset": 70}, {"referenceID": 24, "context": "Interestingly, Iacob et al [26] designed a prototype (MARA) to retrieve app feature requests from comments using a set of linguistic rules.", "startOffset": 27, "endOffset": 31}, {"referenceID": 0, "context": "One of the most recent work in extracting information from reviews is AR-Miner [1].", "startOffset": 79, "endOffset": 82}, {"referenceID": 25, "context": "They adopt the semi-supervised algorithm Expectation Maximization for Naive Bayes (EMNB) [27] to classify between informative and non-informative reviews.", "startOffset": 89, "endOffset": 93}, {"referenceID": 26, "context": "[28] developed a static error-proneness checker for app based on permissions.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "To improve user satisfaction, mobile app developers are interested in relevant user opinions such as complaints or suggestions. An important source for such opinions is user reviews on online app markets. However, manual review analysis for useful opinions is often challenging due to the large amount and the noisy-nature of user reviews. To address this problem, we propose M.A.R.K, a keyword-based framework for semiautomated review analysis. The key task of M.A.R.K is to analyze reviews for keywords of potential interest which developers can use to search for useful opinions. We have developed several techniques for that task including: 1) keyword extracting with customized regularization algorithms; 2) keyword grouping with distributed representation; and 3) keyword ranking with ratings and frequencies analysis. Our empirical evaluation and case studies show that M.A.R.K can identify keywords of high interest and provide developers with useful user opinions. Keywords\u2014App Review, Opinion Mining, Keyword", "creator": "LaTeX with hyperref package"}}}