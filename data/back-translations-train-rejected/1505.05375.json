{"id": "1505.05375", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2015", "title": "Towards Large-scale Inconsistency Measurement", "abstract": "We investigate the problem of inconsistency measurement on large knowledge bases by considering stream-based inconsistency measurement, i.e., we investigate inconsistency measures that cannot consider a knowledge base as a whole but process it within a stream. For that, we present, first, a novel inconsistency measure that is apt to be applied to the streaming case and, second, stream-based approximations for the new and some existing inconsistency measures. We conduct an extensive empirical analysis on the behavior of these inconsistency measures on large knowledge bases, in terms of runtime, accuracy, and scalability. We conclude that for two of these measures, the approximation of the new inconsistency measure and an approximation of the contension inconsistency measure, large-scale inconsistency measurement is feasible.", "histories": [["v1", "Wed, 20 May 2015 13:35:09 GMT  (36kb)", "http://arxiv.org/abs/1505.05375v1", "International Workshop on Reactive Concepts in Knowledge Representation (ReactKnow 2014), co-located with the 21st European Conference on Artificial Intelligence (ECAI 2014). Proceedings of the International Workshop on Reactive Concepts in Knowledge Representation (ReactKnow 2014), pages 63-70, technical report, ISSN 1430-3701, Leipzig University, 2014.this http URL"]], "COMMENTS": "International Workshop on Reactive Concepts in Knowledge Representation (ReactKnow 2014), co-located with the 21st European Conference on Artificial Intelligence (ECAI 2014). Proceedings of the International Workshop on Reactive Concepts in Knowledge Representation (ReactKnow 2014), pages 63-70, technical report, ISSN 1430-3701, Leipzig University, 2014.this http URL", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["matthias thimm"], "accepted": false, "id": "1505.05375"}, "pdf": {"name": "1505.05375.pdf", "metadata": {"source": "CRF", "title": "Towards Large-scale Inconsistency Measurement", "authors": ["Matthias Thimm"], "emails": ["thimm@uni-koblenz.de"], "sections": [{"heading": null, "text": "ar Xiv: 150 5.05 375v 1 [cs.A I] 2 0M ay2 015"}, {"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "2 Preliminaries", "text": "Let us be a propositional signature, i.e. a (finite) set of yardsticks, and let L (At) be the corresponding pronunciation, constructed using the usual connectives. Let K (At) be the formula of all knowledge bases. We write K instead of K (At) when there is no ambiguity about the signature. Semantics to L (At) are given by interpretations: An \u2192 true, false}. Let Int (At) specify the set of all interpretations (or is a model of) of atoms cited by the signature."}, {"heading": "3 An Inconsistency Measure based on Hitting Sets", "text": "The basic idea of our novel inconsistency is inspired by the measurement variable I\u03b7, which contains a probability function (b) that maximizes the probability of all formulas of a knowledge base (b). Basically, looking at this basic idea, one arrives at the idea that a beat rate is set for inconsistent knowledge bases. Definition 5. A subset H is called a beat rate of K if for each individual K a beat rate of K is set. Your word is called a beat rate of K if there is a beat rate of K. Your word is called a beat rate of K if there is a beat rate of K. Your word is called a beat rate of H with a beat rate of H, which is minimal. Hers is defined as the cardinality of any card number with minimum beat rate (we define hK = beat rate if there is no beat rate of K. Definition 6. The function of your: K \u2192 K) is defined above yours."}, {"heading": "4 Inconsistency Measurement in Streams", "text": "Below, we will discuss the problem of measuring inconsistency in large knowledge bases. We will address this problem by applying a flow-based approach to accessing the formulas of a large knowledge base. Formulas of a knowledge base will then have to be processed individually by a flow-based inconsistency measurement. The goal of this formalization is to obtain flow-based inconsistency measurements that approximate the given inconsistency measurements if they had been applied to the knowledge base as a whole. First, we formalize this setting and then offer concrete approaches for some inconsistency measurements."}, {"heading": "4.1 Problem Formalization", "text": "Definition 8. A statement stream S is a function S: N \u2192 L (At). Let S be the totality of all statement streams. A statement stream models a sequence of statement formulas. To a greater extent, a statement stream can also be interpreted as a very general abstraction of the output of a linked open data crawler (such as LDSpider [6]) that creeps knowledge formalized as RDF (Resource Description Framework) out of the net, enriched, for example, with OWL semantics. We model large knowledge bases by statement streams that repeat the formulas of the knowledge base indefinitely. To this end, we assume that a knowledge base K = {\u03c61,.., inspn} indicates the existence of a canonical enumeration Kc = < imfinition c, < imdefinition."}, {"heading": "4.2 A Naive Window-based Approach", "text": "e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e. e..................................................................."}, {"heading": "5 Empirical Evaluation", "text": "In this section we describe our empirical experiments on the runtime, accuracy and scalability of some stream-based inconsistency measurements. Our Java implementations4 have been added to the Tweety Libraries for Knowledge Representation [14].4 IMI, IMIc, I\u03b7, J w, g I: http: / / mthimm.de / r? r = tweety-inc-commons Ic, Ihs: http: / / mthimm.de / r? r = tweety-inc-pl Jm, g, f hs: http: / / mthimm.de / r? r = tweety-stream-hsJ m, g, f c: http: / mthimm.de / r = tweety-stream-c Evaluation framework: http: / / mthimm.de / r? r = tweety-stream-eval"}, {"heading": "5.1 Evaluated Approaches", "text": "For our evaluation, we took into account the inconsistency measures IMI, IMIc, I\u03b7, Ic and Ihs. To enumerate the MIs of a knowledge base (as required by IMI and IMIc), we used the SAT solver lingeling5 for the partial problems of determining the consistency and for calculating a model of a formula. IMI, IMIc and I\u03b7 measures were used to define three different versions of the naive window-based measure J w, gI (with w = 500, 1000, 2000 and g = max). For the measures Ic and Yours, we tested three versions of their flow variants Jm, g0.75, f1c and J m, g0.75, f1 hs (with m = 10, 100, 500) with f1: N \u2192 [0, 1] defined by f1 (i) = 1 / i (0.75, f1c and J m)."}, {"heading": "5.2 Experiment Setup", "text": "To measure the runtime of the different approaches, we created 100 random knowledge bases in CNF (conjunctive normal form), each with 5000 formulas (= disjunctions) and 30 theses. For each generated knowledge base K, we looked at their K-stream and the processing of the stream was interrupted after 40,000 iterations. We fed the K-stream to each of the evaluated stream-based inconsistency measurements and measured the average runtime per iteration and the total runtime. For each iteration, we set a timeout of 2 minutes and stopped processing the stream completely when a timeout occurred. To measure the accuracy, we created another 100 random knowledge bases for each of the considered approaches with specifically specified inconsistency values 8, otherwise we used the same settings as above and measured the returned inconsistency values. To measure the scalability of our stream-based approach, we evaluated by a third."}, {"heading": "5.3 Results", "text": "For the first time in a long time, I have been able to do this for the first time in my life, and I have been able to do it for the first time. I have been able to do it for the first time, and I have been able to do it for the last few years. I have been able to do it for the first time. I have been able to do it for the first time, and I have been able to do it for the first time. I have been able to do it for the last few years, and I have been able to do it for the first time. I have been able to do it for the last few years, and I have been able to do it for the first time. I have been able to do it for the first time, and I have been able to do it for the first time."}, {"heading": "6 Discussion and Conclusion", "text": "In this paper, we discussed the problem of large-scale inconsistency measurement and proposed novel approximation algorithms that are effective for the streaming case. To our knowledge, the computational problems of measuring inconsistency, especially in terms of scalability issues, have not yet been addressed in literature, with the exception of the work of Ma and colleagues [10], who always present an algorithm that approaches inconsistency measurement based on a 4-rated paraconsistent logic (similar to inconsistency measurement), but the main difference between our framework and the algorithm of [10] is that it must process the entire knowledge base at each atomic step and therefore is not directly applicable to the streaming scenario. Empirical evaluation [10] suggests that our streaming variant of Ihs is much more powerful than a Met report with a larger time base of 240 seconds and is not immediately applicable to the streaming scenario."}, {"heading": "A Proofs of technical results", "text": "Proposition 1: The function of yours is a (basic) measurement of inconsistency. Proof. We must show that properties (1.), 2.) and 3.) of definition 3 are satisfactory. 1. If K is consistent, there is a formula in which we always hK > 1. Leave K \u00b2 and let H = \"minimal.\" So H = \"minimal\" is a set of cards of K. \"Then H is also a set of cards of K\" (not necessarily a set of one). Therefore, we have hK \u00b2 and Him (K) \u2264 Him. \"3. Leave\" free \"(K) and define\" minimal. \"H\" a set of cards of K. \"Leave H a set of cards of K\" minimal. \""}], "references": [{"title": "Distance-based Measures of Inconsistency", "author": ["J. Grant", "A. Hunter"], "venue": "Proceedings of the 12th Europen Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU\u201913), pp. 230\u2013241, ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Measuring inconsistency in knowledgebases", "author": ["John Grant", "Anthony Hunter"], "venue": "Journal of Intelligent Information Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Measuring consistency gain and information loss in stepwise inconsistency resolution", "author": ["John Grant", "Anthony Hunter"], "venue": "Proc. of the 11th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "A Textbook of Belief Dynamics", "author": ["S.O. Hansson"], "venue": "Kluwer Academic Publishers", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "On the measure of conflicts: Shapley inconsistency values", "author": ["Anthony Hunter", "Sebastien Konieczny"], "venue": "Artificial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "LDSpider: An open-source crawling framework for the web of linked data", "author": ["Robert Isele", "J\u00fcrgen Umbrich", "Chris Bizer", "Andreas Harth"], "venue": "Proceedings of 9th International Semantic Web Conference (ISWC", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Inconsistency measurement thanks to mus decomposition", "author": ["Said Jabbour", "Yue Ma", "Badran Raddaoui"], "venue": "Proc. of the 13th Int. Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "A Theory of Inconsistency", "author": ["Kevin M. Knight"], "venue": "Ph.D. dissertation, University Of Manchester,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Genetic Algorithms and Simulated Annealing", "author": ["D. Lawrence"], "venue": "Pitman Publishing", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1987}, {"title": "An anytime algorithm for computing inconsistency measurement", "author": ["Yue Ma", "Guilin Qi", "Guohui Xiao", "Pascal Hitzler", "Zuoquan Lin"], "venue": "in Knowledge Science, Engineering and Management,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Bridges from Classical to Nonmonotonic Logic", "author": ["D. Makinson"], "venue": "College Publications", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Logic of Paradox", "author": ["G. Priest"], "venue": "Journal of Philosophical Logic, 8, 219\u2013 241, ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1979}, {"title": "Inconsistency measures for probabilistic logics", "author": ["Matthias Thimm"], "venue": "Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "Inconsistency measurement [2] is a subfield of Knowledge Representation and Reasoning (KR) that is concerned with the quantitative assessment of the severity of inconsistencies in knowledge bases.", "startOffset": 26, "endOffset": 29}, {"referenceID": 10, "context": "In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4].", "startOffset": 119, "endOffset": 127}, {"referenceID": 11, "context": "In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4].", "startOffset": 119, "endOffset": 127}, {"referenceID": 3, "context": "In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4].", "startOffset": 201, "endOffset": 204}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "To this end we present a novel inconsistency measure Ihs that approximates the \u03b7-inconsistency measure from [8] and is particularly apt to be applied to large knowledge bases.", "startOffset": 108, "endOffset": 111}, {"referenceID": 7, "context": "We present a novel inconsistency measure Ihs based on hitting sets and show how this measure relates to other measures and, in particular, that it is a simplification of the \u03b7-inconsistency measure [8] (Section 3).", "startOffset": 198, "endOffset": 201}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8, 10, 1, 2, 5, 13].", "startOffset": 0, "endOffset": 20}, {"referenceID": 9, "context": "[8, 10, 1, 2, 5, 13].", "startOffset": 0, "endOffset": 20}, {"referenceID": 0, "context": "[8, 10, 1, 2, 5, 13].", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "[8, 10, 1, 2, 5, 13].", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "[8, 10, 1, 2, 5, 13].", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "[8, 10, 1, 2, 5, 13].", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "There are two main paradigms for assessing inconsistency [5], the first being based on the (number of) formulas needed to produce inconsistencies and the second being based on the proportion of the language that is affected by the inconsistency.", "startOffset": 57, "endOffset": 60}, {"referenceID": 2, "context": "We adopt the following definition of a (basic) inconsistency measure from [3].", "startOffset": 74, "endOffset": 77}, {"referenceID": 2, "context": "[3, 8].", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "[3, 8].", "startOffset": 0, "endOffset": 6}, {"referenceID": 11, "context": "In order to define the contension measure Ic we need to consider three-valued interpretations for propositional logic [12].", "startOffset": 118, "endOffset": 122}, {"referenceID": 7, "context": "For defining the \u03b7-inconsistency measure [8] we need to consider probability functions P of the form P : Int(At) \u2192 [0, 1] with", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "For defining the \u03b7-inconsistency measure [8] we need to consider probability functions P of the form P : Int(At) \u2192 [0, 1] with", "startOffset": 115, "endOffset": 121}, {"referenceID": 1, "context": "[2, 3, 8] and for some recent developments see e.", "startOffset": 0, "endOffset": 9}, {"referenceID": 2, "context": "[2, 3, 8] and for some recent developments see e.", "startOffset": 0, "endOffset": 9}, {"referenceID": 7, "context": "[2, 3, 8] and for some recent developments see e.", "startOffset": 0, "endOffset": 9}, {"referenceID": 0, "context": "[1, 7].", "startOffset": 0, "endOffset": 6}, {"referenceID": 6, "context": "[1, 7].", "startOffset": 0, "endOffset": 6}, {"referenceID": 11, "context": "Table 1 Truth tables for propositional three-valued logic [12].", "startOffset": 58, "endOffset": 62}, {"referenceID": 4, "context": "The result below shows that Ihs also behaves well with some more properties mentioned in the literature [5, 13].", "startOffset": 104, "endOffset": 111}, {"referenceID": 12, "context": "The result below shows that Ihs also behaves well with some more properties mentioned in the literature [5, 13].", "startOffset": 104, "endOffset": 111}, {"referenceID": 5, "context": "On a wider scope, a propositional stream can also be interpreted as a very general abstraction of the output of a linked open data crawler (such as LDSpider [6]) that crawls knowledge formalized as RDF (Resource Description Framework) from the web, enriched, e.", "startOffset": 157, "endOffset": 160}, {"referenceID": 0, "context": ", the maximum function max or a smoothing function g\u03b1(x, y) = \u03b1x + (1 \u2212 \u03b1)y for some \u03b1 \u2208 [0, 1] (for every x, y \u2208 [0,\u221e)).", "startOffset": 89, "endOffset": 95}, {"referenceID": 8, "context": "The approximation algorithms for Ihs and Ic that are presented in this subsection are using concepts of the programming paradigms of simulated annealing and genetic programming [9].", "startOffset": 177, "endOffset": 180}, {"referenceID": 0, "context": "Let m \u2208 N, g some function g : [0,\u221e)\u00d7 [0,\u221e) \u2192 [0,\u221e) with g(x, y) \u2208 [min{x, y},max{x, y}], and f : N \u2192 [0, 1] some monotonically decreasing function with limn\u2192\u221e f(n) = 0.", "startOffset": 102, "endOffset": 108}, {"referenceID": 0, "context": "3: newV alue = 0 4: for all C \u2208 Cand do 5: rand \u2208 [0, 1] 6: if rand < f(N) then 7: Remove some random \u03c9 from C 8: if \u00ac\u2203\u03c9 \u2208 C : \u03c9 |= form then 9: Add random \u03c9 \u2208 Mod(form) to C", "startOffset": 50, "endOffset": 56}, {"referenceID": 0, "context": "For every probability p \u2208 [0, 1), g some function g : [0,\u221e)\u00d7 [0,\u221e) \u2192 [0,\u221e) with g(x, y) \u2208 [min{x, y},max{x, y}] and g(x, y) > min{x, y} if x 6= y, a monotonically decreasing function f : N \u2192 [0, 1] with limn\u2192\u221e f(n) = 0, and K \u2208 K there is m \u2208 N such that with probability greater or equal p it is the case that", "startOffset": 191, "endOffset": 197}, {"referenceID": 0, "context": "75 ,f1 hs (with m = 10, 100, 500) with f1 : N \u2192 [0, 1] defined via f1(i) = 1/(i + 1) for all i \u2208 N and g0.", "startOffset": 48, "endOffset": 54}, {"referenceID": 9, "context": "One exception is the work by Ma and colleagues [10] who present an anytime algorithm that approximates an inconsistency measure based on a 4-valued paraconsistent logic (similar to the contension inconsistency measure).", "startOffset": 47, "endOffset": 51}, {"referenceID": 9, "context": "The main difference between our framework and the algorithm of [10] is that the latter needs to process the whole knowledge base in each atomic step and is therefore not directly applicable for the streaming scenario.", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "The empirical evaluation [10] also suggests that our streaming variant of Ihs is much more performant as Ma et al.", "startOffset": 25, "endOffset": 29}, {"referenceID": 5, "context": "Current and future work is about the application of our work on linked open data sets [6].", "startOffset": 86, "endOffset": 89}], "year": 2017, "abstractText": "We investigate the problem of inconsistency measurement on large knowledge bases by considering stream-based inconsistency measurement, i. e., we investigate inconsistency measures that cannot consider a knowledge base as a whole but process it within a stream. For that, we present, first, a novel inconsistency measure that is apt to be applied to the streaming case and, second, stream-based approximations for the new and some existing inconsistency measures. We conduct an extensive empirical analysis on the behavior of these inconsistency measures on large knowledge bases, in terms of runtime, accuracy, and scalability. We conclude that for two of these measures, the approximation of the new inconsistency measure and an approximation of the contension inconsistency measure, large-scale inconsistency measurement is feasible.", "creator": "LaTeX with hyperref package"}}}