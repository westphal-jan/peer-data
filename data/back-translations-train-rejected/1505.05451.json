{"id": "1505.05451", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2015", "title": "Fuzzy Least Squares Twin Support Vector Machines", "abstract": "Least Squares Twin Support Vector Machine (LSTSVM) is an extremely efficient and fast version of SVM algorithm for binary classification. LSTSVM combines the idea of Least Squares SVM and Twin SVM in which two non-parallel hyperplanes are found by solving two systems of linear equations. Although, the algorithm is very fast and efficient in many classification tasks, it is unable to cope with two features of real-world problems. First, in many real-world classification problems, it is almost impossible to assign data points to a single class. Second, data points in real-world problems may have different importance. In this study, we propose a novel version of LSTSVM based on fuzzy concepts to deal with these two characteristics of real-world data. The algorithm is called Fuzzy LSTSVM (FLSTSVM) which provides more flexibility than binary classification of LSTSVM. Two models are proposed for the algorithm. In the first model, a fuzzy membership value is assigned to each data point and the hyperplanes are optimized based on these fuzzy samples. In the second model we construct fuzzy hyperplanes to classify data. Finally, we apply our proposed FLSTSVM to an artificial as well as three real-world datasets. Results demonstrate that FLSTSVM obtains better performance than SVM and LSTSVM.", "histories": [["v1", "Wed, 20 May 2015 16:57:02 GMT  (1439kb,D)", "http://arxiv.org/abs/1505.05451v1", null], ["v2", "Fri, 22 Jul 2016 08:59:40 GMT  (10356kb,D)", "http://arxiv.org/abs/1505.05451v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["javad salimi sartakhti", "nasser ghadiri", "homayun afrabandpey", "narges yousefnezhad"], "accepted": false, "id": "1505.05451"}, "pdf": {"name": "1505.05451.pdf", "metadata": {"source": "CRF", "title": "Fuzzy Least Squares Twin Support Vector Machines", "authors": ["Javad Salimi Sartakhtia", "Nasser Ghadiri", "Homayun Afrabandpey", "Narges Yousefnezhad"], "emails": ["j.salimi@ec.iut.ac.ir"], "sections": [{"heading": null, "text": "Finally, the Least Squares Twin Support Vector Machine (LSTSVM) is an extremely efficient and fast version of the SVM binary classification algorithm. LSTSVM combines the idea of the Least Squares SVM and Twin SVM, in which two non-parallel hyperplanes are found by solving two systems of linear equations. Although the algorithm is very fast and efficient in many classification tasks, it is not able to solve two features of real problems. Firstly, in many real-world classification problems, it is almost impossible to assign data points to a single class. Secondly, data points can have a different meaning in real-world problems. In this study, we propose a novel version of LSTSVM, which relies on fuzzy concepts to deal with these two properties of real data. The algorithm is called Fuzzy LSTSVM (FLSTSVM), which offers more flexibility than binary classification of LSTM. Two models are proposed for the algorithm."}, {"heading": "1. Inroduction", "text": "In fact, most of them will be able to hold their own."}, {"heading": "2. Basic Concepts", "text": "This section gives a brief overview of different versions of SVM, namely the standard SVM, TSVM and LSTSVM versions."}, {"heading": "2.1. Support Vector Machine", "text": "Suppose we get a set of training data points xi-Rd, i = 1, \u00b7 \u00b7 \u00b7, n with the caption yi-1, + 1}. SVM looks for a hyperplane with equation w.x + b = 0 with the following constraints: yi (w.xi + b) \u2265 1, \u0418i. (1), where w is the weight vector. Such a hyperplane could be achieved by solving Equation (2): Minimize f (x) = \u0418w-22 (2) is subject to yi (w.xi + b) \u2212 1 \u2265 0The geometric interpretation of this formulation is shown in Figure 1 for a toy example."}, {"heading": "2.2. Twin Support Vector Machine", "text": "In SVM, only one hyperplane is the task of dividing the samples into two groups of positive and negative classes. (2007) The most important equations of the TSVM are: xiw (1) + b (1) = 0 (3) xiw (2) + b (2) = 0where w (i) and b (i) are the weight vector and the bias term of the ith hyperplane. Each hyperplane represents the samples of its class. This concept is shown geometrically in Figure 2 for a toy example. In TSVM, the two hyperplanes are not parallel, and each of them is the closest and furthest away from the samples of its own class."}, {"heading": "2.3. Least Squares Twin Support Vector Machine", "text": "LSTSVM [6, 21] is a binary classifier that combines the idea of LSSVM and TSVM. In other words, LSTSVM uses the smallest error squares to modify the inequality constraints in TSVM to equality constraints and solves a series of linear equations instead of two square programming problems (QPPs). Experiments have shown that LSTSVM can significantly shorten the training time while maintaining the accuracy of the classification [7, 22]. Since the time complexity of SVM is order m3, where m is the number of constraints, theoretically, with the same number of positive and negative samples, the speed of the algorithm increases by a factor of four compared to the standard SVM.LSTSVM finds its hyperplanes (SVM) by having Eq. (6) and Eq. (7), which are linear solvable."}, {"heading": "3. Fuzzy Least Squares Twin Support Vector Machine", "text": "In this section we will first explain the importance of fuzzy classification and then present two approaches to improving LSTSVM using fuzzy set theory. Basic notations used in this section are as follows: samples of positive and negative classes are represented by matrices A and B. A contains m1 positive samples and B contains m2 negative samples. Membership degrees are represented by \u00b5 and slip variables by vectors. All equations are represented in matrix form, with each matrix M representing its transposition by MT. e is a vector of arbitrary size and all its elements are equal to 1."}, {"heading": "3.1. Fuzzy Classification", "text": "In many real-world applications, a sample in the training data does not belong exactly to a single class. Furthermore, in some applications, it would be desirable for the new training samples to have a higher significance than older ones. Given the uncertainty of assigning such values, the blurred sentences provide an elegant way to address this problem. We can define a blurred membership level \u00b5i for each sample in the training data. Membership level is a number between 0 and 1 that can be considered a measure of the impact of the sample on the last class. Therefore, a training sample with a membership level \u00b5i influences class + 1 by \u00b5i and influences class \u2212 1 by (1 \u2212 \u00b5i). Furthermore, by using blurred membership functions, it is possible to assign a membership level to each sample based on its entry time. Sequential learning [23] is another application that causes blurred concepts to be applied in classification algorithms such as SVM. In 2008, Peywomo introduced a 2-year SVM in its work."}, {"heading": "3.2. Fuzzy LSTSVM: Model M1", "text": "Our goal is to construct two crystal-clear hyperplanes to distinguish target classes. (11): To use this model in LSTSVM algorithm, we have Eq. (6) and Eq. (7) in the form of Eq. (10) and Eq. (11): Minimize J1 = 12 (Aw (1) + Eb (1) T (Aw (1) + Eb (1) + TB (7) in the form of Eq. (10) and Eq. (11): Minimize J1 = 12 (Aw (1) + Eb (1)) + Eb (1) T (1))) + \u00b5T (1) + \u00b5T (1) 2 \u00b5T (10)."}, {"heading": "3.3. Fuzzy LSTSVM: Model M2", "text": "In this model, we construct fuzzy hyperplanes to distinguish the classes. < < < < < all the parameters of the model (even the components of the weight vector w, are fuzzy numbers. < < < < < all the parameters used in this thesis are limited to a class of \"triangular\" symmetrical membership functions. (For a symmetrical triangular (triangular) triangular number X = (o, r), o is the center and r the width of the corresponding membership function. Let's assume that W and B are the fuzzy weight vector and fuzzy bias term, with each component of the W term represented by Wi = (wi, ci) and B = (b, d). Then, the equation of a fuzzy hyperplane is defined as follows: W.x + B = < w1, c1 >.x1 + \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 ltn, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 n."}, {"heading": "4. Numerical Experiments", "text": "All experiments are performed in the environment of Matlab 7.9 (R2009b) on a PC with Intel processor (2.9 GHz) with 2 GB RAM. Accuracy used to evaluate a classifier is defined as: (TP + TN) / (TP + FP + TN + FN), where TP, TN, FP and FN are the number of true positive, true negative, false positive and false negative values. Accuracy is also measured using the standard 10-fold cross-validation method [24]. In our implementation, we focus on comparing SVM, LSTSVM and FLSTSVM with model M2."}, {"heading": "4.1. Experiment on Artificial Dataset", "text": "We first consider a two-dimensional \"Xor\" dataset, which is a very common dataset for evaluating the effectiveness of SVM-based algorithms, shown in Fig. 3. This handmade dataset consists of 132 datasets belonging to two classes. Each dataset has two characteristics: a class and a value that determines how much the dataset belongs to the class. Red circles denote the data points of the positive class, while blue circles belong to the negative class.Table 1 shows the results of applying SVM, LSTSVM and FLSTSVM algorithms to the dataset. It should be noted that in this paper only the linear version of all three algorithms is examined, and the obtained values for the accuracy of all three algorithms are fully justifiable. In SVM, there is only one hyperlevel that is responsible for classifying this data, and because the dataset is defined as two-dimensional space, this hyper level has a line that SVM is responsible for two lines in Fig 4a. SVM is shown in Fig 4a."}, {"heading": "4.2. Experiments on Benchmark Datasets", "text": "We also conducted experiments with a collection of four benchmark data sets from the UCI Machine Learning Repository [25], which are Heart-Statlog, Australian Credit Approval, Liver Disorder and Breast Cancer Wisconsin. These data sets represent a wide range of size (from 198 to 690) and characteristics (from 7 to 34), and details of the four data sets are listed in Table 2. Also, Table 3 lists the results of each algorithm. As history shows, FLSTSVM has higher accuracy than the other two algorithms. It should be noted that these experiments only take into account the linear version of the FLSTSVM (and so for the other two algorithms). We maintain that the non-linear version of the proposed algorithm would surpass the non-linear version of SVM and LSTSVM with more significant differences."}, {"heading": "5. Conclusion", "text": "In the first model, M1, each input point was assigned a fuzzy membership and the hyperplanes were optimized based on the fuzzy weights of the samples. In the second model, M2, all parameters to be identified in LSTSVM are considered fuzzy. Also, to distinguish the target class in M2, we construct two fuzzy hyperplanes. We conducted a series of experiments to analyze our classifier against SVM and LSTSVM. Results show that FLSTSVM achieves better accuracy than the other two algorithms. As our future work, we will focus on the non-linear version of Fuzzy LSTSVM."}], "references": [{"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine learning 20 (3) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Text categorization with support vector machines: Learning with many relevant features", "author": ["T. Joachims"], "venue": "Springer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Vision-based rock-type classification of limestone using multi-class support vector machine", "author": ["S. Chatterjee"], "venue": "Applied Intelligence 39 (1) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Gene selection for cancer classification using support vector machines", "author": ["I. Guyon", "J. Weston", "S. Barnhill", "V. Vapnik"], "venue": "Machine learning 46 (1-3) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Hepatitis disease diagnosis using a novel hybrid method based on support vector machine and simulated annealing (svm-sa)", "author": ["J.S. Sartakhti", "M.H. Zangooei", "K. Mozafari"], "venue": "Computer methods and programs in biomedicine 108 (2) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Least squares twin support vector machines for pattern classification", "author": ["M. Arun Kumar", "M. Gopal"], "venue": "Expert Systems with Applications 36 (4) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Least squares support vector machine classifiers", "author": ["J.A. Suykens", "J. Vandewalle"], "venue": "Neural processing letters 9 (3) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "S", "author": ["R. Khemchandani"], "venue": "Chandra, et al., Twin support vector machines for pattern classification, Pattern Analysis and Machine Intelligence, IEEE Transactions on 29 (5) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "The concept of a linguistic variable and its application to approximate reasoningi", "author": ["L.A. Zadeh"], "venue": "Information sciences 8 (3) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1975}, {"title": "Operations on fuzzy numbers", "author": ["D. Dubois", "H. Prade"], "venue": "International Journal of systems science 9 (6) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1978}, {"title": "On solving fuzzy mathematical relationships", "author": ["R.R. Yager"], "venue": "Information and Control 41 (1) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1979}, {"title": "Fuzzy sets and systems: theory and applications", "author": ["D.J. Dubois"], "venue": "Vol. 144, Academic press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1980}, {"title": "Fuzzy support vector machines for pattern classification", "author": ["T. Inoue", "S. Abe"], "venue": "in: Neural Networks, 2001. Proceedings. IJCNN\u201901. International Joint Conference on, Vol. 2, IEEE", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "Fuzzy support vector machines", "author": ["C.-F. Lin", "S.-D. Wang"], "venue": "Neural Networks, IEEE Transactions on 13 (2) ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Fuzzy rule extraction from support vector machines", "author": ["A.C. Chaves", "M.M.B. Vellasco", "R. Tanscheit"], "venue": "in: Hybrid Intelligent Systems, 2005. HIS\u201905. Fifth International Conference on, IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Interval type-2 fuzzy weighted support vector machine learning for energy efficient biped walking", "author": ["L. Wang", "Z. Liu", "C. Chen", "Y. Zhang"], "venue": "Applied Intelligence 40 (3) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Fuzzy one-class support vector machines", "author": ["P.-Y. Hao"], "venue": "Fuzzy Sets and Systems 159 (18) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Sparse least square twin support vector machine with adaptive norm", "author": ["Z. Zhang", "L. Zhen", "N. Deng", "J. Tan"], "venue": "Applied Intelligence 41 (4) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "An overview on twin support vector machines", "author": ["S. Ding", "J. Yu", "B. Qi", "H. Huang"], "venue": "Artificial Intelligence Review 42 (2) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Least squares recursive projection twin support vector machine for classification", "author": ["Y.-H. Shao", "N.-Y. Deng", "Z.-M. Yang"], "venue": "Pattern Recognition 45 (6) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "1-norm least squares twin support vector machines", "author": ["S. Gao", "Q. Ye", "N. Ye"], "venue": "Neurocomputing 74 (17) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Sequence learning", "author": ["B.A. Clegg", "G.J. DiGirolamo", "S.W. Keele"], "venue": "Trends in cognitive sciences 2 (8) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1998}, {"title": "Pattern classification", "author": ["R.O. Duda", "P.E. Hart", "D.G. Stork"], "venue": "John Wiley & Sons", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "It is a kernel-based classifier which was first introduced in 1995 by Vapnik and his colleagues, at AT&T Bell Laboratories [1].", "startOffset": 123, "endOffset": 126}, {"referenceID": 1, "context": "Some of these tasks are: text classification [2], image classification [3], and bioinformatics [4, 5].", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "Some of these tasks are: text classification [2], image classification [3], and bioinformatics [4, 5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 3, "context": "Some of these tasks are: text classification [2], image classification [3], and bioinformatics [4, 5].", "startOffset": 95, "endOffset": 101}, {"referenceID": 4, "context": "Some of these tasks are: text classification [2], image classification [3], and bioinformatics [4, 5].", "startOffset": 95, "endOffset": 101}, {"referenceID": 5, "context": "One of the newest versions of SVM is Least Squares Twin Support Vector Machine (LSTSVM) introduced in 2009 [6].", "startOffset": 107, "endOffset": 110}, {"referenceID": 6, "context": "The algorithm combines the idea of Least Squares SVM (LSSVM) [7] and Twin SVM (TSVM) [8].", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "The algorithm combines the idea of Least Squares SVM (LSSVM) [7] and Twin SVM (TSVM) [8].", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "Although, in some classification tasks LSTSVM provides high accuracies [6] it still suffers from two main drawbacks.", "startOffset": 71, "endOffset": 74}, {"referenceID": 8, "context": "In the literature, the concepts of fuzzy function and fuzzy operations are introduced by different researchers [9, 10, 11, 12, 13].", "startOffset": 111, "endOffset": 130}, {"referenceID": 9, "context": "In the literature, the concepts of fuzzy function and fuzzy operations are introduced by different researchers [9, 10, 11, 12, 13].", "startOffset": 111, "endOffset": 130}, {"referenceID": 10, "context": "In the literature, the concepts of fuzzy function and fuzzy operations are introduced by different researchers [9, 10, 11, 12, 13].", "startOffset": 111, "endOffset": 130}, {"referenceID": 11, "context": "In the literature, the concepts of fuzzy function and fuzzy operations are introduced by different researchers [9, 10, 11, 12, 13].", "startOffset": 111, "endOffset": 130}, {"referenceID": 12, "context": "In the literature several approaches of applying fuzzy sets in SVM have been proposed [14, 15, 16, 17, 18].", "startOffset": 86, "endOffset": 106}, {"referenceID": 13, "context": "In the literature several approaches of applying fuzzy sets in SVM have been proposed [14, 15, 16, 17, 18].", "startOffset": 86, "endOffset": 106}, {"referenceID": 14, "context": "In the literature several approaches of applying fuzzy sets in SVM have been proposed [14, 15, 16, 17, 18].", "startOffset": 86, "endOffset": 106}, {"referenceID": 15, "context": "In the literature several approaches of applying fuzzy sets in SVM have been proposed [14, 15, 16, 17, 18].", "startOffset": 86, "endOffset": 106}, {"referenceID": 16, "context": "In the literature several approaches of applying fuzzy sets in SVM have been proposed [14, 15, 16, 17, 18].", "startOffset": 86, "endOffset": 106}, {"referenceID": 7, "context": "[8] proposed TSVM with the idea of using two hyperplanes in which samples are assigned to a class according to their distance from the hyperplanes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "Each of them is closest to the samples of its own class and farthest from the samples of the opposite class [19, 20].", "startOffset": 108, "endOffset": 116}, {"referenceID": 18, "context": "Each of them is closest to the samples of its own class and farthest from the samples of the opposite class [19, 20].", "startOffset": 108, "endOffset": 116}, {"referenceID": 5, "context": "Least Squares Twin Support Vector Machine LSTSVM [6, 21] is a binary classifier which combines the idea of LSSVM and TSVM.", "startOffset": 49, "endOffset": 56}, {"referenceID": 19, "context": "Least Squares Twin Support Vector Machine LSTSVM [6, 21] is a binary classifier which combines the idea of LSSVM and TSVM.", "startOffset": 49, "endOffset": 56}, {"referenceID": 6, "context": "Experiments have shown that LSTSVM can considerably reduce the training time, while preserving competitive classification accuracy [7, 22].", "startOffset": 131, "endOffset": 138}, {"referenceID": 20, "context": "Experiments have shown that LSTSVM can considerably reduce the training time, while preserving competitive classification accuracy [7, 22].", "startOffset": 131, "endOffset": 138}, {"referenceID": 21, "context": "Sequential learning [23] is another application which induces applying fuzzy concepts in classification algorithms such as SVM.", "startOffset": 20, "endOffset": 24}, {"referenceID": 16, "context": "In 2008 Pei-Yi Hao introduced fuzzy SVM [18].", "startOffset": 40, "endOffset": 44}, {"referenceID": 16, "context": "In the following sections, we integrated the fuzzy set theory into the LSTSVM algorithm in accordance with [18].", "startOffset": 107, "endOffset": 111}, {"referenceID": 22, "context": "Also the accuracies are measured by the standard 10-fold cross-validation methodology [24].", "startOffset": 86, "endOffset": 90}], "year": 2017, "abstractText": "Least Squares Twin Support Vector Machine (LSTSVM) is an extremely efficient and fast version of SVM algorithm for binary classification. LSTSVM combines the idea of Least Squares SVM and Twin SVM in which two nonparallel hyperplanes are found by solving two systems of linear equations. Although, the algorithm is very fast and efficient in many classification tasks, it is unable to cope with two features of real-world problems. First, in many realworld classification problems, it is almost impossible to assign data points to a single class. Second, data points in real-world problems may have different importance. In this study, we propose a novel version of LSTSVM based on fuzzy concepts to deal with these two characteristics of real-world data. The algorithm is called Fuzzy LSTSVM (FLSTSVM) which provides more flexibility than binary classification of LSTSVM. Two models are proposed for the algorithm. In the first model, a fuzzy membership value is assigned to each data point and the hyperplanes are optimized based on these fuzzy samples. In the second model we construct fuzzy hyperplanes to classify data. Finally, we apply our proposed FLSTSVM to an artificial as well as three real-world datasets. Results demonstrate that FLSTSVM obtains better performance than SVM and LSTSVM.", "creator": "TeX"}}}