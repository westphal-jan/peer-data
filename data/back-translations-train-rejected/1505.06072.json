{"id": "1505.06072", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2015", "title": "Diffusion Methods for Classification with Pairwise Relationships", "abstract": "We define two algorithms for propagating information in classification problems with pairwise relationships. The algorithms involve contraction maps and are related to non-linear diffusion and random walks on graphs. The approach is also related to message passing and mean field methods. The algorithms we describe are guaranteed to converge on graphs with arbitrary topology. Moreover they always converge to a unique fixed point, independent of initialization. We prove that the fixed points of the algorithms under consideration define lower-bounds on the energy function and the max-marginals of a Markov random field. Our theoretical results also illustrate a relationship between message passing algorithms and value iteration for an infinite horizon Markov decision process. We illustrate the practical feasibility of our algorithms with preliminary experiments in image restoration and stereo depth estimation.", "histories": [["v1", "Fri, 22 May 2015 13:36:58 GMT  (426kb,D)", "https://arxiv.org/abs/1505.06072v1", null], ["v2", "Mon, 3 Aug 2015 14:37:37 GMT  (426kb,D)", "http://arxiv.org/abs/1505.06072v2", "author information updated"], ["v3", "Tue, 22 Dec 2015 14:10:08 GMT  (476kb,D)", "http://arxiv.org/abs/1505.06072v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["pedro f felzenszwalb", "benar f svaiter"], "accepted": false, "id": "1505.06072"}, "pdf": {"name": "1505.06072.pdf", "metadata": {"source": "CRF", "title": "Diffusion Methods for Classification with Pairwise Relationships", "authors": ["Pedro F. Felzenszwalb", "Benar F. Svaiter"], "emails": ["pff@brown.edu", "benar@impa.br"], "sections": [{"heading": null, "text": "We define two algorithms for the dissemination of information in classification problems with paired relationships. The algorithms are based on contraction maps and are related to non-linear diffusion and random walks on graphs. The approach is also related to message-pass algorithms, including belief propagation and medium field methods. The algorithms we describe are guaranteed to converge with graphs with arbitrary topology. In addition, they always converge to a unique fixed point, regardless of initialization. We prove that the fixed points of the considered algorithms define lower limits of energy function and maximum margins of a Markov random field. Theoretical results also illustrate a relationship between measurement-pass algorithms and value attribution for an infinite horizon Markov decision process. We illustrate the practical application of the investigated algorithms with numerical experiments for image jamming, classification and depth estimation on a sterbineo."}, {"heading": "1 Introduction", "text": "In many classification problems, there are relationships between a number of objects that need to be classified. For example, in image reconstruction, problems with adjacent pixels are likely to belong to the same object or image segment, resulting in relationships between the captions of different pixels in an image. Energy minimization methods based on Markov Random Fields (MRF) address these problems in a common framework [4, 23, 15]. Within this framework, we introduce two new algorithms for classification with paired information. These algorithms are based on contraction maps and refer to nonlinear diffusion and random walks on diagrams. The setting to consider is as follows. Let G = (V, E) be an undirected simple graph and L be a set of captions. A captioning of V is a function x: V \u2192 L is the assignment of a label from L to each vertex."}, {"heading": "1.1 Basic Definitions and Overview of Results", "text": "It is as if it is a disordered, simple, connected graph that we can solve a problem with if we have a non-negative cost-benefit ratio for mapping to a vertex. (D) These costs capture local information about the labeling of each vertex. (D) We have a non-negative cost-benefit ratio for mapping to a vertex. (D) These costs capture local information about the labeling of each vertex. (D) We have a non-negative cost label for mapping to a vertex i and a label b to a vertex j j that is equally denoted by hij (a) or hji (b). (D) These costs capture relationships between the labels of neighboring vertices.gi"}, {"heading": "1.2 Examples", "text": "Figure 1 shows two examples of fixed points of T, if the graph G = (V, E) is a cycle with 5 vertices. In this case, we have a binary identification problem L = {1, 2}. The local costs are all zero, except that the vertex 1 has a preference for identification 2. This is encoded by costs for identification 1, g1 (1) = 1, (13) g1 (2) = 0, (14) gi (a) = 0, (6 = 1, a). (15) In the example (a) we have pair costs that promote the same identifiers for adjacent vertices, hij (a, b) = 0 a = b1 a = 6 = b, (16) In the example (b) we have pair costs that promote different identifiers for adjacent vertices, hij (a, b) = 1 a = b0 a = 6 = b, (17) Figure 1 shows a graph of the local costs for each vertice."}, {"heading": "1.3 Related Work", "text": "For general graphs G, if the paired costs hij (a, b) define a metric q over L, there are polynomial time approximation algorithms for the optimization problem defined by F [14]. In some important cases, the optimization problem can be solved with the help of graph sections and maximum flow algorithms [13, 8, 7, 17], including in particular the case of the MAP estimate for an Ising model with an external field [13]. The algorithms we study are closely related to methods of message transmission, especially with Mining (or equivalent max product) Faith propagation (BP) [23, 15]. If graph G is a tree, BP converts and solves the optimization problem defined by F. Unfortunately, BP is not guaranteed to have convergence and it may have multiple fixed points for general graphs. Some forms of attenuation may help BP to convert the Min-BP algorithm to a simple sum of convergence that will provide a unique alternative to the practice of studying the algorithm BP."}, {"heading": "2 Preliminaries", "text": "The algorithms we are investigating are efficient in the following sense. Let m = | E | and k = | L |. Each iteration in the fixed-point algorithm involves the evaluation of T or S. This can be done in O (mk2) by \"brute force\" evaluation of the expressions in Definition 1.1. In many applications, including image restoration and stereo matching, the paired costs hij have a special structure that allows a faster calculation using the techniques described in [10], resulting in an O (mk) algorithm for each iteration of the fixed-point methods. Furthermore, the algorithms are easily parallelized; the fixed-point algorithms that converge by T and S are fast because the cards are contracts in (RL) V. Let's say: RK \u2192 RK \u2192 RK \u2192 RK \u2192 RK and vice versa standard in RK."}, {"heading": "3 Algorithm defined by T (Diffusion)", "text": "In this section, we examine the fixed point algorithm defined by T. We show that T is a contraction in (RL) V and that the fixed point of T defines a \"factored\" lower limit in F. (26) Lemma 3.1. (Contraction) For any other form of contraction (RL) V is a contraction in relation to the norm in (RL) V - (TH) i \u2212 (TH) i \u2212 (TH) i \u2212 (TH) i \u2212 (TH) i \u2212 (TH) i \u2212 (TH) i \u2212 (TH) i \u00b2 (I) q \u00b2 (YES) i \u2212 (YES)."}, {"heading": "3.1 Linear Programming Formulation", "text": "We note that the LP formulation described here differs from the standard LP relaxation to minimize F (x), which includes the local polytopic described in [22]. Consider the following LP, which depends on a vector of the coefficients a in (RL) V, max aTi (ui) \u2264 pgi (ui) + \u0445 j (i) p 2 hij (ui, uj) + qwjij (uj) i (uj) p (V), \u0445u \u0445V. Note that the constraints in the LP are equivalent to the vector of T. Next, we show that this LP has a unique solution that equals the fixed point of T whenever each coefficient is positive, regardless of its specific values."}, {"heading": "4 Algorithm defined by S (Optimal Control)", "text": "In this section we examine the algorithms defined by S. by showing that S = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D"}, {"heading": "4.1 Random Walks", "text": "The formalism of the MDPs is quite general and includes the fixed point algorithm defined by S. In this section, we analyze this fixed point algorithm further and provide an interpretation based on one-dimensional problems defined by random migrations on G. The weights wij define a random process that generates infinite migrations on G. Starting from any vertex in V, we repeatedly move to an adjacent vertex, and the probability that we move in one step from i-V to j-N (i) is given by wij. An infinite migrations \u03c9 = (\u03c91, \u03c92,.)."}, {"heading": "4.2 Bounding the Value Functions of F", "text": "Now we show that the second inequality follows the first value by taking a convex combination over the second value. To prove the first inequality, we note that fi (ui) = min x x x. The second inequality follows the first value by taking a convex combination over the second value. To prove the first inequality, we point out that fi (ui) = min x x. The second inequality follows the third value."}, {"heading": "5 Numerical Experiments", "text": "In this section, we will demonstrate the practicality of the proposed algorithms based on preliminary experiments in computer-building problems. We will also evaluate the fixed-point algorithms defined by S and T and other methods for random problems in the binary classification of a grid."}, {"heading": "5.1 Image Restoration", "text": "The goal of image restoration is to estimate a clean image z of a noisy or spoiled, cost (SO = cost). A classic approach to solving this problem involves finding a piecemeal smooth image x that resembles y [12, 6]. However, in the weak membrane model, the local cost gi (a) is to punish the differences between x and y, while the paired cost hij (a, b) penalizes the differences between adjacent pixels in x. In this setting, the graph G = (V, E) is a grid in which the vertices V correspond to the pixels and the edges E, while the adjacent pixels are connected to each other. The labels xi x are possible pixel values and a label x defines an image. For our experiments, we use L = {0,.,. 255} according to the possible values in an 8-bit image.To restore y, we define the energy F (x) usinggi (xi) (xi) \u2212 xi."}, {"heading": "5.2 Stereo Depth Estimation", "text": "Most pixels in an image have a corresponding pixel in the other image because they represent the projection of the same three-dimensional point. The difference in the coordinates of the corresponding pixels is called disparity. We assume that the images are corrected so that one pixel (x, y) in Il corresponds to one pixel (x \u2212 d, y) in Ir with d \u2265 0. In corrected images, the distance of a three-dimensional point to the image plane is inversely proportional to the disparity. In practice, we consider the problem of labeling each pixel in Il with an integer disparity in L = 0,., D}. In this case, a label x is a disparity map for Il. The local costs gi (a) encourage pixels in Il to have pixels of similar color in Ir."}, {"heading": "5.3 Binary Classification on a Grid", "text": "In fact, it is the case that most of us are able to move into a different world, in which they are able, in which they are able, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, live, in which they, in which they, in which they, live."}, {"heading": "6 Conclusion and Future Work", "text": "The experimental results in the last section illustrate the practical feasibility of the algorithms studied. Our theoretical results prove that these algorithms are guaranteed to converge to unique fixed points on graphs with arbitrary topology and arbitrary pair relationships, including the case of repulsive interactions that often lead to convergence problems in message delivery. Our results can be extended to other contraction maps similar to T and S and alternative methods."}, {"heading": "S + ICM 35.6 35.6", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "T + ICM 36.0 36.0", "text": "1. Asynchronous Updates. It is possible to define algorithms that update the beliefs of a singlevertex at any time in any order. As long as all vertices are updated infinitely, the resulting algorithms will converge to the same fixed point as the parallel updating methods examined in this paper. We suspect that in a sequential calculation, the sequential updating of vertices in a \"sweep\" would converge faster than a \"parallel\" updating. Furthermore, after a sequential updating of all vertices, the neighbors of these vertices should be the first to be updated with greater variation in the next \"sweep.\" 2. Random runs without retracing. The algorithms defined by S and T can be understood as intervals of random walks on G. It is possible to define alternative algorithms based on random runs without retracing."}], "references": [{"title": "Nonserial Dynamic Programming", "author": ["U. Bertele", "F. Brioschi"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1972}, {"title": "Dynamic Programming and Optimal Control", "author": ["Dimitry P. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Spatial interaction and the statistical analysis of lattice systems", "author": ["Julian Besag"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1974}, {"title": "On the statistical analysis of dirty pictures", "author": ["Julian Besag"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1986}, {"title": "Pseudo-boolean optimization", "author": ["Endre Boros", "Peter L Hammer"], "venue": "Discrete applied mathematics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Fast approximate energy minimization via graph cuts", "author": ["Yuri Boykov", "Olga Veksler", "Ramin Zabih"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Efficient belief propagation for early vision", "author": ["Pedro F Felzenszwalb", "Daniel P Huttenlocher"], "venue": "International Journal of Computer Vision,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Distance transforms of sampled functions", "author": ["Pedro F. Felzenszwalb", "Daniel P. Huttenlocher"], "venue": "Theory of Computing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Dynamic programming and graph algorithms in computer vision", "author": ["Pedro F. Felzenszwalb", "Ramin Zabih"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1984}, {"title": "Exact maximum a posteriori estimation for binary images", "author": ["D.M. Greig", "B.T. Porteous", "A.H. Seheult"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1989}, {"title": "Approximation algorithms for classification problems with pairwise relationships: Metric labeling and markov random fields", "author": ["Jon Kleinberg", "Eva Tardos"], "venue": "Journal of the ACM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Probabilistic Graphical Models", "author": ["Daphne Koller", "Nir Friedman"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Convergent tree-reweighted message passing for energy minimization", "author": ["Vladimir Kolmogorov"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "What energy functions can be minimized via graph cuts", "author": ["Vladimir Kolmogorov", "Ramin Zabih"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Random walks on graphs: A survey", "author": ["L\u00e1szl\u00f3 Lov\u00e1sz"], "venue": "Combinatorics, Paul Erdos is Eighty,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1993}, {"title": "Convergent message passing algorithms: a unifying view", "author": ["Talya Meltzer", "Amir Globerson", "Yair Weiss"], "venue": "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Message-passing for graphstructured linear programs: Proximal methods and rounding schemes", "author": ["Pradeep Ravikumar", "Alekh Agarwal", "Martin J Wainwright"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Efficient MRF energy minimization via adaptive diminishing smoothing", "author": ["Bogdan Savchynskyy", "Stefan Schmidt", "J\u00f6rg Kappes", "Christoph Schn\u00f6rr"], "venue": "In Uncertainty in AI,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Map estimation via agreement on trees: message-passing and linear programming", "author": ["Martin J Wainwright", "Tommi S Jaakkola", "Alan S Willsky"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Graphical models, exponential families, and variational inference", "author": ["Martin J. Wainwright", "Michael I. Jordan"], "venue": "Foundations and Trends R \u00a9 in Machine Learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15].", "startOffset": 109, "endOffset": 120}, {"referenceID": 20, "context": "Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15].", "startOffset": 109, "endOffset": 120}, {"referenceID": 12, "context": "Energy minimization methods based on Markov random fields (MRF) address these problems in a common framework [4, 23, 15].", "startOffset": 109, "endOffset": 120}, {"referenceID": 8, "context": "This approach has been applied to a variety of problems in image processing and computer vision [11].", "startOffset": 96, "endOffset": 100}, {"referenceID": 9, "context": "A classical example involves restoring corrupted images [12, 5].", "startOffset": 56, "endOffset": 63}, {"referenceID": 3, "context": "A classical example involves restoring corrupted images [12, 5].", "startOffset": 56, "endOffset": 63}, {"referenceID": 0, "context": "The optimization problem can be solved in polynomial time using dynamic programming when G is a tree [2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 20, "context": "Min-sum (max-product) belief propagation [23, 15] is a local message passing algorithm that is equivalent to dynamic programming when G is a tree.", "startOffset": 41, "endOffset": 49}, {"referenceID": 12, "context": "Min-sum (max-product) belief propagation [23, 15] is a local message passing algorithm that is equivalent to dynamic programming when G is a tree.", "startOffset": 41, "endOffset": 49}, {"referenceID": 1, "context": "The map defined by S corresponds to value iteration for a Markov decision process (MDP) [3] defined by random walks on G.", "startOffset": 88, "endOffset": 91}, {"referenceID": 20, "context": "This approach is related to mean field methods and variational inference with the Gibbs distribution p(X = x) [23, 15].", "startOffset": 110, "endOffset": 118}, {"referenceID": 12, "context": "This approach is related to mean field methods and variational inference with the Gibbs distribution p(X = x) [23, 15].", "startOffset": 110, "endOffset": 118}, {"referenceID": 11, "context": "3 Related Work For general graphs G, when the pairwise costs hij(a, b) define a metric over L there are polynomial time approximation algorithms for the optimization problem defined by F [14].", "startOffset": 187, "endOffset": 191}, {"referenceID": 10, "context": "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].", "startOffset": 108, "endOffset": 122}, {"referenceID": 5, "context": "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].", "startOffset": 108, "endOffset": 122}, {"referenceID": 4, "context": "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].", "startOffset": 108, "endOffset": 122}, {"referenceID": 14, "context": "In some important cases the optimization problem can be solved using graph cuts and maximum flow algorithms [13, 8, 7, 17].", "startOffset": 108, "endOffset": 122}, {"referenceID": 10, "context": "This includes in particular the case of MAP estimation for an Ising model with an external field [13].", "startOffset": 97, "endOffset": 101}, {"referenceID": 20, "context": "The algorithms we study are closely related to message passing methods, in particular to minsum (or equivalently max-product) belief propagation (BP) [23, 15].", "startOffset": 150, "endOffset": 158}, {"referenceID": 12, "context": "The algorithms we study are closely related to message passing methods, in particular to minsum (or equivalently max-product) belief propagation (BP) [23, 15].", "startOffset": 150, "endOffset": 158}, {"referenceID": 19, "context": "The optimization problem can be posed using a LP with a large number of constraints and relaxed to obtain a tractable LP over the local polytope [22].", "startOffset": 145, "endOffset": 149}, {"referenceID": 16, "context": "Several message passing methods have been motivated in terms of this LP [19].", "startOffset": 72, "endOffset": 76}, {"referenceID": 17, "context": "There are also recent methods which use message passing in the inner loop of an algorithm that converges to the optimal solution of the local polytope LP relaxation [20, 21].", "startOffset": 165, "endOffset": 173}, {"referenceID": 18, "context": "There are also recent methods which use message passing in the inner loop of an algorithm that converges to the optimal solution of the local polytope LP relaxation [20, 21].", "startOffset": 165, "endOffset": 173}, {"referenceID": 20, "context": "The mean-field algorithm [23, 15] is an iterative method for approximating the Gibbs distribution p(x) by a factored distribution q(x),", "startOffset": 25, "endOffset": 33}, {"referenceID": 12, "context": "The mean-field algorithm [23, 15] is an iterative method for approximating the Gibbs distribution p(x) by a factored distribution q(x),", "startOffset": 25, "endOffset": 33}, {"referenceID": 7, "context": "In many applications, including in image restoration and stereo matching, the pairwise cost hij has special structure that allows for faster computation using the techniques described in [10].", "startOffset": 187, "endOffset": 191}, {"referenceID": 15, "context": "This choice leads to uniform random walks on G [18].", "startOffset": 47, "endOffset": 51}, {"referenceID": 19, "context": "We note that the LP formulation described here is different from the standard LP relaxation for minimizing F (x) which involves the local polytope described in [22].", "startOffset": 160, "endOffset": 164}, {"referenceID": 1, "context": "We start by showing that S corresponds to value iteration for an infinite horizon discounted Markov decision process (MDP) [3].", "startOffset": 123, "endOffset": 126}, {"referenceID": 1, "context": "The map L is known to be a \u03b3-contraction [3] with respect to the \u2016 \u00b7 \u2016\u221e norm.", "startOffset": 41, "endOffset": 44}, {"referenceID": 9, "context": "A classical approach to solve this problem involves looking for a piecewise smooth image x that is similar to y [12, 6].", "startOffset": 112, "endOffset": 119}, {"referenceID": 6, "context": "We based our implementations on the belief propagation code from [9], which provides efficient methods for handling truncated quadratic discontinuity costs.", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "We note that the results in Figure 3 are similar to results obtained min-sum belief propagation shown in [9].", "startOffset": 105, "endOffset": 108}, {"referenceID": 3, "context": "ICM Iterative conditional modes [5].", "startOffset": 32, "endOffset": 35}, {"referenceID": 13, "context": "TRWS Sequential tree-reweighted message passing [16].", "startOffset": 48, "endOffset": 52}, {"referenceID": 18, "context": "ADSAL Adaptive Diminishing Smoothing [21].", "startOffset": 37, "endOffset": 41}], "year": 2015, "abstractText": "We define two algorithms for propagating information in classification problems with pairwise relationships. The algorithms are based on contraction maps and are related to non-linear diffusion and random walks on graphs. The approach is also related to message passing algorithms, including belief propagation and mean field methods. The algorithms we describe are guaranteed to converge on graphs with arbitrary topology. Moreover they always converge to a unique fixed point, independent of initialization. We prove that the fixed points of the algorithms under consideration define lower-bounds on the energy function and the max-marginals of a Markov random field. The theoretical results also illustrate a relationship between message passing algorithms and value iteration for an infinite horizon Markov decision process. We illustrate the practical application of the algorithms under study with numerical experiments in image restoration, stereo depth estimation and binary classification on a grid.", "creator": "LaTeX with hyperref package"}}}