{"id": "1505.06427", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2015", "title": "Deep Speaker Vectors for Semi Text-independent Speaker Verification", "abstract": "Recent research shows that deep neural networks (DNNs) can be used to extract deep speaker vectors (d-vectors) that preserve speaker characteristics and can be used in speaker verification. This new method has been tested on text-dependent speaker verification tasks, and improvement was reported when combined with the conventional i-vector method.", "histories": [["v1", "Sun, 24 May 2015 11:22:40 GMT  (1253kb,D)", "http://arxiv.org/abs/1505.06427v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["lantian li", "dong wang", "zhiyong zhang", "thomas fang zheng"], "accepted": false, "id": "1505.06427"}, "pdf": {"name": "1505.06427.pdf", "metadata": {"source": "CRF", "title": "Deep Speaker Vectors for Semi Text-independent Speaker Verification", "authors": ["Lantian Li", "Dong Wang", "Zhiyong Zhang", "Thomas Fang Zheng"], "emails": ["fzheng@tsinghua.edu.cn)"], "sections": [{"heading": null, "text": "This paper covers the whole range of issues that have developed over the last few years. (...) It turns out that the issues that are at stake are not just the issue, but also the issue of whether they are the issues that are at stake, the issues that are at stake, the issues that are at stake. (...) It is the issue of whether the issues that are at stake, the issues that are at stake, the issues that are at stake, the issues that are at stake, the issues that are at stake, the \"the issue that is at stake, the\" the \"the issue that is at stake, the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the\" the \"the"}, {"heading": "II. RELATED WORK", "text": "The difference is that we are extending the application of the DNN-based feature learning approach to semi-text-independent tasks and introducing phone-dependent training; due to the different content of enrollment and test language, our task is more challenging; the DNN model has been used in speaker verification in a different way; for example, in [9] DNNs trained for ASR have been used to replace the UBM model to derive the acoustic statistics for i-vector model training; in [10] a DNN has been used to replace PLDA to improve the discriminatory capability of Ivectors, all of which are based on the generative framework, i.e. the i-vector model. The DNN-based feature learning presented in this paper is purely discriminatory without any generative model being involved."}, {"heading": "III. DNN-BASED FEATURE LEARNING", "text": "This section introduces the DNN-based feature Learning. First, we describe the main structure of the model and the learning process and suggest phone-dependent learning. Finally, the difference between the i-vector approach and the DNN-based approach is discussed."}, {"heading": "A. DNN-based feature extraction", "text": "It is well known that DNNs can learn from raw features layer by layer. This feature has been used in ASR, where phone discrimination features are learned from very low levels such as fbanks or even spectrum. It has been shown that with a well-trained DNN, variations irrelevant to the learning task are gradually eliminated when the input function is propagated by the DNN structure layer by layer. This feature is so powerful that in ASR the primary fbank function has been defeated, which has been dominated in ASR for several decades. This feature can also be used to learn speaker discrimination features. In fact, researchers have put a lot of effort in searching for features that are suitable for speakers, but the efforts are vain and the MFCC has dominated for several decades."}, {"heading": "B. Phone-dependent training", "text": "One potential problem with the DNN-based speaker discrimination model described in the previous section is that it is \"blind learning,\" i.e. the characteristics are learned from raw data without prior information. This means that learning relies solely on the complex deep structure of the DNN model and a large amount of data to detect speaker discriminatory patterns. If the training data is abundant, this is often not a problem; for tasks with limited amounts of data, such as the semi-text-independent task in our hands, this blind learning tends to be difficult because there are too many speaker-independent variations in the raw data, especially phone content. One possible solution is to tell the DNN which phone the current input frame belongs to. This can be achieved simply by adding a telephone indicator in the DNN input. However, it is often not easy to align the telephone alignment for the voice data. An alternative to the telephone indicator is easy to detect a postal telephone vector for this model."}, {"heading": "C. Comparison between i-vectors and d-vectors", "text": "The two types of loudspeaker vectors, the d-vector and the ivector, are fundamentally different from each other. I-vectors are based on a linear Gaussian model in which learning is left unattended and the learning criterion is the maximum probability of acoustic characteristics. In contrast, d-vectors are based on neural networks for which learning is supervised, and the learning criterion is the maximum discrimination for speakers. This difference in model structures and learning methods results in significant differences in the properties of these two vectors. First, the i-vector is \"descriptive,\" representing the loudspeaker by constructing a GMM (derived from the i-vector) to accommodate the acoustic characteristics. In contrast, the d-vector is \"discriminatory,\" representing the loudspeaker by removing irrelevant variances. Second, the i-vector can be considered a \"global\" loudspeaker vector \"from\" all. \""}, {"heading": "IV. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Database", "text": "The experiments are performed using a short phrase database provided by Pachira. The entire database contains recordings of 10 short phrases from 100 speakers (gender specific), and each phrase contains 2 x 5 Chinese characters. For each speaker, each phrase is recorded 15 times, which is 150 utterances per speaker. The training set includes 80 randomly selected speakers, resulting in a total of 12,000 utterances. To prevent overmatching, a cross-validation (CV) set of 1,000 utterances is selected from the training data, and the remaining 11,000 utterances are used for model training, including the DNN model in the d-vector approach and the UBM, the T-matrix, the LDA and PLDA model in the i-vector approach. The evaluation set consists of the remaining 20 speakers. In the text-dependent experiment, the evaluation is performed for each phrase, and in the semi-text-independent experiment, all utterances in the assessment group (a total of 3000 target experiments) are evaluated against each other, with 227,500 results."}, {"heading": "B. Text-dependent recognition", "text": "The first experiment examines the performance of the dvector approach on text-dependent speaker verification tasks and compares it to the i-vector baseline. A similar work was reported in [8], here we simply reproduce this work and suggest some improvements using text-independent data. For release, we report the results on two randomly selected phrases, each designated by P1 and P2. This means that the training data for each phrase are selected from the training set to train the i-vector system or d-vector system, and the corresponding expressions are selected in the assessment set to perform the test. This means that the training data for each phrase consists of 1200 expressions, and the test consists of 300 expressions. For the i-vector system, the number of Gaussian mixtures of the UBM 64, and the i-vector dimensions of the observation are 200. These values were chosen to optimize the performance of the vector system."}, {"heading": "C. Semi text-independent recognition", "text": "This experiment examines the d-vector approach to the semi-text-independent task. The dimension of the two i-vectors and d-vectors is set to 200, and the dimension of the LDA projected vectors is 80. In order for the two systems to contain the same set of parameters, the number of Gaussian components of the i-vector system is set to 128. All statements in the training dataset are used to train the DNN model and the i-vector model.The results of the two systems are shown in Table III. It can be observed that the d-vector system with simple cosmic removal significantly outperforms the i-vector system, showing that the discriminatory d-vectors learned for speakers are more discriminatory than the generatively learned i-vectors."}, {"heading": "D. Phone-dependent training", "text": "In this experiment, the telephone posteriors are included in the input of the DNN structure, as in Fig. 2. The telephone posteriors are generated by a DNN model that was trained for ASR using a Chinese database with 6000 hours of voice data. The telephone set consists of 66 soundless start and end devices in Chinese as well as the silent telephone. Results are presented in the third row of Table III. It is shown that the telephone-dependent training leads to a marginal but consistent improvement in the performance of the d-vector system."}, {"heading": "E. Combination system", "text": "In the following [8] we combine the best i-vector system (PLDA) and the best d-vector system (NLDR with telephone-dependent training) by simply interpolating the results from the two systems. EER results with different values of the interpolation factor (denoted by \u03b1) are shown in Fig. 4. It can be seen that the combination with a corresponding set of \u03b1 leads to better performance. The best EER is 7.14%, which is the lowest EER we can achieve with this dataset so far."}, {"heading": "V. CONCLUSIONS", "text": "The experimental results showed that the DNN-based approach can provide reasonable performance and exceed the iVector baseline with single cosine spacing. However, when discriminatory normalization methods such as LDA and PLDA are used, the i-vector approach performs better. Although it has not yet surpassed the i-vector approach, the d-vector approach is very promising and potentially can be improved in several ways. In particular, a powerful probability model for d-vectors would deal with uncertainty between frames, greatly improving system performance."}], "references": [{"title": "Speaker verification using adapted gaussian mixture models", "author": ["D. Reynolds", "T. Quatieri", "R. Dunn"], "venue": "Digital Signal Processing, vol. 10, no. 1, pp. 19\u201341, 2000.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Joint factor analysis versus eigenchannels in speaker recognition", "author": ["P. Kenny", "G. Boulianne", "P. Ouellet", "P. Dumouchel"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, pp. 1435\u20131447, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Speaker and session variability in gmm-based speaker verification", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, pp. 1448\u20131460, 2007.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Support vector machines using gmm supervectors for speaker verification", "author": ["W. Campbell", "D. Sturim", "D. Reynolds"], "venue": "Signal Processing Letters, IEEE, vol. 13, no. 5, pp. 308\u2013311, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic linear discriminant analysis", "author": ["S. Ioffe"], "venue": "Computer Vision ECCV 2006, Springer Berlin Heidelberg, pp. 531\u2013542, 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "An overview of text-independent speaker recognition: From features to supervectors", "author": ["T. Kinnunen", "H. Li"], "venue": "Speech communication, vol. 52, no. 1, pp. 12\u201340, 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving wideband speech recognition using mixed-bandwidth training data in cd-dnn-hmm", "author": ["J. Li", "D. Yu", "J. Huang", "Y. Gong"], "venue": "SLT, pp. 131\u2013136, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for small footprint text-dependent speaker verification", "author": ["V. Ehsan", "L. Xin", "M. Erik", "L.M. Ignacio", "G.-D. Javier"], "venue": "IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), vol. 28, no. 4, pp. 357\u2013366, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep neural networks for extracting baum-welch statistics for speaker recognition", "author": ["P. Kenny", "V. Gupta", "T. Stafylakis", "P. Ouellet", "J. Alam"], "venue": "Odyssey, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Discriminative scoring for speaker recognition based on i-vectors", "author": ["J. Wang", "D. Wang", "Z.-W. Zhu", "T. Zheng", "F. Song"], "venue": "APSIPA, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": ", the famous Gaussian mixture model-universal background model (GMM-UBM) framework [1].", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "A number of advanced models have been proposed based on the GMM-UBM architecture, among which the i-vector model [2] [3] is perhaps the most successful.", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "A number of advanced models have been proposed based on the GMM-UBM architecture, among which the i-vector model [2] [3] is perhaps the most successful.", "startOffset": 117, "endOffset": 120}, {"referenceID": 3, "context": "For example, the SVM model for GMM-UBMs [4], and the PLDA model for i-vectors [5].", "startOffset": 40, "endOffset": 43}, {"referenceID": 4, "context": "For example, the SVM model for GMM-UBMs [4], and the PLDA model for i-vectors [5].", "startOffset": 78, "endOffset": 81}, {"referenceID": 5, "context": ", the features that are more sensitive to speaker change and largely invariant to change of other irrelevant factors, such as phone contents and channels [6].", "startOffset": 154, "endOffset": 157}, {"referenceID": 6, "context": "The learned features are very powerful and have defeated the conventional feature based on Mel frequency cepstral coefficients (MFCCs) that has dominated in ASR for several decades [7].", "startOffset": 181, "endOffset": 184}, {"referenceID": 7, "context": "A recent study shows that this is possible at least in text-dependent tasks [8].", "startOffset": 76, "endOffset": 79}, {"referenceID": 7, "context": "This paper follows the work in [8].", "startOffset": 31, "endOffset": 34}, {"referenceID": 8, "context": "For example, in [9], DNNs trained for ASR were used to replace the UBM model to derive the acoustic statistics for i-vector model training.", "startOffset": 16, "endOffset": 19}, {"referenceID": 9, "context": "In [10], a DNN was used to replace PLDA to improve discriminative capability of ivectors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 6, "context": "This property has been employed in ASR where phone-discriminative features are learned from very low-level features such as Fbanks or even spectrum [7].", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "Actually researchers have put much effort in looking for features that are more discriminative for speakers [6], but the effort is mostly vain and the MFCC is still the most popular choice.", "startOffset": 108, "endOffset": 111}, {"referenceID": 7, "context": "Our experiments show that features extracted from the last hidden layer perform the best, which is similar to the observation in [8].", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "Following the nomenclature in [8], we call this speaker vector as \u2018d-vector\u2019.", "startOffset": 30, "endOffset": 33}, {"referenceID": 7, "context": "A similar work has been reported in [8], here we just reproduce that work and propose some improvement by leveraging text-independent data.", "startOffset": 36, "endOffset": 39}, {"referenceID": 7, "context": "Similar observations have been reported in [8].", "startOffset": 43, "endOffset": 46}, {"referenceID": 7, "context": "Following [8], we combine the best i-vector system (PLDA) and the best d-vector system (NLDR with phone-dependent training).", "startOffset": 10, "endOffset": 13}], "year": 2015, "abstractText": "Recent research shows that deep neural networks (DNNs) can be used to extract deep speaker vectors (d-vectors) that preserve speaker characteristics and can be used in speaker verification. This new method has been tested on text-dependent speaker verification tasks, and improvement was reported when combined with the conventional i-vector method. This paper extends the d-vector approach to semi textindependent speaker verification tasks, i.e., the text of the speech is in a limited set of short phrases. We explore various settings of the DNN structure used for d-vector extraction, and present a phone-dependent training which employs the posterior features obtained from an ASR system. The experimental results show that it is possible to apply d-vectors on semi text-independent speaker recognition, and the phone-dependent training improves system performance.", "creator": "LaTeX with hyperref package"}}}