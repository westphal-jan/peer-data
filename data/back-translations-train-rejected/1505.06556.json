{"id": "1505.06556", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2015", "title": "Differentially Private Distributed Online Learning", "abstract": "Online learning has been in the spotlight from the machine learning society for a long time. To handle massive data in Big Data era, one single learner could never efficiently finish this heavy task. Hence, in this paper, we propose a novel distributed online learning algorithm to solve the problem. Comparing to typical centralized online learner, the distributed learners optimize their own learning parameters based on local data sources and timely communicate with neighbors. However, communication may lead to a privacy breach. Thus, we use differential privacy to preserve the privacy of learners, and study the influence of guaranteeing differential privacy on the utility of the distributed online learning algorithm. Furthermore, by using the results from Kakade and Tewari (2009), we use the regret bounds of online learning to achieve fast convergence rates for offline learning algorithms in distributed scenarios, which provides tighter utility performance than the existing state-of-the-art results. In simulation, we demonstrate that the differentially private offline learning algorithm has high variance, but we can use mini-batch to improve the performance. Finally, the simulations show that the analytical results of our proposed theorems are right and our private distributed online learning algorithm is a general framework.", "histories": [["v1", "Mon, 25 May 2015 07:59:36 GMT  (1478kb)", "https://arxiv.org/abs/1505.06556v1", null], ["v2", "Tue, 23 Jun 2015 09:19:03 GMT  (3098kb)", "http://arxiv.org/abs/1505.06556v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chencheng li", "pan zhou"], "accepted": false, "id": "1505.06556"}, "pdf": {"name": "1505.06556.pdf", "metadata": {"source": "CRF", "title": "Differentially Private Distributed Online Learning", "authors": ["Chencheng Li"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 5.06 556v 2 [cs.L G] 23 Jun 2015 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, JANUAR 20XX 1Index Terms - Distributed Optimization, Online Learning, Differential Privacy, Offline Learning, Mini-Batch,"}, {"heading": "1 INTRODUCTION", "text": "In fact, it is the case that you are able to live in a country where most people are able to live in a country where they are able to move, to live, to live, to live and to live, where they are able to live, to live and to live."}, {"heading": "2 RELATED WORK", "text": "This year, it has come to the point where there is only one person who is able to retaliate."}, {"heading": "3 PRELIMINARIES", "text": "The answer to this question is: \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"W,\" \"\" W, \"\" \"W,\" \"\" W, \"\" \"W,\" \"W,\" \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"\" W, \"\" W, \"\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W,\" W, \"W, W,\" W, W, W, W, \"W,\" W, W, W, W, W, W, W, \"W, W, W, W, W, W, W, W, W, W, W,\" W, W, W, W, W, W, W, \"W, W, W, W, W, W, W, W, W, W, W, W, W, W, W,\" W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W"}, {"heading": "4 DIFFERENTIALLY PRIVATE DISTRIBUTED ONLINE LEARNING", "text": "The i-th learner updates his local parameters based on his local data points (xit, y i t) with i [1, m]. Even if the m learners are distributed, each learner will exchange information with his neighbors. Based on the time variable matrix, the learners communicate with different sets of their neighbors, which they are indirectly influenced by other data sources. Specifically for a learner i, in each round t, it first gets the parameters exchanged and calculates the weighted averages of them, then it updates the local parameters wit."}, {"heading": "4.1 Privacy Analysis", "text": "To achieve this goal, random noise is added to the parameter wit (see step 7 in Algorithm 1). This method of ensuring differential privacy is known as output perturbation [8]. We know where to add noise in order to next investigate how much noise should be added. Differential privacy aims to weaken the significant difference between A (X) and A (X). To show differential privacy, we need to know how \"sensitive\" algorithms A are. Furthermore, the magnitude of noise depends on the largest change that a single entry in the data source might have; this quantity is referred to as the definition of algorithms A."}, {"heading": "4.2 Regret Analysis", "text": "This means that if algorithm 1 runs better and faster, the regret about our distributed online learning algorithm will not be any less. In other words, faster convergence rate ensures that the m learners make fewer mistakes and predict more accurately. So, let's have the matrix with (i, j) -th equal to aij (t) in Assumption 2. According to the assumption, the convergence is wit, we are looking at the behavior of the time variant matrix. Let's have the matrix with (i, j) -th equal to aij (t) in Assumption 2. As already mentioned, some related papers have examined the matrix convergence of At. For simplicity, we will use one of these results to get the following lemma.Lemma 3 (3)."}, {"heading": "5 APPLICATION TO PRIVATE DISTRIBUTED OFFLINE LEARNING USING MINI-BATCH", "text": "In the second half of the last decade, we have dealt with the question of what is the state of privacy and what is the state of privacy. (In the second half of the last decade, we have dealt with the question of what is the state of privacy.) In the second half of the last decade, we have dealt with the question of how we can take advantage of privacy and the privacy of learning in the individual scenarios. (In the third half of the last decade, we have also assumed that there are different learning scenarios for offline learning.) Each learner can get the examples described (e.g. that there was in the first half of the last decade in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, and in the second half of the last decade, we have divided in the second half of the last decade. (xin the second half of the last decade, we have divided in the second half of the last decade, in the second half of the last decade, in the second half of the second decade in the last decade)."}, {"heading": "5.1 Privacy analysis for Algorithm 2", "text": "Algorithm 2 guarantees the same level of privacy as algorithm 1. Unlike algorithm 1, step 6 in algorithm 2 calculates an average of subgradients. According to the sensitivity analysis in Section 4.1, we easily know that the sensitivity of algorithm 2 must deviate from (8). Then, we calculate a new sensitivity of algorithm 2 in the following dim 7. (sensitivity of algorithm 2) Assuming 1, we leave all definitions that were previously used here again, the L1 sensitivity of algorithm 2 isS2 (t) \u2264 2\u03b1t \u221a nL h. (56) We omit the evidence of Lemma 7 following along the lines of Lemma 1. Obviously Lemma 7 shows that besides the parameters in (6), the sensitivity of algorithm 2 in relation to the batch size h. In comparison (56) we can determine that we add less than algorithm 1."}, {"heading": "5.2 Utility analysis for Algorithm 2", "text": "As described, we will next use the regret limits of algorithm 1 to achieve fast convergence rates for algorithm 2, based on [10]. Note that the following terms 9 and 10 are prepared for the final result, theorem 4.For a clear description, we will first consider centralized offline learning (w) = E [f, x, y)], (x, y)], (x, y). Instead of minimizing (1), we will get the centralized approach to the following problem. Lemma 9 ([10]), assuming 1, we will leave the regret (e.g., say RC, logT) of centralized online learning algorithms."}, {"heading": "6 SIMULATIONS", "text": "In this context, it is also worth mentioning the fact that most of them are people who are able to engage with the public."}, {"heading": "7 CONCLUSION AND DISCUSSION", "text": "We have proposed a differentiated distributed online learning algorithm. We have used subgradients to update learning parameters and used random double stochastic matrix to guide learners to communicate with others. More importantly, our network topology is a time variant. As expected, we reached the repentance limits in the order of O (\u221a T) and O (log T). Interestingly, the amount of private distributed offline learning added also has the order of O (\u221a T) and O (log T) along with non-private regret. In addition, we have used our privately distributed online learning algorithm with good regret to solve the private distributed offline learning problem. To reduce the high variance of our differentiated private algorithm, we use the mini-batch technique to mitigate the impact of additional regret. This method makes the algorithm a guarantor for the same level of privacy under less random use."}, {"heading": "ACKNOWLEDGMENTS", "text": "This research is supported by the National Science Foundation of China with grant 61401169."}], "references": [{"title": "Differential privacy", "author": ["C. Dwork"], "venue": "Proceedings of the 33rd international conference on Automata, Languages and Programming-Volume Part II. Springer-Verlag, 2006, pp. 1\u201312.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Consensus and cooperation in networked multi-agent systems", "author": ["R. Olfati-Saber", "J. Fax", "R. Murray"], "venue": "Proceedings of the IEEE, vol. 95, no. 1, pp. 215\u2013233, Jan 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Distributed stochastic subgradient projection algorithms for convex optimization", "author": ["S. Ram", "A. Nedi\u0107", "V. Veeravalli"], "venue": "Journal of optimization theory and applications, vol. 147, no. 3, pp. 516\u2013545, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed subgradient methods for multi-agent optimization", "author": ["A. Nedic", "A. Ozdaglar"], "venue": "IEEE Transactions on Automatic Control, vol. 54, no. 1, pp. 48\u201361, 2009.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "On the convergence of decentralized gradient descent", "author": ["K. Yuan", "Q. Ling", "W. Yin"], "venue": "arXiv preprint arXiv:1310.7063, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed autonomous online learning: Regrets and intrinsic privacy-preserving properties", "author": ["F. Yan", "S. Sundaram", "S. Vishwanathan", "Y. Qi"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 25, no. 11, pp. 2483\u20132493, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Differentially private online learning", "author": ["P. Jain", "P. Kothari", "A. Thakurta"], "venue": "arXiv preprint arXiv:1109.0105, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "The Journal of Machine Learning Research, vol. 12, pp. 1069\u2013 1109, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic inference and differential privacy", "author": ["O. Williams", "F. McSherry"], "venue": "Advances in Neural Information Processing Systems, 2010, pp. 2451\u20132459.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "On the generalization ability of online strongly convex programming algorithms", "author": ["S.M. Kakade", "A. Tewari"], "venue": "Advances in Neural Information Processing Systems, 2009, pp. 801\u2013808.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Stochastic gradient descent with differentially private updates", "author": ["S. Song", "K. Chaudhuri", "A.D. Sarwate"], "venue": "IEEE Global Conference on Signal and Information Processing, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "ICML, pp. 928\u2013936, 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Agarwal", "S. Kale"], "venue": "Machine Learning, vol. 69, no. 2-3, pp. 169\u2013192, 2007.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Differentially private distributed optimization", "author": ["Z. Huang", "S. Mitra", "N. Vaidya"], "venue": "Proceedings of the 2015 International Conference on Distributed Computing and Networking. ACM, 2015, p. 4.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Online Convex Optimization", "author": ["E. Hazan"], "venue": "2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Dual averaging for distributed optimization", "author": ["J.C. Duchi", "A. Agarwal", "M.J. Wainwright"], "venue": "Communica-  IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. X, NO. X, JANUARY 20XX  13 tion, Control, and Computing (Allerton), 2012 50th Annual Allerton Conference on. IEEE, 2012, pp. 1564\u20131565.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "A differentially private stochastic gradient descent algorithm for multiparty classification", "author": ["A. Rajkumar", "S. Agarwal"], "venue": "International Conference on Artificial Intelligence and Statistics, 2012, pp. 933\u2013941.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Differentially private empirical risk minimization: Efficient algorithms and tight error bounds", "author": ["R. Bassily", "A. Smith", "A. Thakurta"], "venue": "arXiv preprint arXiv:1405.7085, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Privacy integrated queries: an extensible platform for privacy-preserving data analysis", "author": ["F.D. McSherry"], "venue": "Proceedings of the 2009 ACM SIGMOD International Conference on Management of data. ACM, 2009, pp. 19\u2013 30.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Specifically, we use distributed convex optimization as the distributed online learning model, while use differential privacy [1] to protect the privacy.", "startOffset": 126, "endOffset": 129}, {"referenceID": 1, "context": "Distributed convex optimization is considered as a consensus problem [2].", "startOffset": 69, "endOffset": 72}, {"referenceID": 2, "context": "To solve this problem, some related works [3, 4, 5] have been done.", "startOffset": 42, "endOffset": 51}, {"referenceID": 3, "context": "To solve this problem, some related works [3, 4, 5] have been done.", "startOffset": 42, "endOffset": 51}, {"referenceID": 4, "context": "To solve this problem, some related works [3, 4, 5] have been done.", "startOffset": 42, "endOffset": 51}, {"referenceID": 5, "context": "The time-variant communication matrix makes the distributed optimization algorithm converge faster and better than the fixed one used in [6].", "startOffset": 137, "endOffset": 140}, {"referenceID": 0, "context": "Differential privacy [1] is a popular privacy mechanism to preserve the privacy of the learners.", "startOffset": 21, "endOffset": 24}, {"referenceID": 6, "context": "Many privacy-preserving algorithms [7, 8, 9] have been proposed to use differential privacy to protect sensitive information in the centralized offline learning framework.", "startOffset": 35, "endOffset": 44}, {"referenceID": 7, "context": "Many privacy-preserving algorithms [7, 8, 9] have been proposed to use differential privacy to protect sensitive information in the centralized offline learning framework.", "startOffset": 35, "endOffset": 44}, {"referenceID": 8, "context": "Many privacy-preserving algorithms [7, 8, 9] have been proposed to use differential privacy to protect sensitive information in the centralized offline learning framework.", "startOffset": 35, "endOffset": 44}, {"referenceID": 9, "context": "Furthermore, our differentially private DOLA can be used to achieve fast convergence rates for differentially private distributed offline learning algorithm based on [10].", "startOffset": 166, "endOffset": 170}, {"referenceID": 10, "context": "Since the offline learning algorithm has access to all data, the technique of mini-batch [11] is used to reduce the high variance of the differentially private offline learning algorithm.", "startOffset": 89, "endOffset": 93}, {"referenceID": 9, "context": "Motivated by [10] and [11], we try to obtain a good utility of the distributed offline learning algorithm while protect the privacy of the learners.", "startOffset": 13, "endOffset": 17}, {"referenceID": 10, "context": "Motivated by [10] and [11], we try to obtain a good utility of the distributed offline learning algorithm while protect the privacy of the learners.", "startOffset": 22, "endOffset": 26}, {"referenceID": 11, "context": "We respectively obtain the classical regret boundsO( \u221a T ) [12] andO(log T ) [13] for convex and strongly convex objective functions for the algorithm.", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "We respectively obtain the classical regret boundsO( \u221a T ) [12] andO(log T ) [13] for convex and strongly convex objective functions for the algorithm.", "startOffset": 77, "endOffset": 81}, {"referenceID": 6, "context": "[7] studied the differentially private centralized online learning.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] has proposed a DOLA to handle the decentralized data.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "[14] is closely related to our work.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Hazan has studied online convex optimization in his book [15].", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "[16] developed an efficient algorithm for distributed optimization based on dual averaging of subgradients method.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Nedic and Ozdaglar [4] considered a subgradient method for distributed convex optimization, where the functions are convex but not necessarily smooth.", "startOffset": 19, "endOffset": 22}, {"referenceID": 2, "context": "[3] tried to analyze the influence of stochastic subgradient errors on distributed convex optimization based on a time-variant network topology.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Our work extends the works of Nedic and Ozdaglar [4] and Ram et al.", "startOffset": 49, "endOffset": 52}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] presented the output perturbation and objective perturbation ideas about differential privacy in empirical risk minimization (ERM) classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "Rajkumar and Agarwal [17] extended differentially private ERM classification [8] to differentially private ERM multiparty classification.", "startOffset": 21, "endOffset": 25}, {"referenceID": 7, "context": "Rajkumar and Agarwal [17] extended differentially private ERM classification [8] to differentially private ERM multiparty classification.", "startOffset": 77, "endOffset": 80}, {"referenceID": 17, "context": "[18] proposed more efficient algorithms and tighter error bounds for ERM classification on the basis of [8].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[18] proposed more efficient algorithms and tighter error bounds for ERM classification on the basis of [8].", "startOffset": 104, "endOffset": 107}, {"referenceID": 9, "context": "Kakade and Tewari [10] proposed some properties of online learning algorithms if the loss function is Lipschitz and strongly convex.", "startOffset": 18, "endOffset": 22}, {"referenceID": 6, "context": "[7] use the results in [10] to analyze the utility of differentially private offline learning algorithms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[7] use the results in [10] to analyze the utility of differentially private offline learning algorithms.", "startOffset": 23, "endOffset": 27}, {"referenceID": 2, "context": "In our algorithm, each learner computes a weighted average [3] of the m learners\u2019 parameters.", "startOffset": 59, "endOffset": 62}, {"referenceID": 0, "context": "Differential Privacy: Dwork [1] proposed the definition of differential privacy for the first time.", "startOffset": 28, "endOffset": 31}, {"referenceID": 5, "context": "Notice that RD is computed with respect to an arbitrary learner\u2019s parameter w t [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 7, "context": "This method to guarantee differential privacy is known as output perturbation [8].", "startOffset": 78, "endOffset": 81}, {"referenceID": 0, "context": "Further, according to [1], the magnitude of the noise depends on the largest change that a single entry in data source could have on the output of Algorithm 1; this quantity is referred to as the sensitivity of the algorithm.", "startOffset": 22, "endOffset": 25}, {"referenceID": 18, "context": "McSherry [19] has proposed that the privacy guarantee does not degrade across rounds as the samples used in the rounds are disjoint.", "startOffset": 9, "endOffset": 13}, {"referenceID": 18, "context": "This proof follows from the theorem 4 of [19].", "startOffset": 41, "endOffset": 45}, {"referenceID": 2, "context": "Lemma 3 ([3]).", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": "t=1 m \u221a |\u03c3t [1]|2+.", "startOffset": 12, "endOffset": 15}, {"referenceID": 9, "context": "Kakade and Tewari [10] and Jain et al.", "startOffset": 18, "endOffset": 22}, {"referenceID": 6, "context": "[7] have both proposed that online learning algorithms with good regret bounds can be used to achieve fast convergence rates for offline learning algorithms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Based on the analysis in [7], we exploit this application in distributed scenarios.", "startOffset": 25, "endOffset": 28}, {"referenceID": 10, "context": "For solving the problem in (52), stochastic gradient descent (SGD) (mentioned in [11]) was proposed.", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "[11] demonstrated that differentially private SGD algorithm updated with a single point has high variance and used mini-batch to reduce the variance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "According to the theory of parallel composition [19] in differential privacy, we know that the privacy guarantee does not degrade across rounds.", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "2 Utility analysis for Algorithm 2 As described, we next use the regret bounds of Algorithm 1 to achieve fast convergence rates for Algorithm 2 based on [10].", "startOffset": 153, "endOffset": 157}, {"referenceID": 9, "context": "Lemma 9 ([10]).", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "Based on [7] and [10], we study the application of regret bounds to offline convergence rates in distributed scenarios.", "startOffset": 9, "endOffset": 12}, {"referenceID": 9, "context": "Based on [7] and [10], we study the application of regret bounds to offline convergence rates in distributed scenarios.", "startOffset": 17, "endOffset": 21}, {"referenceID": 6, "context": "Our work also have the same three significant advantages in [7].", "startOffset": 60, "endOffset": 63}], "year": 2015, "abstractText": "In this paper, we propose a novel distributed online learning algorithm to handle massive data in Big Data era. Comparing to the typical centralized scenario, our proposed distributed online learning has multi-learners. Each learner optimizes its own learning parameter based on local data source and communicates timely with neighbors. We study the regret of the distributed online learning algorithm. However, communications among the learners may lead to privacy breaches. Thus, we use differential privacy to preserve the privacy of the learners, and study the influence of guaranteeing differential privacy on the regret of the algorithm. Furthermore, our online learning algorithm can be used to achieve fast convergence rates for offline learning algorithms in distributed scenarios. We demonstrate that the differentially private offline learning algorithm has high variance, but we can use mini-batch to improve the performance. The simulations show that our proposed theorems are correct and our differentially private distributed online learning algorithm is a general framework.", "creator": "LaTeX with hyperref package"}}}