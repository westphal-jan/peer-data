{"id": "1506.00799", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2015", "title": "Learning Speech Rate in Speech Recognition", "abstract": "A significant performance reduction is often observed in speech recognition when the rate of speech (ROS) is too low or too high. Most of present approaches to addressing the ROS variation focus on the change of speech signals in dynamic properties caused by ROS, and accordingly modify the dynamic model, e.g., the transition probabilities of the hidden Markov model (HMM). However, an abnormal ROS changes not only the dynamic but also the static property of speech signals, and thus can not be compensated for purely by modifying the dynamic model. This paper proposes an ROS learning approach based on deep neural networks (DNN), which involves an ROS feature as the input of the DNN model and so the spectrum distortion caused by ROS can be learned and compensated for. The experimental results show that this approach can deliver better performance for too slow and too fast utterances, demonstrating our conjecture that ROS impacts both the dynamic and the static property of speech. In addition, the proposed approach can be combined with the conventional HMM transition adaptation method, offering additional performance gains.", "histories": [["v1", "Tue, 2 Jun 2015 08:59:47 GMT  (1227kb,D)", "http://arxiv.org/abs/1506.00799v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["xiangyu zeng", "shi yin", "dong wang"], "accepted": false, "id": "1506.00799"}, "pdf": {"name": "1506.00799.pdf", "metadata": {"source": "CRF", "title": "Learning Speech Rate in Speech Recognition", "authors": ["Xiangyu Zeng", "Shi Yin", "Dong Wang"], "emails": ["zxy@cslt.riit.tsinghua.edu.cn,", "yins@cslt.riit.tsinghua.edu.cn,", "wangdong99@mails.tsinghua.edu.cn"], "sections": [{"heading": null, "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2. Related work", "text": "This paper refers to previous work on ROS remuneration, most of which were mentioned in the introduction. It should be noted that the approach proposed in [12] resembles our method of image rate normalization in the sense that both modify the feature extraction according to the ROS. The difference is that our method introduces the ROS feature to regulate acoustic model learning, while the work in [12] changes the image step size, thus still being an implicit method of adjusting the dynamic model. In other words, the discrete indicator variable (\"slow\" or \"fast\") for different ROS. The difference is that our method does not explicitly train multiple classes, but uses the DNN structure to share the parameters of models for \"each\" ROS. In other words, the discrete indicator variable (\"slow\" or \"fast\") in multi-level training is replaced by a continuous indicator, namely the ROS value."}, {"heading": "3.1. Impact of ROS variance", "text": "We argue that the effects of the ROS variance on speech signals are twofold. In the dynamic aspect, the change in ROS leads to changes in temporal behaviour, i.e. the duration of telephone instances. Different phones are affected differently, and vowels tend to be more strongly affected. In the static aspect, the change in ROS leads to distortions of the spectrum. These two effects have been noted in acoustic research, e.g. [15].Although the change in dynamic property is natural, the distortion of the static property merits discussion. To have an intuition, two language segments of the word \"test\" are selected from our training database (see section 4), one is clearly fast and the other slow. Spectrograms of the two speech signals are shown in Figure 1 and Figure 2 respectively."}, {"heading": "3.2. DNN-based ROS compensation", "text": "A DNN is a special neural network that comprises a \"deep\" structure, i.e. several hidden layers. Due to its deep structure, DNN has several advantages in machine learning. Firstly, it is a compact model in which the units are connected and weights are divided, allowing it to learn complex relationships with a limited number of parameters; secondly, it comprises several hidden layers, making it suitable for learning high properties layer by layer; thirdly, the great freedom in parameter space allows learning patterns in multiple conditions. Attributed to high performance learning, DNN has achieved remarkable success, especially in speech recognition [16, 17]. Due to the advantage of DNNs in learning data in multiple conditions, it is capable of handling signal variations. This ability can be used to learn distortions caused by ROS, especially when the input functions include a long-term window of time."}, {"heading": "3.3. HMM-based ROS compensation", "text": "As already mentioned, the influence of the ROS on the temporal property can be compensated by modifying the dynamic model that is the HMM in speech recognition. The parameters that control the dynamic property of an HMM are the state transition probabilities. It can be shown that the expectation of the duration of a telephone modelled by an HMM is proportional to the self transition probabilities. For the sake of simplicity, one assumes that an HMM consists of only one state, and the self transition probability is pi, the exit probability is correspondingly po = 1 \u2212 pi. The probability that the HMM for n frames isP (n) = pn \u2212 1i (1 \u2212 pi) remains alive, and the expectation of the number of frames n isEP (n) = \u221e n = 1 poNote that EP (n) \u04321ROS, meaning ROS. This relationship can be used to adjust the temporal behavior of the ROS on the phone so that it can be compensated."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Databases", "text": "The experiments are conducted using a spontaneous Chinese language database provided by Tencent. The training set includes 95 hours of language (199499 utterances), and the cross-validation set (CV) used in DNN training includes 5 hours of language (10500 utterances), all of which are collected from online applications covering millions of people, so the ROS variance is clearer and more realistic than most of the widely used databases such as the Wall Street Journal (WSJ) corpus. Figure 4 shows the distribution of ROS values of utterances in the training set. It is evident that the distribution has some Gaussian characteristics, as most of the ROS values are concentrated in the range of 4-10 phones / second. Interestingly, the distribution has a long tail in the range of large ROS values, suggesting that people tend to speak faster than slower. The test set includes 6.3 hours of language, 10781 utterances in total."}, {"heading": "4.2. Experimental settings", "text": "We used the Kaldi toolkit to perform the training and evaluation and largely followed the WSJ s5 DNPU recipe. Specifically, the first step was to establish a GMM baseline; the phone set included 108 Chinese initials and finals and a silent phone to represent non-linguistic frames; the feature consisted of 39-dimensional MFCCs, including 13 static components plus the first and second order derivatives; the acoustic model was based on a context-dependent phone (tri-phones) clustered through decision trees; after clustering, the model consisted of 3656 probability functions (PDF) and the number of Gaussian components was 39995; the GMM system was used to generate phoneme alignments for the training data and provide the prototypes for the DNN system, including the HMM model, which describes the transition properties of the phoneme models."}, {"heading": "4.3. Experimental results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.3.1. Baseline", "text": "Table 1 shows the base performance in terms of the Word Error Rate (WHO). Two baselines are reported, one based on GMM and the other on DNN. It can be seen that a slow language has a significant impact on the results of both baselines, especially on slow expressions. This is consistent with the observation in Figure 1 and Figure 2, which indicates that a slow language tends to have more distortions. Comparing the two baselines shows that the DNN system outperforms the GMM system under all conditions."}, {"heading": "4.3.2. DNN-based compensation", "text": "Table 2 reports on the performance with the DNN-based ROS remuneration. It can be seen that the performance on the slow and fast utterances can be consistently improved with the ROS remuneration. Interestingly, the remuneration has no influence on the performance on the language at normal speed. In order to have a clearer understanding of how the DNN-based ROS remuneration contributes to this, and to compare the different behaviours of GMM and DNN systems under different ROS conditions, the test set is divided into two subgroups according to the ROS: Tst-Slow, where the test expressions whose ROS is greater than 6 phones / second. The number of expressions involved in these two sentences are approximately the same. Accordingly, we divide the training data into Tr-Slow (ROS < 6.3 phones / second) and Tr-Fast, during the training (ROS > 6.3 phones / second)."}, {"heading": "4.3.3. HMM-based compensation", "text": "It is worth pointing out that the DNN-based ROS compensation does not alter the dynamic model (HMM), so the performance improvement achieved in the previous experiment comes entirely from the remuneration for spectrum distortion. To provide clearer confirmation, the conventional HMM-based compensation is implemented following the discussion in Section 3.3. Specifically, we adjust po to adjust the HMM to a specific ROS. In our experiment, the self-transition probability is modified by multiplying a factor \u03b1, and then the transition matrix is normalized to ensure po + p1 = 1. Performance is tested using the fast and slow subsets of the test data. For the fast remuneration \u03b1 is set to 0.5, and for the slow remuneration \u03b1 is set to 1.01162. These values are optimal at the valuation stage. Results are presented in Table 6. It can be seen that the HM-based contribution is monitored for slow performance, but not for slow performance."}, {"heading": "5. Conclusions", "text": "The experimental results confirmed our assumption that the ROS variance causes distortions not only in the temporal domain, but also in the spectral domain. DNN-based ROS compensation can effectively improve performance on fast and slow utterances, while it has no effect on utterances at normal speed.] In combination with conventional HMM-based compensation, additional gains can be made. [1] M. A. Siegler and R. M. Stem, \"On the Impact of Speeches Speaked in Large Words,\" in ICASSP \"95, 1995. [2] N. Morgan, E. Fosler and N. M. Afori,\" Speech recognition using on-line estimation of talking rate, \"in Eurospeech, vol. 4, 1997, pp. 2079-2082. Mirghafori, Nikki, E. Foster, and N. Morgan\" Fast speakers in large vocabol speech analysis:. \""}], "references": [{"title": "On the effects of speech rate in large vocabulary speech recognition systems", "author": ["M.A. Siegler", "R.M. Stem"], "venue": "ICASSP\u201995, 1995.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Speech recognition using on-line estimation of speaking rate", "author": ["N. Morgan", "E. Fosler", "N.M. Afori"], "venue": "Eurospeech, vol. 4, 1997, pp. 2079\u20132082.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Fast speakers in large vocabulary continuous speech recognition: analysis & antidotes", "author": ["Mirghafori", "Nikki", "E. Foster", "N. Morgan"], "venue": "Spoken Language, ICSLP 96. Proceedings., Fourth International Conference on. Vol. 4. IEEE, 1996.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "A fast and reliable rate of speech detector", "author": ["J.P. Verhasselt", "J.-P. Martens"], "venue": "Spoken Language, ICSLP 96. Proceedings., Fourth International Conference on. Vol. 4. IEEE, 1996.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "Syllable detection and segmentation using temporal flow neural networks", "author": ["L. Shastri", "S. Chang", "S. Greenberg"], "venue": "Proc. of the 14th International Congress of Phonetic Sciences, 1996, pp. 1721\u20131724.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "Estimating speaking rate by means of rhythmicity parameters", "author": ["Heinrich", "Christian", "F. Schiel"], "venue": "Proceedings of the Interspeech, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Speech rhythm guided syllable nuclei detection", "author": ["Y. Zhang", "J. Glass"], "venue": "Acoustics, Speech and Signal Processing, ICASSP 2009. IEEE International Conference on IEEE, 2009, pp. 3797\u2013 3800.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Praat script to detect syllable nuclei and measure speech rate automatically", "author": ["N.H. de Jong", "T. Wempe"], "venue": "Behavior research methods, vol. 41, no. 2, 2009, pp. 385\u2013390.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Robust speech rate estimation for spontaneous speech", "author": ["D. Wang", "S.S. Narayanan"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions, vol. 15, no. 8, 2007, pp. 2190\u20132201.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Speech rate change detection in martingale framework", "author": ["H. Yasuda", "M. Kudo"], "venue": "International Conference on Intelligent Systems Design and Applications (ISDA), 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Towards speech rate indenpendence in large vocabulary continous speech recognition", "author": ["F. Martinez", "D. Tapias", "I. Alvarez"], "venue": "ICASSp\u201998, 1998.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "Speaking rate adaptation using continuous frame rate normalization", "author": ["S.M. Chu", "D. Povey"], "venue": "ICASSP\u201910, 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "I-vector-based speaker adaptation of deep neural networks for french broadcast audio transcription", "author": ["V. Gupta", "P. Kenny", "P. Ouellet", "T. Stafylakis"], "venue": "ICASSP\u201914, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Speaker adaptation of dnn-based asr with i-vectors: Does it actually adapt models to speakers?", "author": ["M. Rouvier", "B. Favre"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Effect of speech rate on intersegmental coarticulation in standard chinese", "author": ["Y. hao Li", "J. ping Kong"], "venue": "ISCSLP\u201910, 2010, pp. 44\u201349.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Automatic Speech Recognition A Deep Learning Approach", "author": ["D. Yu", "L. Deng"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "A low or high ROS often causes serious performance reduction [1, 2].", "startOffset": 61, "endOffset": 67}, {"referenceID": 1, "context": "A low or high ROS often causes serious performance reduction [1, 2].", "startOffset": 61, "endOffset": 67}, {"referenceID": 2, "context": "For example [3] uses an ASR system to recognize and segment speech signals, and [4, 5] harness neural networks to detect syllable boundaries.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "For example [3] uses an ASR system to recognize and segment speech signals, and [4, 5] harness neural networks to detect syllable boundaries.", "startOffset": 80, "endOffset": 86}, {"referenceID": 4, "context": "For example [3] uses an ASR system to recognize and segment speech signals, and [4, 5] harness neural networks to detect syllable boundaries.", "startOffset": 80, "endOffset": 86}, {"referenceID": 1, "context": ", energy envelop change [2], rhythm [6, 7], intensity and voicing [8] and sub-band energy [9].", "startOffset": 24, "endOffset": 27}, {"referenceID": 5, "context": ", energy envelop change [2], rhythm [6, 7], intensity and voicing [8] and sub-band energy [9].", "startOffset": 36, "endOffset": 42}, {"referenceID": 6, "context": ", energy envelop change [2], rhythm [6, 7], intensity and voicing [8] and sub-band energy [9].", "startOffset": 36, "endOffset": 42}, {"referenceID": 7, "context": ", energy envelop change [2], rhythm [6, 7], intensity and voicing [8] and sub-band energy [9].", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": ", energy envelop change [2], rhythm [6, 7], intensity and voicing [8] and sub-band energy [9].", "startOffset": 90, "endOffset": 93}, {"referenceID": 9, "context": "For example, the Martingale framework proposed in [10], and the convex weighting optimization method presented in [11].", "startOffset": 50, "endOffset": 54}, {"referenceID": 10, "context": "For example, the Martingale framework proposed in [10], and the convex weighting optimization method presented in [11].", "startOffset": 114, "endOffset": 118}, {"referenceID": 10, "context": "For example in [11], the ROS was categorized into three classes (low, middle and high) and models were trained for each class with data belonging to it according to the ROS.", "startOffset": 15, "endOffset": 19}, {"referenceID": 11, "context": "Another approach proposed in [12] compensates for ROS by normalizing the frame rate at different ROS so that the number of frames keeps the same for different instances of a phone at different ROS levels.", "startOffset": 29, "endOffset": 33}, {"referenceID": 0, "context": "Probably the most widely-adopted ROS compensation method in ASR is to adapt the transitional probabilities of the hidden Markov model (HMM) when decoding utterances at different ROS levels [1, 4].", "startOffset": 189, "endOffset": 195}, {"referenceID": 3, "context": "Probably the most widely-adopted ROS compensation method in ASR is to adapt the transitional probabilities of the hidden Markov model (HMM) when decoding utterances at different ROS levels [1, 4].", "startOffset": 189, "endOffset": 195}, {"referenceID": 11, "context": "It should be highlighted that the frame rate normalization approach proposed in [12] is similar to our method in the sense that both change the features extraction according to the ROS.", "startOffset": 80, "endOffset": 84}, {"referenceID": 11, "context": "The difference is that our method introduces the ROS feature to regularize the acoustic model learning, while the work in [12] changes the frame step size and so is still an implicit way to adjust the dynamic model.", "startOffset": 122, "endOffset": 126}, {"referenceID": 10, "context": "Our proposal is also related to the multi-class training approach [11], i.", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "For example in [13, 14], a speaker indicator in the form of an i-vector is involved in the model training and provides better performance.", "startOffset": 15, "endOffset": 23}, {"referenceID": 13, "context": "For example in [13, 14], a speaker indicator in the form of an i-vector is involved in the model training and provides better performance.", "startOffset": 15, "endOffset": 23}, {"referenceID": 14, "context": ", [15].", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "Attributed to the powerful learning capability, DNN has gained remarkable success particularly in speech recognition [16, 17].", "startOffset": 117, "endOffset": 125}], "year": 2015, "abstractText": "A significant performance reduction is often observed in speech recognition when the rate of speech (ROS) is too low or too high. Most of present approaches to addressing the ROS variation focus on the change of speech signals in dynamic properties caused by ROS, and accordingly modify the dynamic model, e.g., the transition probabilities of the hidden Markov model (HMM). However, an abnormal ROS changes not only the dynamic but also the static property of speech signals, and thus can not be compensated for purely by modifying the dynamic model. This paper proposes an ROS learning approach based on deep neural networks (DNN), which involves an ROS feature as the input of the DNN model and so the spectrum distortion caused by ROS can be learned and compensated for. The experimental results show that this approach can deliver better performance for too slow and too fast utterances, demonstrating our conjecture that ROS impacts both the dynamic and the static property of speech. In addition, the proposed approach can be combined with the conventional HMM transition adaptation method, offering additional performance gains.", "creator": "LaTeX with hyperref package"}}}