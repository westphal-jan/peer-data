{"id": "1506.00893", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2015", "title": "SkILL - a Stochastic Inductive Logic Learner", "abstract": "Probabilistic Inductive Logic Programming (PILP) is a rel- atively unexplored area of Statistical Relational Learning which extends classic Inductive Logic Programming (ILP). This work introduces SkILL, a Stochastic Inductive Logic Learner, which takes probabilistic annotated data and produces First Order Logic theories. Data in several domains such as medicine and bioinformatics have an inherent degree of uncer- tainty, that can be used to produce models closer to reality. SkILL can not only use this type of probabilistic data to extract non-trivial knowl- edge from databases, but it also addresses efficiency issues by introducing a novel, efficient and effective search strategy to guide the search in PILP environments. The capabilities of SkILL are demonstrated in three dif- ferent datasets: (i) a synthetic toy example used to validate the system, (ii) a probabilistic adaptation of a well-known biological metabolism ap- plication, and (iii) a real world medical dataset in the breast cancer domain. Results show that SkILL can perform as well as a deterministic ILP learner, while also being able to incorporate probabilistic knowledge that would otherwise not be considered.", "histories": [["v1", "Tue, 2 Jun 2015 14:10:02 GMT  (18kb)", "http://arxiv.org/abs/1506.00893v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["joana c\\^orte-real", "theofrastos mantadelis", "in\\^es dutra", "ricardo rocha"], "accepted": false, "id": "1506.00893"}, "pdf": {"name": "1506.00893.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["jcr@dcc.fc.up.pt", "theo.mantadelis@dcc.fc.up.pt", "ines@dcc.fc.up.pt", "ricroc@dcc.fc.up.pt"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.00 893v 1 [cs.A I] 2 Jun 2"}, {"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to assert themselves, that they are able to survive on their own."}, {"heading": "2 Motivational Example", "text": "It is a game in which two players play one of the three objects - either stone, paper or scissors - at the same time, by moving their hands, and the winner is selected on the basis of the rules shown in Fig. 1 (which use the prologue syntax). If the dates of this game were recorded, it would include the selection of objects for each round as well as the result of each game, illustrated in Fig. 2, where the first argument represents each round (consecutive integers), the second argument is the player (PlayerA, PlayerB and PlayerC), and the third argument corresponds to the result of each player (Stone, Paper or Scissors). Predict Beats / 3 represents for each round which player is the winner (second argument) and which is the loser (third argument)."}, {"heading": "3 SkILL", "text": "SkILL is a tool that can extract non-trivial knowledge (FOL theories) from probabilistic data. As in the case of ILP systems, SkILL has three main components: Probabilistic background knowledge (PBK) represents the basic information known about the problem, and can consist of rules as well as facts, either probable or not. Probabilistic examples (PE) represent the observations the system is trying to explain. In the classical ILP setting, there can be positive and negative examples, but in the probable environment this information must be encoded as probabilities. These probabilities are the expected values of examples and can represent either statistical information or the degree of belief in an example (based on probability structures of type I or type II [5]."}, {"heading": "3.1 Traversing the Search Space", "text": "This year it is more than ever before."}, {"heading": "3.2 Evaluation Metrics", "text": "The RMSE of a hypothesis H can be used as: RMSEH = 1 | PE | PE is the generalization of the discrete accuracy to calculate the probability, as introduced by De Raedt and Thon [21] and used by Muggleton [15]. The RMSE of a hypothesis H can be used as: RMSEH = 1 | PE | PE = 1 PPE = 1 PPE = 1 PPE = 1 PPE = 1 PPE = 1 PPE = 1 PPE = 1 PPE = 1 PPE = 1 PH (ei) 2 (1), where PH (ei) indicates the probability that H \u2212 P = 1 PPE = 1 \u2212 P \u2212 1 P = 1 \u2212 P \u2212 P = 1 P = 1 \u2212 P = 1 - P = 1 PE = 1 PE = 1 PE = 1 = 1 PE = 1 = 1 PPE = 1 = 1 PPE = 1 = 1 PPE = 1 = 1 = 1 PE = 1 PPE = 1 PPE = 1 = 1 PPE = 1 PPE = 1 = 1 PPE | PE = 1 | PE = 1 PPE = 1 | PE is the generalization of the discrete accuracy to calculate the probability, as introduced by De Raedt and Thon [21] and used by Muggleton [15]."}, {"heading": "3.3 Pruning Combinations", "text": "In fact, it is still too early to say that it is a reactionary project, and that it is a purely reactionary project to realize a reactionary project."}, {"heading": "12 end", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "13 end", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "14 end", "text": "15 give good combinations (HypsN) The determination of the best truncation strategies to use these limits is not obvious, since we must take into account the predictions of a hypothesis in all examples. As the data will most likely not be completely independent or mutually exclusive, the strategies must take into account that the contribution of a hypothesis varies greatly in a combination of two hypotheses, and therefore care must be taken not to cut off rules that may have been important. This concept is better illustrated in Figure 4.Figure 4 (a), where the shaded area represents the possible contribution of the disjunction of hypotheses and the blue dots are the estimated values PH1, H2 (ei) for the disjunction, which in the case of our function may be a good combination () the values in the middle of this interval. Since hypotheses are combined using disjunctions, the value of the combination for a given example can only be greater or equal than the value of any hypothesis ()."}, {"heading": "4 Experimental Settings", "text": "The main focus of SkILL is the discovery of non-trivial knowledge from a data set to explain observations. Currently, the quality of discovered knowledge is assessed by two different metrics (probabilistic accuracy or RMSE).In addition, the FOL theories found by SkILL can also be used for classification by introducing a threshold, which could be learned from the original observations or chosen arbitrarily. This approach has an advantage over the classical ILP (such as Aleph) in its ability to deal with noise in the data. As such, this work presents experiments of both types: the metabolism dataset is used to evaluate the classification accuracy of the system, and a medical dataset of undefined biopsies is used as the basis for extracting non-trivial knowledge in this area."}, {"heading": "4.1 Classification", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "4.2 Knowledge extraction", "text": "This year it is so far that it will be able to mention the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the r"}, {"heading": "5 Related Work", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "6 Conclusions", "text": "This paper presented the PILP learner SkILL, which extends the classical ILP learners by incorporating probabilistic facts and rules into its BK, as well as using probabilistic examples. There are various semantics that can be applied to probabilistic data, and a toy example of probabilities that are used as marginal distributions to motivate the use of data annotated with probabilities was presented. Subsequently, some details about setting SkILL were presented, namely the focus on the strategy of traversing the search space, the evaluation metrics that are applied to hypotheses, and how the search can be efficiently circumscribed. SkILL generates theories by combining hypotheses using a ranking metric and always retaining a number of random hypotheses to ensure that weaker candidates are still taken into account. The evaluation metrics used to select the best hypotheses and to derive the search from probabilistic errors (ILSE), because they are probabilistic principles (MSE) and probabilistic errors (MSE)."}], "references": [{"title": "The YAP Prolog System", "author": ["V. Santos Costa", "R. Rocha", "L. Damas"], "venue": "Journal of Theory and Practice of Logic Programming, 12(1 & 2):5\u201334,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "ProbLog: A probabilistic prolog and its application in link discovery", "author": ["Luc De Raedt", "Angelika Kimmig", "Hannu Toivonen"], "venue": "In IJCAI,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Predicting Malignancy from Mammography Findings and Image-Guided Core Biopsies", "author": ["P. Ferreira", "N. Fonseca", "I. Dutra", "R. Woods", "E. Burnside"], "venue": "International Journal of Data Mining and Biomedicine,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Evaluating inference algorithms for the prolog factor language", "author": ["T. Gomes", "V. Santos Costa"], "venue": "In Fabrizio Riguzzi and Filip \u017delezn\u00fd, editors, Inductive Logic Programming, volume 7842 of Lecture Notes in Computer Science, pages 74\u201385. Springer Berlin Heidelberg,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "An Analysis of First-Order Logics of Probability", "author": ["J. Halpern"], "venue": "Artificial intelligence, 46(3):311\u2013350,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1990}, {"title": "Basic principles of learning bayesian logic programs", "author": ["K. Kersting", "L. De Raedt"], "venue": "In Probabilistic Inductive Logic Programming - Theory and Applications, pages 189\u2013221,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Probabilistic Explanation Based Learning", "author": ["A. Kimmig", "L. De Raedt", "H. Toivonen"], "venue": "In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, pages 176\u2013187. Springer,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "On the Implementation of the Probabilistic Logic Programming Language ProbLog", "author": ["A. Kimmig", "B. Demoen", "L. De Raedt", "V. Santos Costa", "R. Rocha"], "venue": "Theory and Practice of Logic Programming, 11(2 & 3):235\u2013262,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning the Structure of Markov Logic Networks", "author": ["S. Kok", "P. Domingos"], "venue": "In International Conference on Machine learning, pages 441\u2013448. ACM,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Using Machine Learning to Identify Benign Cases with Non-Definitive Biopsy", "author": ["F. Kuusisto", "I. Dutra", "H. Nassif", "Y. Wu", "M. Klein", "H. Neuman", "J. Shavlik", "E. Burnside"], "venue": "In International Conference on e-Health Networking, Application & Services, page 283\u2013285, Lisbon, Portugal, October", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Relational Data Mining", "author": ["N. Lavrac", "S. Dzeroski"], "venue": "Springer, September", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Efficient Algorithms for Prolog Based Probabilistic Logic Programming", "author": ["T. Mantadelis"], "venue": "PhD thesis, Katholieke Universiteit Leuven, November", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Nesting probabilistic inference", "author": ["T. Mantadelis", "G. Janssens"], "venue": "Computing Research Repository, abs/1112.3785,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "MetaBayes: Bayesian Meta-Interpretive Learning using Higher-Order Stochastic Refinement", "author": ["S. Muggleton", "D. Lin", "J. Chen", "A. Tamaddoni-Nezhad"], "venue": "In Inductive Logic Programming, pages 1\u201317. Springer,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Meta-interpretive learning: application to grammatical inference", "author": ["S. Muggleton", "D. Lin", "N. Pahlavi", "A. Tamaddoni-Nezhad"], "venue": "Machine learning,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Inductive Logic Programming: Theory and Methods", "author": ["S. Muggleton", "L. De Raedt"], "venue": "Journal of Logic Programming, 19/20:629\u2013679,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1994}, {"title": "TopLog: ILP Using a Logic Program Declarative Bias", "author": ["S. Muggleton", "J. Santos", "C. Almeida", "A. Tamaddoni-Nezhad"], "venue": "In International Conference on Logic Programming, pages 687\u2013692. Springer,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Stochastic logic programs. In New Generation Computing", "author": ["Stephen Muggleton"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1996}, {"title": "Malignancy rates after surgical excision of discordant breast biopsies", "author": ["B. Poole", "J. Wecsler", "P. Sheth", "S. Sener", "L. Wang", "L. Larsen", "D. Tripathy", "J. Lang"], "venue": "Journal of Surgical Research,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Probabilistic inductive logic programming", "author": ["L. De Raedt", "K. Kersting"], "venue": "In International Conference on Algorithmic Learning Theory, pages 19\u201336. Springer,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "Probabilistic Rule Learning", "author": ["L. De Raedt", "I. Thon"], "venue": "In Inductive Logic Programming, pages 47\u201358. Springer,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Markov Logic Networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine learning,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "PRISM: A language for symbolic-statistical modeling", "author": ["Taisuke Sato", "Yoshitaka Kameya"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1997}, {"title": "Available from http://web.comlab.ox.ac.uk/oucl/research/areas/ machlearn/Aleph", "author": ["A. Srinivasan"], "venue": "The Aleph Manual,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}], "referenceMentions": [{"referenceID": 19, "context": "Statistical Relational Learning (SRL) [20] is a well-known collection of techniques whose main objective is to produce interpretable probabilistic classifiers, often in the form of readable logical sentences.", "startOffset": 38, "endOffset": 42}, {"referenceID": 22, "context": "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.", "startOffset": 147, "endOffset": 163}, {"referenceID": 21, "context": "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.", "startOffset": 147, "endOffset": 163}, {"referenceID": 1, "context": "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.", "startOffset": 147, "endOffset": 163}, {"referenceID": 5, "context": "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.", "startOffset": 147, "endOffset": 163}, {"referenceID": 3, "context": "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.", "startOffset": 147, "endOffset": 163}, {"referenceID": 17, "context": "While researchers have spent their efforts on creating logic languages to represent probabilities and runtime environments that can deal with them [23,22,2,6,4,18], few works have been dedicated to learn rules from probabilistic knowledge.", "startOffset": 147, "endOffset": 163}, {"referenceID": 10, "context": "In this work, we introduce SkILL \u2013 a Stochastic Inductive Logic Learner \u2013 which can combine the rule learning capability of classic Inductive Logic Programming (ILP) [11,16] with uncertain knowledge as probabilistic annotated data to produce First Order Logic (FOL) theories.", "startOffset": 166, "endOffset": 173}, {"referenceID": 15, "context": "In this work, we introduce SkILL \u2013 a Stochastic Inductive Logic Learner \u2013 which can combine the rule learning capability of classic Inductive Logic Programming (ILP) [11,16] with uncertain knowledge as probabilistic annotated data to produce First Order Logic (FOL) theories.", "startOffset": 166, "endOffset": 173}, {"referenceID": 19, "context": "Probabilistic Inductive Logic Programming (PILP) [20]", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.", "startOffset": 43, "endOffset": 46}, {"referenceID": 16, "context": "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.", "startOffset": 108, "endOffset": 115}, {"referenceID": 11, "context": "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.", "startOffset": 108, "endOffset": 115}, {"referenceID": 1, "context": "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.", "startOffset": 141, "endOffset": 146}, {"referenceID": 7, "context": "SKILL runs on top of the Yap Prolog system [1], uses GILPS [17] as the basis rule generator and MetaProbLog [13,12] (an extension of ProbLog [2,8]) as the probabilistic representation language.", "startOffset": 141, "endOffset": 146}, {"referenceID": 4, "context": "3, rules are annotated according to Halpern\u2019s type 1 probability structure [5], where numbers on the left correspond to values of the game domain, which can be interpreted as the frequency with which each event happens.", "startOffset": 75, "endOffset": 78}, {"referenceID": 4, "context": "These probabilities are the expected values of examples and can represent either statistical information or the degree of belief in an example (using type I or type II probability structures [5], respectively).", "startOffset": 191, "endOffset": 194}, {"referenceID": 16, "context": "Initially, the algorithm uses the TopLog engine from the GILPS [17] ILP system, to generate all possible hypotheses composed of only one clause (line 3 in Alg.", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": "The RMSE metric penalizes predictions farther from the expected values, while PAcc is the generalization of the discrete accuracy to the probabilistic setting as introduced by De Raedt and Thon [21] and used by Muggleton [15].", "startOffset": 194, "endOffset": 198}, {"referenceID": 14, "context": "The RMSE metric penalizes predictions farther from the expected values, while PAcc is the generalization of the discrete accuracy to the probabilistic setting as introduced by De Raedt and Thon [21] and used by Muggleton [15].", "startOffset": 221, "endOffset": 225}, {"referenceID": 20, "context": "From [21], TP +TN+FP +FN = |PE|, and TP and TN are equal to the sum over all examples of min(PH(ei), P (ei)) and min(1\u2212PH(ei), 1\u2212P (ei)), respectively.", "startOffset": 5, "endOffset": 9}, {"referenceID": 23, "context": "Results presented for the Aleph system [24], are collected with the default parameters (except noise, which is set to maximum).", "startOffset": 39, "endOffset": 43}, {"referenceID": 18, "context": "The biopsy is very important in determining malignancy of a lesion and usually yields definitive results; however, in 5% to 15% of cases, the results are nondefinitive [19].", "startOffset": 168, "endOffset": 172}, {"referenceID": 9, "context": "Machine learning methods have been used to mitigate this and other problems by allowing to produce models of the data that can distinguish between benign and malignant cases [10,3].", "startOffset": 174, "endOffset": 180}, {"referenceID": 2, "context": "Machine learning methods have been used to mitigate this and other problems by allowing to produce models of the data that can distinguish between benign and malignant cases [10,3].", "startOffset": 174, "endOffset": 180}, {"referenceID": 19, "context": "The PILP setting was first introduced in [20], where three distinct settings \u2013 extended from traditional ILP [11] \u2013 are put forward: probabilistic entailment,", "startOffset": 41, "endOffset": 45}, {"referenceID": 10, "context": "The PILP setting was first introduced in [20], where three distinct settings \u2013 extended from traditional ILP [11] \u2013 are put forward: probabilistic entailment,", "startOffset": 109, "endOffset": 113}, {"referenceID": 20, "context": "Later, Raedt and Thon presented the system ProbFOIL [21], which is not only capable of performing induction over probabilistic examples, but also on background knowledge encoded as ProbLog probabilistic facts.", "startOffset": 52, "endOffset": 56}, {"referenceID": 6, "context": "Probabilistic Explanation Based Learning (PEBL) [7] can find the most likely FOL clause which explains a set of positive examples in terms of a database of probabilistic facts.", "startOffset": 48, "endOffset": 51}, {"referenceID": 21, "context": "Orthogonally, Markov Logic Networks (MLNs) [22] also combine structure learning using a FOL framework with a probabilistic Markov Random Fields approach [9].", "startOffset": 43, "endOffset": 47}, {"referenceID": 8, "context": "Orthogonally, Markov Logic Networks (MLNs) [22] also combine structure learning using a FOL framework with a probabilistic Markov Random Fields approach [9].", "startOffset": 153, "endOffset": 156}, {"referenceID": 8, "context": "Structure learning for MLNs softens the hypotheses by using probabilities and as such produces better classifiers, as shown in [9]; however, MLNs still consider crisp background knowledge, not taking into account the possibility of probabilistic logic facts.", "startOffset": 127, "endOffset": 130}, {"referenceID": 14, "context": "Finally, Meta-Interpretive Learning [15] \u2013 which is a technique aimed at performing predicate invention in ILP using abduction \u2013 can also be used to perform probabilistic structure learning by calculating prior and posterior distributions on the hypotheses space according to the examples explained by a given hypothesis [14].", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "Finally, Meta-Interpretive Learning [15] \u2013 which is a technique aimed at performing predicate invention in ILP using abduction \u2013 can also be used to perform probabilistic structure learning by calculating prior and posterior distributions on the hypotheses space according to the examples explained by a given hypothesis [14].", "startOffset": 321, "endOffset": 325}], "year": 2015, "abstractText": "Probabilistic Inductive Logic Programming (PILP) is a relatively unexplored area of Statistical Relational Learning which extends classic Inductive Logic Programming (ILP). This work introduces SkILL, a Stochastic Inductive Logic Learner, which takes probabilistic annotated data and produces First Order Logic theories. Data in several domains such as medicine and bioinformatics have an inherent degree of uncertainty, that can be used to produce models closer to reality. SkILL can not only use this type of probabilistic data to extract non-trivial knowledge from databases, but it also addresses efficiency issues by introducing a novel, efficient and effective search strategy to guide the search in PILP environments. The capabilities of SkILL are demonstrated in three different datasets: (i) a synthetic toy example used to validate the system, (ii) a probabilistic adaptation of a well-known biological metabolism application, and (iii) a real world medical dataset in the breast cancer domain. Results show that SkILL can perform as well as a deterministic ILP learner, while also being able to incorporate probabilistic knowledge that would otherwise not be considered.", "creator": "LaTeX with hyperref package"}}}