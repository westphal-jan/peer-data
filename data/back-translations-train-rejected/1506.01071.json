{"id": "1506.01071", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2015", "title": "Fast Generation of Best Interval Patterns for Nonmonotonic Constraints", "abstract": "In pattern mining, the main challenge is the exponential explosion of the set of patterns. Typically, to solve this problem, a constraint for pattern selection is introduced. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are neither monotonic nor anti-monotonic, which makes it difficult to generate patterns satisfying these constraints. In this paper we introduce the notion of \"generalized monotonicity\" and Sofia algorithm that allow generating best patterns in polynomial time for some nonmonotonic constraints modulo constraint computation and pattern extension operations. In particular, this algorithm is polynomial for data on itemsets and interval tuples. In this paper we consider stability and delta-measure which are nonmonotonic constraints and apply them to interval tuple datasets. In the experiments, we compute best interval tuple patterns w.r.t. these measures and show the advantage of our approach over postfiltering approaches.", "histories": [["v1", "Tue, 2 Jun 2015 21:32:14 GMT  (52kb)", "https://arxiv.org/abs/1506.01071v1", "18 pages; 2 figures; 2 tables; 1 algorithm; PKDD 2015 Conference Scientific Track"], ["v2", "Tue, 16 Jun 2015 15:31:19 GMT  (52kb)", "http://arxiv.org/abs/1506.01071v2", "18 pages; 2 figures; 2 tables; 1 algorithm; PKDD 2015 Conference Scientific Track"]], "COMMENTS": "18 pages; 2 figures; 2 tables; 1 algorithm; PKDD 2015 Conference Scientific Track", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["aleksey buzmakov", "sergei o kuznetsov", "amedeo napoli"], "accepted": false, "id": "1506.01071"}, "pdf": {"name": "1506.01071.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli"], "emails": ["aleksey.buzmakov@inria.fr,", "skuznetsov@hse.ru,", "amedeo.napoli@loria.fr"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.01 071v 2"}, {"heading": "1 Introduction", "text": "Measures have been proposed to overcome the problem of the combinatorial explosion in the number of valid patterns that can be detected in a dataset. [18] For example, support for patterns, i.e. the number of objects covered by the pattern, is one of the most famous patterns of pattern quality. [12, 1] The final release is available at link.springer.com. In particular, support satisfies the property of anti-monotonicity (also known as the \"a priori principle\"), i.e. the larger pattern is the smaller threshold of support. Many other measures can be mentioned, e.g. benefit limitation [24], pattern stability [10, 15], edge usage [19], edge proximity [13], MCCS [16], cosmic interest [4], pattern robustness [17], etc. Some of these measures (e.g. support, robustness for generators [17], or upper constraint of MCCS [16]) are \"global monotonic.\""}, {"heading": "2 Data Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 FCA and Pattern structures", "text": "The formal concept analysis (FCA) is a formalism for the discovery of knowledge and data mining thanks to the design of concept grids (6). It is also handy for describing models of itemset mining, and, since [14], grid patterns of closed itemsets (i.e., concept grids) and closed descriptions are used for the concise representation of association rules. For more complex data such as sequences and graphics, one can use an extension of the basic model, called pattern [5]. With pattern structures, it is possible to define closed descriptions and give a concise representation of association rules for various descriptions with a natural order (such as subgraph isomorphism order). A pattern is a triple (G, (D,), compound), where G is a set of objects (D,) where G is a set of objects (D,) where G is a set of objects, where G is a set of objects, where G is a set of lattice objects, where G is a set of objects, lattice is a set of semitice descriptions, which is a set of semitice, which is a set of semitice it is a semitice (semitice)."}, {"heading": "2.2 Interval pattern structure", "text": "One possible instantiation of pattern structures is the introduction of interval pattern structures to support efficient processing of numerical data without binarization [8]. Given k numerical or interval attributes whose values are of the form [a, b], where a, b and r, the language of a pattern space is given by tuples of intervals of size k. For the sake of simplicity, we call intervals of the form [a, a] by a.Figure 1a an interval dataset. It contains 6 objects and 2 attributes. An interval as an attribute value corresponds to uncertainty in the value of the attribute. For example, the value of m1 for g2 is exactly known, while the value of m2 is in [1, 2]. Given this intuition for intervals, it is natural to define the similarity of two intervals as its convex hull."}, {"heading": "2.3 Stability index of a concept", "text": "For real datasets, the number of patterns is very large, even the calculation of the number of closed patterns is a # P-complete problem [9]. Various measures have been tested to select the most interesting patterns, such as stability [10]. Stability measures the independence of a concept pattern, i.e., the result of (\u00b7) randomness in data is equal to the concept intention (named after Int (C). Stability of the concept rod (C) is the relative number of subsets of the concept scope (named after Ext (C))), its descriptions, i.e. the result of (\u00b7) is equal to the concept intention (named after Int (C). Stability of the concept rod (C) is the relative number of subsets of the term (C)."}, {"heading": "2.4 Projections of Pattern Structures", "text": "The approach proposed in this paper is based on projections introduced to reduce the complexity of arithmetic patterns."}, {"heading": "2.5 Projections of Interval Pattern Structures", "text": "s use W = {w1, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 W |} to denote all possible values of the left and right endpoints of the intervals corresponding to the attribute in a dataset, so that w1 < w2 < \u00b7 \u00b7 \u00b7 < w | W |}. By reducing the setpoint of the possible values for the left or right end of the interval, we define a projection. Let us look at this in more detail, as the only possible value for the left endpoint of an interval and the only possible value for the right endpoint of an interval, then all the interval patterns are projected onto [w1, w | W | W]. Let us look at two sets L, R that are such that w1 and w | W | W | W | W are the only possible endpoint."}, {"heading": "3 \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Anti-monotonicity w.r.t. a Projection", "text": "Our algorithm is based on projection antimonotonicity, a new idea introduced in this paper. (Many interest metrics for patterns, e.g. stability, are not (anti-) monotonicity.) A measurement variable M is called an anti-monotonic pattern when for two patterns q threshold variables q p, M (q) \u2265 M (p). Support is an anti-monotonical measurement variable w.r.t. Sample variable with support greater than a threshold [1, 12, 14]. Projection antimonotonicity is a generalization of the standard antimonotonicity and enables efficient work with a larger set of interest metrics p. Definition 2 Given a pattern structure P and a price projection, a measurement variable M is called an anti-monotonicity measurement variable w.r.t. the projection antimonotonicity is a measurement variable called an M when working with a larger set of monotonicity (the P)."}, {"heading": "3.2 Anti-monotonicity w.r.t. a Chain of Projections", "text": "In fact, we are able to find a pattern that consists of small frequent itemsets, which are then expanded to larger ones. This corresponds to the extension of a more detailed projection, i.e., the pattern structure P and a chain of projections P (x) = x. For example, to find frequent itemsets, which we typically extend to larger itemsets. This corresponds to the extension of a more detailed projection. The pattern structure P and a chain of projections P < 1 < \u00b7 < \u00b7 K = 1, Measure M is called intervention."}, {"heading": "3.3 Algorithms", "text": "Data: A pattern structure P, a chain of projections composed of different patterns composed of different patterns. (Given patterns, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 k), a measurement quantity M anti-monotonic for the chain. (Given patterns, \u00b7 \u00b7 \u00b7 K), a measurement quantity M anti-monotonic for the chain. (Given patterns, \u00b7 \u00b7 \u00b7 K), a measurement quantity. (0 < i \u2264 k), is a threshold value for M, and Pi \u2212 1 is the set of patterns for the projection. (Given patterns of all patterns whose threshold M is higher than the threshold to which we should extend. (0 < i \u2264 k), a threshold. (Given patterns, \u00b7 K), is a threshold value. (Given patterns, \u00b7 K). (Given patterns, \u00b7 K). (Given patterns, K), (given patterns, K), (given patterns, K), (more)."}, {"heading": "3.4 \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm for Interval Tuple Data", "text": "We say that each component of a tuple p corresponds to an attribute m \u00b2 M, where M is the set of interval attributes. Since the set Wm is fully ordered, we also designate according to W (j) m and W (\u2212 j) m the sets containing the first j (smallest) elements and the last j (largest) elements from Wm. A projection chain for interval tuple data is formed in the same way as in Example 5. We start from the projection, which contains only a pattern corresponding to the largest interval in each component, i.e. for a projection m, a projection of interval tuple data is formed as we discussed in Example 5."}, {"heading": "3.5 \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm for Closed Patterns", "text": "Here we show how to adjust the algorithm for closed patterns. A closed pattern in surface patterns is not necessarily closed in surface patterns, i.e., a pattern structure P = (G, (D,), is converted into surface patterns in PC = (G, (DC, C), C), where DC = 2G). Furthermore, for all x, y and DC x C y = (x y), where a diamond operator is calculated in P and 3 (g, G) = {g}. Therefore, each pattern p in DC corresponds to a closed pattern p in D. A projection of P induces a projection of C, which is calculated in P and vice versa."}, {"heading": "3.6 \u0394-measure and \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm", "text": "In this subsection, we show that \u0394 measure is antimonotonous for each projection; it is a stronger condition than the one required in definition 3. \u0394 measure works for closed patterns, and therefore we identify each description by its extent (subsection 3.5). Proposition 2 is antimonotonous for each projection. Proof: Through the properties of a projection is a magnitude of the magnitude of the magnitude of the magnitude of P [5]. Let us consider the magnitude E and the magnitude of its derivative to the magnitude P. Let us suppose that Ep is a magnitude E preimage for the projection. Since Ec and Ep are magnitude of the magnitude in P, the quantity Ecp = Ec \u2264 Ep is a magnitude in P (the intersection of two closed propositions is a closed projection). Since Ep is a preimage of E, then Ep 6 \u2264 Ec (otherwise Ep) is a preimage of the magnitude of Ecp and not the dimension of Ecp = Ecp (So Ecp)."}, {"heading": "3.7 Example of \u0394-Stable Patterns in Interval Tuple Data", "text": "Let us look at the example in Figure 1 and show how we define all \u0394-stable patterns with a threshold \u03b8 = 2. The projection chain for this example is given in Example 5, it contains 4 projections: \u0432 0 = \u0432 m1 [{0}, {1}] m2 [{0}, {2}] 1 = \u0432 m1 [{0,1}, {0,1}] m2 [{0}, {2}] 2 = \u0432 m1 [{0,1}, {0,1}] m2 [{0,1}] 3 = \u0438 m1 [{0,1}, {0,1}] m2 [{0,1,2}, {0,1,2}]] Since we are looking for closed patterns, each pattern can be identified by its dimension. In Table 1, all patterns are given by their dimensions, i.e. by elements of DC. For each pattern \u0394-i is shown. A cell is shown in grey if the pattern is not taken into account more (the value of the patterns is less than 2)."}, {"heading": "4 Experiments and Discussion", "text": "In this section, we compare our approach with approaches based on post-filtering. In fact, there is no approach that can directly degrade stable patterns, e.g. stable, \u0394-stable or robust patterns. The known approaches use post-filtering to degrade such patterns [15, 13, 2, 17]. Recently, it has also been shown that it is more efficient to degrade interval data without binarization [8]. In their paper, the authors introduce the MinIntChange algorithm to work directly with interval data. Thus, we compare \u03b8-\u043e\u0441\u043e\u0441\u0438\u0445 and MinIntChange to find error-stable patterns. We find \u0394-stable concepts with a computer with a capacity of 3.40GHz and then adjust the frequency threshold so that all \u0394-stable patterns belong to the common ones. Experiments are carried out on an \"Intel (R) Core (TM) i7-2600 CPU @ 3.40GHz\" calculator with 8b memory Ubuntu + 14.04 operating system and are not coded."}, {"heading": "4.1 Dataset Simplification", "text": "For interval tuple data, stable patterns can lie very deep in the search space, so none of the algorithms can find them quickly. Therefore, we join some similar values for each attribute in an interval as follows. At a threshold 0 < \u03b2, two consecutive numbers wi and wi + 1 from a set of values W are joined in the same interval, if wi + 1 \u2212 wi < \u03b2. To set the threshold \u03b2 correctly, we use another threshold 0 < \u03b3 < 1, which is much easier to set. If we assume that the values of the attribute are distributed by several states with the centers w \u00b2 1, \u00b7 \u00b7, w \u00b2 l, then it stands to reason that the difference between the closest centers abs (w \u00b2 i \u2212 w \u00b1 1) is much greater than the difference between the closest values. If we order all values in increasing order and find the maximum difference between states \u04321, we can give an idea of the distance between the typical states in the data."}, {"heading": "4.2 Datasets", "text": "We extract several data sets from the database of Bilkent University 1. The data sets are summarized in Table 2. The names of the data sets are given by standard abbreviations used in the database of Bilkent University. For each data set, we specify the number of objects and attributes and the threshold \u03b3 for which the experiments are carried out. For example, the database EM has 61 objects, 9 numerical attributes, and the threshold \u03b3 is set to 0.3. Categorical attributes and rows with missing values, if any, are removed from the data sets."}, {"heading": "4.3 Experiments", "text": "The last algorithm is abbreviated as MIC. Since the MinIntChange algorithm sometimes produces too many patterns, i.e. we do not have enough memory in our computer to check them all, we interrupt the procedure and display the corresponding time in gray. In addition, we show the number of best patterns and the corresponding threshold. The support threshold for finding the best \u0394-stable patterns is also shown. Thus, dataset CN 5362 contains best \u0394-stable patterns, all of which are \u0394 of 2. To find all these patterns with a follow-up, we should reduce frequent patterns with a support threshold of below 30 or 30105 = 30%. Dataset CN calculates all these patterns in 2.4 seconds, while 1http: / / funapp.cs.bilkent.edut.eu / significantly exceeds the threshold of 30 or 30105 = 30%."}, {"heading": "5 Conclusion", "text": "In this paper, we have introduced a new class of interest metrics that are anti-monotonous, i.e. a chain of projections. We have designed a new algorithm that is able to efficiently find the best metrics for the interval tuple data. The experiments reported in the paper are proof of the efficiency of the \u03b8-Hig\u03b9\u03b1 algorithms based on post-filtering compared to indirect approaches. Many future research directions are possible. Various metrics should be investigated in combination with \u03b8-Higli\u03b1, one of which is robustness, which is very stable and can be applied to non-binary data. Moreover, choosing a projection chain is not easy and can affect the efficiency of the algorithms. Therefore, a thorough investigation of suitable projection chains should be carried out."}], "references": [{"title": "Fast algorithms for mining association rules", "author": ["Rakesh Agrawal", "Ramakrishnan Srikant", "Others"], "venue": "In Proc. 20th int. conf. very large data bases, VLDB,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1994}, {"title": "On Projections of Sequential Pattern Structures (with an application on care trajectories)", "author": ["Aleksey Buzmakov", "Elias Egho", "Nicolas Jay", "Sergei O. Kuznetsov", "Amedeo Napoli", "Chedy R\u00e4\u0131ssi"], "venue": "In Proc. 10th Int. Conf. Concept Lattices Their Appl.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Scalable Estimates of Concept Stability", "author": ["Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "Form. Concept Anal.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Scaling up cosine interesting pattern discovery: A depth-first method", "author": ["Jie Cao", "Zhiang Wu", "Junjie Wu"], "venue": "Inf. Sci. (Ny).,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Pattern Structures and Their Projections", "author": ["Bernhard Ganter", "Sergei O. Kuznetsov"], "venue": "Concept. Struct. Broadening Base,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Formal Concept Analysis: Mathematical Foundations", "author": ["Bernhard Ganter", "Rudolf Wille"], "venue": "Springer, 1st edition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Mining top-k frequent closed patterns without minimum support", "author": ["Jiawei Han", "Jianyong Wang", "Ying Lu", "P Tzvetkov"], "venue": "In Data Mining,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Revisiting Numerical Pattern Mining with Formal Concept Analysis", "author": ["Mehdi Kaytoue", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "IJCAI", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "On Computing the Size of a Lattice and Related Decision Problems", "author": ["Sergei O. Kuznetsov"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "On stability of a formal concept", "author": ["Sergei O. Kuznetsov"], "venue": "Ann. Math. Artif. Intell.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Learning Closed Sets of Labeled Graphs for Chemical Applications", "author": ["Sergei O. Kuznetsov", "Mikhail V. Samokhin"], "venue": "Inductive Log. Program. SE - 12,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Efficient Algorithms for Discovering Association Rules", "author": ["Heikki Mannila", "Hannu Toivonen", "A Inkeri Verkamo"], "venue": "In Knowl. Discov. Data Min.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Efficient mining of all margin-closed itemsets with applications in temporal knowledge discovery and classification by compression", "author": ["Fabian Moerchen", "Michael Thies", "Alfred Ultsch"], "venue": "Knowl. Inf. Syst.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Efficient Mining of Association Rules Using Closed Itemset Lattices", "author": ["Nicolas Pasquier", "Yves Bastide", "Rafik Taouil", "Lotfi Lakhal"], "venue": "Inf. Syst.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "On succinct representation of knowledge community taxonomies with formal concept analysis", "author": ["Camille Roth", "Sergei A. Obiedkov", "Derrick G. Kourie"], "venue": "Int. J. Found. Comput. Sci.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Interesting pattern mining in multi-relational data", "author": ["Eirini Spyropoulou", "Tijl De Bie", "Mario Boley"], "venue": "Data Min. Knowl. Discov.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Finding Robust Itemsets under Subsampling", "author": ["Nikolaj Tatti", "Fabian Moerchen", "Toon Calders"], "venue": "ACM Trans. Database Syst.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Interesting Patterns", "author": ["Jilles Vreeken", "Nikolaj Tatti"], "venue": "Freq. Pattern Min.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Self-sufficient itemsets", "author": ["Geoffrey I. Webb"], "venue": "ACM Trans. Knowl. Discov. Data,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Filtered-top-k association discovery", "author": ["Geoffrey I. Webb"], "venue": "Wiley Interdiscip. Rev. Data Min. Knowl. Discov.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Extracting redundancy-aware top-k patterns", "author": ["Dong Xin", "Hong Cheng", "Xifeng Yan", "Jiawei Han"], "venue": "In Proc. 12th ACM SIGKDD Int. Conf. Knowl. Discov. data Min. - KDD", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Mining significant graph patterns by leap search", "author": ["Xifeng Yan", "Hong Cheng", "Jiawei Han", "Philip S. Yu"], "venue": "In Proc. 2008 ACM SIGMOD Int. Conf. Manag. data - SIGMOD", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "CloSpan: Mining Closed Sequential Patterns in Large Databases", "author": ["Xifeng Yan", "Jiawei Han", "Ramin Afshar"], "venue": "In Proc. SIAM Int\u2019l Conf. Data Min.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Mining itemset utilities from transaction databases", "author": ["Hong Yao", "Howard J Hamilton"], "venue": "Data Knowl. Eng.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}], "referenceMentions": [{"referenceID": 17, "context": "Interestingness measures were proposed to overcome the problem of combinatorial explosion of the number of valid patterns that can be discovered in a dataset [18].", "startOffset": 158, "endOffset": 162}, {"referenceID": 11, "context": ", the larger the pattern is the smaller the support is [12, 1].", "startOffset": 55, "endOffset": 62}, {"referenceID": 0, "context": ", the larger the pattern is the smaller the support is [12, 1].", "startOffset": 55, "endOffset": 62}, {"referenceID": 23, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 64, "endOffset": 68}, {"referenceID": 9, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 88, "endOffset": 96}, {"referenceID": 14, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 88, "endOffset": 96}, {"referenceID": 18, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 149, "endOffset": 153}, {"referenceID": 3, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 171, "endOffset": 174}, {"referenceID": 16, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 195, "endOffset": 199}, {"referenceID": 16, "context": ", support, robustness for generators [17], or upper bound constraint of MCCS [16]) are \u201cglobally anti-monotonic\u201d, i.", "startOffset": 37, "endOffset": 41}, {"referenceID": 15, "context": ", support, robustness for generators [17], or upper bound constraint of MCCS [16]) are \u201cglobally anti-monotonic\u201d, i.", "startOffset": 77, "endOffset": 81}, {"referenceID": 3, "context": "For example, for \u201clocally anti-monotonic\u201d cosine interest [4], the extension of a pattern Y consists in adding only attributes with a smaller support than any attribute from Y .", "startOffset": 58, "endOffset": 61}, {"referenceID": 14, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 40, "endOffset": 52}, {"referenceID": 12, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 40, "endOffset": 52}, {"referenceID": 16, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 40, "endOffset": 52}, {"referenceID": 21, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 94, "endOffset": 98}, {"referenceID": 18, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 172, "endOffset": 176}, {"referenceID": 9, "context": "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.", "startOffset": 34, "endOffset": 38}, {"referenceID": 12, "context": "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.", "startOffset": 57, "endOffset": 61}, {"referenceID": 16, "context": "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.", "startOffset": 77, "endOffset": 81}, {"referenceID": 6, "context": "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.", "startOffset": 67, "endOffset": 78}, {"referenceID": 20, "context": "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.", "startOffset": 67, "endOffset": 78}, {"referenceID": 19, "context": "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.", "startOffset": 67, "endOffset": 78}, {"referenceID": 5, "context": "The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2.", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2.", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "Formal Concept Analysis (FCA) is a formalism for knowledge discovery and data mining thanks to the design of concept lattices [6].", "startOffset": 126, "endOffset": 129}, {"referenceID": 13, "context": "It is also convenient for describing models of itemset mining, and, since [14], lattices of closed itemsets (i.", "startOffset": 74, "endOffset": 78}, {"referenceID": 4, "context": "For more complex data such as sequences and graphs one can use an extension of the basic model, called pattern structures [5].", "startOffset": 122, "endOffset": 125}, {"referenceID": 10, "context": "With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].", "startOffset": 212, "endOffset": 219}, {"referenceID": 7, "context": "With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].", "startOffset": 212, "endOffset": 219}, {"referenceID": 10, "context": "As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.", "startOffset": 12, "endOffset": 16}, {"referenceID": 22, "context": "As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.", "startOffset": 135, "endOffset": 139}, {"referenceID": 7, "context": "A possible instantiation of pattern structures is interval pattern structures introduced to support efficient processing of numerical data without binarization [8].", "startOffset": 160, "endOffset": 163}, {"referenceID": 0, "context": "For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2].", "startOffset": 88, "endOffset": 94}, {"referenceID": 1, "context": "For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2].", "startOffset": 88, "endOffset": 94}, {"referenceID": 0, "context": "For example, for g1 the value of m1 is 0, while for g6 it is 1, thus given the set {g1, g6}, the uncertainty of m1 in this set is [0, 1], i.", "startOffset": 130, "endOffset": 136}, {"referenceID": 0, "context": "m1 is [0, 1].", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "For example, g 1 \u2293 g \u22c4 6 = \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 28, "endOffset": 34}, {"referenceID": 1, "context": "For example, g 1 \u2293 g \u22c4 6 = \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 36, "endOffset": 42}, {"referenceID": 0, "context": "Reciprocally, \u3008[0, 1]; [0, 2]\u3009 = {g1, g2, \u00b7 \u00b7 \u00b7 , g6}.", "startOffset": 15, "endOffset": 21}, {"referenceID": 1, "context": "Reciprocally, \u3008[0, 1]; [0, 2]\u3009 = {g1, g2, \u00b7 \u00b7 \u00b7 , g6}.", "startOffset": 23, "endOffset": 29}, {"referenceID": 8, "context": "For real datasets, the number of patterns can be very large, even computing the number of closed patterns is a #P-complete problem [9].", "startOffset": 131, "endOffset": 134}, {"referenceID": 9, "context": "Different measures were tested for selecting most interesting patterns, such as stability [10].", "startOffset": 90, "endOffset": 94}, {"referenceID": 0, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 18, "endOffset": 24}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 30, "endOffset": 36}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 30, "endOffset": 36}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 49, "endOffset": 55}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 61, "endOffset": 67}, {"referenceID": 0, "context": "(\u2205;\u22a4)[1] (4; \u30080; 2\u3009)[0.", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "1 (234; \u30080; [1, 2]\u3009)[0.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "1 (234; \u30080; [1, 2]\u3009)[0.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "2 (1234; \u30080; [0, 2]\u3009)[0.", "startOffset": 13, "endOffset": 19}, {"referenceID": 1, "context": "3 (56; \u30081; [0, 2]\u3009)[0.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "2 (123456; \u3008[0, 1]; [0, 2]\u3009)[0.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "2 (123456; \u3008[0, 1]; [0, 2]\u3009)[0.", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "Descriptions of 2 subsets of Ext(C) ({g4} and \u2205) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to \u30080; [1, 2]\u3009.", "startOffset": 179, "endOffset": 185}, {"referenceID": 1, "context": "Descriptions of 2 subsets of Ext(C) ({g4} and \u2205) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to \u30080; [1, 2]\u3009.", "startOffset": 179, "endOffset": 185}, {"referenceID": 16, "context": "Concept stability is closely related to the robustness of a closed pattern [17].", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "The problem of computing concept stability is #P-complete [10].", "startOffset": 58, "endOffset": 62}, {"referenceID": 2, "context": "A fast computable stability estimate was proposed in [3], where it was shown that this estimate ranks concepts almost in the same way as stability does.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "The value \u2206(({g2, g3, g4}; \u30080; [1, 2]\u3009)) is equal to 2.", "startOffset": 31, "endOffset": 37}, {"referenceID": 1, "context": "The value \u2206(({g2, g3, g4}; \u30080; [1, 2]\u3009)) is equal to 2.", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "Another example is \u2206((G; \u3008[0, 1]; [0, 2]\u3009)) = 2.", "startOffset": 26, "endOffset": 32}, {"referenceID": 1, "context": "Another example is \u2206((G; \u3008[0, 1]; [0, 2]\u3009)) = 2.", "startOffset": 34, "endOffset": 40}, {"referenceID": 12, "context": "\u0394-measure is related to the work of margin-closeness of an itemset [13].", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "The approach proposed in this paper is based on projections introduced for reducing complexity of computing pattern lattices [5].", "startOffset": 125, "endOffset": 128}, {"referenceID": 0, "context": "The fixed set of this projection consists of {[0, 1], 1}\u00d7 {0, 2, [0, 2]}, i.", "startOffset": 46, "endOffset": 52}, {"referenceID": 1, "context": "The fixed set of this projection consists of {[0, 1], 1}\u00d7 {0, 2, [0, 2]}, i.", "startOffset": 65, "endOffset": 71}, {"referenceID": 0, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 43, "endOffset": 49}, {"referenceID": 1, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 43, "endOffset": 49}, {"referenceID": 0, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 96, "endOffset": 102}, {"referenceID": 0, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 236, "endOffset": 242}, {"referenceID": 1, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 236, "endOffset": 242}, {"referenceID": 1, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 246, "endOffset": 252}, {"referenceID": 0, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 34, "endOffset": 40}, {"referenceID": 1, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 46, "endOffset": 52}, {"referenceID": 1, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 54, "endOffset": 60}, {"referenceID": 0, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 28, "endOffset": 34}, {"referenceID": 1, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 49, "endOffset": 55}, {"referenceID": 0, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 68, "endOffset": 74}, {"referenceID": 1, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 76, "endOffset": 82}, {"referenceID": 0, "context": "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].", "startOffset": 102, "endOffset": 113}, {"referenceID": 11, "context": "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].", "startOffset": 102, "endOffset": 113}, {"referenceID": 13, "context": "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].", "startOffset": 102, "endOffset": 113}, {"referenceID": 3, "context": ", the cosine interest of an itemset, which is only locally antimonotonic [4].", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "any projection [2].", "startOffset": 15, "endOffset": 18}, {"referenceID": 16, "context": "one can prove that robustness of closed patterns from [17] is also anti-monotonic w.", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "This projection allows only for one pattern \u3008[0, 1]; [0, 2]\u3009, i.", "startOffset": 45, "endOffset": 51}, {"referenceID": 1, "context": "This projection allows only for one pattern \u3008[0, 1]; [0, 2]\u3009, i.", "startOffset": 53, "endOffset": 59}, {"referenceID": 1, "context": ", any possible interval of the first component and only one interval [0,2] for the second component.", "startOffset": 69, "endOffset": 74}, {"referenceID": 13, "context": "Closed frequent itemsets are widely used as a condensed representation of all frequent itemsets since [14].", "startOffset": 102, "endOffset": 106}, {"referenceID": 4, "context": "However, the extents of \u03c8(P) are extents of P [5].", "startOffset": 46, "endOffset": 49}, {"referenceID": 4, "context": "By properties of a projection, an extent of \u03c8(P) is an extent of P [5].", "startOffset": 67, "endOffset": 70}, {"referenceID": 0, "context": "At the beginning \u03c80(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 152, "endOffset": 158}, {"referenceID": 1, "context": "At the beginning \u03c80(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 160, "endOffset": 166}, {"referenceID": 1, "context": "Then, in \u03c81(G, (DI ,\u2293), \u03b4) possible preimages of 123456 are patterns with descriptions \u30080; [0, 2]\u3009 and \u30081; [0, 2]\u3009 given by pattern extents 1234 and 56, respectively.", "startOffset": 91, "endOffset": 97}, {"referenceID": 1, "context": "Then, in \u03c81(G, (DI ,\u2293), \u03b4) possible preimages of 123456 are patterns with descriptions \u30080; [0, 2]\u3009 and \u30081; [0, 2]\u3009 given by pattern extents 1234 and 56, respectively.", "startOffset": 107, "endOffset": 113}, {"referenceID": 0, "context": "The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234.", "startOffset": 150, "endOffset": 156}, {"referenceID": 0, "context": "The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234.", "startOffset": 166, "endOffset": 172}, {"referenceID": 1, "context": "The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234.", "startOffset": 166, "endOffset": 172}, {"referenceID": 14, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 12, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 1, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 16, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 7, "context": "Recently it was also shown that it is more efficient to mine interval tuple data without binarization [8].", "startOffset": 102, "endOffset": 105}], "year": 2015, "abstractText": "In pattern mining, the main challenge is the exponential explosion of the set of patterns. Typically, to solve this problem, a constraint for pattern selection is introduced. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are not (anti-)monotonic, which makes it difficult to generate patterns satisfying these constraints. In this paper we introduce the notion of projection-antimonotonicity and \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm that allows efficient generation of the best patterns for some nonmonotonic constraints. In this paper we consider stability and \u0394-measure, which are nonmonotonic constraints, and apply them to interval tuple datasets. In the experiments, we compute best interval tuple patterns w.r.t. these measures and show the advantage of our approach over postfiltering approaches.", "creator": "LaTeX with hyperref package"}}}