{"id": "1506.01163", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2015", "title": "Towards Structured Deep Neural Network for Automatic Speech Recognition", "abstract": "In this paper we propose the Structured Deep Neural Network (Structured DNN) as a structured and deep learning algorithm, learning to find the best structured object (such as a label sequence) given a structured input (such as a vector sequence) by globally considering the mapping relationships between the structure rather than item by item.", "histories": [["v1", "Wed, 3 Jun 2015 08:41:05 GMT  (276kb,D)", "http://arxiv.org/abs/1506.01163v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yi-hsiu liao", "hung-yi lee", "lin-shan lee"], "accepted": false, "id": "1506.01163"}, "pdf": {"name": "1506.01163.pdf", "metadata": {"source": "CRF", "title": "Towards Structured Deep Neural Network for Automatic Speech Recognition", "authors": ["Yi-Hsiu Liao", "Hung-Yi Lee", "Lin-shan Lee"], "emails": ["r03921048@ntu.edu.tw,", "hungyilee@ntu.edu.tw,", "lslee@gate.sinica.edu.tw"], "sections": [{"heading": null, "text": "If automatic speech recognition is considered a special case of such a structured learning problem, where we have the acoustic vector sequence as input and the phoneme markup sequence as output, it becomes possible to learn comprehensively learned enunciation by enunciation as a whole, rather than frame by frame. Structured Support Vector Machine (structured SVM) has been proposed to perform ASR with structured learning, but limited by the linear nature of SVM. Here, we suggest structured DNN to use non-linear transformations in multi-layered networks as a structured and deep learning algorithm. It has been shown that they beat structured SVM in preliminary experiments on TIMIT."}, {"heading": "1. Introduction", "text": "In this context, it should be noted that the solution to the problems that have arisen in recent years is not only a problem, but also a problem that cannot be solved. (...) In this context, I would like to point out that the solution to the problem is not a problem that can be solved, but a problem that can be solved. (...) In this context, I would like to point out that the solution to the problem is not a problem, but a problem that can be solved. (...) In this context, I would like to point out that the solution to the problem is a problem that cannot be solved. (...) In this context, I would like to point out that it is a problem that cannot be solved. (...)"}, {"heading": "2. Proposed Approach \u2013 Structured Deep Neural Network", "text": "The overall picture of the concept of structured DNN for phoneme recognition can be found in Fig. 1. When we obtain an expression with an acoustic vector sequence x and a corresponding phoneme markup sequence y, we can first obtain a structured feature vector (x, y) representing x and y, and the relationships between them as in Fig. 1 (a) (details of the section are given in Section 3), and then feed it either into an SVM as in Fig. 1 (b) or a DNN as in Fig. 1 (c) to obtain a scoring result by means of a scoring function F1 (x, y; \u03b81) or F2 (x, y; \u03b82), where \u04451 and \u04452 are the parameter sets for the SVM and DNN respectively. Since both x and y represent the entire expression by a structure (sequence) and learn SVM or DNN, the pair (x, y) on one level, does not become optimized at this level and the learning at this level becomes global."}, {"heading": "2.1. Structured Learning Concepts", "text": "In structured learning, both the desired results and the input objects can be xi sequences, trees, grids, or graphs, rather than just classes or real numbers. As part of supervised phoneme recognition learning for expressions, we receive a series of training expressions (x1, y1),..., (xN, yN), and X \u00b7 Y, where xi is the acoustic vector sequence of the ith expression, yi is the corresponding reference phoneme labeling sequence, and we want to assign the correct phoneme labeling sequences to unknown expressions. One way to achieve this is to learn any possible phoneme labeling sequence Xiv: 150 6.01 163v 1 [cs.L] 3J unspecified phoneme labeling sequence y, where the parameter setting y is indicated. One way to accomplish this is to learn any possible phoneme labeling sequence Xiv: 150 6.01 point (unspecified phoneme labeling sequence y) and the dot (unspecified dot 16.01-3s.L)."}, {"heading": "2.2. Structured SVM", "text": "Based on the concept of the maximized margin of SVM, we would like to maximize not only the score of the correct label sequence, but also the margin between the score of the correct label sequence and the score of the closest wrong label sequences, and require that the scoring function F (x, y; \u03b81) be linear, F1 (x, y; \u03b81) = < \u03b81, \u044b (x, y) >, (2) where the structured feature vector mentioned above and shown in Figure 1 is representing the structured relationship between x and y, success1 is in vector form and represents < \u00b7, \u00b7 > the inner product. Then, we can train the parameter vector Phenomen1 using training instances {(xi, yi), i = 1, 2,..., L} and then classify the desired label y for the acoustic vector sequence x of each unknown test statement based on the score function F1 (x) as well trained with the SVM (1)."}, {"heading": "2.3. Structured Deep Neural Network (Structured DNN)", "text": "The adoption of the linear scoring function as made in (2) is limited to structured SVM, since this N system contains only a single value (DNN). Instead, the proposed structured DNN uses a series of nonlinear transformations to construct the scoring function F2 (x, y; \u03b82), with hidden layers L to evaluate a single output value F2 (x, y; \u03b82), as shown in Figure 1 (c).h1 = \u03c3 (W0 \u00b7 preservation (x, y)) hl = \u03c3 (Wl \u2212 1 \u00b7 hl \u2212 1), 2 \u2264 l \u2264 l l \u2264 l LF2 (x, 2), and the set of all DNN parameters (WL \u00b7 hL), (3) where Wi is the weight matrix (including the preload) of the layer i, \u03c3 \u2212 (\u00b7) a nonlinear transformation (sigmoid is used), hi the output vector of the hidden layer i, and the set of all DNN parameters WN, WL is 1. WL, WL =..."}, {"heading": "2.4. Inference with Structured DNN", "text": "With the structured DNN trained as above, given the acoustic vector sequence x of an unknown utterance, we must find the best phoneme labeling sequence y for it. For structured SVM in Section 2.2, based on the linear assumption in the learned model parameter \u03b81, we must find enough information to execute the Viterbi algorithm to find the best labeling sequence. This does not apply to structured DNN. From (1) we must in principle search all possible phoneme labeling sequences (KM forK phonemes and M acoustic vectors) for the given acoustic vector sequence and select the one that gives the highest score, which is mathematically not feasible. Instead of searching all possible phonem labeling sequences, we can proceed from a random labeling sequence and then change one phonem labeling after the other way by going through all phonem labeling in the specified form."}, {"heading": "2.5. Training of Structured DNN", "text": "For the structured DNN, how to find and select effective training examples is important here. In addition to the positive examples (reference phoneme identification sequences for the training expression), negative examples (other than reference identification sequences) are selected randomly and by inferring the current model, which is explained below. \"Inferenced identification sequences\" are a feedback mechanism. If the current structured DNN model is used to decode a training expression and obtain a phoneme identification sequence that is far from correct, we add this identification sequence to support the training data used to customize the model. While the generated training data is used, the standard feedback algorithm can be used to update the structured DNN parameters, and additional identification sequences for the training can be selected from any training sequence without random identification or feedback."}, {"heading": "3. Structured Feature Vector \u03a8(x,y)or an utterance", "text": "So it is the task we apply in the label sequence y = 1, 2,... M). Since the most successful and best known solution to this problem is with HMM, we try to decipher what HMM has done in the label sequence (x, y) to be used here. An HMM consists of a number of states, and two of the most important sets of parameters - the transition probabilities between states, and the observation probability distribution for each state is slightly complicated for the work here, so in the preliminary work we use a simplified HMM with only one state for each phoneme."}, {"heading": "4. Experimental Setup", "text": "Initial experiments were carried out with TIMIT. We used the training set without dialect sets for training and the core test set (with 24 speakers and no dialect) for the tests. We trained the models with a set of 48 phonemes and tested them with a set of 39 phonemes that complied with the CMU / MIT standards [?]. We used an online library [?] for structured SVM and modified the Kaldi [?] code to implement structured DNN. Our experiment is based on Karel's Kaldi recipe for the TIMIT script that used LDA-MLLT-fMLR features derived from utilities for GMM, as RBM pre-training, frame crossentropy training and sMBR. On top of Karel's recipe, we used three sets of acoustic vectors (a), (a) LDA-MLLLLLT-fT training modules, the MDNT-MDNT, and the MDNT-MDNT modules."}, {"heading": "5. Experimental Results", "text": "The results are listed in Table 1. Structured DNN without lattice (3 hidden layers 200 neurons per layer) perform no better than structured SVM, although they have learned some structured patterns, obviously due to the poor quality of training data (most of them are random), as well as the fact that the inferno algorithm only changed a phoneme label at a time that is prone to convergence of local maxims. On the other hand, the training / inferencing with lattices was much better as it offered many effective training examples. These structured DNN with lattices gave a telephone rate (PER) of 18.77%, the structured SVM and is actually slightly better than the reception of calcium."}, {"heading": "6. Conclusion and Future Work", "text": "In this paper, we propose a new structured learning architecture, structured DNN for phoneme recognition, which collectively looks at the structures of acoustic vector sequences and pH / Onem label sequences globally. Preliminary test results show that structured DNN exceeded the previously proposed structured SVM and yielded a comparable state-of-the-art result. In the future, we will work on multiple states per phone and explore the possibility of a structured DNN."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "In this paper we propose the Structured Deep Neural Network (Structured DNN) as a structured and deep learning algorithm, learning to find the best structured object (such as a label sequence) given a structured input (such as a vector sequence) by globally considering the mapping relationships between the structure rather than item by item. When automatic speech recognition is viewed as a special case of such a structured learning problem, where we have the acoustic vector sequence as the input and the phoneme label sequence as the output, it becomes possible to comprehensively learned utterance by utterance as a whole, rather than frame by frame. Structured Support Vector Machine (structured SVM) was proposed to perform ASR with structured learning previously, but limited by the linear nature of SVM. Here we propose structured DNN to use nonlinear transformations in multi-layers as a structured and deep learning algorithm. It was shown to beat structured SVM in preliminary experiments on TIMIT.", "creator": "LaTeX with hyperref package"}}}