{"id": "1506.01195", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2015", "title": "Implementation of Training Convolutional Neural Networks", "abstract": "Deep learning refers to a shining branch of machine learning that is based on learning levels of representations. Convolutional Neural Networks (CNN) is one kind of deep neural network. It can study concurrently. In this article, we use convolutional neural network to implement the typical face recognition problem which can overcome the influence of pose or resolution in face recognition. Then, a parallel strategy was proposed in section4. In addition, by measuring the actual time of forward and backward computing, we analysed the maximal speed up and parallel efficiency theoretically.", "histories": [["v1", "Wed, 3 Jun 2015 10:18:49 GMT  (382kb)", "http://arxiv.org/abs/1506.01195v1", "10 pages, 5 figures"], ["v2", "Thu, 4 Jun 2015 02:10:39 GMT  (383kb)", "http://arxiv.org/abs/1506.01195v2", "10 pages, 6 figures"]], "COMMENTS": "10 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["tianyi liu", "shuangsang fang", "yuehui zhao", "peng wang", "jun zhang"], "accepted": false, "id": "1506.01195"}, "pdf": {"name": "1506.01195.pdf", "metadata": {"source": "META", "title": "Implementation of Training Convolutional Neural Networks", "authors": ["Tianyi Liu", "Shuangsang Fang", "Yuehui Zhao", "Peng Wang", "Jun Zhang"], "emails": ["{liutianyi14@mails.ucas.ac.cn}"], "sections": [{"heading": null, "text": "In this article, we use Convolutionary Neural Networks to implement the typical problem of facial recognition, which can overcome the influence of pose or resolution in facial recognition. Subsequently, in Section 4, a parallel strategy was proposed. Furthermore, by measuring the actual time of forward and backward computing, we theoretically analyzed the maximum speed and parallel efficiency. Keywords: Convolutionary Neural Networks, Face Training, Parallel Strategy, Maximum Acceleration."}, {"heading": "1. INTRODUTION", "text": "The structure of these models can be understood as a hidden form of learning based on a hierarchy of characteristics, factors and concepts in which the individual concepts are defined from different angles. \"Deep Learning\" comes from the realm of the Artistic Neural Network, in which several levels of representation and abstraction are intertwined. In the late 1980s, the invention of \"back propagation algorithm,\" as he puts it, gave rise to the hope of a trend in machine learning based on statistical models."}, {"heading": "2. BACKGROUNDAND RELATEDWORK", "text": "Yann LeCun and his team have specifically developed Convoutional Neural Networks to deal with the variability of 2D forms that have been proven to outperform all other techniques. [1] Dan C and his team present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants for image classification. [2] Another team proposes two new frontends for robust speech recognition (LID) that use a Convolutional Neural Network (CNN) trained for automatic speech recognition (ASR). [5] In addition, Convolutional Neural Networks are used in visual recognition [9] and many other areas such as face recognition [6], House Numbers Digit Classification [10], multi-digit number recognition by Street View Imagery [11]. Besides this work, many teams are focusing on the speed of ConvNets."}, {"heading": "3. PRINCIPLE OFCONVELUTIONALNEURALNETWORKS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Methodology", "text": "The neural network algorithm of folding is a multi-layer perceptron, which is the special design for identifying two-dimensional image information. CNN always has several layers: input layer, folding layer, sample layer and output layer. In addition, in a deep network architecture, the folding layer and sample layer can have several. CNN is not as limited as the Boltzmann machine, must be before and after the layer of neurons in the adjacent layer for all connections, the folding layer of neural network algorithms, each neuron does not need to feel a global image, but only feel the local area of the image. Furthermore, each neuron parameter is fixed in the same way, namely on the common distribution of the weights, namely on each neuron with the same folding kernel on the deformation image. (The first step is the input image, the input of the weighting following the folding is the feature of the respective layer image, namely the amplification of the respective layer, which we can obtain."}, {"heading": "3.2 CNNArchitecture Design", "text": "France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France, France"}, {"heading": "4. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Setups", "text": "CPU AMDA8-3500 APU with Radeon (tm) HD Graphics The number of CPU cores 4 memory size 4G operating system Ubuntu 14.04 LS"}, {"heading": "4.2 Parallel Strategy and Parallel Efficiency", "text": "This analysis is based on the hypothesis that both the serial and the parallel method have the same number of trainings. In the serial realization method, the total execution time is N times the sum of t1 and t2Time of the serial execution: 1 2 3 () serialNt t t t Time of parallel execution: 1 2 3max {(')} (/ n) \"parallel t t t Acceleration ratio = / serial parallel t Acceleration efficiency = Acceleration ratio / n N: Number of images n: Number of nodes 1t: Time of forward pass for training an image 2t: Time of backward propagation for training an image 3t: Time for updating the weight and pretension of the neural network."}, {"heading": "4.3 Results Analysis", "text": "The data set we use comes from the Yale Face Database. We select 136 images for analysis, and when we execute our algorithm, we have to divide it into two phases. First, we have to train our algorithm. The purpose of this phase is to determine the minimum error used in the next phase. So, we have to make sure that the algorithm can converge at a certain point. During the training process, the error is reduced until it becomes a constant. In the next step, the constant is used as the threshold. Figure 1 shows that the error does not change after four repetitions, so the best error is 4. The horizontal axis represents the number of iterations and the vertical axis the error. Seconds, we can use the constant obtained from the first step as the threshold to assess whether the algorithm can stop. Table I shows when the training process is successful, the time consumed by the algorithm."}, {"heading": "4.4 Theoretically Analysis of The Maximal Speedup", "text": "By measuring the workout time, especially the average time of t1, t2 and t3, the maximum acceleration and acceleration efficiency are listed below: Series time: 5317.000000 Parallel time: 2665.000000 Acceleration ratio: 1.995122 Acceleration efficiency: 0.997561"}, {"heading": "5. CONCLUSION", "text": "We mainly use the algorithm of neural network folding to extract the deep information of the multi-layered network in the process of face recognition, and we also use the algorithm to do parallel computing on the cloud platform to accelerate the process of face recognition, to analyze the theoretical acceleration ratio, and to perform experimental verification. Experimental results show that we have achieved good results. Of course, the parallelism we do is coarse-grained, and there are still many modules that can be fine-grained in the algorithm. This will be the focus for us in the future to further improve the work.ACKNOWLEDGMENTDuring the time we work together to complete the course task, Prof. Chen takes great pains to offer us guidance and help, so the first person to whom we must offer our thanks is Mr. Chen. At the same time, our great team leader Tianyi Liu deserves our sincere thanks. He has done a lot of work to coordinate and rest the teamwork we can all of them."}], "references": [{"title": "Gradient-based learning applied to document recognition[ J", "author": ["Y Lecun", "L Bottou", "Y Bengio"], "venue": "Proceedings of the IEEE,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Flexible, High Performance Convolutional Neural Networks for Image Classification[J", "author": ["Dan C. Ciresan", "Ueli Meier", "Jonathan Masci"], "venue": "PROCEEDINGS OF THE TWENTY-SECOND IN TERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "ImageNet classification with deep convolutional neural networks,\u201d NIPS[J", "author": ["G. Hinton A K I S"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Application of convolutional neural networks to language ide ntification in noisy conditions[C]//Proc", "author": ["Y Lei", "L Ferrer", "A Lawson"], "venue": "Speaker Odyssey Workshop (submitted)", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Deep Convolutional Network Cascade for Facial Point Detection[C]", "author": ["Y Sun", "X Wang", "X. Tang"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Applying Convolutional Neural Networks con cepts to hybrid NN-HMM model for speech recognition[C]// Acoustics", "author": ["O Abdel-Hamid", "R Mohamed A", "H Jiang"], "venue": "Speech and Signal Proces sing (ICASSP),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "A Theoretical Analysis of Feature Pooling in Visual Recognit ion[J", "author": ["L Boureau Y", "J Ponce", "Y. Lecun"], "venue": "International Conference on Machine Learning Haifa Israel,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Convolutional networks and applications in vision[C]// Circuits and Systems (ISCAS)", "author": ["Y Lecun", "K Kavukcuoglu", "C. Farabet"], "venue": "Proceedings of 2010 IEEE International Symposium on. IEEE,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Convolutional Neural Networks Applied to HouseNumbers Digit Classification[C", "author": ["S. Lecun P"], "venue": "Pattern Recognition (ICPR),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Multi-digit number recognition from street view ima gery using deep convolutional neural networks[J", "author": ["J Goodfellow I", "Y Bulatov", "J Ibarz"], "venue": "arXiv preprint arXiv:1312.6082,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "[1] Dan C and his team present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants for Image Classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Another team proposes two novel frontends for robust language identification (LID) using a convolutional neural network (CNN) trained for automatic speech recognition (ASR).", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] What\u2019s more, Convolutional Neural Networks are used in Visual Recognition[9] and many other areas, such as Facial Point Detection[6], House Numbers Digit Classification[10], Multi-digit Number Recognition from Street View Imagery[11].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[5] What\u2019s more, Convolutional Neural Networks are used in Visual Recognition[9] and many other areas, such as Facial Point Detection[6], House Numbers Digit Classification[10], Multi-digit Number Recognition from Street View Imagery[11].", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "[5] What\u2019s more, Convolutional Neural Networks are used in Visual Recognition[9] and many other areas, such as Facial Point Detection[6], House Numbers Digit Classification[10], Multi-digit Number Recognition from Street View Imagery[11].", "startOffset": 133, "endOffset": 136}, {"referenceID": 8, "context": "[5] What\u2019s more, Convolutional Neural Networks are used in Visual Recognition[9] and many other areas, such as Facial Point Detection[6], House Numbers Digit Classification[10], Multi-digit Number Recognition from Street View Imagery[11].", "startOffset": 172, "endOffset": 176}, {"referenceID": 9, "context": "[5] What\u2019s more, Convolutional Neural Networks are used in Visual Recognition[9] and many other areas, such as Facial Point Detection[6], House Numbers Digit Classification[10], Multi-digit Number Recognition from Street View Imagery[11].", "startOffset": 233, "endOffset": 237}, {"referenceID": 0, "context": "In this work , Facebook AI Group consider a standard architecture [1] trained on the Imagenet dataset [2] for classification and investigate methods to speed convergence by parallelizing training across multiple GPUs.", "startOffset": 66, "endOffset": 69}, {"referenceID": 1, "context": "In this work , Facebook AI Group consider a standard architecture [1] trained on the Imagenet dataset [2] for classification and investigate methods to speed convergence by parallelizing training across multiple GPUs.", "startOffset": 102, "endOffset": 105}], "year": 2015, "abstractText": "Deep learning refers to a shining branch of machine learning that is based on learning levels of representations. Convolutional Neural Networks (CNN) is one kind of deep neural network. It can study concurrently. In this article, we use convolutional neural network to implement the typical face recognition problem which can overcome the influence of pose or resolution in face recognition. Then, a parallel strategy was proposed in section4. In addition, by measuring the actual time of forward and backward computing, we analysed the maximal speed up and parallel efficiency theoretically.", "creator": "WPS Office \u4e2a\u4eba\u7248"}}}