{"id": "1506.01273", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2015", "title": "Summarization of Films and Documentaries Based on Subtitles and Scripts", "abstract": "We assess the performance of generic text summarization algorithms applied to films and documentaries, using the well-known behavior of summarization of news articles as reference. We use three datasets: (i) news articles, (ii) film scripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics are used for comparing generated summaries against news abstracts, plot summaries, and synopses. We show that the best performing algorithms are LSA, for news articles and documentaries, and LexRank and Support Sets, for films. Despite the different nature of films and documentaries, their relative behavior is in accordance with that obtained for news articles.", "histories": [["v1", "Wed, 3 Jun 2015 15:07:14 GMT  (4285kb,D)", "https://arxiv.org/abs/1506.01273v1", "7 pages, 9 tables, 4 figures, submitted to Pattern Recognition Letters (Elsevier)"], ["v2", "Thu, 4 Jun 2015 12:41:55 GMT  (2056kb,D)", "http://arxiv.org/abs/1506.01273v2", "7 pages, 9 tables, 4 figures, submitted to Pattern Recognition Letters (Elsevier)"], ["v3", "Wed, 9 Mar 2016 16:50:43 GMT  (2615kb,D)", "http://arxiv.org/abs/1506.01273v3", "7 pages, 9 tables, 4 figures, submitted to Pattern Recognition Letters (Elsevier)"]], "COMMENTS": "7 pages, 9 tables, 4 figures, submitted to Pattern Recognition Letters (Elsevier)", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR", "authors": ["marta apar\\'icio", "paulo figueiredo", "francisco raposo", "david martins de matos", "ricardo ribeiro", "lu\\'is marujo"], "accepted": false, "id": "1506.01273"}, "pdf": {"name": "1506.01273.pdf", "metadata": {"source": "META", "title": "Summarization of Films and Documentaries Based on Subtitles and Scripts", "authors": ["Marta Apar\u0131\u0301cioa", "Paulo Figueiredoa", "Francisco Raposoa", "David Martins de Matosa", "Ricardo Ribeiroa", "Lu\u0131\u0301s Marujoa"], "emails": ["david.matos@inesc-id.pt"], "sections": [{"heading": null, "text": "We evaluate the performance of generic text summary algorithms applied to movies and documentaries, using extracts from news articles produced by reference models of extractive summaries. We use three sets of data: (i) news articles, (ii) movie scripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics are used to compare generated summaries with news abstracts, plot summaries, and synopses. We show that the most powerful algorithms are LSA for news articles and documentaries, and LexRank and support sets for movies. Despite the different nature of movies and documentaries, their relative behavior is consistent with that of news articles."}, {"heading": "1. Introduction", "text": "Input media for automatic summaries vary from text [18, 5] via language [21, 39, 34] and video [1], but the scope is generally limited to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7]. Nevertheless, applications are gaining attention within the entertainment industry: e.g. summaries of short literary stories [12], musical summaries [31], book summaries [24], or the inclusion of character analysis in film summaries [36]. We are following this trend by creating extractive, text-based video summaries for films and documentaries. Documentaries that began as cinematic representations of reality [10]. Today, they continue to represent historical events, argumentation, and research; they are generally understood as a grasp of reality, and therefore as non-fiction per se. Films, on the other hand, are generally associated with fiction."}, {"heading": "2. Generic Summarization", "text": "Six text-based approaches were used to summarize newspaper articles, subtitles, and scripts, which are described in the following sections."}, {"heading": "2.1. Maximal Marginal Relevance (MMR)", "text": "MMR is a query-based summation method [4]. It selects sentences iteratively via Equation 1 (Q is a query; Sim1 and Sim2 are similarity metrics; Si and Sj are unselected or previously selected records).\u03bb weighs relevance and novelty. MMR can generate generic summaries by treating the input sentences centrically as a query [25, 38].arg max Si [\u03bbSim1 (Si, Q) \u2212 (1 \u2212 \u03bb) maxSj Sim2 (Si, Sj)] (1) ar Xiv: 150 6.01 273v 3 [cs.C L] 9M ar2 012"}, {"heading": "2.2. LexRank", "text": "LexRank [6] is a centrality-based method based on Google's PageRank [3]. A graph is created from records represented as vertices by TF-IDF vectors. Edges are generated when the cosinal similarity exceeds a threshold. Equation 2 is calculated at each vertice until the error rate between two consecutive iterations is less than a certain value. In this equation, d is a damping factor to ensure the convergence of the method, N is the number of vertices and S (Vi) is the score of the ith vertice. S (Vi) = (1 \u2212 d) N + d x x x \u00b2 Vj \u00b2 adj [Vi] Sim (Vi, Vj) \u2022 Vk \u00b2 adj [Vj] Sim (Vj, Vk) S (Vj) (2)"}, {"heading": "2.3. Latent Semantic Analysis (LSA)", "text": "Important topics are determined without the need for external lexical resources [9]: The context of the occurrence of each word provides information about its meaning, thereby establishing relationships between words and sentences that correlate with the way people make associations. Singular Value Decomposition (SVD) is applied to each document, represented by a word-to-sentence A matrix, which leads to its decomposition. The summary consists of selecting the k highest singular values from \u03a3, which reduces the K values U and V T to Uk and V Tk, respectively, with A approaching through Ak = UkKV T k. The most important sentences are selected from V Tk."}, {"heading": "2.4. Support Sets", "text": "Documents typically consist of a mixture of topics comprising a main topic and various secondary topics. Support sentences are defined on the basis of this observation [35]. Important contents are determined by creating a support sentence for each passage by comparing them with all the others. The most semantically related passages determined by geometric proximity are included in the support sentence. Abstracts are compiled by selecting the most relevant passages, i.e. the passages present in the largest number of support sentences. For a segmented information source I, P1, P2,..., PN, support sentences Si for each passage pi are defined by Equation 3, where Sim is a similarity function and i is a threshold. The most important passages are selected by Equation 4.Si, {s, I: Sim (s, pi) > i, s 6 = pi} (3) arg max s: Uni = 1Si | {s: 4,} (4)."}, {"heading": "2.5. Key Phrase-based Centrality (KP-Centrality)", "text": "Ribeiro et al. [32] proposed an extension of the centrality algorithm described in Section 2.4, which uses a two-step method to find important passages. Stage one consists of a feature-rich, monitored step to extract key terms using the MAUI toolkit with additional semantic features: recognition of rhetorical signals, number of designated entities, Part OfSpeech (POS) tags, and 4 n-gram domain model probabilities [20, 19]. Stage two consists of extracting the most important passages, with key terms considered regular passages."}, {"heading": "2.6. Graph Random-walk with Absorbing StateS that HOPs among PEaks for Ranking (GRASSHOPPER)", "text": "GRASSHOPPER [40] is a re-ranking algorithm that maximizes diversity and minimizes redundancy. It requires a weighted chart W (n \u00b7 n: n vertexes representing sentences; weights are defined by a measure of similarity), a probability distribution r (representing an earlier ranking) and \u03bb [0, 1], which represents the relative meaning of W and r. If there is no previous ranking, a uniform distribution can be used. Sentences are evaluated by applying the method of teleporting random shifts in an absorbing Markov chain, based on the n \u00b7 n transition matrix P (calculated by normalizing the W series), i.e. P = 1 \u2212 \u03bb + (1 \u2212 \u03bb) 1r >. The first set to be evaluated is the one with the highest stationary probability arg maxni = 1 \u0432i according to the stationary distribution of P: \u03c0 = P >. Previously selected sentences may never be revisited, by expecting the number of visits to be Nigg = 1 and the number of Nigg = 1."}, {"heading": "3. Datasets", "text": "We use three sets of data: newspaper articles (basic data), movies, and documentaries. Film data consists of subtitles and screenplays that contain scene descriptions and dialogues. Documentary data consists of subtitles that contain mostly monologues. Reference data consists of manual summaries (for newspaper articles), story summaries (for movies and documentaries), and summaries (for movies). Plot summaries are concise descriptions that are sufficient for the reader to get a sense of what is happening in the movie or documentary. Summaries are much longer and can contain important details about the turn of events in history. All data sets have been normalized by removing punctuation marks and timestamps from the subtitles."}, {"heading": "3.1. Newspaper Articles", "text": "TeMa \u0301 rio [28] consists of 100 newspaper articles in Brazilian Portuguese (Table 1) covering areas such as \"World,\" \"Politics\" and \"Foreign Policy.\" Each article has a man-made abstract."}, {"heading": "3.2. Films", "text": "We collected 100 films with an average of 4 plot summaries (minimum 1, maximum 7) and 1 plot summary per film3 (table 2). Table 3 shows the characteristics of the subtitles, screenplays and the concatenation of the two. Not all the information contained in the scripts was used: dialogues were removed to make them more similar to plot summaries."}, {"heading": "3.3. Documentaries", "text": "We have collected 98 documentaries. Table 4 shows the characteristics of their subtitles: Note that the number of sentences is smaller than in the film, which influences the ROUGE (memory-based) rating. We have collected 223 manual action summaries and divided them into four classes (Table 5): 143 \"informative,\" 63 \"questioning,\" 9 \"inviting\" and 8 \"challenge.\" \"informative\" summaries contain factual information about the program; \"questioning\" summaries contain questions that arouse the viewer's curiosity, e.g. \"What is the meaning of life?\"; \"inviting\" are invitations, e.g. \"Do you get time for a 24-year vacation?\"; and \"challenge\" attract viewers on a personal basis, e.g. \"are you ready for...?.\" We chose \"informative\" summaries because of their similarity to the sentences extracted by the summary algorithms. On average, there are 2 story summaries per documentary (at least 1, 3)."}, {"heading": "4. Experimental Setup", "text": "For news articles, summaries were generated with the average size of the manual summaries (\u2248 31% of their size). In contrast to news articles and documentaries, three types of input were taken into account: script, subtitle, screenplay + subtitle.For each documentary, a summary was generated with the same average number of sentences of its manual plot summaries (\u2248 1% of the documentary size).The content quality of the summaries is based on word overlaps (as defined by ROUGE) between generated summaries and their references. ROUGE-N calculates the fraction of selected words correctly identified by the summary algorithms (cf. Equation 5: RS are reference summaries, gram-long is the ngram and gram-long is the sentence matched (gram-long) by the summary algorithms (cf."}, {"heading": "5. Results and Discussion", "text": "In the following sections, the averaged ROUGE 1, ROUGE 2 and ROUGE SU4 values (hereinafter referred to as R-1, R-2 and R-SU4) and the performance of each summing algorithm are presented as a ratio between the value of the generated summaries and this reference (relative performance). In relation to GRASSHOPPER, several parameterizations of the algorithms were used (we present only the best results). In relation to MMR, we found that the best \u03bb corresponds to a higher average number of words per summary. In relation to GRASSHOPPER, we used the same distribution as before."}, {"heading": "5.1. Newspaper Articles (TeMa\u0301rio)", "text": "Table 6 shows the values for each summary algorithm. LSA achieved the best values for R-1, R-2 and R-SU4. Figure 1 shows the relative performance results. 4"}, {"heading": "5.2. Films", "text": "Table 7 shows the values for the film data combinations against the plot summaries. Overall, however, support sets, LSA and LexRank capture the most relevant sentences for the plot summaries. It would be expected that algorithms such as GRASSHOPPER and MMR, which maximize diversity, do well in this context because plot summaries are relatively small and focus on the more important aspects of the movie, ideally without redundant content. However, our results show something else. In the case of scripts, LSA and LexRank are the best approaches with respect to R-1 and R-SU4.Table 8 presents the values for the movie data combinations against the plot synopses. The size of the synopses differs greatly from those of the plot summaries. Although synopses also focus on the most important events in the story, their larger size allows a more refined description of the film events."}, {"heading": "5.3. Documentaries", "text": "Of all the algorithms (Table 9), LSA achieved the best results for R-1 and R-SU4, together with LexRank for R-1. KP-Centrality achieved the best results for R-2. It is important to note that LSA also produces the summaries with the highest number of words (which favors recall). Figure 2 shows the relative performance results: LSA performed better on R-1 and RSU4 than all other algorithms, and KP-Centrality was best on R-2; support sets and KP-Centrality performed closely on R-SU4; the best MMR results were consistently worse on all metrics (MMR summaries have the lowest number of words)."}, {"heading": "5.4. Discussion", "text": "In fact, most of them are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...)"}, {"heading": "6. Conclusions and Future Work", "text": "The other two sets of data, consisting of films and documentaries, were evaluated using plot summaries for films and documentaries as well as synopses for films. Despite the different nature of these areas, the abstract summaries used by people to evaluate them show similar values across all metrics. Our results indicate that this combination is unfavorable. Furthermore, it is possible to determine that all algorithms behave similarly, both for subtitles and screenplays. As mentioned above, the average of the results of the results closely follows the values of R-SU4, suggesting that R-SU4 is suitable for comparison."}, {"heading": "7. Acknowledgements", "text": "This work was supported by national funding from Fundac and the Cie Ncia e a Tecnologia (FCT) with reference UID / CEC / 50021 / 2013."}], "references": [{"title": "Video summarization: Techniques and classification, in: Computer Vision and Graphics", "author": ["M. Ajmal", "M. Ashraf", "M. Shakir", "Y. Abbas", "F. Shah"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Inferring strategies for sentence ordering in multidocument news summarization", "author": ["R. Barzilay", "N. Elhadad", "K. McKeown"], "venue": "Journal of Artificial Intelligence", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine", "author": ["S. Brin", "L. Page"], "venue": "in: Proc. of the 7th Intl. Conf. on World Wide Web,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "The Use of MMR, Diversity-based Reranking for Reordering Documents and Producing Summaries", "author": ["J. Carbonell", "J. Goldstein"], "venue": "in: Proc. of the 21st Annual Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "New methods in automatic abstracting", "author": ["H.P. Edmundson"], "venue": "Journal of the Association for Computing Machinery", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1969}, {"title": "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization", "author": ["G. Erkan", "D.R. Radev"], "venue": "Journal of Artificial Intelligence Research ,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Automatic extraction of cue phrases for important sentences in lecture speech and automatic lecture speech summarization", "author": ["Y. Fujii", "N. Kitaoka", "S. Nakagawa"], "venue": "in: Proc. of INTERSPEECH", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Cluster- Rank: A Graph Based Method for Meeting Summarization", "author": ["N. Garg", "B. Favre", "K. Reidhammer", "D. Hakkani-T\u00fcr"], "venue": "in: Proc. of INTERSPEECH", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Generic Text Summarization Using Relevance Measure and Latent Semantic Analysis", "author": ["Y. Gong", "X. Liu"], "venue": "in: Proc. of the 24th Annual Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Documenting the Documentary: Close Readings of Documentary Film and Video", "author": ["B.K. Grant", "J. Sloniowski"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "A repository of state of the art and competitive baseline summaries for generic news summarization", "author": ["K. Hong", "J.M. Conroy", "B. Favre", "A. Kulesza", "H. Lin", "A. Nenkova"], "venue": "in: Proc. of the Ninth Intl. Conf. on Language Resources and Evaluation (LREC-2014),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Summarizing short stories", "author": ["A. Kazantseva", "S. Szpakowicz"], "venue": "Computational Linguistics", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "A solution to Plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["T.K. Landauer", "S.T. Dutnais"], "venue": "Psychological Review", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "An introduction to latent semantic analysis", "author": ["T.K. Landauer", "P.W. Foltz", "D. Laham"], "venue": "Discourse processes", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "ROUGE: A Package for Automatic Evaluation of Summaries, in: Text Summ", "author": ["C.Y. Lin"], "venue": "Branches Out: Proc. of the ACL-04", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "The automated acquisition of topic signatures for text summarization", "author": ["C.Y. Lin", "E. Hovy"], "venue": "in: Proc. of the 18th Conf. on Computational Linguistics - Volume", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}, {"title": "Exploring correlation between rouge and human evaluation on meeting summaries", "author": ["F. Liu", "Y. Liu"], "venue": "IEEE Transactions on Audio, Speech & Language Processing", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "The Automatic Creation of Literature Abstracts", "author": ["H.P. Luhn"], "venue": "IBM Journal of Research and Development", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1958}, {"title": "Supervised topical key phrase extraction of news stories using crowdsourcing, light filtering and co-reference normalization", "author": ["L. Marujo", "A. Gershman", "J. Carbonell", "R. Frederking", "J.P. Neto"], "venue": "Proceedings of the Eight International Conference on Language Resources and Evaluation", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Keyphrase cloud generation of broadcast news., in: INTERSPEECH, ISCA", "author": ["L. Marujo", "M. Viveiros", "J.P. Neto"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Comparing Lexical, Acoustic/Prosodic, Structural and Discourse Features for Speech Summarization", "author": ["S.R. Maskey", "J. Hirschberg"], "venue": "in: Proc. of the 9th EUROSPEECH - INTERSPEECH", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "From text to speech summarization", "author": ["K. McKeown", "J. Hirschberg", "M. Galley", "S. Maskey"], "venue": "in: Acoustics, Speech, and Signal Processing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Tracking and summarizing news on a daily basis with columbia\u2019s newsblaster", "author": ["K.R. McKeown", "R. Barzilay", "D. Evans", "V. Hatzivassiloglou", "J.L. Klavans", "A. Nenkova", "C. Sable", "B. Schiffman", "S. Sigelman", "M. Summarization"], "venue": "in: Proc. of HLT", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2002}, {"title": "Explorations in automatic book summarization, in: EMNLP-CoNLL\u201907", "author": ["R. Mihalcea", "H. Ceylan"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Extractive Summarization of Meeting Recordings", "author": ["G. Murray", "S. Renals", "J. Carletta"], "venue": "in: Proc. of the 9th European Conf. on Speech Communication and Technology,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Extractive Summarization of Meeting Records", "author": ["G. Murray", "S. Renals", "J. Carletta"], "venue": "in: Proc. of the 9th EUROSPEECH - INTERSPEECH", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Representing Reality: Issues and Concepts in Documentary", "author": ["B. Nichols"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1991}, {"title": "NewsInEssence: A System For Domain-Independent, Real-Time News Clustering and Multi-Document Summarization", "author": ["D.R. Radev", "S. Blair-goldensohn", "Z. Zhang", "R.S. Raghavan"], "venue": "in: Proc. of the First Intl. Conf. on Human Language Technology Research,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2001}, {"title": "NewsInEssence: Summarizing Online News Topics", "author": ["D.R. Radev", "J. Otterbacher", "A. Winkel", "S. Blair-Goldensohn"], "venue": "Communications of the ACM", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2005}, {"title": "On the Application of Generic Summarization Algorithms to Music", "author": ["F. Raposo", "R. Ribeiro", "D.M. de Matos"], "venue": "IEEE Signal Processing", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Self reinforcement for important passage retrieval", "author": ["R. Ribeiro", "L. Marujo", "D. de Matos", "J.P. Neto", "A. Gershman", "J. Car-  bonell"], "venue": "Digital. URL:", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Extractive summarization of broadcast news: Comparing strategies for european portuguese", "author": ["R. Ribeiro", "D. de Matos"], "venue": "in: TSD,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2007}, {"title": "Summarizing speech by contextual reinforcement of important passages", "author": ["R. Ribeiro", "D. de Matos"], "venue": "in: Proc. of PROPOR", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Revisiting Centrality-as-Relevance: Support Sets and Similarity as Geometric Proximity", "author": ["R. Ribeiro", "D.M. de Matos"], "venue": "Journal of Artificial Intelligence", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Character-based movie summarization", "author": ["J. Sang", "C. Xu"], "venue": "in: Proc. of the Intl. Conf. on Multimedia,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "Automatic summarising: The state of the art", "author": ["K. Sp\u00e4rck Jones"], "venue": "Inf. Process. Manage", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2007}, {"title": "Using corpus and knowledge-based similarity measure in maximum marginal relevance for meeting summarization", "author": ["S. Xie", "Y. Liu"], "venue": "in: Proc. - ICASSP, IEEE Intl. Conf. on Acoustics, Speech and Signal Processing,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Extractive Speech Summarization Using Shallow Rhetorical Structure Modeling", "author": ["J.J. Zhang", "R.H.Y. Chan", "P. Fung"], "venue": "IEEE Transactions on Audio Speech and Language Processing", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2010}, {"title": "Improving Diversity in Ranking using Absorbing Random Walks", "author": ["X. Zhu", "A.B. Goldberg", "J.V. Gael", "D. Andrzejewski"], "venue": "in: Proc. of the 5th NAACL - HLT,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2007}], "referenceMentions": [{"referenceID": 17, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 61, "endOffset": 68}, {"referenceID": 4, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 61, "endOffset": 68}, {"referenceID": 20, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 79, "endOffset": 91}, {"referenceID": 37, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 79, "endOffset": 91}, {"referenceID": 32, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 79, "endOffset": 91}, {"referenceID": 0, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 102, "endOffset": 105}, {"referenceID": 1, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 196, "endOffset": 211}, {"referenceID": 28, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 196, "endOffset": 211}, {"referenceID": 31, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 196, "endOffset": 211}, {"referenceID": 10, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 196, "endOffset": 211}, {"referenceID": 25, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 222, "endOffset": 229}, {"referenceID": 7, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 222, "endOffset": 229}, {"referenceID": 6, "context": "Input media for automatic summarization has varied from text [18, 5] to speech [21, 39, 34] and video [1], but the application domain has been, in general, restricted to informative sources: news [2, 30, 33, 11], meetings [26, 8], or lectures [7].", "startOffset": 243, "endOffset": 246}, {"referenceID": 11, "context": "summarization of literary short stories [12], music summarization [31], summarization of books [24], or inclusion of character analyses in movie summaries [36].", "startOffset": 40, "endOffset": 44}, {"referenceID": 29, "context": "summarization of literary short stories [12], music summarization [31], summarization of books [24], or inclusion of character analyses in movie summaries [36].", "startOffset": 66, "endOffset": 70}, {"referenceID": 23, "context": "summarization of literary short stories [12], music summarization [31], summarization of books [24], or inclusion of character analyses in movie summaries [36].", "startOffset": 95, "endOffset": 99}, {"referenceID": 34, "context": "summarization of literary short stories [12], music summarization [31], summarization of books [24], or inclusion of character analyses in movie summaries [36].", "startOffset": 155, "endOffset": 159}, {"referenceID": 9, "context": "Documentaries started as cinematic portrayals of reality [10].", "startOffset": 57, "endOffset": 61}, {"referenceID": 26, "context": "However, films and documentaries do not fundamentally differ: many of the strategies and narrative structures employed in films are also used in documentaries [27].", "startOffset": 159, "endOffset": 163}, {"referenceID": 15, "context": "pt (David Martins de Matos) have been extensively explored for news documents [16, 22, 37, 29, 30, 23].", "startOffset": 78, "endOffset": 102}, {"referenceID": 21, "context": "pt (David Martins de Matos) have been extensively explored for news documents [16, 22, 37, 29, 30, 23].", "startOffset": 78, "endOffset": 102}, {"referenceID": 35, "context": "pt (David Martins de Matos) have been extensively explored for news documents [16, 22, 37, 29, 30, 23].", "startOffset": 78, "endOffset": 102}, {"referenceID": 27, "context": "pt (David Martins de Matos) have been extensively explored for news documents [16, 22, 37, 29, 30, 23].", "startOffset": 78, "endOffset": 102}, {"referenceID": 28, "context": "pt (David Martins de Matos) have been extensively explored for news documents [16, 22, 37, 29, 30, 23].", "startOffset": 78, "endOffset": 102}, {"referenceID": 22, "context": "pt (David Martins de Matos) have been extensively explored for news documents [16, 22, 37, 29, 30, 23].", "startOffset": 78, "endOffset": 102}, {"referenceID": 14, "context": "Generated summaries are evaluated against manual abstracts using ROUGE metrics, which correlate with human judgements [15, 17].", "startOffset": 118, "endOffset": 126}, {"referenceID": 16, "context": "Generated summaries are evaluated against manual abstracts using ROUGE metrics, which correlate with human judgements [15, 17].", "startOffset": 118, "endOffset": 126}, {"referenceID": 3, "context": "MMR is a query-based summarization method [4].", "startOffset": 42, "endOffset": 45}, {"referenceID": 24, "context": "considering the input sentences centroid as a query [25, 38].", "startOffset": 52, "endOffset": 60}, {"referenceID": 36, "context": "considering the input sentences centroid as a query [25, 38].", "startOffset": 52, "endOffset": 60}, {"referenceID": 5, "context": "LexRank [6] is a centrality-based method based on Google\u2019s PageRank [3].", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "LexRank [6] is a centrality-based method based on Google\u2019s PageRank [3].", "startOffset": 68, "endOffset": 71}, {"referenceID": 12, "context": "LSA infers contextual usage of text based on word cooccurrence [13, 14].", "startOffset": 63, "endOffset": 71}, {"referenceID": 13, "context": "LSA infers contextual usage of text based on word cooccurrence [13, 14].", "startOffset": 63, "endOffset": 71}, {"referenceID": 8, "context": "Important topics are determined without the need for external lexical resources [9]: each word\u2019s occurrence context provides information concerning its meaning, producing relations between words and sentences that correlate with the way humans make associations.", "startOffset": 80, "endOffset": 83}, {"referenceID": 33, "context": "Support sets are defined based on this observation [35].", "startOffset": 51, "endOffset": 55}, {"referenceID": 30, "context": "[32] proposed an extension of the centrality algorithm described in Section 2.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Speech (POS) tags, and 4 n-gram domain model probabilities [20, 19].", "startOffset": 59, "endOffset": 67}, {"referenceID": 18, "context": "Speech (POS) tags, and 4 n-gram domain model probabilities [20, 19].", "startOffset": 59, "endOffset": 67}, {"referenceID": 38, "context": "GRASSHOPPER [40] is a re-ranking algorithm that maximizes diversity and minimizes redundancy.", "startOffset": 12, "endOffset": 16}, {"referenceID": 0, "context": "It takes a weighted graph W (n \u00d7 n: n vertexes representing sentences; weights are defined by a similarity measure), a probability distribution r (representing a prior ranking), and \u03bb \u2208 [0, 1], that balances the relative importance of W and r.", "startOffset": 186, "endOffset": 192}, {"referenceID": 25, "context": "recordings, where the best summarizer was also LSA [26].", "startOffset": 51, "endOffset": 55}], "year": 2016, "abstractText": "We assess the performance of generic text summarization algorithms applied to films and documentaries, using extracts from news articles produced by reference models of extractive summarization. We use three datasets: (i) news articles, (ii) film scripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics are used for comparing generated summaries against news abstracts, plot summaries, and synopses. We show that the best performing algorithms are LSA, for news articles and documentaries, and LexRank and Support Sets, for films. Despite the different nature of films and documentaries, their relative behavior is in accordance with that obtained for news articles. c \u00a9 2016 Elsevier Ltd. All rights reserved.", "creator": "LaTeX with hyperref package"}}}