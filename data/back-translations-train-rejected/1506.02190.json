{"id": "1506.02190", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2015", "title": "Thresholding for Top-k Recommendation with Temporal Dynamics", "abstract": "This work focuses on top-k recommendation in domains where underlying data distribution shifts overtime. We propose to learn a time-dependent bias for each item over whatever existing recommendation engine. Such a bias learning process alleviates data sparsity in constructing the engine, and at the same time captures recent trend shift observed in data. We present an alternating optimization framework to resolve the bias learning problem, and develop methods to handle a variety of commonly used recommendation evaluation criteria, as well as large number of items and users in practice. The proposed algorithm is examined, both offline and online, using real world data sets collected from the largest retailer worldwide. Empirical results demonstrate that the bias learning can almost always boost recommendation performance. We encourage other practitioners to adopt it as a standard component in recommender systems where temporal dynamics is a norm.", "histories": [["v1", "Sat, 6 Jun 2015 20:13:28 GMT  (186kb,D)", "https://arxiv.org/abs/1506.02190v1", "10 pages"], ["v2", "Mon, 9 Nov 2015 05:37:07 GMT  (186kb,D)", "http://arxiv.org/abs/1506.02190v2", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["lei tang"], "accepted": false, "id": "1506.02190"}, "pdf": {"name": "1506.02190.pdf", "metadata": {"source": "CRF", "title": "Thresholding for Top-k Recommendation with Temporal Dynamics", "authors": ["Lei Tang"], "emails": ["leitang@acm.org"], "sections": [{"heading": null, "text": "Categories and Subject Descriptions H.2.8 [Information Technology and Systems]: Database Applications - Data Mining; H.3.3 [Information Storage and Retrieval]: Information Filtering General Term Algorithms, Experiments, Performance Keywords Bias Learning, Time Dynamics, Top-k-Recommendation"}, {"heading": "1. INTRODUCTION", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "2.2 Evaluation Criteria", "text": "As for the evaluation, the top ranking items R (fu \u043d) and the relevance of the items are selected, while other metrics must actually be provided. In contrast to typical reviews in collaborative filtering, we focus on recommendations where there are only binary answers: relevant or irrelevant. In our application, we consider an item relevant to a user when the user purchases the item. Let yui (0, 1) determine the relevance of the item i for a specific user u, where 0 is irrelevant, and 1 relevant. For the presentation, we use y (p) u to indicate the relevance of the p-th top ranking item for u. For top k recommendations, standard evaluation criteria include accuracy (ACC), mean average precision (MAP), and normalized discounted cumulative gains (NDCG). Because all of them are relevant in terms of individual user performance, we then describe them as average and all user recommendations."}, {"heading": "3. THE BIAS LEARNING PROBLEM", "text": "As mentioned in the introduction, the ecommerce recommendation suffers from data sparseness on the one hand, so it is imperative to train the recommendation model with a transaction history for as long as possible. On the other hand, the timing of consumer purchases means that we weigh more for those items that have been trending lately. However, such fluctuations can be attributed to all kinds of factors. For example, the retailer itself can occasionally post products at huge discounts to promote. Alternatively, we take a data-based approach to learn a bias for each item. Specifically, we collect transactions in the last few days or weeks and try to demystify the time dynamic, with difficulty taking them all into account. Alternatively, we take a data-based approach to learn a bias for each item. Specifically, we collect transactions that have been conducted in the last few days or weeks or weeks or weeks, and try to determine individual distortions so that certain valuation measures are maximized."}, {"heading": "4. ALGORITHM", "text": "Since bias learning is aimed at finding a bias for each item, we can paraphrase the target in Equation (8) with respect to items: max b1, b2, \u00b7 \u00b7 \u00b7, bmperf (f \u0445 1 + b1, f \u0445 2 + b2, \u00b7 \u00b7, f \u0445 m + bm). (9) The problem is difficult to solve because the precedence in the calculation is hidden in perf. Nevertheless, the problem can be solved if we optimize one Bi at a time. We propose an alternating optimization approach. That is, we set the scores and distortions for all other items and optimize the bias for a particular item. We can traverse all items until the objective function is stabilized. Next, we describe the case of finding the optimal bias for a single item. We use ACC @ k as an example to derive the algorithm and then use it to generalize AP to handle other types of assessment criteria such as MG @."}, {"heading": "4.1 Finding optimal bias for single item", "text": "We start with the simplest case: assuming that for a given user u, item i is not in top-k recommendation, how will the target in Eq. (9) be changed accordingly if we move item i in top-k to move item i in top-k? As soon as item i is moved in top-k, of course the top k-th item in the original recommendation is discarded. This item swap has four cases when we consider the relevance of each item shown below: yui y y y y y (k) u - y (k) - y - y (k) 0 1 0 1 \u2212 1 / k 1 (10) apparently, if both items share the same relevance, that is either relevant or irrelevant, the accuracy of the user u would not change to Eq. (3) The accuracy age only depends on whether these two items are associated with different items."}, {"heading": "4.2 Finding optimal biases for all items", "text": "In the above listing of the results of the last few years in the EU Commission and the EU Commission, the EU Commission has considered whether the EU Commission will be able to take the measures proposed by the EU Commission, in the EU Presidency of the Council of the EU Commission President Jean-Claude Juncker and the EU Presidency of the Council of the EU Commission President Jean-Claude Juncker and the EU Presidency of the EU Commission President Jean-Claude Juncker, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU Commission, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the US, in the USA, in the USA, in the USA, in the USA, in the EU, the EU, in the EU, the EU, the EU, EU, EU, EU, EU, the EU, the EU, the USA, the USA, the USA, the EU, the USA, the EU, the USA, the USA, the USA, the USA, the EU, the USA, the EU, the USA, the USA, the USA, the EU, the USA, the USA, the EU, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the"}, {"heading": "4.3 Scaling up for Practical Implementation", "text": "Firstly, it is not necessary to store the predictive values for all items. Considering the recommendation even for 100K users with 100K items, which is an average size in the era of big data. Suppose each score takes 4 bytes as a floating number, it requires 100K x 100K x 4 = 40G memory space. Therefore, we suggest to use a sparse representation of the predictive values by selecting only the number of top recommendations while setting others to zero. Typically, the number of recommendations to be kept is a multiplier of k. If we need to optimize for example for Performance @ Top-10, we can exclude the top 50 recommendations from one model. For the remaining items, their predictive values are set to 0. This is valid because we often observe a rapid decline in values, no matter what the basic recommendation model is. Secondly, we can exclude the candidate items for pre-setup settings, which should be reduced by two types of time complexity."}, {"heading": "4.4 Extensions to optimize MAP or NDCG", "text": "We have described how to optimize the bias in relation to ACC @ k. Now, we are expanding the algorithm 1 to optimize MAP @ k or NDCG @ k. Unlike accuracy, for which the position of an item in the top k recommendation does not matter, MAP and NDCG are ranked -related metrics. The position of an item in the top k recommendation plays an import role. A relevant item that is rated as the top k-1 leads to a different item than when the item is rated as the top k-th. To calculate the potential change in utility with different bias values, we have to consider all possible positions, rather than just the top k-th item. Nevertheless, the basic idea remains the same. We are calculating the difference and corresponding utility change in relation to each position in top k. Let's take the average precision in Eq. (4) as an example."}, {"heading": "5. EXPERIMENT SETUP", "text": "In this section, we mainly describe the basic setup of our experiments, including the creation of benchmark datasets, baseline recommendation models, and other methods that take into account time dynamics for comparison."}, {"heading": "5.1 Benchmark Data Sets", "text": "We collect XYZ customer transactions and create benchmark records via a split based on the date. User activity prior to the date is used for training, and the following week's transactions are used to evaluate recommendation performance. Relevant benchmarks include ACC @ k, MAP @ k and NDCG @ k as described in Section 2.2. In our experiments, k is used for 10. For easy interpretation, we provide all figures relating to lift (relative improvement) relative to a baseline: Lift = (perf perfbaseline \u2212 1) \u2264 100%. We prepare two benchmark records: one is in the regular season (November 1, 2013) and the other in the holiday season (December 11, 2013). Users \"shopping behavior during the holiday season tends to be significantly different from the regular season, both quantitatively and in terms of trending products. We strive to verify the effectiveness of our proposed method under both settings."}, {"heading": "5.2 Base Recommendation Model", "text": "A commonly used approach to recommendations in e-commerce is the modeling of user actions as a Markov chain [19, 18]. It is equivalent to calculating the similarity of objects [13] while maintaining the metric direction, i.e., the current action of the user depends only on his recent action. The probability of transition from one action to another can be estimated below: P (buy i | bought j) = # Users who bought j, then i # Users who bought j1, j2 and then i # Users who bought j1, j2. (16) The transition from two actions that lead to a purchase can be calculated, for example, as follows: P (buy i | bought j1, j2) = # Users who bought j1, j2, then i # Users who bought j1, j2."}, {"heading": "5.3 Methods Considering Temporal Change", "text": "For our proposed bias learning method (referred to as asMbias), we use most current 3-day transactions to refine the bias of items. All biases, unless stated \u03b2, are learned by optimizing ACC @ k. As for comparison, we also include a baseline method without taking into account time variations.Mlong: This method uses as long history as possible for training. As shown in Figure 2, the longer time window we use, the better the recommendation model. In our experiments, we use up to 15 months of user activity history for training. Besides the baseline, there are several other approaches to take into account time dynamics. Mtruncate: According to Theorem 4.2, if an item does not appear in current transactions, we can remove it from the recommendation. This method trains the recommendation model using 15-month data, but for prediction it only focuses on those items that have recently attracted user attention."}, {"heading": "6. EXPERIMENTS", "text": "In this section, we conduct a series of experiments on the benchmark data sets created to examine performance, sensitivity to based recommendation models and performance indicators. Finally, we report on the results by applying our method to online A / B tests."}, {"heading": "6.1 Performance Comparison", "text": "The number of people mentioned is indeed very high, and the number of people mentioned who are able to move is very high."}, {"heading": "6.2 Optimizing Different Performance Metrics", "text": "Here we apply the proposed bias learning algorithm to rank-related indicators such as MAP or NDCG. In addition, Figures 3 and 4 show the increase in Mbias over the baseline mlong in both sets of data. Initially, all methods lead to a positive increase, implying the effectiveness of learning distortions. However, the optimization criteria lead to a definitive performance difference. First, we suspect that optimizing an indicator would lead to higher numbers in relation to this particular indicator, e.g. optimizing MAP should lead to higher MAP in test performance. In reality, this is not the case. As shown in Figure 4, optimizing MAP actually leads to lower performance in relation to all three indicators and the optimization of NDCG; on the contrary, it results in a comparable performance to ACC. We also compare the difference of learned optimizations in optimizing ACC or NDCG."}, {"heading": "6.3 Bias Learning for Different Base Models", "text": "In previous sub-areas, we have mainly studied properties of bias learning using the Markov model. Here, we examine other basic recommendation models. Our proposed bias learning process is a kind of orthogonal basic model that is used, and it is applicable to a wide range of models. Two models are considered here: matrix factorization (CBR) and category-based recommendation (MF). Matrix factorization is gaining momentum thanks to the Netflix price competition [11, 21]. It is shown that one of the start-up methods is collaborative filtering. Standard matrix factorization aims to achieve a user item matrix as a product of two low ranks."}, {"heading": "6.4 Online A/B Tests", "text": "Each email contains 8 product recommendations. As already mentioned, the Markov model works quite well in our area and is used for basic recommendations. We sample a small percentage of XYZ customers and randomly divide them into two groups, one with bias learning and the other without. We run two tests, on 26 / 11 / 2013 and 7 / 12 / 2013, respectively. Both tests sent around 800K marketing emails. Three widely used metrics are recorded: the click rate (CTR), the average number of orders and turnover per open email. We assign an order / turnover from marketing emails only when customers click on a link and place orders within the same session. Bias-learning lifts are shown in Table 6. For all metrics, we see a positive lift, although only the CTR proves significant."}, {"heading": "7. RELATED WORK", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to move, to move, to fight, to fight, to fight, to fight, to fight, to move, to move, to fight, to fight, to fight, to fight, to fight, to move, to fight, to fight, to fight, to move, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "8. CONCLUSIONS AND FUTURE WORK", "text": "Since user feedback is likely to be rare in most referral systems, we propose to maintain as much data as possible for training recommendation models to avoid a savings problem. On the other hand, we propose to learn an atime-dependent bias for each element, just to capture the change in trend over time. We define the bias problem and present a coordinate-descent-like algorithm to optimize rank-based measures such as ACC, MAP or NDCG. We demonstrate that the algorithm is guaranteed to be terminated in finite steps with appropriate time complexity. Empirical results from offline and online experiments show that the proposed bias learning method is capable of increasing the performance of base recommendation models and capturing the time shift in user feedback."}, {"heading": "9. REFERENCES", "text": "[1] G. Adomavicius and A. Tuzhilin. Toward the nextgeneration of commender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. on Knowl. and Data Eng., 17 (6): 734-749 item, June 2005. [2] D. Agarwal, B.-C. Chen, P. Elango, and R. Ramakrishnan. Content commendation on web portals. Commun. ACM, 56 (6): 92-101, June 2013. [3] F. Aiolli. Efficient top-n commendation for very large scale binary rated datasets. In RecSys, 2013. [4] A. S. Das, A. Garg, A. Garg, and S. Rajaram. Google news personalization: scalable online collaborative filtering. In WWW, pp. 271-280, 2007."}], "references": [{"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["G. Adomavicius", "A. Tuzhilin"], "venue": "IEEE Trans. on Knowl. and Data Eng.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Efficient top-n recommendation for very large scale binary rated datasets", "author": ["F. Aiolli"], "venue": "In RecSys,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Google news personalization: scalable online collaborative filtering", "author": ["A.S. Das", "M. Datar", "A. Garg", "S. Rajaram"], "venue": "In WWW,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "A comprehensive survey of neighborhood-based recommendation methods", "author": ["C. Desrosiers", "G. Karypis"], "venue": "In Recommender systems handbook,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "A study on threshold selection for multi-label classication", "author": ["R.-E. Fan", "C.-J. Lin"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["N. Halko", "P.G. Martinsson", "J.A. Tropp"], "venue": "SIAM Rev.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Learning to rank for recommender systems", "author": ["A. Karatzoglou", "L. Baltrunas", "Y. Shi"], "venue": "In RecSys,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Yahoo! music recommendations: modeling music ratings with temporal dynamics and item taxonomy", "author": ["N. Koenigstein", "G. Dror", "Y. Koren"], "venue": "In RecSys,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Collaborative filtering with temporal dynamics", "author": ["Y. Koren"], "venue": "In KDD, pages 447\u2013456,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Temporal diversity in recommender systems", "author": ["N. Lathia", "S. Hailes", "L. Capra", "X. Amatriain"], "venue": "In SIGIR pages 210\u2013217,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Amazon. com recommendations: Item-to-item collaborative filtering", "author": ["G. Linden", "B. Smith", "J. York"], "venue": "Internet Computing, IEEE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Eigenrank: A ranking-oriented approach to collaborative filtering", "author": ["N.N. Liu", "Q. Yang"], "venue": "In SIGIR pages", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Learning to rank for information retrieval", "author": ["T.-Y. Liu"], "venue": "Foundations and Trends in Information Retrieval,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "One-class collaborative filtering", "author": ["R. Pan", "Y. Zhou", "B. Cao", "N.N. Liu", "R. Lukose", "M. Scholz", "Q. Yang"], "venue": "In ICDM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "author": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme"], "venue": "In UAI,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Factorizing personalized markov chains for next-basket recommendation", "author": ["S. Rendle", "C. Freudenthaler", "L. Schmidt-Thieme"], "venue": "In WWW,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "An mdp-based recommender system", "author": ["G. Shani", "D. Heckerman", "R.I. Brafman"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Climf: Learning to maximize reciprocal rank with collaborative less-is-more filtering", "author": ["Y. Shi", "A. Karatzoglou", "L. Baltrunas", "M. Larson", "N. Oliver", "A. Hanjalic"], "venue": "In RecSys pages 139\u2013146,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Scalable collaborative filtering approaches for large recommender systems", "author": ["G. Tak\u00e1cs", "I. Pil\u00e1szy", "B. N\u00e9meth", "D. Tikk"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Scaling matrix factorization for recommendation with randomness", "author": ["L. Tang", "P. Harrington"], "venue": "In WWW Companion,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Mining concept-drifting data streams using ensemble classifiers", "author": ["H. Wang", "W. Fan", "P.S. Yu", "J. Han"], "venue": "In KDD,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Utilizing related products for post-purchase recommendation in e-commerce", "author": ["J. Wang", "B. Sarwar", "N. Sundaresan"], "venue": "In RecSys pages 329\u2013332,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Opportunity model for e-commerce recommendation: right product; right time", "author": ["J. Wang", "Y. Zhang"], "venue": "In SIGIR pages 303\u2013312,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Cofi rank-maximum margin matrix factorization for collaborative ranking", "author": ["M. Weimer", "A. Karatzoglou", "Q.V. Le", "A.J. Smola"], "venue": "In NIPS,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Learning to rank recommendations with the k-order statistic loss", "author": ["J. Weston", "H. Yee", "R.J. Weiss"], "venue": "In RecSys,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Temporal collaborative filtering with bayesian probabilistic tensor factorization", "author": ["L. Xiong", "X. Chen", "T.-K. Huang", "J.G. Schneider", "J.G. Carbonell"], "venue": "In SDM,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "A study of thresholding strategies for text categorization", "author": ["Y. Yang"], "venue": "In SIGIR pages 137\u2013145,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2001}, {"title": "It takes variety to make a world: diversification in recommender systems", "author": ["C. Yu", "L. Lakshmanan", "S. Amer-Yahia"], "venue": "In EDBT pages 368\u2013378,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Increasing temporal diversity with purchase intervals", "author": ["G. Zhao", "M.L. Lee", "W. Hsu", "W. Chen"], "venue": "In SIGIR,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}], "referenceMentions": [{"referenceID": 11, "context": "Recommender systems have been extensively studied in different domains including eCommerce [13], movie/music ratings [11], news personalization [4], content recommendation at web portals [2], etc.", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "Recommender systems have been extensively studied in different domains including eCommerce [13], movie/music ratings [11], news personalization [4], content recommendation at web portals [2], etc.", "startOffset": 117, "endOffset": 121}, {"referenceID": 2, "context": "Recommender systems have been extensively studied in different domains including eCommerce [13], movie/music ratings [11], news personalization [4], content recommendation at web portals [2], etc.", "startOffset": 144, "endOffset": 147}, {"referenceID": 0, "context": "And all sorts of methods have been proposed for recommendation [1], including contentbased methods, neighborhood based approaches [5], latent", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "And all sorts of methods have been proposed for recommendation [1], including contentbased methods, neighborhood based approaches [5], latent", "startOffset": 130, "endOffset": 133}, {"referenceID": 9, "context": "factor models like SVD or matrix factorization [11].", "startOffset": 47, "endOffset": 51}, {"referenceID": 28, "context": "We assume items are selected solely based on prediction scores, while researchers have been considering other factors like diversity [30], which is beyond the scope of this work.", "startOffset": 133, "endOffset": 137}, {"referenceID": 0, "context": "Hence, normalized discounted cumulative gain (NDCG) is proposed to normalize the DCG into [0, 1]:", "startOffset": 90, "endOffset": 96}, {"referenceID": 17, "context": "One commonly used approach for recommendation in eCommerce is to model user actions as a Markov chain [19, 18].", "startOffset": 102, "endOffset": 110}, {"referenceID": 16, "context": "One commonly used approach for recommendation in eCommerce is to model user actions as a Markov chain [19, 18].", "startOffset": 102, "endOffset": 110}, {"referenceID": 11, "context": "It is tantamount to computing item similarity [13], but keeping the metric directional.", "startOffset": 46, "endOffset": 50}, {"referenceID": 8, "context": "[10, 9] proposed to have a time-dependent bias in matrix factorization for movie/music ratings.", "startOffset": 0, "endOffset": 7}, {"referenceID": 7, "context": "[10, 9] proposed to have a time-dependent bias in matrix factorization for movie/music ratings.", "startOffset": 0, "endOffset": 7}, {"referenceID": 14, "context": "We may randomly sample negative entries for our one-class collaborative filtering [16] problem, but that would essentially connect bias to the sampling rate, which is not acceptable either.", "startOffset": 82, "endOffset": 86}, {"referenceID": 9, "context": "Matrix factorization (MF) gained momentum thanks to the Netflix prize competition[11, 21].", "startOffset": 81, "endOffset": 89}, {"referenceID": 19, "context": "Matrix factorization (MF) gained momentum thanks to the Netflix prize competition[11, 21].", "startOffset": 81, "endOffset": 89}, {"referenceID": 20, "context": "Alternatively, we implemented a randomized version of matrix factorization as described in [22].", "startOffset": 91, "endOffset": 95}, {"referenceID": 5, "context": "It utilizes a randomized SVD [7] to compute approximate Q and then determines P given Q.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "Such a poor performance of matrix factorization is also observed in other domains with binary responses [3].", "startOffset": 104, "endOffset": 107}, {"referenceID": 21, "context": "Mining concept-drifting data streams [23] for classification and pattern mining has been studied extensively.", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": "[10, 9] proposed to have a time-dependent bias in matrix factorization for movie/music ratings.", "startOffset": 0, "endOffset": 7}, {"referenceID": 7, "context": "[10, 9] proposed to have a time-dependent bias in matrix factorization for movie/music ratings.", "startOffset": 0, "endOffset": 7}, {"referenceID": 14, "context": "But the proposed method is not applicable for one-class collaborative filtering [16] problem.", "startOffset": 80, "endOffset": 84}, {"referenceID": 26, "context": "[28] formulate temporal collaborative filtering as a tensor factorization by treating time as one additional dimension.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24, 25] consider the time gap between purchases and propose an opportunity model to identify not only the items to recommend, but also the best timing to recommend a particular product.", "startOffset": 0, "endOffset": 8}, {"referenceID": 23, "context": "[24, 25] consider the time gap between purchases and propose an opportunity model to identify not only the items to recommend, but also the best timing to recommend a particular product.", "startOffset": 0, "endOffset": 8}, {"referenceID": 10, "context": "Meanwhile, improving temporal diversity of recommendation across time [12, 31] is also considered.", "startOffset": 70, "endOffset": 78}, {"referenceID": 29, "context": "Meanwhile, improving temporal diversity of recommendation across time [12, 31] is also considered.", "startOffset": 70, "endOffset": 78}, {"referenceID": 13, "context": "Another related domain is learning to rank [15], which is initially motivated for the problem of information retrieval given queries.", "startOffset": 43, "endOffset": 47}, {"referenceID": 15, "context": "Making recommendations by learning to rank has attracted lots of attentions recently [17, 27, 8].", "startOffset": 85, "endOffset": 96}, {"referenceID": 25, "context": "Making recommendations by learning to rank has attracted lots of attentions recently [17, 27, 8].", "startOffset": 85, "endOffset": 96}, {"referenceID": 6, "context": "Making recommendations by learning to rank has attracted lots of attentions recently [17, 27, 8].", "startOffset": 85, "endOffset": 96}, {"referenceID": 12, "context": "EigenRank [14] extends memory-based (or similarity-based) methods by considering the ranking (rather than rating) of items in computing user similarities.", "startOffset": 10, "endOffset": 14}, {"referenceID": 24, "context": "For instance, CofiRank [26] extends matrix factorization to optimize ranking measures like NDCG instead of rating measures.", "startOffset": 23, "endOffset": 27}, {"referenceID": 18, "context": "CLiMF [20] instead optimizes a lower bound of smooth reciprocal rank.", "startOffset": 6, "endOffset": 10}, {"referenceID": 27, "context": "Our proposed bias learning method in collaborative filtering is partly inspired from the thresholding problem in multi-class/label classification [29, 6].", "startOffset": 146, "endOffset": 153}, {"referenceID": 4, "context": "Our proposed bias learning method in collaborative filtering is partly inspired from the thresholding problem in multi-class/label classification [29, 6].", "startOffset": 146, "endOffset": 153}], "year": 2015, "abstractText": "This work focuses on top-k recommendation in domains where underlying data distribution shifts overtime. We propose to learn a time-dependent bias for each item over whatever existing recommendation engine. Such a bias learning process alleviates data sparsity in constructing the engine, and at the same time captures recent trend shift observed in data. We present an alternating optimization framework to resolve the bias learning problem, and develop methods to handle a variety of commonly used recommendation evaluation criteria, as well as large number of items and users in practice. The proposed algorithm is examined, both offline and online, using real world data sets collected from a retailer website. Empirical results demonstrate that the bias learning can almost always boost recommendation performance. We encourage other practitioners to adopt it as a standard component in recommender systems where temporal dynamics are a norm.", "creator": "LaTeX with hyperref package"}}}