{"id": "1506.02509", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2015", "title": "SVM and ELM: Who Wins? Object Recognition with Deep Convolutional Features from ImageNet", "abstract": "Deep learning with a convolutional neural network (CNN) has been proved to be very effective in feature extraction and representation of images. For image classification problems, this work aim at finding which classifier is more competitive based on high-level deep features of images. In this report, we have discussed the nearest neighbor, support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation. Specifically, we adopt the benchmark object recognition dataset from multiple sources with domain bias for evaluating different classifiers. The deep features of the object dataset are obtained by a well-trained CNN with five convolutional layers and three fully-connected layers on the challenging ImageNet. Experiments demonstrate that the ELMs outperform SVMs in cross-domain recognition tasks. In particular, state-of-the-art results are obtained by kernel ELM which outperforms SVMs with about 4% of the average accuracy. The features and codes are available in", "histories": [["v1", "Mon, 8 Jun 2015 13:58:01 GMT  (1767kb)", "http://arxiv.org/abs/1506.02509v1", "7 pages, 4 figures"]], "COMMENTS": "7 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["lei zhang", "david zhang"], "accepted": false, "id": "1506.02509"}, "pdf": {"name": "1506.02509.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["leizhang@cqu.edu.cn)", "csdzhang@comp.polyu.edu.hk)"], "sections": [{"heading": null, "text": "In this report, however, we discussed the closest neighbor, the support of vector machines and extreme learning machines for image classification under profound revolutionary activation characteristics. Specifically, we adopt benchmark object recognition data from multiple sources with domain bias to evaluate different classifiers. The deep properties of object datasets are obtained by a well-trained CNN team with five revolutionary layers and three fully connected layers at the demanding ImageNet level. Experiments show that the ELMs work in cross-domain recognition tasks. In particular, state-of-the-art results are achieved by ELM, which exceeds SVMs with 4% average accuracy."}, {"heading": "II. OVERVIEW OF SVMS AND ELMS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Support Vector Machine", "text": "In this section the principle of SVM for classification problems is briefly reviewed. Further details can be referred to [19]. In view of a training set of N data points {,} where the labelling of SVM is aimed at solving the following risk minimisation problem with imbalance limitations. iiiN i ibytsC i 1.0.., 2 1minT1 2, xww (1), which is a linear / non-linear mapping function, w and b are the parameters of the classification hyperplane. In general, the original problem (7) of SVM can be converted to its dual formulation with equality limitation for optimization by using Lagrange multiplier method. One can construct the Lagrange function N i iiiiiiiiiiibyCbL11 T121-2,; www problem using the Lagrange multiplier method (Lagrange multiplier method)."}, {"heading": "B. Least Square Support Vector Machine", "text": "LSSVM is an improved and simplified version of SVM. Details can be referred to [20]. We briefly present the basic principle of LSSVM for classification problems. By introducing the square error and equality limitation, LSSVM can be defined as Nibyts CiiiNi ii,,1,1.., 2 1 2 1minT1 22, xw w w w (7) The Lagrange function of (7) can be defined as N i iiiiNi ibyCbL1 T1 221-2 2 1;, xwww (8), where the Lagrange multiplier is located. Optimal conditions can be achieved by using the partial derivatives of (8) in relation to the four variables as 01-0;,,0;,,00;,,0;, T11iiii iiNi iiiiiii iiiii iiii iiii iii iiii bbLy bbww of group 11."}, {"heading": "C. Extreme Learning Machine", "text": "ELM aims to solve the output weights of a single-layer neural network (SLFN) by minimizing the square loss of predicted errors and the norm of output weights for both classification and regression problems. We briefly introduce the principle of ELM for classification problems. Considering that if (= 1,,,] a dataset belongs to the k-th class, the k-th position of (= 1,,,,) N samples with the label = [,,,,,] and -1 is otherwise set, where d is the dimension of the sample and c is the number of classes. Considering that if (= 1,,,,,) the k-th position of (= 1,,,,,) the k-th position of (= 1,,,,,,,,,,,) the k-th position of (= 1,,,,,,,,,,) the k-th position of the sample and c is the number of classes, Lwwwth position of (= 1,,,,,,,,,,) the k-th position of (xwth) Lwth position of (= 1,,,,,,,,,,) the k-th position of (= 1,,) the k-th position of (= 1,,,,,,,,) the k-th position of (xwth) Lwwth class, and the k-th position of (xwth class) Lwwwwwth position of (= 1,,,,,,,,) the k-th position of (= 1,,,,,) the k-th position of (xwth) Lwth position of (xwth class)."}, {"heading": "D. Kernelized Extreme Learning Machine", "text": "The Mercer condition can also be applied to ELM, and this is how aKELM is formulated. KELM can be described as follows: Let = \u0441\u0441\u0435\u0441\u0435\u0441\u0441\u0442\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441stost I HHz\u03b2\u03b2zy1 T111 TT *,, CC hhNNNNNN (18) Note that due to the kernel matrix of training data, i.e., the number L of hidden neurons is not explicit and the decision-making function of KELM can be expressed unambiguously in (18)."}, {"heading": "III. TRAINING AND TESTING PROTOCOL", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. CNN training on ImageNet", "text": "In this report, we propose a comparative investment in SVMs and ELMs for classification based on deep Convolutionary Features. Therefore, we adopt the Deep Convolutional Activated Features (DeCAF) from [17] for experiments. CNN's structures for training in the ImageNet with 1000 categories are the same as those of the proposed CNN in [10]. The basic structure of the adopted feature is illustrated in Fig.1, which includes 5 Convolutionary Layers and 3 Fully Connected Layers. Further details of CNN's training architecture and features can be found [10, 17]."}, {"heading": "B. CNN Testing", "text": "The well-trained network parameters shown in Fig.1 serve as a deep representation of the 4DA dataset (domain adaptation) [31, 32]. CNN output of the 6th (f6) and 7th (f7) fully connected layers, respectively, serves as inputs for SVMs or ELMs for classification. The 4DA dataset includes four domains such as Caltech 256 (C), Amazon (A), Webcam (W) and Dslr (D) from different sources, in which 10 object classes are selected. As shown in Fig.1, the dimension of the characteristics of f6 and f7 is 4096. The detail of the 4DA dataset with deep characteristics is summarized in Table I. Some examples of the dataset for each domain are illustrated in Fig.2."}, {"heading": "C. Classification", "text": "The 4DA dataset is commonly used to evaluate domain adaptations and to transfer learning tasks. Therefore, in this report we examine the classification capability of deep representation on domain shifted data. We adopt the deep features for SVMs / ELMs training and compare classification accuracy. The specific setup is described in the Experiments section."}, {"heading": "IV. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Experimental Setup", "text": "In the experiment, three settings are examined as follows: 1) Settings 1: DSLR domain recognition task. As shown in Table I (ns / c), 20, 8, and 8 samples per class are randomly selected for training Amazon, DSLR, webcam, and Caltech domains, and the remaining samples are used as test samples for each domain. 20 random train / test splits are performed, and the average detection accuracy for each method is reported. 2) Settings 2: Cross-domain detection tasks - source only. We perform a cross-domain detection task. For example, we train an SVM / ELM task on Amazon and test on DSLR, i.e. A \u2192 D. A total of 12 cross-domain tasks are performed among the four domains."}, {"heading": "B. Parameter Setting", "text": "To ensure that the best result of each method can be achieved, we have adjusted the parameters: For SVM, the penalty coefficient C and the kernel parameter \u03c3 are set to 1000 and 1 with the toolbox Libsvm-3.12, respectively; for LSSVM, the two coefficients are automatically optimized with a grid search by providing the toolbox LSSVM-1.7; for ELM, the penalty coefficient C and the number of L of hidden neurons are set to 100 and 5000, respectively; for KELM, the penalty coefficient C and the kernel parameter \u03c3 are set to 100 and 0.01, respectively. Note that the penalty coefficient C and the kernel parameter \u03c3 for SVM, ELM and KELM are set to C = {1, 100, 10000} and \u03c3 = {0.0001, 0.01, 1, 100}."}, {"heading": "C. Experimental Results", "text": "\u00b1 1) The results of the experimental configuration 1, the average accuracy of the 20 randomly generated tension / test splits for five methods, including NN, SVM, LSSVM, ELM and KELM are presented in Table II. We can find that detection performance is slightly different based on the 6th layer (f6) and the 7th layer (f7). The best two methods are highlighted with obesity. From the comparisons we can find that ELM's SVMs and NN methods for all domains, and KELM shows more competitive performance. Specifically, by comparing KELM and SVM, the improvement in accuracy for the deep properties f6 is 0.8%, 1.1% and 2.1% for Amazon SVMs, and KELM shows better performance than the others."}, {"heading": "V. CONCLUSION", "text": "In the report, we present a systematic comparison between SVMs and ELMs for multi-domain object recognition based on the Deep Convolutional Activation features trained by CNN on a subset of images from the 1000th layer of ImageNet. Our goal is to investigate the most appropriate classifiers for high-level deep features in classification. In experiments, the Deep Features of object images from the 10th layer of 4 domains from the 6th and 7th layers of CNN are used as inputs for general classifiers, including NN, SVM, LSSVM, ELM and KELM. Detection accuracy for each method under three different experimental conditions is reported. A number of experimental results clearly show that ELMs exceed SVM-based classifiers in different environments."}, {"heading": "ACKNOWLEDGEMENT", "text": "This work was supported in part by the National Natural Science Foundation of China under grant programs 61401048 and 61305144, in part by the Hong Kong Scholar Program under grant program XJ2013044 and in part by the China Post-Doctoral Science Foundation under grant program 2014M550457."}], "references": [{"title": "Gradient-based learning applied to document recognition", "author": ["Y. Lecun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, 1998.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1998}, {"title": "Face recognition: a convolutional neural-network approach", "author": ["S. Lawrence", "C.L. Giles", "T. Ah Chung", "A.D. Back"], "venue": "IEEE Transactions on Neural Networks, vol. 8, no. 1, 1997.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504-507, 2006.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G. Hinton", "S. Osindero", "Y. The"], "venue": "Neural Comput. Vol. 18, no. 7, pp. 1527-1554, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Deep Boltzman machines", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "Proc. Int\u2019l Conf. Artif. Intell. Statist., pp. 448-455, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning hierarchical representations for face verification with convolutional deep belief networks", "author": ["G.B. Huang", "H. Lee", "E. Learned-Miller"], "venue": "Proc. IEEE Int\u2019l Computer Vision and Pattern Recognition, pp. 2518-2525, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Hybrid Deep Learning for Face Verification", "author": ["Y. Sun", "X. Wang", "X. Tang"], "venue": "Proc. IEEE Int\u2019l Conf. Computer Vision, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "DeepFace: Closing the Gap to Human-Level Performance in Face Verification", "author": ["Y. Taigman", "M. Yang", "M.A. Ranzato", "L. Wolf"], "venue": "Proc. IEEE Int\u2019l Computer Vision and Pattern Recognition, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Na\u00efve-Deep Face Recognition: Touching the Limit of LFW Benchmark or Not?", "author": ["E. Zhou", "Z. Cao", "Q. Yin"], "venue": "arXiv: 1501.04690,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "Proc. IEEE Int\u2019l Conf. Computer Vision and Pattern Recognition, pp. 3642-3649, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Large-Scale Video Classification with Convolutional Neural Networks", "author": ["A. Karpathy", "G. Toderici", "S. Shetty", "T. Leung"], "venue": "Proc. IEEE Int\u2019l Conf. Computer Vision and Pattern Recognition, pp. 1725-1732, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition", "author": ["A.S. Razavian", "H. Azizpour", "J. Sullivan", "S. Carlsson"], "venue": "Proc. IEEE Int\u2019l Conf. Computer Vision and Pattern Recognition, pp. 512-519, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Accurate Object Detection and Semantic Segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "Proc. IEEE Int\u2019l Conf. Computer Vision and Pattern Recognition, pp. 580-587, 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv: 1406.4729.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1406}, {"title": "What is the best multi-stage architecture for object recognition?", "author": ["K. Jarrett", "K. Kavukcuoglu", "M. Ranzato", "Y. LeCun"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "arXiv: 1310.1531, 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Nearest neighbor pattern classification", "author": ["T. Cover", "P. Hart"], "venue": "IEEE Trans. Information Theory, vol. 13, no. 1, pp. 21-27, 1967.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1967}, {"title": "Statistical learning theory", "author": ["V. Vapnik"], "venue": "John Wiley: New York, 1998.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "Least Squares Support Vector Machine Classifiers", "author": ["J.A.K. Suykens", "J. Vandewalle"], "venue": "Neural Processing Letters, vol. 9, no. 3, pp. 293-300, 1999.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Extreme learning machine: Theory and applications", "author": ["G.B. Huang", "Q.Y. Zhu", "C.K. Siew"], "venue": "Neurocomputing, vol. 70, pp. 489-501, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Extreme Learning Machine for Regression and Multiclass Classification", "author": ["G.B. Huang", "H. Zhou", "X. Ding", "R. Zhang"], "venue": "IEEE Trans. Systems, Man, Cybernetics: Part B, vol. 42, no. 2, pp. 513-529, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimization method based on extreme learning machine for classification", "author": ["G.B. Huang", "X.J. Ding", "H.M. Zhou"], "venue": "Neurocomputing, vol. 74, no. 1-3, pp. 155-163, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolutionary Cost-sensitive Extreme Learning Machine and Subspace Extension", "author": ["L. Zhang", "D. Zhang"], "venue": "arXiv:1505.04373, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "What are Extreme Learning Machines? Filling the Gap between Frank Rosenblatt\u2019s Dream and John von Neumann\u2019s Puzzle", "author": ["G.B. Huang"], "venue": "Cognitive Computation, vol. 7, pp. 263-278, 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Representational Learning with Extreme Learning Machine for Big Data", "author": ["L.L.C. Kasun", "H. Zhou", "G.B. Huang", "C.M. Vong"], "venue": "IEEE Intelligent Systems, vol. 28, no. 6, pp. 31-34, 2013.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Local Receptive Fields Based Extreme Learning Machine", "author": ["G.-B. Huang", "Z. Bai", "L.L.C. Kasun", "C.M. Vong"], "venue": "IEEE Computational Intelligence Magazine, vol. 10, no. 2, pp. 18-29, 2015.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain Adaptation Transfer Extreme Learning Machines", "author": ["L. Zhang", "D. Zhang"], "venue": "Proceedings in Adaptation, Learning and Optimization, vol. 3, pp. 103-119, 2015.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain Adaptation Extreme Learning Machines for Drift Compensation in E-nose Systems", "author": ["L. Zhang", "D. Zhang"], "venue": "IEEE Transactions on Instrumentation and Measurement, vol. 64, no. 7, pp. 1790-1801, 2015.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1801}, {"title": "Semi-Supervised and Unsupervised Extreme Learning Machines", "author": ["G. Huang", "S. Song", "J.N.D. Gupta", "C. Wu"], "venue": "IEEE Transactions on Cybernetics, vol. 44, no. 12, pp. 2405-2417, 2014.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "ECCV, 2010.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "CVPR, pp. 2066-2073, 2012.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "In the early, convolutional neural network (CNN), as the most important deep net in deep learning, has been applied to document recognition and face recognition [1, 2].", "startOffset": 161, "endOffset": 167}, {"referenceID": 1, "context": "In the early, convolutional neural network (CNN), as the most important deep net in deep learning, has been applied to document recognition and face recognition [1, 2].", "startOffset": 161, "endOffset": 167}, {"referenceID": 2, "context": "multi-layer perceptrons, MLP) for auto-encoder have been proposed, for examples, stacked auto encoders (SAE) [3], deep belief networks (DBN) [4] and deep Boltzmann machines (DBM) [5].", "startOffset": 109, "endOffset": 112}, {"referenceID": 3, "context": "multi-layer perceptrons, MLP) for auto-encoder have been proposed, for examples, stacked auto encoders (SAE) [3], deep belief networks (DBN) [4] and deep Boltzmann machines (DBM) [5].", "startOffset": 141, "endOffset": 144}, {"referenceID": 4, "context": "multi-layer perceptrons, MLP) for auto-encoder have been proposed, for examples, stacked auto encoders (SAE) [3], deep belief networks (DBN) [4] and deep Boltzmann machines (DBM) [5].", "startOffset": 179, "endOffset": 182}, {"referenceID": 5, "context": "In the latest progress of deep learning, researchers have broken the new record in face verification by using CNNs with different structures [6, 7, 8, 9].", "startOffset": 141, "endOffset": 153}, {"referenceID": 6, "context": "In the latest progress of deep learning, researchers have broken the new record in face verification by using CNNs with different structures [6, 7, 8, 9].", "startOffset": 141, "endOffset": 153}, {"referenceID": 7, "context": "In the latest progress of deep learning, researchers have broken the new record in face verification by using CNNs with different structures [6, 7, 8, 9].", "startOffset": 141, "endOffset": 153}, {"referenceID": 8, "context": "In the latest progress of deep learning, researchers have broken the new record in face verification by using CNNs with different structures [6, 7, 8, 9].", "startOffset": 141, "endOffset": 153}, {"referenceID": 9, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 10, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 11, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 12, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 13, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 14, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 15, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 16, "context": "hk) achieved very competitive results on ImageNet for image classification and Pascal VOC data [10-17].", "startOffset": 95, "endOffset": 102}, {"referenceID": 17, "context": "Therefore, we mainly exploit the nearest neighbor (NN) [18], support vector machine (SVM) [19], least-square support vector machine (LSSVM) [20], extreme learning machine (ELM) [21] and kernel extreme learning machine (KELM) [22].", "startOffset": 55, "endOffset": 59}, {"referenceID": 18, "context": "Therefore, we mainly exploit the nearest neighbor (NN) [18], support vector machine (SVM) [19], least-square support vector machine (LSSVM) [20], extreme learning machine (ELM) [21] and kernel extreme learning machine (KELM) [22].", "startOffset": 90, "endOffset": 94}, {"referenceID": 19, "context": "Therefore, we mainly exploit the nearest neighbor (NN) [18], support vector machine (SVM) [19], least-square support vector machine (LSSVM) [20], extreme learning machine (ELM) [21] and kernel extreme learning machine (KELM) [22].", "startOffset": 140, "endOffset": 144}, {"referenceID": 20, "context": "Therefore, we mainly exploit the nearest neighbor (NN) [18], support vector machine (SVM) [19], least-square support vector machine (LSSVM) [20], extreme learning machine (ELM) [21] and kernel extreme learning machine (KELM) [22].", "startOffset": 177, "endOffset": 181}, {"referenceID": 21, "context": "Therefore, we mainly exploit the nearest neighbor (NN) [18], support vector machine (SVM) [19], least-square support vector machine (LSSVM) [20], extreme learning machine (ELM) [21] and kernel extreme learning machine (KELM) [22].", "startOffset": 225, "endOffset": 229}, {"referenceID": 22, "context": "With similar impact with SVM, it has been proved to be efficient and effective for regression and classification tasks [23, 24].", "startOffset": 119, "endOffset": 127}, {"referenceID": 23, "context": "With similar impact with SVM, it has been proved to be efficient and effective for regression and classification tasks [23, 24].", "startOffset": 119, "endOffset": 127}, {"referenceID": 24, "context": "The latest work about the principles and brain-alike learning of ELM has been presented [25].", "startOffset": 88, "endOffset": 92}, {"referenceID": 25, "context": "The newest work about ELM for deep auto-encoder, local receptive fields for deep learning, transfer learning, and semi-supervised learning have also been proposed [26, 27, 28, 29, 30].", "startOffset": 163, "endOffset": 183}, {"referenceID": 26, "context": "The newest work about ELM for deep auto-encoder, local receptive fields for deep learning, transfer learning, and semi-supervised learning have also been proposed [26, 27, 28, 29, 30].", "startOffset": 163, "endOffset": 183}, {"referenceID": 27, "context": "The newest work about ELM for deep auto-encoder, local receptive fields for deep learning, transfer learning, and semi-supervised learning have also been proposed [26, 27, 28, 29, 30].", "startOffset": 163, "endOffset": 183}, {"referenceID": 28, "context": "The newest work about ELM for deep auto-encoder, local receptive fields for deep learning, transfer learning, and semi-supervised learning have also been proposed [26, 27, 28, 29, 30].", "startOffset": 163, "endOffset": 183}, {"referenceID": 29, "context": "The newest work about ELM for deep auto-encoder, local receptive fields for deep learning, transfer learning, and semi-supervised learning have also been proposed [26, 27, 28, 29, 30].", "startOffset": 163, "endOffset": 183}, {"referenceID": 21, "context": "With the Mercer condition applied, a kernel ELM (KELM) that computes a kernel matrix of hidden layers has also been proposed [22].", "startOffset": 125, "endOffset": 129}, {"referenceID": 18, "context": "More details can be referred to [19].", "startOffset": 32, "endOffset": 36}, {"referenceID": 19, "context": "The details can be referred to [20].", "startOffset": 31, "endOffset": 35}, {"referenceID": 16, "context": "Therefore, we adopt the deep convolutional activated features (DeCAF) from [17] for experiments.", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "The structures of CNN for training on the ImageNet with 1000 categories are the same as the proposed CNN in [10].", "startOffset": 108, "endOffset": 112}, {"referenceID": 9, "context": "Further details of the CNN training architecture and features can be referred to [10, 17].", "startOffset": 81, "endOffset": 89}, {"referenceID": 16, "context": "Further details of the CNN training architecture and features can be referred to [10, 17].", "startOffset": 81, "endOffset": 89}, {"referenceID": 30, "context": "1 are used for deep representation of the 4DA (domain adaptation) dataset [31, 32].", "startOffset": 74, "endOffset": 82}, {"referenceID": 31, "context": "1 are used for deep representation of the 4DA (domain adaptation) dataset [31, 32].", "startOffset": 74, "endOffset": 82}], "year": 2015, "abstractText": "Abstract\u2014Deep learning with a convolutional neural network (CNN) has been proved to be very effective in feature extraction and representation of images. For image classification problems, this work aim at finding which classifier is more competitive based on high-level deep features of images. In this report, we have discussed the nearest neighbor, support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation. Specifically, we adopt the benchmark object recognition dataset from multiple sources with domain bias for evaluating different classifiers. The deep features of the object dataset are obtained by a well-trained CNN with five convolutional layers and three fully-connected layers on the challenging ImageNet. Experiments demonstrate that the ELMs outperform SVMs in cross-domain recognition tasks. In particular, state-of-the-art results are obtained by kernel ELM which outperforms SVMs with about 4% of the average accuracy. The features and codes are available in http://www.escience.cn/people/lei/index.html", "creator": null}}}