{"id": "1506.04557", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2015", "title": "Learning Deep Generative Models with Doubly Stochastic MCMC", "abstract": "Performing inference and learning of deep generative networks in a Bayesian setting is desirable, where a sparsity-inducing prior can be adopted on model parameters or a nonparametric Bayesian process can be used to infer the network structure. However, posterior inference for such deep models is an extremely challenging task, which has largely not been well-addressed. In this paper, we present doubly stochastic gradient-based MCMC, a simple and effective method that can be widely applied for Bayesian inference of deep generative models in continuous parameter spaces. The algorithm is doubly stochastic in the sense that at each MCMC sampling step a mini-batch of data samples are randomly drawn to estimate the gradient of log-posterior and the intractable expectation over latent variables is further estimated via a Monte Carlo sampler. We demonstrate the effectiveness on learning deep sigmoid belief networks (DSBNs). Compared to the state-of-the-art methods using Gibbs sampling with data augmentation, our algorithm is much more efficient and manages to learn DSBNs on large datasets.", "histories": [["v1", "Mon, 15 Jun 2015 11:37:09 GMT  (166kb,D)", "https://arxiv.org/abs/1506.04557v1", null], ["v2", "Sun, 11 Oct 2015 08:29:24 GMT  (370kb,D)", "http://arxiv.org/abs/1506.04557v2", null], ["v3", "Wed, 14 Oct 2015 12:28:24 GMT  (370kb,D)", "http://arxiv.org/abs/1506.04557v3", null], ["v4", "Mon, 7 Mar 2016 14:14:00 GMT  (352kb,D)", "http://arxiv.org/abs/1506.04557v4", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chao du", "jun zhu", "bo zhang"], "accepted": false, "id": "1506.04557"}, "pdf": {"name": "1506.04557.pdf", "metadata": {"source": "META", "title": "Learning Deep Generative Models with Doubly Stochastic MCMC", "authors": ["Chao Du", "Jun Zhu", "Bo Zhang"], "emails": ["DU-C14@MAILS.TSINGHUA.EDU.CN", "DCSZJ@MAIL.TSINGHUA.EDU.CN", "DCSZB@MAIL.TSINGHUA.EDU.CN"], "sections": [{"heading": "1. Introduction", "text": "Depth learning, which consists of multi-layered representations, has become highly important in recent years. (Bengio et al., 2014; Hinton et al., 2006), in part because of its ability to grasp high-grade abstractions. As an important family of deep models, deep generative models (DGMs) (Hinton et al., 2006; Salakhutdinov & Hinton, 2009), we can answer a wide range of questions by performing probabilistic inferences, such as inferring the missing values of input data beyond the scope of recognition networks such as deep neural networks. However, probable inference with DGMs is a challenge, especially if a Bayesian formalism is adopted that is desirable to protect DGM from overadjustment (MacKay, 1992; Neal, 1995) and performing economical Bayesian inferences (Gan et al al al., 2015b)."}, {"heading": "2. Related Work", "text": "Recently, there has been a lot of interest in the development of variable methods for DGMs. A common strategy for dealing with the insoluble posterior distribution is to approximate them with a recognition (or inference) network, and a varying lower limit is then optimized (Kingma & Welling, 2014; Mnih & Gregor, 2014), in which the gradients are also double stochastically estimated. Kingma & Welling (2014) and Mnih & Gregor (2014) apply variance reduction techniques to make these methods practically applicable. Titsias & La \u0301 zaro-Gredilla (2014) suggest a so-called \"double stochastic variant inference\" for non-conjugated Bayesian conclusions. We are inspired by these methods when naming these methods; the reweighted waking sleep (RWS) (Bornschein & Bengio, 2015) and the importance of weighted autocoders (IWAal, 2015)."}, {"heading": "3. Doubly Stochastic Gradient MCMC for Deep Generative Models", "text": "We now present the double stochastic gradient MCMC for deep generative models."}, {"heading": "3.1. Deep Generative Models", "text": "A Deep Generative Model (DGM) assumes that each sample is generated by a vector of hidden variables. < l (< l) A Deep Generative Model (DGM) assumes that each sample is generated by a vector of hidden variables. < l (< l) A Deep Generative Model (x | z, \u03b2) is the probability model. The common probability of a DGM is as follows: p (X, Z | p) = N (zn = 1 p (zn | \u03b1) p (xn | zn, \u03b2), (1), (1), (1) where the probability of a DGM is as follows: p (X, Z | p) = N (zn = 1 p (zn | zn, \u03b2), \u03b2), \u03b2 (1). Depending on the structure of z, various DGMs have been developed, such as deep faith networks (Hinton et al., 2006), deep sigmoid faith networks (Mnih & S, 2014, Gregor & S), and many others."}, {"heading": "3.2. Variational MLE for DGMs", "text": "For DGMs, the variational distribution q (z | x; \u03c6) can be formalized as a recognition model (or inference network) (Kingma & Welling, 2014; Mnih & Gregor, 2014; Bornschein & Bengio, 2015), which takes x stochastically as inputs and outputs z. Specific for DGMs with multi-layer representation z = (l)}} Ll = 1 variation variant in Sec. 3.1, the variational distribution in Sec."}, {"heading": "3.3. Doubly Stochastic Gradient MCMC", "text": "We consider the Bayesian attitude to be a consequence of the posterior distribution p (\u03b8, Z | X), assuming some previous p0 (\u03b8). Bayesian formalism of deep learning has several advantages, such as preventing the model from overfitting and performing sparse / non-parametric Bayesian conclusions, as mentioned above. However, posterior distribution, with the exception of a handful of specific examples, is difficult to derive. Although variable methods can be developed, as in (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014; Bornschein & Bengio, 2015), they often require non-trivial model-specific deviations and can lead to inaccurate approximations if the assumptions are not made properly."}, {"heading": "3.3.1. GENERAL PROCEDURE", "text": "We start from the mildest assumption that the parameter space is continuous and that the log joint distribution log (x, z | \u03b8) can be differentiated with respect to the model parameters \u03b8 almost everywhere except for a zero mass set. \u2212 Such an assumption applies to almost all existing DGMs. \u2212 Then our method takes samples in a collapsed space, in which the model parameters are only achieved by integrating the hidden variables. \u2212 Note: The gradient of the log posterior is a log protocol (\u03b8) N-N-p method (zn | \u03b8) dzn, (9) where for discrete variables the integrate will be a sum. \u2212 Then the gradient of the log posterior is a log X-X method."}, {"heading": "3.3.2. NEURAL ADAPTIVE IMPORTANCE SAMPLER", "text": "The remaining challenge is to calculate the gradient as an expectation in Eqn. (10) It is often incomprehensible what the results of the DGMs look like. Here, we construct an unbiased estimate of the gradient based on a series of samples (z (s)). (13) To draw the samples z (s), a simple strategy is Gibbs sampling. Gibbs samplers are simple and applicable to both discrete and continuous hidden variables. However, it is difficult to develop Gibson bs samplers for most DGMs, as the highly complicated models often lead to non-conjugated results. More importantly, a Gibbs sampler can be slow to mix high-dimensional spaces."}, {"heading": "4. Experiments", "text": "We now present a series of experimental results of our double stochastic MCMC method on several representative, deeply generative models: In the experiments, we use the double stochastic gradient nasal Hoover thermostat with a neural adaptive meaning sampler (DSGNHT-NAIS); in paragraph 4.2, various DGMs are trained with discrete hidden variables, such as sigmoid faith networks (Neal, 1992), on the binarized MNIST (Salakhutdinov & Murray, 2008) and the Caltech 101 silhouettes (Marlin et al., 2010); we compare the prediction capability with state-of-the-of-the-art methods in terms of estimated log probability (Est. LL.) on the test set; we also demonstrate generative performance and analyze sensitivity to the most important hyperparameters; in paragraph 4.3, we train variable auto-encoders (Kingelling & WMI, 2014 and NIST)."}, {"heading": "4.1. Setup", "text": "In our experiments, all models (including recognition models) are initialized using the heuristic method of Glorot & Bengio (2010). We put the student t before all model parameters. We use the reformulated form of multivariate SGNHT as described in supplementary material. The perbatch learning rate is set between {0.01, 0.001, 0.001}, Table 1. MNIST results of various methods are set to five benchmark architectures. \"Dim\" means the number of hidden variables in each layer that comes closest to the data available. Values within the brackets are variable lower limits, values without brackets are estimated loglikelihoods. (?) The results of NVIL are from Mnih & Gregor (2014); the results of Wake-sleep and RWS are from Bornschein & Bengio (2015); and the results of Data Augmentation (DA) are from Gan et (2015b)."}, {"heading": "4.2. Discrete Hidden Variable Models", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1. BINARIZED MNIST", "text": "The binarized MNIST dataset consists of 50,000 training samples, 10,000 validation samples and 10,000 test samples. We consider five benchmark models: three SBN models, one DARN model and one NADE model. For the three models with SBN layers, we also use SBN layers to construct the recognition model; for the two models with DARN layer and NADE layer, we follow Bornschein & Bengio (2015) to use the NADE layer for recognition. Model sizes and results are summarized in Table 1. Details of the construction of the models are presented in Supplementary Material.We first examine the effect of the neural adaptive meaning sampler (NAIS). For comparison, we also estimate the gradient Eqn. (10) We estimate the gradient Eqn (10) directly sampling of p (z | x) using a Gibsampler."}, {"heading": "4.2.2. CALTECH 101 SILHOUETTES", "text": "The Caltech 101 Silhouette dataset consists of 4, 100 training samples, 2, 264 validation samples and 2, 307 test samples. First, we compare our method with RWS using two benchmark models in Table 3 (above) and find that our method makes significant improvements. At SBN / SBN 200-200, we get an Est. LL. test of \u2212 108.0, which improves over RWS by 18 nights. Table 3 (below) summarizes our best results and other state-of-the-art results. Our NADE / NADE 150 network detects an Est. LL. test of \u2212 100.0, which improves RWS on the same model for 4.3 Nats. We observe a remarkable effect of increasing the number of M samples for posterior averages: The Est. LL. test of \u2212 100.0 for M = 100 improves RWS compared to \u2212 105.3 for \u2212 1. Gan al. (2015b) achieves the number of L samples for posterior averages from \u2212 100.0 to \u2212 L."}, {"heading": "4.3. Variational Auto-Encoders", "text": "???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????)??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "5. Conclusions and Future Work", "text": "For deep generative models with continuous parameter space, we propose a powerful Bayesian inference method based on stochastic gradient MCMC. It enjoys several advantages of Bayesian formalism, such as the sparse Bayesian inference. Our results include state-of-the-art performance on standard published data sets. For future work, we will gladly examine the performance of sparse Bayesian models. Learning non-parametric Bayesian DGMs is also an interesting challenge."}, {"heading": "A. Model Setup", "text": "We describe how to construct the models with the conditional stochastic layers (l). Each model should consist of an uppermost layer p (z (L) | \u03b8), a data layer p (x | z (1), \u03b8) and (optionally) several intermediate layers p (z (l) | iz (1 + 1), \u03b8 (l). Output of the layer (l + 1) (random samples) is transmitted as input to layer l and thus as a complete generative process for the data. In principle, the type of each layer can be chosen as long as the input dimension and the output dimension of the adjacent layers match each other. The detection model can be constructed in a similar way. In view of a generative model with hidden layers, the detection model should also include L stochastic layers. The first layer takes x as the input and output model of z (1)."}, {"heading": "B. Experimental Setup", "text": "In our implementation we use the reformulated form of multivariate SGNHT (Ding et al., 2014): \u03b8t + 1 = \u03b8t + ut, (29) ut + 1 = ut \u2212 p = ut \u2212 p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = a = a =. This reformulation is cleaner and easier to implement. In analogy to SGD with a dynamic, the learning rate and 1 \u2212 p = p \u2212 p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p =. The initialization of SGNHT is as follows: u is randomized by N (0, g I) and it is initialized as aI. There are three parameters for SGNHT dynamics: We are the dynamics and the dynamics us."}, {"heading": "C. Derivations", "text": "We provide the derivatives of the Gibbs sampler for the DSGNHT Gibbs. The hidden variables are sampled in layers and dimensions. We define z (0) = x and z (L + 1) = 0 for convenience. Then, the probabilities p (z (l) i | z (l) \u00ac i, x (\u00ac l))) as p (z (l) i | z (l) \u00ac i, z (l) \u00ac i, z (l) \u00ac z, z (l) \u00ac l))). We have the following Gibbs samplers: p (z (l) i (l) \u00ac i, z (\u00ac l) i \u2212 bs (l) \u00ac i, z (< l), z (> l) p (z (< l) | z (z) | z (l) z (l) z (l) i (l) i (z (l) i (z), z (z (z), z (z (> ARz))."}], "references": [{"title": "Learning the structure of deep sparse graphical models", "author": ["R. Adams", "H. Wallach", "Z. Ghahramani"], "venue": "In AISTATS,", "citeRegEx": "Adams et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Adams et al\\.", "year": 2010}, {"title": "Bayesian posterior sampling via stochastic gradient fisher scoring", "author": ["S. Ahn", "A. Korattikara", "M. Welling"], "venue": "In ICML,", "citeRegEx": "Ahn et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ahn et al\\.", "year": 2012}, {"title": "Modeling high-dimensional discrete data with multi-layer neural networks", "author": ["Y. Bengio", "S. Bengio"], "venue": "In NIPS,", "citeRegEx": "Bengio and Bengio,? \\Q2000\\E", "shortCiteRegEx": "Bengio and Bengio", "year": 2000}, {"title": "Deep generative stochastic networks trainable by backprop", "author": ["Y. Bengio", "E. Laufer", "G. Alain", "J. Yosinski"], "venue": "In ICML,", "citeRegEx": "Bengio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2014}, {"title": "Reweighted wake-sleep", "author": ["J. Bornschein", "Y. Bengio"], "venue": "In ICLR,", "citeRegEx": "Bornschein and Bengio,? \\Q2015\\E", "shortCiteRegEx": "Bornschein and Bengio", "year": 2015}, {"title": "Online Algorithms and Stochastic Approximations. Online Learning and Neural Networks, Edited by David Saad", "author": ["L. Bottou"], "venue": null, "citeRegEx": "Bottou,? \\Q1998\\E", "shortCiteRegEx": "Bottou", "year": 1998}, {"title": "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription", "author": ["N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent"], "venue": "In ICML,", "citeRegEx": "Boulanger.Lewandowski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Boulanger.Lewandowski et al\\.", "year": 2012}, {"title": "Stochastic gradient hamiltonian monte carlo", "author": ["T. Chen", "E. Fox", "C. Guestrin"], "venue": "In ICML, pp", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Enhanced gradient for training restricted boltzmann machines", "author": ["K. Cho", "T. Raiko", "A. Ilin"], "venue": "Neural computation,", "citeRegEx": "Cho et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2013}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["N. Ding", "Y. Fang", "R. Babbush", "C. Chen", "R. Skeel", "H. Neven"], "venue": "In NIPS,", "citeRegEx": "Ding et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ding et al\\.", "year": 2014}, {"title": "Graphical models for machine learning and digital communication", "author": ["B.J. Frey"], "venue": null, "citeRegEx": "Frey,? \\Q1998\\E", "shortCiteRegEx": "Frey", "year": 1998}, {"title": "Scalable deep poisson factor analysis for topic modeling", "author": ["Z. Gan", "C. Chen", "R. Henao", "D. Carlson", "L. Carin"], "venue": "In ICML,", "citeRegEx": "Gan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gan et al\\.", "year": 2015}, {"title": "Learning deep sigmoid belief networks with data augmentation", "author": ["Z. Gan", "R. Henao", "D. Carlson", "L. Carin"], "venue": "In AISTATS,", "citeRegEx": "Gan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gan et al\\.", "year": 2015}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio"], "venue": "In AISTATS, pp", "citeRegEx": "Glorot and Bengio,? \\Q2010\\E", "shortCiteRegEx": "Glorot and Bengio", "year": 2010}, {"title": "Sparse autoregressive networks", "author": ["M. Goessling", "Y. Amit"], "venue": "arXiv preprint arXiv:1511.04776,", "citeRegEx": "Goessling and Amit,? \\Q2015\\E", "shortCiteRegEx": "Goessling and Amit", "year": 2015}, {"title": "Deep autoregressive networks", "author": ["K. Gregor", "I. Danihelka", "A. Mnih", "C. Blundell", "D. Wierstra"], "venue": "In ICML,", "citeRegEx": "Gregor et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2014}, {"title": "Draw: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Rezende", "D. Wierstra"], "venue": "In ICML,", "citeRegEx": "Gregor et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2015}, {"title": "Neural adaptive sequential monte carlo", "author": ["S. Gu", "Z. Ghahramani", "R.E. Turner"], "venue": "In NIPS, pp", "citeRegEx": "Gu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gu et al\\.", "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y. Teh"], "venue": "Neural Computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "An introduction to variational methods for graphical models", "author": ["M. Jordan", "Z. Ghahramani", "T. Jaakkola", "L. Saul"], "venue": "MLJ, 37(2):183\u2013233,", "citeRegEx": "Jordan et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Jordan et al\\.", "year": 1999}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J.L. Ba"], "venue": "In ICLR,", "citeRegEx": "Kingma and Ba,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2015}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "In ICLR,", "citeRegEx": "Kingma and Welling,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Welling", "year": 2014}, {"title": "Oneshot learning by inverting a compositional causal process", "author": ["B.M. Lake", "R. Salakhutdinov", "J. Tenenbaum"], "venue": "In NIPS, pp", "citeRegEx": "Lake et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2013}, {"title": "The neural autoregressive distribution estimator", "author": ["H. Larochelle", "I. Murray"], "venue": "In AISTATS,", "citeRegEx": "Larochelle and Murray,? \\Q2011\\E", "shortCiteRegEx": "Larochelle and Murray", "year": 2011}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. Lecun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Lecun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Lecun et al\\.", "year": 1998}, {"title": "High-order stochastic gradient thermostats for bayesian learning of deep models", "author": ["C. Li", "C. Chen", "K. Fan", "L. Carin"], "venue": "In AAAI,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A practical bayesian framework for backpropagation networks", "author": ["D. MacKay"], "venue": "Neural Computation,", "citeRegEx": "MacKay,? \\Q1992\\E", "shortCiteRegEx": "MacKay", "year": 1992}, {"title": "Inductive principles for restricted boltzmann machine learning", "author": ["B. Marlin", "K. Swersky", "B. Chen", "N. Freitas"], "venue": "In AISTATS, pp", "citeRegEx": "Marlin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Marlin et al\\.", "year": 2010}, {"title": "Neural variational inference and learning in belief networks", "author": ["A. Mnih", "K. Gregor"], "venue": "In ICML,", "citeRegEx": "Mnih and Gregor,? \\Q2014\\E", "shortCiteRegEx": "Mnih and Gregor", "year": 2014}, {"title": "Evaluating probabilities under high-dimensional latent variable models", "author": ["I. Murray", "R. Salakhutdinov"], "venue": "In NIPS, pp", "citeRegEx": "Murray and Salakhutdinov,? \\Q2009\\E", "shortCiteRegEx": "Murray and Salakhutdinov", "year": 2009}, {"title": "Connectionist learning of belief networks", "author": ["R.M. Neal"], "venue": "Artificial intelligence,", "citeRegEx": "Neal,? \\Q1992\\E", "shortCiteRegEx": "Neal", "year": 1992}, {"title": "Bayesian learning for neural networks", "author": ["R.M. Neal"], "venue": "PhD thesis, University of Toronto,", "citeRegEx": "Neal,? \\Q1995\\E", "shortCiteRegEx": "Neal", "year": 1995}, {"title": "Iterative neural autoregressive distribution estimator nade-k", "author": ["T. Raiko", "Y. Li", "K. Cho", "Y. Bengio"], "venue": "In NIPS, pp", "citeRegEx": "Raiko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Raiko et al\\.", "year": 2014}, {"title": "Black box variational inference", "author": ["R. Ranganath", "S. Gerrish", "D.M. Blei"], "venue": "In ICML,", "citeRegEx": "Ranganath et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ranganath et al\\.", "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "In ICML,", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Robbins and Monro,? \\Q1951\\E", "shortCiteRegEx": "Robbins and Monro", "year": 1951}, {"title": "On the quantitative analysis of deep belief networks", "author": ["R. Salakhutdinov", "I. Murray"], "venue": "In ICML, pp", "citeRegEx": "Salakhutdinov and Murray,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov and Murray", "year": 2008}, {"title": "Mean field theory for sigmoid belief networks", "author": ["L. Saul", "T. Jaakkola", "M. Jordan"], "venue": "Journal of AI Research,", "citeRegEx": "Saul et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Saul et al\\.", "year": 1996}, {"title": "Doubly stochastic variational bayes for non-conjugate inference", "author": ["M.K. Titsias", "M. L\u00e1zaro-Gredilla"], "venue": "In ICML, pp. 1971\u20131979,", "citeRegEx": "Titsias and L\u00e1zaro.Gredilla,? \\Q2014\\E", "shortCiteRegEx": "Titsias and L\u00e1zaro.Gredilla", "year": 2014}, {"title": "A deep and tractable density estimator", "author": ["B. Uria", "I. Murray", "H. Larochelle"], "venue": "In ICML, pp", "citeRegEx": "Uria et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Uria et al\\.", "year": 2014}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["M. Welling", "Y.W. Teh"], "venue": "In ICML,", "citeRegEx": "Welling and Teh,? \\Q2011\\E", "shortCiteRegEx": "Welling and Teh", "year": 2011}, {"title": "The stepsize \u03b7\u2032 is chosen from {1, 3, 5}\u00d710\u22124 with best performance. The model parameters are initialized following the heuristic of Glorot", "author": [], "venue": null, "citeRegEx": "10\u221210.,? \\Q2010\\E", "shortCiteRegEx": "10\u221210.", "year": 2010}], "referenceMentions": [{"referenceID": 3, "context": "Learning deep models that consist of multi-layered representations has obtained state-of-the-art performance in many tasks (Bengio et al., 2014; Hinton et al., 2006), partly due to their ability on capturing high-level abstractions.", "startOffset": 123, "endOffset": 165}, {"referenceID": 18, "context": "Learning deep models that consist of multi-layered representations has obtained state-of-the-art performance in many tasks (Bengio et al., 2014; Hinton et al., 2006), partly due to their ability on capturing high-level abstractions.", "startOffset": 123, "endOffset": 165}, {"referenceID": 18, "context": "As an important family of deep models, deep generative models (DGMs) (Hinton et al., 2006; Salakhutdinov & Hinton, 2009) can answer a wide range of queries by performing probabilistic inference, such as inferring the missing values of input data, which is beyond the scope of recognition networks such as deep neural networks.", "startOffset": 69, "endOffset": 120}, {"referenceID": 26, "context": "However, probabilistic inference with DGMs is challenging, especially when a Bayesian formalism is adopted, which is desirable to protect the DGM from overfitting (MacKay, 1992; Neal, 1995) and to perform sparse Bayesian inference (Gan et al.", "startOffset": 163, "endOffset": 189}, {"referenceID": 31, "context": "However, probabilistic inference with DGMs is challenging, especially when a Bayesian formalism is adopted, which is desirable to protect the DGM from overfitting (MacKay, 1992; Neal, 1995) and to perform sparse Bayesian inference (Gan et al.", "startOffset": 163, "endOffset": 189}, {"referenceID": 0, "context": ", 2015b) or nonparametric inference (Adams et al., 2010) to learn the network structure.", "startOffset": 36, "endOffset": 56}, {"referenceID": 19, "context": "To address the challenges, approximate methods have to be adopted, including variational (Jordan et al., 1999; Saul et al., 1996) and Markov chain Monte Carlo (MCMC) methods (Robert & Casella, 2005).", "startOffset": 89, "endOffset": 129}, {"referenceID": 37, "context": "To address the challenges, approximate methods have to be adopted, including variational (Jordan et al., 1999; Saul et al., 1996) and Markov chain Monte Carlo (MCMC) methods (Robert & Casella, 2005).", "startOffset": 89, "endOffset": 129}, {"referenceID": 34, "context": "Much progress has been made on stochastic variational methods for DGMs (Kingma & Welling, 2014; Rezende et al., 2014; Ranganath et al., 2014), under some mean-field or parameterization assumptions.", "startOffset": 71, "endOffset": 141}, {"referenceID": 33, "context": "Much progress has been made on stochastic variational methods for DGMs (Kingma & Welling, 2014; Rezende et al., 2014; Ranganath et al., 2014), under some mean-field or parameterization assumptions.", "startOffset": 71, "endOffset": 141}, {"referenceID": 10, "context": "Gan et al. (2015b) present a Gibbs sampler for deep sigmoid belief networks with a sparsity-inducing prior via data augmentation, Adams et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 0, "context": "(2015b) present a Gibbs sampler for deep sigmoid belief networks with a sparsity-inducing prior via data augmentation, Adams et al. (2010) present a Metropolis-Hastings method for cascading Indian buffet process and Li et al.", "startOffset": 119, "endOffset": 139}, {"referenceID": 0, "context": "(2015b) present a Gibbs sampler for deep sigmoid belief networks with a sparsity-inducing prior via data augmentation, Adams et al. (2010) present a Metropolis-Hastings method for cascading Indian buffet process and Li et al. (2016) develop a high-order stochastic gradient MCMC method and apply to deep Poisson factor analysis (Gan et al.", "startOffset": 119, "endOffset": 233}, {"referenceID": 1, "context": "By drawing samples in the collapsed parameter space, our method extends the recent work on stochastic gradient MCMC (Welling & Teh, 2011; Ahn et al., 2012; Chen et al., 2014; Ding et al., 2014) to deal with the challenging task of posterior inference with DGMs.", "startOffset": 116, "endOffset": 193}, {"referenceID": 7, "context": "By drawing samples in the collapsed parameter space, our method extends the recent work on stochastic gradient MCMC (Welling & Teh, 2011; Ahn et al., 2012; Chen et al., 2014; Ding et al., 2014) to deal with the challenging task of posterior inference with DGMs.", "startOffset": 116, "endOffset": 193}, {"referenceID": 9, "context": "By drawing samples in the collapsed parameter space, our method extends the recent work on stochastic gradient MCMC (Welling & Teh, 2011; Ahn et al., 2012; Chen et al., 2014; Ding et al., 2014) to deal with the challenging task of posterior inference with DGMs.", "startOffset": 116, "endOffset": 193}, {"referenceID": 17, "context": "Our work is closely related to the recent progress on neural adaptive proposals for sequential Monte Carlo (NASMC) (Gu et al., 2015).", "startOffset": 115, "endOffset": 132}, {"referenceID": 11, "context": "Finally, Gan et al. (2015a) adopt a Monte Carlo estimate via Gibbs sampling to the intractable gradients under a stochastic MCMC method particularly for topic models.", "startOffset": 9, "endOffset": 28}, {"referenceID": 18, "context": "Depending on the structure of z, various DGMs have been developed, such as deep belief networks (Hinton et al., 2006), deep sigmoid belief networks (Mnih & Gregor, 2014), and deep Boltzmann machines (Salakhutdinov & Hinton, 2009).", "startOffset": 96, "endOffset": 117}, {"referenceID": 37, "context": "Sigmoid Belief Network layer (SBN): A SBN layer (Saul et al., 1996) is a directed graphical model that defines the conditional probability of each independent binary variable z (l) i given the upper layer z (l+1) as follows: p(z (l) i = 1|z ) = \u03c3(Wi,:z (l+1) + bi), (4) where \u03c3(x) = 1/(1 + e\u2212x) is the sigmoid function, Wi,: denotes the i-th row of the weight matrix and bi is the bias.", "startOffset": 48, "endOffset": 67}, {"referenceID": 15, "context": "Deep Autoregressive Network layer (DARN): A DARN (Gregor et al., 2014) layer assumes in-layer connections on the SBN layer.", "startOffset": 49, "endOffset": 70}, {"referenceID": 6, "context": "Boulanger-Lewandowski et al. (2012) and Bornschein & Bengio (2015) amend this model to a conditional NADE layer:", "startOffset": 0, "endOffset": 36}, {"referenceID": 6, "context": "Boulanger-Lewandowski et al. (2012) and Bornschein & Bengio (2015) amend this model to a conditional NADE layer:", "startOffset": 0, "endOffset": 67}, {"referenceID": 34, "context": "To address this challenge, recent progress (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014) has adopted hybrid Monte Carlo and variational methods, which approximate the intractable expectations and their gradients over the parameters (\u03b8,\u03c6) via some unbiased Monte Carlo estimates.", "startOffset": 43, "endOffset": 110}, {"referenceID": 5, "context": "Furthermore, to handle large-scale datasets, stochastic optimization (Robbins & Monro, 1951; Bottou, 1998) of the variational objective can be used with a suitable learning rate annealing scheme.", "startOffset": 69, "endOffset": 106}, {"referenceID": 34, "context": "Though variational methods can be developed as in (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014; Bornschein & Bengio, 2015), under some mean-field or parameterization assumptions, they often require non-trivial model-specific deviations and may lead to inaccurate approximation when the assumptions are not properly made.", "startOffset": 50, "endOffset": 144}, {"referenceID": 1, "context": "A straightforward application of MCMC methods can be Gibbs sampling or stochastic gradient MCMC (Welling & Teh, 2011; Ahn et al., 2012; Chen et al., 2014; Ding et al., 2014).", "startOffset": 96, "endOffset": 173}, {"referenceID": 7, "context": "A straightforward application of MCMC methods can be Gibbs sampling or stochastic gradient MCMC (Welling & Teh, 2011; Ahn et al., 2012; Chen et al., 2014; Ding et al., 2014).", "startOffset": 96, "endOffset": 173}, {"referenceID": 9, "context": "A straightforward application of MCMC methods can be Gibbs sampling or stochastic gradient MCMC (Welling & Teh, 2011; Ahn et al., 2012; Chen et al., 2014; Ding et al., 2014).", "startOffset": 96, "endOffset": 173}, {"referenceID": 9, "context": "We consider the stochastic gradient Nos\u00e9-Hoover thermostat (SGNHT) (Ding et al., 2014).", "startOffset": 67, "endOffset": 86}, {"referenceID": 7, "context": ", stochastic gradient Langevin dynamics (Welling & Teh, 2011), stochastic gradient Hamiltonian Monte Carlo (Chen et al., 2014) and high-order stochastic gradient thermostats (Li et al.", "startOffset": 107, "endOffset": 126}, {"referenceID": 25, "context": ", 2014) and high-order stochastic gradient thermostats (Li et al., 2016).", "startOffset": 55, "endOffset": 72}, {"referenceID": 11, "context": "We follow Gan et al. (2015a) to use the multivariate version of SGNHT that generate samples by simulating the dynamics as follows: \u03b8t+1 = \u03b8t + \u03bbpt, (12) pt+1 = pt \u2212 \u03bb\u03bet pt \u2212 \u03bb\u2207\u03b8\u0168(\u03b8t+1) + \u221a 2AN (0, \u03bbI), \u03bet+1 = \u03bet + \u03bb(pt+1 pt+1 \u2212 I),", "startOffset": 10, "endOffset": 29}, {"referenceID": 17, "context": "Here, we draw inspirations from variational methods and learn adaptive proposals (Gu et al., 2015) by minimizing some criterion.", "startOffset": 81, "endOffset": 98}, {"referenceID": 17, "context": "We optimize the quality of the proposal distribution by minimizing the inclusive KL-divergence between the target posterior distribution and the proposal Ep(z|x,\u03b8)[log p(z|x,\u03b8) q(z|x;\u03c6) ] (Bornschein & Bengio, 2015; Gu et al., 2015) or equivalently maximizing the expected loglikelihood of the recognition model", "startOffset": 188, "endOffset": 232}, {"referenceID": 34, "context": "In contrast, the exclusive KL-divergence L(\u03c6;\u03b8,x) := Eq(z|x;\u03c6)[log q(z|x;\u03c6) p(z|x,\u03b8) ], as widely adopted in the variational methods (Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), does not have such a property \u2014 It can happen that q(z|x;\u03c6) = 0 when p(z|x,\u03b8) > 0; therefore unsuitable for importance sampling.", "startOffset": 133, "endOffset": 200}, {"referenceID": 30, "context": "2, various DGMs with discrete hidden variables, such as sigmoid belief networks (Neal, 1992), are trained on the binarized MNIST (Salakhutdinov & Murray, 2008) and the Caltech 101 Silhouettes (Marlin et al.", "startOffset": 80, "endOffset": 92}, {"referenceID": 27, "context": "2, various DGMs with discrete hidden variables, such as sigmoid belief networks (Neal, 1992), are trained on the binarized MNIST (Salakhutdinov & Murray, 2008) and the Caltech 101 Silhouettes (Marlin et al., 2010) datasets.", "startOffset": 192, "endOffset": 213}, {"referenceID": 22, "context": "3, we train variational auto-encoders (Kingma & Welling, 2014) on the binarized MNIST and the Omniglot (Lake et al., 2013) datasets.", "startOffset": 103, "endOffset": 122}, {"referenceID": 11, "context": "The results of NVIL are from Mnih & Gregor (2014); the results of Wake-sleep and RWS are from Bornschein & Bengio (2015); and the results of Data Augmentation (DA) are from Gan et al. (2015b). Model Dim NVIL Wake-Sleep RWS DA DSGNHT-Gibbs DSGNHT-NAIS SBN 200 (\u2212113.", "startOffset": 173, "endOffset": 192}, {"referenceID": 36, "context": "Results are taken from [1] Bornschein & Bengio (2015), [2] Larochelle & Murray (2011), [3] Uria et al. (2014), [4] Gregor et al.", "startOffset": 91, "endOffset": 110}, {"referenceID": 15, "context": "(2014), [4] Gregor et al. (2014), [5] Salakhutdinov & Murray (2008), [6] Raiko et al.", "startOffset": 12, "endOffset": 33}, {"referenceID": 15, "context": "(2014), [4] Gregor et al. (2014), [5] Salakhutdinov & Murray (2008), [6] Raiko et al.", "startOffset": 12, "endOffset": 68}, {"referenceID": 15, "context": "(2014), [4] Gregor et al. (2014), [5] Salakhutdinov & Murray (2008), [6] Raiko et al. (2014), [7] Murray & Salakhutdinov (2009), [8] Burda et al.", "startOffset": 12, "endOffset": 93}, {"referenceID": 15, "context": "(2014), [4] Gregor et al. (2014), [5] Salakhutdinov & Murray (2008), [6] Raiko et al. (2014), [7] Murray & Salakhutdinov (2009), [8] Burda et al.", "startOffset": 12, "endOffset": 128}, {"referenceID": 15, "context": "(2014), [4] Gregor et al. (2014), [5] Salakhutdinov & Murray (2008), [6] Raiko et al. (2014), [7] Murray & Salakhutdinov (2009), [8] Burda et al. (2015). Trained on the original MNIST dataset.", "startOffset": 12, "endOffset": 153}, {"referenceID": 24, "context": "90, which is trained on the original MNIST dataset (Lecun et al., 1998) and thus not directly comparable.", "startOffset": 51, "endOffset": 71}, {"referenceID": 15, "context": "Gregor et al. (2015) give a lower bound \u221280.", "startOffset": 0, "endOffset": 21}, {"referenceID": 8, "context": "Results are taken from [1] Bornschein & Bengio (2015), [2] Cho et al. (2013), [3] Raiko et al.", "startOffset": 59, "endOffset": 77}, {"referenceID": 8, "context": "Results are taken from [1] Bornschein & Bengio (2015), [2] Cho et al. (2013), [3] Raiko et al. (2014). \u2020 Results are produced using the authors\u2019 published code.", "startOffset": 59, "endOffset": 102}, {"referenceID": 10, "context": "40 by training FVSBN (Frey, 1998) with both training data and validation data.", "startOffset": 21, "endOffset": 33}, {"referenceID": 10, "context": "Gan et al. (2015b) achieve \u221296.", "startOffset": 0, "endOffset": 19}, {"referenceID": 10, "context": "40 by training FVSBN (Frey, 1998) with both training data and validation data. A latest work by Goessling & Amit (2015) achieves \u221288.", "startOffset": 22, "endOffset": 120}], "year": 2016, "abstractText": "We present doubly stochastic gradient MCMC, a simple and generic method for (approximate) Bayesian inference of deep generative models (DGMs) in a collapsed continuous parameter space. At each MCMC sampling step, the algorithm randomly draws a mini-batch of data samples to estimate the gradient of log-posterior and further estimates the intractable expectation over hidden variables via a neural adaptive importance sampler, where the proposal distribution is parameterized by a deep neural network and learnt jointly. We demonstrate the effectiveness on learning various DGMs in a wide range of tasks, including density estimation, data generation and missing data imputation. Our method outperforms many state-of-the-art competitors.", "creator": "LaTeX with hyperref package"}}}