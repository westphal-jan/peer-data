{"id": "1506.04584", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2015", "title": "Re-scale AdaBoost for Attack Detection in Collaborative Filtering Recommender Systems", "abstract": "Collaborative filtering recommender systems (CFRSs) are the key components of successful e-commerce systems. Actually, CFRSs are highly vulnerable to attacks since its openness. However, since attack size is far smaller than that of genuine users, conventional supervised learning based detection methods could be too \"dull\" to handle such imbalanced classification. In this paper, we improve detection performance from following two aspects. First, we extract well-designed features from user profiles based on the statistical properties of the diverse attack models, making hard classification task becomes easier to perform. Then, refer to the general idea of re-scale Boosting (RBoosting) and AdaBoost, we apply a variant of AdaBoost, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features. RAdaBoost is comparable to the optimal Boosting-type algorithm and can effectively improve the performance in some hard scenarios. Finally, a series of experiments on the MovieLens-100K data set are conducted to demonstrate the outperformance of RAdaBoost comparing with some classical techniques such as SVM, kNN and AdaBoost.", "histories": [["v1", "Mon, 15 Jun 2015 13:07:52 GMT  (6785kb,D)", "http://arxiv.org/abs/1506.04584v1", "30 pages, 8 figures"]], "COMMENTS": "30 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.IR cs.CR cs.LG", "authors": ["zhihai yang", "lin xu", "zhongmin cai"], "accepted": false, "id": "1506.04584"}, "pdf": {"name": "1506.04584.pdf", "metadata": {"source": "CRF", "title": "Re-scale AdaBoost for Attack Detection in Collaborative Filtering Recommender Systems", "authors": ["I Zhihai Yang", "Lin Xu", "Zhongmin Cai"], "emails": ["xulinshadow@gmail.com"], "sections": [{"heading": null, "text": "In fact, CFRS are highly susceptible to attack because of their openness. However, since the size of the attack is much smaller than that of actual users, conventionally monitored learning-based detection methods may be too \"boring\" to deal with such an unbalanced classification. In this paper, we improve detection performance for two reasons. First, we use a variant of AdaBoost called Rescale AdaBoost (RAdaBoost) as a detection method based on extracted features. Then, we refer to the general idea of re-scale boosting (RBoosting) and AdaBoost, applying a variant of AdaBoost called Rescale AdaBoost (RAdaBoost). RAdaBoost is similar to the optimal boosting algorithm and can effectively improve performance in some harsh scenarios."}, {"heading": "1. Introduction", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2. Related work", "text": "In fact, most of them will be able to feel as if they are able to survive on their own."}, {"heading": "3. Attack profiles and attack models", "text": "Attackers have different attack scenarios to distort the recommendation results for their advantages. In literature, shilling attacks are classified into two types: max. attack and push attack [3], [12], [25]. In nuclear attacks, attackers degrade the target elements by scoring the lowest, whereas in push attacks, attackers promote the target elements by scoring the highest score by describing the target elements as follows: IT: A set of targets with singletarget attack or multi-target attack. The general form of the attack profiles is described in Table 1. The details of the four item groups are described as follows: IT: A set of targets with singletarget attack or multiple items, called singletarget attack or multi-target attack. The rating is usually the maximum or minimum value in the entire profiles. IS: The set of selected elements with a specified rating by the function (S) are assigned randomly to the elements (Ik: A series of filters)."}, {"heading": "4. Our approach", "text": "In this section, we first present a general introduction to our approach, followed by a detailed description of the two main aspects of our work, including extracting features from user profiles and RAdaBoost for attack detection."}, {"heading": "4.1. The framework of our approach", "text": "As shown in Figure 1, our approach consists of four phases: the phase of creation of training data sets and test data sets, the phase of function extraction, the phase of training classifier via RAdaBoost and the phase of testing for detection results. In the phase of creation of training data sets and 7 test sets, the data sets are constructed using attack profiles (different attack models are injected) and real profiles. Specifically, we use several representative attack models for training data sets, such as random, average attacks, etc., to generate mixed attack profiles. Specifically, we increase the number of attacks (160 attackers for each attack model) when creating the training data set to alleviate the extent of imbalance in the training phase (see Section 5 for more details). Then we combine them with real profiles such as our training data set. For test sets, we increase the attack profiles with different filler sizes and attack sizes to integrate test sets (see section 5)."}, {"heading": "4.2. Feature extraction from user profiles", "text": "Previous work [3, 25, 26, 20] has summarized various parameters to characterize features extracted from user profiles. Generally, these characteristics can be divided into two types: generic and type-specific characteristics. Generic characteristics are basic descriptive statistics that attempt to distinguish between attack profiles and real profiles, and type-specific characteristics are implemented to detect characteristics of profiles generated by specific attack models or specific signatures of attacks. In the present paper, we will use 10 characteristics from these two types. In addition, we will use 5 characteristics based on the filler size [31] and propose another 3 new characteristics that measure the distribution of specific evaluations such as average rating, maximum rating and minimum rating of contents for each user."}, {"heading": "4.2.1. Generic features", "text": "Attack profiles usually have a high deviation from the mean value of the target elements and a small deviation from the mean value of the remaining elements. Therefore, generic characteristics such as RDMA, WDMA, etc. are often used to measure the deviation of the rating of user profiles [3, 25, 26, 34].8Rating Deviation from Mean Agreement (RDMA): RDMAu = \u2211 Nu = 0 | ru, i \u2212 ri | NRiNu (4.1), where Nu is the number of ratings that user u rated, and NRi is the number of ratings given for item i. ru, i is the rating given by user u to item i, ri is the average rating of item i across all users. Weighted Deviation from Mean Agreement (WDMA): WDMAu = \u0445 Nu = 0 | ru, i \u2212 ri | NR2iNu (4.2) Weighted Degree of Agreement (WDA): Wu = Mean (Number of Agreements)."}, {"heading": "4.2.2. Type-specific features", "text": "The model-based methods assume that we have some prior knowledge of the attack models. On the basis of an adopted model, assessments can be automatically divided into bulk goods and selected goods [3, 25, 26, 34]. Therefore, measurements such as MeanVar, FMTD, etc. can be calculated from any subset in order to measure the authenticity of profiles. (Mean Variance (MeanVar): MeanV aru = \u2211 Pu, F (ru, j \u2212 ru) 2 | Pu, F | (4.5), where Pu, F is the remainder of the profile: Pu \u2212 Pu, T, Pu, T = {i-Pu, so ru, i = rmax} (or rmin for nuke attack), Pu is the profile of the user and filler Mean Target Difference (FMTD): FMTD = FMUDu = 1, I-Fu-Fu-Fu-Fu, Fu-Fu-Fu-Fu-Fu, Fu-Fu-Fu-I-I-I-I-I-Fu-Fu, Fu-I-I-Fu-I-Fu-I-I-Fu-I-I-Fu-I-Fu."}, {"heading": "4.2.3. Features based on the filler size", "text": "User profiles with different number of ratings generate different characteristics. Similarly, the number of ratings for different types of articles also generates different characteristics (FSTI, FSPI etc. [31]. Filler size for total items (FSTI): The ratio between the number of articles rated by user u and the number of total articles in the recommendation system [31].FSTIu = \u2211 | I | i = 1O (ru, i) | I | (4,11), where I is the total number of articles in the system. | I | denotes the total number of articles in the system. O (ru, i) is 1 if user u rated articles i, 0 otherwise.Filler size for popular articles (FSPI): The ratio between the number of popular articles rated by user u and the number of total popular articles in the recommendation system [31].FSPIu = Popular articles, I = Popular items, I (4,12)."}, {"heading": "4.2.4. Our proposed features", "text": "We propose 3 new features that focus on the number of specific ratings (such as the maximum score, minimum score and average score) on filler or selected items. Since attackers show different attack intentions in CFRSs, the filler or selected set of attack profiles can be filled with specific items (i.e., select popular items for bandwagon (average and random) attacks, select random items in the system for random attacks) with the highest score or lowest score or average score. For example, take nuclear attacks, the selected items or fillers are rated with maximum score in reversed bandwagon, segment and love / hate attacks (as shown in Table 2). Likewise, the selected items or fillers with minimum score in bandwagon (average), bandwagon (random) and segment attacks are rated with maximum score in reversed bandwagon, segment and love / hate attacks (as shown in Table 2)."}, {"heading": "4.3. Re-scale AdaBoost for attack detection", "text": "As is well known, the number of attackers is usually much smaller than the actual users in CFRSs, so the number of attacks detected in this case can be formulated as an unbalanced classification, as it has proven efficient when confronted with some difficult scenarios as an unbalanced classification. In boosting, weak learners are adapted to the training data by gradually increasing the emphasis on observations characterized by the existing collection of weak learners."}, {"heading": "5. Experiments and analysis", "text": "In this part, we first present the experimental settings, including the datasets, evaluation metrics, and the computation environment. Second, we analyze the 15 effects of the extracted features. Then, we compare the performance of RAdaBoost with three other benchmark methods, such as SVM, kNN, and AdaBoost, across different 4 attack detection methods to demonstrate the performance of RAdaBoost. Finally, the remaining 10 types of attacks are performed using RAdaBoost to further evaluate its performance."}, {"heading": "5.1. Experimental settings", "text": "This year it is in our hands that there is such a process, in which there is such a process."}, {"heading": "5.2. Impact of extracted features", "text": "Bandwagon (average) 18To evaluate the effects of the extracted features, we perform a list of experiments in multiple attack models with different filler sizes, as illustrated in Figure 2. We use the clustering method EM (Expectation-Maximization) (clustering results and EM clustering method were created with Weka 5) to separate attackers from real users as much as possible, based on 10 features (generic and type-specific features), 15 features (additional 5 features based on filler size) and 18 features (all of the above features, including 3 of our proposed features) to analyze the relationship between the number of extracted features and performance in terms of filler size. Similarly, as shown in Figure 2, Bandwagon (average), segment, reverse bandwagon and PIA-AS attacks are taken as examples. Clearly from the results, the false alarm rate decreases significantly when more features are extracted."}, {"heading": "5.3. Experimental results and analysis", "text": "In fact, most of us are able to assert ourselves, that we are able to change and change the world, \"he said in an interview with the New York Times."}, {"heading": "6. Conclusion and further discussions", "text": "\"Shilling\" attacks or \"profile injection\" attacks are serious threats to the Collaborative Filter Recommendation Systems (CFRS). Since the number of attackers detected is much smaller than real users, conventional, learning-based detection methods face the challenges of this unbalanced classification. In the present work, we improved detection performance in two directions. First, we extracted characteristics from user profiles based on the statistical properties of the different attack models in order to classify them much more easily. Then, we applied a variant of the boosting algorithm, the so-called Re-Scale AdaBoost (RAdaBoost), as our detection method, which gradually focuses on affected attacks and could significantly improve the predictive ability in a difficult classification task. And, all of our experimental results also demonstrated the superiority of 21RAdaBoost in shilling detection of attacks, and we will examine more effective features in our future work to characterize them."}], "references": [{"title": "Approximation and learning by greedy algorithms", "author": ["A. Barron", "A. Cohen", "W. Dahmen", "R. DeVore"], "venue": "Ann. Stat., 36(1):64\u201394", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Unsupervised retrieval of attack profiles in collaborative recommender systems", "author": ["K. Bryan", "M. OMahony", "P. Cunningham"], "venue": "ACM conference on Recommender Systems, page 155C162", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Classification features for attack detection in collaborative recommender systems", "author": ["R. Burke", "B. Mobasher", "C. Williams"], "venue": "International Conference on Knowledge Discovery and Data Mining, pages 17\u201320", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.C. Chang", "C.J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, 2:27:1\u201327:27", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "A novel approach to filter out malicious rating profiles from recommender systems", "author": ["C. Chung", "P. Hsu", "S. Huang"], "venue": "Journal of Decision Support Systems, page 314C325", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Evaluation: From precision", "author": ["M.W. David"], "venue": "recall and f-measure to roc, informedness, markedness correlation. Journal of Machine Learning Technologies", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Some remarks on greedy algorithms", "author": ["R. DeVore", "V. Temlyakov"], "venue": "Adv. Comput. Math., 5(1):173\u2013187", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1996}, {"title": "Characterizing l2 boosting", "author": ["J. Ehrlinger", "H. Ishwaran"], "venue": "Ann. Stat., 40(2):1074\u20131101", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "pages 23\u201337", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1995}, {"title": "Experiments with a new boosting algorithm", "author": ["Y. Freund", "R.E. Schapire"], "venue": "ICML, 96:148\u2013156", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["J. Friedman"], "venue": "Ann. Stat., 29(5):1189\u20131232", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Shilling attacks against recommender systems: A comprehensive survey", "author": ["I. Gunes", "C. Kaleli", "A. Bilge", "H. Polat"], "venue": "Artificial Intelligence Review, pages 1\u201333", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Machine Learning in Action", "author": ["P. Harrington"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Forward stagewise regression and the monotone lasso", "author": ["T. Hastie", "J. Taylor", "R. Tibshirani", "G. Walther"], "venue": "Electron. J. Stat., 1:1\u201329", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Attack detection by rough set theory in recommendation system", "author": ["F. He", "X.Wang", "B. Liu"], "venue": "IEEE International Conference on Granular Computing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Detection of shilling attacks in collaborative filtering recommender systems", "author": ["C. Li", "Z. Luo"], "venue": "International Conference of Soft Computing and Pattern Recognition, page 190C193", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Re-scale boosting for regression and classification", "author": ["S.B. Lin", "Y. Wang", "L. Xu"], "venue": "ArXiv:1505.01371", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Lower bounds for the rate of convergence of greedy algorithms", "author": ["E.D. Livshits"], "venue": "Izvestiya: Mathematics, 73(6):1197\u20131215", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Lies and propaganda: detecting spam users in collaborative filtering", "author": ["B. Mehta", "T. Hofmann", "P. Fankhauser"], "venue": "In: IUI07: Proceedings of the 12th International Conference on Intelligent User Interfaces, page 14C21", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Defending recommender systems by influence analysis", "author": ["M. Morid", "M. Shajari"], "venue": "Information Retrieval, pages 137\u2013152", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Assessing impacts of a power user attack on a matrix factorization collaborative recommender system", "author": ["C.E. Seminario", "D.C. Wilson"], "venue": "Florida Artificial Intelligence Research Society Conference", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Attacking item-based recommender systems with power items", "author": ["C.E. Seminario", "D. C Wilson"], "venue": "ACM Conference on Recommender Systems, pages 57\u201364", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "The elements of statistical learning", "author": ["R. Tibshirani T. Hastie", "Jerome J. Friedman"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "Greedy approximation", "author": ["V. Temlyakov"], "venue": "Acta Numer., 17:235\u2013409", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "Defending recommender systems: detection of profile injection attacks", "author": ["C.A. Williams", "B. Mobasher", "R. Burke"], "venue": "SOCA, page 157C170", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Detecting profile injection attacks in collaborative filtering: a classification-based approach", "author": ["C.A. Williams", "B. Mobasher", "R. Burke", "R. Bhaumik"], "venue": "Advances in Web Mining and Web Usage Analysis, page 167C186", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "A survey on shilling attack models and detection techniques for recommender systems", "author": ["Z.A. Wu", "Y.Q. Wang", "J. Cao"], "venue": "Science China, 59(7):551\u2013560", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Hysad: a semi-supervised hybrid shilling attack detector for trustworthy product recommendation", "author": ["Z.A. Wu", "J.J. Wu", "J. Cao", "D.C. Tao"], "venue": "ACM SIGKDD Conference on Knowledge Discovery and Data Mining, page 985C993", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Shrinkage degree in l2-rescale boosting for regression", "author": ["L. Xu", "S.B. Lin", "Y. Wang", "Z.B. Xu"], "venue": "Submitted to IEEE Trans. Neural Netw. & Learn. Syst.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1505}, {"title": "A meta-learning-based approach for detecting profile injection attacks in collaborative recommender systems", "author": ["F. Zhang", "Q. Zhou"], "venue": "J. Comput., 7(1):226\u2013234", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "HHT-SVM: An online method for detecting profile injection attacks in collaborative recommender systems", "author": ["F. Zhang", "Q. Zhou"], "venue": "Knowledge- Based Systems", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Boosting with early stopping: convergence and consistency", "author": ["T. Zhang", "B. Yu"], "venue": "Ann. Stat., 33(4):1538\u20131579", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "Graph-based detection of shilling attacks in recommender systems", "author": ["Z. Zhang", "S. Kulkarni"], "venue": "IEEE International Workshop on Machine Learning for Signal Processing, pages 1\u20136", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Detection of shilling attacks in recommender systems via spectral clustering", "author": ["Z. Zhang", "S.R. Kulkarni"], "venue": "International Conference on Information Fusion, pages 1\u20138", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 1, "context": "[2], [3], [5], [19].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[2], [3], [5], [19].", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "[2], [3], [5], [19].", "startOffset": 10, "endOffset": 13}, {"referenceID": 18, "context": "[2], [3], [5], [19].", "startOffset": 15, "endOffset": 19}, {"referenceID": 16, "context": "Secondly, refer to the general idea of re-scale Boosting (RBoosting) [17],", "startOffset": 69, "endOffset": 73}, {"referenceID": 28, "context": "[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features.", "startOffset": 18, "endOffset": 25}, {"referenceID": 9, "context": "[29] and AdaBoost [9, 10], we apply a variant of Boosting algorithm, called the re-scale AdaBoost (RAdaBoost) as our detection method based on extracted features.", "startOffset": 18, "endOffset": 25}, {"referenceID": 16, "context": "RBoosting is theoretically and experimentally proved to be better than the classical Boosting algorithm [17].", "startOffset": 104, "endOffset": 108}, {"referenceID": 8, "context": "And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13].", "startOffset": 13, "endOffset": 20}, {"referenceID": 9, "context": "And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13].", "startOffset": 13, "endOffset": 20}, {"referenceID": 12, "context": "And AdaBoost [9, 10] is one of the most popular ensemble techniques paradigm and has been shown to be very effective in practice in some hard scenarios [13].", "startOffset": 152, "endOffset": 156}, {"referenceID": 2, "context": "[3] proposed and studied several attributions derived from user profiles for their utility in attack detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "[25], [26] tried to extract features from user profiles and utilized them to detect shilling attacks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[25], [26] tried to extract features from user profiles and utilized them to detect shilling attacks.", "startOffset": 6, "endOffset": 10}, {"referenceID": 14, "context": "[15] introduced the rough set theory into shilling attacks detection by means of taking features of user profiles as the condition attributes of the decision table.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] proposed a hybrid detection method to detect shilling attacks, which combined the naive Bayesian classifiers and augmented expectation maximization based on several selected metrics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Regretfully, their technique also suffered from low F-measure [6] when the filler size is small.", "startOffset": 62, "endOffset": 65}, {"referenceID": 29, "context": "[30] introduced the idea of ensemble learning for improving predictive capability in the attack detection problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] also proposed an online method, HHT-SVM, to detect profile injection attacks by combining Hilbert-Huang transform (HHT) and support vector machine (SVM).", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25].", "startOffset": 96, "endOffset": 99}, {"referenceID": 11, "context": "In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25].", "startOffset": 101, "endOffset": 105}, {"referenceID": 24, "context": "In the literature, \u201cshilling\u201d attacks are classified into two ways: nuke attack and push attack [3], [12], [25].", "startOffset": 107, "endOffset": 111}, {"referenceID": 32, "context": "IS: The set of selected items with specified rating by the function \u03c3(i S k ) [33]; IF : A set of filler items, received randomly items with random assigned ratings \u03c1(il ); IN : A set of items with no ratings; In the present work, we utilize 14 attack models to generate attack profiles.", "startOffset": 78, "endOffset": 82}, {"referenceID": 32, "context": "The details of these attack models are described as follows: 1) Random attack: IS = \u03c6 and \u03c1(i) \u223c N(r, \u03c3) [33].", "startOffset": 105, "endOffset": 109}, {"referenceID": 32, "context": "2) Average attack: IS = \u03c6 and \u03c1(i) \u223c N(ri, \u03c3i) [33].", "startOffset": 47, "endOffset": 51}, {"referenceID": 26, "context": "And then, we use these items as IS, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) \u223c N(ri, \u03c3i ) [27].", "startOffset": 87, "endOffset": 91}, {"referenceID": 26, "context": "4) Bandwagon (random) attack: IS contains a set of popular items, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) \u223c N(r, \u03c3) [27].", "startOffset": 114, "endOffset": 118}, {"referenceID": 11, "context": "And then, we use these items as IS, \u03c3(i) = rmax/rmin (push/nuke) and \u03c1(i) = rmin/rmax (push/nuke) [12].", "startOffset": 98, "endOffset": 102}, {"referenceID": 11, "context": "6) Reverse Bandwagon attack: IS contains a set of unpopular items, \u03c3(i) = rmin/rmax (push/nuke) and \u03c1(i) \u223c N(r, \u03c3) [12].", "startOffset": 115, "endOffset": 119}, {"referenceID": 11, "context": "7) Love/Hate attack: IS = \u03c6 and \u03c1(i) = rmin/rmax (push/nuke) [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 21, "context": "8) AOP attack: A simple and effective strategy to obfuscate the Average attack is to choose filler items with equal probability from the top x% of most popular items rather than from the entire collection of items [22].", "startOffset": 214, "endOffset": 218}, {"referenceID": 21, "context": "This method requires at least 5 users who have rated the same item i and item j [22].", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "Count the number of similarity scores for each item j, and select the top-N item j\u2019s [22].", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "We select the top-N items based on the total number of user ratings they have in their profile [22].", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "This method requires at least 5 co-rated items between user u and user v and does not use significance weighting [21].", "startOffset": 113, "endOffset": 117}, {"referenceID": 20, "context": "Count the number of similarity scores for each user v and select the top 50 user v\u2019s [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "We selected the top 50 users based on the total number of ratings they have in their user profile [21].", "startOffset": 98, "endOffset": 102}, {"referenceID": 2, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 24, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 25, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 19, "context": "Feature extraction from user profiles Previous works [3, 25, 26, 20] summarized different metrics to characterize the features extracted from user profiles.", "startOffset": 53, "endOffset": 68}, {"referenceID": 30, "context": "Besides, we also employ 5 features based on the filler size [31] and propose additional 3 new features which measure the distribution of specific rating such as mean rating, maximum rating and minimum rating in filler items for each user.", "startOffset": 60, "endOffset": 64}, {"referenceID": 2, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 24, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 25, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 33, "context": "are often used to measure the deviation of rating for user profiles [3, 25, 26, 34].", "startOffset": 68, "endOffset": 83}, {"referenceID": 2, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 24, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 25, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 33, "context": "Based on an assumed model, ratings can be automatically divided into filler items and selected items [3, 25, 26, 34].", "startOffset": 101, "endOffset": 116}, {"referenceID": 25, "context": "PT denotes the item set of potential targets [26].", "startOffset": 45, "endOffset": 49}, {"referenceID": 30, "context": "[31].", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "Filler Size with Total Items (FSTI): The ratio between the number of items rated by user u and the number of entire items in the recommender system [31].", "startOffset": 148, "endOffset": 152}, {"referenceID": 30, "context": "Filler Size with Popular Items (FSPI): The ratio between the number of popular items rated by user u and the number of entire popular items in the recommender system [31].", "startOffset": 166, "endOffset": 170}, {"referenceID": 30, "context": "Filler Size with Popular Items in Itself (FSPII): The ratio between the number of popular items rated by user u and the number of entire items rated by user u [31].", "startOffset": 159, "endOffset": 163}, {"referenceID": 30, "context": "Filler Size with Unpopular Items (FSUI): The ratio between the number of unpopular items rated by user u and the number of entire unpopular items in the recommender system [31].", "startOffset": 172, "endOffset": 176}, {"referenceID": 30, "context": "Filler Size with Unpopular Items in Itself (FSUII): The ratio between the number of unpopular items rated by user u and the number of entire items rated by user u [31].", "startOffset": 163, "endOffset": 167}, {"referenceID": 12, "context": "Under this circumstance, Boosting comes into our sights as it has been proved to be efficient when faced with some difficult scenarios as imbalanced classification [13].", "startOffset": 164, "endOffset": 168}, {"referenceID": 8, "context": "The following Algorithm 1 interpret the main idea of AdaBoost [9].", "startOffset": 62, "endOffset": 65}, {"referenceID": 10, "context": "From a statistical view, AdaBoost also can be viewed as a form of \u201dGradient Boosting Machine\u201d [11].", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 120, "endOffset": 123}, {"referenceID": 6, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 172, "endOffset": 183}, {"referenceID": 17, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 172, "endOffset": 183}, {"referenceID": 23, "context": "Original gradient Boosting algorithm was proved to be consistent, which can be easily deduced by applying the method in [1] to [18, Theorem1], however, a number of studies [7, 18, 24] also showed that its approximation rate is far slower.", "startOffset": 172, "endOffset": 183}, {"referenceID": 16, "context": "[17] and Xu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] proposed a re-scale Boosting (RBoosting) to improve the performance of original gradient Boosting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting.", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting.", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "[8], Regularized truncated Boosting [32], \u03b5-Boosting [14], they cheered a novel direction to improve the numerical convergence rate and consequently, the generalization capability of Boosting.", "startOffset": 53, "endOffset": 57}, {"referenceID": 15, "context": "In segment attack, we use movies {50, 183, 185, 200, 234, 443} as the segmented movies [16].", "startOffset": 87, "endOffset": 91}, {"referenceID": 4, "context": "To measure the effectiveness of the proposed detection methods, we use three metrics such as classification error, detection rate and false alarm rate in the test sets, which are used in similar experiments [5].", "startOffset": 207, "endOffset": 210}, {"referenceID": 3, "context": "The details of setting of each method is described as follows: \u2022 SVM: LibSVM and the default parameters are employed as [4] for training binary profile classifier with Prediction = +1 if classified as authentic and Prediction = \u22121 if classified as attack.", "startOffset": 120, "endOffset": 123}, {"referenceID": 22, "context": "\u2022 kNN: Standard kNN algorithm is used as [23].", "startOffset": 41, "endOffset": 45}, {"referenceID": 28, "context": "\u2022 RAdaBoost: For additional shrinkage degree parameter, sk = 2/(k + u), u \u2208 N, in RBoosting, we create 20 equally spaced values of u in logarithmic space between 1 to 10 and select the appropriate u\u2217 as [29].", "startOffset": 203, "endOffset": 207}, {"referenceID": 2, "context": "Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic.", "startOffset": 41, "endOffset": 52}, {"referenceID": 25, "context": "Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic.", "startOffset": 41, "endOffset": 52}, {"referenceID": 29, "context": "Comparing with previous research results [3, 26, 30], the detection performance of RAdaBoost is more optimistic.", "startOffset": 41, "endOffset": 52}], "year": 2015, "abstractText": "Collaborative filtering recommender systems (CFRSs) are the key components of successful e-commerce systems. Actually, CFRSs are highly vulnerable to attacks since its openness. However, since attack size is far smaller than that of genuine users, conventional supervised learning based detection methods could be too \u201cdull\u201d to handle such imbalanced classification. In this paper, we improve detection performance from following two aspects. First, we extract well-designed features from user profiles based on the statistical properties of the diverse attack models, making hard classification task becomes easier to perform. Then, refer to the general idea of re-scale Boosting (RBoosting) and AdaBoost, we apply a variant of AdaBoost, called the rescale AdaBoost (RAdaBoost) as our detection method based on extracted features. RAdaBoost is comparable to the optimal Boosting-type algorithm and can effectively improve the performance in some hard scenarios. Finally, a series of experiments on the MovieLens-100K data set are conducted to demonstrate the outperformance of RAdaBoost comparing with some classical techniques such as SVM, kNN and AdaBoost.", "creator": "LaTeX with hyperref package"}}}