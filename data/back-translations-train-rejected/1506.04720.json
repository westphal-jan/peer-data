{"id": "1506.04720", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2015", "title": "Latent Regression Bayesian Network for Data Representation", "abstract": "Deep directed generative models have attracted much attention recently due to their expressive representation power and the ability of ancestral sampling. One major difficulty of learning directed models with many latent variables is the intractable inference. To address this problem, most existing algorithms make assumptions to render the latent variables independent of each other, either by designing specific priors, or by approximating the true posterior using a factorized distribution. We believe the correlations among latent variables are crucial for faithful data representation. Driven by this idea, we propose an inference method based on the conditional pseudo-likelihood that preserves the dependencies among the latent variables. For learning, we propose to employ the hard Expectation Maximization (EM) algorithm, which avoids the intractability of the traditional EM by max-out instead of sum-out to compute the data likelihood. Qualitative and quantitative evaluations of our model against state of the art deep models on benchmark datasets demonstrate the effectiveness of the proposed algorithm in data representation and reconstruction.", "histories": [["v1", "Mon, 15 Jun 2015 19:34:59 GMT  (197kb,D)", "http://arxiv.org/abs/1506.04720v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["siqi nie", "qiang ji"], "accepted": false, "id": "1506.04720"}, "pdf": {"name": "1506.04720.pdf", "metadata": {"source": "CRF", "title": "Latent Regression Bayesian Network for Data Representation", "authors": ["Siqi Nie", "Qiang Ji"], "emails": ["nies@rpi.edu.", "jiq@rpi.edu."], "sections": [{"heading": "1 Introduction", "text": "Dei r\u00c3 \u00bc f for the leaders for the leaders for the leaders for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership for the leadership"}, {"heading": "2 Related Work", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "3 Latent Regression Bayesian Network", "text": "The latent variables in the LRBN are binary, and the visible variables can be continuous or discrete. Each latent variable is associated with all visible variables. We will discuss the parameterization of both cases below. The case of the continuous latent variables can be called factor analyzers [6, 21] or deep latent Gaussian models [12, 16]."}, {"heading": "3.1 Discrete LRBN", "text": "For discrete LRBN, both latent and observation variables are discrete. For brevity, we will discuss the binary case with observation variables x-Bnd and latent variables h-Bnh. We assume that the latent variables h determine the patterns in the data x, so directional links are used to model their relationships, as in a Bayesian network.Prior probability for latent variables is presented as a log-liner model, P (hj = 1) = \u03c3 (dj), (1) where dj is the parameter that defines the previous distribution for the node hj; \u03c3 (\u00b7) is the sigmoid function \u03c3 (z) = 1 + e \u2212 z).The conditional probability given the latent variables is P (xi = 1 | h) = \u03c3 j wijhj + bi exjyers (bi), (2) where wij is the weight of the link connecting node hj and xi; for the offset is noxi."}, {"heading": "3.2 Hybrid LRBN", "text": "The previous distribution of the latent variables is the same as Equation 1. Given the latent variables, it is assumed that the visible variable follows the Gaussian distribution, but its mean is a linear combination of the latent variables, P (xi | h). To simplify the learning process, each component of the data is normalized, where (5) the weight of the connecting node is hj and xi; bi is the offset of the mean for the node xi; \u03c3i is the standard deviation. To simplify the learning process, each component of the data is normalized, with the weight of the connecting node hj and xi being the weight of the connecting node."}, {"heading": "4 LRBN Inference", "text": "In this section, we present an efficient method of inferring LRBN on the basis of conditional pseudo-probability. Since we have an LRBN model with known parameters, the aim of the inference is to calculate the posterior probability of the latent variables that maximizes the posterior probabilities, i.e., the calculation of P (h | x).In this thesis, we are interested in the maximum of posterior inference (MAP), which is to find the configuration of latent variables that maximizes the posterior probability of the observations, h = argmax h P (h | x).9) The MAP inference is motivated by the observation that the variables in a latent layer assume values after the top layer, which we give their observation probability. Therefore, this configuration dominates all others in explaining each data sample. Furthermore, the goal of feature learning is a function that best explains."}, {"heading": "5 LRBN Learning", "text": "In this section, we present an efficient LRBN learning method based on the Hard Expectation Maximization (EM) algorithm, where the conventional EM algorithm is not an option due to the insolubility of calculating the posterior probability in the E step. [22] The hard version of the EM algorithm has been studied to learn a deep Gaussian mixing model, which has a deep structure in terms of linear transformations, but has only two levels of variables."}, {"heading": "5.1 Learning One Latent Layer", "text": "The aim of parameter learning is to estimate the parameters \u03b8 = {w, b, d} in the face of a series of data samples D = {x (m)} Mm = 1. The conventional maximum probability (ML) of parameter estimation is to maximize the following objective function (\u03b8 = argmax.). (17) The second summation in Eq. 17 is unacceptable due to the exponentially many configurations of h. (18) Note that the maximum approximation of data probability is not equivalent to the approximation of P (h | x). A delta function must be avoided because it is objective. (18) Note that the maximum approximation of data probability is not equivalent to a delta function."}, {"heading": "5.2 Learning Deep Layers", "text": "The learning method of a two-layer LRBN not only provides the parameter \u03b8, but also performs the MAP conclusion to obtain another layer of characteristics h2. If we designate the characteristics as h1 and treat them as input into another LRBN, the same learning procedure can be repeated to learn another layer of characteristics h2. Thereby, we stack another LRBN over the first one to create a deep model.Generally, we let hl designate the variables in the last latent layer (0 \u2264 l, h0 = x) and the parameters involved between layer l and l + 1 are estimated as, expecl \u0445 = argmax successl \u00b2 m logmax hl + 1 PTB (h l, (m), hl + 1 \u2264 l \u2264 L. (25) To optimize the objective function, we use the method of stochastic gradient ascent and replace the input X max loghl + 1 hl L. (TB), \u2264 l + 1, \u2264 l (TB), \u2264 1"}, {"heading": "5.3 Fine Tuning", "text": "To improve the performance of the model globally, we use a top-down fine-tuning process after the layer-by-layer preparation phase. Depending on whether the labels are available or not, fine-tuning can be performed either supervised or unsupervised, as described below."}, {"heading": "5.3.1 Unsupervised Fine Tuning", "text": "By extending equation 18, the objective function for learning with several latent layers by an update variable (j + j = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 2 hl = 2 hl = 1 hl = 1 hl = 1 hl = 2 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 1 hl = 2 hl = 1 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 1 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl = 2 hl"}, {"heading": "5.3.2 Supervised Fine Tuning", "text": "Define a set of target variables t = (t1,..., tC), where C is the total number of classs. tc = 1, if a sample belongs to class c, and tk = 0, \u0435k 6 = c. The supervised fine tuning consists of three steps. Firstly, a layer-by-layer pre-training with L \u2212 1 latent layers (except the top layer) is performed using the method described in Section 5.2, which involves the determination of \u03b8l and hl, 1 \u2264 l \u2264 L L \u2212 1.Second. The parameter \u03b8L for the top two layers is estimated as, \u03b8L \u2212 1 \u0445 = argmax upwards compatible m logP (hL \u2212 1, (m), t (m))). (33) This step works with complete data, which does not require any conclusions, since t is always adhered to."}, {"heading": "6 Experiments", "text": "In this section, we evaluate the performance of LRBN and compare it with other methods using three binary datasets: MNIST, Caltech 101 silhouettes, and OCR letters. Binary datasets are selected to compare with other models, and extending to real datasets is easy."}, {"heading": "6.1 Experimental protocol", "text": "We trained the LRBN model with stochastic gradient ascendant algorithm with learning rate 0.25 hl. The size of the minibatches is set to 20. Two different structures are investigated: a hidden layer with 200 variables and two hidden layers with each layer containing 200 variables, in accordance with the configurations in [5, 13]. For each data set, we randomly selected 100 samples from the training to form a validation set. The common probability on the validation set is a criterion for early stop. In this section, we first evaluate the MAP configuration of the latent variables by reconstruction. Reconstruction is performed as follows: a data vector x, perform a MAP inference to obtain h-maxh P (h-x)."}, {"heading": "6.2 MNIST dataset", "text": "The first experiment is carried out on the binary version of the MNIST dataset (threshold at 0.5), which consists of 70,000 handwritten digits measuring 28 x 28. It is divided into a training set of 60,000 images and a test set of 10,000 images. However, the average reconstruction error of different learning models is shown in Table 1. MAP inference of neural variation conclusions and learning processes (NVIL) [13] occurs via the inference network. The average reconstruction error of the proposed model is 4.56 pixels, which is significantly higher than the other competing methods. This is consistent with our objective function and shows the most likely explanation in the input data effectively captured in the proposed model."}, {"heading": "6.3 Caltech 101 Silhouettes dataset", "text": "The second experiment is carried out using the Caltech 101 Silhouettes dataset, which contains 6364 training images and 2307 test images. The reconstruction error is reported in Table 3.The proposed learning method far exceeds all competing methods, indicating the effectiveness of the max-out approximation.The probability of the test data is recorded in Table 4.With the same dimensionality, the model learned through the proposed algorithm exceeds that learned through the Bayes [5] variation, which is considered to be one of the most advanced methods for forming sigmoid faith networks. With a hidden layer of size 200, the improvement is 34 adders; with a second hidden layer of size 200, the improvement is 28 adders. In addition, our model also performs better than an RBM with many more parameters, indicating the importance of the underlying dependence of the latent variables.Examples are shown in Figure 4."}, {"heading": "6.4 OCR letters dataset", "text": "The last experiment is carried out with the OCR letter dataset, which contains 42,152 training images and 10,000 test images of English letters. The images have a dimensionality of 16 x 8. The reconstruction error is shown in Table 5. The proposed method shows superior performance compared to all competing methods. The average reconstruction error on the test set is 5.95 pixels, which is at least 17 pixels better than the other methods. The log probability of the test data is shown in Table 6. Our model receives a variable lower limit of -35.02, which exceeds the variable Bayes learning method, and is slightly worse than DBM [18], which has 100 times more parameters. Samples from the LRBN are shown in Fig. 5."}, {"heading": "7 Conclusion", "text": "In this paper, we present a targeted depth model based on the latent regression Bayean network to explicitly capture the dependencies between the latent variables for data representation; we introduce an efficient inference method based on pseudo-probability and coordinated ascent; a hard EM learning method is proposed for efficient parameter learning; the proposed inference method solves the inference intractability while maintaining the dependencies between latent variables; we compare theoretically and empirically different models and learning methods; we point out that the latent variables in the Bayesian regression network have strong dependencies that can better explain the patterns in the input layer; and experiments with benchmark datasets show that the proposed model significantly exceeds existing models in data reconstruction and achieves comparable performance in data representation."}], "references": [{"title": "Bounding the test log-likelihood of generative models", "author": ["Yoshua Bengio", "Li Yao", "Kyunghyun Cho"], "venue": "In International Conference on Learning Representations (Conference Track),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "On the statistical analysis of dirty pictures", "author": ["Julian Besag"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1986}, {"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "Journal of machine Learning research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Enhanced gradient for training restricted boltzmann machines", "author": ["K Cho", "Tapani Raiko", "Alexander Ilin"], "venue": "Neural computation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Learning deep sigmoid belief networks with data augmentation", "author": ["Zhe Gan", "Ricardo Henao", "David Carlson", "Lawrence Carin"], "venue": "International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "The em algorithm for mixtures of factor analyzers", "author": ["Zoubin Ghahramani", "Geoffrey E Hinton"], "venue": "Technical report, Technical Report CRG-TR-96-1,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "Deep autoregressive networks", "author": ["Karol Gregor", "Andriy Mnih", "Daan Wierstra"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "The\u201d wake-sleep\u201d algorithm for unsupervised neural networks", "author": ["Geoffrey E Hinton", "Peter Dayan", "Brendan J Frey", "Radford M Neal"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1995}, {"title": "Probabilistic latent semantic indexing", "author": ["Thomas Hofmann"], "venue": "Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "Probabilistic latent semantic analysis", "author": ["Thomas Hofmann"], "venue": "In Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Neural variational inference and learning in belief networks", "author": ["Andriy Mnih", "Karol Gregor"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Connectionist learning of belief networks", "author": ["Radford M Neal"], "venue": "Artificial intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1992}, {"title": "A probabilistic theory of deep learning", "author": ["Ankit B Patel", "Tan Nguyen", "Richard G Baraniuk"], "venue": "arXiv preprint arXiv:1504.00641,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo J Rezende", "Shakir Mohamed", "Daan Wierstra"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Deep boltzmann machines", "author": ["Ruslan Salakhutdinov", "Geoffrey E Hinton"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Efficient learning of deep boltzmann machines", "author": ["Ruslan Salakhutdinov", "Hugo Larochelle"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "On the quantitative analysis of deep belief networks", "author": ["Ruslan Salakhutdinov", "Iain Murray"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Mean field theory for sigmoid belief networks", "author": ["Lawrence K Saul", "Tommi Jaakkola", "Michael I Jordan"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1996}, {"title": "Deep mixtures of factor analysers", "author": ["Yichuan Tang", "Geoffrey E Hinton", "Ruslan Salakhutdinov"], "venue": "In Proceedings of the 29th International Conference on Machine Learning", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Factoring variations in natural images with deep gaussian mixture models", "author": ["Aaron van den Oord", "Benjamin Schrauwen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}], "referenceMentions": [{"referenceID": 14, "context": "Different levels of latent variables capture features (or abstractions [15]) in a coarse-to-fine manner.", "startOffset": 71, "endOffset": 75}, {"referenceID": 16, "context": "Compared with undirected models such as restricted Boltzmann machines (RBMs) and deep Boltzmann machines (DBMs) [17], directed generative models have their own advantages.", "startOffset": 112, "endOffset": 116}, {"referenceID": 7, "context": "[8] introduced a complementary prior for the latent variables which makes the posterior fully factorized.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "Some recent efforts for learning generative models have focused on variational methods [12, 13, 16], by introducing another distribution to approximate the true posterior and maximize a variational lower bound of the data likelihood.", "startOffset": 87, "endOffset": 99}, {"referenceID": 12, "context": "Some recent efforts for learning generative models have focused on variational methods [12, 13, 16], by introducing another distribution to approximate the true posterior and maximize a variational lower bound of the data likelihood.", "startOffset": 87, "endOffset": 99}, {"referenceID": 15, "context": "Some recent efforts for learning generative models have focused on variational methods [12, 13, 16], by introducing another distribution to approximate the true posterior and maximize a variational lower bound of the data likelihood.", "startOffset": 87, "endOffset": 99}, {"referenceID": 1, "context": "It can also be seen as the application of iterated conditional modes (ICM) [2] to directed graphical models.", "startOffset": 75, "endOffset": 78}, {"referenceID": 5, "context": "EM algorithm and its variants have been used for learning latent mixture of factor analyzers [6], probabilistic latent semantic indexing [10], probabilistic latent semantic analysis [11] and latent Dirichlet allocation (LDA) [3].", "startOffset": 93, "endOffset": 96}, {"referenceID": 9, "context": "EM algorithm and its variants have been used for learning latent mixture of factor analyzers [6], probabilistic latent semantic indexing [10], probabilistic latent semantic analysis [11] and latent Dirichlet allocation (LDA) [3].", "startOffset": 137, "endOffset": 141}, {"referenceID": 10, "context": "EM algorithm and its variants have been used for learning latent mixture of factor analyzers [6], probabilistic latent semantic indexing [10], probabilistic latent semantic analysis [11] and latent Dirichlet allocation (LDA) [3].", "startOffset": 182, "endOffset": 186}, {"referenceID": 2, "context": "EM algorithm and its variants have been used for learning latent mixture of factor analyzers [6], probabilistic latent semantic indexing [10], probabilistic latent semantic analysis [11] and latent Dirichlet allocation (LDA) [3].", "startOffset": 225, "endOffset": 228}, {"referenceID": 14, "context": "[15] make one latent variable connecting to a small patch of the input data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20], known as the mean field theory for learning sigmoid belief networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] extended the mean field method, and proposed a Bayesian approach to learn deep sigmoid belief networks by introducing sparsity-encoraging priors on the model parameters.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "The wake-sleep algorithm [9] augments the multi-layer belief networks with feed-forward recognition networks.", "startOffset": 25, "endOffset": 28}, {"referenceID": 12, "context": "Mnih and Gregor [13] introduced the neural variational inference and learning (NVIL) algorithm for sigmoid belief networks.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "Kingma and Welling [12] proposed the auto-encoding variational Bayes method for continuous latent variables, in which a reparameterization is employed to efficiently generate samples from the Gaussian distribution.", "startOffset": 19, "endOffset": 23}, {"referenceID": 15, "context": "[16] propose a stochastic backpropagation algorithm for learning deep generative models with continuous latent variables.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] augment the directed model with an encoder, which is also kind of inference network.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] proposed a complementary prior to ensure a factorized posterior, and proposed a fast learning algorithm for deep belief networks (DBNs), which is basically a hybrid network with a single undirected layer and several directed layers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "The case of continuous latent variables can be referred to as factor analyzers [6, 21] or deep latent Gaussian models [12, 16].", "startOffset": 79, "endOffset": 86}, {"referenceID": 20, "context": "The case of continuous latent variables can be referred to as factor analyzers [6, 21] or deep latent Gaussian models [12, 16].", "startOffset": 79, "endOffset": 86}, {"referenceID": 11, "context": "The case of continuous latent variables can be referred to as factor analyzers [6, 21] or deep latent Gaussian models [12, 16].", "startOffset": 118, "endOffset": 126}, {"referenceID": 15, "context": "The case of continuous latent variables can be referred to as factor analyzers [6, 21] or deep latent Gaussian models [12, 16].", "startOffset": 118, "endOffset": 126}, {"referenceID": 13, "context": "(3) In this case, the model becomes a sigmoid belief network (SBN) [14] with one latent layer.", "startOffset": 67, "endOffset": 71}, {"referenceID": 21, "context": "The hard version of EM algorithm has been explored in [22] for learning a deep Gaussian mixture model.", "startOffset": 54, "endOffset": 58}, {"referenceID": 4, "context": "Two different structures are studied: one hidden layer with 200 variables, and two hidden layers with each layer containing 200 variables, consistent with the configurations in [5, 13].", "startOffset": 177, "endOffset": 184}, {"referenceID": 12, "context": "Two different structures are studied: one hidden layer with 200 variables, and two hidden layers with each layer containing 200 variables, consistent with the configurations in [5, 13].", "startOffset": 177, "endOffset": 184}, {"referenceID": 0, "context": "In this work, we estimate the log-probability using the conservative sampling-based log-likelihood (CSL) method [1],", "startOffset": 112, "endOffset": 115}, {"referenceID": 0, "context": "The expectation of the estimator is a lower bound on the true log-likelihood [1].", "startOffset": 77, "endOffset": 80}, {"referenceID": 3, "context": "For reconstruction we implement the NVIL, RBM, DBN and DBM models following [4, 8, 13, 17] (denoted by (*) in the following tables).", "startOffset": 76, "endOffset": 90}, {"referenceID": 7, "context": "For reconstruction we implement the NVIL, RBM, DBN and DBM models following [4, 8, 13, 17] (denoted by (*) in the following tables).", "startOffset": 76, "endOffset": 90}, {"referenceID": 12, "context": "For reconstruction we implement the NVIL, RBM, DBN and DBM models following [4, 8, 13, 17] (denoted by (*) in the following tables).", "startOffset": 76, "endOffset": 90}, {"referenceID": 16, "context": "For reconstruction we implement the NVIL, RBM, DBN and DBM models following [4, 8, 13, 17] (denoted by (*) in the following tables).", "startOffset": 76, "endOffset": 90}, {"referenceID": 12, "context": "The MAP inference of neural variational inference and learning (NVIL) [13] is through the inference network.", "startOffset": 70, "endOffset": 74}, {"referenceID": 18, "context": "For deep belief network (DBN) [19] and deep Boltzmann machine (DBM) [17], the posterior P (h|x) is already factorized, so that the inference is performed individually for each latent variable.", "startOffset": 30, "endOffset": 34}, {"referenceID": 16, "context": "For deep belief network (DBN) [19] and deep Boltzmann machine (DBM) [17], the posterior P (h|x) is already factorized, so that the inference is performed individually for each latent variable.", "startOffset": 68, "endOffset": 72}, {"referenceID": 12, "context": "Method DIM Recon Error NVIL* [13] 200 - 200 35.", "startOffset": 29, "endOffset": 33}, {"referenceID": 18, "context": "52 DBN* [19] 200 - 200 29.", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "78 DBM* [17] 200 - 200 23.", "startOffset": 8, "endOffset": 12}, {"referenceID": 4, "context": "With the same dimensionality, LRBN outperforms variational Bayes [5], and is similar to that learned using NVIL [13].", "startOffset": 65, "endOffset": 68}, {"referenceID": 12, "context": "With the same dimensionality, LRBN outperforms variational Bayes [5], and is similar to that learned using NVIL [13].", "startOffset": 112, "endOffset": 116}, {"referenceID": 4, "context": "Method DIM 10k VB [5] 200 -116.", "startOffset": 18, "endOffset": 21}, {"referenceID": 4, "context": "91 VB [5] 200 - 200 -110.", "startOffset": 6, "endOffset": 9}, {"referenceID": 12, "context": "74 NVIL [13] 200 -113.", "startOffset": 8, "endOffset": 12}, {"referenceID": 12, "context": "1 NVIL [13] 200 - 200 -99.", "startOffset": 7, "endOffset": 11}, {"referenceID": 18, "context": "8 DBN [19] 500 - 2000 -86.", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "22 DBM [17] 500 - 1000 -84.", "startOffset": 7, "endOffset": 11}, {"referenceID": 4, "context": "With the same dimensionality, the model learned by the proposed algorithm outperforms the one learned by variational Bayes [5], which is considered as one of the state of the art methods of training sigmoid belief networks.", "startOffset": 123, "endOffset": 126}, {"referenceID": 12, "context": "Method DIM Recon Error NVIL* [13] 200 - 200 29.", "startOffset": 29, "endOffset": 33}, {"referenceID": 3, "context": "78 RBM* [4] 200 32.", "startOffset": 8, "endOffset": 11}, {"referenceID": 18, "context": "47 DBN* [19] 200 - 200 28.", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "17 DBM* [17] 200 - 200 24.", "startOffset": 8, "endOffset": 12}, {"referenceID": 4, "context": "Method DIM Log-prob VB [5] 200 -136.", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": "84 VB [5] 200 - 200 -125.", "startOffset": 6, "endOffset": 9}, {"referenceID": 3, "context": "60 RBM [4] 4000 -107.", "startOffset": 7, "endOffset": 10}, {"referenceID": 18, "context": "78 DBN* [19] 200 - 200 -120.", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "46 DBM* [17] 200 - 200 -118.", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "02, which outperforms the variational Bayes learning method, and is slightly worse than DBM [18], which has 100 times more parameters.", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "Method DIM Recon Error NVIL* [13] 200 - 200 14.", "startOffset": 29, "endOffset": 33}, {"referenceID": 3, "context": "79 RBM* [4] 200 16.", "startOffset": 8, "endOffset": 11}, {"referenceID": 18, "context": "83 DBN* [19] 200 - 200 12.", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "47 DBM* [17] 200 - 200 11.", "startOffset": 8, "endOffset": 12}, {"referenceID": 4, "context": "Method DIM Log-prob VB [5] 200 -48.", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": "20 VB [5] 200 - 200 -47.", "startOffset": 6, "endOffset": 9}, {"referenceID": 18, "context": "84 DBN* [19] 200 - 200 40.", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "75 DBM [18] 2000 - 2000 -34.", "startOffset": 7, "endOffset": 11}], "year": 2015, "abstractText": "Deep directed generative models have attracted much attention recently due to their expressive representation power and the ability of ancestral sampling. One major difficulty of learning directed models with many latent variables is the intractable inference. To address this problem, most existing algorithms make assumptions to render the latent variables independent of each other, either by designing specific priors, or by approximating the true posterior using a factorized distribution. We believe the correlations among latent variables are crucial for faithful data representation. Driven by this idea, we propose an inference method based on the conditional pseudo-likelihood that preserves the dependencies among the latent variables. For learning, we propose to employ the hard Expectation Maximization (EM) algorithm, which avoids the intractability of the traditional EM by max-out instead of sum-out to compute the data likelihood. Qualitative and quantitative evaluations of our model against state of the art deep models on benchmark datasets demonstrate the effectiveness of the proposed algorithm in data representation and reconstruction.", "creator": "LaTeX with hyperref package"}}}