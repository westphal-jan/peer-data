{"id": "1506.04776", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2015", "title": "Encog: Library of Interchangeable Machine Learning Models for Java and C#", "abstract": "This paper introduces the Encog library for Java and C#, a scalable, adaptable, multiplatform machine learning framework that was 1st released in 2008. Encog allows a variety of machine learning models to be applied to datasets using regression, classification, and clustering. Various supported machine learning models can be used interchangeably with minimal recoding. Encog uses efficient multithreaded code to reduce training time by exploiting modern multicore processors. The current version of Encog can be downloaded from", "histories": [["v1", "Mon, 15 Jun 2015 21:20:06 GMT  (11kb)", "http://arxiv.org/abs/1506.04776v1", null]], "reviews": [], "SUBJECTS": "cs.MS cs.LG", "authors": ["jeff heaton"], "accepted": false, "id": "1506.04776"}, "pdf": {"name": "1506.04776.pdf", "metadata": {"source": "CRF", "title": "Encog: Library of Interchangeable Machine Learning Models for Java and C#", "authors": ["Jeff Heaton"], "emails": ["jeffheaton@acm.org"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.04 776v 1 [cs.M S] 1 5Keywords: java, c #, neural network, support vector machine, open source software"}, {"heading": "1. Intention and Goals", "text": "This paper describes the Encog API for Java and C #, which is provided as a JAR or DLL library. C # version of Encog is also compatible with the Xamarin Mono package. Encog has an active community that has provided many extensions beyond the scope of this paper, including extensions such as Javascript, GPU processing, C / C + + support, scale support, and interfaces to various automated trading platforms. The scope of this paper is on Java and C # API. Encog allows the Java or C # programmer to experiment with a wide range of machine-language models using a simple, unified interface for clustering, regression, and classification, enabling the programmer to construct applications that determine which model is best suited to the data. Encog provides basic tools for automated model selection."}, {"heading": "2. Framework Overview", "text": "These models are listed here: \u2022 Adaline, Feedforward, Hopfield, PNN / GRNN, RBF & NEAT neural networks \u2022 generalized linear regression (GLM) \u2022 genetic programming (tree-based) \u2022 k-means clustering \u2022 k-next neighbors \u2022 linear regression \u2022 self-organizing map (SOM) \u2022 simple recurrent network (Elman and Jordan) \u2022 support vector machine (SVM) Encog provides optimization algorithms like particle swarm optimization (PSO, 2008), genetic algorithms (GA), Nelder-Mead and simulated annealing. These algorithms can optimize a vector to minimize loss function."}, {"heading": "3. API Overview", "text": "This year, it is more than ever before in the history of the city, where it has gone down in history as never before."}, {"heading": "4. Future Plans and Conclusions", "text": "A number of enhancements are planned for Encog. Grade-enhancing machines (GBM) and deep learning are two future model additions. Several planned enhancements will provide interoperability with other machine learning packages. Future versions of Encog will be able to read and write the Weka Attribute Relation File Format (ARFF) and libsvm data files. Encog will have the ability to load and store models in the Predictive Model Markup Language (PMML) format."}, {"heading": "Acknowledgments", "text": "The Encog community has been very helpful with bug reports, bug fixes and feature suggestions. Encog contributors include Olivier Guiglionda, Seema Singh, Ce'sar Roberto de Souza and others. A full list of Encog contributors can be found in the GitHub repository: https: / / github.com / encog. Alan Mosca, Department of Computer Science and Information Systems, Birkbeck, University of London, UK, created the Encog ensemble functionality. Matthew Dean, Marc Fletcher and Edmund Owen, Semiconductor Physics Research Group, University of Cambridge, UK, created the Encog model for neural networks."}], "references": [{"title": "An empirical study of learning speed in back-propagation networks", "author": ["S. Fahlman"], "venue": "Technical report,", "citeRegEx": "Fahlman.,? \\Q1988\\E", "shortCiteRegEx": "Fahlman.", "year": 1988}, {"title": "The use of multiple measurements in taxonomic problems", "author": ["R. Fisher"], "venue": "Annals of Eugenics,", "citeRegEx": "Fisher.,? \\Q1936\\E", "shortCiteRegEx": "Fisher.", "year": 1936}, {"title": "Genetic programming - on the programming of computers by means of natural selection. Complex adaptive systems", "author": ["J. Koza"], "venue": null, "citeRegEx": "Koza.,? \\Q1993\\E", "shortCiteRegEx": "Koza.", "year": 1993}, {"title": "Data mining considerations for knowledge acquisition in real time strategy games", "author": ["G. Luhasz", "V. Munteanu", "V. Negru"], "venue": "In IEEE 11th International Symposium on Intelligent Systems and Informatics,", "citeRegEx": "Luhasz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Luhasz et al\\.", "year": 2013}, {"title": "An algorithm for least-squares estimation of nonlinear parameters", "author": ["D. Marquardt"], "venue": "SIAM Journal on Applied Mathematics,", "citeRegEx": "Marquardt.,? \\Q1963\\E", "shortCiteRegEx": "Marquardt.", "year": 1963}, {"title": "Practical Neural Network Recipes in C++", "author": ["T. Masters"], "venue": null, "citeRegEx": "Masters.,? \\Q1993\\E", "shortCiteRegEx": "Masters.", "year": 1993}, {"title": "Faitas. Data classification of spectrum analysis using neural network", "author": ["O.O. Matviykiv"], "venue": "Lviv Polytechnic National University,", "citeRegEx": "Matviykiv,? \\Q2012\\E", "shortCiteRegEx": "Matviykiv", "year": 2012}, {"title": "A scaled conjugate gradient algorithm for fast supervised learning", "author": ["M. M\u00f8ller"], "venue": "NEURAL NETWORKS,", "citeRegEx": "M\u00f8ller.,? \\Q1993\\E", "shortCiteRegEx": "M\u00f8ller.", "year": 1993}, {"title": "Extending encog: A study on classifier ensemble techniques", "author": ["A. Mosca"], "venue": "Master\u2019s thesis, Birkbeck, University of London,", "citeRegEx": "Mosca.,? \\Q2012\\E", "shortCiteRegEx": "Mosca.", "year": 2012}, {"title": "Analysis of the publications on the applications of particle swarm optimisation", "author": ["R. Poli"], "venue": "J. Artif. Evol. App.,", "citeRegEx": "Poli.,? \\Q2008\\E", "shortCiteRegEx": "Poli.", "year": 2008}, {"title": "A software framework for building biomedical machine learning classifiers through grid computing resources", "author": ["Ra\u00fal Ramos-Poll\u00e1n", "Miguel \u00c1ngel Guevara-L\u00f3pez", "Eug\u00e9nio C. Oliveira"], "venue": "J. Medical Systems,", "citeRegEx": "Ramos.Poll\u00e1n et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ramos.Poll\u00e1n et al\\.", "year": 2012}, {"title": "Rprop - a fast adaptive learning algorithm", "author": ["M. Riedmiller", "H. Braun"], "venue": "Technical report, Proc. of ISCIS VII), Universitat,", "citeRegEx": "Riedmiller and Braun.,? \\Q1992\\E", "shortCiteRegEx": "Riedmiller and Braun.", "year": 1992}, {"title": "Neurocomputing: Foundations of research", "author": ["D. Rumelhart", "G. Hinton", "R. Williams"], "venue": null, "citeRegEx": "Rumelhart et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1988}, {"title": "Evolving neural networks through augmenting topologies", "author": ["K. Stanley", "R. Miikkulainen"], "venue": "Evol. Comput.,", "citeRegEx": "Stanley and Miikkulainen.,? \\Q2002\\E", "shortCiteRegEx": "Stanley and Miikkulainen.", "year": 2002}, {"title": "Benchmarking and comparing encog, neuroph and joone neural networks. http://goo.gl/A56iyx", "author": ["T. Taheri"], "venue": null, "citeRegEx": "Taheri.,? \\Q2014\\E", "shortCiteRegEx": "Taheri.", "year": 2014}], "referenceMentions": [{"referenceID": 11, "context": "This often allows Encog to perform more efficiently than many other Java and C# libraries, as demonstrated empirically by Taheri (2014) and Matviykiv and Faitas (2012).", "startOffset": 122, "endOffset": 136}, {"referenceID": 5, "context": "This often allows Encog to perform more efficiently than many other Java and C# libraries, as demonstrated empirically by Taheri (2014) and Matviykiv and Faitas (2012). Luhasz et al.", "startOffset": 140, "endOffset": 168}, {"referenceID": 3, "context": "Luhasz et al. (2013) and Ramos-Poll\u00e1n et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 3, "context": "Luhasz et al. (2013) and Ramos-Poll\u00e1n et al. (2012) also saw favorable results when evaluating Encog to similar libraries.", "startOffset": 0, "endOffset": 52}, {"referenceID": 9, "context": "Encog provides optimization algorithms such as particle swarm optimization (PSO) (Poli, 2008), genetic algorithms (GA), Nelder-Mead and simulated annealing.", "startOffset": 81, "endOffset": 93}, {"referenceID": 12, "context": "Propagation-training algorithms for neural network fitting, such as back propagation (Rumelhart et al., 1988), resilient propagation (Riedmiller and Braun, 1992), LevenbergMarquardt (Marquardt, 1963), quickpropagation (Fahlman, 1988), and scaled conjugate gradient (M\u00f8ller, 1993) are included.", "startOffset": 85, "endOffset": 109}, {"referenceID": 11, "context": ", 1988), resilient propagation (Riedmiller and Braun, 1992), LevenbergMarquardt (Marquardt, 1963), quickpropagation (Fahlman, 1988), and scaled conjugate gradient (M\u00f8ller, 1993) are included.", "startOffset": 31, "endOffset": 59}, {"referenceID": 4, "context": ", 1988), resilient propagation (Riedmiller and Braun, 1992), LevenbergMarquardt (Marquardt, 1963), quickpropagation (Fahlman, 1988), and scaled conjugate gradient (M\u00f8ller, 1993) are included.", "startOffset": 80, "endOffset": 97}, {"referenceID": 0, "context": ", 1988), resilient propagation (Riedmiller and Braun, 1992), LevenbergMarquardt (Marquardt, 1963), quickpropagation (Fahlman, 1988), and scaled conjugate gradient (M\u00f8ller, 1993) are included.", "startOffset": 116, "endOffset": 131}, {"referenceID": 7, "context": ", 1988), resilient propagation (Riedmiller and Braun, 1992), LevenbergMarquardt (Marquardt, 1963), quickpropagation (Fahlman, 1988), and scaled conjugate gradient (M\u00f8ller, 1993) are included.", "startOffset": 163, "endOffset": 177}, {"referenceID": 13, "context": "Neural network architectures can be automatically built by a genetic algorithm using NEAT and HyperNEAT (Stanley and Miikkulainen, 2002).", "startOffset": 104, "endOffset": 136}, {"referenceID": 0, "context": ", 1988), resilient propagation (Riedmiller and Braun, 1992), LevenbergMarquardt (Marquardt, 1963), quickpropagation (Fahlman, 1988), and scaled conjugate gradient (M\u00f8ller, 1993) are included. Neural network pruning and model selection can be used to find optimal network architectures. Neural network architectures can be automatically built by a genetic algorithm using NEAT and HyperNEAT (Stanley and Miikkulainen, 2002). A number of preprocessing tools are built into the Encog library. Collected data can be divided into training, test, and validation sets. Time-series data can be encoded into data windows. Quantitative data can be normalized by range or z-score to prevent biases in some models. Masters (1993) normalizes qualitative data using one-of-n encoding or equilateral encoding.", "startOffset": 117, "endOffset": 718}, {"referenceID": 2, "context": "Encog also contains extensive support for genetic programming using a tree representation (Koza, 1993).", "startOffset": 90, "endOffset": 102}, {"referenceID": 1, "context": "A classification example will demonstrate this interchangeability, using the iris dataset (Fisher, 1936).", "startOffset": 90, "endOffset": 104}, {"referenceID": 8, "context": "A code contribution by Mosca (2012) will soon be integrated, enhancing Encog\u2019s ensemble learning capabilities.", "startOffset": 23, "endOffset": 36}], "year": 2015, "abstractText": "This paper introduces the Encog library for Java and C#, a scalable, adaptable, multiplatform machine learning framework that was first released in 2008. Encog allows a variety of machine learning models to be applied to datasets using regression, classification, and clustering. Various supported machine learning models can be used interchangeably with minimal recoding. Encog uses efficient multithreaded code to reduce training time by exploiting modern multicore processors. The current version of Encog can be downloaded from http://www.encog.org.", "creator": "LaTeX with hyperref package"}}}