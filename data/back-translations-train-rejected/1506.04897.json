{"id": "1506.04897", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2015", "title": "Parsing Natural Language Sentences by Semi-supervised Methods", "abstract": "We present our work on semi-supervised parsing of natural language sentences, focusing on multi-source crosslingual transfer of delexicalized dependency parsers. We first evaluate the influence of treebank annotation styles on parsing performance, focusing on adposition attachment style. Then, we present KLcpos3, an empirical language similarity measure, designed and tuned for source parser weighting in multi-source delexicalized parser transfer. And finally, we introduce a novel resource combination method, based on interpolation of trained parser models.", "histories": [["v1", "Tue, 16 Jun 2015 09:54:27 GMT  (59kb)", "http://arxiv.org/abs/1506.04897v1", "Dissertation interim report. Overlap with papers accepted to ACL 2015 and Depling 2015, and a paper under review at IWPT 2015"]], "COMMENTS": "Dissertation interim report. Overlap with papers accepted to ACL 2015 and Depling 2015, and a paper under review at IWPT 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rudolf rosa"], "accepted": false, "id": "1506.04897"}, "pdf": {"name": "1506.04897.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["rosa@ufal.mff.cuni.cz"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.04 897v 1 [cs.C L] 16 Jun 2015"}, {"heading": "1 Introduction", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "2 Data", "text": "One of the positive side effects of the CoNLL joint tasks was the assembly of universal bonds for many languages, which are usually simply referred to as the CoNLL treebanks, as well as the definition of a file format that represents the individual sentences - the CoNLL format. The datasets were used for evaluation in the common tasks, but were also used as a yardstick for the evaluation of later dependencies. Thus, for example, all treebanks define a POS language (part of the speech), to ensure the strong comparability of reported results, but the CoNLL treebanks generally use different annotation styles at morphological and syntactical level. All treebanks define a POS language (part of the speech), which can be used by any word (or token), but the set of POS tags, which are used by any treebank, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S ou-, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S"}, {"heading": "3 Delexicalized Parser Transfer", "text": "This year the number of mentioned, mentioned and mentionedcsrc\u00fc\u00fcehncsrVrhe\u00fce rf\u00fc ide eerwdnei rf\u00fc ide eerwdnei rf\u00fc ide eerwdnei eerwdnei rf\u00fc ide eerwdnei eerwdnei rf\u00fc ide eerwdnei eerwdne.nlrne\u00fcGe"}, {"heading": "3.1 MSTperl parser", "text": "s MSTperl parser (2014), an implementation of the unlabeled single-best MSTParser by McDonald et al. (2005b), with world-class features and non-projective parsing. We train the parser using 3 iterations of MIRA (Crammer and Singer, 2003). The MSTParser model uses a set of binary F features, to which weights are assigned by training on a tree bank. When parsing a set, the parser constructs a complete, weighted, directional graph over the input set tokens, assigning each edge a score that is the sum of the weights of the features active for that edge: se = f Ff (e) \u00b7 wf. (1) The sentence parse tree is the maximum chip-ning tree (MST) above this graph (MST), found using the algorithm of Chu and Liu (1965) and Edmonds (1967) (Edmonds)."}, {"heading": "3.2 Treebank concatenation", "text": "McDonald et al. (2011) applied delexicalized transmission in an environment with multiple available src treebanks, noting that a treebank for a language that is typically close to the tgt language is typically a good choice for the source treebank, but noting that the problem of selecting the best source bank is not trivial; we will continue to refer to the best source bank as an oracle treebank, as it can hardly be identified without having a tgt treebank for evaluation. As a workaround, the authors suggested a simple resource combination method - treebank concatenation - which consists of the following steps: 1. Consider all src treebanks. 2. Train a delex parser on the resulting treebank. 3. Apply the parser to the tgt text. 6These 12 values read: NOUN, VERB, ADDEJ, UJ, APRT, INC, XPRT, INT, INCLUDICATE, INCLUDICATE."}, {"heading": "3.3 Parse tree combination", "text": "An alternative resource combination approach is the parser combination used by Sagae and Lavie (2006) for monolingual parser combinations, in which several independent parsers are applied to the same input set, and the parser trees they produce are combined into a single resulting tree, using the idea of McDonald et al. (2005a), which defines the problem of finding a parser tree as a problem of finding the maximum voltage tree of a weighted directed graph of potential parser tree edges, defining the weight of each edge as the edge included in its output (hence it can also be considered a parser match). To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967) used by McDonald et al."}, {"heading": "4 Treebank Annotation Style for Parsing", "text": "In this context, it should be noted that the case concerns a case in which a person was killed who was able to kill himself."}, {"heading": "4.1 Full Universal Stanford Dependencies", "text": "As a preliminary experiment, we have compared the Prague version with its fully standardized version. Results are shown in Table 2. It can be seen that the Stanford version performs much worse than the Prague version - its results are about 5% lower than the UAS absolute.Upon closer inspection, it turned out that many of the errors are actually due to the sentence end puncture. In Stanford style, the sentence end puncture is to be added as a dependent node of the sentence root knot (typically the main predicate).However, this is difficult for the Firstorder parser, as he has no knowledge of the root knot when evaluating the potential edges.While this is an important point, in Prague style the sentence end punctuation is attached to the technical root knot, which is characterized by special values of the knot the node characteristics, and therefore the assignment is very easy to value.While this is an important point, the punctuation in the Prague style is either attached to the technical root knot to the structure, or it is very important to keep an eye on the punctuation in the style of the Prague part, the punctuation is very similar to the structure in the style of the AS."}, {"heading": "4.2 Conversion between Prague and Stanford adpositions", "text": "To convert between these annotation styles, we have implemented two simple transformation blocks in the Treex NLP framework (Z-abokrtsky, \"2011): \u2022 The conversion from P to S picks up each adposition and appends it as a dependence on its leftmost, non-adpositional child and all its other non-adpositional children. Thus, unless the adposition has adpositional dependent nodes (typically this means a composite adposition), the adposition becomes a leaf node. \u2022 In the conversion from S to P, each adposition is severed - if the leftmost, non-adpositional child is a coordination conjunction, the leftmost, non-adpositional conjunction is taken instead (recursively)."}, {"heading": "4.3 29-to-1 delexicalized parser transfer", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "4.4 Smaller source treebank subsets", "text": "In order to deepen and further confirm our conclusions, we also conducted a series of experiments with smaller subsets of the tree bank collection, selecting several tree bank groups based on the ratio of adposition tokens to all tokens, and selecting only sufficiently large tree banks (more than 100,000 tokens); the subsets are listed in Table 4; we also used a larger \"All9\" set of all 9 selected tree banks, which were then used for training; the remaining 21 languages were used as target languages for the test.The summary results can be found in Table 5. It is easy to see that the conclusions presented in the previous section apply even to these datasets. In addition, the differences in the United Arab Emirates are often much greater, especially for the smaller and highly diverse sets of data, High, Low and Mix, where the benefit of the Stanford style, which makes the dependence trees more similar, becomes quite significant."}, {"heading": "4.5 Supervised parsers", "text": "For the sake of completeness, we also include the results for monitored monolingual lexicalized and delexicalized parsers, using the P and S annotation styles of the adpositions; the setup referred to as \"P / S\" corresponds to a parser trained on a P-style target database whose output is converted to S. The results are then evaluated on the S conversion of the target database test section (analogous to \"S / P\"); for comparison, we also include the two best parser transfer setups (these results are identical to those in Table 3); the results are presented in Table 6. For the lexicalized parser, the P style is clearly better, averaging + 0.77% UAS. To get S-style word analysis trees, it is generally better to analyze the text using a parser trained on a P style database, and then to convert the output parse trees, which results in multiplicity."}, {"heading": "4.6 Conclusion", "text": "We investigated the usefulness of Stanford adposition transfer as an alternative to the Prague style by using a large set of 30 tree trunks for evaluation. We focused in particular on multilingual, delicalized parser transfer, since one of the goals behind the design of the Universal Stanford Dependencies is to be more consistent across languages than other annotation styles. We succeeded in confirming that the Prague annotation style is more advantageous for supervised parsing than the Stanford style, as has already been noted in the literature. However, the Stanford adposition transfer in the context of the Parser transfer generally proved to be more powerful than the Prague style, thanks to its abstraction from the high interlingual variance in adposition usage. In addition, even better results are obtained when the results of parsers trained on both Prague and Stanford tree trunks are combined in one go, with the Uger + 0.1% between the Prague adposition plan and the Prague adposition plan being even stronger than the 39%."}, {"heading": "5 Employing Language Similarity", "text": "In fact, it is in such a way that most of us are able to go to another world, in which they can go to another world, in which they are able to explore another world, in which they are able to explore another world, in which they are able to explore another world, in which they are able to create a new world, in which they are able to create another world, in which they are able to create a new world, in which they are able to explore another world, in which they are able to create another world, in which they are able to create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world a new world, in which they create a new world, in which they create a new world a new world, in which they create a new world, a new world, a new world in which they create a new world, in which they create a new world, a new world in which they create a new world, in which they create a new world, a new world, a new world in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, a new world, a new world, a new world in which they create a new world, in which they create a new world, a new world, in which they create a new world in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world, in which they create a new world in which they create a new world, in which they create a new world, in which they create a new world"}, {"heading": "5.2 Source selection", "text": "For single-source parser transfer, we calculate the KLcpos3 distance of the tgt corpus to each src tree bank. We then select the src * tree bank as the closest: src * = argmin * src KLcpos3 (tgt, src), (5) and use it to train the Delex parser to be applied to tgt."}, {"heading": "5.3 Source weighting", "text": "To convert KLcpos3 from a negative measure of language similarity to a positive src parser weight, we take the fourth power of its inverse value, KL \u2212 4cpos3. A high value of the exponent strongly promotes the most similar source language and gives minimal power to the other languages, which is good if there is a very similar source language. A low value allows the combination of information from a larger number of source languages. We chose a compromise value of 4 based on the performance of the development data. We then add the weighting with KLcpos3 to the parser tree combination (Section 3.3) by multiplying the contribution of each src parser tree by KL \u2212 4cpos3 (tgt, src)."}, {"heading": "5.4 Evaluation", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "5.5 Conclusion", "text": "We introduced KLcpos3, an efficient language similarity measure designed for delicalized transmission of dependency savers. We examined it on a large number of tree banks and showed that it achieves good results both in selecting the source tree for transmission from a source and in weighting the source tree banks in a combination of multiple sources when applied to similar languages, but its performance decreases for distant languages. In the future, we intend to explore combinations of KLcpos3 with other measures of language similarity so that the similarity of distant languages is more reliably estimated."}, {"heading": "6 Model Interpolation", "text": "In this section, we present a new method for the src information combination, which is based on the interpolation of trained MSTperl parser models. Our approach was motivated by the intuition that the finer-grained information provided by the src edge values may be beneficial and likely serve as an src parser confidence. Furthermore, the interpolation of models in terms of inference is significantly less mathematically demanding than the parse tree combination method, since there is only one parser running instead of a set of separate src parsers. We are not aware of any previous work on interpolating dependency parser models; the closest to our approach is the interpolation of multilingual probabilistic context-free grammars by Cohen et al. (2011). The method proceeds as follows: 1. Train a delex parser model on each src tree base (Section 3.1) 2. normalize the parser models with Section 6.4, parserting models."}, {"heading": "6.1 Model normalization", "text": "An important step in modeling interpolation is to normalize each of the trained models, since the characteristic weights in models trained via different tree banks are often not on the same scale (we do not regularize during parser training). We use a simplified version of normalization by standard deviation. First, we calculate the uncorrected sample standard deviation of the characteristic weights in the model assM = 1 | M | 0 f-M (wf-w-M) 2, (6) where w-A is the average characteristic weight and | M-M is the number of characteristic weights in the model M; only characteristics to which the training algorithm has assigned a weight are taken into account. Then, we divide each characteristic weight by the standard deviation: 17 \u0445f-M: = wfsM: = wfsM. (7) The selection of normalization by standard deviation is a combination of its high performance and the stable performance on our standard set of 18%."}, {"heading": "6.2 Unweighted model interpolation", "text": "The interpolated model is a linear combination of the normalized models formed via the src tree banks, resulting in a model that can be used in the same way as a standard MSTperl parser model. In the unweighted model interpolation, the weight of each characteristic (wf) is calculated as the sum of the weights of this characteristic in the normalized src models (wf, src). (8)"}, {"heading": "6.3 Weighted model interpolation", "text": "In the weighted variant of the model interpolation, we extend (8) by multiplying by a weight17We found no further gains in performance when we subtracted the mean of the sample from the weight before the division; the MSTParser models typically seem to be centered very similarly; 18Another well-functioning method was to divide each trait weight by the sum of the absolute values of all trait weights in the model; or a similar method that was applied to each sentence separately during the conclusion, using only the trait weights fired for the sentence to calculate the dividend.w (tgt, src), which correspond to the linguistic similarity of tgt and src: \u0394f-F: wf = ced-srcwf, src \u00b7 w (tgt, src). (9) In our experiments, we use the KL \u2212 4 cpos3 (tgt, src), the weight we have presented in section 5."}, {"heading": "6.4 Evaluation", "text": "Table 8 contains the results of our model interpolation methods as well as the basic methods. For each tgt language, all 29 remaining src treebanks were used for parser training. We base our evaluation on comparing absolute differences in UAS across the entire set of 30 languages as targets. The performance of the weighted model interpolation is comparable to the weighted tree combination - the difference in the average UAS of the methods is less than 0.1%, with model interpolation achieving a higher UAS than the tree combination for 16 of the 30 tgt languages. This shows that the weighted model interpolation is a good alternative to the weighted tree combination.In the unweighted setting, the situation is very different, with the model interpolation being rated much lower than the tree combination (-2.4%) and only slightly higher than the tree combination (+ 0.4%) on average than the tree concatenation (+ 0.4%).This suggests that, unlike our modal weights, the 4% is not a good substitute for the intuitive values for the intuitive 4%."}, {"heading": "6.5 Conclusion", "text": "The evaluation of a large collection of tree banks has shown that in an environment where source languages are weighted because of their similarity to the target language, model interpolation is similar to the parse tree combination approach. Furthermore, the model interpolation is significantly lower in all normalization methods evaluated at the development set. Mathematically, it is more challenging than the tree combination when parsing the target text, because the interpolation can be done efficiently beforehand, requiring only a single parser to be called at runtime, while in the tree combination approach each source parser has to be called individually. In the unweighted setting, model interpolation has consistently performed much worse than the tree combination, which we find quite surprising, and we plan to investigate this further in the future. Nevertheless, the weighted methods are generally better than the unweighted ones, and since the language similarity in which we accurately measure the weighted source of the text used is not weighted in such a way that the weighted resources are of lesser importance."}, {"heading": "7 Cross-lingual Lexicalization", "text": "A very popular method to improve the results of delicalized parser transfer is semi-supervised parser lexicalization (since manually generated parallel tree banks are extremely rare), an approach we did not explore in this paper; instead, we focused on improving the underlying delicalized parser transfer. However, we plan to combine it with semi-supervised lexicalization in the future (preliminary experiments suggest that this will lead to further improvements)."}, {"heading": "7.1 Employing parallel data", "text": "The typical approach to lexicography in Delex parsing is the use of dictionaries, parallel texts and / or machine translation techniques (Zhao et al., 2009; McDonald et al., 2011; Ta \ufffd ckstro \ufffd m et al., 2012; Durrett et al., 2012; Ramasamy et al., 2014). One option is to translate the tgt sentence into the src language, which then allows to use a lexicalized src parser instead of a de-exicalized one. Conformity of the words in the translation with the src words can be established by using word alignment. If one too many or too many alignments are used, the projection of the syntactic structure through alignment is not trivial. Therefore, word-to-word translation to-src words can be used instead."}, {"heading": "7.2 Employing word embeddings", "text": "Recently, especially since the introduction of the word2vec tool by Mikolov et al. (2013), continuous vector space word representations, also known as word embedding, have gained enormous popularity and have proven useful for many tasks of natural language processing. In our environment, we are particularly interested in the approaches that calculate bilingual word vectors trained to assign similar vectors to words with similar meanings, regardless of whether they are src or tgt language words. In this way, we could replace lexical features by embedding features, thus avoiding the lexicalization problem. However, it should be noted that our parser, like parsers of other authors, generally only support categorical features; at least in combinations, but not combined features, are of extremely limited usefulness. Therefore, it is necessary to use the vectors either from continuous space to categorical characteristics, although we are aware of them being lost in this area, or to transform them into a parameter, although many of them are supported by parameters."}, {"heading": "7.3 Self-training", "text": "A certain lexicalization can also be achieved in an unsupervised manner by applying self-training (McClosky et al., 2006), i.e. parsing a (preferably large) POS-marked tgt corpus using the Delex transmission method and then the resulting automatic tree bank to train a standard lexicalized parser in a supervised manner. Although it may seem that such a parser has no chance of surpassing the Delex parser, this is not entirely true, as simply the presence or absence of some phenomena in the corpus can help adjust some parameters of the parser. Furthermore, for practical reasons it may be useful to obtain a standardized tgt parser model that can be used for analyzing new tgt data, rather than always applying the full multisource transmission machinery. Our preliminary experiments, which can be performed with the training sections of the tgt tree banks, can be applied automatically to this overall approach, with both a small but significant improvement on the xicalized system."}, {"heading": "8 Conclusion", "text": "We investigated the influence of treebank annotation styles on parsing performance, focusing on the style of adposition attachment. We found that while Stanford annotation is unfavorable for monitored parsers, it performs very well in the multilingual delexicalized parser transfer setup. We then introduced KLcpos3, an empirical language similarity measurement designed for source parser weighting in delicalized multi-source parser transfer. We found that its performance is generally good, although improvements have yet to be made in cases where the target language of any available source language is too dissimilar. Finally, we introduced a novel resource combination method based on the interpolation of trained MSTParser models. Although we found their performance to be below our expectations, when combined with KL \u2212 4cpos3 weighting, we found that the parsing method matched their results."}, {"heading": "Acknowledgments", "text": "This research was supported by GAUK 1572314 and SIA 260 224 grants, using language resources developed, stored and distributed as part of the LINDAT / CLARIN project of the Ministry of Education, Youth and Sport of the Czech Republic (project LM2010013)."}], "references": [{"title": "The prague dependency treebank", "author": ["Jan Haji\u010d", "Eva Haji\u010dov\u00e1", "Barbora Hladk\u00e1"], "venue": "In Treebanks,", "citeRegEx": "B\u00f6hmov\u00e1 et al\\.,? \\Q2003\\E", "shortCiteRegEx": "B\u00f6hmov\u00e1 et al\\.", "year": 2003}, {"title": "A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing", "author": ["Bohnet", "Nivre2012] Bernd Bohnet", "Joakim Nivre"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods", "citeRegEx": "Bohnet et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bohnet et al\\.", "year": 2012}, {"title": "CoNLL-X shared task on multilingual dependency parsing", "author": ["Buchholz", "Marsi2006] Sabine Buchholz", "Erwin Marsi"], "venue": "In Proceedings of the Tenth Conference on Computational Natural Language Learning,", "citeRegEx": "Buchholz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Buchholz et al\\.", "year": 2006}, {"title": "Linear algorithms for online multitask classification", "author": ["Nicolo Cesa-Bianchi", "Claudio Gentile"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Cavallanti et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cavallanti et al\\.", "year": 2010}, {"title": "On shortest arborescence of a directed graph", "author": ["Chu", "Liu1965] Yoeng-Jin Chu", "Tseng-Hong Liu"], "venue": "Scientia Sinica,", "citeRegEx": "Chu et al\\.,? \\Q1965\\E", "shortCiteRegEx": "Chu et al\\.", "year": 1965}, {"title": "Unsupervised structure prediction with non-parallel multilingual guidance", "author": ["Cohen et al.2011] Shay B. Cohen", "Dipanjan Das", "Noah A. Smith"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Cohen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2011}, {"title": "Ultraconservative online algorithms for multiclass problems", "author": ["Crammer", "Singer2003] Koby Crammer", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2003}, {"title": "The stanford typed dependencies representation", "author": ["De Marneffe", "Christopher D Manning"], "venue": "In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Eval-", "citeRegEx": "Marneffe et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2008}, {"title": "Universal Stanford dependencies: A cross-linguistic typology", "author": ["Natalia Silveira", "Timothy Dozat", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D. Manning"], "venue": "In Proc. of LREC\u201914,", "citeRegEx": "Marneffe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "Syntactic transfer using a bilingual lexicon", "author": ["Durrett et al.2012] Greg Durrett", "Adam Pauls", "Dan Klein"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language", "citeRegEx": "Durrett et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2012}, {"title": "Optimum branchings", "author": ["Jack Edmonds"], "venue": "Journal of Research of the National Bureau of Standards B,", "citeRegEx": "Edmonds.,? \\Q1967\\E", "shortCiteRegEx": "Edmonds.", "year": 1967}, {"title": "Three new probabilistic models for dependency parsing: An exploration", "author": ["Jason M. Eisner"], "venue": "In Proceedings of the 16th Conference on Computational Linguistics - Volume 1,", "citeRegEx": "Eisner.,? \\Q1996\\E", "shortCiteRegEx": "Eisner.", "year": 1996}, {"title": "Corpus variation and parser performance", "author": ["Daniel Gildea"], "venue": "In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Gildea.,? \\Q2001\\E", "shortCiteRegEx": "Gildea.", "year": 2001}, {"title": "Survey on parsing three dependency representations for english", "author": ["Stephan Oepen", "Lilja \u00d8vrelid"], "venue": "In ACL (Student Research Workshop),", "citeRegEx": "Ivanova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ivanova et al\\.", "year": 2013}, {"title": "Effective selftraining for parsing", "author": ["Eugene Charniak", "Mark Johnson"], "venue": "In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Asso-", "citeRegEx": "McClosky et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McClosky et al\\.", "year": 2006}, {"title": "Online largemargin training of dependency parsers", "author": ["Koby Crammer", "Fernando Pereira"], "venue": "In Proceedings of the 43rd annual meeting on association for computational linguistics,", "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Nonprojective dependency parsing using spanning tree algorithms", "author": ["Fernando Pereira", "Kiril Ribarov", "Jan Haji\u010d"], "venue": "In Proceedings of the conference on Human Language Technology and Empirical Methods", "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Multi-source transfer of delexicalized dependency parsers", "author": ["Slav Petrov", "Keith Hall"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "McDonald et al\\.,? \\Q2011\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2011}, {"title": "Universal dependency annotation", "author": ["Joakim Nivre", "Yvonne Quirmbach-Brundage", "Yoav Goldberg", "Dipanjan Das", "Kuzman Ganchev", "Keith B Hall", "Slav Petrov", "Hao Zhang", "Oscar T\u00e4ckstr\u00f6m"], "venue": null, "citeRegEx": "McDonald et al\\.,? \\Q2013\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2013}, {"title": "Efficient estimation of word representations in vector space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "Proceedings of Workshop at ICLR", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Selective sharing for multilingual dependency parsing. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume", "author": ["Naseem et al.2012] Tahira Naseem", "Regina Barzilay", "Amir Globerson"], "venue": null, "citeRegEx": "Naseem et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Naseem et al\\.", "year": 2012}, {"title": "The CoNLL 2007 shared task on dependency parsing", "author": ["Nilsson et al.2007] Jens Nilsson", "Sebastian Riedel", "Deniz Yuret"], "venue": "In Proceedings of the CoNLL shared task session of EMNLP-CoNLL,", "citeRegEx": "Nilsson et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nilsson et al\\.", "year": 2007}, {"title": "Maltparser: A data-driven parsergenerator for dependency parsing", "author": ["Nivre et al.2006] Joakim Nivre", "Johan Hall", "Jens Nilsson"], "venue": "In Proceedings of LREC", "citeRegEx": "Nivre et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2006}, {"title": "Universal dependencies 1.0", "author": ["talia Silveira", "Maria Simi", "Aaron Smith", "Reut Tsarfaty", "Veronika Vincze", "Daniel Zeman"], "venue": null, "citeRegEx": "Silveira et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Silveira et al\\.", "year": 2015}, {"title": "A universal part-of-speech tagset", "author": ["Petrov et al.2012] Slav Petrov", "Dipanjan Das", "Ryan McDonald"], "venue": "In Proc. of LREC-2012,", "citeRegEx": "Petrov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "Coordination structures in dependency treebanks", "author": ["Popel et al.2013] Martin Popel", "David Mare\u010dek", "Jan \u0160t\u011bp\u00e1nek", "Daniel Zeman", "Zden\u011bk \u017dabokrtsk\u00fd"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Popel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Popel et al\\.", "year": 2013}, {"title": "Multilingual dependency parsing: Using machine translated texts instead of parallel corpora", "author": ["David Mare\u010dek", "Zden\u011bk \u017dabokrtsk\u00fd"], "venue": null, "citeRegEx": "Ramasamy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ramasamy et al\\.", "year": 2014}, {"title": "Using parallel features in parsing of machine-translated sentences for correction of grammatical errors", "author": ["Rosa et al.2012] Rudolf Rosa", "Ond\u0159ej Du\u0161ek", "David Mare\u010dek", "Martin Popel"], "venue": "In Proceedings of Sixth Workshop on Syntax,", "citeRegEx": "Rosa et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rosa et al\\.", "year": 2012}, {"title": "HamleDT 2.0: Thirty dependency treebanks stanfordized", "author": ["Rosa et al.2014] Rudolf Rosa", "Jan Ma\u0161ek", "David Mare\u010dek", "Martin Popel", "Daniel Zeman", "Zden\u011bk \u017dabokrtsk\u00fd"], "venue": null, "citeRegEx": "Rosa et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rosa et al\\.", "year": 2014}, {"title": "Parser combination by reparsing", "author": ["Sagae", "Lavie2006] Kenji Sagae", "Alon Lavie"], "venue": "In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,", "citeRegEx": "Sagae et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Sagae et al\\.", "year": 2006}, {"title": "Learnability-based syntactic annotation design", "author": ["Omri Abend", "Ari Rappoport"], "venue": "In Proceedings of COLING", "citeRegEx": "Schwartz et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2012}, {"title": "Functional sentence perspective in a generative description", "author": ["Petr Sgall"], "venue": "Prague studies in mathematical linguistics,", "citeRegEx": "Sgall.,? \\Q1967\\E", "shortCiteRegEx": "Sgall.", "year": 1967}, {"title": "An empirical etudy of non-lexical extensions to delexicalized transfer", "author": ["S\u00f8gaard", "Wulff2012] Anders S\u00f8gaard", "Julie Wulff"], "venue": "In COLING (Posters),", "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2012\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2012}, {"title": "Data point selection for cross-language adaptation of dependency parsers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers", "author": ["Anders S\u00f8gaard"], "venue": null, "citeRegEx": "S\u00f8gaard.,? \\Q2011\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2011}, {"title": "An empirical study of differences between conversion schemes and annotation guidelines", "author": ["Anders S\u00f8gaard"], "venue": "In Proceedings of the Second International Conference on Dependency Linguistics (DepLing", "citeRegEx": "S\u00f8gaard.,? \\Q2013\\E", "shortCiteRegEx": "S\u00f8gaard.", "year": 2013}, {"title": "Ensemble models for dependency parsing: Cheap and good", "author": ["Surdeanu", "Manning2010] Mihai Surdeanu", "Christopher D. Manning"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter", "citeRegEx": "Surdeanu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2010}, {"title": "The conll-2008 shared task on joint parsing of syntactic and semantic dependencies", "author": ["Richard Johansson", "Adam Meyers", "Llu\u0131\u0301s M\u00e0rquez", "Joakim Nivre"], "venue": "In Proceedings of the Twelfth Conference on Computa-", "citeRegEx": "Surdeanu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2008}, {"title": "Cross-lingual word clusters for direct transfer of linguistic structure", "author": ["Ryan McDonald", "Jakob Uszkoreit"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2012\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2012}, {"title": "Target language adaptation of discriminative transfer parsers", "author": ["Ryan McDonald", "Joakim Nivre"], "venue": null, "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2013\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2013}, {"title": "Cross-language parser adaptation between related languages", "author": ["Zeman", "Resnik2008] Daniel Zeman", "Philip Resnik"], "venue": "In IJCNLP 2008 Workshop on NLP for Less Privileged Languages,", "citeRegEx": "Zeman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zeman et al\\.", "year": 2008}, {"title": "Hamledt: To parse or not to parse", "author": ["\u0160t\u011bp\u00e1nek", "Zden\u011bk \u017dabokrtsk\u00fd", "Jan Haji\u010d"], "venue": null, "citeRegEx": "\u0160t\u011bp\u00e1nek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "\u0160t\u011bp\u00e1nek et al\\.", "year": 2012}, {"title": "Reusable tagset conversion using tagset drivers", "author": ["Daniel Zeman"], "venue": "In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "Zeman.,? \\Q2008\\E", "shortCiteRegEx": "Zeman.", "year": 2008}, {"title": "Cross language dependency parsing using a bilingual lexicon", "author": ["Zhao et al.2009] Hai Zhao", "Yan Song", "Chunyu Kit", "Guodong Zhou"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference", "citeRegEx": "Zhao et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 21, "context": "The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Haji\u010d et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community.", "startOffset": 112, "endOffset": 203}, {"referenceID": 36, "context": "The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Haji\u010d et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community.", "startOffset": 112, "endOffset": 203}, {"referenceID": 15, "context": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al.", "startOffset": 188, "endOffset": 212}, {"referenceID": 15, "context": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al. (2006). The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al.", "startOffset": 188, "endOffset": 272}, {"referenceID": 15, "context": "The problem of supervised dependency parsing of natural language sentences has been intensively studied for the past decade, especially since the invention of the graph-based MSTParser by McDonald et al. (2005a), and the transitionbased Malt parser by Nivre et al. (2006). The success of these parsing algorithms, together with several CoNLL shared tasks focused on dependency parsing (Buchholz and Marsi, 2006; Nilsson et al., 2007; Surdeanu et al., 2008; Haji\u010d et al., 2009), even lead to a general transition from constituency parsing to dependency parsing throughout the NLP community. The current state-of-the-art dependency parsers, such as the Mate parser of Bohnet and Nivre (2012), often achieve around 90% UAS (Unlabelled Attachment Score) for many languages.", "startOffset": 188, "endOffset": 690}, {"referenceID": 12, "context": "by Gildea (2001). This naturally motivates research of semi-supervised or unsupervised parsing methods.", "startOffset": 3, "endOffset": 17}, {"referenceID": 15, "context": "However, as shown by McDonald et al. (2011), not only is the similarity of languages only a weakly established concept, but the empirical results are often rather counterintuitive \u2013 for example, to parse Swedish, the best treebank to use turned out to be a Portuguese one, performing better than treebanks for Germanic languages (their dataset included, among other, German, Dutch, Danish, and English).", "startOffset": 21, "endOffset": 44}, {"referenceID": 25, "context": "On the syntactic level, not only the sets of labels are different, but even the unlabelled dependency structures differ, as they correspond to different linguistic theories; probably the highest variance can be found in the annotation of coordination structures, as studied by Popel et al. (2013). While some of the differences may be motivated by inherent properties of the respective languages, they very often correspond merely to more-or-less arbitrary design decisions of technical rather than linguistic nature, taken during the creation of the treebanks.", "startOffset": 277, "endOffset": 297}, {"referenceID": 39, "context": "The issues with cross-lingually incoherent annotation first led Zeman (2008) to the development of the Interset, a method of capturing values of most morphological features and for conversions between various tagsets.", "startOffset": 64, "endOffset": 77}, {"referenceID": 38, "context": "Later, the HamleDT collection of dependency treebanks was created by Zeman et al. (2012), consisting of treebanks harmonized not only on the morphological level (via Interset), but also on the syntactic level, loosely following the annotation style of the Prague Dependency Treebank of B\u00f6hmov\u00e1 et al.", "startOffset": 69, "endOffset": 89}, {"referenceID": 0, "context": "(2012), consisting of treebanks harmonized not only on the morphological level (via Interset), but also on the syntactic level, loosely following the annotation style of the Prague Dependency Treebank of B\u00f6hmov\u00e1 et al. (2003).", "startOffset": 204, "endOffset": 226}, {"referenceID": 18, "context": "In parallel, Petrov et al. (2012) defined the Universal POS tagset (UPOS) as a counter-weight to Interset, as it only captures 12 most important values of coarse-grained POS tags, ignoring all other morphological annotation.", "startOffset": 13, "endOffset": 34}, {"referenceID": 13, "context": "It was later used for annotation of the (eventually) 11 treebanks of the Google Universal Dependency Treebank collection of McDonald et al. (2013). For syntactic annotation, the authors defined their own version of the Stanford Dependencies (De Marneffe and Manning, 2008), modified to better suit the multilingual setting, as the original annotation style was implicitly designed for English.", "startOffset": 124, "endOffset": 147}, {"referenceID": 7, "context": "In turn, de Marneffe et al. (2014) reacted by introducing the Universal Stanford Dependencies as the \u201cofficial\u201d multilingual version of Stanford Dependencies.", "startOffset": 12, "endOffset": 35}, {"referenceID": 7, "context": "In turn, de Marneffe et al. (2014) reacted by introducing the Universal Stanford Dependencies as the \u201cofficial\u201d multilingual version of Stanford Dependencies. This annotation style was immediately adopted by Rosa et al. (2014), who modified it slightly and used it to \u201cstanfordize\u201d the HamleDT collection by implementing a languageneutral conversion pipeline and applying it to the", "startOffset": 12, "endOffset": 227}, {"referenceID": 22, "context": "project of Nivre et al. (2015),2 both defining an annotation style based mainly on UPOS, Interset and Universal Stanford Dependencies, as well as producing a set of 10 treebanks annotated in this way in the 1.", "startOffset": 11, "endOffset": 31}, {"referenceID": 41, "context": "As a prerequisite to applying the method, they map the treebank POS tagsets to a common set, an approach later becoming known as conversion to Interset (Zeman, 2008).", "startOffset": 152, "endOffset": 165}, {"referenceID": 40, "context": "The idea of delexicalized transfer was conceived by Zeman and Resnik (2008), who trained a delexicalized parser on a Danish treebank and evaluated it on a Swedish one.", "startOffset": 52, "endOffset": 76}, {"referenceID": 15, "context": "parser of Rosa (2014), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order", "startOffset": 84, "endOffset": 108}, {"referenceID": 10, "context": "The sentence parse tree is the maximum spanning tree (MST) over that graph, found using the algorithm of Chu and Liu (1965) and Edmonds (1967).", "startOffset": 128, "endOffset": 143}, {"referenceID": 24, "context": "POS tags We use the coarse 12-value UPOS of Petrov et al. (2012).6 For an edge, we use information about the POS tag of the head, dependent, their neighbours, and all of the nodes between them.", "startOffset": 44, "endOffset": 65}, {"referenceID": 22, "context": "the Malt parser of Nivre et al. (2006). For most of our approaches, this will be straightforward, but for the parser model interpolation approach (Section 6), it may be rather intriguing.", "startOffset": 19, "endOffset": 39}, {"referenceID": 10, "context": "To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al.", "startOffset": 54, "endOffset": 88}, {"referenceID": 11, "context": "Other MST algorithms could be used, such as the Eisner algorithm (Eisner, 1996), which is, unlike Chu-Liu-Edmonds, constrained to producing only projective parse trees, and was used by McDonald et al.", "startOffset": 65, "endOffset": 79}, {"referenceID": 13, "context": "The combination is performed using the idea of McDonald et al. (2005a), who formulated the problem of finding a parse tree as a problem of finding the maximum spanning tree of a weighted directed graph of potential parse tree edges.", "startOffset": 47, "endOffset": 71}, {"referenceID": 10, "context": "To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al. (2005b) in the non-projective MSTParser.", "startOffset": 36, "endOffset": 132}, {"referenceID": 10, "context": "To find the MST, we use the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967), which was used by McDonald et al. (2005b) in the non-projective MSTParser. Other MST algorithms could be used, such as the Eisner algorithm (Eisner, 1996), which is, unlike Chu-Liu-Edmonds, constrained to producing only projective parse trees, and was used by McDonald et al. (2005a) in the projective MSTParser.", "startOffset": 36, "endOffset": 374}, {"referenceID": 10, "context": "Find the maximum spanning tree over the graph with the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967).", "startOffset": 81, "endOffset": 115}, {"referenceID": 31, "context": "The Prague style dependencies, on the other hand, are based upon a functionalist approach of Sgall (1967), and annotate adpositions as heads of adpositional groups.", "startOffset": 93, "endOffset": 106}, {"referenceID": 30, "context": "The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013).", "startOffset": 128, "endOffset": 188}, {"referenceID": 34, "context": "The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013).", "startOffset": 128, "endOffset": 188}, {"referenceID": 13, "context": "The issue of dependency representation learnability has been studied by several authors, generally reaching similar conclusions (Schwartz et al., 2012; S\u00f8gaard, 2013; Ivanova et al., 2013).", "startOffset": 128, "endOffset": 188}, {"referenceID": 7, "context": "The approach suggested by de Marneffe et al. (2014) is to use a different annotation style for parsing, with", "startOffset": 29, "endOffset": 52}, {"referenceID": 20, "context": "Several authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; T\u00e4ckstr\u00f6m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer.", "startOffset": 16, "endOffset": 86}, {"referenceID": 38, "context": "Several authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; T\u00e4ckstr\u00f6m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer.", "startOffset": 16, "endOffset": 86}, {"referenceID": 20, "context": "Several authors (Naseem et al., 2012; S\u00f8gaard and Wulff, 2012; T\u00e4ckstr\u00f6m et al., 2013) have employed the World Atlas of Language Structures (WALS) of Dryer and Haspelmath (2013) to estimate the similarity of languages for delex transfer.", "startOffset": 17, "endOffset": 178}, {"referenceID": 33, "context": "In (S\u00f8gaard, 2011), he trains a POS language model on a tgt POS-tagged corpus, and uses it to filter the src treebank, keeping only sentences that look like target language sentences to the language model.", "startOffset": 3, "endOffset": 18}, {"referenceID": 3, "context": "This is made possible by modifying their learning algorithm to use weighted perceptron learning (Cavallanti et al., 2010).", "startOffset": 96, "endOffset": 121}, {"referenceID": 21, "context": "Preliminary trials on the subset of CoNLL 2006 and 2007 data sets (Buchholz and Marsi, 2006; Nilsson et al., 2007) used by McDonald et al.", "startOffset": 66, "endOffset": 114}, {"referenceID": 15, "context": ", 2007) used by McDonald et al. (2011) indicated that these are not suitable for our approach, as they are not harmonized on the dependency annotation level.", "startOffset": 16, "endOffset": 39}, {"referenceID": 15, "context": ", 2007) used by McDonald et al. (2011) indicated that these are not suitable for our approach, as they are not harmonized on the dependency annotation level.12 There, treebank annotation style similarity seems to become more important than language similarity; the lack of harmonization makes the data unnecessarily noisier. Table 7 contains the results of our methods both on the test languages and the development languages. For each target language, we used all remaining 29 source languages for training (in the single-source method, only one of them is selected and applied). We base our evaluation mainly on average UAS on the test tgt languages, and compare the methods by absolute UAS differences. Our baseline is the treebank concatenation method of McDonald et al. (2011), i.", "startOffset": 16, "endOffset": 782}, {"referenceID": 5, "context": "We are not aware of any prior work on interpolating dependency parser models; the closest to our approach is the interpolation of multilingual probabilistic context-free grammars of Cohen et al. (2011). The method proceeds as follows:", "startOffset": 182, "endOffset": 202}, {"referenceID": 27, "context": "through additional features, as has been done by Rosa et al. (2012), which does not require a oneto-one alignment.", "startOffset": 49, "endOffset": 68}, {"referenceID": 19, "context": "Recently, especially since the introduction of the word2vec tool by Mikolov et al. (2013), continuous vector space word representations, also known as word embeddings, have gained huge popularity, and have proven to be useful in many tasks of natural language processing.", "startOffset": 68, "endOffset": 90}, {"referenceID": 14, "context": "Some lexicalization can also be achieved in an unsupervised way by applying self-training (McClosky et al., 2006), i.", "startOffset": 90, "endOffset": 113}], "year": 2015, "abstractText": "We present our work on semi-supervised parsing of natural language sentences, focusing on multi-source crosslingual transfer of delexicalized dependency parsers. We first evaluate the influence of treebank annotation styles on parsing performance, focusing on adposition attachment style. Then, we present KLcpos3 , an empirical language similarity measure, designed and tuned for source parser weighting in multi-source delexicalized parser transfer. And finally, we introduce a novel resource combination method, based on interpolation of trained parser models.", "creator": "LaTeX with hyperref package"}}}