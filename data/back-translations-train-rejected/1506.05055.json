{"id": "1506.05055", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2015", "title": "Numeric Input Relations for Relational Learning with Applications to Community Structure Analysis", "abstract": "Most work in the area of statistical relational learning (SRL) is focussed on discrete data, even though a few approaches for hybrid SRL models have been proposed that combine numerical and discrete variables. In this paper we distinguish numerical random variables for which a probability distribution is defined by the model from numerical input variables that are only used for conditioning the distribution of discrete response variables. We show how numerical input relations can very easily be used in the Relational Bayesian Network framework, and that existing inference and learning methods need only minor adjustments to be applied in this generalized setting. The resulting framework provides natural relational extensions of classical probabilistic models for categorical data. We demonstrate the usefulness of RBN models with numeric input relations by several examples.", "histories": [["v1", "Tue, 16 Jun 2015 18:18:06 GMT  (605kb)", "http://arxiv.org/abs/1506.05055v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jiuchuan jiang", "manfred jaeger"], "accepted": false, "id": "1506.05055"}, "pdf": {"name": "1506.05055.pdf", "metadata": {"source": "CRF", "title": "Numeric Input Relations for Relational Learning with Applications to Community Structure Analysis", "authors": ["Jiuchuan Jiang", "Manfred Jaeger"], "emails": ["jiangjiuchuan@163.com", "jaeger@cs.aau.dk"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.05 055v 1 [cs.L G] 16 JuSpecifically, we use the extended RBN framework to define probability models for multirelational (social) networks, in which the probability of a connection between two nodes depends on numerical latent trait vectors associated with the nodes. A generic learning method can be used to obtain a most likely fit of model parameters and latent trait values for a variety of models that can be expressed in the high-level RBN representation. Specifically, we propose a model that allows us to interpret learned latent trait values as a central level of the community, enabling us to identify nodes that are central to a community, that are nodes between communities or are isolated nodes. In a multirelational environment, the model also provides a description of how different relationships are linked to each community."}, {"heading": "1. Introduction", "text": "In this context, it should be noted that the two cases are very complex and it is only a matter of time before they are put into practice."}, {"heading": "2. SRL Models and Numeric Relations", "text": "An SRL model defines a probability distribution over relational structures. An SRL model can be instantiated over various input ranges, which can only consist of a set of objects or, more generally, a set of objects together with a set of known input relationships. Thus, an SRL model defines conditional probability distributions P (IRprob | IRin, D, \u03b8) (1), where D extends over a class of domains (usually the class of all finite sets), IRin ranges over interpretations over D of a set of input relationships Rin, and IRprob ranges over interpretations of a set of probability relationships (or output relationships) Rprob. Interpretations IRin and IRprob are given as value mappings to the terrestrial atoms (d) (d) Darity (r). In the discrete case, each relationship r has a corresponding finite range of possible values. The distinction between input and probability relationships does not have to be considered explicit in a model, which can also be related."}, {"heading": "2.1 Hybrid SRL Models", "text": "In fact, it is that we are able to assert ourselves, that we are able to be able to be able to be in a position, that we are able to be in a position, that we are able to be in a position, that we are able to be in a position, that we are able to be in a position, that we are able to be in a position, that we are able to put ourselves in a position, that we are able to put ourselves in a position, that we are in a position, that we are in a position, that we are in a position, that we are in a position, that we are able to be in the world. \""}, {"heading": "3. Numerical Input Relations in RBNs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Modeling", "text": "The RBN language is based on probability formulas that define the probability P (r (a) = true) for the base weight of relational atoms r (a). The language of probability formulas is defined by an economical grammar based on the two main constructs of convex combinations and combination functions. Below are two examples of the convex combination construct. To improve the legibility and comprehensibility of the formulas, we use a modification of the original very compact syntax of [12], and write convex combinations in the form of \"wif-else\" statements (\"wif\" stands for \"weighted-if\"). P (heads) = true) wif fair (T) then 0.5 otherwise 0.7 (5) P (Cancer (X) wif) wif 0.3) wif 0.3 then genetic predisposition (X) otherwise 0.1 (6) formula (otherwise 0.1)."}, {"heading": "3.2 Inference and Learning", "text": "Most of them are not able to help themselves and their fellow human beings. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves. (...) Most of them are not able to help themselves."}, {"heading": "4. Examples: Standard Logistic Regression", "text": "We will now demonstrate the usefulness of RBN models with numerical input relationships for practical modeling and learning problems, and the feasibility of learning using probability diagram-based gradient ascent. In this section, we will present examples demonstrating the use of the logistic regression model in our relationship framework for building models that closely follow conventional and interpretable statistical modeling approaches."}, {"heading": "4.1 Propositional: Cancer Data", "text": "In a first experiment, we test whether the standard \"propositional\" logistic regression is properly embedded in our relationship structure using a very small dataset of data on 27 cancer patients, originally introduced in [16] and often used as a standard example of logistic regression. We use a simplified version of the dataset from [1, Table 5.10], which contains a single numerical predictor variable LI and a binary response variable that indicates whether the cancer is in remission after treatment. A standard logistic regression model for predicting remission is somewhat degenerated by the probability formula P (Remission (A) = true) \u2190 COMBINE \u03b1 + \u03b2 \u00b7 LI (A) WITH L-reg. (8) The combination function construct in this formula is not a combination of a multiple-value compression function (reductible) and the single-value (reductible I) merely affects the logistic I (reductible I)."}, {"heading": "4.2 Relational: Water Network", "text": "In this section, we will consider a toy model for the propagation of pollution in a river network. Secondly, secondly, secondly, thirdly, a fixed model of pollution. This example demonstrates the ability to integrate into our framework of relational modeling \u03b2 = 3. Standard logistical response models based on meaningful and interpretable predictor relations. Input domains for this model consist of measuring stations in a river network that measure whether the river is polluted or not. Stations are related to each other by the Boolean upstream relationship, indicating that one station is directly in front of another (i.e., with no other stations in between). For each pair of stations in the upstream relationship, there is also a numerical relationship that includes the inversion of the distance between the two stations. The most common distance between the two stations-then-otherwise construct in rows 1,2,10 of the model of Table 1 defines the polluted values that contain a mixture of two factors \u2212 1, the two of which are attributable to one of the two: 1)."}, {"heading": "5. Application: Community Structure in Multi-Relational Networks", "text": "We will now apply the learning of the numerical input relations in RBNs to the community structure analysis in multilateral networks. Figure 5 shows a small network of 6 individuals connected by two different types of (undirected) connections. However, if one considers only the green (solid) linkage relationship, one would identify {1, 3, 5} and {2, 4, 6} as communities, while the red linkages represent an antagonistic relationship, which is more likely to exist between communities than within communities, and assumes that both are positive indicators of communities, {2, 4, 6}."}, {"heading": "5.1 Community Centrality Degrees", "text": "In this section, we will first consider the individual relational cases to explore models of community membership that meet the desiderata (11) outlined in the previous section. We will present a numerical binary relationship between two (V, C) whose arguments are a node V and a community C. However, the relationship u is limited to not being negative. We can then define the following probability model: P (link (V, W) is a real constant (the interpretation, in the language of log-linear models).This model is quite simple and closely related to other models for link prediction (e.g. for recommendation systems), in which the affinity of objects connected to the objects is measured."}, {"heading": "5.2 Communities in Multi-Relational Networks", "text": "We are generalizing the model (9), (10) to multirelational networks (C). For a network that contains K relations linki (i = 1,.., K), we are introducing K new numerical attributes ti (C) to the cluster objects of the domain. Therefore, the values of ti are severely restricted. The intention is that ti (C) measures whether the existence of links of type i is positive (ti > 0) or negative (ti < 0) with membership in cluster C. We are now defining the probability P (linki (V, W))) using (9) in conjunction with Si + Isis, c: Community (c: Community) u (V, C) \u00b7 ti (C) \u00b7 ti (C) associated with membership in cluster C. We are now defining the probability P (linki (V, W))))), whereby (9) in conjunction with connection with Si + Isis: Community the positive values of the community are identified."}, {"heading": "5.3 Community Significance Measure", "text": "It is highly desirable that a method not only reflects the desired number of communities, but also provides a measure of the meaning or validity of each community. On the basis of our probability model, we obtain such a measure in terms of the explanatory value that a community provides for the observed network structure, formalizing the explanatory value by the probability gain obtained by incorporating community information into the model. In particular, to measure the explanatory value of the community Ck, defined by the u (\u00b7, Ck) values of all nodes, we consider the model defined by (9) in ConjunctionSi = \u03b1i + u (V, Ck) \u00b7 u (W, Ck) \u00b7 ti (Ck). (14) In this model, we now capture the previously learned u (\u00b7, Ck) values and learn the parameters {\u03b1i | i = 1,."}, {"heading": "5.4 Incomplete Network Data", "text": "An important advantage of using probability models for network analysis is the ability to deal with incomplete information: for the probability function q = = q effects, it is not necessary for each pair of nodes V, W to detect the true / false status of the link relationship. Thus, unlike many other graph partitioning and community detection methods, probabilistic approaches can easily deal with incomplete graph data, where links (V, W) atoms also have an unknown state.Apart from dealing with such potentially 3-value graph data, we can also take advantage of this robustness of the probability function to improve the scalability of larger networks by sub-sampling the false link data. Summarizing complete network data, the number of factors in (11), and hence the number of nodes in the probability graph is square in the number of nodes on the network. As networks tend to do this, we tend to associate false links significantly higher in the number of likely nodes."}, {"heading": "5.5 Related Work", "text": "Probabilistic latent characteristic models for social networks (in a one-sided relational context) were proposed in [10], but the emphasis there is more on obtaining interpretable visual embedding of nodes in latent space than on community analysis. SRL modelling tools for clustering in social network analysis were already proposed in [20]. Clusters here consist of nodes with similar properties but not of connected node communities. [23] proposes a non-parametric Bayesian model with discrete latent variables that induces hard partitioning of nodes. This model is formulated for multirelational networks, but only for one-sided relational networks in [23]. Similarly, an RBN model with discrete latent variables for standard partition-based community detection was presented in [14]."}, {"heading": "6. Conclusion", "text": "This year, it has reached the stage where it will be able to take the lead."}], "references": [{"title": "Categorical Data Analysis", "author": ["A. Agresti"], "venue": "Wiley", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Abacus: frequent pattern mining-based community discovery in multidimensional networks", "author": ["Michele Berlingerio", "Fabio Pinelli", "Francesco Calabrese"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "An algorithm for clustering relational data with applications to social network analysis and comparison with multidimensional scaling", "author": ["Ronald L Breiger", "Scott A Boorman", "Phipps Arabie"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1975}, {"title": "Mining hidden community in heterogeneous social networks", "author": ["Deng Cai", "Zheng Shao", "Xiaofei He", "Xifeng Yan", "Jiawei Han"], "venue": "In Proceedings of the 3rd international workshop on Link discovery,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "editors", "author": ["L. De Raedt", "P. Frasconi", "K. Kersting", "S.H. Muggleton"], "venue": "Probabilistic Inductive Logic Programming, volume 4911 of Lecture Notes in Artificial Intelligence. Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Mining the network value of customers", "author": ["Pedro Domingos", "Matt Richardson"], "venue": "In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "editors", "author": ["L. Getoor", "B. Taskar"], "venue": "Introduction to Statistical Relational Learning. MIT Press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Community structure in social and biological networks", "author": ["Michelle Girvan", "Mark EJ Newman"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Extending problog with continuous distributions", "author": ["B. Gutmann", "M. Jaeger", "L. De Raedt"], "venue": "Proceedings of the 20th Int. Conf. on Inductive Logic Programming (ILP), volume 6489 of LNCS, pages 76\u201391. Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Latent space approaches to social network analysis", "author": ["Peter D Hoff", "Adrian E Raftery", "Mark S Handcock"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Latent semantic models for collaborative filtering", "author": ["Thomas Hofmann"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Relational bayesian networks", "author": ["M. Jaeger"], "venue": "Dan Geiger and Prakash Pundalik Shenoy, editors, Proceedings of the 13th Conference of Uncertainty in Artificial Intelligence (UAI-13), pages 266\u2013273, Providence, USA", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1997}, {"title": "Parameter learning for relational Bayesian networks", "author": ["M. Jaeger"], "venue": "Proceedings of the 24th International Conference on Machine Learning (ICML)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Community detection for multiplex social networks based on relational bayesian networks", "author": ["J. Jiang", "M. Jaeger"], "venue": "Proc. of the 21st Int. Symposium on Methodologies for Intelligent Systems (ISMIS)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "A computer program for linear logistic regression analysis", "author": ["Elisa T Lee"], "venue": "Computer programs in biomedicine,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1974}, {"title": "Learning relational dependency networks in hybrid domains", "author": ["I. Ravkic", "J. Ramon", "J. Davis"], "venue": "Machine Learning", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Markov logic networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine Learning, 62(1- 2):107 \u2013 136", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Towards effective visual analytics on multiplex and multilayer networks", "author": ["Luca Rossi", "Matteo Magnani"], "venue": "Chaos, Solitons & Fractals,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Probabilistic classification and clustering in relational data", "author": ["Benjamin Taskar", "Eran Segal", "Daphne Koller"], "venue": "In Proc. of 17th International Joint Conference on Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "Hybrid markov logic networks", "author": ["J. Wang", "P. Domingos"], "venue": "Proceedings of the Twenty-Third National Conference on Artificial Intelligence", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Scan: a structural clustering algorithm for networks", "author": ["Xiaowei Xu", "Nurcan Yuruk", "Zhidan Feng", "Thomas AJ Schweiger"], "venue": "In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Nonparametric relational learning for social network analysis", "author": ["Zhao Xu", "Volker Tresp", "Shipeng Yu", "Kai Yu"], "venue": "In KDD 2008 Workshop on Social Network Mining and Analysis,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "An information flow modelfor conflict and fission in small groups1", "author": ["W Zachary"], "venue": "Journal of anthropological research, 33(4):452\u2013473", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1977}], "referenceMentions": [{"referenceID": 6, "context": "Introduction Statistical-relational learning (SRL) models have mostly been developed for discrete data (see [7, 5] for general overviews).", "startOffset": 108, "endOffset": 114}, {"referenceID": 4, "context": "Introduction Statistical-relational learning (SRL) models have mostly been developed for discrete data (see [7, 5] for general overviews).", "startOffset": 108, "endOffset": 114}, {"referenceID": 19, "context": "Among the relatively few proposals for SRL frameworks with continuous variables are hybrid Markov Logic Networks [21], hybrid ProbLog [9], and hybrid dependency networks [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 8, "context": "Among the relatively few proposals for SRL frameworks with continuous variables are hybrid Markov Logic Networks [21], hybrid ProbLog [9], and hybrid dependency networks [17].", "startOffset": 134, "endOffset": 137}, {"referenceID": 15, "context": "Among the relatively few proposals for SRL frameworks with continuous variables are hybrid Markov Logic Networks [21], hybrid ProbLog [9], and hybrid dependency networks [17].", "startOffset": 170, "endOffset": 174}, {"referenceID": 19, "context": "In these works the complexity of the inference problem is addressed by focussing on approximate, sampling based methods [21, 17], or by imposing significant restrictions on the models, so that the required integration tasks for exact inference become solvable [9].", "startOffset": 120, "endOffset": 128}, {"referenceID": 15, "context": "In these works the complexity of the inference problem is addressed by focussing on approximate, sampling based methods [21, 17], or by imposing significant restrictions on the models, so that the required integration tasks for exact inference become solvable [9].", "startOffset": 120, "endOffset": 128}, {"referenceID": 8, "context": "In these works the complexity of the inference problem is addressed by focussing on approximate, sampling based methods [21, 17], or by imposing significant restrictions on the models, so that the required integration tasks for exact inference become solvable [9].", "startOffset": 260, "endOffset": 263}, {"referenceID": 11, "context": "We then proceed to show how numeric input relations can be integrated into the Relational Bayesian Network (RBN) language [12], with little or no cost in terms of algorithmic developments or computational complexity.", "startOffset": 122, "endOffset": 126}, {"referenceID": 7, "context": "In such networks, it will usually no longer be possible to reduce community structure detection to a form of graph partitioning [8], because different relations may define a multitude of different, overlapping, and partly conflicting community structures.", "startOffset": 128, "endOffset": 131}, {"referenceID": 20, "context": "They thereby allow us, for example, to identify influential hub nodes [22] between communities (nodes with high centrality degree for multiple communities).", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "Markov Logic Networks (MLNs) [18] are one prominent framework in which there is only such an implicit distinction between input and probabilistic relations.", "startOffset": 29, "endOffset": 33}, {"referenceID": 8, "context": "The clear focus of Hybrid ProbLog [9] is to introduce numeric probabilistic relations.", "startOffset": 34, "endOffset": 37}, {"referenceID": 19, "context": "The nature of Hybrid MLNs [21] is a little less clear-cut, due to the only implicit distinction between input and output relations 1.", "startOffset": 26, "endOffset": 30}, {"referenceID": 19, "context": "The probability of x then is given by 1/Ze (x), where W is the sum of weights from all groundings of all features, and Z a normalization constant [21].", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "To improve the readability and understandability of the formulas, we here use a modification of the original very compact syntax of [12], and write convex combinations in the form of \u201cwif-then-else\u201d statements (\u201cwif\u201d stands for \u201cweighted-if\u201d).", "startOffset": 132, "endOffset": 136}, {"referenceID": 0, "context": "The only additional modification one has to make is to ensure that in the end probability formulas defining the probability for a Boolean response variable return values in the interval [0, 1].", "startOffset": 186, "endOffset": 192}, {"referenceID": 12, "context": "For learning the values of numerical relations, we use a slightly generalized version of the gradient graph that was introduced in [13] for parameter learning in RBNs.", "startOffset": 131, "endOffset": 135}, {"referenceID": 14, "context": "on 27 cancer patients that was originally introduced in [16], and which is often used as a standard example for logistic regression.", "startOffset": 56, "endOffset": 60}, {"referenceID": 0, "context": "Figure 2 shows the probability of the response variable as a function of the predictor variable for the parameters \u03b1, \u03b2 learned from the RBN encoding (8), and for the parameters given in [1] (which were fitted using the SAS statistics toolbox).", "startOffset": 187, "endOffset": 190}, {"referenceID": 3, "context": "Proposals for dealing with multi-relational networks often consist of reductions to the single-relational setting, either by aggregating all relations into a single weighted relations [4, 15], or by aggregating results from community detection performed for each relation separately [2].", "startOffset": 184, "endOffset": 191}, {"referenceID": 1, "context": "Proposals for dealing with multi-relational networks often consist of reductions to the single-relational setting, either by aggregating all relations into a single weighted relations [4, 15], or by aggregating results from community detection performed for each relation separately [2].", "startOffset": 283, "endOffset": 286}, {"referenceID": 5, "context": "However, clearly it is desirable to be able to distinguish node 3, which is well connected to both communities, and which for information diffusion purposes would be the most influential node in the network [6], from node 4, which is completely isolated.", "startOffset": 207, "endOffset": 210}, {"referenceID": 10, "context": "We note that in contrast to structurally similar probabilistic latent semantic models [11] the variables u(V,C), u(W,C) have no semantics as (conditional) probabilities, and (9),(10) is not a mixture model with the communities as hidden mixture components.", "startOffset": 86, "endOffset": 90}, {"referenceID": 22, "context": "We applied this model to the well known Zachary Karate Club network depicted in Figure 7 (a), where the node colors represent the known \u201cground truth\u201d communities in this network [24].", "startOffset": 179, "endOffset": 183}, {"referenceID": 9, "context": "We compare the results obtained with model (9),(10) with a slight modification of the distance model proposed in [10].", "startOffset": 113, "endOffset": 117}, {"referenceID": 2, "context": "We apply the model to the multi-relational wiring room network [3] depicted in Figure 8.", "startOffset": 63, "endOffset": 66}, {"referenceID": 2, "context": "The coloring of the nodes represent a community structure found in [3] for this network.", "startOffset": 67, "endOffset": 70}, {"referenceID": 17, "context": "To investigate the effects of learning from randomly sub-sampled data, we consider a multi-relational social network described in [19].", "startOffset": 130, "endOffset": 134}, {"referenceID": 9, "context": "5 Related Work Probabilistic latent feature models for social networks (in the single-relational setting) have been proposed in [10].", "startOffset": 128, "endOffset": 132}, {"referenceID": 18, "context": "To apply SRL modeling tools for node clustering in social network analysis has already been suggested in [20].", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "In [23] a nonparametric Bayesian model with discrete latent variables is proposed, that induces a hard partitioning of the nodes.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "That model is formulated for multi-relational networks, but only applied to single-relational ones in [23].", "startOffset": 102, "endOffset": 106}, {"referenceID": 13, "context": "Similarly, an RBN model with discrete latent variables for standard partitioning-based community detection was presented in [14].", "startOffset": 124, "endOffset": 128}], "year": 2014, "abstractText": "Most work in the area of statistical relational learning (SRL) is focussed on discrete data, even though a few approaches for hybrid SRL models have been proposed that combine numerical and discrete variables. In this paper we distinguish numerical random variables for which a probability distribution is defined by the model from numerical input variables that are only used for conditioning the distribution of discrete response variables. We show how numerical input relations can very easily be used in the Relational Bayesian Network framework, and that existing inference and learning methods need only minor adjustments to be applied in this generalized setting. The resulting framework provides natural relational extensions of classical probabilistic models for categorical data. We demonstrate the usefulness of RBN models with numeric input relations by several examples. In particular, we use the augmented RBN framework to define probabilistic models for multi-relational (social) networks in which the probability of a link between two nodes depends on numeric latent feature vectors associated with the nodes. A generic learning procedure can be used to obtain a maximum-likelihood fit of model parameters and latent feature values for a variety of models that can be expressed in the high-level RBN representation. Specifically, we propose a model that allows us to interpret learned latent feature values as community centrality degrees by which we can identify nodes that are central for one community, that are hubs between communities, or that are isolated nodes. In a multi-relational setting, the model also provides a characterization of how different relations are associated with each community.", "creator": "gnuplot 4.4 patchlevel 3"}}}