{"id": "1506.05085", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2015", "title": "Time Series Classification using the Hidden-Unit Logistic Model", "abstract": "We present a new model for time series classification, called the hidden-unit logistic model, that uses binary stochastic hidden units to model latent structure in the data. The hidden units are connected in a chain structure that models temporal dependencies in the data. Compared to the prior models for time series classification such as the hidden conditional random field, our model can model very complex decision boundaries because the number of latent states grows exponentially with the number of hidden units. We demonstrate the strong performance of our model in experiments on a variety of (computer vision) tasks, including handwritten character recognition, speech recognition, facial expression, and action recognition. We also present a state-of-the-art system for facial action unit detection based on the hidden-unit logistic model.", "histories": [["v1", "Tue, 16 Jun 2015 19:20:00 GMT  (313kb,D)", "http://arxiv.org/abs/1506.05085v1", "16 pages, 4 figures, 3 tables"], ["v2", "Tue, 19 Jan 2016 13:33:52 GMT  (315kb,D)", "http://arxiv.org/abs/1506.05085v2", "17 pages, 4 figures, 3 tables"]], "COMMENTS": "16 pages, 4 figures, 3 tables", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["wenjie pei", "hamdi dibeklio\\u{g}lu", "david m j tax", "laurens van der maaten"], "accepted": false, "id": "1506.05085"}, "pdf": {"name": "1506.05085.pdf", "metadata": {"source": "CRF", "title": "Time Series Classification using the Hidden-Unit Logistic Model", "authors": ["Wenjie Pei", "Hamdi Dibeklio\u011flu"], "emails": ["W.Pei-1@tudelft.nl", "H.Dibeklioglu@tudelft.nl", "D.M.J.Tax@tudelft.nl", "L.J.P.vanderMaaten@tudelft.nl"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to move are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 Related Work", "text": "Much of this work is based on the use of (cores based on) dynamic time shift (e.g., [8]) or hidden Markov models (HMMs) [23]. HMM is a generative model that models the time series data in a chain of latent k-nomial characteristics. Class-related HMMs are often combined with class priorities via Bayes \"rule to obtain a time series classification. Alternatively, HMMs are also commonly used as a base model for Fisher kernels [6], which construct a time series representation consisting of the gradient of a particular time series induced in the parameters of the HMM; the resulting representations can be used on standard classification models such as SVMs. Some recent work has also attempted to learn the parameters of the HMM in a way to learn Fisher kernel representations that are well suited for classification near neighbours."}, {"heading": "3 Hidden-Unit Logistic Model", "text": "The hidden unit logistics model is a probabilistic graphical model that receives a time series as an input unit and is trained to produce a single output unit for that time series. Like the hidden unit logistics model, the model contains a chain of hidden units that aim to model latent temporal characteristics in the data and form the basis for the final classification decision. The crucial difference with the HCRF is that the latent characteristics are located in H binary stochastic hidden units, similar to those in a (discriminatory) RBM. These hidden units can model a very rich latent structure in the data: one can imagine that they divide the data space into small clusters of 2H, all of which can be associated with specific clusters. The parameters of the time chains that connect the hidden units can be used to distinguish between characteristics that are \"constant\" (i.e., likely to be represented for longer time periods or \"volatile\")."}, {"heading": "3.1 Inference", "text": "The key difficulty in calculating this predictive distribution is the sum of all 2H \u00b7 T hidden unit states: M (x1,..., T,..., T, z1,..., T). (4) The chain structure of the hidden unit model allows us to apply a standard forward-backward algorithm that can calculate M (\u00b7 zt) linearly in T in computational time. (4) Specifically, the definition of potential functions that include all terms, time t and hidden unit h: t, h (xt, zt \u2212 1, h, h, y) = exp {zt \u2212 1, hAhzt, h + zt, h, hWhxt + zt zt zt zt zt, hVhy zt, hbh}, can ignore terms and introduce virtual units."}, {"heading": "3.2 Parameter Learning", "text": "Faced with a training set D = {(x (n) 1,..., T, y (n)), the parameters of which we learn using the following parameters: p (y), p (n), p (n), p (n), p (n), p (n) 1,..., T) = N (n) = 1 logM (x) 1,..., T, y (n))) \u2212 log y \u2212 M (x (n) 1,..., p (n). (6) We extend the conditional protocol (n) 1, T) = 1 logM (x (n) 1, T, y (n) \u2212 b \u2212 m (x), p (n), y \u2032). (6) We add the conditional protocol (n), p (n) 1, p (n). (n), p), p (n). (n), p (n)."}, {"heading": "4 Experiments", "text": "To evaluate the performance of the hidden unit logistics model, we conducted classification experiments on five different problems related to time series characteristics: (1) a handwritten online character set (OHC) [29]; (2) a data set of Arabic numerals (ASD) [5]; (3) the Cohn Kanade data set of extended facial expressions (CK +) [16]; (4) the MSR Action 3D data set (Action) [13]; and (5) the MSR Daily Activity 3D data set (Activity) [26]. The five data sets are presented in 4.1, the experimental setup in 4.2 and the results of the experiments in 4.3."}, {"heading": "4.1 Data Sets", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "4.2 Experimental Setup", "text": "In our experiments, the model parameters A, W, V of the hidden logistics model are initialized by scanning from a Gaussian distribution with a variance of 10 \u2212 3. Initial state parameter \u03c0, end state parameter \u03c4 and bias parameters b, c were initialized to 0. Training of our model is performed using a standardized stochastic descent procedure; the learning rate is reduced during training. We set the number of hidden units H to 100. The L2 regularization parameter was minimized by minimizing the error on a small validation set.We compare the performance of our hidden logistics model with the performance of three other time series classification models: (1) the naive logistics model shown in Figure 2, (2) the popular HCRF model [22], and (3) Fisher kernel learning model [18]."}, {"heading": "4.3 Results", "text": "We perform two sets of experiments with the hidden unit of logistics models: (1) a series of experiments in which we evaluate the performance of the model (and the hidden CRF) as a function of the number of hidden units; (2) a series of experiments in which we compare the performance of all models on all data sets; the two sets of experiments are described separately below; (3) The results of these experiments are shown in Figure 3; (a) The results presented in the figure show that the error initially decreases when the number of hidden units increases, because the addition of hidden units to the model of hidden units as a function of the hidden units; and the results of these experiments are shown in Figure 3; (a) The results presented in the figure that the number of hidden units increases are added to the model that allows the data to fit better."}, {"heading": "5 Application to Facial AU Detection", "text": "In this section, we present a facial motion detection system (AU) based on the hidden unit logistics model. We evaluate our system on the CohnKanade Extended Facial Expression Database (CK +) [16] and evaluate its ability to detect 10 prominent facial motion units: AU1, AU2, AU4, AU5, AU6, AU7, AU12, AU15, AU17 and AU25. We compare the performance of our facial motion detection system with the most advanced systems for this problem. Before describing the results of these experiments, we first describe the functional extraction of our AU recognition system and the setup of our experiments."}, {"heading": "5.1 Facial Features", "text": "We extract two types of characteristics from the video images in the CK + dataset: (1) Shape characteristics and (2) Appearance characteristics. Our characteristics are identical to the characteristics used in the system described in [17]; the characteristics are publicly available online. For the sake of completeness, we briefly describe both types of characteristics successively. The shape characteristics represent each frame by eliminating rigid transformations (translation, rotation and scale). The appearance characteristics are based on degree scale intensity values. To capture the change in the facial image, facial images are distorted to a basic shape, where characteristic points for each face are located in the same place.After this texture distortion process, the final faces are distorted by the intensity values of the initial component 17."}, {"heading": "5.2 Experimental Setup", "text": "To measure the effectiveness of the hidden unit logistics model in facial recognition, we conducted experiments with the CK + database [16]. The database consists of 593 image sequences (videos) from 123 subjects with an average length of 18.1 images. The videos show expressions from neutral face to peak formation and include annotations on 30 action units. In our experiments, we only consider the 10 most common action units. Our AU recognition system uses 10 separate binary classifiers to detect action units in the videos. In other words, we train a separate HULM for each face unit. An individual model therefore distinguishes between the presence and absence of the corresponding action unit. To measure the performance of the resulting AU recognition system, we use a 10-fold cross-validation scheme: we randomly select a test fold containing 10% of the videos and use remaining nine folds to train the system."}, {"heading": "5.3 Results", "text": "We conducted experiments with the HULM on three characteristics: (1) shape characteristics, (2) appearance characteristics and (3) concatenation of both feature vectors. We measured the performance of our system by the area below the ROC curve (AUC). Table 2 shows the results for the HULM and for the baseline in [17]. Results show that the HULM exceeds the CRF baseline of [17], with our best model achieving an AUC that is about 0.03 higher than the best result of [17]. To get an insight into which characteristics are modeled by the hidden units of the HULM, we visualized a single column of | W | in Figure 4 for the AU4 and AU25 models trained for appearance characteristics. Specifically, we chose the hidden Table 2. AUC of the HULM and the CRF baseline in [17] for three feature sets. * In [17] the combined feature set also includes SIFT."}, {"heading": "AU HULM [9] [25] [14] [15] [4] [30]", "text": "The figure shows that the appearance of the eyebrows is the most important in the AU4 model (eyebrow lowering), while the mouth area is the most important in the AU25 model (lip part).In Table 3, we compare the performance of our AU recognition system with that of seven other state-of-the-art systems in terms of the more commonly used F1 score. (Please note that the averages are not above the same AUs and cannot easily be compared.) The results in the table show that our system achieves the best F1 values for AU1, AU17 and AU25. It performs very well in most other AUs, illustrating the potential of the hidden unit logistics model."}, {"heading": "6 Conclusions", "text": "In this paper, we have introduced the Hidden Unit Logistic Model (HULM), a new model for the single-line classification of time series. Structurally, the model is similar to the popular Hidden CRF model, but it uses binary stochastic hidden units instead of multinomial hidden units between the data and the label. As a result, the HULM can model exponentially more latent states than a hidden CRF with the same number of parameters. The results of our experiments with HULM on multiple real data sets show that this can lead to improved performance in demanding time series classification tasks. In particular, the HULM works very competitively on complex computer vision problems such as recognizing facial expression. In future work, we intend to explore more complex variants of our Hidden Unit Logistic Model. In particular, we intend to study variants of the model in which simple Markov-ordered units are replaced by performance-temporally capable ones."}], "references": [{"title": "Infinite hidden conditional random fields for human behavior analysis", "author": ["K. Bousmalis", "S. Zafeiriou", "L.P. Morency", "M. Pantic"], "venue": "IEEE Transactions on Neural Networks and Learning Systems 24(1), 170\u2013177", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Variational hidden conditional random fields with coupled dirichlet process mixtures", "author": ["K. Bousmalis", "S. Zafeiriou", "L.P. Morency", "M. Pantic", "Z. Ghahramani"], "venue": "ECML PKDD. pp. 531\u2013547", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Facial action unit detection by cascade of tasks", "author": ["X. Ding", "V. Chu", "F. De la Torre", "J.F. Cohn", "Q. Wang"], "venue": "ICCV", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Improved tree model for Arabic speech recognition", "author": ["N. Hammami", "M. Bedda"], "venue": "Int. Conf. on Computer Science and Information Technology. pp. 521\u2013526", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "A discriminative framework for detecting remot protein homologies", "author": ["T. Jaakkola", "M. Diekhans", "D. Haussler"], "venue": "Journal of Computational Biology 7(1-2), 95\u2013114", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "Probability product kernels", "author": ["T. Jebara", "R. Kondor", "A. Howard"], "venue": "Journal of Machine Learning Research 5, 819\u2013844", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Spatio-temporal event classification using time-series kernel based structured sparsity", "author": ["L.A. Jeni", "A. L\u0151rincz", "Z. Szab\u00f3", "J.F. Cohn", "T. Kanade"], "venue": "ECCV. pp. 135\u2013150", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "A dynamic texture-based approach to recognition of facial actions and their temporal models", "author": ["S. Koelstra", "M. Pantic", "I. Patras"], "venue": "IEEE Trans. on PAMI 32(11), 1940\u20131954", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labelling sequence data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "ICML. pp. 282\u2013289", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "The neural autoregressive distribution estimator", "author": ["H. Larochelle", "I. Murray"], "venue": "Journal of Machine Learning Research 15, 29\u201337", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Classification using discriminative restricted boltzmann machines", "author": ["H. Larochelle", "Y. Bengio"], "venue": "ICML. pp. 536\u2013543", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Action recognition based on a bag of 3d points", "author": ["W. Li", "Z. Zhang", "Z. Liu"], "venue": "CVPR", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Data-free prior model for facial action unit recognition", "author": ["Y. Li", "J. Chen", "Y. Zhao", "Q. Ji"], "venue": "IEEE Trans. on Affective Computing 4(2), 127\u2013141", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Simultaneous facial feature tracking and facial expression recognition", "author": ["Y. Li", "S. Wang", "Y. Zhao", "Q. Ji"], "venue": "IEEE Trans. on Image Processing 22(7), 2559\u20132573", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotion-specified expression", "author": ["P. Lucey", "J. Cohn", "T. Kanade", "J. Saragih", "Z. Ambadar", "I. Matthews"], "venue": "CVPR Workshops. pp. 94\u2013101", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Action unit classification using active appearance models and conditional random fields", "author": ["L. van der Maaten", "E. Hendriks"], "venue": "Cognitive Processing 13(2), 507\u2013518", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning discriminative Fisher kernels", "author": ["L. van der Maaten"], "venue": "ICML. pp. 217\u2013224", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Hidden-unit conditional random fields", "author": ["L. van der Maaten", "M. Welling", "L. Saul"], "venue": "Int. Conf. on Artificial Intelligence & Statistics pp. 479\u2013488", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Latent-dynamic discriminative models for continuous gesture recognition", "author": ["L.P. Morency", "A. Quattoni", "T. Darrell"], "venue": "CVPR", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Conditional Neural Fields", "author": ["J. Peng", "L. Bo", "J. Xu"], "venue": "NIPS", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Hidden conditional random fields", "author": ["A. Quattoni", "S. Wang", "L.P. Morency", "M. Collins"], "venue": "IEEE Trans. on PAMI 29(10), 1848\u20131852", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proceedings of IEEE 77(2), 257\u2013286", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1989}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["J. Shotton", "A. Fitzgibbon", "M. Cook", "T. Sharp", "M. Finocchio", "R. Moore", "A. Kipman", "A. Blake"], "venue": "CVPR", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Fully automatic recognition of the temporal phases of facial actions", "author": ["M.F. Valstar", "M. Pantic"], "venue": "IEEE Trans. on SMC, Part B: Cybernetics 42(1), 28\u201343", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Mining actionlet ensemble for action recognition with depth cameras", "author": ["J. Wang", "Z. Liu", "Y. Wu", "J. Yuan"], "venue": "CVPR", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Hidden conditional random fields for gesture recognition", "author": ["S.B. Wang", "A. Quattoni", "L.P. Morency", "D. Demirdjian", "T. Darrell"], "venue": "CVPR. vol. 2, pp. 1521\u20131527", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning a discriminative hidden part model for human action recognition", "author": ["Y. Wang", "G. Mori"], "venue": "NIPS 21", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Modelling motion primitives and their timing in biologically executed movements", "author": ["B. Williams", "M. Toussaint", "A. Storkey"], "venue": "NIPS. pp. 1609\u20131616", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "A lp-norm MTMKL framework for simultaneous detection of multiple facial action units", "author": ["X. Zhang", "M.H. Mahoor", "S.M. Mavadati", "J.F. Cohn"], "venue": "IEEE Winter Conf. on Applications of Computer Vision. pp. 1104\u20131111", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 20, "context": "A state-of-the-art model for time series classification problem is the hidden-state conditional random field (HCRF) [22], which models latent structure in the data using a chain of k-nomial latent variables.", "startOffset": 116, "endOffset": 120}, {"referenceID": 25, "context": "The HCRF has been successfully used in, amongst others, gesture recognition [27], object recognition [22], and action recognition [28].", "startOffset": 76, "endOffset": 80}, {"referenceID": 20, "context": "The HCRF has been successfully used in, amongst others, gesture recognition [27], object recognition [22], and action recognition [28].", "startOffset": 101, "endOffset": 105}, {"referenceID": 26, "context": "The HCRF has been successfully used in, amongst others, gesture recognition [27], object recognition [22], and action recognition [28].", "startOffset": 130, "endOffset": 134}, {"referenceID": 10, "context": "Similar ideas have been explored before in discriminative RBMs [12] for standard classification problems and in hidden-unit CRFs [19] for sequence labeling.", "startOffset": 63, "endOffset": 67}, {"referenceID": 17, "context": "Similar ideas have been explored before in discriminative RBMs [12] for standard classification problems and in hidden-unit CRFs [19] for sequence labeling.", "startOffset": 129, "endOffset": 133}, {"referenceID": 6, "context": ", [8]) or on hidden Markov models (HMMs) [23].", "startOffset": 2, "endOffset": 5}, {"referenceID": 21, "context": ", [8]) or on hidden Markov models (HMMs) [23].", "startOffset": 41, "endOffset": 45}, {"referenceID": 4, "context": "Alternatively, HMMs are also frequently used as the base model for Fisher kernel [6], which constructs a time series representation that consists of the gradient a particular time series induces in the parameters of the HMM; the resulting representations can be used on standard classifiers such as SVMs.", "startOffset": 81, "endOffset": 84}, {"referenceID": 16, "context": "Some recent work has also tried to learn the parameters of the HMM in such a way as to learn Fisher kernel representations that are well-suited for nearest-neighbor classification [18].", "startOffset": 180, "endOffset": 184}, {"referenceID": 5, "context": "HMMs have also been used as the base model for probability product kernels [7], which fit a single HMM on each time series and define the similarity between two time series as the inner product between the corresponding HMM distributions.", "startOffset": 75, "endOffset": 78}, {"referenceID": 8, "context": "In contrast to HMMs, conditional random fields (CRFs; [10]) are discriminative models that are commonly used for sequence labeling of time series using so-called linear-chain CRFs.", "startOffset": 54, "endOffset": 58}, {"referenceID": 18, "context": "dress this limitation, amongst which are latent-dynamic CRFs [20], conditional neural fields [21], and hidden-unit CRFs [19].", "startOffset": 61, "endOffset": 65}, {"referenceID": 19, "context": "dress this limitation, amongst which are latent-dynamic CRFs [20], conditional neural fields [21], and hidden-unit CRFs [19].", "startOffset": 93, "endOffset": 97}, {"referenceID": 17, "context": "dress this limitation, amongst which are latent-dynamic CRFs [20], conditional neural fields [21], and hidden-unit CRFs [19].", "startOffset": 120, "endOffset": 124}, {"referenceID": 20, "context": "As such, it is closely related to the hidden CRF model [22].", "startOffset": 55, "endOffset": 59}, {"referenceID": 0, "context": "Inference in the iHCRF can be performed via collapsed Gibbs sampling [2] or variational inference [3].", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": "Inference in the iHCRF can be performed via collapsed Gibbs sampling [2] or variational inference [3].", "startOffset": 98, "endOffset": 101}, {"referenceID": 27, "context": "To evaluate the performance of the hidden-unit logistic model, we conducted classification experiments on five different problems involving time series features: (1) an online handwritten character data set (OHC) [29]; (2) a data set of Arabic spoken digits (ASD) [5]; (3) the Cohn-Kanade extended facial expression data set (CK+) [16]; (4) the MSR Action 3D data set (Action) [13]; and (5) the MSR Daily Activity 3D data set (Activity) [26].", "startOffset": 213, "endOffset": 217}, {"referenceID": 3, "context": "To evaluate the performance of the hidden-unit logistic model, we conducted classification experiments on five different problems involving time series features: (1) an online handwritten character data set (OHC) [29]; (2) a data set of Arabic spoken digits (ASD) [5]; (3) the Cohn-Kanade extended facial expression data set (CK+) [16]; (4) the MSR Action 3D data set (Action) [13]; and (5) the MSR Daily Activity 3D data set (Activity) [26].", "startOffset": 264, "endOffset": 267}, {"referenceID": 14, "context": "To evaluate the performance of the hidden-unit logistic model, we conducted classification experiments on five different problems involving time series features: (1) an online handwritten character data set (OHC) [29]; (2) a data set of Arabic spoken digits (ASD) [5]; (3) the Cohn-Kanade extended facial expression data set (CK+) [16]; (4) the MSR Action 3D data set (Action) [13]; and (5) the MSR Daily Activity 3D data set (Activity) [26].", "startOffset": 331, "endOffset": 335}, {"referenceID": 11, "context": "To evaluate the performance of the hidden-unit logistic model, we conducted classification experiments on five different problems involving time series features: (1) an online handwritten character data set (OHC) [29]; (2) a data set of Arabic spoken digits (ASD) [5]; (3) the Cohn-Kanade extended facial expression data set (CK+) [16]; (4) the MSR Action 3D data set (Action) [13]; and (5) the MSR Daily Activity 3D data set (Activity) [26].", "startOffset": 377, "endOffset": 381}, {"referenceID": 24, "context": "To evaluate the performance of the hidden-unit logistic model, we conducted classification experiments on five different problems involving time series features: (1) an online handwritten character data set (OHC) [29]; (2) a data set of Arabic spoken digits (ASD) [5]; (3) the Cohn-Kanade extended facial expression data set (CK+) [16]; (4) the MSR Action 3D data set (Action) [13]; and (5) the MSR Daily Activity 3D data set (Activity) [26].", "startOffset": 437, "endOffset": 441}, {"referenceID": 27, "context": "1 Data Sets The online handwritten character dataset [29] is a pen-trajectory time series data set that consists of three dimensions at each time step, viz.", "startOffset": 53, "endOffset": 57}, {"referenceID": 3, "context": "The Arabic spoken digit dataset contains 8800 utterances [5], which were collected by asking 88 Arabic native speakers to utter all 10 digits ten times.", "startOffset": 57, "endOffset": 60}, {"referenceID": 14, "context": "The Cohn-Kanade extended facial expression data set [16] contains 593 image sequences (videos) from 123 subjects.", "startOffset": 52, "endOffset": 56}, {"referenceID": 15, "context": "We adopt the publicly available shape features used in [17] as the feature representation for our experiments.", "startOffset": 55, "endOffset": 59}, {"referenceID": 14, "context": "These features represent each frame by the variation of 68 feature point locations (x, y) with respect to the first frame [16], which leads to 136-dimensional feature representation for each frame in the video.", "startOffset": 122, "endOffset": 126}, {"referenceID": 11, "context": "The MSR Action 3D data set [13] consists of RGB-D videos of people performing certain actions.", "startOffset": 27, "endOffset": 31}, {"referenceID": 22, "context": "We use the real-time skeleton tracking algorithm of [24] to extract the 3D joint positions from the depth sequences.", "startOffset": 52, "endOffset": 56}, {"referenceID": 24, "context": "We use the 3D joint position features (pairwise relative positions) proposed in [26] as the feature representation for the frames in the videos.", "startOffset": 80, "endOffset": 84}, {"referenceID": 24, "context": "The MSR Daily Activity 3D data set [26] contains RGB-D videos of people performing daily activities.", "startOffset": 35, "endOffset": 39}, {"referenceID": 20, "context": "We compare the performance of our hidden-unit logistic model with that of three other time series classification models: (1) the naive logistic model shown in Figure 2, (2) the popular HCRF model [22], and (3) Fisher kernel learning model [18].", "startOffset": 196, "endOffset": 200}, {"referenceID": 16, "context": "We compare the performance of our hidden-unit logistic model with that of three other time series classification models: (1) the naive logistic model shown in Figure 2, (2) the popular HCRF model [22], and (3) Fisher kernel learning model [18].", "startOffset": 239, "endOffset": 243}, {"referenceID": 20, "context": "The hidden-state CRF\u2019s graphical model is very similar to that of the hidden-unit logistic model [22].", "startOffset": 97, "endOffset": 101}, {"referenceID": 20, "context": "Following [22], we trained HCRFs with 10 latent states on all data sets.", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "In addition to comparing with HCRFs, we compare the performance of our model with that of the recently proposed Fisher kernel learning (FKL) model [18].", "startOffset": 147, "endOffset": 151}, {"referenceID": 16, "context": "We selected the FKL model for our experiments because [18] reports strong performance on a range of time series classification problems.", "startOffset": 54, "endOffset": 58}, {"referenceID": 20, "context": "In our experiments, the number of hidden units in the hiddenunit logistic model was set to 100; following [22], the hidden CRF used 10 latent", "startOffset": 106, "endOffset": 110}, {"referenceID": 16, "context": "Following the experimental setup in [18], we measure the generalization error of all our models on the online handwritten character dataset using 10-fold cross validation.", "startOffset": 36, "endOffset": 40}, {"referenceID": 3, "context": "Following [5], the error rates for the Arabic spoken digits data set in Table 1 were measured using a fixed training/test division: 75% of samples are used for training and left 25% of samples compose test set.", "startOffset": 10, "endOffset": 13}, {"referenceID": 3, "context": "88% reported in [5] (on the same training/test division).", "startOffset": 16, "endOffset": 19}, {"referenceID": 24, "context": "To measure the generalization error of the time series classification models on the MSR Action 3D dataset, we followed the experimental setup of [26]: we used all videos of the five subjects for training, and used the videos of the remaining five subjects for testing.", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "We evaluate our system on the CohnKanade extended facial expression database (CK+) [16], evaluating its ability to detect 10 prominent facial action units: namely, AU1, AU2, AU4, AU5, AU6, AU7, AU12, AU15, AU17, and AU25.", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "Our features are identical to the features used by the system described in [17]; the features are publicly available online.", "startOffset": 75, "endOffset": 79}, {"referenceID": 15, "context": "For further details on the feature extraction, we refer to [17].", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "To gauge the effectiveness of the hidden-unit logistic model in facial AU detection, we performed experiments on the CK+ database [16].", "startOffset": 130, "endOffset": 134}, {"referenceID": 15, "context": "Table 2 shows the results for HULM, and for the baseline in [17].", "startOffset": 60, "endOffset": 64}, {"referenceID": 15, "context": "The results show that the HULM outperforms the CRF baseline of [17], with our best model achieving an AUC that is approximately 0.", "startOffset": 63, "endOffset": 67}, {"referenceID": 15, "context": "03 higher than the best result of [17].", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "AUC of the HULM and the CRF baseline in [17] for three feature sets.", "startOffset": 40, "endOffset": 44}, {"referenceID": 15, "context": "*In [17], the combined feature set also includes SIFT features.", "startOffset": 4, "endOffset": 8}, {"referenceID": 15, "context": "9253 [17] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 7, "context": "AU HULM [9] [25] [14] [15] [4] [30] 1 0.", "startOffset": 8, "endOffset": 11}, {"referenceID": 23, "context": "AU HULM [9] [25] [14] [15] [4] [30] 1 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 12, "context": "AU HULM [9] [25] [14] [15] [4] [30] 1 0.", "startOffset": 17, "endOffset": 21}, {"referenceID": 13, "context": "AU HULM [9] [25] [14] [15] [4] [30] 1 0.", "startOffset": 22, "endOffset": 26}, {"referenceID": 2, "context": "AU HULM [9] [25] [14] [15] [4] [30] 1 0.", "startOffset": 27, "endOffset": 30}, {"referenceID": 28, "context": "AU HULM [9] [25] [14] [15] [4] [30] 1 0.", "startOffset": 31, "endOffset": 35}, {"referenceID": 9, "context": "Specifically, we intend to implement the higher-order chains via a similar factorization as used in neural autoregressive distribution estimators [11].", "startOffset": 146, "endOffset": 150}], "year": 2017, "abstractText": "We present a new model for time series classification, called the hidden-unit logistic model, that uses binary stochastic hidden units to model latent structure in the data. The hidden units are connected in a chain structure that models temporal dependencies in the data. Compared to the prior models for time series classification such as the hidden conditional random field, our model can model very complex decision boundaries because the number of latent states grows exponentially with the number of hidden units. We demonstrate the strong performance of our model in experiments on a variety of (computer vision) tasks, including handwritten character recognition, speech recognition, facial expression, and action recognition. We also present a state-of-the-art system for facial action unit detection based on the hidden-unit logistic model.", "creator": "LaTeX with hyperref package"}}}