{"id": "1506.05514", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2015", "title": "Learning Contextualized Semantics from Co-occurring Terms via a Siamese Architecture", "abstract": "One of the biggest challenges in Multimedia information retrieval and understanding is to bridge the semantic gap by properly modeling concept semantics in context. The presence of out of vocabulary (OOV) concepts exacerbates this difficulty. To address the semantic gap issues, we formulate a problem on learning contextualized semantics from descriptive terms and propose a novel Siamese architecture to model the contextualized semantics from descriptive terms. By means of pattern aggregation and probabilistic topic models, our Siamese architecture captures contextualized semantics from the co-occurring descriptive terms via unsupervised learning, which leads to a concept embedding space of the terms in context. Furthermore, the co-occurring OOV concepts can be easily represented in the learnt concept embedding space. The main properties of the concept embedding space are demonstrated via visualization. Using various settings in semantic priming, we have carried out a thorough evaluation by comparing our approach to a number of state-of-the-art methods on six annotation corpora in different domains, i.e., MagTag5K, CAL500 and Million Song Dataset in the music domain as well as Corel5K, LabelMe and SUNDatabase in the image domain. Experimental results on semantic priming suggest that our approach outperforms those state-of-the-art methods considerably in various aspects.", "histories": [["v1", "Wed, 17 Jun 2015 23:03:43 GMT  (2055kb)", "http://arxiv.org/abs/1506.05514v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.LG", "authors": ["ubai sandouk", "ke chen"], "accepted": false, "id": "1506.05514"}, "pdf": {"name": "1506.05514.pdf", "metadata": {"source": "CRF", "title": "Learning Contextualized Semantics from Co-occurring Terms via a Siamese Architecture", "authors": ["Ke Chen", "Ubai Sandouk"], "emails": ["UBAI.SANDOUK@MANCHESTER.AC.UK", "CHEN@CS.MANCHESTER.AC.UK"], "sections": [{"heading": null, "text": "\u00a9 2015 Ubai Sandouk and Ke Chenthe semantic gap through correct modeling of conceptual semantics in context. The presence of concepts without vocabulary (OOV) exacerbates this difficulty. To address the problems of the semantic gap, we formulate a problem in learning contextualized semantics from descriptive terms and propose a novel Siamese architecture to model contextualized semantics from descriptive terms. Furthermore, our Siamese architecture, through pattern aggregation and probabilistic theme models, captures the contextualized semantics from the commonly occurring descriptive concepts through unattended learning, leading to a concept that embeds the space of concepts in the context. Furthermore, the commonly occurring OOV concepts can easily be represented in the learned concept that embeds space. Visualization dismantles the main features of the concept that embeds space."}, {"heading": "1 Introduction", "text": "In fact, it is such that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is"}, {"heading": "2 Related Work", "text": "In this section, we review relevant work in the field of semantics from descriptive terms, independent of specific multimedia tasks. In terms of semantics from descriptive terms, these approaches fall into one of three different categories: global relations, syntactic relations, and contextualized relations as shown in Figure 1."}, {"heading": "2.1 Global Relatedness", "text": "In fact, most of us will be able to put ourselves in a different world, in which they are able to change the world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2.2 Syntactic Relatedness", "text": "In natural languages, context is explicitly present in the order of words, i.e. in the syntactic context. This dependence between sequences of words helps to grasp the relationship of words in context and thus the understanding of basic linguistic meanings. To grasp syntactic kinship, recently distributed language models have been proposed (Mikolov et al., 2010; Collobert et al., 2011; Mikolov et al., 2013). Such models learn syntactic kinship from linguistic corpora and produce a distributed semantic space in which all words are duly embedded based on their syntactic similarity (Mikolov et al., 2010). During learning, an architecture is trained to predict a missing word in a particular context, i.e. to predict nearby words or possible context words with a word."}, {"heading": "2.3 Contextualized Relatedness", "text": "This often hampers the applicability of such learned models as generic semantics providers. Here, we review a number of approaches that can potentially capture the contextual relativization that is examined in this paper, but end up with a documentary representation! Topic models are a class of statistical methods used for semantic analysis and modeling. In general, a theme model makes use of latent processes to capture occurrences in the form of statistical distributions over observed terms. If a specific term appears in more than one document that exhibits different patterns of sharing with other terms, it could be associated with other topics than with different patterns of meaning in the form of statistical distributions over observed terms."}, {"heading": "3 Term, Local Context and Document Representation", "text": "In this section, we describe the feature extraction for the descriptive term, local context and document representation used in our approach to facilitate the presentation of our proposed Siamese architecture in the next section."}, {"heading": "3.1 Term Representation", "text": "In general, terms can be characterized by either ID-based or statistical representations. An ID-based representation uses a scheme that is directly associated with the ID in symbol form, i.e., a separate unit for each term. A statistical representation uses statistical analysis of the use of the tag within the data set. ID-based representations of terms are often used in earlier contextualized models, such as the CRBM model (Mandel et al., 2011). However, the capacity of an ID-based representation can be limited, making it difficult to accommodate new terms, and it can also impose an unnatural order of terms, such as a numerical ID index representation. Therefore, we use a statistical representation (Markines et al., 2009) in which each descriptive term is presented as a summary of its paired formation with all terms."}, {"heading": "3.2 Local Context Representation", "text": "As described in Section 1, the local context of each term is acquired by taking into account all coexisting terms in the same document. Generally, each document consists of a coherent set of descriptive terms. Without human knowledge and intervention, it is impossible to divide accompanying terms in a document into coherent subgroups of terms. Therefore, a local context representation must be derived from the entire document of cooperative terms. An ideal local context representation should be semantically consistent across documents and easily assessed in real-world applications, such as auto-tag annotation. Obviously, for a document, its uniform representation from the document list is unable to measure similarities between documents and is also subject to generalization. In the recent work of Law, Settles & Mitchell (2010), Latent Direchlet Allocation (LDA) was used to represent terms in the form of topics, and then a model was trained to map the acoustic content to the thematic representation to facilitate hierarchical hierarchy."}, {"heading": "3.3 Document Representation", "text": "In addition to term and local context representations, our approach introduced in the next section also requires a representation of an entire document. In our work, we take the bag of words (BoW) representation of a document referred to by lmn, a binary, sparse feature vector of entries for a given vocabulary in which the entry corresponds to a specific term. Thus: lmn [,] = V1 X (2 & # (& + Y, 2 0 * '(+ X, Y. (. (. (4) In summary, we use the' 3, S3-based aggregation as our term representation to encode the global term contexts, the LDA as our local context representation to summarize semantic coherence in different documents, and the BoW as document representation in our learning model presented in the next section."}, {"heading": "4 Model Description", "text": "In this section we will find a solution to the problem described in Section 1. We will first describe our motivation behind our proposed Siamese architecture and then present its architecture and a two-step algorithm for learning contextualized semantics using descriptive terms. Finally, we will propose two methods to deal with contextualized semantic embedding using the OOV terms based on the space of representation generated by our Siamese architecture."}, {"heading": "4.1 Motivation", "text": "In fact, it is so that most of them are able to move around without being able to see themselves moving around. Most of them are able to move around. Most of them are not able to move around. Most of them are not able to move around. Most of them are able to move around in a position to move around. Most of them are able to move around in a position to move around."}, {"heading": "4.2 Architecture", "text": "As illustrated in Figure 2, the proposed Siamese architecture consists of two identical subnetworks. Each subnetwork is an advanced neural network consisting of hidden layers and two visible layers marked in green; i.e., input and output layers. Each subnetwork receives representations of a term and its local context |, collectively referred to by q, =, |, as input and output a prediction of the BoW representation of all terms in, lmn, in the document from which and | were extracted. Two subnetworks are coupled and trained through a two-step learning process. In the first stage, a subnetwork is trained to perform the prediction task for an initial semantic embedding. As a result, this subnetwork is trained to predict the BoW representation of the ofa document, lmn, based on the input characteristics of a tag and its local context, q."}, {"heading": "4.3 Learning Algorithm", "text": "For the number of layers in a subnetwork, the output is wx q = y Rx. wxO q + {x, 1 \u2264 \u2264 t, where Rx, {x are the weights and bias vectors for the} x layer of the network, y is the elementary hyperbolic tangent function: y ~ = _ O _ _ _. We specify that w q = q specifies the input layer, q = wsO q is the contextualized semantic representation vector, i.e. the output of the t \u2212 1 uv hidden layer, and q = ws q is the prediction vector provided by the output layer. In the following, we will drop all explicit parameters to simplify the representation, e.g. an abbreviated version of ~, and [] represents the input of the vector."}, {"heading": "4.3.1 Training Data", "text": "For learning, we need to create training examples based on different documents in a set of terms or collections used for training. In the face of a training document consisting of coinciding terms, we create training examples where each example is a focused term in a document with the same local context, i.e. the terms in the document. The predictive goal for all examples is the same, i.e. the document representation of this training document mn. We observed that in training for prediction, the local context may prevail over the initial semantic embedding and therefore cause all terms in the same document to have very similar representations, regardless of whether they are meaningfully coherent. As a result, we need to address this problem by introducing negative examples. Considering a training document, we synthesize a negative example by randomly coupling a term that is not included in all terms and use it to form its local context."}, {"heading": "4.3.2 Prediction Learning", "text": "To learn the prediction in the first stage, a subnetwork is initialized with the known uncontrolled, greedy, layer-by-layer learning process, the building block of which is the sparse auto-encoder (Bengio et al., 2007). After initializing a subnetwork of t \u2212 1 hidden layers, the subnetwork is refined by applying the document presentation labels. The learning algorithm for sparse auto-encoders can be found in the appendix. The binary nature of the output makes the cross-entropy loss suitable for this task. Given the entire training data set, examples generated from the documents and a vocabulary of terms, the initial prediction loss should be defined by."}, {"heading": "4.3.3 Distance Learning", "text": "In fact, it is a way in which people are able to determine for themselves what they want and what they want."}, {"heading": "4.4 OOV Term Contextualized Embedding", "text": "In this context, it should be noted that this project is a project, which is a project that is primarily a project, which is a project that is primarily a project."}, {"heading": "5 Experiments on Concept Embedding Learning", "text": "In this section, we describe the experimental settings and visualize the results in terms of using our Siamese architecture to learn the concept of embedding, the CE space, from a number of corpora in different areas. First, we describe all the corpora used in our work, including the semantic priming application presented in the next section. Then, we give the details of our experimental environments in CE learning. Finally, we visualize the contextualized semantic representations of terms that our Siamese architecture learns to demonstrate the most important properties underlying the representations."}, {"heading": "5.1 Data sets", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country."}, {"heading": "5.2 Experimental Settings", "text": "Now, we describe the experimental settings in the training of our Siamese architecture based on three training studies: CAL500, MagTag5K and Corel5K. For function extraction, we have used the methods described in Section 3 to generate the term, local context and document representation from each document. We can select the characteristic vectors of each in-vocabulary term using Equation 2 and generate the representation of OOV terms in a manner similar to those described in Section 4.4. In our experiments, the decoration of characteristics with PCA and the linear scaling of each characteristic was applied to the term and local context representations to ensure that each characteristic is applied in the area (-1, + 1). By applying Equation 3, the local context characteristics of a document were decided on the basis of an extracted LDA work on all the more active terms in the document. To achieve a LDA model, we decided to use the top data of all documents in a training document."}, {"heading": "5.3 Visualization of Concept Embedding", "text": "After the completion of the two-step learning, a trained sub-network represents a 10-dimensional representation for each given term along with its local context. By using the unattended t-SNE (Maaten & Hinton, 2008), we can consciously visualize the representations that we have learned from the training corpora, by projecting the 10-dimensional representation into a two-dimensional space. \"Thanks to the powerful non-linear dimensionality reduction capacity of the t-SNE,\" we expect that the visualization \"the main characteristics of the contextual semantics and relativity that we of the training corporations porporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporporpor"}, {"heading": "6 Application to Semantic Priming", "text": "Semantic priming is an application that relies directly on this semantics without requiring access to content or other media-related information (Lund & Burgess, 1996; Osgood, 1952).Because priming emphasizes the versatility of semantics from an abstract point of view, it provides invaluable insight into the performance of a semantic model regardless of different applications.Therefore, we use this generic task to evaluate the performance of our proposed approach based on the data sets described in Section 5.1 and compare ours with a range of modern methods for learning semantics from cooperating terms for a thorough assessment."}, {"heading": "6.1 Semantic Priming and Evaluation", "text": "This abstract process is often used to evaluate the learned semantics and demonstrate the performance of a semantic learning model (Lund & Burgess, 1996). Ideally, coherent terms should be correctly assigned based on the contextualized semantics inherent in them. To do this, a semantic learning model must resolve the highly nonlinear relationship between terms and contexts by capturing the intentions behind these observed terms as accurately as possible. Thus, the semantic priming task becomes a suitable test bed for evaluating the capabilities of a semantic learning model by measuring the relations of terms in different scenarios, such as the applicability to new documents, the incomplete context, and the presence of OOV terms. Below, we present the priming protocol used in assessing a semantic representation based on terms, and then we can apply this model at a fairly precise level so that we extend the existing semantic terms to the semantic one."}, {"heading": "6.1.1 Priming Protocol", "text": "In fact, the individual terms used in the individual terms can be divided in their entirety into two groups that are related to each other. [...] The semantic terms are designed to be used in different terms depending on the context. [...] The semantic terms function as a very generic evaluation method for learned semantics without access to information other than the learned semantics itself. [...] The semantic terms are designed to be used in their entirety in two groups. [...] The semantic terms are designed to refer in their entirety to different terms. [...] The semantic terms are designed to be applied in their entirety to different terms. [...] The semantic terms are designed to be applied in their entirety to different terms. [...] The semantic terms are designed to be applied in their entirety to different terms."}, {"heading": "6.1.2 Extended Priming Protocol", "text": "The priming protocol specified in Section 6.1.1 is used to evaluate a contextualized semantic learning model that requires the information in an entire document. However, it seems unfair to compare a contextualized semantic learning model with those that only work on a single term without access to document-level information. To allow us to compare ours with more modern semantic learning models, we extend the priming protocol defined in Section 6.1.1 by allowing all semantic learning models to use exactly the same information that is transmitted in an entire document in semantic priming. Therefore, each model is provided with a complete document and the collective priming models in this query document."}, {"heading": "6.1.3 Priming Accuracy", "text": "In general, priming performance is measured by the accuracy indicated by the number of terms used in the vocabulary; the accuracy when only the top entries in a ranking list are taken into account, which are based on a ranking that is altogether less than the number of terms used in the vocabulary. (In this context, we refer to the top entries in a priming list based on a priming list based on a priming protocol (c.f. Equation 8) or M _ \u00b3 +, (= in the extended priming protocol (c.f. Eq. 9). For a document, the priming list based on a priming list is defined by a priming protocol. (~ = \u00c5 \u00b3 +, for the priming protocol M _ \u00b3 +, (~ = for the extended priming protocol). (~ = for the extended priming protocol) Then \u00b3 @; precision is defined as the ratio of the primed terms in the query, i.e. in the document truth (i.e., in the query)."}, {"heading": "6.2 Experimental Protocols", "text": "For a thorough performance assessment of semantic priming, we have designed a series of experiments in different environments that correspond to several real scenarios to test the learned semantic representations, including: a) domain-specific semantics: testing all documents used in the training of a model and those invisible documents in the same corpus; i.e. a subset of documents was not used in the training; b) portability: testing on the different corpora in which none of the documents in this corpora was used in the training; c) loud data: testing for incomplete local context; d) OOV data: testing on synthesized and real documents of OOV terms; and e) comparison: comparing ours with those semantic learning models that were tested in Section 2 with exactly the same settings. As described in Section 5.2, we performed cross-validation in the training of a semantic model for three studies."}, {"heading": "6.2.1 Within-Corpus Setting", "text": "The setting within the corpus refers to the evaluation that the training materials or reserved test documents from the training corpora use (see Section 5.1), i.e. CAL500, MagTag5K and Corel5K. The use of training materials in this setting is intended to test the quality of the semantics that a model learns with respect to this application. Furthermore, the measurement of the priming accuracy on the train documents mimics a real scenario in which all available information is used to build a semantic space that can later be used in a variety of applications. On the other hand, by using the test document subset in this setting, we would evaluate the generalization of the learned semantics into invisible documents that were likely commented by the same group of users. We speak of such an evaluation as within the corpus test (WCT) and expect that this setting would examine the quality and generalization of the learned semantics in a sector-specific sense."}, {"heading": "6.2.2 Cross-Corpora Setting", "text": "Unlike the WCT, we design experiments to test invisible documents in corpora that have never been used in semantic learning. We call this type of assessment a cross-corporation test (CCT), and as a result, the CCT would investigate the transferability of learned semantics to this application. In our CCT experiments, semantic representations purchased on MagTag5K were applied to documents in Million Song Dataset (MSD), and those purchased on Corel5K to documents in LabelMe and SUNDatabase. As described in Section 5.1, we must limit test documents to those that contain only the in-vocabulary found in a training corpus. As a result, there are 817, 520 and 266 suitable test documents in MSD, LabelMe and SUNDatabase, respectively."}, {"heading": "6.2.3 Incomplete Local Context Setting", "text": "In order to achieve a contextualized semantic representation of a term, both the term and its local context, i.e. all terms in the document containing it, as described in our problem formulation in Section 1, must be removed. In real applications, a test document could not match the training data. For example, it could be a subset of a training document, using less informative terms or an extended version of a training document by adding more coherent terms. In this constellation, we would design experiments to test incorrectly matching documents. As argued in Section 6.1.1, it does not seem possible to achieve all the different concepts and their similarities in all possible contexts. Therefore, it is impossible for us to simulate from an in-match situation that more coherent terms are added to existing documents. Fortunately, we can simulate the other in-match situation, incomplete local contexts by removing some terms from existing documents."}, {"heading": "6.2.4 Out of Vocabulary (OOV) Setting", "text": "Based on our proposed approach, we have proposed two methods of dealing with OOV terms as described in Section 4.4. In this reserved subset, there are 1,160 documents in which each of them contains at least one of the 22 reserved terms used as simulated OOV terms. Their concept representations, derived from the semantic model trained on MagTag5K, have been used in semantic priming. In addition, we have also used the real documents that contain OOV terms in the test societies (see our CCT setting in Section 6.2.2). Consequently, there are 39,507 documents that contain OOV terms, the OOV terms in the MSD, 8,703 documents of the OOV terms in the LabelMe, and 11,935 documents that contain OOV terms."}, {"heading": "6.2.5 Comparison Settings", "text": "In fact, it is more than just a question of whether and in what form people will be able to survive themselves, and it is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question of how far they are able to survive themselves. (...) It is a question, it is a question of how far they are able to survive themselves. (...) () () () (() weighs (...) (). () () (()) ((()) ((())) ((()). ((()) (()) ((()). ((())"}, {"heading": "6.3 Within-Corpus Results", "text": "With the experimental setting described in Section 6.2.1 we report on the experimental results of the WCT on three training bodies: MagTag5K, CAL500 and Corel5K in the sense of two priming protocols."}, {"heading": "6.3.1 Priming Results", "text": "In fact, most of them will be able to play by the rules that they have shown over the last five years, and they will be able to play by the rules."}, {"heading": "6.3.2 Extended Priming Results", "text": "In fact, you have to be able to go to another world, you have to go to another world, you have to go to another world, you have to go to another world, you have to go to another world, you have to go to another world, you have to go to another world, you have to go to another world, you have to be able to create a new world, you have to be able to create a new world, you have to be able to create a new world, you have to be able to create a new world."}, {"heading": "6.4 Cross-Corpora Results", "text": "In the CCT experiments, we apply the semantic representation achieved by a model trained on a corpus to another collection of semantic priming tests. Here, we report on the results for the semantics trained on MagTag5K and applied to MSD, as well as for those trained on Corel5K and applied to LabelMe and SUNDatabase in the form of two priming protocols."}, {"heading": "6.4.1 Priming Results", "text": "In fact, most of them are able to assert themselves, they are able to assert themselves, and they are able to assert themselves, and they are able to assert themselves."}, {"heading": "6.4.2 Extended Priming Results", "text": "Figure 15 shows the enhanced primary results of nine different models with respect to four evaluation criteria defined in Section 6.1.3.Figures 15 (a) and 15 (b) illustrate the enhanced primary results on MSD. Compared to the performance on the test subset on MagTag5K shown in Figures 11 (c) and 11 (d), all models, including our poor performance, demonstrate the challenge in transferable semantics with limited training data. It is observed that LSA wins the best in the AUC. Generally, our model leads to better results in large, and high recall rates, while LSA performs others in small ranges; and low recall rates in the CE always outperform."}, {"heading": "6.5 Incomplete Local Context Results", "text": "In the incomplete local context experiments, we randomly remove a number of terms from an evaluation document to synthesize an incomplete local context with three missing rates, up to 10%, between 10% and 30%, and between 30% and 50%, as described in Section 6.2.3. The subsets of training in MagTag5K, CAL500, and Corel5K are used in this experimental environment, and we report on the experimental results in terms of priming and advanced priming protocols. It is also worth noting that the CRBM is not generally suitable, as its local context is the ID of a query document and therefore cannot be distorted. However, we only use the CRBM in the extended priming protocol, although its local context is not distorted."}, {"heading": "6.5.1 Priming Results", "text": "The results of the study show that the use of incomplete local contexts leads to a deterioration of the performance of our model due to information loss. In comparison, the performance of Siam-CE in Figure 16 is lower than that of Figure 8 (a) and 8 (b) and of 1%, 7% and 13% in the absence of three missing rates. In particular, the incomplete local contexts lead to a deterioration of performance at a low level. In contrast, two PTMs, LDA and PLSA show their robust performance in relation to the incomplete documents."}, {"heading": "6.5.2 Extended Priming Results", "text": "In this context, it should be noted that the measures in question are measures that have been taken in recent years to take measures to stop climate change."}, {"heading": "6.6 Out of Vocabulary Results", "text": "In fact, most of them will be able to move in a particular direction in which they want to go."}, {"heading": "7 Discussion", "text": "This year, it has reached the stage where it will be able to put itself at the forefront in order to embark on the path to the future."}, {"heading": "8 Conclusion", "text": "In our approach, we have formulated the problem in such a way that we learn contextualized concept-based semantic representation by embedding concepts in the space of representation. As a result, we have proposed a solution by developing a novel Siamese architecture of deep neural networks and a two-step learning algorithm. Furthermore, we have included the OOV problems in our solution. By means of visualization, we have demonstrated that our approach can capture domain-specific and transferable contextualized semantics conveyed in cooperative terms. In addition, we have applied our approach to semantic priming, a benchmark information retrievaluation task. We have conducted a thorough evaluation via a comparative study with different settings. Experimental results indicate that our approach exceeds a number of state-of-the-art approaches and the effectiveness of our proposed OV methods in terms of information representation."}, {"heading": "Appendix A. Learning Algorithm Details", "text": "In this appendix, we derive the learning algorithms used to train our proposed Siamese architecture. In order to minimize the loss functions defined for prediction and remote metric learning in Section 4 of the main text, we apply the stochastic back propagation (SBP) algorithm for parameter estimation. In order to establish a deep subnetwork for the prediction function, the prediction function is performed in a manner in which the individual levels perform the weights using a quasi-Newton method as described in Section A.1. In Section A.2 and A.3, we present the derivation of loss functions in relation to relevant parameters used to form a subnetwork for the formation of the Siamese architecture for the removal of metric learning. Finally, we sum up the SBP algorithms that can be used in the formation of a subnet for the prediction function and the Siamese architecture."}], "references": [{"title": "Mining association rules between sets of items in large databases", "author": ["R. Agrawal", "T. Imielinski", "A. Swami"], "venue": "In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Agrawal et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 1993}, {"title": "The million song dataset", "author": ["T. Bertin-mahieux", "D. Ellis", "B. Whitman", "P. Lamere"], "venue": "In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR", "citeRegEx": "Bertin.mahieux et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bertin.mahieux et al\\.", "year": 2011}, {"title": "Latent Dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Learning structured embeddings of knowledge bases", "author": ["A. Bordes", "J. Weston", "R. Collobert", "Y. Bengio"], "venue": "In Conference on Artificial Intelligence", "citeRegEx": "Bordes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2011}, {"title": "Stochastic Gradient Descent Tricks", "author": ["L. Bottou"], "venue": null, "citeRegEx": "Bottou.,? \\Q2012\\E", "shortCiteRegEx": "Bottou.", "year": 2012}, {"title": "From machine learning to machine reasoning: an essay", "author": ["L. Bottou"], "venue": "Machine Learning,", "citeRegEx": "Bottou.,? \\Q2014\\E", "shortCiteRegEx": "Bottou.", "year": 2014}, {"title": "Signature verification using a \u201cSiamese\u201d time delay neural network", "author": ["J. Bromley", "J. Bentz", "L. Bottou", "I. Guyon", "Y. Lecun", "C. Moore", "E. S\u00e4ckinger", "R. Shah"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "Bromley et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Bromley et al\\.", "year": 1993}, {"title": "Next-Generation content representation, creation, and searching for new-media applications in education", "author": ["S. Chang", "A. Eleftheriadis", "R. Mcclintock"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Chang et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Chang et al\\.", "year": 1998}, {"title": "Learning speaker-specific characteristics with a deep neural architecture", "author": ["K. Chen", "A. Salman"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Chen and Salman.,? \\Q2011\\E", "shortCiteRegEx": "Chen and Salman.", "year": 2011}, {"title": "Learning a similarity metric discriminatively, with application to face verification", "author": ["S. Chopra", "R. Hadsell", "Y. LeCun"], "venue": "In Conference on Computer Vision and Pattern Recognition", "citeRegEx": "Chopra et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Chopra et al\\.", "year": 2005}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Indexing by latent semantic analysis", "author": ["S. Deerwester", "G. Furnas", "T. Landauer", "R. Harshman"], "venue": "Journal of the American Society for Information Science,", "citeRegEx": "Deerwester et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Deerwester et al\\.", "year": 1990}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of the Royal Statistical Society. Series B (methodological),", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary", "author": ["P. Duygulu", "K. Barnard", "N. de Freitas", "D. Forsyth"], "venue": "In Conference on Computer Vision and Pattern Recognition", "citeRegEx": "Duygulu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Duygulu et al\\.", "year": 2002}, {"title": "Euclidean embedding of co-occurrence data", "author": ["A. Globerson", "G. Chechik", "F. Pereira", "P. Tishby"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Globerson et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Globerson et al\\.", "year": 2007}, {"title": "Distributional structure", "author": ["Z. Harris"], "venue": "WORD-Journal of the International Linguistic Association,", "citeRegEx": "Harris.,? \\Q1954\\E", "shortCiteRegEx": "Harris.", "year": 1954}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["G. Hinton"], "venue": "Neural Computation,", "citeRegEx": "Hinton.,? \\Q2002\\E", "shortCiteRegEx": "Hinton.", "year": 2002}, {"title": "Probabilistic latent semantic indexing", "author": ["T. Hofmann"], "venue": "Proceedings of the 22nd ACM SIGIR Conference on Research and Development in Information Retrieval", "citeRegEx": "Hofmann.,? \\Q1999\\E", "shortCiteRegEx": "Hofmann.", "year": 1999}, {"title": "MCGraph: Multi-criterion representation for scene understanding", "author": ["M. Hueting", "A. Monszpart", "N. Mellado"], "venue": "In SIGGRAPH Asia 2014 Workshop on Indoor Scene Understanding: Where Graphics Meets Vision,", "citeRegEx": "Hueting et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hueting et al\\.", "year": 2014}, {"title": "Multimedia information retrieval: What is it, and why isn\u2019t anyone using it", "author": ["A. Jaimes", "M. Christel", "S. Gilles", "R. Sarukkai", "W. Ma"], "venue": "In Proceedings of the 7th ACM SIGMM International Workshop on Multimedia Information Retrieval,", "citeRegEx": "Jaimes et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Jaimes et al\\.", "year": 2005}, {"title": "Cognition-based semantic annotation for web images", "author": ["J. Jing", "A. Luo", "J. Xuan", "W. Liu"], "venue": "In 4th International Conference on Big Data and Cloud Computing,", "citeRegEx": "Jing et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jing et al\\.", "year": 2014}, {"title": "Contextual music information retrieval and recommendation: State of the art and challenges", "author": ["M. Kaminskas", "F. Ricci"], "venue": "Computer Science Review,", "citeRegEx": "Kaminskas and Ricci.,? \\Q2012\\E", "shortCiteRegEx": "Kaminskas and Ricci.", "year": 2012}, {"title": "The state of the art in tag ontologies: A semantic model for tagging and folksonomies", "author": ["H.L. Kim", "S. Scerri", "J. Breslin", "S. Decker", "H.G. Kim"], "venue": "In International Conference on Dublin Core and Metadata Applications,", "citeRegEx": "Kim et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2008}, {"title": "TagATune: A game for music and sound annotation", "author": ["E. Law", "L. Von Ahn", "R. Dannenberg", "M. Crawford"], "venue": "In Proceedings of the 8th International Society for Music Information Retrieval Conference (ISMIR 2007), pages 361\u2013364,Vienna,", "citeRegEx": "Law et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Law et al\\.", "year": 2007}, {"title": "Learning to tag from open vocabulary labels", "author": ["E. Law", "B. Settles", "T. Mitchell"], "venue": "In European Conference on Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Law et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Law et al\\.", "year": 2010}, {"title": "Evaluation of algorithms using games: The case of music tagging", "author": ["E. Law", "K. West", "M. Mandel", "M. Bay", "J. Downie"], "venue": "In Proceedings of the 10th International Society for Music Information Retrieval Conference (ISMIR", "citeRegEx": "Law et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Law et al\\.", "year": 2009}, {"title": "Is deep learning really necessary for word embeddings? In Advances in Neural Information Processing Systems 26 (NIPS\u201913), Deep Learning", "author": ["R. Lebret", "J. Legrand", "R. Collobert"], "venue": null, "citeRegEx": "Lebret et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lebret et al\\.", "year": 2013}, {"title": "Going beyond text: A hybrid image-text approach for measuring word relatedness", "author": ["C. Leong", "R. Mihalcea"], "venue": "In Proceedings of the 5th International Joint Conference on Natural Language Processing,", "citeRegEx": "Leong and Mihalcea.,? \\Q2011\\E", "shortCiteRegEx": "Leong and Mihalcea.", "year": 2011}, {"title": "Learning latent semantic models for music from social tags", "author": ["M. Levy", "M. Sandler"], "venue": "Journal of New Music Research,", "citeRegEx": "Levy and Sandler.,? \\Q2008\\E", "shortCiteRegEx": "Levy and Sandler.", "year": 2008}, {"title": "Content-based multimedia information retrieval: State of the art and challenges", "author": ["M. Lew", "N. Sebe", "C. Djeraba", "R. Jain"], "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications,", "citeRegEx": "Lew et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lew et al\\.", "year": 2006}, {"title": "Producing high-dimensional semantic spaces from lexical cooccurrence", "author": ["K. Lund", "C. Burgess"], "venue": "Behavior Research Methods, Instruments, & Computers,", "citeRegEx": "Lund and Burgess.,? \\Q1996\\E", "shortCiteRegEx": "Lund and Burgess.", "year": 1996}, {"title": "Visualizing data using t-SNE", "author": ["L. Van Der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Contextual tag inference", "author": ["M. Mandel", "R. Pascanu", "D. Eck", "Y. Bengio", "L. Aiello", "R. Schifanella", "F. Menczer"], "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications,", "citeRegEx": "Mandel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mandel et al\\.", "year": 2011}, {"title": "Autotagging music with conditional restricted Boltzmann machines", "author": ["M. Mandel", "R. Pascanu", "H. Larochelle", "Y. Bengio"], "venue": "Online: http://arxiv.org/abs/1103.2832,", "citeRegEx": "Mandel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mandel et al\\.", "year": 2011}, {"title": "Introduction to Information Retrieval", "author": ["C. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2008}, {"title": "Evaluating similarity measures for emergent semantics of social tagging", "author": ["B. Markines", "C. Cattuto", "F. Menczer", "D. Benz", "A. Hotho", "G. Stumme"], "venue": "In Proceedings of the 18th International Conference on World Wide Web (WWW\u201909),", "citeRegEx": "Markines et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Markines et al\\.", "year": 2009}, {"title": "Three current issues in music autotagging", "author": ["G. Marques", "M. Domingues", "T. Langlois", "F. Gouyon"], "venue": "In Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR", "citeRegEx": "Marques et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Marques et al\\.", "year": 2011}, {"title": "Context modeling in computer vision: Techniques, implications, and applications", "author": ["O. Marques", "E. Barenholtz", "V. Charvillat"], "venue": "Multimedia Tools and Applications,", "citeRegEx": "Marques et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Marques et al\\.", "year": 2011}, {"title": "Facilitation in recognizing pairs of words: Evidence of a dependence between retrieval operations", "author": ["D. Meyer", "R. Schvaneveldt"], "venue": "Journal of Experimental Psychology,", "citeRegEx": "Meyer and Schvaneveldt.,? \\Q1971\\E", "shortCiteRegEx": "Meyer and Schvaneveldt.", "year": 1971}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "G. Corrado", "K. Chen", "J. Dean"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u00fd", "S. Khudanpur"], "venue": "In 11th Annual Conference of the International Speech Communication Association (INTERSPEECH", "citeRegEx": "Mikolov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "A generative context model for semantic music annotation and retrieval", "author": ["R. Miotto", "G. Lanckriet"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing,", "citeRegEx": "Miotto and Lanckriet.,? \\Q2012\\E", "shortCiteRegEx": "Miotto and Lanckriet.", "year": 2012}, {"title": "Learning to embed songs and tags for playlist prediction", "author": ["J. Moore", "S. Chen", "T. Joachims", "D. Turnbull"], "venue": "In Proceedings of the 13th International Society for Music Information Retrieval Conference (ISMIR", "citeRegEx": "Moore et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2012}, {"title": "A review of content-based image retrieval systems in medical applications-clinical benefits and future directions", "author": ["H. M\u00fcller", "N. Michoux", "D. Bandon", "A. Geissbuhler"], "venue": "International Journal of Medical Informatics,", "citeRegEx": "M\u00fcller et al\\.,? \\Q2004\\E", "shortCiteRegEx": "M\u00fcller et al\\.", "year": 2004}, {"title": "The nature and measurement of meaning", "author": ["C. Osgood"], "venue": "Psychological Bulletin,", "citeRegEx": "Osgood.,? \\Q1952\\E", "shortCiteRegEx": "Osgood.", "year": 1952}, {"title": "Glove: Global vectors for word representation", "author": ["J. Pennington", "R. Socher", "C. Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Objects in context", "author": ["A. Rabinovich", "A. Vedaldi", "C. Galleguillos", "E. Wiewiora", "S. Belongie"], "venue": "In IEEE 11th International Conference on Computer Vision (ICCV", "citeRegEx": "Rabinovich et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rabinovich et al\\.", "year": 2007}, {"title": "Holistic context models for visual recognition", "author": ["N. Rasiwasia", "N. Vasconcelos"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Rasiwasia and Vasconcelos.,? \\Q2012\\E", "shortCiteRegEx": "Rasiwasia and Vasconcelos.", "year": 2012}, {"title": "LabelMe: a database and web-based tool for image annotation", "author": ["B. Russell", "A. Torralba", "K. Murphy", "W. Freeman"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Russell et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Russell et al\\.", "year": 2007}, {"title": "Learning a nonlinear embedding by preserving class neighbourhood structure", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "In Proceedings of the 11th International Conference on Artificial Intelligence and Statistics, pages 412\u2013419,", "citeRegEx": "Salakhutdinov and Hinton.,? \\Q2007\\E", "shortCiteRegEx": "Salakhutdinov and Hinton.", "year": 2007}, {"title": "The Neglected user in music information retrieval research", "author": ["M. Schedl", "A. Flexer", "J. Urbano"], "venue": "Journal of Intelligent Information Systems,", "citeRegEx": "Schedl et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schedl et al\\.", "year": 2013}, {"title": "minFunc: unconstrained differentiable multivariate optimization in Matlab", "author": ["M. Schmidt"], "venue": "Online: http://www.cs.ubc.ca/~schmidtm/Software/minFunc.html,", "citeRegEx": "Schmidt.,? \\Q2005\\E", "shortCiteRegEx": "Schmidt.", "year": 2005}, {"title": "Modern information retrieval: A brief overview", "author": ["A. Singhal"], "venue": "IEEE Data Engineering Bulletin,", "citeRegEx": "Singhal.,? \\Q2001\\E", "shortCiteRegEx": "Singhal.", "year": 2001}, {"title": "Content-based image retrieval at the end of the early years", "author": ["A. Smeulders", "M. Worring", "S. Santini", "A. Gupta", "R. Jain"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Smeulders et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Smeulders et al\\.", "year": 2000}, {"title": "Relating things and stuff via object property interactions", "author": ["M. Sun", "B. Kim", "P. Kohli", "S. Savarese"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Sun et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Hierarchical Dirichlet processes", "author": ["W. Teh", "I. Michael", "M. Beal", "D. Blei"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Teh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2006}, {"title": "Using the forest to see the trees: exploiting context for visual object detection and localization", "author": ["A. Torralba", "K. Murphy", "W. Freeman"], "venue": "Communications of the ACM,", "citeRegEx": "Torralba et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 2010}, {"title": "Contextual priming for object detection", "author": ["A. Torralba"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Torralba.,? \\Q2003\\E", "shortCiteRegEx": "Torralba.", "year": 2003}, {"title": "Five approaches to collecting tags for music", "author": ["D. Turnbull", "L. Barrington", "G. Lanckriet"], "venue": "In Proceedings of the 9th International Society for Music Information Retrieval Conference (ISMIR", "citeRegEx": "Turnbull et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Turnbull et al\\.", "year": 2008}, {"title": "Towards musical query-by-semanticdescription using the CAL500 data set", "author": ["D. Turnbull", "L. Barrington", "D. Torres", "G. Lanckriet"], "venue": "In Proceedings of the 30th ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Turnbull et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Turnbull et al\\.", "year": 2007}, {"title": "Enriching music mood annotation by semantic association reasoning", "author": ["J. Wang", "X. Anguera", "X. Chen", "D. Yang"], "venue": "In 2010 IEEE International Conference on Multimedia and Expo,", "citeRegEx": "Wang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2010}, {"title": "Multi-tasking with joint semantic spaces for large-scale music annotation and retrieval", "author": ["J. Weston", "S. Bengio", "P. Hamel"], "venue": "Journal of New Music Research,", "citeRegEx": "Weston et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2011}, {"title": "Semantic context modeling with maximal margin conditional random fields for automatic image annotation", "author": ["Y. Xiang", "X. Zhou", "Z. Liu", "T. Chua", "C. Ngo"], "venue": "In Conference on Computer Vision and Pattern Recognition", "citeRegEx": "Xiang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Xiang et al\\.", "year": 2010}, {"title": "SUN database: Large-scale scene recognition from abbey to zoo", "author": ["J. Xiao", "J. Hays", "K. Ehinger", "A. Oliva", "A. Torralba"], "venue": "In Conference on Computer Vision and Pattern Recognition", "citeRegEx": "Xiao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Xiao et al\\.", "year": 2010}, {"title": "Mining multi-tag association for image tagging", "author": ["Y. Yang", "Z. Huang", "H. Shen", "X. Zhou"], "venue": "World Wide Web,", "citeRegEx": "Yang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 19, "context": "Multimedia information retrieval (MMIR) is a collective terminology referring to a number of tasks involving indexing, comparison and retrieval of multimedia objects (Jaimes et al., 2005).", "startOffset": 166, "endOffset": 187}, {"referenceID": 43, "context": "In addition, information processing tasks in fields such as medicine (M\u00fcller et al., 2004) and education (Chang, Eleftheriadis & Mcclintock, 1998) benefit enormously from advances in MMIR.", "startOffset": 69, "endOffset": 90}, {"referenceID": 53, "context": "2 gap (Smeulders et al., 2000), which stems from the difficulty in linking low-level media representation, e.", "startOffset": 6, "endOffset": 30}, {"referenceID": 29, "context": "Bridging this gap has motivated a number of approaches including feature extraction (Lew et al., 2006), user-inclusive design (Schedl, Flexer & Urbano, 2013), and high-level context modeling (Marques, Barenholtz & Charvillat, 2011).", "startOffset": 84, "endOffset": 102}, {"referenceID": 22, "context": "Examples of such sources include manually constructed knowledge graphs or ontologies (Kim et al., 2008), automatically analyzed media content (Torralba, 2003) or well-explored collections of crowd-sourced descriptive terms or tags (Miotto & Lanckriet, 2012).", "startOffset": 85, "endOffset": 103}, {"referenceID": 57, "context": ", 2008), automatically analyzed media content (Torralba, 2003) or well-explored collections of crowd-sourced descriptive terms or tags (Miotto & Lanckriet, 2012).", "startOffset": 46, "endOffset": 62}, {"referenceID": 54, "context": "For instance, the meaning of a concept, such as activity \u2018upper arm bench\u2019, can be enumerated by a set of its attributes, such as \u2018arms back\u2019 and \u2018arms curl\u2019 (Sun et al., 2013).", "startOffset": 158, "endOffset": 176}, {"referenceID": 57, "context": ", boats and ships, can be attained to improve the object identification performance (Leong & Mihalcea, 2011; Torralba, Murphy & Freeman, 2010; Torralba, 2003).", "startOffset": 84, "endOffset": 158}, {"referenceID": 42, "context": "Similarly, semantics obtained from indirect sources refer to those semantics learnt from unobvious relatedness indicators, such as song co-occurrence in public playlists (Moore et al., 2012) or text/image adjacency online (Jing et al.", "startOffset": 170, "endOffset": 190}, {"referenceID": 20, "context": ", 2012) or text/image adjacency online (Jing et al., 2014), where the incident of multimedia adjacency is assumed to imply relatedness.", "startOffset": 39, "endOffset": 58}, {"referenceID": 62, "context": "For example, the introduction of relatedness-aware refinements with different sources of information over the concept detection task (Fink & Perona, 2003; Miotto & Lanckriet, 2012; Xiang et al., 2010) and the fusion of different high-level types of relatedness (Globerson et al.", "startOffset": 133, "endOffset": 200}, {"referenceID": 14, "context": ", 2010) and the fusion of different high-level types of relatedness (Globerson et al., 2007; Mandel et al., 2011; Weston, Bengio & Hamel, 2011).", "startOffset": 68, "endOffset": 143}, {"referenceID": 32, "context": ", 2010) and the fusion of different high-level types of relatedness (Globerson et al., 2007; Mandel et al., 2011; Weston, Bengio & Hamel, 2011).", "startOffset": 68, "endOffset": 143}, {"referenceID": 46, "context": "Typical applications include music crowd tagging services (Law, Settles & Mitchell, 2010) and multi-object image data set analysis (Rabinovich et al., 2007).", "startOffset": 131, "endOffset": 156}, {"referenceID": 23, "context": "Thanks to crowd-sourced annotation (Turnbull, Barrington & Lanckriet, 2008) and game-based tags collection (Law et al., 2007), large collections of descriptive terms are now accessible.", "startOffset": 107, "endOffset": 125}, {"referenceID": 46, "context": "Obviously, simply counting co-occurrence (Rabinovich et al., 2007) is insufficient in modeling various types of semantics and relatedness in descriptive terms to capture accurate concepts, and more sophisticated techniques are required so that we can capture all the intended semantics or concepts and their relatedness in descriptive terms accurately.", "startOffset": 41, "endOffset": 66}, {"referenceID": 6, "context": "5 In order to tackle the problem described above, we propose a novel Siamese architecture (Bromley et al., 1993) and a two-stage learning algorithm to capture contextualized semantics from descriptive terms.", "startOffset": 90, "endOffset": 112}, {"referenceID": 35, "context": "Aggregation (Markines et al., 2009) is a statistical-based method that focuses on pairwise cooccurrence of terms in the training data set and is sometimes named co-occurrence analysis.", "startOffset": 12, "endOffset": 35}, {"referenceID": 52, "context": "By considering all training documents, aggregation works on a document-term matrix \u03a5 where the presence or absence of each term in each document is represented as binary or frequency indicator (Singhal, 2001).", "startOffset": 193, "endOffset": 208}, {"referenceID": 26, "context": "According to (Lebret et al., 2013), this extension yields improved performance in a specific linguistic task: movie review sentiment evaluation.", "startOffset": 13, "endOffset": 34}, {"referenceID": 26, "context": "According to (Lebret et al., 2013), this extension yields improved performance in a specific linguistic task: movie review sentiment evaluation. Nevertheless, such extension seems quite sensitive to preprocessing and tunable parameters. Similarly, Mandel et al. (2011) proposed an information theoretic inspired (InfoTheo) method that yields a smoothed document representation in the document-term \u03a5 matrix.", "startOffset": 14, "endOffset": 269}, {"referenceID": 11, "context": "Another statistic-based method is Latent Semantic Indexing (LSI) (Deerwester et al., 1990), a popular technique in text information retrieval.", "startOffset": 65, "endOffset": 90}, {"referenceID": 22, "context": "Establishing such a graph representation can be done either manually or by some relatedness analysis (Hueting, Monszpart & Mellado, 2014; Kim et al., 2008; Wang et al., 2010).", "startOffset": 101, "endOffset": 174}, {"referenceID": 60, "context": "Establishing such a graph representation can be done either manually or by some relatedness analysis (Hueting, Monszpart & Mellado, 2014; Kim et al., 2008; Wang et al., 2010).", "startOffset": 101, "endOffset": 174}, {"referenceID": 40, "context": "For capturing the syntactic relatedness, distributed language models (Mikolov et al., 2010; Collobert et al., 2011; Mikolov et al., 2013) were recently proposed.", "startOffset": 69, "endOffset": 137}, {"referenceID": 10, "context": "For capturing the syntactic relatedness, distributed language models (Mikolov et al., 2010; Collobert et al., 2011; Mikolov et al., 2013) were recently proposed.", "startOffset": 69, "endOffset": 137}, {"referenceID": 39, "context": "For capturing the syntactic relatedness, distributed language models (Mikolov et al., 2010; Collobert et al., 2011; Mikolov et al., 2013) were recently proposed.", "startOffset": 69, "endOffset": 137}, {"referenceID": 40, "context": "Such models learn syntactic relatedness from linguistic corpora and yield a distributed semantic space where all words are embedded properly based on their syntactic similarity (Mikolov et al., 2010).", "startOffset": 177, "endOffset": 199}, {"referenceID": 39, "context": "Those models have been attracting increasing attention due to their simplicity and capacity in providing generic semantics for various application tasks (Frome et al., 2013; Mikolov et al., 2013).", "startOffset": 153, "endOffset": 195}, {"referenceID": 10, "context": ", 2010; Collobert et al., 2011; Mikolov et al., 2013) were recently proposed. Such models learn syntactic relatedness from linguistic corpora and yield a distributed semantic space where all words are embedded properly based on their syntactic similarity (Mikolov et al., 2010). During learning, an architecture is trained to predict a missing word given some context, i.e., nearby words, or to predict possible context words given one word. If trained properly, words that can be used interchangeable without breaking language rules, i.e., syntactically close words, will have close embedding vectors. Those models have been attracting increasing attention due to their simplicity and capacity in providing generic semantics for various application tasks (Frome et al., 2013; Mikolov et al., 2013). Moreover, Pennington and Manning (2014) showed how to combine the advantages of simple PCA models with this syntactic relatedness by careful analysis of the ratios of co-occurrence probabilities between pairs of words appearing in each other\u2019s neighborhood.", "startOffset": 8, "endOffset": 840}, {"referenceID": 17, "context": "Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) are the two most prominent topic models used in text and natural language processing.", "startOffset": 46, "endOffset": 61}, {"referenceID": 32, "context": "Another method for introducing a context is using Conditional Restricted Boltzmann Machines (CRBM) in (Mandel et al., 2011).", "startOffset": 102, "endOffset": 123}, {"referenceID": 16, "context": "CRBM (Taylor, Hinton & Roweis, 2007) is a variant of the traditional RBM (Hinton, 2002), a generative model that has two layers of probabilistic", "startOffset": 73, "endOffset": 87}, {"referenceID": 16, "context": "The optimization can be accomplished by the contrastive divergence (CD) algorithm (Hinton, 2002) that implicitly samples the hidden distribution to estimate the free energy.", "startOffset": 82, "endOffset": 96}, {"referenceID": 32, "context": "In CRBM (Mandel et al., 2011), the energy function used in RBM is modified to take the condition Q into account with an additional visible layer connected to the original visible layer via", "startOffset": 8, "endOffset": 29}, {"referenceID": 15, "context": "When it is used in learning semantics from descriptive terms, the observed vector I is set to be the Bag of Words (BoW) binary representation (Harris, 1954) of a considered document.", "startOffset": 142, "endOffset": 156}, {"referenceID": 32, "context": "The collection of terms used by other users for the same document is also used as a different condition in (Mandel et al., 2011).", "startOffset": 107, "endOffset": 128}, {"referenceID": 64, "context": "Yang et al. (2010) suggested the use of mining association rules from image tagged data for the tag completion task.", "startOffset": 0, "endOffset": 19}, {"referenceID": 32, "context": ", the CRBM model (Mandel et al., 2011).", "startOffset": 17, "endOffset": 38}, {"referenceID": 35, "context": "Therefore, we employ a statistics-based representation (Markines et al., 2009) where each descriptive term is represented as a summary of its pair-wise use with all terms over an entire training data set.", "startOffset": 55, "endOffset": 78}, {"referenceID": 5, "context": "Motivated by the argument that learning a simple yet relevant auxiliary task could facilitate learning semantic embedding (Bottou, 2014), we can comply with this requirement by fulfilling a simple yet generic task of predicting all the accompany terms in a document from the representations of a constitutional term and its local context described in Section 3.", "startOffset": 122, "endOffset": 136}, {"referenceID": 6, "context": "To carry out this task, we would develop a variant of Siamese architecture (Bromley et al., 1993) consisting of two identical deep neural networks used in the earlier prediction task to be its subnetworks.", "startOffset": 75, "endOffset": 97}, {"referenceID": 4, "context": "In our two-stage learning, all the parameters are estimated iteratively via the stochastic backpropagation (SBP) (Bottou, 2012) by optimizing the loss functions specified in Equations 5 and 7.", "startOffset": 113, "endOffset": 127}, {"referenceID": 59, "context": "\u2022 CAL500 (Turnbull et al., 2007) is collected through public survey.", "startOffset": 9, "endOffset": 32}, {"referenceID": 36, "context": "\u2022 MagTag5K (Marques et al., 2011) is a controlled version of the MagnaTune 2 data set by removing all repeated or contradicting tags.", "startOffset": 11, "endOffset": 33}, {"referenceID": 25, "context": "In this scenario, the players evaluate the appropriateness of complete tag sets for pieces of music rather than just one tag at a time (Law et al., 2009).", "startOffset": 135, "endOffset": 153}, {"referenceID": 1, "context": "\u2022 Million Song Dataset (Bertin-mahieux et al., 2011) contains acoustic features and meta data of a million songs.", "startOffset": 23, "endOffset": 52}, {"referenceID": 13, "context": "\u2022 Corel5K (Duygulu et al., 2002) was manually annotated by experts who assigned up to five labels to the most prominent objects in each image.", "startOffset": 10, "endOffset": 32}, {"referenceID": 48, "context": "\u2022 LabelMe data set (Russell et al., 2007) contains images labeled by crowed-sourcing via an online labeling tool.", "startOffset": 19, "endOffset": 41}, {"referenceID": 63, "context": "\u2022 SUNDatabase benchmark (Xiao et al., 2010) was created in several stages.", "startOffset": 24, "endOffset": 43}, {"referenceID": 55, "context": "The number of topics were empirically decided by using the hierarchical process as suggested in (Teh et al., 2006).", "startOffset": 96, "endOffset": 114}, {"referenceID": 36, "context": "For MagTag5K, we adopted a default setting suggested by Marques et al. (2011) instead of the random split and 300 documents were randomly selected from subset B for validation while the rest of documents were reserved for test.", "startOffset": 56, "endOffset": 78}, {"referenceID": 44, "context": "Semantic priming is an application that depends directly on those semantics without the need of accessing content or other information regarding media (Lund & Burgess, 1996; Osgood, 1952).", "startOffset": 151, "endOffset": 187}, {"referenceID": 38, "context": "Semantic priming was first introduced by Meyer and Schvaneveldt (1971) to associate semantically related concepts to each other, e.", "startOffset": 41, "endOffset": 71}, {"referenceID": 32, "context": "Following the suggestions in (Mandel et al., 2011), we obtained this pairwise information by using all the 12 aggregation methods listed in the PCA setting and applied such information to the smooth document-term matrix generation.", "startOffset": 29, "endOffset": 50}, {"referenceID": 32, "context": "With the suggestions in (Mandel et al., 2011), we tuned those parameters by a grid search on a reasonable range for each of training data sets with different aggregation methods, respectively.", "startOffset": 24, "endOffset": 45}, {"referenceID": 39, "context": "In our experiments, we use the word2vec source code (Mikolov et al., 2013) to train the Skip Gram models.", "startOffset": 52, "endOffset": 74}, {"referenceID": 16, "context": "33 contrastive divergence algorithm (Hinton, 2002) where we used the recommended learning rate of 0.", "startOffset": 36, "endOffset": 50}, {"referenceID": 32, "context": "To learn semantics from descriptive terms, most of existing techniques often undergo a preprocessing stage by filtering out rarely used terms from those documents concerned (Law, Settles & Mitchell, 2010; Mandel et al., 2011).", "startOffset": 173, "endOffset": 225}, {"referenceID": 3, "context": "First of all, most of existing Siamese architectures are developed to learn a distance metric only in the representation space (Bordes et al., 2011; Bromley et al., 1993; Chopra, Hadsell & LeCun, 2005).", "startOffset": 127, "endOffset": 201}, {"referenceID": 6, "context": "First of all, most of existing Siamese architectures are developed to learn a distance metric only in the representation space (Bordes et al., 2011; Bromley et al., 1993; Chopra, Hadsell & LeCun, 2005).", "startOffset": 127, "endOffset": 201}, {"referenceID": 32, "context": "In addition, the \u201ccontextual tag inference\u201d (Mandel et al., 2011) is an approach that exploits descriptive terms in order to produce a smoothed representation for documents with CRBM.", "startOffset": 44, "endOffset": 65}, {"referenceID": 64, "context": "In nature, the work closest to ours is the \u201cAssociation Rules\u201d (Yang et al. 2010) that lead to contextualized semantic representations on a conceptual level.", "startOffset": 63, "endOffset": 81}, {"referenceID": 11, "context": "Without taking contextual information into account, the learnt semantic representation reflects only the global term-to-term relatedness and hence each term has a unique representation (Deerwester et al., 1990; Markines et al., 2009).", "startOffset": 185, "endOffset": 233}, {"referenceID": 35, "context": "Without taking contextual information into account, the learnt semantic representation reflects only the global term-to-term relatedness and hence each term has a unique representation (Deerwester et al., 1990; Markines et al., 2009).", "startOffset": 185, "endOffset": 233}, {"referenceID": 32, "context": ", smoothing (Mandel et al., 2011) and probabilistic topic models, LDA (Blei, Ng & Jordan, 2003) and PLSA (Hofmann, 1999), offer only a document-level representation but do not address the contextualized term-to-term relatedness issue directly.", "startOffset": 12, "endOffset": 33}, {"referenceID": 17, "context": ", 2011) and probabilistic topic models, LDA (Blei, Ng & Jordan, 2003) and PLSA (Hofmann, 1999), offer only a document-level representation but do not address the contextualized term-to-term relatedness issue directly.", "startOffset": 79, "endOffset": 94}, {"referenceID": 22, "context": "Most of those methods fall into the ontology area and rely on human expertise such as \u201ctag ontologies\u201d (Kim et al., 2008) and \u201cproperty lists\u201d semantics (Sun et al.", "startOffset": 103, "endOffset": 121}, {"referenceID": 54, "context": ", 2008) and \u201cproperty lists\u201d semantics (Sun et al., 2013).", "startOffset": 39, "endOffset": 57}, {"referenceID": 51, "context": "method in the popular implementation of minFunc (Schmidt, 2005).", "startOffset": 48, "endOffset": 63}], "year": 2015, "abstractText": "One of the biggest challenges in Multimedia information retrieval and understanding is to bridge the semantic gap by properly modeling concept semantics in context. The presence of out of vocabulary (OOV) concepts exacerbates this difficulty. To address the semantic gap issues, we formulate a problem on learning contextualized semantics from descriptive terms and propose a novel Siamese architecture to model the contextualized semantics from descriptive terms. By means of pattern aggregation and probabilistic topic models, our Siamese architecture captures contextualized semantics from the co-occurring descriptive terms via unsupervised learning, which leads to a concept embedding space of the terms in context. Furthermore, the co-occurring OOV concepts can be easily represented in the learnt concept embedding space. The main properties of the concept embedding space are demonstrated via visualization. Using various settings in semantic priming, we have carried out a thorough evaluation by comparing our approach to a number of state-of-the-art methods on six annotation corpora in different domains, i.e., MagTag5K, CAL500 and Million Song Dataset in the music domain as well as Corel5K, LabelMe and SUNDatabase in the image domain. Experimental results on semantic priming suggest that our approach outperforms those state-of-the-art methods considerably in various", "creator": "PrimoPDF http://www.primopdf.com"}}}