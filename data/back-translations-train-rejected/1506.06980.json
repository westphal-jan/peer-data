{"id": "1506.06980", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2015", "title": "Strategic Classification", "abstract": "Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior---often referred to as gaming---the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart's law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming.", "histories": [["v1", "Tue, 23 Jun 2015 13:22:10 GMT  (114kb,D)", "http://arxiv.org/abs/1506.06980v1", null], ["v2", "Sun, 22 Nov 2015 18:33:34 GMT  (114kb,D)", "http://arxiv.org/abs/1506.06980v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["moritz hardt", "nimrod megiddo", "christos papadimitriou", "mary wootters"], "accepted": false, "id": "1506.06980"}, "pdf": {"name": "1506.06980.pdf", "metadata": {"source": "CRF", "title": "Strategic Classification", "authors": ["Moritz Hardt", "Nimrod Megiddo", "Christos Papadimitriou", "Mary Wootters"], "emails": [], "sections": [{"heading": null, "text": "We model the classification as an ongoing game between a player named \"Jury\" and a player named \"Participant.\" The jury designs a classifier, and the participant receives an input to the classifier that comes from a distribution. Before being classified, the participant may change his input based on the classifier of the jury. However, the participant incurs costs for these changes according to a cost function. The goal of the jury is to achieve a high classification accuracy in relation to the participant's original input and some underlying target classification functions, provided the participant plays the best answer. The goal of the participant is to achieve an advantageous classification result while taking into account the cost of achieving it. Surprisingly, for a natural class of divisible cost functions and certain generalizations, we obtain computer-efficient learning algorithms that are nearly optimal, achieving a classification error that comes close to the theoretical minimum of 80. Surprisingly, our general algorithms are difficult to learn even with 6 concept classes."}, {"heading": "1 Introduction", "text": "Dre rf\u00fc ide eeisrrrteeeeeeeteerterrrr rf\u00fc ide rf\u00fc ide nlrrf\u00fc ide rf\u00fc ide nlrrgneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerrrrrrrrr iuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiuiueeeeeeeeeeeeeeeeeeeeeeeeeee"}, {"heading": "1.1 Our model", "text": "We will first describe an idealized version of the game in which the jury has perfect information (1,1), which serves as a reference point for how well the jury can hope to do so. We will later trace this back to a version in which the jury knows neither h nor D. It is only considered an example of a strategic game.Definition 1.1 (Full information game). However, the players are jury and constant. Fix a population X, and a probability distribution D over X. Attach a cost function c: X \u00b7 X \u00b7 R + and a target classifier h: In fact {\u2212 1,1}.1 Jury (who knows the cost function c, the distribution D, and the true classifier h) publishes a classifier f: X \u2192.2}. Contestant (who c, D, and f) produces a function: X \u2192 X.The payout to the jury is Prx (x).We (x)."}, {"heading": "1.2 Strategy-robust learning", "text": "A learning algorithm in our setting must achieve two objectives. First, it must learn the unknown target classifier from the examples given. Second, it must achieve high jury payouts in statistical classification by anticipating the best response from Contestant. Below, we give two definitions of category-robust learning that combine these objectives; the second is a stronger requirement than the first. In our second definition, we determine an unknown target classifier h, and demand an algorithm that guarantees a near-optimal jury payout in the statistical classification game with a high probability of using the samples. In our second definition, we present a consistent idea: the learning algorithm must return a high probability classifier that is guaranteed to work on each target classifier h in some concept class H.Definition h (Strategy-robust learning).Let C be a class of cost functions."}, {"heading": "1.3 Our contributions", "text": "Our main result is a strategy-robust learning algorithm, which is equipped with both uniform and non-uniform functions. Our algorithm is computationally efficient if the cost function comes from a broad class of functions that we call separable. In the non-uniform case, the target classifier h cannot be anything. However, in the uniform case, the algorithm is efficient as long as concept class H is statistically learnable, but it does not, in particular, require H to be efficiently learnable. Separable cost functions are functions of the form c (x, y) = max {0, c2 (y) \u2212 c1 (x)}, where c1 and c2 are arbitrary functions that can classify domain X into real numbers. We take the maximum to obtain a non-negative cost function. We will see and discuss a number of natural examples of separable cost functions later on. Our main result is a uniform learning algorithm, and our stronger result is uniform strategy-formally robust learning function 1.7 (Inorem)."}, {"heading": "1.3.1 Experimental evaluation", "text": "The classification of spammers is a natural framework for our methods, since spammers will naturally try to play any automated attempt to identify them. We model a cost function that roughly reflects the loss of revenue that a spammer experiences when changing certain attributes. For example, if a spam message contains a malware-pointing URL, it is costly for the spammer to remove that URL from his message because his message loses its intended purpose. Knowing that modeling a cost function can never be entirely realistic, we evaluate our approach taking into account multiple types of modeling inaccuracies. Specifically, we only assume that our cost function is roughly correct and that the amount of gaming may be below or above the threshold predicted by our theoretical framework. Our empirical observations already show that we often achieve an excellent interpretation of our classification only when we have a significant amount of classified errors between our classification and our classification."}, {"heading": "1.4 Related work", "text": "The deterioration of predictive accuracy due to unforeseen events is often described as a concept shift and results from a number of contexts. A sequence of works on hostile learning is motivated by the question of learning in the presence of an opponent manipulating the examples of a learning algorithm. Typical applications in this area are intrusion detection and spam fighting. Early work considered zero-sum games [BS09, BS11, BKS12, GSBS13], which are not particularly applicable to our problem, since there are almost always cases where the profit should be high for both players (e.g. a good student admitted to a good college). Recent work considers alternative game theory ideas [BS09, BS11, BKS12, GSBS13]. Most closely related is the work of Br\u00fcckner and Scheffer [BS11], who consider a Stackelberg competition for hostile learning."}, {"heading": "2 Separable cost functions", "text": "We begin by examining the class of divisible cost functions, which, of course, turn out to be such in the context of the advertising campaign. To motivate the definition, we recall the example of the school board, which wants to exploit the correlation between parents \"books and students\" performance. (...) In this (admittedly rather stylized) example, the cost of moving from a household to a household of 50 books is simply the cost of the additional books. (...) Generally, this logic applies to any situation in which the cost of each state can be attributed to x, regardless of how it was achieved. (...) If the cost of a state x (x), then the cost of moving from x to y is simply arbitrary. (x, y) = max. (y) \u2212 g (y) \u2212 g (x)"}, {"heading": "In particular, under the conditions of Theorem 2.3, with probability at least 1\u2212 \u03b4,", "text": "The definition of e \u03c3rr (s) \u2212 err (s) \u2212 err (s) \u2212 err (s) \u2212 err (s) = 1m m \u00b2 j = 1 {h (xj), c1 [s \u2212 2] (xj)} \u2212 err (s) \u2212 err (s) = 1m m \u00b2 j = 1 {h (xj), c1 [s \u2212 2] (for all h \u00b2) \u2212 err (s) (s), simultaneously for all h \u00b2 H, s \u00b2 s \u00b2 S, s \u00b2 s \u00b2 s \u00b2 s \u00b2 (see for example Theorem 3.2 in [BBL05])), for all h \u00b2 C, s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, s \u00b2 err (s) \u2212 err (s)."}, {"heading": "3 General cost functions", "text": "While separable cost functions are reasonable, they do not capture everything. In this section, we will consider more general cost functions. We will expand Algorithm 1 to a cost function that is the minimum of any set of separable cost functions. This is a much broader class. In fact, each cost function can be presented as a minimum of separable cost functions, although it is not necessarily very economical."}, {"heading": "4 NP-completeness", "text": "What happens if the cost function c is inseparable? It turns out that for the general cost functions, any algorithm for jury takes more than a polynomial time to obtain a near-optimal classifier, unless the underlying distance function is actually a metric (another very natural class of cost function), and (b) even if the learning algorithm has correct markings h (x) for all members of the population x (X), if the desired deviation is actually small and the distribution D is uniform. The above statements are consequences of the following result: Theorem 4.1. Given a finite population X with uniform distribution, a target label c on X, and a target label h: X 7 \u2192 {\u2212 1}, it is NP-hard to calculate the strategic optimum within the strategic optimum."}, {"heading": "5 Experiments", "text": "We conducted experiments on real-world data from a Brazilian social network called Apontador, which offers site-specific recommendations and ratings."}, {"heading": "5.1 Comparison with SVM under robustness to modeling errors", "text": "To formalize our error model, we assume that there is a true underlying cost function that differs from the cost function that we feed into algorithm 1. We imagine that the true cost function is a mixture of the linear cost function described above plus a square Euclidean distance function: ctrue (x, y) \u03b1, y \u2212 x + \u03b5 x x x x x x-y 2. (8) On the other hand, we execute our algorithm on a cost function that is incorrect in two respects. First, it is separable so that it necessarily ignores the square distance concept. Second, we do a notimagine that we have correctly identified, and we replace it with some square values: assumed (x, y)."}, {"heading": "5.2 A hybrid approach for higher accuracy", "text": "In practice, it is convenient to start from a standard classifier and make it more robust for games, as opposed to introducing a completely new classifier. Our framework provides a convenient way to include a number of well-known classifiers in the design of a strategically robust classifier. As we show below, this can lead to more favorable trade-offs between games and accuracy. The basic idea is to use every known classifier as a feature to which we assign a positive weight in the cost function. In other words, we determine that the classifier itself is a reasonably reliable attribute of the data. In the following, we will try this hybrid approach by combining our classifier with the standard SVM classifier. In fact, in our experiments, we find that the hybrid has a higher accuracy in a robust range of parameters. This is shown in Figure 4.In the case of a linear SVM, the decision limit is given by a vector size and we can assume this function to be true (we can change the SVS + cost function)."}, {"heading": "Acknowledgments", "text": "We are grateful for stimulating discussions with Cynthia Dwork, Brendan Juba, Omer Reingold and Aaron Roth. We are also grateful to Fabricio Benevenuto for pointing out and sharing the Apondatordata set with us, and to an anonymous reviewer who pointed out that our uniform result implied the non-uniform consequence."}, {"heading": "A Proof of Theorem 3.3", "text": "The proof for theorem 3.3. fix h-C. As in the proof for theorem 2.3 (=), we start with the definition of the sentence (f) of x-x, so that f (x) = 1, if it is the best answer to f (y). (For each f-C, we have (f): = {x: max {f (y): f (x): f (x) {s (x) = 1, b (b), b (x), b (x), b (x) < 2) = {x: (b), b: (b), b: (b), b: b: (b), b: b: b: b: b b), b: b: b: b), b: b: b: b: b), b: b (x), b: b: b: b: b), b: b: b: b: b: b), b: b: b: b: b: b, b: b: b: b: b: b, b: b: b: b: b, b: b: b: b: b: b), b: b: b: b: b: b: b: b, b: b: b: b: b: b: b, b: b: b: b: b: b), b: b: b: b: b: b: b: b: b: b: b, b: b: b: b: b: b: b), b: b: b: b: b: b: b: b: b, b: b: b: b: b: b: b: b: b: b: b: b: b: b: b), b: b: b: b: b: b: b: b: b: b: b."}], "references": [{"title": "Theory of classification: A survey of some recent advances", "author": ["St\u00e9phane Boucheron", "Olivier Bousquet", "G\u00e1bor Lugosi"], "venue": "ESAIM: probability and statistics,", "citeRegEx": "Boucheron et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Boucheron et al\\.", "year": 2005}, {"title": "Static prediction games for adversarial learning problems", "author": ["Michael Br\u00fcckner", "Christian Kanzow", "Tobias Scheffer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Br\u00fcckner et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Br\u00fcckner et al\\.", "year": 2012}, {"title": "Nash equilibria of static prediction games", "author": ["Michael Br\u00fcckner", "Tobias Scheffer"], "venue": "In Proc. 23rd NIPS", "citeRegEx": "Br\u00fcckner and Scheffer.,? \\Q2009\\E", "shortCiteRegEx": "Br\u00fcckner and Scheffer.", "year": 2009}, {"title": "Stackelberg games for adversarial prediction problems", "author": ["Michael Br\u00fcckner", "Tobias Scheffer"], "venue": "In Proc 17th ACM SIGKDD,", "citeRegEx": "Br\u00fcckner and Scheffer.,? \\Q2011\\E", "shortCiteRegEx": "Br\u00fcckner and Scheffer.", "year": 2011}, {"title": "Pollution, bad-mouthing, and local marketing: The underground of location-based social networks", "author": ["Helen Costa", "Fabr\u00edcio Barth", "Fabr\u00edcio Benevenuto"], "venue": "Inf. Sci.,", "citeRegEx": "Costa et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Costa et al\\.", "year": 2014}, {"title": "The scored society: Due process for automated predictions", "author": ["Danielle Keats Citron", "Frank Pasquale"], "venue": "Washington Law Review,", "citeRegEx": "Citron and Pasquale.,? \\Q2014\\E", "shortCiteRegEx": "Citron and Pasquale.", "year": 2014}, {"title": "Adversarial classification", "author": ["Nilesh N. Dalvi", "Pedro Domingos", "Mausam", "Sumit K. Sanghai", "Deepak Verma"], "venue": "In Proc 10th ACM SIGKDD,", "citeRegEx": "Dalvi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dalvi et al\\.", "year": 2004}, {"title": "Family scholarly culture and educational success: Evidence from 27 nations", "author": ["M.D.R. Evans", "J. Kelley", "J. Sikora", "D.J. Treiman"], "venue": "Research in Social Stratification and Mobility,", "citeRegEx": "Evans et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Evans et al\\.", "year": 2010}, {"title": "Bayesian games for adversarial regression problems", "author": ["Michael Gro\u00dfhans", "Christoph Sawade", "Michael Br\u00fcckner", "Tobias Scheffer"], "venue": "In Proc. 30th ICML,", "citeRegEx": "Gro\u00dfhans et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gro\u00dfhans et al\\.", "year": 2013}, {"title": "Complexity of computing optimal Stackelberg strategies in security resource allocation games", "author": ["Dmytro Korzhyk", "Vincent Conitzer", "Ronald Parr"], "venue": "In Proc. AAAI,", "citeRegEx": "Korzhyk et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Korzhyk et al\\.", "year": 2010}, {"title": "Stackelberg vs. Nash in security games: An extended investigation of interchangeability, equivalence, and uniqueness", "author": ["Dmytro Korzhyk", "Zhengyu Yin", "Christopher Kiekintveld", "Vincent Conitzer", "Milind Tambe"], "venue": "J. Artif. Intell. Res.(JAIR),", "citeRegEx": "Korzhyk et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Korzhyk et al\\.", "year": 2011}, {"title": "Probability in Banach Spaces: isoperimetry and processes, volume 23", "author": ["Michel Ledoux", "Michel Talagrand"], "venue": null, "citeRegEx": "Ledoux and Talagrand.,? \\Q1991\\E", "shortCiteRegEx": "Ledoux and Talagrand.", "year": 1991}, {"title": "A theory of the learnable", "author": ["Leslie Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant.,? \\Q1984\\E", "shortCiteRegEx": "Valiant.", "year": 1984}], "referenceMentions": [], "year": 2015, "abstractText": "Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior\u2014often referred to as gaming\u2014the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart\u2019s law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming. We model classification as a sequential game between a player named \u201cJury\u201d and a player named \u201cContestant.\u201d Jury designs a classifier, and Contestant receives an input to the classifier drawn from a distribution. Before being classified, Contestant may change his input based on Jury\u2019s classifier. However, Contestant incurs a cost for these changes according to a cost function. Jury\u2019s goal is to achieve high classification accuracy with respect to Contestant\u2019s original input and some underlying target classification function, assuming Contestant plays best response. Contestant\u2019s goal is to achieve a favorable classification outcome while taking into account the cost of achieving it. For a natural class of separable cost functions, and certain generalizations, we obtain computationally efficient learning algorithms which are near optimal, achieving a classification error that is arbitrarily close to the theoretical minimum. Surprisingly, our algorithms are efficient even on concept classes that are computationally hard to learn. For general cost functions, designing an approximately optimal strategy-proof classifier, for inverse-polynomial approximation, is NP-hard. ar X iv :1 50 6. 06 98 0v 1 [ cs .L G ] 2 3 Ju n 20 15", "creator": "LaTeX with hyperref package"}}}