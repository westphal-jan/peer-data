{"id": "1506.08581", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2015", "title": "Variational Inference for Background Subtraction in Infrared Imagery", "abstract": "We propose a Gaussian mixture model for background subtraction in infrared imagery. Following a Bayesian approach, our method automatically estimates the number of Gaussian components as well as their parameters, while simultaneously it avoids over/under fitting. The equations for estimating model parameters are analytically derived and thus our method does not require any sampling algorithm that is computationally and memory inefficient. The pixel density estimate is followed by an efficient and highly accurate updating mechanism, which permits our system to be automatically adapted to dynamically changing operation conditions. Experimental results and comparisons with other methods show that our method outperforms, in terms of precision and recall, while at the same time it keeps computational cost suitable for real-time applications.", "histories": [["v1", "Mon, 29 Jun 2015 11:16:41 GMT  (1210kb,D)", "http://arxiv.org/abs/1506.08581v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["konstantinos makantasis", "anastasios doulamis", "nikolaos doulamis"], "accepted": false, "id": "1506.08581"}, "pdf": {"name": "1506.08581.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["kmakantasis@isc.tuc.gr;", "adoulam@cs.ntua.gr;", "ndoulam@cs.ntua.gr"], "sections": [{"heading": "1. INTRODUCTION", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "1.1. Our contribution", "text": "This paper presents background modeling to be able to provide an estimate of the per-pixel density, taking into account the special properties of infrared images, such as a low signal-to-noise ratio. Our method uses a Gaussian mixing model with an unknown number of components. The advantage of such a model is that its own parameters and structure can be estimated directly from the data, allowing a dynamic adaptation of the model to uncontrolled and changing environments.An important problem in the proposed Gaussian mixing modeling concerns learning the model parameters. In our method, this is addressed using a variable inference frame to correspond to the functional structure of the model with real data distri-tions from the infrared images. Then, the expectation maximization (EM) algorithm is used to match the result of variable inferencing to real measurements."}, {"heading": "2. GAUSSIAN MIXTURE MODELING", "text": "For this reason, in Section 2.1 we briefly describe the basic theory of the Gaussian mixing model, while in Section 2.2 we describe the introduction of conjugate priorities to help us create analytical model estimates such as in Section 3."}, {"heading": "2.1. Model fundamentals", "text": "The Gaussian mixture distribution can be considered as a linear superposition of Gaussian function components = p (x | $, p) = p (x, p) = K (x, p). (1) where the parameters {$k} Kk = 1 0 \u2264 $k \u2264 1 for each k and \u00b2 K = 1 $k = 1 and K is the number of Gaussian components. In the proposed mixture modeling, variable K can assume any natural value up to infinity. However, it is strongly recommended to set the upper limit for K smaller than the cardinality of the dataset, i.e. the number of samples observed. (by introducing a K-dimensional latent variable z, such as K = 1 zk = 1 zk = 1 and p (zk = 1) = $k, the distribution p (x), the distribution variable p (x) can be specified with regard to a boundary distribution p (z) and a conditional distribution (z) as the following k-z (z)."}, {"heading": "2.2. Conjugate priors", "text": "To avoid computational problems in estimating the parameters and structure of the proposed Gaussian model q = q = q = q = = = conjugate priors, which allow us to provide analytical solutions, avoiding the need to use sampling methods and as q (Y) their distribution. Our goal is then to estimate q (Y), which maximizes the model proof p (X). q (Y).q (Y): max ln p (X) (7), where we use the logarithm of p (X) for the calculation purposes. To define the distribution over Y, that is, p (Z) and p (Z)."}, {"heading": "3. OPTIMAL MODEL PARAMETER DISTRIBUTIONS", "text": "According to (5), (6), (8) and (9), the common distribution of all random variables can be factored as the following (X, Z, $, \u00b5, \u03c4) = p (X | Z, \u00b5, \u03c4) p (Z | $) p (\u00b5 | \u03c4) p (\u03c4) (12) X corresponds to the set of observed variables. All proofs are listed in Appendix A."}, {"heading": "3.1. Optimal q\u2217(Z) distribution", "text": "Using (11) and the factorized form of (12), the distribution of the optimized factor q \u0445 (Z) is obtained by a multinomial distribution of formq \u0445 (Z) = N \u0441n = 1 K \u0445 k = 1 (\u03c1nk \u0445 K = 1 \u03c1nj) znk = (13a) = N \u0441n = 1 K \u0445 k = 1 rznknk (13b) as \u03c1nk, we have the quantity\u03c1nk = exp (E [ln $k] + 1 2 E [ln \u03c4k] \u2212 1 2 ln 2\u03c0 \u2212 -1 2 E\u00b5, \u03c4 [(xn \u2212 \u00b5k) 2\u03c4k]) (14) The expected value E [znk] of q \u0445 (Z) is equal to rnk."}, {"heading": "3.2. Optimal q\u2217($) distribution", "text": "Using (12) and (11), the distribution of the optimized factor q \u043a ($) receives a Dirichlet distribution of formq \u043a ($) = \u044b (\u2211 K i = 1 \u03bbi) \u0441Kj = 1 \u0445 (\u03bbj) K-k = 1 $\u03bbk \u2212 1k (15) \u03bbk is equal to Nk + \u03bb0, where Nk = \u2211 N = 1 rnk represents the portion of the data belonging to the k-th component."}, {"heading": "3.3. Optimal q\u2217(\u00b5k|\u03c4k) distribution", "text": "Similarly, the distribution of the optimized factor q * (\u00b5k, \u03c4k) is given by a Gaussian distribution of formq * (\u00b5k | \u03c4k) = N (\u00b5k | mk, (\u03b2k\u03c4) \u2212 1) (16), where the parameters mk and \u03b2k are given by \u03b2k = \u03b20 + Nk (17a) mk = 1\u03b2k (\u03b20m0 + Nkx-k) (17b), where x-k equals 1Nk-N = 1 rnkxn at the center of the data belonging to the k-th component."}, {"heading": "3.4. Optimal q\u2217(\u03c4k) distribution", "text": "According to the estimation of q \u0445 (\u00b5k | \u03c4k), the distribution of the optimized factor q \u0445 (\u03c4k) is obtained by a gamma distribution of the following formq \u0445 (\u03c4k) = gam (\u03c4k | ak, bk) (18), while the parameters ak and bk are given by the following relation sak = a0 + Nk 2 (19a) bk = b0 + 12 (Nk\u03c3k + \u03b20Nk \u03b20 + Nk (x-k \u2212 m0) 2) (19b), where \u03c3k = 1Nk \u0445 N = 1 (xn \u2212 x-k) 2."}, {"heading": "4. DISTRIBUTION PARAMETERS OPTIMIZATION", "text": "We have the same number of observations as the actual number of observations associated with each component. To introduce an uninformative approach, we set the parameters 0 equal to N / K, indicating that the same number of observations is associated with each component. Parameters a0 and b0 (positive values due to the gamma distribution) were set to a value of 10 \u2212 3. Our choice is justified by the fact that the results of updating equations (19a) and (19b) are primarily influenced by the data and the previous values."}, {"heading": "5. ONLINE UPDATING MECHANISM", "text": "After describing how our model fits to N observed data, in this section we present the mechanism that allows our model to automatically adapt to new observed data. We do not use heuristic rules, but statistics based on the observed data. Let's call xnew a new observed sample. Then, there are two cases; either the new observed sample is successfully modeled by our trained model, or not. To estimate whether a new sample is successfully modeled, we find the next component that comes closest to the new sample. $$$1 between components and the new sample we use the Mahalanobis distance, as it is reliable. The next component c of the new sample is the one that is the minimum Mahalanobis distance Dkc = arg min k component. (xnew \u2212 \u00b5k) The probability of the new sample belongs to cp (xnew)."}, {"heading": "6. BACKGROUND SUBTRACTION", "text": "In this section, we use our model for subtracting the background. First, we capture N-frames, which are used to create a history of infrared reactions for each pixel. These gradients act as observed data and serve to form a model for each pixel. To classify a pixel of a newly captured frame as a background or foreground, we calculate the probability that its value is represented by the blend model. If this value is greater than a threshold, the pixel is classified as a background, otherwise it is classified as a foreground. The threshold can be defined depending on the parameters of the mixture to be dynamically adjusted."}, {"heading": "7. EXPERIMENTAL RESULTS", "text": "For the evaluation of our objectives, we have reached the time required to achieve the objectives we have set ourselves."}, {"heading": "8. CONCLUSIONS", "text": "This paper presents a method of background subtraction applicable to thermal imaging cameras, based on Gaussian mixture modelling with an unknown number. We analytically derive the solutions describing the parameters of the model and use EM optimization to estimate its values, avoid sampling algorithms and high computational costs. Due to its low computational costs and real-time operation, our method is suitable for real-world applications."}, {"heading": "A. APPENDIX", "text": "Using (11) and (12), the logarithm of q \u0445 (Z) = q q = q (Z) = ln q (Z) = E $[ln p (Z | $)] + + p p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + p (Z) + 1 E [ln $k] + 1 E [ln $k] \u2212 p (Z) + 1 E [ln $k] \u2212 p (Z) \u2212 p (Z) + 2 E [ln $2 ln 2p (Z) \u2212 n $2 ln 2p (Z), p), p (Z) = p (Z), p (Z), p (Z) and p (Z), p (Z) and p (Z)."}, {"heading": "B. REFERENCES", "text": "[1] C. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics) 6 May 2007. [2] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, March 2004. [3] S. Brutzer, B. Hoferlin, and G. Heidemann. Evaluation of background subtraction techniques for video surveillance. In 2011 IEEConference on Computer Vision and Pattern Recognition (CVPR), pages 1937-1944, June 2011. [4] S.-C. S. Cheung, and C. Kamath. Robust background subtraction with foreground validation for urban traffic video. EURASIP Journalances in Signal Processing, 2005. [5] C. Dai, Y. Zheng, and X. Li. Pedestrian detection and tracking in infrared imagery using shape and appearance."}], "references": [{"title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "author": ["C. Bishop"], "venue": "Springer, Oct.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge University Press, Mar.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Evaluation of background subtraction techniques for video surveillance", "author": ["S. Brutzer", "B. Hoferlin", "G. Heidemann"], "venue": "2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1937\u20131944, June", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust background subtraction with foreground validation for urban traffic video", "author": ["S.-C.S. Cheung", "C. Kamath"], "venue": "EURASIP Journal on Advances in Signal Processing, 2005(14):726261, Aug.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Pedestrian detection and tracking in infrared imagery using shape and appearance", "author": ["C. Dai", "Y. Zheng", "X. Li"], "venue": "Computer Vision and Image Understanding, 106(23):288\u2013299, May", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "On-line estimation with the multivariate gaussian distribution", "author": ["S. Dasgupta", "D. Hsu"], "venue": "Proceedings of the 20th Annual Conference on Learning Theory, COLT\u201907, pages 278\u2013292, Berlin, Heidelberg,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Fusion-based background-subtraction using contour saliency", "author": ["J. Davis", "V. Sharma"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, 2005. CVPR Workshops, pages 11\u201311, June", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Robust background-subtraction for person detection in thermal imagery", "author": ["J.W. Davis", "V. Sharma"], "venue": "Proceedings of the 2004 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW\u201904) Volume 8 - Volume 08, CVPRW \u201904, pages 128\u2013, Washington, DC, USA,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Background-subtraction in thermal imagery using contour saliency", "author": ["J.W. Davis", "V. Sharma"], "venue": "International Journal of Computer Vision, 71(2):161\u2013181, Feb.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Fuzzy statistical modeling of dynamic backgrounds for moving object detection in infrared videos", "author": ["F. El Baf", "T. Bouwmans", "B. Vachon"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009, pages 60\u201365, June", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Non-parametric model for background subtraction", "author": ["A. Elgammal", "D. Harwood", "L. Davis"], "venue": "D. Vernon, editor, Computer Vision ECCV 2000, number 1843 in Lecture Notes in Computer Science, pages 751\u2013767. Springer Berlin Heidelberg, Jan.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Finite asymmetric generalized gaussian mixture models learning for infrared object detection", "author": ["T. Elguebaly", "N. Bouguila"], "venue": "Computer Vision and Image Understanding, 117(12):1659\u20131671, Dec.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Long-term occupancy analysis using graph-based optimisation in thermal imagery", "author": ["R. Gade", "A. Jorgensen", "T. Moeslund"], "venue": "2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3698\u20133705, June", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Background subtraction with DirichletProcess mixture models", "author": ["T. Haines", "T. Xiang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(4):670\u2013683, Apr.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Background subtraction techniques: Systematic evaluation and comparative analysis", "author": ["S. Herrero", "J. Bescs"], "venue": "Proceedings of the 11th International Conference on Advanced Concepts for Intelligent Vision Systems, ACIVS \u201909, pages 33\u201342, Berlin, Heidelberg,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Feature based person detection beyond the visible spectrum", "author": ["K. Jungling", "M. Arens"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, 2009. CVPR Workshops 2009, pages 30\u201337, June", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Tracking motion objects in infrared videos", "author": ["L. Latecki", "R. Miezianko", "D. Pokrajac"], "venue": "IEEE Conference on Advanced Video and Signal Based Surveillance, 2005. AVSS 2005, pages 99\u2013104, Sept.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Student-t background modeling for persons\u2019 fall detection through visual cues", "author": ["K. Makantasis", "A. Doulamis", "N. Matsatsinis"], "venue": "2012 13th International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), pages 1\u20134, May", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Segmentation and tracking of piglets in images", "author": ["N.J.B. McFarlane", "C.P. Schofield"], "venue": "Machine Vision and Applications, 8(3):187\u2013193, May", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}, {"title": "A kalman filter based background updating algorithm robust to sharp illumination changes", "author": ["S. Messelodi", "C.M. Modena", "N. Segata", "M. Zanin"], "venue": "F. Roli and S. Vitulano, editors, Image Analysis and Processing ICIAP 2005, number 3617 in Lecture Notes in Computer Science, pages 163\u2013170. Springer Berlin Heidelberg, Jan.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Achieving real-time object detection and tracking under extreme conditions", "author": ["F. Porikli"], "venue": "Journal of Real-Time Image Processing, 1(1):33\u201340, Mar.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Adaptive background mixture models for real-time tracking", "author": ["C. Stauffer", "W. Grimson"], "venue": "Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., volume 2, pages \u2013252 Vol. 2,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1999}, {"title": "Wallflower: principles and practice of background maintenance", "author": ["K. Toyama", "J. Krumm", "B. Brumitt", "B. Meyers"], "venue": "The Proceedings of the Seventh IEEE International Conference on Computer Vision, 1999, volume 1, pages 255\u2013261 vol.1,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Human detection via classification on riemannian manifolds", "author": ["O. Tuzel", "F. Porikli", "P. Meer"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2007. CVPR \u201907, pages 1\u20138, June", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Pedestrian detection via classification on riemannian manifolds", "author": ["O. Tuzel", "F. Porikli", "P. Meer"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 30(10):1713\u20131727, Oct.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Improved human detection and classification in thermal images", "author": ["W. Wang", "J. Zhang", "C. Shen"], "venue": "2010 17th IEEE International Conference on Image Processing (ICIP), pages 2313\u20132316, Sept.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Pfinder: real-time tracking of the human body", "author": ["C. Wren", "A. Azarbayejani", "T. Darrell", "A. Pentland"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7):780\u2013785, July", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1997}, {"title": "Extracting roadway background image: Mode-based approach", "author": ["J. Zheng", "Y. Wang", "N. Nihan", "M. Hallenbeck"], "venue": "Transportation Research Record: Journal of the Transportation Research Board, 1944:82\u201388, Jan.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Improved adaptive gaussian mixture model for background subtraction", "author": ["Z. Zivkovic"], "venue": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004, volume 2, pages 28\u201331 Vol.2, Aug.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficient adaptive density estimation per image pixel for the task of background subtraction", "author": ["Z. Zivkovic", "F. van der Heijden"], "venue": "Pattern Recognition Letters,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2006}], "referenceMentions": [{"referenceID": 12, "context": "Furthermore, infrared imagery eliminates any privacy issues as people being depicted in the scene can not be identified [13].", "startOffset": 120, "endOffset": 124}, {"referenceID": 3, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 85, "endOffset": 97}, {"referenceID": 20, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 85, "endOffset": 97}, {"referenceID": 23, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 85, "endOffset": 97}, {"referenceID": 24, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 85, "endOffset": 97}, {"referenceID": 15, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 115, "endOffset": 125}, {"referenceID": 16, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 115, "endOffset": 125}, {"referenceID": 25, "context": "For many high-level vision based applications, either they use visual-optical videos [4,21,24,25] or infrared data [16,17,26], the task of background subtraction constitutes a key component, as this is one of the most common methods for locating moving objects, facilitating search space reduction and visual attention modeling.", "startOffset": 115, "endOffset": 125}, {"referenceID": 2, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 114, "endOffset": 121}, {"referenceID": 14, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 114, "endOffset": 121}, {"referenceID": 9, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 171, "endOffset": 175}, {"referenceID": 18, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 203, "endOffset": 211}, {"referenceID": 27, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 203, "endOffset": 211}, {"referenceID": 10, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 245, "endOffset": 253}, {"referenceID": 26, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 245, "endOffset": 253}, {"referenceID": 19, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 280, "endOffset": 288}, {"referenceID": 22, "context": "Background subtraction techniques applied on visual-optical videos model the color properties of depicted objects [3, 15] and can be classified into three main categories [10]: basic background modeling [19, 28], statistical background modeling [11, 27] and background estimation [20, 23].", "startOffset": 280, "endOffset": 288}, {"referenceID": 21, "context": "Towards this direction, the work of Stauffer and Grimson [22], is one of the best known approaches.", "startOffset": 57, "endOffset": 61}, {"referenceID": 17, "context": "in [18] propose a Student-t mixture model for background modeling, taking advantage of Student-t distribution compactness and robustness to noise and outliers.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components.", "startOffset": 13, "endOffset": 17}, {"referenceID": 29, "context": "The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components.", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "The works of [29] and [30] extend the method of [22] by introducing a rule based on a user defined threshold to estimate the number of components.", "startOffset": 48, "endOffset": 52}, {"referenceID": 13, "context": "Haines and Xiang in [14] address this drawback by using a Dirichlet process mixture model.", "startOffset": 20, "endOffset": 24}, {"referenceID": 6, "context": "The authors of [7\u20139] exploit contour saliency to extract foreground objects.", "startOffset": 15, "endOffset": 20}, {"referenceID": 7, "context": "The authors of [7\u20139] exploit contour saliency to extract foreground objects.", "startOffset": 15, "endOffset": 20}, {"referenceID": 8, "context": "The authors of [7\u20139] exploit contour saliency to extract foreground objects.", "startOffset": 15, "endOffset": 20}, {"referenceID": 9, "context": "in [10] present a fuzzy statistical method for background subtraction to incorporate uncertainty into the mixture of Gaussians.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "Elguebaly and Bouguila in [12] propose a finite asymmetric generalized Gaussian mixture model for object detection.", "startOffset": 26, "endOffset": 30}, {"referenceID": 4, "context": "in [5] propose a method for pedestrian detection and tracking using infrared imagery.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "By making the assumption, based on variational inference, that the distribution q(Y ) can be factorized over M disjoint sets such as q(Y ) = \u220fM i=1 qi(Yi), as shown in [1], the optimal solution q \u2217 j (Yj) corresponds to the minimization of KL(q||p) is given by ln q\u2217 j (Yj) = Ei6=j [ln p(X,Y )] + C (11) where Ei6=j [ln p(X,Y )] is the expectation of the joint distribution over all variables Yj for j 6= i and C is a constant.", "startOffset": 168, "endOffset": 171}, {"referenceID": 1, "context": "As shown in [2] convergence of EM algorithm is guaranteed because bound is convex with respect to each of the factors q(Z), q($), q(\u03bc|\u03c4 ) and q(\u03c4 ).", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "When the new observed sample is successfully modeled, the parameters for the Gaussian components are updated using the following the leader [6] approach described as", "startOffset": 140, "endOffset": 143}, {"referenceID": 28, "context": "Second row: updating of model presented in [29].", "startOffset": 43, "endOffset": 47}, {"referenceID": 28, "context": "Figure 2 presents the adaptation of our model (first row) and the model presented in [29] (second row) to new observed data.", "startOffset": 85, "endOffset": 89}, {"referenceID": 28, "context": "On the contrary, the model of [29] is not able to capture the statistical relations of the new observations and fails to separate the data generated from distributions with mean values 16 and 21 (middle column).", "startOffset": 30, "endOffset": 34}, {"referenceID": 6, "context": "OSU datasets [7\u20139] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery.", "startOffset": 13, "endOffset": 18}, {"referenceID": 7, "context": "OSU datasets [7\u20139] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery.", "startOffset": 13, "endOffset": 18}, {"referenceID": 8, "context": "OSU datasets [7\u20139] are widely used for benchmarking algorithms for pedestrian detection and tracking in infrared imagery.", "startOffset": 13, "endOffset": 18}, {"referenceID": 28, "context": "We compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data.", "startOffset": 64, "endOffset": 68}, {"referenceID": 7, "context": "We compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data.", "startOffset": 230, "endOffset": 235}, {"referenceID": 8, "context": "We compared our method with the method presented by Zivkovic in [29] (MOG), which is one of the most robust and widely used background subtraction technique, and with the method for extracting the regions of interest presented in [8,9] (SBG) used for thermal data.", "startOffset": 230, "endOffset": 235}], "year": 2015, "abstractText": "We propose a Gaussian mixture model for background subtraction in infrared imagery. Following a Bayesian approach, our method automatically estimates the number of Gaussian components as well as their parameters, while simultaneously it avoids over/under fitting. The equations for estimating model parameters are analytically derived and thus our method does not require any sampling algorithm that is computationally and memory inefficient. The pixel density estimate is followed by an efficient and highly accurate updating mechanism, which permits our system to be automatically adapted to dynamically changing operation conditions. Experimental results and comparisons with other methods show that our method outperforms, in terms of precision and recall, while at the same time it keeps computational cost suitable for real-time applications.", "creator": "LaTeX with hyperref package"}}}