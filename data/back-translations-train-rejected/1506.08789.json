{"id": "1506.08789", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2015", "title": "Requirement Tracing using Term Extraction", "abstract": "Requirements traceability is an essential step in ensuring the quality of software during the early stages of its development life cycle. Requirements tracing usually consists of document parsing, candidate link generation and evaluation and traceability analysis. This paper demonstrates the applicability of Statistical Term Extraction metrics to generate candidate links. It is applied and validated using two data sets and four types of filters two for each data set, 0.2 and 0.25 for MODIS, 0 and 0.05 for CM1. This method generates requirements traceability matrices between textual requirements artifacts (such as high-level requirements traced to low-level requirements). The proposed method includes ten word frequency metrics divided into three main groups for calculating the frequency of terms. The results show that the proposed method gives better result when compared with the traditional TF-IDF method.", "histories": [["v1", "Mon, 29 Jun 2015 19:21:04 GMT  (749kb)", "http://arxiv.org/abs/1506.08789v1", null]], "reviews": [], "SUBJECTS": "cs.SE cs.CL cs.IR", "authors": ["najla al-saati", "raghda abdul-jaleel"], "accepted": false, "id": "1506.08789"}, "pdf": {"name": "1506.08789.pdf", "metadata": {"source": "CRF", "title": "Requirement Tracing using Term Extraction", "authors": ["Najla Al-Saati", "Raghda Abdul-Jaleel"], "emails": [], "sections": [{"heading": null, "text": "Development lifecycle. Requirements Tracing typically consists of document analysis, candidate link generation, and evaluation and traceability analysis. This work demonstrates the applicability of statistical term extraction metrics to generate candidate links. It is applied and validated with two data sets and four filter types, two for each data set, 0.2 and 0.25 for MODIS, 0 and 0.05 for CM1. This method generates requirements traceability matrices between textual requirements (such as high-level requirements attributed to low-level requirements). The proposed method includes ten word frequency metrics, which are divided into three main groups to calculate the frequency of terms. Results show that the proposed method delivers better results compared to the traditional TF-IDF method."}, {"heading": "Keywords- Requirements Traceability; Traceability Analysis; Candidate Link Generation; Parsing; Term Extraction; Word Frequency Metrics.", "text": "This year it has come to the point where it only takes a few days for it to come to a conclusion."}, {"heading": "Where", "text": "dfi is the total number of documents containing the ith term in the document collection, and n is the size of the document collection. The term meaning is judged by how often this term is in the document and how discriminatory the term is. In other words, rarer terms have a more important presence for the document. A user query is also converted into a similar vector q = (q1,..., qN) of term weights. In this model, the similarity between them is calculated as a cosine of the angle between vectors d and q in N-dimensional space as in Equation. (3) [10] [11].... (3) V. EMPLOYD FILTERS In this work, four filters are introduced to create list candidates with relevance higher than one of the predefined levels: 0, 0.05, 0.2 and 0.25. This filtering acts as an assessment of the quality of the candidate list."}, {"heading": "VII. TERM EXTRACTION", "text": "Term extraction is an important topic in the processing of natural language; its goal is the extraction of words with precise meaning in a collection of texts. More than a few linguists considered these terms to be the basic semantic unit of language. Automation of term extraction includes machine translation, automatic indexing, the construction of lexical knowledge databases and the retrieval of information [13]. Both supervised and unsupervised techniques have been used in previous studies to extract and distinguish terms. [14] Almost all research aimed at locating the most significant phrases from a domain corpus, to be precise, the set of superficial representations of domain concepts that better symbolize the domain to a human expert. [14] Term frequency in a body is a fundamental statistical property. This can then be compared with the frequency of the term in other corpus, to be prepared for other corporeal concepts, to be precise with the occurrence of other corporeal concepts."}, {"heading": "VIII. STATISTICAL TERM METRICS", "text": "This year it is so far that it will be able to erenie.n the aforementioned lcihsrcehnlrc\u00fceF"}], "references": [{"title": "Automated Requirements Trace Retrieval Through Term-Based Enhancement Strategies\", Dissertation for the Degree of Doctor in Philosophy (Ph.D.), College of Computing and Digital Media", "author": ["X. Zou \"Improving"], "venue": "DePaul University,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Baselines in Requirements Tracing", "author": ["S.K.Sundaram", "J.H.Hayes", "A.Dekhtyar"], "venue": "In ACM SIGSOFT Software Engineering Notes", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Software System Failure and Success", "author": ["C. Jones.\"Patterns"], "venue": "Intl Thomson Computer Pr (Sd)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "On Effectiveness of User Feedback-based Information Retrieval Methods for Requirements Tracing", "author": ["J.H.Hayes", "A.Dekhtyar", "S.K.Sundaram", "S.Howard"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Its major objective is to maintain the activities of critical software development, for instance, the assessment of whether a software system has satisfied its definite set of requirements, the verification that all requirements have been employ by the end of the lifecycle, and the analysis of the impact imposed by the proposed changes on the system [1].", "startOffset": 352, "endOffset": 355}, {"referenceID": 1, "context": "Also in 2004, Sundaram, Hayes, and Dekhtyar [6] studied a mixture of IR methods used to solve the requirement traceability problem.", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "More than 80% of the failures in large-scale mission-critical projects are caused by undetected problems in the early phases of the software development lifecycle [8].", "startOffset": 163, "endOffset": 166}, {"referenceID": 3, "context": "Nearly all IR methods are keyword-based: the document and query representations contain information regarding the importance of particular keywords found in the document [10].", "startOffset": 170, "endOffset": 174}, {"referenceID": 3, "context": "(1) [10] [11].", "startOffset": 4, "endOffset": 8}, {"referenceID": 3, "context": "(2) [10][11].", "startOffset": 4, "endOffset": 8}, {"referenceID": 3, "context": "(3) [10][11].", "startOffset": 4, "endOffset": 8}, {"referenceID": 1, "context": "recall measures if a method succeeded in finding all the high-low level requirement pairs that trace to each other, while recall indicates the number of additional pairs found by the method that do not trace to each other[6].", "startOffset": 221, "endOffset": 224}, {"referenceID": 1, "context": "There were 41 and 361 true links found for the MODIS and CM-1 datasets, respectively [6].", "startOffset": 85, "endOffset": 88}, {"referenceID": 1, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "5 TF_IDF XML[6]", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "5 TF_IDF XML[6]", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "8 TF_IDF XML[6]", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "2 TF_IDF XML[6]", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "25) showed better result for all metrics when compared to [6] except for Document Term Frequency in filter 0.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "25 all of metrics showed less result than [6].", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "In CM1 dataset best value obtained in Recall measure was by using filter 0 and metrics (Logged Term Frequency, Document Term Frequency, Term Frequency \u2013 Inverse Document Frequency and Logged Inverse Document Frequency), which showed better results than [6], in filter 0.", "startOffset": 253, "endOffset": 256}, {"referenceID": 1, "context": "5, 2015 Frequency were better than [6].", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "In Precision all of metrics showed less result than [6].", "startOffset": 52, "endOffset": 55}], "year": 2015, "abstractText": "Requirements traceability is an essential step in ensuring the quality of software during the early stages of its development life cycle. Requirements tracing usually consists of document parsing, candidate link generation and evaluation and traceability analysis. This paper demonstrates the applicability of Statistical Term Extraction metrics to generate candidate links. It is applied and validated using two datasets and four types of filters two for each dataset, 0.2 and 0.25 for MODIS, 0 and 0.05 for CM1. This method generates requirements traceability matrices between textual requirements artifacts (such as high-level requirements traced to low-level requirements). The proposed method includes ten word frequency metrics divided into three main groups for calculating the frequency of terms. The results show that the proposed method gives better result when compared with the traditional TF-IDF method. KeywordsRequirements Traceability; Traceability Analysis; Candidate Link Generation; Parsing; Term Extraction; Word Frequency Metrics.", "creator": "Microsoft\u00ae Office Word 2007"}}}