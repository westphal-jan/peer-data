{"id": "1506.08909", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2015", "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems", "abstract": "This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data. The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter. We also describe two neural learning architectures suitable for analyzing this dataset, and provide benchmark performance on the task of selecting the best next response.", "histories": [["v1", "Tue, 30 Jun 2015 00:37:09 GMT  (1018kb,D)", "http://arxiv.org/abs/1506.08909v1", "Accepted as a conference submission to SIGDIAL 2015. 10 pages, 5 figures"], ["v2", "Tue, 21 Jul 2015 16:11:29 GMT  (1019kb,D)", "http://arxiv.org/abs/1506.08909v2", "Accepted as a conference submission to SIGDIAL 2015. 10 pages, 5 figures. Update: Includes link to download dataset"], ["v3", "Thu, 4 Feb 2016 01:21:35 GMT  (1019kb,D)", "http://arxiv.org/abs/1506.08909v3", "SIGDIAL 2015. 10 pages, 5 figures. Update includes link to new version of the dataset, with some added features and bug fixes. See:this https URL"]], "COMMENTS": "Accepted as a conference submission to SIGDIAL 2015. 10 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG cs.NE", "authors": ["ryan lowe", "nissan pow", "iulian serban", "joelle pineau"], "accepted": false, "id": "1506.08909"}, "pdf": {"name": "1506.08909.pdf", "metadata": {"source": "CRF", "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems", "authors": ["Ryan Lowe", "Nissan Pow", "Iulian V. Serban", "Joelle Pineau"], "emails": [], "sections": [{"heading": null, "text": "This paper introduces the Ubuntu Dialogue Corpus, a data set of nearly 1 million multi-turn dialogs with a total of over 7 million utterances and 100 million words. It is a unique resource for exploring the structure of dialog managers based on neural language models that can use large amounts of unlabeled data. It features both the multi-turn capability of conversations in the Dialog State Tracking Challenge datasets and the unstructured nature of interactions from microblog services such as Twitter. We also describe two neural learning architectures that lend themselves to analyzing this data set, and provide benchmark performance in the task of selecting the best next response."}, {"heading": "1 Introduction", "text": "The ability to live in a country where most people live in poverty has declined significantly in recent years."}, {"heading": "2 Related Work", "text": "We review briefly existing dialog records and some of the newer learning architectures used for both structured and unstructured dialogs. Far from being an exhaustive list (due to space constraints), this includes resources that are most closely related to our contribution. A list of the records discussed is given in Table 1."}, {"heading": "2.1 Dialogue Datasets", "text": "These datasets were significant resources for structured dialogs and allowed significant progress in this area, although they are relatively small compared to datasets currently used for the formation of neural architectures. Recently, however, some datasets containing unstructured dialogs extracted from Twitter3 have been used. Ritter et al. [20] collected 1.3 million conversations; this was expanded into [27] to exploit longer contexts using A-B-A triples. Shang et al. [24] used data from a similar Chinese website called Weibo4."}, {"heading": "2.2 Learning Architectures", "text": "A notable exception is the work of Henderson et al. [10], which proposes an RNN structure initialized with a denoting autoencoder to tackle the DSTC-3 domain.The work on unstructured dialogues, recently advanced by Ritter et al. [21], suggested a response generation model for Twitter data based on ideas from statistical machine translation, showing that it is superior to earlier information retrievals (e.g. the closest neighboring country). [13] This idea was further developed by Sordoni et al. [27] to use information from a longer context, using a structure similar to the recurrent Neural Network Encoder model. [4] This model performs rather poorly on A-B-A-Twitter when measured using the BLEU score (a standard for subject translation), with this subject becoming even more comparable to the NN model."}, {"heading": "3 The Ubuntu Dialogue Corpus", "text": "We are looking for a large dataset for the exploration of dialog systems with the following characteristics: \u2022 Two-way conversation as opposed to chat with multiple participants, preferably human-human. \u2022 Large number of conversations; 105 \u2212 106 is typical of datasets used for learning neural networks in other areas of AI. \u2022 Many conversations with multiple phrases (significantly more than 3). \u2022 Task-specific domain as opposed to chat messaging systems. All of these requirements are met by the Ubuntu Dialogue Corpus presented in this paper."}, {"heading": "3.1 Ubuntu Chat Logs", "text": "The Ubuntu chat protocols refer to a collection of protocols from Ubuntu-related chat rooms on the Freenode Internet Relay Chat (IRC) network. This protocol enables real-time chat between a large number of participants. Each chat room or channel has a specific topic, and each channel participant can see all messages posted on a specific channel. Many of these channels are used to provide technical support for various Ubuntu issues. Although users are free to chat on each topic in the channel, most interactions follow a similar pattern. A new user joins the channel and asks a general question about a problem they have with Ubuntu. Then another more experienced user answers with a potential solution after first addressing the \"username\" of the first user, in order to avoid channel confusion - at any given time during the day, there may be between 1 and 20 simultaneous conversations taking place in some channels."}, {"heading": "3.2 Dataset Creation", "text": "In order to create the Ubuntu Dialogue Corpus, a method had to be developed to extract two-way dialogs from the multi-party conversations in the chat room. In the first step, each message was divided into 4 tuples (time, sender, recipient, utterance). Given these 4 tuples, it is easy to group all tuples where there is a suitable sender and recipient. Although it is easy to separate time and sender from the rest, it is not always trivial to find the intended recipient of the message."}, {"heading": "3.2.1 Recipient Identification", "text": "While in most cases the recipient is the first word of the utterance, it is sometimes at the end or not at all in the case of initial questions. In addition, some users choose names that correspond to common English words, such as \"the\" or \"stop,\" which could lead to many false positives. To solve this problem, we create a dictionary of usernames from the previous day and compare the first word of each utterance with its entries. If a match is found and the word does not match a very common English word5, it is assumed that this user was the intended recipient of the message. If no matches are found, it is assumed that the message is an initial question and the value of the recipient is left blank."}, {"heading": "3.2.2 Utterance Creation", "text": "The dialog extraction algorithm works backwards from the first answer, to find the original question to which the answer was given within a limited period of 3 minutes. An initial answer is identified by the presence of a recipient name (someone from the recent conversation history); the initial question is identified as the most recent utterance by the recipient identified in the first answer.Any utterances that are not qualified as a first answer or an initial question are discarded; initial questions that do not produce an answer are also discarded. In addition, we discard conversations that are longer than five utterances in which a user says more than 80% of the utterances, as these are usually not representative of real chat dialogs. Finally, we only look at extracted dialogs that consist of 3 phrases or more to promote the modeling of longer-term dependencys.To alleviate the problem of \"holes\" in the dialog, where a user does not explicitly address the other user, as we do with anyone who speaks explicitly to someone in 5, as we do in 5."}, {"heading": "3.2.3 Special Cases and Limitations", "text": "In this case, each conversation between the first user and the user who responded is treated as a separate dialog, with the unfortunate side effect that the initial question appears several times in multiple dialogs. However, the number of such cases is sufficiently small compared to the size of the record. Another problem is that the time the utterance is posted is not taken into account for segmenting conversations between two users. Even if two users have a conversation that extends several hours or even days, this is treated as a single dialog. However, such dialogs are rare. We include the posting time in the corpus so that other researchers can filter as desired."}, {"heading": "3.3 Dataset Statistics", "text": "Table 2 summarizes the characteristics of the Ubuntu dialogue corpus. One of the most important features of the Ubuntu chat protocols is its size, which is crucial for researching the structure of dialogue managers based on neural architectures. Another important feature is the number of rotations in these dialogs. The distribution of the rotations is shown in Figure 1. It can be seen that the number of dialogs and rotations per dialog follows an approximate legal relationship."}, {"heading": "3.4 Test Set Generation", "text": "We set aside 2% of the Ubuntu Dialogue Corpus conversations (randomly selected) to extract a pair (context, answer, flag) of triples from each dialog; the flag is a Boolean variable that indicates whether the answer was the actual next utterance after the given context or not; the answer is a target (output) utterance that we want to correctly identify; the context consists of a sequence of utterances that appear in the dialog before the answer; we create a pair of triples, one triple containing the correct answer (i.e., the actual next utterance in the dialog), and the other triple contains an incorrect answer that is randomly selected from another part of the test set; the flag is set to 1 in the first case and 0 in the second case; an example pair is shown in Table 3. To make the task more difficult, we can move all pairs of dissent = 10 responses to an incorrect answer."}, {"heading": "3.5 Evaluation Metric", "text": "This classification task is an adjustment of recall and precision metrics previously applied to dialog data sets [23].One family of metrics commonly used in language tasks is Recall @ k. Here, the agent is asked to select the k most likely answers, and it is correct if the true answer is among these k candidates. In the case of binary classification (as in Table 3), only the R @ 1 metric is relevant. Although a language model that performs well in classifying answers is not a indicator of good performance in the next generation of expression, we assume that improvements to a model in the classification task will ultimately lead to improvements in the generation task. See section 6 for more discussion on this point."}, {"heading": "4 Learning Architectures for Unstructured Dialogues", "text": "In order to provide further evidence of the value of our dataset for the study of neural architectures for dialogue managers, we provide performance benchmarks for two neural learning algorithms and a naive baseline. The approaches considered are: TF-IDF, Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM). Prior to applying each method, we perform standard pre-processing of the data using the NLTK6 library and Twitter tokenizer7 to analyze each utterance. We use generic tags for various word categories, such as names, locations, organizations, 6www.nltk.org / 7http: / www.ark.cs.cmu.edu / TweetNLP / URLs and system path. To train the RNNN and LSTM architectures, we process the full training of Ubuntu Dialogue Corpus in the same format as we extract the text in the corresponding section 3.4 of the answer, where we extract the answers from the corresponding flag length."}, {"heading": "4.1 TF-IDF", "text": "The frequency of the term inverse document is a statistic used to determine how important a particular word is to a particular document, in our case context [19]. It is a technique commonly used in classifying documents and retrieving information; the term frequency is simply a count of the number of times a word appears in a given context, while the term \"inverse document\" is a penalty for how often the word appears elsewhere in the corpus.The end result is calculated as the product of these two terms and is in the form of: tfidf (w, d, D) = f (w, d) \u00b7 log N | {d \u00b2 D: w, d} | where f (w, d) indicates the number of times the word w appeared in the context d, N is the total number of dialogs, and the denominator represents the number of dialogs in which the word w occurs. To classify, the TF IDF vectors are first calculated for each of the responses to the highest context, with @ being the highest for each one."}, {"heading": "4.2 RNN", "text": "The internal state is updated at each step of the time as a function of the observed xt variable, and the hidden state at the previous time step ht \u2212 1. Wx andWh are matrices associated with the input and hidden state.ht = f (Whht \u2212 1 + Wxxt) A diagram of an RNN can be seen in Figure 2. RNs are the primary building block of many current neural speech models [21, 27] that use RNNs for an encoder and decoder, the first RNN is used to encode the given context, and the second RNN generates a response by using beam search, where its initial hidden state is distorted using the last hidden state."}, {"heading": "4.3 LSTM", "text": "In addition to the RNN model, we look at the same architecture, but changed the hidden units to Long-Term Short-Term Memory Units (LSTM) [11], which should improve learning of the embedding of the sentence, especially for long pronouncements. LSTMs were introduced to model long-term dependencies, since LSTM units can remember a value for any length of time. This is achieved through a series of gates that determine whether a new input should be remembered, forgotten (and keep the old value), or used as output. The error signal can now be fed back into the gates of the LSTM unit indefinitely, helping to overcome the vanishing and exploding gradients problems in standard RNNNNs, where the error gradients would otherwise decrease or increase exponentially. In training, we used a hidden layer of 200 neurons. Configuration of hyperparameters (including the number of neurons) became NRMs and STLMs independent."}, {"heading": "5 Empirical Results", "text": "The results for the TF-IDF, RNN and LSTM models are presented in Table 4. Results presented here were trained using only 1 / 8 of the Ubuntu Dialogue Corpus. Models were evaluated using both 1 (1 in 2) and 9 (1 in 10) false examples. Of course, Recall @ 2 and Recall @ 5 are not relevant in the case of binary classification. We observe that the LSTM significantly outperforms both the RNN and the TF-IDF in all evaluation metrics. Interestingly, TF-IDF actually outperforms the RNN in the case of Recall @ 1 and Recall @ 2 in the case of the 1 in 10 classification, most likely due to the RNN's limited ability to take into account long contexts that can be overcome by using the LSTM."}, {"heading": "6 Discussion", "text": "This paper introduces the Ubuntu Dialogue Corpus, a large dataset for the research of unstructured multi-turn dialog systems. We describe the structure of the dataset and its properties. The availability of a dataset of this size opens several interesting possibilities for the research of dialog systems based on rich neural network architectures. We present preliminary results demonstrating the use of this dataset to train an RNN and an LSTM for the task of selecting the next best answer in a conversation; we achieve significantly better results with the LSTM architecture. There are several interesting directions for future work."}, {"heading": "6.1 Conversation Disentanglement", "text": "Our approach to the unbundling of conversations consists of a small set of rules. More sophisticated techniques have been proposed, such as the formation of a maximum entropy classifier to cluster expressions in separate dialogues. [6] However, since we are not trying to replicate the exact conversation between two users, but merely retrieve plausible natural dialogues, the heuristic method presented in this paper may be sufficient. This seems to be supported by qualitative analysis of the data, but could be the subject of a more formal evaluation."}, {"heading": "6.2 Altering Test Set Difficulty", "text": "One of the interesting features of the answer selection task is the ability to change the difficulty of the task in a controlled way. We demonstrated this by changing from 1 to 9 wrong answers and varying the Recall @ k parameter. Instead of randomly selecting wrong answers, we will consider wrong answers similar to the actual answer (e.g. measured by cosmic similarity) in the future. We expect that a dialogue model that handles this more difficult task well would also capture a finer-grained semantic meaning of sentences, compared to a model that naively selects answers with most words common to the context such as TF-IDF."}, {"heading": "6.3 State Tracking and Utterance Generation", "text": "The work described here focuses on the task of response selection. In some ways, this can be seen as an incompetent intermediate step between slot filling and utterance generation. In slot filling, the set of candidate outputs (states) is identified a priori by knowledge engineering and is typically smaller than the set of responses taken into account in our work. If the set of candidate responses is close to the size of the data set (e.g. any utterances ever recorded), then we are fairly close to the response generation case. There are several reasons why we should not proceed directly to response generation. Firstly, it is likely that current algorithms are not yet able to produce good results for this task, and it is preferable to approach metrics for which we can make progress. Secondly, we do not yet have a suitable metric for evaluating the performance in response generation case. One option is to use the BLEU [17] or EU METER [METE15] results to generate extremely short BLEU-to-machine translation results."}, {"heading": "Appendix A: Dialogue excerpts", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Open question answering with weakly supervised embedding models", "author": ["A. Bordes", "J. Weston", "N. Usunier"], "venue": "In MLKDD,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Besting the quiz master: Crowdsourcing incremental classification games", "author": ["J. Boyd-Graber", "B. Satinoff", "H. He", "H. Daume"], "venue": "In EMNLP,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.J. Li", "K. Li", "L. Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "You talking to me? a corpus and algorithm for conversation disentanglement", "author": ["M. Elsner", "E. Charniak"], "venue": "In ACL,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Switchboard: Telephone speech corpus for research and development", "author": ["J.J. Godfrey", "E.C. Holliman", "J. Mc- Daniel"], "venue": "In ICASSP,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1992}, {"title": "Dialog state tracking challenge 2 ", "author": ["M. Henderson", "B. Thomson", "J. Williams"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "The second dialog state tracking challenge", "author": ["M. Henderson", "B. Thomson", "J. Williams"], "venue": "In SIGDIAL,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Word-based dialog state tracking with recurrent neural networks", "author": ["M. Henderson", "B. Thomson", "S. Young"], "venue": "In SIGDIAL,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Filter,  rank, and transfer the knowledge: Learning to chat", "author": ["S. Jafarpour", "C. Burges", "A. Ritter"], "venue": "Advances in Ranking,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "CoRR, abs/1412.6980,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "The ME- TEOR metric for automatic evaluation of Machine Translation", "author": ["A. Lavie", "M.J. Denkowski"], "venue": "Machine Translation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Recurrent neural networks", "author": ["L.R. Medsker", "L.C. Jain"], "venue": "Design and Applications,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "W.J. Zhu"], "venue": "In ACL,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "GloVe: Global Vectors for Word Representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "In EMNLP,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Using tf-idf to determine word relevance in document queries", "author": ["J. Ramos"], "venue": "In ICML,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Unsupervised modeling of twitter conversations", "author": ["A. Ritter", "C. Cherry", "W. Dolan"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Datadriven response generation in social media", "author": ["A. Ritter", "C. Cherry", "W. Dolan"], "venue": "In EMNLP,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["A.M. Saxe", "J.L. McClelland", "S. Ganguli"], "venue": "arXiv preprint arXiv:1312.6120,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Quantitative evaluation of user simulation techniques for spoken dialogue systems", "author": ["J. Schatzmann", "K. Georgila", "S. Young"], "venue": "In SIGDIAL,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Neural responding machine for short-text conversation", "author": ["L. Shang", "Z. Lu", "H. Li"], "venue": "arXiv preprint arXiv:1503.02364,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Chatbots: are they really useful", "author": ["B.A. Shawar", "E. Atwell"], "venue": "In LDV Forum,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Optimizing dialogue management with reinforcement learning: Experiments with the NJFun system", "author": ["S. Singh", "D. Litman", "M. Kearns", "M. Walker"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2002}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "J.Y. Nie", "J. Gao", "W. Dolan"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Extending word highlighting in multiparticipant chat", "author": ["C.C. Uthus", "D.W Aha"], "venue": "Technical report, DTIC Document,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "A dataset for research on short-text conversations", "author": ["H. Wang", "Z. Lu", "H. Li", "E. Chen"], "venue": "In EMNLP,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "The dialog state tracking challenge", "author": ["J. Williams", "A. Raux", "D. Ramachandran", "A. Black"], "venue": "In SIGDIAL,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Deep learning for answer sentence selection", "author": ["L. Yu", "K.M. Hermann", "P. Blunsom", "S. Pulman"], "venue": "arXiv preprint arXiv:1412.1632,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Adadelta: an adaptive learning rate method", "author": ["M.D. Zeiler"], "venue": "arXiv preprint arXiv:1212.5701,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}], "referenceMentions": [{"referenceID": 8, "context": "This is in contrast to recent systems which focus on structured dialogue tasks, using a slot-filling representation [9, 26, 30].", "startOffset": 116, "endOffset": 127}, {"referenceID": 24, "context": "This is in contrast to recent systems which focus on structured dialogue tasks, using a slot-filling representation [9, 26, 30].", "startOffset": 116, "endOffset": 127}, {"referenceID": 28, "context": "This is in contrast to recent systems which focus on structured dialogue tasks, using a slot-filling representation [9, 26, 30].", "startOffset": 116, "endOffset": 127}, {"referenceID": 0, "context": "methods, more specifically with neural architectures [1]; however, it is worth noting that many of the most successful approaches, in particular convolutional and recurrent neural networks, were known for many years prior.", "startOffset": 53, "endOffset": 56}, {"referenceID": 4, "context": "It is therefore reasonable to attribute this progress to three major factors: 1) the public distribution of very large rich datasets [5], 2) the availability of substantial computing power, and 3) the development of new training methods for neural architectures, in particular leveraging unlabeled data.", "startOffset": 133, "endOffset": 136}, {"referenceID": 28, "context": "The dataset is orders of magnitude larger than structured corpuses such as those of the Dialogue State Tracking Challenge [30].", "startOffset": 122, "endOffset": 126}, {"referenceID": 19, "context": "It is on the same scale as recent datasets for solving problems such as question answering and analysis of microblog services, such as Twitter [21, 24, 27, 31], but each conversation in our dataset includes several more turns, as well as longer utterances.", "startOffset": 143, "endOffset": 159}, {"referenceID": 22, "context": "It is on the same scale as recent datasets for solving problems such as question answering and analysis of microblog services, such as Twitter [21, 24, 27, 31], but each conversation in our dataset includes several more turns, as well as longer utterances.", "startOffset": 143, "endOffset": 159}, {"referenceID": 25, "context": "It is on the same scale as recent datasets for solving problems such as question answering and analysis of microblog services, such as Twitter [21, 24, 27, 31], but each conversation in our dataset includes several more turns, as well as longer utterances.", "startOffset": 143, "endOffset": 159}, {"referenceID": 29, "context": "It is on the same scale as recent datasets for solving problems such as question answering and analysis of microblog services, such as Twitter [21, 24, 27, 31], but each conversation in our dataset includes several more turns, as well as longer utterances.", "startOffset": 143, "endOffset": 159}, {"referenceID": 23, "context": "Furthermore, because it targets a specific domain, namely technical support, it can be used as a case study for the development of AI agents in targeted applications, in contrast to chatbox agents that often lack a welldefined goal [25].", "startOffset": 232, "endOffset": 236}, {"referenceID": 6, "context": "The Switchboard dataset [7], and the Dialogue State Tracking Challenge (DSTC) datasets [30] have been used to train and validate dialogue management systems for interactive information retrieval.", "startOffset": 24, "endOffset": 27}, {"referenceID": 28, "context": "The Switchboard dataset [7], and the Dialogue State Tracking Challenge (DSTC) datasets [30] have been used to train and validate dialogue management systems for interactive information retrieval.", "startOffset": 87, "endOffset": 91}, {"referenceID": 18, "context": "[20] collected 1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "3 million conversations; this was extended in [27] to take advantage of longer contexts by using A-B-A triples.", "startOffset": 46, "endOffset": 50}, {"referenceID": 22, "context": "[24] used data from a similar Chinese website called Weibo4.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "com/ 69% of their collected data contained exchanges of length 2 [20].", "startOffset": 65, "endOffset": 69}, {"referenceID": 26, "context": "Part of the Ubuntu chat logs have previously been aggregated into a dataset, called the Ubuntu Chat Corpus [28].", "startOffset": 107, "endOffset": 111}, {"referenceID": 2, "context": "Several datasets of question-answer pairs are available [3], however these interactions are much shorter than what we seek to study.", "startOffset": 56, "endOffset": 59}, {"referenceID": 21, "context": "Most dialogue research has historically focused on structured slot-filling tasks [23].", "startOffset": 81, "endOffset": 85}, {"referenceID": 9, "context": "[10], which proposes an RNN structure, initialized with a denoising autoencoder, to tackle the DSTC 3 domain.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21], proposed a response generation model for Twitter data based on ideas from Statistical Machine Translation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "nearest neighbour) approaches [13].", "startOffset": 30, "endOffset": 34}, {"referenceID": 25, "context": "[27] to exploit information from a longer context, using a structure similar to the Recurrent Neural Network Encoder-Decoder model [4].", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[27] to exploit information from a longer context, using a structure similar to the Recurrent Neural Network Encoder-Decoder model [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 19, "context": "[21].", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "A similar encoderdecoder framework is presented in [24].", "startOffset": 51, "endOffset": 55}, {"referenceID": 25, "context": "This model is also evaluated in a human-subject study, although much smaller in size than in [27].", "startOffset": 93, "endOffset": 97}, {"referenceID": 6, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 12, "endOffset": 15}, {"referenceID": 28, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 115, "endOffset": 119}, {"referenceID": 8, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 206, "endOffset": 209}, {"referenceID": 7, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 294, "endOffset": 297}, {"referenceID": 18, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 561, "endOffset": 565}, {"referenceID": 25, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 693, "endOffset": 697}, {"referenceID": 22, "context": "Switchboard [7] Human-human Various 2,400 \u2014 3,000,000 Telephone conversations spoken on pre-specified topics DSTC1 [30] Human-computer State 15,000 210,000 Bus ride information spoken tracking system DSTC2 [9] Human-computer State 3,000 24,000 \u2014 Restaurant booking spoken tracking system DSTC3 [8] Human-computer State 2,265 15,000 \u2014 Tourist information spoken tracking system DSTC4[12] Human-human State 35 \u2014 \u2014 21 hours of tourist info spoken tracking exchange over Skype Twitter Human-human Next utterance 1,300,000 3,000,000 \u2014 Post/ replies extracted Corpus [20] micro-blog generation from Twitter Twitter Triple Human-human Next utterance 29,000,000 87,000,000 \u2014 A-B-A triples from Corpus [27] micro-blog generation Twitter replies Sina Weibo [24] Human-human Next utterance 4,435,959 8,871,918 \u2014 Post/ reply pairs extracted micro-blog generation from Weibo Ubuntu Dialogue Human-human Next utterance 932,429 7,189,051 100,000,000 Extracted from Ubuntu Corpus chat classification Chat Logs", "startOffset": 747, "endOffset": 751}, {"referenceID": 21, "context": "This classification task is an adaptation of the recall and precision metrics previously applied to dialogue datasets [23].", "startOffset": 118, "endOffset": 122}, {"referenceID": 17, "context": "Term frequency-inverse document frequency is a statistic that intends to capture how important a given word is to some document, which in our case is the context [19].", "startOffset": 162, "endOffset": 166}, {"referenceID": 14, "context": "Recurrent neural networks are a variant of neural networks that allows for time-delayed directed cycles between units [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 19, "context": "RNNs have been the primary building block of many current neural language models [21, 27], which use RNNs for an encoder and decoder.", "startOffset": 81, "endOffset": 89}, {"referenceID": 25, "context": "RNNs have been the primary building block of many current neural language models [21, 27], which use RNNs for an encoder and decoder.", "startOffset": 81, "endOffset": 89}, {"referenceID": 1, "context": "We build upon the approach in [2], which has also been recently applied to the problem of question answering [31].", "startOffset": 30, "endOffset": 33}, {"referenceID": 29, "context": "We build upon the approach in [2], which has also been recently applied to the problem of question answering [31].", "startOffset": 109, "endOffset": 113}, {"referenceID": 16, "context": "Word embeddings are initialized using the pre-trained vectors (Common Crawl, 840B tokens from [18]), and fine-tuned during training.", "startOffset": 94, "endOffset": 98}, {"referenceID": 29, "context": "The model is trained by minimizing the cross entropy of all labeled (context, response) pairs [31]:", "startOffset": 94, "endOffset": 98}, {"referenceID": 20, "context": "The Wh matrix is initialized using orthogonal weights [22], while Wx is initialized using a uniform distribution with values between -0.", "startOffset": 54, "endOffset": 58}, {"referenceID": 12, "context": "We use Adam as our optimizer [14], with gradients clipped to 10.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "In addition to the RNN model, we consider the same architecture but changed the hidden units to long-short term memory (LSTM) units [11].", "startOffset": 132, "endOffset": 136}, {"referenceID": 5, "context": "More sophisticated techniques have been proposed, such as training a maximum-entropy classifier to cluster utterances into separate dialogues [6].", "startOffset": 142, "endOffset": 145}, {"referenceID": 15, "context": "One option is to use the BLEU [17] or METEOR [15] scores from machine translation.", "startOffset": 30, "endOffset": 34}, {"referenceID": 13, "context": "One option is to use the BLEU [17] or METEOR [15] scores from machine translation.", "startOffset": 45, "endOffset": 49}, {"referenceID": 25, "context": "However, using BLEU for evaluating generated responses in short Twitter dialogues has been shown to give extremely low scores [27].", "startOffset": 126, "endOffset": 130}, {"referenceID": 15, "context": "Further, since the BLEU score is calculated using N-grams [17], it would provide a very low score for reasonable responses that do not have any words in common with the ground-truth next utterance.", "startOffset": 58, "endOffset": 62}], "year": 2015, "abstractText": "This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data. The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter. We also describe two neural learning architectures suitable for analyzing this dataset, and provide benchmark performance on the task of selecting the best next response.", "creator": "LaTeX with hyperref package"}}}