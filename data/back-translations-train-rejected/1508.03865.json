{"id": "1508.03865", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Aug-2015", "title": "Predicting Grades", "abstract": "To increase efficacy in traditional classroom courses as well as in Massive Open Online Courses (MOOCs), automated systems supporting the instructor are needed. One important problem is to automatically detect students that are going to do poorly in a course early enough to be able to take remedial actions. Existing grade prediction systems focus on maximizing the accuracy of the prediction while overseeing the importance of issuing timely and personalized predictions. This paper proposes an algorithm that predicts the final grade of each student in a class. It issues a prediction for each student individually, when the expected accuracy of the prediction is sufficient. The algorithm learns online what is the optimal prediction and time to issue a prediction based on past history of students' performance in a course. We derive a confidence estimate for the prediction accuracy and demonstrate the performance of our algorithm on a dataset obtained based on the performance of approximately 700 UCLA undergraduate students who have taken an introductory digital signal processing over the past 7 years. We demonstrate that for 85% of the students we can predict with 76% accuracy whether they are going do well or poorly in the class after the 4th course week. Using data obtained from a pilot course, our methodology suggests that it is effective to perform early in-class assessments such as quizzes, which result in timely performance prediction for each student, thereby enabling timely interventions by the instructor (at the student or class level) when necessary.", "histories": [["v1", "Sun, 16 Aug 2015 20:53:09 GMT  (588kb,D)", "http://arxiv.org/abs/1508.03865v1", "13 pages, 15 figures"], ["v2", "Fri, 18 Mar 2016 15:52:33 GMT  (1114kb,D)", "http://arxiv.org/abs/1508.03865v2", "15 pages, 15 figures"]], "COMMENTS": "13 pages, 15 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yannick meier", "jie xu", "onur atan", "mihaela van der schaar"], "accepted": false, "id": "1508.03865"}, "pdf": {"name": "1508.03865.pdf", "metadata": {"source": "CRF", "title": "Predicting Grades", "authors": ["Yannick Meier", "Jie Xu", "Onur Atan", "Mihaela van der Schaar"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of them are able to determine for themselves what they want to do and what they want to do."}, {"heading": "II. RELATED WORK", "text": "This year is more than ever before in the history of the European Union."}, {"heading": "III. FORMALISM, ALGORITHM AND ANALYSIS", "text": "In this section, we formalize the problem mathematically and propose an algorithm that predicts the final result or classification according to the final grade of a student with a given self-confidence."}, {"heading": "A. Definitions and System Description", "text": "This year, the number of undergraduates studying in the United States is even higher than the number of undergraduates studying in the United States. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...) The number of undergraduates studying in the United States is very high. (...)"}, {"heading": "B. Problem Formulation", "text": "After introducing notations, definitions and data structures, we now formalize the problem of grade prediction. We will examine two different types of predictions: the first type, which we call regression setting, is aimed at predicting the overall score of each student individually and promptly; the second, which is called classification setting, is aimed at making a binary prediction of whether the student will perform well or badly or whether he will need additional help or not. Again, the prediction is personalized and takes into account timeliness; for both types of prediction, the same algorithm can be used with only minor modifications, which we will show in Section III-D. We will also show that the binary prediction problem can easily be transferred to a classification in three or more grades. Regardless of the type of prediction, the decision for a student y is known."}, {"heading": "C. Grade Prediction Algorithm, Regression Setting", "text": "In this section, we propose an algorithm that predicts a student's overall performance, based on data from past years and based on the student's results in already graded performance assessments. We describe the algorithm for regression settings and explain the changes that are necessary to the algorithm in the classification setting in Section III-D. Knowing the student's results in Section III-D.A, we can calculate the student's overall score from past performance assessments as well as the associated weights w1,. wk, we only predict the residual distribution of results, y, k and calculate the prediction of the overall score with (3). To make its prediction for the current residuality of a student with attribute xi, y, k, the algorithms find all the characteristics vectors from similar students of past years and their associated residuals ci, y, k."}, {"heading": "D. Grade Prediction Algorithm, Classification Setting", "text": "In Binary Levels we will predict the overall value analogous to Regression Levels and then determine the grade by comparing the predicted Overall Levels-i, y with a Thresholds-zth. To show how we find Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels-Levels Levels-Levels-Levels-Levels-Levels-Levels-Levels"}, {"heading": "E. Confidence-Learning Prediction Algorithm", "text": "In addition to the radii of the ri neighborhoods, the only parameter that the user must choose in algorithm 1 is the maximum confidence threshold qth. Since it is more natural and practical for an instructor to specify a desired prediction accuracy or error directly instead of the confidence threshold, in this section we will show how to automatically learn the appropriate confidence threshold to achieve a certain confidence performance and what consequences this has on the average prediction time. We will discuss a possible method that uses the confidence threshold qth of the neighborhoods in Section IV-B. Formally, we define the problem as follows: p (k, qth). Leave the percentage of current grade students for whom the grade algorithm works with the confidence threshold qth to Qth. \u2264 1 has predicted the overall result by time (performance assessment) k. [0, K] is the minimum percentage of current grade students whose grade the user wants to predict with an accuracy specified E (qth)."}, {"heading": "IV. EXPERIMENTS", "text": "In this section, we present the data, discuss details of applying algorithm 1 to our data set, illustrate how the algorithm works, and evaluate its performance by comparing it with other prediction methods in both regression and binary classification settings. For space reasons, we will not show experimental results for classification settings with more than two categories."}, {"heading": "A. Data Analysis", "text": "Our experiments are based on a dataset of an Undergraduate Digital Signal Processing Course (EE113) that has been taught at UCLA for the past 7 years. The dataset contains the results of all performance assessments of all students and their final grade. The number of students enrolled in the course for a given year varied from 30 to 156, in total the dataset contains the results of about 700 students. Each year, the course consists of 7 homework assignments, an in-class intermediate exam that takes place after the third homework assignment, a course project that must be delivered after homework 7 and the final exam. The duration of the course is 10 weeks and a performance assessment takes place every week. The weights of the performance assessments are given by: 20% homework assignments with equal weight on8 each assignment, 25% intermediate exam, 15% course project and 40% final exams."}, {"heading": "B. Our Algorithm", "text": "In this section we will discuss three important details of the application of algorithms that are able to analyze the results."}, {"heading": "C. Benchmarks", "text": "We compare the performance of our algorithms against five different forecasting methods. \u2022 We use the result ai, y, k student i has been in themost recent performance assessment k alone to say the overall note. \u2022 A second simple benchmark makes the prediction based on the results ai, 1,., k student i has reached up to performance assessments k alone to account the corresponding weights of the performance assessments. \u2022 Linear regression using the ordinary least squares (OLS) finds the least linear mapping between the results of the first k performance assessments and the total score.9 F \u2212 D D + C \u2212 C B \u2212 A 0,15 0.2 0.35 0.4GradesF requ encyAll Years 1 Year 3 Year 4 Year 5 H6 H6 H6 7 Year 7 Year 7 Year 7 Year (a) Grade distributionH5 H5 H5 H5 H5 H5 H5 H5 H6 H6 H6 H6 H6 H6 80.840.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80.80."}, {"heading": "D. Results", "text": "This year it has come to the point where we will be able to retaliate until we are able to retaliate, \"he said.\" We have never lost as much time as this year, \"he said."}, {"heading": "V. CONCLUSION", "text": "In this paper, we are developing an algorithm that allows for a timely and personalized prediction of students \"final grades based solely on their early performance assessment results such as homework, quizzes or mid-term exams. (Using data from a UCLA-taught digital signal processing course, we show that the algorithm is able to learn from past data, that it exceeds benchmark algorithms in terms of accuracy and timeliness in both classification and regression settings, and that predictions are robust even when the course is taught by other instructors. We show that in-class exams are better predictors of a student's overall performance than homework tasks. (Hence, designing courses that would work with a high probability are poorly performed without intervention, and remedial actions at an early stage. Our algorithms can easily include context data from students like their previous GPA data, if the data could be applied exclusively)."}], "references": [{"title": "Open education: New opportunities for signal processing", "author": ["R. Baraniuk"], "venue": "Plenary Speech, 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "etutor: Online learning for personalized education", "author": ["C. Tekin", "J. Braun", "M. van der Schaar"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "l  {q} sparsity penalized linear regression with cyclic descent", "author": ["G. Marjanovic", "V. Solo"], "venue": "IEEE Transactions on Signal Processing, vol. 62, no. 6, pp. 1464\u20131475, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Nearest-neighbor distributed learning by ordered transmissions", "author": ["S. Marano", "V. Matta", "P. Willett"], "venue": "IEEE Transactions on Signal Processing, vol. 61, no. 21, pp. 5217\u20135230, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed sparse linear regression", "author": ["G. Mateos", "J.A. Bazerque", "G.B. Giannakis"], "venue": "IEEE Transactions on Signal Processing, vol. 58, no. 10, pp. 5262\u20135276, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Standardized tests predict graduate students success", "author": ["N.R. Kuncel", "S.A. Hezlett"], "venue": "Science, vol. 315, pp. 1080\u20131081, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Determinants of undergraduate gpas: Sat scores, high-school gpa and high-school rank", "author": ["E. Cohn", "S. Cohn", "D.C. Balch", "J. Bradley"], "venue": "Economics of Education Review, vol. 23, no. 6, pp. 577\u2013586, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Validity of the medical college admission test for predicting medical school performance", "author": ["E.R. Julian"], "venue": "Academic Medicine, vol. 80, no. 10, pp. 910\u2013917, 2005.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Using an admissions exam to predict student success in an adn program", "author": ["P.A. Gallagher", "C. Bomba", "L.R. Crane"], "venue": "Nurse Educator, vol. 26, no. 3, pp. 132\u2013135, 2001.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Comparative study of artificial neural network and statistical models for predicting student grade point averages", "author": ["W.L. Gorr", "D. Nagin", "J. Szczypula"], "venue": "International Journal of Forecasting, vol. 10, no. 1, pp. 17\u2013 34, 1994.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1994}, {"title": "A comparative analysis of techniques for predicting academic performance", "author": ["N.T. Nghe", "P. Janecek", "P. Haddawy"], "venue": "Frontiers In Education Conference-Global Engineering: Knowledge Without Borders, Opportunities Without Passports, 2007. FIE\u201907. 37th Annual. IEEE, 2007, pp. T2G\u20137.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Why college grade point average is difficult to predict.", "author": ["R.D. Goldman", "R.E. Slaughter"], "venue": "Journal of Educational Psychology,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1976}, {"title": "Using data mining to predict secondary school student performance", "author": ["P. Cortez", "A.M.G. Silva"], "venue": "2008.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Predicting student performance in a beginning computer science", "author": ["L.H. Werth"], "venue": "class. ACM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1986}, {"title": "Factors associated with grades in intermediate accounting", "author": ["J.L. Turner", "S.A. Holmes", "C.E. Wiggins"], "venue": "Journal of Accounting Education, vol. 15, no. 2, pp. 269\u2013288, 1997.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1997}, {"title": "Predictors of web-student performance: The role of self-efficacy and reasons for taking an on-line class", "author": ["A.Y. Wang", "M.H. Newlin"], "venue": "Computers in Human Behavior, vol. 18, no. 2, pp. 151\u2013163, 2002.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2002}, {"title": "Predicting students\u2019performance in distance learning using machine learning techniques", "author": ["S. Kotsiantis", "C. Pierrakeas", "P. Pintelas"], "venue": "Applied Artificial Intelligence, vol. 18, no. 5, pp. 411\u2013426, 2004.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Mooc performance prediction via clickstream data and social learning networks", "author": ["C.G. Brinton", "M. Chiang"], "venue": "34th INFOCOM IEEE. 2015, To appear.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting student performance: an application of data mining methods with an educational web-based system", "author": ["B. Minaei-Bidgoli", "D.A. Kashy", "G. Kortemeyer", "W.F. Punch"], "venue": "Frontiers in education, 2003. FIE 2003 33rd annual, vol. 1. IEEE, 2003, pp. T2A\u201313.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "A promising classification method for predicting distance students performance.", "author": ["D. Garc\u0131a-Saiz", "M. Zorrilla"], "venue": "EDM, pp", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Incentive design in peer review: Rating and repeated endogenous matching", "author": ["Y. Xiao", "F. D\u00f6rfler", "M. van der Schaar"], "venue": "Allerton Conference, 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American statistical association, vol. 58, no. 301, pp. 13\u201330, 1963.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1963}, {"title": "Empirical bernstein bounds and sample variance penalization", "author": ["A. Maurer", "M. Pontil"], "venue": "Proceedings of the Int. Conference on Learning Theory, 2009.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": ") and is developed by a large number of contributors rather than by a single author [1].", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Remedial or promotional actions could consist of additional online study material presented to the student in a personalized and/or automated manner [4].", "startOffset": 149, "endOffset": 152}, {"referenceID": 2, "context": "As benchmark algorithms we use well known algorithms such as linear/logistic regression and kNearest Neighbors, which are still a current research topic [5]\u2013[7].", "startOffset": 153, "endOffset": 156}, {"referenceID": 4, "context": "As benchmark algorithms we use well known algorithms such as linear/logistic regression and kNearest Neighbors, which are still a current research topic [5]\u2013[7].", "startOffset": 157, "endOffset": 160}, {"referenceID": 5, "context": "Various studies have investigated the value of standardized tests [8]\u2013[10] admissions exams [11] and GPA in previous programs [9] in predicting the academic success of students in undergraduate or graduate schools.", "startOffset": 66, "endOffset": 69}, {"referenceID": 7, "context": "Various studies have investigated the value of standardized tests [8]\u2013[10] admissions exams [11] and GPA in previous programs [9] in predicting the academic success of students in undergraduate or graduate schools.", "startOffset": 70, "endOffset": 74}, {"referenceID": 8, "context": "Various studies have investigated the value of standardized tests [8]\u2013[10] admissions exams [11] and GPA in previous programs [9] in predicting the academic success of students in undergraduate or graduate schools.", "startOffset": 92, "endOffset": 96}, {"referenceID": 6, "context": "Various studies have investigated the value of standardized tests [8]\u2013[10] admissions exams [11] and GPA in previous programs [9] in predicting the academic success of students in undergraduate or graduate schools.", "startOffset": 126, "endOffset": 129}, {"referenceID": 9, "context": "math, chemistry) [12], [13] have a strongly positive correlation as well.", "startOffset": 17, "endOffset": 21}, {"referenceID": 10, "context": "math, chemistry) [12], [13] have a strongly positive correlation as well.", "startOffset": 23, "endOffset": 27}, {"referenceID": 9, "context": "Reference [12] observes that simple linear and more complex nonlinear (e.", "startOffset": 10, "endOffset": 14}, {"referenceID": 11, "context": "Reference [14] argues that the accuracy of GPA predictions frequently is mediocre due to different grading standards used in different classes and shows a higher validity for grade predictions in single classes.", "startOffset": 10, "endOffset": 14}, {"referenceID": 12, "context": "Consequently, many works focus on identifying relationships between a student\u2019s grade in a particular class and variables related to the student [15]\u2013[19].", "startOffset": 145, "endOffset": 149}, {"referenceID": 16, "context": "Consequently, many works focus on identifying relationships between a student\u2019s grade in a particular class and variables related to the student [15]\u2013[19].", "startOffset": 150, "endOffset": 154}, {"referenceID": 12, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 63, "endOffset": 67}, {"referenceID": 14, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 68, "endOffset": 72}, {"referenceID": 16, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 74, "endOffset": 78}, {"referenceID": 13, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 111, "endOffset": 115}, {"referenceID": 14, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 117, "endOffset": 121}, {"referenceID": 16, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 123, "endOffset": 127}, {"referenceID": 14, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 175, "endOffset": 179}, {"referenceID": 16, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 181, "endOffset": 185}, {"referenceID": 12, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 204, "endOffset": 208}, {"referenceID": 15, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 224, "endOffset": 228}, {"referenceID": 14, "context": "Relevant factors were found to include the student\u2019s prior GPA [15]\u2013[17], [19], performance in related courses [16], [17], [19], performance in early assignments of the class [17], [19], class attendance [15], self-efficacy [18] and whether the student is repeating the class [17].", "startOffset": 276, "endOffset": 280}, {"referenceID": 17, "context": "Other works [20]\u2013[23], which also exclusively use data from the course itself, differ significantly from this paper in several aspects.", "startOffset": 12, "endOffset": 16}, {"referenceID": 19, "context": "Other works [20]\u2013[23], which also exclusively use data from the course itself, differ significantly from this paper in several aspects.", "startOffset": 17, "endOffset": 21}, {"referenceID": 13, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 16, "endOffset": 20}, {"referenceID": 14, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 22, "endOffset": 26}, {"referenceID": 17, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 27, "endOffset": 31}, {"referenceID": 18, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 32, "endOffset": 36}, {"referenceID": 19, "context": "[16], [18] [19] [15], [17] [20] [21]\u2013[23] Our Work", "startOffset": 37, "endOffset": 41}, {"referenceID": 20, "context": "1The performance assessments are usually graded by teaching assistants, by the instructor or even by other students through peer review [24].", "startOffset": 136, "endOffset": 140}, {"referenceID": 0, "context": "Let ai,y,k \u2208 [0, 1] denote the normalized score or grade of student i in performance assessment k of year y.", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "The normalized overall score zi,y \u2208 [0, 1] of yth year student i is the weighted sum of all performance assessments", "startOffset": 36, "endOffset": 42}, {"referenceID": 0, "context": "Without loss of generality we assume that all scores a are normalized to the range [0, 1].", "startOffset": 83, "endOffset": 89}, {"referenceID": 0, "context": "Let p(k, qth) \u2208 [0, 1] denote the proportion of current year students for which the grade prediction algorithm working with confidence threshold qth \u2264 1 has predicted the overall score by time (performance assessment) k \u2208 [0,K].", "startOffset": 16, "endOffset": 22}, {"referenceID": 0, "context": "Note that algorithm 1 does not require a specific normalization and it does not matter that the normalized scores according to (16) will not be in the interval [0, 1] as assumed in Section III for simplicity.", "startOffset": 160, "endOffset": 166}, {"referenceID": 0, "context": ", Xn be independent and bounded random variables with range [0, 1] and expected value \u03bc.", "startOffset": 60, "endOffset": 66}, {"referenceID": 21, "context": "Proof: A proof of Fact 1 can be found in Hoeffding\u2019s paper [25].", "startOffset": 59, "endOffset": 63}, {"referenceID": 0, "context": ", Xn be independent and bounded random random variables with range [0, 1] and variance V ar.", "startOffset": 67, "endOffset": 73}, {"referenceID": 22, "context": "Proof: See [26] for a proof of Fact 2.", "startOffset": 11, "endOffset": 15}], "year": 2017, "abstractText": "To increase efficacy in traditional classroom courses as well as in Massive Open Online Courses (MOOCs), automated systems supporting the instructor are needed. One important problem is to automatically detect students that are going to do poorly in a course early enough to be able to take remedial actions. Existing grade prediction systems focus on maximizing the accuracy of the prediction while overseeing the importance of issuing timely and personalized predictions. This paper proposes an algorithm that predicts the final grade of each student in a class. It issues a prediction for each student individually, when the expected accuracy of the prediction is sufficient. The algorithm learns online what is the optimal prediction and time to issue a prediction based on past history of students\u2019 performance in a course. We derive a confidence estimate for the prediction accuracy and demonstrate the performance of our algorithm on a dataset obtained based on the performance of approximately 700 UCLA undergraduate students who have taken an introductory digital signal processing over the past 7 years. We demonstrate that for 85% of the students we can predict with 76% accuracy whether they are going do well or poorly in the class after the 4th course week. Using data obtained from a pilot course, our methodology suggests that it is effective to perform early in-class assessments such as quizzes, which result in timely performance prediction for each student, thereby enabling timely interventions by the instructor (at the student or class level) when necessary.", "creator": "LaTeX with hyperref package"}}}