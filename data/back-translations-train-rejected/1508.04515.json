{"id": "1508.04515", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Aug-2015", "title": "Exploring Metaphorical Senses and Word Representations for Identifying Metonyms", "abstract": "A metonym is a word with a figurative meaning, similar to a metaphor. Because metonyms are closely related to metaphors, we apply features that are used successfully for metaphor recognition to the task of detecting metonyms. On the ACL SemEval 2007 Task 8 data with gold standard metonym annotations, our system achieved 86.45% accuracy on the location metonyms. Our code can be found on GitHub.", "histories": [["v1", "Wed, 19 Aug 2015 03:26:05 GMT  (727kb)", "http://arxiv.org/abs/1508.04515v1", "9 pages, 8 pages content"]], "COMMENTS": "9 pages, 8 pages content", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wei zhang", "judith gelernter"], "accepted": false, "id": "1508.04515"}, "pdf": {"name": "1508.04515.pdf", "metadata": {"source": "CRF", "title": "Exploring Metaphorical Senses and Word Representations for Identifying Metonyms", "authors": ["Wei Zhang", "Judith Gelernter"], "emails": ["wynnzh@gmail.com", "gelern@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is not as if we were able to go in search of a solution, as we have in the past. (...) In fact, it is not as if we had found a solution. (...) It is not as if we had found a solution. (...) It is not as if we had found a solution. (...) It is not as if we had found a solution. (...) It is as if we had found a solution. (...) It is not as if we had found a solution. (...) It is not as if we had found a solution. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...).). (.). (...).). (.).). (...). (.).). (.).). (...).). (.).). (.).). (.).). (.).). (.).). (.). (.).). (...).).........)..).........)............................................................................................................................"}, {"heading": "2 Related Work", "text": "Then, Nissim and Markert (2003) suggested using syntactic features and word similarity for the task. SemEval task 8 of 2007 contained metonym notations that were widely used for the problem. 2 We use metonym recognition from the term \"entity recognition\" and not the metonym resolution used in the SemEval literature of 2007, because the metonyms are not resolved in anything, but only identified. The SemEval data of 2007 comes from the British National Corpus and is the same data we use for our experiment.Five groups compiled as chronized by Markert and Nissim (2009) because the systems were much better at identifying the literal meaning of a place than at identifying metonyms."}, {"heading": "3 Method", "text": "Our task in metonymic recognition is to define characteristics that distinguish between metonymic and literal use of a potential metonymic word for the site. This section describes the characteristics of abstraction and imagination that we have borrowed from previous research on metonymic recognition (Tsvetkov, 2013 et al.), 3 and our characteristics for word representation, some of which have not yet been used for this purpose. We used the given data set to compare it with other methods, but then we used the so-called \"grammatically related word\" as a characteristic in each extract of the data set, and other groups also used this characteristic for metonymic recognition."}, {"heading": "3.1 Intuition underlying the method", "text": "One assumption for our method is that a potentially metonymic word and the nearby grammatically related word (if not a preposition) share the same degree of abstraction, as illustrated by the examples below. Potentially metonymic word - located in a naming phrase as part of a designated entity phrase. E.g., \"US Federal Trade Commission.\" The potentially metonymic word is \"USA,\" and the grammatically related word \"commission\" is a concrete word that indicates the literal sense. In contrast, the grammatically related word \"position\" is an abstract word and an indicator of the metonymic sense of the potentially metonymic word \"USA.\" This shows that metonymy of a potentially metonymic word can be indicated by the abstractness of the grammatical word. \""}, {"heading": "3.2 Abstractness and imaginability (A&I)", "text": "We use a knowledge base to determine which words are abstract or conceivable. Abstractiveness, according to the Webster dictionary, means \"referring to or incorporating general ideas or qualities, rather than specific persons, objects or actions.\" 5 But sometimes an abstract concept is conceivable, which means \"that one can imagine.\" 6 Sometimes people can call up an image of a concept in the brain, even if it is abstract. For example, \"revenge\" invokes an emotional image, while \"torture\" evokes both emotions and visual images (Tsvetkov et al., 2014). The difference between the two can help us better understand what an abstract sense really means. In metaphor recognition, abstractiveness and imagination have proven to be useful connecting features to indicate the conflict regarding the degree of abstraction of words (Broadwell et al., 2013; Turney et al., 2011; Tsvetkov et al, 2014)."}, {"heading": "3.3 Word representations and abstractions", "text": "The value of each dimension in the vector corresponds to a characteristic and can even have a semantic or grammatical interpretation, so that we call it a word characteristic (Turian et al, 2010). In this research, word representations are a means of recognizing subtle semantic patterns of the metonym or nonmetonym and the surrounding words in the sentence. Word representations essentially augment words in the data by using related words or vectors that contain semantic information to enhance the follow-up potential. Here, we use several word representation methods. This is because in machine learning, a method that does not improve results on its own, the results can be improved in combination with others. This interaction between word representation characteristics is demonstrated in Table 2."}, {"heading": "4 Features", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Knowledge base for abstractness", "text": "The MRC Psycholinguistic Database is a dictionary of linguistic and psycholinguistic attributes experimentally determined (Wilson, 1988). It contains 4295 words evaluated according to the degree of abstraction and 1156 words evaluated according to the degree of imagination. Our hypothesis is that the relative degree of concreteness or abstraction of the dependent word also indicates the relative degree of concreteness or abstraction of the potentialymetonymous word. But we found that the evaluation of abstraction does not strongly indicate whether the candidate location is a metonym or note.Tsvetkov et al. (2014, 2013) trained a logistic regression classifier with the MRC words that use vector space representation as a characteristic.They propagate the abstractness and imagination of the word in relation to all words by classifying each word with vector space representation."}, {"heading": "4.2 Word Representation Feature", "text": "We deal with two types of word representations: word vector representations, and word abstraction, i.e. we have two types of word representations: word vector representations, and word abstraction, i.e. we have two types of word representations, i.e. we have a certain category of words and terms that contain a certain type of word embedding and word embedding. We use three types of words: (1) word embedding, or distributed word representations (Turian et al., 2010), which capture the \"semantics\" of each word such as Latent Semantic Analysis (Landauer et al., 1998), ICA (V\u00e4yrynen et al., 2007), and LDA (Lead et7)."}, {"heading": "4.3 Miscellaneous features", "text": "We also use some other traits that have been shown to be effective (Nastase and Strube, 2009) (Farkas et al., 2007). These traits are the grammatical role (syntactic parse relationship) of the placebo, as given in the corpus annotation of SemEval 2007 to 8, and whether the dependent word is a preposition. Additionally, we add an indicator if the dependent word is in the stop word list."}, {"heading": "4.4 Creating a metonym-verb list", "text": "We used Google Ngram to create a list of verbs http: / / wwwpersonal.umich.edu / ~ jlawler / levin.verbs 11 http: / / wordnet.princeton.edu / wordnet / download / probably to specify metonyms, but the list was ineffective. That's what we did. Google Ngram are excerpts from books that show how often this verb was used with a person as the subject. We use word frequencies from Google Ngram. We were particularly interested in how verbs were used the verb. \""}, {"heading": "5 Experiments, Results and Limitations", "text": "In fact, most people are able to outdo themselves, \"he told the German Press Agency.\" I don't think they're able to outdo me, \"he said.\" I don't think they're able to outdo me. \"He added,\" I don't think they're able to outdo me. \"He added,\" I don't think they're able to outdo me. \"He added,\" I don't think they're able to outdo me. \"He emphasized,\" I don't think I think they're able to outdo me. \""}, {"heading": "6 Promising approaches to improve metonym detection", "text": "More data. The biggest obstacle to our machine learning algorithm is insufficient data. However, the SemEval data is sparsely marked, and there are many more cases of literal and figurative places in the data than are commented on. A more thorough marking of both training and test data could lead to better results via machine learning. Furthermore, the proportion of metonyms found in the data reflects what would be found \"in the wild,\" the imbalance of only about 20% metonyminals in the corpus impairs the ability of the machine learning algorithm to detect metonyms. More marked instances of metonyms would improve recognition accuracy. Context of the paragraph helps determine whether the words used in the paragraph are likely to be used literally or abstractly. Examples of known domains that include a higher proportion of metonyms are sports and politics."}, {"heading": "7 Conclusion", "text": "We applied the metaphorical knowledge of Tsvetkov et al (2014) to abstraction and imagination in order to identify metonymic senses of a word. Their method worked well, mainly because metonyms are abstractions, just like metaphors."}, {"heading": "6 OH, DP, BC , LV, PR, WN, EM, A&I 86.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 OH, DP, BC , LV, PR, WN, EM, VS 85.6", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 OH, DP, BC , LV, PR, WN, EM 86", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 OH, DP, BC , LV, PR, WN 85.9", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 OH, DP , BC, LV 85.9", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 OH, DP, BC 85.8", "text": "Metonymic localization words occur in sentences in a way very similar to the way literal localizations occur, so it is the subtlety of meaning that facilitates the distinction between metonymic and literal meanings, and it is the addition of abstract features and other semantic word representations that make our method effective. This essay offers a new semantic perspective on solving metonymic identification problems that could be extended to other linguistic figures that are abstractions."}, {"heading": "Acknowledgements", "text": "This research was partially supported by the Intelligence Advanced Research Projects Agency (IARPA) via Department of Defense U.S. Army Research Laboratory number W911NF12-C-0020. The U.S. government is authorized to reproduce and distribute reprints for government purposes, regardless of any copyright comments. The views and conclusions contained herein are those of the authors and should not necessarily be interpreted to represent official policy or endorsements, either expressed or implied, by IARPA, DoD / ARL, or the U.S. government. Reference Lead, D. M., Ng, A. Y., Jordan, M. I. (2003).Latent Dirichlet Allocation. The Journal of Machine Learning Research 3, 993-1022. Broadwell, G. A., Boz, U., Cases, I., Strzalkowski, T., L., Taylor, S., Shaikh, S. Liu, N. (2013)."}], "references": [{"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "Proceedings of the 25 international conference on machine", "citeRegEx": "Collobert and Weston,? \\Q2008\\E", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "GYDER: Maxent metonymy resolution", "author": ["R. Farkas", "E. Simon", "G. Szarvas", "D. Varga"], "venue": "Proc. of SemEval 2007, 161-164.", "citeRegEx": "Farkas et al\\.,? 2007", "shortCiteRegEx": "Farkas et al\\.", "year": 2007}, {"title": "Improving vector space word representations using multilingual correlation", "author": ["M. Faruqui", "C. Dyer"], "venue": "Proc of EACL 2014,", "citeRegEx": "Faruqui and Dyer,? \\Q2014\\E", "shortCiteRegEx": "Faruqui and Dyer", "year": 2014}, {"title": "Metonym and metaphor: what\u2019s the difference", "author": ["D. Fass"], "venue": "In Proc. of the twelfth conference on computational linguistics,", "citeRegEx": "Fass,? \\Q1991\\E", "shortCiteRegEx": "Fass", "year": 1991}, {"title": "An introduction to Latent Semantic Analysis. Discourse Processes", "author": ["T.K. Landauer", "P.W. Foltz", "D Laham"], "venue": null, "citeRegEx": "Landauer et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Landauer et al\\.", "year": 1998}, {"title": "Experiments on the exclusion of metonymic location names from GIR. In Evaluation of Multilingual and Multi-modal Information Retrieval: 7th Workshop of the Cross-Language Evaluation", "author": ["J. Leveling", "D. Veiel"], "venue": null, "citeRegEx": "Leveling and Veiel,? \\Q2007\\E", "shortCiteRegEx": "Leveling and Veiel", "year": 2007}, {"title": "Resources for the detection of conventionalized metaphors in four languages", "author": ["L. Levin", "T. Mitamura", "Fromm", "B.D. MacWhinney", "J. Carbonell", "W. Feely", "R. Frederking", "A. Gershman", "C. Ramirez"], "venue": null, "citeRegEx": "Levin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levin et al\\.", "year": 2014}, {"title": "Classification and regression by Random Forest", "author": ["Liaw", "M.A. Wiener"], "venue": "R news", "citeRegEx": "Liaw and Wiener,? \\Q2002\\E", "shortCiteRegEx": "Liaw and Wiener", "year": 2002}, {"title": "Towards a corpus annotated for metonymies: the case of location names", "author": ["K Markert", "M. Nissim"], "venue": "Proceedings of the 3rd International Conference on Language Resources and Evaluation;", "citeRegEx": "Markert and Nissim,? \\Q2002\\E", "shortCiteRegEx": "Markert and Nissim", "year": 2002}, {"title": "Data and models for metonymy resolution", "author": ["K. Markert", "M. Nissim"], "venue": "Lang Resources & Evaluation", "citeRegEx": "Markert and Nissim,? \\Q2009\\E", "shortCiteRegEx": "Markert and Nissim", "year": 2009}, {"title": "Semeval-2007 task 08: Metonymy resolution at semeval2007", "author": ["K. Markert", "M. Nissim"], "venue": "In Proc. of the SemEval 2007,", "citeRegEx": "Markert and Nissim,? \\Q2007\\E", "shortCiteRegEx": "Markert and Nissim", "year": 2007}, {"title": "Supervised and Unsupervised Metonymy Resolution", "author": ["V. Nastase", "M. Strube"], "venue": null, "citeRegEx": "Nastase and Strube,? \\Q2009\\E", "shortCiteRegEx": "Nastase and Strube", "year": 2009}, {"title": "Syntactic features and word similarity for supervised", "author": ["M. Nissim", "K. Markert"], "venue": "Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Nissim and Markert,? \\Q2009\\E", "shortCiteRegEx": "Nissim and Markert", "year": 2009}, {"title": "Cross-Lingual Metaphor Detection Using Common Semantic Features", "author": ["Y Tsvetkov", "E. Mukomel", "A. Gershman"], "venue": "In Proc. of the ACL-IJCNLP 2009 Student Research Workshop. Suntec, Singapore,", "citeRegEx": "Tsvetkov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2013}, {"title": "Metaphor Detection with Cross-Lingual Model Transfer", "author": ["Y. 45-51. Tsvetkov", "L. Boytsov", "A. Gershman", "E. Nyberg", "Dyer C"], "venue": "First Workshop on Metaphor in NLP, Atlanta, Georgia,", "citeRegEx": "Tsvetkov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2013}, {"title": "Geocoding location expressions in Twitter messages: A preference learning method", "author": ["W. 6-11. Zhang", "J. Gelernter"], "venue": "Journal of Spatial Information Science", "citeRegEx": "Zhang and Gelernter,? \\Q2015\\E", "shortCiteRegEx": "Zhang and Gelernter", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "People disagreed about whether location words are literal or figurative (metonymic) about 15% of the time in the case of the official annotators for the SemEval metonym data set we used (Markert and Nissim, 2009), and about 8% of the time in our own assessment of the annotations on this standard data set.", "startOffset": 186, "endOffset": 212}, {"referenceID": 15, "context": "Location grounding (Zhang and Gelernter, 2015) could benefit from excluding location metonyms as well.", "startOffset": 19, "endOffset": 46}, {"referenceID": 5, "context": "0917; Leveling and Veiel (2007) also found that excluding metonyms improved precision in identifying place names.", "startOffset": 6, "endOffset": 32}, {"referenceID": 3, "context": "\u201cIn Metonymy one entity stands for another, in Metaphor, one entity is viewed as another\u201d (Fass, 1991).", "startOffset": 90, "endOffset": 102}, {"referenceID": 3, "context": "\u201cIn Metonymy one entity stands for another, in Metaphor, one entity is viewed as another\u201d (Fass, 1991). By contrast, Radden (2000) considers metonyms to be a particular type of metaphor.", "startOffset": 91, "endOffset": 131}, {"referenceID": 8, "context": "Five groups competed, as chronicled by Markert and Nissim (2009). Overall, the systems were much better at identifying the literal sense of a location than at identifying location metonyms.", "startOffset": 39, "endOffset": 65}, {"referenceID": 11, "context": "Nastase and Strube (2009) achieved good results by combining lexical, encyclopedic and collocation information.", "startOffset": 0, "endOffset": 26}, {"referenceID": 11, "context": "Nastase and Strube (2009) achieved good results by combining lexical, encyclopedic and collocation information. Later, Nastase et al., (2012) added global context in an unsupervised method that", "startOffset": 0, "endOffset": 142}, {"referenceID": 13, "context": "We did not need to train a similar classifier for metonyms in the SemEval dataset because our words happened to appear among the word vectors created by the Tsvetkov et al. (2014). Note that the abstractness classifier would probably predict every potential metonym as concrete, so we use only the abstractness of the grammatically related word to indicate whether the potential metonymic word is indeed a metonym.", "startOffset": 157, "endOffset": 180}, {"referenceID": 2, "context": "We used the 64 dimensional vector trained with a variation of Latent Semantic Analysis by Faruqui and Dyer (2014). The vector construction algorithm is a variation of traditional Latent Semantic Analysis (Deerwester et al.", "startOffset": 90, "endOffset": 114}, {"referenceID": 1, "context": "10 These categories have been used in previous metonym research (Farkas et al., 2007).", "startOffset": 64, "endOffset": 85}, {"referenceID": 1, "context": "Here we used the Synset ID of the WordNet entry, regardless of part of speech, as is also used by Farkas et al. (2007) and Nastase et al.", "startOffset": 98, "endOffset": 119}, {"referenceID": 1, "context": "Here we used the Synset ID of the WordNet entry, regardless of part of speech, as is also used by Farkas et al. (2007) and Nastase et al. (2009).", "startOffset": 98, "endOffset": 145}, {"referenceID": 11, "context": "We use some other features found effective as well (Nastase and Strube, 2009) (Farkas et al.", "startOffset": 51, "endOffset": 77}, {"referenceID": 1, "context": "We use some other features found effective as well (Nastase and Strube, 2009) (Farkas et al., 2007).", "startOffset": 78, "endOffset": 99}, {"referenceID": 10, "context": "6 potential metonymic word annotations for literal or metonymic, and grammatically related word(s) (Markert and Nissim 2007).", "startOffset": 99, "endOffset": 124}, {"referenceID": 10, "context": "Any ambiguous senses when the annotators disagrees were removed from training and testing data (Markert and Nissim 2007).", "startOffset": 95, "endOffset": 120}, {"referenceID": 7, "context": "(2014) used Random Forest (Liaw and Wiener, 2002) for metaphor detection.", "startOffset": 26, "endOffset": 49}, {"referenceID": 12, "context": "Tsvetkov et al. (2014) used Random Forest (Liaw and Wiener, 2002) for metaphor detection.", "startOffset": 0, "endOffset": 23}], "year": 2015, "abstractText": "A metonym is a word with a figurative meaning, similar to a metaphor. Because metonyms are closely related to metaphors, we apply features that are used successfully for metaphor recognition to the task of detecting metonyms. On the ACL SemEval 2007 Task 8 data with gold standard metonym annotations, our system achieved 86.45% accuracy on the location metonyms. Our code can be found on GitHub.", "creator": "Word"}}}