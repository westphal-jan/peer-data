{"id": "1508.05508", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2015", "title": "Towards Neural Network-based Reasoning", "abstract": "We propose Neural Reasoner, a framework for neural network-based reasoning over natural language sentences. Given a question, Neural Reasoner can infer over multiple supporting facts and find an answer to the question in specific forms. Neural Reasoner has 1) a specific interaction-pooling mechanism, allowing it to examine multiple facts, and 2) a deep architecture, allowing it to model the complicated logical relations in reasoning tasks. Assuming no particular structure exists in the question and facts, Neural Reasoner is able to accommodate different types of reasoning and different forms of language expressions. Despite the model complexity, Neural Reasoner can still be trained effectively in an end-to-end manner. Our empirical studies show that Neural Reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding) proposed in [8]. For example, it improves the accuracy on Path Finding(10K) from 33.4% [6] to over 98%.", "histories": [["v1", "Sat, 22 Aug 2015 13:15:09 GMT  (130kb,D)", "http://arxiv.org/abs/1508.05508v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.LG cs.NE", "authors": ["baolin peng", "zhengdong lu", "hang li", "kam-fai wong"], "accepted": false, "id": "1508.05508"}, "pdf": {"name": "1508.05508.pdf", "metadata": {"source": "CRF", "title": "Towards Neural Network-based Reasoning", "authors": ["Baolin Peng", "Zhengdong Lu", "Hang Li", "Kam-Fai Wong"], "emails": ["kfwong}@se.cuhk.edu.hk", "HangLi.HL}@huawei.com"], "sections": [{"heading": "1 Introduction", "text": "Efforts to date in this direction are based on rules-based models, which first require mapping natural languages to logical forms and then inferring about them. Mapping (roughly equivalent to semantic parsing) and concluding are by no means easy, given the variability and flexibility of natural language, the variety of reasoning tasks, and the fragility of a rules-based system. Recently, there have been some new efforts, mainly represented by the Memory Network and its dynamic variants [9, 5], which seek to build a purely neural network-based argumentation system with fully distributed semantics that can draw on multiple facts to answer simple questions, all in natural language, e.g. Fact 1: John traveled to the Memory Network and its dynamic variants. Fact 2: Mary traveled to the Neural System to design neural models."}, {"heading": "2 Overview of Neural Reasoner", "text": "Neural Reasoner has a multi-layered architecture to deal with the complicated logical relationships in reasoning, as illustrated in Figure 1. It consists of a coding layer and multiple levels of reasoning. The coding layer first converts the question and facts from natural-language sentences to vector representations. More specifically, Q encodes \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 q (0), Fk encodes \u2212 \u2212 \u2212 \u2212 f (0) k, k = 1, 2, \u00b7 \u00b7 \u00b7, K.wo q (0), RdQ and f (0) k, or dF. With the representations from the coding level, the reasoning level recursively updates the representations of questions and facts, {q (') f ('), \u00b7 \u00b7 f (') K} reason \u2212 \u2212 \u2212 \u2212 \u2212 \u2192 {q (' + 1) f ('+ 1) f (' + 1) 1 \u00b7 \u00b7 \u00b7 \u00b7 f ('1), which has an interaction between the interposition of the question and the fact."}, {"heading": "3 Model", "text": "In this section, we give an instance of the Neural Reasonder described in Section 2, as illustrated in Figure 2. Vector representations are then fed into the argumentation layers, where the question and facts are updated by a nonlinear transformation jointly controlled by deep neural networks (DNNs) and pooling. Finally, at the answer level, the resulting question representation is used to generate the final answer to the question. Specifically, \u2022 in the coding layer (Level-0), we use recurring neural networks (RNNs) to convert questions and facts into their vector representations, which are then forwarded to the first layer of argumentation."}, {"heading": "3.1 Encoding Layer", "text": "Suppose that we are given a fact or a question as a word sequence {x1, \u00b7 \u00b7, xT}, while the encryption module summarizes the word sequence with a fixed-length vector. To this end, we have various modeling options, e.g. CNN [4] and RNN [7], while in this essay we use GRU [2], a variant of RNN, as the encryption module. It turns out that GRU is able to mitigate the disappearance of the gradient of RNN and can perform a similar performance to the more complicated LSTM [3]. As shown in Figure 3, GRU takes as input a sequence of word vectors (for question or facts) X = {xht, \u00b7 \u00b7, xT}, xi \u00b2 R | V \u2212 h, where | V \u2212 zt for the size of the word hzht words (for question or facts) x = ht (ht), (ht), Wht, (Wt), (t), (t), (t) (t), (t) (t), where \u2212 t is (t)."}, {"heading": "3.2 Reasoning Layers", "text": "The modules in the argumentation levels include those for the interaction between questions and facts, the pooling."}, {"heading": "3.2.1 Question-Fact Interaction", "text": "In the argumentation layer, \"the strongest interaction is between q ('\u2212 1) and f (' \u2212 1) k, resulting in updated representations q (') k and f (') k [q (') k, f (') k] def = gDNN\" ([(q ('\u2212 1))) >, f (' \u2212 1) k >] >; conservation \"), (6), where q (') k and f (') k can generally be of different dimensions than the previous layers. In the simplest case with a single layer in DNN, we have q (') k def = \u03c3 (W >' [('\u2212 1)) >, f (' \u2212 1) k >] + b '), (7) where \u03c3 (\u00b7) stands for the nonlinear activation function."}, {"heading": "3.2.2 Pooling", "text": "Pooling aims to merge the understanding of the question directly after its interaction with all the facts to form the current status of the question, through which we can allow comparison between different facts. There are several strategies for this pooling \u2022 Average / Max Pooling: To get the n element in q ('), we can take the average or maximum of the elements in the same place from {q (') 1, \u00b7 \u00b7 q (') K. For example, in max pooling we have q (') (') (d) = max (' q (') 1 (d), q (') 2 (d), \u00b7, q (') K (d)))), d = 1, 2, \u00b7 \u00b7 D' where q (') (d) (d) stands for the d element of the vector q (') (') ('), clearly this type of pooling is the easiest, \"without any associated parameters; \u2022 Gating: We can have an additional Gk (') (') to determine the dk (')."}, {"heading": "3.3 Answering Layer", "text": "For the sake of simplicity, we will focus on the reasoning tasks, which can be formulated as classification with predefined classes. Specifically, we will use Neural Reasoners to deal with the following two types of questions \u2022 Type I: General questions, i.e. questions with a yes / no answer; \u2022 Type II: Specific questions with a small set of candidate answers. For argumentation layer-L, it pooles the intermediate results to select important information for further use.q = pool ({q (L) 1, q (L) 2, \u00b7, q (L) K}) (8) y = softmax (W > softmaxq (L) (9)) After reaching the last step of reasoning, Q2 is sent in two steps to a standard Softmax layer to generate an answer formulated as a classification problem. There is another type of prediction, called classification, in which the effective classes dynamically change with this single-instance supplying function, for example, a supplementary problem."}, {"heading": "3.4 Training", "text": "Model training aligns the parameters in {RNN0, DNN1, \u00b7 \u00b7, DNNL} and Softmax classification. Similar to [6], we conduct end-to-end training, using the final answer as the sole supervision. Specifically, we use cross entropy for the cost of classification Ereasoning = \u2211 n-T DCE (p (y | rn) | | yn), where n indexes the instances in the training set T, and rn = {Qn, Fn, 1, \u00b7 \u00b7, Fn, Kn} for questions and facts for step 9. Our end-to-end training is the same as [6], while training in [9] and [5] uses the step-by-step labels of the supporting facts for each instance (see Table 1 for examples) in addition to the answer."}, {"heading": "4 Auxiliary Training for Question/Fact Representation", "text": "We use auxiliary training to facilitate the learning of representations of questions and facts. Essentially, in addition to the learned representations of questions and facts in the thought process, we also use these representations to reconstruct the original questions or their more abstract forms with variables (which will be explained later in Section 4.2). In auxiliary training, we intend to achieve the following two objectives \u2022 to compensate for the lack of supervision in the learning task. In our experiments, supervision can be quite weak, as it is only a classification of no more than 12 classes at a time, while the number of instances is 1K to 10K. \u2022 to introduce an advantageous bias for the presentation learning task. Since the network is a complicated non-linear function, backpropagation from the response layer to the coding layer can easily fail to learn well."}, {"heading": "4.1 Multi-task Learning Setting", "text": "As illustrated in Figure 4, we use the simplest way to merge the auxiliary tasks (restoration) with the main task (reasoning) by linearly combining their costs with the target parameter \u03b1E = \u03b1Erecovery + (1 \u2212 \u03b1) Ereasoning (10), where Ereasoning is the cross entropy loss describing the discrepancy of the model prediction from the correct answer (see Section 3.4), and Erecovery is the negative log probability of the sequences to be recovered (question or facts). More precisely: Erecovery = \u2211 n \u00b2 T {Kn \u2211 k = 1 log p (Fn, k | f (0) n, k) + log p (Qn | q (0) n)}, where the probability is estimated as in the encoder decoder frame proposed in [2]."}, {"heading": "4.2 Abstract Forms with Variables", "text": "Rather than restoring the original proposition in question and facts, we also examine the effect of a more abstract form in the auxiliary task. Specifically, we have the RNN decrypted to restore a set of entities that are replaced by variables (which are treated as certain symbols), for example: The triangle is above the pink rectangle. recover \u2212 \u2212 \u2212 \u2212 \u2192 x is above y. the blue square is to the left of the triangle. recover \u2212 \u2212 \u2192 z is to the left of x. Is the pink rectangle to the right of the square? recover \u2212 \u2212 \u2212 \u2212 \u2192 Is y to the right of the z? By doing so, we want to teach the system a more abstract way to present propositions (both questions and facts) and their interactions. Specifically, \u2022 all entities are meaningful only when compared with each other. In other words, the model (in the coding and argumentation layer) should not focus on specific entities, but on their general terms."}, {"heading": "5 Experiments", "text": "We report on our empirical study on the application of Neural Reasoners to the question-and-answer task defined in [8] and compare it with modern neural models [9, 5]."}, {"heading": "5.1 Setup", "text": "bAbI is a synthetic question and answer data set. It contains 20 tasks, each of which consists of a set of facts, a question, and an answer that consists largely of a single word. Mostly, only a subset of facts is relevant to the given question. Two versions of the data are available, one has 1K instances of training per task and the other has 10K instances per task, while the test set for the two versions is the same. We select the two most difficult tasks (among the 20 tasks in [8]) Positional Reasoning and Path Finding to test the thinking ability of Neural Reasoners. Positional Reasoning Task tests the spatial thinking ability of the model, while Path Finding Task, first proposed in [1], tests the ability to fathom the correct path between objects based on instructions from natural language. In Table 1, we give one instance of each task."}, {"heading": "5.2 Implementation Details", "text": "In our experiments, we actually used a simplified version of Neural Reasoner. In version \u2022, we choose not to update the representation at each level, e.g. Fk encoded \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2192 f (0) k = f (1) k = \u00b7 \u00b7 = f (L \u2212 1) k, k = 1, 2, \u00b7 \u00b7, K. This choice urges the update q (') k (and its summary q ('))) to capture all information in the interaction between fact and question. \u2022 We use only two layers, i.e. L = 2, for the relatively simple task in the experiments. Our model was trained with standard back propagation (BP) to maximize the likelihood of correct answers. All parameters, including word embeddings, were initialized by random samples from a uniform distribution [-0,1, 0,1]."}, {"heading": "5.3 Neural Reasoner vs. Competitor Models", "text": "We compare Neural Reasoner with the following three neural reasoning models: 1) Memory Network, including the step-by-step model [9] (referred to as Memory Net-Step) and the end-to-end version [6] (referred to as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step monitoring. In Table 2, we report on the performance of a particular case of Neural Reasoner with 1) two layers of reasoning, 2) 2-layer DNNs as interaction modules in each argument layer, and 3) task to restore the original question and facts. Results are compared with three neural competitors. We have the following observations. \u2022 The proposed Neural Reasoner performs significantly better than Memory Net-N2N as interaction modules, in particular with more training data. \u2022 Although not a fair comparison to our model, Neural Reasoner is actually better than Memory Net-102K and Interaction of Dynamic-N2K."}, {"heading": "5.4 Architectural Variations", "text": "More specifically, we look at the variations in 1) the number of thought layers, 2) the depth of DNN interaction, and 3) the auxiliary tasks, the results of which are summarized in Table 3. We have the following observations: \u2022 Auxiliary tasks are indispensable for the effectiveness of the Neural Reasoner, without which the performance of the Neural Reasoner drops dramatically. This is because, as we suspect in Section 4, the puzzle alone cannot provide enough monitoring for learning precise word vectors and parameters of the RNN encoder. We note that the Neural Reasoner can still surpass Memory Net (N2N) with 10K data on both tasks. \u2022 Neural reasoners with flat architectures, more precisely two layers of thought and one layer of DNN, can apparently benefit from the auxiliary performance of recovering abstract forms on small data sets (1K)."}, {"heading": "6 Conclusion and Future Work", "text": "Our empirical studies show that Neural Reasoners can dramatically improve existing neural thinking systems in two difficult, artificial tasks proposed in [9]. In future work, we will 1) investigate tasks with higher difficulty and depth of reasoning, e.g. tasks that require a large number of supporting facts and facts with complex intrinsic structures, 2) the common structure in different but similar reasoning tasks (e.g. multiple tasks with general questions), and 3) the automatic selection of the reasoning architecture to determine, for example, when thinking based on the data should be stopped."}], "references": [{"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D.L. Chen", "R.J. Mooney"], "venue": "Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, 11  AAAI 2011, San Francisco, California, USA, August 7-11, 2011", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "B", "author": ["K. Cho"], "venue": "van Merrienboer, C. Gulcehre, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In Proceedings of EMNLP, pages 1724\u20131734", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "cC", "author": ["J. Chung"], "venue": "G\u00fclccehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["B. Hu", "Z. Lu", "H. Li", "Q. Chen"], "venue": "Advances in Neural Information Processing Systems 27, pages 2042\u20132050", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["A. Kumar", "O. Irsoy", "J. Su", "J. Bradbury", "R. English", "B. Pierce", "P. Ondruska", "I. Gulrajani", "R. Socher"], "venue": "CoRR, abs/1506.07285", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Weakly supervised memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "CoRR, abs/1503.08895", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, pages 3104\u20133112", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "T. Mikolov"], "venue": "CoRR, abs/1502.05698", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "CoRR, abs/1410.3916", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Adadelta: an adaptive learning rate method", "author": ["M.D. Zeiler"], "venue": "arXiv preprint arXiv:1212.5701", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 7, "context": "Our empirical studies show that Neural Reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding) proposed in [8].", "startOffset": 207, "endOffset": 210}, {"referenceID": 5, "context": "4% [6] to over 98%.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Just recently, there is some new effort, mainly represented by Memory Network and its dynamic variants [9, 5], trying to build a purely neural network-based reasoning system with fully distributed semantics that can infer over multiple facts to answer simple questions, all in natural language, e.", "startOffset": 103, "endOffset": 109}, {"referenceID": 4, "context": "Just recently, there is some new effort, mainly represented by Memory Network and its dynamic variants [9, 5], trying to build a purely neural network-based reasoning system with fully distributed semantics that can infer over multiple facts to answer simple questions, all in natural language, e.", "startOffset": 103, "endOffset": 109}, {"referenceID": 5, "context": "It is purely neural network based and can be trained in an end-to-end way [6], using only supervision from the final answer.", "startOffset": 74, "endOffset": 77}, {"referenceID": 3, "context": ", CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": ", CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module.", "startOffset": 18, "endOffset": 21}, {"referenceID": 1, "context": ", CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module.", "startOffset": 54, "endOffset": 57}, {"referenceID": 2, "context": "GRU is shown to be able to alleviate the gradient vanishing issue of RNN and have similar performance to the more complicated LSTM [3].", "startOffset": 131, "endOffset": 134}, {"referenceID": 8, "context": ", the Single-Supporting-Fact task in [9].", "startOffset": 37, "endOffset": 40}, {"referenceID": 5, "context": "Similar to [6], we perform end-to-end training, taking the final answer as the only supervision.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "Our end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer.", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "Our end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer.", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Our end-to-end training is the same as [6], while the training in [9]and [5] use the stepby-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "As described in [6], those extra labels brings much stronger supervision just the answer in the end-to-end learning setting, and typically yield significantly better result on relatively complicated tasks.", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "where the likelihood is estimated as in the encoder-decoder framework proposed in [2].", "startOffset": 82, "endOffset": 85}, {"referenceID": 7, "context": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5].", "startOffset": 97, "endOffset": 100}, {"referenceID": 8, "context": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5].", "startOffset": 156, "endOffset": 162}, {"referenceID": 4, "context": "We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9, 5].", "startOffset": 156, "endOffset": 162}, {"referenceID": 7, "context": "We select the two most challenging tasks (among the 20 tasks in [8] ) Positional Reasoning and Path Finding, to test the reasoning ability of Neural Reasoner.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "Positional Reasoning task tests model\u2019s spatial reasoning ability, while Path Finding task, first proposed in [1] tests the ability to reason the correct path between objects based on natural language instructions.", "startOffset": 110, "endOffset": 113}, {"referenceID": 9, "context": "We trained all the tasks for 200 epochs with stochastic gradient descent and the gradients which had `2 norm larger than 40 were clipped, learning rate being controlled by AdaDelta [10].", "startOffset": 181, "endOffset": 185}, {"referenceID": 8, "context": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision.", "startOffset": 143, "endOffset": 146}, {"referenceID": 5, "context": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision.", "startOffset": 202, "endOffset": 205}, {"referenceID": 4, "context": "We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision.", "startOffset": 278, "endOffset": 281}, {"referenceID": 8, "context": "The results of Memory Net-step, Memory Net-N2N, and Dynamic Memory Net are taken respectively from [9],[6] and [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 5, "context": "The results of Memory Net-step, Memory Net-N2N, and Dynamic Memory Net are taken respectively from [9],[6] and [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 4, "context": "The results of Memory Net-step, Memory Net-N2N, and Dynamic Memory Net are taken respectively from [9],[6] and [5].", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "Our empirical studies show that Neural Reasoner can dramatically improve upon existing neural reasoning systems on two difficult artificial tasks proposed in [9].", "startOffset": 158, "endOffset": 161}], "year": 2015, "abstractText": "We propose Neural Reasoner , a framework for neural network-based reasoning over natural language sentences. Given a question, Neural Reasoner can infer over multiple supporting facts and find an answer to the question in specific forms. Neural Reasoner has 1) a specific interaction-pooling mechanism, allowing it to examine multiple facts, and 2) a deep architecture, allowing it to model the complicated logical relations in reasoning tasks. Assuming no particular structure exists in the question and facts, Neural Reasoner is able to accommodate different types of reasoning and different forms of language expressions. Despite the model complexity, Neural Reasoner can still be trained effectively in an end-to-end manner. Our empirical studies show that Neural Reasoner can outperform existing neural reasoning systems with remarkable margins on two difficult artificial tasks (Positional Reasoning and Path Finding) proposed in [8]. For example, it improves the accuracy on Path Finding(10K) from 33.4% [6] to over 98%.", "creator": "LaTeX with hyperref package"}}}