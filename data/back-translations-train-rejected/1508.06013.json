{"id": "1508.06013", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "ERBlox: Combining Matching Dependencies with Machine Learning for Entity Resolution", "abstract": "Entity resolution (ER), an important and common data cleaning problem, is about detecting data duplicate representations for the same external entities, and merging them into single representations. Relatively recently, declarative rules called matching dependencies (MDs) have been proposed for specifying similarity conditions under which attribute values in database records are merged. In this work we show the process and the benefits of integrating three components of ER: (a) Classifiers for duplicate/non-duplicate record pairs built using machine learning (ML) techniques, (b) MDs for supporting both the blocking phase of ML and the merge itself; and (c) The use of the declarative language LogiQL -an extended form of Datalog supported by the LogicBlox platform- for data processing, and the specification and enforcement of MDs.", "histories": [["v1", "Tue, 25 Aug 2015 02:35:58 GMT  (320kb,D)", "http://arxiv.org/abs/1508.06013v1", "To appear in Proc. SUM, 2015"]], "COMMENTS": "To appear in Proc. SUM, 2015", "reviews": [], "SUBJECTS": "cs.DB cs.AI cs.LG", "authors": ["zeinab bahmani", "leopoldo bertossi", "nikolaos vasiloglou"], "accepted": false, "id": "1508.06013"}, "pdf": {"name": "1508.06013.pdf", "metadata": {"source": "CRF", "title": "ERBlox: Combining Matching Dependencies with Machine Learning for Entity Resolution", "authors": ["Zeinab Bahmani", "Leopoldo Bertossi", "Nikolaos Vasiloglou"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Matching dependencies", "text": "We assume that attributes do not share attributes, but different attributes can share a domain. An instanceD forR is a finite set of ground atoms of the form R (c1,.., cn), with which we assume that each entity is represented by a relational predicate, and its tuples or rows in expansion correspond to the records for the entity. As in [7], we assume that the records are unique, fixed, global identifiers, rids that are positive integers. This allows us to trace changes in attribute values in records."}, {"heading": "2.2 Support vector machines", "text": "The SVMs technique [25] is a form of kernel-based learning. SVMs can be used to classify vectors in an intra-productive vector space V via R. Vectors. < The algorithms can be used to classify vectors. (e1, f (e1)), (e2), (e3), (e3), (e3), (en, f (en)), (e), and for the function (function) f: f (ei).SVMs find an optimal hyperplane that separates the two classes in which the training vectors are classified. Hyperplane H has an equation of the form w \u2022 x \u2022 b, where the inner product is denoted, x is a vector variable, w is a weight vector of real values, and b is a real number."}, {"heading": "4 Initial Data and Similarity Computation", "text": "We now describe some aspects of the MAS dataset that highlight the input data and output of the individual components of the ERBlox system. The data is presented and made available as follows: The author relationship contains author names and their affiliations; the paper relationship contains paper titles, years, conference identifiers and keywords; the PaperAuthor relationship contains essay IDs, author names, author names and their affiliations; the journal and conference relations contain short names, full names and homepages of journals and conferences. By using ERBlox to this dataset, we determine which articles are written in MAS data by a particular author; this is a clear case of 8 similarity calculations held in appropriate program predispositions; similarity values calculated before they are blocked can be reused at this stage or whenever they are needed."}, {"heading": "5 MD-Based Collective Blocking and Duplicate Detection", "text": "Since each row has an identifier, each row uses its own block number, in an additional attribute Bl # 1. In this way, we create the first blocking instance from the first instance D, which is also referred to as D. (6) Here Bl1, Bl2 are block number variables, and Ri is a database (record). The lists of variables X, X, 2, Bl2 represent all attributes in Ri, but Bl # 2 is a linkage of relative atoms and comparative atoms about similarity, but it does not include similarity comparisons of block numbers, such as Bl3, Bl4, 13 The variables in the X, 3 list appear in Ri or in another database."}, {"heading": "6 MD-Based Merging", "text": "When EntityDuplicate (r1, r2) is created, the corresponding complete datasets are r (1), r (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (3), R (R), R (3), R (R), R (3), R (R), R (3), R (R), R (R), R (3), R (R), R (3), R (R), R (3, R (3), R (3), R (3), R (3), R (R), R (1), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (2), R (3), R (3), R (3), R (3 (3), R (3), R (3), R (3 (3), R (3 (3), R (3), R (3 (3), R (3 (3), R (3), R (3 (3), R (3), R (3 (R (3), R (3), R (R (3), R (3), R (3, R (3), R (3), R (1), R (1), R (1), R (3, R (3 ("}, {"heading": "7 Experimental Evaluation", "text": "We now show that our approach is to improve accuracy compared to standard blocking techniques. In addition to MAS, we used datasets from DBLP and Cora Citation.To emphasize the importance of semantic knowledge in blocking, we consider standard blocking and two different types of blocking techniques, (1) and (2), for MDbased Collective Blocking. Under (1) we define blocking techniques for all blocking techniques used, but under (2) we have MDs for only some of the blocking techniques used. In both cases, we use three measures for comparing blocking techniques. One is the reduction ratio (minus 1) of the number of candidate blocking techniques."}, {"heading": "8 Conclusions", "text": "We have shown that matching dependencies, a new class of data quality / removal of semantic constraints in databases, can be profitably integrated with traditional ML methods, in our case corporate dissolution. They play a role not only in the desired goal of merging duplicate representations, but also in the record-blocking process that precedes the learning task. At this stage, they allow the declarative collection of semantic information that can be used to enrich blocking activity. MD declaration and enforcement, data processing in general, and machine learning can all be integrated using the LogiQL language. Acknowledgements: Part of this research was funded by an NSERC Discovery Fellowship and the NSERC Strategic Network on Business Intelligence (BIN). Z. Bahmani and L. Bertossi are very grateful for the support of LogicBlox during their internship and sabbatical visit."}], "references": [{"title": "Design and Implementation of the LogicBlox System", "author": ["M. Aref", "B. ten Cate", "T.J. Green", "B. Kimelfeld", "D. Olteanu", "E. Pasalic", "T.L. Veldhuizen", "G. Washburn"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "A Comparison of Fast Blocking Methods for Record Linkage", "author": ["R. Baxter", "P. Christen", "T. Churches"], "venue": "Proc. ACM SIGKDD Workshop on Data Cleaning, Record Linkage, and Object Identification", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Declarative Entity Resolution via Matching Dependencies and Answer Set Programs", "author": ["Z. Bahmani", "L. Bertossi", "S. Kolahi", "L. Lakshmanan"], "venue": "Proc. KR", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Generalized Discriminant Analysis using a Kernel Approach", "author": ["Baudat G", "F. Anouar"], "venue": "Neural Computation,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Swoosh: A Generic Approach to Entity Resolution", "author": ["O. Benjelloun", "H. Garcia-Molina", "D. Menestrina", "Q. Su", "S. EuijongWhang", "J. Widom"], "venue": "VLDB Journal,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Data Cleaning and Query Answering with Matching Dependencies and Matching Functions", "author": ["L. Bertossi", "S. Kolahi", "L. Lakshmanan"], "venue": "Proc. ICDT", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Data Cleaning and Query Answering with Matching Dependencies and Matching Functions", "author": ["L. Bertossi", "S. Kolahi", "L. Lakshmanan"], "venue": "Th. Comp. Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Quality and Complexity Measures for Data Linkage and Deduplication", "author": ["P. Christen", "K. Goiser"], "venue": "In Quality Measures in Data Mining, ser. Studies in Computational Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Automatic Record Linkage using Seeded Nearest Neighbour and Support Vector Machine Classification", "author": ["P. Christen"], "venue": "Proc. SIGKDD", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "A Survey of Indexing Techniques for Scalable Record Linkage and Deduplication", "author": ["P. Christen"], "venue": "IEEE Transactions in Knowledge and Data Engineering,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "A Comparison of String Metrics for Matching Names and Records", "author": ["W. Cohen", "P. Ravikumar", "S. Fienberg"], "venue": "Proc. Workshop on Data Cleaning and Object Consolidation", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Nearest Neighbor Pattern Classification", "author": ["T.M. Cover", "P.E. Hart"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1967}, {"title": "Duplicate Record Detection: a Survey", "author": ["A. Elmagarmid", "P. Ipeirotis", "V. Verykios"], "venue": "IEEE Transactions in Knowledge and Data Engineering,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Dependencies Revisited for Improving Data Quality", "author": ["W. Fan"], "venue": "Proc. PODS", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "A Theory for Record Linkage", "author": ["I.P. Fellegi", "A.B. Sunter"], "venue": "Journal of the American Statistical Society,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1969}, {"title": "Data Quality and Record Linkage Techniques", "author": ["T.N. Herzog", "F.J. Scheuren", "W.E. Winkler"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "UNIMATCH: A Record Linkage System: User\u2019s Manual", "author": ["M.A. Jaro"], "venue": "Technical Report, U.S. Bureau of the Census,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1976}, {"title": "A Guided Tour to Approximate String Matching", "author": ["G. Navarro"], "venue": "ACM Computing Surveys,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2001}, {"title": "Large-scale Collective Entity Matching", "author": ["V. Rastogi", "N.N. Dalvi", "M.N. Garofalakis"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Term-weighting Approaches in Automatic Text Retrieval", "author": ["G. Salton", "C. Buckley"], "venue": "Information Processing and Management,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1988}, {"title": "Entity Resolution with Iterative Blocking", "author": ["S. Euijong Whang", "D. Menestrina", "G. Koutrika", "M. Theobald", "H. Garcia-Molina"], "venue": "Proc. SIGMOD", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "The State of Record Linkage and Current Research Problems", "author": ["W.E. Winkler"], "venue": "Technical Report, U.S. Census Bureau,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}], "referenceMentions": [{"referenceID": 12, "context": "In more precise terms, ER is about the identification and fusion of database records (think of rows or tuples in tables) that represent the same real-world entity [8, 15].", "startOffset": 163, "endOffset": 170}, {"referenceID": 7, "context": "This classification problem is approached with machine learning (ML) methods, to learn from previously known or already made classifications (a training set for supervised learning), building a classification model (a classifier) for deciding about other record pairs [10, 15].", "startOffset": 268, "endOffset": 276}, {"referenceID": 12, "context": "This classification problem is approached with machine learning (ML) methods, to learn from previously known or already made classifications (a training set for supervised learning), building a classification model (a classifier) for deciding about other record pairs [10, 15].", "startOffset": 268, "endOffset": 276}, {"referenceID": 18, "context": "Most of the work on applying ML to ER work at the record level [22, 10, 11], and only some of the attributes, or their features, i.", "startOffset": 63, "endOffset": 75}, {"referenceID": 7, "context": "Most of the work on applying ML to ER work at the record level [22, 10, 11], and only some of the attributes, or their features, i.", "startOffset": 63, "endOffset": 75}, {"referenceID": 8, "context": "Most of the work on applying ML to ER work at the record level [22, 10, 11], and only some of the attributes, or their features, i.", "startOffset": 63, "endOffset": 75}, {"referenceID": 1, "context": "used [2, 19, 24].", "startOffset": 5, "endOffset": 16}, {"referenceID": 15, "context": "used [2, 19, 24].", "startOffset": 5, "endOffset": 16}, {"referenceID": 20, "context": "used [2, 19, 24].", "startOffset": 5, "endOffset": 16}, {"referenceID": 13, "context": "made identical [16, 17].", "startOffset": 15, "endOffset": 23}, {"referenceID": 5, "context": "In [6, 7], MDs were extended with matching functions (MFs).", "startOffset": 3, "endOffset": 9}, {"referenceID": 6, "context": "In [6, 7], MDs were extended with matching functions (MFs).", "startOffset": 3, "endOffset": 9}, {"referenceID": 0, "context": "LogiQL supports relational data management and, among several other features [1], an extended form of Datalog with stratified negation [9].", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": "In both cases, the set of MDs are interaction-free [7], which results, for each entity, in the unique set of blocks, and eventually into a single, duplicate-free instance [7].", "startOffset": 51, "endOffset": 54}, {"referenceID": 6, "context": "In both cases, the set of MDs are interaction-free [7], which results, for each entity, in the unique set of blocks, and eventually into a single, duplicate-free instance [7].", "startOffset": 171, "endOffset": 174}, {"referenceID": 11, "context": "We independently used three established classification algorithms: support vector machines (SVMs) [25], k-nearest neighbor (K-NN) [14], and non-parametric Bayes classifier (NBC) [4].", "startOffset": 130, "endOffset": 134}, {"referenceID": 3, "context": "We independently used three established classification algorithms: support vector machines (SVMs) [25], k-nearest neighbor (K-NN) [14], and non-parametric Bayes classifier (NBC) [4].", "startOffset": 178, "endOffset": 181}, {"referenceID": 6, "context": "com 2 For arbitrary sets of MDs, we need higher expressive power [7], such as that provided by answer set programming [3].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "com 2 For arbitrary sets of MDs, we need higher expressive power [7], such as that provided by answer set programming [3].", "startOffset": 118, "endOffset": 121}, {"referenceID": 14, "context": "The experimental results show that our system improves ER accuracy over traditional blocking techniques [18], which we will call standard blocking, where just blocking-key similarities are used.", "startOffset": 104, "endOffset": 108}, {"referenceID": 6, "context": "As in [7], we assume records have unique, fixed, global identifiers, rids, which are positive integers.", "startOffset": 6, "endOffset": 9}, {"referenceID": 13, "context": "= R2[\u02322] [16, 17].", "startOffset": 9, "endOffset": 17}, {"referenceID": 6, "context": "A dynamic, chase-based semantics for MDs with matching functions (MFs) was introduced in [7].", "startOffset": 89, "endOffset": 92}, {"referenceID": 5, "context": "associative, and then induce a partial-order structure \u3008DomA, A\u3009, with: a A a\u2032 :\u21d4 mA(a, a\u2032) = a\u2032 [6, 5].", "startOffset": 97, "endOffset": 103}, {"referenceID": 4, "context": "associative, and then induce a partial-order structure \u3008DomA, A\u3009, with: a A a\u2032 :\u21d4 mA(a, a\u2032) = a\u2032 [6, 5].", "startOffset": 97, "endOffset": 103}, {"referenceID": 6, "context": ", each attribute may appear in either the RHS or LHS of MDs in \u03a3), there is a unique resolved instance that is computable in polynomial time in |D| [7].", "startOffset": 148, "endOffset": 151}, {"referenceID": 0, "context": "Similarity computation is based on similarity functions, Sf i : DomAi \u00d7 DomAi \u2192 [0, 1], each of which assigns a numerical value, called similarity weight, to the comparisons of values for a record attributeAi (from a pre-chosen subset of attributes) (cf.", "startOffset": 80, "endOffset": 86}, {"referenceID": 6, "context": "In essence, this makes our set of merging-MDs interaction-free, and leads to a unique resolved instance [7].", "startOffset": 104, "endOffset": 107}, {"referenceID": 0, "context": "The first attribute is made an identifier [1].", "startOffset": 42, "endOffset": 45}, {"referenceID": 10, "context": "12 We used three well-known similarity functions [13], depending on the attribute domains.", "startOffset": 49, "endOffset": 53}, {"referenceID": 19, "context": "\u201cTF-IDF cosine similarity\u201d [23] used for computing similarities for text-valued attributes, whose values are string vectors.", "startOffset": 27, "endOffset": 31}, {"referenceID": 21, "context": "For attributes with short string values, such as author name, we applied \u201cJaro-Winkler similarity\u201d [26].", "startOffset": 99, "endOffset": 103}, {"referenceID": 17, "context": "Finally, for numerical attributes, such as publication year, we used \u201cLevenshtein distance\u201d [21], which computes similarity of", "startOffset": 92, "endOffset": 96}, {"referenceID": 6, "context": "More generally, for the application-dependent set, \u03a3 , of blocking-MDs we adopt the chase-based semantics for entity resolution [7].", "startOffset": 128, "endOffset": 131}, {"referenceID": 6, "context": "for every two blocking-MDs m1,m2, the set of attributes on the RHS of m1 and the set of attributes on the LHS of m2 on which there are similarity predicates, are disjoint [7].", "startOffset": 171, "endOffset": 174}, {"referenceID": 0, "context": "An atom Ri[X\u0304]=Bl states that predicate Ri is functional on X\u0304 [1].", "startOffset": 63, "endOffset": 66}, {"referenceID": 0, "context": "In LogiQL, \u201c!\u201d, as in the body above, is used for negation [1].", "startOffset": 59, "endOffset": 62}, {"referenceID": 2, "context": "14 Notice that since we have interaction-free sets of blocking-MDs, stratified Datalog programs are expressive enough to express and enforce them [3].", "startOffset": 146, "endOffset": 149}, {"referenceID": 6, "context": "The RHS means that the two records are merged into a new full record r\u0304, with r\u0304[Ai] := mAi(r\u03041[Ai], r\u03042[Ai]) [7].", "startOffset": 110, "endOffset": 113}, {"referenceID": 9, "context": "The former is the number of true duplicate candidate record-pairs divided by the number of true duplicate pairs, and precision is the number of true candidate duplicate record-pairs divided by the total number of candidate pairs [12].", "startOffset": 229, "endOffset": 233}, {"referenceID": 9, "context": "On the other hand, blocking techniques that result in larger blocks generate a higher number of candidate record-pairs that will likely cover more true duplicate pairs, at the cost of having to compare more candidate pairs [12].", "startOffset": 223, "endOffset": 227}], "year": 2016, "abstractText": "Entity resolution (ER), an important and common data cleaning problem, is about detecting data duplicate representations for the same external entities, and merging them into single representations. Relatively recently, declarative rules called matching dependencies (MDs) have been proposed for specifying similarity conditions under which attribute values in database records are merged. In this work we show the process and the benefits of integrating three components of ER: (a) Classifiers for duplicate/non-duplicate record pairs built using machine learning (ML) techniques, (b) MDs for supporting both the blocking phase of ML and the merge itself; and (c) The use of the declarative language LogiQL -an extended form of Datalog supported by the LogicBlox platformfor data processing, and the specification and enforcement of MDs.", "creator": "LaTeX with hyperref package"}}}