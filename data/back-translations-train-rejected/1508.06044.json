{"id": "1508.06044", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "Visualizing NLP annotations for Crowdsourcing", "abstract": "Visualizing NLP annotation is useful for the collection of training data for the statistical NLP approaches. Existing toolkits either provide limited visual aid, or introduce comprehensive operators to realize sophisticated linguistic rules. Workers must be well trained to use them. Their audience thus can hardly be scaled to large amounts of non-expert crowdsourced workers. In this paper, we present CROWDANNO, a visualization toolkit to allow crowd-sourced workers to annotate two general categories of NLP problems: clustering and parsing. Workers can finish the tasks with simplified operators in an interactive interface, and fix errors conveniently. User studies show our toolkit is very friendly to NLP non-experts, and allow them to produce high quality labels for several sophisticated problems. We release our source code and toolkit to spur future research.", "histories": [["v1", "Tue, 25 Aug 2015 06:34:00 GMT  (867kb,D)", "http://arxiv.org/abs/1508.06044v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hanchuan li", "haichen shen", "shengliang xu", "congle zhang"], "accepted": false, "id": "1508.06044"}, "pdf": {"name": "1508.06044.pdf", "metadata": {"source": "CRF", "title": "Visualizing NLP annotations for Crowdsourcing", "authors": ["Hanchuan Li", "Haichen Shen", "Shengliang Xu", "Congle Zhang"], "emails": ["hanchuan@cs.washington.edu", "haichen@cs.washington.edu", "shengliang@cs.washington.edu", "clzhang@cs.washington.edu"], "sections": [{"heading": null, "text": "Visualizing NLP annotations is useful for collecting training data for statistical NLP approaches. Existing toolkits either offer limited visual tools or introduce comprehensive operators to implement complex linguistic rules. Workers need to be well-trained to use them, so their audience can hardly be scaled to large numbers of unskilled crowd-sourcing workers. In this post, we present CROWDANNO, a visualization toolkit that allows crowd-sourcing workers to comment on two general categories of NLP problems: clusters and particles. Workers can complete the tasks with simplified operators in an interactive user interface and conveniently fix errors. User studies show that our toolkit is very friendly to NLP non-experts and allows them to create high-quality labels for multiple complex problems. We publish our source code and toolkit to advance research."}, {"heading": "1 Introduction", "text": "It is not as if it is a comprehensive problem that has been learned in recent years from the training data of a particular domain (usually the sequence observations are performed using neural networks), whose data can often come from other areas, such as social media and biomedical data (Wu et al.). To fully exploit the power of statistical approaches, it is useful to collect quickly plentified training data. As crowd-sourcing platforms (e.g. Amazon Mechanical 1 and ODesk 2) advance, it quickly becomes a large crowd."}, {"heading": "2 Toolkit Overview", "text": "In this section, we will first present the design decisions and the overview of the toolkits, and then we will present the user interface and key functionals.The toolkit is designed and implemented as a web application, as it is easiest for crowdworkers to view.Users of our visualization toolkit include annotation collectors and crowd source workers. In general, annotation collectors (NLP experts and well-trained programmers) use our toolkit to collect training data from crowd-source workers for their NLP systems. We believe that annotation collectors know their NLP problems better than anyone else, so we will leave it to them to implement an HTML page to illustrate their problems.The HTML page would call the APIs to pass data (e.g. objects into clusters) to the toolkits. The core components are then to visualize the problem and allow them to interact with our objects."}, {"heading": "2.1 Cluster Labeling", "text": "Figure 2 shows the user interface. The left side (about 40%) shows the NLP task. An easy way to view the core reference task, as shown in the figure, is to highlight the mentions and give them unique IDs. The right side of the interface serves the interaction purpose, where employees interactively generate the clusters. Each token has a corresponding node in the Operating Area. To bridge the link between text display and graphics diagram, we label each token and associated node with the same index.Our main method of manipulation for merging two nodes is to pull nodes and merge into a group. It is the most intuitive operation for one to merge two nodes without instructions. We explain the selection and dragging, adding and removing nodes, and the color scheme in the following paragraphs."}, {"heading": "SELECT AND DRAG", "text": "Since we have two separate parts, one for displaying text, the other for manipulating clusters and groups, an appropriate selection must be supported to reduce the user's eye movement between two parts. We use three mechanisms to solve this problem: firstly, when the user clicks on an icon, the corresponding node is highlighted in red color; likewise, when the user starts pulling a node, the icon is also highlighted against a red background; secondly, to speed up tracing from the node to the actual text as soon as the user starts pulling a node, the display section is scrolled to the correct position so that the user can easily read the context of that symbol; thirdly, as shown in Figure 3, when the drag event begins, an abbreviation text is displayed under each node so that the user can have a brief idea of what each node represents."}, {"heading": "LINK ADD AND REMOVE", "text": "Our tool does not allow the user to explicitly add a link between two nodes. Instead, the way to add a link by dragging a node close enough to the target node is shown. Figure 4 shows the process of adding a link. When the user starts dragging a node, a shadow circle is shown around each node. This shadow circle indicates the effective area of adding a link. As soon as a node is close enough to that shadow circle, a temporary link (in red) is immediately added to show the result of this operation (shown in Figure 4 (b)). After the user confirms the process by lowering the node, a permanent link is added. Due to the transitivity property of the clustering task, CROWDANNO automatically bundles two groups and assigns the same color to all nodes in this new group. The operation to remove a link is as simple as clicking the link, then the node is displayed in group 5. When the node is removed from the node, the node is shown in the figure 5."}, {"heading": "COLOR SCHEME", "text": "The default color is gray. If a node (or token) does not belong to a group, we use the default fill color (or background color). When generating a group, we assign a new color. If two groups merge, we retain the color of the merging group as the color of a newly merged larger group (Figure 4). If a group is split in two, the majority component retains the color of the original group."}, {"heading": "GROUP POSITIONING", "text": "To improve the ease of use and precision of dragging and adding linkage operations, and to use space effectively, there should be a reasonable distance between nodes and nodes, as well as between groups and groups. We use the d3 force model and calibrate the gravitational parameter to enforce a reasonable gap between nodes. CROWDANNO also calculates a reasonable central point for each group and forces a force in this direction on each node within that group, so groups in a small region will not overlap."}, {"heading": "2.2 Tree Construction", "text": "The task of tree comments is to construct or edit a tree hierarchy from a sentence, a task that is very common in many sentence-based NLP problems such as POS marking."}, {"heading": "INTERFACE", "text": "The user interface for tree comments consists of two parts. We use syntactical parsing as a running example to show how our toolkit can build a parsed tree. Figure 6 shows the general user interface. The left part is the sentence data list. Our toolkit supports multiple sentence comments at the same time. Users can choose from a list of sentence files at the bottom of the left panel. Sentence files are in plain text format. Each sentence file is simply a list of sentences, each of which is a line. Words are separated by spaces. The sentence list in a given input file is displayed in the input area. To the right of each sentence is a small download mark that triggers a click to download the current tree created for that sentence. The right part is the tree editing / construction area. A given input set is split vertically into word nodes. The reason that we organize the sentence nodes this way, instead of always taking up space horizontally, is that each word now occupies mine."}, {"heading": "NODE ADDITION (GROUPING)", "text": "Our tool provides a simple line-cut operation to group an existing group of sub-trees, as shown in Figure 7. As a result, a new node is added that serves as the root of all grouped sub-trees. To our knowledge, we are the first to suggest this visualization operation on tree structures."}, {"heading": "NODE DELETION (UNGROUPING)", "text": "As a knot complement operation, our tool also offers a knot delete operation, also by cutting a line. If a single line is cut, our tool considers it a knot delete. The knot at the bottom of the cut line is deleted unless the knot is a leaf knot. Figure 8 gives the illustration."}, {"heading": "NODE FOLDING", "text": "The two tree editing operations mentioned above are sufficient to build arbitray trees in most NLP tasks. In addition, our tool also offers a node folding operation, which is more of a view modification operation than an editing operation. For each non-leaf node, a click on the node folds the entire subtree and is represented by a colored leaf node, displaying all the words in the subtree. Figure 9 provides an illustration. As we aim at sentence-based tree editing tasks, the tree layout is designed to maintain the node order after each of the operations as an input sequence, i.e. as a sentence sequence."}, {"heading": "3 Evaluation", "text": "Our goal is to evaluate whether our visualization toolkit is useful for NLP non-experts to comment on cluster data and analyze training data."}, {"heading": "3.1 Setup", "text": "It is the time when we go in search of a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution that would enable us to find a solution. \""}, {"heading": "4 Related Work", "text": "In fact, it is so that it is a matter of a manner in which one sees oneself in a position to outwit and outwit oneself, and specifically in the manner in which one is in a position to outwit oneself, in the manner in which one sees oneself in a position, and in the manner in which one is in a position to outwit oneself and outwit oneself, and in the manner in which one is in a position to outwit oneself, and in the manner in which one is in a position to outwit oneself and outwit oneself, and in the manner in which one outwits oneself and oneself, and in the manner in which one outwits oneself and oneself, and oneself, and oneself, in the manner in which one outwit oneself and oneself, and oneself, in the manner in which one outwit oneself and oneself, and oneself, and in the manner in which one is able to outwit oneself, and in the manner in which one is able to outwit oneself and oneself, and in the manner in the manner in which one and in which one is able to outwit oneself and oneself, and in the manner in the manner in which one is able to outwit oneself, and oneself, in the manner in the manner in which one and oneself, and oneself, in the manner in the manner in which one is able to outwit oneself and oneself, and oneself, in the manner in the manner in the manner in which one and oneself, and oneself, in the manner in the manner in which one is able to outwit oneself, and oneself, in the manner in the manner in the manner in which one and oneself, and oneself, in the manner in the manner in the manner in which one and oneself, in the manner in the manner in which one is in the manner in which one and oneself, and in the manner in the manner in the manner in which one is in the manner in which one is in the manner in which one and in the manner in which one is"}, {"heading": "5 Conclusion and Future Work", "text": "In this article, we present CROWDANNO, a toolkit for crowdsourcing NLP annotations. We visualize two important categories of NLP issues: clustering and parsing. By providing simplified operators and interactive interfaces, we enable crowdsourcing employees to generate high-quality training data for NLP issues. In our evaluation, we let laypeople test our toolkit. Results are very promising. Due to the time constraints, we have not yet allowed crowdsourcing employees to really test our toolkit. In the future, we would use the toolkit on AMT to collect real training data for NLP issues."}], "references": [{"title": "Community-based construction of draft and final translation corpus through a translation hosting site minna no hon\u2019yaku (mnh)", "author": ["Masao Utiyama", "Eiichiro Sumita", "Kyo Kageura"], "venue": "In LREC. Citeseer", "citeRegEx": "Abekawa et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Abekawa et al\\.", "year": 2010}, {"title": "Open information extraction for the web", "author": ["Banko et al.2007] Michele Banko", "Michael J Cafarella", "Stephen Soderland", "Matthew Broadhead", "Oren Etzioni"], "venue": "In IJCAI,", "citeRegEx": "Banko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "Annotating named entities in twitter data with crowdsourcing", "author": ["Finin et al.2010] Tim Finin", "Will Murnane", "Anand Karandikar", "Nicholas Keller", "Justin Martineau", "Mark Dredze"], "venue": "In Proceedings of the NAACL HLT 2010 Workshop on Creating", "citeRegEx": "Finin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Finin et al\\.", "year": 2010}, {"title": "Crowdsourcing document relevance assessment with mechanical turk", "author": ["Grady", "Lease2010] Catherine Grady", "Matthew Lease"], "venue": "In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon\u2019s Mechan-", "citeRegEx": "Grady et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Grady et al\\.", "year": 2010}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld"], "venue": "In ACL-HLT,", "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "The rise of crowdsourcing", "author": ["Jeff Howe"], "venue": "Wired magazine,", "citeRegEx": "Howe.,? \\Q2006\\E", "shortCiteRegEx": "Howe.", "year": 2006}, {"title": "Data quality from crowdsourcing: A study of annotation selection criteria", "author": ["Hsueh et al.2009] Pei-Yun Hsueh", "Prem Melville", "Vikas Sindhwani"], "venue": "In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Process-", "citeRegEx": "Hsueh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hsueh et al\\.", "year": 2009}, {"title": "Neurons as monte carlo samplers: Bayesian inference and learning in spiking networks", "author": ["Huang", "Rao2014] Yanping Huang", "Rajesh P Rao"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Huang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2014}, {"title": "How prior probability influences decision making: A unifying probabilistic model", "author": ["Y. Huang", "A.L. Friesen", "T.D. Hanks", "M.N. Shadlen", "R.P.N. Rao"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Huang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Using mechanical turk to annotate lexicons for less commonly used languages", "author": ["Irvine", "Klementiev2010] Ann Irvine", "Alexandre Klementiev"], "venue": "In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Ama-", "citeRegEx": "Irvine et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Irvine et al\\.", "year": 2010}, {"title": "Accurate unlexicalized parsing", "author": ["Klein", "Manning2003] Dan Klein", "Christopher D Manning"], "venue": "In Proceedings of the 41st Annual Meeting on Association for Computational LinguisticsVolume", "citeRegEx": "Klein et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2003}, {"title": "Scaling question answering to the web", "author": ["Kwok et al.2001] Cody Kwok", "Oren Etzioni", "Daniel S Weld"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "Kwok et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kwok et al\\.", "year": 2001}, {"title": "On quality control and machine learning in crowdsourcing", "author": ["Matthew Lease"], "venue": "In Human Computation", "citeRegEx": "Lease.,? \\Q2011\\E", "shortCiteRegEx": "Lease.", "year": 2011}, {"title": "Wordfreak: An open tool for linguistic annotation", "author": ["Morton", "LaCivita2003] Thomas Morton", "Jeremy LaCivita"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics", "citeRegEx": "Morton et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Morton et al\\.", "year": 2003}, {"title": "Divide and conquer: Crowdsourcing the creation of cross-lingual textual entailment corpora", "author": ["Negri et al.2011] Matteo Negri", "Luisa Bentivogli", "Yashar Mehdad", "Danilo Giampiccolo", "Alessandro Marchetti"], "venue": "In Proceedings of the Conference", "citeRegEx": "Negri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Negri et al\\.", "year": 2011}, {"title": "Demonstration of the uam corpustool for text and image annotation", "author": ["Mick O\u2019Donnell"], "venue": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Demo Session,", "citeRegEx": "O.Donnell.,? \\Q2008\\E", "shortCiteRegEx": "O.Donnell.", "year": 2008}, {"title": "A taxonomy of distributed human computation. Human-Computer Interaction Lab Tech Report, University of Maryland", "author": ["Quinn", "Bederson2009] Alexander J Quinn", "Benjamin B Bederson"], "venue": null, "citeRegEx": "Quinn et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Quinn et al\\.", "year": 2009}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["Cliff C Lin", "Chris Manning", "Andrew Y Ng"], "venue": "In Proceedings of the 28th international conference on machine learning (ICML-11),", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Web-based annotation of anaphoric relations and lexical chains", "author": ["Daniela Goecke", "Nils Diewald", "Alexander Mehler", "Irene Cramer"], "venue": "In Proceedings of the Linguistic Annotation Workshop,", "citeRegEx": "St\u00fchrenberg et al\\.,? \\Q2007\\E", "shortCiteRegEx": "St\u00fchrenberg et al\\.", "year": 2007}, {"title": "Information retrieval using markov decision process", "author": ["Nan Wang"], "venue": "International Journal of Computer Systems,", "citeRegEx": "Wang.,? \\Q2015\\E", "shortCiteRegEx": "Wang.", "year": 2015}, {"title": "Learning to rank the severity of unrepaired cleft lip nasal deformity on 3d mesh data", "author": ["Wu et al.2014] Jia Wu", "Raymond Tse", "Linda G Shapiro"], "venue": "In Pattern Recognition (ICPR),", "citeRegEx": "Wu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2014}, {"title": "Collaborative annotation and visualization of functional and discourse structures", "author": ["Yan", "Webster2012] Hengbin Yan", "Jonathan Webster"], "venue": "In Proceedings of the Twenty-Fourth Conference on Computational Linguistics and Speech Processing,", "citeRegEx": "Yan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yan et al\\.", "year": 2012}, {"title": "An adaptive kernel width update for correntropy", "author": ["Zhao et al.2012] Songlin Zhao", "Badong Chen", "Jose C Principe"], "venue": "In Neural Networks (IJCNN), The 2012 International Joint Conference on,", "citeRegEx": "Zhao et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 1, "context": "Statistical machine learning approaches has made great successes in research disciplines such as parsing (Klein and Manning, 2003), information extractions (Banko et al., 2007), question answering (Kwok et al.", "startOffset": 156, "endOffset": 176}, {"referenceID": 11, "context": ", 2007), question answering (Kwok et al., 2001).", "startOffset": 28, "endOffset": 47}, {"referenceID": 17, "context": "Significant advances have been made in recent years on inferrring latent labels for sequence observations using neural networks (Socher et al., 2011; Huang and Rao, 2014) and kenerl methods (Zhao et al.", "startOffset": 128, "endOffset": 170}, {"referenceID": 22, "context": ", 2011; Huang and Rao, 2014) and kenerl methods (Zhao et al., 2012).", "startOffset": 48, "endOffset": 67}, {"referenceID": 20, "context": "Yet offthe-shelf models learned from training data of one particular domain (usually newswire) would often underperform at present tasks, whose data could come from other domains such as social media and biomedical data (Wu et al., 2014).", "startOffset": 220, "endOffset": 237}, {"referenceID": 8, "context": "All these tasks could be treated as some practice of clustering or formulated as a special form of reinforcement learning (Huang et al., 2012).", "startOffset": 122, "endOffset": 142}, {"referenceID": 15, "context": "tools are generally built as local programs such as the WordFreak linguistic annotation tool (Morton and LaCivita, 2003) and the UAM CorpusTool for text and image annotation (O\u2019Donnell, 2008).", "startOffset": 174, "endOffset": 191}, {"referenceID": 18, "context": "specific domains, such as anaphora (St\u00fchrenberg et al., 2007) and financial reports (Wang, 2015).", "startOffset": 35, "endOffset": 61}, {"referenceID": 19, "context": ", 2007) and financial reports (Wang, 2015).", "startOffset": 30, "endOffset": 42}, {"referenceID": 5, "context": "Crowdsourcing (Howe, 2006) is a popular and fast growing research area.", "startOffset": 14, "endOffset": 26}, {"referenceID": 14, "context": "built a cross-lingual textual corpora (Negri et al., 2011); Finin et al.", "startOffset": 38, "endOffset": 58}, {"referenceID": 2, "context": "collected simple named entity annotations using Amazon MTurk and Crowd-Flower (Finin et al., 2010).", "startOffset": 78, "endOffset": 98}, {"referenceID": 6, "context": "Also there are some researchers observed the hardness of collecting high quality data and did some studies on improving that, such as (Hsueh et al., 2009)( how annotations should be selected to maximize quality), and (Lease, 2011) (quality control in crowdsoursing by machine learning).", "startOffset": 134, "endOffset": 154}, {"referenceID": 12, "context": ", 2009)( how annotations should be selected to maximize quality), and (Lease, 2011) (quality control in crowdsoursing by machine learning).", "startOffset": 70, "endOffset": 83}], "year": 2015, "abstractText": "Visualizing NLP annotation is useful for the collection of training data for the statistical NLP approaches. Existing toolkits either provide limited visual aid, or introduce comprehensive operators to realize sophisticated linguistic rules. Workers must be well trained to use them. Their audience thus can hardly be scaled to large amounts of non-expert crowdsourced workers. In this paper, we present CROWDANNO, a visualization toolkit to allow crowd-sourced workers to annotate two general categories of NLP problems: clustering and parsing. Workers can finish the tasks with simplified operators in an interactive interface, and fix errors conveniently. User studies show our toolkit is very friendly to NLP non-experts, and allow them to produce high quality labels for several sophisticated problems. We release our source code and toolkit to spur future research.", "creator": "LaTeX with hyperref package"}}}