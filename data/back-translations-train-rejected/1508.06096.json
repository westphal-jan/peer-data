{"id": "1508.06096", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "Unsatisfiable Cores and Lower Bounding for Constraint Programming", "abstract": "Constraint Programming (CP) solvers typically tackle optimization problems by repeatedly finding solutions to a problem while placing tighter and tighter bounds on the solution cost. This approach is somewhat naive, especially for soft-constraint optimization problems in which the soft constraints are mostly satisfied. Unsatisfiable-core approaches to solving soft constraint problems in SAT (e.g. MAXSAT) force all soft constraints to be hard initially. When solving fails they return an unsatisfiable core, as a set of soft constraints that cannot hold simultaneously. These are reverted to soft and solving continues. Since lazy clause generation solvers can also return unsatisfiable cores we can adapt this approach to constraint programming. We adapt the original MAXSAT unsatisfiable core solving approach to be usable for constraint programming and define a number of extensions. Experimental results show that our methods are beneficial on a broad class of CP-optimization benchmarks involving soft constraints, cardinality or preferences.", "histories": [["v1", "Tue, 25 Aug 2015 10:11:42 GMT  (33kb,D)", "https://arxiv.org/abs/1508.06096v1", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["nicholas downing", "thibaut feydy", "peter j stuckey"], "accepted": false, "id": "1508.06096"}, "pdf": {"name": "1508.06096.pdf", "metadata": {"source": "CRF", "title": "Unsatisfiable Cores and Lower Bounding for Constraint Programming", "authors": ["Nicholas Downing", "Peter J. Stuckey"], "emails": ["ndowning@csse.unimelb.edu.au", "tfeydy@csse.unimelb.edu.au", "pjs@csse.unimelb.edu.au"], "sections": [{"heading": "1 Introduction", "text": "In this case, we will use MAXSAT's flawed Core Europe approach to see what problems exist and how they can be solved. In this case, we will extend the flawed Core Europe approach from MAXSAT to contract programs."}, {"heading": "2 Lazy Clause Generation", "text": "We will give a brief description of the propagation problems and LCG, for further details see [25]. We will consider problems consisting of constraints C over integer variables x1,.., xn, each with a given finite domain Dorig (xi). A workable solution is an evaluation of the variable that meets all constraints, and lies in the domain Dorig = Dorig (x1) \u00b7. \u00b7 Dorig (xn), i.e. it is an evaluation of the variable that meets all constraints. (xi).A Propagation Solver maintains a domain constraint D (xi) Dorig (xi) for each variable, and only considers solutions that lie within D = D (x1). \u00b7 D (xn). The solution interleaves propagation that repeatedly applies propagators to remove unsupported values, and the search that takes into account the resulting sub-problems."}, {"heading": "3 Soft Constraint Optimization", "text": "This year it is more than ever before in the history of the city."}, {"heading": "4 Basic Unsatisfiable Cores Algorithm", "text": "An unsatisfactory core is a clause that contains only letters in y. This clause forces an objective variable to be true and must add some positive values to the objectives. Note: The clauses that contain a literal \"yi\" are not unsatisfactory. Unsatisfactory core approaches to optimization originate from solving a problem called by the high level of algorithms 1 and essentially modify decision-making procedures based on conflict analysis. Each attempt fixes all indeterminate variables in an unsatisfactory core that has never appeared in an unsatisfactory core. 1 In the calculation of cTy, we take false = 0 and true = 1. We make the coefficients positive by negating Boolean letters."}, {"heading": "5 Nested Unsatisfiable Core Algorithm", "text": "This year it is more than ever before."}, {"heading": "6 Notification-based Nested Algorithm", "text": "This is frustrating for the nested algorithm because it does not explicitly include new information in the original formulation that may support future searches; the next (contingent) unsatisfactory core is a duplicated problem; the first unsatisfactory core is a problem that is not explicitly contained in the original formulation; the second (contingent) unsatisfactory core is a duplicated problem in the original formulation."}, {"heading": "7 Enhanced Lower Bounding", "text": "At each node of the industry and the bound tree, we must use the linear constraints cTy < cT \u03b8 (y), where we have the current best solution and fathom (backtrack) when the constraint is a failure. < CTy < cT \u03b8 (y), where there is the best solution and fathom (backtrack). < CTY (2), the unattainable lower limit is reached by using all unfixed yi as false. Information from unsatisfactory cores can be used to strengthen the lower limit. (Suppose that some subsets e.g. y2, y3 and y5 are unfixed, but we have the unsatisfactory core y2, y3 y5).Then it is clearly too conservative to assume that all are wrong and we can increase the estimate by at least min (c2, c3, c5)."}, {"heading": "8 Experiments", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "9 Conclusion", "text": "We have translated MAXSAT's unsatisfactory core methods to solve CP optimization problems with pseudo-Boolean objectives, using the ability of LCG solvers to generate unsatisfactory cores. This is one of the first approaches to soft, intentionally defined constraints that we know of, apart from PBO / WBO [9,21], which only support purposely defined linear constraints. To get the maximum benefit from unsatisfactory cores, we had to expand the method to create and use unsatisfactory cores in the middle of the search, which can be much better than the traditional industry-bound approach to consciously defined optimization problems. In our enhancements, we saw a clear synergy between (i) aggressive assumption that soft constraints persist, and (ii) the use of the resulting information on unsatisfactory or contradictory constraints, for improved constraints."}], "references": [{"title": "Conflict analysis in mixed integer programming", "author": ["T. Achterberg"], "venue": "Discrete Optimization 4(1), 4\u201320", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Solving (Weighted) Partial MaxSAT through Satisfiability Testing", "author": ["C. Ans\u00f3tegui", "M. Bonet", "J. Levy"], "venue": "Kullmann, O. (ed.) Proc. SAT2009, LNCS, vol. 5584, pp. 427\u2013440. Springer Berlin / Heidelberg", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Resolution for Max-SAT", "author": ["M.L. Bonet", "J. Levy", "F. Many\u00e0"], "venue": "AI 171(8-9), 606\u2013618", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Radio Link Frequency Assignment", "author": ["B. Cabon", "S. de Givry", "L. Lobjois", "T. Schiex", "J.P. Warners"], "venue": "Constraints 4, 79\u201389", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "Efficient Intelligent Backtracking Using Linear Programming", "author": ["B. Davey", "N. Boland", "P. Stuckey"], "venue": "IJOC 14(4), 373\u2013386", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Neighborhood Portfolio Approach for Local Search Applied to Timetabling Problems", "author": ["L. Di Gaspero", "A. Schaerf"], "venue": "JMMA 5, 65\u201389", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Explaining Flow-Based Propagation", "author": ["N. Downing", "T. Feydy", "P.J. Stuckey"], "venue": "Beldiceanu, N., Jussien, N., Pinson, E. (eds.) Proc. CPAIOR2012. LNCS, vol. 7298, pp. 146\u2013162. Springer Verlag, Nantes, France", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Translating Pseudo-Boolean Constraints into SAT", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "JSAT 2(1-4), 1\u201326", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Half reification and flattening", "author": ["T. Feydy", "Z. Somogyi", "P. Stuckey"], "venue": "Lee, J. (ed.) Proc. CP2011, LNCS, vol. 6876, pp. 286\u2013301. Springer Berlin / Heidelberg", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "On Solving the Partial MAX-SAT Problem", "author": ["Z. Fu", "S. Malik"], "venue": "Biere, A., Gomes, C. (eds.) Proc. SAT2006, LNCS, vol. 4121, pp. 252\u2013265. Springer Berlin / Heidelberg", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Existential arc consistency: Getting closer to full arc consistency in weighted CSPs", "author": ["S. de Givry", "F. Heras", "M. Zytnicki", "J. Larrosa"], "venue": "Proc. IJCAI05. pp. 193\u2013198. AAAI Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "Itemset mining: A constraint programming perspective", "author": ["T. Guns", "S. Nijssen", "L.D. Raedt"], "venue": "AI 175(12-13), 1951\u20131983", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Solving Steiner tree problems in graphs to optimality", "author": ["T. Koch", "A. Martin"], "venue": "Networks 32(3), 207\u2013232", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Improved Exact Solver for the Weighted MAX-SAT Problem", "author": ["A. Kuegel"], "venue": "Pragmatics of SAT workshop, SAT2010", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "In the quest of the best form of local consistency for Weighted CSP", "author": ["J. Larrosa", "T. Schiex"], "venue": "Proc. IJCAI03. pp. 239\u2013244. AAAI Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Exploiting Unit Propagation to Compute Lower Bounds in Branch and Bound Max-SAT Solvers", "author": ["C. Li", "F. Many\u00e0", "J. Planes"], "venue": "van Beek, P. (ed.) Proc. CP2005, LNCS, vol. 3709, pp. 403\u2013414. Springer Berlin / Heidelberg", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Detecting disjoint inconsistent subformulas for computing lower bounds for Max-SAT", "author": ["C.M. Li", "F. Many\u00e0", "J. Planes"], "venue": "Proc. AAAI06. pp. 86\u201391. AAAI Press", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "IncWMaxSatz. In: Max-SAT", "author": ["H. Lin", "K. Su", "C.M. Li", "J. Argelich"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Algorithms for Weighted Boolean Optimization", "author": ["V. Manquinho", "J. Marques-Silva", "J. Planes"], "venue": "Kullmann, O. (ed.) Proc. SAT2009, LNCS, vol. 5584, pp. 495\u2013 508. Springer Berlin / Heidelberg", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithms for Maximum Satisfiability using Unsatisfiable Cores", "author": ["J. Marques-Silva", "J. Planes"], "venue": "Proc. DATE2008. pp. 408\u2013413", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "On using unsatisfiability for solving maximum satisfiability", "author": ["J. Marques-Silva", "J. Planes"], "venue": "CoRR abs/0712.1097", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Chaff: engineering an efficient SAT solver", "author": ["M. Moskewicz", "C. Madigan", "Y. Zhao", "L. Zhang", "S. Malik"], "venue": "Proc. DAC2001. pp. 530\u2013535", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Propagation via lazy clause generation", "author": ["O. Ohrimenko", "P. Stuckey", "M. Codish"], "venue": "Constraints 14, 357\u2013391", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "A branch-and-cut algorithm for the single-commodity, uncapacitated, fixed-charge network flow problem", "author": ["F. Ortega", "L.A. Wolsey"], "venue": "Networks 41(3), 143\u2013158", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2003}, {"title": "Methods for Visual Understanding of Hierarchical System Structures", "author": ["K. Sugiyama", "S. Tagawa", "M. Toda"], "venue": "Systems, Man and Cybernetics, IEEE Trans. 11(2), 109\u2013125", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1981}, {"title": "Operations Research Techniques in Constraint Programming", "author": ["W.J. Van Hoeve"], "venue": "Ph.D. thesis, Centrum voor Wiskunde en Informatica, The Netherlands", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "NSPLib \u2013 A Nurse Scheduling Problem Library: A tool to evaluate (meta-)heuristic procedures", "author": ["M. Vanhoucke", "B. Maenhout"], "venue": "Proc. ORAHS2005", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 9, "context": "Earlier work on unsatisfiable cores for Maximum Satisfiability (MAXSAT) has shown that it is advantageous to consider soft constraints to be hard constraints initially, solve the problem using a modern SAT solver, and use the resulting evidence of infeasibility to see which (temporarily hard) constraints are conflicting with each other, and soften them again only as necessary [12].", "startOffset": 379, "endOffset": 383}, {"referenceID": 25, "context": "CP handles soft-constraint problems as minimization problems where the objective is a count of violations, the counts being derived from either reified primitive constraints (whose enforcement is controlled by an auxiliary variable) or soft global constraints (for examples of soft global constraints and their propagation algorithms see Van Hoeve [28]).", "startOffset": 348, "endOffset": 352}, {"referenceID": 21, "context": "LCG is a hybrid approach to CP that uses a traditional \u2018propagation and search\u2019 constraint solver as the outer layer which guides the solution process, plus an inner layer which lazily decomposes CP to Boolean satisfiability (SAT) and applies learning SAT solver technology to reduce search [24,25].", "startOffset": 291, "endOffset": 298}, {"referenceID": 22, "context": "LCG is a hybrid approach to CP that uses a traditional \u2018propagation and search\u2019 constraint solver as the outer layer which guides the solution process, plus an inner layer which lazily decomposes CP to Boolean satisfiability (SAT) and applies learning SAT solver technology to reduce search [24,25].", "startOffset": 291, "endOffset": 298}, {"referenceID": 22, "context": "We give a brief description of propagation-based solving and LCG, for more details see [25].", "startOffset": 87, "endOffset": 91}, {"referenceID": 21, "context": "Conflict analysis derives new redundant constraints to avoid repeated search, and, as a side effect, modifies the backtracking procedure to backjump or restart solving at an appropriate point close to the failure [24].", "startOffset": 213, "endOffset": 217}, {"referenceID": 10, "context": "For WCSP, in which each extensional table contains a weight column giving the cost to be paid if the row holds, the best solver seems to be toolbar/toulbar2 [13,17].", "startOffset": 157, "endOffset": 164}, {"referenceID": 14, "context": "For WCSP, in which each extensional table contains a weight column giving the cost to be paid if the row holds, the best solver seems to be toolbar/toulbar2 [13,17].", "startOffset": 157, "endOffset": 164}, {"referenceID": 13, "context": "For MAXSAT, good solvers in a recent evaluation [3] included akmaxsat [16] and MaxSatz [20] variants.", "startOffset": 70, "endOffset": 74}, {"referenceID": 17, "context": "For MAXSAT, good solvers in a recent evaluation [3] included akmaxsat [16] and MaxSatz [20] variants.", "startOffset": 87, "endOffset": 91}, {"referenceID": 15, "context": "Essentially they use lookahead, with unit propagation and failed literal detection, to improve the lower bound [18,19].", "startOffset": 111, "endOffset": 118}, {"referenceID": 16, "context": "Essentially they use lookahead, with unit propagation and failed literal detection, to improve the lower bound [18,19].", "startOffset": 111, "endOffset": 118}, {"referenceID": 2, "context": "In restricted cases they use MAXSAT resolution, in which conflicting clauses are replaced by a unified clause plus compensation clauses [4].", "startOffset": 136, "endOffset": 139}, {"referenceID": 1, "context": "Recently there has also been considerable interest in decomposing MAXSAT to SAT, usually with an unsatisfiable-core approach [2,12,22,23].", "startOffset": 125, "endOffset": 137}, {"referenceID": 9, "context": "Recently there has also been considerable interest in decomposing MAXSAT to SAT, usually with an unsatisfiable-core approach [2,12,22,23].", "startOffset": 125, "endOffset": 137}, {"referenceID": 19, "context": "Recently there has also been considerable interest in decomposing MAXSAT to SAT, usually with an unsatisfiable-core approach [2,12,22,23].", "startOffset": 125, "endOffset": 137}, {"referenceID": 20, "context": "Recently there has also been considerable interest in decomposing MAXSAT to SAT, usually with an unsatisfiable-core approach [2,12,22,23].", "startOffset": 125, "endOffset": 137}, {"referenceID": 21, "context": "Because they use learning instead of lookahead (and other improvements such as activity-based search [24]), they have a considerable advantage over the previously-described approaches.", "startOffset": 101, "endOffset": 105}, {"referenceID": 18, "context": "In particular the Weighted Boolean Optimization (WBO) framework [21] is an application of PBO to soft-constraint problems, using some of the specialized techniques discussed above.", "startOffset": 64, "endOffset": 68}, {"referenceID": 7, "context": "Another option is decomposition to SAT via the PBO solver MiniSAT+ [9], which could be useful if unsatisfiability-based methods aren\u2019t applicable to a particular problem.", "startOffset": 67, "endOffset": 70}, {"referenceID": 8, "context": "Note that a CP system supporting constraint Si can be straightforwardly extended to support the softened form \u00acyi \u2192 Si through half-reification [10].", "startOffset": 144, "endOffset": 148}, {"referenceID": 19, "context": "This is standard for CP systems, although MAXSAT solvers typically use SAT decompositions of the objective using BDDs or sorting networks [22].", "startOffset": 138, "endOffset": 142}, {"referenceID": 19, "context": "In the best MAXSAT implementations [22,23] the relaxation variables for a clause were not created until the clause had appeared in an unsatisfiable subset, with the information about conflicting clauses being extracted from proof traces rather than from the presence of their relaxation literals in a learnt clause.", "startOffset": 35, "endOffset": 42}, {"referenceID": 20, "context": "In the best MAXSAT implementations [22,23] the relaxation variables for a clause were not created until the clause had appeared in an unsatisfiable subset, with the information about conflicting clauses being extracted from proof traces rather than from the presence of their relaxation literals in a learnt clause.", "startOffset": 35, "endOffset": 42}, {"referenceID": 16, "context": "This is the basis of disjoint inconsistent subformula approaches which have been used for MAXSAT [19].", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "Thus the standard procedure of deriving explanations from dual solutions or unbounded dual rays is applicable [1,6,8].", "startOffset": 110, "endOffset": 117}, {"referenceID": 4, "context": "Thus the standard procedure of deriving explanations from dual solutions or unbounded dual rays is applicable [1,6,8].", "startOffset": 110, "endOffset": 117}, {"referenceID": 6, "context": "Thus the standard procedure of deriving explanations from dual solutions or unbounded dual rays is applicable [1,6,8].", "startOffset": 110, "endOffset": 117}, {"referenceID": 21, "context": "We use activitybased search (VSIDS) for all experiments [24].", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "We tried the following combinatorial benchmarks: psm (pattern set mining, 16 instances) is given a set of training items each a vector of Booleans, find some vector which characterizes all items, or if k > 1 find the best k vectors [14]; photo (30 instances) is given a set of people and soft constraints on who they stand next to, place them in a line for a photo; rlfap (radio link frequency assignment, 16 instances) is assigning frequencies to channels with soft constraints that minimize interference [5]; roster (20 instances) is finding a cyclic roster for a single worker over a number of weeks with soft work pattern constraints; and sugiyama (5 instances) is a graph layout problem on layered graphs with soft no-edge-crossings constraints [27].", "startOffset": 232, "endOffset": 236}, {"referenceID": 3, "context": "We tried the following combinatorial benchmarks: psm (pattern set mining, 16 instances) is given a set of training items each a vector of Booleans, find some vector which characterizes all items, or if k > 1 find the best k vectors [14]; photo (30 instances) is given a set of people and soft constraints on who they stand next to, place them in a line for a photo; rlfap (radio link frequency assignment, 16 instances) is assigning frequencies to channels with soft constraints that minimize interference [5]; roster (20 instances) is finding a cyclic roster for a single worker over a number of weeks with soft work pattern constraints; and sugiyama (5 instances) is a graph layout problem on layered graphs with soft no-edge-crossings constraints [27].", "startOffset": 506, "endOffset": 509}, {"referenceID": 24, "context": "We tried the following combinatorial benchmarks: psm (pattern set mining, 16 instances) is given a set of training items each a vector of Booleans, find some vector which characterizes all items, or if k > 1 find the best k vectors [14]; photo (30 instances) is given a set of people and soft constraints on who they stand next to, place them in a line for a photo; rlfap (radio link frequency assignment, 16 instances) is assigning frequencies to channels with soft constraints that minimize interference [5]; roster (20 instances) is finding a cyclic roster for a single worker over a number of weeks with soft work pattern constraints; and sugiyama (5 instances) is a graph layout problem on layered graphs with soft no-edge-crossings constraints [27].", "startOffset": 750, "endOffset": 754}, {"referenceID": 5, "context": "We then tried some much more difficult industrial problems: ctt (curriculumbased timetabling, 32 instances) is finding a weekly repeating timetable for a university subject to various kinds of soft availability constraints and soft no-clashes constraints [7]; stein (Steiner network, 13 instances) is designing a connected network given a set nodes and arcs with a fixed (building) cost per arc [15]; fcnf (fixed-charge network flow, 60 instances) is designing a connected network with fixed (building) and also variable (operating) costs per arc [26]; and nsp (nurse scheduling problem, 32 instances) is designing a roster for a hospital ward based on the shift preferences of each individual nurse [29].", "startOffset": 255, "endOffset": 258}, {"referenceID": 12, "context": "We then tried some much more difficult industrial problems: ctt (curriculumbased timetabling, 32 instances) is finding a weekly repeating timetable for a university subject to various kinds of soft availability constraints and soft no-clashes constraints [7]; stein (Steiner network, 13 instances) is designing a connected network given a set nodes and arcs with a fixed (building) cost per arc [15]; fcnf (fixed-charge network flow, 60 instances) is designing a connected network with fixed (building) and also variable (operating) costs per arc [26]; and nsp (nurse scheduling problem, 32 instances) is designing a roster for a hospital ward based on the shift preferences of each individual nurse [29].", "startOffset": 395, "endOffset": 399}, {"referenceID": 23, "context": "We then tried some much more difficult industrial problems: ctt (curriculumbased timetabling, 32 instances) is finding a weekly repeating timetable for a university subject to various kinds of soft availability constraints and soft no-clashes constraints [7]; stein (Steiner network, 13 instances) is designing a connected network given a set nodes and arcs with a fixed (building) cost per arc [15]; fcnf (fixed-charge network flow, 60 instances) is designing a connected network with fixed (building) and also variable (operating) costs per arc [26]; and nsp (nurse scheduling problem, 32 instances) is designing a roster for a hospital ward based on the shift preferences of each individual nurse [29].", "startOffset": 547, "endOffset": 551}, {"referenceID": 26, "context": "We then tried some much more difficult industrial problems: ctt (curriculumbased timetabling, 32 instances) is finding a weekly repeating timetable for a university subject to various kinds of soft availability constraints and soft no-clashes constraints [7]; stein (Steiner network, 13 instances) is designing a connected network given a set nodes and arcs with a fixed (building) cost per arc [15]; fcnf (fixed-charge network flow, 60 instances) is designing a connected network with fixed (building) and also variable (operating) costs per arc [26]; and nsp (nurse scheduling problem, 32 instances) is designing a roster for a hospital ward based on the shift preferences of each individual nurse [29].", "startOffset": 700, "endOffset": 704}, {"referenceID": 12, "context": "On stein the \u2018cuts\u2019 added for LP-based bounding enforce the connectivity of the network and are similar to [15,26], but our approach is much more generic.", "startOffset": 107, "endOffset": 114}, {"referenceID": 23, "context": "On stein the \u2018cuts\u2019 added for LP-based bounding enforce the connectivity of the network and are similar to [15,26], but our approach is much more generic.", "startOffset": 107, "endOffset": 114}, {"referenceID": 7, "context": "This provides one of the first approaches to soft intensionally defined constraint problems beyond branch and bound that we are aware of, apart from PBO/WBO [9,21] which support intensionally-defined linear constraints only.", "startOffset": 157, "endOffset": 163}, {"referenceID": 18, "context": "This provides one of the first approaches to soft intensionally defined constraint problems beyond branch and bound that we are aware of, apart from PBO/WBO [9,21] which support intensionally-defined linear constraints only.", "startOffset": 157, "endOffset": 163}], "year": 2017, "abstractText": "Constraint Programming (CP) solvers typically tackle optimization problems by repeatedly finding solutions to a problem while placing tighter and tighter bounds on the solution cost. This approach is somewhat naive, especially for soft-constraint optimization problems in which the soft constraints are mostly satisfied. Unsatisfiable-core approaches to solving soft constraint problems in SAT (e.g. MAXSAT) force all soft constraints to be hard initially. When solving fails they return an unsatisfiable core, as a set of soft constraints that cannot hold simultaneously. These are reverted to soft and solving continues. Since lazy clause generation solvers can also return unsatisfiable cores we can adapt this approach to constraint programming. We adapt the original MAXSAT unsatisfiable core solving approach to be usable for constraint programming and define a number of extensions. Experimental results show that our methods are beneficial on a broad class of CP-optimization benchmarks involving soft constraints, cardinality or preferences.", "creator": "LaTeX with hyperref package"}}}