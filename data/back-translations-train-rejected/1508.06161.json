{"id": "1508.06161", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "Robot Language Learning, Generation, and Comprehension", "abstract": "We present a unified framework which supports grounding natural-language semantics in robotic driving. This framework supports acquisition (learning grounded meanings of nouns and prepositions from human annotation of robotic driving paths), generation (using such acquired meanings to generate sentential description of new robotic driving paths), and comprehension (using such acquired meanings to support automated driving to accomplish navigational goals specified in natural language). We evaluate the performance of these three tasks by having independent human judges rate the semantic fidelity of the sentences associated with paths, achieving overall average correctness of 94.6% and overall average completeness of 85.6%.", "histories": [["v1", "Tue, 25 Aug 2015 14:10:21 GMT  (1455kb,D)", "http://arxiv.org/abs/1508.06161v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.CL cs.HC cs.LG", "authors": ["daniel paul barrett", "scott alan bronikowski", "haonan yu", "jeffrey mark siskind"], "accepted": false, "id": "1508.06161"}, "pdf": {"name": "1508.06161.pdf", "metadata": {"source": "CRF", "title": "Robot Language Learning, Generation, and Comprehension", "authors": ["Daniel Paul Barrett", "Scott Alan Bronikowski", "Haonan Yu", "Jeffrey Mark Siskind"], "emails": ["dpbarret@purdue.edu", "sbroniko@purdue.edu", "yu239@purdue.edu", "qobi@purdue.edu"], "sections": [{"heading": "1 Introduction", "text": "With recent advances in machine perception and robotic automation, it is becoming increasingly relevant and important that machines can interact with humans in natural language in a grounded way, with language referring to actual things and activities in the world. Here, we present our efforts to drive - and drive - a mobile robot automatically under the command of naturalism. Our contribution is summarized in Fig. 1. A human telecommunicator receives a series of sentence instructions that define robot paths. The operator then drives a mobile robot according to these instructions through a variety of floor plans. The robot uses onboard odometry and inertial sensors to determine its location in real time and stores traces of the route in log files. From a training corpus of paths paired with phrase descriptions and floor plan specifications, our system automatically learns the meaning of nouns that refer to objects in the floor plan and prepositions that describe both the relationships between these objects and the robots."}, {"heading": "2 Related Work", "text": "In fact, most of them are able to play by the rules that they play by the rules, and they are able to play by the rules that they play by the rules."}, {"heading": "3 Our Mobile Robot", "text": "All the experiments were carried out on a custom mobile robot (Fig. 2), which can be driven by a human telegraph or can drive itself to achieve predefined navigation objectives. Throughout the operation, the robot localization on board the robot is performed in real time via an advanced Kalman filter (Jazwinski, 1970) with odometry of wave encoders on the wheels and inertial guidance by an IMU. Due to sensor noise and mechanical factors such as wheel slides, this localization is noisy, but usually within 20cm of the actual location. The feed, localization and all sensor and file data are logged in a time-stamped format. In experiments to generate and capture, a human tele-operator drives the robot along a variety of paths in a variety of layouts. The path recovered from the localization supports generation and acquisition."}, {"heading": "4 Technical Details", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Grammar and Logical Form", "text": "The question we need to ask is whether we can replace this grammar with another mechanism to generate a logical form (and the prepositional phrases associated with it): as modifiers to nouns in phrases, indicated by a subscript (i.e., spatial relationship), and as adjuncts to verbal phrases, indicated by a subscript. \"Many prepositions can be used in both SR and path form\" (i.e., spatial relationship), and as adjuncts to verbal phrases, indicated by a subscript. \"(Many prepositions can be used in both SR and path form.)"}, {"heading": "4.2 Representation of the Lexicon", "text": "The dictionary defines the meaning of the one and two parameters, while the target object is the object in logical form. The meaning of the one-argument predicate are discrete distributions over the set of class labels. Note that the one-argument predicates, such as BAG, are distinguishable from the class labels, such as Bag. Matching between them is learned. Furthermore, a certain floor plan could have multiple instances of objects of the same class, which would be nested and connected with complex noun phrases such as the chair, which is to the right of the stool, and the chair, which is to the left of the cone. Such disamination of prepositional phrase modifiers of noun phrases can be nested and connected at will. Likewise, waypoints can be determined by conjunctions of the prepositional phrase adjuncts.Two arguments dictate relations between target objects and reference objects. In SR, the reference object predicate the chair is the object, the object is the object during the object is the object."}, {"heading": "4.3 Tasks", "text": "We formulate sentence semantics as a multitude of relationships between a sentence s, or more precisely a formula in logical form, a path p, a sequence of blank waypoints, a floor plan f, a series of labeled waypoints, and an encyclopaedia, the collective micro and area parameters for the angle distributions for each of the two argument predicates, and the separate distributions for each of the Earth's orbital predications. if we learn a lexicon from a collection of observed paths pi taken by the robot in the corresponding floor plans fi, as described by man-made propositions si.generation If we generate a sentence s describing an observed path p taken by the robot in a1Without loss of generality, angles are measured in the robot's frame of reference before the beginning of the action, which is taken as a starting point."}, {"heading": "4.3.1 Acquisition", "text": "To perform the acquisition, we formulate a large hidden Markov model (HMM), with a state k for each prepositional phrase PPpath, k in each sentence in the training corpus. The observations for this HMM are the sequences of waypoints in the training corpus. The output model of each state adds up over all mappings m between object references in the PPpath, k and floorplan waypoints. In the face of such mapping, the output model for a state k consists of the product of probabilities P derived from each atomic formula i in the logical form, k, given the probability models for the predicates determined by the current estimates of the parameters."}, {"heading": "4.3.2 Generation", "text": "This path consists of a collection of 2D floor positions sampled at 50Hz. However, in order to generate a formula in logical form and thus the corresponding sentence, one must select a sub-sequence of this dense sequence that is worthy of description. During the generation, we take care of three properties: \"correctness,\" that the sentence logically applies to the path, \"completeness,\" that the sentence distinguishes the intended path from all other possible paths, and \"conciseness,\" that the sentence is the shortest that does so. We try to find an equilibrium between these properties using the following heuristic algorithms (Fig. 7) First, we try path waypoints in a way that distributes the sampled points evenly along the path. To this end, we extract the path by calculating the integral distance we travel from the starting position for each point in the path and selecting a subsequence whose points we are distributed evenly."}, {"heading": "4.3.3 Comprehension", "text": "To generate understanding, we use the gradient ascent to optimize the scoring function in relation to an unknown path pp \u0445 = arg max p R (s, p, f, \u0441), where R (s, p, f) is the product of all Rk from Equation 2. We calculate an MAP estimate of the common probability to satisfy the conjunction of atomic formulas, assuming that they are independent of each other. The above scoring function alone is insufficient. It represents the strict meaning of the theorem, but does not take into account the constraints of the world, such as the need to avoid collision with the objects in the floor plan. It can also be difficult to optimize, because the costs associated with the relative orientation between two waypoints are increasingly sensitive to small position changes the closer they come together. In order to resolve the problems of waypoints coming too close to the objects and to each other, an obstacle-penalty term between each waypoint and waypoint will be added to a waypoint, as a formula that adds a point to a waypoint, as well as a point between two equal to a point."}, {"heading": "5 Experiments", "text": "We conducted an experiment as shown in Figure 1. We created 250 random grammar sentences in Figure 3, 25 in each of 10 different floor plans randomly generated to place either 4 or 5 objects, with two objects always in the same class, to create ambiguities in the figure. Models were learned for each of the nouns and prepositions, which were automatically included in descriptions of 10 different new ways to fulfill these judgments. (Figure 8 above) The models were learned for each of the nouns and prepositions."}, {"heading": "6 Conclusion", "text": "We show a novel approach to grounding the semantics of natural language in the field of robotic navigation. Sentences describe paths the robot takes in relation to other objects in the vicinity; the meanings of nouns and prepositions are trained from a corpus of paths that are provided with sentence descriptions by a human telecommunications company, which can then support both the automatic generation of sentence descriptions of new trails and the automatic driving of paths to fulfill the predetermined navigation objectives; this is a step toward the ultimate goal of grounded natural language that allows machines to interact with humans when language relates to real things and activities in the real world."}, {"heading": "Acknowledgments", "text": "The views and conclusions contained in this document are those of the authors and should not be interpreted as representing, expressly or implicitly, the official guidelines of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute copies for government purposes, notwithstanding the copyright notices contained herein."}], "references": [{"title": "Handbook of mathematical functions", "author": ["M. Abramowitz", "I.A. Stegun"], "venue": null, "citeRegEx": "Abramowitz and Stegun,? \\Q1972\\E", "shortCiteRegEx": "Abramowitz and Stegun", "year": 1972}, {"title": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process", "author": ["L.E. Baum"], "venue": null, "citeRegEx": "Baum,? \\Q1972\\E", "shortCiteRegEx": "Baum", "year": 1972}, {"title": "Statistical inference for probabilistic functions of finite state Markov chains", "author": ["L.E. Baum", "T. Petrie"], "venue": null, "citeRegEx": "Baum and Petrie,? \\Q1966\\E", "shortCiteRegEx": "Baum and Petrie", "year": 1966}, {"title": "A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains", "author": ["L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss"], "venue": null, "citeRegEx": "Baum et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Baum et al\\.", "year": 1970}, {"title": "Reading between the lines: Learning to map high-level instructions to commands", "author": ["S.R.K. Branavan", "L.S. Zettlemoyer", "R. Barzilay"], "venue": "In ACL,", "citeRegEx": "Branavan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Branavan et al\\.", "year": 2010}, {"title": "Type-logical semantics", "author": ["B. Carpenter"], "venue": null, "citeRegEx": "Carpenter,? \\Q1997\\E", "shortCiteRegEx": "Carpenter", "year": 1997}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D.L. Chen", "R.J. Mooney"], "venue": "In AAAI,", "citeRegEx": "Chen and Mooney,? \\Q2011\\E", "shortCiteRegEx": "Chen and Mooney", "year": 2011}, {"title": "Driving semantic parsing from the world\u2019s response", "author": ["J. Clarke", "D. Goldwasser", "Chang", "M.-W", "D. Roth"], "venue": "In Conference on Computational Natural Language Learning,", "citeRegEx": "Clarke et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Clarke et al\\.", "year": 2010}, {"title": "Computational interpretations of the gricean maxims in the generation of referring expressions", "author": ["R. Dale", "E. Reiter"], "venue": "Cognitive Science,", "citeRegEx": "Dale and Reiter,? \\Q1995\\E", "shortCiteRegEx": "Dale and Reiter", "year": 1995}, {"title": "Teaching a robot spatial expressions", "author": ["S. Dobnik", "S. Pulman", "P. Newman", "A. Harrison"], "venue": "Proceedings of the Second ACLSIGSEM Workshop on The Linguistic Dimensions of Prepositions and their Use in Computa-", "citeRegEx": "Dobnik et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Dobnik et al\\.", "year": 2005}, {"title": "Heterogeneous multi-robot dialogues for search tasks", "author": ["T.K. Harris", "S. Banerjee", "A.I. Rudnicky"], "venue": "In Proceedings of the AAAI Spring Symposium Intelligence", "citeRegEx": "Harris et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Harris et al\\.", "year": 2005}, {"title": "Semantic processing using the hidden vector state model", "author": ["Y. He", "S. Young"], "venue": "Computer Speech & Language,", "citeRegEx": "He and Young,? \\Q2005\\E", "shortCiteRegEx": "He and Young", "year": 2005}, {"title": "Generative models for statistical parsing with combinatory categorial grammar", "author": ["J. Hockenmaier", "M. Steedman"], "venue": "In ACL,", "citeRegEx": "Hockenmaier and Steedman,? \\Q2002\\E", "shortCiteRegEx": "Hockenmaier and Steedman", "year": 2002}, {"title": "Stochastic Processes and Filtering Theory", "author": ["A.H. Jazwinski"], "venue": null, "citeRegEx": "Jazwinski,? \\Q1970\\E", "shortCiteRegEx": "Jazwinski", "year": 1970}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Journal of Fluids Engineering,", "citeRegEx": "Kalman,? \\Q1960\\E", "shortCiteRegEx": "Kalman", "year": 1960}, {"title": "Toward understanding natural language directions", "author": ["T. Kollar", "S. Tellex", "D. Roy", "N. Roy"], "venue": "In International Conference on HumanRobot Interaction,", "citeRegEx": "Kollar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kollar et al\\.", "year": 2010}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Walk the talk: connecting language, knowledge, and action in route instructions", "author": ["M. MacMahon", "B. Stankiewicz", "B. Kuipers"], "venue": "In AAAI,", "citeRegEx": "MacMahon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "MacMahon et al\\.", "year": 2006}, {"title": "Seeing what you\u2019re told: Sentenceguided activity recognition in video", "author": ["N. Siddharth", "A. Barbu", "J.M. Siskind"], "venue": "In CVPR,", "citeRegEx": "Siddharth et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Siddharth et al\\.", "year": 2014}, {"title": "Surface structure and interpretation", "author": ["M. Steedman"], "venue": null, "citeRegEx": "Steedman,? \\Q1996\\E", "shortCiteRegEx": "Steedman", "year": 1996}, {"title": "The syntactic process", "author": ["M. Steedman"], "venue": null, "citeRegEx": "Steedman,? \\Q2000\\E", "shortCiteRegEx": "Steedman", "year": 2000}, {"title": "A voicecommandable robotic forklift working alongside humans in minimally-prepared outdoor", "author": ["S. Teller", "M.R. Walter", "M. Antone", "A. Correa", "R. Davis", "L. Fletcher", "E. Frazzoli", "J. Glass", "J.P. How", "Huang", "A. S"], "venue": null, "citeRegEx": "Teller et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Teller et al\\.", "year": 2010}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["S. Tellex", "T. Kollar", "S. Dickerson", "M.R. Walter", "A.G. Banerjee", "S.J. Teller", "N. Roy"], "venue": "In AAAI,", "citeRegEx": "Tellex et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tellex et al\\.", "year": 2011}, {"title": "Learning perceptually grounded word meanings from unaligned parallel data", "author": ["S. Tellex", "P. Thaker", "J. Joseph", "N. Roy"], "venue": "Machine Learning,", "citeRegEx": "Tellex et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tellex et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 15, "context": "these systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010).", "startOffset": 156, "endOffset": 271}, {"referenceID": 6, "context": "these systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010).", "startOffset": 156, "endOffset": 271}, {"referenceID": 17, "context": "these systems operate only within discrete simulation, as they utilize the internal representation of the simulation to obtain discrete symbolic primitives (Tellex et al., 2014, 2011; Kollar et al., 2010; Chen and Mooney, 2011; MacMahon et al., 2006; Koller et al., 2010).", "startOffset": 156, "endOffset": 271}, {"referenceID": 6, "context": "Their space of possible robot actions, positions and states are very small and are represented in terms of symbolic primitives like TURN LEFT, TURN RIGHT, and MOVE FORWARD N STEPS (Chen and Mooney, 2011), or DRIVE TO LOCATION 1 and PICK UP PALLET 1 (Tellex et al.", "startOffset": 180, "endOffset": 203}, {"referenceID": 23, "context": "Their space of possible robot actions, positions and states are very small and are represented in terms of symbolic primitives like TURN LEFT, TURN RIGHT, and MOVE FORWARD N STEPS (Chen and Mooney, 2011), or DRIVE TO LOCATION 1 and PICK UP PALLET 1 (Tellex et al., 2014).", "startOffset": 249, "endOffset": 270}, {"referenceID": 15, "context": "Kollar et al. (2010) requires hand-drawn positive and negative paths depicting specific word meanings.", "startOffset": 0, "endOffset": 21}, {"referenceID": 15, "context": "Kollar et al. (2010) requires hand-drawn positive and negative paths depicting specific word meanings. Tellex et al. (2011) requires manual annotation of the groundings of all words in the training sentences to specific objects and relationships in the training data.", "startOffset": 0, "endOffset": 124}, {"referenceID": 15, "context": "Kollar et al. (2010) requires hand-drawn positive and negative paths depicting specific word meanings. Tellex et al. (2011) requires manual annotation of the groundings of all words in the training sentences to specific objects and relationships in the training data. Tellex et al. (2014) does not require annotation of the grounding of each word, but does require manual temporal segmentation and alignment of paths and the pieces of multi-part sentences, whereas our method can learn without any such annotation.", "startOffset": 0, "endOffset": 289}, {"referenceID": 13, "context": "During all operation, robot localization is performed onboard the robot in real-time via an Extended Kalman Filter (Jazwinski, 1970) with odometry from shaft encoders on the wheels and inertialguidance from an IMU.", "startOffset": 115, "endOffset": 132}, {"referenceID": 20, "context": "3, which, while small, supports an infinite set of possible utterances, unlike the grammars used in Teller et al. (2010) and Harris et al.", "startOffset": 100, "endOffset": 121}, {"referenceID": 10, "context": "(2010) and Harris et al. (2005). Nothing turns on this however.", "startOffset": 11, "endOffset": 32}, {"referenceID": 0, "context": "The lexical entry for each two-argument predicate is specified as the location \u03bc and concentration \u03ba parameters for multiple independent von Mises distributions (Abramowitz and Stegun, 1972) for a variety of angles between target and reference objects.", "startOffset": 161, "endOffset": 190}, {"referenceID": 2, "context": "We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972).", "startOffset": 39, "endOffset": 93}, {"referenceID": 3, "context": "We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972).", "startOffset": 39, "endOffset": 93}, {"referenceID": 1, "context": "We then train this HMM with Baum-Welch (Baum and Petrie, 1966; Baum et al., 1970; Baum, 1972).", "startOffset": 39, "endOffset": 93}, {"referenceID": 8, "context": "However, finding the smallest collection of modifiers is NP-hard (Dale and Reiter, 1995).", "startOffset": 65, "endOffset": 88}], "year": 2015, "abstractText": "We present a unified framework which supports grounding natural-language semantics in robotic driving. This framework supports acquisition (learning grounded meanings of nouns and prepositions from human annotation of robotic driving paths), generation (using such acquired meanings to generate sentential description of new robotic driving paths), and comprehension (using such acquired meanings to support automated driving to accomplish navigational goals specified in natural language). We evaluate the performance of these three tasks by having independent human judges rate the semantic fidelity of the sentences associated with paths, achieving overall average correctness of 94.6% and overall average completeness of 85.6%.", "creator": "LaTeX with hyperref package"}}}