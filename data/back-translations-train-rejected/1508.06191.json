{"id": "1508.06191", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "A Neuro-Fuzzy Method to Improving Backfiring Conversion Ratios", "abstract": "Software project estimation is crucial aspect in delivering software on time and on budget. Software size is an important metric in determining the effort, cost, and productivity. Today, source lines of code and function point are the most used sizing metrics. Backfiring is a well-known technique for converting between function points and source lines of code. However when backfiring is used, there is a high margin of error. This study introduces a method to improve the accuracy of backfiring. Intelligent systems have been used in software prediction models to improve performance over traditional techniques. For this reason, a hybrid Neuro-Fuzzy is used because it takes advantages of the neural networks learning and fuzzy logic human-like reasoning. This paper describes an improved backfiring technique which uses Neuro-Fuzzy and compares the new method against the default conversion ratios currently used by software practitioners.", "histories": [["v1", "Tue, 25 Aug 2015 15:40:44 GMT  (180kb)", "http://arxiv.org/abs/1508.06191v1", "International Conference on Soft Computing, Intelligent System and Information Technology, Bali, Indonesia, pp. 12-17, 2007"]], "COMMENTS": "International Conference on Soft Computing, Intelligent System and Information Technology, Bali, Indonesia, pp. 12-17, 2007", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["justin wong", "danny ho", "luiz fernando capretz"], "accepted": false, "id": "1508.06191"}, "pdf": {"name": "1508.06191.pdf", "metadata": {"source": "CRF", "title": "A Neuro-Fuzzy Method to Improving Backfiring Conversion Ratios", "authors": ["Justin Wong", "Danny Ho", "Luiz Fernando Capretz"], "emails": ["jwong343@uwo.ca,", "danny@nfa-estimation.com,", "lcapretz@eng.uwo.ca"], "sections": [{"heading": null, "text": "It is a critical aspect in delivering software on time and on budget. Software size is an important metric in determining effort, cost and productivity. Today, source lines of code and function point are the most commonly used yardsticks. Backfiring is a well-known technique for converting between function points and source lines of code. But when backfiring is used, there is a high margin of error. This study leads to a method of improving the accuracy of backfiring models in order to improve performance over traditional techniques. Therefore, hybrid neuro-fuzzy technology is used because it has neural network benefits in terms of learning and fuzzy logic of human reasoning."}, {"heading": "1.1. SLOC", "text": "SLOC is one of the most popular quantity metrics used in the industry today. SLOC measures lines of code in software. SLOC is often used because it is relatively easy to measure and count. Typically, SLOC is used to determine the development effort required for software. Although SLOC is popular and simple, there are some shortcomings in the use of SLOC as a quantity metric. SLOC is not a reliable metric during the software development process, as the SLOC often changes from added and removed source code. In addition, the level of programming knowledge influences the SLOC produced. An experienced programmer, for example, can write less SLOC than a junior programmer. Finally, SLOC is a risky metric when used alone because it is difficult to count an application during development. SLOC counts more effectively when development is complete [6]."}, {"heading": "1.2. Function Point", "text": "First introduced by Albrecht in the 1970s [7], the functional point is a unit of measurement for determining the functional size of an information system. Functional point analysis (FPA) can be used to calculate the size of an application, project development or extension project. Application calculation means the size of an existing application against which the functionality available to end users is measured. In a development project, the measure of the size of the new application to be developed is considered based on the required requirements. Calculation of an extension project measures a maintenance project of an existing application based on all changes, added and remote functions and the data conversion process [8]. Functional points are used to avoid the deficiencies of SLOC. Functional points in analogies, however, still have their disadvantages. For example, functionality in old systems is forgotten, so the overall size of the system is underestimated. Furthermore, incomplete or informal requirements would lead to inconsistent functional points."}, {"heading": "1.3. Backfiring", "text": "The technique of backfiring is a bidirectional mathematical conversion between the function point and the SLOC. The equation for the conversion of the function point to the SLOC is defined in (1). In Equation (1), FP is the input of the function point and the conversion is the SLOC / FP. Equation (1) can be changed to find the number of function points if the SLOC is known. ConversionFP = SLOC (1) For the backshooting procedure, the conversion ratio or SLOC / FP can be found in a programming table. A programming table contains data of the programming language, the language level and the SLOC / FP. A sample programming table is in Table 1. The language level defined by Software Productivity Research (SPR) indicates how powerful the source code language is [9]. For example, Basic Assembler has a language level of 1.0 because it shows an average of 320 SLOC / FP in the language."}, {"heading": "1.4. Fuzzy Logic", "text": "The fuzzy logic used to create a mapping between input and output spaces is derived from the fuzzy set theory, which uses linguistic terms or a fuzzy logic that represents and processes uncertainty. It is composed of member functions that are used to describe linguistic terms such as low, medium, and high with values from 0 to 1."}, {"heading": "1.5. Neural Network", "text": "Neural networks were used to improve traditional software estimation techniques. Aggarwal et al. [10] presented a model that uses neural networks to improve SLOC estimations when the functional point is given as input. Their estimation model used Bayesian regularization to train the neural network. In order to achieve the best results, they examined various training algorithms. In addition, the network took into account the maximum team size, the functional point standard and the language (language of the 3rd and 4th generation). The shortcoming of the neural network was that it had a black box design. Furthermore, the research only took into account the language of the generation instead of the programming languages. Average values SLOC / FP between the 3rd and 4th generation languages are very large in the range of the 3rd / 4th generation."}, {"heading": "1.6. Neuro-Fuzzy Integration", "text": "Neuro-fuzzy is a term used to refer to a hybrid intelligent system that uses both neural network and fuzzy logic. Neuro-fuzzy is used because it takes up the benefits of learning the neural network and fuzzy logic's human-like reasoning [4].Huang et al. [4] introduced a neuro-fuzzy framework and applied it to COCOCOMO. Neurofuzzy technology showed that it could be used to improve software estimation techniques by calibrating their parameters. In this study, it was shown that a neural network could be used to calibrate fuzzy sets to improve performance for many different applications. Based on the flexibility of the technique, the neuro-fuzzy-fuzzy framework was applied to the technique of backfiring by calibrating its parameters. Xia [5] proposed a neuro-fuzzy function punctuation model to improve performance for many software calibration efforts."}, {"heading": "2.2. Input and Output Membership Functions", "text": "Figure 2 and Figure 3 illustrate the input and output fuzzy member functions. A triangular function was used for both the input and output member functions. At the climax of the input triangle of each fuzzy level was the programming language level. The average SLOC / FP was the peak of the output member functions. Peak values were determined from Table 2."}, {"heading": "2.3. Fuzzy Rules and Inference", "text": "Each fuzzy level was directly referenced to a fuzzy output, for example f1 to o1, f2 to o2, and so on. The \"AND\" and \"Activation\" functions used the minimum function for the rules. For defucidation, the maximum accumulation method and the \"Center of Gravity\" method were used."}, {"heading": "2.4. Neural Network", "text": "The neural network was used to calibrate the average source information per function point for each fuzzy level. Furthermore, the input to the neural network was made by the UFP and the fuzzy language level. Indeed, the SLOC was only used during the training. These fuzzy language levels are fed into the network shown in Figure 4, which shows the design of the network. The neural network was designed so that it can be easily interpreted to be an obscure \"black box model.\" In addition, the network design of Xia [5] was shown to avoid improvements in functional value estimates. L1 to Ln were binary fuzzy language level inputs."}, {"heading": "3.1. Evaluation Criteria", "text": "Magnitude of Relative Error (MRE) is a popular criterion commonly used in industry. In the evaluation, MRE is used to measure the error performance of the calibrated model with the original conversion ratios. Although it is popular, Foss et al. [12] showed that MRE is not recommended in the evaluation and comparison of prediction models because MRE does not prove that one model is particularly better than another because the results were misleading [13]. MRE favored underestimation and performed worse in small projects. The equation for calculating MER is defined in (3). Actual prediction = MRE (3) Another method proposed for evaluating and comparing prediction models was Magnitude of Error Relative to the Estimate (MER) [13]. The equation for calculating MER is defined in (4)."}, {"heading": "3.2. Experiments", "text": "In Experiments 1 and 2, half of the data set was trained and the rest used for simulation and evaluation, the data points were randomly selected for each programming language level. Experiments 3 and 4 were based on the size of the projects. In Experiment 3, the projects for the large number of function points were used for training and the small function points were used for simulation. Experiment 4 used small projects for training and large projects for evaluation. Experiments 5, 6 and 7 were based on a larger training set to see if performance improves. Experiments 5 and 6 used 75% of the data set for training. In the experiments, the data points for each programming level were randomly selected. In Experiment 7, 100% of the data set was used for training and evaluation."}, {"heading": "4. Results", "text": "The results in Table 3 showed from the experiments that the NFFPB model showed a satisfactory improvement over the existing conversion ratios in MMRE and MMER. There was no conclusive evidence that Neuro-Fuzzy PRED improved because the results were positive, negative and zero. However, the improvements were small in Experiments 1 and 2 due to the size of the available dataset. Certain programming languages showed a low number of training points, resulting in a small calibration. However, despite the setback, Experiments 5, 6 and 7 showed that there was a greater average improvement in MMRE and MMER compared to the 50% random test results. In Experiments 4 and 7, the MMRE improvement was large. MMRE scores better when evaluating large projects because MMRE favors underestimation. In Experiment 7, there was a large improvement because the same data points were used for training and evaluation."}, {"heading": "5. Conclusion", "text": "The conclusions drawn from the NFFPB model were that it solved the problems of backward conversion and reduced the error in size estimates; the problems with backward conversion were that the conversion rates were wide bandwidth and generic; seven experiments were conducted to compare the calibrated ratios of the NFFPB with the conversion rates of the SPR. Overall, the NFFPB model exceeded the SPR conversion rates in the MMRE and MMER criteria; however, Neuro-Fuzzy did not show an improvement in PRED; the size of the project data available for evaluation weakened the conclusions that were drawn because if more data were available, a greater improvement would occur; the small training data prevented the neural network from minimizing errors; and the improvements were small due to the distortions in the MMRE and MER criteria; in this study, the model attempted to meet both criteria, resulting in only local minimum error points."}, {"heading": "6. Acknowledgment", "text": "Justin Wong thanks his advisors and referees for their helpful comments. He also thanks SPR and ISBSG for providing research data."}, {"heading": "7. References", "text": "[1] Boehm, B., and C. Abts, and S. Chulani. (2000) \"Software Development Cost Estimation Approaches - A Survey.\" Annals of Software Engineering. v 10. pp. 177-205. [2] Stutzke, R. D. (2005). Estimating SoftwareIntensive Systems - Projects, Products, and Processes. Addison-Wesley. [3] Jones C. (November 1995). \"Backfiring: ConvertingLines of Code to Function Points.\" Computer. v 28 (11). (pp. 87-88. [4] Huang X., and D. Ho, and J. Ren, and L.F. Capretz. (January 2006). \"A Soft Computing Framework for Software Effort Estimation.\" (Soft Computing.), v."}], "references": [{"title": "Software Development Cost Estimation Approaches \u2013 A Survey", "author": ["B. Boehm", "C. Abts", "S. Chulani"], "venue": "Annals of Software Engineering", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Estimating Software- Intensive Systems \u2013 Projects, Products, and Processes", "author": ["R.D. Stutzke"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Backfiring: Converting Lines of Code to Function Points", "author": ["Jones C. (Nov"], "venue": "Computer. v", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "A Soft Computing Framework for Software Effort Estimation", "author": ["Huang X", "D. Ho", "J. Ren", "L.F. Capretz. (Jan"], "venue": "Soft Computing. v", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Calibrating Software Size of Function Points Using Neuro-Fuzzy Technique, University of Western Ontario", "author": ["W. Xia"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Software Sizing, Estimation, and Risk Management", "author": ["Galorath D", "M. Evans"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation", "author": ["A.J. Albrecht", "J.E. Jr. Gaffney. (Nov"], "venue": "IEEE Transactions on Software Engineering. v", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1983}, {"title": "Bayesian Regularization in a Neural Network Model to Estimate Lines of Code Using Function Points", "author": ["Aggarwal K. K", "Y. Singh", "P. Chandra", "M. Puri"], "venue": "Journal of Computer Sciences", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "A Simulation Study of the Model Evaluation Criterion MMRE", "author": ["Foss T", "E. Stensrud", "B. Kitchenham", "I. Myrtveit. (Nov"], "venue": "Software Engineering, IEEE Transactions on Software Engineering. v", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "What Accuracy Statistics Really Measure", "author": ["Kitchenham B.A", "S.G. MacDonell", "L.M. Pickad", "M.J. Shepperd"], "venue": "(Jun", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "It can also result in allocating too many resources and underused staff [1].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "Many software estimation techniques such as Constructive Cost Model (COCOMO) and Function Point Analysis have been developed to tackle these problems [2].", "startOffset": 150, "endOffset": 153}, {"referenceID": 2, "context": "Jones [3] introduced the concept of backfiring, which converts function points to logical SLOC statements to effectively sized source code.", "startOffset": 6, "endOffset": 9}, {"referenceID": 2, "context": "While backfiring is useful and simple, there is a high margin of error in converting SLOC data into function points [3].", "startOffset": 116, "endOffset": 119}, {"referenceID": 3, "context": "Neural networks and fuzzy logic have been applied to software estimation methods to improve the accuracy of existing software sizing methods [4, 5].", "startOffset": 141, "endOffset": 147}, {"referenceID": 4, "context": "Neural networks and fuzzy logic have been applied to software estimation methods to improve the accuracy of existing software sizing methods [4, 5].", "startOffset": 141, "endOffset": 147}, {"referenceID": 5, "context": "SLOC counts are more effective when development is completed [6].", "startOffset": 61, "endOffset": 64}, {"referenceID": 6, "context": "Function Point First introduced in the 1970s by Albrecht [7], the function point is a unit of measurement for determining the functional size of an information system.", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "Using function point in analogies can result in wrong estimates because a 1000 function point system does not mean it is two times larger than a 500 function point system [6].", "startOffset": 171, "endOffset": 174}, {"referenceID": 7, "context": "[10] presented a model using neural networks to improve SLOC estimates when the function point is given as an input.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Neuro-Fuzzy is used because it takes advantages of the neural network\u2019s learning and fuzzy logic\u2019s human-like reasoning [4].", "startOffset": 120, "endOffset": 123}, {"referenceID": 3, "context": "[4] introduced a neuro-fuzzy framework and applied it to COCOMO.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Xia [5] proposed a neuro-fuzzy function point model for improving the accuracy of software effort estimates.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "Furthermore, the network design has been shown by Xia [5] to have improvements in function point estimations.", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "For example, for language level 4, it would be represented as [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] based on the proposed fuzzy levels.", "startOffset": 62, "endOffset": 101}, {"referenceID": 8, "context": "[12] showed that when evaluating and comparing prediction models, MRE is not recommended because MRE does not prove that one model is particularly better than another because the results were misleading [13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12] showed that when evaluating and comparing prediction models, MRE is not recommended because MRE does not prove that one model is particularly better than another because the results were misleading [13].", "startOffset": 203, "endOffset": 207}, {"referenceID": 9, "context": "Another method that was proposed for evaluating and comparing prediction models was Magnitude of error Relative to the Estimate (MER) [13].", "startOffset": 134, "endOffset": 138}], "year": 2015, "abstractText": "Software project estimation is crucial aspect in delivering software on time and on budget. Software size is an important metric in determining the effort, cost, and productivity. Today, source lines of code and function point are the most used sizing metrics. Backfiring is a wellknown technique for converting between function points and source lines of code. However when backfiring is used, there is a high margin of error. This study introduces a method to improve the accuracy of backfiring. Intelligent systems have been used in software prediction models to improve performance over traditional techniques. For this reason, a hybrid Neuro-Fuzzy is used because it takes advantages of the neural network\u2019s learning and fuzzy logic\u2019s human-like reasoning. This paper describes an improved backfiring technique which uses Neuro-Fuzzy and compares the new method against the default conversion ratios currently used by software practitioners.", "creator": "PScript5.dll Version 5.2.2"}}}