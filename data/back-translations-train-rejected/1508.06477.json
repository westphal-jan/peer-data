{"id": "1508.06477", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Aug-2015", "title": "Greedy methods, randomization approaches and multi-arm bandit algorithms for efficient sparsity-constrained optimization", "abstract": "Several sparsity-constrained algorithms such as Orthogonal Matching Pursuit or the Frank-Wolfe algorithm with sparsity constraints work by iteratively selecting a novel atom to add to the current non-zero set of variables. This selection step is usually performed by computing the gradient and then by looking for the gradient component with maximal absolute entry. This step can be computationally expensive especially for large-scale and high-dimensional data. In this work, we aim at accelerating these sparsity-constrained optimization algorithms by exploiting the key observation that, for these algorithms to work, one only needs the coordinate of the gradient's top entry. Hence, we introduce algorithms based on greedy methods and randomization approaches that aim at cheaply estimating the gradient and its top entry. Another of our contribution is to cast the problem of finding the best gradient entry as a best arm identification in a multi-armed bandit problem. Owing to this novel insight, we are able to provide a bandit-based algorithm that directly estimates the top entry in a very efficient way. Theoretical results stating that the resulting inexact Frank-Wolfe or Orthogonal Matching Pursuit algorithms act, with high probability, similarly to their exact versions are also given. We have carried out several experiments showing that the greedy deterministic and the bandit approaches we propose can achieve an acceleration of an order of magnitude while being as efficient as the exact gradient when used in algorithms such as", "histories": [["v1", "Wed, 26 Aug 2015 13:01:36 GMT  (139kb)", "https://arxiv.org/abs/1508.06477v1", null], ["v2", "Mon, 22 Aug 2016 07:50:48 GMT  (227kb,D)", "http://arxiv.org/abs/1508.06477v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["a rakotomamonjy", "s ko\\c{c}o", "liva ralaivola"], "accepted": false, "id": "1508.06477"}, "pdf": {"name": "1508.06477.pdf", "metadata": {"source": "CRF", "title": "Greedy methods, randomization approaches and multi-arm bandit algorithms for efficient sparsity-constrained optimization", "authors": ["A. Rakotomamonjy", "S. Ko\u00e7o", "L. Ralaivola"], "emails": ["alain.rakoto@insa-rouen.fr", "sokol.koco@gmail.com", "liva.ralaivola@lif.univ-"], "sections": [{"heading": null, "text": "In fact, it is such that most of us are able to go to another world, in which they go to another world, in which they go to another world, in which they go to another world, in which they go to another world, in which they find themselves in another world, in which they live in another world, in which they live in another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they live in another world, in which they live in another world, in which they live in another world, in which they live in another world, in which they live in which they live in another world, in which they live in which they live in another world, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they do, in which they do, in which they do, in which they do, in which they do, in fact, in fact, in fact, in which they do not exist, in fact, in which they do not exist."}, {"heading": "II. SPARSE LEARNING ALGORITHM WITH EXTREME GRADIENT COMPONENT", "text": "In this section, we present the sparse learning problem that interests us, as well as some algorithms that are often used for sparse learning, and then point out the outstanding common feature of these algorithms, namely the property of the extreme gradient component, and discuss how their estimation can be used to accelerate some classes of sparse learning algorithms."}, {"heading": "A. Framework", "text": "Consider the problem where we want to estimate a relationship between a set of n samples collected in a vector y-Rn and the matrix X-Rn-d. In a sparse signal approximation problem, X would be a matrix whose columns represent the elements of a dictionary and y the target signal, while in a machine learning problem, the i-th line of matrix X, formalized as x-i, xi-Rd, is the characteristics of the i-th example and yi is the label or target associated with this example. Subsequently, we call xi, j the input of X in the i-th line and j-th column. Algorithm 1 Gradient Tracking Algorithm 1: set k = 0, initialize w0 = 0 2: for k = 0.1, \u00b7 do 3: i? = do the vector 3: i? = w function (arg maxi function w)."}, {"heading": "B. Algorithms", "text": "1) Gradient systems: This algorithm is a generalization of yawn algorithms, which only lead to very different types of losses. (1) Gradient: This algorithm is a generalization of yaw algorithms, which has led to only one part of yaw algorithms. (2) The yaw algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms systems algorithms algorithms systems algorithms algorithms systems algorithms systems systems systems systems algorithms systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems systems"}, {"heading": "C. Leveraging from the extreme gradient component estimation", "text": "As explained above, the gradient tracking algorithm must solve the following problem j? = arg maxj (wk) | j for each iteration, i.e., the goal is to find the component of the gradient with the highest absolute value for each iteration.For example, if the specified constraint is the \"1-standard ball C1 = {w-standard ball C1 = {w-standard ball C1 \u2264 1} or the positive simplex constraint C2 = {w-standard ball C2 = 1, wj-standard ball C1 = {w-standard ball C1 = {w-standard ball C1 \u2264 1} or the positive simplex constraint C2} is the\" 1-standard ball C1 = {w-standard ball C1 (wk) and j? = arg max j-standard ball C2 = 1?"}, {"heading": "III. LOOKING FOR THE EXTREME GRADIENT COMPONENT", "text": "This section formalizes the problem of identifying the component of the extreme slope and provides various algorithms to solve it. We first introduce a greedy, then a random approach, and finally show how this problem can be used as the best weapon identification in a multi-armed bandit system."}, {"heading": "A. The problem", "text": "As mentioned in Section II, we are interested in learning problems where the objective function is of the form \"i\" (yi, g (w > xi), so the gradient of our objective function is given by \"L\" (w) = \"i\" (yi, g (w > xi)))) \"g\" (w > xi) xi = X > r (6), where r \"Rn\" is the vector of which i is a component \"(yi, g (w > xi))) g\" (w > xi). This particular form means that the gradient can be calculated iteratively. In fact, the sum \"L\" (w) = \"i\" xiri is invariant in the order in which the index i describes the set..., \"n.\" This makes possible 4 algorithms 3 \"Greedy\" vministerial algorithms to be calculated. \""}, {"heading": "B. Greedy deterministic approach", "text": "The first approach we propose is a greedy approach, which in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the itteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration t, in the iteration in the iteration t, in the iteration in the iteration in the iteration in the iteration, in the iteration in the iteration in the iteration, in the iteration in the iteration, in the iteration in the iteration in the iteration, in the iteration in the iteration in the iteration, in the iteration in the iteration, in the iteration in the iteration in the iteration, in the iteration in the iteration in the iteration in the itteration, in the itteration in the itteration in the itteration, in the itteration in the itteration in the"}, {"heading": "C. Matrix-Vector Product as Expectations", "text": "The problem of finding the extreme component of the gradient can also be considered from the point of view of randomization, as in Algorithm 4.The approach is to consider the calculation of X > r as an expectation of a given random variable. (11) From now on, X consists of the vectors {x > i} ni = 1 and xi \u00b2 Rd. Therefore, the matrix vector product X > r can be rewritten: X > r = n \u00b2 i = 1 rixi. (11) From now on, an integer n denotes the interior of the probability simplicity of the magnitude n: x = [p1 \u00b7 pn]."}, {"heading": "D. Best arm identification and multi-armed bandits", "text": "The two previous approaches seek a comprehensive review of these methods in different areas."}, {"heading": "E. Stopping criteria", "text": "There is no indication of how many elements we need to accumulate to achieve a sufficient approximation of the gradient or the multi-armed bandit algorithms that can only be used to search for the smallest component of deterministic sampling, although the approach to other cases is similar. Denote j? = arg minj _ L (wk) and Ts the maximum number of iterations or samplings to calculate the inexact gradient of j? = arg minj _ L (wk).L (wk)"}, {"heading": "IV. DISCUSSION", "text": "In this section, the approaches we propose are commented on and discussed in comparison to existing work."}, {"heading": "A. Relation and gains compared to OMP and variants", "text": "This work includes OMP [7], [26], Greedy Tracking [16], [27], CoSaMP [19] and some others such as [28]. Most of these algorithms use the uppermost absolute entry of the gradient vector in each iteration, and the work presented in this paper is closely related to these, since we share the same search for the uppermost entry. In fact, the proposed method provides tools that can be applied to many sparse approximation algorithms, including the aforementioned one. What makes our work new and compelling is that each iteration calculates the gradient with as little information as possible. If the stop criterion for estimating this gradient is based on a maximum number of samples - for example, we are interested in constructing the best approximation of the gradient from only 20% of the samples - our approach can be interpreted as a method for calculating the gradient on a limited budget."}, {"heading": "B. Relation with other stochastic MP/FW approaches", "text": "Chen et al. [29] have recently introduced a stochastic version of a matching-pursuit algorithm in a Bayesian context. Their main contribution was to define a prior distribution across each component of the vector w and then to sample this distribution to estimate w. In their approach, the sparseness pattern associated with matching pursuit is controlled by the previous distribution, which is believed to be a mixture of two distributions, one of which leads to a sparseness. Although this approach is indeed stochastical, it differs greatly from ours in the way stochasticity is at play. As we will discuss in the next subsection, our framework is more related to stochastic gradient than stochastic sampling by Chen et al. Stronger similarities to our work appear in the work of Peel et al. [30] In fact, they propose to speed up the atom selection process by selecting an idea at random for this problem."}, {"heading": "C. About stochasticity", "text": "The randomized approach to gradient approximation introduced in Section III-C involves a random sampling of the columns, so in the extreme situation where only a single column i is sampled, we have an approximation to a stochastic gradient method. [13] In the context of the sparse greedy approximation, the first work on stochastic gradient approximation was recently published. Nguyen et al. [13] show that their stochastic version of the iterative hard threshold algorithm or gradient matching algorithm, which aims to solve a sparse approximation with archaic loss functions, behaves correctly in expectation, and the randomized approach goes beyond the stochaotic threshold."}, {"heading": "D. Theoretical considerations", "text": "Although a complete theoretical analysis of the algorithm exists with a probability of at least 1 \u2212 Pt, an interesting property deserves to be mentioned here =. Note: Unlike stochastic gradient approaches, our algorithm is built on inexact gradients, which hopefully have the same minimal component as the true gradient. If this latter fact occurs along the iterations of the FW or OMP algorithms, then below an exact probability of our algorithms to recover at a given iteration K of the OMP or FW, we show the sequence of these minimal components as that one with exact gradient. Suppose that at each iteration t of the OMP or FW, our algorithms for estimating the minimum component is correct."}, {"heading": "V. NUMERICAL EXPERIMENTS", "text": "In this section, we describe the experimental studies we have conducted to demonstrate the computational benefits of using an inaccurate gradient to optimize sparsity constraint problems."}, {"heading": "A. Experimental setting", "text": "To illustrate the usefulness of using an imprecise gradient for sparse learning or sparse approximation, we have established a simple, sparse approximation problem that focuses on computational gain, and for which a sparse signal needs to be restored by the Frank Wolfe, OMP, or CoSaMP algorithm. We believe that if the signal or image at hand can be approximated by representations for which rapid transformations are available, then it is better (and faster) to actually use that representation and rapid transformation. Sparse approximation problems, as viewed in the sequel, mostly occur in over-complete dictionary learning problems. In such a situation, since the dictionary is data-driven, we believe that the approach we propose is relevant."}, {"heading": "B. Sparse learning using a Frank-Wolfe algorithm", "text": "In fact, it is as if most people are able to trump themselves, and that they are able to trump themselves. (...) In fact, it is as if they are able to trump themselves. (...) In fact, it is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves. (...) It is as if they are able to trump themselves."}, {"heading": "C. Sparse Approximation with OMP", "text": "The toy problem is similar to the one used above, except that we analyze the performance of the algorithm for an increasing number of k active atoms and two sizes of the dictionary matrix X. The same methods for calculating the inaccurate gradient are evaluated and compared in terms of efficiency and correctness with the true gradient in an OMP algorithm. In all sample approaches, the stop criterion for the accumulation of gradients is based on the stability criterion with the parameter Ns, which is set adaptively to 2% of the number n of samples. For the successive approach of the bandits, the sampling budget was limited to 20% of the number of entries (which is n \u00b7 d in the matrix X). In all cases, the stop criterion for the OMP algorithm is limited to a fixed number of iterations, and this number is the desired time. Results are shown in Figure X."}, {"heading": "D. Sparse Approximation with CoSaMP", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "E. Application to audio data", "text": "We have compared the efficiency of the approaches we propose to a real signal processing application, and the audio data set we use is the one that Yaghoobi et al. [34] This data set consists of an audio sample recorded by a BBC radio session playing classical music. 8192 pieces of signal were extracted from this audio sample, each of which consists of 1024 time samples. Details of the data set can be found in [34]. From this data set, we have learned 2048 dictionary atoms that use the approach described in [35]. Our goal is to perform an economical approximation of each of the 8192 audio samples over the 2048 dictionary atoms using CoSaMP, and we want to perform the runtime and approximation quality of a CoSaMP algorithm with an exact gradient computation (Exact), a stochastic gradient CoMP algorithm based on the SaMP algorithm."}, {"heading": "F. Benchmark classification problems", "text": "These data sets are commonly used to evaluate sparing learning problems [36], [4] and more details about them can be found in these papers. Here, we consider CoSaMP as a learning algorithm and our goal is to confirm the fact that the approaches we propose for calculating an approximate gradient are capable of speeding up computing time while achieving the same level of accuracy as the exact gradient. For approximate gradient calculations, we have considered the stability criterion with NS = ntrain20 (ntrain is the number of training examples) for deterministic and randomized approaches, and we have set the budget as 0.2 ntrain \u00d7 d for bandit approaches. The protocol we have established is the following. Training and the test sets are achieved by randomly splitting the data set into an 80% -20% multiple."}, {"heading": "VI. CONCLUSIONS", "text": "The methods proposed in this paper aim to accelerate thrift-limited optimization algorithms, rather than the full gradient. This is made possible by the key observation that each iteration requires only the component of the gradient with the smallest or largest entry. By taking advantage of this insight, we propose greedy algorithms, randomized approaches, and bandit-based methods for identifying the best weapons to efficiently evaluate that top entry. Our experimental results show that the bandit and greedy approaches seem to be the most efficient methods for this estimate. Interestingly, the bandit approaches provide guarantees that this top entry can be retrieved with sufficient number of drawings with high probability."}], "references": [{"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society, vol. 58, no. 1, pp. 267\u2013288, 1996.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1996}, {"title": "Least angle regression (with discussion)", "author": ["B. Efron", "T. Hastie", "I. Johnstone", "R. Tibshirani"], "venue": "Annals of statistics, vol. 32, no. 2, pp. 407\u2013499, 2004.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Revisiting frank-wolfe : Projection free sparse convex optimization", "author": ["M. Jaggi"], "venue": "Proceedings og the International Conference on Machine Learning, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonconvex regularizations for feature selection in ranking with sparse svm", "author": ["L. Laporte", "R. Flamary", "S. Canu", "S. Dejean", "J. Mothe"], "venue": "Neural Networks and Learning Systems, IEEE Transactions on, vol. 25, no. 6, pp. 1118\u20131130, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Matching pursuit with time-frequency dictionaries", "author": ["S. Mallat", "Z. Zhang"], "venue": "IEEE Trans Signal Processing, vol. 41, no. 12, pp. 3397\u2013 3415, 1993.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1993}, {"title": "Orthogonal matching pursuit : Recursive function approximation with applications to wavelet decomposition", "author": ["Y.C. Pati", "R. Rezaiifar", "P. Krishnaprasad"], "venue": "Proc. of the 27th Annual Asilomar Conference on Signals, Systems and Computers, 1993.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1993}, {"title": "Embedding prior knowledge within compressed sensing by neural networks", "author": ["D. Merhej", "C. Diab", "M. Khalil", "R. Prost"], "venue": "Neural Networks, IEEE Transactions on, vol. 22, no. 10, pp. 1638\u20131649, Oct 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Solving large scale linear prediction problems using stochastic gradient descent algorithms", "author": ["Tong Zhang"], "venue": "Proceedings of the twentyfirst international conference on Machine learning. ACM, 2004, pp. 116\u2013123.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Pegasos : Primal estimated subgradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "Proceedings of the International Conference on Machine Learning, 2007, pp. 807\u2013814.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Stochastic methods for l 1-regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": "The Journal of Machine Learning Research, vol. 12, pp. 1865\u20131892, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1865}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "Advances in Neural Information Processing Systems, 2013, pp. 315\u2013323.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Linear convergence of stochastic iterative greedy algorithms with sparse constraints", "author": ["N Nguyen", "Deanna Needell", "T. Woolf"], "venue": "http://arxiv.org/abs/1407.0088, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Pure exploration in multi-armed bandits problems", "author": ["S\u00e9bastien Bubeck", "R\u00e9mi Munos", "Gilles Stoltz"], "venue": "Algorithmic Learning Theory. Springer, 2009, pp. 23\u201337.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "More efficient sparsity-inducing algorithms using inexact gradient", "author": ["Alain Rakotomamonjy", "Sokol Ko\u00e7o", "Liva Ralaivola"], "venue": "Signal Processing Conference (EUSIPCO), 2015 23rd European. IEEE, 2015, pp. 709\u2013713.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Gradient pursuits", "author": ["Thomas Blumensath", "Michael E Davies"], "venue": "Signal Processing, IEEE Transactions on, vol. 56, no. 6, pp. 2370\u20132382, 2008.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Orthogonal matching pursuit for sparse quantile regression", "author": ["Aleksandr Aravkin", "Aurelie Lozano", "Ronny Luss", "Prabhajan Kambadur"], "venue": " Data Mining (ICDM), 2014 IEEE International Conference on. IEEE, 2014, pp. 11\u201319.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Group orthogonal matching pursuit for logistic regression", "author": ["Aur\u00e9lie C Lozano", "Grzegorz Swirszcz", "Naoki Abe"], "venue": "International Conference on Artificial Intelligence and Statistics, 2011, pp. 452\u2013460.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Cosamp: Iterative signal recovery from incomplete and inaccurate samples", "author": ["D. Needell", "J. Tropp"], "venue": "Applied and Computational Harmonic Analysis, vol. 26, no. 3, pp. 301\u2013321, 2009.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Greedy sparsity-constrained optimization", "author": ["Sohail Bahmani", "Bhiksha Raj", "Petros T Boufounos"], "venue": "The Journal of Machine Learning Research, vol. 14, no. 1, pp. 807\u2013841, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Some comments on wolfe\u2019s away step", "author": ["J. Gu\u00e9lat", "P. Marcotte"], "venue": "Mathematical Programming, vol. 35, no. 1, 1986.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1986}, {"title": "Fast monte carlo algorithms for matrices i: Approximating matrix multiplication", "author": ["P. Drineas", "R. Kannan", "M. Mahoney"], "venue": "SIAM Journal on Computing, vol. 36, no. 1, pp. 132\u2013157, 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Best arm identification in multi-armed bandits", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck"], "venue": "COLT-23th Conference on Learning Theory- 2010, 2010, pp. 13\u201320.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Almost optimal exploration in multi-armed bandits", "author": ["Zohar Karnin", "Tomer Koren", "Oren Somekh"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML-13), 2013, pp. 1238\u20131246.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Non-stochastic best arm identification and hyperparameter optimization", "author": ["K. Jamieson", "A. Talwalkar"], "venue": "Proceedings of the 19th International Workshop on Artificial Intelligence and Statistic, 2016.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "Signal recovery from random measurements via orthogonal matching pursuit", "author": ["J. Tropp", "A. Gilbert"], "venue": "IEEE Trans. Information Theory, vol. 53, no. 12, pp. 4655\u20134666, 2007.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Algorithms for simultaneous sparse approximation. part I: Greedy pursuit", "author": ["J. Tropp", "A. Gilbert", "M. Strauss"], "venue": "Signal Processing, vol. 86, pp. 572\u2013588, 2006.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Trading accuracy for sparsity in optimization problems with sparsity constraints", "author": ["S. Shalev-Shwartz", "N. Srebro", "T. Zhang"], "venue": "Siam Journal on Optimization, vol. 20, 2010.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Stochastic matching pursuit for bayesian variable selection", "author": ["R.-B. Chen", "C.-H. Chu", "T.-Y. Lai", "Y. Wu"], "venue": "Statistics and Computing, vol. 21, no. 2, pp. 247\u2013259, 2011.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Matching pursuit with stochastic selection", "author": ["Thomas Peel", "Valentin Emiya", "Liva Ralaivola", "Sandrine Anthoine"], "venue": "Signal Processing Conference (EUSIPCO), 2012 Proceedings of the 20th European. IEEE, 2012, pp. 879\u2013883.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Block-  16 coordinate frank-wolfe optimization for structural svms", "author": ["S. Lacoste-Julien", "M. Jaggi", "M. Schmidt", "P. Pletscher"], "venue": "Proceedings of the International Conference on Machine Learning, 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Fast stochastic frank-wolfe algorithms for nonlinear svms", "author": ["Hua Ouyang", "Alexander G Gray"], "venue": "SDM. SIAM, 2010, pp. 245\u2013256.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Stochastic optimization with importance sampling", "author": ["P Zhao", "T Zhang"], "venue": "http://arxiv.org/abs/1401.2753, 2014.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Dictionary learning for sparse approximations with the majorization method", "author": ["M. Yaghoobi", "T. Blumensath", "M. Davies"], "venue": "IEEE Transaction on Signal Processing, vol. 57, no. 6, pp. 2178\u20132191, 2009.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2009}, {"title": "Direct optimization of the dictionary learning problem", "author": ["A. Rakotomamonjy"], "venue": "IEEE Trans. on Signal Processing, vol. 61, no. 12, pp. 5495\u2013 5506, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "A general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems", "author": ["P. Gong", "C. Zhang", "Z. Lu", "J. Huang", "J. Ye"], "venue": "Proceedings of the 30th International Conference on Machine Learning, Atlanta, Georgia, Jun. 2013, pp. 37\u201345.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The resulting problem is the wellknown Lasso problem [1] and a large variety of algorithms for its resolution exist, ranging from homotopy methods [2] to the Frank-Wolfe (FW) algorithm [3].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "The resulting problem is the wellknown Lasso problem [1] and a large variety of algorithms for its resolution exist, ranging from homotopy methods [2] to the Frank-Wolfe (FW) algorithm [3].", "startOffset": 147, "endOffset": 150}, {"referenceID": 2, "context": "The resulting problem is the wellknown Lasso problem [1] and a large variety of algorithms for its resolution exist, ranging from homotopy methods [2] to the Frank-Wolfe (FW) algorithm [3].", "startOffset": 185, "endOffset": 188}, {"referenceID": 3, "context": "In the same flavour, non-convex continuous penalties are also common solutions for relaxing the `0 pseudo-norm [4], [5].", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "In this last context, a flurry of algorithms have been proposed, the most popular ones being the Matching Pursuit (MP) and the Orthogonal Matching Pursuit (OMP) algorithms [6], [7], [8].", "startOffset": 172, "endOffset": 175}, {"referenceID": 5, "context": "In this last context, a flurry of algorithms have been proposed, the most popular ones being the Matching Pursuit (MP) and the Orthogonal Matching Pursuit (OMP) algorithms [6], [7], [8].", "startOffset": 177, "endOffset": 180}, {"referenceID": 6, "context": "In this last context, a flurry of algorithms have been proposed, the most popular ones being the Matching Pursuit (MP) and the Orthogonal Matching Pursuit (OMP) algorithms [6], [7], [8].", "startOffset": 182, "endOffset": 185}, {"referenceID": 7, "context": "Stochastic gradient descent (SGD) algorithms are now classical methods for avoiding the computation of the full gradient in large-scale learning problems [9], [10].", "startOffset": 154, "endOffset": 157}, {"referenceID": 8, "context": "Stochastic gradient descent (SGD) algorithms are now classical methods for avoiding the computation of the full gradient in large-scale learning problems [9], [10].", "startOffset": 159, "endOffset": 163}, {"referenceID": 9, "context": "Most of these works have been devoted to smooth composite optimization although some efforts addressing `1-regularized problems exist [11].", "startOffset": 134, "endOffset": 138}, {"referenceID": 10, "context": "Recently, these SGD algorithms have been further accelerated through the introduction of variance reduction methods for gradient estimation [12].", "startOffset": 140, "endOffset": 144}, {"referenceID": 11, "context": "[13] have proposed stochastic versions of a gradient pursuit algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Next, by casting the problem as a best arm identification multiarmed bandit problem [14], we are able to derive an algorithm that directly estimates the best component of the gradient.", "startOffset": 84, "endOffset": 88}, {"referenceID": 13, "context": "This paper is an extended version of the conference paper [15].", "startOffset": 58, "endOffset": 62}, {"referenceID": 14, "context": "1) Gradient Pursuit: This algorithm is a generalization of the greedy algorithm known as Orthogonal Matching Pursuit (OMP) to generic loss functions [16].", "startOffset": 149, "endOffset": 153}, {"referenceID": 5, "context": "While conceptually simple, this algorithm comes with theoretical guarantees on its ability to recover the exact underlying sparsity pattern of the model, for different types of loss functions [7], [17], [18].", "startOffset": 192, "endOffset": 195}, {"referenceID": 15, "context": "While conceptually simple, this algorithm comes with theoretical guarantees on its ability to recover the exact underlying sparsity pattern of the model, for different types of loss functions [7], [17], [18].", "startOffset": 197, "endOffset": 201}, {"referenceID": 16, "context": "While conceptually simple, this algorithm comes with theoretical guarantees on its ability to recover the exact underlying sparsity pattern of the model, for different types of loss functions [7], [17], [18].", "startOffset": 203, "endOffset": 207}, {"referenceID": 14, "context": "Several variations of this algorithm have been proposed ranging from methods exploring new pursuits directions instead of the gradient [16], to methods making only slight changes to the original one that have strongly impacted the ability of the algorithm to recover signals.", "startOffset": 135, "endOffset": 139}, {"referenceID": 17, "context": "For instance, the CoSaMP [19] and GraSP [20] algorithms select the top 2K entries in the absolute gradient, K being the desired sparsity pattern, optimize over these entries and the already selected K ones, and prune the resulting estimate to be K-sparse.", "startOffset": 25, "endOffset": 29}, {"referenceID": 18, "context": "For instance, the CoSaMP [19] and GraSP [20] algorithms select the top 2K entries in the absolute gradient, K being the desired sparsity pattern, optimize over these entries and the already selected K ones, and prune the resulting estimate to be K-sparse.", "startOffset": 40, "endOffset": 44}, {"referenceID": 19, "context": "Despite its simplistic nature, the FW algorithm has been shown to be linearly convergent [21], [3].", "startOffset": 89, "endOffset": 93}, {"referenceID": 2, "context": "Despite its simplistic nature, the FW algorithm has been shown to be linearly convergent [21], [3].", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "sk = arg mins\u2208C s \u2207\u0302L(wk), then in order to ensure convergence, it is sufficient to have sk so that [3]", "startOffset": 100, "endOffset": 103}, {"referenceID": 20, "context": "Indeed, a result given by [22] (Lemma 4) says that the element p \u2208 \u2206n that minimizes E[\u2016X>r\u2212 \u0108\u2016F ] is such that", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "[14] propose an extensive review of these methods for various settings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Some of the most interesting algorithms are the successive reject [23] and successive halving [24] algorithms which, given a fixed budget of pulls, iteratively discard after some predefined number of pulls (say s) the worst arm or the worst-half arms, respectively, according to the values {V\u0302j,s}j=1.", "startOffset": 66, "endOffset": 70}, {"referenceID": 22, "context": "Some of the most interesting algorithms are the successive reject [23] and successive halving [24] algorithms which, given a fixed budget of pulls, iteratively discard after some predefined number of pulls (say s) the worst arm or the worst-half arms, respectively, according to the values {V\u0302j,s}j=1.", "startOffset": 94, "endOffset": 98}, {"referenceID": 23, "context": "Non-stochastic best arm identification has been barely studied and only a very recent work has addressed this problem [25].", "startOffset": 118, "endOffset": 122}, {"referenceID": 23, "context": "In this non-stochastic setting [25], the framework is that the k-th pull of an arm j provides a loss vj,k and the objective of the bandit algorithm is to identify arg minj limk\u2192\u221e vj,k, assuming that such limits exist for all j.", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "In practice, we choose \u03c4 to be the same for all the arms for computational reasons as explained above, but in theory this is not necessary [25].", "startOffset": 139, "endOffset": 143}, {"referenceID": 23, "context": "[25] for solving the non-stochastic best arm identification problem is also the one used in the stochastic setting namely the successive halving algorithm (Alg.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Indeed, each round-robin pull of the surviving arms can have dependent values, and as long as the algorithm does not adapt to the observed losses during the middle of a round-robin pull [25].", "startOffset": 186, "endOffset": 190}, {"referenceID": 22, "context": "1 in [24]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 2, "context": "Formally, this means that the iterations over gradient approximation can be stopped as soon as \u2016\u2207\u0302Lt \u2212\u2207L\u2016\u221e \u2264 , where depends on the curvature of the function L(w) [3].", "startOffset": 163, "endOffset": 166}, {"referenceID": 23, "context": "A possible strategy for removing the dependency of the bandit algorithm to this pull budget, is to use the doubling trick [25], which consists in running the algorithm with a small value of T and then repeatedly doubling it until some stopping criterion is met.", "startOffset": 122, "endOffset": 126}, {"referenceID": 23, "context": "According to Theorem 1 in [25], there exists a lower bound of pulls for which the algorithm is guaranteed to return the best arm.", "startOffset": 26, "endOffset": 30}, {"referenceID": 5, "context": "These works include OMP [7], [26], greedy pursuit [16], [27], CoSaMP [19] and several others like [28].", "startOffset": 24, "endOffset": 27}, {"referenceID": 24, "context": "These works include OMP [7], [26], greedy pursuit [16], [27], CoSaMP [19] and several others like [28].", "startOffset": 29, "endOffset": 33}, {"referenceID": 14, "context": "These works include OMP [7], [26], greedy pursuit [16], [27], CoSaMP [19] and several others like [28].", "startOffset": 50, "endOffset": 54}, {"referenceID": 25, "context": "These works include OMP [7], [26], greedy pursuit [16], [27], CoSaMP [19] and several others like [28].", "startOffset": 56, "endOffset": 60}, {"referenceID": 17, "context": "These works include OMP [7], [26], greedy pursuit [16], [27], CoSaMP [19] and several others like [28].", "startOffset": 69, "endOffset": 73}, {"referenceID": 26, "context": "These works include OMP [7], [26], greedy pursuit [16], [27], CoSaMP [19] and several others like [28].", "startOffset": 98, "endOffset": 102}, {"referenceID": 27, "context": "[29] have recently introduced a stochastic version of a Matching Pursuit algorithm in a Bayesian context.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30].", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[31] and Ouyang", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "In the context of sparse greedy approximation, the first work devoted to stochastic gradient approximation has been recently released [13].", "startOffset": 134, "endOffset": 138}, {"referenceID": 11, "context": "[13] show that their stochastic version of the iterative hard thresholding algorithm, or the gradient matching pursuit algorithm which aim at greedily solving a sparse approximation problem with arbitrary loss functions, behave properly in expectation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "This component theoretically helps in reducing the error of the gradient estimation [33].", "startOffset": 84, "endOffset": 88}, {"referenceID": 20, "context": "[22] have also shown there exists an importance sampling that minimizes the expectation of the Frobenius norm of the matrix multiplication approximation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Pt = 3 log2 d\u00b7exp ( \u2212 T 8H2(t)log2d ) , where H2(t) is a iterationdependent constant [24] and T the number of pulls.", "startOffset": 85, "endOffset": 89}, {"referenceID": 0, "context": "For \u03b4 \u2208 [0, 1], if the number T of pulls is set so that at each iteration t,", "startOffset": 8, "endOffset": 14}, {"referenceID": 11, "context": "One of these algorithms has been introduced in [13].", "startOffset": 47, "endOffset": 51}, {"referenceID": 11, "context": "When few active atoms are in play, we can note that sometimes, the stochastic approach of [13] fails to recover the support of w.", "startOffset": 90, "endOffset": 94}, {"referenceID": 32, "context": "[34].", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "Details about the dataset can be found in [34].", "startOffset": 42, "endOffset": 46}, {"referenceID": 33, "context": "From this dataset, we have learned 2048 dictionary atoms using the approach described in [35].", "startOffset": 89, "endOffset": 93}, {"referenceID": 34, "context": "These datasets are frequently used for evaluating sparse learning problems [36], [4] and more details about them can be found in these papers.", "startOffset": 75, "endOffset": 79}], "year": 2016, "abstractText": "Several sparsity-constrained algorithms such as Orthogonal Matching Pursuit or the Frank-Wolfe algorithm with sparsity constraints work by iteratively selecting a novel atom to add to the current non-zero set of variables. This selection step is usually performed by computing the gradient and then by looking for the gradient component with maximal absolute entry. This step can be computationally expensive especially for large-scale and high-dimensional data. In this work, we aim at accelerating these sparsity-constrained optimization algorithms by exploiting the key observation that, for these algorithms to work, one only needs the coordinate of the gradient\u2019s top entry. Hence, we introduce algorithms based on greedy methods and randomization approaches that aim at cheaply estimating the gradient and its top entry. Another of our contribution is to cast the problem of finding the best gradient entry as a best arm identification in a multi-armed bandit problem. Owing to this novel insight, we are able to provide a bandit-based algorithm that directly estimates the top entry in a very efficient way. Theoretical observations stating that the resulting inexact FrankWolfe or Orthogonal Matching Pursuit algorithms act, with high probability, similarly to their exact versions are also given. We have carried out several experiments showing that the greedy deterministic and the bandit approaches we propose can achieve an acceleration of an order of magnitude while being as efficient as the exact gradient when used in algorithms such as OMP, Frank-Wolfe or CoSaMP.", "creator": "LaTeX with hyperref package"}}}