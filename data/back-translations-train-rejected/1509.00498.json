{"id": "1509.00498", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Sep-2015", "title": "Sensor-Type Classification in Buildings", "abstract": "Many sensors/meters are deployed in commercial buildings to monitor and optimize their performance. However, because sensor metadata is inconsistent across buildings, software-based solutions are tightly coupled to the sensor metadata conventions (i.e. schemas and naming) for each building. Running the same software across buildings requires significant integration effort.", "histories": [["v1", "Tue, 1 Sep 2015 20:46:19 GMT  (1488kb)", "http://arxiv.org/abs/1509.00498v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["dezhi hong", "jorge ortiz", "arka bhattacharya", "kamin whitehouse"], "accepted": false, "id": "1509.00498"}, "pdf": {"name": "1509.00498.pdf", "metadata": {"source": "CRF", "title": "Sensor-Type Classification in Buildings", "authors": ["Dezhi Hong", "Jorge Ortiz", "Arka Bhattacharya", "Kamin Whitehouse"], "emails": ["whitehouse}@virginia.edu,", "jjortiz@us.ibm.com,", "arka@eecs.berkeley.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 9.00 498v 1 [cs.L G] 1S ep2 01Metadata normalization is critical for scaling the deployment process and allows us to decouple building-specific conventions from the code written for building applications. It also allows us to deal with missing metadata. An important aspect of normalization is the differentiation of sensors according to the type of phenomena observed. In this paper, we propose a general, simple but effective classification scheme to differentiate sensors in buildings by type. We also perform ensemble learning based on data collected from over 2000 sensor streams in two buildings. Our approach is capable of achieving more than 92% accuracy for classification within buildings and more than 82% accuracy for all buildings. We also implement a method for identifying potential misclassified currents. This is important because it allows us to identify ways to obtain more input from experts - input that could help improve the accuracy of classification details that are not available."}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to move to another world, in which they are able to live, in which they want to live."}, {"heading": "2. METHODOLOGY", "text": "In this section, we will describe the design and construction of the feature vector we use to characterize the sensor type, explain what it basically captures and why it works so well to build sensor data, discuss the classification technique we use, and give a detailed description of the training and testing process. Finally, we will articulate a solution for identifying potentially misclassified flows when type-defining soil truth is not available."}, {"heading": "2.1 Feature Extraction", "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "2.2 Classification", "text": "As a rule, most of them are able to play by the rules that they have set themselves, and they are not able to play by the rules that they have set."}, {"heading": "2.3 Quantify Classification Uncertainty", "text": "The ability to measure the reliability of predictive results and identify potential misclassifications is critical to a learning process. It is trivial to identify misclassifications when the basic truth is available, but in many real-world cases the basic truth is not available. Quantifying the classification uncertainty can help identify potential misclassifications and provides the ability to ask the user for feedback that we can use to improve our results. To quantify the uncertainty of the classifications in our learning process, we use the subordinate probabilities learned in the Random Forest. With the subordinate probabilities learned for each class, we can calculate the average probability for each class on each leaf in each tree as follows: Pt (Y) = c) =."}, {"heading": "3. EVALUATION", "text": "To demonstrate the effectiveness of our methodology, we evaluate our classification technique in two different scenarios: a) within the building, i.e. the training and test data for the classification come from the same building, and b) between buildings, where the training and test instances come from two different buildings. Furthermore, we discuss how the number of training instances and the window size of the segment influence the performance of the classification, and finally, we analyze the results of our solution to identify potential misclassifications."}, {"heading": "3.1 Taxonomy", "text": "Most sensor points in the building can be divided into 6 general types that we use in our work. In this essay, we consider 6 types of sensors: CO2, humidity, room temperature, setpoint, air flow rate, other temperature. Room temperature includes only sensors that measure the air temperature of rooms (as \"room temperature\" in Table 1) and other temperatures (as \"other temperature\" in Table 1) includes all other temperature measurements involved in a ventilation system (Figure 3), such as supply air / return air / mixed air temperature and cooling or hot water / return temperature. For setpoints, we only assign a general type that contains all setpoints for each actuator configured in the building."}, {"heading": "3.2 Experimental Setup", "text": "We spent a week collecting data from two different buildings on two campuses: One is 3Included's Rice Hall with permission from the authors of [3].University of Virginia, where sensory impressions are transmitted to a database [25] for 10 seconds to 10 minutes; the other is Sutardja Dai Hall (SDH) at UC Berkeley, where the sensors used [12, 1] transmit periodically between 5 seconds and 10 minutes to an archivist [5].The number for each sensor type in each building is summarized in Table 1, and the type truth for each sensor is manually expanded based on the metadata in the databases.All of our learning and classification processes are implemented based on the scikit-learn [23] library, which is an open source machine learning package that is largely implemented in Python and provides a rich set of APIs."}, {"heading": "3.3 Baseline and Metrics", "text": "As a starting point for comparing our proposed approach, we use a simple trait extraction scheme for each track F = {med, var}, where med and var are only the median and variance calculated over the entire distance. For classification, we measure the averaged cross-validation accuracy in two different scenarios (intra and inter-building). In the case within a building, the data from a single building is divided into training and test sets, in which the results show how accurately we can derive the type information from local information within a building. In the case between buildings, the experiment conducts training and testing between buildings, i.e. we train the classifier on the data from building A and test it on building B. This set of experiments tests how well we apply the classification boundaries from one building and apply them to another. In order to identify potential misclassifications, we choose the true positive rate (TPR, also known as memory), false positive threshold rate (FPR) (even if it is applied to a flassified)."}, {"heading": "3.4 Classification Accuracy", "text": "We perform the two sets of experiments described above, i.e. the intra and inter-building tests, to examine the effectiveness of the feature design and measure how well the classifier performs. Classification results are in Table 2-5. In the table, each row is specific to a type and each column is the percentage of the complete record used for training. Each cell shows two values. The value without brackets is the average classification accuracy for the richer feature vector. The value in brackets is the average classification accuracy for the approach described in Section 3.3. These are compared throughout the table. The last column summarizes the leave-one-out validation results for each approach. 3.4.1 Intra Building Performance From the last column in Tables 2 and 3, we see that the type classification in a single building achieves identical accuracy."}, {"heading": "3.5 Learning Bootstrapping", "text": "In Tables 2-5, the last columns show how accurately we can perform the classification on average. There is also the question of how many instances we need to start the learning process in both intra and inter-building cases. To investigate the impact of the number of instances on classification accuracy, we use different percentages of the original data as a training set, i.e., 5%, 10%, 20%, 33%, 50%, and the results are presented in the first five columns in each table. For each percentage of the training cases used, we apply layered sampling5 to the original sampling5 and the remaining instances are used as a test set. We repeat the same percentage 1 / percent times to reduce random errors and get4In LOO cross-validation, each training takes all instances."}, {"heading": "3.6 Window Size Sensitivity", "text": "All previous classification results have been achieved using features extracted from the original sensor tracks in 45-minute window sections. We are investigating how different window sizes affect classification performance. Figure 4 shows these results. The intra case performs a LOO cross-validation, while Inter-case performs a 10-fold cross-validation. In the intra-building case, the classification is not sensitive to different window sizes as shown in the figure: basically, the accuracy remains virtually the same for both buildings, because as long as we can capture the short-term properties of sensor dynamics in the window-glazed time windows, the size of the time window does not make too much difference. In the inter-building case, however, the size of the time window plays a role in the way that normally the local microclimate in one building can be quite different from that in another, we need to \"adjust\" this common short-term window in order to capture the dynamics that can be used to learn type-related information across buildings."}, {"heading": "3.7 Identifying Potential Misclassifications", "text": "As we discussed in the first section, the ability to quantify confidence in classifications and identify misclassified cases in our sensor type classification is critical to improving overall accuracy, bearing in mind that in many cases our technology is used where the truth is missing. However, as an intermediate step in identifying potentially misclassified cases, we suggest quantifying the \"uncertainty\" of the classification using an entropic approach described in Section 3.3. Figure 5 shows the CDF of the class probability entropy of classification in intra and inter-building scenarios. We see that the collection of correct classifications (in fixed lines) has a unique distribution of correct classifications (in dashed lines). Based on such a distinction in distribution, we can select a certain entropy value as a threshold and filter out all classified cases whose class probability is greater than the threshold given by the summary of our Figure 6."}, {"heading": "4. DISCUSSION", "text": "There are some aspects of our work that we have neglected or have not been able to deepen. First, we discuss extending the type classes and how we could increase the coverage of sensor types in future work. We discuss how we could improve classification accuracy by looking for data sources outside the building data sets. We also discuss why the main component analysis is an aspect that we have not studied in detail, and how the main components can change from building to building. Finally, we explain how our misclassification identifier could be used to improve classification results."}, {"heading": "4.1 Extension of Taxonomy and Class Scope", "text": "Our taxonomy includes five specific and one general type of sensor. We could add more sensor types to the range of classes and make our technology more versatile. There are many types of sensors in modern buildings, and the sensor substance in smart buildings is spreading further, such as occupancy sensors, light sensors, etc. We also want to build a deeper taxonomy for certain types. For example, there are set values for very different actuators. Temperature set points drive the HVAC system, while the air quality set point drives thieves and air mixers, and the ability to distinguish between them can help make general control applications in buildings possible."}, {"heading": "4.2 Improvement on Classification Accuracy", "text": "The learning and classification processes in our work are based only on a number of general characteristics. However, we would like to explore how the use of external or domain-specific knowledge could help improve classification accuracy. For example, if we know that indoor humidity is increasing due to a rainfall forecast, we could look for traces where averages increase as external knowledge to identify traces of humidity."}, {"heading": "4.3 Feature Importance and Selection", "text": "In our study, we did not address the importance of characteristics (i.e. principle component analysis) because the feature vector contains only eight variables. Therefore, classification in a hyperspace of only eight dimensions is not mathematically expensive - even if some of the vector elements contain redundant information. More importantly, selecting the principle characteristics for each building results in a different set of characteristics (as shown in Table 6) per building, making it impossible to classify between buildings. However, evaluating the principle components and uncovering overlaps is important in order to obtain optimal classification performance for intra-building tasks and a one-time analysis."}, {"heading": "4.4 Reducing Misclassification Iteratively", "text": "In cases where ground truth labels are not available, an entropy-based approach can be used iteratively to improve classification outcomes. In each iteration, only a few examples (at the top of the entropy-based \"uncertainty\" ranking) are reviewed and corrected, and the corrected cases could be added to the training set. The training and classification process is repeated until some criteria are met. We expect the number of examples required for manual inspection to be dramatically reduced in each iteration and overall, compared to a one-time inspection of candidates filtered by a certain threshold."}, {"heading": "5. RELATED WORK", "text": "We describe the next, related work in different problem areas and describe the work that uses the random forest as a tool. [14] The aim of the work is to classify audios into categories such as language, music and silence, and the work in this area deals with the same problem as working with an HMM-based statistical model. [14] The aim of the work is to classify audios into categories such as language, background noise and silence."}, {"heading": "6. CONCLUSION", "text": "We describe a general, simple but effective feature extraction design to support sensor type classification with time series data. By experimenting with over 2000 streams from two buildings in two locations, our technique, which uses a method of ensemble learning, is able to achieve an accuracy of more than 92% or 82% for tests inside or between buildings. We also discuss how the window size can be selected for a portion of the original time series and how the number of training cases affects classification accuracy. Generally, about 100 cases are sufficient to start the learning process in the case of 6 types of sensors. Another important contribution to our work is a probability-based solution for identifying potentially misclassified cases. By using probabilities generated by random forests, in both cases we are able to identify learning cases between buildings, at least 30% of the failures. Our technique can serve as a tool for creating metadata for building sorting techniques that we can examine in ways that differ from information that is available."}, {"heading": "7. REFERENCES", "text": "[1] American Society of Heating, Refrigerating andAir-Conditioning Engineers. ASHRAE Standard 135-1995: BACnet. ASHRAE, Inc., 1995. [2] Y. Amit and D. Geman. Shape quantization and recognition with randomized trees. Neural Comput., 9 (7): 1545-1588, October 1997. [3] B. Balaji, J. Xu, A. Nwokafor, R. Gupta, and Y. Agarwal pages: Occupancy based hvac actuation using existing wifi infrastructure within commercial buildings. In Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems, SenSys' 13, pages 17: 1-17, New York, NY, USA, 2013. [4] L. Breiman."}], "references": [{"title": "Shape quantization and recognition with randomized trees", "author": ["Y. Amit", "D. Geman"], "venue": "Neural Comput., 9(7):1545\u20131588, Oct.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Sentinel: Occupancy based hvac actuation using existing wifi infrastructure within commercial buildings", "author": ["B. Balaji", "J. Xu", "A. Nwokafor", "R. Gupta", "Y. Agarwal"], "venue": "Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems, SenSys \u201913, pages 17:1\u201317:14, New York, NY, USA,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Mach. Learn., 45(1):5\u201332, Oct.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "sMAP: a simple measurement and actuation profile for physical information", "author": ["S. Dawson-Haggerty", "X. Jiang", "G. Tolle", "J. Ortiz", "D. Culler"], "venue": "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems, SenSys \u201910,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Gene  selection and classification of microarray data using random forest", "author": ["R. Diaz-Uriarte", "S. Alvarez de Andres"], "venue": "BMC Bioinformatics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "New real-time approaches for video-genre-classification using high-level descriptors and a set of classifiers", "author": ["R. Glasberg", "S. Schmiedeke", "M. Mocigemba", "T. Sikora"], "venue": "Semantic Computing, 2008 IEEE International Conference on, pages 120\u2013127, Aug", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Neural network ensembles", "author": ["L.K. Hansen", "P. Salamon"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., 12(10):993\u20131001, Oct.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1990}, {"title": "Understanding user\u2019s query intent with wikipedia", "author": ["J. Hu", "G. Wang", "F. Lochovsky", "J.-t. Sun", "Z. Chen"], "venue": "In Proceedings of the 18th International Conference on World Wide Web, WWW", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Music type classification by spectral contrast feature", "author": ["D.-N. Jiang", "L. Lu", "H.-J. Zhang", "J.-H. Tao", "L.-H. Cai"], "venue": "Multimedia and Expo, 2002. ICME \u201902. Proceedings. 2002 IEEE International Conference on, volume 1, pages 113\u2013116 vol.1,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Query type classification for web document retrieval", "author": ["I.-H. Kang", "G. Kim"], "venue": "Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval, SIGIR \u201903, pages 64\u201371, New York, NY, USA,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Weakly supervised classification of objects in images using soft random forests", "author": ["R. Lefort", "R. Fablet", "J.-M. Boucher"], "venue": "Proceedings of the 11th European Conference on Computer Vision: Part IV, ECCV\u201910, pages 185\u2013198, Berlin, Heidelberg,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Content-based audio classification and segmentation by using support vector machines", "author": ["L. Lu", "H.-J. Zhang", "S.Z. Li"], "venue": "Multimedia Systems, 8(6):482\u2013492,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Understandable models of music collections based on exhaustive feature generation with temporal statistics", "author": ["F. Moerchen", "I. Mierswa", "A. Ultsch"], "venue": "Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201906, pages 882\u2013891, New York, NY, USA,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Parallel neural networks for multimodal video genre classification", "author": ["M. Montagnuolo", "A. Messina"], "venue": "Multimedia Tools and Applications, 41(1):125\u2013159,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Broadcast news segmentation by audio type analysis", "author": ["T.L. Nwe", "H. Li"], "venue": "Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP \u201905). IEEE International Conference on, volume 2, pages ii/1065\u2013ii/1068 Vol. 2, March", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Popular ensemble methods: An empirical study", "author": ["D. Opitz", "R. Maclin"], "venue": "Journal of Artificial Intelligence Research, 11:169\u2013198,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Random forest classifier for remote sensing  classification", "author": ["M. Pal"], "venue": "International Journal of Remote Sensing, 26(1):217\u2013222,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Activity recognition from accelerometer data", "author": ["N. Ravi", "N. D", "P. Mysore", "M.L. Littman"], "venue": "Proceedings of the Seventeenth Conference on Innovative Applications of Artificial Intelligence(IAAI,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "Ensemble-based classifiers", "author": ["L. Rokach"], "venue": "Artif. Intell. Rev., 33(1-2):1\u201339, Feb.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Indoor localization without infrastructure using the acoustic background spectrum", "author": ["S.P. Tarzia", "P.A. Dinda", "R.P. Dick", "G. Memik"], "venue": "Proceedings of the 9th International Conference on Mobile Systems, Applications, and Services, MobiSys \u201911, pages 155\u2013168, New York, NY, USA,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning a complex metabolomic dataset using random forests and support vector machines", "author": ["Y. Truong", "X. Lin", "C. Beecher"], "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201904, pages 835\u2013840, New York, NY, USA,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "Accurate activity recognition in a home setting", "author": ["T. van Kasteren", "A. Noulas", "G. Englebienne", "B. Kr\u00f6se"], "venue": "In Proceedings of the 10th International Conference on Ubiquitous Computing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}, {"title": "Local business ambience characterization through mobile audio sensing", "author": ["H. Wang", "D. Lymberopoulos", "J. Liu"], "venue": "Proceedings of the 23rd International Conference on World Wide Web, WWW \u201914, pages 293\u2013304, Republic and Canton of Geneva, Switzerland,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "The layout consistent random field for recognizing and segmenting partially occluded objects", "author": ["J. Winn", "J. Shotton"], "venue": "Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 1, CVPR \u201906, pages 37\u201344, Washington, DC, USA,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 15, "context": "In general, ensemble learning methods obtain better predictive performance than any of the constituent learning methods as discussed in [19, 22], if the following assumptions hold [8]: 1) the probability of a correct classification by each individual classifier is greater than 0.", "startOffset": 136, "endOffset": 144}, {"referenceID": 18, "context": "In general, ensemble learning methods obtain better predictive performance than any of the constituent learning methods as discussed in [19, 22], if the following assumptions hold [8]: 1) the probability of a correct classification by each individual classifier is greater than 0.", "startOffset": 136, "endOffset": 144}, {"referenceID": 6, "context": "In general, ensemble learning methods obtain better predictive performance than any of the constituent learning methods as discussed in [19, 22], if the following assumptions hold [8]: 1) the probability of a correct classification by each individual classifier is greater than 0.", "startOffset": 180, "endOffset": 183}, {"referenceID": 2, "context": "Random forests [4] have been widely used and outperform a single tree classifier.", "startOffset": 15, "endOffset": 18}, {"referenceID": 23, "context": "They are also faster [29] in training and testing compared to traditional classifiers such as SVM.", "startOffset": 21, "endOffset": 25}, {"referenceID": 0, "context": "The notion of randomized trees was first introduced in [2] and further well developed in [4].", "startOffset": 55, "endOffset": 58}, {"referenceID": 2, "context": "The notion of randomized trees was first introduced in [2] and further well developed in [4].", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "Usually these parameters are optimized through cross-validation and we refer interested readers to [4] for further deduction and proof of random forest.", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "Note that instead of letting each tree vote for on class as described in the original paper [4], we combine the results from classifiers for an instance by averaging their probabilistic predictions, in order to facilitate our technique used to help identify potential misclassified instances as described in the following section.", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "Included with permission from the authors of [3].", "startOffset": 45, "endOffset": 48}, {"referenceID": 3, "context": "The other building is the Sutardja Dai Hall (SDH) at UC Berkeley, where the deployed sensors [12, 1] transmit to an archiver [5] periodically from anywhere between every 5 seconds to every 10 minutes.", "startOffset": 125, "endOffset": 128}, {"referenceID": 11, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 81, "endOffset": 89}, {"referenceID": 14, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 81, "endOffset": 89}, {"referenceID": 8, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 97, "endOffset": 105}, {"referenceID": 12, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 97, "endOffset": 105}, {"referenceID": 5, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 113, "endOffset": 120}, {"referenceID": 13, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 113, "endOffset": 120}, {"referenceID": 9, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 132, "endOffset": 139}, {"referenceID": 7, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 132, "endOffset": 139}, {"referenceID": 17, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 159, "endOffset": 167}, {"referenceID": 21, "context": "There has been much research work on type classification in the context of audio [14, 18], music [10, 16], video [7, 17], web query [11, 9] and human activity [21, 27].", "startOffset": 159, "endOffset": 167}, {"referenceID": 11, "context": "The goal of [14] is to classify audios into categories such as speech, music, background sound and silence using support vector machines, and the work in [18] addresses the same problem with a HMM-based statistical model.", "startOffset": 12, "endOffset": 16}, {"referenceID": 14, "context": "The goal of [14] is to classify audios into categories such as speech, music, background sound and silence using support vector machines, and the work in [18] addresses the same problem with a HMM-based statistical model.", "startOffset": 154, "endOffset": 158}, {"referenceID": 8, "context": "e, jazz, pop and so forth) classification are [10, 16], which use GMM with EM algorithm and logistic regression respectively.", "startOffset": 46, "endOffset": 54}, {"referenceID": 12, "context": "e, jazz, pop and so forth) classification are [10, 16], which use GMM with EM algorithm and logistic regression respectively.", "startOffset": 46, "endOffset": 54}, {"referenceID": 5, "context": "For video type classification, texture and color-based features are used to classify videos into classes including cartoon, commercial, news and so on with decision tree [7] and neural network [17].", "startOffset": 170, "endOffset": 173}, {"referenceID": 13, "context": "For video type classification, texture and color-based features are used to classify videos into classes including cartoon, commercial, news and so on with decision tree [7] and neural network [17].", "startOffset": 193, "endOffset": 197}, {"referenceID": 9, "context": "Query categorization has also been researched, [11] exploits a rule-based classifier while [9] uses a Markov random walk model.", "startOffset": 47, "endOffset": 51}, {"referenceID": 7, "context": "Query categorization has also been researched, [11] exploits a rule-based classifier while [9] uses a Markov random walk model.", "startOffset": 91, "endOffset": 94}, {"referenceID": 17, "context": "There is also work on human activity classification in general cases [21] (i.", "startOffset": 69, "endOffset": 73}, {"referenceID": 21, "context": "e, running, walking and sitting) and home setting [27] (i.", "startOffset": 50, "endOffset": 54}, {"referenceID": 4, "context": "Random forests have been applied in many different areas [6, 26, 13, 20].", "startOffset": 57, "endOffset": 72}, {"referenceID": 20, "context": "Random forests have been applied in many different areas [6, 26, 13, 20].", "startOffset": 57, "endOffset": 72}, {"referenceID": 10, "context": "Random forests have been applied in many different areas [6, 26, 13, 20].", "startOffset": 57, "endOffset": 72}, {"referenceID": 16, "context": "Random forests have been applied in many different areas [6, 26, 13, 20].", "startOffset": 57, "endOffset": 72}, {"referenceID": 4, "context": "[6] uses a gene as a feature to classify microarray data.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "[26] uses the intensity of hundreds of measured metabolites from medical subjects as features, to classify the subjects into groups of normal, diseased and diseased with drug treatment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "Random forests have also been used in [13] to classify objects in images with image-relevant features.", "startOffset": 38, "endOffset": 42}, {"referenceID": 16, "context": "In the area of remote sensing, [20] utilizes user-defined parameters as features to classify land cover types.", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "Tarzia [24] et.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "Wang [28] et.", "startOffset": 5, "endOffset": 9}], "year": 2015, "abstractText": "Many sensors/meters are deployed in commercial buildings to monitor and optimize their performance. However, because sensor metadata is inconsistent across buildings, softwarebased solutions are tightly coupled to the sensor metadata conventions (i.e. schemas and naming) for each building. Running the same software across buildings requires significant integration effort. Metadata normalization is critical for scaling the deployment process and allows us to decouple building-specific conventions from the code written for building applications. It also allows us to deal with missing metadata. One important aspect of normalization is to differentiate sensors by the type of phenomena being observed. In this paper, we propose a general, simple, yet effective classification scheme to differentiate sensors in buildings by type. We perform ensemble learning on data collected from over 2000 sensor streams in two buildings. Our approach is able to achieve more than 92% accuracy for classification within buildings and more than 82% accuracy for across buildings. We also introduce a method for identifying potential misclassified streams. This is important because it allows us to identify opportunities to attain more input from experts \u2013 input that could help improve classification accuracy when ground truth is unavailable. We show that by adjusting a threshold value we are able to identify at least 30% of the misclassified instances.", "creator": "LaTeX with hyperref package"}}}