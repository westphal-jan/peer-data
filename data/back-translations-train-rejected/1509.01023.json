{"id": "1509.01023", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Sep-2015", "title": "Generating Weather Forecast Texts with Case Based Reasoning", "abstract": "Several techniques have been used to generate weather forecast texts. In this paper, case based reasoning (CBR) is proposed for weather forecast text generation because similar weather conditions occur over time and should have similar forecast texts. CBR-METEO, a system for generating weather forecast texts was developed using a generic framework (jCOLIBRI) which provides modules for the standard components of the CBR architecture. The advantage in a CBR approach is that systems can be built in minimal time with far less human effort after initial consultation with experts. The approach depends heavily on the goodness of the retrieval and revision components of the CBR process. We evaluated CBRMETEO with NIST, an automated metric which has been shown to correlate well with human judgements for this domain. The system shows comparable performance with other NLG systems that perform the same task.", "histories": [["v1", "Thu, 3 Sep 2015 10:21:16 GMT  (538kb)", "http://arxiv.org/abs/1509.01023v1", "6 pages"]], "COMMENTS": "6 pages", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["ibrahim adeyanju"], "accepted": false, "id": "1509.01023"}, "pdf": {"name": "1509.01023.pdf", "metadata": {"source": "META", "title": "Generating Weather Forecast Texts with Case based Reasoning", "authors": ["Ibrahim Adeyanju"], "emails": [], "sections": [{"heading": null, "text": "CBR-METEO, a system for generating weather forecast texts, was developed using a generic framework (jCOLIBRI) that provides modules for the standard components of the CBR architecture.The advantage of a CBR approach is that systems can be built in a minimum of time and with much less human effort after initial consultation with experts.The approach depends heavily on the quality of the retrieval and revision components of the CBR process. We evaluated CBRMETEO with NIST, an automated measurement that has been proven to correlate well with human judgments in this area.The system performs comparably with other NLG systems that perform the same task. Artificial Intelligence, Information Systems, Problem Solving Keywords Weather Forecast, Text Reuse, Text Generation, CBR, NLG"}, {"heading": "1. INTRODUCTION", "text": "In the applied Natural Language Generation (NLG), the domain of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7]. Many techniques have been proposed and applied to the automated generation of weather forecast texts. These techniques include knowledge-intensive approaches in which domain experts and corpus analyses elicit explicit rules [6,8], at different stages of the text generation process. Machine learning models, especially statistical methods, have also been used to design systems that introspectively learn generation models from the corpus [7,9]. The use of machine learning to build text generation models is knowledge-light.Weather forecasting and the generation of weather forecast texts are, however, natural case-based reasoning (CBR) problems. This is because the basic assumptions of the CBR are that we will immediately see similar problems in certain days, and similar problems occur in certain weather conditions."}, {"heading": "2. BACKGROUND", "text": "The automated generation of weather prediction texts has been achieved using several techniques, which can be divided into two broad categories: knowledge-intensive (AI) and knowledge-based (KL) approaches. AI approaches require extensive consultation with domain experts during body analysis and throughout the text creation process. On the other hand, KL approaches rely more heavily on the use of automated methods, which are mainly statistical. One of the earliest AI systems generated predictive texts by inserting numerical values into manually created standard templates [10]. For each possible scenario, several templates are created and one of them is randomly selected during text generation to provide variety. Other AI systems such as ICWF [11], FoG [12] and SumTime [6] developed linguistic models using manually created rules, which are obtained by domain experts and body analysis. Some of these systems, e.g. realistic and time-type planning, will be divided into different architectural modules [13]."}, {"heading": "3. CBR APPROACH TO GENERATING WEATHER FORECAST TEXTS", "text": "This section provides an insight into the CBR (case-based reasoning) paradigm and how it is used to generate weather forecast texts. Basic concepts and terminology in CBR are discussed on the basis of examples from the field of weather forecasting."}, {"heading": "3.1 Case Based Reasoning", "text": "The basic principles in CBR are that similar problems recur and similar problems have similar solutions. It is therefore easier to change an earlier solution to a similar problem than to solve a new problem from scratch. Therefore, the technique requires knowledge in the form of problem-solving episodes in which each episode is referred to as a case. Each case consists of a problem and its solution and a number of cases form the case base. The CBR problem-solving architecture, as shown in Figure 1, typically consists of four components: Retrieve, Reuse, Revise and Retain, commonly referred to as 4Rs [18]. The most similar case / case is / is retrieved from the case bank when a new problem (referred to as input or query) occurs. The information and knowledge in the retrieved similar case / case is then used to resolve the current problem."}, {"heading": "3.2 CBR-METEO: A weather forecast text generation system", "text": "Our system, which we call CBR-METEO, generates weather forecast texts using a repository of previous forecast texts available in a case database. In this area, a case consists of a pair of weather attribute values (for parameters such as humidity, outlook, wind speeds, wind directions and forecast times) and equivalent forecast texts generated by human experts. We limit our weather data to those related to wind forecasts (i.e. wind speeds, directions, gusts and time) and related texts for simplification. CBR-METEO therefore generates a wind forecast text for new wind input data, which can easily be extended to other weather parameters. The system is made using jCOLIBRI [19], an existing CBR framework. jCOLIBRI provides generic modules for each component of the typical CBR architecture (see Figure 1)."}, {"heading": "3.3 Retrieval", "text": "The reactionary tendencies of recent years in the USA and in Europe have intensified considerably in recent years, both in the USA and in Europe."}, {"heading": "3.4 Reuse", "text": "The reuse component of CBR-METEO puts the prediction text associated with the retrieved similar wind data into the context of the input. To this end, the prediction text is evaluated to identify attribute values from the retrieved wind data that are present in the text, and these attribute values are then replaced by their input equivalent. The reuse component does not take action if the retrieved wind data is identical to the input. In other words, the prediction text associated with the retrieved wind data can be returned directly for output if the similarity between the input and retrieved data is equal to 1 at each step during the hierarchical calculation of similarity. In other words, the prediction text associated with the retrieved wind data can be returned directly to the output if the similarity between the input and retrieved data is equal to 1 at each step during the hierarchical calculation of similarity."}, {"heading": "3.5 Revision", "text": "The revision component uses expert rules to ensure that certain phrases conform to the conventions for writing in the domain. Such rules are learned as part of post-edit tasks, where experts are given input data and predictive texts proposed by the reuse component. Figure 5 shows a revised form of prediction text in Figure 4, where one of the expert rules is applied to turn \"6-10\" into \"10 or less\" in the reuse prediction text."}, {"heading": "3.6 Retain", "text": "Retention can be performed in CBR-METEO, where new cases, consisting of input and output (generated prediction texts), are added to the case base after further review by experts. Inputs whose prediction texts CBR-METEO could not generate can also be added after generation by experts or using other techniques. Thus, the system evolves over time and is able to generate accurate prediction texts for most (if not all) inputs when this component is functional."}, {"heading": "3.7 CBR-METEO: A guided illustration", "text": "A summary of the text creation process is shown in Figure 6: The figure shows the transition between the various components (retrieval, reuse, revision, and retention) using the same examples as in Sections 3.2 to 3.6. Here, wind data is the problem, and the forecast text the solution in the CBR context. The wind properties displayed are wind direction (Dir), minimum wind speed (LSpd), and maximum wind speed (HSpd). Attributes associated with gusts are not displayed because they are missing from the input used for illustration."}, {"heading": "4. EXPERIMENTAL SETUP", "text": "We used an experimental design identical to [14]. Compared to other automated evaluation methods such as BLEU [21] and ROUGE [22], we evaluate the forecast text generated by CBR-METEO with NIST [20], which correlates best with expert opinions in the field of weather forecast text generation [15]. We then compare the results with ten existing NLG systems; SumTime hybrid [15] and nine trainable systems [7]."}, {"heading": "4.1 Dataset", "text": "Our experiments were evaluated using the wind weather corpus described in [23], which consists of wind forecast data and texts divided into five folds, each fold further divided into training and test kits. Training includes 2104 wind forecasts, while there are 221 test predictions for all five folds with duplicates. Test kits were used as our queries, while each corresponding training set is the fall basis in our experiments.Wind data were analyzed from the human-written prediction text, in which each phrase is a vector of 7 upels (i, d, smin, smax, gmin, gmax, t), with i the upel ID, d the wind direction, smin and smax being the minimum and maximum wind velocities, gmin and gmax being the minimum and maximum wind velocities, and gmax being the minimum and maximum wind velocities, and t being a time tempo (in, smin, max, max gmax, max, max gmax, max, max gmax, max) wind velocities (the wind velocities are the wind velocities, max, max, max, max, max gmax, max, max, max, max, max, gmax) wind velocities (the wind velocities)."}, {"heading": "4.2 Evaluation results", "text": "The results of the study show that the number of people who are able to reform themselves is able to reform themselves, both in relation to the way they behave, and also in relation to the way they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they behave, how they"}, {"heading": "5. CONCLUSION", "text": "In this paper, we outlined an approach to creating weather forecast texts using CBR technology, which involves retrieving prior similar weather data in response to input data whose text is required; the predictive text associated with the retrieved similar weather data is then reused in the context of the new data, followed by minimal revision; the approach is knowledge-based, ensuring that systems can be built up in a short time and with less human effort; CBR also allows the system to evolve gradually as new predictive texts can be retained for future use. Our system, CBR- METEO, has been evaluated against other NLG systems that perform the same task and has shown comparable results; the limitation of our current system is that it cannot generate predictive texts for all queries if no previous similar weather data is found in the case base; we intend to improve this by loosening our similarity limitations in order to retrieve less similar cases while also requiring other systems to use similar rules for more complex long-term assessments."}, {"heading": "6. ACKNOWLEDGMENTS", "text": "The author would like to thank Nirmalie Wiratunga from Robert Gordon University, UK, and Somayajulu Sripada from the University of Aberdeen, UK, for their useful feedback."}, {"heading": "7. REFERENCES", "text": "[1] Kittredge, R., Polgue \u0301 re, A. and Goldberg, E. 1986.Synthesizing weather reports from formatted data. In Proceedings of the 11th LG 11, 2001. [2] Bourbeau, L., Carcagno, D., Goldberg, E., Kittredge, R., and Polgure, A. 1990. Bilingual generation of weatherforecasts in an operations environment. (Proceedings of COLING '90, 318-320. [3] Sigurd, B., Willners, C., Eeg-Olofsson, M., and Johansson, C. 1992. Deep comprehension, generationand translation of weather predictions (weathra). In COLING-92, 749-755. [4] Coch, J. 1998. Interactive generation and knowledge administration in multimeteo. In Proceedings of the 9th International Workshop on NLG, 300-303."}], "references": [{"title": "Synthesizing weather reports from formatted data", "author": ["R. Kittredge", "A. Polgu\u00e9re", "E. Goldberg"], "venue": "In Proceedings of the 11th. International Conference on Computational Linguistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1986}, {"title": "Bilingual generation of weather forecasts in an operations environment", "author": ["L. Bourbeau", "D. Carcagno", "E. Goldberg", "R. Kittredge", "A. Polgure"], "venue": "In Proceedings of COLING\u201990,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1990}, {"title": "Deep comprehension, generation and translation of weather forecasts (weathra)", "author": ["B. Sigurd", "C. Willners", "M. Eeg-Olofsson", "C. Johansson"], "venue": "In COLING-92,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1992}, {"title": "Interactive generation and knowledge administration in multimeteo", "author": ["J. Coch"], "venue": "In Proceedings of the 9th International Workshop on NLG,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "Integrating text planning and linguistic choice without abandoning modularity: the IGEN generator", "author": ["R. Rubinoff"], "venue": "Computational Linguistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "SumTime- Mousam: Configurable marine weather forecast generator", "author": ["S. Sripada", "E. Reiter", "I. Davy"], "venue": "Expert Update,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models", "author": ["A. Belz"], "venue": "Natural Language Engineering,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Acquiring correct knowledge for natural language generation", "author": ["E. Reiter", "S. Sripada", "R. Robertson"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Learning to order facts for discourse planning in natural  language generation", "author": ["A. Dimitromanolaki", "I. Androutsopoulos"], "venue": "In Proc. of EACL Workshop on NLG", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Computer-produced worded forecasts", "author": ["H. Glahn"], "venue": "American Meteorological Society Bulletin,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1970}, {"title": "The interactive computer worded forecast", "author": ["D.P. Ruth", "M.R. Peroutka"], "venue": "In 9th International Conference on Interactive Information and Processing Systems for Meteorology, Oceanography and Hydrology,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "Using natural-language processing to produce weather reports", "author": ["E. Goldberg", "N. Driedger", "R. Kittredge"], "venue": "IEEE Expert,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Building applied natural language generation systems", "author": ["E. Reiter", "Robert Dale"], "venue": "Natural Language Engineering,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1995}, {"title": "System building cost vs. output quality in data-to-text generation", "author": ["A. Belz", "E. Kow"], "venue": "In Proceedings of 12th European Workshop on NLG", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Comparing automatic and human evaluation of NLG systems", "author": ["A. Belz", "E. Reiter"], "venue": "In Proceedings of EACL\u201906,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Automatic Generation of Poetry using a CBR Approach. In Proceedings of the Conference of the Spanish Association for Artificial Intelligence (CAEPIA)", "author": ["P. Gerv\u00e1s"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Story plot generation based on CBR", "author": ["P. Gerv\u00e1s", "B. D\u0131\u0301az-Agudo", "F. Peinado", "R. Herv\u00e1s"], "venue": "In 12th Conference on Applications and Innovations in Intelligent Systems", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Case-based reasoning: Foundational issues, methodological variations and system approaches", "author": ["A. Aamodt", "E. Plaza"], "venue": "Artificial Intelligence Communications (AICom),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1994}, {"title": "Building CBR systems with jCOLIBRI", "author": ["B. D\u0131az-Agudo", "P.A. Gonzalez-Calero", "J.A. Recio-Garc\u0131a", "A. Sanchez"], "venue": "Special Issue on Experimental Software and Toolkits of the Journal Science of Computer Programming,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Automatic evaluation of machine translation quality using n-gram co-occurrence statistics", "author": ["G. Doddington"], "venue": "In Proceedings of ARPA Work- shop on Human Language Technology", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "BLEU: A method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "Zhu", "W-J"], "venue": "In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2002}, {"title": "Automatic evaluation of summaries using n-gram co-occurrence statistics", "author": ["Lin", "C-Y", "E. Hovy"], "venue": "In Proceedings of the Human Technology Conference (HLT-NAACL", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "Prodigy-METEO: Pre-Alpha Release Notes. University of Brighton, UK, first edition", "author": ["A. Belz"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Learning adaptation knowledge to improve case-based reasoning", "author": ["S. Craw", "N. Wiratunga", "R.C. Rowe"], "venue": "Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "SUMTIME-METEO: Parallel corpus of naturally occurring forecast texts and weather data", "author": ["S. Sripada", "E. Reiter", "J. Hunter", "J. Yu"], "venue": "Technical report,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 1, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 2, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 3, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 4, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 5, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 6, "context": "of weather forecasting is very popular and has been used to test the effectiveness of several text generation techniques [1,2,3,4,5,6,7].", "startOffset": 121, "endOffset": 136}, {"referenceID": 5, "context": "Such techniques include knowledge intensive approaches in which explicit rules are elicited from domain experts and corpus analysis [6,8] at different stages of the text generation process.", "startOffset": 132, "endOffset": 137}, {"referenceID": 7, "context": "Such techniques include knowledge intensive approaches in which explicit rules are elicited from domain experts and corpus analysis [6,8] at different stages of the text generation process.", "startOffset": 132, "endOffset": 137}, {"referenceID": 6, "context": "Machine learning models, especially statistical methods, have also been used to design systems that learn generation models introspectively from the corpus [7,9].", "startOffset": 156, "endOffset": 161}, {"referenceID": 8, "context": "Machine learning models, especially statistical methods, have also been used to design systems that learn generation models introspectively from the corpus [7,9].", "startOffset": 156, "endOffset": 161}, {"referenceID": 9, "context": "inserting numeric values in standard manually-created templates [10].", "startOffset": 64, "endOffset": 68}, {"referenceID": 10, "context": "Other KI systems such as ICWF [11], FoG [12] and SumTime [6] developed", "startOffset": 30, "endOffset": 34}, {"referenceID": 11, "context": "Other KI systems such as ICWF [11], FoG [12] and SumTime [6] developed", "startOffset": 40, "endOffset": 44}, {"referenceID": 5, "context": "Other KI systems such as ICWF [11], FoG [12] and SumTime [6] developed", "startOffset": 57, "endOffset": 60}, {"referenceID": 12, "context": "FoG and SumTime, used NLG architecture [13] where the generation process is separated into different modules.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "Trainable systems are built using models based on statistical methods such as probabilistic context-free grammars and phrase based machine translation [14].", "startOffset": 151, "endOffset": 155}, {"referenceID": 14, "context": "Forecast texts generated by KL systems were reported to have comparable quality to KI systems when evaluated with automated metrics [15].", "startOffset": 132, "endOffset": 136}, {"referenceID": 15, "context": "Synergy between CBR and NLG has previously been exploited for automatic story plot generation [16,17].", "startOffset": 94, "endOffset": 101}, {"referenceID": 16, "context": "Synergy between CBR and NLG has previously been exploited for automatic story plot generation [16,17].", "startOffset": 94, "endOffset": 101}, {"referenceID": 17, "context": "The CBR problem-solving architecture as shown in Figure 1 typically consists of four components: Retrieve, Reuse, Revise and Retain commonly referred to as 4Rs [18].", "startOffset": 160, "endOffset": 164}, {"referenceID": 18, "context": "The system is built using jCOLIBRI [19], an existing CBR framework.", "startOffset": 35, "endOffset": 39}, {"referenceID": 13, "context": "EXPERIMENTAL SETUP We employed a five hold-out experimental design identical to [14] in our experiments.", "startOffset": 80, "endOffset": 84}, {"referenceID": 19, "context": "We evaluate the forecast text generated by CBR-METEO with NIST [20] which correlates best with expert judgements in the domain of weather forecast text generation [15] as compare to other automated evaluation methods such as BLEU [21] and ROUGE [22].", "startOffset": 63, "endOffset": 67}, {"referenceID": 14, "context": "We evaluate the forecast text generated by CBR-METEO with NIST [20] which correlates best with expert judgements in the domain of weather forecast text generation [15] as compare to other automated evaluation methods such as BLEU [21] and ROUGE [22].", "startOffset": 163, "endOffset": 167}, {"referenceID": 20, "context": "We evaluate the forecast text generated by CBR-METEO with NIST [20] which correlates best with expert judgements in the domain of weather forecast text generation [15] as compare to other automated evaluation methods such as BLEU [21] and ROUGE [22].", "startOffset": 230, "endOffset": 234}, {"referenceID": 21, "context": "We evaluate the forecast text generated by CBR-METEO with NIST [20] which correlates best with expert judgements in the domain of weather forecast text generation [15] as compare to other automated evaluation methods such as BLEU [21] and ROUGE [22].", "startOffset": 245, "endOffset": 249}, {"referenceID": 14, "context": "We then compare the results with ten existing NLG systems; SumTime hybrid [15] and nine trainable systems [7].", "startOffset": 74, "endOffset": 78}, {"referenceID": 6, "context": "We then compare the results with ten existing NLG systems; SumTime hybrid [15] and nine trainable systems [7].", "startOffset": 106, "endOffset": 109}, {"referenceID": 22, "context": "1 Dataset Our experiments were evaluated using the wind weather corpus described in [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 14, "context": "The forecast texts consist of natural language forecasts from human forecasters, Sum-Time hybrid system [15] and nine trainable systems [7].", "startOffset": 104, "endOffset": 108}, {"referenceID": 6, "context": "The forecast texts consist of natural language forecasts from human forecasters, Sum-Time hybrid system [15] and nine trainable systems [7].", "startOffset": 136, "endOffset": 139}, {"referenceID": 13, "context": "Although, four trainable systems (PBSMT-unstructured, PSCFG-semantic, PSCFGunstructured and PCFG-greedy) outperform our CBR system according to the results, its performance is very similar to the SumTime hybrid system which was ranked as best by human evaluators [14].", "startOffset": 263, "endOffset": 267}, {"referenceID": 23, "context": "40 adaptation casebase [24] to store cases of text revisions made by domain experts.", "startOffset": 23, "endOffset": 27}, {"referenceID": 24, "context": "The adaptation casebase will be similar to the post-edit corpus currently available in the domain [25].", "startOffset": 98, "endOffset": 102}], "year": 2012, "abstractText": "Several techniques have been used to generate weather forecast texts. In this paper, case based reasoning (CBR) is proposed for weather forecast text generation because similar weather conditions occur over time and should have similar forecast texts. CBR-METEO, a system for generating weather forecast texts was developed using a generic framework (jCOLIBRI) which provides modules for the standard components of the CBR architecture. The advantage in a CBR approach is that systems can be built in minimal time with far less human effort after initial consultation with experts. The approach depends heavily on the goodness of the retrieval and revision components of the CBR process. We evaluated CBRMETEO with NIST, an automated metric which has been shown to correlate well with human judgements for this domain. The system shows comparable performance with other NLG systems that perform the same task. General Terms Artificial Intelligence, Information Systems, Problem-Solving", "creator": "Microsoft\u00ae Office Word 2007"}}}