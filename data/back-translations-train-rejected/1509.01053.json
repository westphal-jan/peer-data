{"id": "1509.01053", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Sep-2015", "title": "Training a Restricted Boltzmann Machine for Classification by Labeling Model Samples", "abstract": "We propose an alternative method for training a classification model. Using the MNIST set of handwritten digits and Restricted Boltzmann Machines, it is possible to reach a classification performance competitive to semi-supervised learning if we first train a model in an unsupervised fashion on unlabeled data only, and then manually add labels to model samples instead of training data samples with the help of a GUI. This approach can benefit from the fact that model samples can be presented to the human labeler in a video-like fashion, resulting in a higher number of labeled examples. Also, after some initial training, hard-to-classify examples can be distinguished from easy ones automatically, saving manual work.", "histories": [["v1", "Thu, 3 Sep 2015 12:13:37 GMT  (144kb,D)", "http://arxiv.org/abs/1509.01053v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["malte probst", "franz rothlauf"], "accepted": false, "id": "1509.01053"}, "pdf": {"name": "1509.01053.pdf", "metadata": {"source": "CRF", "title": "Training a Restricted Boltzmann Machine for classification by labeling model samples", "authors": ["Malte Probst", "Franz Rothlauf"], "emails": ["probst/rothlauf@uni-mainz.de"], "sections": [{"heading": null, "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction", "text": "When solving classification problems in a supervised or semi-supervised manner, it is always necessary to mark samples from the training data in some way. Incorporating these labelled examples into the training process allows the model to directly assign a class label to either an unknown example or the implicit category to which the example belongs. A common approach is to apply labels to all or a subset of training examples before training. This process can be very time consuming, especially if there are many examples and a large subset of them should be labelled. Semi-supervised learning makes it possible to train a sufficient model while only a subset of training data is enriched with labels Chapelle et al. (2010) However, it is still necessary to label some samples before training. This paper presents an alternative approach to classifying images that works in reverse order."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Semi-supervised learning and generative models", "text": "Semi-supervised training is a hybrid of supervised and unsupervised training Chapelle et al. (2010); Zhu and Goldberg (2009). In unsupervised training settings, we try to find interesting structures in a set X consisting of n training examples x1,..., xn, without explicitly assigning classes or labels to these structures, e.g. for clustering or statistical density estimation. In a supervised setting, we are interested in finding a mapping of a variable x to another variable in a training set consisting of example pairs (xi, yi), i.e. we are faced with a classification task. In order to solve a supervised learning problem, it is possible to use discriminatory or generative models. A discriminatory model tries to learn the relationship between xi and yi directly by trying to assess the conditional probability p (y | x) of a label as generative."}, {"heading": "2.2 Restricted Boltzmann Machines", "text": "Restricted Boltzmann machines are stochastic, energy-based neural network models Smolensky (1986). An RBM consists of a visible layer v and a hidden layer h, which are connected by weights wij from each visible neuron vi to each hidden neuron hj and form a two-part graph. They can be trained to model the common distribution of the data submitted to the visible layer, and the hidden neurons by matching the weights wij and the distortions bi and ci. The probability P that a hidden neuron hj is active depends on the activation of the visible units vi and the distortion of the hidden neuron cj, i.e. P (hj = 1 | v) = significance (i wijvi + cj), where Sigm () is the visible function sigm (hj) = 1 + vi \u2212 yy, i.e. the hidden neuron (1) and cj = hidden energy (1)."}, {"heading": "2.3 Training RBMs using contrastive divergence", "text": "In order to form an RBM from a data set, it is necessary to increase the probability (= decrease the energy) of training data vectors and reduce the probability of configurations that do not match training data by updating weights according to log probability gradients \u2202 log (P (v)) \u2202 wij. 1Note that all neurons are modelled as binomial random variables, this can be generalized to any exponential family distribution, see e.g. Welling et al. (2005) or Bengio et al. (2006) It can be shown that this partial derivative is a sum of two terms that are normally referred to as positive and negative gradients, which is why the training algorithm is called contrastive divergence (CD) Hinton (2002). The resulting updating rule for weights is a negative gradient variable."}, {"heading": "3 Post-labeling of MNIST digit model samples with an RBM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Overview", "text": "Figure 1 compares the steps of the standard approach to form a classification RBM with the post-labeling approach used in this thesis. The standard approach first collects training data and then manually applies labels to the data or to a subset of the data. Subsequently, a (semi-) supervised model is trained on marked data, simultaneously learning the regular weights Wij, connecting the visible neurons to the characteristics, as well as label weights wLkj, connecting the label neurons to the characteristics. In post-labeling, we change the order: After collecting the data, we train an RBM unattended on the unmarked data, thus updating only the regular weights Wij. We then have the model generate samples and label these samples. We then use the marked samples to update the label weights wLkj in a monitored manner."}, {"heading": "3.2 Data set", "text": "For our LeCun and Cortes experiments, we used the MNIST database of handwritten digits. The data set contains 60,000 labeled training examples and 10,000 labeled test examples of 28 * 28 pixels of handwritten digits in ten classes. When performing the semi-supervised or unsupervised learning tasks, we remove the labels."}, {"heading": "3.3 Models", "text": "We perform the post-labeling tests on a Boltzmann Restricted Machine with 784 (= 28 * 28) visible neurons vi and 225 hidden neurons hj (feature detectors). To test the competitiveness of the post-labeling approach, we compare it to an RBM of the same size - where the visible layer is extended by k = 10 label neurons - that is trained on labeled data in a supervised (all data labeled) or semi-supervised (only a subset labeled) way. Therefore, during initial training, the post-labeling RBM has only one set of weights weij, while the classical RBM has a second set of label weights wLkj. We train both models with the training algorithm CD-10 and 50,000 images from the training set. The remaining 10,000 examples are held up to find practicable parameters (such as the learning rate) for the supervised model."}, {"heading": "3.4 Interactive post-labeling phase", "text": "The goal of the post-labeling phase is to find suitable label weights wLkj. To this end, we have developed a GUI that shows patterns from the model to a human labeler who can activate the appropriate class with the keyboard or mouse (see Fig. 2). We initialize the visible plane with a randomly selected (unlabeled) image from the training set and have the model perform repeated Gibbs scans between the visible and the hidden layer of the underlying RBM. This results in slight deformation of the shown image at each sampling step, while the model along a3During our experiments, the one-step reconstruction error on models trained with CD-1 shows at 12 for models trained with CD-10. Nevertheless, the visual quality and especially the temporal stability of the representations on repeated Gibbs scans leads to better results in discriminatory tasks."}, {"heading": "3.5 Online learning while labeling", "text": "There are two ways to train the label weights wLkj: The first is to learn online during the post-labeling phase. If a label is activated by the user, we update the label weights proportionally to an approximation of the positive and negative gradients at the same time. In this case, the positive gradient is < ak, hj >, where ak is the activation of the k'th label (as indicated by the user) and hj is the probability that the j'th label is active. Negative gradient approximation is < lk, hj > with the probability that the k'th label is active (as reconstructed by h). Thus, we strengthen links between active features and the correct label and punish links between active features and the potentially incorrect reconstructed label. The distortions are updated accordingly. We enable online learning by default in the GUI."}, {"heading": "3.6 Offline learning after labeling", "text": "Alternatively, it is possible to train the label weights wLkj offline after manually labeling model samples in the GUI. We store all the frames labeled in the GUI and use them to train the label weights wLkj with standard CD-1. Again, the updating of the label weights is proportional to < ak, hj > data \u2212 < lk, hj > model. The only difference to online learning is that we can repeat the labeled training set several times, so the negative course may change during the training, resulting in a better approximation. The weights wij remain unchanged during the learning phase."}, {"heading": "3.7 Improvements and Tweaks", "text": "It is possible to improve the usability of the labeling GUI and the resulting label quality by a few tweaks. First, we can automatically control the speed of the image stream presented to the user. After a few minutes of training, the model already assigns a relatively high probability of the correct class for \"ordinary\" samples (online learning is activated). On the contrary, if the current sample is visually far from the previously described samples, the model does not assign a high probability to any label - it is uncertain which label should be selected for this example. Thus, it is possible to reduce the display speed for samples that seem unknown, allowing the user a more precise selection of the label (especially during class transitions). We have implemented this optimization in the GUI as \"autospeed\" and activated it by default (see fig. 2). Similarly, it is possible to distort the selection of samples from the training to initialize the image (sampling)."}, {"heading": "3.8 Results", "text": "We test both the RBM trained with the (semi-) supervised standard approach and the RBM described with the MNIST test set of 10,000 labeled images. Figure 4 shows the resulting error rate of the RBM trained with the standard approach. After only 500 out of 50,000 images have been labeled, a classification error of approximately 14% results. With an increase in the number of labeled images, the error rate quickly decreases and reaches its minimum of approximately 4% with a fully labeled training set. Figure 5 shows the test set error of the RBM trained with the post-labeling approach. Both online learning and offline learning results show high initial error rates and a rapid decline with increasing GUI time. However, the classification error of epochal offline learning is constantly smaller. It achieves a performance of approximately 6.2% error after 4200 seconds labeling of model samples. Although our goal is to (semi- supervised) we do not compare the results of each of a single labeling approach to 1.5 seconds."}, {"heading": "3.9 Biases to the results", "text": "The results shown above are distorted in two ways: firstly, our initial parameter selection for the unattended model was influenced by our background knowledge from previous monitored tests with the MNIST dataset. On a truly new training set, we would not have this knowledge and would only have to rely on the reconstruction error (see Section 3.3); secondly, our results are distorted by the fact that we use the labels of the official test set, which almost certainly come from a different distribution than those indicated by our labelers during training (note the ambiguity of sevens and ones or fours and nines given the cultural background); if all labels (test and training) come from the same distribution, the error rate in the tests will most likely be lower; the monitored model results can benefit from this fact, as opposed to the results of the post-labeling model."}, {"heading": "4 Discussion", "text": "The results show that the post-labeling approach is competitive in terms of the resulting classification quality compared to the standard approach. It is likely that the model, by following the low-energy gorges, displays samples that resemble a class but are not part of the training data. These samples can then be labeled by the GUI user. On the other hand, the post-labeling approach has a number of disadvantages. As mentioned above, the initial unattended training must be based on metrics such as the reconstruction error. In addition, the quality of the labeled model samples is not as high as the quality of the labeled examples from the real world. As the displayed image is constantly changing, there are almost certainly some mislabeled or inferior samples. Nevertheless, it should be possible to use the labeled samples as a whole to train the label weights of another model than the one from which they originate, as most of them actually copy the whole or inferior samples. Nevertheless, it should be possible to use the labeled samples as a whole in order to retrain the label weights of another model than the one from which they originate, since most of them actually represent the other classes, it is more meaningful to reconstruct the other part of the model."}, {"heading": "5 Conclusion and future work", "text": "We proposed a different approach to the formation of a classification model. Using the MNIST set of handwritten digits, we demonstrated that it is possible to train an RBM on unmarked data and then label model samples using a GUI. This approach offers an alternative to semi-supervised learning, but, given the labelling times tested, does not achieve the classification performance of a model trained on fully labelled data. An interesting question for further research is whether it is possible to improve model quality in relation to the data with the GUI after labelling, i.e. to capture user input (such as \"I only see noise\") during the interactive learning phase in order to improve the quality of the weights connecting the visible and hidden neurons."}], "references": [{"title": "Improving generalization with active learning", "author": ["Cohn", "Les Atlas", "Richard Ladner"], "venue": null, "citeRegEx": "Cohn et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 2010}, {"title": "Using fast weights to improve persistent contrastive divergence", "author": ["Tijmen Tieleman", "Geoffrey Hinton"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Tieleman and Hinton.,? \\Q2009\\E", "shortCiteRegEx": "Tieleman and Hinton.", "year": 2009}, {"title": "Exponential family harmoniums with an application to information retrieval", "author": ["M. Welling", "M. Rosen-Zvi", "Hinton"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Welling et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Welling et al\\.", "year": 2005}, {"title": "Introduction to Semi-Supervised Learning Synthesis Lectures on Artificial Intelligence and Machine Learning", "author": ["Xiaojin Zhu", "Andrew B. Goldberg"], "venue": null, "citeRegEx": "Zhu and Goldberg.,? \\Q2009\\E", "shortCiteRegEx": "Zhu and Goldberg.", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "By trying to maximize the additional information in each new training example this aspect is similar to active learning/selective sampling proposed in Cohn et al. (1994). There are some caveats to this approach: If, at the time of the training, there is no label information, the parametrization of the training process must rely on metrics like the reconstruction error.", "startOffset": 151, "endOffset": 170}, {"referenceID": 3, "context": "(2010); Zhu and Goldberg (2009). In unsupervised training settings, we try to find interesting structures in the a set X consisting of n training examples x1, .", "startOffset": 8, "endOffset": 32}, {"referenceID": 3, "context": "(2010); Zhu and Goldberg (2009). In unsupervised training settings, we try to find interesting structures in the a set X consisting of n training examples x1, ..., xn without explicitly assigning classes or labels to those structures, e.g. for clustering or statistical density estimation. In a supervised setting, we are interested in finding a mapping of a variable x to another variable y in a training set consisting of example pairs (xi, yi), i.e. we are facing a classification task. In order to solve a supervised learning problem, it is possible to use discriminative or generative models. A discriminative model tries to directly learn the relationship between xi and yi, often by trying to directly estimate the conditional probability p(y|x) of a label given a data point. Using a generative model, the approach is more related to the unsupervised case: By learning the structure of the data in X, generative models try to estimate the class-conditional probability p(x|y) or the joint probability p(x, y) and retain the conditional probability p(y|x) using Bayes\u2019 rule Chapelle et al. (2010). Given a well-trained generative model, it is therefore often possible to draw samples from the model that resemble training data, as they come from the same probability distribution.", "startOffset": 8, "endOffset": 1104}, {"referenceID": 3, "context": "(2010); Zhu and Goldberg (2009). In unsupervised training settings, we try to find interesting structures in the a set X consisting of n training examples x1, ..., xn without explicitly assigning classes or labels to those structures, e.g. for clustering or statistical density estimation. In a supervised setting, we are interested in finding a mapping of a variable x to another variable y in a training set consisting of example pairs (xi, yi), i.e. we are facing a classification task. In order to solve a supervised learning problem, it is possible to use discriminative or generative models. A discriminative model tries to directly learn the relationship between xi and yi, often by trying to directly estimate the conditional probability p(y|x) of a label given a data point. Using a generative model, the approach is more related to the unsupervised case: By learning the structure of the data in X, generative models try to estimate the class-conditional probability p(x|y) or the joint probability p(x, y) and retain the conditional probability p(y|x) using Bayes\u2019 rule Chapelle et al. (2010). Given a well-trained generative model, it is therefore often possible to draw samples from the model that resemble training data, as they come from the same probability distribution. Recently, a class of generative models called Restricted Boltzmann Machines has been widely used for discrimination tasks such as digit classification Hinton et al. (2006), phone recognition G.", "startOffset": 8, "endOffset": 1460}, {"referenceID": 3, "context": "(2010); Zhu and Goldberg (2009). In unsupervised training settings, we try to find interesting structures in the a set X consisting of n training examples x1, ..., xn without explicitly assigning classes or labels to those structures, e.g. for clustering or statistical density estimation. In a supervised setting, we are interested in finding a mapping of a variable x to another variable y in a training set consisting of example pairs (xi, yi), i.e. we are facing a classification task. In order to solve a supervised learning problem, it is possible to use discriminative or generative models. A discriminative model tries to directly learn the relationship between xi and yi, often by trying to directly estimate the conditional probability p(y|x) of a label given a data point. Using a generative model, the approach is more related to the unsupervised case: By learning the structure of the data in X, generative models try to estimate the class-conditional probability p(x|y) or the joint probability p(x, y) and retain the conditional probability p(y|x) using Bayes\u2019 rule Chapelle et al. (2010). Given a well-trained generative model, it is therefore often possible to draw samples from the model that resemble training data, as they come from the same probability distribution. Recently, a class of generative models called Restricted Boltzmann Machines has been widely used for discrimination tasks such as digit classification Hinton et al. (2006), phone recognition G. E. Dahl and E.Hinton (2010) or document classification Hinton and Salakhutdinov (2011).", "startOffset": 8, "endOffset": 1510}, {"referenceID": 3, "context": "(2010); Zhu and Goldberg (2009). In unsupervised training settings, we try to find interesting structures in the a set X consisting of n training examples x1, ..., xn without explicitly assigning classes or labels to those structures, e.g. for clustering or statistical density estimation. In a supervised setting, we are interested in finding a mapping of a variable x to another variable y in a training set consisting of example pairs (xi, yi), i.e. we are facing a classification task. In order to solve a supervised learning problem, it is possible to use discriminative or generative models. A discriminative model tries to directly learn the relationship between xi and yi, often by trying to directly estimate the conditional probability p(y|x) of a label given a data point. Using a generative model, the approach is more related to the unsupervised case: By learning the structure of the data in X, generative models try to estimate the class-conditional probability p(x|y) or the joint probability p(x, y) and retain the conditional probability p(y|x) using Bayes\u2019 rule Chapelle et al. (2010). Given a well-trained generative model, it is therefore often possible to draw samples from the model that resemble training data, as they come from the same probability distribution. Recently, a class of generative models called Restricted Boltzmann Machines has been widely used for discrimination tasks such as digit classification Hinton et al. (2006), phone recognition G. E. Dahl and E.Hinton (2010) or document classification Hinton and Salakhutdinov (2011).", "startOffset": 8, "endOffset": 1569}, {"referenceID": 2, "context": "Welling et al. (2005) or Bengio et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 2, "context": "Welling et al. (2005) or Bengio et al. (2006)", "startOffset": 0, "endOffset": 46}, {"referenceID": 1, "context": "If the reconstructions of the model are too stable to produce a constantly changing stream, it is possible to implement a set of \u201dfast weights\u201d as in Tieleman and Hinton (2009). Those fast weights can add a temporary penalty to the areas of low energy just visited, thus forcing the model to wander around.", "startOffset": 150, "endOffset": 177}], "year": 2015, "abstractText": "We propose an alternative method for training a classification model. Using the MNIST set of handwritten digits and Restricted Boltzmann Machines, it is possible to reach a classification performance competitive to semi-supervised learning if we first train a model in an unsupervised fashion on unlabeled data only, and then manually add labels to model samples instead of training data samples with the help of a GUI. This approach can benefit from the fact that model samples can be presented to the human labeler in a video-like fashion, resulting in a higher number of labeled examples. Also, after some initial training, hard-to-classify examples can be distinguished from easy ones automatically, saving manual work.", "creator": "LaTeX with hyperref package"}}}