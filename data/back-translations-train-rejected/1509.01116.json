{"id": "1509.01116", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Sep-2015", "title": "A tree-based kernel for graphs with continuous attributes", "abstract": "The availability of graph data with node attributes that can be either discrete or real-valued is constantly increasing. While existing kernel methods are effective techniques for dealing with graphs having discrete node labels, their adaptation to non-discrete or continuous node attributes has been limited, mainly for computational issues. Recently, a few kernels especially tailored for this domain, have been proposed. In order to alleviate the computational problems, the size of the feature space of such kernels tend to be smaller than the ones of the kernels for discrete node attributes. However, such choice might have a negative impact on the predictive performance. In this paper, we propose a graph kernel for complex and continuous nodes' attributes, whose features are tree structures extracted from specific graph visits. Experimental results obtained on real-world datasets show that the (approximated version of the) proposed kernel is comparable with current state-of-the-art kernels in terms of classification accuracy while requiring shorter running times.", "histories": [["v1", "Thu, 3 Sep 2015 14:59:10 GMT  (1289kb)", "http://arxiv.org/abs/1509.01116v1", "Paper submitted to IEEE Transactions on Neural Networks and Learning Systems"], ["v2", "Tue, 20 Dec 2016 16:54:02 GMT  (1029kb)", "http://arxiv.org/abs/1509.01116v2", "This work has been submitted to the IEEE Transactions on Neural Networks and Learning Systems for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible"]], "COMMENTS": "Paper submitted to IEEE Transactions on Neural Networks and Learning Systems", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["giovanni da san martino", "nicol\\`o navarin", "alessandro sperduti"], "accepted": false, "id": "1509.01116"}, "pdf": {"name": "1509.01116.pdf", "metadata": {"source": "CRF", "title": "A tree-based kernel for graphs with continuous attributes", "authors": ["Giovanni Da San Martino"], "emails": [], "sections": [{"heading": null, "text": "In this article, we propose a graph nucleus for complex and continuous nodes, whose classification properties are exactly as it is. INTRODUCTIONHowever, there is an increasing availability of data in the form of ascribed graphs, i.e. graphs in which some information is tied to nodes and edges (to the graph itself).For compatible reasons, we have focused on problems whose data can be modeled as discrete attributes."}, {"heading": "II. RELATED WORK", "text": "In recent years, several different graph kernels have been proposed for discretely rated graphs in the literature. Early work presented kernels that need to be computed in closed form, such as the random walk kernel [5] or the shortest path kernel [3]. However, these kernels suffer from relatively high computational complexity: O (n3) or O (n4). More recently, research has focused on the efficiency of kernel computation. State-of-the-art kernels use explicit mapping techniques [4], [6], [7], with computational complexities almost linearly in the size of the graphs. If we look at graphs with continuously rated kernel names, this last class of kernels cannot be easily modified to deal with them, because their efficiency hinges on the ability to perform compilations that only match discrete labels. Of course, this is not possible if continuously evaluated kernel drawings are taken into account."}, {"heading": "III. ORDERED DECOMPOSITION DAG KERNELS FOR GRAPHS WITH DISCRETE LABELS", "text": "A graph is disordered if (vi, vj), vj, vi), otherwise it is directed. A path p (vi, vj) of length n in a diagram n is a sequence of nodes v1,. vn, where v1 = vi, vj + 1).A cycle is a path, for v1 = vn. A graph is a path, for v1 = vn. A graph is a path, for v1 = vn. A graph is a path, v1 = vn. A graph is a path, for v1 = vn. A graph is a path, for v1 = vn. A graph is a path, for v1 = vn. A graph is a cycle, for v1 = vn. A graph is acyclic if it has no cycles."}, {"heading": "IV. GRAPH KERNELS FOR CONTINUOUS NODE LABELS", "text": "(This section shows an easy way to define novel kernels for graphs that are able to handle non-discrete node labels (KA = KA). Our strategy is to extend tree kernels to handle complex node labels. However, the kernel we describe is also able to handle continuous labels. We start by describing a simple extension of the discrete label kernel that is presented in Section III. We focus on the computational complexity of the resulting kernel and show that it is not competitive. In addition, in Section V we offer an efficient algorithm for calculating such kernels. We will focus on the ST kernel below, but similar extensions can easily be applied to other tree kernels. A few definitions need to be extended to the continuous domain to simplify presentation, we will also apply the notation and the following function definition to the tasks of the domain."}, {"heading": "V. EFFICIENT IMPLEMENTATION WITH FEATUREMAPS", "text": "In this section, we provide an efficient algorithm to calculate the ODDCLST kernels, which is considered in Section IV. (D = D = D). (D) The kernel was implemented in Python, so the algorithms are (simplified) snippets of the code. Algorithm 1 calculates the FeatureMap of a graph G. FeatureMap is a HashMap that displays all the correct subtrees that appear in the graph, taking only the discrete node labels into account. Each subtree encoded by a value x in the FeatureMap has a different HashMap that contains all the continued attributes of each subtree that are encoded by the same value x in the FeatureMap. We remember that the subtree properties do not take into account the continuous labels, so the same subtree may appear several times in the same graph. 1In the case of discrete domains, the grades cannot be considered to be redefined in the degrees of graphs."}, {"heading": "VI. COMPUTATION SPEEDUP WITH RBF KERNEL APPROXIMATION", "text": "When calculating the execution of algorithm 2, the most expensive step is the calculation of KA () for all pairs of vector labels associated with a sub-tree attribute (lines 7-12). To accelerate the core calculation, we propose to approximate this step. Recently, [14] a method was proposed for generating an (approximate) explicit attribute representation for the RBF kernel by Monte Carlo approximation of its Fourier transformation, which depends on a parameter D that specifies the dimensionality of the resulting approximation, the higher this number the better the approximation. Note that the resulting kernel, even if it is an approximation, is positively semi-definity.If we have this explicit representation, we can replace the RBF kernel with the original vector labels of the resulting approximation, where the higher the number the better the approximation is."}, {"heading": "VII. EXPERIMENTS", "text": "In this section, we compare the ODDCLST kernel presented in Section IV and its approximate version presented in Section VI with several modern cores for graphs with sequential labels. After describing the experimental setup in Section VII-A, we discuss the predictive power of the various cores in Section VII-B. In Section VII-C, we compare the computing times required for the various kernel calculations."}, {"heading": "A. Experimental setup", "text": "The results presented in this section relate to an SVM classifier in a process of nested 10-fold cross-validation, in which the kernel (and the classifier) parameters are validated on the basis of the training datasets; the experiments were repeated 10 times each (with different cross-validation splits), and the average accuracy of the results with standard deviation is reported; the proposed parameters of the kernel parameters were verified on the basis of the following sets: h = {0, 1, 2, 3}, \u03bb = {0.1, 0.3, 0.5, 0.7, 1,2}; for ODDDCLApprox, the D parameter was set to 1000 after preliminary experiments, because there is a good compromise between the computational requirements and the quality of the resulting approximation; note that for higher-rated D classes, one can expect to reproduce almost exactly the results of the ODCLST kernels."}, {"heading": "B. Experimental results", "text": "This year, it has never been as good as it has been this year."}, {"heading": "C. Computational times", "text": "Since the cores are implemented in different languages, we will consider the computing times given in [10] for comparison. We would like to point out that the times given in this section only need to be considered as orders of magnitude. Table II reports such computing times for the different cores. The proposed ODDCLST kernel is faster than the SP kernel, but it is significantly slower than GraphHopper. On the contrary, its approximate version ODDCLApprox is the fastest kernel, with a significant difference in terms of GraphHopper, while it is more accurate in all the data sets considered. Interestingly, GraphHopper shows the lowest runtimes in ENZYMES and SYNTHETIC due to the different substructures considered by the two cores, while the maximum amount of data in ODDCLST PROTEINS is the approximate data size that requires the least CLUC calculation basis that can be directly influenced by DDS."}, {"heading": "VIII. CONCLUSIONS", "text": "In this paper, we presented an extension of the continuous attributes of the ODD kernel framework for graphs. Furthermore, we investigated the performance of a continuous attribute graph kernel derived from the ST kernel for trees. Experimental results on reference data sets show that the resulting kernel is both quick to calculate and quite effective for all data sets studied, which is not the case for continuous attribute graph cores presented in the literature."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was supported by the University of Padua in the framework of the strategic project BIOINFOGEN."}], "references": [{"title": "Protein function prediction via graph kernels.", "author": ["K.M. Borgwardt", "C.S. Ong", "S. Sch\u00f6nauer", "S.V.N. Vishwanathan", "A.J. Smola", "H.-P. Kriegel"], "venue": "Bioinformatics (Oxford, England),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Adaptive Structured Pooling for Action Recognition", "author": ["S. Karaman", "L. Seidenari", "S. Ma"], "venue": "BMVA, pp. 1\u201312, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Shortest-Path Kernels on Graphs", "author": ["K. Borgwardt", "H.-P. Kriegel"], "venue": "ICDM, vol. 0. Los Alamitos, CA, USA: IEEE, 2005, pp. 74\u201381.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "A Tree-Based Kernel for Graphs", "author": ["G. Da San Martino", "N. Navarin", "A. Sperduti"], "venue": "Proceedings of the Twelfth SIAM International Conference on Data Mining, 2012, pp. 975\u2013986.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "On Graph Kernels: Hardness Results and Efficient Alternatives", "author": ["T. Gartner", "P. Flach", "S. Wrobel", "T. G\u00e4rtner"], "venue": "16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, ser. LNCS, vol. 2777. Springer Berlin Heidelberg, 2003, pp. 129\u2013143.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Fast neighborhood subgraph pairwise distance kernel", "author": ["F. Costa", "K. De Grave"], "venue": "ICML. Omnipress, 2010, pp. 255\u2013262.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Fast subtree kernels on graphs", "author": ["N. Shervashidze", "K. Borgwardt"], "venue": "NIPS, 2009, pp. 1660\u20131668.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Efficient Graph Kernels by Randomization", "author": ["M. Neumann", "N. Patricia", "R. Garnett", "K. Kersting"], "venue": "ECML PKDD, ser. LNCS, vol. 7523. Springer Berlin Heidelberg, 2012, pp. 378\u2013393.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Subgraph matching kernels for attributed graphs", "author": ["N. Kriege", "P. Mutzel"], "venue": "ICML, 2012, pp. 1015\u20131022.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Scalable kernels for graphs with continuous attributes", "author": ["A. Feragen", "N. Kasenburg", "J. Petersen", "M. de Bruijne", "K.M. Borgwardt"], "venue": "NIPS, 2013, pp. 216\u2013224.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Propagation kernels: efficient graph kernels from propagated information", "author": ["M. Neumann", "R. Garnett", "C. Bauckhage", "K. Kersting"], "venue": "Machine Learning, Jul. 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Graph invariant kernels", "author": ["F. Orsini", "P. Frasconi", "L.D. Raedt"], "venue": "IJCAI, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast Kernels for String and Tree Matching", "author": ["S.V.N. Vishwanathan", "A.J. Smola"], "venue": "NIPS, 2002, pp. 569\u2013576.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning", "author": ["A. Rahimi", "B. Recht"], "venue": "NIPS, 2009, pp. 1313\u20131320.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "BRENDA, the enzyme database: updates and major new developments.", "author": ["I. Schomburg", "A. Chang", "C. Ebeling", "M. Gremse", "C. Heldt", "G. Huhn", "D. Schomburg"], "venue": "Nucleic Acids Res.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Distinguishing Enzyme Structures from Non-enzymes Without Alignments", "author": ["P.D. Dobson", "A.J. Doig"], "venue": "Journal of Molecular Biology, vol. 330, no. 4, pp. 771\u2013783, 2003.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "However, in many application domains, such as bioinformatics and action recognition, non-discrete node attributes are available [1], [2].", "startOffset": 128, "endOffset": 131}, {"referenceID": 1, "context": "However, in many application domains, such as bioinformatics and action recognition, non-discrete node attributes are available [1], [2].", "startOffset": 133, "endOffset": 136}, {"referenceID": 0, "context": "Two nodes are connected whenever they are neighbors either in the amino acid sequence or in space [1].", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "however the resulting computational times become unfeasible, as in the case of [3].", "startOffset": 79, "endOffset": 82}, {"referenceID": 3, "context": "In this paper, we present a new kernel inspired by the graph kernel framework proposed in [4].", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "The features induced by the kernel are tree structures extracted from breadth-first visits of a graph (contrary to [1] an edge is only traversed once per visit).", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "Early works presented kernels that have to be computed in closed form, such as the random walk kernel [5] or the shortest path kernel [3].", "startOffset": 102, "endOffset": 105}, {"referenceID": 2, "context": "Early works presented kernels that have to be computed in closed form, such as the random walk kernel [5] or the shortest path kernel [3].", "startOffset": 134, "endOffset": 137}, {"referenceID": 3, "context": "State-of-the-art kernels use explicit feature mapping techniques [4], [6], [7], with computational complexities almost linear in the size of the graphs.", "startOffset": 65, "endOffset": 68}, {"referenceID": 5, "context": "State-of-the-art kernels use explicit feature mapping techniques [4], [6], [7], with computational complexities almost linear in the size of the graphs.", "startOffset": 70, "endOffset": 73}, {"referenceID": 6, "context": "State-of-the-art kernels use explicit feature mapping techniques [4], [6], [7], with computational complexities almost linear in the size of the graphs.", "startOffset": 75, "endOffset": 78}, {"referenceID": 7, "context": "adopt slower kernels or discretizing/ignoring the continuous attributes of the graphs, the latter approach was usually the preferred one [8].", "startOffset": 137, "endOffset": 140}, {"referenceID": 8, "context": "In [9] a kernel for graphs with continuous-valued labels has been presented.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "In [10] another more efficient kernel has been presented.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "Very recently, two kernel frameworks able to deal with continuous and vectorial labels have been proposed: in [11] authors propose to use Locality Sensitive Hashing to discretize continuous and vectorial labels, while in [12] a very general framework of graph kernels is proposed.", "startOffset": 110, "endOffset": 114}, {"referenceID": 11, "context": "Very recently, two kernel frameworks able to deal with continuous and vectorial labels have been proposed: in [11] authors propose to use Locality Sensitive Hashing to discretize continuous and vectorial labels, while in [12] a very general framework of graph kernels is proposed.", "startOffset": 221, "endOffset": 225}, {"referenceID": 3, "context": "In fact, in [4], [7] it is shown that tree-features can express a more suitable similarity measure for many tasks.", "startOffset": 12, "endOffset": 15}, {"referenceID": 6, "context": "In fact, in [4], [7] it is shown that tree-features can express a more suitable similarity measure for many tasks.", "startOffset": 17, "endOffset": 20}, {"referenceID": 3, "context": "The framework presented in [4] is especially interesting since it allows to easily define a kernel for graphs from a vast class of tree kernels, and it constitutes the starting point of our proposal.", "startOffset": 27, "endOffset": 30}, {"referenceID": 3, "context": "This section briefly recalls the procedure, described in [4], for extracting, given a graph, the tree structures which the kernel we propose is based on.", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "The decomposition we have defined ensures that isomorphic graphs are represented exactly by the same multiset of DAGs [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 0, "context": "\u03c0(chv[1])#\u03c0(chv[2]) .", "startOffset": 5, "endOffset": 8}, {"referenceID": 1, "context": "\u03c0(chv[1])#\u03c0(chv[2]) .", "startOffset": 15, "endOffset": 18}, {"referenceID": 3, "context": "The ordering function is defined in such a way to ensure that the swapping of nodes with the same \u03c0() value does not change the feature space representation of the examples [4].", "startOffset": 173, "endOffset": 176}, {"referenceID": 12, "context": "the paper is the Subtree Kernel (ST) [13], which counts the number of shared proper subtrees between the two input trees and has O(t log t) complexity (here t is the number of nodes of a tree).", "startOffset": 37, "endOffset": 41}, {"referenceID": 3, "context": "We recall that the tree visits can be limited to a depth h and that, consequently, the size of the tree visits is constant if we assume \u03c1 and h constant: in this case the ODD kernel with ST as tree kernel has complexity O(n log n) [4].", "startOffset": 231, "endOffset": 234}, {"referenceID": 12, "context": "Let us first recall the definition of the C() function of ST [13]:", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "The value of CST () for two subtrees encoded by the same hash value is CST (v1, v2) = \u03bb (v1)| [13], thus we only need to know the size of the subtree.", "startOffset": 94, "endOffset": 98}, {"referenceID": 3, "context": "Since the nodes are sorted in inverse topological order, the encoding of line 8 can be computed with a time complexity of O(\u03c1) [4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 13, "context": "Recently, [14] proposed a method to generate an (approximated) explicit feature space representation for the RBF kernel by Monte Carlo approximation of its Fourier transform.", "startOffset": 10, "endOffset": 14}, {"referenceID": 9, "context": "Following [10], the kernel matrices have been normalized.", "startOffset": 10, "endOffset": 14}, {"referenceID": 9, "context": "We tested our method on the (publicly available) datasets from [10]: ENZYMES, PROTEINS and SYNTHETIC.", "startOffset": 63, "endOffset": 67}, {"referenceID": 14, "context": "ENZYMES is a set of proteins from the BRENDA database [15].", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "Two nodes are connected whenever they are neighbors either in the amino acid sequence or in the 3D space of the protein tertiary structure [1].", "startOffset": 139, "endOffset": 142}, {"referenceID": 15, "context": "PROTEINS is the dataset from [16].", "startOffset": 29, "endOffset": 33}, {"referenceID": 9, "context": "SYNTHETIC is a dataset presented in [10].", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "In Table I we report the experimental results of the proposed ODDCLST kernel, its approximated version ODDCLApprox presented in Section VI, the base kernel ODDST , and the results from the paper [10], corrected according to the erratum.", "startOffset": 195, "endOffset": 199}, {"referenceID": 9, "context": "The reported kernels are: the GraphHopper kernel (GH) [10], the connected subgraph matching kernel (CSM) [9] and the shortest path kernel (SP) [3].", "startOffset": 54, "endOffset": 58}, {"referenceID": 8, "context": "The reported kernels are: the GraphHopper kernel (GH) [10], the connected subgraph matching kernel (CSM) [9] and the shortest path kernel (SP) [3].", "startOffset": 105, "endOffset": 108}, {"referenceID": 2, "context": "The reported kernels are: the GraphHopper kernel (GH) [10], the connected subgraph matching kernel (CSM) [9] and the shortest path kernel (SP) [3].", "startOffset": 143, "endOffset": 146}, {"referenceID": 6, "context": "For sake of comparison, the results of the Weisfeiler-Lehman kernel (WL) [7] and ODDST [4] kernels, that can deal only with discrete attributes, are reported too.", "startOffset": 73, "endOffset": 76}, {"referenceID": 3, "context": "For sake of comparison, the results of the Weisfeiler-Lehman kernel (WL) [7] and ODDST [4] kernels, that can deal only with discrete attributes, are reported too.", "startOffset": 87, "endOffset": 90}, {"referenceID": 9, "context": "Since the kernels are implemented in different languages, we considered for sake of comparison the computational times reported in [10].", "startOffset": 131, "endOffset": 135}, {"referenceID": 9, "context": "\u2217: THE TIMES REFERRING TO GH AND SP ARE REPORTED FROM [10]", "startOffset": 54, "endOffset": 58}], "year": 2017, "abstractText": "The availability of graph data with node attributes that can be either discrete or real-valued is constantly increasing. While existing kernel methods are effective techniques for dealing with graphs having discrete node labels, their adaptation to nondiscrete or continuous node attributes has been limited, mainly for computational issues. Recently, a few kernels especially tailored for this domain, have been proposed. In order to allieviate the computational problems, the size of the feature space of such kernels tend to be smaller than the ones of the kernels for discrete node attributes. However, such choice might have a negative impact on the predictive performance. In this paper, we propose a graph kernel for complex and continuous nodes\u2019 attributes, whose features are tree structures extracted from specific graph visits. Experimental results obtained on real-world datasets show that the (approximated version of the) proposed kernel is comparable with current state-of-the-art kernels in terms of classification accuracy while requiring shorter running times.", "creator": "LaTeX with hyperref package"}}}