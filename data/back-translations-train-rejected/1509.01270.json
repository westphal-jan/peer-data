{"id": "1509.01270", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Sep-2015", "title": "Machine Learning Methods to Analyze Arabidopsis Thaliana Plant Root Growth", "abstract": "One of the challenging problems in biology is to classify plants based on their reaction on genetic mutation. Arabidopsis Thaliana is a plant that is so interesting, because its genetic structure has some similarities with that of human beings. Biologists classify the type of this plant to mutated and not mutated (wild) types. Phenotypic analysis of these types is a time-consuming and costly effort by individuals. In this paper, we propose a modified feature extraction step by using velocity and acceleration of root growth. In the second step, for plant classification, we employed different Support Vector Machine (SVM) kernels and two hybrid systems of neural networks. Gated Negative Correlation Learning (GNCL) and Mixture of Negatively Correlated Experts (MNCE) are two ensemble methods based on complementary feature of classical classifiers; Mixture of Expert (ME) and Negative Correlation Learning (NCL). The hybrid systems conserve of advantages and decrease the effects of disadvantages of NCL and ME. Our Experimental shows that MNCE and GNCL improve the efficiency of classical classifiers, however, some SVM kernels function has better performance than classifiers based on neural network ensemble method. Moreover, kernels consume less time to obtain a classification rate.", "histories": [["v1", "Thu, 3 Sep 2015 20:22:43 GMT  (740kb)", "http://arxiv.org/abs/1509.01270v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hamidreza farhidzadeh"], "accepted": false, "id": "1509.01270"}, "pdf": {"name": "1509.01270.pdf", "metadata": {"source": "CRF", "title": "Machine Learning Methods to Analyze Arabidopsis Thaliana Plant Root Growth", "authors": ["*Hamidreza Farhidzadeh"], "emails": [], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "ANALYSIS OF MIXTURE OF EXPERT AND NEGATIVE CORRELATION LEARNING MODELS", "text": "In this section, the ME- and NCL-methods are examined and reviewed. METhe ME- method was also introduced by Jacobs et al. [9,10]. The authors investigated the use of different error functions in the learning process for expert networks in the ME-method. Jacobs proposed to make NN-experts in different distributions of the data space on site; as a result, the increased diversity among the experts led to improvements in the performance of this method. Various error functions were investigated with respect to a performance criterion and Jacobs then introduced a new error function based on the negative protocol probability of generating the desired output vector under the mixture of Gaussian models: (10), (21 exp (log2 j jj OygEwhere gEwhere gEwhere the proportional contribution of the expert j to the combined output vector and Oi and y are the actual and desired outputs of the i th NN-o-o-o-o-o-o-o-o-o-ratio o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-ratio, where the ratio ratio ratio-o-o-o-o-o-o-o-o-o-o ratio-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o ratio-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-"}, {"heading": "B. NCL", "text": "One of the disadvantages of such an approach is the loss of interactions between individual networks during the learning process. It is therefore possible that some of the independently designed individual networks contribute marginally to the overall ensembles. Liu and Yao [11] proposed the NCL method, which simultaneously and interactively trains NNs in the overall ensembles in their error functions through the correlation penalty terms. In NCL, the error function of the I. NN is expressed through the equation: (12), (21 2 iii POyE, where Oi and y are the actual and desired results of the I. NN, respectively. The first term in (3) is the empirical risk function of I. NN. The second term, Pi, is the correlation penalty function, which can be expressed through the correlation penalty condition."}, {"heading": "C. Comparison the strengths and weaknesses", "text": "In this part, we will compare the strengths and weaknesses of ME and NCL models. Deadline, we will look at the common features of these two models. Both ensemble methods form the basic NNs in a process of multiple communication and collaboration between experts at the same time. As already mentioned, different and specific functions of these models have characteristics that cause experts to learn partial problems or other aspects of the problem in a comparison and cooperation process, and finally the hybrid system learns the entire data space. In other words, the error functions of these methods exhibit characteristics that the base NNNs are generated with bias that exhibit a negative correlation by explicitly dividing the data space between experts [8]. Besides these similarities, there are some differences. The hybrid system consists of two important parts. In the first part, the formation of the base NNNs exhibits better efficiency than I do. The regularization term used in this method provides a convenient way to improve the bias-variance-coefficient-combination and thus to improve the biased-variance-combination."}, {"heading": "GATING NETWORK TO COMBINE NCL EXPERTS OUTPUTS", "text": "After complementing the characteristics of these two models, an integrated system can reserve strengths for points and reduce their weaknesses. Based on this idea, the proposed hybrid system [5] includes two stages of training: in the first stage NNNs are trained by NCL algorithm and in the second stage; gating network is used for the combination of NNNs resulting from permeable level. From another point of view, we can consider this method as an improved NCL method. In NCL, the error function can orient NNs to the training of different aspects or parts of the problem. NCL's local expertise should be considered in its combination method. By means of gating network, as a combination of NNNs output, this required group can provide NN features in the NCL method. In this method, after training NCL neural networks, in the next stage, the gating network is trained to model local knowledge and to combine them."}, {"heading": "INCORPORATION OF THE NCL TRAINING ALGORITHM INTO ME", "text": "The new error function takes the form of the equations (20) and (21), the explicit error function of the ME was achieved by adding the penalty term of NCL to the error function. The proposed method is called Mixture of Negative Correlated Experts (MNCE). Thus, the new error function takes the form of the equations (20) and (21), explicates it (20), () (ji ensjensii OOOOOP (21) The introduced penalty term, similar to NCL, leads to a nearly optimal balance in the diversity of trading structures."}, {"heading": "EXPERIMENTAL", "text": "In order to evaluate the results, we first define our data set. Then the approach to dimension reduction is the main component analysis. In the next step, we define our attribute vector and give it to various classifiers to classify our data set."}, {"heading": "A. Dataset", "text": "An extensive and indexed library of mutated T-DNA inputs leads to finding these operations using reverse genetics. If a mutation causes observable changes in the phenotype to provide evidence of deactivated gene function, reversed genetics can be efficient. However, many deactivated genes in Arabidopsis thaliana do not result in observable changes in the phenotype."}, {"heading": "B. Size of seeds", "text": "Seeds of Arabidopsis thaliana have been studied in sizes 522, 582, 300, 355. Seeds between 522 and 582 are found in small groups, and seeds between 300 and 355 are found in large groups. Seeds that are perpendicular between 2 and 4 days in special circumstances."}, {"heading": "C. Genetic Mutation", "text": "Plant seeds containing mutated T-DNA in the gene GLR.3.3 are provided by the Salk Association. Products used are Salk _ 040458 (glr3.3-1, mutated second axon) and Salk _ 066009 (glr3.3-2, mutated first antron) and the seeds are divided by the method identified in the permeable section."}, {"heading": "D. Genetic Mutation", "text": "As already discussed, data set contains groups in Table 1.It is necessary for classification that at least one wild type species places against mutated species. To this end, groups place against each other, which is demonstrated in Table 2.Each group contains some samples, which each sample contains 300 images. Resolution of each frame is 700 * 900 pixels, which can be shown by a 630,000-ordered pair, which means that each frame belongs to a 630,000 dimension. So the dimension of each sample is - 630,000 \u00d7 300 = 1890000000000already mentioned, the dimensions of these points are 630,000, that we can transform them into the 30-40 dimensions. It can be argued that the difference between two consecutive frames is very small. It means that the seed tip moves only a few pixels = 18900000000000000already mentioned, so that this difference is small even in low dimensions. As a result, this destination points of each frame arises a curve in space. This curve is a dynamic sequence of root growth."}, {"heading": "CONCLUSION", "text": "In this work, we have proposed a new approach to function extraction based on speed and acceleration of motion and developed a method based on NCL and ME and applicable to classification. We have used a gated-NCL and MNCE hybrid system, taking into account the weaknesses and strengths of NCL and ME models. NCL encourages experts through the \"divide and conquer\" principle, which takes into account different parts and aspects of the data space. In addition, we have used different types of SVM classifiers to compare their efficiency with each other and with other ensemble methods. According to the result, the MNCE hybrid system can achieve better performance than GNCL. Furthermore, the Gaussian kernel reduces the efficiency of SVM. Finally, the sigmoid kernel could achieve the best classification error rate between our classifiers. In addition, this hybrid system spends more time than the kernel SVM, as the division of the problem is likely to be used to resolve some partial problems of SVM and the subsequent integration of SVM to improve the result."}], "references": [{"title": "Support-Vector Networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Mach. Learn., vol. 20, pp. 273- 297, 1995.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "Improving combination method of NCL experts using gating network", "author": ["R. Ebrahimpour", "S. Arani", "S. Masoudnia"], "venue": "Neural Computing and Applications, pp. 1-7, 2011/12/01 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaptive mixtures of local experts", "author": ["R.A. Jacobs", "M.I. Jordan", "S.J. Nowlan", "G.E. Hinton"], "venue": "Neural Comput., vol. 3, pp. 79-87, 1991.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1991}, {"title": "On combining classifiers", "author": ["J. Kittler", "M. Hatef", "R.P.W. Duin", "J. Matas"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 20, pp. 226-239, 1998.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1998}, {"title": "Combining Pattern Classifiers: Methods and Algorithms: Wiley- Interscience", "author": ["L.I. Kuncheva"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Simultaneous training of negatively correlated neural networks in an ensemble", "author": ["Y. Liu", "X. Yao"], "venue": "Trans. Sys. Man Cyber. Part B, vol. 29, pp. 716-725, 1999.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1999}, {"title": "Incorporation of a Regularization Term to Control Negative Correlation in Mixture of Experts", "author": ["S. Masoudnia", "R. Ebrahimpour", "S. Arani"], "venue": "Neural Processing Letters, vol. 36, pp. 31- 47, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Kernel Methods for Pattern Analysis", "author": ["J. Shawe-Taylor", "N. Cristianini"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}], "referenceMentions": [{"referenceID": 5, "context": "In supervised learning classification issues, divide and conquer principle is implemented by separating data space to some sub-problems and attributing the experts to model each sub problems [7].", "startOffset": 191, "endOffset": 194}, {"referenceID": 4, "context": "RELATED WORKS Evans and Ishikawa [6] presented an algorithm to measure growth rate and swing rate of tip angle automatically and they implemented it by ADAPT 1 software.", "startOffset": 33, "endOffset": 36}, {"referenceID": 1, "context": "Dashti [3] undermined the significance of phenotypic traits that are implicit in patterns of dynamics in plant root response to sudden changes of its environmental conditions.", "startOffset": 7, "endOffset": 10}, {"referenceID": 2, "context": "Brook [4] differentiated plasticity of root plant in different conditions.", "startOffset": 6, "endOffset": 9}, {"referenceID": 7, "context": "[9,10].", "startOffset": 0, "endOffset": 6}, {"referenceID": 6, "context": "word, the error functions of these methods have characteristics that base NNs are produced with bias that possess negative correlation by dividing data space between experts explicitly [8].", "startOffset": 185, "endOffset": 188}, {"referenceID": 3, "context": "Based on this idea, the proposed hybrid system [5] contains two stages of training.", "startOffset": 47, "endOffset": 50}], "year": 2015, "abstractText": "AbstractOne of the challenging problems in biology is to classify plants based on their reaction on genetic mutation. Arabidopsis Thaliana is a plant that is so interesting, because its genetic structure has some similarities with that of human beings. Biologists classify the type of this plant to mutated and not mutated (wild) types. Phenotypic analysis of these types is a time-consuming and costly effort by individuals. In this paper, we propose a modified feature extraction step by using velocity and acceleration of root growth. In the second step, for plant classification, we employed different Support Vector Machine (SVM) kernels and two hybrid systems of neural networks. Gated Negative Correlation Learning (GNCL) and Mixture of Negatively Correlated Experts (MNCE) are two ensemble methods based on complementary feature of classical classifiers; Mixture of Expert (ME) and Negative Correlation Learning (NCL). The hybrid systems conserve of advantages and decrease the effects of disadvantages of NCL and ME. Our Experimental shows that MNCE and GNCL improve the efficiency of classical classifiers, however, some SVM kernels function has better performance than classifiers based on neural network ensemble method. Moreover, kernels consume less time to obtain a classification rate.", "creator": "Microsoft\u00ae Word 2010"}}}