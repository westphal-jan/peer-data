{"id": "1509.01288", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Sep-2015", "title": "Incremental Active Opinion Learning Over a Stream of Opinionated Documents", "abstract": "Applications that learn from opinionated documents, like tweets or product reviews, face two challenges. First, the opinionated documents constitute an evolving stream, where both the author's attitude and the vocabulary itself may change. Second, labels of documents are scarce and labels of words are unreliable, because the sentiment of a word depends on the (unknown) context in the author's mind. Most of the research on mining over opinionated streams focuses on the first aspect of the problem, whereas for the second a continuous supply of labels from the stream is assumed. Such an assumption though is utopian as the stream is infinite and the labeling cost is prohibitive. To this end, we investigate the potential of active stream learning algorithms that ask for labels on demand. Our proposed ACOSTREAM 1 approach works with limited labels: it uses an initial seed of labeled documents, occasionally requests additional labels for documents from the human expert and incrementally adapts to the underlying stream while exploiting the available labeled documents. In its core, ACOSTREAM consists of a MNB classifier coupled with \"sampling\" strategies for requesting class labels for new unlabeled documents. In the experiments, we evaluate the classifier performance over time by varying: (a) the class distribution of the opinionated stream, while assuming that the set of the words in the vocabulary is fixed but their polarities may change with the class distribution; and (b) the number of unknown words arriving at each moment, while the class polarity may also change. Our results show that active learning on a stream of opinionated documents, delivers good performance while requiring a small selection of labels", "histories": [["v1", "Thu, 3 Sep 2015 22:11:10 GMT  (380kb,D)", "http://arxiv.org/abs/1509.01288v1", "10 pages, 14 figures, conference: WISDOM (KDD'15)"]], "COMMENTS": "10 pages, 14 figures, conference: WISDOM (KDD'15)", "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.LG", "authors": ["max zimmermann", "eirini ntoutsi", "myra spiliopoulou"], "accepted": false, "id": "1509.01288"}, "pdf": {"name": "1509.01288.pdf", "metadata": {"source": "CRF", "title": "Incremental Active Opinion Learning Over a Stream of Opinionated Documents", "authors": ["Max Zimmermann", "Eirini Ntoutsi", "Myra Spiliopoulou"], "emails": ["max.zimmermann@sics.se", "ntoutsi@dbs.ifi.lmu.de", "myra@iti.cs.uni-"], "sections": [{"heading": null, "text": "Keywords opinion mining, active learning, stream mining1Source code is available in R at: https: / / www.dropbox. com / s / y2ptl486f4rvohx / acostream _ src.zip? dl = 0 2Datasets are available at: https: / / www.dropbox.com / s / gcpcyazp7fqentb / streams _ acostream.zip? dl = 0This paper was presented at the Fourth International Workshop on Issues of Sentiment Discovery and Opinion Mining (WISDOM 2015), held in connection with KDD '15 in Sydney on 10 August 2015. Copyright for this work lies with the authors."}, {"heading": "1. INTRODUCTION", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2. RELATED WORK", "text": "There are various active learning approaches provided in recent surveys such as that of a current model. In contrast, they differ in their heuristics to select the uncertainty for which the true label is requested. Garnett et al. [7] They use the most likely or pessimistic imitation texts that emanate from a current model. In contrast, Krempl et al. [10] The imitators are led by their probability or hypotheses to test the reliability of the imitators when they select the next instance. All these approaches follow the same framework and solve the classification with the new instance."}, {"heading": "3. ACTIVE OPINION STREAM LEARNING", "text": "We observe a growing collection of documents D, which form a stream that we monitor at different times t0, t1,..., ti,... Documents arrive at each ti. A document d, D is represented by the bag of words model, i.e. d = w1, w2, \u00b7 \u00b7 \u00b7, wn. Furthermore, we assume an initially designated seed quantity S from documents: For each d, S an expert has assigned a polarity designation c, C (C is the set of possible designations, e.g. positive, negative). We borrow the notation of the original seed quantity from our previous work proposed in [29]. As the flow progresses, the concept of words may change, i.e. a word used to express positive polarity could change its content relationship so that it is used to express negative thoughts. In addition, new words - hitherto unknown words - may appear as people's vocabulary to express their positive or negative opinions."}, {"heading": "3.1 ACOSTREAM Overview", "text": "An overview of our approach is presented in Algorithm 1. In short, it works as follows: The seed set S is used to first train a classifier. (S) The vocabulary consists of the words observed in S and their distribution in the positive, negative class. Note that these numbers are sufficient to approximate the class-related word probabilities and class probabilities in MNB. We employ the classifier to predict the label for each incoming new document d from the stream (line 4). Depending on the active learning strategy (see Section 3.3), we could request the true label c for d from an expert (line 7). If this is the case, we update the associated word class numbers and class numbers in the model."}, {"heading": "3.2 Building and Maintaining a Polarity Classifier Over Time", "text": "Based on the original seed quantity S-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V-V"}, {"heading": "3.3 Actively Selecting Documents to Acquire New Labels", "text": "In fact, it is so that it is a way in which one sees oneself in a position to surpass oneself. (...) In fact, it is so that one sees oneself in a position to surpass oneself. (...) In fact, it is so that one sees oneself in a position to surpass oneself. (...) In fact, it is so that one sees oneself in a position to surpass oneself. (...) In fact, it is so that one sees oneself in a position to surpass oneself. (...) In fact, it is so that one sees oneself in a position to surpass oneself. (...) In fact, it is so that one sees oneself in the world, and in the world to surpass oneself. (...) It is so that one sees oneself in the world, in the world of the world, and in the world. (...) It is as if one is in the world, in the world, in the world, in the world, in the world, the world, in the world, in the world. (...) In fact, it is so that one can surpass oneself. (...) It is so that one is as if one is able to surpass oneself in the world, in the world in the world, in the world in the world, in the world in the world in the world, in the world in the world in the world. (...) It is as if one is as if one is in the world in the world in the world in the world, the world, the world, the world in the world, in the world in the world, in the world in the world, in the world, in the world in the (...)."}, {"heading": "4. EXPERIMENTS", "text": "To evaluate ACOSTREAM, we are experimenting with two real-world datasets of idiosyncratic documents (product reviews and tweets); the original streams have been modified to test the performance of ACOSTREAM in extreme and less extreme cases; for a detailed description of the datasets, see Section 4.1); and we have compared our ACOSTREAM with several baselines presented in Section 4.2; the results of our experiments are presented in Section 4.3."}, {"heading": "4.1 Datasets", "text": "In fact, the fact is that most of them will be able to show themselves that they are able to compete, that they are able to compete, and that they are able to compete, \"he said."}, {"heading": "100 resp. 5.000", "text": "The resulting reordering of the original streams also entails changes in the polarity of the words, i.e. the distribution of the word class changes over time. Figure 3 shows the word distribution of the words \"best\" on StreamJi and \"tomorrow\" on TwitterSentiment as a cumulative ratio of positive (green) and negative (red) documents: The distribution of both words changes over time, e.g. for word \"tomorrow,\" the ratio of negative documents changes greatly, as for example for document 13,800 only negative documents are shown followed by a majority of positive documents. 4.1.2 Solid vocabulary The scenario in which new words emerge over time is an extreme one; although it is quite realistic in learning polarity over streams. To apply our approach to a less extreme scenario, we conduct experiments on streams that do not have any new words over time, i.e. the seed contains all the words of the stream."}, {"heading": "4.2 Learning methods and quality measures", "text": "In the following, we outline the approaches we have used to compare ACOSTREAM. They all use Naive Bayes as classifiers, but differ in the documents they use for customization. \u2022 Incremental MNB: The classifier is updated step by step with each incoming instance, based on the true labels of the instances. This approach assumes 100% availability of true labels. \u2022 Random: The random sampling strategy randomly identifies the incoming instances, rather than actively deciding on the relevance of the label. For each incoming instance, the true label is requested with a probability B, with B being the budget [32]. We change the budget in our experiments under 0.3 and 0.6, e.g. 30% of the documents from the labeling system are asked for the true value."}, {"heading": "4.3 Performance evaluation", "text": "This year it is more than ever before in the history of the city."}, {"heading": "5. CONCLUSION", "text": "Learning polarity in an evolving stream is a challenging task, as the stream is subject to concept changes; existing words may change mood over time, for example due to a different context, but new words may also occur to express opinions. Another challenge for a stream polarity learner is the scarcity of class names, provided the manual labeling of the (infinite) stream is unrealistic. Responding to these challenges requires adapting the model to the underlying stream population based on only a few examples given. In this paper, we proposed our active stream learning framework ACOSTREAM for gradually updating a polarity learner based on actively acquired documents. Our results show that active labeling pays off with two sampling strategies, gaining information and uncertainty. We compare our method with a traditional active learning approach (random sampling), a step-by-step approach that requires no adapted document and one adapted method."}, {"heading": "6. ACKNOWLEDGMENT", "text": "Max Zimmermann's work was carried out during an ERCIM \"Alain Bensoussan\" Fellowship Programme."}, {"heading": "7. REFERENCES", "text": "[1] A. Bifet and E. Frank. Sentiment knowledge discoveryin twitter streaming data. In Discovery Science, 2010. [2] E. Boiy and M. francine Moens. A machine learning approach to sentiment analysis in multilingual web texts. Information Retrieval, pp. 526-558, 2009. [3] P. H. Calais Guerra, A. Veloso, W. Meira, Jr., and V. Almeida. From bias to opinion: A transfer-learning approach to real-time sentiment analysis. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \"11, pp. 150-158, New York, NY, USA, 2011. E. Cambria, B. Schuller, Y. Xia, and C. Havasi. New avenues in opinion mining and sentiment."}], "references": [{"title": "Sentiment knowledge discovery in twitter streaming data", "author": ["A. Bifet", "E. Frank"], "venue": "Discovery Science,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "A machine learning approach to sentiment analysis in multilingual web texts", "author": ["E. Boiy", "M. francine Moens"], "venue": "Information Retrieval,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "From bias to opinion: A transfer-learning approach to real-time sentiment analysis", "author": ["P.H. Calais Guerra", "A. Veloso", "W. Meira", "Jr.", "V. Almeida"], "venue": "In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "New avenues in opinion mining and sentiment analysis", "author": ["E. Cambria", "B. Schuller", "Y. Xia", "C. Havasi"], "venue": "IEEE Intelligent Systems, 28(2):15\u201321, Mar.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey on instance selection for active learning", "author": ["Y. Fu", "X. Zhu", "B. Li"], "venue": "Knowl. Inf. Syst., 35(2):249\u2013283,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Recurrent concepts in data streams classification", "author": ["J. Gama", "P. Kosina"], "venue": "Knowl. Inf. Syst., 40(3):489\u2013507, Sept.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Bayesian optimal active search and surveying", "author": ["R. Garnett", "Y. Krishnamurthy", "X. Xiong", "J. Schneider", "R.P. Mann"], "venue": "J. Langrod and J. Pineau, editors, Proceedings of the 29th International Conference on Machine Learning (ICML 2012), pages 1239\u2013\u20131246, Madison, WI, USA,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Twitter sentiment classification using distant supervision", "author": ["A. Go", "R. Bhayani", "L. Huang"], "venue": "Processing, pages 1\u20136,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Etree: Effective and efficient event modeling for real-time online social media networks", "author": ["H. Gu", "X. Xie", "Q. Lv", "Y. Ruan", "L. Shang"], "venue": "Proceedings of the 2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology - Volume 01, WI-IAT \u201911, pages 300\u2013307, Washington, DC, USA,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Query by transduction", "author": ["S.-S. Ho", "H. Wechsler"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., 30(9):1557\u20131571, Sept.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Active learning for sentiment analysis on data streams: Methodology and workflow implementation in the clowdflows platform", "author": ["J. Kranjc", "J. Smailovi\u0107", "V. Podpe\u010dan", "M. Gr\u010dar", "M. \u017dnidar\u0161i\u010d", "N. Lavra\u010d"], "venue": "Information Processing & Management,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Probabilistic active learning: Towards combining versatility, optimality and efficiency", "author": ["G. Krempl", "D. Kottke", "M. Spiliopoulou"], "venue": "Discovery Science - 17th International Conference, DS 2014, Bled, Slovenia, October 8-10, 2014. Proceedings, pages 168\u2013179,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "A multi-resolution learning approach to tracking concept drift and recurrent concepts", "author": ["M. Lazarescu"], "venue": "H. Gamboa and A. L. N. Fred, editors, PRIS, page 52. INSTICC Press,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "A sequential algorithm for training text classifiers", "author": ["D.D. Lewis", "W.A. Gale"], "venue": "Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201994, pages 3\u201312, New York, NY, USA,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1994}, {"title": "Economically-efficient sentiment stream analysis", "author": ["R. Lourenco Jr.", "A. Veloso", "A. Pereira", "W. Meira Jr.", "R. Ferreira", "S. Parthasarathy"], "venue": "In Proceedings of the 37th International ACM SIGIR Conference on Research; Development in Information Retrieval,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Facing the reality of data stream classification: coping with scarcity of labeled data", "author": ["M.M. Masud", "C. Woolam", "J. Gao", "L. Khan", "J. Han", "K.W. Hamlen", "N.C. Oza"], "venue": "Knowl. Inf. Syst., 33(1):213\u2013244,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Twittermonitor: Trend detection over the twitter stream", "author": ["M. Mathioudakis", "N. Koudas"], "venue": "Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201910, pages 1155\u20131158, New York, NY, USA,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of event models for naive bayes text classification", "author": ["A. McCallum", "K. Nigam"], "venue": "IN AAAI-98 WORKSHOP ON LEARNING FOR TEXT CATEGORIZATION, pages 41\u201348. AAAI Press,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "Machine Learning", "author": ["T.M. Mitchell"], "venue": "McGraw-Hill, Inc., New York, NY, USA, 1 edition,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1997}, {"title": "Foundations of Machine Learning", "author": ["M. Mohri", "A. Rostamizadeh", "A. Talwalkar"], "venue": "The MIT Press,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "Computer Sciences Technical Report 1648, University of Wisconsin\u2013Madison,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Stream-based active learning for sentiment analysis in the financial domain", "author": ["J. Smailovi\u010d", "M. Gr\u010dar", "N. Lavra\u010d", "M. \u017dnidar\u0161i\u010d"], "venue": "Information Sciences, Apr.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["R. Socher", "A. Perelygin", "J.Y. Wu", "J. Chuang", "C.D. Manning", "A.Y. Ng", "C.P. Potts"], "venue": "EMNLP,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews", "author": ["P.D. Turney"], "venue": "Proc. of the 40th Annual Meeting on Association for Computational Linguistics, ACL \u201902, pages 417\u2013424, Stroudsburg, PA, USA,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Machine Learning and  Knowledge Discovery in Databases - European Conference", "author": ["S. Wagner", "M. Zimmermann", "E. Ntoutsi", "M. Spiliopoulou", "editors"], "venue": "ECML PKDD 2015,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Entity-based classification of twitter messages", "author": ["S.R. Yerva", "Z. Mikl\u00f3s", "K. Aberer"], "venue": "IJCSA, 9(1):88\u2013115,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences", "author": ["H. Yu", "V. Hatzivassiloglou"], "venue": "Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, EMNLP \u201903, pages 129\u2013136, Stroudsburg, PA, USA,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2003}, {"title": "Domain-assisted product aspect hierarchy generation: Towards hierarchical organization of unstructured consumer reviews", "author": ["J. Yu", "Z.-J. Zha", "M. Wang", "K. Wang", "T.-S. Chua"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP \u201911, pages 140\u2013150, Stroudsburg, PA, USA,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaptive semi supervised opinion classifier with forgetting mechanism", "author": ["M. Zimmermann", "E. Ntoutsi", "M. Spiliopoulou"], "venue": "Proc. of the 29th Annual ACM Symposium on Applied Computing, SAC\u201914. ACM,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "A semi-supervised self-adaptive classifier over opinionated streams", "author": ["M. Zimmermann", "E. Ntoutsi", "M. Spiliopoulou"], "venue": "2014 IEEE International Conference on Data Mining Workshops, ICDM Workshops 2014, Shenzhen, China, December 14, 2014, pages 425\u2013432,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Discovering and monitoring product features and the opinions on them with OPINSTREAM", "author": ["M. Zimmermann", "E. Ntoutsi", "M. Spiliopoulou"], "venue": "Neurocomputing, 150:318\u2013330,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Active learning with evolving streaming data", "author": ["I. Zliobaite", "A. Bifet", "B. Pfahringer", "G. Holmes"], "venue": "Proc. of ECML PKDD 2011, volume 6913 of LNCS. Springer-Verlag,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 3, "context": "Blogs, social networks and microblogging are the common services to pose experiences [4].", "startOffset": 85, "endOffset": 88}, {"referenceID": 15, "context": "Moreover, polarity learning on a stream of documents is driven by scarcity of labeled data, since up to date labeled reviews or tweets are not available \u2013 it is impractical to expect that a human expert inspects and labels arriving reviews or tweets on sentiment, especially in an infinite data stream scenario [16].", "startOffset": 311, "endOffset": 315}, {"referenceID": 19, "context": "According to Mohri [20], the goal of active learning is to achieve a performance comparable to the standard supervised learning scenario, but with fewer labeled examples.", "startOffset": 19, "endOffset": 23}, {"referenceID": 14, "context": "Most conventional polarity stream mining algorithms, including active learning variants address drift of the document polarity model but assume that the vocabulary is fixed and known in advance [15, 3].", "startOffset": 194, "endOffset": 201}, {"referenceID": 2, "context": "Most conventional polarity stream mining algorithms, including active learning variants address drift of the document polarity model but assume that the vocabulary is fixed and known in advance [15, 3].", "startOffset": 194, "endOffset": 201}, {"referenceID": 30, "context": "In our earlier work [31, 25], we proposed polarity stream learning algorithms that adapt to an evolving vocabulary in the stream.", "startOffset": 20, "endOffset": 28}, {"referenceID": 24, "context": "In our earlier work [31, 25], we proposed polarity stream learning algorithms that adapt to an evolving vocabulary in the stream.", "startOffset": 20, "endOffset": 28}, {"referenceID": 24, "context": "However, in [25] we assume that fresh docuar X iv :1 50 9.", "startOffset": 12, "endOffset": 16}, {"referenceID": 30, "context": "ment labels are made available at each moment, while in [31] we assume solely an initial seed of labeled documents and then we adapt the model in a semi-supervised way.", "startOffset": 56, "endOffset": 60}, {"referenceID": 4, "context": "There exist various active learning approaches, provided in recent surveys such as [5, 21].", "startOffset": 83, "endOffset": 90}, {"referenceID": 20, "context": "There exist various active learning approaches, provided in recent surveys such as [5, 21].", "startOffset": 83, "endOffset": 90}, {"referenceID": 6, "context": "[7] use the most likely or the most pessimistic posterior P (c|d) made by a current model.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[12] and Ho et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] weight the posteriors by their likelihood resp.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Methods that trace recurring concepts [6, 13] and those that monitor context change [17, 9] can trace the association of a word to a label, but only for a limited number of existing contexts, respectively recurring concepts, and for a fixed vocabulary.", "startOffset": 38, "endOffset": 45}, {"referenceID": 12, "context": "Methods that trace recurring concepts [6, 13] and those that monitor context change [17, 9] can trace the association of a word to a label, but only for a limited number of existing contexts, respectively recurring concepts, and for a fixed vocabulary.", "startOffset": 38, "endOffset": 45}, {"referenceID": 16, "context": "Methods that trace recurring concepts [6, 13] and those that monitor context change [17, 9] can trace the association of a word to a label, but only for a limited number of existing contexts, respectively recurring concepts, and for a fixed vocabulary.", "startOffset": 84, "endOffset": 91}, {"referenceID": 8, "context": "Methods that trace recurring concepts [6, 13] and those that monitor context change [17, 9] can trace the association of a word to a label, but only for a limited number of existing contexts, respectively recurring concepts, and for a fixed vocabulary.", "startOffset": 84, "endOffset": 91}, {"referenceID": 31, "context": "[32] propose two sampling strategies which are flexible towards a growing collection as well as considering concept change.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] test uncertainty and relevance 3 sampling with different classifiers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 25, "context": "[26] propose an active stream learning based classifier for classifying tweets into relevant or irrelevant for a given company.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Relevance sampling regards the labeling of those examples which are most likely to be class members [14].", "startOffset": 100, "endOffset": 104}, {"referenceID": 10, "context": "[11] present an active learning framework for selecting the most suitable tweets w.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Similarly [22] contribute an active learning approach distinguishing opinionated (positive and negative) from non-opinionated (neutral) tweets in finance twitter data streams.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "[23] as the contribution of our work is towards active learning strategies for polarity classification rather than pure polarity classification.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "We borrow the notation of initial seed set from our previous work proposed in [29].", "startOffset": 78, "endOffset": 82}, {"referenceID": 17, "context": "It is very fast for induction, robust to irrelevant attributes, while providing good prediction performance [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 18, "context": "The usage of the information gain is motivated by the attribute selection measures used in decision trees [19] and our previous work [30].", "startOffset": 106, "endOffset": 110}, {"referenceID": 29, "context": "The usage of the information gain is motivated by the attribute selection measures used in decision trees [19] and our previous work [30].", "startOffset": 133, "endOffset": 137}, {"referenceID": 20, "context": "for which the certainty is below some fixed threshold \u03b1 [21].", "startOffset": 56, "endOffset": 60}, {"referenceID": 27, "context": "[28] which contains data crawled from cnet.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "More details on the dataset and our preprocessing are also provided in our previous work [30].", "startOffset": 89, "endOffset": 93}, {"referenceID": 7, "context": "Stream TwitterSentiment, first introduced in [8], was collected by querying the (non-streaming) Twitter API for mes-", "startOffset": 45, "endOffset": 48}, {"referenceID": 23, "context": "In StreamJi we focused only on adjectives and adverbs for sentiment analysis since, according to [24, 27], these words bear the actual opinion of the author; similar observation were shown in [30].", "startOffset": 97, "endOffset": 105}, {"referenceID": 26, "context": "In StreamJi we focused only on adjectives and adverbs for sentiment analysis since, according to [24, 27], these words bear the actual opinion of the author; similar observation were shown in [30].", "startOffset": 97, "endOffset": 105}, {"referenceID": 29, "context": "In StreamJi we focused only on adjectives and adverbs for sentiment analysis since, according to [24, 27], these words bear the actual opinion of the author; similar observation were shown in [30].", "startOffset": 192, "endOffset": 196}, {"referenceID": 7, "context": "Stream TwitterSentiment comes with nouns and verbs as stated in [8].", "startOffset": 64, "endOffset": 67}, {"referenceID": 29, "context": "The ordering was done as in our previous work [30].", "startOffset": 46, "endOffset": 50}, {"referenceID": 31, "context": "For every incoming instance the true label is requested with a probability B, where B is the budget [32].", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "To evaluate the quality of our classifiers, we use the kappa statistic, which normalizes the classifier\u2019s accuracy by the accuracy of a chance classifier: k = p0\u2212pc 1\u2212pc [1].", "startOffset": 170, "endOffset": 173}, {"referenceID": 31, "context": "As we deal with an evolving stream of documents a fixed budget of true labels cannot be utilized which is normally applied when comparing across different sampling strategies [32].", "startOffset": 175, "endOffset": 179}], "year": 2015, "abstractText": "Applications that learn from opinionated documents, like tweets or product reviews, face two challenges. First, the opinionated documents constitute an evolving stream, where both the authors\u2019s attitude and the vocabulary itself may change. Second, labels of documents are scarce and labels of words are unreliable, because the sentiment of a word depends on the (unknown) context in the author\u2019s mind. Most of the research on mining over opinionated streams focuses on the first aspect of the problem, whereas for the second a continuous supply of labels from the stream is assumed. Such an assumption though is utopian as the stream is infinite and the labeling cost is prohibitive. To this end, we investigate the potential of active stream learning algorithms that ask for labels on demand. Our proposed ACOSTREAM approach works with limited labels: it uses an initial seed of labeled documents, occasionally requests additional labels for documents from the human expert and incrementally adapts to the underlying stream while exploiting the available labeled documents. In its core, ACOSTREAM consists of a MNB classifier coupled with \u201csampling\u201d strategies for requesting class labels for new unlabeled documents. In the experiments, we evaluate the classifier performance over time by varying: (a) the class distribution of the opinionated stream, while assuming that the set of the words in the vocabulary is fixed but their polarities may change with the class distribution; and (b) the number of unknown words arriving at each moment, while the class polarity may also change. Our results show that active learning on a stream of opinionated documents, delivers good performance while requiring a small selection of labels.", "creator": "LaTeX with hyperref package"}}}