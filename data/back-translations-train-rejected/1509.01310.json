{"id": "1509.01310", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Sep-2015", "title": "The influence of Chunking on Dependency Crossing and Distance", "abstract": "This paper hypothesizes that chunking plays important role in reducing dependency distance and dependency crossings. Computer simulations, when compared with natural languages,show that chunking reduces mean dependency distance (MDD) of a linear sequence of nodes (constrained by continuity or projectivity) to that of natural languages. More interestingly, chunking alone brings about less dependency crossings as well, though having failed to reduce them, to such rarity as found in human languages. These results suggest that chunking may play a vital role in the minimization of dependency distance, and a somewhat contributing role in the rarity of dependency crossing. In addition, the results point to a possibility that the rarity of dependency crossings is not a mere side-effect of minimization of dependency distance, but a linguistic phenomenon with its own motivations.", "histories": [["v1", "Thu, 3 Sep 2015 23:57:46 GMT  (474kb)", "http://arxiv.org/abs/1509.01310v1", "6 figures"]], "COMMENTS": "6 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["qian lu", "chunshan xu", "haitao liu"], "accepted": false, "id": "1509.01310"}, "pdf": {"name": "1509.01310.pdf", "metadata": {"source": "CRF", "title": "The influence of Chunking on Dependency Crossing and Distance", "authors": ["QIAN LU", "CHUNSHAN XU", "HAITAO LIU"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of them will be able to play by the rules that they have established in recent years, and they will be able to play by the rules that they have set themselves."}], "references": [{"title": "Course in General Linguistics", "author": ["SAUSSURE", "F. DE"], "venue": "(Peter Owen,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1960}, {"title": "An introduction to word grammar (Cambridge", "author": ["R. HUDSON"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Dependency syntax: theory and practice (SUNY, Albany", "author": ["I. MEL'\u010cUK"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1988}, {"title": "Human Behavior and the Principle of Least Effort", "author": ["G. ZIPF"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1949}, {"title": "Foundations of language (Oxford", "author": ["R. JACKENDOFF"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Dependency Grammar: from theory to practice", "author": ["H. LIU"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "\u2013 Language used in communication is invariably presented linearly, one unit after another, which is regarded as one of its fundamental property [1].", "startOffset": 144, "endOffset": 147}, {"referenceID": 1, "context": "there is always a sytactic tree structure underlying a onedimensional linear sentence, a structure underpinning both the production and the comprehension of this sentence [2,3].", "startOffset": 171, "endOffset": 176}, {"referenceID": 2, "context": "there is always a sytactic tree structure underlying a onedimensional linear sentence, a structure underpinning both the production and the comprehension of this sentence [2,3].", "startOffset": 171, "endOffset": 176}, {"referenceID": 1, "context": "In terms of dependency grammar, the structure of a sentence can be visualized as a hierarchical dependency tree, whose nodes (vertices) are words, linked to one another by directed edges (dependency relations) [2,3].", "startOffset": 210, "endOffset": 215}, {"referenceID": 2, "context": "In terms of dependency grammar, the structure of a sentence can be visualized as a hierarchical dependency tree, whose nodes (vertices) are words, linked to one another by directed edges (dependency relations) [2,3].", "startOffset": 210, "endOffset": 215}, {"referenceID": 3, "context": "the principle of least effort [17].", "startOffset": 30, "endOffset": 34}, {"referenceID": 4, "context": "one defining characteristic of human languages is duality [18], that is, smaller units at lower level combine to form bigger units at higher level.", "startOffset": 58, "endOffset": 62}, {"referenceID": 1, "context": "\u2013 Dependency grammar holds words as the fundamental syntactic units, linked via dependency relations into complete syntactic constructions [2, 3].", "startOffset": 139, "endOffset": 145}, {"referenceID": 2, "context": "\u2013 Dependency grammar holds words as the fundamental syntactic units, linked via dependency relations into complete syntactic constructions [2, 3].", "startOffset": 139, "endOffset": 145}, {"referenceID": 5, "context": "according to the basic principle of dependency grammar, should be a connected tree with one single root node [21].", "startOffset": 109, "endOffset": 113}, {"referenceID": 1, "context": "tree[2,3]; chunk is defined as the segment composed of a governor and its dependents, and, if any, these dependents\u2019 dependents.", "startOffset": 4, "endOffset": 9}, {"referenceID": 2, "context": "tree[2,3]; chunk is defined as the segment composed of a governor and its dependents, and, if any, these dependents\u2019 dependents.", "startOffset": 4, "endOffset": 9}, {"referenceID": 0, "context": "However if these sentences are chunked with the size interval [1, 23], the", "startOffset": 62, "endOffset": 69}], "year": 2015, "abstractText": "This paper hypothesizes that chunking plays important role in reducing dependency distance and dependency crossings. Computer simulations, when compared with natural languages, show that chunking reduces mean dependency distance (MDD) of a linear sequence of nodes (constrained by continuity or projectivity) to that of natural languages. More interestingly, chunking alone brings about less dependency crossings as well, though having failed to reduce them, to such rarity as found in human languages. These results suggest that chunking may play a vital role in the minimization of dependency distance, and a somewhat contributing role in the rarity of dependency crossing. In addition, the results point to a possibility that the rarity of dependency crossings is not a mere side-effect of minimization of dependency distance, but a linguistic phenomenon with its own motivations. Introduction. \u2013 Language used in communication is invariably presented linearly, one unit after another, which is regarded as one of its fundamental property [1]. However, there is always a sytactic tree structure underlying a onedimensional linear sentence, a structure underpinning both the production and the comprehension of this sentence [2,3]. Therefore, language processing consists, to a considerable degree, in the transformation between the syntactic tree structure and the one-dimensional linear arrangement. What properties can be found in the tree structure of language? What mechanisms constrain the transformation of tree structure into linear structure? The answers to these questions, which may well require researches based on statistical physics and computer simulation, probably will shed much light on how human language operates. In terms of dependency grammar, the structure of a sentence can be visualized as a hierarchical dependency tree, whose nodes (vertices) are words, linked to one another by directed edges (dependency relations) [2,3]. Such a hierarchical tree must be ultimately arranged into a linear sequence, for the purpose of spoken and written communication. So far, researches have repeatedly observed two phenomena in the linear realization of hierarchical dependency structure: the minimization of dependency distance (the number of intervening words) between two syntactically related words [4-13], and the rarity of crossing dependency relations [14,15]. Liu [5] has compared dependency distance of 20 natural languages with that of two different random languages, and pointed out that dependency distance minimization seems to be universal in human languages. Ferrer-i-Cancho has theoretically analyzed these [8,9]. A recent study based on 37 languages has obtained similar findings[11]. Since dependency distance is held as cognitively related to language processing load [16], the minimization of dependency distance is probably a result of the principle of least effort [17]. In addition, it is argued that that the rarity of crossing dependencies is simply a by-product of the pressure to minimize dependency distance and cognitive cost in language processing, having little to do with the syntax of the language [7-10]. Similarly, some studies find that dependency distance will significantly increase if dependency crossings are permitted, and suggests that reducing dependency crossings is probably an important means to restrain dependency distance [4,5]. Dependency distance and crossings are closely related, and in human languages both seem to be subject to minimization. Ferrer-i-Cancho [9,10] has theoretically proven that, for sufficiently short dependency lengths, the probability that two edges cross decreases as their length decreases. However, Liu has found that projective random language (i.e. without any crossing dependency) has significantly longer mean dependency distance than natural langauage [4,5]. Therefore,", "creator": "Acrobat PDFMaker 10.1 for Word"}}}