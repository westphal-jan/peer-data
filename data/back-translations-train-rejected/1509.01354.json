{"id": "1509.01354", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2015", "title": "CNN Based Hashing for Image Retrieval", "abstract": "Along with data on the web increasing dramatically, hashing is becoming more and more popular as a method of approximate nearest neighbor search. Previous supervised hashing methods utilized similarity/dissimilarity matrix to get semantic information. But the matrix is not easy to construct for a new dataset. Rather than to reconstruct the matrix, we proposed a straightforward CNN-based hashing method, i.e. binarilizing the activations of a fully connected layer with threshold 0 and taking the binary result as hash codes. This method achieved the best performance on CIFAR-10 and was comparable with the state-of-the-art on MNIST. And our experiments on CIFAR-10 suggested that the signs of activations may carry more information than the relative values of activations between samples, and that the co-adaption between feature extractor and hash functions is important for hashing.", "histories": [["v1", "Fri, 4 Sep 2015 07:08:44 GMT  (3761kb,D)", "http://arxiv.org/abs/1509.01354v1", "16 pages, 6 figures"]], "COMMENTS": "16 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["jinma guo", "jianmin li"], "accepted": false, "id": "1509.01354"}, "pdf": {"name": "1509.01354.pdf", "metadata": {"source": "CRF", "title": "CNN Based Hashing for Image Retrieval", "authors": ["Jinma Guo", "Jianmin Li"], "emails": [], "sections": [{"heading": null, "text": "Keywords: Convolutional Neural Network, Hashing, Image Retrieval"}, {"heading": "1 Introduction", "text": "In fact, the number of people working for the rights of women and men has increased sharply in recent years, the number of people working for the rights of men and women has increased sharply in recent years, the number of people working for the rights of women and men has doubled in the last ten years, the number of people working for the rights of women and men has doubled in the last ten years, the number of people working for the rights of men and women has doubled in the last ten years, the number of people working for the rights of women and men has doubled, and the number of people working for the rights of women and men has doubled."}, {"heading": "2 Related Work", "text": "In the following sections, we will briefly discuss hashtags and CNN about literature."}, {"heading": "2.1 Hashing Methods", "text": "This year it is more than ever before."}, {"heading": "2.2 Convolutional Neural Network", "text": "Their remarkable achievements in the fields of object recognition [19] [28], recognition [28], image analysis [9] and video classification [16] have greatly narrowed the gap between machine and human vision. CNN [22] is a limited network of neurons whose input factors lie on two-dimensional levels. Inspired by the human visual system, the neurons in the hidden layers of CNN take inputs from a local region of the previous layer and are tiled in relation to their input region."}, {"heading": "2.3 Hashing with CNN", "text": "Similar to [18], CNNH / CNNH + [34] takes raw image data as input, but the latter two divide the learning process into two different stages. In the first stage, the similarity / dissimilarity matrix S is decomposed into a product S = 1qHH T, with the i-th line in H being the target binary codes for the i-th training image. In the second stage, the raw image pixels, the pregenerated binary codes H (CNNH + together with their uniform binary code Y) are transferred to a CNN whose goal is to minimize the error between the output and the target binary vector concatenated by H and Y. However, the decomposition stage would cause additional errors. For example, the sum of square errors (SSE) to reconstruct the 5000-by 5000-by-by-5000 similarity matrix with 48-bit hash codes concatenated by gradient descent in [34] would then cause additional errors. For example, the sum of square errors (SSE) for the reconstruction of the 5000-by 48-bit hash codes concatenated by H and Y would be divided by H and Y."}, {"heading": "3 Methodology", "text": "In fact, it is the case that most people are able to survive on their own if they go into another world in which they are not able to integrate. \"(S. S. S. S. S. S. S. S.)\" It is not as if. \"(S. S. S. S. S. S. S.)\" It is as if. \"(S. S. S. S. S. S. S.)\" It is not as if. \"(S. S. S. S. S. S. S.).\" (S. S. S. S.). \"(S. S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.) (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.) (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S. (S.). (S.). (S.). (S. (S.). (S.). (S.). (S. (S.). (S.). (S. (S.). (S.). (S.). (S. (S.). (S.). (S.). (S. (S.). (S.). (S. (S.). (S.). (S.). (S.). (S.). (S.). (S.). (S. (S. (S.). (S. (S.). (S.). (S.). (S.)"}, {"heading": "4 Experiments", "text": "The description of an architecture is given in the following way: 1x28x28-32C5P2-MP3S2-32C5P0-H32-H10 represents a CNN with 1 channel input of 28 x 28 pixels, a conventional layer of 32 filters having a size of 5 x 5 and 2 paddings around the input cards, a maximum pooling layer of 3 x 2, a 32 filter layer having a conventional layer of 5 x 5 pixels, a hidden layer of 32 neurons, a hidden layer with the ability to exit 0.5, and a hidden layer of 10 neurons, finally a conventional layer having a size of 5 x 5 x 5 pixels and taking care of the input cards, a hidden layer of 32 neurons. We have a hidden layer of 10 neurons, a hidden layer of 10 neurons, a hidden layer of 10 neurons, finally a conventional layer of 10, a conventional layer of 10."}, {"heading": "4.1 MNIST", "text": "Since MNIST is less difficult, we have chosen a two-layer structure to generate the binary codes. To get 32-bit codes, we simply need to change the \"H32\" layer with the corresponding number of neurons and set the drop probability of the dropout layer. We should call the \"H32\" layer a node. In our experiments, the drop probability of the last dropout layer was not a sensitive factor, so we increased the probability that the drop-out layer will fall to 0.5 in all seven models."}, {"heading": "4.2 CIFAR-10", "text": "We used a structure that was larger than the MNIST model, but with smaller filter sizes in this dataset, to generate 32-bit length codes: 3x32x32-32C3P1-32C1P0-MP3S2D0.5-32C3P1-MP3S2-64C3P1-MP3S2-D0.5-H32-D0.5-H10. For the convenience of the later offer, we named the third pool layer \"Pool3\" and the first fully bonded layer \"H32.\" Similar to the MNIST structure, the H32 layer was also the knob. In this experiment, ReLU was used as non-linear units in all six revolutionary layers. We reduced the weights of both convolutionary and fully bonded layers to 20 percent."}, {"heading": "4.3 Anylasis on CIFAR-10", "text": "On CIFAR-10, we performed several other experiments to compare them. One was image recovery using the Euclidean distance between the corresponding characteristics of the query and the images of the dataset as similarity, and the characteristics matched the results of \"H32.\" To show that our model performed best not only because the characteristics extracted by CNN were more powerful, we conducted another experiment with KSH, which performed best on Gist characteristics with results from \"Pool3\" as descriptors of an input image. The results are shown in Table 3, where L2 fc and L2 fc + were both Euclidean characteristics, but the characteristics used by L2 fc + were reflected as follows: Xfc + = {Xfc + 0.5 Xfc + 0 Xfc < 0where Xfc and L2 fc + represent the original characteristics of \"H32,\" we found that these characteristics were not included in both K2 and Lfc-2, and Lfc-2 were added to both."}, {"heading": "5 Discussion", "text": "Figure 3 (a) and Figure 4 (a) showed that the accuracy of the proposed CNNBH has been improved on both MNIST and CIFAR-10 within the hamming radius of 2 with more hash bits, in line with human intuition.In the case of a room where visually similar images are insufficiently distributed, linear projection is hardly capable of reducing the entropy of data samples. In fact, for completely randomly distributed samples, any number of projections cannot reduce entropy and thus do not achieve good retrieval performance. Together with structured data, the performance of the learning-based projection improves. LSH can only achieve sustained good performance if the similarity relationship is maintained in the original space. The selected fully connected layer can be considered as a learning-based linear projection whose inputs are also learnable."}, {"heading": "6 Conclusion", "text": "We have proposed a new method for obtaining the binary hash code of a particular image by binarizing the results of a particular fully connected layer (in our experiments, we chose the first fully connected layer) and the best result on CIFAR-10, as well as the most modern performance on MNIST. Unlike CNNH and CNNH +, which require matrix decomposition, our method trained CNN in a normal raw pixel process, so more training data will not put too much strain on it. Considering that all models use only 5000 samples for training, we can expect a performance improvement with a larger training set, and a large amount of unmarked data remains untouched, which can be another key element for improvement."}], "references": [{"title": "Neural codes for image retrieval", "author": ["A. Babenko", "A. Slesarev", "A. Chigorin", "V.S. Lempitsky"], "venue": "CoRR, abs/1404.1777,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Multidimensional binary search trees used for associative searching", "author": ["J.L. Bentley"], "venue": "Commun. ACM, 18(9):509\u2013517,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1975}, {"title": "Multidimensional binary search trees used for associative searching", "author": ["J.L. Bentley"], "venue": "Commun. ACM, 18(9):509\u2013517,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1975}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "author": ["L. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "CoRR, abs/1412.7062,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Image retrieval: Ideas, influences, and trends of the new age", "author": ["R. Datta", "D. Joshi", "J. Li", "J.Z. Wang"], "venue": "ACM Comput. Surv., 40(2),", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "ImageNet: A LargeScale Hierarchical Image Database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei-Fei"], "venue": "In CVPR09,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Visualizing higher-layer features of a deep network", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P. Vincent"], "venue": "Technical Report 1341, University of Montreal, June", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., 35(8):1915\u20131929,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "An algorithm for finding best matches in logarithmic expected time", "author": ["J.H. Friedman", "J.L. Bentley", "R.A. Finkel"], "venue": "ACM Trans. Math. Softw., 3(3):209\u2013226,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1977}, {"title": "Similarity search in high dimensions via hashing", "author": ["A. Gionis", "P. Indyk", "R. Motwani"], "venue": "In VLDB\u201999, Proceedings of 25th International Conference on Very Large Data Bases, September 7-10, 1999, Edinburgh, Scotland, UK, pages 518\u2013529,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R.B. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "CoRR, abs/1311.2524,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "CoRR, abs/1207.0580,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Nearest neighbors in high-dimensional spaces", "author": ["P. Indyk"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "CoRR, abs/1502.03167,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale video classification with convolutional neural networks", "author": ["A. Karpathy", "G. Toderici", "S. Shetty", "T. Leung", "R. Sukthankar", "L. Fei-Fei"], "venue": "In 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2014, Columbus, OH, USA, June 23-28, 2014, pages 1725\u20131732,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Using very deep autoencoders for content-based image retrieval", "author": ["A. Krizhevsky", "G.E. Hinton"], "venue": "In ESANN 2011, 19th European Symposium on Artificial Neural Networks, Bruges, Belgium, April 27-29, 2011, Proceedings,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States., pages 1106\u20131114,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning to hash with binary reconstructive embeddings", "author": ["B. Kulis", "T. Darrell"], "venue": "In Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada., pages 1042\u20131050,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Kernelized locality-sensitive hashing for scalable image search", "author": ["B. Kulis", "K. Grauman"], "venue": "In IEEE 12th International Conference on Computer Vision, ICCV 2009, Kyoto, Japan, September 27 - October 4, 2009, pages 2130\u20132137,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. Lecun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Proceedings of the IEEE, pages 2278\u20132324,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "Deeply-supervised nets", "author": ["C. Lee", "S. Xie", "P. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "CoRR, abs/1409.5185,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Supervised hashing with kernels", "author": ["W. Liu", "J. Wang", "R. Ji", "Y. Jiang", "S. Chang"], "venue": "In 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, RI, USA, June 16-21, 2012, pages 2074\u20132081,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient algorithms with neural network behavior", "author": ["S.M. Omohundro"], "venue": "Technical Report UIUCDCS R-87-1331, UNIVERSITY OF ILLINOIS AT URBANACHAMPAIGN. Urbana (IL US),", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1987}, {"title": "Semantic hashing", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "Int. J. Approx. Reasoning, 50(7):969\u2013978,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Optimised kd-trees for fast image descriptor matching", "author": ["C. Silpa-Anan", "R. Hartley"], "venue": "In 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2008), 24-26 June 2008, Anchorage, Alaska, USA,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "CoRR, abs/1409.1556,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Intriguing properties of neural networks", "author": ["C. Szegedy", "W. Zaremba", "I. Sutskever", "J. Bruna", "D. Erhan", "I.J. Goodfellow", "R. Fergus"], "venue": "CoRR, abs/1312.6199,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Satisfying general proximity/similarity queries with metric trees", "author": ["J.K. Uhlmann"], "venue": "Inf. Process. Lett., 40(4):175\u2013179,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1991}, {"title": "Regularization of neural networks using dropconnect", "author": ["L. Wan", "M.D. Zeiler", "S. Zhang", "Y. LeCun", "R. Fergus"], "venue": "In Proceedings of the 30th International Conference on Machine Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, pages 1058\u20131066,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Semi-supervised hashing for large-scale search", "author": ["J. Wang", "S. Kumar", "S. Chang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., 34(12):2393\u20132406,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Spectral hashing", "author": ["Y. Weiss", "A. Torralba", "R. Fergus"], "venue": "In Advances in Neural Information Processing Systems 21, Proceedings of the Twenty-Second Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, December 8-11, 2008, pages 1753\u20131760,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "H", "author": ["R. Xia", "Y. Pan"], "venue": "Lai1, C. Liu1, and S. Yan. Supervised hashing for image retrieval via image representation learning. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2014, Qubec City, Canada, Jul 27-31, 2014,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "How transferable are features in deep neural networks? In Z", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 3320\u20133328.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "In Computer Vision - ECCV 2014 - 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I, pages 818\u2013833,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 4, "context": "Recently, the need of efficient retrieval for images or videos has attracted extensive attentions from academia and industry [6].", "startOffset": 125, "endOffset": 128}, {"referenceID": 1, "context": "Tree-based approaches, including KD tree [2][10][27], ball tree [25] and metric tree [30], can organize data with efficient structures which can boost the retrieval speed to O(log(n)).", "startOffset": 41, "endOffset": 44}, {"referenceID": 8, "context": "Tree-based approaches, including KD tree [2][10][27], ball tree [25] and metric tree [30], can organize data with efficient structures which can boost the retrieval speed to O(log(n)).", "startOffset": 44, "endOffset": 48}, {"referenceID": 25, "context": "Tree-based approaches, including KD tree [2][10][27], ball tree [25] and metric tree [30], can organize data with efficient structures which can boost the retrieval speed to O(log(n)).", "startOffset": 48, "endOffset": 52}, {"referenceID": 23, "context": "Tree-based approaches, including KD tree [2][10][27], ball tree [25] and metric tree [30], can organize data with efficient structures which can boost the retrieval speed to O(log(n)).", "startOffset": 64, "endOffset": 68}, {"referenceID": 28, "context": "Tree-based approaches, including KD tree [2][10][27], ball tree [25] and metric tree [30], can organize data with efficient structures which can boost the retrieval speed to O(log(n)).", "startOffset": 85, "endOffset": 89}, {"referenceID": 12, "context": "However, when it comes to high-dimensional data space where the samples are exponentially sparse along each dimension, the performances of these methods will be degraded even to be linear with the dataset capacity [14].", "startOffset": 214, "endOffset": 218}, {"referenceID": 2, "context": "In addition, the memory consumed by these tree-based structures is bigger than that of the original representations in many cases [3].", "startOffset": 130, "endOffset": 133}, {"referenceID": 9, "context": "On the other hand, hashing-based methods [11][21][24][20][34] with lookup tables consume only constant time on a new query.", "startOffset": 41, "endOffset": 45}, {"referenceID": 19, "context": "On the other hand, hashing-based methods [11][21][24][20][34] with lookup tables consume only constant time on a new query.", "startOffset": 45, "endOffset": 49}, {"referenceID": 22, "context": "On the other hand, hashing-based methods [11][21][24][20][34] with lookup tables consume only constant time on a new query.", "startOffset": 49, "endOffset": 53}, {"referenceID": 18, "context": "On the other hand, hashing-based methods [11][21][24][20][34] with lookup tables consume only constant time on a new query.", "startOffset": 53, "endOffset": 57}, {"referenceID": 32, "context": "On the other hand, hashing-based methods [11][21][24][20][34] with lookup tables consume only constant time on a new query.", "startOffset": 57, "endOffset": 61}, {"referenceID": 32, "context": "Although CNNH and CNNH+ [34] gain a great performance boost via leveraging deep models to learn representation and hash codes, they break the learning process into two separate stages and thus may reduce the coadaptiveness which can be of great importance for a high performance of CNN [35].", "startOffset": 24, "endOffset": 28}, {"referenceID": 33, "context": "Although CNNH and CNNH+ [34] gain a great performance boost via leveraging deep models to learn representation and hash codes, they break the learning process into two separate stages and thus may reduce the coadaptiveness which can be of great importance for a high performance of CNN [35].", "startOffset": 286, "endOffset": 290}, {"referenceID": 27, "context": "According to [29], it is the space extended by activations of a certain layer, rather than the the individual units, that contains the semantic information.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "And it has been shown that the deep features learned by CNN are expressive to serve as good descriptors for image retrieval [1].", "startOffset": 124, "endOffset": 127}, {"referenceID": 22, "context": "Besides, we show that the hashing learned by CNN is better than KSH [24] which took features from the layer prior to the selected fully connected layer from our model as input, and is also better than Euclidean-distance-based ranking with the features from the layer same with us as descriptor.", "startOffset": 68, "endOffset": 72}, {"referenceID": 32, "context": "Recently, as the ever-growing web data makes information retrieval and other problems more challenging, hashing has become a popular solution [34] [32] .", "startOffset": 142, "endOffset": 146}, {"referenceID": 30, "context": "Recently, as the ever-growing web data makes information retrieval and other problems more challenging, hashing has become a popular solution [34] [32] .", "startOffset": 147, "endOffset": 151}, {"referenceID": 9, "context": "For example, a typical category of Locality Sensitive Hashing (LSH) [11] uses random projection to construct hash functions.", "startOffset": 68, "endOffset": 72}, {"referenceID": 19, "context": "Unsupervised methods use only unlabeled data as training set, among which are methods such as Kernelized LSH [21], Semantic Hashing [18][26]and Spectral Hashing [33].", "startOffset": 109, "endOffset": 113}, {"referenceID": 16, "context": "Unsupervised methods use only unlabeled data as training set, among which are methods such as Kernelized LSH [21], Semantic Hashing [18][26]and Spectral Hashing [33].", "startOffset": 132, "endOffset": 136}, {"referenceID": 24, "context": "Unsupervised methods use only unlabeled data as training set, among which are methods such as Kernelized LSH [21], Semantic Hashing [18][26]and Spectral Hashing [33].", "startOffset": 136, "endOffset": 140}, {"referenceID": 31, "context": "Unsupervised methods use only unlabeled data as training set, among which are methods such as Kernelized LSH [21], Semantic Hashing [18][26]and Spectral Hashing [33].", "startOffset": 161, "endOffset": 165}, {"referenceID": 18, "context": "BRE (Binary Reconstruction Embedding) [20] learns hash functions by minimizing the reconstruction error between original distances and the Hamming distances of the corresponding binary codes.", "startOffset": 38, "endOffset": 42}, {"referenceID": 30, "context": "As a method of semi-supervised hashing, SPLH (Sequential Projection Learning Hashing) [32] can leverage unlabeled data as well as the relations between pairs of samples annotated with \u201dsimilar\u201d and \u201ddissimilar\u201d to iteratively get good hash functions which will compensate for the violation brought about by previous functions.", "startOffset": 86, "endOffset": 90}, {"referenceID": 17, "context": "Since 2012, explosive interests in computer vision have been attracted by CNN [19].", "startOffset": 78, "endOffset": 82}, {"referenceID": 17, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 74, "endOffset": 78}, {"referenceID": 26, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 78, "endOffset": 82}, {"referenceID": 17, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 94, "endOffset": 98}, {"referenceID": 26, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 98, "endOffset": 102}, {"referenceID": 7, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 118, "endOffset": 121}, {"referenceID": 14, "context": "Its remarkable successes in kinds of tasks such as object recognition [19][23][28], detection [19][28], image parsing [9] and video classification [16] have push the gap between machine and human vision narrow down by a large step.", "startOffset": 147, "endOffset": 151}, {"referenceID": 20, "context": "CNN [22] is a constrained multilayer neuron network whose inputs lie on 2-dimensional planes.", "startOffset": 4, "endOffset": 8}, {"referenceID": 11, "context": "By randomly set a portion of activations of a layer with probability p to zero at every training iteration and multiply the outgoing weights by p during test, dropout [13] works as if thousands of models vote.", "startOffset": 167, "endOffset": 171}, {"referenceID": 29, "context": "Dropconnect [31] is extended from dropout but consumes much more memory.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "ImageNet [7] is a large image database with totally 14 million annotated images.", "startOffset": 9, "endOffset": 12}, {"referenceID": 13, "context": "With a deep CNN, Google has set a new record on LSVRC2014 classification track [15].", "startOffset": 79, "endOffset": 83}, {"referenceID": 3, "context": "It has been suggested that the features in deep layers learned from ImageNet possess great ability to represent visual content of images, and can be used for different tasks, such as scene parsing, detection and image retrieval [5] [12] [1].", "startOffset": 228, "endOffset": 231}, {"referenceID": 10, "context": "It has been suggested that the features in deep layers learned from ImageNet possess great ability to represent visual content of images, and can be used for different tasks, such as scene parsing, detection and image retrieval [5] [12] [1].", "startOffset": 232, "endOffset": 236}, {"referenceID": 0, "context": "It has been suggested that the features in deep layers learned from ImageNet possess great ability to represent visual content of images, and can be used for different tasks, such as scene parsing, detection and image retrieval [5] [12] [1].", "startOffset": 237, "endOffset": 240}, {"referenceID": 0, "context": "Neural codes [1] uses activations at a top layer from an ImageNet-pretrained CNN as descriptors of the corresponding input image.", "startOffset": 13, "endOffset": 16}, {"referenceID": 16, "context": "Similar with [18], CNNH/CNNH+ [34] take raw image data as input, but the latter two divide the learning process into two different stages.", "startOffset": 13, "endOffset": 17}, {"referenceID": 32, "context": "Similar with [18], CNNH/CNNH+ [34] take raw image data as input, but the latter two divide the learning process into two different stages.", "startOffset": 30, "endOffset": 34}, {"referenceID": 32, "context": "For example, the sum of squared errors (SSE) to reconstruct the 5000-by-5000 similarity matrix with 48-bit hash codes generated by gradient descent in [34] (the codes are obtrained from the author\u2019s web page) could be 1.", "startOffset": 151, "endOffset": 155}, {"referenceID": 10, "context": "[12][8] look through the dataset for images that maximize the activation of the neuron, taking the neurons as meaningful filters.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[12][8] look through the dataset for images that maximize the activation of the neuron, taking the neurons as meaningful filters.", "startOffset": 4, "endOffset": 7}, {"referenceID": 34, "context": "Chosen layer Previous works [36][35] have shown that features learned in the shallow layers of a CNN are low-level and general, while those in the deep layers are more abstract and related to particular classes.", "startOffset": 28, "endOffset": 32}, {"referenceID": 33, "context": "Chosen layer Previous works [36][35] have shown that features learned in the shallow layers of a CNN are low-level and general, while those in the deep layers are more abstract and related to particular classes.", "startOffset": 32, "endOffset": 36}, {"referenceID": 15, "context": ", MNIST 2 and CIFAR-10 [17], both of which are widely used in the literature of hashing for image data.", "startOffset": 23, "endOffset": 27}, {"referenceID": 32, "context": "To compare on an equivalent basis, we sampled from each dataset 1000 images as query set and another 5000 from the rest for training like [34] .", "startOffset": 138, "endOffset": 142}, {"referenceID": 32, "context": "As for BRE and CNNH+, we used the best setting reported in the literature [34].", "startOffset": 74, "endOffset": 78}, {"referenceID": 32, "context": "(Adapted from [34])", "startOffset": 14, "endOffset": 18}, {"referenceID": 32, "context": "(Adapted from [34])", "startOffset": 14, "endOffset": 18}], "year": 2015, "abstractText": "Along with data on the web increasing dramatically, hashing is becoming more and more popular as a method of approximate nearest neighbor search. Previous supervised hashing methods utilized similarity/dissimilarity matrix to get semantic information. But the matrix is not easy to construct for a new dataset. Rather than to reconstruct the matrix, we proposed a straightforward CNN-based hashing method, i.e. binarilizing the activations of a fully connected layer with threshold 0 and taking the binary result as hash codes. This method achieved the best performance on CIFAR-10 and was comparable with the state-ofthe-art on MNIST. And our experiments on CIFAR-10 suggested that the signs of activations may carry more information than the relative values of activations between samples, and that the co-adaption between feature extractor and hash functions is important for hashing.", "creator": "LaTeX with hyperref package"}}}