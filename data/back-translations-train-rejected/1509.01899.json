{"id": "1509.01899", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2015", "title": "Integrate Document Ranking Information into Confidence Measure Calculation for Spoken Term Detection", "abstract": "This paper proposes an algorithm to improve the calculation of confidence measure for spoken term detection (STD). Given an input query term, the algorithm first calculates a measurement named document ranking weight for each document in the speech database to reflect its relevance with the query term by summing all the confidence measures of the hypothesized term occurrences in this document. The confidence measure of each term occurrence is then re-estimated through linear interpolation with the calculated document ranking weight to improve its reliability by integrating document-level information. Experiments are conducted on three standard STD tasks for Tamil, Vietnamese and English respectively. The experimental results all demonstrate that the proposed algorithm achieves consistent improvements over the state-of-the-art method for confidence measure calculation. Furthermore, this algorithm is still effective even if a high accuracy speech recognizer is not available, which makes it applicable for the languages with limited speech resources.", "histories": [["v1", "Mon, 7 Sep 2015 04:40:14 GMT  (270kb,D)", "https://arxiv.org/abs/1509.01899v1", "4 pages"], ["v2", "Thu, 10 Sep 2015 09:01:35 GMT  (356kb,D)", "http://arxiv.org/abs/1509.01899v2", "4 pages"]], "COMMENTS": "4 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["quan liu", "wu guo", "zhen-hua ling"], "accepted": false, "id": "1509.01899"}, "pdf": {"name": "1509.01899.pdf", "metadata": {"source": "CRF", "title": "Integrate Document Ranking Information into Confidence Measure Calculation for Spoken Term Detection", "authors": ["Quan Liu", "Wu Guo", "Zhen-Hua Ling"], "emails": ["quanliu@mail.ustc.edu.cn,", "guowu@ustc.edu.cn,", "zhling@ustc.edu.cn"], "sections": [{"heading": null, "text": "Categories and Subject Descriptions H.3.3 [Storage and Retrieval of Information]: Search and Retrieval of Information - Search Process, Selection Process; I.2.7 [Artificial Intelligence]: Natural Language Processing General Terms Algorithms, Management, Verification Keywords Spoken Term Detection, Speech Retrieval, Confidence Measure, Document Ranking, Speech Recognizer."}, {"heading": "1. INTRODUCTION", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country"}, {"heading": "2. RELATED WORK", "text": "More recently [22, 17] they used word repetitions to improve the recognition of spoken terms after observing the phenomenon of word repetition within individual documents; they took advantage of the bursting of keywords by using the most self-confident keyword hypothesis in each document and interpolating it with lower scores; although they had developed an effective method of determining the intercoefficients in their experiments, they focused on the repetition of terms within a document without taking into account the contexts between the documents, e.g. the document ranking information used in this essay; the work in [7] is very similar to ours in that they also gave high priority to the candidate segments contained in high-level documents; however, they proposed recursively calculating the location-dependent document weights; this work calculates the ranking of documents in a simpler way and takes into account the interranking of the document, since in this paper they rank the information, the relevance in their database."}, {"heading": "3. PROPOSED METHOD", "text": "For an input query appointment, a set of one-pass query candidates in the language database can be considered a \"score\" option. First, trust is generated using the traditional STD approach (max. weight). However, each term detection event usually contains location information and a confidence measure, while the location information usually describes the name (or ID) of the candidate, the start time and duration of the confidence. However, for term t we use Oi to represent the location information of the i-th detection event. Confidence is given to the document ranking behavior of the candidates based on a query term. The set of one-pass query candidates is specified as query candidates. Output: The document ranking weight for all documents in the database is calculated. Main procedure: 1. Document clustering cluster the documents in all hypothetical occurrences of the term t by summing all confidence measures in each document."}, {"heading": "4. EXPERIMENTAL SETUP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data Set and Evaluation Condition", "text": "The experiments were performed with three standard spoken word recognition tasks, the English Convertible Telephone Language (CTS) Rating Set STD 2006, Vietnamese OpenKWS 2013 and Tamil OpenKWS 2014. The English CTS Rating Set consisted of approximately 3 hours of speech, and the keyword set consisted of 411 keywords. Vietnamese and Tamil development sets each consisted of approximately 10 hours of speech. Vietnamese Rating Set CTS consisted of 4065 keywords, 901 of which appeared in the development set and were used in our experiments. For the Tamil task, we used the keyword set kwlist3, supplied by IBM, which consisted of 2375 keywords. The intention of using three tasks was to evaluate the proposed algorithm using three very different languages with different ASR accuracy, different amount of training data, and variations in the size of the keywords."}, {"heading": "4.2 Automatic Speech Recognizer", "text": "Our ASR motors were built using state-of-the-art DNN-HMM-based acoustic modeling [18]. For the English task, 309 hours of language instruction were used for the acoustic model, and the transcriptions of these language files were used to train a 3 gram language model.The criterion of cross entropy was used to train the DNN models.The first approach was cross-language training, in which we used a DNN model derived from 1000 hours of Chinese CTS data to initialize Vietnamese DNN parameters. In addition, the Rectified Linear Unit (ReLU) was used to replace the signature function in the DNS files."}, {"heading": "4.3 STD Indexer and Keyword Searcher", "text": "We developed a toolkit called iSTD to build our Keyword Search subsystem for STD. We followed the work in [12, 13] to construct the inverted index on the basis of confusion networks. Candidates for the occurrence of the term were then found by keyword searching on the inverted index. The trust reassessment algorithm proposed in this article was also integrated into this toolkit."}, {"heading": "5. EXPERIMENTAL RESULTS", "text": "5.1 The effectiveness of Document Ranking 1http: / / www.nist.gov / itl / iad / mig / openkws.cfm 2http: / / www.itl.nist.gov / iad / mig / tests / std / 2006 / docs / std06evalplan-v10.pdfIn order to test the rationality of applying Document Ranking information to STD tasks, we examined the relationship between the performance of term recognition and the position of the document. Here, the positions of the document were derived by sorting all documents in descending order of the weights calculated according to Algorithm 1. Figure 1 shows the correlation curve for the Vietnamese STD task mentioned above. Results were obtained by averaging over 901 query keywords. Correlation curves show that documents with high document ranking weights generally exhibit high precision and recall of the term rating."}, {"heading": "5.2 Results of Tuning Interpolation Coefficients", "text": "The interpolation coefficient \u03b1 in (4) controls the balance between the document weights and the basic confidence measures for a particular query term. To investigate its practical implications, the ATWVs of the Vietnamese STD task development group were compared to the different interpolation coefficients in Fig. 2. We can see that a reasonable choice for \u03b1 is in the range of 0.05 to 0.4. In the next section, experimental results for different tasks are presented, \u03b1 being matched to the development and should be 0.05, 0.1 and 0.15 for Tamil, Vietnamese and English, respectively."}, {"heading": "5.3 Results of STD Tasks", "text": "We compared the proposed confidence measurement algorithm with the base system for the three STD tasks. The base system directly used the ASR posterior score as the confidence measure for each query date. Keyword-specific threshold was applied to all systems as the final decision-retrieval method [16]. Experimental results are listed in Table 2. We see that the proposed confidence reassessment approach achieves consistent improvements for all three typical language retrieval tasks. Considering the amount of training data available in these three tasks, the survey results in Table 2 also suggest that the proposed confidence estimation method is neither language-dependent nor sensitive to the amounts of training resources."}, {"heading": "6. CONCLUSIONS", "text": "Inspired by the PageRank algorithm and the use of language models in the area of text information search, we propose to integrate document ranking information into the calculation of confidence measures for the occurrence of terms. Document ranking information shows the topic relevance between each document and the query date, while topic-related documents should contain more accurate matches. Experiments on three standard STD tasks show the effectiveness of this algorithm by introducing information about document ranking."}, {"heading": "7. REFERENCES", "text": "[1] S. Brin and L. Page. The anatomy of a large-scalehypertextual web search engine. Computer networks and ISDN systems, 30 (1): 107-117, 1998. [2] B. Chen. Latent topic modelling of word co-occurence information for spoken document retrieval. In Proc. ICASSP, pp. 3961-3964. IEEE, 2009. [3] J. Chiu and A. Lee S. Rudnicky. Using conversational word bursts in spoken word detection. In Proc. INTERSPEECH, pp. 2247-2251, 2013. [4] J. G. Fiscus, J. Ajot, J. Garofolo and G. Doddingtion. Results of the 2006 spoken word detection evaluation. In Proc. SIGIR, Volume 7, pp. 51-57, 2007. [5] H. Jiang. Confidence measures for speech recognition."}], "references": [{"title": "The anatomy of a large-scale hypertextual web search engine", "author": ["S. Brin", "L. Page"], "venue": "Computer networks and ISDN systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Latent topic modelling of word co-occurence information for spoken document retrieval", "author": ["B. Chen"], "venue": "In Proc. ICASSP,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Using conversational word bursts in spoken term detection", "author": ["J. Chiu", "A.I. Rudnicky"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Doddingtion. Results of the 2006 spoken term detection evaluation", "author": ["J.G. Fiscus", "J. Ajot", "J.S. Garofolo"], "venue": "In Proc. SIGIR,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Confidence measures for speech recognition: A survey", "author": ["H. Jiang"], "venue": "Speech communication,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Spoken content retrieval: Searching spontaneous conversational speech", "author": ["J. Kohler", "M. Larson", "F. de Jong", "W. Kraaij", "R. Ordelman"], "venue": "In ACM SIGIR Forum,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "High priority in highly ranked documents in spoken term detection", "author": ["K. Konno", "Y. Itoh", "K. Kojima", "M. Ishigame", "K. Tanaka", "S.-w. Lee"], "venue": "In Signal and Information Processing Association Annual Summit and Conference (APSIPA),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Improved open-vocabulary spoken content retrieval with word and subword lattices using acoustic feature similarity", "author": ["H.-y. Lee", "P.-w. Chou", "L.-s. Lee"], "venue": "Computer Speech & Language,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Improved spoken term detection using support vector machines based on lattice context consistency", "author": ["H.-y. Lee", "T.-w. Tu", "C.-P. Chen", "C.-y. Huang", "L.-s. Lee"], "venue": "In Proc. ICASSP,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "A novel confidence measure based on context consistency for spoken term detection", "author": ["H. Li", "J. Han", "T. Zheng", "G. Zheng"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "System combination and score normalization for spoken term detection", "author": ["J. Mamou", "J. Cui", "X. Cui", "M.J.F. Gales", "B. Kingsbury", "K. Knill", "L. Mangu", "D. Nolden", "M. Picheny", "B. Ramabhadran", "R. Schl\u00fcter", "A. Sethy", "P.C. Woodl"], "venue": "In Proc. ICASSP,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Vocabulary independent spoken term detection", "author": ["J. Mamou", "B. Ramabhadran", "O. Siohan"], "venue": "In Proc. SIGIR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Efficient spoken term detection using confusion networks", "author": ["L. Mangu", "B. Kingsbury", "H. Soltau", "H.-K. Kuo", "M. Picheny"], "venue": "In Proc. ICASSP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Discriminative score normalization for keyword search decision", "author": ["V.T. Pham", "H. Xu", "N.F. Chen", "S. Sivadas", "B.P. Lim", "E.S. Chng", "H. Li"], "venue": "In Proc. ICASSP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "A language modeling approach to information retrieval", "author": ["J.M. Ponte", "W.B. Croft"], "venue": "In Proc. SIGIR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1998}, {"title": "An in-depth comparison of keyword specific thresholding and sum-to-one score normalization", "author": ["Y. Proc. Wang", "F. Metze"], "venue": "In INTERSPEECH,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Using word burst analysis to rescore keyword search candidates on low-resource languages", "author": ["J. Richards", "M. Ma", "A. Rosenberg"], "venue": "In Proc. ICASSP,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Conversational speech transcription using context-dependent deep neural networks", "author": ["F. Seide", "G. Li", "D. Yu"], "venue": "In INTERSPEECH,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "A comparison of multiple methods for rescoring keyword search lists for low resource languages", "author": ["V. Soto", "L. Mangu", "A. Rosenberg", "J. Hirschberg"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Calibration and multiple system fusion for spoken term detection using linear logistic regression", "author": ["J. van Hout", "L. Ferrer", "D. Vergyri", "N. Scheffer", "Y. Lei", "V. Mitra", "S. Wegmann"], "venue": "In Proc. ICASSP,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Lda-based document models for ad-hoc retrieval", "author": ["X. Wei", "W.B. Croft"], "venue": "In Proc. SIGIR,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Can you repeat that? using word repetition to improve spoken term detection", "author": ["J. Wintrode", "S. Khudanpur"], "venue": "In Proc. ACL,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "A study of smoothing methods for language models applied to information retrieval", "author": ["C. Zhai", "J. Lafferty"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}], "referenceMentions": [{"referenceID": 11, "context": "and plays a central role in information management and speech retrieval [12, 4, 6, 13].", "startOffset": 72, "endOffset": 86}, {"referenceID": 3, "context": "and plays a central role in information management and speech retrieval [12, 4, 6, 13].", "startOffset": 72, "endOffset": 86}, {"referenceID": 5, "context": "and plays a central role in information management and speech retrieval [12, 4, 6, 13].", "startOffset": 72, "endOffset": 86}, {"referenceID": 12, "context": "and plays a central role in information management and speech retrieval [12, 4, 6, 13].", "startOffset": 72, "endOffset": 86}, {"referenceID": 4, "context": "The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13].", "startOffset": 109, "endOffset": 120}, {"referenceID": 11, "context": "The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13].", "startOffset": 109, "endOffset": 120}, {"referenceID": 12, "context": "The text transcriptions contain all the possibly recognized words with corresponding posterior probabilities [5, 12, 13].", "startOffset": 109, "endOffset": 120}, {"referenceID": 4, "context": "Formally, in STD applications, a confidence measure (CM) is defined to represent the reliability of each detected term occurrence, which is usually estimated by the recognizer [5, 12].", "startOffset": 176, "endOffset": 183}, {"referenceID": 11, "context": "Formally, in STD applications, a confidence measure (CM) is defined to represent the reliability of each detected term occurrence, which is usually estimated by the recognizer [5, 12].", "startOffset": 176, "endOffset": 183}, {"referenceID": 10, "context": "The baseline system of this paper could then be evaluated on it directly by conducting standard score normalization and final decision [11, 13].", "startOffset": 135, "endOffset": 143}, {"referenceID": 12, "context": "The baseline system of this paper could then be evaluated on it directly by conducting standard score normalization and final decision [11, 13].", "startOffset": 135, "endOffset": 143}, {"referenceID": 9, "context": "In [10, 9], the confidence measure of query occurrence is re-estimated based on the context consistency information.", "startOffset": 3, "endOffset": 10}, {"referenceID": 8, "context": "In [10, 9], the confidence measure of query occurrence is re-estimated based on the context consistency information.", "startOffset": 3, "endOffset": 10}, {"referenceID": 18, "context": "[19] proposed a two-stage cascaded machine learning approach for rescoring keyword search outputs for low resource languages.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] proposed a modified logistic regression strategy for term detection optimization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Discriminative score normalization method was introduced to normalize confidence measures through discriminative modeling [14].", "startOffset": 122, "endOffset": 126}, {"referenceID": 7, "context": "Moreover, another method was proposed in [8] to employ extra acoustic features for getting a better confidence measure.", "startOffset": 41, "endOffset": 44}, {"referenceID": 14, "context": "However, all these methods fail to utilize long-term contexts at document or topic level, which has been proved to be useful for some other information retrieval (IR) tasks [15, 23].", "startOffset": 173, "endOffset": 181}, {"referenceID": 22, "context": "However, all these methods fail to utilize long-term contexts at document or topic level, which has been proved to be useful for some other information retrieval (IR) tasks [15, 23].", "startOffset": 173, "endOffset": 181}, {"referenceID": 20, "context": "Clustering and latent topic models have also gained improvements over traditional vector space models for IR [21, 2].", "startOffset": 109, "endOffset": 116}, {"referenceID": 1, "context": "Clustering and latent topic models have also gained improvements over traditional vector space models for IR [21, 2].", "startOffset": 109, "endOffset": 116}, {"referenceID": 0, "context": "the hyperlink between every two pages and computes a converged importance score for each page [1].", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "In [3], they improved term detection performance based on the word burstiness in spoken conversational corpora.", "startOffset": 3, "endOffset": 6}, {"referenceID": 21, "context": "More recently, [22, 17] took advantage of word repetition to improve spoken term detection, having observed the phenomenon of word repetition within single documents.", "startOffset": 15, "endOffset": 23}, {"referenceID": 16, "context": "More recently, [22, 17] took advantage of word repetition to improve spoken term detection, having observed the phenomenon of word repetition within single documents.", "startOffset": 15, "endOffset": 23}, {"referenceID": 6, "context": "The work in [7] is very similar to us since they also gave a high priority to the candidate segments that are included in highly ranked documents.", "startOffset": 12, "endOffset": 15}, {"referenceID": 17, "context": "Our ASR engines were built using the DNN-HMM based acoustic modeling, which is the state-of-the-art approach for speech recognition [18].", "startOffset": 132, "endOffset": 136}, {"referenceID": 11, "context": "We followed the work in [12, 13] to construct the inverted index based on confusion networks.", "startOffset": 24, "endOffset": 32}, {"referenceID": 12, "context": "We followed the work in [12, 13] to construct the inverted index based on confusion networks.", "startOffset": 24, "endOffset": 32}, {"referenceID": 15, "context": "Keywordspecific threshold was applied for all systems as the final decision recall method [16].", "startOffset": 90, "endOffset": 94}], "year": 2015, "abstractText": "This paper proposes an algorithm to improve the calculation of confidence measure for spoken term detection (STD). Given an input query term, the algorithm first calculates a measurement named document ranking weight for each document in the speech database to reflect its relevance with the query term by summing all the confidence measures of the hypothesized term occurrences in this document. The confidence measure of each term occurrence is then re-estimated through linear interpolation with the calculated document ranking weight to improve its reliability by integrating document-level information. Experiments are conducted on three standard STD tasks for Tamil, Vietnamese and English respectively. The experimental results all demonstrate that the proposed algorithm achieves consistent improvements over the state-of-the-art method for confidence measure calculation. Furthermore, this algorithm is still effective even if a high accuracy speech recognizer is not available, which makes it applicable for the languages with limited speech resources.", "creator": "LaTeX with hyperref package"}}}