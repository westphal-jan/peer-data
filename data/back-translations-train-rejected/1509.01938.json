{"id": "1509.01938", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2015", "title": "Exploiting Out-of-Domain Data Sources for Dialectal Arabic Statistical Machine Translation", "abstract": "Statistical machine translation for dialectal Arabic is characterized by a lack of data since data acquisition involves the transcription and translation of spoken language. In this study we develop techniques for extracting parallel data for one particular dialect of Arabic (Iraqi Arabic) from out-of-domain corpora in different dialects of Arabic or in Modern Standard Arabic. We compare two different data selection strategies (cross-entropy based and submodular selection) and demonstrate that a very small but highly targeted amount of found data can improve the performance of a baseline machine translation system. We furthermore report on preliminary experiments on using automatically translated speech data as additional training data.", "histories": [["v1", "Mon, 7 Sep 2015 07:54:17 GMT  (28kb,D)", "http://arxiv.org/abs/1509.01938v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["katrin kirchhoff", "bing zhao", "wen wang"], "accepted": false, "id": "1509.01938"}, "pdf": {"name": "1509.01938.pdf", "metadata": {"source": "CRF", "title": "Exploiting Out-of-Domain Data Sources for Dialectal Arabic Statistical Machine Translation", "authors": ["Katrin Kirchhoff", "Bing Zhao", "Wen Wang"], "emails": ["kk2@u.washington.edu", "bingzhao@gmail.com", "wwang@speech.sri.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to trump themselves, and they are able to trump themselves. (...) Most of them are not able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them have trumped themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them are able to trump themselves. (...) Most of them have trumped themselves. (...) Most of them have trumped themselves. (...) Most of them are able to trump themselves. (...)"}, {"heading": "2 Data Selection: Previous Work", "text": "A currently widely used method for data selection in SMT (which we also use as the starting method in Section 5) uses the cross-entropy method between two language models (Moore and Lewis, 2010), with one trained on the test set of interest and another on generic or cross-domain training data. We call this the cross-entropy method. This method trains a test set-specific (or domain-specific) language model, LMin, and a generic (out- or mixed-domain) language model, LMout. Each sentence x-V in the training data is evaluated by both language models and gets the log ratio of probabilities of the language model assigned as a score: mce (x) = 1 '(x) log [Pr (x | LMin) / Pr (x | LMout)]] (1), where \"(x) is the length of the sentence x. Sentences are then selected in descending order based on their results and the uppermost sentences of this year's interdisciplinary assortment (N) to guarantee an extension of this method in 2011."}, {"heading": "3 Submodular Data Selection", "text": "The results of the study show that the data are in the areas of clustering (Narasimhan and Bilmes, 2007), observation selection (Krause et al., 2008), sensor placement (Krause and Guestrin, 2011), or image segmentation (Jegelka and Bilmes, 2011). Within natural language processing (NLP), submodular functions for extractive text selection (Lin and Bilmes, 2012) were used to explain the submodular functions, we introduce the following notation: a finite set of data elements V, the sediment. An evaluation function f: 2V \u2192 R + is then defined to return a non-negative real value for any subset X-V."}, {"heading": "4 Data", "text": "The external data sources used for the selection experiments are listed in Table 2. We use 22 LDC corporas that contain MSA and other Arabic dialects, particularly Egyptian and Levantine. For example, training corporas developed for the GALE, TIDES and BOLT projects were included, as were the Levantine Arabic Tree trunk, an Egyptian Arabic word corpus and a corpus of dialectical Arabic web data (75% Levantine, 25% Egyptian) translated by crowdsourcing (hence, translations are noisy)."}, {"heading": "5 Experiments and Results", "text": "We use two different MT systems for translating IA into English, an in-house system based on Moses and the SRI MT system developed for the DARPA BOLT (Broad Operational Language Translation) project (see Ayan et al., 2013; Kirchhoff et al., 2015). The first is a flat phrase-based statistical MT system with a hierarchical lexicalized translation model and a 6 gram language model trained on the target side of the Transtac training data. For pre-processing, we use a statistical morphological segmentator developed in the BOLT project. The second system is similar in nature but has a hierarchical phrase-based translation model and uses sparse features (see Zhao et al., 2014) for morality information."}, {"heading": "5.1 Initial evaluation of selection techniques", "text": "In a first series of experiments, we tried to measure the performance of the cross entropy versus the submodular selection technique by subselecting the Transtac training data. We selected 10-40% of the Transtac training data; the feature set U was the set of all n-grams up to length 7 of the melody and dev sentences. We examined both translation directions, IA \u2192 English and English \u2192 IA. Table 3 shows the BLEU values. Compared to using 100% of the training data, the same or even better performance can be achieved by using a subset of data when using the submodular subselection technique, even for small percentages of the training data. The cross entropy method lags behind this performance, presumably due to the failure of this method to control the redundancy in the selected set."}, {"heading": "5.2 Selection of out-of-domain training data", "text": "The LDC corpora were pre-processed in the same way as the Transtac data, i.e. they were pre-processed and morphologically segmented, and the greedy algorithm was used in combination with Equation 3 to select parallel sentences from the corpora listed in Table 2 so that the resulting corpus on the source side contains no more than 100k words, and the selected data was then added to both the MT and LM training data. Table 4 shows the BLEU values and the stationary word error rate (PER) for the in-house MT system used for development purposes (note that the baseline results differ from those in Table 3 because the baseline MT system was changed between experiments and trained on different dataset definitions and tokenization schemes)."}, {"heading": "5.3 Using translated speech data", "text": "In addition to the various parallel text corporas listed in Table 2, we had access to a corpus of Iraqi Arabic telephone calls (CTS) (LDC2006T16), which includes language transcriptions but no translations. Although the data correspond to the dialect of interest, it is not necessarily matched thematically or stylistically. To obtain parallel data, we translated the transcriptions of this corpus using our base system IA \u2192 EN. In this experiment, we found that 80% of the selected data came from the CTS corpus, but the translation performance did not improve (see Table 6). The likely reason for this is that the translations were too loud to be used as parallel data, and introduced more confusion and irrelevant variations than the translations were useful."}, {"heading": "6 Conclusion", "text": "We have described procedures for data selection to identify Iraqi Arabic data resources in unrelated dialectical and / or MSA corporations. We have shown that carefully selected data can improve MT performance, even if the overall amount is very small. In addition, we have compared two different data selection techniques, the widely used cross-entropy selection method and a more recently developed method based on submodular functional optimization, the latter yielding slightly better results than the former. Finally, we have conducted initial experiments to use automatically translated conversational language as additional training data. While the data was heavily aligned with the in-domain data on the source side, the translations were too noisy to achieve further improvement in machine translation performance."}, {"heading": "Acknowledgments", "text": "This study was funded by the Defense Advanced Research Projects Agency (DARPA) under contract HR0011-12-C-0016 - Subcontract 19-000234 and by the Intelligence AdvancedResearch Projects Activity (IARPA) under contract FA8650-12-2-7263. The U.S. Government is authorized to produce and distribute reproductions for government purposes, notwithstanding the copyright notices contained therein. The views and conclusions contained herein are those of the authors and should not necessarily be interpreted to represent the official guidelines or recommendations of Intelligence Advanced Research Projects Activity (IARPA) or the U.S. Government."}], "references": [{"title": "A supervised POS tagger for written Arabic social networking corpora", "author": ["Al-Sabbagh", "R. Girju2012] Al-Sabbagh", "R. Girju"], "venue": "In Proceedings of KONVENS", "citeRegEx": "Al.Sabbagh et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Al.Sabbagh et al\\.", "year": 2012}, {"title": "Automatic Identification of Arabic Dialects", "author": ["F.S. Alorifi"], "venue": null, "citeRegEx": "Alorifi,? \\Q2008\\E", "shortCiteRegEx": "Alorifi", "year": 2008}, {"title": "Handling OOV words in dialectal Arabic to English machine translation", "author": ["M. Aminian et al.2014] Aminian", "M. Ghoneim", "M. Diab"], "venue": "In EMNLP Workshop on Language Technology for Closely Related Languages and Language Variants", "citeRegEx": "Aminian et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Aminian et al\\.", "year": 2014}, {"title": "Domain adaptation via pseudo in-domain data selection", "author": ["A. Axelrod et al.2011] Axelrod", "X. He", "J. Gao"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Axelrod et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Axelrod et al\\.", "year": 2011}, {"title": "Can you give me another word for hyperbaric? - improving speech translation using targeted clarification questions", "author": ["N.F. Ayan et al.2013] Ayan et al"], "venue": "Proceedings of ICASSP", "citeRegEx": "al.,? \\Q2013\\E", "shortCiteRegEx": "al.", "year": 2013}, {"title": "Parsing Arabic dialects", "author": ["Chiang et al.2006] Chiang", "David", "M.Diab", "N. Habash", "O. Rambow", "S. Shareef"], "venue": "In Proceedings of EACL", "citeRegEx": "Chiang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chiang et al\\.", "year": 2006}, {"title": "Pos tagging of dialectal Arabic: a minimally supervised approach", "author": ["Duh", "K. Kirchhoff2005] Duh", "K. Kirchhoff"], "venue": "Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages,", "citeRegEx": "Duh et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Duh et al\\.", "year": 2005}, {"title": "Lexicon acquisition for dialectal Arabic using transductive learning", "author": ["Duh", "K. Kirchhoff2006] Duh", "K. Kirchhoff"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Duh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Duh et al\\.", "year": 2006}, {"title": "Adaptation data selection using neural language models: Experiments in machine translation", "author": ["K. Duh et al.2013] Duh", "G. Neubig", "K. Sudoh", "H. Tsukada"], "venue": "Proceedings of ACL", "citeRegEx": "Duh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Duh et al\\.", "year": 2013}, {"title": "Combinatorial Structures and their Applications, chapter Submodular functions, matroids and certain polyhedra, pages 69\u201387", "author": ["J. Edmonds"], "venue": null, "citeRegEx": "Edmonds,? \\Q1970\\E", "shortCiteRegEx": "Edmonds", "year": 1970}, {"title": "A threshold of ln n for approximating set cover", "author": ["U. Feige"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Feige,? \\Q1998\\E", "shortCiteRegEx": "Feige", "year": 1998}, {"title": "Morphological analysis and generation for Arabic dialects", "author": ["N. Habash et al.2005] Habash", "O. Rambow", "G. Kiraz"], "venue": "In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages", "citeRegEx": "Habash et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2005}, {"title": "A morphological analyzer for Egyptian Arabic", "author": ["N. Habash et al.2012] Habash", "R. Eskander", "A. Hawwari"], "venue": "In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology (SIGMOR-", "citeRegEx": "Habash et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2012}, {"title": "Morphological analysis and disambiguation for dialectal Arabic", "author": ["N. Habash et al.2013] Habash", "R. Roth", "O. Rambow", "R. Eskander", "N. Tomeh"], "venue": "In Proceedings of NAACL,", "citeRegEx": "Habash et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2013}, {"title": "Introduction to Arabic natural language processing", "author": ["N. Habash"], "venue": "Synthesis Lectures on Human Language Technologies,", "citeRegEx": "Habash,? \\Q2010\\E", "shortCiteRegEx": "Habash", "year": 2010}, {"title": "Submodularity beyond submodular energies: coupling edges in graph cuts. In Computer Vision and Pattern Recognition (CVPR), Colorado Springs, CO, June", "author": ["Jegelka", "S. Bilmes2011] Jegelka", "J.A. Bilmes"], "venue": null, "citeRegEx": "Jegelka et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jegelka et al\\.", "year": 2011}, {"title": "Submodularity for data selection in statistical machine translation", "author": ["Kirchhoff", "K. Bilmes2014] Kirchhoff", "J. Bilmes"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Kirchhoff et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kirchhoff et al\\.", "year": 2014}, {"title": "Morphological modeling for machine translation of English-iraqi Arabic spoken dialogs", "author": ["Y.C. Tam dn C. Richey", "W. Wang"], "venue": "Proceedings of NAACL", "citeRegEx": "Kirchhoff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kirchhoff et al\\.", "year": 2015}, {"title": "Submodularity and its applications in optimized information gathering", "author": ["Krause", "A. Guestrin2011] Krause", "C. Guestrin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Krause et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2011}, {"title": "Robust submodular observation selection", "author": ["A. Krause et al.2008] Krause", "H.B. McMahan", "C. Guestrin", "A. Gupta"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Krause et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2008}, {"title": "Learning mixtures of submodular shells with application to document summarization", "author": ["Lin", "H. Bilmes2012] Lin", "J. Bilmes"], "venue": "In Uncertainty in Artifical Intelligence (UAI), Catalina Island,", "citeRegEx": "Lin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2012}, {"title": "Developing and using a pilot dialectal Arabic treebank", "author": ["M. Maamouri et al.2006] Maamouri", "A. Bies", "T. Buckwalter", "M. Diab", "N. Habash", "O. Rambow", "D. Tabessi"], "venue": "In Proceedings of the Fifth International Conference on Language Resources", "citeRegEx": "Maamouri et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Maamouri et al\\.", "year": 2006}, {"title": "Improving in-domain data selection for small in-domain sets", "author": ["M. Mediani et al.2014] Mediani", "J. Winebarger", "A. Waibel"], "venue": "In Proceedings of IWSLT", "citeRegEx": "Mediani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mediani et al\\.", "year": 2014}, {"title": "Intelligent selection of language model training data", "author": ["Moore", "R. Lewis2010] Moore", "W. Lewis"], "venue": "In Proceedings EMNLP", "citeRegEx": "Moore et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2010}, {"title": "Local search for balanced submodular clustering", "author": ["Narasimhan", "M. Bilmes2007] Narasimhan", "J. Bilmes"], "venue": "In Proceedings of IJCAI", "citeRegEx": "Narasimhan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2007}, {"title": "An analysis of approximations for maximizing submodular set functions i", "author": ["L.A. Wolsey", "M.L. Fisher"], "venue": "Mathematical Programming,", "citeRegEx": "Nemhauser et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser et al\\.", "year": 1978}, {"title": "Automatic identification of Arabic language varieties and dialects in social media", "author": ["F. Sadat et al.2014] Sadat", "F. Kazemi", "A. Farzindar"], "venue": "In Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP),", "citeRegEx": "Sadat et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sadat et al\\.", "year": 2014}, {"title": "Dialectal to standard Arabic paraphrasing to improve Arabic-English statistical machine translation", "author": ["Salloum", "W. Habash2011] Salloum", "N. Habash"], "venue": "In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects", "citeRegEx": "Salloum et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Salloum et al\\.", "year": 2011}, {"title": "Dialectal Arabic to English machine translation: Pivoting through modern standard Arabic", "author": ["Salloum", "W. Habash2013] Salloum", "N. Habash"], "venue": "In Proceedings of NAACL", "citeRegEx": "Salloum et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Salloum et al\\.", "year": 2013}, {"title": "Using document summarization techniques for speech data subset selection", "author": ["K. Wei et al.2013] Wei", "Y. Liu", "K. Kirchhoff", "J. Bilmes"], "venue": "In Proceedings of NAACL", "citeRegEx": "Wei et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2013}, {"title": "Arabic dialect identification", "author": ["Zaidan", "O. Callison-Burch2014] Zaidan", "C. Callison-Burch"], "venue": "Computational Linguistics,", "citeRegEx": "Zaidan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaidan et al\\.", "year": 2014}, {"title": "Machine translation of Arabic dialects", "author": ["Zbib et al.2012] Zbib", "Rabih", "Erika Malchiodi", "Jacob Devlin", "David Stallard", "Spyros Matsoukas", "Richard Schwartz", "John Makhoul", "Omar F. Zaidan", "Chris Callison-Burch"], "venue": "In Proceedings of the 2012 Conference", "citeRegEx": "Zbib et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zbib et al\\.", "year": 2012}, {"title": "An autoencoder with bilingual sparse features for improved statistical machine translation", "author": ["B. Zhao et al.2014] Zhao", "Y.-C. Tam", "J. Zheng"], "venue": "In Proceedings of ICASSP", "citeRegEx": "Zhao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 14, "context": "An overview of the main characteristics of DA can be found in (Habash, 2010).", "startOffset": 62, "endOffset": 76}, {"referenceID": 11, "context": "Work on DA annotation tools includes the development of morphological analyzers for Arabic dialects (Habash et al., 2005; Habash et al., 2012; Habash et al., 2013), treebanks (Maamouri et al.", "startOffset": 100, "endOffset": 163}, {"referenceID": 12, "context": "Work on DA annotation tools includes the development of morphological analyzers for Arabic dialects (Habash et al., 2005; Habash et al., 2012; Habash et al., 2013), treebanks (Maamouri et al.", "startOffset": 100, "endOffset": 163}, {"referenceID": 13, "context": "Work on DA annotation tools includes the development of morphological analyzers for Arabic dialects (Habash et al., 2005; Habash et al., 2012; Habash et al., 2013), treebanks (Maamouri et al.", "startOffset": 100, "endOffset": 163}, {"referenceID": 21, "context": ", 2013), treebanks (Maamouri et al., 2006) and parsers (Chiang et al.", "startOffset": 19, "endOffset": 42}, {"referenceID": 5, "context": ", 2006) and parsers (Chiang et al., 2006), unsupervised (Duh and Kirchhoff, 2005) or supervised (Al-Sabbagh and Girju, 2012) training of POS taggers for DA, and lexicon acquisition (Duh and Kirchhoff, 2006).", "startOffset": 20, "endOffset": 41}, {"referenceID": 31, "context": "(Zbib et al., 2012) compare utilizing large amounts of MSA data for training and creating a small corpus of DA training data.", "startOffset": 0, "endOffset": 19}, {"referenceID": 2, "context": "In (Aminian et al., 2014) the specific problem of out-of-vocabulary words in MT for DA is addressed by replacing DA words with their MSA equivalents.", "startOffset": 3, "endOffset": 25}, {"referenceID": 1, "context": "In principle, automatic dialect identification methods (Alorifi, 2008; Sadat et al., 2014; Zaidan and Callison-Burch, 2014) might be used for this purpose; however, these methods are themselves error-prone and have not been developed for all dialects of Arabic.", "startOffset": 55, "endOffset": 123}, {"referenceID": 26, "context": "In principle, automatic dialect identification methods (Alorifi, 2008; Sadat et al., 2014; Zaidan and Callison-Burch, 2014) might be used for this purpose; however, these methods are themselves error-prone and have not been developed for all dialects of Arabic.", "startOffset": 55, "endOffset": 123}, {"referenceID": 29, "context": "Two different data selection methods are investigated, the widely-used cross entropy method of (Moore and Lewis, 2010), and a more recent submodular data selection method (Wei et al., 2013).", "startOffset": 171, "endOffset": 189}, {"referenceID": 3, "context": "In (Axelrod et al., 2011) the monolingual selection method is extended to bilingual corpora.", "startOffset": 3, "endOffset": 25}, {"referenceID": 8, "context": "In (Duh et al., 2013), neural language models are used instead of backoff language models.", "startOffset": 3, "endOffset": 21}, {"referenceID": 22, "context": "Finally, (Mediani et al., 2014) propose a different method for drawing the out-of-domain sample and the use of word-association models to improve the data for training the out-of-domain language model.", "startOffset": 9, "endOffset": 31}, {"referenceID": 9, "context": "Submodular functions (Edmonds, 1970; Fujishige, 2005) were first developed in mathematics, operations research and economics; more recently, they have been used for a variety of optimization problems in machine learning as well.", "startOffset": 21, "endOffset": 53}, {"referenceID": 19, "context": "For example, they have been applied to the problems of clustering (Narasimhan and Bilmes, 2007), observation selection (Krause et al., 2008), sensor placement (Krause and Guestrin, 2011), or image segmentation (Jegelka and Bilmes, 2011).", "startOffset": 119, "endOffset": 140}, {"referenceID": 10, "context": "Solving this problem exactly is NP-complete (Feige, 1998), and expressing it as an ILP procedure renders it impractical for large data sizes.", "startOffset": 44, "endOffset": 57}, {"referenceID": 25, "context": "63 f (Xopt) where Xopt is the optimal and X\u0303\u2217 is the greedy solution (Nemhauser et al., 1978).", "startOffset": 69, "endOffset": 93}, {"referenceID": 17, "context": "We use two different MT systems for translation from IA to English, an in-house system based on Moses and the SRI MT system developed for the DARPA BOLT (Broad Operational Language Translation) spoken dialog translation project (see (Ayan et al., 2013; Kirchhoff et al., 2015) for more details).", "startOffset": 233, "endOffset": 276}, {"referenceID": 32, "context": "The second system is similar in nature but has a hierarchical phrase-based translation model and utilizes sparse features (see (Zhao et al., 2014) for more information).", "startOffset": 127, "endOffset": 146}], "year": 2015, "abstractText": "Statistical machine translation for dialectal Arabic is characterized by a lack of data since data acquisition involves the transcription and translation of spoken language. In this study we develop techniques for extracting parallel data for one particular dialect of Arabic (Iraqi Arabic) from out-ofdomain corpora in different dialects of Arabic or in Modern Standard Arabic. We compare two different data selection strategies (cross-entropy based and submodular selection) and demonstrate that a very small but highly targeted amount of found data can improve the performance of a baseline machine translation system. We furthermore report on preliminary experiments on using automatically translated speech data as additional training data.", "creator": "LaTeX with hyperref package"}}}