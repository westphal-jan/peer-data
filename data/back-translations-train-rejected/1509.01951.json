{"id": "1509.01951", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2015", "title": "Hierarchical Deep Learning Architecture For 10K Objects Classification", "abstract": "Evolution of visual object recognition architectures based on Convolutional Neural Networks &amp; Convolutional Deep Belief Networks paradigms has revolutionized artificial Vision Science. These architectures extract &amp; learn the real world hierarchical visual features utilizing supervised &amp; unsupervised learning approaches respectively. Both the approaches yet cannot scale up realistically to provide recognition for a very large number of objects as high as 10K. We propose a two level hierarchical deep learning architecture inspired by divide &amp; conquer principle that decomposes the large scale recognition architecture into root &amp; leaf level model architectures. Each of the root &amp; leaf level models is trained exclusively to provide superior results than possible by any 1-level deep learning architecture prevalent today. The proposed architecture classifies objects in two steps. In the first step the root level model classifies the object in a high level category. In the second step, the leaf level recognition model for the recognized high level category is selected among all the leaf models. This leaf level model is presented with the same input object image which classifies it in a specific category. Also we propose a blend of leaf level models trained with either supervised or unsupervised learning approaches. Unsupervised learning is suitable whenever labelled data is scarce for the specific leaf level models. Currently the training of leaf level models is in progress; where we have trained 25 out of the total 47 leaf level models as of now. We have trained the leaf models with the best case top-5 error rate of 3.2% on the validation data set for the particular leaf models. Also we demonstrate that the validation error of the leaf level models saturates towards the above mentioned accuracy as the number of epochs are increased to more than sixty.", "histories": [["v1", "Mon, 7 Sep 2015 08:49:39 GMT  (708kb)", "http://arxiv.org/abs/1509.01951v1", "As appeared in proceedings for CS &amp; IT 2015 - Second International Conference on Computer Science &amp; Engineering (CSEN 2015)"]], "COMMENTS": "As appeared in proceedings for CS &amp; IT 2015 - Second International Conference on Computer Science &amp; Engineering (CSEN 2015)", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["atul laxman katole", "krishna prasad yellapragada", "amish kumar bedi", "sehaj singh kalra", "mynepalli siva chaitanya"], "accepted": false, "id": "1509.01951"}, "pdf": {"name": "1509.01951.pdf", "metadata": {"source": "CRF", "title": "HIERARCHICAL DEEP LEARNING ARCHITECTURE FOR 10K OBJECTS CLASSIFICATION", "authors": ["Atul Laxman Katole", "Krishna Prasad Yellapragada", "Amish Kumar Bedi", "Sehaj Singh Kalra", "Mynepalli Siva Chaitanya"], "emails": [], "sections": [{"heading": null, "text": "The development of visual object recognition architectures based on Convolutional Neural Networks & Convolutional Deep Belief Networks paradigms has revolutionized artificial vision science.These architectures extract and learn the hierarchical visual features of the real world by using supervised and unsupervised learning approaches, neither of which can yet be realistically scaled to provide recognition for a very large number of objects up to 10K. We propose a hierarchical deep learning architecture inspired by the Divide & Conquer principle, which breaks down the large-scale recognition architecture into root & leaf model architecture.Each of the root & leaf models is trained exclusively to deliver better results than possible through a currently prevailing 1-level deep learning architecture.The proposed architecture classifies objects in two steps. In the first step, the root-level model classifies the object into a high-level category. In the second step, the high-level recognition model is recognized for the high-level category."}, {"heading": "1. INTRODUCTION", "text": "Deep Learning based vision architectures learn to extract & represent visual features with model architecture that are composed of layers of non-linear transformations stacked on each [1]; learn high level abstractions from low level features extracted from images using supervised or unsupervised learning algorithms [2]; expand unattended learning algorithms that train deep faith networks toward training convolutional networks have shown that they scale to realistic image sizes [4]; both supervised and unsupervised learning approaches have matured and have created architectures that can successfully classify objects into 1000 & 100 categories; but neither approach can realistically scale to classify objects out of 10K categories."}, {"heading": "2. RELATED WORKS", "text": "We have not encountered any work that uses a hierarchical architecture of deep learning on two levels to classify 10K objects in images, but object detection on this large scale using flat architectures using SVMs is discussed in [5] This work presents a study on large-scale categorization with more than 10K image classes using multi-scale spatial pyramids (SPM) [14] on bags of visual words (BOW) [13] for Feature Extraction & Support Vector Machines (SVM) for classification, which creates ten different datasets, each derived from ImageNet with 200 to 10,000 categories. On the basis of these datasets, the impact on classification accuracy is determined based on different factors such as the number of labels in a dataset, the density of the dataset and the hierarchy of labels in a dataset. Methods are proposed that predict the classifier's expanded information about the relationship between different labels based on the total cost structure of a fictitious class, which can be calculated by predicting the total cost structure of a 10K."}, {"heading": "3. PROBLEM STATEMENT", "text": "Supervised learning based on deep visual recognition CNN architectures consist of several stacked convolutionary levels to learn hierarchical visual characteristics [1] as illustrated in Figure 1. Regularization approaches such as stochastic pooling, dropout, and data expansion have been used to increase detection accuracy. Lately, the faster convergence of these architectures has been attributed to the inclusion of rectified linear units [ReLU] nonlinearity in each layer of weight. the reported top 5 error rate is 4.9% for classification into 1K categories [6] using the generic architectural elements mentioned above in 22 layers of weight.Unattended learning-based architectural model as a convolutionary DBN learns the visual feature hierarchy by greedily training layer by layer by layer. These architectures have an accuracy of 65.5% for the objects reported as not yet realistic for classification of both 10101 architectures [1]."}, {"heading": "4. PROPOSED METHOD", "text": "The proposed architecture classifies objects in two steps as follows: 1. Root Level Model Architecture: In the first step, the root, i.e. the first level in the architectural hierarchy, recognizes high-level categories. This very deep-sighted architectural model with 14 layers of weight [3] is trained among all leaf models with stochastic gradient descent [2]. The architectural elements are presented in Table 1.2. Leaf Level Model Architecture: In the second step, the leaf identification model is selected for the recognized high-level category among all leaf models. This leaf identification model is presented using the same input object image that classifies it in a specific category. Leaf architecture in the architectural hierarchy recognizes specific objects or finer categories. This model is compiled using chaotic gradient model descent models of CDM [102] which can be coached on a CDM subgradient model of an architectural element [102]."}, {"heading": "5. SUPERVISED TRAINING", "text": "In the vision, the lower properties [e.g. pixels, edge-lets, etc.] are merged into high-level abstractions [e.g. edges, motifs], and these higher-level abstractions are merged into further higher-level abstractions [e.g. object parts, objects], etc. A significant portion of the detection models in our two-level hierarchical architecture are trained through supervised trainings. The algorithms used in this method are called error-back propagation algorithms. These algorithms require a significantly high number of labeled training images per object category in their dataset."}, {"heading": "5.1. CNN based Architecture", "text": "CNN is a biologically inspired architecture in which several traceable revolutionary steps are stacked on top of each other. Each CNN layer learns extractors in the hierarchy of visual characteristics and attempts to mimic the trait hierarchy of the human visual system, which manifests itself in different areas of the human brain as V1 & V2. [10] Finally, the fully connected layers act as trait classifiers and learn to classify the extracted features of the CNN layers into different categories or objects. The fully connected layers can be compared to the V4 region of the brain, which classifies the hierarchical features as being generated by area V2. In our architecture, the root plane and CNN models at the leaf level are trained with a supervised, weight-shifting backspread method. In this learning method, the objective cross entropy is compared with the error-correction learning rule / -minimization mechanism that actually relates to the local weights calculated in the error course mechanism."}, {"heading": "5.2. Architectural Elements", "text": "The proposed architecture consists of the following elements: Enhanced Discriminative Function: We have selected deeper architectures and smaller nuclei for the root and leaf models, as they make the objective function more discriminatory; this can be interpreted as making the training process more difficult by making it more difficult to select the trait extractors from the higher dimensional feature space. ReLU Nonlinearity: We have used ReLU nonlinearity against sigmoidal, i.e. non-saturating nonlinearity in each layer, as it reduces the training time by approaching the weights more quickly [2]. Pooling: The output of the revolutionary ReLU combination is fed to a pool layer according to alternative revolutionary layers. The output of the pool layer is invariant to the slightest changes in the location of the features in the object. The pooling method is either maxpooling or stochastic pooling."}, {"heading": "5.3. Training Process", "text": "We have modified libCCV's open source CNN implementation to realize the proposed architecture trained on NVIDIA GTX \u2122 TITAN GPUs. The root and leaf models are trained with stochastic gradient pedigree [2].The leaf models are trained simultaneously as batches of 10 models per GPU on the two GPU systems.The first 4 leaf models were initialized from the ground up and trained for 15 epochs with a learning rate of 0.01 and a momentum of 0.9.The rest of the leaf models are initialized from the trained leaf models and trained at a learning rate of 0.001.The root model was trained for 32 epochs with a learning rate of 0.001 after being initialized by a similar model trained on ImageNet 1K data.It takes 10 days to train a stack of 20 leaf models for 15 epochs. Currently, the root model and 25 September / 47 work is estimated to be completed within these 15th and 5th weeks."}, {"heading": "6. UNSUPERVISED TRAINING", "text": "Statistical mechanics has fundamentally inspired the concept of unattended training. Statistical mechanics, in particular, is the study of the macroscopic equilibrium properties of large systems of elements based on the motion of atoms and electrons. Due to the enormous degree of freedom required by the foundations of statistical mechanics, the use of probabilistic methods is the most suitable candidate for modelling the characteristics that make up the training data sets [9]."}, {"heading": "6.1. CDBN based Architecture", "text": "The networks trained with statistical mechanisms model the underlying training data sets using the Boltzmann distribution. To avoid the painfully slow training time required to train the Boltzmann machines, several variants of the same have been proposed, with the Restricted Boltzmann Machine [RBM] being the one that provides the best possible modeling capabilities in a minimum of time. The resulting stacks of RBM layers are trained layer by layer [4], leading to the Deep Belief Networks [DBN] that successfully document the solution for image [1-4], speech recognition [8] and callable problem domains. DBN can be described as multi-layer generative models that learn the hierarchy of non-linear feature detectors. The lower layer learns low-layer features that flow into the higher level and help them to learn complex traits. The resulting network maximizes the likelihood that the training data has its own boundaries."}, {"heading": "6.2. Training Process", "text": "The updates of the hidden units in the positive phase of the CD-1 step were done with sampling, rather than using the real estimated probabilities. Also, we had used mini-batch size of 10 in the training.We had monitored the accuracy of the training using -1. Reconstruction error: It refers to the square error between the original data and the reconstructed data.While it does not guarantee exact training, it should generally decrease during the training.Also, any large increase indicates that the training is misworking.2. Weight Printout: Finally, what you learn must be visualized as oriented, localized edge filters.Pressure weights during the training help determine whether the weights of this filter-like form \"approach.\" If the ratio of the variance of reconstructed data to the variance of the input image is greater than 2, we reduce the learning rate by a factor of 0.9 to 0.9 and the chosen weight setting is not increased to 0.9."}, {"heading": "7. TWO-LEVEL HIERARCHY CREATION", "text": "The two-level hierarchy design for classifying 10K object categories requires decision-making based on the following parameters: 1. Number of sheet models to train and 2. Number of output nodes in each sheet model. To determine these parameters, we first create a hierarchy tree from the 10184 synsets (classes) in the ImageNet10K dataset (as described in Section 7.1), and then try to divide and organize all classes into 64 sheet models, each with a maximum of 256 classes, using a set of thumb rules (as described in Section 7.2)."}, {"heading": "7.1. Building Hierarchical Tree", "text": "The WordNet-ISA relationship is a file that lists the parent-child relationships between the synsets in ImageNet. For example, a line \"n02403454 n02403740\" in the relationship file refers to the parent-child synset as n02403454 (cow) and child synset as n02403740 (heifer). Since the depth of a synset in the ImageNet hierarchy has no relation to its semantic label, we focused on forming the deepest branch for a synset, i.e. heifer is also the child of another category n01321854 (young mammal). We used a simplified method that exploits the relationship between synset ID and depth; the deeper a category nXXX, the greater its number. Therefore, we used the parent category of the heifer as the basis for a synset."}, {"heading": "7.2. Thumb-rules for Building Hierarchical Tree", "text": "The hierarchy tree indicates that the data set is distorted into categories such as flora, animal, fungus, natural objects, instruments, etc., which are closer to the tree root, i.e. 80% of the synsets fall under 20% of the branches. Taking into account the number of models to train and the time and resources required to fine-tune each model, the following rules of thumb were adopted to define the solution parameters: 1. The ideal hierarchy will have 64 leaf models, each capable of classifying 256 categories 2. The root and leaf model synsets must be decided in such a way that the hierarchy structure is as flat as possible 3. The total number of synsets in a leaf model should be less than 256 and 4. If leaf models have more than 256 subcategories, the remaining subcategories will be split or merged with another leaf."}, {"heading": "7.3. Final Solution Parameters", "text": "The final solution parameters are as follows: 47 sheet models, with each sheet model classified from 200 to 256 synsets."}, {"heading": "8. RESULTS", "text": "We formulate the Root & Leaf models into a hierarchy on 2 levels. In all root-level models and 47 Leaf-level models, this architecture must be completed by mid-September. Each Leaf-level model recognizes categories ranging from 45 to 256 numbers. We use ImageNet10K datasets [7] derived from 10184 synsets of the release of ImageNet.Each Leaf node has at least 200 labeled images, covering a total of 9M pictures.The top 5 error rates for 25 of 47 Leaf-level models have been calculated.The graph in Fig. 5 records the top 5 errors of Leaf models in relation to training epochs. We observe that when the Leaf models are trained with a higher number of training epochs, the top 5 error rates for the complete 10K object classification decrease."}, {"heading": "9. CONCLUSIONS", "text": "The top 5 failure rate for the entire two-tiered architecture must be calculated in conjunction with the failure rates of root & leaf models. The implementation of this two-tiered visual recognition architecture will greatly simplify the object detection scenario for large-scale object detection problems.At the same time, the proposed two-tiered hierarchical deep learning architecture will help significantly increase the accuracy of complex object detection scenarios. The trade in the proposed two-tiered architecture is the size of the hierarchical detection model. The total size of the two-tiered detection models, including root & leaf models, is approximately 5Gb. This size could limit the execution of the entire architecture to low-end devices.The same size is not a limitation when executed with high-end device or cloud-based detection models where the RAM size is higher. Apart from this, we can use the two-tiered hierarchical model for always splitting the cloud between the devices and the cloud."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We take this opportunity to thank our mentor Dr. Shankar M Venkatesan and offer our deepest greetings for his guidance and constant encouragement. Without his support, it would not have been possible to realize this essay."}], "references": [{"title": "Convolutional Networks and Applications in Vision,", "author": ["Yann LeCun", "Koray Kavukvuoglu", "Cl\u00e9ment Farabet"], "venue": "in Proc. International Symposium on Circuits and Systems", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "ImageNet classification with deep convolutional neural networks", "author": [], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "in arXiv technical report,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H Lee", "R Grosse", "R Ranganath", "AY Ng"], "venue": "Proceedings of the 26th International Conference on Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "What Does Classifying More Than 10,000 Image Categories Tell Us?", "author": ["Jia Deng", "Alexander C. Berg", "Kai Li", "Li Fei-Fei"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "and L", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li"], "venue": "Fei-Fei., \u201cImageNet: A Large-Scale Hierarchical Image Database\u201d, in CVPR09", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition", "author": ["George E. Dahl", "Dong Yu", "Li Deng", "Alex Acero"], "venue": "IEEE Transactions on Audio, Speech & Language Processing", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Neural Networks: A Comprehensive Foundation", "author": ["S. Haykin"], "venue": "3rd ed., New Jersey, Prentice Hall", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Higher Order Visual Processing in Macaque Extrastriate Cortex\" ,Physiological", "author": ["G. Orban"], "venue": "Reviews, Vol. 88,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Pooling for Regularization of Deep Convolutional Neural Networks", "author": ["Matthew D. Zeiler", "Rob Fergus", "\u201dStochastic"], "venue": "in ICLR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Visual categorization with bags of keypoints", "author": ["C.R. Dance", "J. Willamowski", "L. Fan", "C. Bray", "G. Csurka"], "venue": "ECCV International Workshop on Statistical Learning in Computer Vision", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "IEEE Computer Society Conf. Computer Vision and Pattern Recognition", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Deep learning based vision architectures learn to extract & represent visual features with model architectures that are composed of layers of non-linear transformations stacked on top of each other [1].", "startOffset": 198, "endOffset": 201}, {"referenceID": 1, "context": "Recent advances in training CNNs with gradient descent based backpropagation algorithm have shown very accurate results due to inclusion of rectified linear units as nonlinear transformation [2].", "startOffset": 191, "endOffset": 194}, {"referenceID": 3, "context": "Also extension of unsupervised learning algorithms that train deep belief networks towards training convolutional networks have exhibited promise to scale it to realistic image sizes [4].", "startOffset": 183, "endOffset": 186}, {"referenceID": 4, "context": "But object recognition on this large scale using shallow architectures utilizing SVMs is discussed in [5].", "startOffset": 102, "endOffset": 105}, {"referenceID": 11, "context": "This effort presents a study of large scale categorization with more than 10K image classes using multi-scale spatial pyramids (SPM) [14] on bag of visual words (BOW) [13] for feature extraction & Support Vector Machines (SVM) for classification.", "startOffset": 133, "endOffset": 137}, {"referenceID": 10, "context": "This effort presents a study of large scale categorization with more than 10K image classes using multi-scale spatial pyramids (SPM) [14] on bag of visual words (BOW) [13] for feature extraction & Support Vector Machines (SVM) for classification.", "startOffset": 167, "endOffset": 171}, {"referenceID": 0, "context": "Supervised learning based deep visual recognition CNN architectures are composed of multiple convolutional stages stacked on top of each other to learn hierarchical visual features [1] as captured in Figure 1.", "startOffset": 181, "endOffset": 184}, {"referenceID": 3, "context": "4% for classifying 101 objects [4].", "startOffset": 31, "endOffset": 34}, {"referenceID": 2, "context": "This very deep vision architectural model with 14 weight layers [3] is trained using stochastic gradient descent [2].", "startOffset": 64, "endOffset": 67}, {"referenceID": 1, "context": "This very deep vision architectural model with 14 weight layers [3] is trained using stochastic gradient descent [2].", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "This model is trained using stochastic gradient descent [2].", "startOffset": 56, "endOffset": 59}, {"referenceID": 3, "context": "CDBN based leaf level models can be trained with unsupervised learning approach in case of scarce labelled images [4].", "startOffset": 114, "endOffset": 117}, {"referenceID": 4, "context": "We use ImageNet10K dataset [5], which is compiled from 10184 synsets of the Fall-2009 release of ImageNet.", "startOffset": 27, "endOffset": 30}, {"referenceID": 8, "context": "Each CNN layer learns feature extractors in the visual feature hierarchy and attempts to mimic the human visual system feature hierarchy manifested in different areas of human brain as V1 & V2 [10].", "startOffset": 193, "endOffset": 197}, {"referenceID": 1, "context": "non-saturating nonlinearities in each layer as it reduces the training time by converging upon the weights faster [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 9, "context": "This distribution is computed from the neuron activation within the given region [12].", "startOffset": 81, "endOffset": 85}, {"referenceID": 1, "context": "The root & leaf level models are trained using stochastic gradient descent [2].", "startOffset": 75, "endOffset": 78}, {"referenceID": 7, "context": "The enormous degree of freedom as necessitated by statistical mechanics foundation makes the use of probabilistic methods to be the most suitable candidate for modelling features that compose the training data sets [9].", "startOffset": 215, "endOffset": 218}, {"referenceID": 3, "context": "The resulting stacks of RBM layers are greedily trained layer by layer [4] resulting in the Deep Belief Networks [DBN] that successfully provides the solution to image [1- 4], speech recognition [8] and document retrieval problem domains.", "startOffset": 71, "endOffset": 74}, {"referenceID": 3, "context": "The resulting stacks of RBM layers are greedily trained layer by layer [4] resulting in the Deep Belief Networks [DBN] that successfully provides the solution to image [1- 4], speech recognition [8] and document retrieval problem domains.", "startOffset": 168, "endOffset": 174}, {"referenceID": 6, "context": "The resulting stacks of RBM layers are greedily trained layer by layer [4] resulting in the Deep Belief Networks [DBN] that successfully provides the solution to image [1- 4], speech recognition [8] and document retrieval problem domains.", "startOffset": 195, "endOffset": 198}, {"referenceID": 3, "context": "But DBN has its own limitations when scaling to realistic image sizes [4].", "startOffset": 70, "endOffset": 73}, {"referenceID": 3, "context": "We perform the block Gibbs sampling using conditional distribution as suggested in [4] to learn the convolutional weights connecting the visible and hidden layers where v and h are activations of neurons in visible & hidden layers respectively.", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "We had probabilistic Max Pooling layers after convolutional layers [4].", "startOffset": 67, "endOffset": 70}, {"referenceID": 5, "context": "We use ImageNet10K dataset [7], which is compiled from 10184 synsets of the Fall-2009 release of ImageNet.", "startOffset": 27, "endOffset": 30}], "year": 2015, "abstractText": "Evolution of visual object recognition architectures based on Convolutional Neural Networks & Convolutional Deep Belief Networks paradigms has revolutionized artificial Vision Science. These architectures extract & learn the real world hierarchical visual features utilizing supervised & unsupervised learning approaches respectively. Both the approaches yet cannot scale up realistically to provide recognition for a very large number of objects as high as 10K. We propose a two level hierarchical deep learning architecture inspired by divide & conquer principle that decomposes the large scale recognition architecture into root & leaf level model architectures. Each of the root & leaf level models is trained exclusively to provide superior results than possible by any 1-level deep learning architecture prevalent today. The proposed architecture classifies objects in two steps. In the first step the root level model classifies the object in a high level category. In the second step, the leaf level recognition model for the recognized high level category is selected among all the leaf models. This leaf level model is presented with the same input object image which classifies it in a specific category. Also we propose a blend of leaf level models trained with either supervised or unsupervised learning approaches. Unsupervised learning is suitable whenever labelled data is scarce for the specific leaf level models. Currently the training of leaf level models is in progress; where we have trained 25 out of the total 47 leaf level models as of now. We have trained the leaf models with the best case top-5 error rate of 3.2% on the validation data set for the particular leaf models. Also we demonstrate that the validation error of the leaf level models saturates towards the above mentioned accuracy as the number of epochs are increased to more than sixty. The top-5 error rate for the entire two-level architecture needs to be computed in conjunction with the error rates of root & all the leaf models. The realization of this two level visual recognition architecture will greatly enhance the accuracy of the large scale object recognition scenarios demanded by the use cases as diverse as drone vision, augmented reality, retail, image search & retrieval, robotic navigation, targeted advertisements etc.", "creator": "Microsoft\u00ae Word 2010"}}}