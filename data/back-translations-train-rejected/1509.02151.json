{"id": "1509.02151", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2015", "title": "C3: Lightweight Incrementalized MCMC for Probabilistic Programs using Continuations and Callsite Caching", "abstract": "Lightweight, source-to-source transformation approaches to implementing MCMC for probabilistic programming languages are popular for their simplicity, support of existing deterministic code, and ability to execute on existing fast runtimes. However, they are also slow, requiring a complete re-execution of the program on every Metropolis Hastings proposal. We present a new extension to the lightweight approach, C3, which enables efficient, incrementalized re-execution of MH proposals. C3 is based on two core ideas: transforming probabilistic programs into continuation passing style (CPS), and caching the results of function calls. We show that on several common models, C3 reduces proposal runtime by 20-100x, in some cases reducing runtime complexity from linear in model size to constant. We also demonstrate nearly an order of magnitude speedup on a complex inverse procedural modeling application.", "histories": [["v1", "Mon, 7 Sep 2015 19:35:42 GMT  (891kb,AD)", "https://arxiv.org/abs/1509.02151v1", null], ["v2", "Tue, 8 Sep 2015 17:53:35 GMT  (891kb,AD)", "http://arxiv.org/abs/1509.02151v2", "Fix typo in author name"]], "reviews": [], "SUBJECTS": "cs.AI cs.PL", "authors": ["daniel ritchie", "reas stuhlm\\\"uller", "noah d goodman"], "accepted": false, "id": "1509.02151"}, "pdf": {"name": "1509.02151.pdf", "metadata": {"source": "CRF", "title": "C3: Lightweight Incrementalized MCMC for Probabilistic Programs using Continuations and Callsite Caching", "authors": ["Daniel Ritchie", "Andreas Stuhlm\u00fcller", "Noah D. Goodman"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2 Approach", "text": "It is indeed the case that we will be able to fulfil the demands that have been made, in the way that we put them into practice."}, {"heading": "3 Compile-time Source Transformations", "text": "Light MH transforms the source code of probability programs to calculate random addresses; the transformed code can then be executed at existing runtimes for the deterministic language of the host. C3 fits into this framework by adding three additional source transformations: caching, function marking, and a default sequel style transform for functional languages. Caching This transformation encloses each function call page with a call to an intrinsic cache function (Figure 2 center). This function performs runtime cache queries, as in Section 4.Function marking This transformation analyzes the body of each function and marks the function with both a lexical unique ID and the values of its free variables (Figure 2 right). In Section 4, we describe how C3 uses this information to decide whether a function call needs to be executed again. The final source transformation reads: Caching \u2192 Caching \u2192 Address Summation \u2192 Fact, as it can now be applied frequently."}, {"heading": "4 Runtime Caching Implementation", "text": "In this section we describe how C3 efficiently implements these two types of computational \"short circuits\" for probabilistic function programs. Figure 3 shows the high-level code for the most important subroutines that control the caching system."}, {"heading": "4.1 Cache Representation", "text": "C3 uses a tree-structured cache: it stores one node for each function call. The children of a node correspond to the callees of the function. Random decisions are stored as leaf nodes. C3 also maintains a stack of nodes that tracks the program call stack (nodeStack in Figure 3). In cache searches, the desired node, if it exists, must be a child of the node on top of that stack. Exploiting this property speeds up searches that would otherwise come from the cache root. Overall, this structure provides expected constant time searches, additions, and deletions. In addition, C3 can efficiently determine when a child node has become \"stale\" (i.e. unreachable) by storing the children of a node in execution order. A child node is marked as parent node when it is unreachable, or when its execution is started on line 6 (unreachable)."}, {"heading": "4.2 Short-Circuit On Function Entry", "text": "As described in Section 3, each function call is wrapped up in a cache call that retrieves (or creates) a cache node for the current address. C3 then evaluates whether the associated function call of the node needs to be re-evaluated or whether its previous return value can be reused (the execute function). Reuse is possible if the following two criteria are met: 1. The arguments of the function are equivalent to those of the previous execution; 2. The function itself is equivalent to those of the previous execution; the first criterion can be verified with conservative equality tests; C3 uses low-value equality tests, although deeper equality tests may result in greater reuse for structured argument types."}, {"heading": "4.3 Short-Circuit On Function Exit", "text": "If C3 executes the program again after changing a random selection (using the Propagate function), the controller may at some point return to a function call whose return value has not changed. In this case, C3 can terminate the execution prematurely by calling the exit continuation kexit. During the function exit, the execution function of C3 detects whether the controller returns from a suggestion by checking whether the call is terminated without having been entered beforehand (line 20). This condition signals that the current reexecution comes from a descendant of the outgoing call, i.e. a random selection number 1 / / / Use the query table to derive 2 / / the sequence of latent states. 3 var hmm = Function (n, obs) {4 if (n = = 0) 5 return values are true; 6 otherwise {7 var prev = hmm = hmm, mm = transition data; 8 var (9); prev (n); 11 if the observation is changed."}, {"heading": "4.4 Optimizations", "text": "C3 makes sure that the amount of work it does in response to a cache proposal is only proportional to the amount of track of the program execution affected by this proposal. Firstly, it keeps references to all random choices in a hash table that offers expected constant time additions, deletions and random element searches. This table enables C3 to perform a uniform random selection in constant time instead of the linear time cost of scanning through the entire cache. 14 Secondly, suggestions can be rejected, which requires copying the cache if its previous state has to be restored on rejection. C3 avoids copying the entire cache by means of a copy-on-write schema with principles similar to transactional memory [14]: Changes to the properties of a cache node are staged and only obliged if the proposal is accepted. Therefore, C3 copies only as much of the cache as it actually visits cache during the reexecution of the cache proposal Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- Cache- CacheCache- Cache- Cache- CacheCache- CacheCache- CacheCache- CacheCache- Cache- CacheCache- CacheCacheCacheCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCeCe"}, {"heading": "5 Experimental Results", "text": "This year it is more than ever before."}, {"heading": "6 Related Work", "text": "The ideas behind C3 have links to other areas of active research. First, the gradual creation of MCMC proposals for PPLs falls under the umbrella of incremental computation [18]. Much of the active work in this area is aimed at developing universal languages and compilers to be able to incrementalize any program [19]. However, there are systems like ours that look for simpler solutions to domain-specific incrementalization problems. In particular, the C3 cache caching mechanism was partly inspired by recent work in computer graphics on hierarchical rendering caches [20]. 1Venture PPL has an algorithm for gradually updating a probable execution trace in response to a random change [5]. This method, implemented as part of a user-defined interpreter, tracks the structure emanating from the modified node, identifies nodes that need to be quickly updated or removed, and can determine when a reassessment needs to be completed."}, {"heading": "7 Discussion and Future Work", "text": "In this paper, C3 was introduced, a lightweight source-to-source compilation system for incrementalizing MCMC updates in probability programs. We described how the two main components of C3, continuations and call-site caching, allow both function calls to be re-executed and to finish re-execution prematurely. Our experimental results show that C3 can provide incremental acceleration compared to previous lightweight inference systems on typical generative models. It even allows constant updates in some cases where previous systems took linear time. We also show that C3 improves performance almost tenfold on a complex, computer-heavy inverse process modeling problem. Our implementation of C3 is freely available as part of the open source programming language WebPPPL. Careful optimization of computing efficiency, as demonstrated in this paper, is necessary to transform the PLCum during the work."}], "references": [{"title": "Lightweight Implementations of Probabilistic Programming Languages Via Transformational Compilation", "author": ["David Wingate", "Andreas Stuhlm\u00fcller", "Noah D. Goodman"], "venue": "AISTATS", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "BLOG: Probabilistic Models with Unknown Objects", "author": ["Brian Milch", "Bhaskara Marthi", "Stuart J. Russell", "David Sontag", "Daniel L. Ong", "Andrey Kolobov"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Figaro: An object-oriented probabilistic programming language", "author": ["A. Pfeffer"], "venue": "Technical report, Charles River Analytics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Church: a language for generative models", "author": ["Noah D. Goodman", "Vikash K. Mansinghka", "Daniel M. Roy", "Keith Bonawitz", "Joshua B. Tenenbaum"], "venue": "UAI", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["Vikash K. Mansinghka", "Daniel Selsam", "Yura N. Perov"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "A New Approach to Probabilistic Programming Inference", "author": ["F. Wood", "J.W. van de Meent", "V. Mansinghka"], "venue": "AISTATS", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "The Design and Implementation of Probabilistic Programming Languages", "author": ["Noah D Goodman", "Andreas Stuhlm\u00fcller"], "venue": "http://dippl.org,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Quicksand: A Lightweight Embedding of Probabilistic Programming for Procedural Modeling and Design", "author": ["Daniel Ritchie"], "venue": "In The 3rd NIPS Workshop on Probabilistic Programming,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Context-specific Independence in Bayesian Networks", "author": ["Craig Boutilier", "Nir Friedman", "Moises Goldszmidt", "Daphne Koller"], "venue": "UAI", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1996}, {"title": "Compiling with Continuations", "author": ["Andrew W. Appel"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Monocopy and associative algorithms in an extended lisp", "author": ["E. Goto"], "venue": "Technical report,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1974}, {"title": "Global Value Numbers and Redundant Computations", "author": ["B.K. Rosen", "M.N. Wegman", "F.K. Zadeck"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Transactional Memory: Architectural Support for Lockfree Data Structures", "author": ["Maurice Herlihy", "J. Eliot B. Moss"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1993}, {"title": "Controlling Procedural Modeling Programs with Stochastically-Ordered Sequential Monte Carlo", "author": ["Daniel Ritchie", "Ben Mildenhall", "Noah D. Goodman", "Pat Hanrahan"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Generating Efficient MCMC Kernels from Probabilistic Programs", "author": ["Lingfeng Yang", "Pat Hanrahan", "Noah D. Goodman"], "venue": "AISTATS", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "A Categorized Bibliography on Incremental Computation", "author": ["G. Ramalingam", "Thomas Reps"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1993}, {"title": "Type-Directed Automatic Incrementalization", "author": ["Yan Chen", "Joshua Dunfield", "Umut A. Acar"], "venue": "PLDI", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Lazy Incremental Computation for Efficient Scene Graph Rendering", "author": ["Michael W\u00f6rister", "Harald Steinlechner", "Stefan Maierhofer", "Robert F. Tobler"], "venue": "HPG", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "SWIFT: Compiled Inference for Probabilistic Programs", "author": ["Lei Li", "Yi Wu", "Stuart J. Russell"], "venue": "Technical report,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Following a moving target\u2014Monte Carlo inference for dynamic Bayesian models", "author": ["Walter R. Gilks", "Carlo Berzuini"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Lightweight, source-to-source transformation approaches to implementing MCMC for probabilistic programming languages are popular for their simplicity, support of existing deterministic code, and ability to execute on existing fast runtimes [1].", "startOffset": 240, "endOffset": 243}, {"referenceID": 1, "context": "Many different PPL systems have been proposed, such as BLOG [2], Figaro [3], Church [4], Venture [5], Anglican [6], and Stan [7].", "startOffset": 60, "endOffset": 63}, {"referenceID": 2, "context": "Many different PPL systems have been proposed, such as BLOG [2], Figaro [3], Church [4], Venture [5], Anglican [6], and Stan [7].", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "Many different PPL systems have been proposed, such as BLOG [2], Figaro [3], Church [4], Venture [5], Anglican [6], and Stan [7].", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "Many different PPL systems have been proposed, such as BLOG [2], Figaro [3], Church [4], Venture [5], Anglican [6], and Stan [7].", "startOffset": 97, "endOffset": 100}, {"referenceID": 5, "context": "Many different PPL systems have been proposed, such as BLOG [2], Figaro [3], Church [4], Venture [5], Anglican [6], and Stan [7].", "startOffset": 111, "endOffset": 114}, {"referenceID": 0, "context": "One popular choice is the \u2018Lightweight MH\u2019 framework [1].", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "For example, Stochastic Matlab can access Matlab\u2019s rich matrix and image manipulation routines [1], WebPPL runs on Google\u2019s highly-optimized V8 Javascript engine [8], and Quicksand\u2019s host language compiles to fast machine code using LLVM [9].", "startOffset": 95, "endOffset": 98}, {"referenceID": 6, "context": "For example, Stochastic Matlab can access Matlab\u2019s rich matrix and image manipulation routines [1], WebPPL runs on Google\u2019s highly-optimized V8 Javascript engine [8], and Quicksand\u2019s host language compiles to fast machine code using LLVM [9].", "startOffset": 162, "endOffset": 165}, {"referenceID": 7, "context": "For example, Stochastic Matlab can access Matlab\u2019s rich matrix and image manipulation routines [1], WebPPL runs on Google\u2019s highly-optimized V8 Javascript engine [8], and Quicksand\u2019s host language compiles to fast machine code using LLVM [9].", "startOffset": 238, "endOffset": 241}, {"referenceID": 8, "context": "ues are preserved and reused when possible, limiting the effect of a proposal to a subset of the changed variable\u2019s Markov blanket (sometimes a much smaller subset, due to context-specific independence [10]).", "startOffset": 202, "endOffset": 206}, {"referenceID": 4, "context": "Custom PPL interpreters can leverage this property to incrementalize proposal re-execution [5], but implementing such interpreters is complicated, and using them makes it difficult or impossible to leverage libraries and fast runtimes for existing deterministic languages.", "startOffset": 91, "endOffset": 94}, {"referenceID": 6, "context": "We first describe how to implement C3 in any functional PPL with first-class functions; our implementation is integrated into the open-source WebPPL probabilistic programming language [8].", "startOffset": 184, "endOffset": 187}, {"referenceID": 9, "context": "CPS re-organizes a program to make all data and control flow explicit\u2014instead of returning, functions invoke a \u2018continuation\u2019 function which represents the remaining computation to be performed [11].", "startOffset": 194, "endOffset": 198}, {"referenceID": 10, "context": "Deep equality testing is more expensive, though this can be mitigated using data structure techniques such as hash consing [12] or compiler optimizations such as global value numbering [13].", "startOffset": 123, "endOffset": 127}, {"referenceID": 11, "context": "Deep equality testing is more expensive, though this can be mitigated using data structure techniques such as hash consing [12] or compiler optimizations such as global value numbering [13].", "startOffset": 185, "endOffset": 189}, {"referenceID": 12, "context": "C3 avoids copying the entire cache using a copy-on-write scheme with similar principles to transactional memory [14]: modifications to a cache node\u2019s properties are staged and only committed if the proposal is accepted.", "startOffset": 112, "endOffset": 116}, {"referenceID": 6, "context": "The source code for all models used in this section is available in the ancillary materials, and our implementation of C3 itself is available as part of the WebPPL probabilistic programming language [8].", "startOffset": 199, "endOffset": 202}, {"referenceID": 13, "context": "We use a simple grammarlike program for tree skeletons presented in prior work, conditioning its output to be volumetrically similar to a target shape [16].", "startOffset": 151, "endOffset": 155}, {"referenceID": 14, "context": "The four models are: the HMM and LDA models from Figure 4, a one-dimensional finite Gaussian mixture model (GMM), and a hierarchical linear regression model (HLR) [17].", "startOffset": 163, "endOffset": 167}, {"referenceID": 15, "context": "First, incrementalizing MCMC proposals for PPLs falls under the umbrella of incremental computation [18].", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "Much of the active work in this field seeks to build general-purpose languages and compilers to incrementalize any program [19].", "startOffset": 123, "endOffset": 127}, {"referenceID": 17, "context": "In particular, C3\u2019s callsite caching mechanism was inspired in part by recent work in computer graphics on hierarchical render caches [20].", "startOffset": 134, "endOffset": 138}, {"referenceID": 4, "context": "The Venture PPL features an algorithm to incrementally update a probabilistic execution trace in response to a random choice change [5].", "startOffset": 132, "endOffset": 135}, {"referenceID": 14, "context": "The Shred system also incrementalizes MH updates for PPLs [17].", "startOffset": 58, "endOffset": 62}, {"referenceID": 18, "context": "The Swift compiler for the BLOG language is another recent system supporting incrementalized MCMC updates [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 19, "context": "Finally, while the results presented in this paper focus on single-site Metropolis Hastings, C3\u2019s core incrementalization scheme also applies to other sampling algorithms, such as Gibbs samplers or particle filter rejuvenation kernels [22].", "startOffset": 235, "endOffset": 239}, {"referenceID": 3, "context": "An incomplete, undocumented version of C3\u2019s callsite caching mechanism also appears in the original MIT-Church implementation of the Church probabilistic programming language [4].", "startOffset": 175, "endOffset": 178}], "year": 2015, "abstractText": "Lightweight, source-to-source transformation approaches to implementing MCMC for probabilistic programming languages are popular for their simplicity, support of existing deterministic code, and ability to execute on existing fast runtimes [1]. However, they are also slow, requiring a complete re-execution of the program on every Metropolis Hastings proposal. We present a new extension to the lightweight approach, C3, which enables efficient, incrementalized re-execution of MH proposals. C3 is based on two core ideas: transforming probabilistic programs into continuation passing style (CPS), and caching the results of function calls. We show that on several common models, C3 reduces proposal runtime by 20-100x, in some cases reducing runtime complexity from linear in model size to constant. We also demonstrate nearly an order of magnitude speedup on a complex inverse procedural modeling application.", "creator": "LaTeX with hyperref package"}}}