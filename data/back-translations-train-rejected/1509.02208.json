{"id": "1509.02208", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2015", "title": "Unsupervised Discovery of Linguistic Structure Including Two-level Acoustic Patterns Using Three Cascaded Stages of Iterative Optimization", "abstract": "Techniques for unsupervised discovery of acoustic patterns are getting increasingly attractive, because huge quantities of speech data are becoming available but manual annotations remain hard to acquire. In this paper, we propose an approach for unsupervised discovery of linguistic structure for the target spoken language given raw speech data. This linguistic structure includes two-level (subword-like and word-like) acoustic patterns, the lexicon of word-like patterns in terms of subword-like patterns and the N-gram language model based on word-like patterns. All patterns, models, and parameters can be automatically learned from the unlabelled speech corpus. This is achieved by an initialization step followed by three cascaded stages for acoustic, linguistic, and lexical iterative optimization. The lexicon of word-like patterns defines allowed consecutive sequence of HMMs for subword-like patterns. In each iteration, model training and decoding produces updated labels from which the lexicon and HMMs can be further updated. In this way, model parameters and decoded labels are respectively optimized in each iteration, and the knowledge about the linguistic structure is learned gradually layer after layer. The proposed approach was tested in preliminary experiments on a corpus of Mandarin broadcast news, including a task of spoken term detection with performance compared to a parallel test using models trained in a supervised way. Results show that the proposed system not only yields reasonable performance on its own, but is also complimentary to existing large vocabulary ASR systems.", "histories": [["v1", "Mon, 7 Sep 2015 22:23:01 GMT  (2608kb,D)", "http://arxiv.org/abs/1509.02208v1", "Accepted by ICASSP 2013"]], "COMMENTS": "Accepted by ICASSP 2013", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["cheng-tao chung", "chun-an chan", "lin-shan lee"], "accepted": false, "id": "1509.02208"}, "pdf": {"name": "1509.02208.pdf", "metadata": {"source": "CRF", "title": "UNSUPERVISED DISCOVERY OF LINGUISTIC STRUCTURE INCLUDING TWO-LEVEL ACOUSTIC PATTERNS USING THREE CASCADED STAGES OF ITERATIVE OPTIMIZATION", "authors": ["Cheng-Tao Chung", "Chun-an Chan", "Lin-shan Lee"], "emails": ["r01921031@ntu.edu.tw,", "chunanchan@gmail.com,", "lslee@gate.sinica.edu.tw"], "sections": [{"heading": null, "text": "Index terms - unattended learning, hidden Markov models, spoken word recognition, zero-resource speech recognition, iterative optimization1. INTRODUCTIONSupervised training of HMMs for automatic speech recognition relies not only on collecting huge amounts of acoustic data, but also on obtaining the appropriate precise labels. Such supervised training method performs reasonably in most circumstances, but at high cost, and in many situations such annotated data sets are simply not available. Considerable efforts have therefore been made [1] - [15] for the unattended discovery of acoustic patterns from vast amounts of acoustic data, which are now easily achieved without manual labels and appropriate knowledge. Most such efforts only detect one level of phonems such as acoustic patterns. However, speech signals have multi-level structures, including at least phonemes and words, and such structures are very helpful in the analysis or decoding of language."}, {"heading": "2. PROPOSED APPROACH: CASCADED THREE STAGES", "text": "The aim is to make-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-up-"}, {"heading": "2.1. Initialization Step", "text": "Here, we initialize the labels from top to bottom by first dividing each utterance into word-like segments based on the discontinuities in a parameter evaluated by energy and MFCC characteristics. For each word-like segment, we further divide it into subword-like segments in the following way. We perform a turning point transformation on the filtered self-similarity dotplot [17] for the acoustic characteristics of each hypothesized word-like segment. The watershed transformation is able to capture the number of objects and their boundaries in a grayscale image [18]. Thus, the intersections of the diagonal entries of the point plot with the watershed are assumed to be the boundaries between subword-like segments. An example point and its watershed transform, including the hypothesized subordinate segment boundaries in the figure. 3.We then extract an average representative segment-hypothesized for each differentiated word segment."}, {"heading": "2.2. Stage(I):Acoustic Optimization", "text": "The process in level (I) is illustrated in Fig. 2 (a). In each iteration, the acoustic model set \u03b8ai uses the HMMs trained on the corpus with the ML criterion. The lexicon \u03b8xi is derived by capturing all the word-like patterns that occur in Wi + 1, with the number exceeding a threshold. Free word decoding is then performed on the entire corpus, based on \u03b8ai and \u03b8 x i, resulting in an updated label Wi + 1. Updating Wi + 1 not only updates the HMM parameters of the Northai and HMM segmentation limits, but the vocabulary size of successxi can shrink if the number of some word-like patterns becomes small enough."}, {"heading": "2.3. Stage(II):Linguistic Optimization", "text": "The only difference is that an N-gram language model is appreciated for the word-like patterns on the Wi label and is used to decode the updated Wi + 1 labels. N-grams help create better Wi + 1 labels, especially for word-like patterns that often occur together."}, {"heading": "2.4. Stage(III):Lexical Optimization", "text": "In this step, we reconstruct new word-like patterns as in Fig. 2 (c) by splitting the word-like patterns into word-like patterns in \u03b8xi \u2212 1, and then reconstructing new word-like patterns based on Wi. These segments of several consecutive word-like patterns, which appear frequent enough and with sufficiently high right and left context variation, are considered to be word-like patterns, which can be achieved by building an efficient data structure called PAT-Tree using the terms Wi [19]. In this way, the lexicon successxi can be significantly updated in each iteration. This updated lexicon successxi is then used in the keypad key to generate the terms Wi + 1. The entire process is completed if there is no significant difference between Wi + 1 and Wi + 1, resulting in the automatically detected linguistic structure \u03b8 = {\u03b8a, successx, \u03b8l}, in which the final version of Wi + 1.3 is practiced."}, {"heading": "3.1. Experimental Setup", "text": "The proposed approach was tested in the preliminary experiments on a corpus of Mandarin news broadcasts conducted in Taiwan in 2001 with a length of 4 hours and 5,034 utterances. HMMs used for each sub-word-like pattern had 13 states with only one Gaussian component each. This configuration was selected on the assumption that the subword-like interest patterns should describe more signal path variations and less acoustic variations. Signal segments with larger acoustic variations should be classified as distinct patterns. The final linguistic structure, including all patterns, models and parameters, was achieved by 30 iterations at each stage (I) (II) (III) in Figure 1 of the entire corpus."}, {"heading": "3.2. Initial Observations and Analysis", "text": "Interestingly, almost all of the 208 polysyllable patterns preserved here roughly correspond to mandarin syllables (each Chinese character is pronounced as a mandarin syllable).A global view of the exact correlation of the 208 subword-like patterns to the total of 399 mandarin syllables that are manually labeled for the corpus is in Fig. 4. Mandarin syllables on the horizontal scale of the figure are sorted by acoustic similarity (only a quarter of them are explicitly printed due to the limited space).Each circle here represents 35 or more subword-like patterns on the vertical scale, the central frame of which belonged to the mandarin syllable on the horizontal scale. This figure implied a very close one-to-to-one-to-one mapping relationship with some blurring around adjacent syllables (the 362-word patterns corresponded to approximately 154 frequently occurring plural words and 20-word patterns)."}, {"heading": "3.3. Justification of the Initialization and Iterative Stages", "text": "We performed further tests with configurations slightly different from the proposed approach on a subset of 942 expressions from the 5034 in the tested corpus. We evaluated the accuracy of the syllable by mapping each discovered subword-like pattern to a corresponding Mandarin syllable (as in Fig. 4) for each configuration considered. In the first part, we initialized W0 with 3 different methods and then applied only 50 iterations of level (I). The three methods are (1) the proposed two-step top-down labeling with word-like segments, (2) transforming subword initialization with only waterlike segments, but without higher word-like segments, (3) the same as (2), but without k-mean clusters, with the same number of subword-like pattern IDs randomly mapped to each subword-like segment, and the main difference between the methods (1) and the (2) was the two-step pattern structure."}, {"heading": "3.4. Spoken Term Detection", "text": "We applied the detected patterns to a spoken word recognition task [22] - [27] and compared them to a set of Mandarin syllable models trained on a manually annotated corpus of 24.5 hours of Mandarin Broadcast News with a 72k vocabulary trigram used in recognition. The performance of monitored HMMs serves as a cap on the performance of our unattended HMMs. We tested the performance of monitored and unmonitored models under the same scenario. The query set consisted of 52 name units from countries, organizations and political leaders. For each query, we decoded their corresponding expressions in the corpus and selected the most common HMM sequences to represent each query by an example of the best query results. Syllable HMMs were used for the monitored case, and subword-like patterns HMMs were used for the unattended case."}, {"heading": "4. CONCLUSION", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. Most of them are not able to survive themselves, because they are not able to survive themselves. Most of them are able to survive themselves, and most of them are not able to survive themselves, and most of them are not able to survive themselves."}], "references": [{"title": "Unsupervised Training of Speaker Independent Acoustic Models", "author": ["A. Jansen", "K. Church \u201cTowards"], "venue": "InterSpeech,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "A Nonparametric Bayesian Approach to Acoustic Model Discovery", "author": ["C. Lee", "J. Glass"], "venue": "in Proc. The Association for Computer Linguistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Unsupervised training of an HMM-based Speech Recognizer for Topic Classification", "author": ["H. Gish", "M. Siu", "A. Chan", "B. Belfield"], "venue": "InterSpeech,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Improved Topic Classification and Keyword Discovery using an HMM-based Speech Recognizer Trained without Supervision", "author": ["M. Siu", "H. Gish", "A. Chan", "W. Belfield"], "venue": "in Inter- Speech,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Unsupervised acoustic sub-word unit detection for query-by-example spoken term detection", "author": ["M. Huijbregts", "M. McLaren", "D. van Leeuwen"], "venue": "ICASSP, 2011, pp. 4436\u20134439.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Unsupervised acoustic and language model training with small amounts of labelled data", "author": ["S. Novotney", "R. Schwartz", "J. Ma"], "venue": "ICASSP, 2009, pp. 4297\u20134300.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Unsupervised Hidden Markov Modeling of Spoken Queries for Spoken Term Detection without Speech Recognition", "author": ["C. Chan", "L. Lee"], "venue": "InterSpeech,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Altosaar \u201cComputational language acquisition by statistical bottom-up processing,", "author": ["O.J. Rasanen", "T.U.K. Laine"], "venue": "in Inter- Speech,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "A noise robust method for pattern discovery in quantized time series: the concept matrix approach,", "author": ["O.J. Rasanen", "U.K. Laine", "T. Altosaar"], "venue": "InterSpeech,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Self-learning vector quantization for pattern discovery from speech", "author": ["O.J. Rasanen", "U.K. Laine", "T. Altosaar"], "venue": "InterSpeech, 2009, pp. 852\u2013855.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Rasanen, Fully unsupervised word learning from continuous speech using transitional probabilities of atomic acoustic events", "author": ["J. O"], "venue": "InterSpeech,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Unsupervised Spoken Term Detection with Spoken Queries ", "author": ["C. Chan"], "venue": "Ph.D dissertation, National Taiwan University,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Unsupervised optimal phoneme segmentation: objectives, algorithm and comparisons", "author": ["Y. Qiao", "N. Shimomura", "N. Minematsu"], "venue": "ICASSP, 2008, pp. 3989\u20133992.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Integrating Frame-based and Segmentbased Dynamic Time Warping for Unsupervised Spoken Term Detection with Spoken Queries", "author": ["C. Chan", "L. Lee"], "venue": "in ICASSP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Toward Unsupervised Model-based Spoken Term Detection with Spoken Queries without Annotated Data", "author": ["C. Chan", "C. Chung", "Y. Kuo", "L. Lee"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Performance analysis for lattice-based speech indexing approaches using word and subword units", "author": ["Y.-c. Pan", "L.-s. Lee"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 18, no. 6, August 2010, pp. 1562\u20131574.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Topological gray-scale watershed transform", "author": ["M. Couprie", "G. Bertrand"], "venue": "Proc. of SPIE Vision Geometry V, 1997, vol. 3168, pp. 136\u2013146.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Updateable PAT-Tree Approach to Chinese Key Phrase Extraction using Mutual Information: A Linguistic Foundation for Knowledge Management", "author": ["T. Ong", "H. Chen"], "venue": "Proc. the Second Asian Digital Library Conference, 1999, pp. 63\u201384.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Enhancing Query Expansion for Semantic Retrieval of Spoken Content with Automatically Discovered Acoustic Patterns", "author": ["H. Lee", "Y. Li", "C. Chung", "L. Lee"], "venue": "submitted to ICASSP, 2013", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Approximating the Kullback Liebler Divergence between Gaussain Mixture Models", "author": ["J. Hershey", "P. Olsen"], "venue": "in ICASSP,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "The spoken web search task at Mediaeval 2011", "author": ["F. Metze", "N. Rajput"], "venue": "ICASSP, 2012, pp. 5165\u20135168.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "An acoustic segment modeling approach to query-by-example spoken term detection", "author": ["H. Wang", "C.-C. Leung", "T. Lee", "B. Ma", "H. Li"], "venue": "ICASSP, 2012, pp. 5157\u20135160.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Keyword spotting of arbitrary words using minimal speech resources", "author": ["A. Garcia", "H. Gish"], "venue": "ICASSP, 2006.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "A phonetic search approach to the 2006 NIST spoken term detection evaluation", "author": ["R. Wallace", "R. Vogt", "S. Sridharan"], "venue": "InterSpeech, 2007, pp. 2385\u20132388.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Open vocabulary spoken-document retrieval based on query expansion using related web documents", "author": ["M. Terao", "T. Koshinaka", "S. Ando", "R. Isotani", "A. Okumura"], "venue": "InterSpeech, 2008, pp. 2171\u20132174.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "A comparison of queryby example methods for spoken term detection", "author": ["W. Shen", "C.M. White", "T.J. Hazen"], "venue": "InterSpeech, 2009, pp. 2143\u20132146.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "From hmms to segment models: A unified view of stochastic modeling for speech recognition", "author": ["M. Ostendorf", "V. Digalakis", "O.A. Kimball"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 4, pp. 360V-378, 1995.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1995}, {"title": "A piecewise aggregate approximation lowerbound estimate for posteriorgram-based dynamic time warping", "author": ["Y. Zhang", "J.R. Glass"], "venue": "InterSpeech, 2011, pp. 1909\u20131912.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Speech recognition and utterance verification based on a generalized confidence score", "author": ["M.-W. Koo", "C.-H. Lee", "B.-H. Juang"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 9, no. 8, pp. 821V-832, 2001.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}, {"title": "An acoustic segment model approach to incorporating temporal information into speaker modeling for text-independent speaker recognition", "author": ["Y. Tsao", "H. Sun", "H. Li", "C.-H. Lee"], "venue": "ICASSP, 2010, pp. 4422\u20134425.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "This is why substantial effort [1]-[15] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data which may be easily obtained nowadays, without manual labels and corresponding knowledge.", "startOffset": 31, "endOffset": 34}, {"referenceID": 14, "context": "This is why substantial effort [1]-[15] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data which may be easily obtained nowadays, without manual labels and corresponding knowledge.", "startOffset": 35, "endOffset": 39}, {"referenceID": 15, "context": "However, it is well known that speech signals have multi-level structure including at least phoneme and words, and such structure are very helpful in analysing or decoding speech[16].", "startOffset": 178, "endOffset": 182}, {"referenceID": 16, "context": "Watershed transformation is able to capture the number of objects and their borders in a gray scale image [18].", "startOffset": 106, "endOffset": 110}, {"referenceID": 17, "context": "This can be achieved by constructing an efficient data structure called PAT-Tree using the labels Wi[19].", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "Method (1) brought us halfway through the proposed approach (initialization and stage (I)) producing two-level patterns, while method (2) was similar to the unsupervised initialization methods used previously with one-level patterns only [1][17].", "startOffset": 238, "endOffset": 241}, {"referenceID": 2, "context": "approach wile method (3) was actually the intuitive joint optimization of both acoustic and linguistic parameters similar to previously proposed approaches [3][4].", "startOffset": 156, "endOffset": 159}, {"referenceID": 3, "context": "approach wile method (3) was actually the intuitive joint optimization of both acoustic and linguistic parameters similar to previously proposed approaches [3][4].", "startOffset": 159, "endOffset": 162}, {"referenceID": 18, "context": "optimization in stage (III), on the other hand, are better observed in a companion paper on semantic retrieval of spoken content also submitted to ICASSP 2013[20], since the word-like patterns carried semantics.", "startOffset": 158, "endOffset": 162}, {"referenceID": 20, "context": "We also applied the discovered patterns on a task of spoken term detection [22]-[27] and compared to a set of Mandarin syllable models trained on a manually annotated corpus of 24.", "startOffset": 75, "endOffset": 79}, {"referenceID": 25, "context": "We also applied the discovered patterns on a task of spoken term detection [22]-[27] and compared to a set of Mandarin syllable models trained on a manually annotated corpus of 24.", "startOffset": 80, "endOffset": 84}, {"referenceID": 19, "context": "The distance metric used for DTW was the KL-divergence between the two Gaussian mixtures [21].", "startOffset": 89, "endOffset": 93}, {"referenceID": 0, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 61, "endOffset": 64}, {"referenceID": 1, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 64, "endOffset": 67}, {"referenceID": 2, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 67, "endOffset": 70}, {"referenceID": 3, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 70, "endOffset": 73}, {"referenceID": 4, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 76, "endOffset": 79}, {"referenceID": 6, "context": "The main difference from similar approaches proposed earlier [1][2][3][4][5][6][7] lies in the two-level acoustic patterns and the layer-after-layer gradual learning of the model parameters with cascaded stages of iterative optimization.", "startOffset": 79, "endOffset": 82}, {"referenceID": 0, "context": "Although some earlier approaches [1] also took hierarchical knowledge into consideration, our work used 13-state single Gaussian HMMs as compared to the conventional HMMs with smaller number of states and multi-Gaussian [1][2][3][4] to model the trajectories of acoustic patterns with less acoustic variation.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "Although some earlier approaches [1] also took hierarchical knowledge into consideration, our work used 13-state single Gaussian HMMs as compared to the conventional HMMs with smaller number of states and multi-Gaussian [1][2][3][4] to model the trajectories of acoustic patterns with less acoustic variation.", "startOffset": 220, "endOffset": 223}, {"referenceID": 1, "context": "Although some earlier approaches [1] also took hierarchical knowledge into consideration, our work used 13-state single Gaussian HMMs as compared to the conventional HMMs with smaller number of states and multi-Gaussian [1][2][3][4] to model the trajectories of acoustic patterns with less acoustic variation.", "startOffset": 223, "endOffset": 226}, {"referenceID": 2, "context": "Although some earlier approaches [1] also took hierarchical knowledge into consideration, our work used 13-state single Gaussian HMMs as compared to the conventional HMMs with smaller number of states and multi-Gaussian [1][2][3][4] to model the trajectories of acoustic patterns with less acoustic variation.", "startOffset": 226, "endOffset": 229}, {"referenceID": 3, "context": "Although some earlier approaches [1] also took hierarchical knowledge into consideration, our work used 13-state single Gaussian HMMs as compared to the conventional HMMs with smaller number of states and multi-Gaussian [1][2][3][4] to model the trajectories of acoustic patterns with less acoustic variation.", "startOffset": 229, "endOffset": 232}, {"referenceID": 14, "context": "A more complete experiment on spoken term detection in a companion paper submitted to ICASSP 2013 [15] demonstrates how our model can outperform the segmental DTW approach.", "startOffset": 98, "endOffset": 102}, {"referenceID": 18, "context": "retrieval of spoken content also submitted to ICASSP 2013 [20].", "startOffset": 58, "endOffset": 62}], "year": 2015, "abstractText": "Techniques for unsupervised discovery of acoustic patterns are getting increasingly attractive, because huge quantities of speech data are becoming available but manual annotations remain hard to acquire. In this paper, we propose an approach for unsupervised discovery of linguistic structure for the target spoken language given raw speech data. This linguistic structure includes two-level (subwordlike and word-like) acoustic patterns, the lexicon of word-like patterns in terms of subword-like patterns and the N-gram language model based on word-like patterns. All patterns, models, and parameters can be automatically learned from the unlabelled speech corpus. This is achieved by an initialization step followed by three cascaded stages for acoustic, linguistic, and lexical iterative optimization. The lexicon of word-like patterns defines allowed consecutive sequence of HMMs for subword-like patterns. In each iteration, model training and decoding produces updated labels from which the lexicon and HMMs can be further updated. In this way, model parameters and decoded labels are respectively optimized in each iteration, and the knowledge about the linguistic structure is learned gradually layer after layer. The proposed approach was tested in preliminary experiments on a corpus of Mandarin broadcast news, including a task of spoken term detection with performance compared to a parallel test using models trained in a supervised way. Results show that the proposed system not only yields reasonable performance on its own, but is also complimentary to existing large vocabulary ASR systems.", "creator": "LaTeX with hyperref package"}}}