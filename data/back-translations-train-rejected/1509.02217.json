{"id": "1509.02217", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2015", "title": "Enhancing Automatically Discovered Multi-level Acoustic Patterns Considering Context Consistency With Applications in Spoken Term Detection", "abstract": "This paper presents a novel approach for enhancing the multiple sets of acoustic patterns automatically discovered from a given corpus. In a previous work it was proposed that different HMM configurations (number of states per model, number of distinct models) for the acoustic patterns form a two-dimensional space. Multiple sets of acoustic patterns automatically discovered with the HMM configurations properly located on different points over this two-dimensional space were shown to be complementary to one another, jointly capturing the characteristics of the given corpus. By representing the given corpus as sequences of acoustic patterns on different HMM sets, the pattern indices in these sequences can be relabeled considering the context consistency across the different sequences. Good improvements were observed in preliminary experiments of pattern spoken term detection (STD) performed on both TIMIT and Mandarin Broadcast News with such enhanced patterns.", "histories": [["v1", "Mon, 7 Sep 2015 22:56:49 GMT  (3182kb,D)", "http://arxiv.org/abs/1509.02217v1", "Accepted by ICASSP 2015"]], "COMMENTS": "Accepted by ICASSP 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["cheng-tao chung", "wei-ning hsu", "cheng-yi lee", "lin-shan lee"], "accepted": false, "id": "1509.02217"}, "pdf": {"name": "1509.02217.pdf", "metadata": {"source": "CRF", "title": "ENHANCING AUTOMATICALLY DISCOVERED MULTI-LEVEL ACOUSTIC PATTERNS CONSIDERING CONTEXT CONSISTENCY WITH APPLICATIONS IN SPOKEN TERM DETECTION", "authors": ["Cheng-Tao Chung", "Wei-Ning Hsu", "Cheng-Yi Lee", "Lin-Shan Lee"], "emails": ["b97901182@gmail.com,", "mhng1580@gmail.com,", "chenyi2229@gmail.com,", "lslee@gate.sinica.edu.tw"], "sections": [{"heading": null, "text": "In fact, most of them are able to survive on their own."}, {"heading": "2.1. Pattern Discovery for a Given Model Configuration", "text": "Given an unlabeled speech corpus, it is not difficult to find unattended the desired acoustic patterns from the corpus for a selected set of hyperparameters determining the configuration of the HMM (number of states per model and number of different models) [2] [4] [5] [20]. This can be achieved by first finding an initial label \u03c90 based on a set of accepted patterns for all observations in the corpus as in (1) [6]. Subsequently, in each iteration t the HMM parameter specified in the previous iteration can be trained with the \u03c9t \u2212 1 label as in (2), and the new label \u03c9t can be achieved by deciphering the pattern with the obtained parameter as in (3)."}, {"heading": "2.2. Model Granularity Space for Multi-level Pattern Sets", "text": "The above process can be performed with many different HMM configurations, each characterized by two hyperparameters: the number of states m in each HMM acoustic pattern and the total number of unique acoustic patterns n during initialization. Transcribing a signal decoded with these patterns can be considered a temporal segmentation of the signal so that the total number n unique acoustic patterns represents the phonetic granularity, resulting in a two-dimensional representation of the acoustic pattern configurations in terms of temporal and phonetic granularities as shown in Figure 1. Each point in this two-dimensional space corresponds to the phonetic granularity."}, {"heading": "2.3. Pattern Relabeling Considering Context Consistency", "text": "Context constraints that have been successfully explored in language modeling can be used here to re-label the pattern b > Pattern B > Pattern B > Pattern B, as in an example in Fig. 2. We assume that the patterns \"b\" and \"B\" without context are similar to those in Fig. 2 (a). However, if we look at the context, from the corpus we can observe that many realizations of the pattern \"b\" are preceded by pattern \"a\" and pattern \"b,\" while most realizations of the pattern \"B\" have a different context. Therefore, by looking at all realizations of the pattern \"B,\" preceding pattern \"a\" and following pattern \"c\" as pattern \"b,\" we can amplify the contrast between patterns \"b\" and \"B,\" as shown in the next iteration of acoustic model actualization, as in Fig. B > Pattern B > Pattern B > Pattern B > Pattern B > Pattern B > Pattern are divided into two contexts. \""}, {"heading": "2.4. Pattern Relabeling Method", "text": "Let \u03c9 (mk, nk, l) be the index for a decoded acoustic pattern at the time l (within an enunciation in the corpus) l (using the acoustic pattern set with granularity \u043d (mk, nk). The renamed pattern \u03c9 (mk, nk, l) is then called in (4a), i.e. the pattern among all patterns in the set of economy (mk, nk), which is the product of the three probabilities in (4b) (4d) with the context or in l, n and m. The first probability Pl (w) in (4b) for the context sequence l is actually the product of forward bigram and backward bigram, which is well known in language modeling. The other two probabilities Pn (w), Pm (w) in (4c) and mood) are exactly the same, with the exception of nk \u2212 1, nk \u2212 1 and mk \u2212 1, mk \u2212 1, mk + k (n) and the neighboring patterns are (n)."}, {"heading": "2.5. Pattern Enhancement by Re-estimation after Relabeling", "text": "The re-labeling in (4a) can be inserted into the recursive process of discovering the patterns in each iteration in (2) (3), as shown in (5) (6). (6) When an iteration as in (2) (3) is complete, a new set of patterns as in (2) will be created to obtain a new set of labels as in (3). The new labels in (3) will then be re-labeled with (4a) based on the new labels in (3) to produce a slightly better labeling than in (5). This slightly better labeling will then be used in (6) to create a slightly better model in (6), which is almost the same as in (2), except here based on the slightly better labeling in (5), these two pages can be converted into (6) and the individual process in (5) in two steps each."}, {"heading": "2.6. Spoken Term Detection", "text": "There are various applications for the acoustic patterns presented here. In this section, we summarize the type and manner of the spoken patterns Q = Q = Q = Q = Q = Q = Q = Q = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Q = Q = Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q Q"}, {"heading": "3.1. Purity in Pattern Sequences for known Words", "text": "In order to evaluate the quality of the acoustic patterns, which we generated with different temporal and phonetic granularities, we use the Gini impurity for the pattern sequences found for the known radio frequency words, as these can be evaluated for all given patterns. (24) For the word \"water,\" it is decoded into the various pattern sequences, which each affect a percentage of the realizations (8), we can evaluate the Gini impurity."}, {"heading": "3.2. Unsupervised Spoken Term Detection", "text": "We have two separate terms based on two spoken archives. In the first experiment, the TIMIT training was used as a spoken archive and the spoken query consisted of 16 words randomly selected by the TIMIT testers. In the second experiment, the spoken pattern of Mandarin Broadcast News was used in 5034 spoken documents and the spoken query was selected by 10 words from another development group. In both cases, a spoken example of a spoken word was selected from the data set, and the search for other instances within the spoken archive was driven by 10 words. Conventional 39-dimensional MFCC characteristics were used for the HMMs. 20 sets of acoustic patterns were used for m = 3, 7, 11 and n = 50, 300 sets for the Mandarin Broadcast News."}], "references": [{"title": "A graph-based gaussian component clustering approach to unsupervised acoustic modeling", "author": ["Haipeng Wang", "Tan Lee", "Cheung-Chi Leung", "Bin Ma", "Haizhou Li"], "venue": "Fifteenth Annual Conference of the International Speech Communication Association, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards unsupervised training of speaker independent acoustic models", "author": ["Aren Jansen", "Kenneth Church"], "venue": "INTER- SPEECH, 2011, pp. 1693\u20131692.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A nonparametric bayesian approach to acoustic model discovery", "author": ["Chia-ying Lee", "James Glass"], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1. Association for Computational Linguistics, 2012, pp. 40\u201349.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Unsupervised training of an hmm-based speech recognizer for topic classification", "author": ["Herbert Gish", "Man-hung Siu", "Arthur Chan", "William Belfield"], "venue": "INTERSPEECH, 2009, pp. 1935\u20131938.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Improved topic classification and keyword discovery using an hmm-based speech recognizer trained without supervision", "author": ["Man-Hung Siu", "Herbert Gish", "Arthur Chan", "William Belfield"], "venue": "INTERSPEECH, 2010, pp. 2838\u20132841.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised discovery of linguistic structure including twolevel acoustic patterns using three cascaded stages of iterative optimization", "author": ["Cheng-Tao Chung", "Chun-an Chan", "Lin-shan Lee"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 2013, pp. 8081\u20138085.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Toward unsupervised model-based spoken term detection with spoken queries without annotated data", "author": ["Chun-an Chan", "Cheng-Tao Chung", "Yu-Hsin Kuo", "Lin-shan Lee"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Lattice-based search for spoken utterance retrieval", "author": ["Murat Saraclar", "Richard Sproat"], "venue": "Urbana, vol. 51, pp. 61801, 2004.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1801}, {"title": "Rapid and accurate spoken term detection", "author": ["David RH Miller", "Michael Kleber", "Chia-Lin Kao", "Owen Kimball", "Thomas Colthurst", "Stephen A Lowe", "Richard M Schwartz", "Herbert Gish"], "venue": "INTERSPEECH, 2007, pp. 314\u2013317.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Vocabulary independent spoken term detection", "author": ["Jonathan Mamou", "Bhuvana Ramabhadran", "Olivier Siohan"], "venue": "Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2007, pp. 615\u2013622.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "A phonetic search approach to the 2006 nist spoken term detection evaluation", "author": ["Roy G Wallace", "Robert J Vogt", "Sridha Sridharan"], "venue": "2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Performance analysis for lattice-based speech indexing approaches using words and subword units", "author": ["Yi-cheng Pan", "Lin-shan Lee"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 18, no. 6, pp. 1562\u20131574, 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "The spoken web search task at mediaeval 2011", "author": ["Florian Metze", "Nitendra Rajput", "Xavier Anguera", "Marelie Davel", "Guillaume Gravier", "Charl Van Heerden", "Gautam V Mantena", "Armando Muscariello", "Kishore Prahallad", "Igor Szoke"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on. IEEE, 2012, pp. 5165\u2013 5168.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Indexing raw acoustic features for scalable zero resource search", "author": ["Aren Jansen", "Benjamin Van Durme"], "venue": "INTER- SPEECH, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Unsupervised spoken keyword spotting via segmental dtw on gaussian posteriorgrams", "author": ["Yaodong Zhang", "James R Glass"], "venue": "Automatic Speech Recognition & Understanding, 2009. ASRU 2009. IEEE Workshop on. IEEE, 2009, pp. 398\u2013 403.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Unsupervised acoustic sub-word unit detection for query-by-example spoken term detection", "author": ["Marijn Huijbregts", "Mitchell McLaren", "David van Leeuwen"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 4436\u20134439.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "An acoustic segment modeling approach to query-by-example spoken term detection", "author": ["Haipeng Wang", "Cheung-Chi Leung", "Tan Lee", "Bin Ma", "Haizhou Li"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on. IEEE, 2012, pp. 5157\u20135160.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "A hierarchical system for word discovery exploiting dtw-based initialization", "author": ["Oliver Walter", "Timo Korthals", "Reinhold Haeb-Umbach", "Bhiksha Raj"], "venue": "Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on. IEEE, 2013, pp. 386\u2013391.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised spoken term detection with spoken queries by multi-level acoustic patterns with varying model granularity", "author": ["Cheng-Tao Chung", "Chun-an Chan", "Lin-shan Lee"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on. IEEE, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised models for morpheme segmentation and morphology learning", "author": ["Mathias Creutz", "Krista Lagus"], "venue": "ACM Transactions on Speech and Language Processing (TSLP), vol. 4, no. 1, pp. 3, 2007.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["Stanley F Chen", "Joshua Goodman"], "venue": "Proceedings of the 34th annual meeting on Association for Computational Linguistics. Association for Computational Linguistics, 1996, pp. 310\u2013318.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1996}, {"title": "Approximating the kullback leibler divergence between gaussian mixture models", "author": ["John R Hershey", "Peder A Olsen"], "venue": "Acoustics, Speech and Signal Processing, 2007. ICASSP 2007. IEEE International Conference on. IEEE, 2007, vol. 4, pp. IV\u2013 317.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Constructing category hierarchies for visual recognition", "author": ["Marcin Marsza\u0142ek", "Cordelia Schmid"], "venue": "Computer Vision\u2013 ECCV 2008, pp. 479\u2013491. Springer, 2008.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Technical note: Some properties of splitting criteria", "author": ["Leo Breiman"], "venue": "Machine Learning, vol. 24, no. 1, pp. 41\u201347, 1996.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1996}, {"title": "Object retrieval with large vocabularies and fast spatial matching", "author": ["James Philbin", "Ondrej Chum", "Michael Isard", "Josef Sivic", "Andrew Zisserman"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR\u201907. IEEE Conference on. IEEE, 2007, pp. 1\u20138.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "A support vector method for optimizing average precision", "author": ["Yisong Yue", "Thomas Finley", "Filip Radlinski", "Thorsten Joachims"], "venue": "Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2007, pp. 271\u2013278.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 34, "endOffset": 37}, {"referenceID": 2, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 37, "endOffset": 40}, {"referenceID": 3, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 40, "endOffset": 43}, {"referenceID": 4, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 43, "endOffset": 46}, {"referenceID": 5, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 46, "endOffset": 49}, {"referenceID": 6, "context": "This is why substantial effort [1][2][3][4][5][6][7] has been made for unsupervised discovery of acoustic patterns from huge quantities of acoustic data without annotation, which may be easily obtained nowadays.", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 61, "endOffset": 64}, {"referenceID": 9, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 64, "endOffset": 68}, {"referenceID": 10, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 263, "endOffset": 267}, {"referenceID": 13, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 267, "endOffset": 271}, {"referenceID": 14, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 271, "endOffset": 275}, {"referenceID": 15, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 275, "endOffset": 279}, {"referenceID": 16, "context": "For some applications such as Spoken Term Detection (STD) [8][9][10][11][12] in which the goal is simply to match and find some signal segments, the extra effort of building an LVCSR system using corpora with human annotations is very often an unnecessary burden [13][14][15][16][17].", "startOffset": 279, "endOffset": 283}, {"referenceID": 11, "context": "However, it is well known that speech signals have multilevel structures including at least phonemes and words, and such structures are very helpful in analysing or decoding speech [12].", "startOffset": 181, "endOffset": 185}, {"referenceID": 17, "context": "A similar two-level framework was also developed recently [18].", "startOffset": 58, "endOffset": 62}, {"referenceID": 18, "context": "In a more recent attempt [19], we further proposed a framework of discovering multi-level acoustic patterns with varying model granularity.", "startOffset": 25, "endOffset": 29}, {"referenceID": 1, "context": "Given an unlabeled speech corpus, it is not difficult for unsupervised discovery of the desired acoustic patterns from the corpus for a chosen hyperparameter set \u03c8 that determines the HMM configuration (number of states per model and number of distinct models) [2][4][5][6][20].", "startOffset": 261, "endOffset": 264}, {"referenceID": 3, "context": "Given an unlabeled speech corpus, it is not difficult for unsupervised discovery of the desired acoustic patterns from the corpus for a chosen hyperparameter set \u03c8 that determines the HMM configuration (number of states per model and number of distinct models) [2][4][5][6][20].", "startOffset": 264, "endOffset": 267}, {"referenceID": 4, "context": "Given an unlabeled speech corpus, it is not difficult for unsupervised discovery of the desired acoustic patterns from the corpus for a chosen hyperparameter set \u03c8 that determines the HMM configuration (number of states per model and number of distinct models) [2][4][5][6][20].", "startOffset": 267, "endOffset": 270}, {"referenceID": 5, "context": "Given an unlabeled speech corpus, it is not difficult for unsupervised discovery of the desired acoustic patterns from the corpus for a chosen hyperparameter set \u03c8 that determines the HMM configuration (number of states per model and number of distinct models) [2][4][5][6][20].", "startOffset": 270, "endOffset": 273}, {"referenceID": 19, "context": "Given an unlabeled speech corpus, it is not difficult for unsupervised discovery of the desired acoustic patterns from the corpus for a chosen hyperparameter set \u03c8 that determines the HMM configuration (number of states per model and number of distinct models) [2][4][5][6][20].", "startOffset": 273, "endOffset": 277}, {"referenceID": 5, "context": "This can be achieved by first finding an initial label \u03c90 based on a set of assumed patterns for all observations in the corpus \u03c7 as in (1) [6].", "startOffset": 140, "endOffset": 143}, {"referenceID": 18, "context": "Note that in our previous work [19], the effect of the third dimension, the acoustic granularity which is the number of Gaussians in each state, was shown to be negligible, thus here we simply set the number of Gaussians in each state to be 4 in all cases.", "startOffset": 31, "endOffset": 35}, {"referenceID": 20, "context": "Katz smoothing [21] was applied to deal with unseen pattern bigrams.", "startOffset": 15, "endOffset": 19}, {"referenceID": 18, "context": "In this section we summarize the way to perform spoken term detection [19].", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "The KL-divergence KL(i, j) between two pattern HMMs in (7) is defined as the symmetric KL-divergence between the states based on the variational approximation [22] summed over the states.", "startOffset": 159, "endOffset": 163}, {"referenceID": 22, "context": "To transform the KL divergence into a similarity measure between 0 and 1, a negative exponential was applied [23] with a scaling factor \u03b2.", "startOffset": 109, "endOffset": 113}, {"referenceID": 18, "context": "However, previous experiments showed that the extra improvements brought in this way is almost negligible, probably because the M \u00d7 N different pattern sequences based on the M \u00d7 N different pattern sets can be considered as a huge lattice including many one-best paths which will be jointly considered here [19].", "startOffset": 308, "endOffset": 312}, {"referenceID": 18, "context": "including longer /shorter patterns), so the different time-warped matching and insertion/deletion between d and q is already automatically included [19].", "startOffset": 148, "endOffset": 152}, {"referenceID": 18, "context": "But here we simply assume the detection is completely unsupervised without any annotation, and all pattern sets are equally weighted [19].", "startOffset": 133, "endOffset": 137}, {"referenceID": 23, "context": "the word \u201cwater\u201d) are decoded into I different pattern sequences, each occupying a percentage fi of the realizations (\u03a3ifi = 1), we can evaluate the Gini impurity [24] for the word using the I percentages f={fi, i=1,2,.", "startOffset": 163, "endOffset": 167}, {"referenceID": 24, "context": "We used the mean average precision (MAP) [25][26] as the performance measure, a higher value implies better performance.", "startOffset": 41, "endOffset": 45}, {"referenceID": 25, "context": "We used the mean average precision (MAP) [25][26] as the performance measure, a higher value implies better performance.", "startOffset": 45, "endOffset": 49}], "year": 2015, "abstractText": "This paper presents a novel approach for enhancing the multiple sets of acoustic patterns automatically discovered from a given corpus. In a previous work it was proposed that different HMM configurations (number of states per model, number of distinct models) for the acoustic patterns form a two-dimensional space. Multiple sets of acoustic patterns automatically discovered with the HMM configurations properly located on different points over this two-dimensional space were shown to be complementary to one another, jointly capturing the characteristics of the given corpus. By representing the given corpus as sequences of acoustic patterns on different HMM sets, the pattern indices in these sequences can be relabeled considering the context consistency across the different sequences. Good improvements were observed in preliminary experiments of pattern spoken term detection (STD) performed on both TIMIT and Mandarin Broadcast News with such enhanced patterns.", "creator": "LaTeX with hyperref package"}}}