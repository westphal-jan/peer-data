{"id": "1509.02412", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2015", "title": "Unsupervised Domain Discovery using Latent Dirichlet Allocation for Acoustic Modelling in Speech Recognition", "abstract": "Speech recognition systems are often highly domain dependent, a fact widely reported in the literature. However the concept of domain is complex and not bound to clear criteria. Hence it is often not evident if data should be considered to be out-of-domain. While both acoustic and language models can be domain specific, work in this paper concentrates on acoustic modelling. We present a novel method to perform unsupervised discovery of domains using Latent Dirichlet Allocation (LDA) modelling. Here a set of hidden domains is assumed to exist in the data, whereby each audio segment can be considered to be a weighted mixture of domain properties. The classification of audio segments into domains allows the creation of domain specific acoustic models for automatic speech recognition. Experiments are conducted on a dataset of diverse speech data covering speech from radio and TV broadcasts, telephone conversations, meetings, lectures and read speech, with a joint training set of 60 hours and a test set of 6 hours. Maximum A Posteriori (MAP) adaptation to LDA based domains was shown to yield relative Word Error Rate (WER) improvements of up to 16% relative, compared to pooled training, and up to 10%, compared with models adapted with human-labelled prior domain knowledge.", "histories": [["v1", "Tue, 8 Sep 2015 15:29:23 GMT  (70kb,D)", "http://arxiv.org/abs/1509.02412v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mortaza doulaty", "oscar saz", "thomas hain"], "accepted": false, "id": "1509.02412"}, "pdf": {"name": "1509.02412.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Domain Discovery using Latent Dirichlet Allocation for Acoustic Modelling in Speech Recognition", "authors": ["Mortaza Doulaty", "Oscar Saz", "Thomas Hain"], "emails": ["t.hain}@sheffield.ac.uk"], "sections": [{"heading": null, "text": "Although both acoustic and linguistic models can be domain specific, the work in this paper focuses on acoustic modeling. We present a novel method of unattended domain discovery using latent dirichlet allocation (LDA) modeling, which assumes that there are a number of hidden domains in the data, with each audio segment being considered a weighted mix of domain properties. Classifying audio segments in domains enables domain specific acoustic models for automatic speech recognition to be created. Experiments are conducted with a dataset of different speech data covering speech from radio and television broadcasts, telephone conversations, meetings, lectures, and reading languages."}, {"heading": "1. Introduction", "text": "This year it is so far that it will be able to the mentioned rf\u00fc the mentioned rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rfu the rfu the rfu the ru the rfu the rfu the rfu the rfu the rfu the ru the rfu the rfu the ru the rfu the rfu the rfu the ru the rfu the rfu the rfu the rfu the ru the rfu the ru the ru the ru the ru the ru the ru the rfu the ru the rfu the ru the ru the rfu the ru the rfu the ru the"}, {"heading": "2. Latent Dirichlet Allocation", "text": "The latent dirichlet allocation (LDA) [7] is an unattended probability model = \u03b2 q = \u03b2 q Generative model for collecting discrete data. It aims to describe how each element is generated within the collection, provided that there are a number of hidden topics and that each element can be modelled as a finite mix of these topics. An infinite mix of an underlying set of subject probabilities is also used to model each topic [7]. However, the model can be applied to other tasks, such as object categorisation and localization in image processing [10], automatic harmonic analysis in music processing [11], or acoustic information retrieval in unstructured audio analysis [9]. In the context of text corpora, a dataset is defined as a collection of documents and each document is a collection of words. Given a vocabulary of size V, each word is represented by a V-dimensional binary."}, {"heading": "3. Unsupervised Domain Discovery", "text": "The proposed technique uses an LDA model to detect hidden and latent acoustic areas in multidomain speech data. As LDA stands for the collection of discrete data (such as text corpora) [7], each language segment of the length T-frame, x = {x1,..., xt,..., xT}, is presented as a set of discrete symbols to support modeling within this framework. To this end, the n-dimensional audio frames, xt-Rn, are quantified into a dictionary of V-acoustic \"words,\" x-t, {1... V} [8]. First, a Gaussian Mixture Model (GMM) is quantified using Expectation Maximisation (EM) and the mixing process to achieve the desired codebook size V (enforcement of the covariance matrix for identity formation, equivalent to LBG-VQ [14]). Then, the means of the Gaussian component are used to quantify the codebook and the codebook."}, {"heading": "4. Experimental setup", "text": "To evaluate the proposed domain discovery and adaptation method in a multi-domain and diverse ASR task, a data set of 6 different data types was first selected from the following sources: \u2022 Radio (RD): BBC Radio4 broadcasts in February 2009. \u2022 Television (TV): BBC broadcasts in May 2008. \u2022 Telephone Language (CT): From the Fisher Corpus1 [15]. \u2022 Meetings (MT): From AMI [16] and ICSI [17] Corpora. \u2022 Lectures (TK): From TedTalks [18]. \u2022 Read speech (RS): From the WSJCAM0 corpus [19].A subset of 10h from each domain was selected to form the training set (60h in total), and 1h from each domain a test (6h in total) was performed."}, {"heading": "4.1. Baseline results", "text": "Table 1 shows the results of the Word Error Rate (WHO) for the domain-internal Maximum Likelihood Model (ML), which was trained with the bundled 60 hours of all domains, as well as the results of the ML domain models, which were trained with 10 hours of domain data each. It also includes the MAP-adapted models from the pooled model for each domain. Experiments were conducted with PLP and PLP + BN features."}, {"heading": "5. Results", "text": "The experiments were aimed at evaluating two aspects of the proposed LDA modeling for unattended domain discovery: firstly, whether LDA could be successfully used to find hidden domains, and whether these domains represented the hidden properties of audio; secondly, once hidden domains were identified, whether domain adjustments could be applied to them, and whether improvements in ASR performance were achieved via baselines."}, {"heading": "5.1. Unsupervised domain discovery", "text": "For the use of LDA models as described in Section 2, two parameters had to be specified first: First, the number of domains to be found had to be specified before the training; also, since the audio frames had to be quantified, the size of codebook V also had to be specified; for this purpose, a series of experiments with different codebooks and the number of domains was conducted; codebooks of the size 128 to 8192 were used and a codebook was given; different LDA models with a different number of domains from 4 to 64 were estimated [23, 24] whereas the training data in Section 4. Since these domains were latent, there was no basic truth to verify them at this stage. An initial way of assessing how the different latent domains behaved was to distribute the data according to manual labels that were included."}, {"heading": "5.2. Domain adaptation", "text": "To evaluate the possibilities offered by the uncontrolled discovery of domains in ASR, the adaptation of the MAP domain to each of these new domains was carried out using domains of size 4, 6, 8, 10 and 12 and a code book of acoustic words of size 2,048. Each MAP-specific model was used to decipher the corresponding language segments in the test set assigned to this domain. Figure 4 shows the general WHO in the test set with different numbers of topics using both types of characteristics, PLP and PLP + BN. The lowest WHO values, 30.4% for PLP characteristics and 25.4% for PLP + BN, were achieved with 8 domains for both types of characteristics showing 16% and 5% relative improvement over their respective ML baselines."}, {"heading": "6. Conclusions", "text": "A novel technique based on latent dirichlet allocation (LDA) has been proposed to detect latent domains in widely differing language data in an uncontrolled manner. It consisted of data from television and radio broadcasts, meetings, lectures, lectures and telephone conversations with a 60-hour training set and a 6-hour test set. It was assumed that there was a set of hidden domains and that each audio segment is a mixture of different properties of these hidden domains of varying weights. LDA models were used to detect the latent domains, and then these domains were used to perform the adjustment of the Maximum A Posteriori (MAP) domain. Results showed a relative improvement of up to 16% over the Maximum Likelihood baseline tracked models and up to 10% over the MAP-adapted models to human-tagged domains with the detected LDA domains."}, {"heading": "7. Acknowledgements", "text": "This work was supported by the EPSRC Programme Grant EP / I031022 / 1 Natural Speech Technology (NST)."}, {"heading": "8. Data Access Statement", "text": "The language data used in this paper comes from the following sources: Fisher Corpus (LDC catalogue number LDC2004T19), ICSI Meetings corpus (LDC2004S02), WSJCAM0 (LDC95S24), AMI corpus (DOI number 10.1007 / 11677482 3), TedTalks data (freely available as part of the IWSLT evaluation), BBC radio and television data (this data has been distributed to NST project partners under an agreement with BBC F & D and is not yet publicly available), the specific file lists used for training and testing in this paper and the results files can be downloaded from http: / / mini.dcs.shef.ac.uk / publications / papers / is15-doulaty2."}, {"heading": "9. References", "text": "[1] J.-L. Gauvain and C.-H. Lee, \"Maximum a posteriori P. 69janao P. 5 Bell Systems: 79. BC Canada Networks 79 [441 Mixture Observations of markov chains,\" IEEE Transactions on Speech and Audio processing, vol. 2, no. 2, pp. 291-298, 1994. [2] C. J. Leggetter and P. C. Woodland, \"Maximum likelihood.\" [3] M. J. Gales, \"Cluster adaptive Training for Speech recognition.\" in Proceedings of the 5th International Conference on Spoken Language Processing (ICSLP-Interspeech), Sydney, Australia, 1998, pp. 1783-1786. [4] D. Yu and L. Deng, Automatic Speech Recognition: A Deep Learproach."}], "references": [{"title": "Maximum a posteriori estimation for multivariate gaussian mixture observations of markov chains", "author": ["J.-L. Gauvain", "C.-H. Lee"], "venue": "IEEE Transactions on Speech and audio processing, vol. 2, no. 2, pp. 291\u2013298, 1994.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Maximum likelihood linear regression for speaker adaptation of continuous density hidden markov models", "author": ["C.J. Leggetter", "P.C. Woodland"], "venue": "Computer Speech & Language, vol. 9, no. 2, pp. 171\u2013185, 1995.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "Cluster adaptive training for speech recognition.", "author": ["M.J. Gales"], "venue": "Proceedings of the 5th International Conference on Spoken Language Processing (ICSLP\u2013Interspeech), Sydney, Australia,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Automatic Speech Recognition: A Deep Learning Approach", "author": ["D. Yu", "L. Deng"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Multi-level adaptive networks in tandem and hybrid ASR systems", "author": ["P. Bell", "P. Swietojanski", "S. Renals"], "venue": "Proceddings of the 2013 IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), Vancouver BC, Canada, 2013, pp. 6975\u20136979.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep maxout networks for lowresource speech recognition", "author": ["Y. Miao", "F. Metze", "S. Rawat"], "venue": "Proceedings of the 2013 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), Olomouc, Czech Republic, 2013, pp. 398\u2013403.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Latent Dirichlet Allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "Journal of Machine Learning Research, vol. 3, pp. 993\u2013 1022, 2003.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Audio scene understanding using topic models", "author": ["S. Kim", "S. Sundaram", "P. Georgiou", "S. Narayanan"], "venue": "Proceedings of the Neural Information Processing System (NIPS) Workshop, Whistler BC, Canada, 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Acoustic topic model for audio information retrieval", "author": ["S. Kim", "S. Narayanan", "S. Sundaram"], "venue": "Proceedings of the 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), New Paltz NY, USA, 2009, pp. 37\u201340.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Discovering objects and their location in images", "author": ["J. Sivic", "B.C. Russell", "A.A. Efros", "A. Zisserman", "W.T. Freeman"], "venue": "Proceedings of the 10th International Conference on Computer Vision (ICCV), Beijing, China, 2005, pp. 370\u2013377.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "A probabilistic topic model for unsupervised learning of musical key-profiles.", "author": ["D. Hu", "L.K. Saul"], "venue": "Proceedings of the 10th International Society for Music Information Retrieval Conference (ISMIR),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "On information and sufficiency", "author": ["S. Kullback", "R.A. Leibler"], "venue": "The annals of mathematical statistics, vol. 2, no. 1, pp. 79\u201386, 1951.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1951}, {"title": "Finding scientific topics", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "Proceedings of the National Academy of Sciences of the United States of America, vol. 101, pp. 5228\u20135235, 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Vector quantization and signal compression", "author": ["A. Gersho", "R.M. Gray"], "venue": "Berlin, Germany: Springer Science & Business Media,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1992}, {"title": "The Fisher corpus: A resource for the next generations of speech-to-text.", "author": ["C. Cieri", "D. Miller", "K. Walker"], "venue": "Proceedings of the 4th International Conference on Language Resources and Evaluation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "The AMI meeting corpus: A preannouncement", "author": ["J. Carletta", "S. Ashby", "S. Bourban", "M. Flynn", "M. Guillemot", "T. Hain", "J. Kadlec", "W. Karaiskos", "Vasilis Kraaij", "M. Kronenthal", "G. Lathoud", "M. Lincoln", "A. Lisowska", "I. McCowan", "W. Post", "D. Reidsma", "P. Wellner"], "venue": "Proceedings of the Third International Workshop on Machine Learning for Multimodal Interaction, Bethesda MD, USA, 2006, pp. 28\u201339.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "The ICSI meeting corpus", "author": ["A. Janin", "D. Baron", "J. Edwards", "D. Ellis", "D. Gelbart", "N. Morgan", "B. Peskin", "T. Pfau", "E. Shriberg", "A. Stolcke", "C. Wooters"], "venue": "Proceedings of the 2003 IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), Hong Kong, 2003.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "The USFD spoken language translation system for IWSLT 2014", "author": ["R.W.N. Ng", "M. Doulaty", "R. Doddipatla", "O. Saz", "M. Hasan", "T. Hain", "W. Aziz", "K. Shaf", "L. Specia"], "venue": "Lake Tahoe NV, USA, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "WSJCAM0: A british english speech corpus for large vocabulary continuous speech recognition", "author": ["T. Robinson", "J. Fransen", "D. Pye", "J. Foote", "S. Renals"], "venue": "Proceedings of the 1995 IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), Detroit MI, USA, 1995.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}, {"title": "Parallel training of neural networks for speech recognition", "author": ["K. Vesely", "L. Burget", "F. Grezl"], "venue": "Proceedings of the 11th Annual Conference of the International Speech Communication Association (Interspeech), Makuhari, Japan, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Using neural network front-ends on far field multiple microphones based speech recognition", "author": ["Y. Liu", "P. Zhang", "T. Hain"], "venue": "Proceedings of the 2014 IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), Florence, Italy, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "The HTK book (for HTK version 3.4)", "author": ["S. Young", "G. Evermann", "M. Gales", "T. Hain", "D. Kershaw", "X. Liu", "G. Moore", "J. Odell", "D. Ollason", "D. Povey"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Online learning for latent dirichlet allocation", "author": ["M. Hoffman", "F.R. Bach", "D.M. Blei"], "venue": "Proceedings of the Neural Information Processing System (NIPS) Workshop, Vancouver BC, Canada, 2010, pp. 856\u2013864.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["R. Rehurek", "P. Sojka"], "venue": "Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC), Valletta, Malta, 2010, pp. 45\u201350.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Spatial latent dirichlet allocation", "author": ["X. Wang", "E. Grimson"], "venue": "Proceedings of the Neural Information Processing System (NIPS) Workshop, Whistler BC, Canada, 2008, pp. 1577\u20131584.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Background\u2013tracking acoustic features for genre identification of broadcast shows", "author": ["O. Saz", "M. Doulaty", "T. Hain"], "venue": "Proceedings of the 2014 IEEE Workshop on Spoken Language Technologies (SLT), Lake Tahoe NV, USA, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "These domain dependent models have been usually trained via Maximum Likelihood (ML) if a sufficiently large amount of domain data existed or using adaptation techniques such as Maximum A Posteriori [1], Maximum Likelihood Linear Regression (MLLR) [2] or Cluster Adaptive Training [3].", "startOffset": 198, "endOffset": 201}, {"referenceID": 1, "context": "These domain dependent models have been usually trained via Maximum Likelihood (ML) if a sufficiently large amount of domain data existed or using adaptation techniques such as Maximum A Posteriori [1], Maximum Likelihood Linear Regression (MLLR) [2] or Cluster Adaptive Training [3].", "startOffset": 247, "endOffset": 250}, {"referenceID": 2, "context": "These domain dependent models have been usually trained via Maximum Likelihood (ML) if a sufficiently large amount of domain data existed or using adaptation techniques such as Maximum A Posteriori [1], Maximum Likelihood Linear Regression (MLLR) [2] or Cluster Adaptive Training [3].", "startOffset": 280, "endOffset": 283}, {"referenceID": 3, "context": "For more recent Deep Neural Network (DNN)\u2013based systems, domain adaptation is also possible with linear transformations, conservative training and subspace methods [4] with frameworks such as Multi\u2013Level Adaptive Networks (MLAN) [5] or Deep Maxout Networks (DMN) [6].", "startOffset": 164, "endOffset": 167}, {"referenceID": 4, "context": "For more recent Deep Neural Network (DNN)\u2013based systems, domain adaptation is also possible with linear transformations, conservative training and subspace methods [4] with frameworks such as Multi\u2013Level Adaptive Networks (MLAN) [5] or Deep Maxout Networks (DMN) [6].", "startOffset": 229, "endOffset": 232}, {"referenceID": 5, "context": "For more recent Deep Neural Network (DNN)\u2013based systems, domain adaptation is also possible with linear transformations, conservative training and subspace methods [4] with frameworks such as Multi\u2013Level Adaptive Networks (MLAN) [5] or Deep Maxout Networks (DMN) [6].", "startOffset": 263, "endOffset": 266}, {"referenceID": 6, "context": "LDA is an statistical approach to discover latent topics in a collection of documents in an unsupervised manner [7].", "startOffset": 112, "endOffset": 115}, {"referenceID": 7, "context": "In audio tasks, LDA has been used for classifying unstructured audio files into onomatopoeic and semantic descriptions with successful results [8, 9].", "startOffset": 143, "endOffset": 149}, {"referenceID": 8, "context": "In audio tasks, LDA has been used for classifying unstructured audio files into onomatopoeic and semantic descriptions with successful results [8, 9].", "startOffset": 143, "endOffset": 149}, {"referenceID": 6, "context": "Latent Dirichlet Allocation Latent Dirichlet Allocation (LDA) [7] is an unsupervised probabilistic generative model for collections of discrete data.", "startOffset": 62, "endOffset": 65}, {"referenceID": 6, "context": "Also, an infinite mixture over an underlying set of topic probabilities is used to model each topic [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 9, "context": "LDA is mostly used for topic modelling of text corpora, however, the model can be applied to other tasks, such as object categorisation and localisation in image processing [10], automatic harmonic analysis in music processing [11] or acoustic information retrieval in unstructured audio analysis [9].", "startOffset": 173, "endOffset": 177}, {"referenceID": 10, "context": "LDA is mostly used for topic modelling of text corpora, however, the model can be applied to other tasks, such as object categorisation and localisation in image processing [10], automatic harmonic analysis in music processing [11] or acoustic information retrieval in unstructured audio analysis [9].", "startOffset": 227, "endOffset": 231}, {"referenceID": 8, "context": "LDA is mostly used for topic modelling of text corpora, however, the model can be applied to other tasks, such as object categorisation and localisation in image processing [10], automatic harmonic analysis in music processing [11] or acoustic information retrieval in unstructured audio analysis [9].", "startOffset": 297, "endOffset": 300}, {"referenceID": 6, "context": "A reasonable approximate can be acquired using variational approximation which is shown to work reasonably well in various applications [7].", "startOffset": 136, "endOffset": 139}, {"referenceID": 11, "context": "Training tries to minimise the Kullback\u2013Leiber divergence (KLD) [12] between the real and the approximated joint probabilities (equations 2 and 3) [7]:", "startOffset": 64, "endOffset": 68}, {"referenceID": 6, "context": "Training tries to minimise the Kullback\u2013Leiber divergence (KLD) [12] between the real and the approximated joint probabilities (equations 2 and 3) [7]:", "startOffset": 147, "endOffset": 150}, {"referenceID": 12, "context": "Other training methods based on Markov\u2013Chain Monte-Carlo is also proposed, like Gibbs sampling method [13].", "startOffset": 102, "endOffset": 106}, {"referenceID": 6, "context": "Since LDA is for collections of discrete data (such as text corpora) [7], every speech segment of length T frames, x = {x1, .", "startOffset": 69, "endOffset": 72}, {"referenceID": 7, "context": "V } [8].", "startOffset": 4, "endOffset": 7}, {"referenceID": 13, "context": "First a Gaussian Mixture Model (GMM) is trained using Expectation Maximisation (EM) and mix\u2013up procedure to reach the desired codebook size V (enforcing the co\u2013variance matrix to be identity, equivalent to LBG\u2013VQ [14]).", "startOffset": 213, "endOffset": 217}, {"referenceID": 14, "context": "\u2022 Telephone speech (CT): From the Fisher corpus [15].", "startOffset": 48, "endOffset": 52}, {"referenceID": 15, "context": "\u2022 Meetings (MT): From AMI [16] and ICSI [17] corpora.", "startOffset": 26, "endOffset": 30}, {"referenceID": 16, "context": "\u2022 Meetings (MT): From AMI [16] and ICSI [17] corpora.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "\u2022 Lectures (TK): From TedTalks [18].", "startOffset": 31, "endOffset": 35}, {"referenceID": 18, "context": "\u2022 Read speech (RS): From the WSJCAM0 corpus [19].", "startOffset": 44, "endOffset": 48}, {"referenceID": 19, "context": "DNN training was performed with the TNet toolkit [20] and more details can be found at [21].", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "DNN training was performed with the TNet toolkit [20] and more details can be found at [21].", "startOffset": 87, "endOffset": 91}, {"referenceID": 21, "context": "For both types of features, baseline ML GMM\u2013HMM models were trained using HTK [22] with 5\u2013state crossword triphones and 16 gaussians per state.", "startOffset": 78, "endOffset": 82}, {"referenceID": 22, "context": "Codebooks of size 128 up to 8,192 were used and given a codebook, different LDA models with a varying number of domains from 4 to 64 were estimated [23, 24] using the training data described in Section 4.", "startOffset": 148, "endOffset": 156}, {"referenceID": 23, "context": "Codebooks of size 128 up to 8,192 were used and given a codebook, different LDA models with a varying number of domains from 4 to 64 were estimated [23, 24] using the training data described in Section 4.", "startOffset": 148, "endOffset": 156}, {"referenceID": 11, "context": "Following this, KL divergence [12] was proposed as an appropriate metric to measure the consistency of the hidden topics discovered by LDA.", "startOffset": 30, "endOffset": 34}, {"referenceID": 24, "context": "In applying LDA for image processing, there are some variants of the original LDA model, such as Spatial LDA [25] which encodes spatial structure with the visual words.", "startOffset": 109, "endOffset": 113}, {"referenceID": 25, "context": "Newer sets of features, better targeted to describe background acoustic characteristics [26], could also provide an improvement over PLP features, which are known to describe well phonetic and speaker information.", "startOffset": 88, "endOffset": 92}], "year": 2015, "abstractText": "Speech recognition systems are often highly domain dependent, a fact widely reported in the literature. However the concept of domain is complex and not bound to clear criteria. Hence it is often not evident if data should be considered to be out-of-domain. While both acoustic and language models can be domain specific, work in this paper concentrates on acoustic modelling. We present a novel method to perform unsupervised discovery of domains using Latent Dirichlet Allocation (LDA) modelling. Here a set of hidden domains is assumed to exist in the data, whereby each audio segment can be considered to be a weighted mixture of domain properties. The classification of audio segments into domains allows the creation of domain specific acoustic models for automatic speech recognition. Experiments are conducted on a dataset of diverse speech data covering speech from radio and TV broadcasts, telephone conversations, meetings, lectures and read speech, with a joint training set of 60 hours and a test set of 6 hours. Maximum A Posteriori (MAP) adaptation to LDA based domains was shown to yield relative Word Error Rate (WER) improvements of up to 16% relative, compared to pooled training, and up to 10%, compared with models adapted with human-labelled prior domain knowledge.", "creator": "LaTeX with hyperref package"}}}