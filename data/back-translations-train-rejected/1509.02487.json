{"id": "1509.02487", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2015", "title": "Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection", "abstract": "We formulate and study a fundamental search and detection problem, Schedule Optimization, motivated by a variety of real-world applications, ranging from monitoring content changes on the web, social networks, and user activities to detecting failure on large systems with many individual machines.", "histories": [["v1", "Tue, 8 Sep 2015 18:28:24 GMT  (705kb)", "http://arxiv.org/abs/1509.02487v1", null], ["v2", "Thu, 10 Sep 2015 02:22:51 GMT  (705kb)", "http://arxiv.org/abs/1509.02487v2", null]], "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["ahmad mahmoody", "evgenios m kornaropoulos", "eli upfal"], "accepted": false, "id": "1509.02487"}, "pdf": {"name": "1509.02487.pdf", "metadata": {"source": "CRF", "title": "Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection", "authors": ["Ahmad Mahmoody"], "emails": ["eli}@cs.brown.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 9.02 487v 1 [cs.D S] 8 September 2We assume that a large system consists of many nodes, with each node generating its own rate of generating new events or items. A monitoring application can check a small number of nodes at each step, and our goal is to calculate an exploratory plan that minimizes the expected number of undiscovered items in the system or correspondingly minimizes the expected time to discover a new item in the system. We investigate the schedule optimization problem in terms of both deterministic and randomized cordless algorithms. We offer lower limits on the cost of an optimal schedule and construct close to optimal schedules with rigorous mathematical guarantees. Finally, we present an adaptive algorithm that starts without prior information about the system and adapts to the optimal cordless algorithms by adapting to the observed data."}, {"heading": "1 Introduction", "text": "We perform and study a basic stochastic search and detection problem, Schedule Optimization, that captures a variety of practical applications, ranging from monitoring content changes on the Web, social networks and user activity, to detecting failure on large systems using many individual machines.Our optimization problem consists of a large number of units or nodes that generate events or items, according to a random process with known or unknown parameters. A detection algorithm can detect new items in the system by taking a small number of nodes in each step. This setting defines a discrete, endless time process, and the goal of the stochastic optimization problem is to create an exploration plan that minimizes the long-term expected number of undiscovered items in the system, or equivalent, minimizes the expected time to discover a new item in the system. We outline several important applications of this schedule optimizer problem: News and Feed Aggregators. To provide a current summary of news aggregator, websites frequently and a significant site search."}, {"heading": "1.1 Our Contribution", "text": "We consider an infinite discrete time process in which n nodes generate new elements according to a stochastic process regulated by a generating vector \u03c0 (see section 3 for details).An algorithm can examine up to c nodes per step to detect all new elements in these nodes. The goal is to minimize the cost of the algorithm (or exploratory plan), which we consider to be the long-term (stationary) expected number of undiscovered elements in the system.First, we show that the obvious approach of probing the nodes at each step with the maximum expected number of undiscovered elements in that step is not optimal. In fact, the cost of such a plan can be far from the optimal one. Our first result toward efficient schedules is a lower limit on the cost of a deterministic or random plan as a function of the generating vector. Next, we assume that the generating vector circle is known and explicit constructions of cost determining coministerial schedules (c and a coconstructive factor of which we subsuct 1)."}, {"heading": "2 Related Work", "text": "The news and feed aggregation problem is a very well-researched issue, in which the general objective is to obtain updates from news websites (e.g. through RSS feeds). Among many objectives introduced [19,9,1] in investigating this problem, the most similar of our cost function is the delay function represented by [21]. In [21] it is assumed that the rates of news publication do not change, where in our setting these rates can change and our algorithm (adaptive) can adapt to the new environment. Also, we assume that the number of subjects is fixed (or limited) in terms of limited computing power for simultaneous subjects, but [21] uses a relaxed assumption, in which the number of subjects has a fixed length, which can lead to a high number of subjects in a single step."}, {"heading": "3 Model and Problem Definition", "text": "We examine an infinite, discrete scheduling in which a series of n nodes, indexed by 1, is specified., n, generate new items after a random generating process. The generating time in a particular time step is characterized by a generating schedule defined by a generating vector., We first focus on a static generating process in which the generating vector does not change in time. We then expand our results to generating vectors that change over time. Our goal is to detect new events as quickly as possible by trying a small number of nodes in each step. In particular, we look at trying vectors that can go up to c nodes per step."}, {"heading": "4 Results", "text": "We begin this section by first showing that the obvious approach of maximizing the expected number of detections at each step is anything but optimal; then we prove a lower limit on the cost of a schedule and provide deterministic and memoryless c schemes that are within a factor of (3 + (c \u2212 1) / c) or (2 + (c \u2212 1) / c) of optimum; finally, we introduce an algorithm, Adaptive, that outputs an unabashed c scheme that comes close to the optimal c scheme if the generative vector \u03c0 is not known in advance. We also show that adaptive can be used to obtain a c scheme point, the cost of which is within (2 + (c \u2212 1) / c) of an optimal c scheme. In this section, we mean \u03c4Si (t) the number of steps from the last time the node is checked to the time the Qi is not met during the execution of the S (if the expectations are not met during the S)."}, {"heading": "4.1 On Maximizing Immediate Gain", "text": "Let S be a 1 scheme that probes the node with the maximum expected number of undiscovered items at each step. Let's (2) assume the expected number of undiscovered items at the node i and at the time t is \u03c0i\u03c4 S i (t), and thus S (t) = argmaxi \u03c0i\u03c4Si (t).Let's suppose that \u03c0i = 2 \u2212 i, for 1 \u2264 i \u2264 n. Since the probability that node 1 in each step has an undiscovered item is at least 1 / 2, node i is not examined more than once in each 2i \u2212 1 step. So, the expected number of time steps in which an item remains undetected at node i is at least 12i \u2212 1 (1 +. + 2 i \u2212 1) = 2 i \u2212 1 \u2212 1 \u2212 1 i \u2212 1 \u2212 1 \u2212 2 \u2212 2 (Problem) = 2 \u2212 1 + 2 > 2i \u2212 2. Using Lemma 1, the cost of this step is not equal to at least 1 \u00b2 / 2."}, {"heading": "4.2 Lower Bound on Optimal Cost", "text": "In this section, we provide a lower limit for the optimal costs, i.e., the costs for an optimal procedure duration are ni = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 1 = 2 = 1 = 2 = 2 = 2 = 1 = 1 = 2 = 1 = 2 = 2 = 2 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 1 = 2 = 2 = 2 = 1 = 2 = 2 = 2 = 2 = 1 = 1 = 2 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 2 = 2 = 2 = 1 = 1 = 1 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 2 = 1 = 2 = 1 = 2 = 2 = 1 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 1 = 2 = 1 = 2 = 1 = 1 = 2 = 1 = 2 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 1 = 2 = 1 = 1 = 2 = 1 = 2 = 1 = 1 = 1 = 1 = 1 = 2 = 1 = 1 = 1 = 1 = 2 = 1 = 1 = 1 = 1 = 2 = 2 = 1 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2"}, {"heading": "4.4 On Optimal Memoryless Schedule", "text": "Here we look at memoryless schedules and show that the memoryless 1 plan can be easily calculated with minimal cost. We call a memoryless plan with minimal cost between memoryless schedules, an optimal memoryless plan. Then, the cost (R, \u03c0) for a memoryless c plan is limited. (Theorem 3. Let us leave R = (p1,.., pn) for each memoryless 1 plan. Then, the cost (R, \u03c0) for a memoryless c plan is limited.) 2, and the equality applies if and only if pi = zipi \u00b2 for each memoryless plan. (Theorem 3.) Since testing each node i is a geometric distribution with the parameter pi, the expected time until an article generated in the node i is discovered is an ideal R i = 1 / pi = minimized cost. Therefore, we have cost (R = 1 / optimal point for pi)."}, {"heading": "4.5 On Adaptive Algorithm for Memoryless Schedules", "text": "Suppose the schema algorithm starts with no information about the generating vector \u03c0 (or that the vector has changed). We design and analyze an adaptive algorithm that outputs a schema-1 schema algorithm. \u2212 The results are easily scalable to the optimal memoryless algorithm R (see Section 4.4), where the adaptive algorithm outputs a c-schema convergent to Rc (as in Section 4.4). \u2212 To simplify the presentation, we present and analyze a 1-schema algorithm. \u2212 The results start with a schema. \u2212 The results are easily scalable to any integer c > 1, where the adaptive algorithm outputs a c-schema convergent to Rc (as in Section 4.4). \u2212 Every iteration of the algorithm begins with a schema. \u2212 The results are easily scalable to any integer c > 1, where the algorithm adapts to Rc (as in Section 4.4)."}], "references": [{"title": "Adaptive pull-based policies for wide area data delivery", "author": ["L. Bright", "A. Gal", "L. Raschid"], "venue": "ACM Transactions on Database Systems (TODS) 31(2), 631\u2013671", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Emerging topic detection on twitter based on temporal and social terms evaluation", "author": ["M. Cataldi", "L. Di Caro", "C. Schifanella"], "venue": "Proceedings of the Tenth International Workshop on Multimedia Data Mining. pp. 4:1\u20134:10. MDMKDD \u201910, ACM, New York, NY, USA", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "The discoverability of the web", "author": ["A. Dasgupta", "A. Ghosh", "R. Kumar", "C. Olston", "S. Pandey", "A. Tomkins"], "venue": "Proceedings of the 16th international conference on World Wide Web. pp. 421\u2013430. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "The growing role of news in trading automation (Oct 2009), http://www.machinereadablenews.com/images/dl/Machine_Readable_News_and_Algorithmic_Trading.pdf", "author": ["A. Delaney"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Alphaflash trader automated trading based on economic events", "author": ["D.B. Group"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Divergent series, vol", "author": ["G.H. Hardy"], "venue": "334. American Mathematical Soc.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1991}, {"title": "Review of sensor placement strategies for contamination warning systems in drinking water distribution systems", "author": ["W. Hart", "R. Murray"], "venue": "Journal of Water Resources Planning and Management 136(6), 611\u2013619", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "How computers trawl a sea of data for stock picks", "author": ["B. Hope"], "venue": "The Wall Street Journal (Apr 2015),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Online refresh strategies for content based feed aggregation", "author": ["R. Horincar", "B. Amann", "T. Arti\u00e8res"], "venue": "World Wide Web pp. 1\u201335", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient sensor placement optimization for securing large water distribution networks", "author": ["A. Krause", "J. Leskovec", "C. Guestrin", "J. VanBriesen", "C. Faloutsos"], "venue": "Journal of Water Resources Planning and Management 134(6), 516\u2013526", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "The robot journalist in the age of social physics: The end of human journalism? In: The New World of Transitioned Media, pp", "author": ["N.L. Latar"], "venue": "65\u201380. Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Probability, Statistics, and Random Processes For Electrical Engineering (3rd Edition)", "author": ["A. Leon-Garcia"], "venue": "Prentice Hall, 3 edn.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Cost-effective outbreak detection in networks", "author": ["J. Leskovec", "A. Krause", "C. Guestrin", "C. Faloutsos", "J.M. VanBriesen", "N.S. Glance"], "venue": "Berkhin, P., Caruana, R., Wu, X. (eds.) KDD. pp. 420\u2013429. ACM", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Discovering the web\u2019s hidden alpha (Jun 2014), http://www.eaglealpha.com/whitepaper_pdf", "author": ["E.A. Ltd"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Twittermonitor: Trend detection over the twitter stream", "author": ["M. Mathioudakis", "N. Koudas"], "venue": "Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data. pp. 1155\u20131158. SIGMOD \u201910, ACM, New York, NY, USA", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Structured Data Challenges in Finance and Statistics (Nov 2011), http://www.slideshare.net/wesm/structured-data-challenges-in-finance-and-statistics", "author": ["W. McKinney"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "The handbook of news analytics in finance, vol", "author": ["G. Mitra", "L. Mitra"], "venue": "596. John Wiley & Sons", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Probability and computing: Randomized algorithms and probabilistic analysis", "author": ["M. Mitzenmacher", "E. Upfal"], "venue": "Cambridge University Press", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Deriving dynamics of web pages: A survey", "author": ["M. Oita", "P. Senellart"], "venue": "TWAW (Temporal Workshop on Web Archiving)", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "The battle of the water sensor networks (bwsn): A design challenge for engineers and algorithms", "author": ["A Ostfeld"], "venue": "Journal of Water Resources Planning and Management 134(6), 556\u2013568", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient monitoring algorithm for fast news alerts", "author": ["K.C. Sia", "J. Cho", "H.K. Cho"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 19(7), 950\u2013961", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimal crawling strategies for web search engines", "author": ["J.L. Wolf", "M.S. Squillante", "P. Yu", "J. Sethuraman", "L. Ozsen"], "venue": "Proceedings of the 11th international conference on World Wide Web. pp. 136\u2013147. ACM", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 8, "context": "[9,21,1] Algorithmic Trading on Data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[9,21,1] Algorithmic Trading on Data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 0, "context": "[9,21,1] Algorithmic Trading on Data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 3, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 13, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 4, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 16, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 10, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 7, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 15, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 18, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 33, "endOffset": 41}, {"referenceID": 8, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 33, "endOffset": 41}, {"referenceID": 0, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 33, "endOffset": 41}, {"referenceID": 20, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 145, "endOffset": 149}, {"referenceID": 20, "context": "In [21] it is assumed that the rates of the news publication does not change, where in our setting these rates may change and our algorithm (Adaptive) can adapt itself to the new setting.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "Also, we assume at any given time the number of probes is fixed (or bounded) regarding the limited computational power for simultaneous probes, but [21] uses a relaxed assumption by fixing the number of probes over a time window of a fixed length which may result in high number of probes at a single time step.", "startOffset": 148, "endOffset": 152}, {"referenceID": 20, "context": "Finally, [21] introduces a deterministic algorithm in which the number of probes to each feed is obtained by applying the Lagrange multipliers method (very similar result to Theorem 3), but they loose the guarantee on optimality of their solution, by rounding the estimated number of probes to integers.", "startOffset": 9, "endOffset": 13}, {"referenceID": 2, "context": "However, it differs from our model substantially: in web-crawling algorithm data get updated, so missing some intermediate snapshot would not affect the quality of the algorithm, where in our model data are generated and they all need to be processed [3,22].", "startOffset": 251, "endOffset": 257}, {"referenceID": 21, "context": "However, it differs from our model substantially: in web-crawling algorithm data get updated, so missing some intermediate snapshot would not affect the quality of the algorithm, where in our model data are generated and they all need to be processed [3,22].", "startOffset": 251, "endOffset": 257}, {"referenceID": 19, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 125, "endOffset": 129}, {"referenceID": 12, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 223, "endOffset": 232}, {"referenceID": 9, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 223, "endOffset": 232}, {"referenceID": 6, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 223, "endOffset": 232}, {"referenceID": 1, "context": "Besides having different objectives, our model differs mainly in this accessibility assumption: the social network providers have an immediate access to all tweets or postings as they are submitted to their servers, whereas in our model we consider an outside observer who needs an efficient mechanism to monitor changes, without having such full access privilege [2,15].", "startOffset": 364, "endOffset": 370}, {"referenceID": 14, "context": "Besides having different objectives, our model differs mainly in this accessibility assumption: the social network providers have an immediate access to all tweets or postings as they are submitted to their servers, whereas in our model we consider an outside observer who needs an efficient mechanism to monitor changes, without having such full access privilege [2,15].", "startOffset": 364, "endOffset": 370}, {"referenceID": 5, "context": "(Cesaro Means [6]).", "startOffset": 14, "endOffset": 17}, {"referenceID": 11, "context": "i=1 \u03c0i\u03c9 S i , where the last eqaulity is obtained by applying Little\u2019s Law [12].", "startOffset": 75, "endOffset": 79}, {"referenceID": 17, "context": "Applying a Chernoff bound [18] for the sum of t\u2032 independent random variables with either Bernulli or Poisson distribution we have Pr [ |\u03c0\u0303i(t)\u2212 \u03c0i| > t\u2212 1 3 \u03c0i ]", "startOffset": 26, "endOffset": 30}], "year": 2017, "abstractText": "We formulate and study a fundamental search and detection problem, Schedule Optimization, motivated by a variety of real-world applications, ranging from monitoring content changes on the web, social networks, and user activities to detecting failure on large systems with many individual machines. We consider a large system consists of many nodes, where each node has its own rate of generating new events, or items. A monitoring application can probe a small number of nodes at each step, and our goal is to compute a probing schedule that minimizes the expected number of undiscovered items at the system, or equivalently, minimizes the expected time to discover a new item in the system. We study the Schedule Optimization problem both for deterministic and randomized memoryless algorithms. We provide lower bounds on the cost of an optimal schedule and construct close to optimal schedules with rigorous mathematical guarantees. Finally, we present an adaptive algorithm that starts with no prior information on the system and converges to the optimal memoryless algorithms by adapting to observed data.", "creator": "LaTeX with hyperref package"}}}