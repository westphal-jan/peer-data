{"id": "1509.02512", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2015", "title": "DeepCough: A Deep Convolutional Neural Network in A Wearable Cough Detection System", "abstract": "In this paper, we present a system that employs a wearable acoustic sensor and a deep convolutional neural network for detecting coughs. We evaluate the performance of our system on 14 healthy volunteers and compare it to that of other cough detection systems that have been reported in the literature. Experimental results show that our system achieves a classification sensitivity of 95.1% and a specificity of 99.5%.", "histories": [["v1", "Tue, 8 Sep 2015 19:59:19 GMT  (528kb,D)", "http://arxiv.org/abs/1509.02512v1", "BioCAS-2015"]], "COMMENTS": "BioCAS-2015", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["justice amoh", "kofi odame"], "accepted": false, "id": "1509.02512"}, "pdf": {"name": "1509.02512.pdf", "metadata": {"source": "CRF", "title": "DeepCough: A Deep Convolutional Neural Network in A Wearable Cough Detection System", "authors": ["Justice Amoh"], "emails": ["justice.amoh.jr.th@dartmouth.edu"], "sections": [{"heading": null, "text": "I. INTRODUCTIONReal-time automated cough detection could be valuable for the diagnosis and treatment of respiratory diseases. As cough is relatively rare, a cough detector must have a very low false alarm rate to be useful at all. On the other hand, such a system needs a sufficiently high sensitivity to detect the rare cough event. Researchers have tried to address these challenges by using complex hand-crafted or hand-controlled features [1], [2]. Unfortunately, these features can take time to develop and may not necessarily be optimal for cough detection. In this study, we propose a deep neural network framework to learn good features that lead to better cough detection."}, {"heading": "II. SYSTEM OVERVIEW", "text": "The proposed cough detection system includes a portable sensor to detect the user's breathing or voice sounds in real time, and the sensor shown in Figure 1 is attached to the chest using a high-quality medical foam adhesive. Once worn, it feeds pulmonary and abdominal sounds to a computer or smartphone for further processing and classification of events. Unlike previous systems that relied on conventional condenser microphones [3], our sensor is a more application-specific sensor consisting of a piezoelectric converter and additional signal conditioning electronics that amplify acoustic events of interest. Specifically, the sensor amplifies breathing sounds, attenuates spoken speech and eliminates environmental noise overall. Also, the contact piezo converter captures the additional vibrational energy that coughs in the body, helping to improve distinction."}, {"heading": "III. COUGH DETECTION DETAILS", "text": "Our cough detection algorithm includes a pre-processing stage followed by a classifier. The pre-processing stage extracts some preliminary features and also limits the amount of uninteresting data that is included in the classifier. The classifier is a Convolutionary Neural Network (CNN) that performs additional feature extractions and designates an audio event either as a cough or not."}, {"heading": "A. Preprocessing", "text": "To eliminate irrelevant data such as silence and background noise, the preprocessor implements the frame recording process proposed by Lu et al. [5]. For each 16-frame (64 ms) window, the effective energy is calculated and compared to a predetermined threshold. Low-energy windows are assumed to be silent or ambient sound, and they are discarded. High-energy windows are \"approved\" and subjected to further processing. For each approved window, a 128-fold Short Time Fourier Transform (STFT) is performed to provide a 64 x 16-fold spectral seg-ar Xiv: 150 9.02 512v 1 [cs.N E] 8S ep2 015ment (i.e. spectrogram of 64 ms data). These spectral segments are the inputs fed to CNN for classification."}, {"heading": "B. Convolutional Neural Network Architecture", "text": "In recent years, CNNs have been successfully applied to several computer vision tasks such as object recognition, localization, and tracking. [7] Our network consists of five layers: 2 layers of snake lines, 2 snake lines, natural speech processing, and classification of music genres. In our work, we implement a distinction between coughing and speech noises."}, {"heading": "IV. EXPERIMENTAL METHODS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Data Collection", "text": "To build and evaluate the proposed system, we created a database of lung noises from 14 healthy volunteers: 7 men and 7 women. All subjects gave informed consent, and the experimental protocol was approved by the Dartmouth College Institutional Review Board. The piezo sensor was used to collect acoustic data while the subjects were guided through a series of procedures, including generating forced coughing fits and reading out some loud instructions. Each subject produced an average of 40 coughing noises, resulting in a total of 627 coughing samples in our database. For the speech data, the subjects read 20 phonetically balanced instructions from the Harvard Sentences database [11]. From these sentence recordings, snippets were extracted so that there were an equal number of voice and cough samples, and each sample was of a similar length. For an objective assessment of our piezo sensor, we also used a professional voice recorder, 12 of both Olympus and 4zo at the same time."}, {"heading": "B. Network Training", "text": "When forming our neural network, we first divide our database into two parts: 70% for building the model and 30% for the test. We divide the model-building data into training and validation sets in a ratio of 80: 20. The training set is used to actually train the network. The trained model is then run several times against the validation set to find optimal hyperparameters for the model (e.g. learning rate, number of filters, etc.) Once all the hyperparameters are found, the model is retrained and run against the test set for the final evaluation. We expand our input data to introduce a translational invariance into learning by re-buffering the 16-frame spectral segments from the same events to have a 4-frame overlap (25%). Segments at the edges are zero-padded if necessary to introduce a translational invariance into our learning database with 279."}, {"heading": "C. Experiments", "text": "In order to evaluate the performance of the proposed system, two experiments are undertaken: the first one examines the hypothesis that CNN has better cough detection properties than the traditional handmade MFCC characteristics; the second one compares the entire end-to-end detection system with alternative approaches; Experiment 1: To test how effective the learned CNN characteristics are, we compare them to the MFCC characteristics. We extract 13 MFCC coefficients from all 8 ms of the training examples (50%), resulting in an equivalent number of frames as in the STFT spectral segments (16 per 64 ms) used in the formation of CNN characteristics."}, {"heading": "V. RESULTS & DISCUSSION", "text": "Table 1 shows the results of Experiment 1. First, we note that our CNN model performs much better (~ 10% more) than an SVM based on the raw STFT data. This is consistent with the notion that CNN actually extracts features from the STFT that are useful for classification. Furthermore, the CNN model based on this data set appears to outperform the MFCC either with the Softmax classifier or the SVM, suggesting that CNN is a more effective feature extractor for cough classification. An interesting observation is that the MFCC + SVM model provides a specificity comparable to that of the CNN model. Specificity in this binary cough language discrimination model indicates the accuracy of the model in recognizing speech events. And so one possible explanation for why MFCC still manages to achieve a high specificity could be the fact that MFCs are particularly effective at being designed and used by humans, as we hear and are very effective."}, {"heading": "VI. CONCLUSIONS", "text": "In this study, we proposed a system that utilizes a portable acoustic sensor and a deep convolutionary neural network to detect coughs; we evaluated our model's ability to extract good features for the custom sensor and cough detection; we also demonstrated that our revolutionary network model outperforms previous work in the literature; and future work will examine other neural network architectures that are better suited to time-varying inputs such as recurring neural networks; and a more immediate follow-up study would be an expanded passive data collection where subjects or patients can wear our sensors for hours or days to detect unforced coughs. ACKNOWLEGMENTThis work is supported by the Neukom Institute for Computational Science at Dartmouth College. We would like to thank Professor Lorenzo Toressani (Computer Science Department, Dartmouth College) for discussions and suggestions on methods and resources for deep learning."}], "references": [{"title": "The automatic recognition and counting of cough.", "author": ["S.J. Barry", "A.D. Dane", "A.H. Morice", "A.D. Walmsley"], "venue": "Cough (London, England),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "An automated system for 24-h monitoring of cough frequency: the leicester cough monitor.", "author": ["S. Matos", "S.S. Birring", "I.D. Pavord", "D.H. Evans"], "venue": "IEEE transactions on bio-medical engineering,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "The Leicester Cough Monitor: Preliminary validation of an automated cough detection system in chronic cough", "author": ["S.S. Birring", "T. Fleming", "S. Matos", "a. a. Raj", "D.H. Evans", "I.D. Pavord"], "venue": "European Respiratory Journal, vol. 31, no. 5, pp. 1013\u20131018, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Accurate and privacy preserving cough sensing using a low-cost microphone", "author": ["E.C. Larson", "T. Lee", "S. Liu", "M. Rosenfeld", "S.N. Patel"], "venue": "Proceedings of the 13th international conference on Ubiquitous computing - UbiComp \u201911, p. 375, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Sound- Sense: scalable sound sensing for people-centric applications on mobile phones", "author": ["H. Lu", "W. Pan", "N. Lane", "T. Choudhury", "A. Campbell"], "venue": "Proceedings of the 7th international conference on Mobile systems, applications, and services, pp. 165\u2013178, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances In Neural Information Processing Systems, pp. 1\u20139, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "International Conference on Machine Learning, vol. 32, pp. 647\u2013655, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition", "author": ["G. Hinton", "L. Deng", "D. Yu", "G.E. Dahl", "A.-r. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T.N. Sainath", "B. Kingsbury"], "venue": "Ieee Signal Processing Magazine, no. November, pp. 82\u201397, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Unsupervised feature learning for audio classification using convolutional deep belief networks.", "author": ["H. Lee", "P. Pham", "Y. Largman", "A. Ng"], "venue": "Nips, pp", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "IEEE recommended practice for speech quality measurements", "author": ["E.H. Rothauser", "W.D. Chapman", "N. Guttman", "H.R. Silbiger", "J.L. Sullivan"], "venue": "IEEE Trans. Audio . . . , vol. AU-17, no. 297, pp. 225\u2013246, 1969.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1969}, {"title": "Lasagne: First release.", "author": ["S. Dieleman", "J. Schl\u00fcter", "C. Raffel"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Detection of Cough Sounds in Continuous Audio Recordings Using Hidden Markov Models", "author": ["S. Matos", "S. Member", "S.S. Birring", "I.D. Pavord", "D.H. Evans", "S. Member"], "venue": "vol. 53, no. 6, pp. 1078\u2013 1083, 2006.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "A Neural Network Based Algorithm for Automatic Identification of Cough Sounds", "author": ["V. Swarnkar", "U.R. Abeyratne", "S.M. Ieee", "Y. Amrulloh", "C. Hukins", "R. Triasih"], "venue": "pp. 1764\u20131767, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Researchers have attempted to address these challenges by employing complex hand-crafted or hand-tuned features [1], [2].", "startOffset": 112, "endOffset": 115}, {"referenceID": 1, "context": "Researchers have attempted to address these challenges by employing complex hand-crafted or hand-tuned features [1], [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 2, "context": "In contrast to previous systems that relied on conventional condenser microphones [3], [4], ours is a more applicationspecific sensor consisting of a piezoelectric transducer and additional signal conditioning electronics that enhance acoustic events of interest.", "startOffset": 82, "endOffset": 85}, {"referenceID": 3, "context": "In contrast to previous systems that relied on conventional condenser microphones [3], [4], ours is a more applicationspecific sensor consisting of a piezoelectric transducer and additional signal conditioning electronics that enhance acoustic events of interest.", "startOffset": 87, "endOffset": 90}, {"referenceID": 0, "context": "such features have proved effective in speech recognition and have yielded impressive results in cough studies [1], [2], they are not necessarily optimal for the specific task of cough detection.", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "such features have proved effective in speech recognition and have yielded impressive results in cough studies [1], [2], they are not necessarily optimal for the specific task of cough detection.", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "To eliminate irrelevant data such as silence and background noise, the preprocessor implements the frame admission process suggested by Lu et al [5].", "startOffset": 145, "endOffset": 148}, {"referenceID": 5, "context": "Recently, CNNs have been successfully applied to several computer vision tasks such as object recognition, localization and tracking [7], [8].", "startOffset": 133, "endOffset": 136}, {"referenceID": 6, "context": "Recently, CNNs have been successfully applied to several computer vision tasks such as object recognition, localization and tracking [7], [8].", "startOffset": 138, "endOffset": 141}, {"referenceID": 7, "context": "CNNs have also been applied to other domains such as action recognition, speech recognition, natural language processing and music genre classification [9].", "startOffset": 152, "endOffset": 155}, {"referenceID": 5, "context": "We chose ReLU activations over the traditional tanh or sigmoid functions because ReLU doesn\u2019t have the vanishing gradient problem and often leads to a faster convergence [7].", "startOffset": 170, "endOffset": 173}, {"referenceID": 8, "context": "Previous applications of convolutional networks in audio sometimes convolved along either time or frequency axis [10].", "startOffset": 113, "endOffset": 117}, {"referenceID": 9, "context": "For the speech data, subjects read out 20 phonetically-balanced prompts from the Harvard Sentences database [11].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "Implementation of the convolutional network is done using Lasagne [12], a Theano-based library for training neural networks.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "This HMM configuration is fairly common in cough studies and in speech recognition [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 0, "context": "HACC [1] LPC-PNN 15 1000 80.", "startOffset": 5, "endOffset": 8}, {"referenceID": 1, "context": "LCM [2] MFCC-HMM 19 10000 85.", "startOffset": 4, "endOffset": 7}, {"referenceID": 12, "context": "[14] NN 3 100 93.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4] PCA-Random Forest 17 150 92.", "startOffset": 0, "endOffset": 3}], "year": 2015, "abstractText": "In this paper, we present a system that employs a wearable acoustic sensor and a deep convolutional neural network for detecting coughs. We evaluate the performance of our system on 14 healthy volunteers and compare it to that of other cough detection systems that have been reported in the literature. Experimental results show that our system achieves a classification sensitivity of 95.1% and a specificity of 99.5%.", "creator": "LaTeX with hyperref package"}}}