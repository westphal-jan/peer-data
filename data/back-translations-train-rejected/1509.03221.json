{"id": "1509.03221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2015", "title": "Recurrent Neural Network Based Modeling of Gene Regulatory Network Using Bat Algorithm", "abstract": "Correct inference of genetic regulations inside a cell is one of the greatest challenges in post genomic era for the biologist and researchers. Several intelligent techniques and models were already proposed to identify the regulatory relations among genes from the biological database like time series microarray data. Recurrent Neural Network (RNN) is one of the most popular and simple approach to model the dynamics as well as to infer correct dependencies among genes. In this paper, Bat Algorithm (BA) was applied to optimize the model parameters of RNN model of Gene Regulatory Network (GRN). Initially the proposed method is tested against small artificial network without any noise and the efficiency was observed in term of number of iteration, number of population and BA optimization parameters. The model was also validated in presence of different level of random noise for the small artificial network and that proved its ability to infer the correct inferences in presence of noise like real world dataset. In the next phase of this research, BA based RNN is applied to real world benchmark time series microarray dataset of E. Coli. The results shown that it can able to identify the maximum true positive regulation but also include some false positive regulations. Therefore, BA is very suitable for identifying biological plausible GRN with the help RNN model", "histories": [["v1", "Fri, 21 Aug 2015 10:20:44 GMT  (642kb)", "http://arxiv.org/abs/1509.03221v1", "14 pages, 4 figure. arXiv admin note: text overlap witharXiv:1004.4170by other authors"], ["v2", "Wed, 2 Aug 2017 08:25:40 GMT  (216kb)", "http://arxiv.org/abs/1509.03221v2", "14 pages, 4 figure. arXiv admin note: text overlap witharXiv:1004.4170by other authors"]], "COMMENTS": "14 pages, 4 figure. arXiv admin note: text overlap witharXiv:1004.4170by other authors", "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["sudip mandal", "goutam saha", "rajat k pal"], "accepted": false, "id": "1509.03221"}, "pdf": {"name": "1509.03221.pdf", "metadata": {"source": "CRF", "title": "Recurrent Neural Network Based Modeling of Gene Regulatory Network Using Bat Algorithm", "authors": ["Sudip Mandal", "Goutam Saha", "Rajat K. Pal"], "emails": ["sudip.mandal007@gmail.com", "dr_goutamsaha@yahoo.com", "pal.rajatk@gmail.com"], "sections": [{"heading": null, "text": "Biologist and researcher. Several intelligent techniques and models have already been proposed to identify regulatory relationships between genes from the biological database, such as time series microarray data. Recurrent neural network (RNN) is one of the most popular and simplest approaches to model dynamics and derive correct dependencies between genes."}, {"heading": "In this paper, Bat Algorithm (BA) was applied to optimize the model parameters of RNN model of Gene Regulatory", "text": "This year it has come to the point where it only takes a few days for it to come to a conclusion."}, {"heading": "A. Preliminary of RNN Model for GRN", "text": "Since the inputs of a classical Artificial Neural Network come only from the training data set, NNs are not suitable for modelling the dynamics of a system. However, the RNN model is a closed loop with a delay variable between the outputs of each neuron in the output layer of the RNN to each of the neurons in the input layer, which is suitable for modelling the temporal data. In the canonical RNN model [29], the regulations of the gene are expressed with the following closely coupled architecture [15], [16], [17], [18], [19], [20] where it is assumed that each of the total neurons in the output unit (+) is a gene expression value of the next point in time, and the neurons in the input units () are the interput function of gene 1 () are the gene expression of the current state for the same genes, i.e. with each gene and each gene."}, {"heading": "B. Preliminary of Bat Algorithm for training of RNN", "text": "This year, it has come to the point where it is less than a year since the EU Presidency of the Council of the European Union reached the stage where it holds the Presidency of the Council of the European Union."}, {"heading": "A. Estimation Criteria and Decoupled Recurrent Neural Network", "text": "All optimization methods use an objective function or fitness value to measure the goodness of a solution = gene optimization is a square error criterion defined as:, \",\" \",\" \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\" \",\", \"\", \"\", \",\" \",\", \",\" \",\", \"\", \",\", \",\", \"\", \",\" \",\", \"\", \"\""}, {"heading": "B. Regularization as Penalty Term for Real Life Network", "text": "However, the real-life gene network is sparsely networked, i.e. there are very few connections between the genes and the measured data is also very loud. RNN-based GRN models can have different optimal solutions with very low error values, depending on the different connectivity or structure between these genes of the network and the corresponding values of the kinetic parameters. In order to overcome this overfit problem for the real genetic network, the balance must be achieved between minimizing errors and the actual regulation structure of the GRN. Thus, a regulation term is introduced, together with an error function, to avoid overmatching, in order to find the original network by limiting the regulation size and also limiting the scope of reach during optimization."}, {"heading": "C. Learning Process", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "C. Model Selection or Parametric Sensitivity", "text": "As a next we have selected a minimum of 200 experiments for all other experiments.50 100 200 25000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"}], "references": [{"title": "Identification of a Gene Expression Signature Common to Distinct Cancer Pathways", "author": ["N. Fankhauser", "I. Cima1", "P. Wild", "W. Krek"], "venue": "Cancer Informatics, Vol.11, pp. 139-146, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Linking microarray data to the literature (2001)", "author": ["D.R. Masys"], "venue": "Nature Genetics, Vol. 28, pp. 9-10,2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Microarray data normalization and transformation", "author": ["J. Quackenbush"], "venue": "Nature Genetics., vol. 32, pp. 496\u2013501, 2002.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Identification of Genetic Networks from a Small Number of Gene Expression Patterns under the Boolean Network Model", "author": ["T. Akutsu", "S. Miyano", "S. Kuhara"], "venue": "Pacific Symposium on Biocomputing 4, pp. 17-28, 1999.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1999}, {"title": "Modeling Regulatory Networks with Weight Matrices", "author": ["D.C. Weaver", "C.T. Workman", "G.D. Stormo"], "venue": "Pacific Symposium on Biocomputing 4, pp.123, 1999.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "Gene networks inference using dynamic Bayesian networks", "author": ["B.E. Perrin", "L. Ralaivola", "A. Mazurie", "S. Bottani", "J. Mallet", "F. D'Alche-Buc"], "venue": "Bioinformatics, vol. 19, Suppl 2, pp. II138-II148, 2003.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Comparative evaluation of reverse engineering gene regulatory networks with relevance networks, graphical Gaussian models and Bayesian networks", "author": ["A.V. Werhli", "M. Grzegorczyk", "D. Husmeier"], "venue": "Bioinformatics,vol. 22, no. 20, p. 2523, 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Inference of S-system models of genetic networks using a cooperative coevolutionary algorithm", "author": ["S. Kimura", "K. Ide", "A. Kashihara", "M. Kano", "M. Hatakeyama", "R. Masui", "N. Nakagawa", "S. Yokoyama", "S. Kuramitsu", "A. Konagaya"], "venue": "Bioinformatics, vol. 21, no. 7, p. 1154, 2005.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Inference of Biological S-System Using the Separable Estimation Method and the Genetic Algorithm", "author": ["L.Z. Liu", "F.X. Wu", "W.J. Zhang"], "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics, Vol. 9, No. 4, pp. 955-965, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Incorporating Time-Delays in S-System Model for Reverse Engineering Genetic Networks", "author": ["A.R. Chowdhury", "M. Chetty", "N.X. Vinh"], "venue": "BMC Bioinformatics, Vol. 14, pp. 1-22, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Reverse Engineering of Gene Regulatory Networks Using Dissipative Particle Swarm Optimization", "author": ["L. Palafox", "N. Noman", "H. Iba"], "venue": "IEEE Transactions on Evolutionary Computation, Vol. 17, No. 4, pp. 577-587, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "S-System Based Gene Regulatory Network Reconstruction Using Firefly Algorithm", "author": ["S. Mandal", "G. Saha", "R.K. Pal"], "venue": "Third International Conference on Computer, Communication, Control and Information Technology (C3IT-2015), pp.1-5, 2015, doi: 10.1109/C3IT.2015.7060217.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Discovering Gene Networks with a Neural-Genetic Hybrid", "author": ["E. Keedwell", "A. Narayanan"], "venue": "IEEE/ACM Transaction in Computational Biology and Bioinformatics, vol. 2, no. 3, pp. 231-242, 2005.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "Modeling Genetic Regulatory Dynamics in Neural Development", "author": ["M.Wahde", "J.Hertz"], "venue": "Journal Computational Biology, vol. 8(4), pp.429\u2013442, 2001.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "A Field Guide to Dynamical Recurrent Networks", "author": ["J. Kolen", "S. Kremer"], "venue": "IEEE Press, 2001.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "Modeling human cancer-related regulatory modules by GA-RNN hybrid algorithms", "author": ["J.H. Chiang", "S.Y. Chao"], "venue": "BMC Bioinformatics, Vol. 8(91), 2007.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Inference of genetic regulatory networks with recurrent neural network models using particle swarm optimization", "author": ["R. Xu", "I.I.D. Wunsch", "R. Frank"], "venue": "IEEE/ACM Trans. Computat. Biol. Bioinform., vol. 4, no.4, pp. 681\u2013692, Oct.\u2013Dec. 2007.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Study on the Use of Evolutionary Technique for Inference in Gene Regulatory Networks", "author": ["L. Palafox", "N. Noman", "H. Iba"], "venue": "Proceeding in Information and Communication Technology (PICT 6), pp. 82-92, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Reconstruction of Gene Regulatory Networks from Gene Expression Data Using Decoupled Recurrent Neural Network Model", "author": ["N. Noman", "L. Palafox", "H. Iba"], "venue": "Proceeding in Information and Communication Technology (PICT 6), pp. 93-103, 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "A Recurrent Fuzzy Neural Model of a Gene Reglatory Network for Knoledge Extraction Using Invasive Wee and Artificial Bee Colony Optimization Algorithm", "author": ["P. Rakshit", "P Das", "A. Konar", "M. Nasipuri", "R. Janarthanan"], "venue": "1 International Conference on Recent Advances in Information Technology (RAIT), 2012.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "A Swarm Intelligence Framework for Reconstructing Gene Networks: Searchnig for Biologically Plausible Architecture", "author": ["K. Kentzoglannakis", "M. Poole"], "venue": "IEEE/ACM Trans. Computat. Biol. Bioinform., vol. 9, no. 2, pp. 358-372, 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "No free lunch theorems for optimization,\u201d IEEE Transaction on Evolutionary Computing", "author": ["D.H. Wolpert", "W.G. Macready"], "venue": "Vol. 1, pp.67\u201382, 1997.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1997}, {"title": "A New Metaheuristic Bat-Inspired Algorithm", "author": ["X.-S. Yang"], "venue": "in: Nature Inspired Cooperative Strategies for Optimization (NISCO 2010) (Eds. J. R. Gonzalez et al.), Studies in Computational Intelligence, Springer Berlin, 284, Springer, 65-74, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Engineering Optimization: An Introduction with Metaheuristic Applications", "author": ["X.-S. Yang"], "venue": "Wiley , 2010.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Application of Bat Algorithm and Fuzzy Systems to Model Exergy Changes in a Gas Turbine", "author": ["A.L. Tamiru", "F.M. Hashim"], "venue": "Artificial Intelligence, Evolutionary Computing and Metaheuristics Studies in Computational Intelligence, Volume 427, pp 685-719, 2013.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Bat Algorithm for Topology Optimization in Microelectronic Applications", "author": ["X.-S. Yang", "M. Karamanoglu", "S. Fong"], "venue": "IEEE conference FGCT-2012,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Bat Algorithm for Multiobjective Optimization", "author": ["X.S. Yang"], "venue": "Int. J. Bio-Inspired Computation, Vol. 3, No. 5, pp.267-274, 2011.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}, {"title": "Bat algorithm: literature review and applications", "author": ["X.S. Yang"], "venue": "Int. J. Bio-Inspired Computation,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Neural network model of gene expression", "author": ["J.Vohradsk \u0301y"], "venue": "The FASEB Journal: official publication of the Federation of American Societies for Experimental Biology, vol. 15(3), pp. 846\u2013854, 2001.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2001}, {"title": "Improved Bat Algorithm (IBA) on Continuous Optimization Problems", "author": ["S. Yilmaz", "E.U. Kucuksille"], "venue": "Lecture Notes on Software Engineering Vol. 1, No. 3, pp. 279-283, August 2013.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Modified Bat Algorithm", "author": ["S. Y\u0131lmaz", "E. Ugur Kucuksille", "Y. Cengiz"], "venue": "Elektronika IR Elektrotechnika, vol. 20, no. 2, pp. 71-78, 2014.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Large-scale mapping and validation of Escherichia coli transcriptional regulation from a compendium of expression profiles.\" PLoS biology", "author": ["Faith", "J.Jeremiah"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "Assigning numbers to the arrows: parameterizing a gene regulation network by using accurate expression kinetics", "author": ["M. Ronen", "R. Rosenberg", "B.I.Shraiman", "U. Alon"], "venue": "Proceedings of the National Academy of Sciences 99, 10555, 2002.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "A General Recurrent Neural Network Approach to Model Genetic Regulatory Networks", "author": ["Xiao Hu", "A. Maglia", "D.C. Wunsch"], "venue": "Engineering in Medicine and Biology Society, 2005. IEEE-EMBS 2005. 27th Annual International Conference of the , vol., no., pp.4735-4738, 2006", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Thus, the study of GRNs appears to be very essential in order to discover the genetic causes of a particular disease and for the subsequent design of new and effective methods of treatment to control the disease causing genes with their mutual interactions [1].", "startOffset": 257, "endOffset": 260}, {"referenceID": 1, "context": "DNA microarrays [2], [3] are widely used now-a-days for the purpose of investigation of the mechanism that is responsible for Cancer.", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "DNA microarrays [2], [3] are widely used now-a-days for the purpose of investigation of the mechanism that is responsible for Cancer.", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "Boolean networks [4], [5] examine binary state transition matrices to search patterns in gene expression depending on a binary state function.", "startOffset": 17, "endOffset": 20}, {"referenceID": 4, "context": "Boolean networks [4], [5] examine binary state transition matrices to search patterns in gene expression depending on a binary state function.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "A Dynamic Bayesian network [6], [7] makes conditional probabilistic transitions between network states that merge the features of Hidden Markov model to include the feedback.", "startOffset": 27, "endOffset": 30}, {"referenceID": 6, "context": "A Dynamic Bayesian network [6], [7] makes conditional probabilistic transitions between network states that merge the features of Hidden Markov model to include the feedback.", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": "S-system [8], [9], [10], [11], [12] is also a popular model of Biochemical System Theory, represents a GRN as a set of differential equation with power law function.", "startOffset": 9, "endOffset": 12}, {"referenceID": 8, "context": "S-system [8], [9], [10], [11], [12] is also a popular model of Biochemical System Theory, represents a GRN as a set of differential equation with power law function.", "startOffset": 14, "endOffset": 17}, {"referenceID": 9, "context": "S-system [8], [9], [10], [11], [12] is also a popular model of Biochemical System Theory, represents a GRN as a set of differential equation with power law function.", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "S-system [8], [9], [10], [11], [12] is also a popular model of Biochemical System Theory, represents a GRN as a set of differential equation with power law function.", "startOffset": 25, "endOffset": 29}, {"referenceID": 11, "context": "S-system [8], [9], [10], [11], [12] is also a popular model of Biochemical System Theory, represents a GRN as a set of differential equation with power law function.", "startOffset": 31, "endOffset": 35}, {"referenceID": 12, "context": "Neural Network [13], [14] along with GA was also proposed to infer GRN successfully.", "startOffset": 15, "endOffset": 19}, {"referenceID": 13, "context": "Neural Network [13], [14] along with GA was also proposed to infer GRN successfully.", "startOffset": 21, "endOffset": 25}, {"referenceID": 14, "context": "However, in this work, we have used Recurrent Neural Network (RNN) [15] which is closed loop Neural Network with a delayed feedback variable suitable to model genetic system dynamics from temporal data.", "startOffset": 67, "endOffset": 71}, {"referenceID": 15, "context": "[16] proposed the hybridization of Genetic Algorithm (GA) and RNN for finding feed-forward regulated genes when some transcription factors were given to construct cancer-related regulatory modules in human cancer microarray data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] used Particle Swarm Optimization (PSO) to predict of dynamics and network structure of small artificial network and SOS network of E.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] have implemented K-means Population Based Incremental Learning (KPBIL) to optimize the parameters of the RNN and the model is tested against small real and artificial network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] proposed Decoupled Recurrent Neural Network which was trained Differential Evolution (DE) technique and introduced a penalty term or L1 regularizer in the objective function to balance between accuracy and network structure.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] have proposed weight matrix based Recurrent Fuzzy Neural Model using Invasive Weed and Artificial Bee Colony (ABC) Optimization technique along with a new penalty function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] hybridized PSO and Ant Colony Optimization (ACO) for reverse engineering problem of GRN where PSO was used to train the RNN parameters and ACO was introduced to find the biological plausible network structure.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Moreover, No Free Lunch (NFL) theorem [22] logically states that there is no single metaheuristic which is best suited for solving all kind of optimization problems.", "startOffset": 38, "endOffset": 42}, {"referenceID": 22, "context": "-S Yang [23], [24], was based on the use of echolocation of bats during their foraging.", "startOffset": 8, "endOffset": 12}, {"referenceID": 23, "context": "-S Yang [23], [24], was based on the use of echolocation of bats during their foraging.", "startOffset": 14, "endOffset": 18}, {"referenceID": 24, "context": "To the authors\u2019 best knowledge, Bat Algorithm (BA) was successfully implemented in others field of engineering [25], [26] has yet to be incorporated for parameters optimization of S-System.", "startOffset": 111, "endOffset": 115}, {"referenceID": 25, "context": "To the authors\u2019 best knowledge, Bat Algorithm (BA) was successfully implemented in others field of engineering [25], [26] has yet to be incorporated for parameters optimization of S-System.", "startOffset": 117, "endOffset": 121}, {"referenceID": 26, "context": "As BA can be successfully implemented for continuous parameter optimization and multi-objective optimization [27], [28], it may be suitable for parameter optimization of S-system based model of GRN.", "startOffset": 109, "endOffset": 113}, {"referenceID": 27, "context": "As BA can be successfully implemented for continuous parameter optimization and multi-objective optimization [27], [28], it may be suitable for parameter optimization of S-system based model of GRN.", "startOffset": 115, "endOffset": 119}, {"referenceID": 28, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 23, "endOffset": 27}, {"referenceID": 14, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 114, "endOffset": 118}, {"referenceID": 15, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 120, "endOffset": 124}, {"referenceID": 16, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 126, "endOffset": 130}, {"referenceID": 17, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 132, "endOffset": 136}, {"referenceID": 18, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 138, "endOffset": 142}, {"referenceID": 19, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 144, "endOffset": 148}, {"referenceID": 20, "context": "In canonical RNN model [29], the gene\u2019s regulations are expressed with the following tightly coupled architecture [15], [16], [17], [18], [19], [20], [21] where it is assumed that each of the total N neurons in the output unit ei(t + \u2206t) is a gene expression value of next time instant, and the neurons in the input units ei(t) are the gene expression of present state for same genes, thus they interacts with each and everyone.", "startOffset": 150, "endOffset": 154}, {"referenceID": 22, "context": "Preliminary of Bat Algorithm for training of RNN Bat Algorithm (BA), initially proposed by Yang [23], is inspired by echolocation behaviour of bats [30].", "startOffset": 96, "endOffset": 100}, {"referenceID": 29, "context": "Preliminary of Bat Algorithm for training of RNN Bat Algorithm (BA), initially proposed by Yang [23], is inspired by echolocation behaviour of bats [30].", "startOffset": 148, "endOffset": 152}, {"referenceID": 29, "context": "Moreover bats can discriminate between a prey and an obstacle easily even in complete darkness [30].", "startOffset": 95, "endOffset": 99}, {"referenceID": 23, "context": "In order to convert these behaviours to Bat Algorithm, some rules are idealized by Yang [24].", "startOffset": 88, "endOffset": 92}, {"referenceID": 23, "context": "\uf0b7 All bats use echolocation to measure distance or direction of objects, and they can also discriminate the difference between food/prey and background obstacles by some magical way [24], [30], [31].", "startOffset": 182, "endOffset": 186}, {"referenceID": 29, "context": "\uf0b7 All bats use echolocation to measure distance or direction of objects, and they can also discriminate the difference between food/prey and background obstacles by some magical way [24], [30], [31].", "startOffset": 188, "endOffset": 192}, {"referenceID": 30, "context": "\uf0b7 All bats use echolocation to measure distance or direction of objects, and they can also discriminate the difference between food/prey and background obstacles by some magical way [24], [30], [31].", "startOffset": 194, "endOffset": 198}, {"referenceID": 0, "context": "They can automatically adjust the wavelength (or frequency) of their emitted pulses and adjust the rate of pulse emission r \u03b5 [0, 1], depending on the proximity of their target [24], [30], [31].", "startOffset": 126, "endOffset": 132}, {"referenceID": 23, "context": "They can automatically adjust the wavelength (or frequency) of their emitted pulses and adjust the rate of pulse emission r \u03b5 [0, 1], depending on the proximity of their target [24], [30], [31].", "startOffset": 177, "endOffset": 181}, {"referenceID": 29, "context": "They can automatically adjust the wavelength (or frequency) of their emitted pulses and adjust the rate of pulse emission r \u03b5 [0, 1], depending on the proximity of their target [24], [30], [31].", "startOffset": 183, "endOffset": 187}, {"referenceID": 30, "context": "They can automatically adjust the wavelength (or frequency) of their emitted pulses and adjust the rate of pulse emission r \u03b5 [0, 1], depending on the proximity of their target [24], [30], [31].", "startOffset": 189, "endOffset": 193}, {"referenceID": 23, "context": "\uf0b7 Although the loudness can vary in many ways, it is assumed that the loudness varies from a large (positive) A0 to a minimum constant value Amin [24], [30], [31].", "startOffset": 146, "endOffset": 150}, {"referenceID": 29, "context": "\uf0b7 Although the loudness can vary in many ways, it is assumed that the loudness varies from a large (positive) A0 to a minimum constant value Amin [24], [30], [31].", "startOffset": 152, "endOffset": 156}, {"referenceID": 30, "context": "\uf0b7 Although the loudness can vary in many ways, it is assumed that the loudness varies from a large (positive) A0 to a minimum constant value Amin [24], [30], [31].", "startOffset": 158, "endOffset": 162}, {"referenceID": 23, "context": "Initialization of parameters or solutions: Initial population [24], [30] of positions of bats are randomly produced from real-valued vectors with dimension jb and number of bats n, by taking into account lower and upper boundaries.", "startOffset": 62, "endOffset": 66}, {"referenceID": 29, "context": "Initialization of parameters or solutions: Initial population [24], [30] of positions of bats are randomly produced from real-valued vectors with dimension jb and number of bats n, by taking into account lower and upper boundaries.", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "rand is a function that generate random value within the limit [0,1].", "startOffset": 63, "endOffset": 68}, {"referenceID": 23, "context": "Update Process of Frequency, Velocity and Position: The frequency factor controls step size of a solution in BA [24], [30].", "startOffset": 112, "endOffset": 116}, {"referenceID": 29, "context": "Update Process of Frequency, Velocity and Position: The frequency factor controls step size of a solution in BA [24], [30].", "startOffset": 118, "endOffset": 122}, {"referenceID": 0, "context": "\u03b2 \u03b5 [0, 1] is random generated number to modify the frequency.", "startOffset": 4, "endOffset": 10}, {"referenceID": 23, "context": "For local search part of algorithm (exploitation) one solution is selected among the selected best solutions and random walk [24], [30] is applied.", "startOffset": 125, "endOffset": 129}, {"referenceID": 29, "context": "For local search part of algorithm (exploitation) one solution is selected among the selected best solutions and random walk [24], [30] is applied.", "startOffset": 131, "endOffset": 135}, {"referenceID": 0, "context": "xnew = xold + \u03b5 A nt (6) Where A is average loudness of all bats and \u03b5 \u03b5 [0, 1] is random number which represents direction and intensity of random-walk [24], [30], [31].", "startOffset": 73, "endOffset": 79}, {"referenceID": 23, "context": "xnew = xold + \u03b5 A nt (6) Where A is average loudness of all bats and \u03b5 \u03b5 [0, 1] is random number which represents direction and intensity of random-walk [24], [30], [31].", "startOffset": 153, "endOffset": 157}, {"referenceID": 29, "context": "xnew = xold + \u03b5 A nt (6) Where A is average loudness of all bats and \u03b5 \u03b5 [0, 1] is random number which represents direction and intensity of random-walk [24], [30], [31].", "startOffset": 159, "endOffset": 163}, {"referenceID": 30, "context": "xnew = xold + \u03b5 A nt (6) Where A is average loudness of all bats and \u03b5 \u03b5 [0, 1] is random number which represents direction and intensity of random-walk [24], [30], [31].", "startOffset": 165, "endOffset": 169}, {"referenceID": 23, "context": "Loudness and Pulse Emission Rate Update Process: Loudness and pulse emission rate must be updated as iterations proceed [24], [30].", "startOffset": 120, "endOffset": 124}, {"referenceID": 29, "context": "Loudness and Pulse Emission Rate Update Process: Loudness and pulse emission rate must be updated as iterations proceed [24], [30].", "startOffset": 126, "endOffset": 130}, {"referenceID": 23, "context": "Loudness A and pulse emission rate r are updated by the following equations Aib nt+1 = \u03b1 Aib nt (7) rib nt+1 = rib 0 [1 \u2212 e ] (8) where \u03b1 and \uf067\uf020are loudness reduction and pulse rate increment constants [24], [30].", "startOffset": 202, "endOffset": 206}, {"referenceID": 29, "context": "Loudness A and pulse emission rate r are updated by the following equations Aib nt+1 = \u03b1 Aib nt (7) rib nt+1 = rib 0 [1 \u2212 e ] (8) where \u03b1 and \uf067\uf020are loudness reduction and pulse rate increment constants [24], [30].", "startOffset": 208, "endOffset": 212}, {"referenceID": 0, "context": "rib 0 and Aib 0 are initial pulse rate and initial loudness which are random values between [0,1].", "startOffset": 92, "endOffset": 97}, {"referenceID": 18, "context": "To generate the sparse solutions, the concept of in-degree or cardinality [19] of genes in error function was already introduced.", "startOffset": 74, "endOffset": 78}, {"referenceID": 18, "context": "If any of these (N-I) elements achieved a non zero-value during optimization process, the solution will be penalized in the following way [19] for decoupled RNN system fi = (ecal ,k ,i,t \u2212 eexp ,k ,i ,t) 2 + t=1 M k=1 c ( Wi,j ) N\u2212I j=1 (12) where Wi,j is the vector which contains the absolute values of wi ,j but sorted in ascending order.", "startOffset": 138, "endOffset": 142}, {"referenceID": 22, "context": "Now the pseudo code [23], [24], [30] of the proposed method can be given as 1.", "startOffset": 20, "endOffset": 24}, {"referenceID": 23, "context": "Now the pseudo code [23], [24], [30] of the proposed method can be given as 1.", "startOffset": 26, "endOffset": 30}, {"referenceID": 29, "context": "Now the pseudo code [23], [24], [30] of the proposed method can be given as 1.", "startOffset": 32, "endOffset": 36}, {"referenceID": 10, "context": "Now, the two parameters, Sensitivity (Sn) and Specificity (SP) of the reconstructed network are define as follows [11], [18], [19]", "startOffset": 114, "endOffset": 118}, {"referenceID": 17, "context": "Now, the two parameters, Sensitivity (Sn) and Specificity (SP) of the reconstructed network are define as follows [11], [18], [19]", "startOffset": 120, "endOffset": 124}, {"referenceID": 18, "context": "Now, the two parameters, Sensitivity (Sn) and Specificity (SP) of the reconstructed network are define as follows [11], [18], [19]", "startOffset": 126, "endOffset": 130}, {"referenceID": 16, "context": "Earlier approaches [17], [19], [20] already used this network to verify their proposed algorithm\u2019s efficiency.", "startOffset": 19, "endOffset": 23}, {"referenceID": 18, "context": "Earlier approaches [17], [19], [20] already used this network to verify their proposed algorithm\u2019s efficiency.", "startOffset": 25, "endOffset": 29}, {"referenceID": 19, "context": "Earlier approaches [17], [19], [20] already used this network to verify their proposed algorithm\u2019s efficiency.", "startOffset": 31, "endOffset": 35}, {"referenceID": 29, "context": "The search space was selected as wi ,j \u2208 [-30,30], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 20] same as earlier work [19].", "startOffset": 41, "endOffset": 49}, {"referenceID": 9, "context": "The search space was selected as wi ,j \u2208 [-30,30], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 20] same as earlier work [19].", "startOffset": 56, "endOffset": 64}, {"referenceID": 19, "context": "The search space was selected as wi ,j \u2208 [-30,30], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 20] same as earlier work [19].", "startOffset": 74, "endOffset": 81}, {"referenceID": 18, "context": "The search space was selected as wi ,j \u2208 [-30,30], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 20] same as earlier work [19].", "startOffset": 103, "endOffset": 107}, {"referenceID": 0, "context": "Boundary of frequency was intialized as [0,1] and step size during random walk was fixed by 0.", "startOffset": 40, "endOffset": 45}, {"referenceID": 19, "context": "It can be observed that the proposed RNN-BA method is much superior than RNN-IWO+ABC [20] and RNN-ACO+PSO [21] with respect to selectivity and sensitivity.", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "It can be observed that the proposed RNN-BA method is much superior than RNN-IWO+ABC [20] and RNN-ACO+PSO [21] with respect to selectivity and sensitivity.", "startOffset": 106, "endOffset": 110}, {"referenceID": 19, "context": "IPR of RNN-BA model is also very smaller and better than RNN-IWO+ABC [20] and RNN-ACO+PSO [17] that proves the accuracy of the proposed model.", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "IPR of RNN-BA model is also very smaller and better than RNN-IWO+ABC [20] and RNN-ACO+PSO [17] that proves the accuracy of the proposed model.", "startOffset": 90, "endOffset": 94}, {"referenceID": 18, "context": "However, only RNN-DE [19] process gave better performance than our RNN-BA model in term of IPR.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "Process TP FP TN FN Sn Sp RNN-BA 8 0 8 0 1 1 RNN-PSO [17] 8 0 8 0 1 1 RNN-DE [19] 8 0 8 0 1 1 RNN-IWO+ABC [20] 7 3 5 1 0.", "startOffset": 53, "endOffset": 57}, {"referenceID": 18, "context": "Process TP FP TN FN Sn Sp RNN-BA 8 0 8 0 1 1 RNN-PSO [17] 8 0 8 0 1 1 RNN-DE [19] 8 0 8 0 1 1 RNN-IWO+ABC [20] 7 3 5 1 0.", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "Process TP FP TN FN Sn Sp RNN-BA 8 0 8 0 1 1 RNN-PSO [17] 8 0 8 0 1 1 RNN-DE [19] 8 0 8 0 1 1 RNN-IWO+ABC [20] 7 3 5 1 0.", "startOffset": 106, "endOffset": 110}, {"referenceID": 20, "context": "63 RNN-ACO+PSO [21] 5 1 7 3 0.", "startOffset": 15, "endOffset": 19}, {"referenceID": 16, "context": "RNN-PSO [17] 3 50 150 608.", "startOffset": 8, "endOffset": 12}, {"referenceID": 18, "context": "RNN-DE [19] 10 50 500 \u2245 0", "startOffset": 7, "endOffset": 11}, {"referenceID": 19, "context": "RNN-IWO+ABC [20] 4 150 600 45.", "startOffset": 12, "endOffset": 16}, {"referenceID": 20, "context": "RNN-ACO+PSO [21] 1 300 300 --", "startOffset": 12, "endOffset": 16}, {"referenceID": 0, "context": "Where d(t) is initial noiseless data, ns is percentage of random noise and rand is a function that generate random number between [0,1].", "startOffset": 130, "endOffset": 135}, {"referenceID": 31, "context": "[32] was first introduced by Uri Alon group [33] which is a benchmark in GRN problem to find out the effectiveness of the inference algorithm on real time dataset and network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[32] was first introduced by Uri Alon group [33] which is a benchmark in GRN problem to find out the effectiveness of the inference algorithm on real time dataset and network.", "startOffset": 44, "endOffset": 48}, {"referenceID": 33, "context": "[34]", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "The search space was selected as wi ,j \u2208 [-10,10], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 10] same as earlier work [19].", "startOffset": 41, "endOffset": 49}, {"referenceID": 9, "context": "The search space was selected as wi ,j \u2208 [-10,10], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 10] same as earlier work [19].", "startOffset": 56, "endOffset": 64}, {"referenceID": 9, "context": "The search space was selected as wi ,j \u2208 [-10,10], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 10] same as earlier work [19].", "startOffset": 74, "endOffset": 81}, {"referenceID": 18, "context": "The search space was selected as wi ,j \u2208 [-10,10], \u03b2i \u2208 [-10,10] and \u03c4i \u2208 [0, 10] same as earlier work [19].", "startOffset": 103, "endOffset": 107}], "year": 2015, "abstractText": "Correct inference of genetic regulations inside a cell is one of the greatest challenges in post genomic era for the biologist and researchers. Several intelligent techniques and models were already proposed to identify the regulatory relations among genes from the biological database like time series microarray data. Recurrent Neural Network (RNN) is one of the most popular and simple approach to model the dynamics as well as to infer correct dependencies among genes. In this paper, Bat Algorithm (BA) was applied to optimize the model parameters of RNN model of Gene Regulatory Network (GRN). Initially the proposed method is tested against small artificial network without any noise and the efficiency was observed in term of number of iteration, number of population and BA optimization parameters. The model was also validated in presence of different level of random noise for the small artificial network and that proved its ability to infer the correct inferences in presence of noise like real world dataset. In the next phase of this research, BA based RNN is applied to real world benchmark time series microarray dataset of E. Coli. The results shown that it can able to identify the maximum true positive regulation but also include some false positive regulations. Therefore, BA is very suitable for identifying biological plausible GRN with the help RNN model.", "creator": "Microsoft\u00ae Office Word 2007"}}}