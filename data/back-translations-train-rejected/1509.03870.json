{"id": "1509.03870", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Sep-2015", "title": "The USFD Spoken Language Translation System for IWSLT 2014", "abstract": "The University of Sheffield (USFD) participated in the International Workshop for Spoken Language Translation (IWSLT) in 2014. In this paper, we will introduce the USFD SLT system for IWSLT. Automatic speech recognition (ASR) is achieved by two multi-pass deep neural network systems with adaptation and rescoring techniques. Machine translation (MT) is achieved by a phrase-based system. The USFD primary system incorporates state-of-the-art ASR and MT techniques and gives a BLEU score of 23.45 and 14.75 on the English-to-French and English-to-German speech-to-text translation task with the IWSLT 2014 data. The USFD contrastive systems explore the integration of ASR and MT by using a quality estimation system to rescore the ASR outputs, optimising towards better translation. This gives a further 0.54 and 0.26 BLEU improvement respectively on the IWSLT 2012 and 2014 evaluation data.", "histories": [["v1", "Sun, 13 Sep 2015 16:58:41 GMT  (108kb,D)", "http://arxiv.org/abs/1509.03870v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["raymond w m ng", "mortaza doulaty", "rama doddipatla", "wilker aziz", "kashif shah", "oscar saz", "madina hasan", "ghada alharbi", "lucia specia", "thomas hain"], "accepted": false, "id": "1509.03870"}, "pdf": {"name": "1509.03870.pdf", "metadata": {"source": "CRF", "title": "The USFD Spoken Language Translation System for IWSLT 2014", "authors": ["Raymond W. M. Ng", "Mortaza Doulaty", "Rama Doddipatla", "Wilker Aziz", "Kashif Shah", "Oscar Saz", "Madina Hasan", "Ghada AlHarbi", "Lucia Specia", "Thomas Hain"], "emails": ["o.saztorralba@sheffield.ac.uk", "m.hasan@sheffield.ac.uk", "GAlHarbi1@sheffield.ac.uk", "l.specia@sheffield.ac.uk", "t.hain@sheffield.ac.uk"], "sections": [{"heading": "1. Introduction", "text": "In this paper, the system of the University of Sheffield (USFD) for the International Workshop on Spoken Language Translation (IWSLT) 2014 is presented. USFD participated in English-French and English-German SLT tasks. ASR and MT systems used state-of-the-art technologies. On the ASR side, two deep neural network systems were used, which were based on partially different data and different tandem configurations. On the MT side, phrase-based translation models were created. ASR and MT system integration attempts were made using a translation quality estimation system. It took into account the system results of both ASR and MT, as well as features extracted from the ASR issues in the source language. ASR hypotheses were subsequently rescorted on the basis of the predicted translation quality. This leads to improvements in performance with regard to the BLEU score. Below, the primary data used for the system integration are shown in sections 2 of the ASR and \u00a7 3 of the ASR system."}, {"heading": "2. Data processing and selection", "text": "The ASR and MT systems were trained primarily on TED lecture data [1]. For ASR, TED and the additional data form two data sets on which two systems were trained. For MT, out-of-domain data after data selection was included in the training of translation models and target language models."}, {"heading": "2.1. ASR acoustic modelling", "text": "The composition of the two data sets shown in Table 1.TED serves as a common data set in both ASR1 and ASR2. Their segmentations in ASR1 and ASR2 differ slightly and this is explained later. E-Corner Lecture Data (ECRN) supplements the two data sets with a duration of 60 hours [2]. ASR1 also contains 106 hours of LLC lecture data. ASR2 adds 165 hours of meeting data from AMI, AMIDA and ICSI companies, so that the trained model also reflects generic domains outside of the lecture. TED portions in both ASR1 and ASR2 are taken from 734 TED lectures published before December 31, 2010. Each lecture has a duration of approximately 15 minutes."}, {"heading": "2.2. Language models and MT", "text": "Text data for the formation of language models and translation models were obtained from the related websites of the IWSLT and WMT ratings [5, 6]. TED was considered as in-domain training data and the full data set was used. Four out-of-domain (OOD) data sets from Messages Comment v9, Common Crawl, Gigaword and Europarl v7 were also used, after a data selection process. OOD corpora were selected using the cross-entropy difference criterion [7]. Given a sentence xI1 \u00b7 xI] with I words, cross-entropy values H (xI1, ID) and H (xIOD) were used using GID, the ID language model (in this case, TED) and GOOD, the language model of OOOD values (built on the corpus)."}, {"heading": "3. Automatic speech recognition", "text": "This year it is more than ever before."}, {"heading": "4. Machine translation", "text": "All TED data (3.17 million words) were then used for phrase extraction. [12] According to previous findings [12], the data selection was used using a criterion of cross-entropy difference (detailed in \u00a7 2.2) to select the optimal batch of OOD data, which accounts for about 5% of the total data, or 30.58 million words. Phrase length was limited to 5 and word alignment was achieved using FASTALIGN [13]. Lexicalized rendering models were trained using the same data. For language modeling, we used the complete sets of OD data (i.e. no data selection). 5-gram LMs were trained using LMPLZ. The 100-best MIRA vote was used [15]. For the English-French system, the coordination with the IWSLT system was performed."}, {"heading": "5. Decoding", "text": "In fact, we are able to put ourselves at the top, \"he said in an interview with the German Press Agency.\" We have to put ourselves at the top, \"he said,\" but we also have to put ourselves at the top. \""}, {"heading": "6. System integration", "text": "The USFD primary system is a pipeline SLT system in which 1-best ASR result was transmitted directly to the MT system. System integration experiments were tested in the En-Fr-SLT task and the results were submitted as contrastive systems. Figure 2 shows the integrated system and its comparison with the pipeline system. In the integrated system, the ASR hypotheses are expanded in the form of lattices, confusion networks or N-leaderboards. A Quality Assessment (QE) module was evaluated and rescorded before being fed into the MT system. In our implementation, the best outputs from the ASR system are used at IWSLT 2011."}, {"heading": "7. Summary", "text": "This paper describes the USFD SLT System for IWSLT 2014. Automatic Speech Recognition (ASR) is achieved through two multi-pass systems with deep neural networks with slightly different tandem configurations and different training data. Machine Translation (MT) is achieved through a monolingual phrase translation system that restores the case and inserts punctuations, followed by a bilingual phrase translation system. USFD contrast systems examine the integration of ASR and MT using a quality assurance system to revive the ASR results, resulting in better translation."}, {"heading": "8. References", "text": "[1] TED, \"Technology entertainment design,\" http: / / ted.com predivey, \"2006. [2] M. Hasan, R. Doddipatla, and T. Hain,\" Multi-pass sentence-end detection of lecture speech, \"in Proc. Interspeech, 2014. [3] T. Hain, L. Burget, J. Dines, P. N. Garner, A. E. Hannani, M. Huijbregts, M. Karafiat, M. Lincoln, and V. Wan,\" The AMIDA 2009 meeting transcription system, \"in Proc. Interspeech 2010, 2010, pp. 358-361. [4] R. Doddipatla, M. Hasan, and T. Hain.\" bottleneck layer training for speaker adaptation in automatic speech recognition, \"2014. [5] M. Cettolo, C. Girardi, and M. Federico,\" WIT3: Web inventory of transcribed and translated talks. \""}], "references": [{"title": "Technology entertainment design", "author": ["TED"], "venue": "http://www. ted.com, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Multi-pass sentence-end detection of lecture speech", "author": ["M. Hasan", "R. Doddipatla", "T. Hain"], "venue": "Proc. Interspeech, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "The AMIDA 2009 meeting transcription system", "author": ["T. Hain", "L. Burget", "J. Dines", "P.N. Garner", "A.E. Hannani", "M. Huijbregts", "M. Karafiat", "M. Lincoln", "V. Wan"], "venue": "Proc. Interspeech 2010, 2010, pp. 358\u2013361.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Speaker dependent bottleneck layer training for speaker adaptation in automatic speech recognition", "author": ["R. Doddipatla", "M. Hasan", "T. Hain"], "venue": "2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "WIT3: Web inventory of transcribed and translated talks", "author": ["M. Cettolo", "C. Girardi", "M. Federico"], "venue": "Proceedings of Conference of European Association for Machine Translation Trento (Italy), 2012, pp. 261\u2013268.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Intelligent selection of language model training data", "author": ["R.C. Moore", "W. Lewis"], "venue": "Proceedings of the ACL 2010 Conference Short Papers, ser. ACLShort \u201910. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010, pp. 220\u2013224.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Tandem connectionist feature extraction for conventional HMM systems", "author": ["H. Hermansky", "D. Ellis", "S. Sharma"], "venue": "Proc. ICASSP, 2000.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Minimum phone error and I-smoothing for improved discriminative training", "author": ["D. Povey", "P.C. Woodland"], "venue": "Proc. ICASSP, 2002.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Implicit modelling of pronunciation variation in automatic speech recognition", "author": ["T. Hain"], "venue": "Speech Communication, vol. 46, pp. 171\u2013188, 2005.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Moses: open source toolkit for statistical machine translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens", "C. Dyer", "O. Bojar", "A. Constantin", "E. Herbst"], "venue": "Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ser. ACL \u201907. Stroudsburg, PA, USA: Association for Computational Linguistics, 2007, pp. 177\u2013180.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Edinburgh SLT and MT system description for the IWSLT 2013 evaluation", "author": ["A. Birch", "N. Durrani", "P. Koehn"], "venue": "Proceedings of International Workshop on Spoken Language Translation, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "A simple, fast, and effective reparameterization of IBM model 2", "author": ["C. Dyer", "V. Chahuneau", "N.A. Smith"], "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Atlanta, Georgia: Association for Computational Linguistics, June 2013, pp. 644\u2013648.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Scalable modified Kneser-Ney language model estimation", "author": ["K. Heafield", "I. Pouzyrevsky", "J.H. Clark", "P. Koehn"], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Sofia, Bulgaria: Association for Computational Linguistics, August 2013, pp. 690\u2013696.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Batch tuning strategies for statistical machine translation", "author": ["C. Cherry", "G. Foster"], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, ser. NAACL HLT \u201912. Stroudsburg, PA, USA: Association for Computational Linguistics, 2012, pp. 427\u2013436.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Modelling punctuation prediction as machine translation", "author": ["S. Peitz", "M. Freitag", "A. Mauser", "H. Ney"], "venue": "Proc. IWSLT, 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Segmentation and punctuation prediction in speech language translation using a monolingual translation system", "author": ["E. Cho", "J. Niehues", "A. Waibel"], "venue": "Proc. IWSLT, 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Automatic speech recognition for scientific purposes webASR", "author": ["T. Hain", "A.E. Hannani", "S.N. Wrigley", "V. Wan"], "venue": "Proc. Interspeech, 2008, pp. 504\u2013507.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Heteroscedastic discriminant analysis and reduced rank HMMs for improved speech recognition", "author": ["N. Kumar", "A.G. Andreou"], "venue": "Speech Communication, vol. 26, pp. 283\u2013297, 1998.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "Forest rescoring: Faster decoding with integrated language models", "author": ["L. Huang", "D. Chiang"], "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Prague, Czech Republic: Association for Computational Linguistics, June 2007, pp. 144\u2013151.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "QuEst - A translation quality estimation framework", "author": ["L. Specia", "K. Shah", "J.G.C. d. Souza", "T. Cohn"], "venue": "Proceedings of 51st Annual Meeting of the Association for Computational Linguistics: Demo Session, Sofia, Bulgaria, 2013, p. 794.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "QuEst - design, implementation and extensions of a framework for machine translation quality estimation", "author": ["K. Shah", "E. Avramidis", "E. Bi\u00e7ici", "L. Specia"], "venue": "Prague Bull. Math. Linguistics, vol. 100, pp. 19\u201330, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "An Investigation on the Effectiveness of Features for Translation Quality Estimation", "author": ["K. Shah", "T. Cohn", "L. Specia"], "venue": "Machine Translation Summit XIV, Nice, France, 2013, pp. 167\u2013174.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Meteor universal: Language specific translation evaluation for any target language", "author": ["M. Denkowski", "A. Lavie"], "venue": "Proceedings of WMT14, 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Quality estimation for ASR K-best list rescoring in spoken language translation", "author": ["R.W.M. Ng", "K. Shah", "W. Aziz", "L. Specia", "T. Hain"], "venue": "Submitted to Proc. ICASSP, 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "The ASR and MT systems were primarily trained on TED lecture data [1].", "startOffset": 66, "endOffset": 69}, {"referenceID": 1, "context": "The two data sets are augmented by e-corner lecture data (ECRN) with a duration of 60 hours [2].", "startOffset": 92, "endOffset": 95}, {"referenceID": 2, "context": "In ASR2, 165 hours of meeting data from the AMI, AMIDA and ICSI corpora are added so the trained model will reflect also generic domains other than lectures [3, 4].", "startOffset": 157, "endOffset": 163}, {"referenceID": 3, "context": "In ASR2, 165 hours of meeting data from the AMI, AMIDA and ICSI corpora are added so the trained model will reflect also generic domains other than lectures [3, 4].", "startOffset": 157, "endOffset": 163}, {"referenceID": 4, "context": "Textual data for the training of language models and translation models were obtained from the affiliated websites of the IWSLT and WMT evaluations [5, 6].", "startOffset": 148, "endOffset": 154}, {"referenceID": 5, "context": "The OOD corpora were selected with the cross entropy difference criterion [7].", "startOffset": 74, "endOffset": 77}, {"referenceID": 6, "context": "There are two DNN systems with tandem configurations in ASR [8].", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "Bottleneck (BN) features were derived from deep neural network (DNN)s [4], and GMM-HMM systems were trained on these bottleneck features.", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "To improve the performance of the acoustic model, minimum phone error (MPE) training was performed using the lattices which were generated using a uni-gram language model [9].", "startOffset": 171, "endOffset": 174}, {"referenceID": 2, "context": "All ASR LMs were based on a word-list with a 60k word vocabulary extracted based on our standard English ASR inventory and the English part of the TED MT training data for IWSLT 2014 [3, 5].", "startOffset": 183, "endOffset": 189}, {"referenceID": 4, "context": "All ASR LMs were based on a word-list with a 60k word vocabulary extracted based on our standard English ASR inventory and the English part of the TED MT training data for IWSLT 2014 [3, 5].", "startOffset": 183, "endOffset": 189}, {"referenceID": 8, "context": "Pronunciation probabilities were incorporated in final stage decoding [10].", "startOffset": 70, "endOffset": 74}, {"referenceID": 9, "context": "A phrase-based model using MOSES [11] in a standard setting was employed.", "startOffset": 33, "endOffset": 37}, {"referenceID": 10, "context": "Following previous findings [12], data selection via a cross-entropy difference criterion (detailed in \u00a72.", "startOffset": 28, "endOffset": 32}, {"referenceID": 11, "context": "The phrase length was limited to 5 and word-alignment was obtained with FASTALIGN [13].", "startOffset": 82, "endOffset": 86}, {"referenceID": 12, "context": "5-gram LMs were trained using LMPLZ [14].", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "100-best MIRA tuning was employed [15].", "startOffset": 34, "endOffset": 38}, {"referenceID": 14, "context": "Following previous work [16, 17], a monolingual translation system was trained to recover casing and punctuation from the ASR output, thus producing source sentences which are more adequate for translation.", "startOffset": 24, "endOffset": 32}, {"referenceID": 15, "context": "Following previous work [16, 17], a monolingual translation system was trained to recover casing and punctuation from the ASR output, thus producing source sentences which are more adequate for translation.", "startOffset": 24, "endOffset": 32}, {"referenceID": 9, "context": "The evaluation systems for ASR and MT are multi-pass systems with resource optimisation and environment management capabilities [11, 18].", "startOffset": 128, "endOffset": 136}, {"referenceID": 16, "context": "The evaluation systems for ASR and MT are multi-pass systems with resource optimisation and environment management capabilities [11, 18].", "startOffset": 128, "endOffset": 136}, {"referenceID": 17, "context": "In a pilot experiment, PLP systems with heteroscedastic linear discriminant analysis (HLDA) were trained on the ASR2 data [19].", "startOffset": 122, "endOffset": 126}, {"referenceID": 18, "context": "MT Decoding was performed with cube pruning [20] both in tuning and testing.", "startOffset": 44, "endOffset": 48}, {"referenceID": 19, "context": "The QE module derived 117 QuEst [21, 22] features from each sentence to describe its linguistic, statistical properties as well as the statistics from the ASR and MT models.", "startOffset": 32, "endOffset": 40}, {"referenceID": 20, "context": "The QE module derived 117 QuEst [21, 22] features from each sentence to describe its linguistic, statistical properties as well as the statistics from the ASR and MT models.", "startOffset": 32, "endOffset": 40}, {"referenceID": 21, "context": "Out of the 117 features, top 58 features were selected using the Gaussian Process (GP) with RBF kernel as described in [23].", "startOffset": 119, "endOffset": 123}, {"referenceID": 22, "context": "Further, GP was used to learn the relationship between the selected features and the translation performance of the sentence (in this case, sentence-based METEOR score) [24].", "startOffset": 169, "endOffset": 173}, {"referenceID": 23, "context": "Details of the integrated system were described in [25].", "startOffset": 51, "endOffset": 55}], "year": 2015, "abstractText": "The University of Sheffield (USFD) participated in the International Workshop for Spoken Language Translation (IWSLT) in 2014. In this paper, we will introduce the USFD SLT system for IWSLT. Automatic speech recognition (ASR) is achieved by two multi-pass deep neural network systems with adaptation and rescoring techniques. Machine translation (MT) is achieved by a phrase-based system. The USFD primary system incorporates state-of-the-art ASR and MT techniques and gives a BLEU score of 23.45 and 14.75 on the English-to-French and English-to-German speech-totext translation task with the IWSLT 2014 data. The USFD contrastive systems explore the integration of ASR and MT by using a quality estimation system to rescore the ASR outputs, optimising towards better translation. This gives a further 0.54 and 0.26 BLEU improvement respectively on the IWSLT 2012 and 2014 evaluation data.", "creator": "LaTeX with hyperref package"}}}