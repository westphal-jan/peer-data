{"id": "1509.04098", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Sep-2015", "title": "Fame for sale: efficient detection of fake Twitter followers", "abstract": "$\\textit{Fake followers}$ are those Twitter accounts specifically created to inflate the number of followers of a target account. Fake followers are dangerous for the social platform and beyond, since they may alter concepts like popularity and influence in the Twittersphere - hence impacting on economy, politics, and society. In this paper, we contribute along different dimensions. First, we review some of the most relevant existing features and rules (proposed by Academia and Media) for anomalous Twitter accounts detection. Second, we create a baseline dataset of verified human and fake follower accounts. Such baseline dataset is publicly available to the scientific community. Then, we exploit the baseline dataset to train a set of machine-learning classifiers built over the reviewed rules and features. Our results show that most of the rules proposed by Media provide unsatisfactory performance in revealing fake followers, while features proposed in the past by Academia for spam detection provide good results. Building on the most promising features, we revise the classifiers both in terms of reduction of overfitting and cost for gathering the data needed to compute the features. The final result is a novel $\\textit{Class A}$ classifier, general enough to thwart overfitting, lightweight thanks to the usage of the less costly features, and still able to correctly classify more than 95% of the accounts of the original training set. We ultimately perform an information fusion-based sensitivity analysis, to assess the global sensitivity of each of the features employed by the classifier. The findings reported in this paper, other than being supported by a thorough experimental methodology and interesting on their own, also pave the way for further investigation on the novel issue of fake Twitter followers.", "histories": [["v1", "Mon, 14 Sep 2015 13:59:11 GMT  (44kb)", "http://arxiv.org/abs/1509.04098v1", null], ["v2", "Tue, 10 Nov 2015 17:31:40 GMT  (44kb)", "http://arxiv.org/abs/1509.04098v2", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CR cs.LG", "authors": ["stefano cresci", "roberto di pietro", "marinella petrocchi", "angelo spognardi", "maurizio tesconi"], "accepted": false, "id": "1509.04098"}, "pdf": {"name": "1509.04098.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Stefano Cresci", "Roberto Di Pietro", "Marinella Petrocchi", "Angelo Spognardi", "Maurizio Tesconi"], "emails": ["stefano.cresci@iit.cnr.it", "roberto.di_pietro@alcatel-lucent.com", "marinella.petrocchi@iit.cnr.it", "angelo.spognardi@iit.cnr.it", "maurizio.tesconi@iit.cnr.it"], "sections": [{"heading": null, "text": "In this paper, we contribute along other dimensions. First, we review some of the most relevant existing features and rules (proposed by Academia and Media) for anomalous Twitter accounts. Second, we create a baseline dataset for verified human and fake follower accounts. Second, we create a baseline dataset for verified follower accounts. Such baseline datasets are available to the scientific community. Then, we use baseline datasets to train a number of machine-learning classifiers built through the verified rules and functions. Our results show that most of the rules proposed by the media are unsatisfactory."}, {"heading": "1. Introduction", "text": "In the recent past, the media has begun to turn the accounts of politicians, celebrities, and popular brands into a place where they can respond to rising inflation. Statistics report over a billion Twitter subscribers with 302 million monthly active users. Twitter's annual advertising revenue in 2014 was estimated at about $480 million. Popular public figures, such as actors and singers, as well as traditional mass media (radio, TV, and newspapers) use Twitter as a new media channel. This versatility and proliferation of use has made Twitter the ideal arena for disseminating abnormal accounts that behave in an unconventional manner. Academic attention has largely focused on spammers who actively target their accounts for the spread of malware by sending spam and advertising activities of questionable legality. To improve their effectiveness, these malicious accounts are often armed with automated Twitter programs, known as controlled real users, known as bots."}, {"heading": "2. Related Work", "text": "Quote from [7]: \"A fake Twitter account is considered a form of deception (i.e., a deception of both the content and personal information of the profiles, as well as a deception if the profile does not follow others out of personal interest, but because they are paid to do so).\" The second characterization of deception is exactly the one we deal with in our newspaper. We explicitly consider fake followers to be those Twitter accounts that are appropriately created and sold to customers who aim to increase their influence and engagement in the eyes of the world, with the illusion of a large number of followers.Thus-defined fake followers are just one example of anomalous accounts that spread across Twitter. Anomalies have actually been identified in literature as spammers (i.e. accounts that promote unwanted and often harmful content that contain links to malicious pages [8], or as bots (i.e. computer programs that control social accounts that mimic real users [9] that are self-identified as accounts, i.e., those that are either cyborated, or accounts that are)."}, {"heading": "2.1. Grey literature and Online Blogs", "text": "Before we cover the academic literature, we briefly report on the online documentation, which presents a set of intuitive criteria for identifying fake followers, although these have not been scientifically proven to be effective. The reason we cite this work is twofold: On the one hand, online articles and posts attest to the search for a correct distinction between real and fake Twitter followers; on the other, we aim to scientifically assess whether such criteria can actually be used to detect fake followers.As an example, a well-known blogger in [11] cites as possible bot-like distinguishing features the fact that bot accounts typically have a huge amount of followers and a small number of followers; 2) tweet the same for all; and, 3) play the follow-unfollow game, i.e. they follow and then do not follow an account within 24 hours. Criteria that are advertised by online blogs, such writers are usually based on the number of people in newspapers, not the number of people in the company."}, {"heading": "2.2. Academic literature", "text": "In recent years, the number of spam attacks on Twitter has multiplied, from several angles. An example of this is a branch of research that has focused on the textual content of tweets [4], both on the redirection of embedded URLs in tweets [18], and on the classification of Twitter pages [19]. Other work that deals with the problem of deception on Twitter exceeds the limitations of tweets that are unable to correctly label those tweets, as well as on spam tweets by authors responsible for the task of deceiving people. Authority, plausibility and support, independent corroboxes, and press work, overcomes the limitations of tweets that are unable to best label those tweets as spam."}, {"heading": "2.3. Differences and similarities with our approach", "text": "The goal of our research is the automatic detection of those Twitter accounts that were specifically created to increase the number of followers of a particular target account (so-called fake Twitter followers). A priori, both spammers, bots and real user accounts could fall into the macro category of fake followers, and specific features have already been proven effective in the literature to detect spammers and bots, could also work in the case of fake followers. In fact, it was this observation that initially drove the authors of this paper in the direction of testing rules and features from past work using a reference data set of real accounts and fake followers. This helped to curtail those rules and features that behaved worst when detecting false followers, and those that behaved well. From a technical point of view, we rely in our experiments on machine learning-based classifiers that used features of 1), 2), and those of UR3, and those of UR8, as well as those of UR8, that were already abiding by certain characteristics."}, {"heading": "3. Baseline datasets", "text": "In this section, we present the data sets of Twitter accounts that were used to conduct our empirical study throughout the paper. We describe in detail how we collected each one and how we verified whether they were real people or fake followers. Despite the final size of the base data set, we searched a total of 9 million Twitter accounts and about 3 million tweets for our research. To further investigate the novel question of fake Twitter followers, our base data set was made publicly available for research [33]."}, {"heading": "3.1. The Fake Project", "text": "The Fake Project started its activities on December 12, 2012 with the establishment of the Twitter account @ TheFakeProject. Its profile reports the following motto: \"Follow me only if you are NOT a fake,\" and explains that the initiative is linked to a research project owned by researchers at the IIT-CNR in Pisa, Italy. In the first phase, the owners contacted other researchers and journalists to promote the initiative, and foreign journalists and bloggers also supported the initiative in their countries. Over a period of twelve days (December 12-24, 2012), the account was followed by 574 followers. Through the Twitter APIs, we combed through a series of public information about these followers along with their followers and followers. For this data set, we combed through the 574 accounts, which resulted in the collection of 616,193 tweets and 971,649 relationships (i.e., linked Twitter accounts).All followers volunteered to join the project. To include them in our reference group of people, we also launched a T74 @ followers, each received a fake message."}, {"heading": "3.2. #elezioni2013 dataset", "text": "The data set # elezioni2013, henceforth E13, was born to support a research initiative for a sociological study carried out in collaboration with the University of Perugia and the University of Sapienza in Rome. Between January 9 and February 28, 2013, the study focused on the strategic changes in the Italian political panorama. Researchers identified 84,033 unique Twitter accounts that used the hashtag # elezioni2013 in their tweets. Identification of these accounts was based on specific keyword-driven queries about the username and biography of the accounts \"profiles, including bloggers, journalists, social media strategists / analysts and congressmen. Certain names of political parties were also searched. Finally, all accounts belonging to politicians and candidates, parties, journalists, bloggers, certain associations and groups, and whoever was in any way officially involved in politics were searched."}, {"heading": "3.3. Baseline dataset of human accounts", "text": "The above data sets form our definitive set of HUM verified human accounts dating back to 1950. It is worth noting how the two sets of data differ from each other. The TFP set consists of accounts recruited on a voluntary basis: individuals who took part in the initiative to be part of an academic study on the discovery of fake followers on Twitter, and a mix of researchers, social media experts and journalists, mostly from Italy, but also from the US and other European countries. The E13 set consists of particularly active Italian Twitter users with different professional backgrounds and from different social classes who share a common interest in politics but do not belong to the following categories: politicians, parties, journalists, bloggers."}, {"heading": "3.4. Baseline dataset of fake followers", "text": "In April 2013, we purchased 3000 fake accounts from three different online Twitter markets. Specifically, we purchased 1000 fake accounts from http: / / fastfollowerz.com, 1000 from http: / / intertwitter.com, and 1000 fake accounts from http: / / twittertechnology.com at a cost of 19, 14, and 13 dollars. Surprisingly, fastfollowerz and intertwitter gave us a few more accounts than we paid for, respectively 1169 and 1337 instead of 1000. We trawled through all of these accounts to create a quick follower record called FSF and an intertwitter record called INT. Instead, we were unable to search through all of the 1000 fake followers we had purchased from them since 155. The remaining 845 accounts form the Twitter Technology dataset known as TWT. We recognize that our dataset is illustrative and not exhaustive, of all the possible existing followers we can find most frequently on Twitter."}, {"heading": "3.5. Baseline dataset of fake followers and human accounts", "text": "The final data we have gathered in our experiments consist of two parts, one and one."}, {"heading": "4. Fake detection with algorithms based on classification rules", "text": "In this section, we detail three procedures originally proposed by bloggers and social media analysts, which were explicitly designed for the detection of fake followers and bot accounts. These proposals were presented in [12, 11, 14]. The work we focus on in this section is not directly attributable to academic work, but it is an example of the growing interest in the phenomenon of fake Twitter followers by media and social marketing companies. Although we do not expect these proposals to be satisfactorily fulfilled for the complex task of detecting fake followers, we believe that a thorough analysis of the proposed criteria could still provide some useful insights. Randomly, all procedures are proposed as algorithms based on a list of rules or criteria: each account to be classified will need to be checked against all rules and the results of controls in order to obtain the final classification. Unfortunately, in many cases, details about how to combine the criteria will not be available to the public."}, {"heading": "4.1. Followers of political candidates", "text": "Camisani-Calzolari [12] then conducted a series of tests on samples of Twitter followers of Romney and Obama, both for the last US presidential election and for popular Italian politicians. In [12], an algorithm is executed to evaluate an account based on some of its public attributes. The quoted algorithm assigns enough detail to the accounts examined to be reproducible: it assigns human points to each of the criteria in Table 2 and classifies an account based on the gap between the sum of the two values. Finally, for each non-verifiable criterion, the account receives a bot point, with the exception of criteria 8, 13, 14, 15, 16 and 17: in this case, no bot points are assigned if it only uses APIs. To verify these rules, we refer to the source metadata of tweets that contain a different value representing the platform."}, {"heading": "4.2. Stateofsearch.com", "text": "Among the several bloggers who propose their golden rules for identifying suspicious Twitter accounts, we consider the \"7 signals to watch out for to detect Twitter bots,\" according to the founder of the social media site stateofsearch.com [11]. The \"7 signals to look out for\" to detect Twitter bots are in Table 3.Rule 3 was implemented by looking at the tweet as a unit. We consider the last 20 tweets of each timeline. For rules 6 and 7, we consider the existence of a duplicate profile picture when at least three accounts within the record have the same profile picture. In rule 5, we consider all tweets that are not posted by the site twitter.com. For rules 6 and 7, when looking for friends or follower lists of an account, Twitter only gives followers information about the current list price, without giving details about past friends or followers. Additionally, Twitter does not consider any tweets that are related to the moment a user is followed in the following group of a follower, as a rule 6 is followed by a follower or follower is the only one behavior that is followed by a follower."}, {"heading": "4.3. Socialbakers\u2019 FakeFollowerCheck", "text": "Several companies provide online tools to classify Twitter followers based on their fakeness level. At this point, we look at Socialbakers \"\" FakeFollowerCheck Tool. \"[14] While the company website provides eight criteria for evaluating the fakeness level of followers of a particular account, it omits details about how such criteria can be combined to classify the accounts. We contacted their customer service department, but were told that\" the way the relevant criteria are measured is more of an internal information. \"The FakeFollowerCheck Tool analyzes the followers of an account and considers them likely to be fake if the criteria listed in Table 4 are fulfilled. In general, 2 we look at expressions such as\" diet \"or\" making money \"or\" at home \"(both English and Italian translations), as suggested by the website Socialbakers."}, {"heading": "4.4. Evaluation methodology", "text": "All of the above criteria were applied to the 2 predicted human accounts (called the confusion of the matrix), where each position represents 36 points, as well as to all 3351 fake follower accounts purchased from the Twitter account markets (FSF, INT, TWT), as in Section 3. We conducted an experiment for each rule, taking into account two classes of accounts, the fake follower and the people. To summarize the results of each experiment, we consider some evaluation measures based on four standard indicators, namely: \u2022 True Positives (TP): the number of these fake followers, which are usually recognized as fake followers; \u2022 True Negative Followers (TN): the number of these human followers, which are usually recognized as human followers; \u2022 False Positives (FP): the number of these human followers, which are usually recognized as fake followers; \u2022 False Negative Followers (FN): the number of these human followers, which is recognized as the individual follower of the rule."}, {"heading": "4.5. Evaluation of Camisani-Calzolari algorithm", "text": "The detection algorithm in [12] aggregates the 22 criteria for identifying human and bot behavior introduced in Section 4.1. The end result depends on the global score achieved by the account: if the result is greater than 0, the account is labeled as human; if it is between 0 and -4, it is labeled as neutral; otherwise, it is labeled as bot.Table 6 describes the results of executing the algorithm over the entire record, including the FAK record, namely all purchased fake follower accounts. Although the algorithm achieves very good results in detecting the real human accounts, it achieves poor detection of false follower accounts. Most of the accounts were also labeled as human, mainly because the fake followers in our dataset have features that easily achieve a higher human score than the bot on.The above inability to detect the fake accounts is very low to recognize the results of our experiment."}, {"heading": "4.6. Single rule evaluation", "text": "In this section, we analyze the effectiveness of each rule as drafted by the original authors * to evaluate which rule can be considered a good criterion for detecting fake Twitter followers *. Table 8 summarizes the results achieved by applying each rule introduced in sections 4.1, 4.2, and 4.3. In Table 8, we highlight the rules that reach high MCC values. As expected by the definition of MCC, such rules also have a combination of high accuracy, precision, and memory. However, it is worth observing the values for information gain and the Pearson correlation coefficient."}, {"heading": "5. Fake detection with algorithms based on feature sets", "text": "In this section, we examine work in [8, 2] dealing with the detection of spam accounts on Twitter. Both propose a list of features to be extracted from manually classified records of accounts. Such feature sets are then used to train and test classifiers for machine learning to distinguish between humans and spammers. Although the proposed features were originally designed to detect spam, we consider them here for the first time as detecting another category of Twitter accounts, i.e. the fake follower. Although there are many other works in the literature that focus on Twitter spam detection (see Section 2), many of them consider features that can be in some way aligned with those analyzed in this and in the previous section, i.e. the fake follower accounts. Unlike rule-based algorithms in Section 4, features are presented here as quantifying the properties of the samples considered knowledge (see the previous section 2), which introduce the characteristics considered knowledge models for such classes."}, {"heading": "5.1. Detecting spammers in social networks", "text": "The study presented in [8] focuses on spambot detection, using several characteristics that can be derived from both the profile and the timeline when searching the details of an account. For each account examined, such characteristics are evaluated in a random forest algorithm [23, 43], which shows whether the account is a spambot or not. Results of the analysis in [8] showed some interesting characteristics of the spambot accounts examined, as in Table 9. To evaluate feature 3, we implement the notion of message similarity by verifying the existence of at least two tweets in the last 15 tweets of the account timeline, in which four consecutive words are the same. This notion was taken up in a later paper by the same authors [25]. Without the original training set, we could not reproduce the same classifier, but we selected the five characteristics and used them to train a series of classifiers with our Table 12 results reported in the 5.Data Set."}, {"heading": "5.2. Fighting evolving Twitter spammers", "text": "The authors of [2] have observed that Twitter spammers frequently change their behavior to circumvent existing spam detection techniques, so they proposed to consider some new features that make it difficult for spammers to circumvent them. In addition to the features available directly via the account query, the authors propose some graphic-, automation- and time-based features. In Table 10, we describe nine of these, along with the result of their analysis in [2].The authors of [2] combine their features into four different machine learning classifiers and compare their implementation with other existing approaches. We were unable to fully reproduce the machine learning classifiers in [2] because we had a different dataset. Instead, here we evaluate how these features, which have proven to be quite robust against spammer-applied evaluation techniques, perform in the detection of fake Twitter followers. As in [2], the following rate (feature 9) would not be considered less robust than the rating of the friends mentioned above, but rather more accurate than the rating of the number of friends mentioned above."}, {"heading": "5.3. Evaluation", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "5.4. Discussion", "text": "By examining the internal structure of the classifiers, we gain insights into the best traits that do more to distinguish between human followers and false followers. In the case of decision trees, the best traits are those that are closer to the root, and the classifier automatically finds the numerical thresholds that mark the boundary between human followers and false followers for a given trait. It should be noted that the Decorate, AdaBoost, and Random Forest algorithms also ultimately use combinations of simple decision tree classifiers. Although they perform very well, they have the disadvantage of being difficult to analyze as they can consist of dozens of individual trees that interact with each other. Then, we focus only on the J48 classifier (a single decision tree) to examine how the traits are applied during the classification process."}, {"heading": "5.4.1. Differences between fake followers and spam accounts", "text": "Looking at the tree structure, we observe some interesting differences between the fake followers in our BAS dataset and the spam accounts characterized in [8] and [2]. For example, it was found that the feature-URL ratio is higher for spammers than for legitimate users, as highlighted in [8] (Section 5.1). Instead, looking at the tree structure of our J48 classifier, low values for this feature show fake followers, compared to higher values indicating human accounts in our base dataset. More than 72% of the fake followers in our training dataset have a URL ratio of less than 0.05, as opposed to 14% of human accounts. Similarly, the API ratio was found to be higher for spammers than for legitimate accounts ([2], see also Section 5.2)."}, {"heading": "5.4.2. Reducing overfitting", "text": "It is known that trained classifiers are subject to \"overfitting,\" namely the problem that is less specialized on the training dataset and unable to generalize the classification to new and invisible data [45].One simple way to avoid overfitting is to keep the classifier as simple as possible. In the case of a decision tree algorithm, for example, one solution could be the reduction in the number of nodes and, possibly, the height of the tree. The decision tree that comes with the feature set of Stringhini et al. [8] has 22 leaves, 43 nodes, and a height of 7, while the best feature is the friends / (follower) ratio that starts at the root. The decision tree with the feature set of Yang et al. [2] has 17 leaves, 33 nodes and a height of 8 nodes, and a height of 7, while the best feature is the friends / (follower)."}, {"heading": "5.4.3. Bidirectional link ratio", "text": "In Section 5.3, we observed that the bidirectional link ratio had the highest information gain of all the features considered. To test whether this is the key feature for distinguishing between humans and fake followers, and how strongly it affects the detection process, we compare the results of the earlier expert results with those of a new one. We are building a decision tree classifier that excludes the bi-link ratio from the feature set of Yang et al. [2] and compare its effectiveness against the classifier built with the full set. The results will be shown in the last rows of Table 13. This experiment is particularly interesting because, as in the next Section 6, this feature is the most expensive to evaluate. The results in Table 13 show an apparent decrease in accuracy, precision and memory of the less pruned trees (partial tree having 0.25 and reduced errors 3 folds), as well as for both F measurements and AUC, and even a noticeable decrease in the MCC measure."}, {"heading": "6. An efficient and lightweight classifier", "text": "Similarly, we have seen that the feature set proposed by Yang et al. [2] seems to be slightly more effective than that proposed by Stringhini et al. [8] when used in feature-based classifiers aimed at detecting fake followers. Here, we are looking for an efficient and lightweight classifier that uses the best features and the best rules, not only in terms of detection performance, but also in terms of their valuation costs. In particular, we can distinguish between the calculation costs and the creep costs required to evaluate a feature (or rule). Calculation costs can generally be reduced through optimized algorithms and data representations, and they are negligible compared to creep costs. Therefore, in this section, we focus on the latter: We quantify the creep costs of each feature and each rule, and we build a series of lightweight classifiers that enable the use of the most efficient features and the rules in the following sections:"}, {"heading": "6.1. Crawling cost analysis", "text": "Intuitively, some features require little data to compute, while others require downloading large amounts of data that we need to follow the followers. For the sake of this analysis, we divide the features into three categories: A) Profile: features that require information to be present in the profile of the followers of the target account (such as profile has names); B) Timeline: features that require the tweets in the timeline of the followers of the target account (such as tweets from the API); C) Relationship: features that require information about the accounts that are related (i.e., that are a friend, or a follower, or both) with the followers of the target account (such as bidirectional link ratio); each category that in turn belongs to a crawling cost class that is directly linked to the amount of data that Twitter is scratching. Starting from the list of followers, or a follower, or both, or the link of the target (such as the bidirectory)."}, {"heading": "6.2. The Class A classifier", "text": "All the rules and features taken into account in this study fall into one of the three categories listed above, as set out in Table 14. Therefore, their impact on the final cost of the entire functionality and, ultimately, on the class of the classifier is effective: A classifier using a particular feature belongs to the class of more expensive features. Then, we consider all classifiers of the previous sections to be Class B classifiers. We aim to verify that the classifier performs services comparable to those of the most expensive class B and Class C. [2] This belongs to Class C. We consider a lightweight classifier that works only with Class A characteristics. We aim to see whether the classifier performs services comparable to those of the most expensive class B and Class C. Table 16 reports the results of the classifiers building on our BAS datasets, with two distinct features: all features that include Class A and Class A characteristics."}, {"heading": "6.3. Validation of the Class A classifier", "text": "This year, it is only a matter of time before there is an agreement, until there is an agreement."}, {"heading": "6.4. Assessing the global importance of Class A features", "text": "Motivated by the results of our Class A classifiers, we proceeded to assess the global importance of Class A traits for detecting fake Twitter followers. In order to estimate the significance of each trait among all 8 classifiers, we followed the information-based sensitivity analysis used in [46]. Information fusion is a technique that aims to use the predictive power of several different models to achieve a combined predictive accuracy that is better than the predictions of each model. Rather, sensitivity analysis aims to assess the relative importance of the different traits used to build a classification model. Therefore, it is possible to combine information that estimates the global importance of several traits used in different machine classifiers in order to achieve a common classification."}, {"heading": "7. Conclusions", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "Acknowledgements", "text": "The authors thank the anonymous reviewers who have contributed to improving the quality of the manuscript."}], "references": [{"title": "Detecting social spam campaigns on Twitter", "author": ["Z. Chu", "I. Widjaja", "H. Wang"], "venue": "in: Applied Cryptography and Network Security, Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Empirical evaluation and new design for fighting evolving Twitter spammers", "author": ["C. Yang", "R. Harkreader", "G. Gu"], "venue": "Information Forensics and Security, IEEE Transactions on 8 (8) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "A generic statistical approach for spam detection in online social networks", "author": ["F. Ahmed", "M. Abulaish"], "venue": "Computer Communications 36 (10) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Twitter spammer detection using data stream clustering", "author": ["Z. Miller", "B. Dickinson", "W. Deitrick", "W. Hu", "A.H. Wang"], "venue": "Information Sciences 260 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Measuring user influence in Twitter: The million follower fallacy", "author": ["M. Cha", "H. Haddadi", "F. Benevenuto", "P.K. Gummadi"], "venue": "ICWSM 10 (10-17) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Information credibility on Twitter", "author": ["C. Castillo", "M. Mendoza", "B. Poblete"], "venue": "in: Proceedings of the 20th international conference on World Wide Web, ACM", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Detecting deception in online social networks", "author": ["J.S. Alowibdi", "U.A. Buy", "P.S. Yu", "L. Stenneth"], "venue": "in: Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Detecting spammers on social networks", "author": ["G. Stringhini", "C. Kruegel", "G. Vigna"], "venue": "in: 26th Annual Computer Security Applications Conference, ACSAC \u201910, ACM", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "The socialbot network: When bots socialize for fame and money", "author": ["Y. Boshmaf", "I. Muslukhov", "K. Beznosov", "M. Ripeanu"], "venue": "in: 27th Annual Computer Security Applications Conference, ACSAC \u201911, ACM, New York, NY, USA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Detecting automation of Twitter accounts: Are you a human", "author": ["Z. Chu", "S. Gianvecchio", "H. Wang", "S. Jajodia"], "venue": "bot, or cyborg?, IEEE Trans. Dependable Sec. Comput. 9 (6) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "digitalevaluations), Analysis of Twitter followers of the US Presidential Election candidates", "author": ["M. Camisani-Calzolari"], "venue": "Barack Obama and Mitt Romney (August", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "A Criticism to Society (as seen by Twitter analytics)", "author": ["S. Cresci", "R. Di Pietro", "M. Petrocchi", "A. Spognardi", "M. Tesconi"], "venue": "in: 1st International Workshop on Big Data Analytics for Security, IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards online spam filtering in social networks", "author": ["H. Gao", "Y. Chen", "K. Lee", "D. Palsetia", "A.N. Choudhary"], "venue": "in: 19th Annual Network and Distributed System Security Symposium, NDSS 2012, San Diego, California, USA, February 5-8, 2012", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "WarningBird: A near real-time detection system for suspicious URLs in Twitter stream", "author": ["S. Lee", "J. Kim"], "venue": "IEEE Trans. Dependable Secur. Comput. 10 (3) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Design and evaluation of a real-time URL spam filtering service", "author": ["K. Thomas", "C. Grier", "J. Ma", "V. Paxson", "D. Song"], "venue": "in: 32nd IEEE Symposium on Security and Privacy, S&P 2011, 22-25 May 2011, Berkeley, California, USA", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Tweet", "author": ["A. Zubiaga", "H. Ji"], "venue": "but verify: epistemic study of information verification on Twitter, Social Network Analysis and Mining 4 (1) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Spam ain\u2019t as diverse as it seems: Throttling OSN spam with templates underneath", "author": ["H. Gao", "Y. Yang", "K. Bu", "Y. Chen", "D. Downey", "K. Lee", "A. Choudhary"], "venue": "in: Annual Computer Security Applications Conference, ACSAC", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "SDHM: A hybrid model for spammer detection in Weibo", "author": ["Y. Liu", "B. Wu", "B. Wang", "G. Li"], "venue": "in: Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Data Mining: Practical Machine Learning Tools and Techniques", "author": ["M. Hall", "I. Witten", "E. Frank"], "venue": "3rd Edition, Morgan Kaufmann", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Early filtering of ephemeral malicious accounts on Twitter", "author": ["S. Lee", "J. Kim"], "venue": "Computer Communications 54 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Poultry markets: on the underground economy of Twitter followers", "author": ["G. Stringhini", "M. Egele", "C. Kruegel", "G. Vigna"], "venue": "in: Workshop on online social networks, WOSN \u201912, ACM", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Follow the Green: Growth and Dynamics in Twitter Follower Markets", "author": ["G. Stringhini", "G. Wang", "M. Egele", "C. Kruegel", "G. Vigna", "H. Zheng", "B.Y. Zhao"], "venue": "in: Internet Measurement Conference, IMC \u201913", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Trafficking fraudulent accounts: The role of the underground market in Twitter spam and abuse", "author": ["K. Thomas", "D. McCoy", "C. Grier", "A. Kolcz", "V. Paxson"], "venue": "in: 22nd USENIX Security Symposium, USENIX, Washington, D.C.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Uncovering social spammers: social honeypots + machine learning", "author": ["K. Lee", "J. Caverlee", "S. Webb"], "venue": "in: SIGIR Conference on Research and Development in Information Retrieval, ACM", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Peri-Watchdog: Hunting for hidden botnets in the periphery of online social networks", "author": ["G. Yan"], "venue": "Computer Networks 57 (2) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Spam detection on Twitter using traditional classifiers", "author": ["M. McCord", "M. Chuah"], "venue": "in: Autonomic and Trusted Computing, Vol. 6906 of LNCS, Springer Berlin Heidelberg", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Using communities against deception in online social networks", "author": ["S.Y. Bhat", "M. Abulaish"], "venue": "Computer Fraud & Security 2014 (2) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning when training data are costly: the effect of class distribution on tree induction", "author": ["G.M. Weiss", "F. Provost"], "venue": "Journal of Artificial Intelligence Research 19 ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2003}, {"title": "Glossary of terms", "author": ["R. Kohavi", "F. Provost"], "venue": "Machine Learning 30 (2-3) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1998}, {"title": "Assessing the accuracy of prediction algorithms for classification: an overview", "author": ["P. Baldi", "S. Brunak", "Y. Chauvin", "C. Andersen", "H. Nielsen"], "venue": "Bioinformatics 16 (5) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "Evaluation: from precision", "author": ["D.M.W. Powers"], "venue": "recall and F-measure to ROC, informedness, markedness and correlation, International Journal of Machine Learning Technologies 2 (1) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "The elements of statistical learning", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Vol. 1, Springer Series in Statistics", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Machine Learning", "author": ["T.M. Mitchell"], "venue": "1st Edition, McGraw-Hill, Inc., New York, NY, USA", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1997}, {"title": "Mathematical statistics and data analysis", "author": ["J. Rice"], "venue": "Cengage Learning", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2006}, {"title": "An introduction to variable and feature selection", "author": ["I. Guyon", "A. Elisseeff"], "venue": "The Journal of Machine Learning Research 3 ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2003}, {"title": "The WEKA data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD explorations newsletter 11 (1) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2009}, {"title": "LIBSVM: A library for Support Vector Machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST) 2 (3) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2011}, {"title": "The problem of overfitting", "author": ["D.M. Hawkins"], "venue": "Journal of chemical information and computer sciences 44 (1) ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2004}, {"title": "Developing an early warning system to predict currency crises", "author": ["C. Sevim", "A. Oztekin", "O. Bali", "S. Gumus", "E. Guresen"], "venue": "European Journal of Operational Research 237 (3) ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Composite forecasting: combining forecasts for improved accuracy", "author": ["C.W. Chase Jr"], "venue": "Journal of Business Forecasting Methods & Systems 19 (2) ", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2000}, {"title": "Making best use of model evaluations to compute sensitivity indices", "author": ["A. Saltelli"], "venue": "Computer Physics Communications 145 (2) ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 1, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 2, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 3, "context": "Academia has mostly focused its attention on spammers, those accounts actively putting their efforts in spreading malware, sending spam, and advertising activities of doubtful legality [1, 2, 3, 4].", "startOffset": 185, "endOffset": 197}, {"referenceID": 4, "context": "However, artificially inflating the number of followers can also be finalized to make an account more trustworthy and influential, in order to stand from the crowd and to attract other genuine followers [5].", "startOffset": 203, "endOffset": 206}, {"referenceID": 5, "context": "Similarly, if the practice of buying fake followers is adopted by malicious accounts, as spammers, it can act as a way to post more authoritative messages and launch more effective advertising campaigns [6].", "startOffset": 203, "endOffset": 206}, {"referenceID": 6, "context": "Quoting from [7], \u201cA fake Twitter account is considered as one form of deception (i.", "startOffset": 13, "endOffset": 16}, {"referenceID": 7, "context": "accounts that advertise unsolicited and often harmful content, containing links to malicious pages [8]), or bots (i.", "startOffset": 99, "endOffset": 102}, {"referenceID": 8, "context": ", computer programs that control social accounts, as stealthy as to mimic real users [9]), or cyborgs (i.", "startOffset": 85, "endOffset": 88}, {"referenceID": 9, "context": ", accounts that interweave characteristics of both manual and automated behavior [10]).", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "A series of reports published by the firm Digital evaluations [12] have attracted the attention of Italian and European newspapers and magazines, raising doubts on the Twitter popularity of politicians and leading international companies.", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "The results in [12], however, lack a validation phase.", "startOffset": 15, "endOffset": 19}, {"referenceID": 11, "context": "Moreover, as demonstrated in our previous work [16], these analyses are affected by several biases like small and statistically unsound sampling strategies.", "startOffset": 47, "endOffset": 51}, {"referenceID": 3, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 77, "endOffset": 87}, {"referenceID": 2, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 77, "endOffset": 87}, {"referenceID": 12, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 77, "endOffset": 87}, {"referenceID": 13, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 141, "endOffset": 145}, {"referenceID": 14, "context": "As an example, a branch of research focused on the textual content of tweets [4, 3, 17], studying the redirection of embedded URLs in tweets [18], and classifying the URLs landing pages [19].", "startOffset": 186, "endOffset": 190}, {"referenceID": 15, "context": "For instance, in [20] authors evaluate 4 epistemological features for the task of deception detection: authority, plausibility and support, independent corroboration, and presentation.", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "Work in [21] overcomes the limitation of not being able to correctly label those tweets without URLs as spam tweets, by proposing a composite tool, able to match incoming tweets with underlying templates commonly used by spammers.", "startOffset": 8, "endOffset": 12}, {"referenceID": 6, "context": "Instead of considering the content of tweets, work in [7] tries to classify if an account can be trusted or not based on possibly inconsistent information originating from the profile of the account only.", "startOffset": 54, "endOffset": 57}, {"referenceID": 7, "context": "Within this research line, we cite here [8], [2], and [22].", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "Within this research line, we cite here [8], [2], and [22].", "startOffset": 45, "endOffset": 48}, {"referenceID": 17, "context": "Within this research line, we cite here [8], [2], and [22].", "startOffset": 54, "endOffset": 58}, {"referenceID": 7, "context": "The work in [8] presents an analysis on how spammers operate on Facebook, Twitter, and MySpace, reporting that the suspicious accounts shared some common traits on specific features.", "startOffset": 12, "endOffset": 15}, {"referenceID": 18, "context": "Those served as input to a machine learning-based classifier [23] leading to the detection of more than 15,000 spam profiles, that Twitter promptly deleted.", "startOffset": 61, "endOffset": 65}, {"referenceID": 1, "context": "In [2], the authors propose a taxonomy of criteria for detecting Twitter spammers.", "startOffset": 3, "endOffset": 6}, {"referenceID": 17, "context": "In [22], the authors leverage a combination of behavioral features (such as tweeting and retweeting activities), network features (such as the number of an account\u2019s followers and friends), and content-based features to develop a hybrid mathematical model for spammer detection in Weibo, the Chinese microblogging site resembling Twitter.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "The authors of [10] classify Twitter accounts in three classes: humans, bot, and cyborgs.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "The algorithms proposed in [24, 4] aim at spotting groups of automated malicious Twitter accounts as quickly as possible, to avoid the accounts\u2019 owners from taking advantage of them.", "startOffset": 27, "endOffset": 34}, {"referenceID": 3, "context": "The algorithms proposed in [24, 4] aim at spotting groups of automated malicious Twitter accounts as quickly as possible, to avoid the accounts\u2019 owners from taking advantage of them.", "startOffset": 27, "endOffset": 34}, {"referenceID": 20, "context": "In [25], the authors list several criteria to detect clients and victims of Twitter account markets, that are", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In another work [26], the same research team provides more details about the account markets, analyzing additional properties and characteristics of their customers (e.", "startOffset": 16, "endOffset": 20}, {"referenceID": 22, "context": "The authors of [27] monitor prices, availability, and fraud perpetrated by a set of merchants of Twitter accounts over the course of a ten-months period.", "startOffset": 15, "endOffset": 19}, {"referenceID": 0, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 23, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 24, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 25, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 26, "context": "There are other works for spam detection, not detailed here, like [1, 28, 29, 30, 31, 32], which base their results on subsets, or on slightly modified versions, of criteria considered by the selected set of related work.", "startOffset": 66, "endOffset": 89}, {"referenceID": 7, "context": "From a technical point of view, in our experiments we rely on machine learning-based classifiers exploiting features of 1) profile, 2) activity, and 3) relationships of the accounts, similarly to [8, 2].", "startOffset": 196, "endOffset": 202}, {"referenceID": 1, "context": "From a technical point of view, in our experiments we rely on machine learning-based classifiers exploiting features of 1) profile, 2) activity, and 3) relationships of the accounts, similarly to [8, 2].", "startOffset": 196, "endOffset": 202}, {"referenceID": 12, "context": "Instead, we do not rely on features inherent to specific contents of tweets, such as the presence of URLs and the semantics of the text [17, 19].", "startOffset": 136, "endOffset": 144}, {"referenceID": 14, "context": "Instead, we do not rely on features inherent to specific contents of tweets, such as the presence of URLs and the semantics of the text [17, 19].", "startOffset": 136, "endOffset": 144}, {"referenceID": 21, "context": "Finally, similarly to [26], we bought fake Twitter followers from different markets available on the Web.", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "We conducted such an exercise independently from [26] and, moreover, goals of the two works are quite different, ours focusing on accounts sold by these markets, while the other targeting their customers.", "startOffset": 49, "endOffset": 53}, {"referenceID": 27, "context": "In particular, Weiss and Provost, in [34], considered the performances of decision-tree based classifiers to predict the samples of 26 different datasets, with different distributions between the minority and majority classes.", "startOffset": 37, "endOffset": 41}, {"referenceID": 27, "context": "To validate this assumption, we performed the experiments in [34] to our dataset.", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "These proposals were introduced in [12, 11, 14].", "startOffset": 35, "endOffset": 47}, {"referenceID": 10, "context": "Details on how aggregation has been performed are provided in [12] only.", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "Driven by the provided details, we implement the full algorithm described in [12] and we present its detection performances in Section 4.", "startOffset": 77, "endOffset": 81}, {"referenceID": 10, "context": "Camisani-Calzolari [12] carried out a series of tests over samples of Twitter followers of Romney and Obama, for the last US presidential elections, as well as for popular Italian politicians.", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "In [12] it is detailed an algorithm to evaluate an account based on some of its public features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "The meaning of each indicator is graphically highlighted by the matrix in Table 5 (called the confusion matrix ), where each column represents the instances in the predicted class, while each row represents the instances in the actual class [36]: In order to evaluate the application of each single rule to the accounts in", "startOffset": 241, "endOffset": 245}, {"referenceID": 29, "context": "\u2022 Matthew Correlation Coefficient (MCC from now on) [37]: the estimator of the correlation between the predicted class and the real class of the samples, defined as:", "startOffset": 52, "endOffset": 56}, {"referenceID": 30, "context": "Moreover, there are situations where some predictive models perform better than others, even having a lower accuracy [38].", "startOffset": 117, "endOffset": 121}, {"referenceID": 30, "context": "Furthermore, MCC is considered the unbiased version of the F-Measure, since it uses all the four elements of the confusion matrix [38].", "startOffset": 130, "endOffset": 134}, {"referenceID": 31, "context": "For completeness, when available, we also report the area-under-the-curve metric (AUC ), that is the area under the Receiver Operating Characteristic (ROC) curve [39].", "startOffset": 162, "endOffset": 166}, {"referenceID": 32, "context": "It can be informally defined as the expected reduction in entropy caused by the knowledge of the value of a given attribute [40].", "startOffset": 124, "endOffset": 128}, {"referenceID": 10, "context": "Table 7: Evaluation of Camisani-Calzolari algorithm (CC algorithm) [12].", "startOffset": 67, "endOffset": 71}, {"referenceID": 33, "context": "tionship between two random variables X and Y [41, 42].", "startOffset": 46, "endOffset": 54}, {"referenceID": 34, "context": "tionship between two random variables X and Y [41, 42].", "startOffset": 46, "endOffset": 54}, {"referenceID": 10, "context": "The detection algorithm in [12] aggregates the 22 criteria for identifying human and bot behavior, introduced in Section 4.", "startOffset": 27, "endOffset": 31}, {"referenceID": 10, "context": "Camisani-Calzolari [12] (satisfaction of rules means human behavior) 1 profile has name 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 33, "context": "This is clearly not linearly dependent on the class values, resulting in lower values for the Pcc* with respect to the Pcc [41].", "startOffset": 123, "endOffset": 127}, {"referenceID": 10, "context": "Thus, we can derive that the rule is based on a right assumption (for example, the use of hashtags), but the rule definition is too simple to be effective: the algorithm proposed by [12] is simply too naive for the complex task of fake accounts detection in Twitter.", "startOffset": 182, "endOffset": 186}, {"referenceID": 7, "context": "In this section, we examine works in [8, 2] that address spam account detection on Twitter.", "startOffset": 37, "endOffset": 43}, {"referenceID": 1, "context": "In this section, we examine works in [8, 2] that address spam account detection on Twitter.", "startOffset": 37, "endOffset": 43}, {"referenceID": 31, "context": "In \u201cglassbox\u201d models, such as Decision Trees and Regression Models, the inner structure of the models can be understood by humans, also providing insights on how the classifiers identify fake accounts [39].", "startOffset": 201, "endOffset": 205}, {"referenceID": 7, "context": "The study presented in [8] focuses on spambot detection.", "startOffset": 23, "endOffset": 26}, {"referenceID": 18, "context": "For each investigated account, such characteristics are exploited in a Random Forest algorithm [23, 43], that outputs if the account is a spambot or not.", "startOffset": 95, "endOffset": 103}, {"referenceID": 35, "context": "For each investigated account, such characteristics are exploited in a Random Forest algorithm [23, 43], that outputs if the account is a spambot or not.", "startOffset": 95, "endOffset": 103}, {"referenceID": 7, "context": "The results of the analysis in [8] depicted some interesting features of the spambot accounts under investigation, as reported in Table 9.", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "This notion has been given in a later work by the same authors [25].", "startOffset": 63, "endOffset": 67}, {"referenceID": 1, "context": "The authors of [2] observed that Twitter spammers often modify their behavior in order to evade existing spam detection techniques.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "In Table 10 we detail nine of them, together with the outcome of their analysis in [2].", "startOffset": 83, "endOffset": 86}, {"referenceID": 23, "context": "age of the account (this feature also appears in [28]): the more an account is aged, the more it could be considered a good one; 6.", "startOffset": 49, "endOffset": 53}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "The authors of [2] combine their features in four different machine learning classifiers and compare their implementation with other existing approaches.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "We were unable to completely reproduce the machine learning classifiers in [2], since we had a different dataset.", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "As in [2], the following rate (feature 9) has been approximated with the ratio friends/age, since a precise evaluation would require to know the evolution of the number of friends of an account, but this is, indeed, publicly unavailable.", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "Finally, in [2] there are also other features in addition to those mentioned above.", "startOffset": 12, "endOffset": 15}, {"referenceID": 7, "context": "[8] 1 number of friends 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] 1 age 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 36, "context": "Our SVM classifier exploits a Radial Basis Function (RBF) kernel and has been trained using libSVM as the machine learning algorithm [44].", "startOffset": 133, "endOffset": 137}, {"referenceID": 35, "context": "All the classifiers and the optimization algorithms employed in this work are implemented within the Weka framework [43].", "startOffset": 116, "endOffset": 120}, {"referenceID": 7, "context": "Among these algorithms, RF was the only one used in [8].", "startOffset": 52, "endOffset": 55}, {"referenceID": 1, "context": "Instead, authors of [2] employed D, RF, J48 and BN.", "startOffset": 20, "endOffset": 23}, {"referenceID": 31, "context": "We have decided to include AB in our work, since it is considered one of the most effective machine learning algorithms for classification tasks [39].", "startOffset": 145, "endOffset": 149}, {"referenceID": 1, "context": "[2] RF Random Forest 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] RF Random Forest 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "Then, we have used a 10-fold cross validation [23] to estimate the performances of each obtained classifier.", "startOffset": 46, "endOffset": 50}, {"referenceID": 1, "context": "The ones built over the feature set of [2] achieve slightly better results.", "startOffset": 39, "endOffset": 42}, {"referenceID": 1, "context": "In addition, all the classifiers based on the feature set by [2] have a higher AUC, when compared with the ones built with the feature set by [8].", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "In addition, all the classifiers based on the feature set by [2] have a higher AUC, when compared with the ones built with the feature set by [8].", "startOffset": 142, "endOffset": 145}, {"referenceID": 1, "context": "[2] show that the features of Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] exhibit the tendency to consider as fake followers some human accounts.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "With both the [2] and [8] feature sets, BN, kNN and LR classifiers achieve, overall, worse performances.", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "With both the [2] and [8] feature sets, BN, kNN and LR classifiers achieve, overall, worse performances.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": "The SVM classifier, instead, achieves remarkable results, especially with the feature set of [2].", "startOffset": 93, "endOffset": 96}, {"referenceID": 7, "context": "Looking at the tree structure, we observe some interesting differences between the fake followers in our BAS dataset and the spam accounts characterized in [8] and [2].", "startOffset": 156, "endOffset": 159}, {"referenceID": 1, "context": "Looking at the tree structure, we observe some interesting differences between the fake followers in our BAS dataset and the spam accounts characterized in [8] and [2].", "startOffset": 164, "endOffset": 167}, {"referenceID": 7, "context": "For example, the feature URL ratio has been found to have a higher value for spammers than for legitimate users, as highlighted in [8] (Section 5.", "startOffset": 131, "endOffset": 134}, {"referenceID": 1, "context": "Similarly, the API ratio feature has been found higher for spammers than for legitimate accounts ([2], see also Section 5.", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "A similar behavior has been observed for the average neighbor\u2019s tweets feature, that has been found to be lower for spammers in [2], but higher for our fake followers.", "startOffset": 128, "endOffset": 131}, {"referenceID": 37, "context": "It is well known that trained classifiers can be subject to \u201coverfitting\u201d, namely the problem of being too specialized on the training dataset and unable to generalize the classification to new and unseen data [45].", "startOffset": 210, "endOffset": 214}, {"referenceID": 7, "context": "[8] has 22 leaves, 43 nodes, and a height of 7, whereas the best feature is the friends/(followers\u02c62) ratio that places at the root.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] has 17 leaves, 33 nodes and a height of 8, with the bi-directional link ratio as the root.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] subtree raising 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] subtree raising 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], without the bi-link ratio feature subtree raising 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": ", by using the reduce-error pruning with small test sets [23, 43].", "startOffset": 57, "endOffset": 65}, {"referenceID": 35, "context": ", by using the reduce-error pruning with small test sets [23, 43].", "startOffset": 57, "endOffset": 65}, {"referenceID": 1, "context": "[2], reducing the number of nodes from 33 to 11 decreases the accuracy of 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] reduces its recall of 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] only drops of 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "95 (as in the last lines of Table 13, for [8] and [2], respectively).", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "95 (as in the last lines of Table 13, for [8] and [2], respectively).", "startOffset": 50, "endOffset": 53}, {"referenceID": 1, "context": "[2], and the friends/(followers\u02c62), URL ratio, and number of friends as the subset for the Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] original feature set.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and compare its effectiveness against the classifier built with the complete set.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Camisani-Calzolari [12] has name, has image, has address, has biography, followers \u2265 30, belongs to a list, tweets \u2265 50, URL in profile, 2 \u00d7 followers \u2265 friends geo-localized, is favorite, uses punctuation, uses hashtag, uses iPhone, uses Android, uses Foursquare, uses Instagram, uses Twitter.", "startOffset": 19, "endOffset": 23}, {"referenceID": 7, "context": "[8] number of friends, number of tweets, friends (followers\u02c62) tweet similarity, URL ratio", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] age, following rate API ratio, API URL ratio, API tweet similarity bi-link ratio, average neighbors\u2019 followers, average neighbors\u2019 tweets, followings to median neighbor\u2019s followers", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] seems to be slightly more effective than the one proposed by Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8], when used in feature-based classifiers aiming at fake followers detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], that belongs to Class C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and Stringhini et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8], as reported in Table 12.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "We have to point out, however, that countermeasures could be taken to evade some of the simplest features our classifiers are built upon [2].", "startOffset": 137, "endOffset": 140}, {"referenceID": 21, "context": "All the accounts acquired with the two aforementioned approaches have been labeled as humans, following the same approach used in [26].", "startOffset": 130, "endOffset": 134}, {"referenceID": 38, "context": "In order to estimate the importance of the single features among all the 8 classifiers, we followed the information fusion-based sensitivity analysis technique adopted in [46].", "startOffset": 171, "endOffset": 175}, {"referenceID": 39, "context": "Information fusion is a technique aimed at leveraging the predictive power of several different models in order to achieve a combined prediction accuracy which is better than the predictions of the single models [47].", "startOffset": 212, "endOffset": 216}, {"referenceID": 40, "context": "Sensitivity analysis, instead, aims at assessing the relative importance of the different features used to build a classification model [48].", "startOffset": 136, "endOffset": 140}, {"referenceID": 7, "context": "1 friends/(followers\u02c62) ratio [8] 1.", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 23, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 3, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 0, "context": "000 2 age [2, 28, 4, 1] 0.", "startOffset": 10, "endOffset": 23}, {"referenceID": 0, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 3, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 7, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 10, "context": "919 3 number of tweets [1, 4, 8, 12, 14] 0.", "startOffset": 23, "endOffset": 40}, {"referenceID": 10, "context": "816 4 profile has name [12] 0.", "startOffset": 23, "endOffset": 27}, {"referenceID": 26, "context": "782 5 number of friends [32, 8, 14, 4] 0.", "startOffset": 24, "endOffset": 38}, {"referenceID": 7, "context": "782 5 number of friends [32, 8, 14, 4] 0.", "startOffset": 24, "endOffset": 38}, {"referenceID": 3, "context": "782 5 number of friends [32, 8, 14, 4] 0.", "startOffset": 24, "endOffset": 38}, {"referenceID": 10, "context": "781 6 has URL in profile [12] 0.", "startOffset": 25, "endOffset": 29}, {"referenceID": 1, "context": "768 7 following rate [2] 0.", "startOffset": 21, "endOffset": 24}, {"referenceID": 10, "context": "755 9 belongs to a list [12] 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "752 10 profile has image [12] 0.", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "707 16 has address [12] 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "664 18 has biography [12] 0.", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "602 19 number of followers [12, 4, 3] 0.", "startOffset": 27, "endOffset": 37}, {"referenceID": 3, "context": "602 19 number of followers [12, 4, 3] 0.", "startOffset": 27, "endOffset": 37}, {"referenceID": 2, "context": "602 19 number of followers [12, 4, 3] 0.", "startOffset": 27, "endOffset": 37}], "year": 2017, "abstractText": "Fake followers are those Twitter accounts specifically created to inflate the number of followers of a target account. Fake followers are dangerous for the social platform and beyond, since they may alter concepts like popularity and influence in the Twittersphere\u2014hence impacting on economy, politics, and society. In this paper, we contribute along different dimensions. First, we review some of the most relevant existing features and rules (proposed by Academia and Media) for anomalous Twitter accounts detection. Second, we create a baseline dataset of verified human and fake follower accounts. Such baseline dataset is publicly available to the scientific community. Then, we exploit the baseline dataset to train a set of machine-learning classifiers built over the reviewed rules and features. Our results show that most of the rules proposed by Media provide unsatisfactory performance in revealing fake followers, while features proposed in the past by Academia for spam detection provide good results. Building on the most promising features, we revise the classifiers both in terms of reduction of overfitting and cost for gathering the data needed to compute the features. The final result is a novel Class A classifier, general enough to thwart overfitting, lightweight thanks to the usage of the less costly features, and still able to correctly classify more than 95% of the accounts of the original training set. We ultimately perform an information fusion-based sensitivity analysis, to assess the global sensitivity of each of the features employed by the classifier. The findings reported in this paper, other than being supported by a thorough experimental methodology and interesting on their own, also pave the way for further investigation on the novel issue of fake Twitter followers.", "creator": "LaTeX with hyperref package"}}}