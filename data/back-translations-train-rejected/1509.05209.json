{"id": "1509.05209", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Sep-2015", "title": "Extraction of evidence tables from abstracts of randomized clinical trials using a maximum entropy classifier and global constraints", "abstract": "Systematic use of the published results of randomized clinical trials is increasingly important in evidence-based medicine. In order to collate and analyze the results from potentially numerous trials, evidence tables are used to represent trials concerning a set of interventions of interest. An evidence table has columns for the patient group, for each of the interventions being compared, for the criterion for the comparison (e.g. proportion who survived after 5 years from treatment), and for each of the results. Currently, it is a labour-intensive activity to read each published paper and extract the information for each field in an evidence table. There have been some NLP studies investigating how some of the features from papers can be extracted, or at least the relevant sentences identified. However, there is a lack of an NLP system for the systematic extraction of each item of information required for an evidence table. We address this need by a combination of a maximum entropy classifier, and integer linear programming. We use the later to handle constraints on what is an acceptable classification of the features to be extracted. With experimental results, we demonstrate substantial advantages in using global constraints (such as the features describing the patient group, and the interventions, must occur before the features describing the results of the comparison).", "histories": [["v1", "Thu, 17 Sep 2015 11:20:35 GMT  (25kb)", "http://arxiv.org/abs/1509.05209v1", "27 pages, 10 tables"]], "COMMENTS": "27 pages, 10 tables", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["antonio trenta", "anthony hunter", "sebastian riedel"], "accepted": false, "id": "1509.05209"}, "pdf": {"name": "1509.05209.pdf", "metadata": {"source": "CRF", "title": "Extraction of evidence tables from abstracts of randomized clinical trials using a maximum entropy classifier and global constraints", "authors": ["Antonio Trenta", "Anthony Hunter"], "emails": ["anthony.hunter@ucl.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 150 9.05 209v 1 [cs.C LKeywords: Information Extraction; Machine Reading of Medical Information; Automatic Analysis of Clinical Evidence; Mining Medical Literature; Randomized Clinical Trials; Automatic Compilation of Evidence Tables; Evidence-Based Medicine. \u2022 Corresponding Author Email: anthony.hunter @ ucl.ac.uk12"}, {"heading": "1 Introduction", "text": "The systematic use of evidence is already well established in healthcare in the form of evidence-based decision-making [1]. Much of this evidence is published in the form of randomized clinical trials (RCTs), which are published as articles in medical journals [2]. Unfortunately, the rapidly growing number of published RCTs on a topic means that it is difficult for a physician or biomedical researcher to collect and assimilate this evidence effectively and efficiently."}, {"heading": "1.1 State of the art", "text": "Searching for relevant RCTs involves retrieval techniques applied to the free text and indexing of the RCTs through information providers such as PubMed, Medline, etc. Each of the retrieved RCTs must then be read to extract information about the patient class, the interventions are then compared in the study, the results are then considered labor-intensive activity, and the information for each field extracted in an evidence table. Although many annotation software tools have been developed, it is still very expensive and time consuming to populate an evidence table."}, {"heading": "1.2 Overview of our approach", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "2 Methods", "text": "In this section, we explain how we obtained our training and test data from PubMed and how we commented on this dataset, which covered interventions in glaucoma and ocular hypertension."}, {"heading": "2.1 Data Collection", "text": "The results of this study were presented in varying degrees, most of which were able to identify themselves."}, {"heading": "2.2 Preprocessing", "text": "This year it has come to the point where it is a purely reactionary project, which is a purely reactionary project, which is a reactionary project."}, {"heading": "2.3 System Overview", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country."}, {"heading": "3 Results and discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Evaluation", "text": "The performance of the system (full model) has been tested against two baseline models (vanilla and zero models).The vanilla model is a rudimentary version of the full model. It still includes the basic maximum entropy classifier, but in the inference phase it deals with a simpler ILP problem that does not take into account most of the constraints introduced in the previous paragraph.This model simply points the correct label to the label that is most likely to be in this class in abstraction, in other words, it does not take into account the sequential and positioning constraints of the complete model. Instead, the maximum entropy classifier is identical to the full model with which the same characteristics are also to be (token, chunk, set, paragraph and conjunction characteristics).The zero model is in terms of the sequential and positioning constraints of the full model."}, {"heading": "3.2 Results", "text": "In fact, most of them will be able to orient themselves in a different direction than in a different direction, namely the direction in which they have been moving."}, {"heading": "4 Conclusion and future work", "text": "This year it is more than ever before."}, {"heading": "5 Acknowledgments", "text": "The authors thank Zi Wei Liu and Matthew Williams for their feedback on the clinical aspects of this work and the anonymous speakers for a number of valuable suggestions to improve the work."}, {"heading": "Appendix A", "text": "Glaucoma: (clinical trial \"[publication type]) AND (glaucoma [title / abstract]) AND (randomised or randomised or double masked [title / abstract]) NOT (\" protocol \"or\" non-randomised \"[title / abstract]) Prescription drugs: (mitomycin [title] or brimonidine [title] OR brinzolamide [title] ORdorzolamide [title] OR carteolol [title] OR betaxolol [title] OR fluorouracil [title] OR latanoprost [title] OR bimatoprost [title] OR travoprost [title] OR travoprost [title] ORtimolol [title] AND (randomised [title] OR randomised [title] OR randomised [title] OR randomised [title] AND (\" glaucoma] [MeSH-term] glaucoma [title] All titles Glaucoma]"}, {"heading": "Appendix B", "text": "To formalize the ILP problem, we introduce a series of decision variables X = [x0, x1,..., xN] where N is the number of candidate markers in the summary, each xi being equal to [xi, A1, xi, A2, xi, R1, xi, R2] and xi being equal when the token is assigned to i, and otherwise zero. The following auxiliary variables are introduced: \u2022 z [0, N], L = {P, A1, A2, OC, R1, R2, O} to represent the position of the label in the summary, isz = N = 1xi, i L \u2022 dA, and dR to represent positions A1-A2 and R1-R2."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Systematic use of the published results of randomized clinical trials is<lb>increasingly important in evidence-based medicine. In order to collate and<lb>analyze the results from potentially numerous trials, evidence tables are<lb>used to represent trials concerning a set of interventions of interest. An<lb>evidence table has columns for the patient group, for each of the interven-<lb>tions being compared, for the criterion for the comparison (e.g. proportion<lb>who survived after 5 years from treatment), and for each of the results.<lb>Currently, it is a labour-intensive activity to read each published paper<lb>and extract the information for each field in an evidence table. There have<lb>been some NLP studies investigating how some of the features from papers<lb>can be extracted, or at least the relevant sentences identified. However,<lb>there is a lack of an NLP system for the systematic extraction of each item<lb>of information required for an evidence table. We address this need by a<lb>combination of a maximum entropy classifier, and integer linear program-<lb>ming. We use the later to handle constraints on what is an acceptable<lb>classification of the features to be extracted. With experimental results,<lb>we demonstrate substantial advantages in using global constraints (such<lb>as the features describing the patient group, and the interventions, must<lb>occur before the features describing the results of the comparison).", "creator": "LaTeX with hyperref package"}}}