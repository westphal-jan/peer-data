{"id": "1509.05636", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2015", "title": "Visual Generalized Coordinates", "abstract": "An open problem in robotics is that of using vision to identify a robot's own body and the world around it. Many models attempt to recover the traditional C-space parameters. Instead, we propose an alternative C-space by deriving generalized coordinates from $n$ images of the robot. We show that the space of such images is bijective to the motion space, so these images lie on a manifold $\\mathcal{V}$ homeomorphic to the canonical C-space. We now approximate this manifold as a set of $n$ neighbourhood tangent spaces that result in a graph, which we call the Visual Roadmap (VRM). Given a new robot image, we perform inverse kinematics visually by interpolating between nearby images in the image space. Obstacles are projected onto the VRM in $O(n)$ time by superimposition of images, leading to the identification of collision poses. The edges joining the free nodes can now be checked with a visual local planner, and free-space motions computed in $O(nlogn)$ time. This enables us to plan paths in the image space for a robot manipulator with unknown link geometries, DOF, kinematics, obstacles, and camera pose. We sketch the proofs for the main theoretical ideas, identify the assumptions, and demonstrate the approach for both articulated and mobile robots. We also investigate the feasibility of the process by investigating various metrics and image sampling densities, and demonstrate it on simulated and real robots.", "histories": [["v1", "Fri, 18 Sep 2015 14:17:57 GMT  (4099kb,D)", "http://arxiv.org/abs/1509.05636v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["m seetha ramaiah", "amitabha mukerjee", "arindam chakraborty", "sadbodh sharma"], "accepted": false, "id": "1509.05636"}, "pdf": {"name": "1509.05636.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["M Seetha Ramaiah", "Amitabha Mukerjee", "Arindam Chakraborty", "Sadbodh Sharma"], "emails": ["sadbodh}@iitk.ac.in"], "sections": [{"heading": null, "text": "It is only a matter of time before such an approach is adopted, which allows a robot to work in less controlled environments, as is increasingly demanded in social and interactive applications for robots. There are two ways to approach this problem - either by learning a body scheme [4], or by adapting a canonical robot model. Body approaches do not have scaled robotic models used for global motion planning, and robot model regression requires intrusive structures on the robot [11], and even then it cannot perceive the surroundings."}, {"heading": "II. ALGORITHM OVERVIEW AND INVERSE KINEMATICS", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "C. Difficulties with Manifold discovery algorithms", "text": "For robots that incorporate movement with an S1 topology, the C-space and thus the VRM-space is not globally euclidean. For example, the C-space of a freely rotating 2-DOF articulated robot S1 \u00b7 S1 = T2, i.e. a torus [20]. Traditional nonlinear dimension reduction algorithms (e.g. [2]) assume that the target space for dimension reduction is a euclidean space (a sub-space of Rn). This means that a d-torus manifold, which is dimensional, cannot be mapped globally to a Rd-space, with which it is locally homomorphic. Another practical difficulty with NLDR algorithms is that it is very difficult to add to the manifold new points, without recalculating the entire structure, uniform and uniform, and uniform, and uniform, and uniform, and uniform, and uniform, and uniform, and uniform, and non-linear coordinates are little more than a convenience and not materially uniform, and the graphics, which result from the angle,"}, {"heading": "D. Collision Detection in VCS", "text": "In imaging, robots and obstacle are assigned to a beam of beams that approach the optical center of the camera (Figure 4).Let CRi be the bundle subtended at camera optical center CO by the robot in configuration q (i), CA be the bundle subtended at CO by the obstacle A and IRi, IA be the image regions corresponding to the robot and the obstacle.Lemma 2. If CRi \u00b2 C = \u2205 A (i) =.So, robot configurations for which the beams do not overlap with the obstacle, the image regions are guaranteed to be in free space F. Note that the conversation is not true.Lemma 3 CA \u00b2 C R = \u2205 iff IA I R =.Theorem 2. (Visual Collision Theorem) For a robot in a given position q (i), if IRi (i).We note that the above is not."}, {"heading": "B. Local Planner in VRM", "text": "We say that an edge (u, v) of G is safe if the geodetic path from u to v is manifold in the configuration (v). Geodesy is due to the shortest path on G. Since nodes V are in free space, we must guarantee that each edge is also safe. We describe three local planners who work with robotic images and can be used on visual maps. To ensure that an edge is safe, these methods construct a new image that includes in estimates the volume of the robot in the workspace and check this image for collision. Figure 6 shows examples of images generated by these local planners."}, {"heading": "C. Start and Goal states", "text": "To plan motion on the VRM, we must map the source (s) and target (t) of the images on the VRM G. We first make sure that the poses, t themselves are in free space, then add them to G and connect them to their nearest k neighbors in X. Then we run a local planner on the new edges and, as before, find the shortest path between s and t. Adding a new node (image) to the graph is a calculation that requires O (nk) distance calculation steps to find them. Time for the distance calculation depends on the metric used. Again, this approach is almost identical to traditional roadmap methods [20], except that the tests are all visual."}, {"heading": "V. EMPIRICAL ANALYSIS : METRICS AND LOCAL PLANNERS", "text": "Factors influencing the path quality in the VRM include the sample density, the metric used and the local planner. We are now presenting an empirical study on these aspects (Fig. 7) on a planar 3-Link simulation arm and a number of similar obstacles as in Fig. 6."}, {"heading": "A. Gold Standard Local Planner", "text": "In the traditional configuration space, we assume that two configurations are connected by a linear link. To see if an edge (u, v) is actually safe, we create intermediate images by interpolating joint angle vectors with a resolution. We observe that a linear interpolation in the joint angle space does not have to be the same as an interpolation in the visual C space, but we assume that the difference for a reasonable sample density would be relatively small. If all these images are collision-free, we treat (u, v) as safe. The performance of the local planners is evaluated relative to this gold standard local planner."}, {"heading": "B. Effect of Sampling Density and Distance Metric", "text": "In our experiments, we used 30,000 (100x100x3) dimensional vectors for image spacing. Random projections (RP [22], [23]) is a method for dimensionality reduction that preserves L2 spacing. In our experiments, we projected 30,000 (100x100x3) dimensional vectors for image spacing. Random projections (RP [22], [23]) is a method for dimensionality reduction that preserves L2 spacing."}, {"heading": "VI. DEMONSTRATIONS ON REAL ROBOTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Planar Scara robot", "text": "We now demonstrate the algorithm of a real robot, a Scara 4 DOF arm, in which two swivels move the first two links in a plane so that the movement has two degrees of freedom. We observe this robot with an overhead camera. 4000 images are scanned from a video as the robot moves through its working area between random poses, and the neighbourhood diagram is calculated. Afterwards, several obstacles are introduced into the working space and the obstacles are detected by subtraction in the background."}, {"heading": "B. CRS A465 robot arm", "text": "Here we are dealing with a robot in a 3-D working area. To detect collision situations, a single camera angle is clearly not enough. So we construct a common multitude of views by stitching the corresponding images together and constructing a common diversity in the combined image area. Fig. 9 shows the 3-DOF working area and a path, with the obstacle nodes marked in black."}, {"heading": "VII. CONCLUSION", "text": "In this work, we have introduced a new approach to the long-standing perception of the problem of robotics, which includes the problem of learning bodies [4], [5], [7]. Although it has long been known that there are many types of generalized coordinates, so far there have been few attempts to rely on this intuition. Paradise proposed attempts to develop such a non-traditional GC, and approaches the C-space resulting from the set of images. We show what such a formulation is like for tasks such as inverse kinematics or the movement of planners."}], "references": [{"title": "A global geometric framework for nonlinear dimensionality reduction", "author": ["J.B. Tenenbaum", "V. de Silva", "J.C. Langford"], "venue": "Science, vol. 290, no. 5500, pp. 2319\u20132323, 2000.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Engelberger, Robotics in practice: management and applications of industrial robots", "author": ["F. J"], "venue": "Kogan Page,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1980}, {"title": "L\u2019espace et la geometrie", "author": ["H. Poincare"], "venue": "Science and Hypothesis, 1895, pp. 60\u201371, transl. W. J. Greenstreet, 1905.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1895}, {"title": "Body schema in robotics: a review", "author": ["M. Hoffmann", "H.G. Marques", "A. Hernandez Arieta", "H. Sumioka", "M. Lungarella", "R. Pfeifer"], "venue": "Autonomous Mental Development, IEEE Transactions on, vol. 2, no. 4, pp. 304\u2013324, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Map learning with uninterpreted sensors and effectors", "author": ["D. Pierce", "B. Kuipers"], "venue": "Artificial Intelligence, vol. 92, pp. 169\u2013229, 1997.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1997}, {"title": "Perception of the structure of the physical world using unknown multimodal sensors and effectors", "author": ["D. Philipona", "J. O\u2019Regan", "J. Nadal", "O. Coenen"], "venue": "Advances in neural information processing systems, vol. 16, 2003.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Cognitive navigation based on nonuniform gabor space sampling, unsupervised growing networks, and reinforcement learning", "author": ["A. Arleo", "F. Smeraldi", "W. Gerstner"], "venue": "Neural Networks, IEEE Transactions on, vol. 15, no. 3, pp. 639\u2013652, 2004.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Sensor map discovery for developing robots", "author": ["J. Stober", "L. Fishgold", "B. Kuipers"], "venue": "AAAI Fall Symposium on Manifold Learning and Its Applications, 2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "On-line regression algorithms for learning mechanical models of robots: a survey", "author": ["O. Sigaud", "C. Sala\u00fcn", "V. Padois"], "venue": "Robotics and Autonomous Systems, vol. 59, no. 12, pp. 1115\u20131129, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Approaches to Probabilistic Model Learning for Mobile Manipulation Robots", "author": ["J. Sturm"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Path-planning for visual servoing: a review and issues", "author": ["M. Kazemi", "K. Gupta", "M. Mehrandezh"], "venue": "Visual Servoing via Advanced Numerical Methods, 2010, pp. 189\u2013207.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "An action perspective on motor development", "author": ["C. Von Hofsten"], "venue": "Trends in cognitive sciences, vol. 8, no. 6, pp. 266\u2013272, 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Motor development", "author": ["K. Adolph", "S. Berger"], "venue": "Handbook of child psychology, 2006.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Imagination and abstraction of sensorimotor flow: Towards a robot model", "author": ["J. Stening", "H. Jacobsson", "T. Ziemke"], "venue": "Proceedings of the AISB05 Symposium on Next Generation approaches to Machine Consciousness: Imagination, Development, Intersubjectivity, and Embodiment, 2005, pp. 50\u201358.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Probabilistic roadmaps for path planning in high-dimensional configuration spaces", "author": ["L.E. Kavraki", "P. \u0160vestka", "J.-C. Latombe", "M.H. Overmars"], "venue": "Robotics and Automation, IEEE Transactions on, vol. 12, no. 4, pp. 566\u2013580, 1996.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1996}, {"title": "Dimension reduction by local principal component analysis", "author": ["N. Kambhatla", "T.K. Leen"], "venue": "Neural Computation, vol. 9, no. 7, pp. 1493\u2013 1516, 1997.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "A better scaled local tangent space alignment algorithm", "author": ["J. Yang", "F. Li", "J. Wang"], "venue": "Neural Networks, 2005. IJCNN\u201905. Proceedings. 2005 IEEE International Joint Conference on, vol. 2, 2005, pp. 1006\u2013 1011.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Principles of Robot Motion: Theory, Algorithms, and Implementations", "author": ["H. Choset", "K.M. Lynch", "S. Hutchinson", "G.A. Kantor", "W. Burgard", "L.E. Kavraki", "S. Thrun"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Good features to track", "author": ["J. Shi", "C. Tomasi"], "venue": "1994 IEEE Conference on Computer Vision and Pattern Recognition (CVPR\u201994), 1994, pp. 593 \u2013 600.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1994}, {"title": "Random projection in dimensionality reduction: applications to image and text data", "author": ["E. Bingham", "H. Mannila"], "venue": "Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2001, pp. 245\u2013250.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Experiments with random projection", "author": ["S. Dasgupta"], "venue": "Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 2000, pp. 143\u2013151.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 1, "context": "see [3] ch.", "startOffset": 4, "endOffset": 7}, {"referenceID": 2, "context": "There have been two methods for approaching this problem - either based on learning a body schema [4]\u2013[9], or by fitting a canonical robot model [10].", "startOffset": 98, "endOffset": 101}, {"referenceID": 7, "context": "There have been two methods for approaching this problem - either based on learning a body schema [4]\u2013[9], or by fitting a canonical robot model [10].", "startOffset": 102, "endOffset": 105}, {"referenceID": 8, "context": "There have been two methods for approaching this problem - either based on learning a body schema [4]\u2013[9], or by fitting a canonical robot model [10].", "startOffset": 145, "endOffset": 149}, {"referenceID": 9, "context": "Body schema approaches have not scaled up to full scale robotic models or used for global motion planning, and robot model regression requires intrusive structures on the robot [11] and even then", "startOffset": 177, "endOffset": 181}, {"referenceID": 0, "context": "(d) The image manifold V , visualized here in R using the Isomap algorithm [2], shows that the robot images - from a 570\u00d7570-dimensional image space - lie on the 2-D surface of a torus.", "startOffset": 75, "endOffset": 78}, {"referenceID": 10, "context": "posed by stitching together local visual servos [12], but these require that the goal be constantly visible.", "startOffset": 48, "endOffset": 52}, {"referenceID": 11, "context": "In fact, this idea draws inspiration from proposals for how an infant learns to use its limbs [13], [14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "In fact, this idea draws inspiration from proposals for how an infant learns to use its limbs [13], [14].", "startOffset": 100, "endOffset": 104}, {"referenceID": 13, "context": "One could then \u201cimagine\u201d the consequence of a motor command, and compare these quickly to find discrepancies [15].", "startOffset": 109, "endOffset": 113}, {"referenceID": 14, "context": "This can often be effectively approximated by the maximum distance covered by any point [17].", "startOffset": 88, "endOffset": 92}, {"referenceID": 15, "context": "Image space neighbourhoods are then used to construct a local-PCA based nonlinear manifold [18].", "startOffset": 91, "endOffset": 95}, {"referenceID": 0, "context": "Isomap [2]).", "startOffset": 7, "endOffset": 10}, {"referenceID": 15, "context": "However, such methods have difficulty in introducing new data points and in interpolating local data, so we avoid computing the manifold altogether, and restrict ourselves to a piecewise algorithm, as in [18], [19].", "startOffset": 204, "endOffset": 208}, {"referenceID": 16, "context": "However, such methods have difficulty in introducing new data points and in interpolating local data, so we avoid computing the manifold altogether, and restrict ourselves to a piecewise algorithm, as in [18], [19].", "startOffset": 210, "endOffset": 214}, {"referenceID": 17, "context": "For example, the C-space of a freely-rotating 2-DOF articulated robot is S \u00d7 S = T, which is a torus [20].", "startOffset": 101, "endOffset": 105}, {"referenceID": 0, "context": "[2]) assume that the target space for dimensionality reduction is a euclidean space (a subspace of R).", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "Here we propose an approximation based on high-contrast points known as the Shi-Tomasi features [21].", "startOffset": 96, "endOffset": 100}, {"referenceID": 17, "context": "This approach again, is almost identical to traditional roadmap methods [20], except that the tests are all visual.", "startOffset": 72, "endOffset": 76}, {"referenceID": 19, "context": "Random projections (RP [22], [23]) is a dimensionality reduction method that preserves L2 distances.", "startOffset": 23, "endOffset": 27}, {"referenceID": 20, "context": "Random projections (RP [22], [23]) is a dimensionality reduction method that preserves L2 distances.", "startOffset": 29, "endOffset": 33}, {"referenceID": 2, "context": "In this work, we have introduced a new approach towards the longstanding perceptual robotics problem, which subsumes the problem of body schema learning [4], [5], [7].", "startOffset": 153, "endOffset": 156}, {"referenceID": 3, "context": "In this work, we have introduced a new approach towards the longstanding perceptual robotics problem, which subsumes the problem of body schema learning [4], [5], [7].", "startOffset": 158, "endOffset": 161}, {"referenceID": 5, "context": "In this work, we have introduced a new approach towards the longstanding perceptual robotics problem, which subsumes the problem of body schema learning [4], [5], [7].", "startOffset": 163, "endOffset": 166}], "year": 2015, "abstractText": "An open problem in robotics is that of using vision to identify a robot\u2019s own body and the world around it. Many models attempt to recover the traditional C-space parameters. Instead, we propose an alternative C-space by deriving generalized coordinates from n images of the robot. We show that the space of such images is bijective to the motion space, so these images lie on a manifold V homeomorphic to the canonical C-space. We now approximate this manifold as a set of n neighbourhood tangent spaces that result in a graph, which we call the Visual Roadmap (VRM). Given a new robot image, we perform inverse kinematics visually by interpolating between nearby images in the image space. Obstacles are projected onto the VRM in O(n) time by superimposition of images, leading to the identification of collision poses. The edges joining the free nodes can now be checked with a visual local planner, and free-space motions computed in O(nlogn) time. This enables us to plan paths in the image space for a robot manipulator with unknown link geometries, DOF, kinematics, obstacles, and camera pose. We sketch the proofs for the main theoretical ideas, identify the assumptions, and demonstrate the approach for both articulated and mobile robots. We also investigate the feasibility of the process by investigating various metrics and image sampling densities, and demonstrate it on simulated and real robots.", "creator": "LaTeX with hyperref package"}}}