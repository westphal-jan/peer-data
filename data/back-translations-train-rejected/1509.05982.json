{"id": "1509.05982", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Sep-2015", "title": "Denoising without access to clean data using a partitioned autoencoder", "abstract": "Training a denoising autoencoder neural network requires access to truly clean data, a requirement which is often impractical. To remedy this, we introduce a method to train an autoencoder using only noisy data, having examples with and without the signal class of interest. The autoencoder learns a partitioned representation of signal and noise, learning to reconstruct each separately. We illustrate the method by denoising birdsong audio (available abundantly in uncontrolled noisy datasets) using a convolutional autoencoder.", "histories": [["v1", "Sun, 20 Sep 2015 09:03:48 GMT  (1112kb,D)", "http://arxiv.org/abs/1509.05982v1", null], ["v2", "Tue, 22 Sep 2015 20:51:05 GMT  (1112kb,D)", "http://arxiv.org/abs/1509.05982v2", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["dan stowell", "richard e turner"], "accepted": false, "id": "1509.05982"}, "pdf": {"name": "1509.05982.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Richard E. Turner"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "An autoencoder (AE) is a neural network that has been trained unattended to encode its input into a latent representation and to decode that representation into a faithful reconstruction of its input; the autoencoder can then be used as a codec, or to convert data into its latent representation for downstream processing such as classification; the denoting autoencoder (PCS) is a variant of this, in which the inputs are combined with some corruption (such as additive noise or masking), and the system is trained to restore the clean, noisy data [1]. The PCS training scheme can be used in denoising applications and is also a popular method to encourage the autoencoder to learn a latent representation of the data. Autoencoders, including the PCS, have produced leading results in deep signal processing in recent years."}, {"heading": "2 Partitioned autoencoders", "text": "In practice, a DAE will learn that there are no incentives to \"overshoot,\" which may cause any disturbances. \"We,\" it says in the explanatory statement, \"have only a very limited number of areas of application.\" \"We,\" it says in the explanatory statement, \"have only a very limited number of areas of application.\" \"We,\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"\" \"We.\" \"\" \".\" \"\" \"\" \".\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\". \"\" \"\" \"\" \".\" \"\" \"\" \"\". \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \".\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\""}, {"heading": "3 Convolutional partitioned autoencoder for au-", "text": "In our application, we aim to extract information from audio spectrograms indexed by time and frequency. We will therefore use an autoencoder that is convolutional in time and fully connected in frequency, as is standard for newer audio analysis of neural networks [5]. Faced with an input matrix X indexed by discrete time and frequency h, we define our encoding function to bef (X) = mp (Wc? (X \u2212 \u00b5) / p), where Wc is a tensor of encoding weights indexed by time and frequency h, we define our encoding function to bef (X) = mp (Wc?) / p), where we are a tensor of encoding weights indexed by time and frequency h (r)."}, {"heading": "4 Evaluation", "text": "It is about the question of whether and in what form people will be able to put themselves in the world, and about the question of how far they are able to put themselves in the world, and about the question of how far they are able to put themselves in the world, and about the question of how far they are able to put themselves in the world, and about the question of how far they are able to put themselves in the world, and about the question of how far they are able to put themselves in the world, in which they are able to put themselves in the world, in which they are able to change the world, in order to put themselves in the world, in order to change the world, in order to change the world, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them, in order to change them."}, {"heading": "5 Conclusions", "text": "We have introduced a partitioned autoencoder that can learn to denote data with better accuracy than a standard PCE, where there are usually no noise-free examples available for training. Under customized conditions, this partitioned scheme makes better use of the available data than a PCE. Unlike a PCE, our partitioned autoencoder learns to render the signal and noise content and can reconstruct either or both, which may be part of its advantage over a standard PCE that does not learn to render the noise content. Further work will explore deeper / broader architectures to improve universality, and use the representations to support classification and other tasks."}, {"heading": "6 Acknowledgments", "text": "We are grateful to Pavel Linhart for recording the chaff-chaff bird sounds used in this study."}], "references": [{"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "P.-A. Manzagol"], "venue": "The Journal of Machine Learning Research, vol. 11, pp. 3371\u20133408, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional inverse graphics network", "author": ["T.D. Kulkarni", "W. Whitney", "P. Kohli", "J.B. Tenenbaum"], "venue": "arXiv preprint arXiv:1503.03167, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Discovering hidden factors of variation in deep networks", "author": ["B. Cheung", "J.A. Livezey", "A.K. Bansal", "B.A. Olshausen"], "venue": "arXiv preprint arXiv:1412.6583, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "End-to-end learning for music audio", "author": ["S. Dieleman", "B. Schrauwen"], "venue": "Proc ICASSP, 2014, pp. 6964\u20136968.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "An analysis of unsupervised pre-training in light of recent advances", "author": ["T.L. Paine", "P. Khorrami", "W. Han", "T.S. Huang"], "venue": "arXiv preprint arXiv:1412.6597, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Zero-bias autoencoders and the benefits of co-adapting features", "author": ["R. Memisevic", "K. Konda", "D. Krueger"], "venue": "arXiv preprint arXiv:1402.3337, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Adadelta: an adaptive learning rate method", "author": ["M.D. Zeiler"], "venue": "arXiv preprint arXiv:1212.5701, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["A.M. Saxe", "J.L. McClelland", "S. Ganguli"], "venue": "arXiv preprint arXiv:1312.6120, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Segregating event streams and noise with a Markov renewal process model", "author": ["D. Stowell", "M.D. Plumbley"], "venue": "Journal of Machine Learning Research, vol. 14, pp. 1891\u20131916, 2013, preprint arXiv:1211.2972.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1891}, {"title": "Improved multiple birdsong tracking with distribution derivative method and Markov renewal process clustering", "author": ["D. Stowell", "S. Mu\u0161evi\u010d", "J. Bonada", "M.D. Plumbley"], "venue": "Proceedings of the International Conference on Audio and Acoustic Signal Processing (ICASSP), 2013, preprint arXiv:1302.3642.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Theano: new features and speed improvements", "author": ["F. Bastien", "P. Lamblin", "R. Pascanu", "J. Bergstra", "I.J. Goodfellow", "A. Bergeron", "N. Bouchard", "Y. Bengio"], "venue": "Proceedings of NIPS 2012, 2012. 10", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "The denoising autoencoder (DAE) is a variant of this in which the inputs are combined with some corruption (such as additive noise or masking), and the system is trained to recover the clean, de-noised data [1].", "startOffset": 207, "endOffset": 210}, {"referenceID": 0, "context": "Autoencoders including the DAE have yielded leading results in recent years in deep learning for signal processing [1, 2].", "startOffset": 115, "endOffset": 121}, {"referenceID": 1, "context": "Autoencoders including the DAE have yielded leading results in recent years in deep learning for signal processing [1, 2].", "startOffset": 115, "endOffset": 121}, {"referenceID": 2, "context": "There has been recent interest in adapting the training schemes of autoencoders such that the latent representation is explicitly semantic, capturing attributes of the input in specific subsets of the latent variables [3, 4].", "startOffset": 218, "endOffset": 224}, {"referenceID": 3, "context": "There has been recent interest in adapting the training schemes of autoencoders such that the latent representation is explicitly semantic, capturing attributes of the input in specific subsets of the latent variables [3, 4].", "startOffset": 218, "endOffset": 224}, {"referenceID": 3, "context": "Crucially, in this prior work the training scheme relies heavily on the existence of large structured datasets: in [4] a balanced dataset of labelled digit images; in [3] a dataset of faces constructed through systematic variation of attributes such as pose and lighting.", "startOffset": 115, "endOffset": 118}, {"referenceID": 2, "context": "Crucially, in this prior work the training scheme relies heavily on the existence of large structured datasets: in [4] a balanced dataset of labelled digit images; in [3] a dataset of faces constructed through systematic variation of attributes such as pose and lighting.", "startOffset": 167, "endOffset": 170}, {"referenceID": 2, "context": "The scheme of [3] would be appropriate if the SNR of each training example were known and systematically varied, but in uncontrolled datasets this information is rarely available.", "startOffset": 14, "endOffset": 17}, {"referenceID": 1, "context": "while relatively easy to train because they have far fewer free parameters than an equivalent fully-connected network [2, 5].", "startOffset": 118, "endOffset": 124}, {"referenceID": 4, "context": "while relatively easy to train because they have far fewer free parameters than an equivalent fully-connected network [2, 5].", "startOffset": 118, "endOffset": 124}, {"referenceID": 4, "context": "We will thus use an autoencoder which is convolutional in time and fully-connected in frequency, as is standard for recent neural network audio analysis [5].", "startOffset": 153, "endOffset": 156}, {"referenceID": 5, "context": "[7, 8]).", "startOffset": 0, "endOffset": 6}, {"referenceID": 6, "context": "[7, 8]).", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "We train the network using AdaDelta to control the SGD learning rates [9].", "startOffset": 70, "endOffset": 73}, {"referenceID": 8, "context": "[10]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "As foreground we use recordings of chiff chaff (similarly to [11, 12]).", "startOffset": 61, "endOffset": 69}, {"referenceID": 10, "context": "As foreground we use recordings of chiff chaff (similarly to [11, 12]).", "startOffset": 61, "endOffset": 69}, {"referenceID": 11, "context": "Our system is implemented in the Theano framework [13] making use of GPU processing.", "startOffset": 50, "endOffset": 54}], "year": 2017, "abstractText": "Training a denoising autoencoder neural network requires access to truly clean data, a requirement which is often impractical. To remedy this, we introduce a method to train an autoencoder using only noisy data, having examples with and without the signal class of interest. The autoencoder learns a partitioned representation of signal and noise, learning to reconstruct each separately. We illustrate the method by denoising birdsong audio (available abundantly in uncontrolled noisy datasets) using a convolutional autoencoder.", "creator": "TeX"}}}