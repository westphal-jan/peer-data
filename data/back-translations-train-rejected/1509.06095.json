{"id": "1509.06095", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2015", "title": "Multilayer bootstrap network for unsupervised speaker recognition", "abstract": "We apply multilayer bootstrap network (MBN), a recent proposed unsupervised learning method, to unsupervised speaker recognition. The proposed method first extracts supervectors from an unsupervised universal background model, then reduces the dimension of the high-dimensional supervectors by multilayer bootstrap network, and finally conducts unsupervised speaker recognition by clustering the low-dimensional data. The comparison results with 2 unsupervised and 1 supervised speaker recognition techniques demonstrate the effectiveness and robustness of the proposed method.", "histories": [["v1", "Mon, 21 Sep 2015 02:28:44 GMT  (185kb,D)", "http://arxiv.org/abs/1509.06095v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SD", "authors": ["xiao-lei zhang"], "accepted": false, "id": "1509.06095"}, "pdf": {"name": "1509.06095.pdf", "metadata": {"source": "CRF", "title": "MULTILAYER BOOTSTRAP NETWORK FOR UNSUPERVISED SPEAKER RECOGNITION", "authors": ["Xiao-Lei Zhang"], "emails": ["xiaolei.zhang9@gmail.com"], "sections": [{"heading": null, "text": "Index Terms - multi-layer bootstrap network, speech recognition, unattended learning."}, {"heading": "1. INTRODUCTION", "text": "It is important in many speech systems, such as loudspeaker diarization, speech recognition and speech recognition. Supervised methods include maximum a posteriori estimation [1, 2], linear discriminatory analysis (LDA) [3, 4], support for vector machines [2], deep neural networks [5, 6], etc. Because the construction of a manually labeled body is intensive and time-consuming, it is imperative to develop unattended loudspeaker recognition methods. Existing methods include principled component analysis (PCA), k-mean clustering, gene mixing model (GMM), agglomerative hierarchical clustering, and common factor analysis."}, {"heading": "2. SYSTEM", "text": "Faced with an unlabeled speaker recognition corpus, we propose the following unattended algorithm: 1 \u2022 The first step is a loudspeaker and session-independent unattended Universal Background Model (UBM) [1] consisting of an acoustic feature that generates a ddimensional supervector for each utterance, known as x = [nT, fT] T, where n is the accumulation of the mixed cast across all frames of the utterance and f is the vector shape of first-order centered statistics. \u2022 The second step reduces the dimension of x from d to d (d, fT) by multilayered bootstrap network (MBN) introduced in Section 3. \u2022 The third step leads k-meaning clusters to the low-dimensional data if the number of underlying speakers is known, or agglomerative clustering if the number of speakers is unknowledge.1The source code is from http: tesgglesi.com / 2015 / hanggooxi5xleg.x1]"}, {"heading": "3. MULTILAYER BOOTSTRAP NETWORK", "text": "The structure of MBN [13] is shown in Fig. 1. MBN is a multi-layer local PCA algorithm that implicitly enlarges the area of a local region from the lowest hidden layer to the top hidden layer by high-dimensional sparse encoding and receives a low-dimensional characteristic explicitly by PCA at the output level.Each hidden layer of MBN consists of a group of independent k-center clusterings. Each k-center cluster has k-output units, each of which indicates a cluster. the output units of all clusters are trained as input of their top layer [13].MBN is trained layer by layer from bottom up. To form a hidden layer, which has a d-dimensional input X = {x1,., xn}, MBN forms each individual layer x."}, {"heading": "3.1. A typical hyperparameter setting", "text": "MBN has five hyperparameters {V, L, {kl} Ll = 1, a, r}, where V is the number of k centers clustering per layer, L the number of hidden levels and kl the hyperparameter k at the oldest hidden level. As shown in [13], MBN is robust against hyperparameter selection. Here we present a typical setting: \u2022 The setting of the hyperparameter k. (i) k1 should be as large as possible, i.e. k1 \u2192 n. Suppose the largest k supported by hardware is kmax, then k1 = min (0.9n, kmax). (ii) kl decays by a factor of, e.g. 0.5, with the increase in the hidden levels. That is, kl = 0.5 kl \u2212 1. (ii) kL should be larger than the number of loudspeakers. Typically kL with respect to hyperparameter 1.5c. If unknown, we should simply set a scale > 30 to a relatively large problem, for example, kl = a relatively large scale."}, {"heading": "4. RELATED WORK", "text": "The proposed method learns multi-layered nonlinear transformations related to deep learning (also known as multi-layered neural networks) - a current advanced topic in many areas of language processing, such as speech recognition [5, 6], speech recognition [14], speech separation and improvement [15-18], speech synthesis [19] and speech activity detection [20, 21]. The above methods of deep learning are all monitored and limited to neural networks, while the proposed method is an unattended method that differs from neural networks."}, {"heading": "5. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Experimental setup", "text": "We used the Training Corpus of the Language Separation Challenge (SSC) [22]. The Training Corpus contains 34 speakers, each of which has 500 clean expressions. We chose the first 100 expressions (a.k.a, sessions) of each speaker for the evaluation, which amounts to 3400 expressions. We set the frame length to 25 milliseconds and drew a 25-dimensional MFCC feature. For the proposed MBN-based speaker recognition, we took the typical parameter settings of MBN. Specifically, V = 0.5, r = 0.5, and K were set to 3060-1530-382."}, {"heading": "5.2. Results", "text": "Because all comparison methods use UBM to extract speakerand-independent supervectors, we need to examine how they behave in different UBM settings, in terms of the number of mixtures and the expectation maximization (EM) iterations. (i) 2The source code is from http: / / erdb.microsoft.com / enus / a6262fec-4060-a08c-037f5b / 3http: / erdb.google.com / Site / zhangxiaolei321 / eBnlbmA-i.rmndUeaD The mix of UBM reflects the capacity of UBM to model an underlying data distribution: If the number of UBM is smaller than the number of speakers, then the number of UBM is greater than the number of UBM."}, {"heading": "6. CONCLUSIONS", "text": "In this paper, we have proposed a multi-layer bootstrap network based on unattended speaker recognition algorithms, which first uses UBM to extract a high-dimensional feature from the original MFCC acoustic feature, then MBN to reduce the high-dimensional feature to a low-dimensional space, and finally clustering the low-dimensional data. We have compared it to the PCA, k-means-clustering, and LDA-based methods, where the first two methods are left unattended and the third method is supervised. Experimental results have shown that the proposed method outperforms the unattended methods and outperforms approaches to the monitored method. Furthermore, it is insensitive to different parameter settings of UBM and MBN, making its practical application easier."}, {"heading": "7. ACKNOWLEDGEMENT", "text": "The author thanks Prof. DeLiang Wang for providing the Ohio Computing Center and Dr. Ke Hu for his help with the SSC-Corpus."}, {"heading": "8. REFERENCES", "text": "[1] Douglas A Reynolds, Thomas F Quatieri, and Robert B Dunn, \"Speaker verification using adapted gaussian mixture models,\" Digital Signal Process., vol. 10, no. 1, pp. 19-41, 2000. [2] William M Campbell, Douglas E Sturim, Douglas A Reynolds, and Alex Solomonoff, \"SVM based speaker verification using a GMM supervector kernel and NAP variability compensation,\" in Proc. IEEE Lang Int. Conf. Acoust., Speech, Signal Process., 2006, vol. 1, pp. 97-100. [3] Patrick Kenny, Gilles Boulianne, Pierre Ouellet."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "We apply multilayer bootstrap network (MBN), a recent pro-<lb>posed unsupervised learning method, to unsupervised speaker<lb>recognition. The proposed method first extracts supervectors<lb>from an unsupervised universal background model, then re-<lb>duces the dimension of the high-dimensional supervectors by<lb>multilayer bootstrap network, and finally conducts unsuper-<lb>vised speaker recognition by clustering the low-dimensional<lb>data. The comparison results with 2 unsupervised and 1 su-<lb>pervised speaker recognition techniques demonstrate the ef-<lb>fectiveness and robustness of the proposed method.", "creator": "LaTeX with hyperref package"}}}