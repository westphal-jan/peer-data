{"id": "1509.06103", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2015", "title": "Noise Robust IOA/CAS Speech Separation and Recognition System For The Third 'CHIME' Challenge", "abstract": "This paper presents the contribution to the third 'CHiME' speech separation and recognition challenge including both front-end signal processing and back-end speech recognition. In the front-end, Multi-channel Wiener filter (MWF) is designed to achieve background noise reduction. Different from traditional MWF, optimized parameter for the tradeoff between noise reduction and target signal distortion is built according to the desired noise reduction level. In the back-end, several techniques are taken advantage to improve the noisy Automatic Speech Recognition (ASR) performance including Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Long short-term memory (LSTM) using medium vocabulary, Lattice rescoring with a big vocabulary language model finite state transducer, and ROVER scheme. Experimental results show the proposed system combining front-end and back-end is effective to improve the ASR performance.", "histories": [["v1", "Mon, 21 Sep 2015 03:37:11 GMT  (59kb)", "http://arxiv.org/abs/1509.06103v1", "5 pages, 1 figure"]], "COMMENTS": "5 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.SD cs.CL", "authors": ["xiaofei wang", "chao wu", "pengyuan zhang", "ziteng wang", "yong liu", "xu li", "qiang fu", "yonghong yan"], "accepted": false, "id": "1509.06103"}, "pdf": {"name": "1509.06103.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xiaofei Wang", "Chao Wu", "Pengyuan Zhang", "Ziteng Wang", "Yong Liu", "Xu Li", "Qiang Fu", "Yonghong Yan"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 9: 06 103v 1 [cs.S D] 21 Sep 2015Index Terms - CHiME challenge, Multi-channel Wiener filter, Deep Neural Network, Noise Robust, Automatic Speech Recognition"}, {"heading": "1. INTRODUCTION", "text": "This year is the highest in the history of the country."}, {"heading": "2. SPEECH ENHANCEMENT FRONT-END", "text": "To suppress background noise, the Multi-Channel Viennese Filter (MWF) is inserted into the Multi-Microphone Set-up (NK) (1). Since MWF does not require transmission functions between a target loudspeaker and microphones, it is suitable for the CHiME3 task. Taking speech distortion into account in its optimization criterion, MWF is generalized as speech distortion (SDW-MWF) as a multi-channel Viennese filter (SDW-MWF), which offers a compromise between voice distortion and noise reduction [12, 13, 14]. In this work, a commercially optimized method based on SDW-MWF signal distortion is used."}, {"heading": "3. BACK-END DESCRIPTION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Acousitic modeling with neural network", "text": "Fig.1 demonstrates the back-end description including the techniques we used for the proposed system.The GMM baseline includes the standard triphone-based acoustic models with various functional transformations, including linear discriminant analysis (LDA), maximum probability linear transformation (MLLT), and feature space maximum probability linear regression (fMLLR) with speaker adaptive training (SAT).The DNN baseline provides the state-of-the-art ASR performance. It is based on the Kaldi recipe for Track 2 of the 2nd CHiME Challenge [16]. The DNN is used using the standard procedure (pre-training with restricted Boltzmann machines, cross-entropy training and sequence discriminatory training).This baseline requires relatively massive computational resources (GPUs for DNN training and many CPUs for the lattice generation).We start using DNN-based formation of DNN filters based on DNT-48, which are plugged into the DNN filters for DNT based on the DN7 dimensions."}, {"heading": "3.2. Combination of different systems", "text": "In order to combine these multiple voice recognition outputs into a single one, we use ROVER at the decision level [11] in the final step. Fusion allows us to achieve a lower error rate than any of the individual systems alone. In this paper, NIST Scoring Toolkit (SCTK, version 1.3) is used as a rover tool to combine the different results. It records N input files and performs N-Way Dynamic Programming (DP) alignment on these files."}, {"heading": "4. EXPERIMENTS AND RESULTS", "text": "In this section, we list the ASR improvement step by step according to each technique we use, leading to the final WER of the test kit provided by the CHiME challenge. Table1 indicates the baseline \"CHiME\" provided by GMM and DNN, Table.2 shows the ASR results according to the proposed system and Table.3 shows the ASR results under each scenario, including bus (BUS), cafe (CAF), pedestrian zone (PED) and intersection (STR) according to the best system according to ROVER."}, {"heading": "4.1. ASR performance of front-end speech enhancement", "text": "Table.2 shows that the WER of real test data decreases from 37.36% to 23.19% by changing the language improvement method from MVDR (provided by CHiME organizers [17]) to the proposed SDW-MWF under the acoustic model GMM. If we randomly calculate the SNR of training data from -6dB-6dB (designated by Random SNR in Table.2) instead of the estimated SNR calculated from actually recorded data to simulate training sessions, the WER drops to 22.07%. Under the acoustic model DNN + sMBR, the WER decreases from 33.76% to 18.4% of the test data using SDW-MWF and random SNR schemes. It is worth noting that all training data are improved to compensate for the discrepancy between training data and test data."}, {"heading": "4.2. Back-end ASR performance", "text": "The results of the DNN model on the development and evaluation line are also presented in Table 2. We can see that DNN receives 16.63% relative WER reduction compared to the GMM system on the real data of the test set. Obviously, the improvement is not sufficient, then we tried to use several other NN topologies. As shown in Table 2, the CNN acoustic models perform better than conventional DNN. The WER decreases from 18.4% to 17.87%. Table 2 shows that LSTM receives further improvements. Compared to GMM, a relative reduction of 14.09% was achieved. After the mesh rescoring, all systems receive significant improvements. Finally, the best ASR result was achieved by combining all systems with mesh rescoring. We achieve a final WER of 13.2% on the real data of the test set, resulting in a relative reduction of WHO 60.9% compared to the result of 33.23% in relation to the best baseline GMM."}, {"heading": "5. CONCLUSION", "text": "This paper presents a state-of-the-art ASR system designed to reduce the effects of noise using a 6-microphone array under various real-world application scenarios. Two aspects are presented separately: Frontend speech improvement using SDW-MWF achieves a significant performance improvement. Backend techniques such as GMM, DNN, CNN and LSTM are examined. Combining the four systems with lattice rescoring has the best ASR performance in the development and test section. We achieve a relative reduction of WER by 60.9% compared to the real data of the test data compared to the best base system."}, {"heading": "6. REFERENCES", "text": "In recent years, it has become clear that the two countries are not just one country, but also a country where people are able to integrate and integrate, and where people are able to integrate and integrate. [1] Jon Barker, Ricard Marxer, Emmanuel Vincent Watanabe and Shinji Watanabe. [2] See how people in the countries in which they live interact with each other. [3] See how people in the countries in which they live interact with each other. [4] See how people in the countries in which they live interact with each other. [4] See how people in the countries in which they live interact with each other. [4] See how people in the countries in which they live and in which they live, in which they live, in which they live and in which they live, in which they live and in which they live. [4] See how people in which they live and in which they live, in which they live, in which they live and in which they live."}], "references": [{"title": "The third \u2019chime\u2019 speech separation and recognition challenge: Dataset, task and baselines", "author": ["Jon Barker", "Ricard Marxer", "Emmanuel Vincent", "Shinji Watanabe"], "venue": "Submitted to IEEE 2015 Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Gsvd-based optimal filtering for multi-microphone speech enhancement", "author": ["Simon Doclo", "Marc Moonen"], "venue": "Microphone Arrays, pp. 111\u2013132. Springer, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Prob-  abilistic and bottle-neck features for LVCSR of meetings", "author": ["F. Grezl", "M. Karafiat", "S. Kontar", "J. Cernocky"], "venue": "Acoustics, Speech and Signal Processing, 2007. ICASSP 2007. IEEE International Conference on, 2007, vol. 4, pp. IV\u2013757\u2013IV\u2013760.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Exploring strategies for training deep neural networks", "author": ["H. Larochelle", "Y. Bengio", "J. Louradour", "P. Lamblin"], "venue": "J. Mach. Learn. Res., vol. 10, pp. 1\u201340, June 2009.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Conversational speech transcription using context-dependent deep neural networks", "author": ["F. Seide", "G. Li", "D. Yu"], "venue": "INTERSPEECH, 2011, pp. 437\u2013440.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Hybrid acoustic models for distant and multichannel large vocabulary speech recognition", "author": ["P. Swietojanski", "A. Ghoshal", "S. Renals"], "venue": "Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on, Dec 2013, pp. 285\u2013290.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Using neural network front-ends on far field multiple microphones based speech recognition", "author": ["Yulan Liu", "Pengyuan Zhang", "Thomas Hain"], "venue": "ICASSP2014 - Speech and Language Processing (ICASSP2014 - SLTC), Florence, Italy, May 2014, pp. 5579\u20135583.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep convolutional neural networks for LVCSR", "author": ["T.N. Sainath", "A.R. Mohamed", "B. Kingsbury", "B. Ramabhadran"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, 2013, pp. 8614\u20138618.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition", "author": ["Hasim Sak", "Andrew Senior", "Fran04oise Beaufays"], "venue": "Eprint Arxiv1402, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling", "author": ["Hasim Sak", "Andrew Senior", "Fran04oise Beaufays"], "venue": "Interspeech, pp. 338 \u2013 342, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)", "author": ["J.G. Fiscus"], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding, 1997.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "On optimal frequency-domain multichannel linear filtering for noise reduction", "author": ["Mehrez Souden", "Jacob Benesty", "Sofi\u00e8ne Affes"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 18, no. 2, pp. 260\u2013 276, 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Spatially pre-processed speech distortion weighted multi-channel wiener filtering for noise reduction", "author": ["Ann Spriet", "Marc Moonen", "Jan Wouters"], "venue": "Signal Processing, vol. 84, no. 12, pp. 2367\u20132387, 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Gsvd-based optimal filtering for single and multimicrophone speech enhancement", "author": ["Simon Doclo", "Marc Moonen"], "venue": "Signal Processing, IEEE Transactions on, vol. 50, no. 9, pp. 2230\u20132244, 2002.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Frequency-domain criterion for the speech distortion weighted multichannel wiener filter for robust noise reduction", "author": ["Simon Doclo", "Ann Spriet", "Jan Wouters", "Marc Moonen"], "venue": "Speech Communication, vol. 49, no. 7, pp. 636\u2013656, 2007.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Recurrent deep neural networks for robust speech recognition", "author": ["Chao Weng", "Dong Yu", "Shigetaka Watanabe", "Biing- Hwang Fred Juang"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on. IEEE, 2014, pp. 5532\u20135536.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "On diagonal loading for minimum variance beamformers", "author": ["Xavier Mestre", "Miguel Lagunas"], "venue": "Signal Processing and Information Technology, 2003. ISSPIT 2003. Proceedings of the 3rd IEEE International Symposium on. IEEE, 2003, pp. 459\u2013462.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "The 3rd \u2019CHiME\u2019 speech separation and recognition challenge is such a platform for testing the recognition rate of noisy speech in complex environments [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 1, "context": "Therefore, taking speech distortion into account in the multi-channel optimization criterion, multi-channel wiener filter (WMF) technique has been proposed to estimate the desired speech component in noisy environment [2].", "startOffset": 218, "endOffset": 221}, {"referenceID": 2, "context": "[3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "As noted in several publications [4, 5, 6, 7], DNNs show general word error rate (WER) improvements on the order of 10-30%", "startOffset": 33, "endOffset": 45}, {"referenceID": 4, "context": "As noted in several publications [4, 5, 6, 7], DNNs show general word error rate (WER) improvements on the order of 10-30%", "startOffset": 33, "endOffset": 45}, {"referenceID": 5, "context": "As noted in several publications [4, 5, 6, 7], DNNs show general word error rate (WER) improvements on the order of 10-30%", "startOffset": 33, "endOffset": 45}, {"referenceID": 6, "context": "As noted in several publications [4, 5, 6, 7], DNNs show general word error rate (WER) improvements on the order of 10-30%", "startOffset": 33, "endOffset": 45}, {"referenceID": 7, "context": "CNNs are a more effective model for speech compared to DNNs [8].", "startOffset": 60, "endOffset": 63}, {"referenceID": 8, "context": "LSTM are also proved more effective than DNNs and conventional RNNs for acoustic modeling [9, 10].", "startOffset": 90, "endOffset": 97}, {"referenceID": 9, "context": "LSTM are also proved more effective than DNNs and conventional RNNs for acoustic modeling [9, 10].", "startOffset": 90, "endOffset": 97}, {"referenceID": 10, "context": "In this paper, we take advantage of these techniques for acoustic modeling and make a combination of them to achieve a better ASR performance [11].", "startOffset": 142, "endOffset": 146}, {"referenceID": 1, "context": "In order to suppress background noise, multichannel wiener filter (MWF) is introduced to the multi-microphone set-up [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 11, "context": "Taking speech distortion into account in its optimization criterion, MWF is generalized as speech distortion weighted multichannel wiener filter (SDW-MWF), which provides a tradeoff between speech distortion and noise reduction [12, 13, 14].", "startOffset": 228, "endOffset": 240}, {"referenceID": 12, "context": "Taking speech distortion into account in its optimization criterion, MWF is generalized as speech distortion weighted multichannel wiener filter (SDW-MWF), which provides a tradeoff between speech distortion and noise reduction [12, 13, 14].", "startOffset": 228, "endOffset": 240}, {"referenceID": 13, "context": "Taking speech distortion into account in its optimization criterion, MWF is generalized as speech distortion weighted multichannel wiener filter (SDW-MWF), which provides a tradeoff between speech distortion and noise reduction [12, 13, 14].", "startOffset": 228, "endOffset": 240}, {"referenceID": 12, "context": "To find an optimal estimate of the target signal, the designed SDW-MWF criterion is [13, 15]", "startOffset": 84, "endOffset": 92}, {"referenceID": 14, "context": "To find an optimal estimate of the target signal, the designed SDW-MWF criterion is [13, 15]", "startOffset": 84, "endOffset": 92}, {"referenceID": 15, "context": "It is based on the Kaldi recipe for Track 2 of the 2nd CHiME Challenge [16].", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "The LSTM network used in this paper is a two layer LSTM RNN, where each LSTM layer has 1024 memory cells and a dimensionality reducing recurrent projection layer of 200 linear units [9, 10].", "startOffset": 182, "endOffset": 189}, {"referenceID": 9, "context": "The LSTM network used in this paper is a two layer LSTM RNN, where each LSTM layer has 1024 memory cells and a dimensionality reducing recurrent projection layer of 200 linear units [9, 10].", "startOffset": 182, "endOffset": 189}, {"referenceID": 10, "context": "To combine these multiple speech recognition outputs into a single one, we employ ROVER at the decision level [11] in the final step.", "startOffset": 110, "endOffset": 114}, {"referenceID": 16, "context": "19% by changing the speech enhancement method from MVDR (supplied by CHiME organizers [17]) to the proposed SDW-MWF under GMM acoustic model.", "startOffset": 86, "endOffset": 90}], "year": 2015, "abstractText": "This paper presents the contribution to the third \u2019CHiME\u2019 speech separation and recognition challenge including both front-end signal processing and back-end speech recognition. In the front-end, Multi-channel Wiener filter (MWF) is designed to achieve background noise reduction. Different from traditional MWF, optimized parameter for the tradeoff between noise reduction and target signal distortion is built according to the desired noise reduction level. In the back-end, several techniques are taken advantage to improve the noisy Automatic Speech Recognition (ASR) performance including Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Long short-term memory (LSTM) using medium vocabulary, Lattice rescoring with a big vocabulary language model finite state transducer, and ROVER scheme. Experimental results show the proposed system combining front-end and back-end is effective to improve the ASR performance.", "creator": "LaTeX with hyperref package"}}}