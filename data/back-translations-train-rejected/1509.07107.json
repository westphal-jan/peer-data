{"id": "1509.07107", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Sep-2015", "title": "On The Direct Maximization of Quadratic Weighted Kappa", "abstract": "In recent years, quadratic weighted kappa has been growing in popularity in the machine learning community as an evaluation metric in domains where the target labels to be predicted are drawn from integer ratings, usually obtained from human experts. For example, it was the metric of choice in several recent, high profile machine learning contests hosted on Kaggle : www.kaggle.com/c/asap-aes , www.kaggle.com/c/asap-sas , www.kaggle.com/c/diabeticretinopathy- detection . Yet, little is understood about the nature of this metric, its underlying mathematical properties, where it fits among other common evaluation metrics such as mean squared error (MSE) and correlation, or if it can be optimized analytically, and if so, how. Much of this is due to the cumbersome way that this metric is commonly defined. In this paper we first derive an equivalent but much simpler, and more useful, definition for quadratic weighted kappa, and then employ this alternate form to address the above issues.", "histories": [["v1", "Wed, 23 Sep 2015 19:39:39 GMT  (209kb,D)", "http://arxiv.org/abs/1509.07107v1", "preliminary draft"], ["v2", "Tue, 29 Sep 2015 21:30:43 GMT  (199kb,D)", "http://arxiv.org/abs/1509.07107v2", "preliminary draft"], ["v3", "Sun, 6 Dec 2015 15:16:19 GMT  (0kb,I)", "http://arxiv.org/abs/1509.07107v3", "realized some inaccuracies, and some sloppy reasoning. Need some time to fix"]], "COMMENTS": "preliminary draft", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["david vaughn", "derek justice"], "accepted": false, "id": "1509.07107"}, "pdf": {"name": "1509.07107.pdf", "metadata": {"source": "CRF", "title": "On The Direct Maximization of Quadratic Weighted Kappa", "authors": ["David Vaughn", "Derek Justice"], "emails": ["DVAUGHN@MEASINC.COM", "DJUSTICE@MEASINC.COM"], "sections": [{"heading": null, "text": "However, little is understood about the nature of this metric, its underlying mathematical properties, where it lies alongside other common evaluation variables such as mean square error (MSE) and correlation, or whether it can be optimized analytically, and if so, how. Much of this is due to the cumbersome definition of this metric. In this paper, we first derive an equivalent but much simpler and more useful definition of square weighted kappa, and then use this alternative form to address the above problems."}, {"heading": "1. Preliminaries", "text": "Although developed for the first time in the statistical community as a measure of concordance between assessors, \u0443 has more recently become a popular performance metric in supervised machine learning, especially in situations where the target variable y is a discrete interval variable (usually drawn from non-negative integers), as is common in most human assessment scales (e.g. \"on a scale of 1 to 10\"), which differs from the ordinal regression setting, where there is only a sequence of descriptions but no intrinsic or constant length interval between them. Some have argued that the use of square-weighted kappa as a measurement in the field of human assessments imposes the erroneous assumption of \"equal intervals,\" where there should be none (how this assumption is expressed in the metric itself will be unclear in the following section)."}, {"heading": "1.1. Standard Definition", "text": "Quadratic weighted kappa, which we write to distinguish from linear weighted kappa, was originally developed as a measure of concordance between the kappa. In this scenario, there are two raters, A and B, each associated with a vector of n integer ratings a, b, and Ln \u00b7 1, where L = {1, 2, \u00b7 \u00b7 \u00b7, is \"a finite set\" of possible values. To calculate the concordance between a and b., it is customary to start calculating frequency tables. The observed confusion matrix U = (ui, j) is first calculated as: ui, j = n-k = 1I (ak = i) \u00b7 I (bk = j) Next, the expected confusion matrix V = (vi, j) and the confusion matrix e, assuming that there is no correlation between the raters."}, {"heading": "1.2. Alternate Form", "text": "Suppose a data matrix X = [x > 1, \u00b7 \u00b7, x > n] > < Rn \u00b7 d of n dots in d-dimensional space and a vector y \u00b7 Ln \u00b7 1 of n integer labels, where L = {1, 2, \u00b7 \u00b7, 'is a finite series of possible labels. We assume that there is a true functional relationship yi = f (xi) between each dot xi and its label yi. The goal is to find a function y = f (xi) that comes as close as possible to the true function. With this notation, we can begin to rewrite the standard definition of \"i = f (xi), first pointing out that the numberer is simply a default sum of square errors: < U, W > F = n \u00b2 k = 1 (yk \u2212 f (xk)))) 2 (\" \u2212 1) 2 = y (\"\u2212 1) 2Next, we note that the Ny can be simplified in terms similar to the Ny and the Ny."}, {"heading": "2. Linear Model", "text": "We are looking at a simple linear model for y = f (X): f (X) = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = > short-term = = short-term = short-term = short-term = short-term = short-term = short-term = short-term = = short-term = short-term = = short = = short = = short = = short = = = = = short = = = = = short = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "2.1. Regularization", "text": "It is often useful to include a regularization term in the optimization to take into account cases in which X > X = > result is singular or poorly conditioned, which could lead to a numerically unstable (or non-existent) solution. In addition, it provides a practical mechanism for manual adjustment of the bias / variance trade-offs. It is easy to agree on a normative penalty term within the current framework, which results in a slightly modified optimization solution: max. \u2212 X. < y \u00b7 X\u03b1 > -. \"X.\" \"II.\".. \"\" \"II.\" \"II.\" II. \"II.\". \"II.\".. \"\" II. \"..\" \"II.\" \"II.\" \"II.\".. \"..\".. \"II.\".. \"..\".. \"..\" II.. \"..\".. \"..\".. \"II..\".. \"..\".. \"..\".. \"..\".. \"..\".. \"..\".. \"..\" II. \"..\". \".\".. \".\" \".\". \".\" \"..\" II. \"..\". \".\" \"..\". \"..\". \".\". \".\". \"\" II. \"..\". \"\".. \".\".. \".\". \".\". \".\" II. \"..\" \"..\". \".\". \"..\". \".\" \".\". \"II.\" \"..\".. \".\". \"..\". \".\". \"..\". \".\". \"II.\" \"..\". \".\". \"..\". \".\". \"II.\".. \".\".. \".\". \".\". \".\". \".\".. \"II.\" \"\". \".\".. \".\". \".\". \".\". \"II.\" \".\".. \".\". \".\" \".\" \"\". \"\" II. \"\". \"\".. \"..\" \".\". \"\". \"\". \"\". \"\". \".\". \"\" II. \"..\". \"\".. \".\" \"\". \".\" \"\". \"\". \".\" \".\". \""}, {"heading": "3. Link to Correlation", "text": "There is an interesting connection between the square weighted kappa and correlation. There are many (equivalent) definitions of correlation, but the simplest is just the normalized point product between two vectors u, v: \u03c1 (u, v) = < u \u00b7 v >. Now we return to the (non-regulated) terms for the \"optimal solution,\" and we can expand the expression for \"y\" (y, y) and (7) and (8) simplify: \"y\" (y, y) = < y \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" < y \"s\" s \"s\" s \"s\" s \"s\" s. \"< y\" s \"s\" s \"s\" s \"s.\""}, {"heading": "Appendix: Proof of Strict Quasiconcavity", "text": "We would like to show that the mode of operation (\u03b1) = 2 < y \u00b7 X\u03b1 > is quasi-concavant, if we apply to any two points u, v and any positive weight distribution < 1, the following applies (Avriel, 2003): f (v) + (1 \u2212 concavant) v) > min [f (u), f (v)]] (A-1) (without loss of universality), that min [v), v (v)] (u)] (v (u), which leads us to write: (v). \u2212 2 < y \u2212 Xv > y (2 + Xv)."}], "references": [{"title": "Nonlinear programming: analysis and methods", "author": ["Avriel", "Mordecai"], "venue": "Courier Corporation,", "citeRegEx": "Avriel and Mordecai.,? \\Q2003\\E", "shortCiteRegEx": "Avriel and Mordecai.", "year": 2003}], "referenceMentions": [], "year": 2017, "abstractText": "In recent years, quadratic weighted kappa has been growing in popularity in the machine learning community as an evaluation metric in domains where the target labels to be predicted are drawn from integer ratings, usually obtained from human experts. For example, it was the metric of choice in several recent, high profile machine learning contests hosted on Kaggle : www.kaggle.com/c/asap-aes , www.kaggle.com/c/asap-sas , www.kaggle.com/c/diabeticretinopathy-detection . Yet, little is understood about the nature of this metric, its underlying mathematical properties, where it fits among other common evaluation metrics such as mean squared error (MSE) and correlation, or if it can be optimized analytically, and if so, how. Much of this is due to the cumbersome way that this metric is commonly defined. In this paper we first derive an equivalent but much simpler, and more useful, definition for quadratic weighted kappa, and then employ this alternate form to address the above issues. 1. Preliminaries Although first developed in the statistical community as a measure of inter-rater agreement, \u03ba has more recently become a popular performance metric in supervised machine learning, specifically in situations where the target (dependent) variable y is a discrete, interval variable (usually drawn from non-negative integers) such as is common in most human rating scales (e.g.\u201con a scale from 1 to 10\u201d). This differs from the ordinal regression setting, where there only exists an ordering over labels, but no intrinsic or constant length interval between them. Some have argued that the use of quadratic weighted kappa as a metric in the domain of human ratings imposes the erroneous assumption of \u201cequal intervals\u201d where there should be none (how this assumption is expressed in the metric itself will be made clear in the following section). For example, when rating student essays on a scale from 1 to 5, the difference between a 1 and a 2 may not be equal to the difference between a 4 and a 5. While this may or may not be true in certain cases, we will not be concerned with that here. 1.1. Standard Definition Quadratic weighted kappa, which we write \u03ba to distinguish from linear weighted kappa, was originally developed as a measure of inter-rater agreement. In this scenario, there are two raters, A and B, each associated with a vector of n integer ratings a,b \u2208 Ln\u00d71 where L = {1, 2, \u00b7 \u00b7 \u00b7 , `} is a finite set of ` possible values. We seek to quantify the level of agreement between a and b. In order to compute \u03ba(a,b), it is customary to start by computing frequency tables. The observed confusion matrix U = (ui,j) \u2208 N`\u00d7` is first computed as:", "creator": "LaTeX with hyperref package"}}}