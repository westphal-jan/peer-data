{"id": "1509.07481", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Sep-2015", "title": "Spatially Encoding Temporal Correlations to Classify Temporal Data Using Convolutional Neural Networks", "abstract": "We propose an off-line approach to explicitly encode temporal patterns spatially as different types of images, namely, Gramian Angular Fields and Markov Transition Fields. This enables the use of techniques from computer vision for feature learning and classification. We used Tiled Convolutional Neural Networks to learn high-level features from individual GAF, MTF, and GAF-MTF images on 12 benchmark time series datasets and two real spatial-temporal trajectory datasets. The classification results of our approach are competitive with state-of-the-art approaches on both types of data. An analysis of the features and weights learned by the CNNs explains why the approach works.", "histories": [["v1", "Thu, 24 Sep 2015 19:14:20 GMT  (2223kb,D)", "http://arxiv.org/abs/1509.07481v1", "Submit to JCSS. Preliminary versions are appeared in AAAI 2015 workshop and IJCAI 2016 [arXiv:1506.00327]"]], "COMMENTS": "Submit to JCSS. Preliminary versions are appeared in AAAI 2015 workshop and IJCAI 2016 [arXiv:1506.00327]", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["zhiguang wang", "tim oates"], "accepted": false, "id": "1509.07481"}, "pdf": {"name": "1509.07481.pdf", "metadata": {"source": "CRF", "title": "Spatially Encoding Temporal Correlations to Classify Temporal Data Using Convolutional Neural Networks", "authors": ["I Zhiguang Wanga", "Tim Oates"], "emails": ["zgwang813@gmail.com"], "sections": [{"heading": null, "text": "We propose an offline approach to explicit spatial encoding of temporal patterns as different types of images, namely Gramian Angular Fields and Markov Transition Fields. This enables the use of computer vision techniques for feature learning and classification. We used Tiled Convolutional Neural Networks to learn high-grade features from individual GAF, MTF and GAF MTF images on 12 benchmark time series datasets and two real spatio-temporal trajectory datasets. The classification results of our approach compete with state-of-the-art approaches to both types of data. An analysis of features and weights learned from the CNNs explains why this approach work.Keywords: Time series, trajectory, classification, Gramian Angular Field, Markov Transition Field, Convolutional Neural Networks"}, {"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own."}, {"heading": "2. Motivation", "text": "Most real data have a temporal component, whether it is measurements of natural (weather, sound) or man-made (stock market, robotics) phenomena. Traditional approaches to modelling and displaying time series data fall into three categories. Time series data presents learning problems, non-data adaptive models such as discrete Fourier transformation (DFT) [24], discrete wavelet transformation (DWT), discrete cosmic transformation (DCT), temporary models that are immutable in relation to the data. Discrete wavelet transformation (DWT) [24], discrete cosmic transformation (DCT), and discrete cosmic transformation (DCT), which deal with an algorithm that is immutable to capture the intrinsic temporal correlation with the different basic properties. Meanwhile, researchers in the model-based approaches, the model function of time series (such as ARMA) and time series (such as time series) are explored."}, {"heading": "3. Encoding Methods", "text": "The first type of image is the Gramic Angle Field (GAF), in which we represent time series in a polar coordinate system instead of the typical Cartesian coordinates. In the Gramic Matrix, each element is actually the cosine of the summation of paired time values. Inspired by earlier work on the duality between time series and complex networks [31], the basic idea of the second framework, the Markov Transition Field (MTF), is to construct the Markov matrix of quantity containers after discretization and to code the dynamic transition probability in a quasi-gramic matrix."}, {"heading": "3.1. Gramian Angular Field", "text": "Faced with a time series X = {x1, x2, xn} of n real evaluated observations, Werescale X such that all values fall within the interval [\u2212 1, 1] or [0, 1] of: x \u00b7 i \u2212 1 = (xi \u2212 max (X) + (xi \u2212 min (X))) max (X) \u2212 min (X) (1) or x \u00b7 i0 = xi \u2212 min (X) \u2212 min (X) (2) Thus, we can represent the rescaled time series X (X) in polar coordinates by representing the value as angular Kosin and the time stamp as radius with the equations below (x) \u2212 min (2)."}, {"heading": "3.2. Markov Transition Field", "text": "We develop this idea by sequentially representing the Markov transition probabilities in order to obtain information in the temporal dimension. Faced with a time series X, we identify its Q-quantile bins and assign each of their transition processes to the respective time axis. We are the frequency with which a point in the quantitative Q1 quantity is followed by a point in the quantitative Q1 quantity."}, {"heading": "4. Tiled Convolutional Neural Networks", "text": "It is the first phase in which the weight matrix W is learned, while the matrix V represents the topographic structure of the units."}, {"heading": "5. Experiments on Time Series Data", "text": "We use tiled CNNs for classification using GAF and MTF representation on twelve tough data sets, on which the classification error rate with the modern SAX-BoP approach is above 0.1 [35, 22]. Detailed statistics are summarized in Table 1. Data sets are divided into training and test sets for experimental comparisons in advance. For each data set, the table contains its name, the number of classes, the number of training and test instances, and the length of each time series."}, {"heading": "5.1. Experiment Settings", "text": "In our experiments, the size of the GAF image is regulated by the number of PAA containers SGAF. Given a time series X of size n, we divide the time series into adjacent, non-intersecting windows along the time axis and extract the means of each container. This allows us to construct the smaller GAF matrix GSGAF \u00d7 SGAF. MTF requires that the time series in Q quantity containers be discredited in order to calculate the Q-Q-Markov transition matrix from which we then construct the raw MTF image Mn \u00d7 n. Before classification, we shrink the MTF image size to SMTF \u00d7 SMTF through the blurring core {1m2} m \u00d7 m, where m = d calculates nSMTF details from which we then construct the raw MTF image Mn \u00d7 n."}, {"heading": "5.2. Results and Discussion", "text": "In fact, it's not that it's about the way it's played out in the United States and Europe over the past few years, it's about the way it's developed in the United States. \"It's not about the way it's played out,\" he said. \"But it's not about the way it's played out in the United States.\" \"It's about the way it's played out in the United States.\" \"It's about the way it's played out,\" he said. \"It's about the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way it's played out, the way's played out, the way's played, the way's played out, the way's played out, the way's played out, the way's played, the way's been played, the way's been played, the way's been played, the way's been played, the way, the way's"}, {"heading": "5.3. Analysis of Learned Features", "text": "In this section we analyze the features and weights that we have learned through the Tiled CNNs to explain why our approach works. As said, the Mapping function of time series to GAF is surreal and the uncertainty in its inverted image comes from the ambiguity of Coins. The most important diagnoses of GAF, i.e., it allows us to reconstruct the original time series by using the sign of the time ignore (????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "6. Experiments on Trajectory Data", "text": "In this section, we describe the application of our approaches to classifying spatio-temporal trajectory data. Trajectory data are complex because motion patterns are often driven by unperceived targets and constrained by an unknown environment. To compare our results with other benchmark approaches, including the ground-breaking work from [39], we conduct experiments with two benchmark datasets: the Animal and Hurricane Track datasets (Figure 8). Both datasets have trajectories of different lengths. For the Animal dataset, the X and Y coordinates are extracted from animal movements observed in June 1995. It is divided into three classes by species: elk, deer and cattle, as shown in Figure 15. The number of trajectory categories (points) is 38 (734), 117 (433), two (433), two (2430) and three (1) points."}, {"heading": "6.1. Hilbert Space Filling Curves", "text": "We use Hilbert Space Filling Curves (SFC) to transform the orbit into time series while we study spatio-temporal information.Spatial fillings have been studied by mathematicians since the late 19th century, when the first graphic representation by David Hilbertin was proposed in 1891 [40]. Spatial fillings provide a linear representation from multidimensional space to 1-dimensional space. This representation can be thought of as a division of D-dimensional space into D-dimensional hypercube with a line running through each hypercube. In retrospect, the filling of curve approaches shows that they are able to maintain locality between objects in multidimensional space in linear space, and thus to perform various tasks such as clustering [41], high-dimensional outliers, discovery of 4 points, and the trajectory query [43] and classification [44]."}, {"heading": "6.2. Experiment Settings", "text": "The parameter settings are the same as for the previous experiments with UCR datasets (Section 5). The optimal SFC order is selected together with other parameters by 5-fold cross-validation of {3,4,5,6,7,8,9,10}. Note that both trajectory datasets have a fairly small sample size of different length. If the path length (and the time series length generated by SFC) is smaller than the image size S, we duplicate each point of the time series uniformly in time to stretch the sequence to length S. If the difference between the length of a time series and S is smaller than the original time series length, the interpolation strategy changes to random duplication instead of following the temporal order."}, {"heading": "6.3. Results and Discussion", "text": "In fact, it is such that most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "7. Conclusions and Future Work", "text": "We developed a pipeline to convert trajectory and time series data into novel representations, GAF and MTF images, and extracted high-level features using CNNs, which were then used for classification, and we demonstrated that our approach delivers competitive results compared to modern methods by scanning a relatively small parameter space. We found that GAFMTF multichannel images are scalable to a larger number of quasi-orthogonal features that provide more comprehensive images. Our analysis of high-level features learned from CNNs suggested that tiled CNNs function like multifrequency moving averages that benefit from the 2D time dependence preserved by the Gramian matrix. Important future work will include applying our method to vast amounts of data and searching in a fuller time parameter space to solve real-world problems."}, {"heading": "8. Author Biography", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.1. Author I", "text": "Zhiguang Wang earned his bachelor's degree in Mathematics and Applied Mathematics from Fudan University, Shanghai, China, in 2012, and then enrolled in the doctoral program. He received first prize at the National Mathematics Olympiad of China in Senior in 2007 and the NSF Travel Award for IJCAI in 2015. He is currently a doctoral student in the Department of Computer Science and Electrical Engineering at the University of Maryland Baltimore County. His research interests include artificial intelligence, machine learning theory, deep neural networks, nonconvex optimization with a focus on mathematical modeling, time series analysis, and pattern recognition in data streaming."}, {"heading": "8.2. Author II", "text": "Tim Oates is a professor of computer science at the University of Maryland Baltimore County. Prior to coming to UMBC in the fall of 2001, he spent a year as a postdoc in the artificial intelligence laboratory at the Massachusetts Institute of Technology. In 2004, Dr. Oates received a prestigious NSF CAREER Award. He is the author or co-author of more than 190 peer-reviewed papers and is a member of the Association for Computing Machinery and the Association for the Advancement of Artificial Intelligence. His research interests include pattern recognition in time series, grammatical inference, graph mining, statistical processing of natural language, robotics, and language acquisition."}], "references": [{"title": "Robust text-independent speaker identification using gaussian mixture speaker models", "author": ["D.A. Reynolds", "R.C. Rose"], "venue": "Speech and Audio Processing, 27  IEEE Transactions on 3 (1) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Maximum likelihood linear regression for speaker adaptation of continuous density hidden markov models", "author": ["C.J. Leggetter", "P.C. Woodland"], "venue": "Computer Speech & Language 9 (2) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural computation 18 (7) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Acoustic modeling using deep belief networks, Audio, Speech, and Language Processing, IEEE Transactions on", "author": ["A.-r. Mohamed", "G.E. Dahl", "G. Hinton"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "G", "author": ["G. Hinton", "L. Deng", "D. Yu"], "venue": "E. Dahl, A.-r. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath, et al., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups, Signal Processing Magazine, IEEE 29 (6) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "New types of deep neural network learning for speech recognition and related applications: An overview", "author": ["L. Deng", "G. Hinton", "B. Kingsbury"], "venue": "in: Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, IEEE", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "J", "author": ["L. Deng", "J. Li", "J.-T. Huang", "K. Yao", "D. Yu", "F. Seide", "M. Seltzer", "G. Zweig", "X. He"], "venue": "Williams, et al., Recent advances in deep learning for speech research at microsoft, in: Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, IEEE", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE 86 (11) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "Receptive fields", "author": ["D.H. Hubel", "T.N. Wiesel"], "venue": "binocular interaction and functional architecture in the cat\u2019s visual cortex, The Journal of physiology 160 (1) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1962}, {"title": "Face recognition: A convolutional neural-network approach", "author": ["S. Lawrence", "C.L. Giles", "A.C. Tsoi", "A.D. Back"], "venue": "Neural Networks, IEEE Transactions on 8 (1) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "in: Advances in neural information processing systems", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Convolutional networks and applications in vision", "author": ["Y. LeCun", "K. Kavukcuoglu", "C. Farabet"], "venue": "in: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on, IEEE", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P.-A. Manzagol", "P. Vincent", "S. Bengio"], "venue": "The Journal of Machine Learning Research 11 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning convolutional feature hierarchies for visual recognition", "author": ["K. Kavukcuoglu", "P. Sermanet", "Y.-L. Boureau", "K. Gregor", "M. Mathieu", "Y.L. Cun"], "venue": "in: Advances in neural information processing systems", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Tiled convolutional neural networks", "author": ["J. Ngiam", "Z. Chen", "D. Chia", "P.W. Koh", "Q.V. Le", "A.Y. Ng"], "venue": "in: Advances in Neural Information Processing Systems", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition, in: Acoustics", "author": ["O. Abdel-Hamid", "A.-r. Mohamed", "H. Jiang", "G. Penn"], "venue": "Speech and Signal Processing (ICASSP),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion", "author": ["L. Deng", "O. Abdel-Hamid", "D. Yu"], "venue": "in: Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, IEEE", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "D", "author": ["O. Abdel-Hamid", "L. Deng"], "venue": "Yu, Exploring convolutional neural network structures and optimization techniques for speech recognition., in: INTER- SPEECH", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Time series classification using multi-channels deep convolutional neural networks", "author": ["Y. Zheng", "Q. Liu", "E. Chen", "Y. Ge", "J.L. Zhao"], "venue": "in: Web-Age Information Management, Springer", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Perceptual linear predictive (plp) analysis of speech", "author": ["H. Hermansky"], "venue": "the Journal of the Acoustical Society of America 87 (4) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1990}, {"title": "Exploiting representational diversity for time series classification", "author": ["T. Oates", "C.F. Mackenzie", "D.M. Stein", "L.G. Stansbury", "J. Dubose", "B. Aarabi", "P.F. Hu"], "venue": "in: Machine Learning and Applications (ICMLA), 2012 11th International Conference on, Vol. 2, IEEE", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient similarity search in sequence databases", "author": ["R. Agrawal", "C. Faloutsos", "A. Swami"], "venue": "Springer", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1993}, {"title": "Haar wavelets for efficient similarity search of time-series: with and without time warping", "author": ["F.-P. Chan", "A.-C. Fu", "C. Yu"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 15 (3) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Efficiently supporting ad hoc queries in large datasets of time sequences", "author": ["F. Korn", "H.V. Jagadish", "C. Faloutsos"], "venue": "ACM SIGMOD Record 26 (2) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1997}, {"title": "Distance measures for effective clustering of arima time-series", "author": ["K. Kalpakis", "D. Gada", "V. Puttagunta"], "venue": "in: Data Mining, 2001. ICDM 2001, Proceedings IEEE International Conference on, IEEE", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "A hidden markov model-based approach to sequential data clustering", "author": ["A. Panuccio", "M. Bicego", "V. Murino"], "venue": "in: Structural, Syntactic, and Statistical Pattern Recognition, Springer", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2002}, {"title": "Recurrence networksa novel paradigm for nonlinear time series analysis", "author": ["R.V. Donner", "Y. Zou", "J.F. Donges", "N. Marwan", "J. Kurths"], "venue": "New Journal of Physics 12 (3) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Recurrence-based time series analysis by means of complex network methods", "author": ["R.V. Donner", "M. Small", "J.F. Donges", "N. Marwan", "Y. Zou", "R. Xiang", "J. Kurths"], "venue": "International Journal of Bifurcation and Chaos 21 (04) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Time series classification using compression distance of recurrence plots", "author": ["D.F. Silva", "V. Souza", "M. De", "G.E. Batista"], "venue": "in: Data Mining (ICDM), 2013 IEEE 13th International Conference on, IEEE", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Duality between time series and networks", "author": ["A.S. Campanharo", "M.I. Sirer", "R.D. Malmgren", "F.M. Ramos", "L.A.N. Amaral"], "venue": "PloS one 6 (8) ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Scaling up dynamic time warping for datamining applications", "author": ["E.J. Keogh", "M.J. Pazzani"], "venue": "in: Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, ACM", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2000}, {"title": "H", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici"], "venue": "Larochelle, et al., Greedy layerwise training of deep networks, Advances in neural information processing systems 19 ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Rotation-invariant similarity in time series using bag-of-patterns representation", "author": ["J. Lin", "R. Khade", "Y. Li"], "venue": "Journal of Intelligent Information Systems 39 (2) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}, {"title": "Liblinear: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "The Journal of Machine Learning Research 9 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "Fast shapelets: A scalable algorithm for discovering time series shapelets", "author": ["T. Rakthanmanon", "E. Keogh"], "venue": "in: Proceedings of the thirteenth SIAM conference on data mining (SDM), SIAM", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Sax-vsm: Interpretable time series classification using sax and vector space model", "author": ["P. Senin", "S. Malinchik"], "venue": "in: Data Mining (ICDM), 2013 IEEE 13th International Conference on, IEEE", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Traclass: trajectory classification using hierarchical region-based and trajectory-based clustering", "author": ["J.-G. Lee", "J. Han", "X. Li", "H. Gonzalez"], "venue": "Proceedings of the VLDB Endowment 1 (1) ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "Ueber die stetige abbildung einer line auf ein fl\u00e4chenst\u00fcck", "author": ["D. Hilbert"], "venue": "Mathematische Annalen 38 (3) ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1891}, {"title": "Analysis of the clustering properties of the hilbert space-filling curve", "author": ["B. Moon", "H.V. Jagadish", "C. Faloutsos", "J.H. Saltz"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 13 (1) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2001}, {"title": "Outlier mining in large high-dimensional data sets", "author": ["F. Angiulli", "C. Pizzuti"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 17 (2) ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2005}, {"title": "Efficient maintenance of continuous queries for trajectories", "author": ["H. Ding", "G. Trajcevski", "P. Scheuermann"], "venue": "GeoInformatica 12 (3) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "Preventing\u201d overfitting\u201d of cross-validation data", "author": ["A.Y. Ng"], "venue": "in: ICML, Vol. 97", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1997}, {"title": "Automatic early stopping using cross validation: quantifying the criteria", "author": ["L. Prechelt"], "venue": "Neural Networks 11 (4) ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "Researchers have achieved success using combinations of HMMs with acoustic models based on Gaussian Mixture models (GMMs) [1, 2].", "startOffset": 122, "endOffset": 128}, {"referenceID": 1, "context": "Researchers have achieved success using combinations of HMMs with acoustic models based on Gaussian Mixture models (GMMs) [1, 2].", "startOffset": 122, "endOffset": 128}, {"referenceID": 2, "context": "Deep learning has become increasingly popular since the introduction of effective ways to train multiple hidden layers [3] and has been proposed as a replacement for GMMs to model acoustic data in speech recognition tasks [4].", "startOffset": 119, "endOffset": 122}, {"referenceID": 3, "context": "Deep learning has become increasingly popular since the introduction of effective ways to train multiple hidden layers [3] and has been proposed as a replacement for GMMs to model acoustic data in speech recognition tasks [4].", "startOffset": 222, "endOffset": 225}, {"referenceID": 4, "context": "These Deep Neural Network - Hidden Markov Model hybrid systems (DNN-HMM) achieved remarkable performance in a variety of speech recognition tasks [5, 6, 7].", "startOffset": 146, "endOffset": 155}, {"referenceID": 5, "context": "These Deep Neural Network - Hidden Markov Model hybrid systems (DNN-HMM) achieved remarkable performance in a variety of speech recognition tasks [5, 6, 7].", "startOffset": 146, "endOffset": 155}, {"referenceID": 6, "context": "These Deep Neural Network - Hidden Markov Model hybrid systems (DNN-HMM) achieved remarkable performance in a variety of speech recognition tasks [5, 6, 7].", "startOffset": 146, "endOffset": 155}, {"referenceID": 7, "context": "Another deep learning architecture used in computer vision is convolutional neural networks (CNNs) [8].", "startOffset": 99, "endOffset": 102}, {"referenceID": 8, "context": "CNNs exploit translational invariance within their structures by extracting features through receptive fields [9] and learn with weight sharing.", "startOffset": 110, "endOffset": 113}, {"referenceID": 9, "context": "CNNs are the state-of-the-art approach in various image recognition and computer vision tasks [10, 11, 12].", "startOffset": 94, "endOffset": 106}, {"referenceID": 10, "context": "CNNs are the state-of-the-art approach in various image recognition and computer vision tasks [10, 11, 12].", "startOffset": 94, "endOffset": 106}, {"referenceID": 11, "context": "CNNs are the state-of-the-art approach in various image recognition and computer vision tasks [10, 11, 12].", "startOffset": 94, "endOffset": 106}, {"referenceID": 12, "context": "Since unsupervised pretraining has been shown to improve performance [13], sparse coding and Topographic Independent Component Analysis (TICA) are integrated as unsupervised pretraining approaches to learn more diverse features with complex invariances [14, 15].", "startOffset": 69, "endOffset": 73}, {"referenceID": 13, "context": "Since unsupervised pretraining has been shown to improve performance [13], sparse coding and Topographic Independent Component Analysis (TICA) are integrated as unsupervised pretraining approaches to learn more diverse features with complex invariances [14, 15].", "startOffset": 253, "endOffset": 261}, {"referenceID": 14, "context": "Since unsupervised pretraining has been shown to improve performance [13], sparse coding and Topographic Independent Component Analysis (TICA) are integrated as unsupervised pretraining approaches to learn more diverse features with complex invariances [14, 15].", "startOffset": 253, "endOffset": 261}, {"referenceID": 15, "context": "Recently, CNNs have been shown to further improve hybrid model performance by applying convolution and max-pooling in the frequency domain on the TIMIT phone recognition task [17].", "startOffset": 175, "endOffset": 179}, {"referenceID": 16, "context": "A heterogeneous pooling approach proved to be beneficial for training acoustic invariance [18].", "startOffset": 90, "endOffset": 94}, {"referenceID": 17, "context": "Further exploration with limited weight sharing and a weighted softmax pooling layer has been proposed to optimize CNN structures for speech recognition tasks [19].", "startOffset": 159, "endOffset": 163}, {"referenceID": 18, "context": "[20] explores supervised feature learning with CNNs to classify multi-channel time series with two datasets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Unlike speech recognition systems in which acoustic/speech data input is typically represented by concatenating Mel-frequency cepstral coefficients (MFCCs) or perceptual linear predictive coefficient (PLPs) [21], typical time series data are not likely to benefit from transformations applied to speech or acoustic data.", "startOffset": 207, "endOffset": 211}, {"referenceID": 14, "context": "We applied deep Convolutional Neural Networks with a pretraining stage that exploits local orthogonality by Topographic ICA [15] to \u201cvisually\u201d inspect and classify time series.", "startOffset": 124, "endOffset": 128}, {"referenceID": 21, "context": "In time series learning problems, non-data adaptive models, such as Discrete Fourier Transformation (DFT) [23], Discrete Wavelet Transformation (DWT) [24], and Discrete Cosine Transformation (DCT) [25], compute the transformation with an algorithm that is invariant with respect to the data to capture the intrinsic temporal correlation with the different basis functions.", "startOffset": 106, "endOffset": 110}, {"referenceID": 22, "context": "In time series learning problems, non-data adaptive models, such as Discrete Fourier Transformation (DFT) [23], Discrete Wavelet Transformation (DWT) [24], and Discrete Cosine Transformation (DCT) [25], compute the transformation with an algorithm that is invariant with respect to the data to capture the intrinsic temporal correlation with the different basis functions.", "startOffset": 150, "endOffset": 154}, {"referenceID": 23, "context": "In time series learning problems, non-data adaptive models, such as Discrete Fourier Transformation (DFT) [23], Discrete Wavelet Transformation (DWT) [24], and Discrete Cosine Transformation (DCT) [25], compute the transformation with an algorithm that is invariant with respect to the data to capture the intrinsic temporal correlation with the different basis functions.", "startOffset": 197, "endOffset": 201}, {"referenceID": 24, "context": "Meanwhile, researchers explored in the model-based approaches to model time series, such as Auto-Regressive Moving Average models (ARMA) [26] and Hidden Markov Models (HMMs) [27], in which the underlying data is assumed to fit a specific type of model to explicitly function the temporal patterns.", "startOffset": 137, "endOffset": 141}, {"referenceID": 25, "context": "Meanwhile, researchers explored in the model-based approaches to model time series, such as Auto-Regressive Moving Average models (ARMA) [26] and Hidden Markov Models (HMMs) [27], in which the underlying data is assumed to fit a specific type of model to explicitly function the temporal patterns.", "startOffset": 174, "endOffset": 178}, {"referenceID": 26, "context": "tems [28, 29].", "startOffset": 5, "endOffset": 13}, {"referenceID": 27, "context": "tems [28, 29].", "startOffset": 5, "endOffset": 13}, {"referenceID": 28, "context": "extended the recurrence plot paradigm for time series classification using compression distance [30].", "startOffset": 96, "endOffset": 100}, {"referenceID": 29, "context": "Another way to build a weighted adjacency matrix is extracting transition dynamics from the first order Markov matrix [31].", "startOffset": 118, "endOffset": 122}, {"referenceID": 29, "context": "Inspired by previous work on the duality between time series and complex networks [31], the main idea of the second framework, the Markov Transition Field (MTF), is to build the Markov matrix of quantile bins after discretization and encode the dynamic transition probability in a quasi-Gramian matrix.", "startOffset": 82, "endOffset": 86}, {"referenceID": 0, "context": ", xn} of n real-valued observations, we rescale X so that all values fall in the interval [\u22121, 1] or [0, 1] by:", "startOffset": 101, "endOffset": 107}, {"referenceID": 30, "context": "To reduce the size of the GAF images, we apply Piecewise Aggregate Approximation [32] to smooth the time series while keeping the overall trends.", "startOffset": 81, "endOffset": 85}, {"referenceID": 29, "context": "We propose a framework that is similar to [31] for encoding dynamical transition statistics.", "startOffset": 42, "endOffset": 46}, {"referenceID": 14, "context": "Tiled Convolutional Neural Networks [15] are a variation of Convolutional Neural Networks.", "startOffset": 36, "endOffset": 40}, {"referenceID": 14, "context": "Algorithm 1 Unsupervised pretraining with TICA [15] Require: {x}t=1, v, s,W, V as input Ensure: W as output repeat f = \u2211T t=1 \u2211m i=1 \u221a\u2211m k=1 Vik( \u2211n j=1Wkjx (t) j ) 2, g = f old \u2202W , f new = +\u221e, \u03b1 = 1 while f > f do W = W \u2212 \u03b1g W = Localize(W, s) W = tieWeights(W, k) W = orthogonalizeLocalRF (W) W = tieWeights(W, k) f = \u2211T t=1 \u2211m i=1 \u221a\u2211m k=1 Vik( \u2211n j=1Wkjx (t) j ) 2", "startOffset": 47, "endOffset": 51}, {"referenceID": 31, "context": "Other unsupervised feature learning algorithms such as RBMs and autoencoders [33] require more parameter tuning, especially during optimization.", "startOffset": 77, "endOffset": 81}, {"referenceID": 14, "context": "In [15], the authors empirically demonstrate that tiled CNNs perform well with limited labeled data because the partial weight tying requires fewer parameters and reduces the need for a large amount of labeled data.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "Our experimental settings follow the default deep network structures and parameters in [15].", "startOffset": 87, "endOffset": 91}, {"referenceID": 32, "context": "1 with the state-of-the-art SAX-BoP approach [35, 22].", "startOffset": 45, "endOffset": 53}, {"referenceID": 20, "context": "1 with the state-of-the-art SAX-BoP approach [35, 22].", "startOffset": 45, "endOffset": 53}, {"referenceID": 33, "context": "At the last layer of the Tiled CNN, we use a linear soft margin SVM [36] and select C by 5-fold cross validation over {10\u22124, 10\u22123, .", "startOffset": 68, "endOffset": 72}, {"referenceID": 34, "context": "Table 3 compares the classification error rate of our approach with previously published results of five competing methods: two state-of-the-art 1NN classifiers based on Euclidean distance and DTW, the recently proposed Fast-Shapelets based classifier [37], the classifier based on Bag-of-Patterns (BoP) [35, 22] and the most recent SAX-VSM approach [38].", "startOffset": 252, "endOffset": 256}, {"referenceID": 32, "context": "Table 3 compares the classification error rate of our approach with previously published results of five competing methods: two state-of-the-art 1NN classifiers based on Euclidean distance and DTW, the recently proposed Fast-Shapelets based classifier [37], the classifier based on Bag-of-Patterns (BoP) [35, 22] and the most recent SAX-VSM approach [38].", "startOffset": 304, "endOffset": 312}, {"referenceID": 20, "context": "Table 3 compares the classification error rate of our approach with previously published results of five competing methods: two state-of-the-art 1NN classifiers based on Euclidean distance and DTW, the recently proposed Fast-Shapelets based classifier [37], the classifier based on Bag-of-Patterns (BoP) [35, 22] and the most recent SAX-VSM approach [38].", "startOffset": 304, "endOffset": 312}, {"referenceID": 35, "context": "Table 3 compares the classification error rate of our approach with previously published results of five competing methods: two state-of-the-art 1NN classifiers based on Euclidean distance and DTW, the recently proposed Fast-Shapelets based classifier [37], the classifier based on Bag-of-Patterns (BoP) [35, 22] and the most recent SAX-VSM approach [38].", "startOffset": 350, "endOffset": 354}, {"referenceID": 36, "context": "To compare our results with other benchmark approaches including the seminal work from [39], we run experiments on two benchmark datasets, the animal movement dataset (Animal) and the hurricane track dataset (Hurricane) (Figure 8).", "startOffset": 87, "endOffset": 91}, {"referenceID": 36, "context": "Figure 8: Overview of the trajectory and the RB-TB features [39] learnt in (a).", "startOffset": 60, "endOffset": 64}, {"referenceID": 37, "context": "in 1891 [40].", "startOffset": 8, "endOffset": 12}, {"referenceID": 38, "context": "Recently, filling curve based approaches have shown to be able to preserve locality between objects in the multidimensional space in the linear space, and thus have been applied to different tasks like clustering [41], high dimensional outlier detection [42], and trajectory query [43] and classification [44].", "startOffset": 213, "endOffset": 217}, {"referenceID": 39, "context": "Recently, filling curve based approaches have shown to be able to preserve locality between objects in the multidimensional space in the linear space, and thus have been applied to different tasks like clustering [41], high dimensional outlier detection [42], and trajectory query [43] and classification [44].", "startOffset": 254, "endOffset": 258}, {"referenceID": 40, "context": "Recently, filling curve based approaches have shown to be able to preserve locality between objects in the multidimensional space in the linear space, and thus have been applied to different tasks like clustering [41], high dimensional outlier detection [42], and trajectory query [43] and classification [44].", "startOffset": 281, "endOffset": 285}, {"referenceID": 2, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 1, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 1, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 1, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 6, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 6, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 7, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 10, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 12, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 12, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 1, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 0, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 0, "context": "The final time series generated after SFC transformation is T = [0, 3, 2, 2, 2, 7, 7, 8, 11, 13, 13, 2, 1, 1].", "startOffset": 64, "endOffset": 109}, {"referenceID": 36, "context": "Both \u2019Animal\u2019 and \u2019Hurricane\u2019 datasets have been used in previous research [39, 44] to achieve state-of-the-art classification accuracy.", "startOffset": 75, "endOffset": 83}, {"referenceID": 41, "context": "Previous work has discussed overfitting during cross validation and proposed potential techniques to address this problem [45, 46].", "startOffset": 122, "endOffset": 130}, {"referenceID": 42, "context": "Previous work has discussed overfitting during cross validation and proposed potential techniques to address this problem [45, 46].", "startOffset": 122, "endOffset": 130}], "year": 2015, "abstractText": "We propose an off-line approach to explicitly encode temporal patterns spatially as different types of images, namely, Gramian Angular Fields and Markov Transition Fields. This enables the use of techniques from computer vision for feature learning and classification. We used Tiled Convolutional Neural Networks to learn high-level features from individual GAF, MTF, and GAF-MTF images on 12 benchmark time series datasets and two real spatial-temporal trajectory datasets. The classification results of our approach are competitive with state-of-the-art approaches on both types of data. An analysis of the features and weights learned by the CNNs explains why the approach works.", "creator": "LaTeX with hyperref package"}}}