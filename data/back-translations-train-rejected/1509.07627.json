{"id": "1509.07627", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Sep-2015", "title": "Feature Evaluation of Deep Convolutional Neural Networks for Object Recognition and Detection", "abstract": "In this paper, we evaluate convolutional neural network (CNN) features using the AlexNet architecture and very deep convolutional network (VGGNet) architecture. To date, most CNN researchers have employed the last layers before output, which were extracted from the fully connected feature layers. However, since it is unlikely that feature representation effectiveness is dependent on the problem, this study evaluates additional convolutional layers that are adjacent to fully connected layers, in addition to executing simple tuning for feature concatenation (e.g., layer 3 + layer 5 + layer 7) and transformation, using tools such as principal component analysis. In our experiments, we carried out detection and classification tasks using the Caltech 101 and Daimler Pedestrian Benchmark Datasets.", "histories": [["v1", "Fri, 25 Sep 2015 08:26:53 GMT  (1785kb)", "http://arxiv.org/abs/1509.07627v1", "5 pages, 3 figures"]], "COMMENTS": "5 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.MM", "authors": ["hirokatsu kataoka", "kenji iwata", "yutaka satoh"], "accepted": false, "id": "1509.07627"}, "pdf": {"name": "1509.07627.pdf", "metadata": {"source": "CRF", "title": "Feature Evaluation of Deep Convolutional Neural Networks for Object Recognition and Detection", "authors": ["Hirokatsu Kataoka", "Kenji Iwata", "Yutaka Satoh"], "emails": ["hirokatsu.kataoka@aist.go.jp,"], "sections": [{"heading": null, "text": "ar Xiv: 150 9.07 627v 1 [cs.C V] 25 SE"}, {"heading": "1. Introduction", "text": "In recent years, Convolutionary Neural Networks (CNNs) have improved markedly from the point of view of the network architectures required to detect accuracy and reduce processing costs. [15] Currently, CNNs are mainly used to help users understand objects and scenes in an image. However, in our study, we applied a CNN to an ImageNet dataset containing over 1.4 million images and 1,000 object categories [13]. Using such a large-format dataset allows us to model a variety of object identifiers. However, by using the pre-trained ImageNet dataset model, we have found that CNN is able to represent significantly more effective feature variations. Donahue et al work on feature extraction."}, {"heading": "2. Related works", "text": "In the time since the Neocognitron was first proposed by Fukushima [3], neuron-based detection has become one of the most widely used neural network architectures. Following this study, the LeNet-5 [10] Neocognitron model has added a baseline to CNNs to build a more significant model. Current network architectures include standard structures such as several fully interconnected layers, while current challengers use pre-formed [7], drop-outs [8] and reflected linear units (ReLU) [12] as improved learning models. The most outstanding computer vision result was achieved by AlexNet in the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC2012), which is a leader in image recognition with 1,000 classes [9]. AlexNet enabled the number of layers in network architectures to increase (Krizhevsky, which includes a panel-rich model."}, {"heading": "3. Feature settings and representations", "text": "In this article, we evaluate two types of deep-learning features. Figure 1 shows the architectures of AlexNet [9] and VGGNet [16]. We believe that while the evaluation itself is very important, particular attention must be paid to tunings such as concatenation and feature transformation. Basically, deep-learning architectures are based on their approaches. Feature setting. We start with the extraction of the middle and lower layers. The layers 3-7 of AlexNet and VGGNet are shown in Figure 1. Next, we extract each max-pooling layer (layer 3-5) and the last two fully connected layers (layer 6 and 7) in VGGGNet.Concatenation and Transformation. Next, we link adjacent or single-level layers such as layer-3,4,5 and layer-3,5,7. For feature transformation, we simply apply PCA, which is set to 1,500 dimensions in this experiment."}, {"heading": "4. Experiments", "text": "In this section, we discuss our experiments performed with the Daimler Pedestrian Benchmark [11] and the Caltech 101 [2] dataset. Figure 2 and 3 show the results of our in-depth CNN feature evaluations of the Daimler and Caltech 101 datasets. Figures also show VGGNet, AlexNet and their compressed features with PCA (VGGNet (PCA) and AlexNet (PCA), respectively. In the Daimler dataset experiment, we found that the VGNet (PCA) layers 5 and 4 had the best performance rates with 99.35% and 98.92%, respectively. In addition, we found that PCA transforms low-dimensional features and feature vectors with better rates than the original features. The VGGNet layer 5 (98.91%) and layer 4 (98.81%) each have + 0.44% and + 0.11% improved feature vectors, respectively. When AlexNet is used, the layers show the best results of 95 and 97.3 and 971%, respectively, for the peak rates of Gtech, respectively."}, {"heading": "345 78.13 77.95", "text": "The results above show that fully connected layers or max pooling layers located near fully connected layers do not always deliver the highest performance in detection and detection tasks. The main difference between AlexNet and VGGNet is the architectural depth. In addition, VGGNet assigns very small 3 x 3 revolutionary cores to the 7 x 7 (Conv 1), 5 x 5 (Conv 2) and 3 x 3 (other) cores in AlexNet. The settings break the functionality representation. The classification results of the concatenated vectors show in Tables 1 and 2. Here you can see that the concatenation of VGGNet-5.7 (other) cores in AlexNet represents the highest rates of the calendar layer, that the calendar results of layer 9101 and layer Vasch-5.5 are the highest data sets."}, {"heading": "5. Conclusion", "text": "In this work, we examined two different Convolutionary Neural Network Architectures (CNN) AlexNet and VGGNet. Convolutionary features of layers 3-7 were performed on the Daimler Pedestrian Benchmark and the Cal-tech 101 datasets, and then we attempted to implement function concatenation and PCA transformation. Our experimental results show that the fully connected layers were not always better suited for detection tasks. Furthermore, experiments with the Daimler and Caltech 101 datasets showed that layer 5 tends to provide the highest level of accuracy, and that concatenation of sinuous and fully connected layers improves detection performance."}], "references": [{"title": "Decaf:a deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Learning generative visual models from few training examples: an incremental bayesian approach tested on 101 object categories", "author": ["L. Fei-Fei", "R. Fergus", "P. Perona"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition Workshop on Generative-Model Based Vision (CVPRW),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift", "author": ["K. Fukushima"], "venue": "in position,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1980}, {"title": "Regionbased convolutional networks for accurate object detection and segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Convolutional neural networks at constrained time cost", "author": ["K. He", "J. Sun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural Computation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Computation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1989}, {"title": "Daimler mono pedestrian classification benchmark dataset: An experimental study on pedestrian", "author": ["S. Munder", "D.M. Gavrila"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Imagenet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Deep learning in neural networks: An overveiw", "author": ["J. Schmidhuber"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "International Conference on Learning Representation (ICLR),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Selective search for object recognition", "author": ["J.R.R. Uijlings", "K.E.A. van de Sande", "T. Gevers", "A.W.M. Smeulders"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}], "referenceMentions": [{"referenceID": 8, "context": "In this paper, we evaluate convolutional neural network (CNN) features using the AlexNet architecture developed by [9] and very deep convolutional network (VGGNet) architecture developed by [16].", "startOffset": 115, "endOffset": 118}, {"referenceID": 15, "context": "In this paper, we evaluate convolutional neural network (CNN) features using the AlexNet architecture developed by [9] and very deep convolutional network (VGGNet) architecture developed by [16].", "startOffset": 190, "endOffset": 194}, {"referenceID": 14, "context": "Over the past few years, convolutional neural networks (CNNs) have significantly improved from the standpoint of the network architectures needed to facilitate recognition accuracy and to reduce processing costs [15].", "startOffset": 212, "endOffset": 216}, {"referenceID": 12, "context": "4 million images and 1,000 object categories [13].", "startOffset": 45, "endOffset": 49}, {"referenceID": 0, "context": "employed CNN features as a feature vector by combining those features with a support vector machine (SVM) classifier [1], while other researchers have evaluated and visualized CNN features with an eight-layer AlexNet architecture [9].", "startOffset": 117, "endOffset": 120}, {"referenceID": 8, "context": "employed CNN features as a feature vector by combining those features with a support vector machine (SVM) classifier [1], while other researchers have evaluated and visualized CNN features with an eight-layer AlexNet architecture [9].", "startOffset": 230, "endOffset": 233}, {"referenceID": 15, "context": "More recent architectures utilize deep structures, such as the very deep convolutional network (VGGNet) [16] and GoogLeNet [17], which were developed by Oxford University\u2019s Visual Geometry Group and Google Inc.", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "More recent architectures utilize deep structures, such as the very deep convolutional network (VGGNet) [16] and GoogLeNet [17], which were developed by Oxford University\u2019s Visual Geometry Group and Google Inc.", "startOffset": 123, "endOffset": 127}, {"referenceID": 4, "context": "[5], the most important CNN feature is deep architecture.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": ", [6, 14]).", "startOffset": 2, "endOffset": 9}, {"referenceID": 13, "context": ", [6, 14]).", "startOffset": 2, "endOffset": 9}, {"referenceID": 2, "context": "In the time since the neocognitron was first proposed by Fukushima [3], neuron-based recognition has become one of the most commonly used neural network architectures.", "startOffset": 67, "endOffset": 70}, {"referenceID": 9, "context": "Following that study, the LeNet-5 [10] neocognitron model added a baseline to CNNs in order to create a more significant model.", "startOffset": 34, "endOffset": 38}, {"referenceID": 6, "context": "Current network architectures include standard structures such as multiple fully connected layers, while recent challengers employ pre-trained [7], dropout [8], and rectified linear units (ReLU) [12] as improved learning models.", "startOffset": 143, "endOffset": 146}, {"referenceID": 7, "context": "Current network architectures include standard structures such as multiple fully connected layers, while recent challengers employ pre-trained [7], dropout [8], and rectified linear units (ReLU) [12] as improved learning models.", "startOffset": 156, "endOffset": 159}, {"referenceID": 11, "context": "Current network architectures include standard structures such as multiple fully connected layers, while recent challengers employ pre-trained [7], dropout [8], and rectified linear units (ReLU) [12] as improved learning models.", "startOffset": 195, "endOffset": 199}, {"referenceID": 8, "context": "The most outstanding computer vision result was obtained by AlexNet in the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC2012), which remains the image recognition leader, with 1,000 classes [9].", "startOffset": 207, "endOffset": 210}, {"referenceID": 15, "context": "More recent variations, such as the 16- or 19-layer VGGNet [16], and the 22-layer GoogLeNet [17] models, have even deeper architectures.", "startOffset": 59, "endOffset": 63}, {"referenceID": 16, "context": "More recent variations, such as the 16- or 19-layer VGGNet [16], and the 22-layer GoogLeNet [17] models, have even deeper architectures.", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "These deeper models outperform conventional models on the ILSVRC dataset [13].", "startOffset": 73, "endOffset": 77}, {"referenceID": 3, "context": "[4].", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "Those authors adopted selective search [18] as an object proposal approach and VGGNet for the CNN architecture.", "startOffset": 39, "endOffset": 43}, {"referenceID": 8, "context": "Figure 1 shows the architectures of AlexNet [9] and VGGNet [16].", "startOffset": 44, "endOffset": 47}, {"referenceID": 15, "context": "Figure 1 shows the architectures of AlexNet [9] and VGGNet [16].", "startOffset": 59, "endOffset": 63}, {"referenceID": 0, "context": "The parameters are based on DeCAF [1].", "startOffset": 34, "endOffset": 37}, {"referenceID": 10, "context": "In this section, we discuss our experiments conducted using the Daimler pedestrian benchmark [11] and Caltech 101 [2] Datasets.", "startOffset": 93, "endOffset": 97}, {"referenceID": 1, "context": "In this section, we discuss our experiments conducted using the Daimler pedestrian benchmark [11] and Caltech 101 [2] Datasets.", "startOffset": 114, "endOffset": 117}], "year": 2015, "abstractText": "In this paper, we evaluate convolutional neural network (CNN) features using the AlexNet architecture developed by [9] and very deep convolutional network (VGGNet) architecture developed by [16]. To date, most CNN researchers have employed the last layers before output, which were extracted from the fully connected feature layers. However, since it is unlikely that feature representation effectiveness is dependent on the problem, this study evaluates additional convolutional layers that are adjacent to fully connected layers, in addition to executing simple tuning for feature concatenation (e.g., layer 3 + layer 5 + layer 7) and transformation, using tools such as principal component analysis. In our experiments, we carried out detection and classification tasks using the Caltech 101 and Daimler Pedestrian Benchmark Datasets.", "creator": "LaTeX with hyperref package"}}}