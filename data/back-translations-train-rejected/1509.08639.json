{"id": "1509.08639", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2015", "title": "Tuned and GPU-accelerated parallel data mining from comparable corpora", "abstract": "The multilingual nature of the world makes translation a crucial requirement today. Parallel dictionaries constructed by humans are a widely-available resource, but they are limited and do not provide enough coverage for good quality translation purposes, due to out-of-vocabulary words and neologisms. This motivates the use of statistical translation systems, which are unfortunately dependent on the quantity and quality of training data. Such has a very limited availability especially for some languages and very narrow text domains. Is this research we present our improvements to Yalign mining methodology by reimplementing the comparison algorithm, introducing a tuning scripts and by improving performance using GPU computing acceleration. The experiments are conducted on various text domains and bi-data is extracted from the Wikipedia dumps.", "histories": [["v1", "Tue, 29 Sep 2015 08:44:14 GMT  (768kb)", "http://arxiv.org/abs/1509.08639v1", "Machine translation, comparable corpora, Machine learning, NLP, Knowledge-free learning, Unsupervised bi-lingual data mining"]], "COMMENTS": "Machine translation, comparable corpora, Machine learning, NLP, Knowledge-free learning, Unsupervised bi-lingual data mining", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.DS", "authors": ["krzysztof wo{\\l}k", "krzysztof marasek"], "accepted": false, "id": "1509.08639"}, "pdf": {"name": "1509.08639.pdf", "metadata": {"source": "CRF", "title": "Tuned and GPU-accelerated parallel data mining from comparable corpora", "authors": ["Krzysztof Wo\u0142k", "Krzysztof Marasek"], "emails": ["kwolk@pja.edu.pl"], "sections": [{"heading": null, "text": "Parallel dictionaries created by humans are a diversified resource, but they are limited and do not provide enough coverage for high-quality translation purposes due to words not present in vocabulary and neologisms. This motivates the use of statistical translation systems, which unfortunately depend on the quantity and quality of training data. This has a very limited availability especially for some languages and very narrow text areas. If this is research, we present our improvements to the mining methodology of Yalign by reimplementing the comparison algorithm, introducing a tuning script and improving performance using GPU computing acceleration. Experiments are conducted on different text domains and bi-data are extracted from the Wikipedia dumps. Keywords: machine translation, comparable corpora, machine learning, NLP, knowledge-free learning."}, {"heading": "1 Introduction", "text": "The aim of this study is to create parallel and comparable corpora. This work improves SMT quality by processing and filtering parallel corpora and by extracting additional data from the resulting comparable corpora. To enrich the language resources of SMT systems, various adaptation and interpolation techniques are applied to the processed data. SMT systems were evaluated using random samples of parallel data using automated algorithms to evaluate the quality and potential applicability of the results of SMT systems [1]. However, for experiments, the Moses Statistical Machine Translation Toolkit software and related tools and unique implementations of processing scripts for the Polish language are used. Furthermore, the multi-pronged implementation of the GIZA + + tool is used to align models with parallel data and perform their symmetry at the phrase level."}, {"heading": "2 State of the art", "text": "The authors suggest two different approaches: the first idea is to use an online translation system to translate the Dutch Wikipedia pages into English, and they try to compare the original EN pages with the translated ones; the idea, although interesting, seems to be unworkable, and it presents a chicken-or-egg problem generated by the Wikipedia titles, and they try to compare the original EN pages with the translated ones; and the second method is that the authors return numerous, loud sentences."}, {"heading": "3 Parallel data mining", "text": "For the data mining experiments, the range of TED lectures prepared for the evaluation campaign IWSLT 20141 by FBK2 was selected, which is very extensive and covers many unrelated topics [9]. Narrower ranges were also selected; the first corpus consisting of documents from the European Medicines Agency (EMEA) [10]; the second corpus was taken from the deliberations of the European Parliament (EUP) by Philipp Koehn (University of Edinburgh) [11]; and experiments on the Basic Travel Expression Corpus (BTEC), tourism-related judgments [12]; and finally, a large corpus was used by the website OpenSubtitles.org as an example of human dialogues. Table 1 provides details of the number of unique words (WORDS) and their forms, as well as the number of bilingual sentence pairs (PAIRS)."}, {"heading": "4 Yalign and improvements", "text": "This means that the ability to create parallel corpora from sources such as translated documents and the Web is not able to accomplish large-scale parallel data retrieval; the standard implementation accepts plain text or web links that are necessary to meet the requirements of two selected languages. [2] This means that the tool is not computationally feasible. [3] The standard implementation accepts plain text or web links that are necessary to meet the requirements of two selected languages. [4] In addition, the Yalign software is unilaterally feasible. To improve performance, the Yalign solution must be linked to articles from the database."}, {"heading": "5 Evaluation of obtained comparable corpora", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "7 Conclusions", "text": "The results for SMT systems, which are based only on mined data, are not very surprising. Firstly, they confirm the quality and high level of parallelism of the corpora. This can be inferred from the translation quality, especially for the TED data set. However, only two BLEU scoring anomalies were observed when comparing systems that were trained strictly on Indomain (TED) data and data for EN on PL translation were mined. It also seems reasonable that the best SMT scores were achieved on TED data. This data set is the most similar to Wikipedia articles and overlaps with them on many topics. Furthermore, the Yalign classifier, which was trained on the TED data set, shows that most parallel sentences were recognized. The results show that the METEOR metric, in some cases, increases when the other metrics decrease. The most likely explanation for this is that other metrics are not related to these topics, but to a lack of metrics in Wikipedia only, compared to a correlation to both."}], "references": [{"title": "Alignment of the Polish-English Parallel Text for a Statistical Machine Translation.\", Computer Technology and Application 4, Publisher: David Publishing, ISSN:1934-7332 (Print)", "author": ["K. Wo\u0142k", "K. Marasek"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Finding similar sentences across multiple languages in Wikipedia,", "author": ["S.F. Adafree", "M. deRijke"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Method for building sentence-aligned corpus from Wikipedia,", "author": ["K. Yasuda", "E. Sumita"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Extracting bilingual words pairs from Wikipedia,", "author": ["F.M. Tyer", "J.A. Pienaar"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Extracting parallel sentences from comparable corpora using document level alignment,", "author": ["J. Smith", "C. Quirk", "K. Toutanova"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Automatic building and using parallel resources for SMT from comparable corpora,", "author": ["S. Pal", "P. Pakray", "S.K. Naskar"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "A light way to collect comparable corpora from the Web.\" LREC", "author": ["A. Aker", "E. Kanoulas", "R.J. Gaizauskas"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "WIT3: Web inventory of transcribed and translated talks,", "author": ["M Cettolo", "C. Girardi", "M. Federico"], "venue": "In Proc. of EAMT,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "News from OPUS \u2014 A collection of multilingual parallel corpora with tools and interfaces.,", "author": ["J. Tiedemann"], "venue": "Recent Advances in Natural Language Processing (vol V),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Parallel data, tools and interfaces in OPUS.\u201d", "author": ["J. Tiedemann"], "venue": "In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "TED Polish-to-English translation system for the IWSLT 2012", "author": ["K. Marasek"], "venue": "Proceedings of the 9th International Workshop on Spoken Language Translation IWSLT 2012,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Statistical machine translation.,", "author": ["P. Koehn"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Finding shortest paths on real road networks: the case for A*", "author": ["W. Zeng", "R.L. Church"], "venue": "International Journal of Geographical Information Science", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Bioinformatics inspired algorithm for stereo correspondence", "author": ["R. Dieny", "J. Thevenon", "J. Martinez-del-Rincon", "J.-C. Nebel"], "venue": "International Conference on Computer Vision Theory and Applications,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "A GPU Implementation of Needleman-Wunsch, Specifically for use in the Program PyroNoise", "author": ["R. Roessler"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "performed on random samples of parallel data using automated algorithms to evaluate the quality and potential usability of the SMT systems\u2019 output [1].", "startOffset": 147, "endOffset": 150}, {"referenceID": 0, "context": "In the case of parallel models, Moore-Levis Filtering is used, while singlelanguage models are linearly interpolated [1].", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": "An interesting idea for mining parallel data from Wikipedia was described in [3].", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "Yasuda and Sumita [4] proposed a MT bootstrapping framework based on statistics that generate a sentence-aligned corpus.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "Interwiki links were leveraged by the approach of Tyers and Pienaar in [5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "In [6] the authors attempt to advance the state of art in parallel data mining by modeling document-level alignment using the observation that parallel sentences can most likely be found in close proximity.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "The author of [7] introduces an automatic alignment method for parallel text fragments that uses a textual entailment technique and a phrase-based SMT system.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "The authors in [8] propose obtaining only title and some meta-information, such as publication date and time for each document, instead of its full contents to reduce the cost of building the comparable corpora.", "startOffset": 15, "endOffset": 18}, {"referenceID": 7, "context": "This domain is very wide and covers many unrelated subject areas [9].", "startOffset": 65, "endOffset": 68}, {"referenceID": 8, "context": "The first corpus is composed of documents from the European Medicines Agency (EMEA) [10].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "The second corpus was extracted from the proceedings of the European Parliament (EUP) by Philipp Koehn (University of Edinburgh) [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 10, "context": "In addition, experiments on the Basic Travel Expression Corpus (BTEC), tourism-related sentences, were also conducted [12].", "startOffset": 118, "endOffset": 122}, {"referenceID": 11, "context": "The monolingual part of the corpora was used as language model and was adapted for each corpus by using linear interpolation [13].", "startOffset": 125, "endOffset": 129}, {"referenceID": 11, "context": "National Institute of Standards & Technology (NIST) metric, the Metric for Evaluation of Translation with Explicit Ordering (METEOR) and Translation Error Rate (TER) [13].", "startOffset": 166, "endOffset": 170}, {"referenceID": 12, "context": "The A* search algorithm [14] was modified to use Needleman-Wunch [15], and a tuning script of mining parameters was developed.", "startOffset": 24, "endOffset": 28}, {"referenceID": 13, "context": "The A* search algorithm [14] was modified to use Needleman-Wunch [15], and a tuning script of mining parameters was developed.", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "The data mining approaches used were: directional (PL->EN classifier) mining (MONO), bi-directional (additional EN->PL classifier) mining (BI), bidirectional mining with Yalign using a GPU-accelerated version of the NeedlemanWunch [16] algorithm (NW), and mining using a NW version of Yalign that was tuned (NWT).", "startOffset": 231, "endOffset": 235}], "year": 2015, "abstractText": "The multilingual nature of the world makes translation a crucial requirement today. Parallel dictionaries constructed by humans are a widelyavailable resource, but they are limited and do not provide enough coverage for good quality translation purposes, due to out-of-vocabulary words and neologisms. This motivates the use of statistical translation systems, which are unfortunately dependent on the quantity and quality of training data. Such has a very limited availability especially for some languages and very narrow text domains. Is this research we present our improvements to Yalign\u2019s mining methodology by reimplementing the comparison algorithm, introducing a tuning scripts and by improving performance using GPU computing acceleration. The experiments are conducted on various text domains and bi-data is extracted from the Wikipedia dumps.", "creator": "Microsoft\u00ae Word 2013"}}}