{"id": "1510.00552", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Oct-2015", "title": "Exposing the Probabilistic Causal Structure of Discrimination", "abstract": "\\emph{Discrimination discovery} from data is an important task aiming at identifying patterns of illegal and unethical discriminatory activities against protected-by-law groups, e.g.,~ethnic minorities. While any legally-valid proof of discrimination requires evidence of causality, the state-of-the-art methods are essentially correlation-based, albeit, as it is well known, correlation does not imply causation.", "histories": [["v1", "Fri, 2 Oct 2015 10:31:29 GMT  (2385kb,D)", "https://arxiv.org/abs/1510.00552v1", null], ["v2", "Mon, 5 Oct 2015 08:38:16 GMT  (2385kb,D)", "http://arxiv.org/abs/1510.00552v2", null], ["v3", "Wed, 8 Mar 2017 21:10:10 GMT  (2385kb,D)", "http://arxiv.org/abs/1510.00552v3", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["francesco bonchi", "sara hajian", "bud mishra", "daniele ramazzotti"], "accepted": false, "id": "1510.00552"}, "pdf": {"name": "1510.00552.pdf", "metadata": {"source": "CRF", "title": "Exposing the Probabilistic Causal Structure of Discrimination", "authors": ["Francesco Bonchi", "Sara Hajian", "Bud Mishra", "Daniele Ramazzotti"], "emails": ["francesco.bonchi@isi.it", "sara.hajian@eurecat.org", "mishra@nyu.edu", "daniele.ramazzotti@disco.unimib.it"], "sections": [{"heading": null, "text": "In this paper, we take a principled causal approach to the data-mining problem of identifying discrimination in databases. In accordance with Suppes \"probabilistic causal theory, we define a method for extracting from a dataset of historical decision-making documents the causal structures that exist between the attributes in the data, resulting in a kind of limited Bayesian network that we call the Suppes-Bayes Causal Network (SBCN). Next, we develop a toolkit of methods based on random movements at the top of the SBCN and dealing with various anti-discrimination legal concepts, such as direct and indirect discrimination, group discrimination and individual discrimination, real demand and preferential. Our experiments with real datasets confirm the consequential power of our approach to all these different tasks."}, {"heading": "1. INTRODUCTION", "text": "In fact, it is so that most people are able to determine for themselves what they want and what they want. (...) It is not so that men are able to determine for themselves. (...) It is not so that they are able to determine for themselves. (...) It is not so that they can do it. (...) It is so. \"(...) It is so.\" (...) It is so. \"(...) It is so.\" (...) \"(...).\" (...). \"(...).\" (...). \"(...).\" (...). \"(.\" (.). \"(.).\" (.). \"(.).\" (.). \"(.\" (...). \"(.).\" (. \"(.).\" (.) \"(.\" (.). \"(.\" (.). \"(.)\" (. \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (. \").\" (. \"(.).\" (. \").\" (. \").\" (. \"(.).\" (.). \"(.).\" (. \").\" (.). \"(.\"). \"(.\" (.). \"(.).\" (. \").\" (.). \"(.).\" (. \").\" (.). \"(.\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).).\" (. \"(.).\" (.). \"(.).\" (. \"(.).).\" (. \"(.\" (.).). \"(.).\"). \"(.\"). \"(.\"). \"(.\"). \"(It.\" (. \"(.).\" (.).). \"(.).\" (. \"(.).\" (.).). \"(.).\" (.).). \"(.).\" (.).). \"(.\""}, {"heading": "2. RELATED WORK", "text": "In this paper, instead, we focus on the problem of discrimination in a dataset of historical records, and in the rest of this section, we present most related types of literature; the result is a set of classification rules that relate to local and overlapping niches; this model deals only with group discrimination (inductive part) and the ranking of rules based on discrimination (deductive part); the result is a set of classification rules that constitute possible discrimination; this model deals only with group discrimination. Luong et al. [16] uses the idea of situational discrimination [17] to detect individual discrimination."}, {"heading": "3. SUPPES-BAYES CAUSAL NETWORK", "text": "In order to investigate discrimination as a causal consequence problem, we use the criteria defined in the theories of probabilistic causality [6]. In particular, we follow [7], where Suppes proposed the concept of prima facie causality, which lies at the core of probabilistic causation. Definition 1 (probabilistic causality [7]) For all two events h and e, which each occur before their effect (temporal priority) and (ii) it must increase the probability of observing the effect (probability increase). Definition 1 (probabilistic causation [7]). For all two events h and e, which occur at times th and te, it is true that under the mild assumptions, the 0 < P (e) < 1, the event h is referred to as the prima facie cause of the event e, if it occurs before the effect and the cause, the probability of the effect is increased."}, {"heading": "3.1 Suppes\u2019 constraints", "text": "We start with an input relation table D, defined by a set of h categorical attributes, by providing only a portion of the analytical data. If sequential numerical attributes exist in D, we assume that they have been discredited to become categorical. From D, we derive D \u2032, a m \u00b7 s binary matrix that represents m Bernoulli variables of type < attribute = value > The first limitation, temporal priority, cannot simply be verified in the data, since we have no temporal information for the events. Especially in our context, the events for which we want to think about temporal priority are the Bernoulli variables < attribute = value >. The idea here is that income = low cannot be a cause of gender = female, since the time in which an individual's gender is determined is a causal condition."}, {"heading": "3.2 Network simplification", "text": "The conditions of soups are necessary, but not sufficient, to evaluate causality [28]: in particular, if the sample size is small, the model may have false positives (wrong causes) even after limiting the temporal priority and probability increase criteria of soups (aimed at removing false negatives). Consequently, although we expect all statistically relevant causal relationships to be modeled in G, we also expect some false ones. In our proposal, instead of other structural conditions used in various approaches to causality (see e.g. [6, 24, 25]), we are conducting a network simplification (i.e., we save the network by removing arcs) with a point-based approach, especially by relying on the Bayesian information criterion (BIC) as a regulated probability value [8]. We consider as inputs for this score the chart G \u00b2 and the dataset D \u00b2. Given these conditions, we choose the arcs that are E \u00b2."}, {"heading": "3.3 Confidence score", "text": "Using the reconstructed SBCN, we can also define the probable relationships between the individual events (nodes). As an example, let us assume that the nodes, each representing income = low and gender = female, are the only two direct causes (i.e., with arcs in the direction) of credit = refusal. In view of the SBCN, we can estimate the conditional probabilities for each node in the diagram, i.e., the probability of a loan = gender = female in the example by calculating the conditional probability only of the nodes that are directly connected to an Arc. To get an overview of the state-based methods, see [23], however, we expect to deal largely with complete data, i.e. for each directly connected node in the SBCN, we expect several observations of a possible combination of attribute = value. For this reason, we can simply estimate the node probabilities by counting the data."}, {"heading": "3.4 Expressivity of a SBCN", "text": "We conclude this section with a discussion of the causal relationships that we model with an SBCN. Suppose that there is a true (but unknown) probability distribution that generates the observed data, the structure of which can be modeled with a Dag. Moreover, we consider the causal structure of such a Dag and also let us assume that every node with more than one cause has conjunctive parents: every observation of the child node is driven by the appearance of all its parents."}, {"heading": "4. DISCRIMINATION DISCOVERY BY RANDOM WALKS", "text": "In this section, we propose several random methods that replace the reconstructed SBCN to perform different discrimination recognition tasks."}, {"heading": "4.1 Group discrimination and favoritism", "text": "The fundamental problem in analyzing direct discrimination is precisely to quantify the degree of discrimination that a given protected group (e.g., an ethnic group) has suffered in relation to a decision (e.g., refusal of credit). In contrast to discrimination, preference refers to the case of a person who is treated better than others for reasons that are not related to individual merit or business necessity. In the following, we refer to preference as positive discrimination as opposed to negative discrimination. In the face of an SBCN, we define a measure of group discrimination (either negative or positive) for each node v. workplace preference could result in each node representing a pair < attribute = value >, so it is essentially what we call a group, e.g. < gender = female >. Our task is to assign each node a score of discrimination."}, {"heading": "4.2 Indirect discrimination", "text": "European Union legislation [2] broadly defines indirect discrimination as such \"where a seemingly neutral provision, criterion or practice would place persons of racial or ethnic origin at a particular disadvantage vis-\u00e0-vis other persons.\" In other words, the actual result of the seemingly neutral provision is the same as an explicitly discriminatory provision. A typical legal case study of indirect discrimination deals with redlining: for example, the refusal of a loan based on the zip code, which in some areas is an attribute strongly correlated to race. Thus, even if the attribute of race cannot be required at the time of application (i.e. would not be included in the data), racial discrimination still occurs. Indirect discrimination detection refers to the task of data mining to detecting the attribute values that can act as proxies of the protected groups and indirectly lead to discriminatory decisions [13, 14, 11]. In our same environment, indirect discrimination can be determined through indirect application in section 4.1."}, {"heading": "4.3 Genuine requirement", "text": "The legal concept of the genuine requirement refers to the finding of that part of the discrimination that can be explained by other legally justified attributes; for example, the refusal to recognize women can be explained by the fact that most of them have low salaries or delays in returning previous loans. A typical example in the literature is that of the \"real professional requirement,\" also called \"business necessity\" in [29, 30]. In the state of data mining methods for discovering discrimination, it is also known as explicable discrimination [31] and conditional discrimination [18]. The task here is to assess to what extent the discrimination that a group recognizes is \"explainable\" on a legal basis. Let v-V be the node that represents the group suspected of being discriminated against, and ul-V be a node whose causal connection with a negative or positive decision is legally justified."}, {"heading": "4.4 Individual and subgroup discrimination", "text": "Similarly, subgroup discrimination refers to discrimination against a subgroup that is described by a combination of several protected and unprotected attributes: personal data, demographics, social, economic and cultural indicators, etc. Consider, for example, the case of gender discrimination in credit approval: Although an analyst can observe that no discrimination occurs in general, it may turn out that older women rarely obtain car loans. Both issues can be addressed by generalizing the technology introduced in Section 4.1 to deal with a number of start nodes, rather than just one. Given an SBCN = (V, E, W) let v1,. To define a discrimination score for v1,.., vn, we will set a discrimination value for v1,., vn, a negative value for vv1,."}, {"heading": "5. EXPERIMENTAL EVALUATION", "text": "This year, the number of job-related redundancies has fallen by 20 per cent compared to previous years."}, {"heading": "5.2 Group discrimination and favoritism", "text": "Next, we will focus on the evaluation of the discrimination value ds - we defined it in Section 4.1, as well as the average number of steps that random walks take to arrive at negative and positive decisions, each of which is designated as \u2212 (v) or + (v).Tables 4, 5 and 6 give the discrimination value ds \u2212 for the data sets adults, Germany and census incomes.The first and most important observation is that our discrimination value provides a very clear signal, with some disadvantaged groups having a very high discriminatory value (equal to 1 or very close), and similarly clear signals of preference, with groups ds \u2212 (v) = 0 or equivalent ds + (v) = 1. This becomes clearer in the Adult dataset, where the positive and negative decisions are artificially derived from the income attribute. In the German credit dataset, which is more realistic because the decision attribute is really credit, both discrimination and preference in Germany are less pronounced than the fact that both are related."}, {"heading": "5.3 Genuine requirement", "text": "Next, we focus on real requirements (or explainable discrimination).Table 7 shows some examples of fractions of explainable discrimination (both positive and negative) on the adult dataset. We can see how some fractions of discrimination against protected groups by intermediate nodes, such as a low educational profile or a simple job, can be \"explained.\" If these intermediate nodes are considered to be legally justified, then it is not readily possible to assert a discrimination claim. Likewise, we can observe that the preference of groups such as married men is largely explained by higher education and good job positions such as leadership or leadership positions."}, {"heading": "5.4 Subgroup and Individual Discrimination", "text": "Next, we turn our attention to subgroup and individual discrimination discovery. Here, the problem is to assign a score of discrimination not to a single node (group), but to several nodes (representing the attributes of an individual or a subgroup of citizens). In Section 4.4, based on the PageRank of positive and negative decision, ppr (\u03b4 +) and ppr (\u03b4 \u2212) respectively personalized on the nodes of interest. Figure 3 presents a scatter chart of ppr (\u03b4 +) versus ppr () for each individual in the German credit dataset. We can observe the perfect separation between individuals who correspond to a high personalized PageRank in terms of positive decision \u2212 and those associated with a high personalized PageRank relative to negative decision-making. ds \u2212 (v) as (v) as + (v) as + (v) MIGSAME Not in the universe 1 year old 0.071 4,88,821,SWF 0.94."}, {"heading": "5.5 Comparison with prior art", "text": "In this section we will discuss examples in which our causality method draws different conclusions from the correlation method presented in [13, 14, 15] using the same data sets and the same protected groups; the first example concerns the foreign group of workers from German credit records, whose discrimination table is already shown in Figure 7. Following the approaches of [13, 14, 15] of the group of foreign workers, the results are heavily discriminated against. Indeed, Figure 7 shows an RD value (risk difference) of 0.244, which is considered a strong signal: in fact, RD > 0 is already considered discrimination [15].However, we can observe that the foreign working group is not very significant per se, as they cannot compare 963 tuples from of7We with repeat problems. Indeed, our causal approach is not discrimination in relation to foreign workers who are considered an inseparable node in the SBBCN.The second example is in the opposite direction."}, {"heading": "6. CONCLUSIONS", "text": "Discovering discrimination from databases is a fundamental task in understanding past and current trends in discrimination, in resolving litigation disputes, in validating microdata prior to publication. While discrimination is a causal phenomenon and every claim of discrimination must prove a causal link, most of the literature on data mining methods for detecting discrimination is based on correlation grounds. In this paper, we propose a new approach to detecting discrimination that is capable of addressing different types of discrimination within a single unifying framework. It is the first discrimination detection method based on probabilistic causal theory. We define a method to extract a graph that represents the causal structures found in the database, and then propose several random methods of causal structures that clearly address a number of different discrimination problems.Our experimental task of assessing the great flexibility of our discrimination will address each other, while clearly recognizing different aspects of our predictive task."}, {"heading": "7. REFERENCES", "text": "[1] Australian legislation, \"Equal opportunityact-victoria state, (b) anti-discrimination act-queensland state, 2008.\" [2] EU legislation, \"(a) race equality directive, 2000 / 43 / ec, 2000; (b) employment equality directive, 2000 / 78 / ec, 2000; (c) equal treatment of persons, European Parliament resolution, 2009.\" [3] S. R. Foster, \"Causation in antidiscrimination law: Beyond intention versus impact,\" Hous. L. Rev., vol. 41, p. 1469, 2004. [4] M. Dabady, R. M. Blank, C. F. Citro et al., Measuring racial discrimination. National Academies Press, 2004. [5] P. J. Bickel, E. A. Hammel, and J. W. O'Connell, \"Sex bias in graduate admissions: Data from berkeley,\" Science, vol. 187, 1975."}], "references": [{"title": "Causation in antidiscrimination law: Beyond intent versus impact", "author": ["S.R. Foster"], "venue": "Hous. L. Rev., vol. 41, p. 1469, 2004.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Measuring racial discrimination", "author": ["M. Dabady", "R.M. Blank", "C.F. Citro"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Sex bias in graduate admissions: Data from berkeley", "author": ["P.J. Bickel", "E.A. Hammel", "J.W. O\u2019Connell"], "venue": "Science, vol. 187, no. 4175, 1975.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1975}, {"title": "Probabilistic causation", "author": ["C. Hitchcock"], "venue": "The Stanford Encyclopedia of Philosophy, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "A probabilistic theory of causality", "author": ["P. Suppes"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1970}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Annals of Statistics, vol. 6, no. 2, pp. 461\u2013464, 1978.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1978}, {"title": "A multidisciplinary survey on discrimination analysis", "author": ["A. Romei", "S. Ruggieri"], "venue": "The Knowledge Engineering Review, pp. 1\u201357, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "A methodology for direct and indirect discrimination prevention in data mining", "author": ["S. Hajian", "J. Domingo-Ferrer"], "venue": "TKDE, 25(7), 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Data preprocessing techniques for classification without discrimination", "author": ["F. Kamiran", "T. Calders"], "venue": "KAIS, 33(1), 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Discrimination-aware data mining", "author": ["D. Pedreshi", "S. Ruggieri", "F. Turini"], "venue": "KDD, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Measuring discrimination in socially-sensitive decision records.", "author": ["D. Pedreschi", "S. Ruggieri", "F. Turini"], "venue": "in SDM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Data mining for discrimination discovery", "author": ["S. Ruggieri", "D. Pedreschi", "F. Turini"], "venue": "TKDD, 4(2), 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "k-nn as an implementation of situation testing for discrimination discovery and prevention", "author": ["B.T. Luong", "S. Ruggieri", "F. Turini"], "venue": "KDD, 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Proving discrimination cases: The role of situation testing", "author": ["I. Rorive"], "venue": "2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Handling conditional discrimination", "author": ["I. Zliobaite", "F. Kamiran", "T. Calders"], "venue": "ICDM, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Fairness through awareness", "author": ["C. Dwork", "M. Hardt", "T. Pitassi", "O. Reingold", "R. Zemel"], "venue": "ITCS, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Integrating induction and deduction for finding evidence of discrimination", "author": ["D. Pedreschi", "S. Ruggieri", "F. Turini"], "venue": "ICAIL, 2009.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Anti-discrimination Analysis Using Privacy Attack Strategies", "author": ["S. Ruggieri", "S. Hajian", "F. Kamiran", "X. Zhang"], "venue": "PKDD, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Combating discrimination using bayesian networks", "author": ["K. Mancuhan", "C. Clifton"], "venue": "Artificial Intelligence and Law, 22(2), 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT press,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Counterfactual theories of causation", "author": ["P. Menzies"], "venue": "The Stanford Encyclopedia of Philosophy, spring 2014 ed., E. N. Zalta, Ed., 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Causation and manipulability", "author": ["J. Woodward"], "venue": "The Stanford Encyclopedia of Philosophy, winter 2013 ed., E. N. Zalta, Ed., 2013.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Sparsityboost: A new scoring function for learning bayesian network structure", "author": ["E. Brenner", "D. Sontag"], "venue": "arXiv:1309.6820, 2013.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Inferring tree causal models of cancer progression with probability raising", "author": ["L.O. Loohuis", "G. Caravagna", "A. Graudenzi", "D. Ramazzotti", "G. Mauri", "M. Antoniotti", "B. Mishra"], "venue": "PLoS ONE, 9(12), 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Capri: Efficient inference of cancer progression models from cross-sectional data", "author": ["D. Ramazzotti"], "venue": "Bioinformatics, 31(18), 2015.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "EU anti-discrimination law", "author": ["E. Ellis", "P. Watson"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Discrimination-and privacy-aware patterns", "author": ["S. Hajian", "J. Domingo-Ferrer", "A. Monreale", "D. Pedreschi", "F. Giannotti"], "venue": "DAMI, 29(6), 2015.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Scaling personalized web search", "author": ["G. Jeh", "J. Widom"], "venue": "WWW 2003.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2003}, {"title": "Computing communities in large networks using random walks", "author": ["P. Pons", "M. Latapy"], "venue": "ISCIS, 2005.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Statistics", "author": ["D. Feedman", "R. Pisani", "R. Purves"], "venue": "3rd Edition, WW Norton & Company, New York (1998).", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "Although these definitions do not directly imply causation, as stated in [3] all discrimination claims require plaintiffs to demonstrate a causal connection between the challenged outcome and a protected status characteristic.", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "This highlights the need to assess discrimination as a causal inference problem [4]", "startOffset": 80, "endOffset": 83}, {"referenceID": 2, "context": "org/wiki/Simpson\u2019s_paradox rates of admission, while men tended to apply to departments with higher rates [5].", "startOffset": 106, "endOffset": 109}, {"referenceID": 3, "context": "Following Suppes\u2019 probabilistic causation theory [6, 7] we define a method to extract, from a dataset of historical decision records, the causal structures existing among the attributes in the data.", "startOffset": 49, "endOffset": 55}, {"referenceID": 4, "context": "Following Suppes\u2019 probabilistic causation theory [6, 7] we define a method to extract, from a dataset of historical decision records, the causal structures existing among the attributes in the data.", "startOffset": 49, "endOffset": 55}, {"referenceID": 4, "context": "Imposing Suppes\u2019 temporal priority and probability raising we obtain what we call the prima facie causes graph [7], which might still contain spurious causes (false positives).", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "This regularization is done by means of the Bayesian Information Criterion (BIC) [8].", "startOffset": 81, "endOffset": 84}, {"referenceID": 6, "context": "Discrimination analysis is a multi-disciplinary problem, involving sociological causes, legal reasoning, economic models, statistical techniques [9, 10].", "startOffset": 145, "endOffset": 152}, {"referenceID": 7, "context": "Some authors [11, 12] study how to prevent data mining from becoming itself a source of discrimination.", "startOffset": 13, "endOffset": 21}, {"referenceID": 8, "context": "Some authors [11, 12] study how to prevent data mining from becoming itself a source of discrimination.", "startOffset": 13, "endOffset": 21}, {"referenceID": 9, "context": "[13, 14, 15] propose a technique based on extracting classification rules (inductive part) and ranking the rules according to some legally grounded measures of discrimination (deductive part).", "startOffset": 0, "endOffset": 12}, {"referenceID": 10, "context": "[13, 14, 15] propose a technique based on extracting classification rules (inductive part) and ranking the rules according to some legally grounded measures of discrimination (deductive part).", "startOffset": 0, "endOffset": 12}, {"referenceID": 11, "context": "[13, 14, 15] propose a technique based on extracting classification rules (inductive part) and ranking the rules according to some legally grounded measures of discrimination (deductive part).", "startOffset": 0, "endOffset": 12}, {"referenceID": 12, "context": "[16] exploit the idea of situation-testing [17] to detect individual discrimination.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16] exploit the idea of situation-testing [17] to detect individual discrimination.", "startOffset": 43, "endOffset": 47}, {"referenceID": 14, "context": "[18] focus on the concept of genuine requirement to detect that part of discrimination which may be explained by other, legally grounded, attributes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "In [19] Dwork et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "[20, 21] adopt a form of rule inference to cope with the indirect discovery of discrimination.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "[20, 21] adopt a form of rule inference to cope with the indirect discovery of discrimination.", "startOffset": 0, "endOffset": 8}, {"referenceID": 18, "context": "Mancuhan and Clifton [22] propose Bayesian networks as a tool for discrimination discovery.", "startOffset": 21, "endOffset": 25}, {"referenceID": 9, "context": "Our proposal has also lower computational cost than methods such as [13, 14, 15] which require to compute a potentially exponential number of association/classification rules.", "startOffset": 68, "endOffset": 80}, {"referenceID": 10, "context": "Our proposal has also lower computational cost than methods such as [13, 14, 15] which require to compute a potentially exponential number of association/classification rules.", "startOffset": 68, "endOffset": 80}, {"referenceID": 11, "context": "Our proposal has also lower computational cost than methods such as [13, 14, 15] which require to compute a potentially exponential number of association/classification rules.", "startOffset": 68, "endOffset": 80}, {"referenceID": 3, "context": "In order to study discrimination as a causal inference problem, we exploit the criteria defined in the theories of probabilistic causation [6].", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "In particular, we follow [7], where Suppes proposed the notion of prima facie causation that is at the core of probabilistic causation.", "startOffset": 25, "endOffset": 28}, {"referenceID": 4, "context": "Definition 1 (Probabilistic causation [7]).", "startOffset": 38, "endOffset": 41}, {"referenceID": 19, "context": "In the literature many algorithms exist to carry out structural learning of general Bayesian networks and they usually fall into two families [23].", "startOffset": 142, "endOffset": 146}, {"referenceID": 3, "context": "These algorithms exploit structural conditions defined in various approaches to causality [6, 24, 25].", "startOffset": 90, "endOffset": 101}, {"referenceID": 20, "context": "These algorithms exploit structural conditions defined in various approaches to causality [6, 24, 25].", "startOffset": 90, "endOffset": 101}, {"referenceID": 21, "context": "These algorithms exploit structural conditions defined in various approaches to causality [6, 24, 25].", "startOffset": 90, "endOffset": 101}, {"referenceID": 22, "context": "Several hybrid approaches have also been recently proposed [26, 27, 28].", "startOffset": 59, "endOffset": 71}, {"referenceID": 23, "context": "Several hybrid approaches have also been recently proposed [26, 27, 28].", "startOffset": 59, "endOffset": 71}, {"referenceID": 24, "context": "Several hybrid approaches have also been recently proposed [26, 27, 28].", "startOffset": 59, "endOffset": 71}, {"referenceID": 23, "context": "We recall that the probability raising condition is equivalent to constraining for positive statistical dependence [27]: in the prima facie graph we model all and only the positive correlated relations among the nodes already partially ordered by temporal priority, consistently with Suppes\u2019 characterization of causality in terms of relevance.", "startOffset": 115, "endOffset": 119}, {"referenceID": 24, "context": "Suppes\u2019 conditions are necessary but not sufficient to evaluate causation [28]: especially when the sample size is small, the model may have false positives (spurious causes), even after constraining for Suppes\u2019 temporal priority and probability raising criteria (which aim at removing false negatives).", "startOffset": 74, "endOffset": 78}, {"referenceID": 3, "context": ", [6, 24, 25]), we perform a network simplification (i.", "startOffset": 2, "endOffset": 13}, {"referenceID": 20, "context": ", [6, 24, 25]), we perform a network simplification (i.", "startOffset": 2, "endOffset": 13}, {"referenceID": 21, "context": ", [6, 24, 25]), we perform a network simplification (i.", "startOffset": 2, "endOffset": 13}, {"referenceID": 5, "context": ", we sparsify the network by removing arcs) with a score based approach, specifically by relying on the Bayesian Information Criterion (BIC) as the regularized likelihood score [8].", "startOffset": 177, "endOffset": 180}, {"referenceID": 19, "context": "For an overview of state-of-the-art methods for doing this, see [23].", "startOffset": 64, "endOffset": 68}, {"referenceID": 9, "context": "Indirect discrimination discovery refers to the data mining task of discovering the attributes values that can act as a proxy to the protected groups and lead to discriminatory decisions indirectly [13, 14, 11].", "startOffset": 198, "endOffset": 210}, {"referenceID": 10, "context": "Indirect discrimination discovery refers to the data mining task of discovering the attributes values that can act as a proxy to the protected groups and lead to discriminatory decisions indirectly [13, 14, 11].", "startOffset": 198, "endOffset": 210}, {"referenceID": 7, "context": "Indirect discrimination discovery refers to the data mining task of discovering the attributes values that can act as a proxy to the protected groups and lead to discriminatory decisions indirectly [13, 14, 11].", "startOffset": 198, "endOffset": 210}, {"referenceID": 25, "context": "A typical example in the literature is the one of the \u201cgenuine occupational requirement\u201d, also called \u201cbusiness necessity\u201d in [29, 30].", "startOffset": 126, "endOffset": 134}, {"referenceID": 26, "context": "In the state of the art of data mining methods for discrimination discovery, it is also known as explainable discrimination [31] and conditional discrimination [18].", "startOffset": 124, "endOffset": 128}, {"referenceID": 14, "context": "In the state of the art of data mining methods for discrimination discovery, it is also known as explainable discrimination [31] and conditional discrimination [18].", "startOffset": 160, "endOffset": 164}, {"referenceID": 27, "context": ", vn, we perform a personalized PageRank [32] computation with respect to v1, .", "startOffset": 41, "endOffset": 45}, {"referenceID": 29, "context": "This section reports the experimental evaluation of our approach on four datasets, Adult, German credit and census-income from the UCI Repository of Machine Learning Databases, and Berkeley Admissions Data from [34].", "startOffset": 211, "endOffset": 215}, {"referenceID": 29, "context": "[34].", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "Given that our SBCN is a directed graph with edge weight, as a first characterization we try to partition it using a random-walks-based community detection algorithm, called Walktrap and proposed in [33], whose unique parameter is the maximum number of steps in a random walk (we set it to 8), and which automatically identifies the right number of communities.", "startOffset": 199, "endOffset": 203}, {"referenceID": 28, "context": "Table 3: Communities found in the SBCN extracted from the Adult dataset by Walktrap[33].", "startOffset": 83, "endOffset": 87}, {"referenceID": 9, "context": "In this section, we discuss examples in which our causation-based method draws different conclusions from the correlation-based methods presented in [13, 14, 15] using the same datasets and the same protected groups .", "startOffset": 149, "endOffset": 161}, {"referenceID": 10, "context": "In this section, we discuss examples in which our causation-based method draws different conclusions from the correlation-based methods presented in [13, 14, 15] using the same datasets and the same protected groups .", "startOffset": 149, "endOffset": 161}, {"referenceID": 11, "context": "In this section, we discuss examples in which our causation-based method draws different conclusions from the correlation-based methods presented in [13, 14, 15] using the same datasets and the same protected groups .", "startOffset": 149, "endOffset": 161}, {"referenceID": 9, "context": "Following the approaches of [13, 14, 15] the foreign worker group results strongly discriminated.", "startOffset": 28, "endOffset": 40}, {"referenceID": 10, "context": "Following the approaches of [13, 14, 15] the foreign worker group results strongly discriminated.", "startOffset": 28, "endOffset": 40}, {"referenceID": 11, "context": "Following the approaches of [13, 14, 15] the foreign worker group results strongly discriminated.", "startOffset": 28, "endOffset": 40}, {"referenceID": 11, "context": "244 which is considered a strong signal: in fact RD > 0 is already considered discrimination [15].", "startOffset": 93, "endOffset": 97}, {"referenceID": 18, "context": "We could not compare with [22] due to repeatability issues.", "startOffset": 26, "endOffset": 30}, {"referenceID": 9, "context": "994), while the approaches of [13, 14, 15] fail to discover discrimination against black minority when the value of minimum support threshold used for extracting classification rules is more than 10%.", "startOffset": 30, "endOffset": 42}, {"referenceID": 10, "context": "994), while the approaches of [13, 14, 15] fail to discover discrimination against black minority when the value of minimum support threshold used for extracting classification rules is more than 10%.", "startOffset": 30, "endOffset": 42}, {"referenceID": 11, "context": "994), while the approaches of [13, 14, 15] fail to discover discrimination against black minority when the value of minimum support threshold used for extracting classification rules is more than 10%.", "startOffset": 30, "endOffset": 42}, {"referenceID": 9, "context": "However, following the approaches of [13, 14, 15], the contingency table shown in Figure 10 can be extracted from Berkeley Admission Data.", "startOffset": 37, "endOffset": 49}, {"referenceID": 10, "context": "However, following the approaches of [13, 14, 15], the contingency table shown in Figure 10 can be extracted from Berkeley Admission Data.", "startOffset": 37, "endOffset": 49}, {"referenceID": 11, "context": "However, following the approaches of [13, 14, 15], the contingency table shown in Figure 10 can be extracted from Berkeley Admission Data.", "startOffset": 37, "endOffset": 49}], "year": 2017, "abstractText": "Discrimination discovery from data is an important task aiming at identifying patterns of illegal and unethical discriminatory activities against protected-by-law groups, e.g., ethnic minorities. While any legally-valid proof of discrimination requires evidence of causality, the state-of-theart methods are essentially correlation-based, albeit, as it is well known, correlation does not imply causation. In this paper we take a principled causal approach to the data mining problem of discrimination detection in databases. Following Suppes\u2019 probabilistic causation theory, we define a method to extract, from a dataset of historical decision records, the causal structures existing among the attributes in the data. The result is a type of constrained Bayesian network, which we dub Suppes-Bayes Causal Network (SBCN). Next, we develop a toolkit of methods based on random walks on top of the SBCN, addressing different anti-discrimination legal concepts, such as direct and indirect discrimination, group and individual discrimination, genuine requirement, and favoritism. Our experiments on real-world datasets confirm the inferential power of our approach in all these different tasks.", "creator": "LaTeX with hyperref package"}}}