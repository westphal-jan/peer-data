{"id": "1510.01291", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2015", "title": "A Common-Factor Approach for Multivariate Data Cleaning with an Application to Mars Phoenix Mission Data", "abstract": "Data quality is fundamentally important to ensure the reliability of data for stakeholders to make decisions. In real world applications, such as scientific exploration of extreme environments, it is unrealistic to require raw data collected to be perfect. As data miners, when it is infeasible to physically know the why and the how in order to clean up the data, we propose to seek the intrinsic structure of the signal to identify the common factors of multivariate data. Using our new data driven learning method, the common-factor data cleaning approach, we address an interdisciplinary challenge on multivariate data cleaning when complex external impacts appear to interfere with multiple data measurements. Existing data analyses typically process one signal measurement at a time without considering the associations among all signals. We analyze all signal measurements simultaneously to find the hidden common factors that drive all measurements to vary together, but not as a result of the true data measurements. We use common factors to reduce the variations in the data without changing the base mean level of the data to avoid altering the physical meaning.", "histories": [["v1", "Mon, 5 Oct 2015 19:21:22 GMT  (1103kb)", "http://arxiv.org/abs/1510.01291v1", "12 pages, 10 figures, 1 table"], ["v2", "Wed, 7 Oct 2015 16:47:30 GMT  (1599kb)", "http://arxiv.org/abs/1510.01291v2", "12 pages, 10 figures, 1 table"]], "COMMENTS": "12 pages, 10 figures, 1 table", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["dongping fang", "elizabeth oberlin", "wei ding", "samuel p kounaves"], "accepted": false, "id": "1510.01291"}, "pdf": {"name": "1510.01291.pdf", "metadata": {"source": "CRF", "title": "A Common-Factor Approach for Multivariate Data Cleaning with an Application to Mars Phoenix Mission Data", "authors": ["Dongping Fang", "Elizabeth Oberlin", "Wei Ding", "Samuel P. Kounaves"], "emails": ["dongping.fang@zurichna.com", "Elizabeth.Oberlin@tufts.edu", "wei.ding@umb.edu", "Samuel.Kounave@tufts.edu"], "sections": [{"heading": null, "text": "In real-world applications such as scientific exploration of extreme environments, it is unrealistic to demand that the raw data collected must be perfect. As a data miner, when it is physically impossible to know the reason and how to clean up the data, we propose to look for the intrinsic structure of the signal to identify the common factors of multivariate data. Using our new data-driven learning method - the common factor data cleaning approach - we address an interdisciplinary challenge in cleansing multivariate data when complex external influences seem to interfere with multiple measurements. Existing data analytics typically process a signal measurement at once without taking into account the relationships between all signals. We analyze all signal measurements simultaneously to find the hidden common factors that bring all measurements together, but not as a result of true data measurements. We use common factors to reduce the variations in the data without changing the basic level of the data."}, {"heading": "1. INTRODUCTION", "text": "In fact, it is unrealistic to collect the data that it is. WCL collects over three million data and performs the first comprehensive chemical analysis of the soil on Mars. Initial data provide new scientific evidence to support microbial life, and even its atmospheric chemistry is present."}, {"heading": "2. METHODOLOGY", "text": "It is time for EU member states to agree on a common position in order to find a common position."}, {"heading": "3. COMPARATIVE STUDIES USING SYNTHETIC DATA", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "4. ANALYSIS OF MARTIAN SOIL DATA", "text": "This year, it has come to the point where it is only a matter of time before a result is achieved."}, {"heading": "5. CONCLUSION AND FUTURE DEVELOPMENT", "text": "This method is easy to use, intuitive and effective as a more unified approach to data purification. Our method eliminates the need for special handling of data in complicated scenarios where the origin of noise is difficult to understand. So far, this common factor algorithm has been successfully applied to WCL experiments, as has been shown, and it would likely be successful in other cases of data interpretation where the results are interlinked in a sensor array and subject to extensive but unknown systematic noise. Sensor arrays are commonly used in the field of environmental monitoring, where several different measurements are performed simultaneously and the combination of data is used to obtain otherwise inaccessible information about the system. When these sensor arrays are used in extreme and remote environments, the data obtained can exhibit extensive noise, which, although unknown at source, affects all individual sensors to varying degrees."}, {"heading": "6. ACKNOWLEDGMENTS", "text": "This work was supported by NASA under grant NNX13AJ69G."}, {"heading": "7. REFERENCES", "text": "[1] Kounaves, S. P., Hecht, M. H., West, S. J, Morookian, J. M., Young, S. M., Quinn, R. C., Grunthaner, P., Wen, X., Weilert, M., Cable, C. A., Fisher, A., Gospodinova, K., Kapit, J., Stroble, S., Hsu, P. C., Clark, B. C., and Ming, D. W. 2009. The MECA Wet Chemistry Laboratory on the 2007 Phoenix Mars Scout Lander, Journal of geophysical research. 114, E00A19 [2] Kounaves, S. P., Hecht, M., Kapit, J., Gospodinova, K., DeFlores, L., Quinn, R., Boynton, W. V., Clark, B. C., Catling, D. C., Hredzak, P., Ming, D. W., D. W., Moore, Q., Shusterman."}], "references": [{"title": "Soluble salts at the Phoenix Lander site, Mars: A reanalysis of the Wet Chemistry Laboratory data", "author": ["J.D. Toner", "D.C. Catling", "B. Light"], "venue": "Geochimica et Cosmochimica Acta", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Phoenix MECA Non-Imaging Reduced Data V1.0, PHX-M-MECA-4-NIRDR- V1.0", "author": ["M.H. Hecht"], "venue": "NASA Planetary Data System,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Phoenix Mars MECA Non- Imaging EDR V1.0", "author": ["Hecht", "Michael"], "venue": "NASA Planetary Data System,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "A primer on wavelets and their scientific applications", "author": ["Walker", "James S"], "venue": "CRC press,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Journal of Basic Engineering", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1960}, {"title": "Machine Vision: Theory, Algorithms and Practicalities", "author": ["E. Davies"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Image Denoising Using Hidden Markov Models, urAsia- ICT 2002: Information and Communication Technology, Lecture Notes in Computer", "author": ["Ghabeli", "Leila", "Amindavar", "Hamidreza"], "venue": "Science Volume", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Scale mixtures of normal distributions", "author": ["D. Andrews", "C. Mallows"], "venue": "J.R. Statist. Doc, vol. 36, pp. 99, 1974.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1974}, {"title": "Identifying a Simplifying Structure in Time Series", "author": ["D. PE\u00d1A", "G.E.P. BOX"], "venue": "Journal of American Statistical Association,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1987}, {"title": "Common stochastic trends in a system of exchange rates", "author": ["R.T. Baillie", "T Bollerslev"], "venue": "Journal of Finance", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1989}, {"title": "Differential dependency network analysis to identify condition-specific topological changes in biological networks, Bioinformatic", "author": ["B Zhang"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Brain covariance selection: better individual functional connectivity models using population prior, Advances in Neural Information Processing Systems", "author": ["G Varoquaux"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}], "referenceMentions": [{"referenceID": 3, "context": "The existing state-of-the-art denoising methods, including Fourier filtering [8], Kalman smoothing [9] [12], Gaussian smoothing [10], and Hidden Markov Model denoising [11], do not work well for this type of problem because they are designed to cope with a single data measurement, ignoring the associated shared behavior among multiple datasets.", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "The existing state-of-the-art denoising methods, including Fourier filtering [8], Kalman smoothing [9] [12], Gaussian smoothing [10], and Hidden Markov Model denoising [11], do not work well for this type of problem because they are designed to cope with a single data measurement, ignoring the associated shared behavior among multiple datasets.", "startOffset": 99, "endOffset": 102}, {"referenceID": 7, "context": "The existing state-of-the-art denoising methods, including Fourier filtering [8], Kalman smoothing [9] [12], Gaussian smoothing [10], and Hidden Markov Model denoising [11], do not work well for this type of problem because they are designed to cope with a single data measurement, ignoring the associated shared behavior among multiple datasets.", "startOffset": 103, "endOffset": 107}, {"referenceID": 5, "context": "The existing state-of-the-art denoising methods, including Fourier filtering [8], Kalman smoothing [9] [12], Gaussian smoothing [10], and Hidden Markov Model denoising [11], do not work well for this type of problem because they are designed to cope with a single data measurement, ignoring the associated shared behavior among multiple datasets.", "startOffset": 128, "endOffset": 132}, {"referenceID": 6, "context": "The existing state-of-the-art denoising methods, including Fourier filtering [8], Kalman smoothing [9] [12], Gaussian smoothing [10], and Hidden Markov Model denoising [11], do not work well for this type of problem because they are designed to cope with a single data measurement, ignoring the associated shared behavior among multiple datasets.", "startOffset": 168, "endOffset": 172}, {"referenceID": 8, "context": "In [13-16], the principles of identifying common-mode regularities were discussed to identify a simplifying structure, shared trends in financial data and covariance selection in biological data, but not for the data cleaning using common external factors which is a quite different problem.", "startOffset": 3, "endOffset": 10}, {"referenceID": 9, "context": "In [13-16], the principles of identifying common-mode regularities were discussed to identify a simplifying structure, shared trends in financial data and covariance selection in biological data, but not for the data cleaning using common external factors which is a quite different problem.", "startOffset": 3, "endOffset": 10}, {"referenceID": 10, "context": "In [13-16], the principles of identifying common-mode regularities were discussed to identify a simplifying structure, shared trends in financial data and covariance selection in biological data, but not for the data cleaning using common external factors which is a quite different problem.", "startOffset": 3, "endOffset": 10}, {"referenceID": 11, "context": "In [13-16], the principles of identifying common-mode regularities were discussed to identify a simplifying structure, shared trends in financial data and covariance selection in biological data, but not for the data cleaning using common external factors which is a quite different problem.", "startOffset": 3, "endOffset": 10}, {"referenceID": 8, "context": "Though the idea of common factors is used in many fields [5, 13 \u2013 16], to the best of our knowledge, we are the first research team to use the idea of common hidden factors on data cleaning.", "startOffset": 57, "endOffset": 69}, {"referenceID": 11, "context": "Though the idea of common factors is used in many fields [5, 13 \u2013 16], to the best of our knowledge, we are the first research team to use the idea of common hidden factors on data cleaning.", "startOffset": 57, "endOffset": 69}, {"referenceID": 0, "context": "[3] used Kalman smoothing method with random walk plus noise model: EEtt = \u03bc\u03bctt + \u03b5\u03b5tt & \u03bc\u03bctt = \u03bc\u03bctt\u22121 + \u03b7\u03b7tt .", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[3] because they also included the variation in mean estimates at different time points.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "These data are publicly available at the NASA Planetary Data System [6, 7].", "startOffset": 68, "endOffset": 74}, {"referenceID": 2, "context": "These data are publicly available at the NASA Planetary Data System [6, 7].", "startOffset": 68, "endOffset": 74}, {"referenceID": 0, "context": "Previous analysis of the WCL data has employed Fourier filtering [2] and Kalman smoothing [3] techniques to reduce the noise associated with the data sets, under the assumption that the associated noise is mostly random in nature.", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "Using the common-factor cleaned data, the total ion concentrations and associated uncertainty are calculated (Table 1 and Figure 10) and compared with concentration estimates from previous studies using Fourier filtering by Kounaves et al [2] and Kalman smoothing by Toner et al [3].", "startOffset": 279, "endOffset": 282}, {"referenceID": 0, "context": "\u2019s estimated range [3].", "startOffset": 19, "endOffset": 22}], "year": 2015, "abstractText": "Data quality is fundamentally important to ensure the reliability of data for stakeholders to make decisions. In real world applications, such as scientific exploration of extreme environments, it is unrealistic to require raw data collected to be perfect. As data miners, when it is infeasible to physically know the why and the how in order to clean up the data, we propose to seek the intrinsic structure of the signal to identify the common factors of multivariate data. Using our new data-driven learning method\u2014the common-factor data cleaning approach, we address an interdisciplinary challenge on multivariate data cleaning when complex external impacts appear to interfere with multiple data measurements. Existing data analyses typically process one signal measurement at a time without considering the associations among all signals. We analyze all signal measurements simultaneously to find the hidden common factors that drive all measurements to vary together, but not as a result of the true data measurements. We use common factors to reduce the variations in the data without changing the base mean level of the data to avoid altering the physical meaning. We have reanalyzed the NASA Mars Phoenix mission data used in the leading effort by Kounaves\u2019s team (lead scientist for the wet chemistry experiment on the Phoenix) [1, 2] with our proposed method to show the resulting differences. We demonstrate that this new common-factor method successfully helps reducing systematic noises without definitive understanding of the source and without degrading the physical meaning of the signal.", "creator": "Acrobat PDFMaker 11 for Word"}}}