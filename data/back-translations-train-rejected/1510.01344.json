{"id": "1510.01344", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2015", "title": "Within-Brain Classification for Brain Tumor Segmentation", "abstract": "Purpose: In this paper, we investigate a framework for interactive brain tumor segmentation which, at its core, treats the problem of interactive brain tumor segmentation as a machine learning problem.", "histories": [["v1", "Mon, 5 Oct 2015 20:32:04 GMT  (478kb,D)", "http://arxiv.org/abs/1510.01344v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["mohammad havaei", "hugo larochelle", "philippe poulin", "pierre-marc jodoin"], "accepted": false, "id": "1510.01344"}, "pdf": {"name": "1510.01344.pdf", "metadata": {"source": "CRF", "title": "Within-Brain Classification for Brain Tumor Segmentation", "authors": ["Mohammad Havaei", "Hugo Larochelle", "Philippe Poulin", "Pierre-Marc Jodoin"], "emails": ["mohammad.havaei@gmail.com", "hugo.larochelle@usherbrooke.ca", "philippe.Poulin2@usherbrooke.ca", "pierre-marc.jodoin@usherbrooke.ca"], "sections": [{"heading": null, "text": "Methods: This method has an advantage over typical machine learning methods for this task, in which generalizations are made between brains. The problem with these methods is that they have to deal with the correction of intensity distortions and other MRI-specific noises. In this work, we avoid these problems by approaching the problem as a problem within the generalization of the brain. Specifically, we propose a semi-automatic method that segments a brain tumor within that brain only by training and generalization, based on a minimum of user interaction. Conclusion: We are also investigating how adding coordinates of spatial characteristics (i.e. i, j, k) to the intensity characteristics can significantly improve the performance of various classification methods such as SVM, kNN and random forests. This would only be possible within an interactive framework. We are also investigating the use of a more appropriate kernel and the adjustment of hyperparameters specifically for each brain."}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Related Work", "text": "In fact, most of them are able to outdo themselves."}, {"heading": "3 Investigating Within-Brain Generalization", "text": "In generalization within the brain, segmentation of each brain is treated as a separate machine learning experiment, in which a classifier is trained (on voxels marked by the user) and used to generalize new observations (voxels not marked by the user).This approach is motivated by the observation that a machine learning experiment (including hyper-parameter selection) can actually be performed with current computers and for relatively small sets of data with small attribute space within a very short period of time, even for more complex algorithms that require more than just storing the data (as in kNN).In addition, segmentation only within a particular brain eliminates the difficult problem of generalizing the conditions for brain imaging. Below, we describe the details of our approach and enumerate the various variations we have examined in this direction. Figure 2 shows our method to the point we explain in this section 3."}, {"heading": "3.1 Feature representation and manual selection", "text": "The first step of our method is the collection of voxel mark data for a particular brain image into a segment. This is done by the user, who roughly selects a subset of voxels associated with each class, via a graphical user interface. The number of strokes required to obtain the training data depends on the number of tumors in a given brain. Normally, however, one or two strokes per class will suffice. We will record as B a binary mask that indicates whether a voxel v has been manually selected (i.e. labeled) or not. T will then be the class selection mask in which Tv {edema, non enhancing tumor, enhancing tumor, healthy} is the class label associated with the voxel v by the user. We also have to opt for a feature representation for the different voxels. Each brain image I select will come with 3 MRI modalities (TC, each Tir, each flair is represented in a voxel)."}, {"heading": "3.2 Voxel classifiers", "text": "We are studying the use of different machine learning algorithms to generate a classifier. Although we could theoretically consider any existing algorithm, it is natural to prefer algorithms known for their use as robust and relatively \"black boxes.\" For example, we do not want the user (typically a physician or neuroscientist) to have to manually set hyperparameters for each brain, with trial and error. Therefore, we have selected algorithms that are known to be easy to tune or tend to work well for the default values of their hyperparameters. These algorithms have also proved successful for the automatic segmentation of brain tumors [18, 14]."}, {"heading": "3.2.1 K-Nearest Neighbors (kNN)", "text": "First, k is considered next neighbor (kNN), one of the simplest classifiers. For each voxel v, kNN finds under the training data D the set k closest neighbors (Nv) based on Fv. LetNv = (((Fv1, Tv1), (Fv2, Tv2),..., (Fvk, Tvk), where Fvi is the closest training point of Fv. The kNN classification rule assigns a class label to any voxel v according to this equation. Note that this formulation can be regarded as using a subordinate class probability: p (Tv = c | Fv) = 1k. (Fvi, Tvi) (a, b) returns 1 if a = b and 0 otherwise."}, {"heading": "3.2.2 Support Vector Machine", "text": "In its parametric form, it is a linear classifier that attempts to classify data points by maximizing the margin between the decision boundaries of the different classes and their next points. Of greater interest in our setting is the kernel-based version of SVM [11]. A choice for the kernel that often proves successful is the radial base function (RBF) kernel: K (Fj, Fv) = exp (-\u03b3 Fj \u2212 Fv \u043222). (3) where it is a hyperparameter. A slip variable C is also used to loosen the constraints in the SVM optimization problem (RBF). (Fj, Fv) The resulting classifier effectively takes the form of a template matcher that compares a given input example with each other.) This variable C is used to compare the constraints in the SVM optimization problem (Fv), the resulting classifier function (SVM) is often used as the SVM (Optimizer Projector Projector)."}, {"heading": "3.2.3 Ensemble of Decision Trees", "text": "Another popular approach to classification is ensembles of decision trees. Each decision tree is trained by recursive division of the attribute space, according to a heuristic that favors a good separation of classes. As soon as a criterion for stopping tree growth is reached, a conditional class distribution is calculated on each leaf, based on the training data falling into the corresponding partition. Specifically, the class distribution p (Tv = c | Fv) asP (Tv = c | Fv) = Nc N (5) is specified, where Nc is the relative frequency of examples belonging to class c of the partition where Fv falls, and N the total number of examples. However, the performance of a single decision tree is often disappointing."}, {"heading": "3.3 Distance Metric/Kernel", "text": "The performance of the SVM classifier often depends on the choice of metrics or kernels used to compare data points. Therefore, it is generally advantageous to adapt this choice to each individual problem. For example, the conventional RBF kernel actually gives the same weight to each dimension of the attribute space. However, within our framework within the brain, the spatial coordinate characteristics < i, j, k > and modality characteristics actually influence different roles. Intuitively, one role of spatial coordinates is to prevent a custom voxel from beginning to influence prediction in a distant voxel, for example to avoid false positives in distant regions. Therefore, modality characteristics are largely informative near a user-designated voxel. Therefore, we may want to weigh modality and spatial characteristics differently within the SVM RBF kernel."}, {"heading": "3.4 Importance of Within-Brain Hyper-Parameter Se-", "text": "One approach commonly implemented [14] is the selection of hyperparameters by cross-validation in a grid search approach on a subset of the brain and the determination of the selected set of hyperparameters for the rest of the brain. We hypothesize given the variations in the MRI data, where a fixed set of hyperparameters is not optimal for generalization. An alternative option is to perform hyperparameter selection individually for each brain in order to adapt to the specificity of each case. We measure the potential benefits of this approach in our experiments by selecting the hyperparameters for the SVM, namely the slack variable C and the coefficient. A detailed discussion of this experiment is presented in Section 4.2.4."}, {"heading": "3.4.1 Conditional Random Fields (CRF)", "text": "As already mentioned, segmentation accuracy can be easily improved by using a model of 3D spatial regularity of labels (SVV). One way to assert spatial regularity is to define a common (conditional) distribution over the labels of all labels in the brain, which expresses the expected dependencies between adjacent labels. Conditional Random Fields (CRF) provide a convenient formalism for this. CRFs directly model the posterior probabilities of labels that directly express the characteristics P (T | F), thereby mitigating the need to model the distribution via the feature vectors F. (CRFs directly model the posterior probabilities of the characteristics P (T | F): P (T | F) = 1 Z-v (Fv) v-v), the distribution via the feature vectors F (Tv, Fv, Fv, Tr, Fr)."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Setup", "text": "rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the f\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf the rf\u00fc the rf\u00fc the rf the rf the rf\u00fc the rf the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the f\u00fc the rf\u00fc the rf\u00fc the rf the f\u00fc the rf the ru the rf the f\u00fc the ru the rf the rf the rf the ru the ru"}, {"heading": "4.2 Results and Discussion", "text": "In this section, we report on experimental results obtained with the machine learning methods presented in Section 3.2, including linear SVM (LSVM), SVM kernel with rbf kernel (KSVM), our proposed product core SVM (PKSVM), kNN, decision trees trained with Ada-Boost (ADT), and Random Forests (RDT), all of which have been explored with and without CRF. CRF parameters \u03b1 and \u03b2 have been determined for each method by cross-validation on 6 brains on the training set. We also examine the extent to which adding spatial features < i, j, k > contributes to improving performance by adding a \"\u0445\" to the method name."}, {"heading": "4.2.1 KNN", "text": "The results of the kNN-related experiments are presented in Table 1. First, we carried out an experiment without including the features < i, j, k > in the feature vector as shown in [20]. Since its method does not use the spatial coordinate characteristics or CRF regularization, it performs significantly worse than other kNN-related experiments. While adding the spatial coordinates to this method significantly improves the result, the best performance is achieved when we use both spatial coordinates and CRF regularization."}, {"heading": "4.2.2 SVM", "text": "The results for the SVM-related experiments are in Table 2. The results confirm that the use of spatial coordinate characteristics (represented by \"*\") and the use of the CRF model (represented by \"-CRF\") improves the performance of both a linear SVM (LSVM) and an RBF SVM (KSVM) nucleus. This experiment also shows that the non-linearity of the SVM nucleus is of crucial importance as it significantly exceeds the linear SVM (LSVM). As for the PKSVM method, which stands for the SVM RBF product core presented in Section 3.3 (see Equation (7), it significantly improved the results of kernel SVM and kernel SVM + CRF, underscoring the relative importance of the spatial coordinate characteristics < i, j, k > compared to the input modalities T1, T2 and Flair."}, {"heading": "4.2.3 Decision trees", "text": "For these experiments, we set the number of decision trees for AdaBoost (ADT) and Random Forests (RDT) to 100 and the sheet size to 1. Decision stumps were used for AdaBoost. Quantitative results are presented in Table 3. Although adding spatial features is advantageous for both Random Forests and AdaBoost, the use of the CRF model is mostly advantageous, except for Random Forst without spatial coordinates. However, segmentation systems based on decision trees tend to be inferior to the use of kNN or SVM methods."}, {"heading": "4.2.4 Robustness of hyper-parameter selection", "text": "In our method of using SVM as a classifier, the hyperparameter (regularization constant C and kernel hyperparameter) was always validated individually for each brain. Considering the variation in MRI data and tumor types that we use for a fixed set of hyperparameters, performance does deteriorate significantly. To evaluate the importance of performing per brain model, we conducted an experiment in which we used a fixed configuration of hyperparameters and tumor types. For this experiment, we looked at our top two segmentation methods, PKSVM-CRF * and KSVM-CRF."}, {"heading": "4.2.5 Speed-up procedure", "text": "Each segmentation method presented in this paper uses manually selected voxels as input. However, these selected voxels often execute similar information, especially for adjacent voxels whose < i, j, k > position is almost identical and whose T1, T2, flair values are likely identical. To speed up the segmentation process, one can randomly scan the training data. To have a general idea of the extent to which we can scan the data without infringing overall precision, we conducted an experiment in which we split the training points into healthy and non-healthy subsets and evaluate them separately in order to maintain an equilibrium between the size of the healthy class in relation to other classes. The result of this process is a smaller training set, but with approximately the same proportion of healthy points and non-healthy subsets. Figure 4 shows the result of this experiment. Curves were achieved by taking BRS points from 20 ATS randomly selected from a number of 71 brain ATS."}, {"heading": "5 Conclusion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Putting it all together", "text": "However, the official BRATS website provides a ranking system for this purpose. As the BRATS organizers have recently made all methods anonymous, a full comparison is not possible. Therefore, we evaluate our method on the basis of the MICCAI-BRATS 2013 results, for which references to the methods were available, as shown in Table 5. As you can see, the results mentioned in Table 5 come from methods competing in the BRATS 2013 challenge, for which a static table is available [https: / / www.virtualskeleton.ch / StaticResults2013]. Since then, other methods have been placed in second and third place, closely behind those competing in the BRATS 2013 challenge. and kNN-CRF * is in sixth place in this table."}, {"heading": "5.2 Processing time and memory usage", "text": "A major advantage of our proposed method is that it has a very short processing time and memory usage, while at the same time it has a high accuracy. Due to the small dimensionality of our feature space, it only takes an average of 50 MB of RAM to store the feature space of a brain, which is very small compared to modern methods, whose storage space is in the order of GB. For example, Festa et al. use a feature space of 300 dimensions for their random forest approach, which would take up to 2.7 GB. Tustison et al. Reza et al. and Meier et al. also take a similar approach with random forests. These methods rely on a high number of texture features, which are computationally time-consuming and time-consuming to store. Apart from the feature space, our proposed methods have a different speed and memory size. We can make a comparison in terms of accuracy, speed and memory usage, as shown in Table 6."}, {"heading": "6 Conflict of Interest", "text": "The authors declare that they have no conflict of interest."}, {"heading": "7 Ethical approval", "text": "All procedures carried out in studies involving human participants complied with the ethical standards of the Institutional and / or National Research Committee and the 1964 Helsinki Declaration and its subsequent amendments or comparable ethical standards. This article does not include studies involving human participants carried out by one of the authors."}], "references": [{"title": "Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization. In: Medical Image Computing and Computer-Assisted Intervention", "author": ["S Bauer", "L Nolte", "M Reyes"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "A survey of mri-based medical image analysis for brain tumor studies. Physics in medicine and biology", "author": ["S Bauer", "R Wiest", "L Nolte", "M Reyes"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Probabilistic segmentation of brain tumors based on multi-modality magnetic resonance images", "author": ["H Cai", "R Verma", "Y Ou", "S Lee", "E Melhem", "C Davatzikos"], "venue": "Biomedical Imaging: From Nano to Macro,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Multimodal Brain Tumor Segmentation", "author": ["K Farahani", "B Menze", "M Reyes"], "venue": "(BRATS", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Multimodal brain tumor segmentation using the tumor-cut method on the brats dataset", "author": ["A Hamamci", "G Unal"], "venue": "Proc Workshod on Brain Tumor Segmentation,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Tumorcut: Segmentation of brain tumors on contrast enhanced mr images for radiosurgery applications", "author": ["A Hamamci", "N Kucuk", "K Karaman", "K Engin", "G Unal"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Level-set evolution with region competition: automatic 3-d segmentation of brain tumors", "author": ["S Ho", "E Bullitt", "G Gerig"], "venue": "Proc. Int. Conf. Pattern Recognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Ensemble segmentation for gbm brain tumors on mr images using confidence-based averaging", "author": ["J Huo", "K Okada", "EM van Rikxoort", "HJ Kim", "JR Alger", "WB Pope", "JG Goldin", "MS Brown"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Segmentation and quantification of brain tumor", "author": ["C Jiang", "X Zhang", "W Huang", "C Meinel"], "venue": "Virtual Environments, Human-Computer Interfaces and Measurement Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Kernel methods in computer vision. Foundations and Trends in Computer Graphics and Vision", "author": ["CH Lampert"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Segmenting brain tumors using pseudo\u2013conditional random fields. In: Medical Image Computing and Computer-Assisted Intervention", "author": ["C Lee", "S Wang", "A Murtha", "M Brown", "R Greiner"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "A combined mri and mrsi based multiclass system for brain tumour recognition using ls-svms with class probabilities and feature selection", "author": ["J Luts", "A Heerschap", "J Suykens", "SV Huffel"], "venue": "Artificial Intelligence in Medicine", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "The multimodal brain tumor image segmentation benchmark (brats)", "author": ["B Menze", "M Reyes", "KV Leemput"], "venue": "IEEE Trans on Medical Imaging (accepted)", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Machine learning: a probabilistic perspective", "author": ["K Murphy"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In: Advances in large margin classifiers, Citeseer", "author": ["J Platt"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Robust estimation for brain tumor segmentation. In: Medical Image Computing and Computer- Assisted Intervention-MICCAI", "author": ["M Prastawa", "E Bullitt", "S Ho", "G Gerig"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Segmenting brain tumors using alignment-based features", "author": ["M Schmidt", "I Levner", "R Greiner", "A Murtha", "A Bistritz"], "venue": "In: Int. Conf on Machine Learning and Applications,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Iterative multilevel mrf leveraging context and voxel information for brain tumour segmentation in mri", "author": ["N Subbanna", "D Precup", "T Arbel"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Comparison of supervised mri segmentation methods for tumor volume determination during therapy. Magnetic resonance imaging", "author": ["M Vaidyanathan", "L Clarke", "R Velthuizen", "S Phuphanich", "A Bensaid", "L Hall", "J Bezdek", "H Greenberg", "A Trotti", "M Silbiger"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Fluid vector flow and applications in brain tumor segmentation", "author": ["T Wang", "I Cheng", "A Basu"], "venue": "IEEE Trans Biomedical Eng", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}], "referenceMentions": [{"referenceID": 16, "context": "Manual segmentation is not only time consuming and tedious, it is also subject to variations between observers and also within the same observer [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 1, "context": "Among them, automatic methods, which rely on machine learning, are very popular and in some cases very efficient [2].", "startOffset": 113, "endOffset": 116}, {"referenceID": 16, "context": "Also, to improve generalization, these methods often compute high dimensional feature vectors [18] which add to the processing time and take up a lot of memory.", "startOffset": 94, "endOffset": 98}, {"referenceID": 3, "context": "segmentation system and achieve a competitive performance compared to the methods submitted to the brain tumor segmentation challenge (BRATSURL [5]) online evaluation benchmark.", "startOffset": 144, "endOffset": 147}, {"referenceID": 1, "context": "Most of these methods use either deformable models or classification methods to perform segmentation (see Bauer et al [2] for a survey).", "startOffset": 118, "endOffset": 121}, {"referenceID": 12, "context": "[14] used a series of intensity and texture based features to make a feature space of over 300 dimensions, on which a random forest classifier was trained.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "also used random forests [14].", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "[12] performed binary segmentation (tumor vs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] used a kernel SVM for multiclass segmentation of brain tumors, where a CRF is used to regularize the results.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "Schmidt et al [18] compared the combination of many different feature sets, such as binary mask, average intensity, left to right symmetry.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "Luts et al [13] also compared different feature selection methods such as Fisher discriminant analysis, Kruskal wallis, relief-f and ARD for LS-SVM.", "startOffset": 11, "endOffset": 15}, {"referenceID": 8, "context": "Following an energy minimization criterion, the contour shrinks down towards the borders of the tumor [10, 21].", "startOffset": 102, "endOffset": 110}, {"referenceID": 19, "context": "Following an energy minimization criterion, the contour shrinks down towards the borders of the tumor [10, 21].", "startOffset": 102, "endOffset": 110}, {"referenceID": 5, "context": "Hamamci et al [7] used a socalled CA-based method on T1 weighted images to produce a probability map for the tumor, based on seeds provided by the user.", "startOffset": 14, "endOffset": 17}, {"referenceID": 4, "context": "For a two class segmentation (tumor, edema) this method takes 1 minute for user interaction and 10-20 minutes for segmentation depending on the size of the tumor [6].", "startOffset": 162, "endOffset": 165}, {"referenceID": 6, "context": "Ho et al [8] use the difference between T1 and T1C together with a Gaussian mixture model (GMM) to get a probability map of the tumor, which is used in a level-set model to initialize the contour.", "startOffset": 9, "endOffset": 12}, {"referenceID": 15, "context": "Prastawa et al [17] used voxel registration with an atlas as a way to get a probability map for abnormalities.", "startOffset": 15, "endOffset": 19}, {"referenceID": 7, "context": "Huo et al [9] used three segmentation methods: fuzzy connectedness, GrowCut and voxel classification using SVM to generate candidate segmentations for each voxel.", "startOffset": 10, "endOffset": 13}, {"referenceID": 18, "context": "[20]", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3] also proposed a semi-automatic segmentation method that uses instead Quadratic Discriminative Aanalysis to perform multi-class segmentation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "brain tumor segmentation [18, 14].", "startOffset": 25, "endOffset": 33}, {"referenceID": 12, "context": "brain tumor segmentation [18, 14].", "startOffset": 25, "endOffset": 33}, {"referenceID": 9, "context": "Of higher interest in our setting is the kernelized version of SVM [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 9, "context": "Also, a slack variable C is used to relax the constraints in the SVM optimization problem [11].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "where f(Fv, c) is the unthresholded output of the SVM and A,B are the parameters to be estimated [16].", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "The two most popular algorithms for ensembles of decision trees are random forests and Adaboost [15].", "startOffset": 96, "endOffset": 100}, {"referenceID": 12, "context": "One approach which is commonly implemented [14] is to choose hyper-parameters by cross-validation in a grid search approach on a subset of brains and fix the selected set of hyper-parameters for the rest of the brains.", "startOffset": 43, "endOffset": 47}, {"referenceID": 3, "context": "All our experiments were conducted on real patient data obtained from the brain tumor segmentation challenge dataset (Farahani et al [5]) as part of the MICCAI conference.", "startOffset": 133, "endOffset": 136}, {"referenceID": 12, "context": "Similarly for P1 and P0 [14].", "startOffset": 24, "endOffset": 28}, {"referenceID": 12, "context": "This includes methods from the 2013 BRATS challenge published in [14] as well as anonymized unpublished methods for which no reference is available.", "startOffset": 65, "endOffset": 69}, {"referenceID": 18, "context": "We first made an experiment without including the \u3008i, j, k\u3009 position features in the feature vector as presented by [20].", "startOffset": 116, "endOffset": 120}, {"referenceID": 17, "context": "Recently Subbanna et al [19] published competitive results on the BRATS 2013 dataset, reporting Dice measures of 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "However, as mentioned in [19], their method takes 70 minutes to process a subject, which is significantly slower than our method.", "startOffset": 25, "endOffset": 29}, {"referenceID": 12, "context": "also take a similar approach using random forests [14].", "startOffset": 50, "endOffset": 54}, {"referenceID": 12, "context": "For example, Tustison\u2019s method takes around 30 minutes to process a brain as mentioned in Menze et al [14].", "startOffset": 102, "endOffset": 106}], "year": 2015, "abstractText": "Purpose: In this paper, we investigate a framework for interactive brain tumor segmentation which, at its core, treats the problem of interactive brain tumor segmentation as a machine learning problem. Methods: This method has an advantage over typical machine learning methods for this task where generalization is made across brains. The problem with these methods is that they need to deal with intensity bias correction and other MRI-specific noise. In this paper, we avoid these issues by approaching the problem as one of within brain generalization. Specifically, we propose a semi-automatic method that segments a brain tumor by training and generalizing within that brain only, based on some minimum user interaction. Conclusion: We investigate how adding spatial feature coordinates (i.e. i, j, k) to the intensity features can significantly improve the performance of different classification methods such as SVM, kNN and random forests. This would only be possible within an interactive framework. We also investigate the use of a more appropriate kernel and the adaptation of hyper-parameters specifically for each brain. \u2217mohammad.havaei@gmail.com \u2020hugo.larochelle@usherbrooke.ca \u2021philippe.Poulin2@usherbrooke.ca \u00a7pierre-marc.jodoin@usherbrooke.ca 1 ar X iv :1 51 0. 01 34 4v 1 [ cs .C V ] 5 O ct 2 01 5 Results: As a result of these experiments, we obtain an interactive method whose results reported on the MICCAI-BRATS 2013 dataset are the second most accurate compared to published methods, while using significantly less memory and processing power than most stateof-the-art methods.", "creator": "LaTeX with hyperref package"}}}