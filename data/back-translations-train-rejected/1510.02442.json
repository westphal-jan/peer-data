{"id": "1510.02442", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Oct-2015", "title": "Uniform Learning in a Deep Neural Network via \"Oddball\" Stochastic Gradient Descent", "abstract": "When training deep neural networks, it is typically assumed that the training examples are uniformly difficult to learn. Or, to restate, it is assumed that the training error will be uniformly distributed across the training examples. Based on these assumptions, each training example is used an equal number of times. However, this assumption may not be valid in many cases. \"Oddball SGD\" (novelty-driven stochastic gradient descent) was recently introduced to drive training probabilistically according to the error distribution - training frequency is proportional to training error magnitude. In this article, using a deep neural network to encode a video, we show that oddball SGD can be used to enforce uniform error across the training set.", "histories": [["v1", "Thu, 8 Oct 2015 18:55:22 GMT  (1171kb)", "http://arxiv.org/abs/1510.02442v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["andrew j r simpson"], "accepted": false, "id": "1510.02442"}, "pdf": {"name": "1510.02442.pdf", "metadata": {"source": "META", "title": "Uniform Learning in a Deep Neural Network via \"Oddball\" Stochastic Gradient Descent", "authors": ["Andrew J.R. Simpson"], "emails": ["Andrew.Simpson@Surrey.ac.uk"], "sections": [{"heading": null, "text": "This year it is more than ever before."}], "references": [{"title": "Oddball SGD\u201d: Novelty Driven Stochastic Gradient Descent for Training Deep Neural Networks\u201d, arxiv.org abs/ 1509.05765", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "On-the-Fly Learning in a Perpetual Learning Machine\u201d, arxiv.org abs/1509.00913", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Abstract Learning via Demodulation in a Deep Neural Network\u201d, arxiv.org abs/1502.04042", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors\u201d, The Computing Research Repository (CoRR), abs/1207.0580", "author": ["GE Hinton", "N Srivastava", "A Krizhevsky", "I Sutskever", "R Salakhutdinov"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Dither is Better than Dropout for Regularising Deep Neural Networks\u201d, arxiv.org abs/1508.04826", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Parallel Dither and Dropout for Regularising Deep Neural Networks\u201d, arxiv.org abs/1508.07130", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Taming the ReLU with Parallel Dither in a Deep Neural Network\u201d, arxiv.org abs/1509.05173", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "The result of this is a novelty-driven SGD known as \u201coddball SGD\u201d [1].", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "It has been demonstrated that oddball SGD can speed up learning by a large factor [1] with respect to the generalisation error on the test set.", "startOffset": 82, "endOffset": 85}, {"referenceID": 0, "context": "In order to robustly enforce uniformity of learning via oddball SGD [1], we raise the error magnitudes (across the training set) to a large power prior to normalised application as selection probability during oddball SGD.", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "Each pixel consisted of a grayscale intensity, normalised to the range [0,1].", "startOffset": 71, "endOffset": 76}, {"referenceID": 1, "context": "This is a form of arbitrary associative memory [2].", "startOffset": 47, "endOffset": 50}, {"referenceID": 1, "context": "Thus, we used the DNN as a deep [2] video encoder/decoder.", "startOffset": 32, "endOffset": 35}, {"referenceID": 0, "context": "Pixel intensities were normalized to the range [0,1].", "startOffset": 47, "endOffset": 52}, {"referenceID": 0, "context": "This vector represents the state of novelty of each training element [1].", "startOffset": 69, "endOffset": 72}, {"referenceID": 3, "context": "Dropout [4] and dither [5-7] were not used (for reasons that are beyond the scope of this article).", "startOffset": 8, "endOffset": 11}, {"referenceID": 4, "context": "Dropout [4] and dither [5-7] were not used (for reasons that are beyond the scope of this article).", "startOffset": 23, "endOffset": 28}, {"referenceID": 5, "context": "Dropout [4] and dither [5-7] were not used (for reasons that are beyond the scope of this article).", "startOffset": 23, "endOffset": 28}, {"referenceID": 6, "context": "Dropout [4] and dither [5-7] were not used (for reasons that are beyond the scope of this article).", "startOffset": 23, "endOffset": 28}, {"referenceID": 0, "context": "In this article, we have demonstrated that oddball SGD [1] may be used to enforce uniformity of learning across a training set.", "startOffset": 55, "endOffset": 58}], "year": 2015, "abstractText": "When training deep neural networks, it is typically assumed that the training examples are uniformly difficult to learn. Or, to restate, it is assumed that the training error will be uniformly distributed across the training examples. Based on these assumptions, each training example is used an equal number of times. However, this assumption may not be valid in many cases. \u201cOddball SGD\u201d (novelty-driven stochastic gradient descent) was recently introduced to drive training probabilistically according to the error distribution \u2013 training frequency is proportional to training error magnitude. In this article, using a deep neural network to encode a video, we show that oddball SGD can be used to enforce uniform error across the training set.", "creator": "PDFCreator Version 1.7.1"}}}