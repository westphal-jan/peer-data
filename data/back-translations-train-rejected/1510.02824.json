{"id": "1510.02824", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Oct-2015", "title": "On the Complexity of Inner Product Similarity Join", "abstract": "A number of tasks in classification, information retrieval, recommendation systems, and record linkage reduce to the core problem of inner product similarity join (IPS join): identifying pairs of vectors in a collection that have a sufficiently large inner product. IPS join is well understood when vectors are normalized and some approximation of inner products is allowed. However, the general case where vectors may have any length appears much more challenging. Recently, new upper bounds based on asymmetric locality-sensitive hashing (ALSH) and asymmetric embeddings have emerged, but little has been known on the lower bound side. In this paper we initiate a systematic study of inner product similarity join, showing new lower and upper bounds. Our main results are:", "histories": [["v1", "Fri, 9 Oct 2015 21:10:12 GMT  (247kb,D)", "https://arxiv.org/abs/1510.02824v1", null], ["v2", "Tue, 20 Oct 2015 09:45:18 GMT  (104kb,D)", "http://arxiv.org/abs/1510.02824v2", null], ["v3", "Thu, 7 Apr 2016 11:36:25 GMT  (166kb,D)", "http://arxiv.org/abs/1510.02824v3", "in Proc. 35th ACM Symposium on Principles of Database Systems, 2016"]], "reviews": [], "SUBJECTS": "cs.DS cs.DB cs.LG", "authors": ["thomas d ahle", "rasmus pagh", "ilya razenshteyn", "francesco silvestri"], "accepted": false, "id": "1510.02824"}, "pdf": {"name": "1510.02824.pdf", "metadata": {"source": "CRF", "title": "On the Complexity of Inner Product Similarity Join", "authors": ["Thomas D. Ahle", "Rasmus Pagh", "Ilya Razenshteyn", "Francesco Silvestri"], "emails": ["thdy@itu.dk", "pagh@itu.dk", "ilyaraz@mit.edu", "fras@itu.dk"], "sections": [{"heading": null, "text": "\u2022 New upper and lower limits for (A) LSH-based algorithms. Specifically, we show that asymmetry can be avoided by loosening the LSH definition to take into account only the collision probability of different elements. \u2022 A new indexing method for IPS based on linear sketches that implies that our hardness results are not far from being dense. Our technical contributions include new asymmetric embeddings that may be of independent interest. At the conceptual level, we strive for greater clarity, for example by distinguishing between signed and unsigned variants of IPS compounds, and by shedding new light on the effect of asymmetry."}, {"heading": "1. INTRODUCTION", "text": "This work deals with internal product similarity Join (IPS Join), where the task is to find at least one pair1 (p, q) female product similarity for each q'Q point in two groups P, Q'Rd, where the internal product (or its absolute value) exceeds a certain threshold. Our results also apply to the problem where we are looking for each q'Q. The research leading to these results was funded by the European Research Council under the Seventh Framework Programme of the European Union (FP7 / 2007-2013) / ERC Funding Agreement No. 614331. 1As our focus is on lower limits, we do not consider the more general problem of finding all such pairs. Also, note that it is customary from an upper side to limit the number of occurrences of each tuple in a compound to a certain number k.of vector p'P maximizing the inner product, a search problem known in the literature as maximum search for internal product MIPS (45) [45]."}, {"heading": "Motivation", "text": "Similarity links have been extensively studied in the database and in information gathering communities as a mechanism for linking noisy or incomplete data (see e.g. [6, 61]). In particular, it is now known that in many cases it is possible to improve the square time complexity of a naive algorithm that explicitly takes into account all pairs of tuples. In the database community, the most prominent technique used to demonstrably achieve a subquadratic runtime is location-dependent hash (LSH) [25, 24]. In the database community, similarity links were originally linked through applications in data purification [17, 10]. However, it has since become clear that similarities combine for a number of other data processing applications such as clustering, semi-supervised learning and collaborative filtering (see e.g. [44] and other examples of similarities between the available systems]."}, {"heading": "Challenges of IPS join", "text": "In fact, there are reasons why Xiv: 151 0.02 824v 3 [cs.D S] 7 April 201 6 to believe that internal product similarity may be inherently more difficult than other types of similarity search: Williams [56, 4] has shown that a truly subquadratic exact algorithm for IPS compounds would contradict the Strong Exponential Time hypothesis, an important conjecture regarding computational complexity. On the upside, new reductions of (special cases of) approximate IPS compounds for fast matrix multiplication [51, 29] have been found, leading to truly subquadratic algorithms even with approximation factors asymptotically close to 1."}, {"heading": "Problem definitions", "text": "We are interested in two variants of IPS accession, which differ slightly in the wording of the objective function."}, {"heading": "1.1 Overview of results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Hardness results", "text": "The first results of the work are conditional lower limits for approximate signed and unsigned IPS compounds, which are based on a conjecture about the orthogonal vector problem (OVP), which consists in determining whether two sentences A, B {0, 1} d, each with n vectors, contain x-A and y-B, so that xT y = 0. It is assumed that there can be no algorithm that solves OVP in O (n2 \u2212) as soon as d = n (log n), for a given constant > 0. In fact, such an algorithm would imply that the Strong Exponential Time Hypothesis (SETH) is true [56]. Many recent interesting hardness results are based on reductions of OVP, but we believe that our first example of using the conjecture is to show the conditional hardness for a harmless problem."}, {"heading": "Then the OVP conjecture is false.", "text": "For the search problem, Theorem 1 implies that, assuming the OVP presumption, there is little data structure for signed / unsigned (cs, s) internal product search with (nd) O (1) build time and n1 \u2212 dO (1) query time, for constant > 0. This is followed by considering a join instance with an alpha constant small enough that we can build the data structure on P in time o (nd). We can then query all points of Q in time n1 + \u03b1 (1), which contradicts the OVP conjection. Our result can be seen as an explanation for why all LSH schemes for IPS are not able to provide sub-linear query times for small s. However, since the theorem does not cover the case where c is very small, e.g. n \u2212 eg for unsigned {\u2212 1} d, we show in Section 4 that there are useful data structures."}, {"heading": "Then the OVP conjecture is false.", "text": "The {\u2212 1} d case seems to be harder than the {0, 1} d case. In fact, Valiant [51] reduces the general case of P, Q Rd to the case P, Q {\u2212 1, 1} d with the Charikar hyperplane LSH [15]. Another piece of evidence is that we have an even better data runtime n1 + Log (s / d) Log (s / d) Log (s / d) Log (s / d) Log (s / d) Log (s / d) Log (s / d) Log (s / d) with LSH for {0, 1} d is particularly interesting as it is common in practice, for example, when the vectors represent sentences. A better understanding of the upper and lower limits for this case is a nice open problem. For a ellaborate comparison of the different upper and lower limits, see Table 1. Techniques."}, {"heading": "IPS upper bounds", "text": "We first show that it is possible to improve the asymmetric LSH in [39, 46] by simply inserting the best known data structure for Approximate Near Neighborfor '2 on a sphere [9] into the decrease in [39, 12]. However, with data / query points in the single ball, this LSH reaches for some areas of c and s.Then we show how to get around the impossibility by showing that there is a symmetric LSH when the data and the query space coincide, by allowing the limits of collision probability not to be met if the data and query vectors are identical. \u2212 We conclude by describing a data structure based on the line sketches for' p in the given time [5], which are not sufficient for each given time (1) < we conclude by describing a data structure that achieves a similar structure for each given time (1) based on the safe time [1]."}, {"heading": "1.2 Previous work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Similarity join", "text": "Similar connectivity problems have been extensively investigated in database literature (e.g. [17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), in information search (e.g. [14, 21, 59]), and in the discovery of knowledge (e.g. [3, 13, 54, 60, 62]). Most literature takes into account algorithms for certain metrics (the task being to connect tuples that are close according to the metric) or specific areas of application (e.g. the detection of near-duplicates). A distinction is made between methods that approximate distances in the sense that we only care about distances up to a factor c > 1, and methods that take exact distances into account. Known exact methods do not guarantee subquadratic runtime. It has recently been demonstrated how approximate LSH-based similarity connections can be made I / O efficient [41]."}, {"heading": "IPS join", "text": "The inner product similarity in the case of normalized vectors is known as \"cosinal similarity\" and is well understood [16, 33, 43]. While the general case in which vectors may be of arbitrary length appears theoretically challenging, practice-efficient indices for unsigned search based on tree data structures in combination with a technique of bipartition similar to k-d trees and in [12] based on main axis trees were proposed in [43, 30]. Document term vectors Low and Zheng [35] showed that unsigned searches can be accelerated using matrix compression. However, like many similarity problems, the exact version considered in these papers suffers from the curse of dimensionality [55]. The efficiency of approximate IPS approaches based on LSH is investigated in [45, 39]. These papers show that a traditional LSH domain exists if the domain domain is automatically the domain domain domain domain number 46 and if it is the unit suction within it is significant."}, {"heading": "Algebraic techniques", "text": "Finally, more recent breakthroughs were achieved in both approximate (unsigned) connection problem and exact problem. Valiant [51] showed how to reduce the problem to matrix multiplication when cs \u2248 O (\u221a n) and s \u2248 O (n), which significantly improves the asymptotic time complexity of approaches based on LSH. Recently, this technique was improved by Karppa et al. [29], which also generalized sub-quadratic runtime to the case when log (s) / log (cs) is small. In another surprising development, Alman and Williams [4] showed that for d = O (log n) dimensions, truly subquadratic algorithms for the exact IPS connection problem are possible on binary vectors. Their algorithm is based on an algebraic technique (probable polynomials) and tools from circuit complexity."}, {"heading": "2. HARDNESS OF IPS JOIN", "text": "In the next section 2.1, we will first give an overview of the OVP and the conjectures associated with it. Then, in Section 2.2, we will prove theorem 1 by describing some reductions from the OVP to signed / unsigned connections."}, {"heading": "2.1 Preliminaries", "text": "The orthogonal vector problem (OVP) is defined as follows: Definition 3 (OVP) > Q > D = D = D. Given two sentences P and Q, each containing n vectors in {0, 1} d, we can tell if there are vectors p-P and q-Q, so that pT q = 0. OVP derives its hardness from the Strong Exponential Time Hypothesis (Williams [56]), but could potentially be true even if SETH does not exist. Therefore, we assume the following plausible conjecture: 3Conjecture 1 (OVP, [56]). For each constant > 0, there is no algorithm for OVP with | P | = | Q | = n and dimension d = O (log n) runs in O (n2 \u2212) time.The conjecture does not apply to d = O (log n): Recently Abboud et al. [1] we have proposed an algorithm for OVP."}, {"heading": "2.2 Reductions from OVP", "text": "We will do this by showing the existence of certain efficient \"gap embeddings\" that make orthogonality with connections detectable. We need the following definition: Definition 4 (Gap Embedding) = q = q. An unsigned (d1, d2, cs, s) gap in domain A is a pair of functions (f, g): {0, 1} d1 \u2192 Ad 2, where d \u00b2 2 \u2264 d2, and for each x, y \u00b2 d1, d1} d1: (f) d1, T g (y) | s, if xT y = 0 (x) t \u00b2 d1, if xT y = 1A is analog to \"signed embedding,\" but without the absolute value symbols. We still require that the functions f and g can be evaluated polynomially to d2.Gap embeddings in time."}, {"heading": "3. LIMITATIONS OF LSH FOR IPS", "text": "We provide an upper limit on the gap between P1 and P2 for an (s, cs, P1, P2) asymmetric LSH for signed / unsigned IPS. For simplicity's sake, we assume that the data and query domains contain the d-dimensional spheres of radius 1 and U \u2265 1. < The limit applies to a fixed set of data vectors, so does the data-dependent LSH [9]. One consequence of our result is that there can be no asymmetric LSH for each dimension d 1 if the set of query vectors is unlimited to obtain a result similar to that of [39], but which requires the data space to be unlimited. We show in Lemma 4 that the gap P1 \u2212 P2 can be expressed as a function of the length of two sequences of query and data vectors with appropriate collision properties."}, {"heading": "4. UPPER BOUNDS", "text": "This section contains three observations with implications for IPS accession and its indexing version. First, in Section 4.1, we note that by inserting the best-known LSH for \"2 distances on a sphere [9] into a reduction represented in [12, 39], we obtain a data structure based on LSH for signed MIPS with the search time component \u03c1 = (1 \u2212 s) / (1 + (1 \u2212 2c) s. Then, in Section 4.2, we show how to bypass the results in [39, 45] which show that symmetrical LSH is not possible when the data and query domains match (although there is an asymmetrical LSH). We use a slightly modified definition of LSH that disregards the collision probability of 1 for pairs of identical vectors, and assume that vectors are represented with finite precision (the LSH-38 construction is used by solved from a matrix containing 39)."}, {"heading": "4.1 Asymmetric LSH for signed IPS", "text": "We assume that the data and query ranges are ddimensional spheres with corresponding radius 1 and U. Vectors are embedded in a (d + 2) -dimensional sphere of unity, using the asymmetric map as in [39]: a data vector p is mapped to (p, \u221a 1 \u2212 | p | | | 2, 0), while a query q is mapped to (q / U, 0, \u221a 1 \u2212 | | 2 / U2). This transformation scales only the inner product by a factor U, and therefore the search for a signed inner product can be seen as an example of ANN in '2, using the distance threshold r = 2 (1 \u2212 s / U) and the approximation c \u2032 = (1 \u2212 cs / U) / (1 \u2212 s / U). The latter can be solved in space (n1 + \u03c1 + dn) and the query of time O (nO) using the LSH construction [9]."}, {"heading": "4.2 Symmetric LSH for almost all vectors", "text": "Neyshabur and Srebro [39] show that an asymmetrical view of LSH is required for signed IPS = any x-unit. In fact, they show that a symmetrical LSH for signed IPS does not exist if data and query domains are balls of the same radius, while an asymmetrical LSH exists. (On the other hand, if the data domain is a ball of the given radius U and the query domain is a sphere of the same radius, a symmetrical LSH actually exists.) In this section, we show that even if data and query spaces match a non-trivial symmetrical LSH, if we disregard the trivial collision probability of 1, if data and query vectors are identical, then a symmetrical LSH exists."}, {"heading": "4.3 Unsigned IPS via linear sketches", "text": "In this section we propose a linear unsignedc MIPS sketch that can be used for solving insignificant (cs, s) data structures. < # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "5. CONCLUSION", "text": "This paper has examined various aspects of the complexity of the approximate similarity associated with the inner product. In particular, we have linked the severity of this problem to the OVP conjecture. Under some assumptions about c and s, the proposed conditional lower limits exclude algorithms for signed / unsigned (cs, s) IPS connections that expire in n2 \u2212 time for a constant > 0 unless the OVP conjecture is wrong. Nevertheless, the data structures in Section 4 show that it is still possible to achieve weak subquadratic time, and even really subquadratic time for small values of the approximation factor. The hardness of signed / unsigned IPS applies even to weak approximation factors when the vector domain {\u2212 1, 1} d. In fact, the result applies if c \u2265 0 is signed connections and if c \u0430 e (o \u2212 log / log is unsigned) to the inner product."}, {"heading": "6. REFERENCES", "text": "[1] A. Abboud, R. Williams and H. Yu. More Applications of the Polynomial Method to Algorithm Design (FOA 2015)."}], "references": [{"title": "More applications of the polynomial method to algorithm design", "author": ["A. Abboud", "R. Williams", "H. Yu"], "venue": "In Proc. 26th ACM-SIAM Symposium on Discrete Algorithms (SODA),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Handbook of mathematical functions: with formulas, graphs, and mathematical tables", "author": ["M. Abramowitz", "I.A. Stegun"], "venue": "Courier Corporation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1964}, {"title": "Two-locus association mapping in subquadratic time", "author": ["P. Achlioptas", "B. Sch\u00f6lkopf", "K. Borgwardt"], "venue": "In Proc. 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Probabilistic polynomials and hamming nearest neighbors", "author": ["J. Alman", "R. Williams"], "venue": "In Proc. 56th IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "High frequency moments via max-stability", "author": ["A. Andoni"], "venue": "Unpublished manuscript,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions", "author": ["A. Andoni", "P. Indyk"], "venue": "Commun. ACM,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Practical and optimal LSH for angular distance", "author": ["A. Andoni", "P. Indyk", "M. Kapralov", "T. Laarhoven", "I. Razenshteyn", "L. Schmidt"], "venue": "In Proc. 28th Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Sketching and embedding are equivalent for norms", "author": ["A. Andoni", "R. Krauthgamer", "I.P. Razenshteyn"], "venue": "In Proc. 47th ACM on Symposium on Theory of Computing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Optimal data-dependent hashing for approximate near neighbors", "author": ["A. Andoni", "I. Razenshteyn"], "venue": "In Proc. 47th Symposium on Theory of Computing (STOC),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Efficient exact set-similarity joins", "author": ["A. Arasu", "V. Ganti", "R. Kaushik"], "venue": "In Proc. International  Conference on Very Large Data Bases (VLDB),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Similarity joins in relational database systems", "author": ["N. Augsten", "M.H. B\u00f6hlen"], "venue": "Synthesis Lectures on Data Management,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Speeding up the xbox recommender system using a euclidean transformation for inner-product spaces", "author": ["Y. Bachrach", "Y. Finkelstein", "R. Gilad-Bachrach", "L. Katzir", "N. Koenigstein", "N. Nice", "U. Paquet"], "venue": "In Proc. 8th ACM Conference on Recommender Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Efficient distributed locality sensitive hashing", "author": ["B. Bahmani", "A. Goel", "R. Shinde"], "venue": "In Proc. ACM International Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Scaling up all pairs similarity search", "author": ["R.J. Bayardo", "Y. Ma", "R. Srikant"], "venue": "In Proc. International Conference on World Wide Web (WWW),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Similarity estimation techniques from rounding algorithms", "author": ["M.S. Charikar"], "venue": "In Proc. 34 ACM Symposium on Theory of computing (STOC),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Similarity estimation techniques from rounding algorithms", "author": ["M.S. Charikar"], "venue": "In Proc. 34th ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "A primitive operator for similarity joins in data cleaning", "author": ["S. Chaudhuri", "V. Ganti", "R. Kaushik"], "venue": "In Proc.22nd International Conference on Data Engineering (ICDE),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Efficient evaluation of all-nearest-neighbor queries", "author": ["Y. Chen", "J.M. Patel"], "venue": "In Proc. International Conference on Data Engineering (ICDE),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Finding interesting associations without support pruning", "author": ["E. Cohen", "M. Datar", "S. Fujiwara", "A. Gionis", "P. Indyk", "R. Motwani", "J.D. Ullman", "C. Yang"], "venue": "IEEE Trans. Knowl. Data Eng.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2001}, {"title": "Fast exact max-kernel search", "author": ["R.R. Curtin", "A.G. Gray", "P. Ram"], "venue": "In Proc. 13th SIAM International Conference on Data Mining (SDM),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Google news personalization: scalable online collaborative filtering", "author": ["A. Das", "M. Datar", "A. Garg", "S. Rajaram"], "venue": "In Proc. International Conference on World Wide Web (WWW),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Fast, accurate detection of 100,000 object classes on a single machine", "author": ["T. Dean", "M. Ruzon", "M. Segal", "J. Shlens", "S. Vijayanarasimhan", "J. Yagnik"], "venue": "In Proc. IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Object detection with discriminatively trained part-based models", "author": ["P. Felzenszwalb", "R. Girshick", "D. McAllester", "D. Ramanan"], "venue": "IEEE  Transactions on Pattern Analysis and Machine Intelligence,,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Similarity search in high dimensions via hashing", "author": ["A. Gionis", "P. Indyk", "R. Motwani"], "venue": "In Proc. 25th International Conference on Very Large Data Bases (VLDB),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1999}, {"title": "Approximate nearest neighbor: Towards removing the curse of dimensionality", "author": ["S. Har-Peled", "P. Indyk", "R. Motwani"], "venue": "Theory of computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Metric space similarity joins", "author": ["E.H. Jacox", "H. Samet"], "venue": "ACM Transactions on Database Systems (TODS),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Efficient parallel partition-based algorithms for similarity search and join with edit distance constraints", "author": ["Y. Jiang", "D. Deng", "J. Wang", "G. Li", "J. Feng"], "venue": "In Proc. Joint EDBT/ICDT Workshops,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Cutting-plane training of structural svms", "author": ["T. Joachims", "T. Finley", "C.-N.J. Yu"], "venue": "Mach. Learn.,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "A faster subquadratic algorithm for finding outlier correlations", "author": ["M. Karppa", "P. Kaski", "J. Kohonen"], "venue": "In Proc. 27th ACM-SIAM Symposium on Discrete Algorithms", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Efficient retrieval of recommendations in a matrix factorization framework", "author": ["N. Koenigstein", "P. Ram", "Y. Shavitt"], "venue": "In Proc. 21st ACM International Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "The johnson-lindenstrauss lemma is optimal for linear dimensionality reduction", "author": ["K.G. Larsen", "J. Nelson"], "venue": "CoRR, abs/1411.2404,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "An efficient similarity join algorithm with cosine similarity predicate", "author": ["D. Lee", "J. Park", "J. Shim", "S.-g. Lee"], "venue": "In Database and Expert Systems Applications,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Pass-join: A partition-based method for similarity joins", "author": ["G. Li", "D. Deng", "J. Wang", "J. Feng"], "venue": "Proc. VLDB Endowment,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Fast top-k similarity queries via matrix compression", "author": ["Y. Low", "A.X. Zheng"], "venue": "In Proc. ACM International Conference on Information and Knowledge Management (CIKM)KM,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2012}, {"title": "String similarity measures and joins with synonyms", "author": ["J. Lu", "C. Lin", "W. Wang", "C. Li", "H. Wang"], "venue": "In Proc. 2013 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Lower bounds on locality sensitive hashing", "author": ["R. Motwani", "A. Naor", "R. Panigrahi"], "venue": "In Proc. 22nd Symposium on Computational Geometry (SoCS),", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "On deterministic sketching and streaming for sparse recovery and norm estimation", "author": ["J. Nelson", "H.L. Nguyen", "D.P. Woodruff"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "On symmetric and asymmetric lshs for inner product search", "author": ["B. Neyshabur", "N. Srebro"], "venue": "In Proc. 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2015}, {"title": "Optimal lower bounds for locality-sensitive hashing (except when q is tiny)", "author": ["R. O\u2019Donnell", "Y. Wu", "Y. Zhou"], "venue": "ACM Trans. Comput. Theory,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "I/O-efficient similarity join", "author": ["R. Pagh", "N. Pham", "F. Silvestri", "M. St\u00f6ckel"], "venue": "In Proc. 23rd European Symposium on Algorithms (ESA),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Approximate furthest neighbor in high dimensions", "author": ["R. Pagh", "F. Silvestri", "J. Sivertsen", "M. Skala"], "venue": "In Proc. 8th International Conference on Similarity Search and Applications (SISAP),", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Maximum inner-product search using cone trees", "author": ["P. Ram", "A.G. Gray"], "venue": "In Proc. 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2012}, {"title": "Bayesian locality sensitive hashing for fast similarity search", "author": ["V. Satuluri", "S. Parthasarathy"], "venue": "Proc. VLDB Endowment,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}, {"title": "Asymmetric LSH (ALSH) for sublinear time maximum inner product search (MIPS)", "author": ["A. Shrivastava", "P. Li"], "venue": "In Proc. 27th Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2014}, {"title": "Asymmetric minwise hashing for indexing binary inner products and set containment", "author": ["A. Shrivastava", "P. Li"], "venue": "In Proc. 24th International Conference on World Wide Web (WWW),", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "The similarity join database operator", "author": ["Y.N. Silva", "W.G. Aref", "M.H. Ali"], "venue": "In Proc. International Conference on Data Engineering (ICDE),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2010}, {"title": "Maximum-margin matrix factorization", "author": ["N. Srebro", "J.D.M. Rennie", "T.S. Jaakola"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2005}, {"title": "Rank, trace-norm and max-norm", "author": ["N. Srebro", "A. Shraibman"], "venue": "In Proc. 18th Conference on Learning Theory COLT, volume 3559 of LNCS,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2005}, {"title": "Lemp: Fast retrieval of large entries in a matrix product", "author": ["C. Teflioudi", "R. Gemulla", "O. Mykytiuk"], "venue": "In Proc. ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2015}, {"title": "Finding correlations in subquadratic time, with applications to learning parities and the closest pair problem", "author": ["G. Valiant"], "venue": "J. ACM,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2015}, {"title": "Fast-join: An efficient method for fuzzy token matching based string similarity join", "author": ["J. Wang", "G. Li", "J. Fe"], "venue": "In Proc. International Conference on Data Engineering (ICDE),", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2011}, {"title": "Can we beat the prefix filtering?: an adaptive framework for similarity join and search", "author": ["J. Wang", "G. Li", "J. Feng"], "venue": "In Proc. ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2012}, {"title": "Scalable all-pairs similarity search in metric spaces", "author": ["Y. Wang", "A. Metwally", "S. Parthasarathy"], "venue": "In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2013}, {"title": "A quantitative analysis and performance study for similarity-search methods in high-dimensional spaces", "author": ["R. Weber", "H.-J. Schek", "S. Blott"], "venue": "In Proc. 24rd International Conference on Very Large Data Bases (VLDB),", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1998}, {"title": "A new algorithm for optimal 2-constraint satisfaction and its implications", "author": ["R. Williams"], "venue": "Theoretical Computer Science,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2005}, {"title": "Sketching as a tool for numerical linear algebra", "author": ["D.P. Woodruff"], "venue": "Foundations and Trends in Theoretical Computer Science,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2014}, {"title": "Gorder: an efficient method for knn join processing", "author": ["C. Xia", "H. Lu", "B.C. Ooi", "J. Hu"], "venue": "In Proc. VLDB,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2004}, {"title": "Efficient similarity joins for near duplicate detection", "author": ["C. Xiao", "W. Wang", "X. Lin", "J.X. Yu"], "venue": "In Proc. International Conference on World Wide Web (WWW),", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2008}, {"title": "Dimension independent similarity computation", "author": ["R.B. Zadeh", "A. Goel"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2013}, {"title": "Similarity search: the metric space approach, volume 32", "author": ["P. Zezula", "G. Amato", "V. Dohnal", "M. Batko"], "venue": "Springer Science & Business Media,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2006}, {"title": "Fastanova: an efficient algorithm for genome-wide association study", "author": ["X. Zhang", "F. Zou", "W. Wang"], "venue": "In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2008}], "referenceMentions": [{"referenceID": 42, "context": "the vector p \u2208 P that maximizes the inner product, a search problem known in literature as maximum inner product search (MIPS) [43, 45].", "startOffset": 127, "endOffset": 135}, {"referenceID": 44, "context": "the vector p \u2208 P that maximizes the inner product, a search problem known in literature as maximum inner product search (MIPS) [43, 45].", "startOffset": 127, "endOffset": 135}, {"referenceID": 5, "context": "[6, 61]).", "startOffset": 0, "endOffset": 7}, {"referenceID": 60, "context": "[6, 61]).", "startOffset": 0, "endOffset": 7}, {"referenceID": 24, "context": "The most prominent technique used to achieve provably subquadratic running time is locality-sensitive hashing (LSH) [25, 24].", "startOffset": 116, "endOffset": 124}, {"referenceID": 23, "context": "The most prominent technique used to achieve provably subquadratic running time is locality-sensitive hashing (LSH) [25, 24].", "startOffset": 116, "endOffset": 124}, {"referenceID": 16, "context": "In the database community the similarity join problem was originally motivated by applications in data cleaning [17, 10].", "startOffset": 112, "endOffset": 120}, {"referenceID": 9, "context": "In the database community the similarity join problem was originally motivated by applications in data cleaning [17, 10].", "startOffset": 112, "endOffset": 120}, {"referenceID": 43, "context": "[44] for references and further examples).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "We refer to the recent book by Augsten and B\u00f6hlen [11] for more background on similarity join algorithms in database systems.", "startOffset": 50, "endOffset": 54}, {"referenceID": 30, "context": "Inner product is an important measure of similarity between real vectors, particularly in information retrieval and machine learning contexts [31, 48], but not captured by techniques for metric similarity joins such as [26, 61].", "startOffset": 142, "endOffset": 150}, {"referenceID": 47, "context": "Inner product is an important measure of similarity between real vectors, particularly in information retrieval and machine learning contexts [31, 48], but not captured by techniques for metric similarity joins such as [26, 61].", "startOffset": 142, "endOffset": 150}, {"referenceID": 25, "context": "Inner product is an important measure of similarity between real vectors, particularly in information retrieval and machine learning contexts [31, 48], but not captured by techniques for metric similarity joins such as [26, 61].", "startOffset": 219, "endOffset": 227}, {"referenceID": 60, "context": "Inner product is an important measure of similarity between real vectors, particularly in information retrieval and machine learning contexts [31, 48], but not captured by techniques for metric similarity joins such as [26, 61].", "startOffset": 219, "endOffset": 227}, {"referenceID": 49, "context": "[50] studied the IPS join problem motivated by applications in recommender systems based on latent-factor models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Other examples of applications for IPS join are object detection [23] and multi-class prediction [22, 28].", "startOffset": 65, "endOffset": 69}, {"referenceID": 21, "context": "Other examples of applications for IPS join are object detection [23] and multi-class prediction [22, 28].", "startOffset": 97, "endOffset": 105}, {"referenceID": 27, "context": "Other examples of applications for IPS join are object detection [23] and multi-class prediction [22, 28].", "startOffset": 97, "endOffset": 105}, {"referenceID": 19, "context": "IPS join also captures the so-called maximum kernel search, a general machine learning approach with applications such as image matching and finding similar protein/DNA sequences [20].", "startOffset": 179, "endOffset": 183}, {"referenceID": 55, "context": "to believe that inner product similarity may be inherently more difficult than other kinds of similarity search: Williams [56, 4] has shown that a truly subquadratic exact algorithm for IPS join would contradict the Strong Exponential Time Hypothesis, an important conjecture in computational complexity.", "startOffset": 122, "endOffset": 129}, {"referenceID": 3, "context": "to believe that inner product similarity may be inherently more difficult than other kinds of similarity search: Williams [56, 4] has shown that a truly subquadratic exact algorithm for IPS join would contradict the Strong Exponential Time Hypothesis, an important conjecture in computational complexity.", "startOffset": 122, "endOffset": 129}, {"referenceID": 50, "context": "On the upper bound side new reductions of (special cases of) approximate IPS join to fast matrix multiplication have appeared [51, 29], resulting in truly subquadratic algorithms even with approximation factors asymptotically close to 1.", "startOffset": 126, "endOffset": 134}, {"referenceID": 28, "context": "On the upper bound side new reductions of (special cases of) approximate IPS join to fast matrix multiplication have appeared [51, 29], resulting in truly subquadratic algorithms even with approximation factors asymptotically close to 1.", "startOffset": 126, "endOffset": 134}, {"referenceID": 44, "context": "The idea is to consider collisions between two different hash functions, using one hash function for query vectors and another hash function for data vectors [45, 46, 39].", "startOffset": 158, "endOffset": 170}, {"referenceID": 45, "context": "The idea is to consider collisions between two different hash functions, using one hash function for query vectors and another hash function for data vectors [45, 46, 39].", "startOffset": 158, "endOffset": 170}, {"referenceID": 38, "context": "The idea is to consider collisions between two different hash functions, using one hash function for query vectors and another hash function for data vectors [45, 46, 39].", "startOffset": 158, "endOffset": 170}, {"referenceID": 44, "context": "In this paper, we use the following definition of asymmetric LSH based on the definition in [45].", "startOffset": 92, "endOffset": 96}, {"referenceID": 5, "context": "The \u03c1 value of an (asymmetric) LSH is defined as usual with \u03c1 = logP1/ logP2 [6].", "startOffset": 77, "endOffset": 80}, {"referenceID": 55, "context": "Indeed, such an algorithm would imply that the Strong Exponential Time Hypothesis (SETH) is true [56].", "startOffset": 97, "endOffset": 101}, {"referenceID": 28, "context": "[29], who get sub-quadratic running time for unsigned join of normalized vectors in {\u22121, 1}, when log(s/d)/ log(cs/d) is a constant smaller than 1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "In fact Valiant [51] reduces the general case of P,Q \u2286 R to the case P,Q \u2286 {\u22121, 1} using the Charikar hyperplane LSH [15].", "startOffset": 16, "endOffset": 20}, {"referenceID": 14, "context": "In fact Valiant [51] reduces the general case of P,Q \u2286 R to the case P,Q \u2286 {\u22121, 1} using the Charikar hyperplane LSH [15].", "startOffset": 117, "endOffset": 121}, {"referenceID": 50, "context": "For the {\u22121, 1} we use an enhanced, deterministic version of the \u201cChebyshev embedding\u201d [51], while for the interesting {0, 1} part, we initiate a study of embeddings for restricted alphabets.", "startOffset": 87, "endOffset": 91}, {"referenceID": 38, "context": "As a special case, we get the impossibility result in [39, 45], that there cannot exist an asymmetric LSH for unbounded query vectors.", "startOffset": 54, "endOffset": 62}, {"referenceID": 44, "context": "As a special case, we get the impossibility result in [39, 45], that there cannot exist an asymmetric LSH for unbounded query vectors.", "startOffset": 54, "endOffset": 62}, {"referenceID": 28, "context": "Unsigned (cs, s) over {\u22121, 1} c \u2265 e \u221a log n log log n ) c < n\u2212 [29] log(s/d)", "startOffset": 63, "endOffset": 67}, {"referenceID": 28, "context": "log(cs/d) \u2265 1\u2212 o( 1 logn ) [29] log(s/d) log(cs/d) = 1\u2212 [29]", "startOffset": 27, "endOffset": 31}, {"referenceID": 28, "context": "log(cs/d) \u2265 1\u2212 o( 1 logn ) [29] log(s/d) log(cs/d) = 1\u2212 [29]", "startOffset": 56, "endOffset": 60}, {"referenceID": 28, "context": "The upper bounds cited to [29] use fast matrix multiplication, whereas the rest don\u2019t and are usable as data structures.", "startOffset": 26, "endOffset": 30}, {"referenceID": 36, "context": "Indeed, previous results [37, 40] have investigated lower bounds for symmetric LSH and it is not clear if they can be extended to the asymmetric case.", "startOffset": 25, "endOffset": 33}, {"referenceID": 39, "context": "Indeed, previous results [37, 40] have investigated lower bounds for symmetric LSH and it is not clear if they can be extended to the asymmetric case.", "startOffset": 25, "endOffset": 33}, {"referenceID": 38, "context": "The starting point of our proof is the same as in [39]: Use a collision matrix given by two sequences of data and query vectors that force the gap to be small.", "startOffset": 50, "endOffset": 54}, {"referenceID": 38, "context": "The proof in [39] then applies an asymptotic analysis of the margin complexity of this matrix [49], and it shows that for any given value of P1 \u2212 P2 there are sufficiently large data and query domains for which the gap must be smaller.", "startOffset": 13, "endOffset": 17}, {"referenceID": 48, "context": "The proof in [39] then applies an asymptotic analysis of the margin complexity of this matrix [49], and it shows that for any given value of P1 \u2212 P2 there are sufficiently large data and query domains for which the gap must be smaller.", "startOffset": 94, "endOffset": 98}, {"referenceID": 38, "context": "Our method also highlights a dependency of the gap on the dimension, which is missing in [39].", "startOffset": 89, "endOffset": 93}, {"referenceID": 38, "context": "We first show that it is possible to improve the asymmetric LSH in [39, 46] by just plugging the best known data structure for Approximate Near Neighbor for `2 on a sphere [9] into the reduction in [39, 12].", "startOffset": 67, "endOffset": 75}, {"referenceID": 45, "context": "We first show that it is possible to improve the asymmetric LSH in [39, 46] by just plugging the best known data structure for Approximate Near Neighbor for `2 on a sphere [9] into the reduction in [39, 12].", "startOffset": 67, "endOffset": 75}, {"referenceID": 8, "context": "We first show that it is possible to improve the asymmetric LSH in [39, 46] by just plugging the best known data structure for Approximate Near Neighbor for `2 on a sphere [9] into the reduction in [39, 12].", "startOffset": 172, "endOffset": 175}, {"referenceID": 38, "context": "We first show that it is possible to improve the asymmetric LSH in [39, 46] by just plugging the best known data structure for Approximate Near Neighbor for `2 on a sphere [9] into the reduction in [39, 12].", "startOffset": 198, "endOffset": 206}, {"referenceID": 11, "context": "We first show that it is possible to improve the asymmetric LSH in [39, 46] by just plugging the best known data structure for Approximate Near Neighbor for `2 on a sphere [9] into the reduction in [39, 12].", "startOffset": 198, "endOffset": 206}, {"referenceID": 45, "context": "In the {0, 1} domain, this LSH improves upon the state of the art [46] for some ranges of c and s.", "startOffset": 66, "endOffset": 70}, {"referenceID": 38, "context": "Then we show how to circumvent the impossibility results in [39, 45] by showing that there exists a symmetric LSH when the data and query space coincide by allowing the bounds on collision probability to not hold when the data and query vectors are identical.", "startOffset": 60, "endOffset": 68}, {"referenceID": 44, "context": "Then we show how to circumvent the impossibility results in [39, 45] by showing that there exists a symmetric LSH when the data and query space coincide by allowing the bounds on collision probability to not hold when the data and query vectors are identical.", "startOffset": 60, "endOffset": 68}, {"referenceID": 4, "context": "We conclude by describing a data structure based on the linear sketches for `p in [5] for unsigned (cs, s) search: for any given 0 < \u03ba \u2264 1/2, the data structure yields a c = 1/n approximation with \u00d5 ( dn2\u22122/\u03ba ) construction", "startOffset": 82, "endOffset": 85}, {"referenceID": 28, "context": "We note that the result in [29] also reaches subquadtratic time for the {\u22121, 1} case.", "startOffset": 27, "endOffset": 31}, {"referenceID": 16, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 17, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 18, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 25, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 26, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 33, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 35, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 46, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 51, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 52, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 57, "context": "[17, 18, 19, 26, 27, 34, 36, 47, 52, 53, 58]), as well as in information retrieval (e.", "startOffset": 0, "endOffset": 44}, {"referenceID": 13, "context": "[14, 21, 59]), and knowledge discovery (e.", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[14, 21, 59]), and knowledge discovery (e.", "startOffset": 0, "endOffset": 12}, {"referenceID": 58, "context": "[14, 21, 59]), and knowledge discovery (e.", "startOffset": 0, "endOffset": 12}, {"referenceID": 2, "context": "[3, 13, 54, 60, 62]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 12, "context": "[3, 13, 54, 60, 62]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 53, "context": "[3, 13, 54, 60, 62]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 59, "context": "[3, 13, 54, 60, 62]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 61, "context": "[3, 13, 54, 60, 62]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 40, "context": "It was recently shown how approximate LSH-based similarity join can be made I/O-efficient [41].", "startOffset": 90, "endOffset": 94}, {"referenceID": 15, "context": "The inner product similarity for the case of normalized vectors is known as \u201ccosine similarity\u201d and it is well understood [16, 33, 43].", "startOffset": 122, "endOffset": 134}, {"referenceID": 32, "context": "The inner product similarity for the case of normalized vectors is known as \u201ccosine similarity\u201d and it is well understood [16, 33, 43].", "startOffset": 122, "endOffset": 134}, {"referenceID": 42, "context": "The inner product similarity for the case of normalized vectors is known as \u201ccosine similarity\u201d and it is well understood [16, 33, 43].", "startOffset": 122, "endOffset": 134}, {"referenceID": 42, "context": "While the general case where vectors may have any length appears theoretically challenging, practically efficient indexes for unsigned search were proposed in [43, 30], based on tree data structures combined with a branch-and-bound space partitioning technique similar to k-d trees, and in [12] based on principal component axes trees.", "startOffset": 159, "endOffset": 167}, {"referenceID": 29, "context": "While the general case where vectors may have any length appears theoretically challenging, practically efficient indexes for unsigned search were proposed in [43, 30], based on tree data structures combined with a branch-and-bound space partitioning technique similar to k-d trees, and in [12] based on principal component axes trees.", "startOffset": 159, "endOffset": 167}, {"referenceID": 11, "context": "While the general case where vectors may have any length appears theoretically challenging, practically efficient indexes for unsigned search were proposed in [43, 30], based on tree data structures combined with a branch-and-bound space partitioning technique similar to k-d trees, and in [12] based on principal component axes trees.", "startOffset": 290, "endOffset": 294}, {"referenceID": 34, "context": "For document term vectors Low and Zheng [35] showed that unsigned search can be sped up using matrix compression ideas.", "startOffset": 40, "endOffset": 44}, {"referenceID": 54, "context": "However, as many similarity search problems, the exact version considered in these papers suffers from the curse of dimensionality [55].", "startOffset": 131, "endOffset": 135}, {"referenceID": 44, "context": "The efficiency of approximate IPS approaches based on LSH is studied in [45, 39].", "startOffset": 72, "endOffset": 80}, {"referenceID": 38, "context": "The efficiency of approximate IPS approaches based on LSH is studied in [45, 39].", "startOffset": 72, "endOffset": 80}, {"referenceID": 45, "context": "An asymmetric LSH for binary inner product is proposed in [46].", "startOffset": 58, "endOffset": 62}, {"referenceID": 50, "context": "Valiant [51] showed how to reduce the problem to matrix multiplication, when cs \u2248 O( \u221a n) and s \u2248 O(n), significantly improving on the asymptotic time complexity of approaches based on LSH.", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "[29], who also generalized the sub-quadratic running time to the case when log(s)/ log(cs) is small.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "In another surprising development Alman and Williams [4] showed that for d = O (log n) dimensions, truly subquadratic algorithms for the exact IPS join problem on binary vectors is possible.", "startOffset": 53, "endOffset": 56}, {"referenceID": 55, "context": "OVP derives its hardness from the Strong Exponential Time Hypothesis (Williams [56]), but could potentially be true even if SETH is not.", "startOffset": 79, "endOffset": 83}, {"referenceID": 55, "context": "Conjecture 1 (OVP, [56]).", "startOffset": 19, "endOffset": 23}, {"referenceID": 0, "context": "[1] have proposed an algorithm for OVP running in time n2\u22121/O(\u03b3 log 2 , when d = \u03b3 log n.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": ", [2] page 782):", "startOffset": 2, "endOffset": 5}, {"referenceID": 50, "context": "The polynomials have the following properties [51]:", "startOffset": 46, "endOffset": 50}, {"referenceID": 50, "context": "We note that the Chebyshev embedding proposed by Valiant [51] can provide similar results; however, our construction is deterministic, while Valiant\u2019s is randomized.", "startOffset": 57, "endOffset": 61}, {"referenceID": 8, "context": "The bound holds for a fixed set of data vectors, so it applies also to data dependent LSH [9].", "startOffset": 90, "endOffset": 93}, {"referenceID": 38, "context": "A consequence of our result is that there cannot exist an asymmetric LSH for any dimension d \u2265 1 when the set of query vectors is unbounded, getting a result similar to that of [39], which however requires even the data space to be unbounded and d \u2265 2.", "startOffset": 177, "endOffset": 181}, {"referenceID": 38, "context": "We observe that these sequences are similar to the one used in [39].", "startOffset": 63, "endOffset": 67}, {"referenceID": 41, "context": "[42]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "1 that by plugging the best known LSH for `2 distance on a sphere [9] into a reduction presented in [12, 39], we get a data structure based on LSH for signed MIPS with search time exponent \u03c1 = (1\u2212 s)/(1 + (1\u2212 2c)s).", "startOffset": 66, "endOffset": 69}, {"referenceID": 11, "context": "1 that by plugging the best known LSH for `2 distance on a sphere [9] into a reduction presented in [12, 39], we get a data structure based on LSH for signed MIPS with search time exponent \u03c1 = (1\u2212 s)/(1 + (1\u2212 2c)s).", "startOffset": 100, "endOffset": 108}, {"referenceID": 38, "context": "1 that by plugging the best known LSH for `2 distance on a sphere [9] into a reduction presented in [12, 39], we get a data structure based on LSH for signed MIPS with search time exponent \u03c1 = (1\u2212 s)/(1 + (1\u2212 2c)s).", "startOffset": 100, "endOffset": 108}, {"referenceID": 38, "context": "2, we show how to circumvent the results in [39, 45] showing that symmetric LSH is not possible when the data and query domains coincide (while an asymmetric LSH does exist).", "startOffset": 44, "endOffset": 52}, {"referenceID": 44, "context": "2, we show how to circumvent the results in [39, 45] showing that symmetric LSH is not possible when the data and query domains coincide (while an asymmetric LSH does exist).", "startOffset": 44, "endOffset": 52}, {"referenceID": 37, "context": "The LSH construction uses explicit incoherent matrices built using Reed-Solomon codes [38] to implement a symmetric version of the reduction in [12, 39].", "startOffset": 86, "endOffset": 90}, {"referenceID": 11, "context": "The LSH construction uses explicit incoherent matrices built using Reed-Solomon codes [38] to implement a symmetric version of the reduction in [12, 39].", "startOffset": 144, "endOffset": 152}, {"referenceID": 38, "context": "The LSH construction uses explicit incoherent matrices built using Reed-Solomon codes [38] to implement a symmetric version of the reduction in [12, 39].", "startOffset": 144, "endOffset": 152}, {"referenceID": 4, "context": "3 we solve unsigned (cs, s) join using linear sketches for `p norms from [5].", "startOffset": 73, "endOffset": 76}, {"referenceID": 38, "context": "Vectors are embedded into a (d+2)-dimensional unit sphere using the asymmetric map as in [39]: a data vector p is", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "The latter can be solved in space O(n + dn) and query time O(n) using the LSH construction of [9].", "startOffset": 94, "endOffset": 97}, {"referenceID": 38, "context": "In Figure 2, we plot the \u03c1 values of three LSH constructions: the one proposed here (with U = 1), the one from [39], and the one from [46].", "startOffset": 111, "endOffset": 115}, {"referenceID": 45, "context": "In Figure 2, we plot the \u03c1 values of three LSH constructions: the one proposed here (with U = 1), the one from [39], and the one from [46].", "startOffset": 134, "endOffset": 138}, {"referenceID": 38, "context": "We point out that our bound is always stronger than the one from [39] and sometimes stronger than the one from [46], despite that the latter is tailored for binary vectors.", "startOffset": 65, "endOffset": 69}, {"referenceID": 45, "context": "We point out that our bound is always stronger than the one from [39] and sometimes stronger than the one from [46], despite that the latter is tailored for binary vectors.", "startOffset": 111, "endOffset": 115}, {"referenceID": 6, "context": "We point out that in practice one may want to use a recent LSH family from [7] that\u2014both in theory and in practice\u2014is superior to the hyperplane LSH from [16] used in [39].", "startOffset": 75, "endOffset": 78}, {"referenceID": 15, "context": "We point out that in practice one may want to use a recent LSH family from [7] that\u2014both in theory and in practice\u2014is superior to the hyperplane LSH from [16] used in [39].", "startOffset": 154, "endOffset": 158}, {"referenceID": 38, "context": "We point out that in practice one may want to use a recent LSH family from [7] that\u2014both in theory and in practice\u2014is superior to the hyperplane LSH from [16] used in [39].", "startOffset": 167, "endOffset": 171}, {"referenceID": 38, "context": "Neyshabur and Srebro [39] show that an asymmetric view on LSH for signed IPS is required.", "startOffset": 21, "endOffset": 25}, {"referenceID": 8, "context": "We then plug in any Euclidean LSH for ANN on the sphere, for example the one from [9].", "startOffset": 82, "endOffset": 85}, {"referenceID": 38, "context": "This reduction treats data and query vectors identically, unlike the one from [39], and thus we are able to obtain a symmetric LSH.", "startOffset": 78, "endOffset": 82}, {"referenceID": 37, "context": ", in [38] it is shown how to build such vectors using Reed-Solomon codes.", "startOffset": 5, "endOffset": 9}, {"referenceID": 31, "context": "The resulting dimension is O ( \u03b5\u22122 logN ) = O ( kd/\u03b5 ) [32, 38].", "startOffset": 55, "endOffset": 63}, {"referenceID": 37, "context": "The resulting dimension is O ( \u03b5\u22122 logN ) = O ( kd/\u03b5 ) [32, 38].", "startOffset": 55, "endOffset": 63}, {"referenceID": 8, "context": "from [9, 7], with distance threshold r = 2(1\u2212s+ ), approximation factor c\u20322 = (1\u2212cs\u2212 )/r.", "startOffset": 5, "endOffset": 11}, {"referenceID": 6, "context": "from [9, 7], with distance threshold r = 2(1\u2212s+ ), approximation factor c\u20322 = (1\u2212cs\u2212 )/r.", "startOffset": 5, "endOffset": 11}, {"referenceID": 5, "context": "This LSH can used for solving signed (cs, s) IPS as a traditional LSH [6], although it is required an initial step that verifies whether a query vector is in the input set and, if this is the case, returns the vector q itself if q q \u2265 s.", "startOffset": 70, "endOffset": 73}, {"referenceID": 38, "context": "Figure 2: Our \u03c1 value (DATA-DEP) compared to that of [39] (SIMP) and the binary data only of [46] (MH-ALSH).", "startOffset": 53, "endOffset": 57}, {"referenceID": 45, "context": "Figure 2: Our \u03c1 value (DATA-DEP) compared to that of [39] (SIMP) and the binary data only of [46] (MH-ALSH).", "startOffset": 93, "endOffset": 97}, {"referenceID": 56, "context": "This problem can be tackled using linear sketches (for an overview see [57, 8]).", "startOffset": 71, "endOffset": 78}, {"referenceID": 7, "context": "This problem can be tackled using linear sketches (for an overview see [57, 8]).", "startOffset": 71, "endOffset": 78}, {"referenceID": 4, "context": "More specifically, we use the following result from [5]: for every 2 \u2264 \u03ba \u2264 \u221e there exists a distribution over \u00d5(n1\u22122/\u03ba)\u00d7 n matrices \u03a0 such that for every x \u2208 R one has:", "startOffset": 52, "endOffset": 55}, {"referenceID": 4, "context": "Thus, to build a data structure for computing \u2016Aq\u2016\u221e, we sample a matrix \u03a0 according to the aforementioned result in [5] and com-", "startOffset": 116, "endOffset": 119}, {"referenceID": 45, "context": "1 improves upon the state of the art [46] based on minwise hashing for different values (e.", "startOffset": 37, "endOffset": 41}], "year": 2016, "abstractText": "A number of tasks in classification, information retrieval, recommendation systems, and record linkage reduce to the core problem of inner product similarity join (IPS join): identifying pairs of vectors in a collection that have a sufficiently large inner product. IPS join is well understood when vectors are normalized and some approximation of inner products is allowed. However, the general case where vectors may have any length appears much more challenging. Recently, new upper bounds based on asymmetric locality-sensitive hashing (ALSH) and asymmetric embeddings have emerged, but little has been known on the lower bound side. In this paper we initiate a systematic study of inner product similarity join, showing new lower and upper bounds. Our main results are: \u2022 Approximation hardness of IPS join in subquadratic time, assuming the strong exponential time hypothesis. \u2022 New upper and lower bounds for (A)LSH-based algorithms. In particular, we show that asymmetry can be avoided by relaxing the LSH definition to only consider the collision probability of distinct elements. \u2022 A new indexing method for IPS based on linear sketches, implying that our hardness results are not far from", "creator": "LaTeX with hyperref package"}}}