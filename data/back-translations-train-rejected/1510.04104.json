{"id": "1510.04104", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Sep-2015", "title": "A Preliminary Study on the Learning Informativeness of Data Subsets", "abstract": "Estimating the internal state of a robotic system is complex: this is performed from multiple heterogeneous sensor inputs and knowledge sources. Discretization of such inputs is done to capture saliences, represented as symbolic information, which often presents structure and recurrence. As these sequences are used to reason over complex scenarios, a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention. Such problems need to be addressed to ensure timely and meaningful human-robot interaction. Our work is towards understanding the variability of learning informativeness when training on subsets of a given input dataset. This is in view of reducing the training size while retaining the majority of the symbolic learning potential. We prove the concept on human-written texts, and conjecture this work will reduce training data size of sequential instructions, while preserving semantic relations, when gathering information from large remote sources.", "histories": [["v1", "Mon, 28 Sep 2015 15:21:00 GMT  (129kb,D)", "http://arxiv.org/abs/1510.04104v1", "The 8th International Workshop on Human-Friendly Robotics (HFR 2015), Munich, Germany"]], "COMMENTS": "The 8th International Workshop on Human-Friendly Robotics (HFR 2015), Munich, Germany", "reviews": [], "SUBJECTS": "cs.CL cs.RO", "authors": ["simon kaltenbacher", "nicholas h kirk", "dongheui lee"], "accepted": false, "id": "1510.04104"}, "pdf": {"name": "1510.04104.pdf", "metadata": {"source": "CRF", "title": "A Preliminary Study on the Learning Informativeness of Data Subsets", "authors": ["Simon Kaltenbacher", "Nicholas H. Kirk", "Dongheui Lee"], "emails": ["simon.kaltenbacher@campus.lmu.de", "nicholas.kirk@tum.de", "dhlee@tum.de"], "sections": [{"heading": null, "text": "In this context, it is worth mentioning that this is an attempt to investigate the causes of the emergence of epidemics."}, {"heading": "CHI-SQUARE AND ANDERSON-DARLING TESTS SHOWING THERE IS NO GAUSSIAN NULL HYPOTHESIS REJECTION FOR WORD2VEC AND PERPLEXITY ACCURACY VALUES OF RANDOM SUBSETS (10% SIGNIFICANCE LEVEL).", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "RANDOM SUBSETS.", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Online prediction of activities with structure: Exploiting contextual associations and sequences", "author": ["N.H. Kirk", "K. Ramirez-Amaro", "E. Dean-Leon", "M. Saveriano", "G. Cheng"], "venue": "2015 IEEE-RAS International Conference on Humanoid Robots, IEEE, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Controlled natural languages for language generation in artificial cognition", "author": ["N.H. Kirk", "D. Nyga", "M. Beetz"], "venue": "2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 6667\u20136672, IEEE, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding and executing instructions for everyday manipulation tasks from the world wide web", "author": ["M. Tenorth", "D. Nyga", "M. Beetz"], "venue": "2010 IEEE International Conference on Robotics and Automation (ICRA), pp. 1486\u20131491, IEEE, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in neural information processing systems, pp. 3111\u20133119, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Scaling to very very large corpora for natural language disambiguation", "author": ["M. Banko", "E. Brill"], "venue": "Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, pp. 26\u201333, Association for Computational Linguistics, 2001.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Towards learning object affordance priors from technical texts", "author": ["N.H. Kirk"], "venue": "\u201dActive Learning in Robotics\u201d Workshop, 2014 IEEE-RAS International Conference on Humanoid Robots, IEEE, 2014.  ar  X  iv  :1  51 0.  04  10  4v  1 [  cs  .C  L  ]  2  8  Se  p  20  15", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "As these sequences are used to reason over complex scenarios [1], a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention [1], [2].", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "As these sequences are used to reason over complex scenarios [1], a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention [1], [2].", "startOffset": 292, "endOffset": 295}, {"referenceID": 1, "context": "As these sequences are used to reason over complex scenarios [1], a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention [1], [2].", "startOffset": 297, "endOffset": 300}, {"referenceID": 2, "context": "We prove the concept on human-written texts, and conjecture this work will reduce training data size of sequential instructions, while preserving semantic relations, when gathering information from large remote sources [3].", "startOffset": 219, "endOffset": 222}, {"referenceID": 3, "context": "We evaluated the learning informativess of such sets in terms of semantic word-sense classification accuracy (with WORD2VEC [4]), and of n-gram perplexity.", "startOffset": 124, "endOffset": 127}, {"referenceID": 4, "context": "semantic measures) [5].", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "Within the robotics domain, in order to reduce computational complexity of the training phase, cardinality reduction of human-written instructions is particularly important for non-recursive online training algorithms, such as current symbol-based probabilistic reasoning systems [1], [3], [6].", "startOffset": 280, "endOffset": 283}, {"referenceID": 2, "context": "Within the robotics domain, in order to reduce computational complexity of the training phase, cardinality reduction of human-written instructions is particularly important for non-recursive online training algorithms, such as current symbol-based probabilistic reasoning systems [1], [3], [6].", "startOffset": 285, "endOffset": 288}, {"referenceID": 5, "context": "Within the robotics domain, in order to reduce computational complexity of the training phase, cardinality reduction of human-written instructions is particularly important for non-recursive online training algorithms, such as current symbol-based probabilistic reasoning systems [1], [3], [6].", "startOffset": 290, "endOffset": 293}], "year": 2015, "abstractText": "Estimating the internal state of a robotic system is complex: this is performed from multiple heterogeneous sensor inputs and knowledge sources. Discretization of such inputs is done to capture saliences, represented as symbolic information, which often presents structure and recurrence. As these sequences are used to reason over complex scenarios [1], a more compact representation would aid exactness of technical cognitive reasoning capabilities, which are today constrained by computational complexity issues and fallback to representational heuristics or human intervention [1], [2]. Such problems need to be addressed to ensure timely and meaningful human-robot interaction. Our work is towards understanding the variability of learning informativeness when training on subsets of a given input dataset. This is in view of reducing the training size while retaining the majority of the symbolic learning potential. We prove the concept on human-written texts, and conjecture this work will reduce training data size of sequential instructions, while preserving semantic relations, when gathering information from large remote sources [3].", "creator": "LaTeX with hyperref package"}}}