{"id": "1510.05970", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2015", "title": "Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches", "abstract": "We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.", "histories": [["v1", "Tue, 20 Oct 2015 17:15:05 GMT  (2585kb,D)", "http://arxiv.org/abs/1510.05970v1", "Submitted to the Journal of Machine Learning Research"], ["v2", "Wed, 18 May 2016 19:53:41 GMT  (2591kb,D)", "http://arxiv.org/abs/1510.05970v2", null]], "COMMENTS": "Submitted to the Journal of Machine Learning Research", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jure \\v{z}bontar", "yann lecun"], "accepted": false, "id": "1510.05970"}, "pdf": {"name": "1510.05970.pdf", "metadata": {"source": "CRF", "title": "Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches", "authors": ["Jure \u017dbontar", "Yann LeCun"], "emails": ["ZBONTAR@CS.NYU.EDU", "YANN@CS.NYU.EDU"], "sections": [{"heading": "1. Introduction", "text": "Consider the following problem: In view of two images taken from different horizontal positions, we would like to calculate the disparity d for each pixel in the left image. Disparity refers to the difference in the horizontal position of an object in the left and right image - an object in position (x, y) in the left image appears in position (x-d, y) in the right image. If we know the disparity of an object, we can calculate its depth z with the following relation: z = fBd, where the focal length of the camera is and the distance between the camera centers."}, {"heading": "2. Related Work", "text": "Before the introduction of large stereo datasets such as KITTI and Middlebury, relatively few stereo algorithms used ground truth information to learn parameters of their models; in this section, wereview those who did it. For a general overview of stereo algorithms see Brown and Szeliski (2002).Kong and Tao (2004) used the sum of squared distances to calculate an initial matching cost. They then trained a model to predict the probability distribution across three classes: the initial disparity is correct, the initial disparity is flawed due to the moderation of a foreground object, and the initial disparity is flawed due to other reasons. The predicted probabilities were used to predict the initial matching cost. Kong and Tao (2006) later expand their work by combining predictions obtained by calculating normalized cross-correlation."}, {"heading": "3. Matching Cost", "text": "A typical stereo algorithm starts by calculating match costs for all eligible disparities d at each position p. A simple method of calculating match costs is the sum of absolute differences: CSAD (p, d) = \u2211 q-Np | IL (q) \u2212 IR (qd) |, (1) where IL (p) and IR (p) are the image intensities at position p in the left and right image and Np the number of locations within a fixed rectangular window with the center p.We use bold lowercase letters (p, q and r) to denote image locations. Appending a lowercase letter d to a location has the following meaning: if p = (x, y) then pd = (x \u2212 d, y). We use font for the names of hyperparameters. For example, we would use patch size to interpret the size of the neighborhood p.Equation (1) in such a way that the costs associated with a patch image can be combined with a high position on two stereo images."}, {"heading": "3.1 Constructing the Data Set", "text": "A training example consists of two image fields, one from the left and one from the right: < PLn \u00b7 n (p), PRn \u00b7 n (q) >, where PLn \u00b7 n (p) denotes an n \u00b7 n area of the left image with the center p = (x, y). For each location where the true disparity d is known, we extract a negative and a positive example. A negative example is obtained by setting the center of the right field toq = (x \u2212 d + oneg, y), where oneg is either selected from the interval [dataset neg low, dataset neg high] or whose origin is reflected in [\u2212 dataset neg high, \u2212 dataset neg low]."}, {"heading": "3.2 Network Architectures", "text": "We describe two network architectures to learn how to measure similarity in image fields. The first architecture is faster than the second, but produces disparity maps that are slightly less accurate. In both cases, the input into the network consists of two small image fields and the output is a measure of the similarity between them."}, {"heading": "3.2.1 FAST ARCHITECTURE", "text": "The first architecture is a Siamese network, i.e., two subnets with common weighting connected at the head (Bromley et al., 1993), which consist of a number of revolutionary layers with linear units after all but the last layer. Both subnets output a vector that captures the properties of the input field, and the resulting two vectors are compared using the measure of cosine similarity to produce the final output of the network. Figure 2 provides an overview of the architecture, with the network trained to minimize hinges loss, and the loss is calculated by centering sample pairs around the same image position, with one example belonging to the positive and one to the negative class. Let s + be the output of the network for the positive example, s \u2212 be the output of the network for the negative example, and let m, the border, be a positive real number. The hinges loss for this example is defined as maximum (+) of the net (+) for \u2212 the example."}, {"heading": "3.2.2 ACCURATE ARCHITECTURE", "text": "The second architecture derives from the first by replacing the cosinal similarity with a number of fully connected layers (see Figure 3).This architectural change has increased the runtime but reduced the error rate.The two subnetworks comprise a number of revolutionary layers, each layer followed by an even linear unit.The resulting two vectors are concatenated and are passed through a number of fully connected layers, followed by rectified linear units.The last connected layer produces a single number, which, after being transformed by the sigmoid function, is interpreted as a similarity value between the input fields. We use the binary entropy loss for training. We would have preferred to use the same loss for both architectures, but have decided against it. We could have used the loss for the exact architecture, but the binary constellation constellation was chosen as it was slightly better than the hinge loss."}, {"heading": "3.3 Computing the Matching Cost", "text": "The output of the network is used to initialize the match costs: CCNN (p, d) = \u2212 s (< PL (p), PR (pd) >), where s (< PL (p), PR (pd) >) is the output of the network when executed in the input fields PL (p) and PR (pd). The minus sign converts the match value to match costs. To calculate the total match costs or CCNN (p, d), we would naively have to perform the forward pass for each image location and each disparity to be taken into account. \u2022 The following three implementation details kept the runtime manageable: \u2022 The outputs of the two sub-networks only need to be calculated once per site and do not need to be recalculated for each disparity."}, {"heading": "4. Stereo Method", "text": "The raw results of the Convolutionary Neural Network are not sufficient to produce accurate disparity maps, with errors particularly noticeable in low-texture regions and closed areas, and the quality of the disparity maps can be improved through a series of post-processing steps known as the Stereo Method. The stereo method we used was influenced by Mei et al. (2011) and includes cross-based cost aggregation, semi-global matching, left-right consistency testing, subpixel enhancement, a median, and a bilateral filter."}, {"heading": "4.1 Cross-based Cost Aggregation", "text": "Information from adjacent pixels can be combined by averaging the matching cost over a specified window. This approach fails near depth discontinuities (where the assumption of a constant depth within a window is violated).We prefer a method that adaptively selects the neighborhood for each pixel so that support is collected only from pixels of the same physical object. The method starts with the construction of an upright cross at each position; this cross is used to define the local support region. The left arm pl at position p extends to the left as long as the following two conditions apply: \u2022 I (p) \u2212 I (pl) | cbca intensity; the image intensity elspan at position p and the image intensity d extends to the left as long as the following two conditions apply."}, {"heading": "4.2 Semiglobal Matching", "text": "In fact, the reality is that most people in the world who are able to survive are able to survive themselves if they do not put themselves in a position to survive themselves. (...) Most people in the world who are able to survive themselves are able to survive themselves. (...) Most people in the world who are able to survive themselves are able to survive. (...) (S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "4.3 Computing the Disparity Image", "text": "The disparity image D (p) is calculated by the winner-take-all strategy, i.e. by determining the disparity d, which C (p, d) minimizes: D (p) = argmin d C (p, d)."}, {"heading": "4.3.1 INTERPOLATION", "text": "The interpolation steps attempt to resolve the conflicts between the disparity map predicted for the left image and the disparity map predicted for the right image. Let DL designate the disparity map that will be obtained by treating the left image as a reference image - this has been the case so far, i.e. DL (p) = D (p) - and let DR designate the disparity map that will be obtained by treating the right image as a reference image. DL and DR sometimes disagree about what the correct disparity should be at a particular position. We recognize these conflicts by performing a left-right consistency check. We label each position p by applying the following rules: Correct if | d \u2212 DR (pd) | \u2264 1 for d = DL (p), incongruence if | d \u2212 DR (pd) | \u2264 1 for each other d, occlusion otherwise. For positions marked as occlusion, we want to indicate the position that we find the disparity value that comes from the T, and the background is correct for it."}, {"heading": "4.3.2 SUBPIXEL ENHANCEMENT", "text": "Subpixel magnification provides an easy way to increase the resolution of a stereo algorithm. We fit a square curve through the adjacent costs to get a new disparity image: DSE (p) = d \u2212 C + \u2212 C \u2212 2 (C + \u2212 2C + C \u2212), where d = DINT (p), C \u2212 = CSGM (p, d \u2212 1), C = CSGM (p, d) and C + = CSGM (p, d + 1)."}, {"heading": "4.3.3 REFINEMENT", "text": "The final steps of the stereo method consist of a 5 \u00b7 5 median filter and the following bilateral filter: DBF (p) = 1W (p) \u2211 q-Np-DSE (q) \u00b7 g (\u0435p-q) \u00b7 1 {| IL (p) \u2212 IL (q) | < Blur threshold}, where g (x) is the probability density function of a zero mean normal distribution with standard deviation Blur sigma and W (p) is the normalizing constant: W (p) = \u2211 q-Npg (\u0418p-q) \u00b7 1 {| IL (p) \u2212 IL (q) | < Blur threshold}. The role of the bilateral filter is to smooth the disparity chart without blurring the edges. DBF is the final output of our stereo method."}, {"heading": "5. Experiments", "text": "We used three stereo datasets in our experiments: KITTI 2012, KITTI 2015, and Middlebury. The error rates shown in Tables 1, 2, and 4 were determined by submitting the generated disparity maps to the online evaluation server. All other error rates were calculated by dividing the data set into two parts, with one part used for training and the other for validation."}, {"heading": "5.1 KITTI Stereo Data Set", "text": "The people mentioned, who are able to hide, are able to hide, and are able to put themselves in a position to put themselves in a position to put themselves in the position they are in. \"We have to be able to put ourselves in the position they are in,\" he said. \"We have to put ourselves in a position to put ourselves in, to put ourselves in a position to put ourselves in,\" he said."}, {"heading": "5.2 Middlebury Stereo Data Set", "text": "The image pairs of the Middlebury Stereo dataset are spatial scenes shot in controlled light environments.Structured light was used to measure the true differences with higher density and precision than in the KITTI dataset, which was published in five separate papers in 2001, 2003, 2005, 2006 and 2014 (Scharstein and Szeliski, 2002, 2003; Scharstein and Pal, 2007; Hirschmu \ufffd ller and Scharstein, 2007; Scharstein et al., 2014).In this paper, we refer to the Middlebury dataset as a concatenation of all five datasets; a summary of all datasets is provided in Table 3.Each scene in the 2005, 2006 and 2014 dataset was shot under a number of light ratios and shutter exposures, with a typical image pair taken under four light conditions and seven exposure settings for a total of 28 scene.An online ranking similar to that of KITTI shows a list of all submitted methods."}, {"heading": "5.3 Details of Learning", "text": "The dataset contains 25 million examples at KITTI 2012, 17 million examples at KITTI 2015 and 38 million examples at Middlebury dataset. At the time of the training, the input to the network was a stack of 128 pairs of image fields. At test time, the input was the entire left and right image. We could also have used entire images during the training, as it would allow us to implement the speed optimizations described in Section 3.3. There were several reasons why we preferred image fields: It was easier to control the stack size, the examples could be mixed so that a stack of patches contained several different images, and it was easier to get the same number of positive and negative examples within a stack."}, {"heading": "5.4 Data Set Augmentation", "text": "Transformations are applied during training time and have no impact on mileage. We will randomly rotate, scale and shear the training patches; we will also change their brightness and contrast. Transformation parameters are randomly selected for each pair of patches, and after an epoch of training, the same example for the network is presented for the second time, new random parameters are selected. We will select slightly different transformation parameters for the left and right image; for example, we would rotate the left patch by 10 degrees and the right one by 14 degrees. Different data sets benefit from different types of transformations and in some cases where the wrong transformations are increased. On the Middlebury database, we have the advantage that the images were taken under different lighting conditions."}, {"heading": "5.5 Runtime", "text": "We measure the runtime of our implementation on a computer with an NVIDIA Titan X graphics processor unit. Table 7 contains runtime measurements across a range of hyperparameter settings for three datasets: KITTI, Middlebury half-resolution, and a new fictitious dataset called Tiny, which we use to demonstrate the performance of our method using the type of images normally used for autonomous driving or robotics. The image sizes on which we measured runtime were: 1242 x 350 with 228 levels of deviation for the KITTI dataset, 1500 x 1000 with 200 levels of deviation for the Middlebury dataset, and 320 x 240 with 32 levels of deviation for the Tiny dataset. Table 7 shows that the fast architecture is up to 90 times faster than the exact architecture. In addition, runtimes of the fast architecture are 0.78 seconds for KITTI, 2.03 seconds for Middlebury, and 0.06 seconds for the Tiny dataset."}, {"heading": "5.6 Matching Cost", "text": "We argue that the low error rate of our method is due to the Convolutionary Neural Network and not to a superior stereo method. We verify this claim by replacing the Convolutionary Neural Network with two standard approaches to calculating the matching costs: \u2022 The sum of absolute differences that calculate the matching costs according to Equation (1), that is, the matching costs between two image fields are calculated by adding up the absolute differences in image intensity between the corresponding locations. \u2022 The census transformation, which represents each image position as a bit vector, is a hyperparameter whose value, after experimenting with several, is set to 81. The vector is calculated by centering a 9 x 9 image field around the position of interest and comparing the intensity values of each pixel in the patch with the intensity value of the pixel in the center."}, {"heading": "5.7 Stereo Method", "text": "The stereo method includes a number of post-processing steps: cross-based cost aggregation, semi-global matching, interpolation, subpixel chance, a median, and a bilateral filter. We have conducted a series of experiments in which we exclude each of the above steps and recorded the validation error (see Table 8).The last two lines of Table 8 point to the importance of the post-processing steps of the stereo method. We see that when all of the post-processing steps are removed, the precision architecture validation error increases from 2.61% to 13.49% in KITTI 2012, from 3.25% to 13.38% in KITTI 2015, and from 7.91% to 28.33% in Middlebury. Of all post-processing steps of the stereo method, the semi-global matching affects the validation error the most. When removed, the validation error increases from 2.61% to 4.26% in KITT91%, and from 4.51% in KITT91% in KITTI and 4.91% in mean regions."}, {"heading": "5.8 Data Set Size", "text": "We use a supervised learning approach to measure the similarity between image fields. It is therefore obvious to ask how the size of the dataset affects the quality of the disparity maps. To answer this question, we train our networks on smaller training sets obtained by selecting a random sample set (see Table 9). We observe that the validation error decreases with the increasing number of training examples. These experiments suggest a simple strategy to improve the results of our stereo method: capture a larger dataset."}, {"heading": "20 3.17 2.84 4.13 3.53 11.14 9.73", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "40 3.11 2.75 4.10 3.40 10.35 8.71", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "60 3.09 2.67 4.05 3.34 10.14 8.36", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "80 3.05 2.65 4.02 3.29 10.09 8.21", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.9 Hyperparameters", "text": "In order to better understand the effects of each hyperparameter on the validation error, we perform a series of experiments in which we vary the value of one hyperparameter exponentially with the number of hyperparameters, while setting the others to their default values. Results are presented in Table 10 and can be summarized by observing that increasing the size of the network improves generalization performance, but only to the point where generalization performance is likely to decrease due to the size of the dataset. Note that the number of convective layers implicitly controls the size of the image fields. For example, a network with a convective layer compares 3 x 3 cores image fields of size 3 x 3, while a network with five convective layers compares image fields of size 11 x 11."}, {"heading": "6. Conclusion", "text": "We introduced two Convolutionary Neural Network Architectures to learn how to measure similarity in image fields and applied them to the problem of stereo matching. The source code of our implementation is available at https: / / github.com / jzbontar / mc-cnn. The online repository contains methods for calculating the Disparity Map, training the network, and post-processing the Stereo Method. The accurate architecture generates Disparity Map with a lower error rate than any previously published method on the KITTI 2012, KITTI 2015, and Middlebury datasets. The fast architecture calculates the Disparity Map up to 90 times faster than the precise architecture with only a small error increase. These results suggest that Convolutionary Neural Networks are well suited to calculate stereo matching costs even for applications that require real-time performance."}], "references": [{"title": "The OpenCV library", "author": ["Gary Bradski"], "venue": "Dr. Dobb\u2019s Journal of Software Tools,", "citeRegEx": "Bradski.,? \\Q2000\\E", "shortCiteRegEx": "Bradski.", "year": 2000}, {"title": "Signature verification using a siamese time delay neural network", "author": ["Jane Bromley", "James W Bentz", "L\u00e9on Bottou", "Isabelle Guyon", "Yann LeCun", "Cliff Moore", "Eduard S\u00e4ckinger", "Roopak Shah"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "Bromley et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Bromley et al\\.", "year": 1993}, {"title": "Discriminative learning of local image descriptors", "author": ["Matthew Brown", "Gang Hua", "Simon Winder"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Brown et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2011}, {"title": "Large displacement optical flow: descriptor matching in variational motion estimation", "author": ["Thomas Brox", "Jitendra Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Brox and Malik.,? \\Q2011\\E", "shortCiteRegEx": "Brox and Malik.", "year": 2011}, {"title": "Low-level vision by consensus in a spatial hierarchy of regions", "author": ["Ayan Chakrabarti", "Ying Xiong", "Steven J. Gortler", "Todd Zickler"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Chakrabarti et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chakrabarti et al\\.", "year": 2015}, {"title": "A deep visual correspondence embedding model for stereo matching costs", "author": ["Zhuoyuan Chen", "Xun Sun", "Yinan Yu", "Liang Wang", "Chang Huang"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "cuDNN: Efficient primitives for deep learning", "author": ["Sharan Chetlur", "Cliff Woolley", "Philippe Vandermersch", "Jonathan Cohen", "John Tran", "Bryan Catanzaro", "Evan Shelhamer"], "venue": "CoRR, abs/1410.0759,", "citeRegEx": "Chetlur et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chetlur et al\\.", "year": 2014}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["Ronan Collobert", "Koray Kavukcuoglu", "Cl\u00e9ment Farabet"], "venue": "In BigLearn, NIPS Workshop,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "A two-stage correlation method for stereoscopic depth estimation", "author": ["Nils Einecke", "Julian Eggert"], "venue": "In Digital Image Computing: International Conference on Techniques and Applications (DICTA),", "citeRegEx": "Einecke and Eggert.,? \\Q2010\\E", "shortCiteRegEx": "Einecke and Eggert.", "year": 2010}, {"title": "Flownet: Learning optical flow with convolutional networks", "author": ["Philipp Fischer", "Alexey Dosovitskiy", "Eddy Ilg", "Philip H\u00e4usser", "Caner Haz\u0131rba\u015f", "Vladimir Golkov", "Patrick van der Smagt", "Daniel Cremers", "Thomas Brox"], "venue": "CoRR, abs/1504.06852,", "citeRegEx": "Fischer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fischer et al\\.", "year": 2015}, {"title": "Efficient large-scale stereo matching", "author": ["Andreas Geiger", "Martin Roser", "Raquel Urtasun"], "venue": "In Proceedings of the 10th Asian Conference on Computer Vision - Volume Part I,", "citeRegEx": "Geiger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Geiger et al\\.", "year": 2011}, {"title": "Vision meets robotics: the KITTI dataset", "author": ["Andreas Geiger", "Philip Lenz", "Christoph Stiller", "Raquel Urtasun"], "venue": "International Journal of Robotics Research (IJRR),", "citeRegEx": "Geiger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Geiger et al\\.", "year": 2013}, {"title": "Displets: Resolving stereo ambiguities using object knowledge", "author": ["Fatma G\u00fcney", "Andreas Geiger"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "G\u00fcney and Geiger.,? \\Q2015\\E", "shortCiteRegEx": "G\u00fcney and Geiger.", "year": 2015}, {"title": "Ensemble learning for confidence measures in stereo vision", "author": ["Ralf Haeusler", "Rahul Nair", "Daniel Kondermann"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Haeusler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Haeusler et al\\.", "year": 2013}, {"title": "MatchNet: Unifying feature and metric learning for patch-based matching", "author": ["Xufeng Han", "Thomas Leung", "Yangqing Jia", "Rahul Sukthankar", "Alexander C Berg"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Han et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Han et al\\.", "year": 2015}, {"title": "Stereo processing by semiglobal matching and mutual information", "author": ["Heiko Hirschm\u00fcller"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Hirschm\u00fcller.,? \\Q2008\\E", "shortCiteRegEx": "Hirschm\u00fcller.", "year": 2008}, {"title": "Evaluation of cost functions for stereo matching", "author": ["Heiko Hirschm\u00fcller", "Daniel Scharstein"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Hirschm\u00fcller and Scharstein.,? \\Q2007\\E", "shortCiteRegEx": "Hirschm\u00fcller and Scharstein.", "year": 2007}, {"title": "Evaluation of stereo matching costs on images with radiometric differences", "author": ["Heiko Hirschm\u00fcller", "Daniel Scharstein"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Hirschm\u00fcller and Scharstein.,? \\Q2009\\E", "shortCiteRegEx": "Hirschm\u00fcller and Scharstein.", "year": 2009}, {"title": "SphereFlow: 6 DoF scene flow from RGB-D pairs", "author": ["Michael Hornacek", "Andrew Fitzgibbon", "Carsten Rother"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Hornacek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hornacek et al\\.", "year": 2014}, {"title": "A method for learning matching errors for stereo computation", "author": ["Dan Kong", "Hai Tao"], "venue": "British Machine Vision Conference,", "citeRegEx": "Kong and Tao.,? \\Q2004\\E", "shortCiteRegEx": "Kong and Tao.", "year": 2004}, {"title": "Stereo matching via learning multiple experts behaviors", "author": ["Dan Kong", "Hai Tao"], "venue": "British Machine Vision Conference,", "citeRegEx": "Kong and Tao.,? \\Q2006\\E", "shortCiteRegEx": "Kong and Tao.", "year": 2006}, {"title": "Stratified dense matching for stereopsis in complex scenes", "author": ["Jana Kostkov\u00e1", "Radim S\u00e1ra"], "venue": "British Machine Vision Conference,", "citeRegEx": "Kostkov\u00e1 and S\u00e1ra.,? \\Q2003\\E", "shortCiteRegEx": "Kostkov\u00e1 and S\u00e1ra.", "year": 2003}, {"title": "Real-time stereo matching on CUDA using an iterative refinement method for adaptive support-weight correspondences", "author": ["Jedrzej Kowalczuk", "Eric T Psota", "Lance C Perez"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology,", "citeRegEx": "Kowalczuk et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kowalczuk et al\\.", "year": 2013}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Learning for stereo vision using the structured support vector machine", "author": ["Yunpeng Li", "Daniel P Huttenlocher"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Li and Huttenlocher.,? \\Q2008\\E", "shortCiteRegEx": "Li and Huttenlocher.", "year": 2008}, {"title": "On building an accurate stereo matching system on graphics hardware", "author": ["Xing Mei", "Xun Sun", "Mingcai Zhou", "Haitao Wang", "Xiaopeng Zhang"], "venue": "IEEE International Conference on Computer Vision Workshops (ICCV Workshops),", "citeRegEx": "Mei et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mei et al\\.", "year": 2011}, {"title": "Object scene flow for autonomous vehicles", "author": ["Moritz Menze", "Andreas Geiger"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Menze and Geiger.,? \\Q2015\\E", "shortCiteRegEx": "Menze and Geiger.", "year": 2015}, {"title": "Scalable parallel programming with CUDA", "author": ["John Nickolls", "Ian Buck", "Michael Garland", "Kevin Skadron"], "venue": null, "citeRegEx": "Nickolls et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Nickolls et al\\.", "year": 2008}, {"title": "Towards a simulation driven stereo vision system", "author": ["Martin Peris", "Atsuto Maki", "Sara Martull", "Yasuhiro Ohkawa", "Kazuhiro Fukui"], "venue": "In 21st International Conference on Pattern Recognition (ICPR),", "citeRegEx": "Peris et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Peris et al\\.", "year": 2012}, {"title": "Learning conditional random fields for stereo", "author": ["Daniel Scharstein", "Chris Pal"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Scharstein and Pal.,? \\Q2007\\E", "shortCiteRegEx": "Scharstein and Pal.", "year": 2007}, {"title": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms", "author": ["Daniel Scharstein", "Richard Szeliski"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Scharstein and Szeliski.,? \\Q2002\\E", "shortCiteRegEx": "Scharstein and Szeliski.", "year": 2002}, {"title": "High-accuracy stereo depth maps using structured light", "author": ["Daniel Scharstein", "Richard Szeliski"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Scharstein and Szeliski.,? \\Q2003\\E", "shortCiteRegEx": "Scharstein and Szeliski.", "year": 2003}, {"title": "High-resolution stereo datasets with subpixel-accurate ground truth", "author": ["Daniel Scharstein", "Heiko Hirschm\u00fcller", "York Kitajima", "Greg Krathwohl", "Nera Ne\u0161i\u0107", "Xi Wang", "Porter Westling"], "venue": "German Conference on Pattern Recognition (GCPR),", "citeRegEx": "Scharstein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Scharstein et al\\.", "year": 2014}, {"title": "Learning local feature descriptors using convex optimisation", "author": ["Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Efficient high-resolution stereo matching using local plane sweeps", "author": ["Sudipta N Sinha", "Daniel Scharstein", "Richard Szeliski"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Sinha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2014}, {"title": "Learning to detect ground control points for improving the accuracy of stereo matching", "author": ["Aristotle Spyropoulos", "Nikos Komodakis", "Philippos Mordohai"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Spyropoulos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Spyropoulos et al\\.", "year": 2014}, {"title": "A quantitative analysis of current practices in optical flow estimation and the principles behind them", "author": ["Deqing Sun", "Stefan Roth", "Michael J Black"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Sun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2014}, {"title": "Learning image descriptors with the boosting-trick", "author": ["Tomasz Trzcinski", "Mario Christoudias", "Vincent Lepetit", "Pascal Fua"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Trzcinski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Trzcinski et al\\.", "year": 2012}, {"title": "Piecewise rigid scene flow", "author": ["Christoph Vogel", "Konrad Schindler", "Stefan Roth"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "Vogel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 2013}, {"title": "View-consistent 3D scene flow estimation over multiple frames", "author": ["Christoph Vogel", "Stefan Roth", "Konrad Schindler"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "Vogel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 2014}, {"title": "3D scene flow estimation with a piecewise rigid scene model", "author": ["Christoph Vogel", "Konrad Schindler", "Stefan Roth"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Vogel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 2015}, {"title": "Efficient joint segmentation, occlusion labeling, stereo and flow estimation", "author": ["Koichiro Yamaguchi", "David McAllester", "Raquel Urtasun"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "Yamaguchi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yamaguchi et al\\.", "year": 2014}, {"title": "Learning to compare image patches via convolutional neural networks", "author": ["Sergey Zagoruyko", "Nikos Komodakis"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Zagoruyko and Komodakis.,? \\Q2015\\E", "shortCiteRegEx": "Zagoruyko and Komodakis.", "year": 2015}, {"title": "Computing the stereo matching cost with a convolutional neural network", "author": ["Jure \u017dbontar", "Yann LeCun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "\u017dbontar and LeCun.,? \\Q2015\\E", "shortCiteRegEx": "\u017dbontar and LeCun.", "year": 2015}, {"title": "Cross-based local stereo matching using orthogonal integral images", "author": ["Ke Zhang", "Jiangbo Lu", "Gauthier Lafruit"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology,", "citeRegEx": "Zhang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2009}, {"title": "Estimating optimal parameters for MRF stereo from a single image pair", "author": ["Li Zhang", "Steven M Seitz"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Zhang and Seitz.,? \\Q2007\\E", "shortCiteRegEx": "Zhang and Seitz.", "year": 2007}], "referenceMentions": [{"referenceID": 30, "context": "According to the taxonomy of Scharstein and Szeliski (2002), a typical stereo algorithm consists of four steps: matching", "startOffset": 29, "endOffset": 60}, {"referenceID": 23, "context": "We propose training a convolutional neural network (LeCun et al., 1998) on pairs of small image patches where the true disparity is known (for example, obtained by a LIDAR sensor or structured light).", "startOffset": 51, "endOffset": 71}, {"referenceID": 43, "context": "This paper extends our previous work (\u017dbontar and LeCun, 2015) by including a description of a new architecture, results on two new data sets, lower error rates, and more thorough experiments.", "startOffset": 37, "endOffset": 62}, {"referenceID": 15, "context": "Following Hirschm\u00fcller and Scharstein (2009) we refer to the first two steps as computing the matching cost and the last two steps as the stereo method.", "startOffset": 10, "endOffset": 45}, {"referenceID": 25, "context": "(2012) initialized the matching cost with AD-Census (Mei et al., 2011), and used multiclass linear discriminant analysis to learn a mapping from the computed matching cost to the final disparity.", "startOffset": 52, "endOffset": 70}, {"referenceID": 13, "context": "Recent work (Haeusler et al., 2013; Spyropoulos et al., 2014) focused on estimating the confidence of the computed matching cost.", "startOffset": 12, "endOffset": 61}, {"referenceID": 35, "context": "Recent work (Haeusler et al., 2013; Spyropoulos et al., 2014) focused on estimating the confidence of the computed matching cost.", "startOffset": 12, "endOffset": 61}, {"referenceID": 2, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015).", "startOffset": 85, "endOffset": 192}, {"referenceID": 37, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015).", "startOffset": 85, "endOffset": 192}, {"referenceID": 33, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015).", "startOffset": 85, "endOffset": 192}, {"referenceID": 14, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015).", "startOffset": 85, "endOffset": 192}, {"referenceID": 9, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015).", "startOffset": 85, "endOffset": 192}, {"referenceID": 37, "context": "Several methods have been suggested for solving the problem of learning local image descriptors, such as boosting (Trzcinski et al., 2012), convex optimization (Simonyan et al.", "startOffset": 114, "endOffset": 138}, {"referenceID": 33, "context": ", 2012), convex optimization (Simonyan et al., 2014), and convolutional neural networks (Zagoruyko and Komodakis, 2015; Han et al.", "startOffset": 29, "endOffset": 52}, {"referenceID": 42, "context": ", 2014), and convolutional neural networks (Zagoruyko and Komodakis, 2015; Han et al., 2015).", "startOffset": 43, "endOffset": 92}, {"referenceID": 14, "context": ", 2014), and convolutional neural networks (Zagoruyko and Komodakis, 2015; Han et al., 2015).", "startOffset": 43, "endOffset": 92}, {"referenceID": 20, "context": "For a general overview of stereo algorithms see Scharstein and Szeliski (2002). Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost.", "startOffset": 48, "endOffset": 79}, {"referenceID": 15, "context": "Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost.", "startOffset": 0, "endOffset": 20}, {"referenceID": 15, "context": "Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost. They then trained a model to predict the probability distribution over three classes: the initial disparity is correct, the initial disparity is incorrect due to fattening of a foreground object, and the initial disparity is incorrect due to other reasons. The predicted probabilities were used to adjust the initial matching cost. Kong and Tao (2006) later extend their work by combining predictions obtained by computing normalized cross-correlation over different window sizes and centers.", "startOffset": 0, "endOffset": 443}, {"referenceID": 15, "context": "Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost. They then trained a model to predict the probability distribution over three classes: the initial disparity is correct, the initial disparity is incorrect due to fattening of a foreground object, and the initial disparity is incorrect due to other reasons. The predicted probabilities were used to adjust the initial matching cost. Kong and Tao (2006) later extend their work by combining predictions obtained by computing normalized cross-correlation over different window sizes and centers. Peris et al. (2012) initialized the matching cost with AD-Census (Mei et al.", "startOffset": 0, "endOffset": 604}, {"referenceID": 15, "context": "Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost. They then trained a model to predict the probability distribution over three classes: the initial disparity is correct, the initial disparity is incorrect due to fattening of a foreground object, and the initial disparity is incorrect due to other reasons. The predicted probabilities were used to adjust the initial matching cost. Kong and Tao (2006) later extend their work by combining predictions obtained by computing normalized cross-correlation over different window sizes and centers. Peris et al. (2012) initialized the matching cost with AD-Census (Mei et al., 2011), and used multiclass linear discriminant analysis to learn a mapping from the computed matching cost to the final disparity. Ground-truth data was also used to learn parameters of probabilistic graphical models. Zhang and Seitz (2007) used an alternative optimization algorithm to estimate optimal values of Markov random field hyperparameters.", "startOffset": 0, "endOffset": 903}, {"referenceID": 15, "context": "Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost. They then trained a model to predict the probability distribution over three classes: the initial disparity is correct, the initial disparity is incorrect due to fattening of a foreground object, and the initial disparity is incorrect due to other reasons. The predicted probabilities were used to adjust the initial matching cost. Kong and Tao (2006) later extend their work by combining predictions obtained by computing normalized cross-correlation over different window sizes and centers. Peris et al. (2012) initialized the matching cost with AD-Census (Mei et al., 2011), and used multiclass linear discriminant analysis to learn a mapping from the computed matching cost to the final disparity. Ground-truth data was also used to learn parameters of probabilistic graphical models. Zhang and Seitz (2007) used an alternative optimization algorithm to estimate optimal values of Markov random field hyperparameters. Scharstein and Pal (2007) constructed a new data set of 30 stereo pairs and used it to learn parameters of a conditional random field.", "startOffset": 0, "endOffset": 1039}, {"referenceID": 15, "context": "Kong and Tao (2004) used the sum of squared distances to compute an initial matching cost. They then trained a model to predict the probability distribution over three classes: the initial disparity is correct, the initial disparity is incorrect due to fattening of a foreground object, and the initial disparity is incorrect due to other reasons. The predicted probabilities were used to adjust the initial matching cost. Kong and Tao (2006) later extend their work by combining predictions obtained by computing normalized cross-correlation over different window sizes and centers. Peris et al. (2012) initialized the matching cost with AD-Census (Mei et al., 2011), and used multiclass linear discriminant analysis to learn a mapping from the computed matching cost to the final disparity. Ground-truth data was also used to learn parameters of probabilistic graphical models. Zhang and Seitz (2007) used an alternative optimization algorithm to estimate optimal values of Markov random field hyperparameters. Scharstein and Pal (2007) constructed a new data set of 30 stereo pairs and used it to learn parameters of a conditional random field. Li and Huttenlocher (2008) presented a conditional random field model with a non-parametric cost function and used a structured support vector machine to learn the model parameters.", "startOffset": 0, "endOffset": 1175}, {"referenceID": 11, "context": "Recent work (Haeusler et al., 2013; Spyropoulos et al., 2014) focused on estimating the confidence of the computed matching cost. Haeusler et al. (2013) used a random forest classifier to combine several confidence measures.", "startOffset": 13, "endOffset": 153}, {"referenceID": 11, "context": "Recent work (Haeusler et al., 2013; Spyropoulos et al., 2014) focused on estimating the confidence of the computed matching cost. Haeusler et al. (2013) used a random forest classifier to combine several confidence measures. Similarly, Spyropoulos et al. (2014) trained a random forest classifier to predict the confidence of the matching cost and used the predictions as soft constraints in a Markov random field to decrease the error of the stereo method.", "startOffset": 13, "endOffset": 262}, {"referenceID": 2, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015). The two problems share a common subtask: to measure the similarity between image patches. Brown et al. (2011) introduced a general framework for learning image descriptors and used Powell\u2019s method to select good hyperparameters.", "startOffset": 86, "endOffset": 304}, {"referenceID": 2, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015). The two problems share a common subtask: to measure the similarity between image patches. Brown et al. (2011) introduced a general framework for learning image descriptors and used Powell\u2019s method to select good hyperparameters. Several methods have been suggested for solving the problem of learning local image descriptors, such as boosting (Trzcinski et al., 2012), convex optimization (Simonyan et al., 2014), and convolutional neural networks (Zagoruyko and Komodakis, 2015; Han et al., 2015). Works of Zagoruyko and Komodakis (2015) and Han et al.", "startOffset": 86, "endOffset": 733}, {"referenceID": 2, "context": "A related problem to computing the matching cost is learning local image descriptors (Brown et al., 2011; Trzcinski et al., 2012; Simonyan et al., 2014; Han et al., 2015; Fischer et al., 2015). The two problems share a common subtask: to measure the similarity between image patches. Brown et al. (2011) introduced a general framework for learning image descriptors and used Powell\u2019s method to select good hyperparameters. Several methods have been suggested for solving the problem of learning local image descriptors, such as boosting (Trzcinski et al., 2012), convex optimization (Simonyan et al., 2014), and convolutional neural networks (Zagoruyko and Komodakis, 2015; Han et al., 2015). Works of Zagoruyko and Komodakis (2015) and Han et al. (2015), in particlar, are very similar to our own, differing mostly in the architecture of the network; concretely, the inclusion of pooling and subsampling to account for larger patch sizes and larger variation in viewpoint.", "startOffset": 86, "endOffset": 755}, {"referenceID": 1, "context": "1 FAST ARCHITECTURE The first architecture is a siamese network, that is, two shared-weight sub-networks joined at the head (Bromley et al., 1993).", "startOffset": 124, "endOffset": 146}, {"referenceID": 25, "context": "The stereo method we used was influenced by Mei et al. (2011) and comprises crossbased cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median, and a bilateral filter.", "startOffset": 44, "endOffset": 62}, {"referenceID": 44, "context": "In crossbased cost aggregation (Zhang et al., 2009) we build a local neighborhood around each location comprising pixels with similar image intensity values with the hope that these pixels belong to the same object.", "startOffset": 31, "endOffset": 51}, {"referenceID": 15, "context": "Following Hirschm\u00fcller (2008), we define an energy function E(D) that depends on the disparity image D:", "startOffset": 10, "endOffset": 30}, {"referenceID": 15, "context": "Although Hirschm\u00fcller (2008) suggested choosing sixteen direction, we only optimized along the two horizontal and the two vertical directions; adding the diagonal directions did not improve the accuracy of our system.", "startOffset": 9, "endOffset": 29}, {"referenceID": 10, "context": "43 67 2 Displets G\u00fcney and Geiger (2015) 2.", "startOffset": 17, "endOffset": 41}, {"referenceID": 10, "context": "43 67 2 Displets G\u00fcney and Geiger (2015) 2.47 265 3 MC-CNN \u017dbontar and LeCun (2015) 2.", "startOffset": 17, "endOffset": 84}, {"referenceID": 10, "context": "43 67 2 Displets G\u00fcney and Geiger (2015) 2.47 265 3 MC-CNN \u017dbontar and LeCun (2015) 2.61 100 4 PRSM Vogel et al. (2015) F, MV 2.", "startOffset": 17, "endOffset": 120}, {"referenceID": 10, "context": "43 67 2 Displets G\u00fcney and Geiger (2015) 2.47 265 3 MC-CNN \u017dbontar and LeCun (2015) 2.61 100 4 PRSM Vogel et al. (2015) F, MV 2.78 300 MC-CNN-fst Fast architecture 2.82 0.8 5 SPS-StFl Yamaguchi et al. (2014) F, MS 2.", "startOffset": 17, "endOffset": 208}, {"referenceID": 10, "context": "43 67 2 Displets G\u00fcney and Geiger (2015) 2.47 265 3 MC-CNN \u017dbontar and LeCun (2015) 2.61 100 4 PRSM Vogel et al. (2015) F, MV 2.78 300 MC-CNN-fst Fast architecture 2.82 0.8 5 SPS-StFl Yamaguchi et al. (2014) F, MS 2.83 35 6 VC-SF Vogel et al. (2014) F, MV 3.", "startOffset": 17, "endOffset": 250}, {"referenceID": 4, "context": "05 300 7 Deep Embed Chen et al. (2015) 3.", "startOffset": 20, "endOffset": 39}, {"referenceID": 4, "context": "05 300 7 Deep Embed Chen et al. (2015) 3.10 3 8 JSOSM Unpublished work 3.15 105 9 OSF Menze and Geiger (2015) F 3.", "startOffset": 20, "endOffset": 110}, {"referenceID": 4, "context": "28 3000 10 CoR Chakrabarti et al. (2015) 3.", "startOffset": 15, "endOffset": 41}, {"referenceID": 11, "context": "1 KITTI Stereo Data Set The KITTI stereo data set (Geiger et al., 2013; Menze and Geiger, 2015) is a collection of rectified image pairs taken from two video cameras mounted on the roof of a car, roughly 54 centimeters apart.", "startOffset": 50, "endOffset": 95}, {"referenceID": 26, "context": "1 KITTI Stereo Data Set The KITTI stereo data set (Geiger et al., 2013; Menze and Geiger, 2015) is a collection of rectified image pairs taken from two video cameras mounted on the roof of a car, roughly 54 centimeters apart.", "startOffset": 50, "endOffset": 95}, {"referenceID": 30, "context": "8 2 SPS-St Yamaguchi et al. (2014) 5.", "startOffset": 11, "endOffset": 35}, {"referenceID": 20, "context": "31 2 3 OSF Menze and Geiger (2015) F 5.", "startOffset": 11, "endOffset": 35}, {"referenceID": 20, "context": "31 2 3 OSF Menze and Geiger (2015) F 5.79 3000 4 PR-Sceneflow Vogel et al. (2013) F 6.", "startOffset": 11, "endOffset": 82}, {"referenceID": 12, "context": "24 150 5 SGM+C+NL Hirschm\u00fcller (2008); Sun et al.", "startOffset": 18, "endOffset": 38}, {"referenceID": 12, "context": "24 150 5 SGM+C+NL Hirschm\u00fcller (2008); Sun et al. (2014) F 6.", "startOffset": 18, "endOffset": 57}, {"referenceID": 12, "context": "24 150 5 SGM+C+NL Hirschm\u00fcller (2008); Sun et al. (2014) F 6.84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.", "startOffset": 18, "endOffset": 99}, {"referenceID": 3, "context": "84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.", "startOffset": 39, "endOffset": 61}, {"referenceID": 3, "context": "84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.84 86 7 SGM+SF Hirschm\u00fcller (2008); Hornacek et al.", "startOffset": 39, "endOffset": 100}, {"referenceID": 3, "context": "84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.84 86 7 SGM+SF Hirschm\u00fcller (2008); Hornacek et al. (2014) F 6.", "startOffset": 39, "endOffset": 124}, {"referenceID": 3, "context": "84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.84 86 7 SGM+SF Hirschm\u00fcller (2008); Hornacek et al. (2014) F 6.84 2700 8 ELAS Geiger et al. (2011) 9.", "startOffset": 39, "endOffset": 164}, {"referenceID": 3, "context": "84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.84 86 7 SGM+SF Hirschm\u00fcller (2008); Hornacek et al. (2014) F 6.84 2700 8 ELAS Geiger et al. (2011) 9.72 0.3 9 OCV-SGBM Hirschm\u00fcller (2008) 10.", "startOffset": 39, "endOffset": 204}, {"referenceID": 3, "context": "84 270 6 SGM+LDOF Hirschm\u00fcller (2008); Brox and Malik (2011) F 6.84 86 7 SGM+SF Hirschm\u00fcller (2008); Hornacek et al. (2014) F 6.84 2700 8 ELAS Geiger et al. (2011) 9.72 0.3 9 OCV-SGBM Hirschm\u00fcller (2008) 10.86 1.1 10 SDM Kostkov\u00e1 and S\u00e1ra (2003) 11.", "startOffset": 39, "endOffset": 246}, {"referenceID": 43, "context": "Third place on the leaderboard is held by our previous work (\u017dbontar and LeCun, 2015) with an error rate of 2.", "startOffset": 60, "endOffset": 85}, {"referenceID": 12, "context": "The method in second place (G\u00fcney and Geiger, 2015) uses the matching cost computed by our previous work (\u017dbontar and LeCun, 2015).", "startOffset": 27, "endOffset": 51}, {"referenceID": 43, "context": "The method in second place (G\u00fcney and Geiger, 2015) uses the matching cost computed by our previous work (\u017dbontar and LeCun, 2015).", "startOffset": 105, "endOffset": 130}, {"referenceID": 29, "context": "The data sets were published in five separates works in the years 2001, 2003, 2005, 2006, and 2014 (Scharstein and Szeliski, 2002, 2003; Scharstein and Pal, 2007; Hirschm\u00fcller and Scharstein, 2007; Scharstein et al., 2014).", "startOffset": 99, "endOffset": 222}, {"referenceID": 16, "context": "The data sets were published in five separates works in the years 2001, 2003, 2005, 2006, and 2014 (Scharstein and Szeliski, 2002, 2003; Scharstein and Pal, 2007; Hirschm\u00fcller and Scharstein, 2007; Scharstein et al., 2014).", "startOffset": 99, "endOffset": 222}, {"referenceID": 32, "context": "The data sets were published in five separates works in the years 2001, 2003, 2005, 2006, and 2014 (Scharstein and Szeliski, 2002, 2003; Scharstein and Pal, 2007; Hirschm\u00fcller and Scharstein, 2007; Scharstein et al., 2014).", "startOffset": 99, "endOffset": 222}, {"referenceID": 32, "context": "Rectifying a pair of images using standard calibration procedures, like the ones present in the OpenCV library, results in vertical disparity errors of up to nine pixels on the Middlebury data set (Scharstein et al., 2014).", "startOffset": 197, "endOffset": 222}, {"referenceID": 32, "context": "Each stereo pair in the 2014 data set is rectified twice: once using a standard, imperfect approach, and once using precise 2D correspondences for perfect rectification (Scharstein et al., 2014).", "startOffset": 169, "endOffset": 194}, {"referenceID": 20, "context": "1 2435 5 IDR Kowalczuk et al. (2013) Half 18.", "startOffset": 13, "endOffset": 37}, {"referenceID": 14, "context": "49 6 SGM Hirschm\u00fcller (2008) Half 18.", "startOffset": 9, "endOffset": 29}, {"referenceID": 14, "context": "49 6 SGM Hirschm\u00fcller (2008) Half 18.7 9.90 7 LPS Sinha et al. (2014) Half 19.", "startOffset": 9, "endOffset": 70}, {"referenceID": 14, "context": "49 6 SGM Hirschm\u00fcller (2008) Half 18.7 9.90 7 LPS Sinha et al. (2014) Half 19.4 9.52 8 LPS Sinha et al. (2014) Full 20.", "startOffset": 9, "endOffset": 111}, {"referenceID": 14, "context": "49 6 SGM Hirschm\u00fcller (2008) Half 18.7 9.90 7 LPS Sinha et al. (2014) Half 19.4 9.52 8 LPS Sinha et al. (2014) Full 20.3 25.8 9 SGM Hirschm\u00fcller (2008) Quarter 21.", "startOffset": 9, "endOffset": 152}, {"referenceID": 8, "context": "48 10 SNCC Einecke and Eggert (2010) Half 22.", "startOffset": 11, "endOffset": 37}, {"referenceID": 27, "context": "The post-processing steps of the stereo method were implemented in CUDA (Nickolls et al., 2008), the network training was done with the Torch7 environment (Collobert et al.", "startOffset": 72, "endOffset": 95}, {"referenceID": 7, "context": ", 2008), the network training was done with the Torch7 environment (Collobert et al., 2011) using the fast convolution routines of the cuDNN v2 library (Chetlur et al.", "startOffset": 67, "endOffset": 91}, {"referenceID": 6, "context": ", 2011) using the fast convolution routines of the cuDNN v2 library (Chetlur et al., 2014).", "startOffset": 68, "endOffset": 90}, {"referenceID": 0, "context": "The OpenCV library (Bradski, 2000) was used for the affine transformation in the data augmetntation step.", "startOffset": 19, "endOffset": 34}], "year": 2015, "abstractText": "We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.", "creator": "LaTeX with hyperref package"}}}