{"id": "1510.06153", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2015", "title": "Creating Scalable and Interactive Web Applications Using High Performance Latent Variable Models", "abstract": "In this project we outline a modularized, scalable system for comparing Amazon products in an interactive and informative way using efficient latent variable models and dynamic visualization. We demonstrate how our system can build on the structure and rich review information of Amazon products in order to provide a fast, multifaceted, and intuitive comparison. By providing a condensed per-topic comparison visualization to the user, we are able to display aggregate information from the entire set of reviews while providing an interface that is at least as compact as the \"most helpful reviews\" currently displayed by Amazon, yet far more informative.", "histories": [["v1", "Wed, 21 Oct 2015 07:29:23 GMT  (1739kb,D)", "http://arxiv.org/abs/1510.06153v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.IR", "authors": ["aaron q li", "yuntian deng", "kublai jing", "joseph w robinson"], "accepted": false, "id": "1510.06153"}, "pdf": {"name": "1510.06153.pdf", "metadata": {"source": "CRF", "title": "Creating Scalable and Interactive Web Applications Using High Performance Latent Variable Models", "authors": ["Aaron Q Li", "Yuntian Deng"], "emails": ["aaron@potatos.io", "yuntiand@cs.cmu.edu", "hjing@andrew.cmu.edu", "jwrobins@andrew.cmu.edu"], "sections": [{"heading": null, "text": "In this project, we outline a modular, scalable system for interactive and informative comparison of Amazon products using efficient latent variable models and dynamic visualization. We show how our system can build on the structure and rich valuation information of Amazon products to enable quick, multi-faceted and intuitive comparison. By providing a compressed, topic-specific comparison visualization for the user, we are able to view aggregate information from the entire review series while providing an interface that is at least as compact as the \"most helpful reviews\" currently displayed by Amazon, but much more informative."}, {"heading": "1 Introduction", "text": "Latent variable models are an extremely versatile tool for deriving structures and hierarchies from unstructured data. Typical use cases of latent variable models are learning topics from documents, creating user profiles, predicting user behavior, and creating hierarchies of class names. Although latent variable models are arguably some of the most powerful tools in machine learning, they are often overlooked and underused in practice. In the real world, the use of latent variable models presents many challenges: models are slow to calculate, hardly scalable, and the results are loud and difficult to visualize. While previous work in [1, 4, 19, 3, 20, 2] challenges in terms of computing speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic-based modeling outcomes, there is still a system that combines these components and presents the results to end-users in a modular, intuitive way that we build on this large-scale architecture.1"}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Current Amazon System", "text": "Amazon's current system for presenting ratings to potential customers consists of three distinct views: customer offers, the most helpful reviews, and the full review list. Below, we detail each of these views and outline the deficiencies that our system aims to address."}, {"heading": "2.1.1 Quotes", "text": "The Quotation View provides a quick overview of a product and consists of three single sentence quotes from user reviews, which are designed to capture the mood about various aspects of a product in a concise and user-friendly way. For example, the quotes from the Macally Power Adapter in Figure 1 show customers \"opinions about the cable length and durability of the product, a potentially annoying indicator light and low cost compared to the brand name alternative. Although these quotes provide insight into a product, there is a serious limitation in that they represent only the ratings of a few representatives. Regardless of how these representatives are selected, their usefulness is always limited by their inability to convey aggregated information about consumer sentiment towards different characteristics of a product. However, we note the concise and simplicity of this representation. In designing our alternative system, we try to maintain as much of this simplicity as possible while improving the information content."}, {"heading": "2.1.2 Most Helpful Reviews", "text": "The Most Helpful Reviews section, displayed on Amazon's website above the full review list, offers the \"most helpful\" high and low reviews in a comparison-oriented view, such as Figure 2, also with the Macally power supply. With this view, users can see two opposing product experiences that other customers have deemed legitimate, with one benefit being the reduction in noise from user feedback. However, these \"most helpful reviews\" can often be quite long and capture only a few facets of the product. In addition, helpfulness reviews are greatly distorted by the initial review of a review - a review that quickly receives a helpful review is much more likely to receive additional positive votes and vice versa. In our system, we hope to solve these problems by placing much less emphasis on help reviews when presenting information, while capturing a greater number of product facets and the amount of text content that needs to be read."}, {"heading": "2.1.3 Full Review List", "text": "The full review list in sorted order serves as the last source of reference. As there are hundreds of reviews for even moderately popular products, it is generally impossible for a potential customer to review this entire list. However, this view provides the informative completeness that the two previous views lack. Our proposed system is designed to maintain this completeness while improving individual review search and allowing multiple sorted review lists based on different aspects of a product that the user may be interested in."}, {"heading": "2.2 Latent Variable Models", "text": "Many potentially suitable latent variable models exist for analysis of Amazon reviews, such as unattended models described in [8, 9, 12, 13, 17], supervised models in [10, 11] and hierarchical models in [15, 16, 22, 23]. However, few of them have been designed with efficient conclusions and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25]. For practical reasons, we will only illustrate how our system works with latent variable models accompanied by efficient samplers introduced in [1, 20]."}, {"heading": "2.2.1 Latent Dirichlet Allocation", "text": "Our prototype uses the latent dimension allocation (LDA) [13], a widely used topic model, in which one assumes that documents are generated from mixture distributions of language models associated with individual themes. In other words, the documents are generated by the latent variable model: For each document d, a topic distribution is generated from a Dirichlet distribution with parameters. (2) For each word i (\u03b2), a topic distribution is created from a Dirichlet distribution with parameters. (1... nd) In document d, a topic is generated from multinomic topoi-topoi-topoi-topoi-topoi-topoi-topoi-topoi-dimensions dimensions dimensions-dimensions-dimensions-dimensions-dimensions-dimensions-topoi-dimensions-topoi-topoi-topoi-topoi-dimensions-dimensions-dimensions-dimensions-dimensions-topoi-dimensions-dimensions-dimensions-topoi-dimensions-topoi-dimensions-dimensions-topoi-dimensions-dimensions-topoi-dimensions-dimensions-topoi-dimensions-topoi-dimensions-dimensions-topoi-dimensions-dimenoi-dimensions-topoi-dimensions-dimensions-topoi-topoi-dimensions-dimenoi-dimensions-topoi-dimensions-dimensions-dimenoi-topoi-dimensions-dimensions-dimenoi-dimensions-dimenoi-dimenoi-dimenoi-dimensional-dimensions-dimenoi-dimensions-dimenoi-dimensions-topoi-dimensions-dimenoi-dimenoi-dimensions-dimenoi-dimenoi-dimenoi-dimensions-topoi-dimenoi-dimensions-dimenoi-dimenoi-dimensional-dimenoi-dimensions-dimenoi-topoi-dimenoi-dimensional-dimensions-dimenoi-dimenoi-dimensional-dimenoi-dimensional-dimensional-dimenoi-dimenoi-dimensional-dimensional-"}, {"heading": "3 Proposed System", "text": "We propose a system that is able to handle simultaneous requests for product names from multiple users, analyze relevant evaluations by efficiently sampling latent variable models, and display optimized model updates in real time.3.1 Architecture Figure 3 shows the architectural design of our proposed system. In this design, almost every component is asynchronous and stateless. In addition, many tasks can be performed in a distributed manner to offset computing costs."}, {"heading": "3.1.1 Components", "text": "The main components of our system are distributed web servers, asynchronous task scheduler, data warehouse, search engine, word pre-processing engine, modularized simultaneous modeling engine, update pool and quality evaluator. The workflow of the system is as follows: After a request is accepted by one of the web servers, a request is sent to the rating search engine, which determines if there are already pre-processed results in the data warehouse and if not, how much further pre-processing is required. Requests from pre-processing tasks are created and sent to the word processor, where background staff continuously pre-process fresh reviews while giving top priority to new requests from the search engine. When pre-processed data is ready, the results are sent to the current modeling machine on the topic. Multiple topic modeling instances are created simultaneously and sent back to the web server, with each update sending every few Gibbs sampling iterations to a pool where the results are evaluated for quality."}, {"heading": "3.1.2 Distributed Computing", "text": "Our use of multiple samples raises the following question: How best to evaluate the quality of model results efficiently? The most popular two evaluation metrics, protocol probability and perplexity, both have their own merits. Compared to protocol probability, perplexity is typically considered a more accurate metric when the amount of test data is large but can be evaluated much more slowly. In our system, we chose protocol probability as the primary measure of quality for the following reasons: \u2022 The number of evaluations can be very limited for some products. Calculation confusion about insufficient test data can lead to an inaccurate evaluation of quality. \u2022 There is almost no overhead for calculating the protocol probability."}, {"heading": "3.2 Towards Large Scale", "text": "The modular and stateless design allows for easier scalability towards large-scale processing. For example, Cassandra for data storage, Play! for distributed web servers, Parameter Servers for theme modeling engines and UIMA for pre-processing can be integrated into our system to scale to other modules with minimal modifications."}, {"heading": "3.3 Visual Design", "text": "In order to visualize the thousands to millions of parameters estimated by latent variable models, we design an intuitive visualization framework that is best suited for theme models. We analyze the meaning and structure of statistical models, their rarity features and linkages, and how they can be mapped to a two-dimensional Euclidean space. In addition, we divide presentable information into a hierarchy in which a subset of information is available to the user at each level."}, {"heading": "4 Implementation", "text": "Our prototype system uses the electronics category from the SNAP Amazon Reviews dataset [7], a subset consisting of approximately 1 million reviews and 76,000 products. The main components of our system - preprocessing, database, modeling and visualization - are described below."}, {"heading": "4.1 Pre-Processing & NLP", "text": "Our pre-processing pipeline is primarily based on Stanford's CoreNLP, a robust and highly modular package that has been proven to deliver state-of-the-art performance on a variety of tasks. Using CoreNLP, we transform raw review text into a lemmatized token form that is enhanced with language components. Ratings are used instead of sentiment to provide a more intuitive per-topic rating and reduce computing time. Similarly, on our machine, we found that the pre-processing time increased from 4.1 ms to 706 ms per review when mood analysis was added, making real-time mood calculation with CoreNLP unfeasible. Similarly, our initial intention was to include name recognition in our pre-processing pipeline, and our tests showed that Stanford's implementation of that word is much too slow - on our CoreNLP machine, we added the name of an average of 93.6 seconds to deactivate that word instead."}, {"heading": "4.2 Database", "text": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our hiring because we need a high degree of parallelism and availability, but relatively little consistency; for the prototype system, a relational database is selected to accomplish this task due to its simplicity and better performance at a relatively low volume of data; to reduce overhead, the same database is used as the cache for pre-processed data; a background task is continuously running for pre-processing fresh ratings, with product ratings prioritizing ity.There are some challenges in using a database for such a system. For example, if a query is accepted, the system must quickly determine whether pre-processed ratings are available in the cache. If only a portion of the relevant ratings are cached, the quickest strategy to produce a reasonable response is to return the processed ratings and the requester process has not yet cached the problem, so that the currently multiple available reviews cannot be duplicated."}, {"heading": "4.3 Topic Modeling", "text": "We use a customized version of the open source MAchine Learning LanguagE Toolkit (MALLET) [26] as our modeling base. By generating a theme model from each product in parallel, we achieve significant acceleration compared to MALLET's single threaded mode and significantly less overhead compared to MALLET's multithreaded mode. Our system is flexible in terms of the number of themes that can always be reduced to a core sentence for presentation to the user in relation to any number of themes. As MALLET's implementation of LDA's multithreaded mode uses, we continue the sample until the relative convergence of themes \u2212 we empirically determine the number of iterations for producing good results. In addition, we perform alpha / beta optimization of all 100 iterations. We value review theme and word distributions that we then feed into our model."}, {"heading": "4.4 Visualization", "text": "To achieve satisfactory performance, we used multiple rendering buffers and an advanced object management framework. The geometry of each data point is calculated in real time. Rating content is pulled from on-demand servers to minimize traffic. In addition, we have employed many invisible techniques to minimize traffic, calculation and rendering efforts to maintain a smooth user experience."}, {"heading": "5 Results", "text": "Our final prototype allows the user to query product reviews via an intuitive web interface and visualize initial results in less than 3 seconds in most cases. It allows easy visualization of topic ratings with the ability to quickly select individual ratings. Selecting a topic leads to a page window with topic-specific product comparison and topic-sorted summaries. See the case studies below for more details."}, {"heading": "5.1 Case Studies", "text": "In the following, we present two product comparison case studies to demonstrate the usefulness and simplicity of our system: In the first, we compare the Macally PS-AC4 AC Power Adapter for Apple G4 with the Apple USB Power Adapter for iPod (White) and repeat this analysis with a separate housing consisting of two cameras, the Canon Digital Rebel XT 8MP Digital SLR Camera with EF-S 18-55mm f3.5-5.6 Lens (Black) and the Sony Cybershot DSC-T1 5MP Digital Camera with 3x optical zoom."}, {"heading": "5.1.1 Power Adapters", "text": "Figure 4 shows the user interface that a user of our system would see when comparing the two power supplies, using the Macally adapter as a reference product. On our computer, an initial view was available within about 2 seconds, and the updates lasted for a few seconds thereafter. From the clouds of words, we immediately see that customers tend to value the power cable of the Macally adapter highly, which gives the topic a high weight and the associated rating of 4.1. In contrast, we see 2.5 stars attributed to a topic dominated by \"work,\" \"computer\" and \"battery.\" Clicking on this topic will open the panel on the right, where we quickly learn that this product tends to die after a few months and temporarily fail to function and not charge the customer's computer."}, {"heading": "5.1.2 Cameras", "text": "As we can see, the Sony camera (left column) has potential problems with red eyes and flash, while the closest topic to the Canon model suggests a higher design and image quality, and the relatively high similarity (37%) of these issues suggests that the two actually describe the same facet of the camera. If you look at the top reviews of the Sony camera, you can see concerns about indoor image quality compared to Canon. Users whose main concern is image quality quickly realize that Canon is generally considered superior in this area. However, cost-conscious users who need a cheaper and more compact device can also benefit from this interface by learning that the Sony camera's problems are due to image quality problems rather than device failures."}, {"heading": "6 Future Work", "text": "In terms of modeling performance, we also expect that future project iterations will use a continuously updated, crawler-based system to provide more up-to-date information and enable us to process new data in advance as it occurs. We also plan to explore alternative distance measurements for topics. Compared to our limited Hellinger distance measurement, we suspect that incorporating part-of-speech information will lead to better pairings. Specifically, we plan to experiment with calculating distances only on nouns, which can create feelings (which typically manifest in adjective use) in a natural way. Related part-of-speech experiments may also prove useful."}], "references": [{"title": "Parameter Server for Distributed Machine Learning", "author": ["Mu Li", "Li Zhou", "Zichao Yang", "Aaron Q Li", "Fei Xia", "David G Anderson", "Alexander J Smola"], "venue": "NIPS Big Learning Workshop", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "High Performance Latent Variable Models WWW 2015", "author": ["Aaron Q Li", "Amr Ahmed", "Mu Li", "Vanja Josifovski", "Alexander J Smola"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Krevl, SNAP Large Network Dataset Collection 2014 http: //snap.stanford.edu/data/web-Amazon-links.html", "author": ["Jure Leskovec", "Andrej"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Integrating Document Clustering and Topic Modeling UAI", "author": ["Pengxiao Xie", "Eric P. Xing"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Mining and summarizing customer reviews KDD", "author": ["Hu", "Minqing", "Bing Liu"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Jointly Modeling Aspects, Ratings and Sentiments for Movie Recommendation (JMARS) KDD2014", "author": ["Qiming Diao"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "A Joint Model of Text and Aspect Ratings for Sentiment Summarization", "author": ["Titov", "Ivan", "Ryan T. McDonald"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Latent Dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "JMLR, 3:993\u20131022, Jan.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "A Collapsed Variational Bayesian Inference Algorithm for Latent Dirichlet Allocation NIPS2007", "author": ["Y.W. Teh", "D. Newman", "M. Welling"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Mixed Membership Stochastic Blockmodels", "author": ["E.M. Airoldi", "D. Blei", "S. Fienberg", "E.P. Xing"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "An architecture for parallel topic models", "author": ["A.J. Smola", "S. Narayanamurthy"], "venue": "PVLDB", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient methods for topic model inference on streaming document collections", "author": ["L. Yao", "D. Mimno", "A. McCallum"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Interpretation and Trust: Designing Model- Driven Visualizations for Text Analysis", "author": ["J. Chuang", "D. Ramage", "C.D. Manning", "J. Heer"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Hierarchical dirichlet processes", "author": ["Y. Teh", "M. Jordan", "M. Beal", "D. Blei"], "venue": "JASA, 101(576):1566\u20131581,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Differential topic models", "author": ["C. Chen", "W. Buntine", "N. Ding", "L. Xie", "L. Du"], "venue": "IEEE Pattern Analysis and Machine Intelligence,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "A bayesian review of the poisson-dirichlet", "author": ["W. Buntine", "M. Hutter"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Sampling table configurations for the hierarchical poissondirichlet process", "author": ["C. Chen", "L. Du", "W. Buntine"], "venue": "ECML, pages 296\u2013311,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "MALLET: A Machine Learning for Language Toolkit", "author": ["Andrew Kachites McCallum"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2002}, {"title": "Scalable SQL and NoSQL Data Stores", "author": ["Rick Cattell"], "venue": "ACM SIGMOD Record,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Bigtable: A distributed storage system for structured data", "author": ["Fay Chang", "Jeffrey Dean", "Sanjay Ghemawat", "Wilson C Hsieh", "Deborah A Wallach", "Mike Burrows", "Tushar Chandra", "Andrew Fikes", "Robert E Gruber"], "venue": "ACM Transactions on Computer Systems (TOCS),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}, {"title": "Cassandra: A Decentralized Structured Storage System", "author": ["Avinash Lakshman", "Prashant Malik"], "venue": "ACM SIGOPS Operating Systems Review,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 10, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 0, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 11, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 12, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 125, "endOffset": 135}, {"referenceID": 3, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 4, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 6, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 7, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 9, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 5, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 179, "endOffset": 187}, {"referenceID": 13, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 216, "endOffset": 232}, {"referenceID": 14, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 216, "endOffset": 232}, {"referenceID": 8, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 11, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 15, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 16, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 11, "context": "For practical reasons, we only illustrate how our system works with latent variable models accompanied with efficient samplers, such as those introduced in [1, 20].", "startOffset": 156, "endOffset": 163}, {"referenceID": 7, "context": "Our prototype makes use of Latent Dirichlet Allocation (LDA) [13], a widely used topic model in which one assumes that documents are generated from mixture distributions of language models associated with individual topics.", "startOffset": 61, "endOffset": 65}, {"referenceID": 11, "context": "nd} in document d draw a topic from the multinomial \u03b8d via zdi \u223cMult(\u03b8d) (3) Draw a word from the multinomial \u03c8zdi via wdi \u223cMult(\u03c8zdi) (4) The Dirichlet-multinomial design in this model makes it simple to do inference due to distribution conjugacy \u2013 we can integrate out the multinomial parameters \u03b8d and \u03c8k, thus allowing one to express p(w, z|\u03b1, \u03b2, nd) in a closed-form [20].", "startOffset": 372, "endOffset": 376}, {"referenceID": 11, "context": "However, there are many approaches for substantially accelerating sampling speed by exploiting the topic sparsity to reduce time complexity to O(kd + kw) [20] and further to O(kd) [1], where O(kd) denotes the number of topics instantiated in a document and O(kw) denotes the number of topics instantiated for a word across all documents.", "startOffset": 154, "endOffset": 158}, {"referenceID": 2, "context": "Our prototype system uses the Electronics category from the SNAP Amazon reviews dataset [7], a subset that consists of approximately 1 million reviews and 76,000 products.", "startOffset": 88, "endOffset": 91}, {"referenceID": 18, "context": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency.", "startOffset": 16, "endOffset": 24}, {"referenceID": 19, "context": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency.", "startOffset": 16, "endOffset": 24}, {"referenceID": 20, "context": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency.", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "We use a customized version of the open-source MAchine Learning LanguagE Toolkit (MALLET) [26] as our modeling base.", "startOffset": 90, "endOffset": 94}, {"referenceID": 1, "context": "In terms of modeling performance, replacing MALLET with higher performing implementations based on ideas described in [1, 2, 4] would reduce sampling time and allow our system to scale to a larger number of users.", "startOffset": 118, "endOffset": 127}], "year": 2015, "abstractText": "In this project we outline a modularized, scalable system for comparing Amazon products in an interactive and informative way using efficient latent variable models and dynamic visualization. We demonstrate how our system can build on the structure and rich review information of Amazon products in order to provide a fast, multifaceted, and intuitive comparison. By providing a condensed per-topic comparison visualization to the user, we are able to display aggregate information from the entire set of reviews while providing an interface that is at least as compact as the \u201cmost helpful reviews\u201d currently displayed by Amazon, yet far more informative.", "creator": "LaTeX with hyperref package"}}}