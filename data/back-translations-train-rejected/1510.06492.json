{"id": "1510.06492", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Oct-2015", "title": "Generalized Shortest Path Kernel on Graphs", "abstract": "We consider the problem of classifying graphs using graph kernels. We define a new graph kernel, called the generalized shortest path kernel, based on the number and length of shortest paths between nodes. For our example classification problem, we consider the task of classifying random graphs from two well-known families, by the number of clusters they contain. We verify empirically that the generalized shortest path kernel outperforms the original shortest path kernel on a number of datasets. We give a theoretical analysis for explaining our experimental results. In particular, we estimate distributions of the expected feature vectors for the shortest path kernel and the generalized shortest path kernel, and we show some evidence explaining why our graph kernel outperforms the shortest path kernel for our graph classification problem.", "histories": [["v1", "Thu, 22 Oct 2015 05:49:31 GMT  (205kb,D)", "http://arxiv.org/abs/1510.06492v1", "Short version presented at Discovery Science 2015 in Banff"]], "COMMENTS": "Short version presented at Discovery Science 2015 in Banff", "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["linus hermansson", "fredrik d johansson", "osamu watanabe"], "accepted": false, "id": "1510.06492"}, "pdf": {"name": "1510.06492.pdf", "metadata": {"source": "CRF", "title": "Generalized Shortest Path Kernel on Graphs", "authors": ["Linus Hermansson", "Fredrik D. Johansson", "Osamu Watanabe"], "emails": ["linus3@is.titech.ac.jp", "watanabe@is.titech.ac.jp", "frejohk@chalmers.se"], "sections": [{"heading": null, "text": "Keywords: Graph Kernel \u00b7 SVM \u00b7 Machine Learning \u00b7 Shortest Path"}, {"heading": "1 Introduction", "text": "Classifying graphs according to their structure is a problem that has been studied for a long time and has many useful applications [1,5,13,14]. By classifying graphs, researchers have been able to predict important problems such as accurately predicting the toxicity of chemical compounds [14], whether or not human tissue contains cancer [1], whether or not a particular protein is an enzyme [5], and many other applications. It is generally assumed that the number of self-propagating paths between all the nodal pairs of a given diagram is useful for understanding the structure of the diagram [9,15]. However, calculating the number of such paths between all nodes is a mathematically hard task (usually # P-hard). However, only calculating the number of the shortest paths between the nodal pairs is possible in polynomial time and such paths at least, which is why some researchers consider shortest paths as a substitute."}, {"heading": "2 Preliminaries", "text": "In this paper, we use the symbols G, V, E (with a subscript or a superscript) to denote graphs, sets of nodes, and sets of edges. We fix n and m to denote the number of nodes and edges of the graphs under consideration. We think that the number of elements of the set is S. We are interested in the length and number of shortest paths. In terms of the cores we use for the classification of graphs, we use characteristics to express such information. For each graph G, for each d, we leave the number of pairs of G with a shortest length of d. (In other words, distance d nodes) we invoke a vector vsp = [n1, n2] a vector."}, {"heading": "3 Shortest Path Kernel and Generalized Shortest Path Kernel", "text": "A graph kernel is a function k (G1, G2) on pairs of graphs that can be represented as an internal product k (G1, G2) = < \u03c6 (G1), \u03c6 (G2) > H for some mapping \u03c6 (G) to a Hilbert space H, of possibly infinite dimension. In many cases, graph kernels can be considered as similarity functions on graphs. Graph kernels were used as tools for using SVM classifiers for graph classification problems [4,5,10].The kernel on which we build in this paper is the shortest path (SP) kernel, the graph kernel, which compares graphs on the shortest path length of all nodes [4]. By D (G) we denote the multiple set of shortest distances between all node pairs in graph G."}, {"heading": "4 Random Graph Models", "text": "We examine the advantage of our GSPI kernel over the SPI kernel for a synthetic random diagram classification problem. Our target problem is to distinguish random graphs with two relatively \"dense parts\" using simple graphs generated by the Erdo-Re-Nyi model. Here we mean by \"dense part\" a partial graph that has more edges in its interior compared to its exterior. Note: For each edge density parameter p, 0 < p < p < p < p \u00b2 nyi model (with the parameter p) becomes a graph G (with the parameter p) by creating an edge between each pair of nodes with the probability p < p; p < p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; &ltp; < p; < p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p"}, {"heading": "5 Experiments", "text": "In this section, we compare the performance of the GSPI kernel with the SPI kernel on datasets where the goal is to classify whether a graph is a single-cluster graph or a two-cluster graph."}, {"heading": "5.1 Generating Datasets and Experimental Setup", "text": "All datasets are generated using the models G (n, p1) and G (n / 2, n / 2, p2, q2) described above. q2 is selected so that the expected number of edges is the same for both classes of graphs. Note that at p2 = p1, the two cluster graphs actually become single-cluster graphs, where all node pairs are connected with the same probability, meaning that the two classes are indistinguishable. The greater the difference between p1 and p2, the more different the single-cluster graphs are compared to the two-cluster graphs. In our experiments, we create graphs where n-200, 400, 600, 800, 1000}, np1 = c0 = 40 and p2 = {1,2 p1, 1,3 p1, 1,5 p1, 1,5 p1}."}, {"heading": "5.2 Results", "text": "Table 1 shows the accuracy of both kernels, using 10x cross-validation, on the different datasets. As can be seen, none of the kernels is very good on the datasets where p2 = 1.2p1. This is because the two-cluster graphs generated in this dataset are almost identical to the single-cluster graphs. As p2 increases compared to p1, the task of classifying the graphs becomes easier. As can be seen in the table, the GSPI kernel outperforms the SPI kernel on almost all datasets. In particular, on datasets where p2 = 1.4p1, the GSPI kernel has an increase in accuracy of over 20% on multiple datasets. If n = 200 the increase in accuracy is over 40%, the results shown are only for datasets where c0 = 40, experiments, the other values for c0."}, {"heading": "6 Analysis", "text": "In this section, we will give some approximate analyses of random feature vectors to provide theoretical support for our experimental observations. First, we will show that single-cluster and two-cluster diagrams have quite similar SPI feature vectors (as their expectations are), then, we will show some evidence that there is a not negligible difference in their GSPI feature vectors. In this section, we will look at feature vectors that are defined by looking only at paths from each fixed source node s. For example, we will set n (1) d the number of nodes at the distance d from in8a to 8a cluster diagram, and n (2) d x the number of nodes that have x shortest lengths d to s in a two-cluster diagram. Here, we will introduce a way to specify an approximation. For all functions a and b that depend on n, we will write a certain rel, by which we < c to s is relative (< n; n = 1)."}, {"heading": "6.1 Approximate Comparison of SPI Feature Vectors", "text": "We consider relatively small distances d, so that d can be considered a small constant w.r.t. We show that E [n (1) d] and E [n (2) d] are similar in the following sense \u2212 \u2212 \u2212 This smallness assumption is for our analysis, and we believe that the situation is more or less the same for each d.9theorem 1. To derive this relation, we assume a certain independence from the existence of two paths in G. See the argument below for the difference between E [n (1) d] and E [n (2) d] d for large values of c0.Proof. First, we consider a uniform diagram G = (V, E) and analyze E [n."}, {"heading": "6.2 Heuristic Comparison of GSPI Feature Vectors", "text": "We assume that in this section the expected GSPI characteristics are contained in any arbitrary V2 value. We assume that we estimate the probability that in this section the expected GSPI characteristics of the vectors E [v (1) gsp] and E [v (2) gsp], i.e. we assume that they have some not negligible differences. Since it is not so easy to analyze the distribution of the values d = 2 part of the GSPI characteristics vectors, i.e., subvectors [n (z) 2, x] x 1 for z {1}. Since it is not so easy to analyze the distribution of the values d = 2 part of the GSPI characteristics, i.e., we perform some \"heuristic\" analyses. We start with a one-cluster diagram G, and leave V2 denote the set of G nodes at distance 2 from the source node."}, {"heading": "6.3 Inclusion-Exclusion Principle", "text": "In the entire analysis we have always used the first term of the inclusion principle ps = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K ="}, {"heading": "7 Conclusions and Future Work", "text": "We have defined a new graph kernel based on the number of shortest paths between node pairs in a graph. The feature vectors of the GSP kernel take no longer to compute than the feature vectors of the SP kernel. The reason for this is the fact that the number of shortest paths between node pairs is a by-product of using the Dijkstra algorithm to determine the length of the shortest paths between all node pairs in a graph. The number of shortest paths between node pairs contains relevant information for certain types of graphs. Specifically, we have shown in our experiments that the GSP kernel, which also uses the number of shortest paths between node pairs, surpasses the SP kernel, which uses only the length of the shortest paths between node pairs, in the task of classifying graphs as one or two clusters, giving an analysis of why the GSP kernel is capable of classifying the graph when the two graphs are equal."}], "references": [{"title": "Cell-graph mining for breast tissue modeling and classification", "author": ["C. Bilgin", "C. Demir", "C. Nagi", "B. Yener"], "venue": "In Engineering in Medicine and Biology Society,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Distance distribution in random graphs and application to network exploration", "author": ["V.D. Blondel", "J.-L. Guillaume", "J.M. Hendrickx", "R.M. Jungers"], "venue": "Physical Review E,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Shortest-path kernels on graphs", "author": ["K.M. Borgwardt", "H.-P. Kriegel"], "venue": "In Prof. of ICDM,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Protein function prediction via graph kernels", "author": ["K.M. Borgwardt", "C.S. Ong", "S. Sch\u00f6nauer", "S. Vishwanathan", "A.J. Smola", "H.P. Kriegel"], "venue": "Bioinformatics, 21(suppl 1):i47\u2013i56,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "A note on two problems in connexion with graphs", "author": ["E.W. Dijkstra"], "venue": "Numerische mathematik,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1959}, {"title": "Average path length in random networks", "author": ["A. Fronczak", "P. Fronczak", "J.A. Ho lyst"], "venue": "Physical Review E,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "On graph kernels: Hardness results and efficient alternatives", "author": ["T. G\u00e4rtner", "P. Flach", "S. Wrobel"], "venue": "Learning Theory and Kernel Machines,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Theoretical and numerical study of fractal dimensionality in self-avoiding walks", "author": ["S. Havlin", "D. Ben-Avraham"], "venue": "Physical Review A,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1982}, {"title": "Entity disambiguation in anonymized graphs using graph kernels", "author": ["L. Hermansson", "T. Kerola", "F. Johansson", "V. Jethava", "D. Dubhashi"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Global graph kernels using geometric embeddings", "author": ["F. Johansson", "V. Jethava", "D. Dubhashi", "C. Bhattacharyya"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Semi-supervised feature selection for graph classification", "author": ["X. Kong", "P.S. Yu"], "venue": "In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "An application of boosting to graph classification", "author": ["T. Kudo", "E. Maeda", "Y. Matsumoto"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "The complexity of counting self-avoiding walks in subgraphs of two-dimensional grids and hypercubes", "author": ["M. L\u00edskiewicz", "M. Ogihara", "S. Toda"], "venue": "Theoretical Computer Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Pegasos: primal estimated sub-gradient solver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical Programming,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Efficient graphlet kernels for large graph comparison", "author": ["N. Shervashidze", "S. Vishwanathan", "T. Petri", "K. Mehlhorn", "K.M. Borgwardt"], "venue": "In Proc. of AISTATS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Classifying graphs into different classes depending on their structure is a problem that has been studied for a long time and that has many useful applications [1,5,13,14].", "startOffset": 160, "endOffset": 171}, {"referenceID": 3, "context": "Classifying graphs into different classes depending on their structure is a problem that has been studied for a long time and that has many useful applications [1,5,13,14].", "startOffset": 160, "endOffset": 171}, {"referenceID": 10, "context": "Classifying graphs into different classes depending on their structure is a problem that has been studied for a long time and that has many useful applications [1,5,13,14].", "startOffset": 160, "endOffset": 171}, {"referenceID": 11, "context": "Classifying graphs into different classes depending on their structure is a problem that has been studied for a long time and that has many useful applications [1,5,13,14].", "startOffset": 160, "endOffset": 171}, {"referenceID": 11, "context": "By classifying graphs researchers have been able to solve important problems such as to accurately predict the toxicity of chemical compounds [14], classify if human tissue contains cancer or not [1], predict if a particular protein is an enzyme or not [5], and many more.", "startOffset": 142, "endOffset": 146}, {"referenceID": 0, "context": "By classifying graphs researchers have been able to solve important problems such as to accurately predict the toxicity of chemical compounds [14], classify if human tissue contains cancer or not [1], predict if a particular protein is an enzyme or not [5], and many more.", "startOffset": 196, "endOffset": 199}, {"referenceID": 3, "context": "By classifying graphs researchers have been able to solve important problems such as to accurately predict the toxicity of chemical compounds [14], classify if human tissue contains cancer or not [1], predict if a particular protein is an enzyme or not [5], and many more.", "startOffset": 253, "endOffset": 256}, {"referenceID": 7, "context": "It is generally regarded that the number of self-loop-avoiding paths between all pairs of nodes of a given graph is useful for understanding the structure of the graph [9,15].", "startOffset": 168, "endOffset": 174}, {"referenceID": 12, "context": "It is generally regarded that the number of self-loop-avoiding paths between all pairs of nodes of a given graph is useful for understanding the structure of the graph [9,15].", "startOffset": 168, "endOffset": 174}, {"referenceID": 2, "context": "This approach has proven successful for classifying several types of graphs [4,5,10].", "startOffset": 76, "endOffset": 84}, {"referenceID": 3, "context": "This approach has proven successful for classifying several types of graphs [4,5,10].", "startOffset": 76, "endOffset": 84}, {"referenceID": 8, "context": "This approach has proven successful for classifying several types of graphs [4,5,10].", "startOffset": 76, "endOffset": 84}, {"referenceID": 6, "context": "Such as graph kernels considering all walks [8], shortest paths [4], small subgraphs [17], global graph properties [11], and many more.", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "Such as graph kernels considering all walks [8], shortest paths [4], small subgraphs [17], global graph properties [11], and many more.", "startOffset": 64, "endOffset": 67}, {"referenceID": 14, "context": "Such as graph kernels considering all walks [8], shortest paths [4], small subgraphs [17], global graph properties [11], and many more.", "startOffset": 85, "endOffset": 89}, {"referenceID": 9, "context": "Such as graph kernels considering all walks [8], shortest paths [4], small subgraphs [17], global graph properties [11], and many more.", "startOffset": 115, "endOffset": 119}, {"referenceID": 4, "context": "For example, we can use Dijkstra\u2019s algorithm [6] for each node in a given graph, which gives all node pairs\u2019 shortest path length (i.", "startOffset": 45, "endOffset": 48}, {"referenceID": 0, "context": "We could consider the intervals {[1, 10], [11, 20].", "startOffset": 33, "endOffset": 40}, {"referenceID": 8, "context": "We could consider the intervals {[1, 10], [11, 20].", "startOffset": 33, "endOffset": 40}, {"referenceID": 9, "context": "We could consider the intervals {[1, 10], [11, 20].", "startOffset": 42, "endOffset": 50}, {"referenceID": 2, "context": "Graph kernels have been used as tools for using SVM classifiers for graph classification problems [4,5,10].", "startOffset": 98, "endOffset": 106}, {"referenceID": 3, "context": "Graph kernels have been used as tools for using SVM classifiers for graph classification problems [4,5,10].", "startOffset": 98, "endOffset": 106}, {"referenceID": 8, "context": "Graph kernels have been used as tools for using SVM classifiers for graph classification problems [4,5,10].", "startOffset": 98, "endOffset": 106}, {"referenceID": 2, "context": "The kernel that we build upon in this paper is the shortest path (SP) kernel, which compares graphs based on the shortest path length of all pairs of nodes [4].", "startOffset": 156, "endOffset": 159}, {"referenceID": 2, "context": "where k is a positive definite kernel [4].", "startOffset": 38, "endOffset": 41}, {"referenceID": 2, "context": "One of the most common kernels for k is the indicator function, as used in Borgwardt and Kriegel [4].", "startOffset": 97, "endOffset": 100}, {"referenceID": 0, "context": "This means that the inner product between two feature vectors always is in [0, 1].", "startOffset": 75, "endOffset": 81}, {"referenceID": 13, "context": "We use Pegasos [16] for solving the SVM.", "startOffset": 15, "endOffset": 19}, {"referenceID": 5, "context": "[7] and assume that every specific path exists independently.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "For smaller n, we may use a better approximation from [7], which will be explained in Subsection 6.", "startOffset": 54, "endOffset": 57}, {"referenceID": 5, "context": "For example, we in fact used the approximation from [7] for deriving the mixed normal distributions of Fig.", "startOffset": 52, "endOffset": 55}, {"referenceID": 5, "context": "Here for completeness, we state this approximation as a lemma and give its proof that is outlined in [7].", "startOffset": 101, "endOffset": 104}, {"referenceID": 5, "context": "The above bound for the error term Q is slightly weaker than the one in [7], but it is sufficient enough for many situations, in particular for our usage.", "startOffset": 72, "endOffset": 75}], "year": 2015, "abstractText": "We consider the problem of classifying graphs using graph kernels. We define a new graph kernel, called the generalized shortest path kernel, based on the number and length of shortest paths between nodes. For our example classification problem, we consider the task of classifying random graphs from two well-known families, by the number of clusters they contain. We verify empirically that the generalized shortest path kernel outperforms the original shortest path kernel on a number of datasets. We give a theoretical analysis for explaining our experimental results. In particular, we estimate distributions of the expected feature vectors for the shortest path kernel and the generalized shortest path kernel, and we show some evidence explaining why our graph kernel outperforms the shortest path kernel for our graph classification problem.", "creator": "LaTeX with hyperref package"}}}