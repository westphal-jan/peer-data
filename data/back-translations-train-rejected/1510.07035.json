{"id": "1510.07035", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Oct-2015", "title": "Fast Latent Variable Models for Inference and Visualization on Mobile Devices", "abstract": "In this project we outline Vedalia, a high performance distributed network for performing inference on latent variable models in the context of Amazon review visualization. We introduce a new model, RLDA, which extends Latent Dirichlet Allocation (LDA) [Blei et al., 2003] for the review space by incorporating auxiliary data available in online reviews to improve modeling while simultaneously remaining compatible with pre-existing fast sampling techniques such as [Yao et al., 2009; Li et al., 2014a] to achieve high performance. The network is designed such that computation is efficiently offloaded to the client devices using the Chital system [Robinson &amp; Li, 2015], improving response times and reducing server costs. The resulting system is able to rapidly compute a large number of specialized latent variable models while requiring minimal server resources.", "histories": [["v1", "Fri, 23 Oct 2015 05:26:09 GMT  (694kb,D)", "http://arxiv.org/abs/1510.07035v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CL cs.DC cs.IR", "authors": ["joseph w robinson", "aaron q li"], "accepted": false, "id": "1510.07035"}, "pdf": {"name": "1510.07035.pdf", "metadata": {"source": "META", "title": "Fast Latent Variable Models for Inference and Visualization on Mobile Devices", "authors": ["Joseph W Robinson", "Aaron Q Li"], "emails": ["JWROBINS@ANDREW.CMU.EDU", "AARON@POTATOS.IO"], "sections": [{"heading": "1. Introduction", "text": "Recent advances in machine learning have led to several classes of latent variable models that allow one to embed additional unobserved structures in a problem to improve outcomes, such as the latent dirichlet allocation (LDA) (Lead et al., 2003), a generative model that assumes that documents contain a mixture of topics; each topic is then presented as a probability distribution across words in the corpus. A current application of this method is Amazon Review Modeling (Li et al., 2014c), in which each review text is treated as a document and the products are displayed via a word cloud containing the uppermost words per topic. However, while works such as the Alias Method (Li et al., 2014a), GPU Sampling (Li et al., 2012), Copyright 2015 by the author (s) and Parameter Server (Li et al., 2013; 2015) have led to significant speed improvements for large-scale systems, rather than operating systems that have been undertaken with much less hardware for these models."}, {"heading": "2. Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Current Amazon System", "text": "The current Amazon system for viewing reviews is divided into three sections: Quotes give the user a set of three one-line excerpts of reviews as a high-level overview of the product. A list of the \"most helpful reviews\" gives the user more detailed information through the eyes of some selected reviewers. The full review list is then available as a backup for the ambitious buyer who wants to view thousands of reviews to make sure their purchase is worth it. It is easy to spot a few potential flaws in this system - a user is either able to view the experience of a small group of individuals, or he needs to view the full uncurated review list. Therefore, despite the availability of millions of reviews across the site, their knowledge is not aggregated. In addition, the system does not quickly convey a multi-layered view of the product. For example, a user buying a smartphone might be interested in monitoring the general mood via the camera, battery life, reliability, connection, etc."}, {"heading": "2.2. Previous Topic Modeling Approach", "text": "In fact, it is the case that most of them will be able to move into a different world, in which they see themselves in a position in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2.3. Pre-existing work on modeling reviews", "text": "Existing latent variable models developed for review analysis (Brody & Elhadad, 2010; Jo & Oh, 2011; Titov & McDonald, 2008) tend to lag behind scalability and generality; they generally improve on LDA by using word associations and sentence contexts to build more representative words; they also focus specifically on a fixed number of known aspects, which greatly limits the potential application of these models, and as a result, they cannot capture unknown topics / aspects on a fine-grained level (e.g. a third-party charging adapter does not work on some Apple computers); these models also ignore a large amount of auxiliary data such as user reviews, helplessness and helplessness."}, {"heading": "2.4. Latent Dirichlet Allocation", "text": "The latent dirichlet allocation (LDA) (Blei et al., 2003) is a widely used topic model, in which it is assumed that documents are generated from mixture distributions of language models associated with individual topics, that is, documents are generated by the latent variable model, namely by the latent variable model. (1) For each topic, however, a word distribution is calculated from a dirichlet distribution with parameters. (2) For each word, a word distribution is calculated from a dirichlet distribution with parameters. (3) Draw a word from a dirichlet distribution with parameters. (3) Draw a word from the multinomic distribution with parameters. (3) Draw a word from the dirichlet distribution with parameters. (3) Draw a word from the multinomic distribution."}, {"heading": "2.5. Chital Computation Marketplace", "text": "Chital is a scalable, distributed computing market designed to efficiently allocate tasks with high CPU and low network bandwidth between a network of mobile devices. Chital's five key aspects are 1) task distribution across the market, 2) a credit score system to monitor user behavior 3) real-time matching mechanisms to maximize user profit 4) an optional lottery system to further promote participation 5) an evaluation system to verify the submitted models. Each of these models is discussed in detail below."}, {"heading": "2.5.1. MARKETPLACE", "text": "The marketplace is the most important underlying component in Chital for task assignment. In the market, each user has the opportunity to participate in the background calculation; once he has chosen, that user is then listed as a computational seller and can be assigned modeling tasks that are performed in the background. If a Vedalia user enters a request, a corresponding request is sent to a centralized server system - that user is now a buyer. Provided that the buyer has sufficient computing power on his phone, the buyer is also automatically listed as a seller for the duration of his model calculation. The marketplace then agrees with a pair of sellers and requests that both sellers generate a model from the data supplied. This data is then returned to the central server, where the system determines whether model verification is necessary. Let c1 and c2 specify the creditworthiness of the two sellers, and p1 and p2 specify the perplexity of the seller's score + 2% of the probability of a high \u2212 11%. Then, the probability is high \u2212 11."}, {"heading": "2.5.2. CREDIT SYSTEM", "text": "Then each user who joins the system as a seller will start with a credit of 0. When building a model, the difficulties of each of the two models returned by the sellers will be compared; a credit from the seller of the worst model will then be transferred to the seller of the best model. The seller of the best model will additionally receive a credit of 0 over time. However, if a malicious seller attempts to provide fake results in order to purchase lottery tickets, the credit distribution shifts from the bad to the good users. As a result, it becomes less likely that the system will have to verify the results of good users, and it becomes increasingly likely that it will perform verifications on bad users."}, {"heading": "2.5.3. MATCHING MECHANISMS", "text": "The core of Chital is a real-time matching system that links each query to two vendors; the matching problem can be formulated as a bipartite matching problem where both sides of the vertices arrive online; each buyer vertex must match two vendor vertices; and, in addition, after matching has been established, the matched vertices will only be temporarily unavailable for a period of time due to the performance of the vendor nodes and the size of the buyer node's task before the matching is removed and the vertices become reavailable.Although online graph matching, in particular bipartite matching, is a well-researched area of research (Karp et al., 1990; Mehta, 2013), our problem-building makes it difficult to apply an existing algorithm for two reasons: our problem introduces an additional \"time dimension,\" and our goal is to maximize overall user gain in order to convince them to voluntarily join the system and to continue to work on this new concept of real-time equality and Li's evolution."}, {"heading": "2.5.4. LOTTERY SYSTEM", "text": "s advertising revenue for a lottery system. At the end of each lottery period, the user is given a random sample with a probability of winning proportional to the number of lottery tickets the user has. However, note that the existence of the lottery system is entirely voluntary, as a rational user would voluntarily participate in the system if a good matching mechanism with strategic certainty and empirical equilibrium from Nash were used. In our empirical studies (Robinson & Li, 2015) we found, using appropriate parameters, that the user always saves computing time by a large margin within our simulation."}, {"heading": "2.5.5. EVALUATION SYSTEM", "text": "The evaluation is a multi-level system consisting of model validation, selection and verification. During validation, the basic characteristics of the distributions submitted are verified (e.g. sum of 1. Any model that fails during validation is immediately discarded. Upon selection, the perplexity of each model submitted is calculated. The model with the lower perplexity is selected to be returned to the end user until verification. During verification, the market first calculates the probability of secondary verification, as described in 2.5.1. A value s is then uniformly sampled for [0.1]; if s > pv occurs, verification takes place. During verification, some additional iterations of the Gibbs sample are executed on the selected model on capital servers, and the final confusion of the model is calculated.If the final perplexity is substantially different from the model submitted, the system therefore refuses to submit it."}, {"heading": "3. Proposed System", "text": "We propose a system that integrates a new latent variable model, RLDA, which is well suited for mobile devices and review analysis. It naturally expands LDA while maintaining a structure that allows the application techniques introduced in SparseLDA and AliasLDA to achieve high performance at any scale. In addition, the system is integrated into Chital for scalability and is available to the end user in the form of a mobile application."}, {"heading": "3.1. RLDA", "text": "Extended Review Deferred Dirichlet Allocation (RLDA) is an adjustment of the LDA model that is well suited for modeling ratings in a mobile environment due to its high sampling performance and increased structure relative to standard LDA. In Figure 3.1, we present the RLDA model in plate notation. Notations are shown in Figure 3.1Note that despite the introduction of latent variables r, cd and our per-document observed variables rd, \u03c3d, hd, ud, \u03bdd, the basic structure of the LDA is maintained. As always, we can see that the distribution of topics of each rating now depends on the distorted evaluation of the rating. This makes intuitive sense insofar as we expect more negative reviews to talk about various topics that are completely positive; as an example, negative reviews may tend to focus on poor product quality and customer service, with positive reviews focusing on product satisfaction and exemplary applications."}, {"heading": "3.2. Model Updating", "text": "When using the Chital system, of course, the model update is done by random sampling using the existing model with the new ratings added to the rating set. Thus, when using a lottery system, the number of lottery tickets awarded to the seller is determined fairly accurately by the computational effort required to update the model. To avoid convergence to poor Optima, we recalculate a product model after a few updates. This methodology allows products to be updated quickly when new ratings are available, while model quality is maintained by occasional complete recalculations."}, {"heading": "3.3. Core Set Selection", "text": "To accommodate a variable number of topics, we first perform an RLDA sample with a fixed number of topics k. The number of topics can then be reduced to a smaller core set after the sample by applying techniques in (Feldman et al., 2011) combined with the estimation of the informativeness of the top words in each topic."}, {"heading": "3.4. Visualization", "text": "Given the limited screen space available on mobile devices, the user interface is designed from the ground up with simplicity. The first screen is a simple search with a single input field in which the user can query products. After submitting a product query, the user receives a list of products from which he can select to create a theme model. Unlike (Li et al., 2014c), the display of themes is traced back to its core. We display each topic based on its rating in thematically weighted order, but unlike the Amazon system, we divide the visualization into a series of tabs, one for each topic. The user can use an intuitive SeekBar to select themes. Once selected, a topic overview is displayed, including the topic-weighted rating, the topic weight and the top k token of the theme listed as keywords. Above this topic overview is a summary of viewpager views that can be used quickly by sorting reviews."}, {"heading": "4. Implementation Details", "text": "In the following, we briefly describe the implementation of Vedalia, with an emphasis on performance-critical details and modeling."}, {"heading": "4.1. Architecture, Preprocessing, and Database", "text": "To accommodate the new system design, we have made significant architectural changes compared to the previous system (Li et al., 2014b); we have dropped integration with parameter-like computing clusters, but significantly increased the power of pre-processing clusters and databases; in addition, the model result selection system and the push update mechanism for intermediate results are no longer required, so they will be fully replaced by the Chital system; we plan a large-scale pre-processing task with Apache Spark (Zaharia et al., 2010) combined with Stanford CoreNLP (Manning et al., 2014) once enough ratings are embedded in the database to reduce wait times and eliminate overhead during model computation; and we have a 1-rack, multiple node Cassandra (Lakshman & Malik, 2010) database for storing and streaming product information, raw reviews and analyzed evaluations to achieve the best performance in error tolerance, consistency and consistency."}, {"heading": "4.2. Model Views", "text": "To reduce bandwidth and protect models from external use, we avoid sending the entire model to the end user. The original model view is sent to the user as a list of subject descriptions (ID, probability, expected rating, expected helpfulness, expected helpfulness) and the associated top-n-words. As with the previous system, we postpone sending rating texts to the end user until it is requested, which is especially important in a mobile environment where many users use the app on a bandwidth-restricted data plan. To improve the user experience, ratings can be cached for offline viewing."}, {"heading": "4.3. Sampling", "text": "In fact, it is not that we are in a position to find a solution that will enable us to solve the problems that we want to solve, \"he told the Deutsche Presse-Agentur in an interview with the\" Frankfurter Allgemeine Zeitung \"(Friday)."}, {"heading": "5. Case Study", "text": "To evaluate the effectiveness of the system, we compare the new Vedalia system with the current Amazon system (ASIN B00080FO4O). At the time of modeling, the product had 487 reviews with an average rating of approximately 3.5 stars. When queriing this product, the user receives the performance indicated in Figures 3 and 4. In Figure 3, we see that the keywords on the subject are generally positive, with the emphasis drawing attention to the iHome's ability to recharge your phone's battery and the slight (but not significant) disappointment with the brightness of the screen when trying to sleep. In Figure 4, we see more negative, highlighted keywords, with the product's below-average build quality and unjustifiably high price.In Figure 5, we see the review representation in the official Amazon app for Android."}, {"heading": "6. Future Work", "text": "In the immediate future, we will file a patch with MALLET (McCallum, 2002) to fix the faulty ParallelTopicModel parallel implementation. Many users of MALLET will notice that the library is much slower when using the multithreaded implementation, which is due to the \"Thread.sleep ()\" call in the inner loop of the parameter estimation when using more than one thread, which is used as a temporary hack to fix a concurrent error (non-volatile thread cachedboolean value retrieved from another thread). In designing our system, we have corrected this error and refactored the ParallelTopicModel and WorkerRunnable code to achieve much higher performance and take full advantage of all cores in a multithreaded environment. In terms of future work on RLDA, we would like to continuously improve the performance of the model by scheduling better product categories in comparison, planning a better product structure in advance of hierarchical products."}], "references": [{"title": "An unsupervised aspect-sentiment model for online reviews", "author": ["Brody", "Samuel", "Elhadad", "Noemie"], "venue": "In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics,", "citeRegEx": "Brody et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Brody et al\\.", "year": 2010}, {"title": "Scalable training of mixture models via coresets", "author": ["Feldman", "Dan", "Faulkner", "Matthew", "Krause", "Andreas"], "venue": "In Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Feldman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2011}, {"title": "Aspect and sentiment unification model for online review analysis", "author": ["Jo", "Yohan", "Oh", "Alice H"], "venue": "In Proceedings of the Forth International Conference on Web Search and Web Data", "citeRegEx": "Jo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jo et al\\.", "year": 2011}, {"title": "An optimal algorithm for online bipartite matching", "author": ["Karp", "Vazirani"], "venue": "In STOC: ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "Karp et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Karp et al\\.", "year": 1990}, {"title": "Cassandra: A decentralized structured storage system", "author": ["Lakshman", "Avinash", "Malik", "Prashant"], "venue": "SIGOPS Oper. Syst. Rev.,", "citeRegEx": "Lakshman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lakshman et al\\.", "year": 2010}, {"title": "Snap large network dataset collection", "author": ["Leskovec", "Jure", "Krevl", "Andrej"], "venue": null, "citeRegEx": "Leskovec et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2014}, {"title": "Multi-gpu distributed parallel bayesian differential topic", "author": ["Li", "Aaron Q"], "venue": null, "citeRegEx": "Li and Q.,? \\Q2012\\E", "shortCiteRegEx": "Li and Q.", "year": 2012}, {"title": "Reducing sampling complexity of topic models, 2014a", "author": ["Li", "Aaron Q", "Ahmed", "Amr", "Ravi", "Sujith", "Smola", "Alexander J"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Creating scalable and interactive web applications using high performance latent variable models", "author": ["Li", "Aaron Q", "Deng", "Yuntian", "Jing", "Kublai", "Robinson", "Joseph W"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Creating scalable and interactive web applications using high performance latent variable models, 2014c", "author": ["Li", "Aaron Q", "Robinson", "Joseph W", "Deng", "Yuntian", "Jing", "Kublai"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Parameter server for distributed machine", "author": ["Li", "Mu", "Zhou", "Yang", "Zichao", "Aaron Q", "Xia", "Fei", "Anderson", "David G", "Smola", "Alexander J"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Kachites. Mallet: A machine learning for language toolkit", "author": ["McCallum", "Andrew"], "venue": null, "citeRegEx": "McCallum and Andrew,? \\Q2002\\E", "shortCiteRegEx": "McCallum and Andrew", "year": 2002}, {"title": "Online matching and ad allocation", "author": ["Mehta", "Aranyak"], "venue": "Foundations and Trends in Theoretical Computer Science,", "citeRegEx": "Mehta and Aranyak.,? \\Q2013\\E", "shortCiteRegEx": "Mehta and Aranyak.", "year": 2013}, {"title": "Scalable computation marketplace for latent variable modeling on mobile", "author": ["Robinson", "Joseph W", "Li", "Aaron Q"], "venue": null, "citeRegEx": "Robinson et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Robinson et al\\.", "year": 2015}, {"title": "Modeling online reviews with multi-grain topic models", "author": ["Titov", "Ivan", "McDonald", "Ryan T"], "venue": "In Proceedings of the 17th International Conference on World Wide Web,", "citeRegEx": "Titov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Titov et al\\.", "year": 2008}, {"title": "Efficient methods for topic model inference on streaming document collections", "author": ["Yao", "Limin", "Mimno", "David", "McCallum", "Andrew"], "venue": null, "citeRegEx": "Yao et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2009}, {"title": "Spark:cluster computing working", "author": ["Zaharia", "Matei", "Chowdhury", "Mosharaf", "Franklin", "Michael J", "Shenker", "Scott", "Stoica", "Ion"], "venue": null, "citeRegEx": "Zaharia et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zaharia et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 15, "context": ", 2003) for the review space by incorporating auxiliary data available in online reviews to improve modeling while simultaneously remaining compatible with preexisting fast sampling techniques such as (Yao et al., 2009; Li et al., 2014a) to achieve high performance.", "startOffset": 201, "endOffset": 237}, {"referenceID": 10, "context": "and Parameter Server (Li et al., 2013; 2015) has resulted in substantial speed improvements for large scale systems, much less has been done for a more hardware-constrained setting such as smartphones running Android or iOS.", "startOffset": 21, "endOffset": 44}, {"referenceID": 15, "context": "The Dirichlet-multinomial design in this model makes it simple to do inference due to distribution conjugacy \u2013 we can integrate out the multinomial parameters \u03b8d and \u03c8k, thus allowing one to express p(w, z|\u03b1, \u03b2, nd) in a closedform (Yao et al., 2009).", "startOffset": 232, "endOffset": 250}, {"referenceID": 15, "context": "However, there are many approaches for substantially accelerating sampling speed by exploiting the topic sparsity to reduce time complexity to O(kd + kw) (Yao et al., 2009) and further to O(kd) (Li et al.", "startOffset": 154, "endOffset": 172}, {"referenceID": 3, "context": "Although online graph matching especially online bipartite matching is a well-studied major research area (Karp et al., 1990; Mehta, 2013), our problem setup makes it difficult to apply any existing algorithm for two reasons: our problem introduces an extra \u201dtime dimension\u201d, and our objective is to maximize overall user gain thereby to convince them joining the system voluntarily.", "startOffset": 106, "endOffset": 138}, {"referenceID": 1, "context": "The number of topics can then be reduced to a smaller core set post-sampling by using techniques in (Feldman et al., 2011) combined with estimating the informativeness of the top words in each topic.", "startOffset": 100, "endOffset": 122}, {"referenceID": 16, "context": "We schedule large-scale batch review preprocessing task using Apache Spark (Zaharia et al., 2010) combined with Stanford CoreNLP (Manning et al.", "startOffset": 75, "endOffset": 97}, {"referenceID": 15, "context": "Sampling can be performed by following a procedure which transforms the auxiliary information along with other latent variables into word observation, then sample the transformed data in an LDA-like fashion, where an adaptation of SparseLDA (Yao et al., 2009) sampling is performed in order to estimate model parameters.", "startOffset": 241, "endOffset": 259}], "year": 2015, "abstractText": "In this project we outline Vedalia, a high performance distributed network for performing inference on latent variable models in the context of Amazon review visualization. We introduce a new model, RLDA, which extends Latent Dirichlet Allocation (LDA) (Blei et al., 2003) for the review space by incorporating auxiliary data available in online reviews to improve modeling while simultaneously remaining compatible with preexisting fast sampling techniques such as (Yao et al., 2009; Li et al., 2014a) to achieve high performance. The network is designed such that computation is efficiently offloaded to the client devices using the Chital system (Robinson & Li, 2015), improving response times and reducing server costs. The resulting system is able to rapidly compute a large number of specialized latent variable models while requiring minimal server resources.", "creator": "LaTeX with hyperref package"}}}