{"id": "1510.07385", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Oct-2015", "title": "How to merge three different methods for information filtering ?", "abstract": "Twitter is now a gold marketing tool for entities concerned with online reputation. To automatically monitor online reputation of entities , systems have to deal with ambiguous entity names, polarity detection and topic detection. We propose three approaches to tackle the first issue: monitoring Twitter in order to find relevant tweets about a given entity. Evaluated within the framework of the RepLab-2013 Filtering task, each of them has been shown competitive with state-of-the-art approaches. Mainly we investigate on how much merging strategies may impact performances on a filtering task according to the evaluation measure.", "histories": [["v1", "Mon, 26 Oct 2015 07:17:36 GMT  (20kb)", "http://arxiv.org/abs/1510.07385v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["jean-val\\`ere cossu", "ludovic bonnefoy", "xavier bost", "marc el b\\`eze"], "accepted": false, "id": "1510.07385"}, "pdf": {"name": "1510.07385.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 151 0.07 385v 1 [cs.C L] 26 E"}, {"heading": "1 Introduction", "text": "Online reputation is key information for public figures and companies to respond to and anticipate public opinion. In fact, knowing what makes their reputation good or bad allows them to make informed decisions. Thus, a company can make additional efforts in its call centers if it finds that its consumers are dissatisfied. Monitoring the online reputation of companies requires the ability to retrieve all opinions or reviews about them. Automatic approaches then have to deal with the noise generated by the monitored company. This noise is mainly the result of the ambiguity of entity names (e.g. jaguar, which can refer to an animal or an automobile manufacturer). A classification step is required to filter out sources that actually do not mention the monitored company. Topicdetection is necessary to determine what matter is being discussed in the source, and finally, the polarity of the entity has to be appreciated (is the opinion positive, neutral or negative?). Each of these three issues is a new problem that needs to be addressed in large quantities of documents. Furthermore, online reputation is a short-term problem requiring to work in large quantities of documents."}, {"heading": "2 Related Work", "text": "A decade ago, a TREC task called \"filtering\" (Robertson and Soboroff, 2002) was defined as finding documents relevant to a query in a data stream. Effective approaches were inspired by retrieval techniques to evaluate documents (Okapi (Robertson and al, 2002), Rocchio (Schapire and al, 1998),...).In 2012, a new TREC task called \"Knowledge Base Acceleration\" (KBA) (Frank and al, 2012) began with a broader definition: filtering a temporal corpus of documents that relate to a set of units from Wikipedia. The most powerful approach used a classifier (SVM) by features that represent whether or not a term is contained in a document, regardless of its frequency (Kjersten and McNamee, 2012)."}, {"heading": "3 Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Cosine distance (TF-IDF-Gini)", "text": "The first approach is a supervised classification based on cosinal similarity. Vectors for calculating similarities are created using the Term Frequency-Inverse Document Frequency (TFIDF) (Salton and Buckley, 1988) and the Gini purity criterion (Torres and al, 2012). Tweets are cleaned up by removing hypertext links and punctuation marks, hashtags and @ before a username. We have removed a number of tool words and some entity IDs. Terms are narrowed down. We create a list of n-grams based on the Gini purity criterion. We create term models (words or n-grams) for both classes (related and unrelated tweets) and term frequencies are calculated using the TF-IDF and the Gini criterion. These models take into account the following metadata: user ID, entity ID and language, which are integrated as terms in the Tweet bag of individual terms and the distance between the tweets."}, {"heading": "3.2 KNN with discriminant features", "text": "As in Section 3.1, each tweet is presented as a vector whose components are weighted according to TF-IDF and the Gini purity criterion. In addition, the method takes into account tokens created from the metadata (author, entity ID). The stop list from Section 3.1 was used."}, {"heading": "3.3 Adaptation KBA\u201912 system", "text": "In the KBA filter task, the state-of-the-art approach is to capture the intrinsic characteristics of highly relevant documents using three types of characteristics: document-centric characteristics, company profile characteristics, and time characteristics (Bonnefoy and al, 2013). These characteristics are calculated for each candidate document and used with a Random Forest classifier to determine whether or not the document is related to a particular entity. Unlike previous approaches, it does not require new examples for each new entity. We want to measure the robustness of this approach by applying it to a different type of document (i.e. tweets). No adjustments are made to it, but tweets are still pre-edited: stopwords are deleted and @ are shared before usernames and hashtags are shared. The classifier is trained on all related and unrelated examples for any type of business (automotive, universities, banks, and music / artists)."}, {"heading": "4 Merging algorithms", "text": "To improve performance, we use three ways to combine our system services."}, {"heading": "4.1 Linear combination of outputs score", "text": "N systems are available. For each tweet T of the test set, a system j associates each designation Lk with a confidence value sj (T, Lk) (j = 1,..., N). The designation L is selected according to the following rule: L = argmaxkN \u2211 j = 1sj (T, Lk) (1)"}, {"heading": "4.2 ELECTRE I method", "text": "The aim of this method (Roy, 1991) is to select the best designation from the list of names arranged according to the different systems. A relation S-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L-L"}, {"heading": "4.3 PROMETHEE mono-criterion method", "text": "This method is based on a concordance matrix: for each pair of labels (li, lj) the matrix coefficient cij corresponds to the concordance index c (li, lj) introduced in the previous section. Two sums are calculated for each pair li: sl (li) = \u2211 j cij and sc (li) = \u2211 j cji. sl (li) measures the tendency of li to dominate the other labels and sl (li) the tendency of li to be dominated. The end result of the labels is the difference sl (li) \u2212 sc (li) and the dominant label size is the one whose score is maximum."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Replab 2013 Framework", "text": "The corpus is a bilingual (English and Spanish) collection of tweets containing the name of one of the 61 companies selected in four areas: automotive, banking, universities and music / artists. Tweets were collected by retrieving the Twitter search engine 1. The data set covers a period from 1 June 2012 to 31 December 2012. 42,700 tweets were provided for training purposes and 100,000 tweets for evaluation. The training set is composed of the 700 initial tweets retrieved for each unit. At least 2,200 tweets were collected for each unit. However, tweets are not homogeneously distributed across the entities.The systems are rated according to the following standards: accuracy, reliability and sensitivity (amigo and al, 2013). Reliability is defined as precision of binary relationships predicted by the system in relation to those derived from the gold standard; and sensitivity is similarly defined as recall of relationships. An F measurement is then used to really match the two measurements well."}, {"heading": "5.2 Results", "text": "Table 1 shows the results of our approaches against the official RepLab 2013 Baseline and the median sys-1http: / / twitter.com / searchtem among participants. Baseline2 is a monitored system that matches each tweet in the test set with the most similar tweet in the training set and assumes that the comments in the tweet from the training set are also valid for the tweet in the test set. Tweet similarity is calculated using Jaccard removal and a manageable bag-of-words representation of the tweet. The method described in Section 3.2 can be considered an improved version of the training set. Two systems (KNN and KBA with F readings of respectively.381 and.341) have achieved greater performance than the baseline for all measures. The confidence interval (.002 and.005 for accuracy and F measurement) calculated following the polling method (Voorhees, 1998) shows that the difference between the systems is significant."}, {"heading": "6 Conclusion", "text": "In this article, we outlined some of the interesting features of the systems we evaluated in RepLab 2013, as well as their performance. We proposed several combinations of these strategies to benefit from the variety of information our systems provide. We also demonstrated that these fusion strategies must be applied according to the measurement metric in order to achieve the best results according to a particular metric or to achieve a trade-off. As a merger strategy cannot achieve the best score according to every metric, we can accept a loss according to a metric if it has a real impact on the official metrics of the task. A more advanced view would be to apply a particular merger unit by unit, especially for unbalanced units."}], "references": [{"title": "A", "author": ["A. Davis", "A. Veloso"], "venue": "da Silva, W. M. Jr. and A. Laender. Named entity disambiguation in streaming data. Proceedings of the 50th meeting of the ACL", "citeRegEx": "Davis and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "O\u2019Riordan and G", "author": ["C A. Younus"], "venue": "Pasi. CIRGDISCO at RepLab2012 Filtering Task: A Two-Pass Approach for Company Name Disambiguation in Tweets. in proceedings of CLEF", "citeRegEx": "Younus and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "The hltcoe approach to the trec 2012 kba track", "author": ["B. Kjersten", "P. McNamee"], "venue": "Proceedings of The 21th TREC", "citeRegEx": "Kjersten and McNamee2012", "shortCiteRegEx": null, "year": 2012}, {"title": "The outranking approach and the foundations of ELECTRE methods", "author": ["B. Roy"], "venue": "Theory and Decision,", "citeRegEx": "Roy.,? \\Q1991\\E", "shortCiteRegEx": "Roy.", "year": 1991}, {"title": "Aide \u00e0 la d\u00e9cision robuste pour la localisation d\u2019un centre de traitement des d\u00e9chets", "author": ["Gourion", "Josselin2012] D. Gourion", "D. Josselin"], "venue": "Comparaison de me\u0301thodes d\u2019analyse multicrite\u0300res. Annales de l\u2019ISUP", "citeRegEx": "Gourion et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gourion et al\\.", "year": 2012}, {"title": "Overview of RepLab 2012: Evaluating Online Reputation Management Systems", "author": ["E. Amig\u00f2", "A. Corujo", "J. Gonzalo", "E. Meij", "M. de Rijke"], "venue": "proceedings of CLEF", "citeRegEx": "Amig\u00f2 and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A General Evaluation Measure for Document Organization Tasks", "author": ["E. Amig\u00f2", "J. Gonzalo", "F. Verdejo"], "venue": "SIGIR", "citeRegEx": "Amig\u00f2 and al2013", "shortCiteRegEx": null, "year": 2013}, {"title": "1998", "author": ["Ellen M. Voorhees"], "venue": "Variations in Relevance Judgements and the Measurement of Retrieval Effectiveness. Information Processing and Management, 36(5), 697\u2013716.", "citeRegEx": "Voorhees1998", "shortCiteRegEx": null, "year": 2000}, {"title": "Term weighting approaches in automatic text retrieval, pp 513\u2013523", "author": ["Salton", "Buckley1988] G. Salton", "C. Buckley"], "venue": "Information Processing and Management", "citeRegEx": "Salton et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Salton et al\\.", "year": 1988}, {"title": "Using an Emotion-based Model and Sentiment Analysis Techniques to Classify Polarity for Reputation", "author": ["J. Carrillo de Albornoz", "I. Chugur", "E. Amig\u00f2"], "venue": "proceedings of CLEF", "citeRegEx": "Carrillo and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "FBM-Yahoo! at RepLab 2012", "author": ["J. Chenlo", "J. Atserias", "C. Rodriguez", "R. Blanco"], "venue": "proceedings of CLEF", "citeRegEx": "Chenlo and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Building an entity-centric stream filtering test collection for trec 2012", "author": ["J. Frank", "M. Kleiman-Weiner", "D. Roberts", "F. Niu", "C. Zhang", "C. R\u00e9"], "venue": "Proceedings of The 21th TREC", "citeRegEx": "Frank and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Multiple Criteria Decision Analysis: State of the Art Surveys", "author": ["J. Figueira", "S. Greco", "M. Ehrgott"], "venue": "Springer Verlag", "citeRegEx": "Figueira and al2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Mining spatio-temporal information on micro-blogging streams using a density-based online clustering method", "author": ["J. Lee"], "venue": "Expert Systems with Applications", "citeRegEx": "Lee2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Bellot and F", "author": ["J M. Torres-Moreno", "P M. El-Beze"], "venue": "Bechet.", "citeRegEx": "Torres and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A Weakly-Supervised Detection of Entity Central Documents in a Stream", "author": ["L. Bonnefoy", "V. Bouvier", "P. Bellot"], "venue": "SIGIR", "citeRegEx": "Bonnefoy and al2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining Multiple Similarity Metrics Using a Multicriteria Approach", "author": ["Lamontagne", "Abi-zeid2006] L. Lamontagne", "I. Abi-zeid"], "venue": "Proceedings of ECCBR", "citeRegEx": "Lamontagne et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lamontagne et al\\.", "year": 2006}, {"title": "From Sentiment to Reputation ILPS at RepLab 2012", "author": ["M. Hendrike Peetz", "M. de Rijke", "A. Schuth"], "venue": "proceedings of CLEF", "citeRegEx": "Peetz and al2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Kernel methods for document filtering", "author": ["N. Cancedda", "C. Goutte", "J.M. Renders", "N. Cesa-Bianchi", "A. Conconi", "Y. Li", "J. Shawe-Taylor", "A. Vinokourov", "T. Graepel", "C. Gentile"], "venue": "Proceedings of The 11th TREC", "citeRegEx": "Cancedda and al2002", "shortCiteRegEx": null, "year": 2002}, {"title": "The trec 2002 filtering track report", "author": ["S. Robertson", "I. Soboroff"], "venue": "Proceedings of The 11th TREC", "citeRegEx": "Robertson and Soboroff2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Microsoft cambridge at trec 2002: Filtering track", "author": ["S. Robertson", "S. Walker", "H. Zaragoza", "R. Herbrich"], "venue": "Proceedings of The 11th TREC", "citeRegEx": "Robertson and al2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Boosting and rocchio applied to text filtering", "author": ["Schapire", "al1998] R. Schapire", "Y. Singer", "A. Singhal"], "venue": null, "citeRegEx": "Schapire et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Schapire et al\\.", "year": 1998}, {"title": "Maximum likelihood estimation for filtering thresholds", "author": ["Zhang", "Callan2001] Y. Zhang", "J. Callan"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2001}], "referenceMentions": [], "year": 2015, "abstractText": "Twitter is now a gold marketing tool for entities concerned with online reputation. To automatically monitor online reputation of entities, systems have to deal with ambiguous entity names, polarity detection and topic detection. We propose three approaches to tackle the first issue: monitoring Twitter in order to find relevant tweets about a given entity. Evaluated within the framework of the RepLab2013 Filtering task, each of them has been shown competitive with state-of-the-art approaches. Mainly we investigate on how much merging strategies may impact performances on a filtering task according to the evaluation measure.", "creator": "LaTeX with hyperref package"}}}