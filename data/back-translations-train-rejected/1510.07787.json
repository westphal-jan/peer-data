{"id": "1510.07787", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2015", "title": "Redesigning pattern mining algorithms for supercomputers", "abstract": "Upcoming many core processors are expected to employ a distributed memory architecture similar to currently available supercomputers, but parallel pattern mining algorithms amenable to the architecture are not comprehensively studied. We present a novel closed pattern mining algorithm with a well-engineered communication protocol, and generalize it to find statistically significant patterns from personal genome data. For distributing communication evenly, it employs global load balancing with multiple stacks distributed on a set of cores organized as a hypercube with random edges. Our algorithm achieved up to 1175-fold speedup by using 1200 cores for solving a problem with 11,914 items and 697 transactions, while the naive approach of separating the search space failed completely.", "histories": [["v1", "Tue, 27 Oct 2015 06:59:14 GMT  (416kb,D)", "http://arxiv.org/abs/1510.07787v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.AI", "authors": ["kazuki yoshizoe", "aika terada", "koji tsuda"], "accepted": false, "id": "1510.07787"}, "pdf": {"name": "1510.07787.pdf", "metadata": {"source": "CRF", "title": "Redesigning pattern mining algorithms for supercomputers", "authors": ["Kazuki Yoshizoe", "Aika Terada", "Koji Tsuda"], "emails": ["zoe.f16xl@gmail.com", "terada@cbms.k.u-tokyo.ac.jp", "tsuda@k.u-tokyo.ac.jp"], "sections": [{"heading": null, "text": "We present a novel closed pattern mining algorithm with a sophisticated communication protocol and generalize it to find statistically significant patterns from personal genome data. To distribute communication evenly, it uses a global load distribution with multiple stacks distributed over a series of cores organized as a hypercube with random edges. Our algorithm achieved up to 1175-fold acceleration by using 1200 cores to solve a problem with 11,914 items and 697 transactions, while the naive approach of completely separating the search space failed. Keywords: frequent itemset mining, parallelization of distributed memory, statistical significance, multiple testing."}, {"heading": "1 Introduction", "text": "In parallel, shared memory environment algorithms [2] are at a loss, as upcoming multi-core systems such as Intel Single-Chip Cloud Computers (SCC) inevitably enable a distributed storage architecture due to difficulties in storing data at the same time.This paper aims to redesign pattern mining algorithms for distributed storage environments.The parallel search algorithms are distributed across the search tree by maintaining unexplored nodes in one or more stacks and picking up a processing core and exploring the search tree further down.The newly found nodes are stored on stacks, and are then used by the Graduate School of Frontier Sciences, University of Tokyo, Kashiwa, Japan \u2020 Tokyo Institute of Technology, Tokyo, Japan Research Fellow of Japan Society for the Promotion of Science, e."}, {"heading": "2 Backgrounds", "text": "2.1 Linear Time Closed Article Quantity Miner (LCM) In view of an article set I such that there is no article set j / \u0445I that meets sup (I) = sup (I), I am a closed article set. In other words, when an article is added to a closed article set, the support becomes smaller and smaller. Closed Article Quantity provides a lossless compressed expression for the enumeration of article sets. The original search space of article sets Miner (LCM) becomes gray in article sets and edges in Fig. 1. Linear Time Closed Article Quantity Miner (LCM) is a famous technique in frequent article set mining [7] that changes the search space to a tree with edges that connect only closed article sets. Please refer [7] for details of the LCM algorithm that is unbalanced."}, {"heading": "3 Significant Pattern Mining", "text": "In this section we will explain significant mining patterns introduced by Terada et al. [11]. Suppose we have several transactions. Each transaction contains a number of items and is classified into positive or negative. Overall, Npos transactions are divided into positive categories. The aim of the significant mining patterns is to list statistically significant relationships between itemsets and the classification in such a way that the probability of at least one false discovery occurring, which is called a family error factor (FWER), is highest. 3.1 Statistical evaluation for a bulletin Given an itemset I, we evaluate the statistical significance of I as follows: Let x (I) and n (I) be the frequency of I in all transactions and in positive transactions. The P value of I is calculated by Fisher's one-sided scrutiny asP (I) = min {x (I), Npos} \u2211 ni = n (I) (I)."}, {"heading": "3.3 Support increase algorithm for LAMP", "text": "In the third phase, statistically significant item sets are extracted from the closed item sets. The definition of adequate minimum support comes from the theory as described in section 3, which is shown in the left side of the figure. 2. The number of closed item sets decreases monotonously as the number of closed item sets (e.g. frequency) increases. On the other hand, Equation 3.1 can calculate the threshold for the closed item set number, which increases monotonously as the size of the closed item set number increases. (The numbers in the figure are just examples, but come from a small but realistic problem.) The inequality sign tilts at \u03bb = 5. Subtracting from the threshold 1 of the minimum support we get the corresponding minimum support, 4 in this case, and the closed target number CS (4) will be the correction factor for the statistically significant item sets."}, {"heading": "4 Proposed Method", "text": "Since our target is a tree, we use the term node to denote nodes in the tree. To avoid confusion, we use the normal term arithmetic node only in limited places, and use the term process instead. A process is mapped to a CPU core, so there will be 12 processes on a 12-core machine."}, {"heading": "4.1 Parallelize depth first search using stack", "text": "When the search reaches the node, there are no children and the function returns. Backtracking can be implemented in a natural way in this way. However, we will now describe how to transform this into a stack-based version as preparation for parallelization. As shown in the DFS Loop function in Fig. 3, we can replace the recursive function call for each child with push to and pop from the stack. Only the root node is moved to the stack before the algorithm starts. Then, the top entry of the stack is cracked and the children of the node are pushed onto the stack. The algorithm terminates when the stack is empty. To do this approach, each node on the stack must have enough data for the search. For itemset mining, the itemset data itself identifies the node of the search stairs. Figure 4 shows the behavior of the DFS Loop children."}, {"heading": "5 Experiments", "text": "It is. (It is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it is. (it.) It is. (it.) It. (it is. (it.) It is. (it. (it.) It is. (it.) It is. (it. (it.) It is. (it. (it.) It. (it is. (it.) It is. (it. (it.) It. (it. (it.) It is. (it. (it.) It is. (it. (it.) It. (it. (it.) It. (it. (it.) It. (it. (it.) It. (it. (it.) is. (it. (it.) It. (it. (it.) It. (it. It. (it.) It. (it. (it. It. (it. It.) is. (it. It. (it. It.) is. (it. (it.) It. (it. (it.) It. (it.) It. (it. (it. It. (it.) It. (it.) It. It is. (it. (it. It is. (it.) It. It. (it. (it. It.) is. It is. (it. (it.) It is. (it.) It. (it. (it. It. It is.) It is. It is. (it. It. It. (it. It."}, {"heading": "5.5 Comparison with LAMP2 (e.g. LCM)", "text": "LAMP2, described in [12] uses LCM Ver. 5.3 as the base tool. As our code is geared to large and high density databases, LAMP2 exceeds our approach when executed on a single core, as shown in Table 2. However, it turns out that for large problems, which are our main goal, the difference was small and our 12-core result exceeded the single LAMP2 process. However, the results show that although it was not our main goal, there was a large margin for improvement for sparse databases with a large number of transactions. 5.6 Finding significant patterns As a result, we found statistically significant patterns from the given database, which are significant combinations of mutations in terms of genomics. From HapMap Domain. 20, we found statistically significant items with a maximum of 8 items within less than 20 seconds, which goes far beyond the capability of brute force search."}, {"heading": "6 Related Work", "text": "However, the first version of LAMP uses a wider scattering to find the optimal value. Our parallel strategy is known as efficient, and therefore Minato et al. has proposed a fast algorithm for searching for depth. [12] However, more acceleration is needed to analyze the density and the large datasets. Our parallel strategy is applicable to detect not only significant itemset, but also subgraph mining. [22] The parallel search is based on recent advances in the world of work."}, {"heading": "7 Conclusions and Future Work", "text": "Our parallel algorithm achieved 260 to 1175-fold acceleration with 1,200 cores. Of course, scalability was better for more difficult problems, which should be the main objectives of a parallel approach. As a result, our approach is extremely promising. The main difference between traditional algorithms and massive parallel algorithms is not whether memory is shared or distributed. From the algorithm's point of view, memory on another computer is just a slow and large memory. Future algorithms will have to deal with such environments. We expect our algorithm to continue to be efficient in the future when a greater number of cores and memory is available. KY is supported by JST ERATO, Kakenhi 25700038, 15H02708. AT is supported by JSPS Research Fellowships for Young Scientists. KT is supported by JST CREST, RIKEN PostK, NIMS MI2I, Kakenhi Nanostructure, 15H7H11."}], "references": [{"title": "Parallel mining of association rules", "author": ["R. Agrawal", "J.C. Shafer"], "venue": "IEEE TKDE, no. 6, pp. 962\u2013969, 1996.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1996}, {"title": "Paraminer: a generic pattern mining algorithm for multi-core architectures", "author": ["B. Negrevergne", "A. Termier", "M.-C. Rousset", "J.- F. M\u00e9haut"], "venue": "Data Min. Knowl. Discov., vol. 28, no. 3, pp. 593\u2013633, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Mining treestructured data on multicore systems", "author": ["S. Tatikonda", "S. Parthasarathy"], "venue": "Proc. VLDB Endow., vol. 2, no. 1, pp. 694\u2013705, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Adaptive parallel graph mining for CMP architectures", "author": ["G. Buehrer", "S. Parthasarathy", "Y. Chen"], "venue": "Proc. ICDM 2006, pp. 97\u2013106, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Discovering closed frequent itemsets on multicore: Parallelizing computations and optimizing memory accesses", "author": ["B. N\u00e9grevergne", "A. Termier", "J. M\u00e9haut", "T. Uno"], "venue": "Proc. HPCS 2010, pp. 521\u2013528, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Intel lifts the hood on its \u201csingle-chip cloud computer", "author": ["A.-M. Corley"], "venue": "IEEE Spectrum Online (9 feb 2010), 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "LCM ver. 2: Efficient mining algorithms for frequent/closed/maximal itemsets", "author": ["T. Uno", "M. Kiyomi", "H. Arimura"], "venue": "Proc. IEEE ICDM\u201904 Workshop FIMI\u201904, vol. 126, 2004.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Lifeline-based global load balancing", "author": ["V.A. Saraswat", "P. Kambadur", "S. Kodali", "D. Grove", "S. Krishnamoorthy"], "venue": "Proc. PPoPP \u201911, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Personal genomes: The case of the missing heritability", "author": ["B. Maher"], "venue": "Nature, vol. 456, no. 7218, pp. 18\u201321, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "A survey of data mining methods for linkage disequilibrium mapping", "author": ["P. Onkamo", "H. Toivonen"], "venue": "Hum Genomics, vol. 2, no. 5, pp. 336\u2013340, 2006.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Statistical significance of combinatorial regulations", "author": ["A. Terada", "M. Okada-Hatakeyama", "K. Tsuda", "J. Sese"], "venue": "Proc Natl Acad Sci U S A., vol. 110, no. 32, pp. 12 996\u201313 001, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "A Fast Method of Statistical Assessment for Combinatorial Hypotheses Based on Frequent Itemset Enumeration", "author": ["S. Minato", "T. Uno", "K. Tsuda", "A. Terada", "J. Sese"], "venue": "ECML/PKDD 2014, vol. 8725, pp. 422\u2013436, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Evaluation of a simple, scalable, parallel best-first search strategy", "author": ["A. Kishimoto", "A. Fukunaga", "A. Botea"], "venue": "Artif. Intell., vol. 195, pp. 222\u2013248, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Transposition Table Driven Work Scheduling in Distributed Search.", "author": ["J.W. Romein", "A. Plaat", "H.E. Bal", "J. Schaeffer"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "A modified Bonferroni method for discrete data", "author": ["R.E. Tarone"], "venue": "Biometrics, vol. 46, no. 2, pp. 515\u2013522, 1990.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1990}, {"title": "Small-world datacenters", "author": ["J.-Y. Shin", "B. Wong", "E.G. Sirer"], "venue": "Proc. SOCC \u201911, 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Scalable parallel numerical constraint solver using global load balancing", "author": ["D. Ishii", "K. Yoshizoe", "T. Suzumura"], "venue": "Proc. X10 2015, pp. 33\u201338, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Algorithms for distributed termination detection", "author": ["F. Mattern"], "venue": "Distributed Computing, vol. 2, no. 3, pp. 161\u2013175, 1987.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1987}, {"title": "Genetic control of human brain transcript expression in Alzheimer disease.", "author": ["J.A. Webster", "J.R. Gibbs", "J. Clarke"], "venue": "Am J Hum Genet.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Significant subgraph mining with multiple testing correction", "author": ["M. Sugiyama", "F. Llinares-L\u00f3pez", "N. Kasenburg", "K.M. Borgwardt"], "venue": "SIAM SDM15, pp. 37\u201345, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Scalable Distributed Monte-Carlo Tree Search", "author": ["K. Yoshizoe", "A. Kishimoto", "T. Kaneko", "H. Yoshimoto", "Y. Ishikawa"], "venue": "SoCS\u201911, pp. 180\u2013187, 2011.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Parallel algorithms for pattern mining have been a longstanding subject of research [1, 2, 3, 4, 5].", "startOffset": 84, "endOffset": 99}, {"referenceID": 1, "context": "Parallel algorithms for pattern mining have been a longstanding subject of research [1, 2, 3, 4, 5].", "startOffset": 84, "endOffset": 99}, {"referenceID": 2, "context": "Parallel algorithms for pattern mining have been a longstanding subject of research [1, 2, 3, 4, 5].", "startOffset": 84, "endOffset": 99}, {"referenceID": 3, "context": "Parallel algorithms for pattern mining have been a longstanding subject of research [1, 2, 3, 4, 5].", "startOffset": 84, "endOffset": 99}, {"referenceID": 4, "context": "Parallel algorithms for pattern mining have been a longstanding subject of research [1, 2, 3, 4, 5].", "startOffset": 84, "endOffset": 99}, {"referenceID": 1, "context": "Algorithms for shared memory environments [2] are losing ground, because upcoming many-core systems such as Intel Single-Chip Cloud Computer (SCC) [6] will inevitably employ a distributed memory architecture due to difficulty in concurrent memory access.", "startOffset": 42, "endOffset": 45}, {"referenceID": 5, "context": "Algorithms for shared memory environments [2] are losing ground, because upcoming many-core systems such as Intel Single-Chip Cloud Computer (SCC) [6] will inevitably employ a distributed memory architecture due to difficulty in concurrent memory access.", "startOffset": 147, "endOffset": 150}, {"referenceID": 1, "context": "Thus, distribution of stacks to cores and efficient communication among them is a central issue that does not arise in shared memory studies [2].", "startOffset": 141, "endOffset": 144}, {"referenceID": 6, "context": "Our algorithm generalizes the LCM algorithm [7] based on global load balancing with multiple stacks distributed on a set of cores organized as a hypercube with random edges [8].", "startOffset": 44, "endOffset": 47}, {"referenceID": 7, "context": "Our algorithm generalizes the LCM algorithm [7] based on global load balancing with multiple stacks distributed on a set of cores organized as a hypercube with random edges [8].", "startOffset": 173, "endOffset": 176}, {"referenceID": 8, "context": ", mutation profiles of individuals [9].", "startOffset": 35, "endOffset": 38}, {"referenceID": 9, "context": "Among several pattern mining-based approaches for genetics studies [10], we picked up limitlessarity multiple testing procedure (LAMP) [11, 12], because it computes properly corrected P-values for each pattern of alleles, and allows us to find all statistically significant patterns.", "startOffset": 67, "endOffset": 71}, {"referenceID": 10, "context": "Among several pattern mining-based approaches for genetics studies [10], we picked up limitlessarity multiple testing procedure (LAMP) [11, 12], because it computes properly corrected P-values for each pattern of alleles, and allows us to find all statistically significant patterns.", "startOffset": 135, "endOffset": 143}, {"referenceID": 11, "context": "Among several pattern mining-based approaches for genetics studies [10], we picked up limitlessarity multiple testing procedure (LAMP) [11, 12], because it computes properly corrected P-values for each pattern of alleles, and allows us to find all statistically significant patterns.", "startOffset": 135, "endOffset": 143}, {"referenceID": 6, "context": "Linear time Closed itemset Miner (LCM) is a famous technique in frequent itemset mining [7], which modifies the search space to a tree with edges connecting only closed itemsets.", "startOffset": 88, "endOffset": 91}, {"referenceID": 6, "context": "Please refer to [7] for the details of the LCM algorithm.", "startOffset": 16, "endOffset": 19}, {"referenceID": 7, "context": "To equally distribute the workload to processes, parallel search techniques have been developed for popular search algorithms ([8], [13],[14]).", "startOffset": 127, "endOffset": 130}, {"referenceID": 12, "context": "To equally distribute the workload to processes, parallel search techniques have been developed for popular search algorithms ([8], [13],[14]).", "startOffset": 132, "endOffset": 136}, {"referenceID": 13, "context": "To equally distribute the workload to processes, parallel search techniques have been developed for popular search algorithms ([8], [13],[14]).", "startOffset": 137, "endOffset": 141}, {"referenceID": 10, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "2 LAMP More recently, the multiple testing procedure, which is named LAMP, has been proposed for detecting significant itemsets [11].", "startOffset": 128, "endOffset": 132}, {"referenceID": 14, "context": "The first key point is obtained from the Tarone\u2019s P-value bound strategy [16].", "startOffset": 73, "endOffset": 77}, {"referenceID": 11, "context": "However, by using the support increase algorithm [12], minimum support can be found in a single run.", "startOffset": 49, "endOffset": 53}, {"referenceID": 15, "context": "It became known recently that the diameter of random graph is small [17].", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "Global Load Balancing (GLB) method was proposed in [8] which distributes workloads following hypercube edges and random edges.", "startOffset": 51, "endOffset": 54}, {"referenceID": 16, "context": "We set l = 2 (the hypercube has the highest possible dimensions) and w = 1 based on preliminary experiments and our past experience ([18]).", "startOffset": 133, "endOffset": 137}, {"referenceID": 17, "context": "Mattern proposed several variations of the time algorithm in [19].", "startOffset": 61, "endOffset": 65}, {"referenceID": 18, "context": "The HapMap and Alzheimer (Alz) data obtained from two genomewide association studies (GWASs), which is widely conducting research to detect causal genes of disease (Alzheimer study [20], the HapMap project [21]).", "startOffset": 181, "endOffset": 185}, {"referenceID": 10, "context": "Additionally, to investigate effect on dataset containing small number of items and large number of transactions, we used human breast cancer transcriptome dataset (MCF7), which was analyzed in [11].", "startOffset": 194, "endOffset": 198}, {"referenceID": 11, "context": "LCM) LAMP2 described in [12] uses LCM ver.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "1 LAMP Multiple testing procedures for significant pattern mining have been proposed [11, 12, 22].", "startOffset": 85, "endOffset": 97}, {"referenceID": 11, "context": "1 LAMP Multiple testing procedures for significant pattern mining have been proposed [11, 12, 22].", "startOffset": 85, "endOffset": 97}, {"referenceID": 19, "context": "1 LAMP Multiple testing procedures for significant pattern mining have been proposed [11, 12, 22].", "startOffset": 85, "endOffset": 97}, {"referenceID": 10, "context": "LAMP [11] uses Bonferroni-like multiple testing procedures with Tarone\u2019s P-value bound strategy [16] to improve the sensitivity of the correction through frequent itemset mining.", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "LAMP [11] uses Bonferroni-like multiple testing procedures with Tarone\u2019s P-value bound strategy [16] to improve the sensitivity of the correction through frequent itemset mining.", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "proposed a fast algorithm for LAMP using the depth-first search [12].", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "Our parallel strategy is applicable to detecting not only significant itemset but also significant subgraph mining [22].", "startOffset": 115, "endOffset": 119}, {"referenceID": 7, "context": "2 Parallel search As already described, our work is based on recent progress in smarter workload distribution using hypercube with random edges [8].", "startOffset": 144, "endOffset": 147}, {"referenceID": 16, "context": "A similar approach was applied to Numerical Constraints Satisfaction Progress (NCSP) and achieved approximately 500-fold speedup on 600 cores [18].", "startOffset": 142, "endOffset": 146}, {"referenceID": 13, "context": "IDA* can be parallelized by distributing the hash table based on a hash function as shown in TDS approach [14].", "startOffset": 106, "endOffset": 110}, {"referenceID": 12, "context": "A* search requires priority queue and seems more difficult, but efficient performance was achieved by Hash Distributed A* (HDA*) algorithm [13], which is applied to planning problems.", "startOffset": 139, "endOffset": 143}, {"referenceID": 20, "context": "However, even for two player games where most of the branches are pruned, successful parallel algorithms are reported, for example, parallel Monte Carlo Tree Search algorithm [23].", "startOffset": 175, "endOffset": 179}, {"referenceID": 0, "context": "3 Parallel Itemset Mining Speedup using up to 32 nodes (32 processors) is reported for parallelization of the variants of the apriori algorithm in [1].", "startOffset": 147, "endOffset": 150}, {"referenceID": 2, "context": "Recent work on shared memory environment include [3] and [2].", "startOffset": 49, "endOffset": 52}, {"referenceID": 1, "context": "Recent work on shared memory environment include [3] and [2].", "startOffset": 57, "endOffset": 60}], "year": 2015, "abstractText": "Upcoming many core processors are expected to employ a distributed memory architecture similar to currently available supercomputers, but parallel pattern mining algorithms amenable to the architecture are not comprehensively studied. We present a novel closed pattern mining algorithm with a well-engineered communication protocol, and generalize it to find statistically significant patterns from personal genome data. For distributing communication evenly, it employs global load balancing with multiple stacks distributed on a set of cores organized as a hypercube with random edges. Our algorithm achieved up to 1175-fold speedup by using 1200 cores for solving a problem with 11,914 items and 697 transactions, while the naive approach of separating the search space failed completely.", "creator": "LaTeX with hyperref package"}}}