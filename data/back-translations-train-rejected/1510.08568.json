{"id": "1510.08568", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2015", "title": "Feature-Based Diversity Optimization for Problem Instance Classification", "abstract": "Understanding the behaviour of heuristic search methods is a challenge. This even holds for simple local search methods such as 2-OPT for the Traveling Salesperson problem. In this paper, we present a general framework that is able to construct a diverse set of instances that are hard or easy for a given search heuristic. Such a diverse set is obtained by using an evolutionary algorithm for constructing hard or easy instances that are diverse with respect to different features of the underlying problem. Examining the constructed instance sets, we show that many combinations of two or three features give a good classification of the TSP instances in terms of whether they are hard to be solved by 2-OPT.", "histories": [["v1", "Thu, 29 Oct 2015 05:40:54 GMT  (567kb,D)", "https://arxiv.org/abs/1510.08568v1", "15 pages, 15 figures"], ["v2", "Fri, 8 Apr 2016 05:12:48 GMT  (658kb,D)", "http://arxiv.org/abs/1510.08568v2", "20 pages, 18 figures"]], "COMMENTS": "15 pages, 15 figures", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["wanru gao", "samadhi nallaperuma", "frank neumann"], "accepted": false, "id": "1510.08568"}, "pdf": {"name": "1510.08568.pdf", "metadata": {"source": "CRF", "title": "Feature-Based Diversity Optimization for Problem Instance Classification", "authors": ["Wanru Gao"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that we are able to go in search of a solution that is capable of finding a solution, that is able to find a solution, that is able to find a solution, and that is able to find a solution that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution."}, {"heading": "2 Background", "text": "We consider the classic NP-hard-Euclidean Traveling Salesperson (TSP) problem to be an example of the development of hard and simple instances with different characteristics. Our methodology can be applied to any optimization problem, but the advantage of using the TSP in our study is that it has already been extensively studied from different perspectives, including the area of function-based analyses. The goal is to find a Hamiltonian cycle whose sum of distances is minimal. A candidate for the TSP is often represented by a permutation at the Euclidean level and Euclidean distances d."}, {"heading": "3 Feature-Based Diversity Optimization", "text": "In this section we present our approach of developing a series of simple or hard cases that are different in relation to important problem characteristics. As in previous algorithms 1: (\u00b5 + \u03bb) -EAD 1: We initialize the population P with \u00b5 TSP instances of approximation to the population. 2 Leave C P, where the population I = TSP instance is removed. 3 For each individual person, a descendant I \u2032 of I is created by mutation. If \u03b1A (I \u2032) > \u03b1h, add I \u2032 to P. 4 While I have an individual I = argminJ-P d (J, P) uniformly atrandom. 5 Repeat step II to 4 up termination criterion is achieved. We measure the hardness of a given instance by the ratio of the solution quality achieved by the considered algorithm and the value of an optimal solution. The approximation ratio of an algorithm I is defined for a given instance."}, {"heading": "4 Range of Feature Values", "text": "We first evaluate our diversity optimization approach with respect to the diversity generated with respect to a single feature in each run. Focusing on a single feature in each run provides insight into the possible range of a particular feature value for hard or simple cases. The previous study [11] suggests that there are some differences in the possible range of characteristic values for simple and hard instances. We examine the impact of diversity optimization on the range of features by comparing the instances generated by diversity optimization with the instances generated by the conventional approach. Evolving hard instances based on the conventional evolutionary algorithm have obtained instances with mean approximation ratios of 1.12 for n = 25, 1.16 for n = 50 and 1.18 for n = 100. For simple instances, the mean approximation ratios are 1 for n = 25.50 and 1.03 for n = 100. Figure 1 (left) presents the variation of the mean distance between the function and the centered points."}, {"heading": "5 Classification Based on Multiple Features", "text": "Since a single characteristic is not able to clearly classify the hard / simple cases, the following combinations of two or three different characteristics will be examined."}, {"heading": "5.1 Diversity Maximization over Single Feature Value", "text": "rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "5.2 Diversity Maximization over Multiple Feature Values", "text": "To investigate the relationship between trait combination and hardness of instances, a weighted population diversity is introduced based on multiple traits. Therefore, the weighted population diversity for a given set of traits {f1, f2,..., fk} is defined as the weighted sum of normalized population diversity via these k-traits. An instance I's contribution to weighted population diversity is defined as {I, P), where the normalized contribution to population diversity d (I, P) via certain traits i and wi represents the weight of traits i. An individual's contribution to population diversity based on the maximum population diversity based on the trait is normalized (I, P) denotes the normalized contribution to population diversity d (I, P) via certain traits i and wi represents the weight of traits i and the individual traits i.The contribution of a person to the simple way of obtaining population diversity is used to obtain the weighted insights in this algorithm."}, {"heading": "6 Instances Classification Using Support Vector Machine", "text": "Supporting vector machines (SVM) are well-known supervised learning models in machine learning that can be used for classification, regression and outlier detection [3, 8]. To quantify the separation between instances of different hardness based on characteristic values, SVM models are constructed for each combination of characteristics."}, {"heading": "6.1 Linear SVM", "text": "The linear classifier is the first model to be tested in the classification of the dataset. In SVM, the linear classifiers that can separate the data with maximum margin are called the optimal separating hyperplane. It is clear from the diagrams in Figures 2, 3, 4 and 5 that none of the datasets is linearly separable. Taking into account the compromise between maximizing the margin and minimizing the number of misclassified data, the soft margin SVM is used for classification. Let ACCn be the training accuracy of a combination of features in separating the hard and simple instances of size n. We define ACCn as the ratio of the instances correctly classified by the model."}, {"heading": "6.2 Nonlinear Classification with RBF Kernel", "text": "The kernel of the Radial Basic Function (RBF) is one of the known core functions used in the SVM classification. In the application of RBF, two parameters must be selected, namely C (cost) and \u03b3. Setting the parameter for RBF is crucial, since increasing C and \u03b3 leads to precise separation of training data, but at the same time causes overadjustment. SVMs here are generated to quantify the separation rate between hard and simple instances, rather than classifying other instances. After some initial experiments, (C, \u03b3) is set to (100.2) in all tests to avoid overadjustment. This parameter setting may not be the best parameter for the particular feature combination in the SVM classification, but it helps us gain some understanding of the separation of hard and simple instances generated on the same condition. Tables 1 and 2 show the accuracy of two different features in the SVM classification with an SVM average accuracy of three instances of 825 and an SVM average accuracy of three instances."}, {"heading": "7 Conclusions", "text": "With this work, we have introduced a new methodology for developing simple / hard instances that are diverse in terms of the characteristics of the present optimization problem. Using our diversity optimization approach, we have shown that the simple and hard instances achieved by our approach cover a much larger area in the attribute space than previous methods. The diversity optimization approach provides cases that are diverse in terms of the characteristics studied. The proposed population diversity measurements provide a good evaluation of the different attribute values over one or more attribute values. In particular, our experimental studies for 2-OPT and TSP have shown that our wide range of different instances can be fairly well divided into simple and hard instances when considering a suitable combination of multiple characteristics that provide some guidance for predicting as the next step. In particular, the SVM classification model, built with the diverse instances that can automate TSP instances based on the problem hardness models, requires a strong basis for selecting algorithms for automated pre-classification."}], "references": [{"title": "Solution of a min-max vehicle routing problem", "author": ["D. Applegate", "W. Cook", "S. Dash", "A. Rohe"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "editors", "author": ["B. Bonet", "S. Koenig"], "venue": "Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA. AAAI Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning, 20(3):273\u2013 297", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1995}, {"title": "A method for solving traveling-salesman problems", "author": ["G.A. Croes"], "venue": "Operations Research, 6(6):791\u2013812", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1958}, {"title": "Worst case and probabilistic analysis of the 2-opt algorithm for the TSP", "author": ["M. Englert", "H. R\u00f6glin", "B. V\u00f6cking"], "venue": "Algorithmica, 68(1):190\u2013264", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Support vector machines for classification and regression", "author": ["S.R. Gunn"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Algorithm runtime prediction: Methods & evaluation", "author": ["F. Hutter", "L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Artif. Intell.,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Theoretical analysis of two ACO approaches for the traveling salesman problem", "author": ["T. K\u00f6tzing", "F. Neumann", "H. R\u00f6glin", "C. Witt"], "venue": "Swarm Intelligence, 6(1):1\u2013 21", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "A novel feature-based approach to characterize algorithm performance for the traveling salesperson problem", "author": ["O. Mersmann", "B. Bischl", "H. Trautmann", "M. Wagner", "J. Bossek", "F. Neumann"], "venue": "Annals of Mathematics and Artificial Intelligence, 69(2):151\u2013182", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "e1071: Misc Functions of the Department of Statistics", "author": ["D. Meyer", "E. Dimitriadou", "K. Hornik", "A. Weingessel", "F. Leisch"], "venue": "Probability Theory Group ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1071}, {"title": "Parameter prediction based on features of evolved instances for ant colony optimization and the traveling salesperson problem", "author": ["S. Nallaperuma", "M. Wagner", "F. Neumann"], "venue": "PPSN XIII - 13th International Conference, Ljubljana, Slovenia, September 13-17, 2014. Proceedings, pages 100\u2013109", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "A feature-based comparison of local search and the christofides algorithm for the travelling salesperson problem", "author": ["S. Nallaperuma", "M. Wagner", "F. Neumann", "B. Bischl", "O. Mersmann", "H. Trautmann"], "venue": "FOGA \u201913, pages 147\u2013160", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Bioinspired Computation in Combinatorial Optimization:Algorithms and Their Computational Complexity", "author": ["F. Neumann", "C. Witt"], "venue": "Springer-Verlag New York, Inc., New York, NY, USA, 1st edition", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "R: A Language and Environment for Statistical Computing", "author": ["R Core Team"], "venue": "R Foundation for Statistical Computing, Vienna, Austria", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Measuring instance difficulty for combinatorial optimization problems", "author": ["K. Smith-Miles", "L. Lopes"], "venue": "Computers & OR, 39(5):875\u2013889", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "J", "author": ["K. Smith-Miles"], "venue": "van Hemert, and X. Y. Lim. Understanding TSP difficulty by learning from evolved instances. In 4th International Conference on Learning and Intelligent Optimization (LION), LION\u201910, pages 266\u2013280. Springer", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Defining and optimizing indicator-based diversity measures in multiobjective search", "author": ["T. Ulrich", "J. Bader", "L. Thiele"], "venue": "R. Schaefer, C. Cotta, J. Kolodziej, and G. Rudolph, editors, PPSN (1), volume 6238 of Lecture Notes in Computer Science, pages 707\u2013717. Springer", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Integrating decision space diversity into hypervolume-based multiobjective search", "author": ["T. Ulrich", "J. Bader", "E. Zitzler"], "venue": "M. Pelikan and J. Branke, editors, GECCO, pages 455\u2013462. ACM", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolving combinatorial problem instances that are difficult to solve", "author": ["J.I. van Hemert"], "venue": "Evolutionary Computation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "A perspective view and survey of meta-learning", "author": ["R. Vilalta", "Y. Drissi"], "venue": "Artificial Intelligence Review,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "Satzilla: portfolio-based algorithm selection for sat", "author": ["L. Xu", "F. Hutter", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}], "referenceMentions": [{"referenceID": 20, "context": "In both the artificial intelligence (AI) [23, 9, 22, 5, 7] and operational research communities [17, 21], this topic has become a major point of interest.", "startOffset": 41, "endOffset": 58}, {"referenceID": 6, "context": "In both the artificial intelligence (AI) [23, 9, 22, 5, 7] and operational research communities [17, 21], this topic has become a major point of interest.", "startOffset": 41, "endOffset": 58}, {"referenceID": 19, "context": "In both the artificial intelligence (AI) [23, 9, 22, 5, 7] and operational research communities [17, 21], this topic has become a major point of interest.", "startOffset": 41, "endOffset": 58}, {"referenceID": 14, "context": "In both the artificial intelligence (AI) [23, 9, 22, 5, 7] and operational research communities [17, 21], this topic has become a major point of interest.", "startOffset": 96, "endOffset": 104}, {"referenceID": 18, "context": "In both the artificial intelligence (AI) [23, 9, 22, 5, 7] and operational research communities [17, 21], this topic has become a major point of interest.", "startOffset": 96, "endOffset": 104}, {"referenceID": 8, "context": "The feature-based analysis of heuristic search algorithms has become an important part in understanding such type of algorithms [11, 18].", "startOffset": 128, "endOffset": 136}, {"referenceID": 15, "context": "The feature-based analysis of heuristic search algorithms has become an important part in understanding such type of algorithms [11, 18].", "startOffset": 128, "endOffset": 136}, {"referenceID": 12, "context": "Thereby, it provides an important tool for bridging the gap between pure experimental investigations and mathematical methods for analysing the performance of search algorithms [15, 10, 6].", "startOffset": 177, "endOffset": 188}, {"referenceID": 7, "context": "Thereby, it provides an important tool for bridging the gap between pure experimental investigations and mathematical methods for analysing the performance of search algorithms [15, 10, 6].", "startOffset": 177, "endOffset": 188}, {"referenceID": 4, "context": "Thereby, it provides an important tool for bridging the gap between pure experimental investigations and mathematical methods for analysing the performance of search algorithms [15, 10, 6].", "startOffset": 177, "endOffset": 188}, {"referenceID": 8, "context": "Current methods for the feature-based analysis are based on constructing hard and easy instances for an investigated search heuristic and a given optimization problem by evolving instances using an evolutionary algorithm [11, 14, 13].", "startOffset": 221, "endOffset": 233}, {"referenceID": 11, "context": "Current methods for the feature-based analysis are based on constructing hard and easy instances for an investigated search heuristic and a given optimization problem by evolving instances using an evolutionary algorithm [11, 14, 13].", "startOffset": 221, "endOffset": 233}, {"referenceID": 10, "context": "Current methods for the feature-based analysis are based on constructing hard and easy instances for an investigated search heuristic and a given optimization problem by evolving instances using an evolutionary algorithm [11, 14, 13].", "startOffset": 221, "endOffset": 233}, {"referenceID": 16, "context": "Following some recent work on using evolutionary algorithms for generating diverse sets of instances that are all of high quality [19, 20], we introduce an evolutionary algorithm which maximizes diversity of the obtained instances in terms of a given feature.", "startOffset": 130, "endOffset": 138}, {"referenceID": 17, "context": "Following some recent work on using evolutionary algorithms for generating diverse sets of instances that are all of high quality [19, 20], we introduce an evolutionary algorithm which maximizes diversity of the obtained instances in terms of a given feature.", "startOffset": 130, "endOffset": 138}, {"referenceID": 0, "context": "For our investigations cities are always in the normalized plane [0,1]2, i.", "startOffset": 65, "endOffset": 70}, {"referenceID": 0, "context": "each city has an x- and y-coordinate in the interval [0,1].", "startOffset": 53, "endOffset": 58}, {"referenceID": 0, "context": "In following, a TSP instance always consists of a set of n points in [0,1]2 and the Euclidean distances between them.", "startOffset": 69, "endOffset": 74}, {"referenceID": 3, "context": "Local search heuristics have been shown to be very successful when dealing with the TSP and the most prominent local search operator is the 2-OPT operator [4].", "startOffset": 155, "endOffset": 158}, {"referenceID": 18, "context": "Using an evolutionary algorithm, it is possible to evolve sets of hard and easy instances by maximizing or minimizing the fitness (tour length in the case of the TSP) of each instance [21, 17, 11, 18].", "startOffset": 184, "endOffset": 200}, {"referenceID": 14, "context": "Using an evolutionary algorithm, it is possible to evolve sets of hard and easy instances by maximizing or minimizing the fitness (tour length in the case of the TSP) of each instance [21, 17, 11, 18].", "startOffset": 184, "endOffset": 200}, {"referenceID": 8, "context": "Using an evolutionary algorithm, it is possible to evolve sets of hard and easy instances by maximizing or minimizing the fitness (tour length in the case of the TSP) of each instance [21, 17, 11, 18].", "startOffset": 184, "endOffset": 200}, {"referenceID": 15, "context": "Using an evolutionary algorithm, it is possible to evolve sets of hard and easy instances by maximizing or minimizing the fitness (tour length in the case of the TSP) of each instance [21, 17, 11, 18].", "startOffset": 184, "endOffset": 200}, {"referenceID": 8, "context": "In [11], there are 47 features in 8 groups used to provide an understanding of algorithm performance for the TSP.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "Within this study, A(I) is the tour length obtained by 2-OPT for a given TSP instance I and OPT (I) is the optimal tour length which we obtain in our experiments by using the exact TSP solver Concorde [1].", "startOffset": 201, "endOffset": 204}, {"referenceID": 8, "context": "In [11], 47 features of TSP instances for characterizing easy and hard TSP instances have been studied.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "We refer the reader to [11] for a detailed explanation for each feature.", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "All programs in our experiments are written in R and run in R environment [16].", "startOffset": 74, "endOffset": 78}, {"referenceID": 8, "context": "We use the functions in tspmeta package to compute the feature values [11].", "startOffset": 70, "endOffset": 74}, {"referenceID": 8, "context": "Based on previous investigations in [11] and initial experimental investigations, we set \u03b1e = 1 for instances of size 25 and 50, and \u03b1e = 1.", "startOffset": 36, "endOffset": 40}, {"referenceID": 8, "context": "The previous study [11], suggests that there are some differences in the possible range of feature values for easy and hard instances.", "startOffset": 19, "endOffset": 23}, {"referenceID": 8, "context": "We study the effect of the diversity optimization on the range of features by comparing the instances generated by diversity optimization to the instances generated by the conventional approach in [11].", "startOffset": 197, "endOffset": 201}, {"referenceID": 8, "context": "Each set consists of 100 instances generated by independent runs [11].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "According to the observation and discussion in [11], the two features distance max and angle mean can be considered together to provide an accurate classification of the hard and easy instances.", "startOffset": 47, "endOffset": 51}, {"referenceID": 2, "context": "Support vector machines (SVMs) are well-known supervised learning models in machine learning which can be used for classification, regression and outliers detection [3, 8].", "startOffset": 165, "endOffset": 171}, {"referenceID": 5, "context": "Support vector machines (SVMs) are well-known supervised learning models in machine learning which can be used for classification, regression and outliers detection [3, 8].", "startOffset": 165, "endOffset": 171}, {"referenceID": 9, "context": "All classification experiments are done in R with library{e1071} [12].", "startOffset": 65, "endOffset": 69}], "year": 2016, "abstractText": "Understanding the behaviour of heuristic search methods is a challenge. This even holds for simple local search methods such as 2-OPT for the Traveling Salesperson problem. In this paper, we present a general framework that is able to construct a diverse set of instances that are hard or easy for a given search heuristic. Such a diverse set is obtained by using an evolutionary algorithm for constructing hard or easy instances that are diverse with respect to different features of the underlying problem. Examining the constructed instance sets, we show that many combinations of two or three features give a good classification of the TSP instances in terms of whether they are hard to be solved by 2-OPT.", "creator": "LaTeX with hyperref package"}}}