{"id": "1510.08578", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2015", "title": "My Reflections on the First Man vs. Machine No-Limit Texas Hold 'em Competition", "abstract": "The first ever human vs. computer no-limit Texas hold 'em competition took place from April 24-May 8, 2015 at River's Casino in Pittsburgh, PA. In this article I present my thoughts on the competition design, agent architecture, and lessons learned.", "histories": [["v1", "Thu, 29 Oct 2015 06:53:15 GMT  (31kb,D)", "http://arxiv.org/abs/1510.08578v1", null], ["v2", "Sat, 23 Jan 2016 20:41:52 GMT  (31kb,D)", "http://arxiv.org/abs/1510.08578v2", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI cs.MA", "authors": ["sam ganzfried"], "accepted": false, "id": "1510.08578"}, "pdf": {"name": "1510.08578.pdf", "metadata": {"source": "CRF", "title": "My Reflections on the First Man vs. Machine No-Limit Texas Hold \u2019em Competition\u2217", "authors": ["Sam Ganzfried"], "emails": ["sam.ganzfried@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "The first Man vs. Computer no-limit Texas hold'em contest took place from April 24 to May 8, 2015 at River's Casino in Pittsburgh, PA, organized by Carnegie Mellon University professor Tuomas Sandholm. 20,000 hands of two players no-limit Texas hold'em were played between the computer program \"Claudico\" and four of the best human specialists in this variation of poker, Dong Kim, Jason Les, Bjorn Li, and Doug Polk. To evaluate the performance, we used \"duplicate\" chips in which the same hands were played twice with the cards to reduce the role of luck (and thus decrease the variance), giving each person a partner who swapped the identical hands for Claudico with the cards. Polk was paired with Les, and Kim was paired with Li."}, {"heading": "2 Agent Architecture", "text": "In fact, most of them will be able to move to a different world in which they are able to live than in a world in which they are able to live and live."}, {"heading": "2.1 Offline abstraction and equilibrium computation", "text": "Claudico's action abstraction was generated manually and included sizes ranging from 0.1 pot in certain situations to all-in (using all remaining chips).The information abstraction was based on 5There are (up to) four rounds of betting in one hand Texas Hold'em Poker. First, both players are dealt two private cards and there is a first round called preflop. Then three public cards are dealt and there is the flop. Then there is another public card on the turn, followed by a last public card in the river betting round. A hierarchical algorithm that first groups the public flop boards with three cards into public buckets, then groups the private information states for each postflop round (i.e. flop, turn, river) separately for each public bucket (for the preflop round no information abstraction was performed) [3]. This hierarchical abstraction algorithm allowed us to apply a new, scalable version of CFR [distributed]."}, {"heading": "2.2 Action translation", "text": "For action translation mapping, we used pseudo-harmonic mapping, which maps an opponent's bet x on one of the nearest variables in abstraction A, B according to the following formula: f (x) the probability that x will be mapped to A [6]: f (x) = (B \u2212 x) (1 + A) (B \u2212 A) (1 + x). This mapping was derived from analytical solutions of simplified poker games and has proven to be better than previous approaches in terms of usability in simplified games, as well as the best previous approach in terms of empirical performance against unlimited Texas hold'em agents. Mapping also fulfills several axioms and theoretical properties that do not satisfy the best previous mappings, for example, it is continuous in A and B, and thus resistant to small changes in action abstraction."}, {"heading": "2.3 Post-processing", "text": "We used additional post-game techniques to round up the action probabilities calculated by the offline equilibrium finding algorithm [8]. We used a generalization of the previous approach, which used a different rounding threshold for each round of betting (i.e., the action probabilities below the threshold were rounded to zero and then renormalized all the probabilities), applying a more aggressive (i.e. larger) threshold used for the later rounds of betting, since the balance finding algorithm achieved a worse convergence for these rounds because it had fewer samples. We did not apply post-game editing for ourselves on the river when using the final game solver, and assumed that none of the agents used any post-game editing in generating the master strategies used as inputs for the final game solver. 66. It may seem a bit strange that we would have applied the end game to our own endgame, but that the endgame was used for endgame endgame endgame endgame."}, {"heading": "2.4 Endgame solving", "text": "The final play solving algorithm consists of several steps [7]. First, the common hand-strength input distribution is calculated by applying Bayes \"rule to the pre-calculated master strategies, using a recently developed technique that requires only a linear number of lookups in the large strategy table (while the naive approach requires a square number of lookups and is impractical), and then the balance for each hand is calculated, taking these distributions into account. 7 Then, the hands are bundled separately for each player based on the calculated imbalances for the given situation using an information abstraction algorithm. Finally, an exact Nash balance is calculated in the game that corresponds to this information abstraction and an action abstraction precalculated for the specific pot and stack size of the current hand. All this calculation was performed in real time during the game. To calculate balances within the finals, we used Gurosen [15] for soldering."}, {"heading": "3 Problematic Hands", "text": "In fact, it is the case that we are able to find a solution that will enable us to find a solution, that we are able to find a solution, that we are able to find a solution, and that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution."}, {"heading": "4 Conclusion", "text": "This year is the highest in the history of the country."}], "references": [{"title": "The Mathematics of Poker", "author": ["Jerrod Ankenman", "Bill Chen"], "venue": "ConJelCo LLC,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Approximating game-theoretic optimal strategies for full-scale poker", "author": ["Darse Billings", "Neil Burch", "Aaron Davidson", "Robert Holte", "Jonathan Schaeffer", "Terence Schauenberg", "Duane Szafron"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Hierarchical abstraction, distributed equilibrium computation, and post-processing, with application to a champion no-limit Texas Hold\u2019em agent", "author": ["Noam Brown", "Sam Ganzfried", "Tuomas Sandholm"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AA- MAS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Solving imperfect information games using decomposition", "author": ["Neil Burch", "Michael Johanson", "Michael Bowling"], "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Tractable objectives for robust policy optimization", "author": ["Katherine Chen", "Michael Bowling"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Action translation in extensive-form games with large action spaces: Axioms, paradoxes, and the pseudo-harmonic mapping", "author": ["Sam Ganzfried", "Tuomas Sandholm"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Endgame solving in large imperfect-information games", "author": ["Sam Ganzfried", "Tuomas Sandholm"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AA- MAS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Strategy purification and thresholding: Effective non-equilibrium approaches for playing large games", "author": ["Sam Ganzfried", "Tuomas Sandholm", "Kevin Waugh"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "A competitive Texas Hold\u2019em poker player via automated abstraction and real-time equilibrium computation", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Better automated abstraction techniques for imperfect information games, with application to Texas Hold\u2019em poker", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Lossless abstraction of imperfect information games", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "Journal of the ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "A heads-up no-limit Texas Hold\u2019em poker player: Discretized betting models and automatically generated equilibrium-finding programs", "author": ["Andrew Gilpin", "Tuomas Sandholm", "Troels Bjerre S\u00f8rensen"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AA- MAS),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Phil Gordon\u2019s Little Gold Book: Advanced Lessons for Mastering Poker 2.0", "author": ["Phil Gordon"], "venue": "Gallery Books,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Smoothing techniques for computing Nash equilibria of sequential games", "author": ["Samid Hoda", "Andrew Gilpin", "Javier Pe\u00f1a", "Tuomas Sandholm"], "venue": "Mathematics of Operations Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Measuring the size of large no-limit poker games", "author": ["Michael Johanson"], "venue": "Technical report, University of Alberta,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Finding optimal abstract strategies in extensive-form games", "author": ["Michael Johanson", "Nolan Bard", "Neil Burch", "Michael Bowling"], "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Evaluating state-space abstractions in extensive-form games", "author": ["Michael Johanson", "Neil Burch", "Richard Valenzano", "Michael Bowling"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Fast algorithms for finding randomized strategies in game trees", "author": ["Daphne Koller", "Nimrod Megiddo", "Bernhard von Stengel"], "venue": "In Proceedings of the 26th ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "Extensive-form game abstraction with bounds", "author": ["Christian Kroer", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation (EC),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Steering evolution strategically: Computational game theory and opponent exploitation for treatment planning, drug design, and synthetic biology", "author": ["Tuomas Sandholm"], "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Abstraction methods for game theoretic poker", "author": ["Jiefu Shi", "Michael Littman"], "venue": "In CG \u201900: Revised Papers from the Second International Conference on Computers and Games,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "A practical use of imperfect recall", "author": ["Kevin Waugh", "Martin Zinkevich", "Michael Johanson", "Morgan Kan", "David Schnizlein", "Michael Bowling"], "venue": "In Proceedings of the Symposium on Abstraction, Reformulation and Approximation (SARA),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Regret minimization in games with incomplete information", "author": ["Martin Zinkevich", "Michael Bowling", "Michael Johanson", "Carmelo Piccione"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}], "referenceMentions": [{"referenceID": 14, "context": "Thus, the game tree for no-limit has a much larger branching factor and is significantly larger; there are 10165 nodes in the game tree for no-limit, while there are around 1017 nodes for limit [16].", "startOffset": 194, "endOffset": 198}, {"referenceID": 12, "context": "Bottom line: If your hand is worth playing, it is worth raising\u201d [13].", "startOffset": 65, "endOffset": 69}, {"referenceID": 2, "context": "The architecture of that agent has been described in detail in a recent paper [3].", "startOffset": 78, "endOffset": 81}, {"referenceID": 1, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 77, "endOffset": 84}, {"referenceID": 20, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 77, "endOffset": 84}, {"referenceID": 8, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 142, "endOffset": 161}, {"referenceID": 9, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 142, "endOffset": 161}, {"referenceID": 11, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 142, "endOffset": 161}, {"referenceID": 16, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 142, "endOffset": 161}, {"referenceID": 21, "context": "The first abstractions for two-player Texas hold \u2019em were manually generated [2, 22], while current abstractions are computed algorithmically [9, 10, 12, 18, 23].", "startOffset": 142, "endOffset": 161}, {"referenceID": 10, "context": "For smaller games, such as Rhode Island hold \u2019em, abstraction can be performed losslessly, and the abstract game is actually isomorphic to the full game [11].", "startOffset": 153, "endOffset": 157}, {"referenceID": 22, "context": "The second step is to compute an -equilibrium in the smaller abstracted game, using a custom iterative equilibrium-finding algorithm such as counterfactual regret minimization (CFR) [24] or a generalization of Nesterov\u2019s excessive gap technique [14].", "startOffset": 182, "endOffset": 186}, {"referenceID": 13, "context": "The second step is to compute an -equilibrium in the smaller abstracted game, using a custom iterative equilibrium-finding algorithm such as counterfactual regret minimization (CFR) [24] or a generalization of Nesterov\u2019s excessive gap technique [14].", "startOffset": 245, "endOffset": 249}, {"referenceID": 2, "context": "Several procedures have been shown to significantly improve performance that modify the action probabilities of the abstract equilibrium strategies by placing more weight on certain actions [3, 8].", "startOffset": 190, "endOffset": 196}, {"referenceID": 7, "context": "Several procedures have been shown to significantly improve performance that modify the action probabilities of the abstract equilibrium strategies by placing more weight on certain actions [3, 8].", "startOffset": 190, "endOffset": 196}, {"referenceID": 6, "context": "An additional crucial component of Claudico, that was not present in Tartanian7 due to a last-minute technical difficulty (thought a version of it was present in prior agent Tartanian6), is an approach for real-time computation of solutions in the part of the game tree that we have reached to a greater degree of accuracy than in the offline computation, called endgame solving, which is depicted in Figure 2 [7].", "startOffset": 410, "endOffset": 413}, {"referenceID": 6, "context": "Furthermore, endgame solving has been previously demonstrated to improve performance empirically against strong computer programs in no-limit Texas hold \u2019em [7].", "startOffset": 157, "endOffset": 160}, {"referenceID": 2, "context": ", flop, turn, river) separately for each public bucket (no information abstraction was performed for the preflop round) [3].", "startOffset": 120, "endOffset": 123}, {"referenceID": 2, "context": "This hierarchical abstraction algorithm allowed us to apply a new scalable distributed version of CFR [3].", "startOffset": 102, "endOffset": 105}, {"referenceID": 5, "context": "For the action translation mapping, we used the pseudo-harmonic mapping, which maps a bet x of the opponent to one of the nearest sizes in the abstraction A,B according to the following formula, where f(x) the probability that x is mapped to A [6]:", "startOffset": 244, "endOffset": 247}, {"referenceID": 0, "context": "So we pick a random number in [0,1], and if it is above 16 we interpret the bet as 0.", "startOffset": 30, "endOffset": 35}, {"referenceID": 7, "context": "We used additional post-processing techniques to round the action probabilities that had been computed by the offline equilibrium-finding algorithm [8].", "startOffset": 148, "endOffset": 151}, {"referenceID": 6, "context": "The endgame solving algorithm consists of several steps [7].", "startOffset": 56, "endOffset": 59}, {"referenceID": 17, "context": "To compute equilibria within the endgames, we used Gurobi\u2019s parallel linear program solver [15] to solve the sequence-form optimization formulation [19].", "startOffset": 148, "endOffset": 152}, {"referenceID": 0, "context": "aspx As one example, Ankenman and Chen describe a game called the \u201cClairvoyance Game\u201d where player 1 is dealt a winning/losing hand with probability 1 2 each, and is allowed to bet any amount up to initial stack n into a pot of 1; then player 2 can call or fold [1].", "startOffset": 262, "endOffset": 265}, {"referenceID": 5, "context": "This solution holds regardless of the stack size n; so even if n = 1, 000, 000, it would be optimal for player 1 to bet all-in for 1,000,000 to win a pot of 1 (a sketch of Ankenman and Chen\u2019s argument with the computed equilibrium strategies also appears in [6]).", "startOffset": 258, "endOffset": 261}, {"referenceID": 6, "context": "Endgame solving has been proven to have theoretical guarantees in certain games while it can lead to strategies with high exploitability in others (even if the full game has a single Nash equilibrium and just a single endgame is considered) [7].", "startOffset": 241, "endOffset": 244}, {"referenceID": 3, "context": "Recently an approach has been developed for game decomposition that has theoretical guarantees [4], however from personal communication with the authors I have learned that the approach performs worse empirically than our approach that does not have a worst-case guarantee.", "startOffset": 95, "endOffset": 98}, {"referenceID": 10, "context": "One line of work performs lossless abstraction, that guarantees that the abstract game is exactly isomorphic to the original game [11].", "startOffset": 130, "endOffset": 134}, {"referenceID": 18, "context": "Recent work has also presented the first lossy abstraction algorithms with bounds on the solution quality [20].", "startOffset": 106, "endOffset": 110}, {"referenceID": 15, "context": "For medicine, algorithms that were created in the course of research on poker [17] have been applied to compute robust policies for diabetes management [5]; recently it has been proposed that equilibrium-finding algorithms are applicable to the problem of treating diseases such as the HIV virus that can mutate adversarially [21].", "startOffset": 78, "endOffset": 82}, {"referenceID": 4, "context": "For medicine, algorithms that were created in the course of research on poker [17] have been applied to compute robust policies for diabetes management [5]; recently it has been proposed that equilibrium-finding algorithms are applicable to the problem of treating diseases such as the HIV virus that can mutate adversarially [21].", "startOffset": 152, "endOffset": 155}, {"referenceID": 19, "context": "For medicine, algorithms that were created in the course of research on poker [17] have been applied to compute robust policies for diabetes management [5]; recently it has been proposed that equilibrium-finding algorithms are applicable to the problem of treating diseases such as the HIV virus that can mutate adversarially [21].", "startOffset": 326, "endOffset": 330}, {"referenceID": 5, "context": "For the pseudo-harmonic action translation mapping, in addition to showing that it outperforms the best prior approach in terms of exploitability in several games, we have also presented several axioms and theoretical properties that it satisfies; for example, it is Lipschitz continuous in A and B, and therefore robust to small changes in the actions used in the action abstraction [6].", "startOffset": 384, "endOffset": 387}, {"referenceID": 7, "context": ", selecting the highest-probability action with probability 1) leads to an improved performance in uniform random 4\u00d7 4 matrix games using random 3 \u00d7 3 abstractions when playing against the Nash equilibrium of the full 4 \u00d7 4 game for the opponent [8].", "startOffset": 246, "endOffset": 249}, {"referenceID": 7, "context": "Surprisingly, the improvements in empirical performance do not necessarily come at the expense of worst-case exploitability, and a degree of thresholding has been demonstrated to actually reduce exploitability for a limit Texas hold \u2019em agent [8].", "startOffset": 243, "endOffset": 246}], "year": 2017, "abstractText": "The first ever human vs. computer no-limit Texas hold \u2019em competition took place from April 24\u2013 May 8, 2015 at River\u2019s Casino in Pittsburgh, PA. In this article I present my thoughts on the competition design, agent architecture, and lessons learned.", "creator": "TeX"}}}