{"id": "1510.08983", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Oct-2015", "title": "Highway Long Short-Term Memory RNNs for Distant Speech Recognition", "abstract": "In this paper, we extend the deep long short-term memory (DLSTM) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers. These direct links, called highway connections, enable unimpeded information flow across different layers and thus alleviate the gradient vanishing problem when building deeper LSTMs. We further introduce the latency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole history while keeping the latency under control. Efficient algorithms are proposed to train these novel networks using both frame and sequence discriminative criteria. Experiments on the AMI distant speech recognition (DSR) task indicate that we can train deeper LSTMs and achieve better improvement from sequence training with highway LSTMs (HLSTMs). Our novel model obtains $43.9/47.7\\%$ WER on AMI (SDM) dev and eval sets, outperforming all previous works. It beats the strong DNN and DLSTM baselines with $15.7\\%$ and $5.3\\%$ relative improvement respectively.", "histories": [["v1", "Fri, 30 Oct 2015 06:40:14 GMT  (375kb,D)", "https://arxiv.org/abs/1510.08983v1", null], ["v2", "Mon, 11 Jan 2016 09:48:01 GMT  (616kb,D)", "http://arxiv.org/abs/1510.08983v2", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.CL cs.LG", "authors": ["yu zhang", "guoguo chen", "dong yu", "kaisheng yao", "sanjeev khudanpur", "james glass"], "accepted": false, "id": "1510.08983"}, "pdf": {"name": "1510.08983.pdf", "metadata": {"source": "CRF", "title": "HIGHWAY LONG SHORT-TERM MEMORY RNNS FOR DISTANT SPEECH RECOGNITION", "authors": ["Yu Zhang", "Guoguo Chen", "Dong Yu", "Kaisheng Yao", "Sanjeev Khudanpur", "James Glass"], "emails": ["yzhang87@mit.edu,", "glass@mit.edu,", "guoguo@jhu.edu,", "khudanpur@jhu.edu,", "Kaisheng.YAO}@microsoft.com"], "sections": [{"heading": null, "text": "Index Terms - Highway LSTM, CNTK, LSTM, Sequence Training"}, {"heading": "1. INTRODUCTION", "text": "This year, we will be able to put ourselves in a position to take the lead."}, {"heading": "2. RELATED WORK", "text": "All of these works share the same idea of adding gated linear connections between different levels. [16] The road networks proposed in [16] adaptively insert some dimensions of input directly into the output so that information can flow much more easily between levels. However, their formulation differs from ours and their focus is DNN. The work in [17] shares the same idea and model structure. [18] is more general and uses a general form. However, their task is based on text, e.g. machine translation, while our focus is on remote speech recognition. Furthermore, we used suspenders as a way to control the highway connections that prove crucial to DSR.1The tools and scripts used to produce the results reported in this paper are publicly available as part of the CNTK toolkit [15], and anyone who has access to the data should be able to reproduce our results.ar Xiv: 151 0.08 0.032.E [15]"}, {"heading": "3. HIGHWAY LONG SHORT-TERM MEMORY RNNS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Long short-term memory RNNs", "text": "The LSTM-RNN was originally proposed in [19] to solve the problem of decreasing gradients in the RNNs. It introduces a linear dependence between ct, the state of the memory cell at the time t, and ct \u2212 1, the state of the same cell at t \u2212 1. Nonlinear gates are introduced to control the flow of information.The operation of the network follows the equation = \u03c3 (Wxixt + Wmiht \u2212 1 + Wcict \u2212 1 + bi) (1) ft = \u03c3 (Wxoxt + Wmfht \u2212 1 + Wcfct \u2212 1 + bf) (2) ct = ft \u2212 1 + it tanh (Wxcxt + Wmcmt \u2212 1 + bc) (3) ot = \u03c3 (Wxoxt + Wmoht \u2212 1 + Wmfht + bo) (4) mt = ot tanh (ct) (5) iterative (Wxxt + Wmcmt \u2212 1 + bc) (3) \u03c3 + Woct (Wxcoct) \u2212 (Wx1)."}, {"heading": "3.2. Deep LSTM RNNs", "text": "Deep LSTM RNNNs are formed by stacking several layers of LSTM cells. Specifically, the output of the lower layer LSTM cells of the upper layer is fed as input xl + 1t. Although each LSTM layer is deep in time, since it can be unrolled in time to become a feedback neural network in which each layer has the same weights, deep LSTM RNNNNs still significantly outperform single-layer LSTM RNNNNs. It is thought [8] that DLSTM RNNNNNNs can make better use of parameters by distributing them over space over several layers. Note that in conventional DLSTM RNNNNNNs, the interaction between cells in different layers must take place via the output input connection."}, {"heading": "3.3. HLSTM RNNs", "text": "The Highway LSTM (HLSTM) RNN proposed in this paper is shown in Figure 1. It has a direct connection (in the red block) between the memory cells clt in the lower layer l and the memory cells cl + 1t in the upper layer l + 1. The carry gate controls how much information can flow from the cells of the lower layer directly to the cells of the upper layer. Gate function on the layer l + 1 at the time t isd (l + 1) t = \u03c3 (b (l + 1) d + W l + 1 x (l + 1) t + w l + 1 cd c (l + 1) t \u2212 1 + w (l + 1) ld c t t), (6) where b (l + 1) d is a bias term, W (l + 1) xd is the weight matrix matrix connecting layer (l) that connects the carry gate to the input of this layer, Lc + 1 (l)."}, {"heading": "3.4. Bidirectional Highway LSTM RNNs", "text": "The bi-directional RNNs exploit past and future contexts by processing the data in both directions with two separate hidden layers. It is shown in [6, 7, 13] that bi-directional LSTN RNNs can actually improve the results of speech recognition. In this study, we also extend the HLSTM RNNs from unidirectional to bidirectional. Note that the back layer follows the same equations used in the front layer, except that t \u2212 1 is replaced by t + 1 to take advantage of future frames and the model of t = T after 1. The output of the front and back layer is linked to form the input to the next layer."}, {"heading": "4. EFFICIENT NETWORK TRAINING", "text": "For unidirectional RNN models, in order to better utilize the parallelization power of the GPU card in [15], multiple sequences (e.g. 40) are often packed into the same mini-batch. However, when used at the sequence level (BLSTM or sequence training), the limited memory of the GPU limits the number of sequences that can be packed into a mini-batch, especially for LVCSR tasks with long training sequences and large model sizes. An alternative to acceleration is the use of asynchronous SGD based on a GPU / CPU farm [20]. In this section, we focus more on the full utilization of the PU power algorithms proposed here."}, {"heading": "4.1. Latency-controlled bi-directional model training", "text": "This year, more than ever before in the history of a country in which it is a country in which it is not a country, but a country in which it is a country, a country in which it is a country, a country, a country, a country, a country, a country, a country, a city, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country"}, {"heading": "5. EXPERIMENT SETUP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Corpus", "text": "The AMI corpus includes approximately 100 hours of recordings of meetings recorded in instrumented meeting rooms. Multiple microphones have been used, including custom headset microphones (IHM), lapel microphones, and one or more microphone arrays. In this work, we use the condition of a single remote microphone (SDM) for our experiments. Our systems are trained and tested using the split recommended in the corpus release: an 80-hour training kit, a development kit, and a 9-hour test kit. For our training, we use all segments provided by the corpus, including those with overlapping language. Our models are evaluated solely on the basis of the assessment set."}, {"heading": "5.2. System description", "text": "A maximum probability acoustic training recipe is used to train a GMM-HMM triphone system.Forced alignment is performed on the training data of this three-layer DNN to provide labels for further neural network training.The Computational Network Toolkit (CNTK) [15] is used for neural network training.We start with the formation of a 6-layer DNN, with 2, 048 sigmoid units per layer.40-dimensional filter bank functions, along with their corresponding delta and delta delta characteristics are used as raw function vectors.We link 15 frames of raw function vectors, which leads to a dimension of 1, 800. This DNN in turn is used to align the training data to generate labels for further LSTM training.Our (H) LSTM models, unless explicitly stated, we are formed a layer of 10 layers."}, {"heading": "6. RESULTS", "text": "All experiments are performed with AMI SDM1 eval set unless otherwise stated. As we do not exclude the overlapping language segments during the model training, in addition to the results on the complete eval set, we also show results on a subset containing only the non-overlapping language segments as [14]."}, {"heading": "6.1. 3-layer Highway (B)LSTMP", "text": "Table 1 shows the WER performance of the three-layer LSTMP and BLSTMP RNNNs as well as their highway versions. By way of comparison, the performance of the DNN network is also listed. The table shows that the highway version of the LSTM RNNNs consistently performs better than their non-highway counterparts, albeit by a small margin."}, {"heading": "6.2. Highway (B)LSTMP with dropout", "text": "In our experiments, we use a low failure rate of 0.1 for early training phases and increase it to 0.8 after 5 training phases. The performance of Highway (B) LSTMP networks with dropouts is shown in Table 2 as we see that dropouts help to further reduce the WER for motorway networks. If a network goes deeper, training is usually difficult. Table 3 compares the performance of flat and deep networks. The table shows that for a normal LSTMP network, when it goes from 3 to 8 layers, detection performance drops drastically. However, for the motorway network, the WER increases only slightly. The table suggests that the motorway connection between LSTM layers goes much deeper into the network than the normal LSTM layers."}, {"heading": "6.4. Highway LSTMP with sequence training", "text": "The table suggests that the introduction of the motorway link between the LSTMP layers is beneficial for sequence discrimination training. For example, sequence training on the 3-layer LSTMP network without the motorway link brings the WER from 50.7 to 49.3, a relative improvement of only 3% for this particular task. After the introduction of the motorway link and dropout, the improvement is relative from 50.4 to 47.5%. The relative improvement is even greater for the subset of the non-overlapping segment, which is about 7%. Results suggest that sequence training is beneficial both from the motorway link and from a deeper structure."}, {"heading": "7. CONCLUSION", "text": "We presented a novel LSTM network and applied it to a remote speech recognition task. Experimental results indicate that this type of network consistently outperforms the normal (B) LSTMP networks, especially when it comes to controlling access to the highway. Further experiments also suggest that the highway link allows the network to go much deeper, and derives greater benefits from sequence discrimination. [1] G. E. Dahl, D. Yu, L. Deng, and A. Acero, enable in-depth neural networks for large vocabulary speech. \"IEEE-Transactions on Audio, Speech and Language Processing, vol. 20, Nr. 1, pp. 30-42, 2012. F. Seide, G. Li, and D. Yu,\" Conversational Speech transcription using context-dependent neural networks. \""}], "references": [{"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["G.E. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "IEEE Transactions on Audio, Speech and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Conversational speech transcription using context-dependent deep neural networks", "author": ["F. Seide", "G. Li", "D. Yu"], "venue": "Proc. Annual Conference of International Speech Communication Association (INTERSPEECH), 2011, pp. 437\u2013440.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["G. Hinton", "L. Deng", "D. Yu", "G. Dahl", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath", "B. Kingsbury"], "venue": "IEEE Signal Processing Magazine, no. 6, pp. 82\u201397, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "An investigation of deep neural networks for noise robust speech recognition", "author": ["M. Seltzer", "D. Yu", "Y.Q. Wang"], "venue": "Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Convolutional neural networks for distant speech recognition", "author": ["P. Swietojanski", "A. Ghoshal", "S. Renals"], "venue": "Signal Processing Letters, IEEE, vol. 21, no. 9, pp. 1120\u20131124, September 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G. Hinton"], "venue": "Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Hybrid speech recognition with deep bidirectional LSTM", "author": ["A. Graves", "N. Jaitly", "A. Mohamed"], "venue": "Proc. IEEE Workshop on Automfatic Speech Recognition and Understanding (ASRU), 2013, pp. 273\u2013278.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "Fifteenth Annual Conference of the International Speech Communication Association, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Hybrid acoustic models for distant and multichannel large vocabulary speech recognition", "author": ["P. Swietojanski", "A. Ghoshal", "S. Renals"], "venue": "ASRU, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Microphone array processing for distant speech recognition: From closetalking microphones to far-field sensors.", "author": ["K. Kumatani", "J.W. McDonough", "B. Raj"], "venue": "IEEE Signal Process. Mag., vol. 29,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Transcribing meetings with the amida systems.", "author": ["T. Hain", "L. Burget", "J. Dines", "P.N. Garner", "F. Grzl", "A.E. Hannani", "M. Huijbregts", "M. Karafit", "M. Lincoln", "V. Wan"], "venue": "IEEE Transactions on Audio, Speech & Language Processing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Making the most from multiple microphones in meeting recognition", "author": ["A. Stolcke"], "venue": "ICASSP, 2011.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Training deep bidirectional lstm acoustic model for lvcsr by a context-sensitive-chunk bptt approach", "author": ["K. Chen", "Z.-J. Yan", "Q. Huo"], "venue": "Interspeech, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Convolutional neural networks for distant speech recognition", "author": ["P. Swietojanski", "A. Ghoshal", "S. Renals"], "venue": "IEEE Singal Processing Letters, vol. 21, no. 9, pp. 1120\u20131124, 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "An introduction to computational networks and the computational network toolkit", "author": ["D. Yu", "A. Eversole", "M. Seltzer", "K. Yao", "B. Guenter", "O. Kuchaiev", "Y. Zhang", "F. Seide", "G. Chen", "H. Wang", "J. Droppo", "A. Agarwal", "C. Basoglu", "M. Padmilac", "A. Kamenev", "V. Ivanov", "S. Cyphers", "H. Parthasarathi", "B. Mitra", "Z. Huang", "G. Zweig", "C. Rossbach", "J. Currey", "J. Gao", "A. May", "B. Peng", "A. Stolcke", "M. Slaney", "X. Huang"], "venue": "Microsoft Technical Report, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Highway networks", "author": ["R. Srivastava", "K. Greff", "J. Schmidhuber"], "venue": "2015. [Online]. Available: http://arxiv.org/abs/ 1505.00387", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Depth-gated lstm", "author": ["K. Yao", "T. Cohn", "K. Vylomova", "K. Duh", "C. Dyer"], "venue": "2015. [Online]. Available: http://arxiv. org/abs/1508.03790", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Grid long short-term memory", "author": ["N. Kalchbrenner", "I. Danihelka", "A. Graves"], "venue": "2015. [Online]. Available: http: //arXiv.org/abs/1507.01526", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation, vol. 9, no. 8, p. 17351438, 1997.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1997}, {"title": "Asynchronous stochastic optimization for sequence training of deep neural networks", "author": ["G. Heigold", "E. McDermott", "V. Vanhoucke", "A. Senior", "M. Bacchiani"], "venue": "ICASSP, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "unleashing the killer corpus: experiences in creating the multi-everything ami meeting corpus", "author": ["J. Carletta"], "venue": "Language Resources & Evaluation Journal, vol. 41, no. 2, pp. 181\u2013190, 2007.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Multiple dimension levenshtein edit distance calculations for evaluating asr systems during simultaneous speech", "author": ["J. Fiscus", "J. Ajot", "N. Radde", "C. Laprun"], "venue": "LREC, 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "The Kaldi speech recognition toolkit", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motl\u0131\u0301\u010dek", "Y. Qian", "P. Schwarz", "J. Silovsk\u00fd", "G. Stemmer", "K. Vesel\u00fd"], "venue": "ASRU, 2011.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Feature engineering in context-dependent deep neural networks for conversational speech transcription", "author": ["F. Seide", "G. Li", "X. Chen", "D. Yu"], "venue": "Proc. IEEE Workshop on Automfatic Speech Recognition and Understanding (ASRU), 2011, pp. 24\u2013 29.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "An efficient gradient-based algorithm for online training of recurrent network trajectories", "author": ["R. Williams", "J. Peng"], "venue": "Neural Computation, vol. 2, p. 490501, 1990.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1990}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "2012. [Online]. Available: http://arxiv.org/abs/1207.0580", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Recently the deep neural network (DNN)-based acoustic models (AMs) greatly improved automatic speech recognition (ASR) accuracy on many tasks [1, 2, 3, 4].", "startOffset": 142, "endOffset": 154}, {"referenceID": 1, "context": "Recently the deep neural network (DNN)-based acoustic models (AMs) greatly improved automatic speech recognition (ASR) accuracy on many tasks [1, 2, 3, 4].", "startOffset": 142, "endOffset": 154}, {"referenceID": 2, "context": "Recently the deep neural network (DNN)-based acoustic models (AMs) greatly improved automatic speech recognition (ASR) accuracy on many tasks [1, 2, 3, 4].", "startOffset": 142, "endOffset": 154}, {"referenceID": 3, "context": "Recently the deep neural network (DNN)-based acoustic models (AMs) greatly improved automatic speech recognition (ASR) accuracy on many tasks [1, 2, 3, 4].", "startOffset": 142, "endOffset": 154}, {"referenceID": 4, "context": "Further improvements were reported by using more advanced models such as convolutional neural networks (CNNs) [5] and long short-term memory (LSTM) recurrent neural networks (RNNs) [6, 7, 8].", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "Further improvements were reported by using more advanced models such as convolutional neural networks (CNNs) [5] and long short-term memory (LSTM) recurrent neural networks (RNNs) [6, 7, 8].", "startOffset": 181, "endOffset": 190}, {"referenceID": 6, "context": "Further improvements were reported by using more advanced models such as convolutional neural networks (CNNs) [5] and long short-term memory (LSTM) recurrent neural networks (RNNs) [6, 7, 8].", "startOffset": 181, "endOffset": 190}, {"referenceID": 7, "context": "Further improvements were reported by using more advanced models such as convolutional neural networks (CNNs) [5] and long short-term memory (LSTM) recurrent neural networks (RNNs) [6, 7, 8].", "startOffset": 181, "endOffset": 190}, {"referenceID": 8, "context": "Although these new techniques help to decrease the word error rate (WER) on distant speech recognition (DSR) [9], DSR remains a challenging task due to the reverberation and overlapping acoustic signals, even with sophisticated front-end processing techniques [10, 11, 12] and multi-pass decoding schemes.", "startOffset": 109, "endOffset": 112}, {"referenceID": 9, "context": "Although these new techniques help to decrease the word error rate (WER) on distant speech recognition (DSR) [9], DSR remains a challenging task due to the reverberation and overlapping acoustic signals, even with sophisticated front-end processing techniques [10, 11, 12] and multi-pass decoding schemes.", "startOffset": 260, "endOffset": 272}, {"referenceID": 10, "context": "Although these new techniques help to decrease the word error rate (WER) on distant speech recognition (DSR) [9], DSR remains a challenging task due to the reverberation and overlapping acoustic signals, even with sophisticated front-end processing techniques [10, 11, 12] and multi-pass decoding schemes.", "startOffset": 260, "endOffset": 272}, {"referenceID": 11, "context": "Although these new techniques help to decrease the word error rate (WER) on distant speech recognition (DSR) [9], DSR remains a challenging task due to the reverberation and overlapping acoustic signals, even with sophisticated front-end processing techniques [10, 11, 12] and multi-pass decoding schemes.", "startOffset": 260, "endOffset": 272}, {"referenceID": 7, "context": "It is reported [8] that deep LSTM (DLSTM) RNNs help improve generalization and often outperform single-layer LSTM RNNs.", "startOffset": 15, "endOffset": 18}, {"referenceID": 12, "context": "It also trains and decodes faster than context-sensitive-chunk BLSTMs [13] which can only access limited past and future context.", "startOffset": 70, "endOffset": 74}, {"referenceID": 13, "context": "4% over CNNs [14], and 5.", "startOffset": 13, "endOffset": 17}, {"referenceID": 15, "context": "After developing the highway LSTMs independently we noticed that similar work has been done in [16, 17, 18].", "startOffset": 95, "endOffset": 107}, {"referenceID": 16, "context": "After developing the highway LSTMs independently we noticed that similar work has been done in [16, 17, 18].", "startOffset": 95, "endOffset": 107}, {"referenceID": 17, "context": "After developing the highway LSTMs independently we noticed that similar work has been done in [16, 17, 18].", "startOffset": 95, "endOffset": 107}, {"referenceID": 15, "context": "The highway networks proposed in [16] adaptively carry some dimensions of the input directly to the output so that information can flow across layers much more easily.", "startOffset": 33, "endOffset": 37}, {"referenceID": 16, "context": "The work in [17] share the same idea and model structure.", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "[18] is more general and uses a generic form.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "1The tools and scripts used to produce the results reported in this paper are publicly available as part of the CNTK toolkit[15], and anyone with access to the data should be able to reproduce our results.", "startOffset": 124, "endOffset": 128}, {"referenceID": 18, "context": "The LSTM RNN was initially proposed in [19] to solve the gradient diminishing problem in RNNs.", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "It is conjectured [8] that DLSTM RNNs can make better use of parameters by distributing them over the space through multiple layers.", "startOffset": 18, "endOffset": 21}, {"referenceID": 5, "context": "It is shown in [6, 7, 13] that bidirectional LSTN RNNs can indeed improve the speech recognition results.", "startOffset": 15, "endOffset": 25}, {"referenceID": 6, "context": "It is shown in [6, 7, 13] that bidirectional LSTN RNNs can indeed improve the speech recognition results.", "startOffset": 15, "endOffset": 25}, {"referenceID": 12, "context": "It is shown in [6, 7, 13] that bidirectional LSTN RNNs can indeed improve the speech recognition results.", "startOffset": 15, "endOffset": 25}, {"referenceID": 14, "context": "For unidirectional RNN models, to better utilize the parallelization power of the GPU card, in [15], multiple sequences (e.", "startOffset": 95, "endOffset": 99}, {"referenceID": 19, "context": "One alternative way to speed up is using asynchronous SGD based on a GPU/CPU farm [20].", "startOffset": 82, "endOffset": 86}, {"referenceID": 12, "context": "To speed up the training of bi-direcctional RNNs, the Contextsensitive-chunk BPTT (CSC-BPTT) is proposed in [13].", "startOffset": 108, "endOffset": 112}, {"referenceID": 20, "context": "We evaluated our models on the AMI meeting corpus [21].", "startOffset": 50, "endOffset": 54}, {"referenceID": 21, "context": "NIST\u2019s asclite tool [22] is used for scoring.", "startOffset": 20, "endOffset": 24}, {"referenceID": 22, "context": "Kaldi [23] is used for feature extraction, early stage triphone training as well as decoding.", "startOffset": 6, "endOffset": 10}, {"referenceID": 14, "context": "The Computational Network Toolkit (CNTK) [15] is used for neural network training.", "startOffset": 41, "endOffset": 45}, {"referenceID": 7, "context": "Our (H)LSTM models, unless explicitly stated otherwise, are added with a projection layer on top of each layer\u2019s output, as proposed in [8], and are trained with 80-dimensional log Mel filterbank (FBANK) features.", "startOffset": 136, "endOffset": 139}, {"referenceID": 23, "context": "All models are randomly initialized without either generative or discriminative pretraining [24].", "startOffset": 92, "endOffset": 96}, {"referenceID": 24, "context": "To train the unidirectional model, the truncated back-propagationthrough-time (BPTT) [25] is used to update the model parameters.", "startOffset": 85, "endOffset": 89}, {"referenceID": 25, "context": "For frame level cross-entropy training, L2 constraint regularization [26] is used.", "startOffset": 69, "endOffset": 73}, {"referenceID": 13, "context": "Since we do not exclude the overlapping speech segments during model training, in addition to results on the full eval set, we also show results on a subset that only contains the non-overlapping speech segments as [14].", "startOffset": 215, "endOffset": 219}], "year": 2016, "abstractText": "In this paper, we extend the deep long short-term memory (DLSTM) recurrent neural networks by introducing gated direct connections between memory cells in adjacent layers. These direct links, called highway connections, enable unimpeded information flow across different layers and thus alleviate the gradient vanishing problem when building deeper LSTMs. We further introduce the latency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole history while keeping the latency under control. Efficient algorithms are proposed to train these novel networks using both frame and sequence discriminative criteria. Experiments on the AMI distant speech recognition (DSR) task indicate that we can train deeper LSTMs and achieve better improvement from sequence training with highway LSTMs (HLSTMs). Our novel model obtains 43.9/47.7% WER on AMI (SDM) dev and eval sets, outperforming all previous works. It beats the strong DNN and DLSTM baselines with 15.7% and 5.3% relative improvement respectively.", "creator": "LaTeX with hyperref package"}}}