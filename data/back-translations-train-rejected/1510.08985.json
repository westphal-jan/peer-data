{"id": "1510.08985", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Oct-2015", "title": "Prediction-Adaptation-Correction Recurrent Neural Networks for Low-Resource Language Speech Recognition", "abstract": "In this paper, we investigate the use of prediction-adaptation-correction recurrent neural networks (PAC-RNNs) for low-resource speech recognition. A PAC-RNN is comprised of a pair of neural networks in which a {\\it correction} network uses auxiliary information given by a {\\it prediction} network to help estimate the state probability. The information from the correction network is also used by the prediction network in a recurrent loop. Our model outperforms other state-of-the-art neural networks (DNNs, LSTMs) on IARPA-Babel tasks. Moreover, transfer learning from a language that is similar to the target language can help improve performance further.", "histories": [["v1", "Fri, 30 Oct 2015 06:42:03 GMT  (493kb,D)", "http://arxiv.org/abs/1510.08985v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["yu zhang", "ekapol chuangsuwanich", "james glass", "dong yu"], "accepted": false, "id": "1510.08985"}, "pdf": {"name": "1510.08985.pdf", "metadata": {"source": "CRF", "title": "PREDICTION-ADAPTATION-CORRECTION RECURRENT NEURAL NETWORKS FOR LOW-RESOURCE LANGUAGE SPEECH RECOGNITION", "authors": ["Yu Zhang", "Ekapol Chuangsuwanich", "James Glass", "Dong Yu"], "emails": ["glass}@mit.edu", "dongyu@microsoft.com"], "sections": [{"heading": null, "text": "Index terms - DNN, LSTM, PAC-RNN, Multilingual1, where we already incorporate information. INTRODUCTIONThe behavior of prediction, adaptation and correction is widely observed in human speech recognition [1]. For example, listeners can guess what you will say next and wait to confirm their guess. They can adjust their hearing efforts by predicting the speech rate and sound state based on current information, or predict and adapt a letter based on the talker's pronunciation. They try to emulate some of these mechanisms by using two DNNs; a DNN prediction that predicts the next phoneme, and a DNN correction that estimates the current state probability based on the current situation, and the hypothesis from the DNN prediction. The model showed promising results on TIMIT, but it was unclear whether a similar gain could be achieved on larger tasks where we could already include the information."}, {"heading": "2.1. Model structure and training", "text": "The PAC-RNN used in this thesis follows our previous work in [2]. Fig. 1 illustrates the structure of the PAC-RNN studied in this thesis. The main components of the model are a correction DNN and a prediction DNN. The correction DNN estimates the state posterior probability pcorr (st | ot, xt) given ot, the observational feature correction vector and xt, the information from the prediction DNN, at the time. The prediction DNN prognostictsar Xiv: 151 0.08 985v 1 [cs.C] 30 Oct 201 5future target information. Note that since yt, the information from the correction DNN \u2212 the information from the prediction DNN, and vice versa, is formed a recursive loop. The information from the prediction DNN, xt, xt, is from a bottleneck hidden layer output value hpredt 1. To predict more, we can hide T. = layer values"}, {"heading": "2.2. PAC-RNN-LSTM", "text": "To further improve the PAC-RNN model, we use an LSTM to replace the DNN used in the correction model. Input of this LSTM is the acoustic characteristic that is not associated with the information from the prediction model xt. The prediction model can also be an LSTM, but we have not observed any increase in performance in the experiments. To keep it simple, we use the same DNN prediction model as [2].3."}, {"heading": "3.1. Stacked bottleneck (SBN) features", "text": "The BN characteristics used in this thesis follow on from our previous work in [13]. An SBN is a hierarchical architecture that is realized as a concatenation of two DNNs, each with its own bottleneck layer. As input characteristics for the second DNN, the outputs from the BN layer in the first DNN are used, whose outputs on the BN layer are then used as final characteristics for the standard GMM-HMM training."}, {"heading": "3.2. Bottleneck-CMLLR features in a hybrid system", "text": "In this paper, we take a similar approach by replacing the DNN with recurring architectures (LSTM or PAC-RNN), taking the BN-CMLR features from a multilingual trained network and adapting them to the target language. For the DNN and the PAC-RNN, these features were stacked in the context of 31 (\u00b1 15) frames and multiplied by a factor of 5. Subsequently [5] no context extension is used for the LSTM. The output state label is also delayed by 5 in order to use the information from the future."}, {"heading": "3.3. Multilingual training and adaptation of SBN features", "text": "The multilingual training of the SBN follows [14], in which all DNN targets of each language are merged, each with its own Softmax layer. Adaptation of the multilingual SBN to a target language can be done by additional fine-tuning steps on each DNN, using the data from the target language sequentially. Our previous work [7] shows that using only the language closest to the target language from the pool of source languages to train the second DNN can serve as a better initialization model than the multilingual second DNN. The closest language can be identified solely from the acoustic data, by training a Language Identification (LID) system. A flow chart showing how to train an LID-based multilingual system shows Fig. 2. We start by matching the first DNN with data from the target language. Instead of using the second multilingual DNN for initialization, we train the second DNN on the nearest data and output targets."}, {"heading": "3.4. Multilingual training of BN-hybrid system", "text": "The input of the hybrid system (DNN, LSTM or PAC-RNN) is the same as that of the second DNN in the SBN system. During the customization phase, the Softmax is replaced by the target language state labels (phone labels for the PAC-RNN prediction model) with random initialization, while the hidden layers are initialized from the DNN, LSTM or PAC-RNN, which is trained in the next language.4. EXPERIENCE"}, {"heading": "4.1. IARPA-Babel corpus", "text": "The IARPA-Babel program focuses on the recognition of ASR and spoken terms in languages with limited resources. [15] The goal of the program is to reduce the time required to develop ASR and spoken terms in a new language. The data from the Babel program consists of language collections from a growing list of languages. The project is in its fourth year. For this work, we are looking at the overall package (60-80 hours of training data) of the 11 languages that were published as source languages in the first two years, while languages in the third year will be the target languages [16]. Some languages also contain a mixture of microphone data recorded in both train and test expressions at 48 kHz. To this end, we have reduced all broadband data to 8 kHz and treated them in the same way as the other recordings. For the target languages, we are focusing on the Very Limited Language Pack (VLLLP), which includes only 3 hours of transcribed training data."}, {"heading": "4.2. Recognition system", "text": "In fact, it is so that it will be able to eren.ndU nI \"s tis rf\u00fc the nlrf\u00fc the nlrf\u00fc eerwdneei eerwdne\u00fcGn nI\" s tis rf\u00fc the nlrf\u00fc, \"tasg tlrf\u00fc ide nlrf\u00fc eaJng0eaeaeaJng0eaeaJng0eaeaJrh-eaJng0e1e1h0e1h0ea0-0-1-0-0-0-0-0-0-0-0-0-0-0-1-1-1-1-0-1-0-1-0-1-0-0-1-0-0-1-1-0-0-1-0-0-1-0-1-0-0-1-0-1-0-1-0-1-0-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-0-1-0-1-0-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-1-0-0-1-1-0-0-1-1-0-1-0-1-0-1-0-1-0-1-0-1-1-0-0-1-1-0-1-0-0-1-1-1-0-0-0-0-0-1-0-1-1-0-1-0-0-0-1-0-1-0-0-0-0-1-1-1-0-1-1-0-1-0-0-0-0-1-0-1-0-1-0-1-0-0-1-1-0-0-0-1-0-0-1-0-0-0-1-1-0-0-1-1-1-0-"}, {"heading": "4.3. PAC-RNN results with BN features", "text": "The first three lines are the results from SBN systems. Both the multilingual and the closest language systems are adapted to the target language for the entire stacked network. In hybrid systems, the BN features extracted from the first DNN of the adapted multilingual SBN are the input. The DNN hybrid system outperforms the multilingual SBN, but is very similar to the closest language system. LSTM improves the DNN by about 1%. PACRNN DNN outperforms LSTM by another percent across all languages. By simply replacing the correction model with a single-layer LSTM, we can see further improvements."}, {"heading": "4.4. Effect of transfer learning on recurrent architectures", "text": "In this subsection, we examine the impact of multilingual transfer learning for each model. We first use the language closest to the target language (based on the LID prediction shown in the table) to train DNN, LSTM and PAC-RNN models and then adapt them to the target language. The lower part of Table 1 summarizes the ASR results. As shown, the LSTM models perform significantly better than the basic SBN system. Using the PAC-RNN model results in a noticeable improvement over the LSTM. Likewise, the PAC-RNN-LSTM can further improve the results."}, {"heading": "Acknowledgements", "text": "The authors would like to thank everyone in the Babelon team for feedback and support for various resources using the following language packs: Cantonese (IARPA-babel101-v0.4c), Turkish (IARPA-babel105b-v0.4), Pashto (IARPA-babel104b-v0.4aY), Tagalog (IARPA-babel101-v0.2g) and Vietnamese (IARPA-babel107bv0.7), Assamese (IARPA-babel103b-v0.3), Lao (IARPA-babel203b-v0.3), Laos (2014), Bengali (IARPA-babel102b-v0.4), Zulu (IARPA-babel206bv0.1e), Tamil (IARPA-babel204b-v1.1b)."}], "references": [{"title": "A neural model of speech production and its application to studies of the role of auditory feedback in speech", "author": ["F. Guenther", "J. Perkell"], "venue": "Speech Motor Control in Normal and Disordered Speech, 2004.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Speech recognition with prediction-adaptation-correction recurrent neural networks", "author": ["Y. Zhang", "D. Yu", "M. Seltzer", "J. Droppo"], "venue": "Proc. ICASSP, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G. Hinton"], "venue": "Proc. ICASSP, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Hybrid speech recognition with deep bidirectional LSTM", "author": ["A. Graves", "N. Jaitly", "A. Mohamed"], "venue": "Proc. ASRU, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory recurrent neural network architectures for large scale acoustic modeling", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "Fifteenth Annual Conference of the International Speech Communication Association, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Data augmentation, feature combination, and multilingual neural networks to improve ASR and KWS performance for low-resource languages", "author": ["Z. T\u00fcske", "P. Golik", "D. Nolden", "R. Schl\u00fcter", "H. Ney"], "venue": "Proc. Inter- Speech, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Language ID-based training of multilingual stacked bottleneck features", "author": ["E. Chuangsuwanich", "Y. Zhang", "J. Glass"], "venue": "Proc. InterSpeech, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptation of multilingual stacked bottle-neck neural network structure for new languages", "author": ["F. Gr\u00e9zl", "M. Karafi\u00e1t", "K. Vesel\u00fd"], "venue": "Proc. ICASSP, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed learning of multilingual DNN feature extractors using GPUs", "author": ["Y. Miao", "H. Zhang", "F. Metze"], "venue": "Proc. InterSpeech, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Crosslanguage knowledge transfer using multilingual deep neural network with shared hidden layers", "author": ["J. Huang", "J. Li", "D. Yu", "L. Deng", "Y. Gong"], "venue": "Proc. ICASSP, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-lingual speech recognition with low-rank multi-task deep neural networks", "author": ["A. Mohan", "R. Rose"], "venue": "Proc. ICASSP, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "BUT ASR system for BABEL surprise evaluation 2014", "author": ["M. Karafi\u00e1t", "K. Vesel\u00fd", "I. Sz\u0151ke", "L. Burget", "F. Gr\u00e9zl", "M. Hannemann", "J. \u010cernock\u00fd"], "venue": "Proc. SLT, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Extracting deep neural network bottleneck features using low-rank matrix factorization", "author": ["Y. Zhang", "E. Chuangsuwanich", "J. Glass"], "venue": "Proc. ICASSP, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Study of probabilistic and bottle-neck features in multilingual environment", "author": ["F. Gr\u00e9zl", "M. Karafi\u00e1t", "M. Janda"], "venue": "Proc. ASRU, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Multilingual data selection for training stacked bottleneck features", "author": ["E. Chuangsuwanich", "Y. Zhang", "J. Glass"], "venue": "Proc. ICASSP, 2016, p. submitted.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Developing STT and KWS systems using limited language resources", "author": ["V. Le", "L. Lamel", "A. Messaoudi", "W. Hartmann", "J. Gauvain", "C. Woehrling", "J. Despres", "A. Roy"], "venue": "Proc. InterSpeech, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Unicode-based graphemic systems for limited resources languages", "author": ["M.Gales", "K.Knill", "A.Ragni"], "venue": "Proc. ICASSP, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Hypothesis spaces for minimum bayes risk training in large vocabulary speech recognition", "author": ["M. Gibson", "T. Hain"], "venue": "Proc. InterSpeech, 2006.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Enhancing low resource keyword spotting with automatically retrieved web documents", "author": ["L. Zhang", "D. Karakos", "W. Hartmann", "R. Hsiao", "R. Schwartz", "S. Tsakalidis"], "venue": "Proc. InterSpeech, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "An introduction to computational networks and the computational network toolkit", "author": ["D. Yu", "A. Eversole", "M. Seltzer", "K. Yao", "B. Guenter", "O. Kuchaiev", "F. Seide", "H. Wang", "J. Droppo", "Z. Huang", "Y. Zhang", "G. Zweig", "C. Rossbach", "J. Currey", "J. Gao", "A. May", "A. Stolcke", "M. Slaney"], "venue": "Tech. Rep. MSR, Microsoft Research, 2014, http://cntk.codeplex.com.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "An efficient gradient-based algorithm for online training of recurrent network trajectories", "author": ["R. Williams", "J. Peng"], "venue": "Neural Computation, vol. 2, pp. 490\u2013501, 1990.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1990}, {"title": "The Kaldi speech recognition toolkit", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motl\u0131\u0301\u010dek", "Y. Qian", "P. Schwarz", "J. Silovsk\u00fd", "G. Stemmer", "K. Vesel\u00fd"], "venue": "Proc. ASRU, 2011.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "The behavior of prediction, adaptation, and correction is widely observed in human speech recognition [1].", "startOffset": 102, "endOffset": 105}, {"referenceID": 1, "context": "Previously [2], we proposed the prediction-adaptationcorrection RNN (PAC-RNN) which tries to emulate some of these mechanisms by using two DNNs; a prediction DNN that predicts the next phoneme, and a correction DNN that estimates the current state probability based on both the current frame and the hypothesis from the prediction DNN.", "startOffset": 11, "endOffset": 14}, {"referenceID": 2, "context": "Recurrent networks such as LSTMs [3, 4] are known to require a large amount of training data in order to perform well [5].", "startOffset": 33, "endOffset": 39}, {"referenceID": 3, "context": "Recurrent networks such as LSTMs [3, 4] are known to require a large amount of training data in order to perform well [5].", "startOffset": 33, "endOffset": 39}, {"referenceID": 4, "context": "Recurrent networks such as LSTMs [3, 4] are known to require a large amount of training data in order to perform well [5].", "startOffset": 118, "endOffset": 121}, {"referenceID": 5, "context": "This approach has been used for robust feature extraction via bottleneck (BN) features [6, 7, 8, 9], or for classifiers in hybrid DNN-HMM approaches [10, 11].", "startOffset": 87, "endOffset": 99}, {"referenceID": 6, "context": "This approach has been used for robust feature extraction via bottleneck (BN) features [6, 7, 8, 9], or for classifiers in hybrid DNN-HMM approaches [10, 11].", "startOffset": 87, "endOffset": 99}, {"referenceID": 7, "context": "This approach has been used for robust feature extraction via bottleneck (BN) features [6, 7, 8, 9], or for classifiers in hybrid DNN-HMM approaches [10, 11].", "startOffset": 87, "endOffset": 99}, {"referenceID": 8, "context": "This approach has been used for robust feature extraction via bottleneck (BN) features [6, 7, 8, 9], or for classifiers in hybrid DNN-HMM approaches [10, 11].", "startOffset": 87, "endOffset": 99}, {"referenceID": 9, "context": "This approach has been used for robust feature extraction via bottleneck (BN) features [6, 7, 8, 9], or for classifiers in hybrid DNN-HMM approaches [10, 11].", "startOffset": 149, "endOffset": 157}, {"referenceID": 10, "context": "This approach has been used for robust feature extraction via bottleneck (BN) features [6, 7, 8, 9], or for classifiers in hybrid DNN-HMM approaches [10, 11].", "startOffset": 149, "endOffset": 157}, {"referenceID": 11, "context": "In [12], Karafi\u00e1t et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "The work presented here is an extension of [2] based on our multilingual framework in [7].", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "The work presented here is an extension of [2] based on our multilingual framework in [7].", "startOffset": 86, "endOffset": 89}, {"referenceID": 1, "context": "The PAC-RNN used in this work follows our previous work in [2].", "startOffset": 59, "endOffset": 62}, {"referenceID": 1, "context": "For the prediction DNN, we follow [2], and use the phoneme label for the prediction targets.", "startOffset": 34, "endOffset": 37}, {"referenceID": 2, "context": "LSTMs have improved speech recognition accuracy on many tasks over DNNs [3, 4, 5].", "startOffset": 72, "endOffset": 81}, {"referenceID": 3, "context": "LSTMs have improved speech recognition accuracy on many tasks over DNNs [3, 4, 5].", "startOffset": 72, "endOffset": 81}, {"referenceID": 4, "context": "LSTMs have improved speech recognition accuracy on many tasks over DNNs [3, 4, 5].", "startOffset": 72, "endOffset": 81}, {"referenceID": 1, "context": "To keep it simple, we use the same DNN prediction model as [2].", "startOffset": 59, "endOffset": 62}, {"referenceID": 12, "context": "The BN features used in this work follow our previous work in [13].", "startOffset": 62, "endOffset": 66}, {"referenceID": 11, "context": "In [12], the authors proposed a DNN hybrid system that used the first stage BN features with speaker adaptation (BNCMLLR).", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "Following [5], no context expansion is used for the LSTM.", "startOffset": 10, "endOffset": 13}, {"referenceID": 13, "context": "The multilingual training of the SBN follows [14] where all the DNN targets from each language are pooled together, each with its own softmax layer.", "startOffset": 45, "endOffset": 49}, {"referenceID": 6, "context": "Our previous work [7] shows that using just the language closest to the target language from the pool of source languages to train the second DNN can serve as a better initialization model than the multilingual second DNN.", "startOffset": 18, "endOffset": 21}, {"referenceID": 14, "context": "For this work we will consider the Full pack (60-80 hours of training data) of the 11 languages released in the first two years as source languages, while the languages in the third year will be the target languages [16].", "startOffset": 216, "endOffset": 220}, {"referenceID": 15, "context": "Note that for IARPA-Babel languages, the difference between phonetic and graphemic systems in WER are often less than 1% [17, 18].", "startOffset": 121, "endOffset": 129}, {"referenceID": 16, "context": "Note that for IARPA-Babel languages, the difference between phonetic and graphemic systems in WER are often less than 1% [17, 18].", "startOffset": 121, "endOffset": 129}, {"referenceID": 17, "context": "Discriminative training was done on the CD-HMMs using the Minimum Bayes risk (MBR) criterion [19].", "startOffset": 93, "endOffset": 97}, {"referenceID": 18, "context": "The web data was cleaned and filtered using techniques described in [20].", "startOffset": 68, "endOffset": 72}, {"referenceID": 19, "context": "We implemented the hybrid models using the computational network toolkit (CNTK) [21].", "startOffset": 80, "endOffset": 84}, {"referenceID": 20, "context": "The truncated backpropagation-through-time (BPTT) [22] is used to update the model parameters and each utterance is segmented into multiple chunks.", "startOffset": 50, "endOffset": 54}, {"referenceID": 21, "context": "For decoding, we fed the posteriors generated by CNTK into the Kaldi ASR toolkit [23], which then generates the recognition results.", "startOffset": 81, "endOffset": 85}], "year": 2015, "abstractText": "In this paper, we investigate the use of prediction-adaptationcorrection recurrent neural networks (PAC-RNNs) for lowresource speech recognition. A PAC-RNN is comprised of a pair of neural networks in which a correction network uses auxiliary information given by a prediction network to help estimate the state probability. The information from the correction network is also used by the prediction network in a recurrent loop. Our model outperforms other state-of-theart neural networks (DNNs, LSTMs) on IARPA-Babel tasks. Moreover, transfer learning from a language that is similar to the target language can help improve performance further.", "creator": "LaTeX with hyperref package"}}}