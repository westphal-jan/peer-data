{"id": "1510.09079", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Oct-2015", "title": "SentiWords: Deriving a High Precision and High Coverage Lexicon for Sentiment Analysis", "abstract": "Deriving prior polarity lexica for sentiment analysis - where positive or negative scores are associated with words out of context - is a challenging task. Usually, a trade-off between precision and coverage is hard to find, and it depends on the methodology used to build the lexicon. Manually annotated lexica provide a high precision but lack in coverage, whereas automatic derivation from pre-existing knowledge guarantees high coverage at the cost of a lower precision. Since the automatic derivation of prior polarities is less time consuming than manual annotation, there has been a great bloom of these approaches, in particular based on the SentiWordNet resource. In this paper, we compare the most frequently used techniques based on SentiWordNet with newer ones and blend them in a learning framework (a so called 'ensemble method'). By taking advantage of manually built prior polarity lexica, our ensemble method is better able to predict the prior value of unseen words and to outperform all the other SentiWordNet approaches. Using this technique we have built SentiWords, a prior polarity lexicon of approximately 155,000 words, that has both a high precision and a high coverage. We finally show that in sentiment analysis tasks, using our lexicon allows us to outperform both the single metrics derived from SentiWordNet and popular manually annotated sentiment lexica.", "histories": [["v1", "Fri, 30 Oct 2015 13:19:47 GMT  (276kb)", "http://arxiv.org/abs/1510.09079v1", "in Affective Computing, IEEE Transactions on (2015)"]], "COMMENTS": "in Affective Computing, IEEE Transactions on (2015)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lorenzo gatti", "marco guerini", "marco turchi"], "accepted": false, "id": "1510.09079"}, "pdf": {"name": "1510.09079.pdf", "metadata": {"source": "CRF", "title": "SentiWords: Deriving a High Precision and High Coverage Lexicon for Sentiment Analysis", "authors": ["Lorenzo Gatti", "Marco Guerini", "Marco Turchi"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 151 0.09 079v 1 [cs.C L] 30 Oct 201 5Index Terms - Natural Language Processing, Text Analysis, Machine Learning. Personal use of this material is permitted, and permission must be obtained from IEEE for all other uses, in current or future media, including the reprint / re-publication of this material for advertising or promotional purposes, the creation of new collective works, the resale or redistribution to servers or lists, or the reuse of copyrighted components of this work in other works. DOI: 10.1109 / TAFFC.2015.2476456"}, {"heading": "1 INTRODUCTION", "text": "Rather, it is as if it is a pure shipping company, one of the largest shipping companies in the world that has ever existed, one of the largest in the history of the European Union."}, {"heading": "2 RELATED WORK", "text": "This year is the highest in the history of the country."}, {"heading": "3 PROPOSED APPROACH", "text": "In the broad field of sentiment analysis, we first focus on the specific problem of posterior-toprior polarity evaluation words, using SWN in both regression and classification experiments, and for the regression task we use the same formulas (along a continuum between -1 and 1), but only the signs of the result. In these experiments, we also use an ensemble method that combines the various formulas, the underlying hypothesis being that by mixing these formulas and looking at the same information from different perspectives (i.e. the posterior polarities that SWN combines in different ways), we can obtain a better prediction. In the second part of the paper, we confirm the improvement we can achieve with the icon generated by our ensemble method."}, {"heading": "3.1 SentiWordNet", "text": "SentiWordNet [2] is a lexical resource composed of \"synsets,\" i.e. sets of lemma # PoS # sense-number tuples (where the smallest sense-number corresponds to the most common sense of the problem) that have the same meaning. Each synset s is associated with the numerical scores Pos (s) and Neg (s), which range from 0 to 1. These scores represent the positive and negative value (or posterior polarity) of the synset and are shared by each entry in the synset. Scores were automatically assigned by a classification committee trained on the glands of three subsets of WordNet: one composite positive and negative synsets and one containing \"neutral\" synsets, i.e. synsets that are neither positive nor negative."}, {"heading": "3.2 Prior Polarities Formulae", "text": "In this sense, it is only a matter of time before there is a result in which there will be a result."}, {"heading": "3.3 Learning Algorithms", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "4 HUMAN-ANNOTATED SENTIMENT LEXICA", "text": "To assess how well previous polarity formulas work, a gold standard with word polarities provided by human annotators is needed. Below, we describe in detail the two resources we used for our experiments, namely ANEW for regression experiments and General Inquirer for classification."}, {"heading": "4.1 ANEW", "text": "ANEW [19] is a resource designed to provide a set of normative emotional ratings for a large number of words (about 1,000, half of them from similar previous experiments [49], [50]) in the English language. It contains a set of words rated in terms of pleasure (affective value), arousal and dominance, which were collected by students divided into groups by gender using the \"Self-Assessment Manikin,\" an affective rating system that uses graphics to represent values (e.g. happy / unhappy, excited / calm, controlled / under control) along different emotional dimensions, asking students to choose which image reflects their feelings when reading each word. Words were shown in different order between groups and presented in isolation (i.e. no context was provided), which means that this resource can be a human validation of earlier polarity values and may be used as the gold standard for given words."}, {"heading": "4.2 General Inquirer", "text": "The Harvard General Inquirer Dictionary (henceforth GI) is a widely used resource designed for automatic text analysis. [23] Its latest revision4 contains 11,789 words, with 182 semantic and pragmatic terms and their share of speech. Words and their categories were originally taken from the Harvard IV4 Psychosociological Dictionary [51] and the Lasswell Value Dictionary [52]. GI categories were defined to be used in social science content analysis applications, but this resource has also been extensively used for mood analysis. In this essay, we consider the positive and negative categories (1,915 words and 2,291 words, respectively, for a total of 4,206 affective words), which indicate words with positive or negative value. As with ANEW, since these words have no context, we consider the labels as binary human assigned earlier polarities, which can therefore be used as the gold standard."}, {"heading": "5 PRIOR POLARITIES EXPERIMENTS", "text": "To use the ANEW dataset to measure the performance of the previous polarities, we had to assign a PoS for all words to get the SWN dilemma # PoS format. To do this, we proceeded as follows: for each word, check if it exists between SWN1 and SWN3 Lemmas; if not, lemmatize the word using the TextPro tool suite [53] and check if the problem exists, instead5. If it is not found (i.e., the word cannot be automatically aligned), remove the word from the list (this was the case for 30 words of the 1,034 contained in the TextPro tool suite). The remaining 1,004 Lemmas were then associated with all Lemmas present in SWN to get the final Lemma # PoS. Note that a Lemma may have more than one PoS, for example, writer is only one noun."}, {"heading": "5.1 Discussion", "text": "In this section, we summarize the main results of our analysis by answering the various questions we presented at the beginning of the paper (since the results are largely consistent in measurements in both regression and classification): SentiWordNet improves randomly. One of the first things that is worth noting - in Tables 2, 3, 4 and 5 - is that the random approach (rnd) is, as expected, the worst performance, while all other approaches based on SWN have statistically significant improvements in both MAE and accuracy (p < 0.001).SWN3 is better than SWN1, with SWN3 improving results in both regression (MAE\u00b5 0.398 vs. 0.366, p < 0.001) and classification copyright (c) 2015 IEEE."}, {"heading": "6 ERROR ANALYSIS", "text": "This year it is so far that it will be able to retaliate in order to reewnn, \"he says.\" It is as if it will be able to revenge, \"he says.\" But it is as if it is able to revenge, \"he says.\" It is as if it will be able to revenge, \"he says.\" It is as if it will be able to revenge, \"he says."}, {"heading": "7 SentiWords", "text": "In the previous sections, we have shown how an ensemble method (SVMfs) can be used to calculate more accurate previous polarities based on the values of the rear polarities of SWN3. We used these results to create SentiWords, a lexicon that maximizes both precision and coverage. To get this result, we trained our classifier on a larger dataset, the 13,915 entries of Warr [22], and used it to comment on all the lemma PoS of SWN3. Specifically, we processed Warr as in ANEW (see Section 5). In this way, we obtained a list of 18,154 lemma-PoS, each of which was associated with the value value specified by human annotators, coupled with the values of the formulas randomly selected as characteristics. We used this as training to create a more precise SVMfs regression model."}, {"heading": "8 PRIOR POLARITIES AND SENTIMENT ANALYSIS", "text": "To confirm the improvement we can make in mood analysis with SentiWords through individual metrics and other widely used handmade lexicographies such as ANEW - which are more accurate but have a much lower range - we conducted an extensive series of experiments. In these experiments, we also looked at two sets of data sets commented on with mood values (from -1 to 1) as well as mood labels (NEGATIVE or POSITIVE). Compared with SentiWords, we also looked at 4 human commented lexicographies (ANEW, Warr and Stanf as gold standards for regression, the same for classification, but with GI instead of ANEW) to test the importance of the reach and precision of our newly created lists. Specifically: \u2022 ANEW represents a gold standard with a low range on a continuous scale. \u2022 GI represents a gold standard with a low range in a slum format. \u2022 Warr represents a gold standard with a high range (currently available for highest polarity)."}, {"heading": "8.1 Datasets", "text": "To assess how well the use of previous polarities performs in the specific task of text-based sentiment analysis, we tested our resource and the Gold Standard lexicon for two distinct datasets, 7. The Stanf lexicon is not available per se, we created it by extracting all the individual words contained in the Stanford Sentiment Treebank (see Section 8.1.2 for a description of the dataset), with their manually annotated affective score.Copyright (c) 2015 IEEE. Personal use is permitted. For all other purposes, permission must be obtained from the IEEE by using pubs-permissions @ ieee.org.This is the version of an author's article published in IEEE Transactions on Affective Computing. Changes to this version were made by the publisher prior to publication. The final version is available at http: / xd.ido.org / 10.TAF645.two language-based sentences, simplified with FC6105.AF645.2014.2"}, {"heading": "8.1.1 SemEval", "text": "The public data set provided for the SemEval2007 task \"Affective Text\" [57] focuses on the recognition of emotions in 1,000 news headlines, both in regression and in classification. Headlines typically consist of a few words and are often written with the intention of \"provoking\" emotions in order to attract readers \"attention. An example of a headline from the data set is the following:\" Iraqi car bombs kill 22 people, injure more than 60. \"For the regression task, the provided value is -0.98, while for the classification task the label is NEGATIVE. This data set (which will henceforth be called SemEval) is of interest to us because the\" compositional \"problem, given the simplified syntax of news headlines that, for example, contain fewer adverbs (such as negations or amplifiers), has less significance than normal sentences [58]. Each header of the data set has been uploaded to the word\" S, \"where the word has been uploaded to the Poxlex 7, with only one word being English.\" The public data set provided for the SemEval2007 task \"Affective Text\" [57] focuses on the recognition of emotions in 1,000 news headlines, both regression and classification."}, {"heading": "8.1.2 Sentiment Treebank", "text": "The Stanford Sentiment Treebank (STB) is a corpus of fully labeled parse trees that allows a complete analysis of the compositional effects of sentiment in language. [7] The corpus is based on the data set introduced in [59] and consists of 11,855 individual sentences extracted from film reviews. It has been compared with the Stanford parser [60] and contains a total of 215,154 unique phrases from these parse trees, each commented by three human judges (using Mechanical Turk). An example of a movie review set is: \"One of the most beautiful, human, and significant Holocaust films ever made.\" For the regression task, the provided value is + 0.97, while for the classification task the provided label is POSITIVE. For our experiments, we took the 11,855 sentences of the STB data set and lemmated and blanked all the words of the STB report as the STB report, where the STB report had the word as the STS-4."}, {"heading": "9 SENTIMENT ANALYSIS EXPERIMENTS", "text": "The reasons for this choice are given by the fact that the results of the previous evaluation can also be given to words that are not \"relevant\" to the task of text-based sentiment analysis, such as auxiliary verbs that distort the results. Nevertheless, it is not a mistake per se to give a score to such keywords: if people perceive that they convey an affective meaning when taken in isolation, this information can be very useful for other sentimental tasks. It goes back, for example, to the naming described in the introduction, let us consider the paradigmatic example of terms that tend to use evocative names - since their smell cannot be \"shown\" in advertising: We have \"Must\" from Cartier, or \"Be\" from CalvinKlein, both of which are auxiliary verbs. Both examples have aCopyright (c) 2015 IEEE."}, {"heading": "9.1 Discussion", "text": "\"I think it's going to take a lot of time for people to get used to the fact that they're not going to be able to do it,\" he said, adding that he was \"not going to be able to do it in the same way that I was able to do it in the first place.\""}, {"heading": "10 CONCLUSIONS", "text": "While manually annotated lexicographs offer high precision but lack coverage, the automatic derivation of existing knowledge guarantees high coverage at the expense of lower precision. Based on the experience of automatically deriving earlier polarities from the SentiWordNet resource, we used a learning system that - using manually generated lexicographs - is able to better predict the earlier value of invisible words. Finally, we demonstrated that it is possible to use this technique to create a resource (SentiWords) with very wide reach and good precision. With our Mood Analysis lexicographs, we were able to exceed both the individual metrics derived from SentiWordNet and the popular manually annotated mood lexicographics."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors thank Jose \u0301 Camargo De Souza for his help in selecting the feature films. This work was partially supported by the Trento RISE PerTe project."}], "references": [{"title": "A survey of opinion mining and sentiment analysis", "author": ["B. Liu", "L. Zhang"], "venue": "Mining Text Data, C. C. Aggarwal and C. Zhai, Eds. Springer US, 2012, pp. 415\u2013463.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "SentiWordNet: A publicly available lexical resource for opinion mining", "author": ["A. Esuli", "F. Sebastiani"], "venue": "Proc. 5th Int\u2019l Conf. Language Resources and Evaluation (LREC 06), 2006, pp. 417\u2013 422.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Sentiment analysis: How to derive prior polarities from SentiWordNet", "author": ["M. Guerini", "L. Gatti", "M. Turchi"], "venue": "Proc. 2013 Conf. Empirical Methods on Natural Language Processing (EMNLP 13), 2013, pp. 1259\u20131269.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Generating morepositive and more-negative text", "author": ["D.Z. Inkpen", "O. Feiguina", "G. Hirst"], "venue": "Computing Attitude and Affect in Text: Theory and Applications. Springer, 2006, pp. 187\u2013 198.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Valentino: A tool for valence shifting of natural language texts", "author": ["M. Guerini", "O. Stock", "C. Strapparava"], "venue": "Proc. 6th Int\u2019l Conf. Language Resources and Evaluation (LREC 08), 2008, pp. 243\u2013246.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Generating shifting sentiment for a conversational agent", "author": ["S. Whitehead", "L. Cavedon"], "venue": "Proc. North Am. Chapter of the Assoc. Computational Linguistics: Human Language Technologies 2010 (NAACL HLT 10) Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, June 2010, pp. 89\u201397.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["R. Socher", "A. Perelygin", "J.Y. Wu", "J. Chuang", "C.D. Manning", "A.Y. Ng", "C. Potts"], "venue": "Proc. 2013 Conf. Empirical Methods on Natural Language Processing (EMNLP 13), 2013, pp. 1631\u20131642.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Contextual valence shifters", "author": ["L. Polanyi", "A. Zaenen"], "venue": "Computing attitude and affect in text: Theory and applications. Springer, 2006, pp. 1\u201310.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Sentiment composition", "author": ["K. Moilanen", "S. Pulman"], "venue": "Proceedings of the Recent Advances in Natural Language Processing International Conference, 2007, pp. 378\u2013382.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Affect analysis model: Novel rule-based approach to affect sensing from text", "author": ["A. Neviarouskaya", "H. Prendinger", "M. Ishizuka"], "venue": "Natural Language Eng., vol. 17, no. 1, pp. 95\u2013135, Jan. 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["S. Wang", "C. Manning"], "venue": "Proc. 50th Ann. Meeting of the Assoc. for Computational Linguistics (ACL 12), 2012, pp. 90\u201394.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "A computational approach to the automation of creative naming", "author": ["G. \u00d6zbal", "C. Strapparava"], "venue": "Proc. 50th Ann. Meeting of the Assoc. for Computational Linguistics (ACL 12), 2012, pp. 703\u2013711.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Brand Pitt: A corpus to explore the art of naming", "author": ["G. \u00d6zbal", "C. Strapparava", "M. Guerini"], "venue": "Proc. 8th Int\u2019l Conf. Language Resources and Evaluation (LREC 12), 2012, pp. 1822\u2013 1828.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and Trends in Information Retrieval, vol. 2, no. 1-2, pp. 1\u2013135, 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Just how mad are you? Finding strong and weak opinion clauses", "author": ["T. Wilson", "J. Wiebe", "R. Hwa"], "venue": "Proc. 19th Nat\u2019l Conf. Artificial Intelligence (AAAI 04), 2004, pp. 761\u2013769. Copyright (c) 2015 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org. This is the author\u2019s version of an article that has been published in IEEE Transactions on Affective Computing. Changes were made to this version by the publisher prior to publication. The final version is available at http://dx.doi.org/10.1109/TAFFC.2015.2476456", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Online textual communications annotated with grades of emotion strength", "author": ["G. Paltoglou", "M. Thelwall", "K. Buckley"], "venue": "Proc. 3rd Int\u2019l Workshop of Emotion: Corpora for research on Emotion and Affect (satellite of LREC 10), 2010, pp. 25\u201331.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Sentiment lexicon creation from lexical resources", "author": ["B. Heerschop", "A. Hogenboom", "F. Frasincar"], "venue": "Business Information Systems, ser. Lecture Notes in Business Information Processing, W. Abramowicz, Ed. Springer Berlin Heidelberg, 2011, vol. 87, pp. 185\u2013196. [Online]. Available: http://dx.doi.org/10.1007/978-3-642-21863-7 16", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining", "author": ["S. Baccianella", "A. Esuli", "F. Sebastiani"], "venue": "Proc. 7th Conf. Int\u2019l Language Resources and Evaluation (LREC 10), 2010, pp. 2200\u20132204.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Affective norms for English words (ANEW): Instruction manual and affective ratings", "author": ["M. Bradley", "P. Lang"], "venue": "Univ. of Florida, tech. report C-1, 1999.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Lexicon-based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "M. Stede"], "venue": "Computational linguistics, vol. 37, no. 2, pp. 267\u2013307, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "The dictionary of affect in language", "author": ["C. Whissell"], "venue": "Emotion: Theory, research, and experience, vol. 4, no. 113-131, p. 94, 1989.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1989}, {"title": "Norms of valence, arousal, and dominance for 13,915 english lemmas", "author": ["A. Warriner", "V. Kuperman", "M. Brysbaert"], "venue": "Behavior research methods, vol. 45, no. 4, pp. 1\u201317, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "The General Inquirer: A Computer Approach to Content Analysis", "author": ["P. Stone", "D. Dunphy", "M. Smith"], "venue": "MIT press,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1966}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann"], "venue": "Proc. Conf. Human Language Technology and Empirical Methods in Natural Language Processing (HLT/EMNLP 05), 2005, pp. 347\u2013354.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "WordNet-Affect: an affective extension of WordNet", "author": ["C. Strapparava", "A. Valitutti"], "venue": "Proc. 4th Int\u2019l Conf. Language Resources and Evaluation (LREC 04), 2004, pp. 1083 \u2013 1086.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "Affect analysis of text using fuzzy semantic typing", "author": ["P. Subasic", "A. Huettner"], "venue": "IEEE Trans. Fuzzy Systems, vol. 9, no. 4, pp. 483\u2013496, 2001.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2001}, {"title": "Crowdsourcing a word\u2013 emotion association lexicon", "author": ["S.M. Mohammad", "P.D. Turney"], "venue": "Computational Intelligence, vol. 29, no. 3, pp. 436\u2013465, 2013.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Textual affect sensing for sociable and expressive online communication", "author": ["A. Neviarouskaya", "H. Prendinger", "M. Ishizuka"], "venue": "Affective Computing and Intelligent Interaction, ser. Lecture Notes in Computer Science, A. Paiva, R. Prada, and R. Picard, Eds. Springer Berlin Heidelberg, 2007, vol. 4738, pp. 218\u2013229.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "DepecheMood: a lexicon for emotion analysis from crowd-annotated news", "author": ["J. Staiano", "M. Guerini"], "venue": "Proc. 52nd Ann. Meeting of the Assoc. for Computational Linguistics (ACL 14), pp. 427\u2013433, 2014.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Sentiful: A lexicon for sentiment analysis", "author": ["A. Neviarouskaya", "H. Prendinger", "M. Ishizuka"], "venue": "IEEE Trans. Affective Computing, vol. 2, no. 1, pp. 22\u201336, 2011.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Using syntactic and contextual information for sentiment polarity analysis", "author": ["S. Agrawal", "T. Siddiqui"], "venue": "Proc. 2nd Int\u2019l Conf. Interaction Sciences: Information Technology, Culture and Human (ICIS 09), 2009, pp. 620\u2013623.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "FBK: Sentiment analysis in twitter with tweetsted", "author": ["F. Chowdhury", "M. Guerini", "S. Tonelli", "A. Lavelli"], "venue": "Proc. 7th Int\u2019l Workshop on Semantic Evaluation (SemEval \u201913), vol. 2, June 2013, pp. 466\u2013470.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Sentiment analysis of movie reviews on discussion boards using a linguistic approach", "author": ["T. Thet", "J. Na", "C. Khoo", "S. Shakthikumar"], "venue": "Proc. 1st Int\u2019l CIKM Workshop on Topic-sentiment analysis for mass opinion (TSA 09), 2009, pp. 81\u201384.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2009}, {"title": "Are SentiWordNet scores suited for multidomain sentiment classification?", "author": ["K. Denecke"], "venue": "Proc. 4th Int\u2019l Conf. Digital Information Management (ICDIM", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2009}, {"title": "Sentiment polarity identification in financial news: A cohesion-based approach", "author": ["A. Devitt", "K. Ahmad"], "venue": "Proc. 45th Ann. Meeting of the Assoc. for Computational Linguistics (ACL 07), 2007, pp. 984\u2013991.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2007}, {"title": "Development of a novel algorithm for sentiment analysis based on adverb-adjectivenoun combinations", "author": ["J. Sing", "S. Sarkar", "T. Mitra"], "venue": "Proc. 3rd Nat\u2019l Conf. Emerging Trends  and Applications in Computer Science (NCETACS 12), 2012, pp. 38\u201340.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "UPAR7: A knowledge-based system for headline sentiment tagging", "author": ["F. Chaumartin"], "venue": "Proc. 4th Int\u2019l Workshop on Semantic Evaluations (IWSE 07), 2007, pp. 422\u2013425.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "Endorsements and rebuttals in blog distillation", "author": ["G. Berardi", "A. Esuli", "F. Sebastiani", "F. Silvestri"], "venue": "Information Sciences, vol. 249, pp. 38\u201347, 2013.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2013}, {"title": "Sentence level subjectivity and sentiment analysis experiments in NTCIR-7 MOAT challenge", "author": ["L. Qu", "C. Toprak", "N. Jakob", "I. Gurevych"], "venue": "Proc. 7th NII Test Collection for IR Systems Workshop Meeting (NTCIR-7), 2008, pp. 210\u2013217.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2008}, {"title": "Pattern classification using ensemble methods", "author": ["L. Rokach"], "venue": "World Scientific,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2010}, {"title": "Kernel methods for pattern analysis", "author": ["J. Shawe-Taylor", "N. Cristianini"], "venue": "Cambridge Univ. press,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2004}, {"title": "Gaussian processes for machine learning", "author": ["C. Rasmussen", "C. Williams"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2006}, {"title": "Support vector machines", "author": ["A. Mammone", "M. Turchi", "N. Cristianini"], "venue": "Wiley Interdisciplinary Reviews: Computational Statistics, vol. 1, no. 3, pp. 283\u2013289, 2009.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2009}, {"title": "LIBSVM: A library for support vector machines", "author": ["C. Chang", "C. Lin"], "venue": "ACM Trans. Intelligent Systems and Technology, vol. 2, no. 3, pp. 27:1\u201327:27, 2011.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2011}, {"title": "Feature selection for SVMs", "author": ["J. Weston", "S. Mukherjee", "O. Chapelle", "M. Pontil", "T. Poggio", "V. Vapnik"], "venue": "Proc. 14th Conf. Neural Information Processing Systems (NIPS 00), 2000, pp. 668\u2013 674.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2000}, {"title": "Stability selection", "author": ["N. Meinshausen", "P. B\u00fchlmann"], "venue": "J. of the Royal Statistical Soc.: Series B (Statistical Methodology), vol. 72, no. 4, pp. 417\u2013473, 2010.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "Bayesian classification with gaussian processes", "author": ["C. Williams", "D. Barber"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 20, no. 12, pp. 1342\u20131351, 1998.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1998}, {"title": "An approach to environmental psychology", "author": ["A. Mehrabian", "J.A. Russell"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1974}, {"title": "Words high and low in pleasantness as rated by male and female college students", "author": ["F.S. Bellezza", "A.G. Greenwald", "M.R. Banaji"], "venue": "Behavior Research Methods, Instruments, & Computers, vol. 18, no. 3, pp. 299\u2013303, 1986.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1986}, {"title": "Validation of the General Inquirer Harvard IV Dictionary", "author": ["D. Dunphy", "C. Bullard", "E. Crossing"], "venue": "Proc. Pisa Conf. Content Analysis, 1974.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1974}, {"title": "The Lasswell value dictionary", "author": ["H. Lasswell", "J. Namenwirth"], "venue": "New Haven, 1969.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 1969}, {"title": "The TextPro tool suite", "author": ["E. Pianta", "C. Girardi", "R. Zanoli"], "venue": "Proc. 6th Int\u2019l Conf. Language Resources and Evaluation (LREC 08), 2008, pp. 2603\u20132607.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2008}, {"title": "More accurate tests for the statistical significance of result differences", "author": ["A. Yeh"], "venue": "Proc. 18th Int\u2019l Conf. Computational Linguistics (COLING 00), 2000, pp. 947\u2013953.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2000}, {"title": "Semeval-2010 task 17: All-words word sense disambiguation on a specific domain", "author": ["E. Agirre", "O. De Lacalle", "C. Fellbaum", "S. Hsieh", "M. Tesconi", "M. Monachini", "P. Vossen", "R. Segers"], "venue": "Proc. 5th Int\u2019l Workshop on Semantic Evaluation (IWSE 10), 2010, pp. 75\u201380.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2010}, {"title": "Modelling annotator bias with multitask gaussian processes: An application to machine translation quality estimation", "author": ["T. Cohn", "L. Specia"], "venue": "Proc. 51th Ann. Meeting of the Assoc. for Computational Linguistics (ACL 13), 2013, pp. 32\u201342.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2013}, {"title": "SemEval-2007 task 14: Affective text", "author": ["C. Strapparava", "R. Mihalcea"], "venue": "Proc. 4th Int\u2019l Workshop on Semantic Evaluations (SemEval 07), 2007, pp. 70\u201374.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2007}, {"title": "Onts: optima news translation system", "author": ["M. Turchi", "M. Atkinson", "A. Wilcox", "B. Crawley", "S. Bucci", "R. Steinberger", "E. Van der Goot"], "venue": "Proc. Demonstrations at the 13th Conf. European Chapter of the Assoc. for Computational Linguistics (EACL 12), 2012, pp. 25\u201330.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2012}, {"title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales", "author": ["B. Pang", "L. Lee"], "venue": "Proc. 43rd Ann. Meeting of the Assoc. for Computational Linguistics (ACL 05), 2005, pp. 115\u2013124.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning to identify emotions in text", "author": ["C. Strapparava", "R. Mihalcea"], "venue": "Proc. 23rd Ann. ACM Symp. Applied computing (SAC 08), 2008, pp. 1556\u20131560.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "lists of positive and negative words \u2013 often in conjunction with other methods (usually machine learning based) [1], to assign sentiment scores to texts.", "startOffset": 112, "endOffset": 115}, {"referenceID": 1, "context": "We focus on SentiWordNet (henceforth SWN), a resource that has been widely adopted since it provides a broadcoverage lexicon \u2013 built in a semi-automatic manner \u2013 for English [2].", "startOffset": 174, "endOffset": 177}, {"referenceID": 2, "context": "In detail, the first part of the paper \u2013 that is based on our previous work, presented in [3] \u2013 addresses three main research questions about words prior polarity computation: (i) is there any relevant difference in the posterior-to-prior polarity formulae performance (both in regression and classification tasks)? (ii) Is there any relevant variation in prior polarity values if we use different releases of SWN (i.", "startOffset": 90, "endOffset": 93}, {"referenceID": 3, "context": "First, it is fundamental for tasks such as affective modification of existing texts, where words polarity together with their scores are necessary for creating multiple versions of a text, varying its affective dimension [4], [5], [6].", "startOffset": 221, "endOffset": 224}, {"referenceID": 4, "context": "First, it is fundamental for tasks such as affective modification of existing texts, where words polarity together with their scores are necessary for creating multiple versions of a text, varying its affective dimension [4], [5], [6].", "startOffset": 226, "endOffset": 229}, {"referenceID": 5, "context": "First, it is fundamental for tasks such as affective modification of existing texts, where words polarity together with their scores are necessary for creating multiple versions of a text, varying its affective dimension [4], [5], [6].", "startOffset": 231, "endOffset": 234}, {"referenceID": 6, "context": "Works using compositional approaches worth mentioning are: [7], that uses recursive neural networks to learn compositional rules for sentiment analysis, while [8], [9], [10] exploit hand-coded rules.", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "Works using compositional approaches worth mentioning are: [7], that uses recursive neural networks to learn compositional rules for sentiment analysis, while [8], [9], [10] exploit hand-coded rules.", "startOffset": 159, "endOffset": 162}, {"referenceID": 8, "context": "Works using compositional approaches worth mentioning are: [7], that uses recursive neural networks to learn compositional rules for sentiment analysis, while [8], [9], [10] exploit hand-coded rules.", "startOffset": 164, "endOffset": 167}, {"referenceID": 9, "context": "Works using compositional approaches worth mentioning are: [7], that uses recursive neural networks to learn compositional rules for sentiment analysis, while [8], [9], [10] exploit hand-coded rules.", "startOffset": 169, "endOffset": 173}, {"referenceID": 10, "context": "The work in [11] partially accounts for this problem arguing that using word bigrams allows improvement over BOW based methods, where words are taken as features in isolation.", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "Finally, tasks such as copywriting, where evocative names are a key element to a successful product [12], [13] require exhaustive lists of emotion related words.", "startOffset": 100, "endOffset": 104}, {"referenceID": 12, "context": "Finally, tasks such as copywriting, where evocative names are a key element to a successful product [12], [13] require exhaustive lists of emotion related words.", "startOffset": 106, "endOffset": 110}, {"referenceID": 13, "context": "A general overview can be found in [14], [1], [15], [16].", "startOffset": 35, "endOffset": 39}, {"referenceID": 0, "context": "A general overview can be found in [14], [1], [15], [16].", "startOffset": 41, "endOffset": 44}, {"referenceID": 14, "context": "A general overview can be found in [14], [1], [15], [16].", "startOffset": 46, "endOffset": 50}, {"referenceID": 15, "context": "A general overview can be found in [14], [1], [15], [16].", "startOffset": 52, "endOffset": 56}, {"referenceID": 16, "context": "Automatically created resources are usually larger, but their precision is highly dependent on the annotation algorithm [17] and, in general, not as accurate as manual resources.", "startOffset": 120, "endOffset": 124}, {"referenceID": 1, "context": "One of the most well-known resources is SentiWordNet (SWN) [2], [18], in which each entry is a set of lemma#PoS#sense-number sharing the same meaning, called synset.", "startOffset": 59, "endOffset": 62}, {"referenceID": 17, "context": "One of the most well-known resources is SentiWordNet (SWN) [2], [18], in which each entry is a set of lemma#PoS#sense-number sharing the same meaning, called synset.", "startOffset": 64, "endOffset": 68}, {"referenceID": 2, "context": "These approaches, detailed in [3], produce a list of approximately 155,000 words, where the lower precision given by the automatic scoring of SWN is compensated by the high coverage.", "startOffset": 30, "endOffset": 33}, {"referenceID": 18, "context": "Another widely used resource is the Affective Norms for English Words (ANEW) [19], providing valence scores for roughly 1,000 words, which were manually assigned by several annotators.", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "Similarly, the SO-CAL entries [20] consist of roughly 4,000 words manually tagged by a small number of linguists with a multi-class label (from very_negative to very_positive).", "startOffset": 30, "endOffset": 34}, {"referenceID": 20, "context": "The Dictionary of Affect in Language (DAL) contains roughly 9,000 words manually rated along the dimensions \u2018pleasantness\u2019, \u2018activation\u2019 and \u2018imagery\u2019 [21].", "startOffset": 151, "endOffset": 155}, {"referenceID": 21, "context": "More recently, a resource replicating the ANEW annotation approach using crowdsourcing was released by Warriner and colleagues [22], providing sentiment scores for approxi-", "startOffset": 127, "endOffset": 131}, {"referenceID": 22, "context": "Finally, the General Inquirer lexicon [23] provides a binary classification (positive/negative) of approximately 4,000 sentiment-bearing words manually annotated, while the resource presented in [24] expands the General Inquirer to 6,000 words.", "startOffset": 38, "endOffset": 42}, {"referenceID": 23, "context": "Finally, the General Inquirer lexicon [23] provides a binary classification (positive/negative) of approximately 4,000 sentiment-bearing words manually annotated, while the resource presented in [24] expands the General Inquirer to 6,000 words.", "startOffset": 195, "endOffset": 199}, {"referenceID": 24, "context": "One of the most used resources is WordNetAffect [25] which contains manually assigned affective labels to WordNet synsets (ANGER, JOY, FEAR, etc.", "startOffset": 48, "endOffset": 52}, {"referenceID": 25, "context": "Fuzzy Affect Lexicon [27] contains roughly 4,000 lemma-PoS manually annotated by one linguist using 80 emotion labels.", "startOffset": 21, "endOffset": 25}, {"referenceID": 26, "context": "EmoLex [28] contains almost 10,000 lemmas annotated with an intensity label for each emotion using Mechanical Turk.", "startOffset": 7, "endOffset": 11}, {"referenceID": 27, "context": "Finally Affect database is an extension of SentiFul [29] and contains 2,500 words in the form lemma#PoS, while DepecheMood [30] contains about 37,000 words also in the lemma#PoS format, and was automatically built by harvesting crowd-sourced affective annotation from a social news network.", "startOffset": 52, "endOffset": 56}, {"referenceID": 28, "context": "Finally Affect database is an extension of SentiFul [29] and contains 2,500 words in the form lemma#PoS, while DepecheMood [30] contains about 37,000 words also in the lemma#PoS format, and was automatically built by harvesting crowd-sourced affective annotation from a social news network.", "startOffset": 123, "endOffset": 127}, {"referenceID": 1, "context": "SentiWordNet [2] is a lexical resource composed of \u201csynsets\u201d, i.", "startOffset": 13, "endOffset": 16}, {"referenceID": 24, "context": "good#a#1), and (ii) automatically expanded by traversing the WordNet hierarchy to find \u201crelated\u201d synsets, using the method described in [25].", "startOffset": 136, "endOffset": 140}, {"referenceID": 17, "context": "0 [18] (SWN3).", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "This produces two scores in the range [0, 1], f(posScore) and f(negScore), for each lemma-PoS.", "startOffset": 38, "endOffset": 44}, {"referenceID": 29, "context": "Based on [31], [32], [5], [33], this is the most basic form of prior polarities.", "startOffset": 9, "endOffset": 13}, {"referenceID": 30, "context": "Based on [31], [32], [5], [33], this is the most basic form of prior polarities.", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "Based on [31], [32], [5], [33], this is the most basic form of prior polarities.", "startOffset": 21, "endOffset": 24}, {"referenceID": 31, "context": "Based on [31], [32], [5], [33], this is the most basic form of prior polarities.", "startOffset": 26, "endOffset": 30}, {"referenceID": 32, "context": "It was used in [34], [35], [36], [37].", "startOffset": 15, "endOffset": 19}, {"referenceID": 33, "context": "It was used in [34], [35], [36], [37].", "startOffset": 21, "endOffset": 25}, {"referenceID": 34, "context": "It was used in [34], [35], [36], [37].", "startOffset": 27, "endOffset": 31}, {"referenceID": 35, "context": "It was used in [34], [35], [36], [37].", "startOffset": 33, "endOffset": 37}, {"referenceID": 29, "context": "Based on [31], it considers only senses having a Pos(s) greater than or equal to the corresponding Neg(s), and greater than 0 (the stronglyPos set).", "startOffset": 9, "endOffset": 13}, {"referenceID": 36, "context": "The system presented in [38] uses a similar approach of weighted mean.", "startOffset": 24, "endOffset": 28}, {"referenceID": 37, "context": "Similar to the w1, this formula weigths each lemma with a harmonic series, see for example [39] (where w2 appears with the fd variant).", "startOffset": 91, "endOffset": 95}, {"referenceID": 38, "context": "A similar approach has been used in [40].", "startOffset": 36, "endOffset": 40}, {"referenceID": 39, "context": "While it is quite straightforward for classification problems (see [41], chapter 3), combining regression scores can require ad-hoc decisions.", "startOffset": 67, "endOffset": 71}, {"referenceID": 40, "context": "For this purpose, we used two non-parametric learning approaches, Support Vector Machines (SVMs) [42] and Gaussian Processes (GPs) [43], to test the performance of all the metrics in conjunction.", "startOffset": 97, "endOffset": 101}, {"referenceID": 41, "context": "For this purpose, we used two non-parametric learning approaches, Support Vector Machines (SVMs) [42] and Gaussian Processes (GPs) [43], to test the performance of all the metrics in conjunction.", "startOffset": 131, "endOffset": 135}, {"referenceID": 40, "context": "An exhaustive explanation of the two methodologies can be found in [42], [44] and [43].", "startOffset": 67, "endOffset": 71}, {"referenceID": 42, "context": "An exhaustive explanation of the two methodologies can be found in [42], [44] and [43].", "startOffset": 73, "endOffset": 77}, {"referenceID": 41, "context": "An exhaustive explanation of the two methodologies can be found in [42], [44] and [43].", "startOffset": 82, "endOffset": 86}, {"referenceID": 43, "context": "In the SVM experiments, we use C-SVM and \u01ebSVM implemented in the LIBSVM toolbox [45].", "startOffset": 80, "endOffset": 84}, {"referenceID": 44, "context": "As demonstrated in [46], SVMs can benefit from the application of feature selection techniques.", "startOffset": 19, "endOffset": 23}, {"referenceID": 45, "context": "For this purpose, Randomized Lasso, or stability selection [47] is applied before training the SVM learner.", "startOffset": 59, "endOffset": 63}, {"referenceID": 41, "context": "More details on the differences between GPs for regression and classification and the GP kernels are available in \u00a72, \u00a73, \u00a74 in [43] lihood functions is tractable.", "startOffset": 128, "endOffset": 132}, {"referenceID": 46, "context": "Unfortunately, this is not valid for the classification task where an approximation method (Laplace [48] in our experiments) is required.", "startOffset": 100, "endOffset": 104}, {"referenceID": 18, "context": "ANEW [19] is a resource developed to provide a set of normative emotional ratings for a large number of words (roughly 1,000, half of them taken from similar previous experiments [49], [50]) in the English language.", "startOffset": 5, "endOffset": 9}, {"referenceID": 47, "context": "ANEW [19] is a resource developed to provide a set of normative emotional ratings for a large number of words (roughly 1,000, half of them taken from similar previous experiments [49], [50]) in the English language.", "startOffset": 179, "endOffset": 183}, {"referenceID": 48, "context": "ANEW [19] is a resource developed to provide a set of normative emotional ratings for a large number of words (roughly 1,000, half of them taken from similar previous experiments [49], [50]) in the English language.", "startOffset": 185, "endOffset": 189}, {"referenceID": 22, "context": "The Harvard General Inquirer dictionary (henceforth GI) is a widely used resource, built for automatic text analysis [23].", "startOffset": 117, "endOffset": 121}, {"referenceID": 49, "context": "Words and their categories were initially taken from the Harvard IV4 Psychosociological Dictionary [51] and the Lasswell Value Dictionary [52].", "startOffset": 99, "endOffset": 103}, {"referenceID": 50, "context": "Words and their categories were initially taken from the Harvard IV4 Psychosociological Dictionary [51] and the Lasswell Value Dictionary [52].", "startOffset": 138, "endOffset": 142}, {"referenceID": 51, "context": "To do so, we proceeded as follows: for each word, check if it is present among both SWN1 and SWN3 lemmas; if not, lemmatize the word with the TextPro tool suite [53] and check if the lemma is present instead.", "startOffset": 161, "endOffset": 165}, {"referenceID": 52, "context": "An approximate randomization test [54] was used for the classification experiments instead.", "startOffset": 34, "endOffset": 38}, {"referenceID": 53, "context": "In SemEval2010, only 5 participants out of 29 performed better than the most frequent threshold [55].", "startOffset": 96, "endOffset": 100}, {"referenceID": 54, "context": "This is in contrast to the results presented in [56], where GPs on the single task are on average better than SVMs.", "startOffset": 48, "endOffset": 52}, {"referenceID": 21, "context": "To obtain this result, we trained our classifier on a larger dataset, the 13,915 entries of Warr [22], and used it to annotate all the lemma-PoS of SWN3.", "startOffset": 97, "endOffset": 101}, {"referenceID": 55, "context": "The public dataset provided for the SemEval2007 task on \u2018Affective Text\u2019 [57] is focused on emotion recognition in 1,000 news headlines, both in regression and classification settings.", "startOffset": 73, "endOffset": 77}, {"referenceID": 56, "context": "This dataset (which will be referred to as SemEval henceforth) is of interest to us since the \u2018compositional\u2019 problem is less prominent given the simplified syntax of news headlines, containing, for example, fewer adverbs (like negations or intensifiers) than normal sentences [58].", "startOffset": 277, "endOffset": 281}, {"referenceID": 6, "context": "The Stanford Sentiment Treebank (STB) is a corpus with fully labelled parse trees, that allows for a complete analysis of the compositional effects of sentiment in language [7].", "startOffset": 173, "endOffset": 176}, {"referenceID": 57, "context": "The corpus is based on the dataset introduced in [59] and consists of 11,855 single sentences extracted from movie reviews.", "startOffset": 49, "endOffset": 53}, {"referenceID": 58, "context": "without any syntactic or compositional reasoning that can boost the performance) we used a na\u0131\u0308ve approach that averages over all the word scores in a sentence, similar, for example, to the approaches used in [61] and [30].", "startOffset": 209, "endOffset": 213}, {"referenceID": 28, "context": "without any syntactic or compositional reasoning that can boost the performance) we used a na\u0131\u0308ve approach that averages over all the word scores in a sentence, similar, for example, to the approaches used in [61] and [30].", "startOffset": 218, "endOffset": 222}], "year": 2015, "abstractText": "Deriving prior polarity lexica for sentiment analysis \u2013 where positive or negative scores are associated with words out of context \u2013 is a challenging task. Usually, a trade-off between precision and coverage is hard to find, and it depends on the methodology used to build the lexicon. Manually annotated lexica provide a high precision but lack in coverage, whereas automatic derivation from pre-existing knowledge guarantees high coverage at the cost of a lower precision. Since the automatic derivation of prior polarities is less time consuming than manual annotation, there has been a great bloom of these approaches, in particular based on the SentiWordNet resource. In this paper, we compare the most frequently used techniques based on SentiWordNet with newer ones and blend them in a learning framework (a so called \u2018ensemble method\u2019). By taking advantage of manually built prior polarity lexica, our ensemble method is better able to predict the prior value of unseen words and to outperform all the other SentiWordNet approaches. Using this technique we have built SentiWords, a prior polarity lexicon of approximately 155,000 words, that has both a high precision and a high coverage. We finally show that in sentiment analysis tasks, using our lexicon allows us to outperform both the single metrics derived from SentiWordNet and popular manually annotated sentiment lexica.", "creator": "LaTeX with hyperref package"}}}