{"id": "1511.01042", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Nov-2015", "title": "Detecting Interrogative Utterances with Recurrent Neural Networks", "abstract": "In this paper, we explore different neural network architectures that can predict if a speaker of a given utterance is asking a question or making a statement. We com- pare the outcomes of regularization methods that are popularly used to train deep neural networks and study how different context functions can affect the classification performance. We also compare the efficacy of gated activation functions that are favorably used in recurrent neural networks and study how to combine multimodal inputs. We evaluate our models on two multimodal datasets: MSR-Skype and CALLHOME.", "histories": [["v1", "Tue, 3 Nov 2015 19:26:16 GMT  (91kb,D)", "http://arxiv.org/abs/1511.01042v1", "6 pages, accepted to NIPS 2015 Workshop on Machine Learning for Spoken Language Understanding and Interaction"], ["v2", "Mon, 16 Nov 2015 03:54:19 GMT  (91kb,D)", "http://arxiv.org/abs/1511.01042v2", "6 pages, accepted to NIPS 2015 Workshop on Machine Learning for Spoken Language Understanding and Interaction"]], "COMMENTS": "6 pages, accepted to NIPS 2015 Workshop on Machine Learning for Spoken Language Understanding and Interaction", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["junyoung chung", "jacob devlin", "hany hassan awadalla"], "accepted": false, "id": "1511.01042"}, "pdf": {"name": "1511.01042.pdf", "metadata": {"source": "CRF", "title": "Detecting Interrogative Utterances with Recurrent Neural Networks", "authors": ["Junyoung Chung", "Jacob Devlin", "Hany Hassan Awadalla"], "emails": ["junyoung.chung@umontreal.ca", "hanyh}@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "Our understanding of language is a long-term goal of machine learning and potentially has huge implications for practical applications. However, the difficulty of processing speech signals itself is a bottleneck, for example, the core part of the language translation needs to be processed in the text domain. In other words, failure to capture the key features in the speech signals can lead to unexpected results in the next applications. Determining whether a given utterance is a question or not can be one of the key features in applications such as language translation. Unfortunately, a speech recognition system is unlikely to achieve two objectives simultaneously: (1) extract text sequences from the input utterances, (2) identify questions. We can imagine a question recognition system that works independently and relieves the burden of the speech recognition system. [15, 10, 4, 14, 3] Later, a remark that a question can form a row with the output of the speech recognition system and is passed on to the machine translation system."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Types of Questions", "text": "Questions can have different canonical forms, and they are usually not standardized, but we can divide the questions into three groups based on some criteria. Table 1 shows an example from each group. We note that declarative questions are rather unclear to distinguish them from non-question statements by looking at their canonical forms, as they do not normally contain wh words. However, audio signals can contain the characteristics that can be useful in making predictions about these types of examples, where a question usually has a rising pitch at the end of the utterance."}, {"heading": "2.2 Neural Networks", "text": "An RNN can process a sequence x = (x1, x2,.., xT) by recursively applying a transitional function g to each symbol: st = g (xt, st \u2212 1), (1), where g is usually a deterministic nonlinear transitional function. g gains extra strength to capture long-term memories when implemented with gated activation functions [6], such as long-term short-term memory [LSTM, 7] or gated recurrent unit [GRU, 5]. We can add additional hidden layers in advance or after the RNN to increase the capacity of the model: zt = h (g (f (xt), st \u2212 1)))), (2), where a sequence z = (z1, z2,..., zT) is the transformed character representation of the input sequence x, and f and h are additional hidden layers. Instead of using the entire contexture we can use a GRC and reduce the dimension function."}, {"heading": "3 Proposed Models", "text": "We use a neural network-based approach where we can stack multiple feedback and recurring layers to learn hierarchical features from the training examples and objective function using stochastic gradient lowering. We consider two types of inputs, namely text transcripts and audio signals of utterances. Depending on the types of inputs used, we can divide the models into three groups: (1) receive text inputs only, (2) receive audio inputs only, and (3) receive both inputs. If a model receives both inputs as (3), we can imagine a simple but naive way to combine two different features, as shown in Figure 1. For a model in each group, it can choose the context function to become either an equation (3) or an equation (4), so that the number of combinations becomes six. However, there is another model that receives both inputs, uses equation (4) as a context function."}, {"heading": "4 Experiment Settings", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets", "text": "MSR-Skype MSR-Skype dataset contains 18,006 examples specified as text-audio pairs, and the proportion of positive and negative examples is well balanced. Each example is an utterance that is manually segmented. We only use examples that contain 3 to 25 words to train the models. We use 80% of the examples as a training set and keep 20% of the examples to validate and evaluate the models. CALLHOME We use a subset of the original CALLHOME, where the text transcripts are created by human commentators. There are 2,528 examples specified as text-audio pairs. Utterances are manually segmented, and the traction / validation / test splits are shared as well as the MSR-Skype datasets. Pre-processing For the text data we remove punctuations, commas, question marks, exclamation marks, exclamation marks to prevent the model from making specific decisions based on these tokens."}, {"heading": "4.2 Results", "text": "In fact, it turns out that the models that have got older are not the first two, but the first to get older."}, {"heading": "5 Conclusion", "text": "We are examining different types of RNN-based architectures for detecting questions in English utterances. We are discovering some features that can help the models achieve better values in detecting questions. Different types of input can complement each other, and the models can benefit from using text and audio sources as inputs. Attention Mechanism (c2) helps the models that receive long audio sequences as inputs. Regulatory methods can help the models to generalize better, but if the models receive multimodal input, we need to be more careful with these regulatory methods."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the developers of Theano [2] and the following research funding and computer support agencies: Microsoft, NSERC, Calcul Que \ufffd bec, Compute Canada, the Canada Research Chairs and CIFAR."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Theano: new features and speed improvements", "author": ["F. Bastien", "P. Lamblin", "R. Pascanu", "J. Bergstra", "I.J. Goodfellow", "A. Bergeron", "N. Bouchard", "Y. Bengio"], "venue": "Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Speaker role recognition using question detection and characterization", "author": ["T. Bazillon", "B. Maza", "M. Rouvier", "F. Bechet", "A. Nasr"], "venue": "In INTERSPEECH,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Any questions? automatic question detection in meetings", "author": ["K. Boakye", "B. Favre", "D. Hakkani-T\u00fcr"], "venue": "In IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["J. Chung", "C. Gulcehre", "K. Cho", "Y. Bengio"], "venue": "In NIPS Workshop on Deep Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Batch normalized recurrent neural networks", "author": ["C. Laurent", "G. Pereyra", "P. Brakel", "Y. Zhang", "Y. Bengio"], "venue": "arXiv preprint arXiv:1510.01378,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Analysis of statistical question classification for fact-based questions", "author": ["D. Metzler", "W.B. Croft"], "venue": "Information Retrieval,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "In Proceedings of the 27th International Conference on Machine Learning (ICML),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Bidirectional recurrent neural networks", "author": ["M. Schuster", "K.K. Paliwal"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1929}, {"title": "Exploiting salient patterns for question detection and question retrieval in community-based question answering", "author": ["K. Wang", "T.-S. Chua"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Detection of questions in chinese conversational speech", "author": ["J. Yuan", "D. Jurafsky"], "venue": "In IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}], "referenceMentions": [{"referenceID": 14, "context": "We can think of a question detection system that works independently and unburdens the load of the speech recognition system [15, 10, 4, 14, 3].", "startOffset": 125, "endOffset": 143}, {"referenceID": 9, "context": "We can think of a question detection system that works independently and unburdens the load of the speech recognition system [15, 10, 4, 14, 3].", "startOffset": 125, "endOffset": 143}, {"referenceID": 3, "context": "We can think of a question detection system that works independently and unburdens the load of the speech recognition system [15, 10, 4, 14, 3].", "startOffset": 125, "endOffset": 143}, {"referenceID": 13, "context": "We can think of a question detection system that works independently and unburdens the load of the speech recognition system [15, 10, 4, 14, 3].", "startOffset": 125, "endOffset": 143}, {"referenceID": 2, "context": "We can think of a question detection system that works independently and unburdens the load of the speech recognition system [15, 10, 4, 14, 3].", "startOffset": 125, "endOffset": 143}, {"referenceID": 9, "context": "Previous studies have focused on using hand-designed features and classifiers such as support vector machines (SVMs) [10, 14] or tree-based classifiers [15, 4, 3].", "startOffset": 117, "endOffset": 125}, {"referenceID": 13, "context": "Previous studies have focused on using hand-designed features and classifiers such as support vector machines (SVMs) [10, 14] or tree-based classifiers [15, 4, 3].", "startOffset": 117, "endOffset": 125}, {"referenceID": 14, "context": "Previous studies have focused on using hand-designed features and classifiers such as support vector machines (SVMs) [10, 14] or tree-based classifiers [15, 4, 3].", "startOffset": 152, "endOffset": 162}, {"referenceID": 3, "context": "Previous studies have focused on using hand-designed features and classifiers such as support vector machines (SVMs) [10, 14] or tree-based classifiers [15, 4, 3].", "startOffset": 152, "endOffset": 162}, {"referenceID": 2, "context": "Previous studies have focused on using hand-designed features and classifiers such as support vector machines (SVMs) [10, 14] or tree-based classifiers [15, 4, 3].", "startOffset": 152, "endOffset": 162}, {"referenceID": 0, "context": "Our question detection system runs as fast as other real-time systems at the test time, receives multimodal inputs and returns a scalar score value \u0177 \u2208 [0, 1].", "startOffset": 152, "endOffset": 158}, {"referenceID": 5, "context": "g gains extra strength to capture long-term memories when implemented with gated activation functions [6] such as long short-term memory [LSTM, 7] or gated recurrent unit [GRU, 5].", "startOffset": 102, "endOffset": 105}, {"referenceID": 4, "context": "The context function c can be either defined as introduced in [5]:", "startOffset": 62, "endOffset": 65}, {"referenceID": 0, "context": "or as introduced in [1]:", "startOffset": 20, "endOffset": 23}, {"referenceID": 10, "context": "In this study, we implement f and hwith deep neural networks (DNNs) using fully-connected layers and rectified linear units [11] as non-linearity, g with a recurrent layer using either GRU or LSTM as the state transition function, and the context function c with either Eq.", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "We implement the RNN with its bidirectional variant [12].", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "For each model in each group, we train it with three different ways: (1) without any regularization methods, (2) use dropout [13] and (3) use batch normalization (BN) [8] (note that we are not the first to apply batch normalization to a neural network architecture that contains an RNN [9]).", "startOffset": 125, "endOffset": 129}, {"referenceID": 7, "context": "For each model in each group, we train it with three different ways: (1) without any regularization methods, (2) use dropout [13] and (3) use batch normalization (BN) [8] (note that we are not the first to apply batch normalization to a neural network architecture that contains an RNN [9]).", "startOffset": 167, "endOffset": 170}, {"referenceID": 8, "context": "For each model in each group, we train it with three different ways: (1) without any regularization methods, (2) use dropout [13] and (3) use batch normalization (BN) [8] (note that we are not the first to apply batch normalization to a neural network architecture that contains an RNN [9]).", "startOffset": 286, "endOffset": 289}, {"referenceID": 0, "context": "The lengths of the audio sequences are usually longer than the text sequences, and attention mechanism (c2) [1] is known to be a nice solution to deal with long sequences.", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "The authors would like to thank the developers of Theano [2].", "startOffset": 57, "endOffset": 60}], "year": 2017, "abstractText": "In this paper, we explore different neural network architectures that can predict if a speaker of a given utterance is asking a question or making a statement. We compare the outcomes of regularization methods that are popularly used to train deep neural networks and study how different context functions can affect the classification performance. We also compare the efficacy of gated activation functions that are favorably used in recurrent neural networks and study how to combine multimodal inputs. We evaluate our models on two multimodal datasets: MSR-Skype and CALLHOME.", "creator": "LaTeX with hyperref package"}}}