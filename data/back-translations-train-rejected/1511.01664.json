{"id": "1511.01664", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2015", "title": "Stochastic Proximal Gradient Descent for Nuclear Norm Regularization", "abstract": "In this paper, we utilize stochastic optimization to reduce the space complexity of convex composite optimization with a nuclear norm regularizer, where the variable is a matrix of size $m \\times n$. By constructing a low-rank estimate of the gradient, we propose an iterative algorithm based on stochastic proximal gradient descent (SPGD), and take the last iterate of SPGD as the final solution. The main advantage of the proposed algorithm is that its space complexity is $O(m+n)$, in contrast, most of previous algorithms have a $O(mn)$ space complexity. Theoretical analysis shows that it achieves $O(\\log T/\\sqrt{T})$ and $O(\\log T/T)$ convergence rates for general convex functions and strongly convex functions, respectively.", "histories": [["v1", "Thu, 5 Nov 2015 09:24:13 GMT  (15kb)", "https://arxiv.org/abs/1511.01664v1", null], ["v2", "Sat, 5 Dec 2015 08:02:25 GMT  (15kb)", "http://arxiv.org/abs/1511.01664v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lijun zhang", "tianbao yang", "rong jin", "zhi-hua zhou"], "accepted": false, "id": "1511.01664"}, "pdf": {"name": "1511.01664.pdf", "metadata": {"source": "CRF", "title": "Stochastic Proximal Gradient Descent for Nuclear Norm Regularization", "authors": ["Lijun Zhang", "Tianbao Yang", "Rong Jin", "Zhi-Hua Zhou"], "emails": ["zhanglj@lamda.nju.edu.cn", "tianbao-yang@uiowa.edu", "rongjin@cse.msu.edu", "zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 151 1.01 664v 2 [cs \u221a T) and O (log T / T) convergence rates for general convex functions and strongly convex functions respectively. Keywords: Stochastic Proximal Gradient Descent, Nuclear Norm Regularization"}, {"heading": "1. Introduction", "text": "In this paper, we take a different perspective and use stochastic optimization as a tool to reduce spatial complexity for certain problems."}, {"heading": "2.1 Construction of the Low-rank Stochastic Gradients", "text": "For this purpose we need the following definition by Avron et al. (2012). Definition 1 (Probing Matrix) A random n \u00b7 k matrix Y is a random matrix that is drawn when E [Y Y's] = I.Avron et al. (2012) also provides multiple distribution families for the efficient generation of sample matrices. Lemma 2 Let Y = Z / \u221a k, where Z is a random matrix that is drawn each of the following distributions: 1. Independent entries that assume values + 1 and \u2212 1 with equal probability, 1 / 2.2. Independent and identically distributed standard normal centers. 3. Each column of Z is drawn formally randomly and independently of each other."}, {"heading": "2.2 Efficient Implementation of the Updating", "text": "During the optimization process, all iterates Wt are represented in the SVD form Wt = U't tV t, which requires O (m + n) rt memory. In this case, rt is the rank of Wt. By taking advantage of the fact that G-t = AtB t is also represented in a lower factorization form, we can efficiently implement the update rule in (2) if W = Rm \u00b7 n or W = [W | W] Rm \u00b7 n, HW = F \u2264 R}. We start with the incremental SVD, which represents a core operation during the upgrade."}, {"heading": "2.2.1 Incremental SVD", "text": "Then the economics SVD of X + AB's can be calculated in O (m + n) (r + c) (r + c) 2 + (r + c) 3) time with O (m + n) (r + c)) memory. We provide a detailed procedure below (Brand, 2006, Section 2). Let P be an orthogonal basis for the column space of (I \u2212 UU) A and set RA = P (I \u2212 UU) A. Note that Cols (P) = rows (RA) = rank (I \u2212 UU) A) \u2264 c and zero if A is in the column space of U \u2212 UU. Then we have [U A] = [U P] [I U A 0 RA 0] [RB V] an orthogonal basis for the column space of (I \u2212 UU]."}, {"heading": "2.2.2 Updating for Unbounded Domain", "text": "We first introduce the operator Singular Value Shrinkage (SVS) with the threshold \u03bb, which is denoted by D\u03bb [\u00b7] (Cai et al., 2010). For a matrix Y-Rm \u00b7 n with the Singular Value Shrinkage (SVS) with the threshold \u03bb, which is denoted by Diag (\u03c31,.., \u03c3min (m, n), we have a matrix Y-Rm \u00b7 n with the Singular Value Shrinkage (SVS), where we have a matrix Y-Rm \u00b7 n. The following theory shows that D\u03bb [Y] is the optimal solution for an unlimited smallest square problem with the nuclear standard regularization (Cai et al., 2010, theorem 2,1 \u2212 \u03bb). Theorem 1 For each individual step D-Rm \u00b7 n, which is not implied."}, {"heading": "2.2.3 Updating for Frobenius Norm Ball", "text": "To facilitate the presentation, we are introducing the metric projection operator on the Frobenius standard ball with the x-x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "3. Analysis", "text": "The convergence of the last iteration of SGD was analyzed by Rakhlin et al. (2012) and Shamir and Zhang (2012). By extending their analysis, we provide the convergence of SPGD to solve the problem regulated by the atomic standard in (1). The following theorem shows that the last iteration for general convex functions has a convergence rate of O (log T / \u221a T). Theorem 3 assumes that there are constants G and D that are such that E [\u0102G-t-2F] \u2264 G2 for all t and supW, W \u00b2 W \u00b2 W \u2212 W \u00b2 T \u2264 D. If we set a convergence of T = c / \u221a T, we have a convergence of F (WT) \u2212 F (W \u00b2) \u2264 (D2c + c + c (G2 + 16r\u03bb2 + 4\u043aG-W)."}, {"heading": "3.1 Proof of Theorem 3", "text": "The proof is an extension of Theorem 2 in Shamir and Zhang (2012), which implies a similar guarantee for the last stage of SGD. Of the property strongly convex, i.e., (2) by Hazan and Kale (2011), the updating rule in (2) implies 1 2) Wt + 1 (Wt + 1) Wt + 1 (Wt) < Wt + 1 \u2212 Wt \u2212 2 (Wt) Wt (Wt) 2 (Wt) 2 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt 4 (Wt) 4 (Wt) 4 (Wt) 4 (Wt), 4 (Wt) 4 (Wt (Wt) 4 (Wt) 4 (Wt), 4 (Wt (Wt) 4 (Wt) 4 (Wt (Wt), 5) 5 (Wt (Wt (Wt) 4, 5) 4 (Wt (Wt), 5), 4 (Wt (5), 4 (Wt (Wt), 5), 4 (Wt (5), 4 (Wt (5), 5), 4 (Wt (Wt), 5), 4 (Wt (Wt)"}, {"heading": "3.2 Proof of Lemma 3", "text": "The proof is similar to that of Lemma 1 in (Rakhlin et al., 2012), which is similar to the analysis of the behaviour of SGD. Using the fact that f (\u00b7) is \"strongly convex,\" (11) it becomes a \"strongly convex\" (Wt) + \"strongly convex\" (W) \u2212 \"W\" (G) \u2212 \"W\" (G) \u2212 \"G\" (G) \u2212 \"G\" (G) \u2212 \"W\" (G) \u2212 \"W\" (G) \u2212 T \"(G) \u2212 T\" (G) \u2212 T \"G\" (G) \u2212 T \"W\" (G) \u2212 T \"W\" (G) \u2212 T \"W\" (W) \u2212 T \"W\" (W) \u2212 T \"W\" (W) \u2212 W \"(W)."}, {"heading": "3.3 Proof of Theorem 4", "text": "The proof is similar to that of theorem 1 in Shamir and Zhang (2012), and therefore we show only the difference.If we follow the derivative of (14), we have for all W-W-W [T-T = T-k F (Wt) \u2212 F (W)] \u2264 E [E-W-WT \u2212 k \u2212 k \u00b2 2F] 2\u03b7T \u2212 k + T-T = T-k + 1E [E-W \u2212 Wt \u00b2 2F] 2 (1E-T \u2212 1) + 12 (G2 + 16rp \u00b2 + 4E) T-T = T \u2212 k \u00b2 t (19) reservedE [< Wt \u2212 W, E [G-T] \u2212 G-T >] = 0, T \u2212 k. If we replace this T = 1 / (\u00b5t), (19) it becomes E [T-k \u00b2 T (Wt) \u2212 F (W) \u2212 G-T >] = 0, we can replace this T = 1 / (\u00b5t) 2K \u00b2 K (W \u00b2) (2K)."}, {"heading": "4. Conclusion", "text": "In this paper, we propose a memory-efficient algorithm for solving the problem regulated by the core standard in (1). Compared to previous studies, the proposed algorithm has two advantages: i) its spatial complexity is O (m + n) instead of O (mn) and ii) it is equipped with a formal convergence rate.The spatial complexity of our algorithm also depends on the rank of the intermediate iterate Wt. Although Wt tends to be a low-ranking matrix due to the regulator of the core standards, an explicit upper limit on its rank is unknown. This problem will be investigated in future work. We will also investigate whether it is possible to derive efficient updates for other areas of matrices, such as the spectral standard Ball."}, {"heading": "Appendix A. Proof of Theorem 2", "text": "We consider two cases as: Theory 1 states that the solution to an unqualified optimization problem in (3) is the optimal solution for (4).A.2 for (Y).F > R We denote the singular values of Y by (1, 2,... From (3) we know that X1 2 x (Y).2 x (Y).2 x (X).2 x (X).2 x (X).2 x (F).2 x (X).2 x (F < 2 x).2 x (F).2 x (F).2 x (F).2 x (Z).2 x (Z).2 x (Z).2 x (Z).2 x (Z).2 x (Z)."}], "references": [{"title": "Efficient and practical stochastic subgradient descent for nuclear norm regularization", "author": ["Haim Avron", "Satyen Kale", "Shiva Kasiviswanathan", "Vikas Sindhwani"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Avron et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Avron et al\\.", "year": 2012}, {"title": "Convex Optimization", "author": ["Stephen Boyd", "Lieven Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Fast low-rank modifications of the thin singular value decomposition", "author": ["Matthew Brand"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "Brand.,? \\Q2006\\E", "shortCiteRegEx": "Brand.", "year": 2006}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["Jian-Feng Cai", "Emmanuel J. Cand\u00e8s", "Zuowei Shen"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Cai et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Cai et al\\.", "year": 1956}, {"title": "Efficient low-rank stochastic gradient descent methods for solving semidefinite programs", "author": ["Jianhui Chen", "Tianbao Yang", "Shenghuo Zhu"], "venue": "In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Beyond the regret minimization barrier: an optimal algorithm for stochastic strongly-convex optimization", "author": ["Elad Hazan", "Satyen Kale"], "venue": "In Proceedings of the 24th Annual Conference on Learning Theory,", "citeRegEx": "Hazan and Kale.,? \\Q2011\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2011}, {"title": "Accelerated gradient methods for stochastic optimization and online learning", "author": ["Chonghai Hu", "James Kwok", "Weike Pan"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2009}, {"title": "An optimal method for stochastic composite optimization", "author": ["Guanghui Lan"], "venue": "Mathematical Programming,", "citeRegEx": "Lan.,? \\Q2012\\E", "shortCiteRegEx": "Lan.", "year": 2012}, {"title": "A sparsity preserving stochastic gradient method for composite optimization", "author": ["Qihang Lin", "Xi Chen", "Javier Pe\u00f1a"], "venue": "Computational Optimization and Applications,", "citeRegEx": "Lin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2011}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nemirovski et al\\.", "year": 2009}, {"title": "Gradient methods for minimizing composite functions", "author": ["Yu. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov.,? \\Q2013\\E", "shortCiteRegEx": "Nesterov.", "year": 2013}, {"title": "Making gradient descent optimal for strongly convex stochastic optimization", "author": ["Alexander Rakhlin", "Ohad Shamir", "Karthik Sridharan"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Rakhlin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rakhlin et al\\.", "year": 2012}, {"title": "Stochastic convex optimization", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "In Proceedings of the 22nd Annual Conference on Learning Theory,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes", "author": ["Ohad Shamir", "Tong Zhang"], "venue": "ArXiv e-prints,", "citeRegEx": "Shamir and Zhang.,? \\Q2012\\E", "shortCiteRegEx": "Shamir and Zhang.", "year": 2012}, {"title": "O(log T ) projections for stochastic optimization of smooth and strongly convex functions", "author": ["Lijun Zhang", "Tianbao Yang", "Rong Jin", "Xiaofei He"], "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML),", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 6, "context": "Stochastic optimization has received lots of attention recently in data mining and machine learning communities (Hu et al., 2009; Shalev-Shwartz et al., 2009; Zhang et al., 2013).", "startOffset": 112, "endOffset": 178}, {"referenceID": 12, "context": "Stochastic optimization has received lots of attention recently in data mining and machine learning communities (Hu et al., 2009; Shalev-Shwartz et al., 2009; Zhang et al., 2013).", "startOffset": 112, "endOffset": 178}, {"referenceID": 14, "context": "Stochastic optimization has received lots of attention recently in data mining and machine learning communities (Hu et al., 2009; Shalev-Shwartz et al., 2009; Zhang et al., 2013).", "startOffset": 112, "endOffset": 178}, {"referenceID": 9, "context": "It is generally formulated as a minimization problem where the objective is an expectation over unknown distributions (Nemirovski et al., 2009), or defined in terms of the access model, which assumes there is a stochastic oracle that generates unbiased estimate of the objective or its gradient (Hazan and Kale, 2011).", "startOffset": 118, "endOffset": 143}, {"referenceID": 5, "context": ", 2009), or defined in terms of the access model, which assumes there is a stochastic oracle that generates unbiased estimate of the objective or its gradient (Hazan and Kale, 2011).", "startOffset": 159, "endOffset": 181}, {"referenceID": 10, "context": "Note that the above problem is a special case of convex composite optimization (Nesterov, 2013).", "startOffset": 79, "endOffset": 95}, {"referenceID": 10, "context": "This setting excludes deterministic methods for solving (1) (Nesterov, 2013), as they need to evaluate the gradient of f(\u00b7), which needs O(mn) memory.", "startOffset": 60, "endOffset": 76}, {"referenceID": 8, "context": "Although various stochastic algorithms has been proposed for convex composite optimization and can also be applied to (1), their primal goal is to reduce the time complexity of evaluating the gradient of f(\u00b7) instead of the space complexity (Lin et al., 2011; Lan, 2012).", "startOffset": 241, "endOffset": 270}, {"referenceID": 7, "context": "Although various stochastic algorithms has been proposed for convex composite optimization and can also be applied to (1), their primal goal is to reduce the time complexity of evaluating the gradient of f(\u00b7) instead of the space complexity (Lin et al., 2011; Lan, 2012).", "startOffset": 241, "endOffset": 270}, {"referenceID": 11, "context": "Built upon recent progresses in stochastic optimization (Rakhlin et al., 2012; Shamir and Zhang, 2012), we further analyze the convergence property of the proposed algorithm, and show that the last iterate has an O(log T/ \u221a T ) convergence rate for general convex functions, and an O(log T/T ) rate for strongly convex functions.", "startOffset": 56, "endOffset": 102}, {"referenceID": 13, "context": "Built upon recent progresses in stochastic optimization (Rakhlin et al., 2012; Shamir and Zhang, 2012), we further analyze the convergence property of the proposed algorithm, and show that the last iterate has an O(log T/ \u221a T ) convergence rate for general convex functions, and an O(log T/T ) rate for strongly convex functions.", "startOffset": 56, "endOffset": 102}, {"referenceID": 0, "context": "The only memory-efficient algorithm for solving (1) that we found in the literature is a heuristic algorithm developed by Avron et al. (2012). Under the condition that it is possible to generate a stochastic gradient of f(\u00b7) which is also low-rank, they propose to combine SGD and truncated SVD to solve (1).", "startOffset": 122, "endOffset": 142}, {"referenceID": 0, "context": "The only memory-efficient algorithm for solving (1) that we found in the literature is a heuristic algorithm developed by Avron et al. (2012). Under the condition that it is possible to generate a stochastic gradient of f(\u00b7) which is also low-rank, they propose to combine SGD and truncated SVD to solve (1). By representing all the intermediate solutions and stochastic gradients in low-rank factorization forms, the space complexity can be reduced to O(m+n). The major limitation of this approach is that there is no theoretical guarantee about its convergence, due to the fact that the truncated SVD operation introduces a constant error in each iteration. Furthermore, when the objective value is difficult to calculate, it is also unclear which iterate should be used as the final solution. Inspired by the previous studies, we develop a novel stochastic algorithm that optimizes (1) in a memory-efficient way and is supported by formal theoretical guarantees. Specifically, we propose to use stochastic proximal gradient descent (SPGD) instead of SGD to solve (1), and take the last iterate of SPGD as the final solution. Similar to the heuristic algorithm of Avron et al. (2012), the proposed algorithm always maintains a low-rank factorization of iterates that can be conveniently held in memory, and both the time and space complexities in each iteration are O(m+n).", "startOffset": 122, "endOffset": 1186}, {"referenceID": 0, "context": "The existence and construction of such a low-rank matrix can be found in previous studies (Avron et al., 2012; Chen et al., 2014), and will be discussed later.", "startOffset": 90, "endOffset": 129}, {"referenceID": 4, "context": "The existence and construction of such a low-rank matrix can be found in previous studies (Avron et al., 2012; Chen et al., 2014), and will be discussed later.", "startOffset": 90, "endOffset": 129}, {"referenceID": 0, "context": "The existence and construction of such a low-rank matrix can be found in previous studies (Avron et al., 2012; Chen et al., 2014), and will be discussed later. Denote by Wt the solution at the t-th iteration, and let \u011ct = AtB \u22a4 t be the low-rank stochastic gradient of f(\u00b7) at Wt. Then, we update the current solution by the SPGD, which is a stochastic variant of composite gradient mapping Nesterov (2013)", "startOffset": 91, "endOffset": 407}, {"referenceID": 0, "context": "1 Construction of the Low-rank Stochastic Gradients For a given matrix W , there are various ways to construct a low-rank stochastic gradient \u011c satisfying E[\u011c] \u2208 \u2202f(W ) (Avron et al., 2012; Chen et al., 2014).", "startOffset": 169, "endOffset": 208}, {"referenceID": 4, "context": "1 Construction of the Low-rank Stochastic Gradients For a given matrix W , there are various ways to construct a low-rank stochastic gradient \u011c satisfying E[\u011c] \u2208 \u2202f(W ) (Avron et al., 2012; Chen et al., 2014).", "startOffset": 169, "endOffset": 208}, {"referenceID": 0, "context": "1 Construction of the Low-rank Stochastic Gradients For a given matrix W , there are various ways to construct a low-rank stochastic gradient \u011c satisfying E[\u011c] \u2208 \u2202f(W ) (Avron et al., 2012; Chen et al., 2014). For brevity, we just describe a general approach. To this end, we need the following definition from Avron et al. (2012). Definition 1 (Probing Matrix) A random n\u00d7k matrix Y is a probing matrix if E[Y Y \u22a4] = I.", "startOffset": 170, "endOffset": 331}, {"referenceID": 11, "context": "Analysis The convergence of the last iterate of SGD has been analyzed by Rakhlin et al. (2012) and Shamir and Zhang (2012).", "startOffset": 73, "endOffset": 95}, {"referenceID": 11, "context": "Analysis The convergence of the last iterate of SGD has been analyzed by Rakhlin et al. (2012) and Shamir and Zhang (2012). By extending their analysis, we provide the convergence of SPGD for solving the nuclear norm regularized problem in (1).", "startOffset": 73, "endOffset": 123}, {"referenceID": 12, "context": "1 Proof of Theorem 3 The proof is an extension of Theorem 2 in Shamir and Zhang (2012), which establishes a similar guarantee for the last iterate of SGD.", "startOffset": 63, "endOffset": 87}, {"referenceID": 5, "context": ", (2) of Hazan and Kale (2011), the updating rule in (2) implies 1 2 \u2016Wt+1 \u2212Wt\u2016F + \u03b7t\u3008Wt+1 \u2212Wt, \u011ct\u3009+ \u03b7t\u03bb\u2016Wt+1\u2016\u2217 \u2264 2 \u2016W \u2212Wt\u2016F + \u03b7t\u3008W \u2212Wt, \u011ct\u3009+ \u03b7t\u03bb\u2016W\u2016\u2217 \u2212 1 2 \u2016W \u2212Wt+1\u2016F for all W \u2208 W.", "startOffset": 9, "endOffset": 31}, {"referenceID": 13, "context": "Then, it is straightforward to prove this theorem by following the arguments of Theorem 2 in Shamir and Zhang (2012). Specifically, we just need to replace (5) in Shamir and Zhang (2012) with (14) in this paper, and the rest is identical.", "startOffset": 93, "endOffset": 117}, {"referenceID": 13, "context": "Then, it is straightforward to prove this theorem by following the arguments of Theorem 2 in Shamir and Zhang (2012). Specifically, we just need to replace (5) in Shamir and Zhang (2012) with (14) in this paper, and the rest is identical.", "startOffset": 93, "endOffset": 187}, {"referenceID": 11, "context": "2 Proof of Lemma 3 The proof of is similar to that of Lemma 1 in (Rakhlin et al., 2012), which is devoted to analyze the behavior of SGD.", "startOffset": 65, "endOffset": 87}, {"referenceID": 13, "context": "3 Proof of Theorem 4 The proof is similar to that of Theorem 1 in Shamir and Zhang (2012), and thus we just show the difference.", "startOffset": 66, "endOffset": 90}, {"referenceID": 13, "context": "Then, Theorem 4 can be proved by replacing (2) in Shamir and Zhang (2012) with (20) in this paper.", "startOffset": 50, "endOffset": 74}, {"referenceID": 1, "context": "Following the standard analysis of convex optimization (Boyd and Vandenberghe, 2004), we introduce a dual variable \u03bc for the constraint and obtain the Lagrange dual function", "startOffset": 55, "endOffset": 84}], "year": 2015, "abstractText": "In this paper, we utilize stochastic optimization to reduce the space complexity of convex composite optimization with a nuclear norm regularizer, where the variable is a matrix of size m \u00d7 n. By constructing a low-rank estimate of the gradient, we propose an iterative algorithm based on stochastic proximal gradient descent (SPGD), and take the last iterate of SPGD as the final solution. The main advantage of the proposed algorithm is that its space complexity is O(m + n), in contrast, most of previous algorithms have a O(mn) space complexity. Theoretical analysis shows that it achieves O(log T/ \u221a T ) and O(log T/T ) convergence rates for general convex functions and strongly convex functions, respectively.", "creator": "LaTeX with hyperref package"}}}