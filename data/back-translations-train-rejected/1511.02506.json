{"id": "1511.02506", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2015", "title": "Towards Structured Deep Neural Network for Automatic Speech Recognition", "abstract": "In this paper we propose the Structured Deep Neural Network (structured DNN) as a structured and deep learning framework. This approach can learn to find the best structured object (such as a label sequence) given a structured input (such as a vector sequence) by globally considering the mapping relationships between the structures rather than item by item.", "histories": [["v1", "Sun, 8 Nov 2015 17:08:54 GMT  (385kb,D)", "http://arxiv.org/abs/1511.02506v1", "arXiv admin note: text overlap witharXiv:1506.01163"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1506.01163", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["yi-hsiu liao", "hung-yi lee", "lin-shan lee"], "accepted": false, "id": "1511.02506"}, "pdf": {"name": "1511.02506.pdf", "metadata": {"source": "CRF", "title": "TOWARDS STRUCTURED DEEP NEURAL NETWORK FOR AUTOMATIC SPEECH RECOGNITION", "authors": ["Yi-Hsiu Liao", "Hung-yi Lee", "Lin-shan Lee"], "emails": ["r03921048@ntu.edu.tw,", "hungyilee@ntu.edu.tw,", "lslee@gate.sinica.edu.tw"], "sections": [{"heading": null, "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}, {"heading": "2.1. Structured Learning Concept", "text": "In structured learning, both the desired results y and the input objects x can be sequences, trees, grids or graphs, rather than just classes or real numbers. As part of supervised phoneme recognition learning for expressions, we receive a series of training expressions (x1, y1),..., (xN, yN), where xi is the acoustic vector sequence of the ith expression, yi is the corresponding reference phoneme label sequence, and we want to assign correct phoneme label sequences to unknown expressions. One way to achieve this is to assign any phoneme label sequence y to an acoustic vector sequence x: X \u2192 Y, assigning each acoustic vector sequence x to a phoneme label sequence y, where the parameter set y is one way to achieve this is to assign any phoneme label sequence y, by assigning an acoustic vector sequence x to a phoneme label sequence x (x), and a punctuation Y (x: highest)."}, {"heading": "2.2. Structured SVM", "text": "Based on SVM's maximized margin concept, we want to maximize not only the score of the correct labeling sequence (> effector function), but also the margin between the score of the correct labeling sequence and the results of the next wrong labeling sequences as shown in Figure 2. In Figure 2, yi is the correct labeling sequence, and all other erroneous labeling sequences are in blue. The score of the correct labeling sequence F1 (x, yk; Phenomen1) is higher than the highest score among the false labeling sequences, F1 (x, yk; Phenomen1), after \u2206 (yi, yk), which is the difference between the results of the two sequences yi and yk. All erroneous labeling sequences are lower than the values of the correct sequence (yi, yk) or the margin. Maximizing this margin is the learning goal of the structured SVM. The structured SVM used in the SVM function is as shown below."}, {"heading": "2.3. Structured Deep Neural Network (Structured DNN)", "text": "The assumption of the linear scoring function as in (2) limits the structured SVM. Instead, the proposed structured DNN uses a series of nonlinear transformations to form the scoring function F2 (x, y; \u03b82) with hidden L layers to evaluate a single output value F2 (x, y; \u03b82) as in Figure 1 (c).h1 = \u03c3 (W0 \u00b7 (x, y)) hl = \u03c3 (Wl \u2212 1 \u00b7 hl \u2212 1), 2 \u2264 l \u2264 LF2 (x, y; \u03b82) = \u03c3 (WL \u00b7 hL), (5) where Wi is a weight matrix (including the preload) of the layer i, \u03c3 (\u00b7) is a nonlinear transformation (sigmoid is used here), hi is the output vector of the hidden layer i and the set of all DNN parameters (W0, W1, W2,..., WL)."}, {"heading": "2.3.1. Approximating phoneme accuracy (Approx. Ph. Acc)", "text": "Firstly, the phoneme accuracy of a label sequence y is defined as C (yi, y) = 1 \u2212 \u2206 (yi, y), where yi is the correct label sequence, and \u2206 (yi, y) is the phoneme error rate of y for the correct label sequence yi. The parameter set \u03b82 of the structured DNN can be trained by minimizing the following loss function: L (\u03b82) = N \u2211 i = 1 x Y [C (yi, y) \u2212 F2 (xi, y)] 2. (6) By minimizing (6) the DNN learns to minimize the mean square error between its output F2 (xi, y; \u03b82) for xi and y and the phoneme accuracy of y, C (yi, y) for all training expressions and for each expression, all possible phoneme sequences y-Y. In other words, the score function F2 (cty; sub-2) for all phoneme sequences, C (yi), Y and Y (y) for all possible phonemy and Y (C) expression."}, {"heading": "2.3.2. Maximizing the margin (Max. Margin)", "text": "Inspired by the maximum margin concept of structured SVM, we replace the linear part of structured SVM with non-linear DNN in order to use both DNN and maximum margin. Therefore, the proposed structured DNN optimizes the following formula: min \u03b82, 2 + C N \u2211 i = 1 L \u2032 i (\u03b82), L \u2032 i (\u03b82) = \u2211 y max (0, F2 (xi, y; \u03b82) + \u0445 (yi, y) \u2212 F2 (xi, yi; \u03b82))))) (7) L \u2032 i (\u03b82) in (7) is parallel to Li (\u03b81) in (4), except that succ1 and F1 (.) in (4) are replaced by \u03b82 and F2 (.) in (7), while the outer max operator in (4) is replaced by summation1. Since the loss function L \u2032 i (\u03b82) would be greater than zero if F2 (xi, y; approximate) + 2 (proportional), if we are not proportional (DNY)."}, {"heading": "2.4. Inference with Structured DNN", "text": "With the structured DNN trained as above, given the acoustic vector sequence x of an unknown utterance, we must find the best phoneme labeling sequence y for it. For structured SVM in Section 2.2, the learned model parameter \u03b81, based on the linear assumption, contains enough information to execute the Viterbi algorithm to find the best labeling sequence. This does not apply to structured DNN. From (1) we must principally search for the given acoustic vector sequence via all possible phoneme labeling sequences (KM for K-phonemes and M-acoustic vectors) and select the one that yields the highest number of points, which is mathematically impossible to do. Instead of searching through all possible phoneme labeling sequences (KM for K-phonemes and M-acoustic vectors), we first decrypt x using WFST to create a grid, and then search for the phoneme labeling sequences in1We replace the outer max labeling sequences in this manner (4) with SVM structured in the above manner."}, {"heading": "2.5. Training of Structured DNN", "text": "In structured SVM, we are able to find training examples due to the linear property in order to generate the maximum margin. In structured DNN, it is important how to find and select effective training examples. Besides the positive examples (reference phoneme labelling sequences for training expressions), in this thesis negative examples (other than reference labelling sequences) are selected both randomly and from the grid decoded by WFST. For each training expression with grid, the negative examples have three sources: (a) N completely random sequences, (b) N random paths on the grid and (c) the N-best paths on the grid."}, {"heading": "2.6. Full-scale structured DNN (FSDNN)", "text": "In this case, we can spread the errors of the structured DNN throughout the entire configuration, in which all parameters from the filter bank to the entire message scale from the message scale to the message scale from the message scale to the entire message scale from the message scale to the message scale from the message scale to the message scale from the message scale to the message scale. FSDNN can be considered a special case (or as a structured version) of the Convolutional Neural Network [25], which works perfectly in computer vision and speech recognition [26]."}], "references": [{"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural computation, vol. 18, no. 7, pp. 1527\u20131554, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Geoffrey E Hinton", "Ruslan R Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["George E Dahl", "Dong Yu", "Li Deng", "Alex Acero"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Acoustic modeling using deep belief networks", "author": ["Abdel-rahman Mohamed", "George E Dahl", "Geoffrey Hinton"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 20, no. 1, pp. 14\u201322, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["Geoffrey Hinton", "Li Deng", "Dong Yu", "George E Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N Sainath"], "venue": "Signal Processing Magazine, IEEE, vol. 29, no. 6, pp. 82\u201397, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Acoustic modeling with deep neural networks using raw time signal for lvcsr", "author": ["Zolt\u00e1n T\u00fcske", "Pavel Golik", "Ralf Schl\u00fcter", "Hermann Ney"], "venue": "Proceedings of the Annual Conference of International Speech Communication Association (INTERSPEECH), 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep vs. wide: depth on a budget for robust speech recognition", "author": ["Oriol Vinyals", "Nelson Morgan"], "venue": "INTERSPEECH, 2013, pp. 114\u2013118.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Subspace gaussian mixture models for speech recognition", "author": ["Daniel Povey", "Lukas Burget", "Mohit Agarwal", "Pinar Akyazi", "Kai Feng", "Arnab Ghoshal", "Ondrej Glembek", "Nagendra K Goel", "Martin Karafi\u00e1t", "Ariya Rastrow"], "venue": "Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on. IEEE, 2010, pp. 4330\u20134333.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando CN Pereira"], "venue": "2001.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons", "author": ["Andrew McCallum", "Wei Li"], "venue": "Proceedings of the seventh conference on Natural language  learning at HLT-NAACL 2003-Volume 4. Association for Computational Linguistics, 2003, pp. 188\u2013191.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Hidden conditional random fields for phone classification", "author": ["Asela Gunawardana", "Milind Mahajan", "Alex Acero", "John C Platt"], "venue": "INTERSPEECH, 2005, pp. 1117\u20131120.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "A segmental crf approach to large vocabulary continuous speech recognition", "author": ["Geoffrey Zweig", "Patrick Nguyen"], "venue": "Automatic Speech Recognition & Understanding, 2009. ASRU 2009. IEEE Workshop on. IEEE, 2009, pp. 152\u2013157.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Hidden conditional random fields for phone recognition", "author": ["Yun-Hsuan Sung", "Daniel Jurafsky"], "venue": "Automatic Speech Recognition & Understanding, 2009. ASRU 2009. IEEE Workshop on. IEEE, 2009, pp. 107\u2013 112.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep-structured hidden conditional random fields for phonetic recognition", "author": ["Dong Yu", "Li Deng"], "venue": "IN- TERSPEECH. Citeseer, 2010, pp. 2986\u20132989.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Large margin methods for structured and interdependent output variables", "author": ["Ioannis Tsochantaridis", "Thorsten Joachims", "Thomas Hofmann", "Yasemin Altun"], "venue": "Journal of Machine Learning Research, 2005, pp. 1453\u2013 1484.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Structured support vector machines for noise robust continuous speech recognition", "author": ["Shi-Xiong Zhang", "Mark JF Gales"], "venue": "INTERSPEECH, 2011, pp. 989\u2013990.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Structured svms for automatic speech recognition", "author": ["Shi-Xiong Zhang", "Mark JF Gales"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 21, no. 3, pp. 544\u2013555, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "An initial attempt for phoneme recognition using structured support vector machine (svm)", "author": ["Hao Tang", "Chao-Hong Meng", "Lin-Shan Lee"], "venue": "Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on. IEEE, 2010, pp. 4926\u20134929.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "A training algorithm for optimal margin classifiers", "author": ["Bernhard E Boser", "Isabelle M Guyon", "Vladimir N Vapnik"], "venue": "Proceedings of the fifth annual workshop on Computational learning theory. ACM, 1992, pp. 144\u2013 152.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "Deep neural support vector machines for speech recognition", "author": ["Shi-Xiong Zhang", "Chaojun Liu", "Kaisheng Yao", "Yifan Gong"], "venue": ".", "citeRegEx": "21", "shortCiteRegEx": null, "year": 0}, {"title": "Integrating deep neural networks into structural classification approach based on weighted finite-state transducers", "author": ["Yotaro Kubo", "Takaaki Hori", "Atsushi Nakamura"], "venue": "INTERSPEECH, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Cutting-plane training of structural svms", "author": ["Thorsten Joachims", "Thomas Finley", "Chun- Nam John Yu"], "venue": "Machine Learning, vol. 77, no. 1, pp. 27\u201359, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Face recognition: A convolutional neural-network approach", "author": ["Steve Lawrence", "C Lee Giles", "Ah Chung Tsoi", "Andrew D Back"], "venue": "Neural Networks, IEEE Transactions on, vol. 8, no. 1, pp. 98\u2013113, 1997.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Convolutional networks for images, speech, and time series", "author": ["Yann LeCun", "Yoshua Bengio"], "venue": "The handbook of brain theory and neural networks, vol. 3361, no. 10, 1995.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1995}, {"title": "Speaker-independent phone recognition using hidden markov models", "author": ["K-F Lee", "H-W Hon"], "venue": "Acoustics, Speech and Signal Processing, IEEE Transactions on, vol. 37, no. 11, pp. 1641\u20131648, 1989.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1989}, {"title": "struct svm, support vector machine for complex outputs", "author": ["Thorsten Joachims"], "venue": "2008.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "The kaldi speech recognition toolkit", "author": ["Daniel Povey", "Arnab Ghoshal", "Gilles Boulianne", "Lukas Burget", "Ondrej Glembek", "Nagendra Goel", "Mirko Hannemann", "Petr Motlicek", "Yanmin Qian", "Petr Schwarz", "Jan Silovsky", "Georg Stemmer", "Karel Vesely"], "venue": "IEEE 2011 Workshop on Automatic Speech Recognition and Understanding. Dec. 2011, IEEE Signal Processing Society, IEEE Catalog No.: CFP11SRW-USB.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Using Deep Neural Networks (DNN) [1, 2] with HMM is a good example [3\u20135].", "startOffset": 33, "endOffset": 39}, {"referenceID": 1, "context": "Using Deep Neural Networks (DNN) [1, 2] with HMM is a good example [3\u20135].", "startOffset": 33, "endOffset": 39}, {"referenceID": 2, "context": "Using Deep Neural Networks (DNN) [1, 2] with HMM is a good example [3\u20135].", "startOffset": 67, "endOffset": 72}, {"referenceID": 3, "context": "Using Deep Neural Networks (DNN) [1, 2] with HMM is a good example [3\u20135].", "startOffset": 67, "endOffset": 72}, {"referenceID": 4, "context": "Using Deep Neural Networks (DNN) [1, 2] with HMM is a good example [3\u20135].", "startOffset": 67, "endOffset": 72}, {"referenceID": 5, "context": "In general, HMMs consider the phoneme structure by states and the transitions among them, but trained primarily on frame level regardless of being based on DNN [6, 7] or Gaussian Mixture Model (or subspace GMM, SGMM [8]).", "startOffset": 160, "endOffset": 166}, {"referenceID": 6, "context": "In general, HMMs consider the phoneme structure by states and the transitions among them, but trained primarily on frame level regardless of being based on DNN [6, 7] or Gaussian Mixture Model (or subspace GMM, SGMM [8]).", "startOffset": 160, "endOffset": 166}, {"referenceID": 7, "context": "In general, HMMs consider the phoneme structure by states and the transitions among them, but trained primarily on frame level regardless of being based on DNN [6, 7] or Gaussian Mixture Model (or subspace GMM, SGMM [8]).", "startOffset": 216, "endOffset": 219}, {"referenceID": 8, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 32, "endOffset": 39}, {"referenceID": 9, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 32, "endOffset": 39}, {"referenceID": 10, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 32, "endOffset": 39}, {"referenceID": 11, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 32, "endOffset": 39}, {"referenceID": 12, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 32, "endOffset": 39}, {"referenceID": 13, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 32, "endOffset": 39}, {"referenceID": 14, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 84, "endOffset": 91}, {"referenceID": 15, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 84, "endOffset": 91}, {"referenceID": 16, "context": "Conditional Random Fields (CRF) [10\u201315] and structured Support Vector Machine (SVM) [16\u201318] are good example approaches.", "startOffset": 84, "endOffset": 91}, {"referenceID": 17, "context": "Recently, structured SVM has been used to perform initial phoneme recognition by learning the relationships between the acoustic vector sequence and the phoneme label sequence of the whole utterance jointly rather than on the frame level or from different sets of knowledge sources [19], utilizing the nice properties of SVM [20] to classify the structured patterns of utterances with maximized margin.", "startOffset": 282, "endOffset": 286}, {"referenceID": 18, "context": "Recently, structured SVM has been used to perform initial phoneme recognition by learning the relationships between the acoustic vector sequence and the phoneme label sequence of the whole utterance jointly rather than on the frame level or from different sets of knowledge sources [19], utilizing the nice properties of SVM [20] to classify the structured patterns of utterances with maximized margin.", "startOffset": 325, "endOffset": 329}, {"referenceID": 19, "context": "In recent work, the front-end feature extraction DNN has been integrated with SVM [21] and Weighted Finite-State Transducers (WFST) [22], but here we further integrate the frontend DNN with structured DNN, which is completely different from the previous work.", "startOffset": 82, "endOffset": 86}, {"referenceID": 20, "context": "In recent work, the front-end feature extraction DNN has been integrated with SVM [21] and Weighted Finite-State Transducers (WFST) [22], but here we further integrate the frontend DNN with structured DNN, which is completely different from the previous work.", "startOffset": 132, "endOffset": 136}, {"referenceID": 21, "context": "Formula (3) can be solved by quadratic programming and the cutting-plane algorithm [23], and is equivalent to the following formula:", "startOffset": 83, "endOffset": 87}, {"referenceID": 21, "context": "With the scoring function F1(x,y; \u03b81) and the trained parameter set \u03b81, we can find the label sequence y for the acoustic vector sequence x of any input testing utterance by the well known Viterbi algorithm [23].", "startOffset": 207, "endOffset": 211}, {"referenceID": 22, "context": "The FSDNN we proposed can be considered as a special case (or structured version) of Convolutional Neural Network [24] [25] which works perfectly in computer vision and speech recognition [26].", "startOffset": 114, "endOffset": 118}, {"referenceID": 23, "context": "The FSDNN we proposed can be considered as a special case (or structured version) of Convolutional Neural Network [24] [25] which works perfectly in computer vision and speech recognition [26].", "startOffset": 119, "endOffset": 123}, {"referenceID": 24, "context": "The FSDNN we proposed can be considered as a special case (or structured version) of Convolutional Neural Network [24] [25] which works perfectly in computer vision and speech recognition [26].", "startOffset": 188, "endOffset": 192}, {"referenceID": 25, "context": "The models were trained with a set of 48 phonemes and tested with a set of 39 phonemes, conformed to CMU/MIT standards [27].", "startOffset": 119, "endOffset": 123}, {"referenceID": 26, "context": "We used an online library [28] for structured SVM, and modified the kaldi [29] code to implement structured DNN.", "startOffset": 26, "endOffset": 30}, {"referenceID": 27, "context": "We used an online library [28] for structured SVM, and modified the kaldi [29] code to implement structured DNN.", "startOffset": 74, "endOffset": 78}], "year": 2015, "abstractText": "In this paper we propose the Structured Deep Neural Network (structured DNN) as a structured and deep learning framework. This approach can learn to find the best structured object (such as a label sequence) given a structured input (such as a vector sequence) by globally considering the mapping relationships between the structures rather than item by item. When automatic speech recognition is viewed as a special case of such a structured learning problem, where we have the acoustic vector sequence as the input and the phoneme label sequence as the output, it becomes possible to comprehensively learn utterance by utterance as a whole, rather than frame by frame. Structured Support Vector Machine (structured SVM) was proposed to perform ASR with structured learning previously, but limited by the linear nature of SVM. Here we propose structured DNN to use nonlinear transformations in multi-layers as a structured and deep learning approach. This approach was shown to beat structured SVM in preliminary experiments on TIMIT.", "creator": "LaTeX with hyperref package"}}}