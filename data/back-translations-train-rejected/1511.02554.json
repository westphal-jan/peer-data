{"id": "1511.02554", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2015", "title": "Deep Recurrent Neural Networks for Sequential Phenotype Prediction in Genomics", "abstract": "In analyzing of modern biological data, we are often dealing with ill-posed problems and missing data, mostly due to high dimensionality and multicollinearity of the dataset. In this paper, we have proposed a system based on matrix factorization (MF) and deep recurrent neural networks (DRNNs) for genotype imputation and phenotype sequences prediction. In order to model the long-term dependencies of phenotype data, the new Recurrent Linear Units (ReLU) learning strategy is utilized for the first time. The proposed model is implemented for parallel processing on central processing units (CPUs) and graphic processing units (GPUs). Performance of the proposed model is compared with other training algorithms for learning long-term dependencies as well as the sparse partial least square (SPLS) method on a set of genotype and phenotype data with 604 samples, 1980 single-nucleotide polymorphisms (SNPs), and two traits. The results demonstrate performance of the ReLU training algorithm in learning long-term dependencies in RNNs.", "histories": [["v1", "Mon, 9 Nov 2015 02:11:00 GMT  (1410kb)", "http://arxiv.org/abs/1511.02554v1", "Under review at DeSE 2015"], ["v2", "Tue, 1 Dec 2015 20:48:34 GMT  (0kb,I)", "http://arxiv.org/abs/1511.02554v2", "The articles is a draft and needs improvement"], ["v3", "Sun, 17 Jan 2016 03:30:10 GMT  (265kb)", "http://arxiv.org/abs/1511.02554v3", "The articles is accepted at DeSE 2015"]], "COMMENTS": "Under review at DeSE 2015", "reviews": [], "SUBJECTS": "cs.NE cs.CE cs.LG", "authors": ["farhad pouladi", "hojjat salehinejad", "amir mohammad gilani"], "accepted": false, "id": "1511.02554"}, "pdf": {"name": "1511.02554.pdf", "metadata": {"source": "META", "title": "Deep Recurrent Neural Networks for Sequential (1).pages", "authors": ["Farhad Pouladi", "Hojjat Salehinejad", "Amir Mohammad Gilani"], "emails": ["pouladi@ictfaculty.ir", "hsalehin@uoguelph.ca", "am.gilani@mci.ir"], "sections": [{"heading": null, "text": "This year it is more than ever before."}, {"heading": "II. DATA STRUCTURE", "text": "For the experiments, we use a dataset from Afzalipour Research Hospital. The genotype data contain genotypes from 1980 SNPs for 604 observations and the phenotype data provide measurements of two phenotypes, called feature 1 and feature 2. From 1980 SNPs in the genotype data contain 5% missing genotypes. The percentage of missing genotype observations for each SNP varies between 1 and 25. For each characteristic, 30 randomly selected observations show missing values."}, {"heading": "III. METHODOLOGY", "text": "To address the problem of the missing genotype and phenotype, we use matrix factorization (MF) and RNNs techniques to adjust predictive models as shown in Figure 1. To do this, after data preprocessing, the genotype dataset with missing values is imported into the MF system to predict the missing genotype values. By having the estimated genotype dataset and corresponding phenotypes on page 3, the RNN is used in a supervised manner to train a network model to predict phenotypes based on the known genotype-phenotype pairs. Each level is described in detail in the following subsections."}, {"heading": "A. Data Pre-processing", "text": "Generally, SNP genotypes (AA, BB, AB or zero) are referred to as integer numbers for computational purposes, but some programs can work directly with this AA / AB / BB format. Pre-processing provides the ability to clean data, remove noise, translate genotype data, and display / distinguish missing values from available data."}, {"heading": "B. Matrix Factorization Model", "text": "The proposed MF structure for the imputation of genotype data is presented in Figure 2. In this model, we consider the number of samples and the number of SNPs. Therefore, the genotype data are considered a matrix U X V, called GU x V. The MF technique is to estimate two matrices, PU x F and Q V x F with latent characteristics, so that their product G'U x V G U x V as: where each element of the genotype matrix G 'is calculated by using the dot product, such as: WHU x F and Q, to find the best values for the matrices P and Q, we must minimize the objective function describing the difference between G and G0 genotype matrices [10]. To do this, the gradient descent algorithm is used as an optimizer in Figure 2 to update the characteristic matrices P and Q."}, {"heading": "C. Recurrent Neural Network with Rectified Linear Unit Model", "text": "The RNN used in the proposed model in Figure 1 consists of input, hidden, and output layers, where each layer consists of corresponding units; the input layer consists of N input units, where their inputs are defined as a sequence of vectors by time t such as {..., Xt-1, Xt, Xt + 1,...}, where Xt = (x1, x2,..., xn); in a fully connected RNN, the input units are connected to hidden units in the hidden layer, where the connections are defined by a weight matrix W I H. The hidden layer consists of M hidden units ht = (h1, h2,..., h M), which are connected to each other by time with recursive connections. As shown in Figure 3b, the hidden units are defined before the input of the layer vas.The hidden layer structure defines the state space or \"memory\" of the system H. Where f"}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "The proposed model is implemented for parallel processing with Theano in Python [23], [18], [19]. In this section, we present the performance result from comparing simple RNN, LSTM and ReLU training methods for predicting phenotype sequences, and then compare the ReLU method with the known method of the sparse partial least square (SPLS)."}, {"heading": "A. Parameter Setting", "text": "As described in Section II, it is assumed that the genotype data is either missing or being observed. Therefore, the observed genotypes are presented as Gu, v = 0, 1, 2} and the missing (null) data as Gu, v = 5 for the experiments [1]. The genotype data set GU, V consists of V = 1980 SNPs for U = 604 observations. Parameter settings for all experiments are presented in Table I, adapted to the literature, [14], [19], [29], unless a change is mentioned. As recommended in the literature, the 10-fold cross-validation is used to adjust the parameters eta and K for the SPLS algorithm using the SPLS package in the programming language R [19], [20], [6]. Parameter setting is considered separately for each feature provided in the phenotype data set for 1 \u2264 K at least 10. The optimal values are considered in Table IDue to the 10, the small data available for the validation of the type S and the% for the available data in the SPS."}, {"heading": "B. Simulation Results Analysis", "text": "In this subsection, the performance results of the proposed method are presented and compared with the SPLS method for the described dataset in Section II. Performance of the methods is evaluated by measuring the correlation between the original genotype and the phenotype values with the corresponding predicted values. Furthermore, the average cost of adapting the MF model for different epochs is shown in Figure 6. To take a deeper look at the details, the number of latent characteristics F is shown in linear and logarithmic scales. Furthermore, the measure for calculating the cost average is the mean square error, which is the average of the page 7squared difference between the targets and the output of the MF model. As the results show, the number of latent characteristics F leads to a lower average of costs. Furthermore, the model will fit better than in any epoch, but after epoch 110 the progress is not very significant."}, {"heading": "V. CONCLUSION AND FUTURE WORKS", "text": "This paper proposes a novel model that uses matrix factorization and deep recurrent neural networks (DRNN) for genotype imputation and phenotype prediction. As we are interested in pursuing sequences with long-term dependencies in genomics, the state-of-the-art method of recited linear unit learning is used. Results show that those using the ReLU methods perform better in training compared to the LSTM-RNN methods and simple RNN methods. ReLU learning methods also have less computational complexity compared to the LSTM method. Future research will be interesting to analyze other advances in deep learning for genotype phenotype applications; in particular, that these algorithms are moving toward simpler designs that are suitable for big data applications."}], "references": [{"title": "Genotype imputation for genome-wide association studies", "author": ["J. Marchini", "B. Howie"], "venue": "Nature Reviews Genetics, vol. 11, pp. 499-511, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Kardia1, \u201cImputing missing genotypic data of single-nucleotide polymorphisms using neural networks,", "author": ["Y.V. Sun", "S. LR"], "venue": "European Journal of Human Genetics,", "citeRegEx": "Sun and LR.,? \\Q2008\\E", "shortCiteRegEx": "Sun and LR.", "year": 2008}, {"title": "Rapid and accurate haplotype phasing and missing-data inference for whole-genome association studies by use of localized haplotype clustering,", "author": ["SR. Browning", "BL. Browning"], "venue": "American journal of human genetics,", "citeRegEx": "Browning and Browning,? \\Q2007\\E", "shortCiteRegEx": "Browning and Browning", "year": 2007}, {"title": "MaCH: using sequence and genotype data to estimate haplotypes and unobserved genotypes,", "author": ["Y. Li", "CJ. Willer", "J. Ding", "P. Scheet", "GR. Abecasis"], "venue": "Genetic Epidemiology,", "citeRegEx": "Li et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Li et al\\.", "year": 2010}, {"title": "A flexible and accurate genotype imputation method for the next generation of genome-wide association studies,\u201c PLoS genetics", "author": ["BN. Howie", "P. Donnelly", "J. Marchini"], "venue": null, "citeRegEx": "Howie et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Howie et al\\.", "year": 2009}, {"title": "Sparse partial least squares regression for simultaneous dimension reduction and variable selection,", "author": ["H. Chun", "S. Kele"], "venue": "J R Stat Soc Series B Stat Methodol,", "citeRegEx": "Chun and Kele,? \\Q2010\\E", "shortCiteRegEx": "Chun and Kele", "year": 2010}, {"title": "Regression shrinkage and selection via the lasso,", "author": ["R. Tibshirani"], "venue": "J. Royal. Statist. Soc B.,", "citeRegEx": "Tibshirani,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani", "year": 1996}, {"title": "A New Kernel Non-Negative Matrix Factor- ization and Its Application in Microarray Data Analysis,", "author": ["Y. Li", "A. Ngom"], "venue": "in Proc. IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology,", "citeRegEx": "Li and Ngom,? \\Q2012\\E", "shortCiteRegEx": "Li and Ngom", "year": 2012}, {"title": "Nonlinear nonnegative matrix factorization based on Mercer kernel construction,", "author": ["P. Binbin", "L. Jianhuang", "C. Wen-Sheng"], "venue": "Pattern Recognition,", "citeRegEx": "Binbin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Binbin et al\\.", "year": 2011}, {"title": "Dictionary IdentificationSparse Matrix- Factorization via l1-Minimization,", "author": ["R. Gribonval", "K. Schnass"], "venue": "IEEE Transactions on Information Theory, vol. 56,", "citeRegEx": "Gribonval and Schnass,? \\Q2010\\E", "shortCiteRegEx": "Gribonval and Schnass", "year": 2010}, {"title": "A Pistachio Nuts Classification Technique: An ANN Based Signal Processing Scheme,", "author": ["S. Mahdavi-Jafari", "H. Salehinejad", "S. Talebi"], "venue": "Computational Intelligence for Modelling Control & Automation, International Conference on,", "citeRegEx": "Mahdavi.Jafari et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mahdavi.Jafari et al\\.", "year": 2008}, {"title": "Micro-Differential Evolution with Vectorized Random Mutation Fac- tor,", "author": ["H. Salehinejad", "S. Rahnamayan", "H.R. Tizhoosh", "S.Y. Chen"], "venue": "in Proc. IEEE Congress on Evolutionary Computation,", "citeRegEx": "Salehinejad et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Salehinejad et al\\.", "year": 2014}, {"title": "Learning the parts of objects by non-negative matrix factorization,", "author": ["D.D. Lee", "S. Seung"], "venue": "Nature,", "citeRegEx": "Lee and Seung,? \\Q1999\\E", "shortCiteRegEx": "Lee and Seung", "year": 1999}, {"title": "Tumor Classification Based on Non-Negative Matrix Factorization Using Gene Expression Data,", "author": ["C. Zheng", "et. al"], "venue": "IEEE Transactions on NanoBioscience,", "citeRegEx": "Zheng and al.,? \\Q2011\\E", "shortCiteRegEx": "Zheng and al.", "year": 2011}, {"title": "Type-II Opposition-based Differential Evolutions,", "author": ["H. Salehinejad", "S. Rahnamayan", "H.R. Tizhoosh"], "venue": "in Proc. IEEE Congress on Evolutionary Computation,", "citeRegEx": "Salehinejad et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Salehinejad et al\\.", "year": 2014}, {"title": "Micro-Differential Evolution: Diversity Enhancement and Comparative Study,", "author": ["H. Salehinejad"], "venue": "University of Ontario Institute of Technology,", "citeRegEx": "Salehinejad,? \\Q2014\\E", "shortCiteRegEx": "Salehinejad", "year": 2014}, {"title": "3D localization in large-scale Wireless Sensor Networks: A microdifferential evolution approach,\u201d in Personal, Indoor, and Mobile Radio Communication (PIMRC), 2014", "author": ["H. Salehinejad", "R. Zadeh", "R. Liscano", "S. Rahnamayan"], "venue": "IEEE 25th Annual International Symposium on, vol.,", "citeRegEx": "Salehinejad et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Salehinejad et al\\.", "year": 2014}, {"title": "SciPy: Open Source Scientific Tools for Python,", "author": ["E. Jones", "E. Oliphant", "P. Peterson", "et. al"], "venue": null, "citeRegEx": "Jones et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Jones et al\\.", "year": 2001}, {"title": "Theano: A CPU and GPU Math Expression Compiler,\u201c in Proceedings of the Python for Scientific Computing", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "et. al"], "venue": null, "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Optimum Localization of Wind Turbine Sites Using Opposition Based Ant Colony Optimization,", "author": ["F. Pouladi", "A.M. Gilani", "B. Nikpour", "H. Salehinejad"], "venue": "in Developments in eSystems Engineering (DeSE),", "citeRegEx": "Pouladi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pouladi et al\\.", "year": 2013}, {"title": "Dynamic Fuzzy Logic-Ant Colony System-Based Route Selection System,", "author": ["H. Salehinejad", "S. Talebi"], "venue": "Applied Computational Intelligence and Soft Computing,", "citeRegEx": "Salehinejad and Talebi,? \\Q2010\\E", "shortCiteRegEx": "Salehinejad and Talebi", "year": 2010}, {"title": "Cognitive radio networks spectrum allocation: An ACS perspective", "author": ["F. Koroupi", "S. Talebi", "H. Salehinejad"], "venue": "Scientia Iranica, vol. 19, Issue 3, pp. 767-773, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "An Algorithm for Least-Squares Estimation of Non- linear Parameters,", "author": ["D. Marquardt"], "venue": "SIAM Journal on Applied Mathematics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1963}, {"title": "The Levenberg-Marquardt Algorithm,", "author": ["A. Ranganathan"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "An Introduction to the spls Package, Version 1.0", "author": ["D. Chung", "et. al."], "venue": "June 10, 2012.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Package spls", "author": ["D. Chung", "et. al."], "venue": "R programming language, February 20, 2015.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Theano: new features and speed improvements", "author": ["F. Bastien", "P. Lamblin", "R. Pascanu", "J. Bergstra", "I. Goodfellow", "A. Bergeron", "N. Bouchard", "D. Warde-Farley", "Y. Bengio"], "venue": "NIPS 2012 deep learning workshop", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "A Simple Way to Initialize Recurrent Networks of Rectified Linear Units,", "author": ["Le", "Q. V", "N. Jaitly", "G.E. Hinton Google"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription,", "author": ["N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent"], "venue": "Appearing in Proc. ICML,", "citeRegEx": "Boulanger.Lewandowski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Boulanger.Lewandowski et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "The genome-wide association (GWA) studies have discovered many convincingly replicated associations for complex human diseases using high-throughput single-nucleotide olymorphism (SNP) genotypes [1], [2].", "startOffset": 195, "endOffset": 198}, {"referenceID": 0, "context": "The genotype imputation has been used for fine-map associations and facilitates the combination of results across studies [1].", "startOffset": 122, "endOffset": 125}, {"referenceID": 21, "context": "Some examples are in localization [17], [20],navigation [21], and spectrum assignment [22] problems.", "startOffset": 86, "endOffset": 90}, {"referenceID": 27, "context": "The hidden state is consisted of highdimensional non-linear dynamics which enables modelling any phenomena, if trained well [31], [30].", "startOffset": 130, "endOffset": 134}, {"referenceID": 27, "context": "Learning long term dependencies in RNNs is difficult task [30].", "startOffset": 58, "endOffset": 62}, {"referenceID": 27, "context": "A recent proposed method suggests that proper initialization of the RNN weights with rectified linear units has good performance in modeling longrange dependencies [30].", "startOffset": 164, "endOffset": 168}, {"referenceID": 27, "context": "In ReLU, when the error derivatives for the hidden units are back-propagated through time they remain constant provided no extra error-derivatives are added [30].", "startOffset": 157, "endOffset": 161}, {"referenceID": 0, "context": "Therefore, the observed genotypes are represented as Gu,v \u2208 {0, 1, 2} and the missing (null) data is represented as Gu,v = 5 for the experiments [1].", "startOffset": 145, "endOffset": 148}, {"referenceID": 26, "context": "Parameter setting for all the experiments are presented in Table I adapted from the literature, [14], [19], [29], unless a change is mentioned.", "startOffset": 108, "endOffset": 112}], "year": 2015, "abstractText": "In analyzing of modern biological data, we are often dealing with ill-posed problems and missing data, mostly due to high dimensionality and multicollinearity of the dataset. In this paper, we have proposed a system based on matrix factorization (MF) and deep recurrent neural networks (DRNNs) for genotype imputation and phenotype sequences prediction. In order to model the long-term dependencies of phenotype data, the new Recurrent Linear Units (ReLU) learning strategy is utilized for the first time. The proposed model is implemented for parallel processing on central processing units (CPUs) and graphic processing units (GPUs). Performance of the proposed model is compared with other training algorithms for learning long-term dependencies as well as the sparse partial least square (SPLS) method on a set of genotype and phenotype data with 604 samples, 1980 single-nucleotide polymorphisms (SNPs), and two traits. The results demonstrate performance of the ReLU training algorithm in learning long-term dependencies in RNNs.", "creator": "Pages"}}}