{"id": "1511.02595", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2015", "title": "A New Relaxation Approach to Normalized Hypergraph Cut", "abstract": "Normalized graph cut (NGC) has become a popular research topic due to its wide applications in a large variety of areas like machine learning and very large scale integration (VLSI) circuit design. Most of traditional NGC methods are based on pairwise relationships (similarities). However, in real-world applications relationships among the vertices (objects) may be more complex than pairwise, which are typically represented as hyperedges in hypergraphs. Thus, normalized hypergraph cut (NHC) has attracted more and more attention. Existing NHC methods cannot achieve satisfactory performance in real applications. In this paper, we propose a novel relaxation approach, which is called relaxed NHC (RNHC), to solve the NHC problem. Our model is defined as an optimization problem on the Stiefel manifold. To solve this problem, we resort to the Cayley transformation to devise a feasible learning algorithm. Experimental results on a set of large hypergraph benchmarks for clustering and partitioning in VLSI domain show that RNHC can outperform the state-of-the-art methods.", "histories": [["v1", "Mon, 9 Nov 2015 08:30:03 GMT  (272kb,D)", "http://arxiv.org/abs/1511.02595v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["cong xie", "wu-jun li", "zhihua zhang"], "accepted": false, "id": "1511.02595"}, "pdf": {"name": "1511.02595.pdf", "metadata": {"source": "CRF", "title": "A New Relaxation Approach to Normalized Hypergraph Cut", "authors": ["Cong Xie", "Wu-Jun Li", "Zhihua Zhang"], "emails": ["xcgoner1108@gmail.com", "liwujun@nju.edu.cn", "zhang-zh@cs.sjtu.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "The goal of graph partitioning [Wu and Leahy, 1993] is to divide the indentations (nodes) in a graph into multiple groups (clusters), minimizing the number of edges in different clusters while maximizing the number of edges within the clusters. In addition to the goal that should be achieved in diagrams, the volumes of the different clusters should be as balanced as possible."}, {"heading": "2 Preliminaries", "text": "In this section we present the notation and problem definition of this paper. Furthermore, the spectral cluster approach [Zhou et al., 2006] is briefly presented."}, {"heading": "2.1 Notation", "text": "Let V = {v1, v2,..., vn} denote the set of n vertices (nodes) and E = {e1, e2,..., em} the set of m undirected hyperhedra. A hyperhedra is a subset of V that can contain more than two vertices. Note that an ordinary edge is still a hyperedge that has exactly two vertices. A hypergraph is defined as H = (V, E) with vertex set V and hyperedge set E. A hypergraph H can be represented by an n \u00b7 m matrix B with the entries B (v, e) = 1 at v-e and 0 otherwise. We define a n \u00b7 n diagonal matrix D with diagonal entries D (v, v) = \u2211 e-E (v, e), the degree of the vertex v. Some notations that are used are listed in Table 1."}, {"heading": "2.2 Normalized Hypergraph Cut", "text": "Let each vertex v-V be uniquely assigned to a cluster c-C, where C = {c1, c2,.., cp} denotes the p-cluster. Each hyperedge encompasses a series of different clusters. A p-way hypergraph intersection is a sequence of intersected subsets ci V with the problem that the individual hyperedges are intersected in such a way that the number of hyperedges encompassing different clusters is minimized. Now, we formally define the normalized hypergraph intersection problem (NHC). We define the volume of the cluster ci, which is vol (ci) = [ci) v-ci D (v, v). A hyperedge gets an intersection if its vertices encompass two different clusters. Given the set of clusters C, the intersection of a hyperedge e is defined as a hyperedge [p], j-hyperedge [p], j-value [p], j-value."}, {"heading": "2.3 Spectral Approach", "text": "The spectral approach [Zhou et al., 2006] approaches the NHC by \"clique expansion.\" Each hyperedge e is transformed into a fully connected subgraph with the same edge weight 1 / 2 / 3. Subsequently, the hypergraph is converted into a weighted ordinary graph. NHC problem is solved by spectral clustering [Ng et al., 2001] on the extended graph, i.e. the p smallest eigenvalues are calculated and the corresponding eigenvectors are treated as the new characteristics for the vertices, which are further clustered using the K-Means algorithm to obtain the final solution. In the spectral approach, the number of sections of a hyperedge is approximated by the edge section of the corresponding clique, which is the number of edges in different clusters normalized by the total number of nodes in the clique."}, {"heading": "3 Methodology", "text": "In this section, we provide a novel model for the formulation of the NHC problem and a corresponding relaxed optimization problem. Afterwards, an efficient learning algorithm to solve this problem is presented."}, {"heading": "3.1 NHC Formulation", "text": "The solution can be represented as a n \u00b7 p matrix X with the entries X (v, c) = 1 if v \u00b7 c and 0 otherwise, where v is a vertex and c is a cluster. Note that the columns of X are reciprocally orthogonal. Considering the mapping of vertices, the mapping of hyperedges can therefore be performed as p \u00b7 m matrix S with the entries S (c, e) = 1 if v \u00b2 c is such that e 3 v and S (c, e) = 0 otherwise where e is a hyperedge. Note that S = sgn matrix S with the entries S (c, e) = 1 if v \u00b2 c (c, e) = 0 otherwise where e is a hyperedge."}, {"heading": "3.2 Relaxation", "text": "The problem in (3) is NP-hard, which cannot be solved due to the quadratic form in the objective function and the occurrence of the drawing function. To make the problem palatable, we simplify the expression and use elementary matrix operations to obtain S and the corresponding S before relaxing the problem. First, we simplify the objective function. Note that the quadratic form in (3) can be rewritten into a sum form. (5), which leads to a simpler expression of the problem: min X, if pe is the number of clusters occurring e hyperedge e, or pe = \u2211 C S (c, e). Obviously, the minimization (4) of the minimization of p is equivalent to the minimization of E pe, (5), which leads to a simpler expression of the problem."}, {"heading": "3.3 Learning Algorithm", "text": "Now we are developing a learning algorithm to solve the relaxed optimization problem in (8). Since the objective function is minimized under the orthogonal constraint, the corresponding workable solution Mpn = {X-X-Rn \u00b7 p-X-X-Ip} is the Boots multiplicity. There are algorithms in [Edelman et al., 1998; Wen and Yin, 2013] that have been proposed to deal with such types of constraints. Note that the optimization problem with orthogonal constraints is non-convex, which means that there is no guarantee to obtain a global minimizer. To find a local minimizer on the Boots multiplicity, we are performing the Cayley transformation [Wen and Yin, 2013] to develop a learning algorithm."}, {"heading": "3.4 Complexity Analysis", "text": "The flops for calculating the objective function, the gradient matrix G, and the corresponding skew-symmetric matrix A are O (mnp), O (mnp), and O (n2p), respectively. Calculating Q in (11) requires calculating the inverse of (I + \u03c42A). According to the Sherman-Morrison-Woodbury formula, if p is much smaller than n / 2, we only need to calculate the inverse of a 2p \u00d7 2pmatrix. Therefore, calculating Y (\u03c4) requires 8np2 + O (p3). For another consideration, updating Y (GDP) 4np2 + O (p3) requires calculating the spectral matrix of T."}, {"heading": "4 Experiment", "text": "In this section the effectiveness of our algorithm is tested by empirical evaluation of real hypergraphs. Our experiment was carried out on a workstation with Intel E5-2650-v2 2.6 GHz (2 x 8 cores) and 128 GB DDR3 RAM."}, {"heading": "4.1 Datasets and Baselines", "text": "The hypergraphs used in our experiment are from a series of hypergraph benchmarks for clustering and partitioning in the VLSI range from the ISPD98 Circuit Benchmark Suite 1. In total, there are 18 hypergraphs in the data set, the 12 largest of which are selected for our experiment. Information on the data sets is in Table 2.In our experiment, we use the spectral approach mentioned in Section 2.3 [Zhou et al., 2006] as the baseline. Our method in Algorithm 1 is called a relaxed normalized hypergraph section (RNHC). In all experiments, we choose the parameter \u03b1 = 100, the maximum number of iterations T = 1000 and the stop criterion = 10 \u2212 9 for our algorithm. The reason why we do not compare our algorithm with heuristic approaches such as hMetis and Parkway is that we focus only on solving the NHC problem by optimizing in this essay. And the most spectral approach is related to our algorithm."}, {"heading": "4.2 Clustering Visualization", "text": "In Figure 1, we illustrate the clustering generated by the spectral approach and RNHC on ibm07. In the figure, we illustrate the matrix B: 1http: / / vlsicad.ucsd.edu / UCLAWeb / cheese / ispd98.htmlthe matrix B. Each row of B represents a vertex and each column a hyperedge. A non-empty dot on (x, y) in the figure implies that the yth vertex belongs to the xth hyperedge. The number of clusters is 3. Different colors indicate different clusters. Vertex points are arranged in such a way that the vertex points are grouped in the same cluster, and the hyperedges in the two figures 1 (a) and 1 (b) are arranged in the same order. In a better clustering, there should be less overlapping columns (hyperedges) between clusters."}, {"heading": "4.3 Accuracy Comparison", "text": "The reason why we compare the best NHC value instead of the average performance is that both algorithms use the K-Means algorithm for final clustering, the result of which depends on the starting point. Sometimes, K-Means simply fails to obtain p-clusters, which means that some of the clusters are empty. In addition, K-Means occasionally produces extremely bad NHC values due to a bad starting point. Such errors can render average performance meaningless. In addition, it is also hard to tell which attempt fails and which succeeds. We test the objective value of NHC in (2) for each algorithm. Comparison of the objective value is shown in Figure 2. Note that a smaller objective value implies a better NHC. It is evident that our algorithm generates a better objective value in most cases."}, {"heading": "4.4 Speed Comparison", "text": "To ensure fairness, all experiments are performed in a single thread by setting \"maxNumCompThreads (1)\" in MATLAB. We can find that our RNHC algorithm is faster than the baseline in all cases."}, {"heading": "5 Conclusion", "text": "In this work, we have proposed a new model for formulating the normalized hypergraph section problem. Furthermore, we have developed an effective approach to loosening the new model and developed an efficient learning algorithm to solve the relaxed hypergraph section problem. Experimental results on real hypergraphs have shown that our algorithm can exceed the current state of the art. It is interesting to apply our approach to other practical problems in the future, such as the problem of parenting graphs in distributed computation."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Normalized graph cut (NGC) has become a popular research topic due to its wide applications in a large variety of areas like machine learning and very large scale integration (VLSI) circuit design. Most of traditional NGC methods are based on pairwise relationships (similarities). However, in real-world applications relationships among the vertices (objects) may be more complex than pairwise, which are typically represented as hyperedges in hypergraphs. Thus, normalized hypergraph cut (NHC) has attracted more and more attention. Existing NHC methods cannot achieve satisfactory performance in real applications. In this paper, we propose a novel relaxation approach, which is called relaxed NHC (RNHC), to solve the NHC problem. Our model is defined as an optimization problem on the Stiefel manifold. To solve this problem, we resort to the Cayley transformation to devise a feasible learning algorithm. Experimental results on a set of large hypergraph benchmarks for clustering and partitioning in VLSI domain show that RNHC can outperform the state-of-the-art methods.", "creator": "TeX"}}}