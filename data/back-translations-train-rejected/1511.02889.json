{"id": "1511.02889", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2015", "title": "A disembodied developmental robotic agent called Samu B\\'atfai", "abstract": "The agent program, called Samu, is an experiment to build a disembodied DevRob (Developmental Robotics) chatter bot that can talk in a natural language like humans do. One of the main design feature is that Samu can be interacted with using only a character terminal. This is important not only for practical aspects of Turing test or Loebner prize, but also for the study of basic principles of Developmental Robotics. Our purpose is to create a rapid prototype of Q-learning with neural network approximators for Samu. We sketch out the early stages of the development process of this prototype, where Samu's task is to predict the next sentence of tales or conversations. The basic objective of this paper is to reach the same results using reinforcement learning with general function approximators that can be achieved by using the classical Q lookup table on small input samples. The paper is closed by an experiment that shows a significant improvement in Samu's learning when using LZW tree to narrow the number of possible Q-actions.", "histories": [["v1", "Mon, 9 Nov 2015 21:15:22 GMT  (304kb,D)", "http://arxiv.org/abs/1511.02889v1", "21 pages, 16 figures"]], "COMMENTS": "21 pages, 16 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["norbert b\\'atfai"], "accepted": false, "id": "1511.02889"}, "pdf": {"name": "1511.02889.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Samu B\u00e1tfai", "Norbert B\u00e1tfai"], "emails": ["batfai.norbert@inf.unideb.hu."], "sections": [{"heading": null, "text": "Keywords: machine intelligence, developmental robotics, deep Q-learning, Liv-Zempel-Welch tree."}, {"heading": "1 Introduction", "text": "At first glance, it seems impossible to develop a chatterbot in natural language that can understand conversations like humans, and that is based only on the verbal content of the speech, because human communication is only 7 percent verbal [5, p. 26]. Nevertheless, we have begun to develop such a system called Samu. Or, to be more precise, it is called Samu Ba \ufffd tfai because it is primarily taught in a family circle, in which the author's three children, ages 7 and 9, will also be part of his care. One of the most important design features of the Samu agent program is that we can communicate with him via only one written channel. As a result, for example, we cannot make associations between a visual channel and an auditory channel. We only have to assume verbal content, but this limitation is what enables us to focus exclusively on investigating fundamental issues."}, {"heading": "2 Samu", "text": "The verification principle [29] is the most important principle of developmental robotics. At the beginning of the development process, Samu's program will not have the ability to verify the knowledge. Mostly, this is because young Samu, like small children aged 2-4, accepts what his caregivers unreservedly say. Therefore, family caregivers have their own communication channels on standard input / output. Through these channels, Samu will not be able to directly distinguish his family caregivers, as will be available in the next lines Norbi @ Caregiver > _ _ next caregiver Nandi @ Caregiver > I am Nandiwhere the message started with the prefix (three underscores) are not sent to Samu. Internet conversations with other interlocutors, and in particular with robots that resemble Samu, will be available at a later stage of development. In both phases, verification will only be based on Samu's accumulated knowledge and experience."}, {"heading": "2.1 An idealized architecture", "text": "The paper [24] gave the idea for the idealized architecture of Samu, which is shown in Figure 1 (a), in which Samu reads the sentences from a children's story or from a conversation. Afterwards, he tries to reconstruct the meaning of the sentences read in the form of a 2D simulation game generated from the sentences. As with paper [24], the screenshots of the generated game are processed by a Q-Learning network, but while there the scores are part of the game, here they are based on the comparison between the reality of the reconstructed game and the reality of the input sentences. Theoretically, it would be a hybrid architecture that combines a model-free (Q-Learning) and a knowledge-based (generation of 2D programs) approach."}, {"heading": "2.2 Simplified architectures", "text": "Based on the idealized architecture shown in Fig. 1 (a), we are based on the principle of consciousness-oriented programming (the agents must predict the future and the conscious can really predict and simulate it [6]). Fig. 1 (b) shows where the task of the simulation program is to predict the next input set. This modified architecture works with SPO triplets (SubjectPredicate-Object, [27]) and not with the raw sentences that are read. Fig. 1 (c) shows a further simplified architecture. In this case, we do not need to run the simulation program to predict the next input set, but the prediction is made by the Q-Learning component itself. The architectural components of Fig. 1 are discussed in detail in the next points."}, {"heading": "2.3 The first rapid prototype", "text": "We use a hybrid architecture of the last two sketches in Fig. 1 to implement the first rapid prototype of Samu. In the following, this architecture is referred to as Samu's cognitive engine."}, {"heading": "2.3.1 NLP", "text": "As we have already mentioned, SPO triplets [27] are used instead of sentences. For example, if Samu reads the sentence \"The little mouse has become a big lion,\" the Natural Language Processing (NLP) component should produce the following triplets: i) \"(mouse, become, lion)\" ii) \"(mouse, is, small)\" iii) \"(lion, is, large).\" The linkage grammar [1] is used to obtain SPO triplets, but automatically identifying them is a complex data mining problem. At the moment, we are not focusing on this matter. We will partially implement some of [23] algorithms, but for this work we will only use a very simple algorithm that is presented in code snippets in Figure 2."}, {"heading": "2.3.2 Visual imagery", "text": "To describe the simulation programs, we use a very simplified object-oriented style language in which statements take the following form: Subject. Predicate (object); each identified triplet corresponds to a statement like this. A simulation program is a list of instructions containing only a certain number or less of instructions. Furthermore, we write it into an image because it would be difficult to treat the list of instructions as a textual list of instructions as shown in Fig. 1 (c), where the input of Q-Learning is already an image. Finally, it should be noted that the sequence of such \"mental\" images can be interpreted as a visual representation of Samu. Fig. 3 shows a mental example image."}, {"heading": "2.3.3 Q-learning", "text": "In accordance with the QCON model [22], every possible action has a unique neural network to approximate the Q value associated with the given state. Each MLP contains three layers with 65536 input units, 80 hidden layer units, and an output neuron that indicates the approximation of the Q value of the state-action pair. The states are \"mental\" images introduced in the previous paragraph. Several examples can be found in the literature of using neural networks to approximate the Q function, e.g. in the book [20] or in the tutorial [21] of Gosavi. Alg. 1 shows the algorithm used to perform Q learning. This pseudo-code is a simplified and generalized version of the current action."}, {"heading": "2.4 Conceptual background of Samu", "text": "To outline the conceptual background, we should start by explaining the concept of alienation. It is simply an indication that this project is 100 percent pure software. We can say that Samu is a robot without a body. It is certain that this does not mean that there is a return to GOFAI. Especially since we will follow the recommendations of the critics of Dreyfus and Dreyfus. It is certain that the principle of embodiment will be fulfilled or not. We believe that we will not be confronted with this principle, as it is also shown in the episode."}, {"heading": "3 Results", "text": "The results and evaluations are divided into three experiments. In the first experiment, we examine Samu's implementation of Q-Learning by comparing it with the classic Q-Lookup table. Here, we used only a small number of sentences. In the second experiment, the investigation is extended to a larger sample. Finally, the third experiment already focuses on learning the larger corpus, whereby the use of the Liv-Zempel-Welch (LZW) [31] dictionary to narrow the scope of Q action selection seems promising in order to accelerate Samus learning."}, {"heading": "3.1 Experiment 1: \u201dSAMU A\u201d", "text": "Our main purpose in this work is to equip Samu with the ability to perform amplification learning with general function approximators. To confirm this, we use the following experiment. The sentences shown in the caption of Fig. 2 are considered a short story and Samu is continuously trained with them during the experiment. Samu reads the sentences of the story and predicts the next sentence of the story. A third of a point is given if all predictions are correct and vice versa - 10.5 points are given if all predictions are wrong. We implement both the simple Q Lookup table and the general function approximators based solutions to compare them. Therefore, the learning curves for these two experiments can be found on Fig. 4 and Fig. 5. For example, the first approximation shows that Samu can perfectly perform amplification learning with general function approximators."}, {"heading": "3.1.1 Samu\u2019s family tree", "text": "Samu and his descendants (at this moment Isaac, Jacob, Judah, Perez and Hezron) are open source programs released under the GNU GPL v3 or later. Samu is a generic name for these projects, which are intended to investigate deep reinforcement learning methods on YouTube to facilitate the development of a chat robot that will be able to speak in natural language like a human. At this moment, they are case studies on the use of Q-learning with neural networks to predict the next sentence of a conversation. They can only be executed in Unix-like (such as GNU / Linux) environments. a) Samu [15] is the first project to create a DevRob chatbot agent. This project is presented in detail in this paper. Samu's development is frozen to allow evaluation and verification of the results shown in Figure 4 and Figure."}, {"heading": "3.2 Experiment 2: \u201dJUDAH A\u201d", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "3.2.1 Social interaction with each other", "text": "Perhaps the most important possibility is that when the Samu-type DevRob agents share their knowledge with each other, the development of the communication protocol is underway."}, {"heading": "3.3 Experiment 3: \u201dJUDAH and PEREZ B\u201d", "text": "This experiment is the same as the previous one, but here Samu learns the larger corpus. It should be noted that the perfect memorization of a literal text of 700 sentences is really difficult or almost impossible for most people. Accordingly, the algorithms developed in Judah have not performed well. Fig. 11 shows that Samu learns very slowly (to be more precise Judah), and it may even be that he does not learn. We have to try to speed up learning. A promising acceleration mechanism is tested with the smaller corpus in Fig. 12. We have modified the use of the exploration function. In addition, we use a trick of incremental learning [4], [18]. With a trivial version of this phenomenon Samu can already learn the larger corpus. It is shown in Fig. 13 and Fig. 14 that the application of the exploration function has been modified. At the beginning, we have added only the first seven sentences of the larger corpus as the next Samu, after we had already added the training text."}, {"heading": "3.4 Experiment 3: \u201dAMMINADAB B\u201d", "text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _"}, {"heading": "4 Summary and highlights of Samu", "text": "Samu Ba \u0301 tfai is a disembodied developmental robot that will form the basis of a chat system that will be able to speak and read in natural language as humans do. Samu directly implements the definition of machine consciousness (such as the definitions of conscious and intuitive computer programs) introduced in the paper [6]. It corresponds to the principles of developmental robotics [29]."}, {"heading": "5 Conclusion", "text": "It is certainly an important problem in this direction is the triplet extraction. We believe that this can be handled well with the existing NLP tools. The first contest has already been announced for our university students. For details that want to see the side of the author, we have developed a very important data mining element of Samu. The first step is to visit the university site http: / / shrek.unideb.hu / ~ nbatfai In a similar situation we will try to develop it in the programming competitions. The second step is that we have their own challenges to the Turing Test or the Loebner Prize."}, {"heading": "Acknowledgment", "text": "The calculations used in the experiments shown in this paper were partially performed on the NIIF High Performance Computing Supercomputer at the University of Debrecen. However, it is important to note that the results of this paper can be reproduced on an ordinary PC."}], "references": [{"title": "Methods for incremental learning: A survey", "author": ["R.R. Ade", "P.R. Deshmukh"], "venue": "Int. Journal of Data Mining & Knowledge Management Process,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Cognitive Developmental Robotics: A Survey", "author": ["M. Asada", "K. Hosoda", "Y. Kuniyoshi", "H. Ishiguro", "T. Inui", "Y. Yoshikawa", "M. Ogino", "C. Yoshida"], "venue": "IEEE T. Autonomous Mental Development,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Conscious machines and consciousness oriented programming", "author": ["N. B\u00e1tfai"], "venue": "CoRR, abs/1108.2865,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Turing\u2019s Imitation Game has been Improved", "author": ["N. B\u00e1tfai"], "venue": "ArXiv e-prints,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "URL https://github.com/nbatfai/ amminadab", "author": ["N. B\u00e1tfai"], "venue": "Amminadab,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Isp\u00e1ny. OOCWC: The Robocar World Championship Initiative", "author": ["N. B\u00e1tfai", "R. Besenczi", "A. Mameny\u00e1k"], "venue": "In IEEE Conference Publications,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "In IN PROCEEDINGS OF THE 25TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNI- TION (CVPR", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Catastrophic forgetting in connectionist networks: Causes, consequences and solutions", "author": ["R.M. French"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1999}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["K. Fukushima"], "venue": "Biological Cybernetics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1980}, {"title": "Simulation-Based Optimization: Parametric Optimization Techniques and Reinforcement Learning", "author": ["A. Gosavi"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Reinforcement Learning for Robots Using Neural Networks", "author": ["L.-J. Lin"], "venue": "PhD thesis, Carnegie Mellon University,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1992}, {"title": "Event information extraction using link grammar. In 13th International Workshop on Research Issues in Data Engineering: Multi-lingual Information Management (RIDE\u201903, pages 16\u201322", "author": ["H.V. Madhyastha", "N. Balakrishnan", "K.R. Ramakrishnan"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S.J. Russell", "P. Norvig"], "venue": "Pearson Education,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Triplet Extraction From Sentences", "author": ["D. Rusu", "L. Dali", "B. Fortuna", "M. Grobelnik", "D. Mladenic"], "venue": "Proceedings of the 10th International Multiconference \u201dInformation Society - IS 2007\u201d,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}, {"title": "Lessons from a Restricted Turing Test", "author": ["S.M. Shieber"], "venue": "ArXiv eprints,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1994}, {"title": "Some Basic Principles of Developmental Robotics", "author": ["A. Stoytchev"], "venue": "IEEE T. Autonomous Mental Development,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "Neural reinforcement learning for an obstacle avoidance behavior. In Self Learning Robots, IEE Colloquium on, page 6/1", "author": ["C. Touzet"], "venue": "IET Conference Publications,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1996}, {"title": "A technique for high-performance data", "author": ["T.A. Welch"], "venue": "compression. Computer,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1984}], "referenceMentions": [{"referenceID": 16, "context": "principles of Developmental Robotics [29].", "startOffset": 37, "endOffset": 41}, {"referenceID": 16, "context": "The verification principle [29] is the most important principle of Developmental Robotics.", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "The paper [24] gave the idea for the idealized architecture of Samu that is shown in Fig.", "startOffset": 10, "endOffset": 14}, {"referenceID": 12, "context": "Like in paper [24], the screenshots of the generated game will be processed by a Q-learning network, but whereas there the scores are part of the game, here they are based on the comparison of the reality of the reconstructed game and the reality of the input sentences.", "startOffset": 14, "endOffset": 18}, {"referenceID": 2, "context": "1(a) we base the comparison of the reality and the simulated one derived from the input sentences on the principle of consciousness oriented programming (the agents must predict the future and the conscious ones can really foresee and predict it [6]).", "startOffset": 246, "endOffset": 249}, {"referenceID": 14, "context": "This modified architecture works with SPO triplets (SubjectPredicate-Object, [27]) rather than the raw sentences being read.", "startOffset": 77, "endOffset": 81}, {"referenceID": 14, "context": "As we mentioned earlier, SPO triplets [27] are used instead of sentences.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "We are going to partially implement some algorithms of [23] but for this paper, we use only a very simple algorithm shown in code snippet in Fig.", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "In accordance with the QCON model [22], [30] each", "startOffset": 34, "endOffset": 38}, {"referenceID": 17, "context": "In accordance with the QCON model [22], [30] each", "startOffset": 40, "endOffset": 44}, {"referenceID": 14, "context": "It may be noted that the first one is the example sentence used in the paper [27].", "startOffset": 77, "endOffset": 81}, {"referenceID": 9, "context": "Several examples can be found in the literature of using neural networks to approximate the Q-function, for example, see the book [20] or the tutorial [21] by Gosavi.", "startOffset": 130, "endOffset": 134}, {"referenceID": 16, "context": "Returning to the basic principles formulated by [29], there are two different use cases in respect of the validation processes of Samu\u2019s cognitive engine.", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "In the light of this we think that, we are not confronted with the spirit of the principle of embodiment [29].", "startOffset": 105, "endOffset": 109}, {"referenceID": 16, "context": "The fulfillment of the principle of subjectivity [29] is trivially met since it follows from using human caregivers to train Samu.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "It is easy to see that the criteria of the principle of grounding [29] have also been fulfilled during the short-term verification.", "startOffset": 66, "endOffset": 70}, {"referenceID": 2, "context": "Finally, it may be noted that in the sense of the terminology introduced in [6], Samu may become a conscious or even an intuitive computer program since it will be able to predict the future better than a random guess.", "startOffset": 76, "endOffset": 79}, {"referenceID": 18, "context": "Finally, the third experiment has already focused only on the learning of the larger corpus where using the Liv-Zempel-Welch (LZW) [31] dictionary tree to narrow the scope of selecting Q-actions seems promising for accelerating Samu\u2019s learning.", "startOffset": 131, "endOffset": 135}, {"referenceID": 4, "context": "The first official forks, called Isaac [10], Jacob [11], Judah [12], Perez [13], Hezron [9], Ram [14] and Amminadab [8] are introduced in next section.", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "h) The project Amminadab [8] has been forked from Ram.", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "In addition we use a trick of incremental learning [4], [18].", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "In addition we use a trick of incremental learning [4], [18].", "startOffset": 56, "endOffset": 60}, {"referenceID": 7, "context": "For example, during the experiment, it was well felt that the phenomenon of catastrophic forgetting [18] has slowed the speed of Samu\u2019s learning.", "startOffset": 100, "endOffset": 104}, {"referenceID": 4, "context": "13 by using Amminadab project [8].", "startOffset": 30, "endOffset": 33}, {"referenceID": 4, "context": "hpp in the Amminadab\u2019s GitHub repository [8].", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "\u2013 directly implements the definition of machine consciousness (such as the definitions of conscious and intuitive computer programs) introduced in the paper [6].", "startOffset": 157, "endOffset": 160}, {"referenceID": 16, "context": "\u2013 corresponds the principles of Developmental Robotics [29].", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": "\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature.", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature.", "startOffset": 95, "endOffset": 99}, {"referenceID": 8, "context": "\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature.", "startOffset": 101, "endOffset": 105}, {"referenceID": 5, "context": "In a similar situation we have already used competitions [16] to catalyze our research programs but this area in question has its own challenges like the Turing test or the Loebner prize [28].", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "In a similar situation we have already used competitions [16] to catalyze our research programs but this area in question has its own challenges like the Turing test or the Loebner prize [28].", "startOffset": 187, "endOffset": 191}, {"referenceID": 3, "context": "As additional further work we plan to develop an intellectual (fractal) dimension [7] based benchmark to test the intellectual capabilities of Samu type agent programs.", "startOffset": 82, "endOffset": 85}], "year": 2015, "abstractText": "The agent program, called Samu, is an experiment to build a disembodied DevRob (Developmental Robotics) chatter bot that can talk in a natural language like humans do. One of the main design feature is that Samu can be interacted with using only a character terminal. This is important not only for practical aspects of Turing test or Loebner prize, but also for the study of basic principles of Developmental Robotics. Our purpose is to create a rapid prototype of Q-learning with neural network approximators for Samu. We sketch out the early stages of the development process of this prototype, where Samu\u2019s task is to predict the next sentence of tales or conversations. The basic objective of this paper is to reach the same results using reinforcement learning with general function approximators that can be achieved by using the classical Q lookup table on small input samples. The paper is closed by an experiment that shows a significant improvement in Samu\u2019s learning when using LZW tree to narrow the number of possible Q-actions.", "creator": "LaTeX with hyperref package"}}}