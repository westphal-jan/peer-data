{"id": "1511.03055", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2015", "title": "Tiny Descriptors for Image Retrieval with Unsupervised Triplet Hashing", "abstract": "A typical image retrieval pipeline starts with the comparison of global descriptors from a large database to find a short list of candidate matches. A good image descriptor is key to the retrieval pipeline and should reconcile two contradictory requirements: providing recall rates as high as possible and being as compact as possible for fast matching. Following the recent successes of Deep Convolutional Neural Networks (DCNN) for large scale image classification, descriptors extracted from DCNNs are increasingly used in place of the traditional hand crafted descriptors such as Fisher Vectors (FV) with better retrieval performances. Nevertheless, the dimensionality of a typical DCNN descriptor --extracted either from the visual feature pyramid or the fully-connected layers-- remains quite high at several thousands of scalar values. In this paper, we propose Unsupervised Triplet Hashing (UTH), a fully unsupervised method to compute extremely compact binary hashes --in the 32-256 bits range-- from high-dimensional global descriptors. UTH consists of two successive deep learning steps. First, Stacked Restricted Boltzmann Machines (SRBM), a type of unsupervised deep neural nets, are used to learn binary embedding functions able to bring the descriptor size down to the desired bitrate. SRBMs are typically able to ensure a very high compression rate at the expense of loosing some desirable metric properties of the original DCNN descriptor space. Then, triplet networks, a rank learning scheme based on weight sharing nets is used to fine-tune the binary embedding functions to retain as much as possible of the useful metric properties of the original space. A thorough empirical evaluation conducted on multiple publicly available dataset using DCNN descriptors shows that our method is able to significantly outperform state-of-the-art unsupervised schemes in the target bit range.", "histories": [["v1", "Tue, 10 Nov 2015 10:38:37 GMT  (1299kb,D)", "http://arxiv.org/abs/1511.03055v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CV cs.LG", "authors": ["jie lin", "olivier mor\\`ere", "julie petta", "vijay chandrasekhar", "antoine veillard"], "accepted": false, "id": "1511.03055"}, "pdf": {"name": "1511.03055.pdf", "metadata": {"source": "CRF", "title": "Tiny Descriptors for Image Retrieval with Unsupervised Triplet Hashing", "authors": ["Jie Lin", "Olivier Mor\u00e8re", "Julie Petta", "Vijay Chandrasekhar", "Antoine Veillard"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we propose Unsupervised Triplet Hashing (UTH), a completely unattended method for calculating extremely compact binary hashes - in the 32-256 bit range - from high-dimensional global descriptors. UTH consists of two consecutive deep learning steps. First, Stacked Restricted Boltzmann Machines (SRBM), a type of unattended deep neural networks, are used to learn binary embedding functions that are able to reduce the descriptor size to the desired bit rate. SRBMs are typically able to ensure a very high compression rate at the expense of some desirable metric properties of the original DCNN descriptor space. Subsequently, triplet networks, a ranking scheme based on weight distribution networks, are used to adjust the binary embedding functions as accurately as possible to preserve the useful descriptor space characteristics of the original CNN."}, {"heading": "1 INTRODUCTION", "text": "To this end, MPEG has issued an international standard entitled Compact Descriptors for Visual Search (CDVS) [3] for description extraction and, more recently, for image source compression; the size of the data sent over the wireless network must be as small as possible to reduce latency and improve the user experience; an alternative approach to sending JPEG images or MPEG video is to extract feature descriptors on the mobile device, compress the descriptors and transmit them over the wireless network, but this could be prohibitively expensive at low uplink speeds; such an approach to reduce the amount of transmission data by orders of magnitude that can be used both for visual search and for the visual contributions of Jie Lin, Olivier More and Julie Petta.ar Xiv: 151 1.03 055v 1 [cs.R I for Nov 10] Database Search [For this purpose, MPEG has published a Description Rev 22 database with this purpose]."}, {"heading": "2 RELATED WORK AND CONTRIBUTIONS", "text": "One promising approach is the suppression of small descriptions. [8] We have shown in recent years that the use of representations derived from DCNN depends not only on the way they are made by people, but also on the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the way they by the way they are made by the way they are made by the way they are made by the way they are made by the way they are made by the"}, {"heading": "3 EVALUATION FRAMEWORK", "text": "We use 3 popular data sets for small-scale experiments: INRIA Holidays (500 queries, 991 database images) [23], University of Kentucky Benchmark (UKbench) (10200 queries, 10200 database images) [24] and Oxford5k Buildings (55 queries, 5063 database images) [25]. For large-scale retrieval experiments, we present results on holidays and UKbench data sets combined with the 1 million MIR FLICKR Distractor data set [26]. Note that the UKbench data set is used in the CDVS evaluation framework [3]. Most schemes, including our proposed scheme, require a training step. We use the ImageNet dataset for training, which consists of 1 million images from 1000 different classes [27] (class names are never used in this work). We randomly sample a subset of 150K images from ImageNet to learn image binding features."}, {"heading": "4 UNSUPERVISED TRIPLET HASHING", "text": "This work focuses on the compression of high-dimensional descriptors into low bit rate and a hidden layer of hidden binary codes for image installation. [We have the model for preserving ranking information from the original uncompressed image description to the triplets of the images.] The entire process is uncontrolled and does not require any described data and is illustrated in Figure 1. Deep Embedding Network. Our previous work showed that high-dimensional vectors can be converted to low-dimensional codes by forming multi-layer neural networks that can function significantly better than most unverified hashing approaches to image substance retrieval [15].An RBM is an undirected graphical model consisting of a layer of visible units and a layer of hidden units."}, {"heading": "5 EXPERIMENTAL RESULTS", "text": "In fact, most of them are able to survive by themselves if they do not play by the rules. (...) Most of them are not able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...)"}, {"heading": "6 CONCLUSION", "text": "We proposed UTH, a novel, completely unattended method of compressing global image descriptors to extremely small binary hashes (32-256 bits). After pre-training using SRBMs, the model parameters are fine-tuned using image triple images to maintain the good query performance of the uncompressed descriptors. Through a thorough empirical evaluation, we showed that the fine-tuning step consistently improves the query results and that UTH is close to the performance of the uncompressed descriptor at 256 bits. On average, the results suggest that UTH is currently the best uncontrolled hashing scheme that outperforms other popular schemes such as LSH, PCAHash or ITQ.10."}], "references": [{"title": "Compressed Histogram of Gradients: A Low Bitrate Descriptor", "author": ["V. Chandrasekhar", "G. Takacs"], "venue": "International Journal of Computer Vision, pp. 384\u2013399, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Interframe coding of feature descriptors for mobile augmented reality", "author": ["M. Makar", "V. Chandrasekhar"], "venue": "IEEE Transactions on Image Processing, 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Large-scale Image Retrieval with Compressed Fisher Vectors", "author": ["F. Perronnin", "Y. Liu", "J. Sanchez", "H. Poirier"], "venue": "Proceedings of IEEE Conference on CVPR, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Residual Enhanced Visual Vector as a Compact Signature for Mobile Visual Search", "author": ["D.M. Chen", "S.S. Tsai"], "venue": "Signal Processing, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Rate-adaptive compact fisher codes for mobile visual search", "author": ["J. Lin", "L.-Y. Duan"], "venue": "IEEE Signal Processing Letters, pp. 195\u2013198, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural Codes for Image Retrieval", "author": ["A. Babenko", "A. Slesarev", "A. Chigorin", "V. Lempitsky"], "venue": "Proceedings of European Conference on Computer Vision (ECCV), 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv:1409.1556, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Object Recognition from Local Scale-Invariant Features", "author": ["D. Lowe"], "venue": "Proceedings of IEEE Conference on CVPR, 1999.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "A Practical Guide to CNNs and Fisher Vectors for Image Instance Retrieval", "author": ["V. Chandrasekhar", "J. Lin", "O. Morere", "H. Goh", "A. Veillard"], "venue": "arXiv:1508.02496, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Binary Hash Codes for Large-Scale Image Search", "author": ["K. Grauman", "R. Fergus"], "venue": "Machine Learning for Computer Vision, 2013, pp. 49\u201387.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Iterative Quantization: A Procrustean Approach to Learning Binary Codes", "author": ["Y. Gong", "S. Lazebnik"], "venue": "Proceedings of IEEE Conference on CVPR, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Compact Global Descriptors for Visual Search", "author": ["V. Chandrasekhar", "J. Lin", "O. Morere", "A. Veillard", "H. Goh"], "venue": "Proceedings of IEEE Data Compression Conference (DCC), 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Locality-Sensitive Hashing Scheme based on p-stable Distributions", "author": ["M. Datar", "N. Immorlica"], "venue": "Proceedings of the Twentieth Annual Symposium on Computational Geometry, 2004.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Spectral Hashing", "author": ["Y. Weiss", "A. Torralba", "R. Fergus"], "venue": "Proceedings of Neural Information Processing Systems (NIPS), 2008.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning Binary Codes for High-Dimensional Data Using Bilinear Projections.", "author": ["Y. Gong", "S. Kumar"], "venue": "Proceedings of IEEE Conference on CVPR,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Aggregating local image descriptors into compact codes", "author": ["H. J\u00e9gou", "F. Perronnin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1704\u20131716, 2012.  11", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep metric learning using Triplet network", "author": ["E. Hoffer", "N. Ailon"], "venue": "International Conference on Learning Representations, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Fine-grained Image Similarity with Deep Ranking", "author": ["J.Wang", "Y.Wang"], "venue": "Proceedings of IEEE Conference on CVPR, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Simultaneous Feature Learning and Hash Coding with Deep Neural Networks", "author": ["H. Lai", "Y. Pan", "Y. Liu", "S. Yan"], "venue": "Proceedings of IEEE Conference on CVPR, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Hamming Embedding and Weak Geometric Consistency for Large Scale Image Search", "author": ["H. J\u00e9gou", "M. Douze", "C. Schmid"], "venue": "Proceedings of ECCV, 2008.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Scalable Recognition with a Vocabulary Tree", "author": ["D. Nist\u00e9r", "H. Stew\u00e9nius"], "venue": "Proceedings of IEEE Conference on CVPR, 2006.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "Object Retrieval with Large Vocabularies and Fast Spatial Matching", "author": ["J. Philbin", "O. Chum"], "venue": "Proceedings of IEEE Conference on CVPR, 2007.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "New Trends and Ideas in Visual Concept Detection: The MIR Flickr Retrieval Evaluation Initiative", "author": ["M. Huiskes", "B. Thomee", "M. Lew"], "venue": "ACM International Conference on MIR, 2010.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong"], "venue": "Proceedings of IEEE Conference on CVPR, 2009.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer"], "venue": "arXiv:1408.5093, 2014.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "A Practical Guide to Training Restricted Boltzmann Machines", "author": ["G. Hinton"], "venue": "Neural Networks: Tricks of the Trade, 2012, pp. 599\u2013619.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, pp. 504\u2013507, 2006.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}, {"title": "Locality-Sensitive Binary Codes from Shift-Invariant Kernels", "author": ["M. Raginsky", "S. Lazebnik"], "venue": "Proceedings of Neural Information Processing Systems (NIPS), 2009.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "and augmented reality applications [1] [2].", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "and augmented reality applications [1] [2].", "startOffset": 39, "endOffset": 42}, {"referenceID": 2, "context": "Examples include Fisher Vectors [4], Residual Enhanced Visual Vector(REVV) [5], Scalable Compressed Fisher Vector (SCFV) [6], and the recently proposed descriptor based on Deep Convolutional Neural Networks (DCNN) [7], such as AlexNet [8] and OxfordNet [9].", "startOffset": 32, "endOffset": 35}, {"referenceID": 3, "context": "Examples include Fisher Vectors [4], Residual Enhanced Visual Vector(REVV) [5], Scalable Compressed Fisher Vector (SCFV) [6], and the recently proposed descriptor based on Deep Convolutional Neural Networks (DCNN) [7], such as AlexNet [8] and OxfordNet [9].", "startOffset": 75, "endOffset": 78}, {"referenceID": 4, "context": "Examples include Fisher Vectors [4], Residual Enhanced Visual Vector(REVV) [5], Scalable Compressed Fisher Vector (SCFV) [6], and the recently proposed descriptor based on Deep Convolutional Neural Networks (DCNN) [7], such as AlexNet [8] and OxfordNet [9].", "startOffset": 121, "endOffset": 124}, {"referenceID": 5, "context": "Examples include Fisher Vectors [4], Residual Enhanced Visual Vector(REVV) [5], Scalable Compressed Fisher Vector (SCFV) [6], and the recently proposed descriptor based on Deep Convolutional Neural Networks (DCNN) [7], such as AlexNet [8] and OxfordNet [9].", "startOffset": 214, "endOffset": 217}, {"referenceID": 6, "context": "Examples include Fisher Vectors [4], Residual Enhanced Visual Vector(REVV) [5], Scalable Compressed Fisher Vector (SCFV) [6], and the recently proposed descriptor based on Deep Convolutional Neural Networks (DCNN) [7], such as AlexNet [8] and OxfordNet [9].", "startOffset": 235, "endOffset": 238}, {"referenceID": 7, "context": "Examples include Fisher Vectors [4], Residual Enhanced Visual Vector(REVV) [5], Scalable Compressed Fisher Vector (SCFV) [6], and the recently proposed descriptor based on Deep Convolutional Neural Networks (DCNN) [7], such as AlexNet [8] and OxfordNet [9].", "startOffset": 253, "endOffset": 256}, {"referenceID": 8, "context": "Subsequently, local descriptors like SIFT [10] and CHoG [1] are used in the GCC step to check if a valid geometric transform exists between database and query images.", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "Subsequently, local descriptors like SIFT [10] and CHoG [1] are used in the GCC step to check if a valid geometric transform exists between database and query images.", "startOffset": 56, "endOffset": 59}, {"referenceID": 6, "context": "Motivated by the remarkable success of deep learning for large-scale image classification [8] [9], recent work show that the use of representations extracted from DCNN is quickly gaining ground over hand-crafted descriptors such as Fisher Vectors as favoured state-of-the-art global image descriptors for image instance retrieval [7] [12].", "startOffset": 90, "endOffset": 93}, {"referenceID": 7, "context": "Motivated by the remarkable success of deep learning for large-scale image classification [8] [9], recent work show that the use of representations extracted from DCNN is quickly gaining ground over hand-crafted descriptors such as Fisher Vectors as favoured state-of-the-art global image descriptors for image instance retrieval [7] [12].", "startOffset": 94, "endOffset": 97}, {"referenceID": 5, "context": "Motivated by the remarkable success of deep learning for large-scale image classification [8] [9], recent work show that the use of representations extracted from DCNN is quickly gaining ground over hand-crafted descriptors such as Fisher Vectors as favoured state-of-the-art global image descriptors for image instance retrieval [7] [12].", "startOffset": 330, "endOffset": 333}, {"referenceID": 9, "context": "Motivated by the remarkable success of deep learning for large-scale image classification [8] [9], recent work show that the use of representations extracted from DCNN is quickly gaining ground over hand-crafted descriptors such as Fisher Vectors as favoured state-of-the-art global image descriptors for image instance retrieval [7] [12].", "startOffset": 334, "endOffset": 338}, {"referenceID": 6, "context": ", the neural networks in [8] [9] have 7 and 19 layers respectively, and take weeks to train with millions of images on GPU.", "startOffset": 25, "endOffset": 28}, {"referenceID": 7, "context": ", the neural networks in [8] [9] have 7 and 19 layers respectively, and take weeks to train with millions of images on GPU.", "startOffset": 29, "endOffset": 32}, {"referenceID": 10, "context": "While there is plenty of work on learning binary codes [13] for compressing small descriptors like SIFT, there is relatively little work on compression of high-dimensional global descriptors.", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "proposed the popular Iterative Quantization (ITQ) [14].", "startOffset": 50, "endOffset": 54}, {"referenceID": 12, "context": "Our previous work [15] employed deeply stacked Restriction Boltzmann Machines (SRBM) to learn low dimensional non-linear subspaces of uncompressed descriptors.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "[16], Spectral Hashing (SH) [17] and Bilinear Projection Binary Codes (BPBC) [18], etc.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16], Spectral Hashing (SH) [17] and Bilinear Projection Binary Codes (BPBC) [18], etc.", "startOffset": 28, "endOffset": 32}, {"referenceID": 15, "context": "[16], Spectral Hashing (SH) [17] and Bilinear Projection Binary Codes (BPBC) [18], etc.", "startOffset": 77, "endOffset": 81}, {"referenceID": 16, "context": "Besides hashing schemes, quantization based method such as Product Quantization (PQ) [19] are an alternative way to compress descriptors.", "startOffset": 85, "endOffset": 89}, {"referenceID": 16, "context": "proposed PCA followed by random rotations and PQ for obtaining compact representations [19].", "startOffset": 87, "endOffset": 91}, {"referenceID": 4, "context": "The MPEG CDVS standard adopted the Scalable Compressed Fisher Vector [6], which was based on direct scalar quantization of high-dimensional Fisher Vectors.", "startOffset": 69, "endOffset": 72}, {"referenceID": 12, "context": "First, we use SRBMs to learn a first version of the binary embedding functions in a fashion similar to our previous work in [15] where we showed that the method is able to produce very compact hashes with good retrieval performances.", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "Unlike other approaches using triplet learning networks [20] [21] [22], our approach is fully-unsupervised and does not require additional label data for the triplets.", "startOffset": 56, "endOffset": 60}, {"referenceID": 18, "context": "Unlike other approaches using triplet learning networks [20] [21] [22], our approach is fully-unsupervised and does not require additional label data for the triplets.", "startOffset": 61, "endOffset": 65}, {"referenceID": 19, "context": "Unlike other approaches using triplet learning networks [20] [21] [22], our approach is fully-unsupervised and does not require additional label data for the triplets.", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "UTH expands our previous work on hash compression [15] with a fine-tuning step based on triplet networks to preserve the ranking information from the high-dimensional global descriptors.", "startOffset": 50, "endOffset": 54}, {"referenceID": 20, "context": "We use 3 popular data sets for small scale experiments: INRIA Holidays (500 queries, 991 database images) [23], University of Kentucky Benchmark (UKbench) (10200 queries,", "startOffset": 106, "endOffset": 110}, {"referenceID": 21, "context": "10200 database images) [24], and Oxford5k Buildings (55 queries, 5063 database images) [25].", "startOffset": 23, "endOffset": 27}, {"referenceID": 22, "context": "10200 database images) [24], and Oxford5k Buildings (55 queries, 5063 database images) [25].", "startOffset": 87, "endOffset": 91}, {"referenceID": 23, "context": "For large-scale retrieval experiments, we present results on Holidays and UKbench data sets, combined with the 1 million MIR-FLICKR distractor data set [26].", "startOffset": 152, "endOffset": 156}, {"referenceID": 24, "context": "We use the ImageNet data set for training, which consists of 1 million images from 1000 different classes [27] (class labels are never used in the scope of this work).", "startOffset": 106, "endOffset": 110}, {"referenceID": 7, "context": "The starting global image descriptor is extracted from the 19-layer OxfordNet proposed for ImageNet classification in the seminal contribution by the VGG group [9].", "startOffset": 160, "endOffset": 163}, {"referenceID": 25, "context": "The features are extracted using the open-source software Caffe [28].", "startOffset": 64, "endOffset": 68}, {"referenceID": 5, "context": "We find that layer fc6 (the first fully connected layer before softmax) performs the best for image retrieval, similar to the recently reported results in [7].", "startOffset": 155, "endOffset": 158}, {"referenceID": 12, "context": "Our previous work showed that high dimensional vectors can be converted to low-dimensional codes by training multi-layer neural networks based on stacked Restricted Boltzmann Machines (SRBM), which can perform significantly better than most unsupervised hashing approaches for image instance retrieval [15].", "startOffset": 302, "endOffset": 306}, {"referenceID": 26, "context": "RBM can be trained by minimizing the contrastive divergence objective [29], which approximates the maximum likelihood of the input distribution.", "startOffset": 70, "endOffset": 74}, {"referenceID": 26, "context": "Besides, binary RBMs are a lot faster and easier to train than continuous RBMs [29].", "startOffset": 79, "endOffset": 83}, {"referenceID": 27, "context": "The number of layers and the number of hidden units in each layer are parameters that are typically chosen experimentally [30] [8] [9].", "startOffset": 122, "endOffset": 126}, {"referenceID": 6, "context": "The number of layers and the number of hidden units in each layer are parameters that are typically chosen experimentally [30] [8] [9].", "startOffset": 127, "endOffset": 130}, {"referenceID": 7, "context": "The number of layers and the number of hidden units in each layer are parameters that are typically chosen experimentally [30] [8] [9].", "startOffset": 131, "endOffset": 134}, {"referenceID": 12, "context": "More details are available in our previous work [15].", "startOffset": 48, "endOffset": 52}, {"referenceID": 17, "context": "The idea of using weight sharing network for model fine-tuning is not new and previous work can be found for image classification and semantic retrieval [20] [21] [22].", "startOffset": 153, "endOffset": 157}, {"referenceID": 18, "context": "The idea of using weight sharing network for model fine-tuning is not new and previous work can be found for image classification and semantic retrieval [20] [21] [22].", "startOffset": 158, "endOffset": 162}, {"referenceID": 19, "context": "The idea of using weight sharing network for model fine-tuning is not new and previous work can be found for image classification and semantic retrieval [20] [21] [22].", "startOffset": 163, "endOffset": 167}, {"referenceID": 17, "context": "The objective function is solved by Stochastic Gradient Descent (SGD) [20].", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "These parameters are chosen from the greedy optimization discussed in our previous work [15].", "startOffset": 88, "endOffset": 92}, {"referenceID": 12, "context": "To evaluate the effect of network weights initialization in the pre-training stage, we present mAP results on Holidays dataset at output size 64 bits (see Figure 2(b)), for comparison (1) SRBM based network weights proposed in our previous work [15] with (2) random unit-norm network weights (denoted as UniW).", "startOffset": 245, "endOffset": 249}, {"referenceID": 13, "context": "(1) LSH [16].", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "(2) SKLSH [31].", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "(3) SH [17].", "startOffset": 7, "endOffset": 11}, {"referenceID": 11, "context": "(4) PCAHash [14].", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "(5) ITQ [14].", "startOffset": 8, "endOffset": 12}, {"referenceID": 15, "context": "(6) BPBC [18].", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "Instead of the large projection matrices used in [14], the authors apply bilinear random projections, which require far less memory, to transform the data.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "(7) SRBM [15].", "startOffset": 9, "endOffset": 13}, {"referenceID": 7, "context": "Another promising direction would be to learn compact global descriptors for instance retrieval, directly from image pixel data using CNNs [9].", "startOffset": 139, "endOffset": 142}], "year": 2015, "abstractText": "A typical image retrieval pipeline starts with the comparison of global descriptors from a large database to find a short list of candidate matches. A good image descriptor is key to the retrieval pipeline and should reconcile two contradictory requirements: providing recall rates as high as possible and being as compact as possible for fast matching. Following the recent successes of Deep Convolutional Neural Networks (DCNN) for large scale image classification, descriptors extracted from DCNNs are increasingly used in place of the traditional hand crafted descriptors such as Fisher Vectors (FV) with better retrieval performances. Nevertheless, the dimensionality of a typical DCNN descriptor \u2013extracted either from the visual feature pyramid or the fully-connected layers\u2013 remains quite high at several thousands of scalar values. In this paper, we propose Unsupervised Triplet Hashing (UTH), a fully unsupervised method to compute extremely compact binary hashes \u2013in the 32-256 bits range\u2013 from high-dimensional global descriptors. UTH consists of two successive deep learning steps. First, Stacked Restricted Boltzmann Machines (SRBM), a type of unsupervised deep neural nets, are used to learn binary embedding functions able to bring the descriptor size down to the desired bitrate. SRBMs are typically able to ensure a very high compression rate at the expense of loosing some desirable metric properties of the original DCNN descriptor space. Then, triplet networks, a rank learning scheme based on weight sharing nets is used to fine-tune the binary embedding functions to retain as much as possible of the useful metric properties of the original space. A thorough empirical evaluation conducted on multiple publicly available dataset using DCNN descriptors shows that our method is able to significantly outperform state-of-the-art unsupervised schemes in the target bit range.", "creator": "LaTeX with hyperref package"}}}