{"id": "1511.03088", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2015", "title": "USFD: Twitter NER with Drift Compensation and Linked Data", "abstract": "This paper describes a pilot NER system for Twitter, comprising the USFD system entry to the W-NUT 2015 NER shared task. The goal is to correctly label entities in a tweet dataset, using an inventory of ten types. We employ structured learning, drawing on gazetteers taken from Linked Data, and on unsupervised clustering features, and attempting to compensate for stylistic and topic drift - a key challenge in social media text. Our result is competitive; we provide an analysis of the components of our methodology, and an examination of the target dataset in the context of this task.", "histories": [["v1", "Tue, 10 Nov 2015 12:34:47 GMT  (22kb)", "http://arxiv.org/abs/1511.03088v1", "Paper in ACL anthology:this https URL"]], "COMMENTS": "Paper in ACL anthology:this https URL", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["leon derczynski", "isabelle augenstein", "kalina bontcheva"], "accepted": false, "id": "1511.03088"}, "pdf": {"name": "1511.03088.pdf", "metadata": {"source": "CRF", "title": "USFD: Twitter NER with Drift Compensation and Linked Data", "authors": ["Leon Derczynski"], "emails": ["leon@dcs.shef.ac.uk", "isabelle@dcs.shef.ac.uk", "kalina@dcs.shef.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 151 1,03 088v 1 [cs.C L] 10 Nov 201 5"}, {"heading": "1 Introduction", "text": "Social media is a very challenging genre for Natural Language Processing (NLP) (Derczynski et al., 2013a), which provides large-volume linguistically idiosyncratic texts rich in latent signals, the correct interpretation of which requires diverse contextual and authorization-based information. As a result, NLP systems can be trained on more consistent, longer documents such as Newswire, which are largely impotent because of this loud content (Derczynski et al., 2015b). As they suffer from a persistent lack of commented Twitter records, it may be useful to understand what ticks this genre and how our existing techniques and resources can be better generalized to such a sophisticated text source. This post focuses on the introduction of our Named Entity Recognition (NER) entry into the WNUT evaluation challenge (Baldwin et al., 2015), which we are building on our 2014 and Bonteva experiments."}, {"heading": "2 Datasets", "text": "The training and development kits associated with the challenge came from the corpus of Ritter et al. (2011), which was a set of 2394 tweets from the end of 2010 that were commented on with ten entity types, including the \"other\" type. A later publication of the Challenge yielded a set of 420 tweets from 2015 that were commented on the same way (dev 2015). Since no other tweet company uses this 10-class entity model, we stuck with this data for the monitored parts of our approach. For voice modeling, we used a set of 250 million tweets from the Twitter garden hose, which represents a fair 10% sample of all tweets (Kergl et al., 2014), which were reduced to purely English tweets using langid.py (Lui and Baldwin, 2012) and then tokenized using the tool twokenizer (Connor et al., 2010)."}, {"heading": "3 Method", "text": "The task of WNUT Twitter NER required many challenges in the area of data economy. First, the data sets involved are simply very small, making it difficult to generalize in the area of supervised learning and meaning that effect quantities cannot be reliably measured. Second, Twitter language is probably one of the loudest and most idiosyncratic text genres, manifesting itself in a large number of word types due to lexical variations (Eisenstein, 2013). Third, language, and in particular the units contained in tweets, change over time, which is commonly referred to as drift. Most of the WNUT training data comes from 2010, and only a small portion from 2015, leading to a lack of examples of modern language."}, {"heading": "3.1 Unsupervised Clustering", "text": "We use an unsupervised aggregation of terms to generate word type characteristics. The goal here is to progressively reduce the number of word types inherent in the text type. 250 million tweets from 2010-2012 were used to generate 2,000 word classes using Brown clustering. Typically, 1,000 or fewer word types are used; the greater number of classes was chosen because it helped increase the expressivity of representation (Derczynski et al., 2015a), while the selection of bit depths to be used often produces brittle feature sets (Koo et al., 2008), and so we leave it to the classifier to decide which of them are useful. Typical levels are 4, 6, 10 and 20, although the selection of bit depths to be used often produces a brittle feature set (Koo et al., 2008), and so we leave it to the classifier to decide which of them are useful. The typical levels are 4, 10, and 20, although the selection of bit depths to be used often results in a brittle feature set (Koo et al., 2008), and we leave it to the classifier to decide which ones to use as the filters that we will be most effective for making these decisions in our investigations, the 5.1."}, {"heading": "3.2 Morpho-Syntactic Features", "text": "To model the context, we used relatively conventional features: the token itself, the uniforms and bigrams in an [\u2212 2, 2] offset window of the current token, and both word form (e.g. London becomes Xxxxxx) and reduced word form (London becomes Xx) characteristics. In addition, we added a part-of-speech tag for each token, which was automatically generated by a custom Tweet-PoS tagger that uses an extension of the PTB tagset (Derczynski et al., 2013b). To capture orthographic information, we use suffix and prefix characteristics of length [1.. 3]. Capitalization is notoriously unreliable in tweets and is often overtaken by newswire systems trained on more canonical text forms. To wean these systems from capital letters while minimizing false negatives, we used large-format Gazetteer characteristics to Gazetteer."}, {"heading": "3.3 Gazetteers", "text": "While we collected and experimented with a variety of gazetteers, the most helpful were: \u2022 Freebase Gazetteers selected for remote monitoring (Augenstein et al., 2014); \u2022 ANNIE First Name Lists (Cunningham et al., 2002); \u2022 First Name Trigger Terms (Derczynski et al., 2014); \u2022 Lists of Named Time Expressions (Brucato et al., 2013) used in the other category due to the prevalence of festival and event names. Freebase (Bollacker et al., 2008) is a large knowledge base consisting of approximately 3 billion facts.1 As such, it has been widely used as background knowledge for NLP tasks such as entity and relationship extraction (Augenstein et al., 2014). Gazetteers for the 10 entity types we build from freebase types.Some of the types correspond directly to freebase types."}, {"heading": "3.4 Learning Models and Representation", "text": "Since BIO NE chunking is easily described as a sequence marking problem, we experimented with structured learning. CRF with L-BFGS updates, CRF with passive-aggressive updates to combat Twitter noise (Derczynski and Bontcheva, 2014), and structured perceptron (also useful for Twitter noise (Johannsen et al., 2014)) gave CRF L-BFGS the best performance in our data set for the ten-type task."}, {"heading": "3.5 Training Data", "text": "The original dataset was harvested in 2010, long enough to be demonstrably disadvantaged compared to modern data (Fromreide et al., 2014), and therefore it was crucial to include a little more. To correct the size imbalance - the dev-2015 data is 0.175 larger than the 2010 data - we weighted the older dataset by 0.7, as proposed by (Cherry and Guo, 2015), implemented by uniformly scaling individual characteristic values to older instances, successfully reducing the negative effects of the inevitable drift."}, {"heading": "4 Performance", "text": "It is also worth noting that the performance of the nottype task is significantly better across all metrics, suggesting that the system is capable of correctly identifying entities, but there are problems with their type classification. We found that the biggest contributors to the performance of our system were the freebase gazetteer features, and the use of Brown clusters with high values of m (the number of classes) and large amounts of up-to-date input data. As a result, our computing efforts over the past week were based on the fact that the largest Brown clustering task we were able to perform at the time was not based on data. We also noticed during testing that while passive-aggressive CRF updates contributed to entity detection in tweets (Derczynski and Bontcheva, 2014), these types of learning tasks were not sufficient."}, {"heading": "5 Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Features", "text": "In terms of the characteristics we have adopted, we have focused on the rigid observations in the emergency pillars to see what the general indicators of the designated entities are in the tweets, the largest of which can be found in Table 3. It is important to note that the characteristics indicating URLs, hashtags and usernames indicate an entity, and that lowercase letters that include interpretations and interpretations of entities indicate not only entities, but also entities. The short-lived and hashtag-shaped words are not entities indicating that they are run within an entity; numbers that rarely coincide with entities; and that they have an entry in the video games Gazetteer entity, and that they indicate an entity indicating an entity."}, {"heading": "5.2 Gold standard", "text": "These problems are partly a general problem in the development of gold standards, i.e. the more complicated the task, the more people tend to miss out on correct answers (Tissot et al., 2015). For Twitter NERC with 10 types, some of the tokens are very difficult to name because the context window is very small (140 characters), which also leads to acronyms that are often used to save space, and because the world knowledge about sports, music, etc., is needed. Specifically, the following groups of problems in gold standard education have been identified: While some of the NE types are well defined, other types are very broad and therefore pose a major challenge."}, {"heading": "6 Conclusion", "text": "This article describes the USFD system introduced in W-NUT 2015, which achieves performance by unattended feature generation, by freebase gazetteer, and by weighting input data by date of origin to account for drift, resulting in a state-of-the-art performance of Twitter NER."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the European Union under Funding Agreement No 611233 PHEME, 44http: / / www.pheme.euand EPSRC UK Funding Agreement No EP / K017896 / 1 uComp.5."}], "references": [{"title": "Relation extraction from the web using distant supervision", "author": ["D. Maynard", "F. Ciravegna"], "venue": "In Knowledge Engineering and Knowledge Management,", "citeRegEx": "Augenstein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Augenstein et al\\.", "year": 2014}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "In Proceedings of the 2008 ACM SIGMOD international conference on Management", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "TwitIE: An Open-Source Information Extraction Pipeline for Microblog Text", "author": ["L. Derczynski", "A. Funk", "M.A. Greenwood", "D. Maynard", "N. Aswani"], "venue": "In Proceedings of the International Conference on Re-", "citeRegEx": "Bontcheva et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bontcheva et al\\.", "year": 2013}, {"title": "Class-based n-gram models of natural language", "author": ["Brown et al.1992] P. Brown", "V. Della Pietra", "P. de Souza", "J. Lai", "R. Mercer"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Recognising and interpreting named temporal expressions", "author": ["Brucato et al.2013] M. Brucato", "L. Derczynski", "H. Llorens", "K. Bontcheva", "C.S. Jensen"], "venue": "In RANLP,", "citeRegEx": "Brucato et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Brucato et al\\.", "year": 2013}, {"title": "The unreasonable effectiveness of word representations for Twitter named entity recognition", "author": ["Cherry", "Guo2015] C. Cherry", "H. Guo"], "venue": "In Proc. NAACL", "citeRegEx": "Cherry et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cherry et al\\.", "year": 2015}, {"title": "TweetMotif: Exploratory Search and Topic Summarization for Twitter", "author": ["Connor et al.2010] B.O. Connor", "M. Krieger", "D. Ahn"], "venue": "In Proceedings of the Fourth AAAI Conference on Weblogs and Social Media (ICWSM),", "citeRegEx": "Connor et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Connor et al\\.", "year": 2010}, {"title": "GATE: an Architecture for Development of Robust HLT Applications", "author": ["D. Maynard", "K. Bontcheva", "V. Tablan"], "venue": "In Proceedings of the 40th Annual Meeting on Association", "citeRegEx": "Cunningham et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Cunningham et al\\.", "year": 2002}, {"title": "Passive-aggressive sequence labeling with discriminative post-editing for recognising person entities in tweets", "author": ["Derczynski", "Bontcheva2014] L. Derczynski", "K. Bontcheva"], "venue": "In Proceedings http://www.ucomp.eu", "citeRegEx": "Derczynski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2014}, {"title": "MicroblogGenre Noise and Impact on Semantic Annotation Accuracy", "author": ["D. Maynard", "N. Aswani", "K. Bontcheva"], "venue": "In Proceedings of the 24th ACM Conference on Hypertext and Social Media. ACM", "citeRegEx": "Derczynski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2013}, {"title": "Twitter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data", "author": ["A. Ritter", "S. Clark", "K. Bontcheva"], "venue": "In Proceedings of Recent Advances in Natural Language Processing (RANLP)", "citeRegEx": "Derczynski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2013}, {"title": "Extrinsic impact of tuning Brown clustering", "author": ["S. Chester", "K.S. B\u00f8gh"], "venue": null, "citeRegEx": "Derczynski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2015}, {"title": "2015b. Analysis of named entity recognition and linking for tweets", "author": ["D. Maynard", "G. Rizzo", "M. van Erp", "G. Gorrell", "R. Troncy", "K. Bontcheva"], "venue": "Information Processing and Management,", "citeRegEx": "Derczynski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2015}, {"title": "What to do about bad language on the internet", "author": ["J. Eisenstein"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Eisenstein.,? \\Q2013\\E", "shortCiteRegEx": "Eisenstein.", "year": 2013}, {"title": "Crowdsourcing and annotating NER for Twitter #drift", "author": ["D. Hovy", "A. S\u00f8gaard"], "venue": "In Proc. LREC", "citeRegEx": "Fromreide et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fromreide et al\\.", "year": 2014}, {"title": "More or less supervised supersense tagging of twitter", "author": ["D. Hovy", "H.M. Alonso", "B. Plank", "A. S\u00f8gaard"], "venue": "Proc. *SEM,", "citeRegEx": "Johannsen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Johannsen et al\\.", "year": 2014}, {"title": "On the endogenesis of Twitter\u2019s Spritzer and Gardenhose sample streams", "author": ["Kergl et al.2014] D. Kergl", "R. Roedler", "S. Seeber"], "venue": "In Proc. ASONAM,", "citeRegEx": "Kergl et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kergl et al\\.", "year": 2014}, {"title": "Simple semi-supervised dependency parsing", "author": ["Koo et al.2008] T. Koo", "X. Carreras", "M. Collins"], "venue": "In Proc. ACL,", "citeRegEx": "Koo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "langid.py: An off-the-shelf language identification tool. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL)", "author": ["Lui", "Baldwin2012] M. Lui", "T. Baldwin"], "venue": null, "citeRegEx": "Lui et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lui et al\\.", "year": 2012}, {"title": "Named entity recognition in tweets: An experimental study", "author": ["Ritter et al.2011] A. Ritter", "S. Clark", "Mausam", "O. Etzioni"], "venue": "In Proc. of Empirical Methods for Natural Language Processing (EMNLP),", "citeRegEx": "Ritter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Using gazetteers in discriminative information extraction", "author": ["Smith", "Osborne2006] A. Smith", "M. Osborne"], "venue": "In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),", "citeRegEx": "Smith et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2006}, {"title": "Analysis of temporal expressions annotated in clinical notes", "author": ["Tissot et al.2015] H. Tissot", "A. Roberts", "L. Derczynski", "G. Gorrell", "M. Didonet Del Fabro"], "venue": "In Proceedings of 11th Joint ACL-ISO Workshop on Interoperable Semantic Annotation,", "citeRegEx": "Tissot et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tissot et al\\.", "year": 2015}, {"title": "Wikidata: A Free Collaborative Knowledge Base", "author": ["Vrande\u010di\u0107", "Kr\u00f6tzsch2014] D. Vrande\u010di\u0107", "M. Kr\u00f6tzsch"], "venue": "Communications of the ACM", "citeRegEx": "Vrande\u010di\u0107 et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vrande\u010di\u0107 et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 2, "context": ", 2015), which builds on our earlier experiments with Twitter and news NER (Derczynski and Bontcheva, 2014; Bontcheva et al., 2013; Cunningham et al., 2002).", "startOffset": 75, "endOffset": 156}, {"referenceID": 7, "context": ", 2015), which builds on our earlier experiments with Twitter and news NER (Derczynski and Bontcheva, 2014; Bontcheva et al., 2013; Cunningham et al., 2002).", "startOffset": 75, "endOffset": 156}, {"referenceID": 19, "context": "The training and development sets provided with the challenge were drawn from the Ritter et al. (2011) corpus.", "startOffset": 82, "endOffset": 103}, {"referenceID": 16, "context": "For language modelling, we used a set of 250 million tweets drawn from the Twitter garden hose, which is a fair 10% sample of all tweets (Kergl et al., 2014).", "startOffset": 137, "endOffset": 157}, {"referenceID": 6, "context": "py (Lui and Baldwin, 2012), and then tokenized using the twokenizer tool (Connor et al., 2010), which gives the same tokenization as used in the input and evaluation corpora.", "startOffset": 73, "endOffset": 94}, {"referenceID": 4, "context": "The first two were manually created, and covered named temporal expressions (Brucato et al., 2013) and first person names (Cunningham et al.", "startOffset": 76, "endOffset": 98}, {"referenceID": 7, "context": ", 2013) and first person names (Cunningham et al., 2002).", "startOffset": 31, "endOffset": 56}, {"referenceID": 0, "context": "The last comprised more recent data, drawn automatically from Freebase as part of a distant supervision approach to entity detection and relation annotation (Augenstein et al., 2014).", "startOffset": 157, "endOffset": 182}, {"referenceID": 13, "context": "Secondly, Twitter language is arguably one of the noisiest and idiosyncratic text genres, which manifests as a large number of word types, and very large vocabularies due to lexical variation (Eisenstein, 2013).", "startOffset": 192, "endOffset": 210}, {"referenceID": 3, "context": "250 million tweets from 20102012 were used to generate 2,000 word classes using Brown clustering (Brown et al., 1992).", "startOffset": 97, "endOffset": 117}, {"referenceID": 17, "context": "The typical levels are 4, 6, 10 and 20, though selection of bit depths to use often yields brittle feature sets (Koo et al., 2008), and so we leave it to the classifier to decide which ones are useful.", "startOffset": 112, "endOffset": 130}, {"referenceID": 0, "context": "\u2022 Freebase gazetteers mined for distant supervision (Augenstein et al., 2014);", "startOffset": 52, "endOffset": 77}, {"referenceID": 7, "context": "\u2022 ANNIE first name lists (Cunningham et al., 2002); NE type Freebase type", "startOffset": 25, "endOffset": 50}, {"referenceID": 4, "context": "\u2022 Lists of named temporal expressions (Brucato et al., 2013), used due to the prevalence of festival and event names in the other category.", "startOffset": 38, "endOffset": 60}, {"referenceID": 1, "context": "Freebase (Bollacker et al., 2008) is a large knowledge base consisting of around 3 billion facts1.", "startOffset": 9, "endOffset": 33}, {"referenceID": 0, "context": "As such, it has been used extensively as background knowledge for NLP tasks such as entity and relation extraction (Augenstein et al., 2014).", "startOffset": 115, "endOffset": 140}, {"referenceID": 19, "context": "There were several other gazetteer sources that we tried but which did not work very well: IMDb dumps,2 Ritter\u2019s LabeledLDA lists (Ritter et al., 2011) (duplicated in the baseline system), and ANNIE\u2019s other gazetteers (largely consisting of organisations, loca-", "startOffset": 130, "endOffset": 151}, {"referenceID": 15, "context": "Out of CRF using L-BFGS updates, CRF with passive-aggressive updates to combat Twitter noise (Derczynski and Bontcheva, 2014), and structured perceptron (also useful on Twitter noise (Johannsen et al., 2014)), CRF L-BFGS provided the best performance on our dataset for the ten-types task.", "startOffset": 183, "endOffset": 207}, {"referenceID": 14, "context": "The original dataset was harvested in 2010, long enough ago to be demonstrably disadvantaged when compared with modern data (Fromreide et al., 2014), and so it was critical to include something more.", "startOffset": 124, "endOffset": 148}, {"referenceID": 19, "context": "Finally, we found that other gazetteer types were not helpful to performance; taking for example all of the ANNIE gazetteers, gazetteers from IMDb dumps, entity names extracted from other Twitter NER corpora, or entities generated through LLDA (Ritter et al., 2011) all decreased performance.", "startOffset": 244, "endOffset": 265}, {"referenceID": 19, "context": "Finally, we found that other gazetteer types were not helpful to performance; taking for example all of the ANNIE gazetteers, gazetteers from IMDb dumps, entity names extracted from other Twitter NER corpora, or entities generated through LLDA (Ritter et al., 2011) all decreased performance. We suspect this is due to their swamping already-small input dataset with too great a profusion of information, c.f. Smith and Osborne (2006).", "startOffset": 245, "endOffset": 435}, {"referenceID": 21, "context": "the more complicated the task is, the more humans tend to disagree on correct answers (Tissot et al., 2015).", "startOffset": 86, "endOffset": 107}], "year": 2015, "abstractText": "This paper describes a pilot NER system for Twitter, comprising the USFD system entry to the W-NUT 2015 NER shared task. The goal is to correctly label entities in a tweet dataset, using an inventory of ten types. We employ structured learning, drawing on gazetteers taken from Linked Data, and on unsupervised clustering features, and attempting to compensate for stylistic and topic drift \u2013 a key challenge in social media text. Our result is competitive; we provide an analysis of the components of our methodology, and an examination of the target dataset in the context of this task.", "creator": "LaTeX with hyperref package"}}}