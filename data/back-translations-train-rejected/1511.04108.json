{"id": "1511.04108", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2015", "title": "LSTM-based Deep Learning Models for Non-factoid Answer Selection", "abstract": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework, the other is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. Experimental results on a public insurance-domain dataset demonstrate that the extended models substantially outperform two state-of-the-art non-DL baselines and a strong DL baseline.", "histories": [["v1", "Thu, 12 Nov 2015 22:01:54 GMT  (109kb,D)", "http://arxiv.org/abs/1511.04108v1", null], ["v2", "Wed, 18 Nov 2015 15:00:46 GMT  (199kb,D)", "http://arxiv.org/abs/1511.04108v2", "correct some typos"], ["v3", "Thu, 7 Jan 2016 17:56:29 GMT  (130kb,D)", "http://arxiv.org/abs/1511.04108v3", "added new experiments on TREC-QA"], ["v4", "Mon, 28 Mar 2016 04:12:45 GMT  (122kb,D)", "http://arxiv.org/abs/1511.04108v4", "added new experiments on TREC-QA"]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["ming tan", "cicero dos santos", "bing xiang", "bowen zhou"], "accepted": false, "id": "1511.04108"}, "pdf": {"name": "1511.04108.pdf", "metadata": {"source": "CRF", "title": "LSTM-BASED DEEP LEARNING MODELS FOR NON- FACTOID ANSWER SELECTION", "authors": ["Ming Tan", "Bing Xiang"], "emails": ["mingtan@us.ibm.com", "bingxia@us.ibm.com", "zhou@us.ibm.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "The answer selection problem can be formulated as follows: Given a question q and an answer candidate pool {a1, a2, \u00b7 \u00b7, as} for this question, we aim to search for the best answer candidate ak, where 1 \u2264 k \u2264 s. An answer is a symbolic sequence of any length, and a question can correspond to several ground truth answers. During the examination, the candidate answers to a question can not be observed at the training stage. Answer selection is one of the essential components in typical question answer (QA) systems. It is also a stand-alone task with applications in the knowledge base construction and information extraction. The nature of this problem is a mapping between a question and an answer. The big challenge is that the correct answer might not directly share keywords with the question. Instead, they can only be semantically related. In addition, the answers are sometimes loud and contain a large amount of unrelated information."}, {"heading": "2 RELATED WORK", "text": "Previous work in this area usually required feature engineering, linguistic tools, or external resources; furthermore, semantic features have been constructed based on WordNet in (Yih et al., 2013), which pairs semantically related words based on semantic relationships; whereas the answer selection problem has been converted into a syntactical matching between the question / answer trees (Wang & Manning, 2010; Wang et al., 2013); and more recently, discriminatory tree editing functions for tree extraction and engineering have been automated (Severyn & Moschitti, 2013). While these methods may be effective, they may suffer from the availability of these additional resources, the remarkable efforts of feature engineering and systematic complexity are due to the introduction of linguistic tools such as parse trees and dependency relationships."}, {"heading": "3 APPROACH", "text": "In this section, we describe the proposed framework and its variations. First, we present the general framework that aims to build bidirectional LSTM on both questions and their candidate answers, and then we use similarity metrics to measure the distance between the pairs of answers. In the following two subsections, we expand the base model in two independent directions."}, {"heading": "3.1 BASIC MODEL: QA-LSTM", "text": "The question of the why and the why, the why and the why, the why and the why, the why and the why, the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why?"}, {"heading": "3.2 QA-LSTM/CNN", "text": "In this subsection, we use a CNN structure that builds on the results of biLSTM to provide a composite representation of questions and answers. CNN's structure in this work is similar to that in (Feng et al., 2015), as in Figure 2. Unlike the traditional forward-facing neural network, where each output is interactive on each input, the revolutionary structure imposes only local interactions between the inputs within a filter size. In this work, the structure for each window with the size of m in biLSTM output vectors, i.e. Hm (t) = [h (t + 1), \u00b7 \u00b7, h (t + m \u2212 1)], where t is a specific time step, the Convolutionary Filter F = [F (0) \u00b7 \u00b7 F (m \u2212 1)], shows a value as a sequence."}, {"heading": "3.3 ATTENTION-BASED QA-LSTM", "text": "In this subsection, we examine an extension from a different perspective. Instead of generating a QA representation independently, we use a simple attention model for the answer vector generation based on the knowledge of the questioner. An attention mechanism is used to alleviate this weakness by dynamically aligning the more informative parts of the answers to the questions. This strategy has been applied in many other natural language processing tasks, such as machine translation (Bahdanau et al., 2015; Sutskever et al., 2014), sentence summarization (Rush et al., 2015), and factoid question."}, {"heading": "4 EXPERIMENT SETTINGS", "text": "After describing a number of models in the previous section, we evaluate the proposed approaches to the Insurance Domain Data Set InsuranceQA, provided by Feng et al. (2015). The InsuranceQA data set contains a training set, a validation set and two test sets. We list the number of questions and answers in the data set in Table 1. It suggests that a question may match several answers, the questions are much shorter than answers. The average length of the questions is 7 and the average length of the answers is 94. This corpus comprises a total of 24981 unique answers. The answer pool for each question includes 500 candidates, including answers to the basic truth. The answer pools are included in the published data set."}, {"heading": "4.1 BASELINES", "text": "For comparison, we give the performance of four baselines in Table 2: two state-of-the-art NonDL approaches and two variations of a strong DL approach based on CNN as feature vectors. Similar to this work, candidates are reclassified on the basis of cosinal similarity to a question.Architecture II in (Feng et al., 2015): Instead of LSTM, a CNN model is used to learn a distributed vector representation of a given question and its answer candidates, and the answers are evaluated by cosinal similarity to the question.Architecture II in (Feng et al., 2015): Instead of LSTM, a CNN model is used to learn a distributed vector representation of a given question and its answer candidates."}, {"heading": "4.2 SETUP", "text": "The models in this work are implemented from scratch with Theano (Bastien et al., 2012), and all experiments are processed in a GPU cluster, each model is trained for 140 epochs. All models are converged after 140 epochs. We use accuracy in validation to find the best epoch and hyperparameter settings for testing, the word embedding is trained by word2vec (Mikolov et al., 2013), and the word vector size is 100. Word embedding is also parameters and is also optimized during training. Stochastic Gradient Descent (SGD) is the optimization strategy. The learning rate in our experiments is 0.1. We have tried different boundary values, such as 0.05, 0.1 and 0.15, and finally set the margin as 0.1. We have also tried to include the l2 standard in the training target experiments, but show no regulatory factors."}, {"heading": "5 RESULTS AND DISCUSSIONS", "text": "Table 3 summarizes the results of our models on InsuranceQA 4, which we achieve with 4,000 measurement data. From row (A) to (C), we list QA-LSTM without any CNN structure or attention model. However, they differ from how to use the biLSTM output vectors to form sentential embeddings for questions and answers shown in Section 3.1. Potential reason for this is that the max pooling models combine more local values for each dimension, so more local information about the output embeddings.From row (D) to (F), CNN layers are built on top of the biLSTM with different filter numbers."}, {"heading": "6 CONCLUSION", "text": "In this paper, we examine the task of response selection through the use of a bi-directional, LSTM-based deep learning framework. The proposed framework is not based on feature engineering, linguistic tools or external resources and can be applied to any area. We extend the basic framework in two directions. First, we combine a revolutionary neural network into this framework to provide more composite representations for questions and anecdotes. Second, we integrate a simple but efficient attention mechanism in generating response embeddings according to the question. Experimental results from a public insurance data set show that both extensions exceed a strong deep learning baseline, which relies only on CNN for QA embedding, but without LSTM structure and attention. In the future, we would like to further evaluate the approaches described in this paper for various tasks, such as predicting the response quality in the QA community and the textual recognition of problems."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "KyungHyun", "Bengio", "Yoshua"], "venue": "Proceedings of International conference of learning representations,", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Theano: new features and speed improvements", "author": ["Bastien", "Frederic", "Lamblin", "Pascal", "Pascanu", "Razvan", "Bergstra", "James", "Goodfellow", "Ian J", "Bergeron", "Arnaud", "Bouchard", "Nicolas", "Bengio", "Yoshua"], "venue": "Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop,", "citeRegEx": "Bastien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Applying deep learning to answer selection: A study and an open task", "author": ["Feng", "Minwei", "Xiang", "Bing", "Glass", "Michael", "Wang", "Lidan", "Zhou", "Bowen"], "venue": "IEEE Automatic Speech Recognition and Understanding Workshop (ASRU),", "citeRegEx": "Feng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2015}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Graves", "Alex", "Mohamed", "Abdel-rahman", "Hinton", "Geoffrey"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Graves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Tree edit models for recognizing textual entailments, paraphrases, and answers to questions", "author": ["Heilman", "Michael", "Smith", "Noah A"], "venue": "Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics (NAACL),", "citeRegEx": "Heilman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Heilman et al\\.", "year": 2010}, {"title": "Teaching machines to read and comprehend", "author": ["Hermann", "Karl Moritz", "Kocisky", "Tomas", "Grefenstette", "Edward", "Espeholt", "Lasse", "Kay", "Will", "Suleyman", "Mustafa", "Blunsom", "Phil"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "Jurgen"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Hu", "Baotian", "Lu", "Zhengdong", "Li", "Hang", "Chen", "Qingcai"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Hu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A neural attention model for sentence summarization", "author": ["Rush", "Alexander", "Chopra", "Sumit", "Weston", "Jason"], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Rush et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Automatic feature engineering for answer selection and extraction", "author": ["Severyn", "Aliaksei", "Moschitti", "Alessandro"], "venue": "In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Severyn et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Severyn et al\\.", "year": 2013}, {"title": "End-to-end memory networks", "author": ["Sukhbaatar", "Sainbayar", "Szlam", "Arthur", "Weston", "Jason", "Fergus", "Rob"], "venue": "arXiv preprint arXiv:1503.08895,", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc V"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Document modeling with gated recurrent neural network for sentiment classification", "author": ["Tang", "Duyu", "Qin", "Bing", "Liu", "Ting"], "venue": "In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "A neural conversational model", "author": ["Vinyals", "Oriol", "Le", "Quoc V"], "venue": "Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "A long short-term memory model for answer sentence selection in question answering", "author": ["Wang", "Di", "Nyberg", "Eric"], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Probabilistic tree-edit models with structured latent variables for textual entailment and question answering", "author": ["Wang", "Mengqiu", "Manning", "Christopher"], "venue": "The Proceedings of the 23rd International Conference on Computational Linguistics (COLING),", "citeRegEx": "Wang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2010}, {"title": "What is the jeopardy model? a quasisynchronous grammar for qa", "author": ["Wang", "Mengqiu", "Smith", "Noah", "Teruko", "Mitamura"], "venue": "The Proceedings of EMNLP-CoNLL,", "citeRegEx": "Wang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2007}, {"title": "tagspace: Semantic embeddings from hashtags", "author": ["Weston", "Jason", "Chopra", "Sumit", "Adams", "Keith"], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Weston et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "Answer extraction as sequence tagging with tree edit distance", "author": ["Yao", "Xuchen", "Durme", "Benjamin", "Clark", "Peter"], "venue": "Proceedings of NAACL-HLT,", "citeRegEx": "Yao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2013}, {"title": "Question answering using enhanced lexical semantic models", "author": ["Yih", "Wen-tau", "Chang", "Ming-Wei", "Meek", "Christopher", "Pastusiak", "Andrzej"], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguist (ACL),", "citeRegEx": "Yih et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2013}, {"title": "Deep learning for answer sentence selection", "author": ["Yu", "Lei", "Hermann", "Karl M", "Blunsom", "Phil", "Pulman", "Stephen"], "venue": "NIPS Deep Learning Workshop,", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 13, "context": "Recently, deep learning models have obtained a significant success on various natural language processing tasks, such as semantic analysis (Tang et al., 2015), machine translation (Bahdanau et al.", "startOffset": 139, "endOffset": 158}, {"referenceID": 0, "context": ", 2015), machine translation (Bahdanau et al., 2015) and text summarization (Rush et al.", "startOffset": 29, "endOffset": 52}, {"referenceID": 9, "context": ", 2015) and text summarization (Rush et al., 2015).", "startOffset": 31, "endOffset": 50}, {"referenceID": 2, "context": "We conduct the experiments based on InsuranceQA (Feng et al., 2015) 1, a newly-released non-factoid QA dataset from the insurance domain.", "startOffset": 48, "endOffset": 67}, {"referenceID": 20, "context": "For example, semantic features were constructed based on WordNet in (Yih et al., 2013).", "startOffset": 68, "endOffset": 86}, {"referenceID": 17, "context": "In (Wang & Manning, 2010; Wang et al., 2007), the answer selection problem is transformed to a syntactical matching between the question/answer parse trees.", "startOffset": 3, "endOffset": 44}, {"referenceID": 19, "context": "Some work tried to fulfill the matching using minimal edit sequences between dependency parse trees (Heilman & Smith, 2010; Yao et al., 2013).", "startOffset": 100, "endOffset": 141}, {"referenceID": 2, "context": "The approaches for non-factoid question answering generally pursue the solution on the following directions: Firstly, the question and answer representations are learned and matched by certain similarity metrics (Feng et al., 2015; Yu et al., 2014).", "startOffset": 212, "endOffset": 248}, {"referenceID": 21, "context": "The approaches for non-factoid question answering generally pursue the solution on the following directions: Firstly, the question and answer representations are learned and matched by certain similarity metrics (Feng et al., 2015; Yu et al., 2014).", "startOffset": 212, "endOffset": 248}, {"referenceID": 0, "context": "Finally, recently proposed models for textual generation can intrinsically be used for answer selection and generation (Bahdanau et al., 2015; Vinyals & Le, 2015).", "startOffset": 119, "endOffset": 162}, {"referenceID": 2, "context": "There are two major differences between our approaches and the work in (Feng et al., 2015): (1) The architectures developed in (Feng et al.", "startOffset": 71, "endOffset": 90}, {"referenceID": 2, "context": ", 2015): (1) The architectures developed in (Feng et al., 2015) are only based on CNN, whereas our models are based on bidirectional LSTMs, which are more capable of exploiting long-range sequential context information.", "startOffset": 44, "endOffset": 63}, {"referenceID": 0, "context": "Finally, recently proposed models for textual generation can intrinsically be used for answer selection and generation (Bahdanau et al., 2015; Vinyals & Le, 2015). The proposed framework belongs to the first category. There are two major differences between our approaches and the work in (Feng et al., 2015): (1) The architectures developed in (Feng et al., 2015) are only based on CNN, whereas our models are based on bidirectional LSTMs, which are more capable of exploiting long-range sequential context information. Moreover, we also integrate the CNN structures on the top of biLSTM for better performance. (2) Feng et al. (2015) tackle the question and answer independently, while one of our proposed structures developed an efficient attentive models to generate answer embeddings according to the question.", "startOffset": 120, "endOffset": 636}, {"referenceID": 3, "context": "Our LSTM implementation is similar to the one in (Graves et al., 2013) with minor modification.", "startOffset": 49, "endOffset": 70}, {"referenceID": 2, "context": "Following the same ranking loss in (Feng et al., 2015; Weston et al., 2014; Hu et al., 2014), we define the training objective as a hinge loss.", "startOffset": 35, "endOffset": 92}, {"referenceID": 18, "context": "Following the same ranking loss in (Feng et al., 2015; Weston et al., 2014; Hu et al., 2014), we define the training objective as a hinge loss.", "startOffset": 35, "endOffset": 92}, {"referenceID": 7, "context": "Following the same ranking loss in (Feng et al., 2015; Weston et al., 2014; Hu et al., 2014), we define the training objective as a hinge loss.", "startOffset": 35, "endOffset": 92}, {"referenceID": 2, "context": "As discussed in (Feng et al., 2015), this is reasonable, because for a shared layer network, the corresponding elements in question and answer vectors represent the same biLSTM outputs.", "startOffset": 16, "endOffset": 35}, {"referenceID": 2, "context": "The structure of CNN in this work is similar to the one in (Feng et al., 2015), as shown in Figure 2.", "startOffset": 59, "endOffset": 78}, {"referenceID": 0, "context": "This strategy has been used in many other natural language processing tasks, such as machine translation (Bahdanau et al., 2015; Sutskever et al., 2014), sentence summarization (Rush et al.", "startOffset": 105, "endOffset": 152}, {"referenceID": 12, "context": "This strategy has been used in many other natural language processing tasks, such as machine translation (Bahdanau et al., 2015; Sutskever et al., 2014), sentence summarization (Rush et al.", "startOffset": 105, "endOffset": 152}, {"referenceID": 9, "context": ", 2014), sentence summarization (Rush et al., 2015) and factoid question answering (Hermann et al.", "startOffset": 32, "endOffset": 51}, {"referenceID": 5, "context": ", 2015) and factoid question answering (Hermann et al., 2015; Sukhbaatar et al., 2015).", "startOffset": 39, "endOffset": 86}, {"referenceID": 11, "context": ", 2015) and factoid question answering (Hermann et al., 2015; Sukhbaatar et al., 2015).", "startOffset": 39, "endOffset": 86}, {"referenceID": 5, "context": "Inspired by the work in (Hermann et al., 2015), we develop a very simple but efficient attention on the basic model.", "startOffset": 24, "endOffset": 46}, {"referenceID": 5, "context": "The major difference between this approach and the one in (Hermann et al., 2015) is that Hermann et al.", "startOffset": 58, "endOffset": 80}, {"referenceID": 5, "context": "The major difference between this approach and the one in (Hermann et al., 2015) is that Hermann et al. (2015)\u2019s attentive reader emphasizes the informative part of supporting facts, and then uses a combined embedding of the query and the supporting facts to predict the factoid answers.", "startOffset": 59, "endOffset": 111}, {"referenceID": 2, "context": "Having described a number of models in the previous section, we evaluate the proposed approaches on the insurance domain dataset, InsuranceQA, provided by Feng et al. (2015). The InsuranceQA dataset provides a training set, a validation set, and two test sets.", "startOffset": 155, "endOffset": 174}, {"referenceID": 2, "context": "Architecture-II in (Feng et al., 2015) 61.", "startOffset": 19, "endOffset": 38}, {"referenceID": 2, "context": "Architecture-II in (Feng et al., 2015): Instead of using LSTM, a CNN model is employed to learn a distributed vector representation of a given question and its answer candidates, and the answers are scored by cosine similarity with the question.", "startOffset": 19, "endOffset": 38}, {"referenceID": 2, "context": "This is the model which achieved the best performance in (Feng et al., 2015).", "startOffset": 57, "endOffset": 76}, {"referenceID": 1, "context": "The models in this work is implemented with Theano (Bastien et al., 2012) from scratch, and all experiments are processed in a GPU cluster.", "startOffset": 51, "endOffset": 73}, {"referenceID": 8, "context": "The word embedding is trained by word2vec (Mikolov et al., 2013), and the word vector size is 100.", "startOffset": 42, "endOffset": 64}, {"referenceID": 2, "context": "Compared to Architecture II in (Feng et al., 2015), which involved a large number of CNN filters, (H) model also has fewer parameters.", "startOffset": 31, "endOffset": 50}, {"referenceID": 2, "context": "Row F shared a highly analogous CNN structure with Architecture II in Feng et al. (2015), except that the later used a shallow hidden layer to transform the word embeddings into the input of CNN structure, while Row F take the output of biLSTM as CNN input.", "startOffset": 70, "endOffset": 89}], "year": 2017, "abstractText": "In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework, the other is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. Experimental results on a public insurance-domain dataset demonstrate that the extended models substantially outperform two state-of-theart non-DL baselines and a strong DL baseline.", "creator": "LaTeX with hyperref package"}}}