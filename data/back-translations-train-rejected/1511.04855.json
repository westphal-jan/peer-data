{"id": "1511.04855", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Nov-2015", "title": "Deep Learning for steganalysis is better than a Rich Model with an Ensemble Classifier, and is natively robust to the cover source-mismatch", "abstract": "Since the BOSS competition, in 2010, most steganalysis approaches use a learning methodology involving two steps: feature extraction, such as the Rich Models (RM), for the image representation, and use of the Ensemble Classifier (EC) for the learning step. In 2015, Qian et al. have shown that the use of a deep learning approach that jointly learns and computes the features, is very promising for the steganalysis. In this paper, we follow-up the study of Qian et al., and show that, due to intrinsic joint minimization, the results obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural Network (FNN), if well parameterized, surpass the conventional use of a RM with an EC. First, numerous experiments were conducted in order to find the best \" shape \" of the CNN. Second, experiments were carried out in the clairvoyant scenario in order to compare the CNN and FNN to an RM with an EC. The results show more than 16% reduction in the classification error with our CNN or FNN. Third, experiments were also performed in a cover-source mismatch setting. The results show that the CNN and FNN are naturally robust to the mismatch problem. In Addition to the experiments, we provide discussions on the internal mechanisms of a CNN, and weave links with some previously stated ideas, in order to understand the impressive results we obtained.", "histories": [["v1", "Mon, 16 Nov 2015 07:59:14 GMT  (361kb,D)", "http://arxiv.org/abs/1511.04855v1", "IS&amp;T. Media Watermarking, Security, and Forensics, Part of IS&amp;T International Symposium on Electronic Imaging, EI'2016, Feb 2015, San Fransisco, United States"]], "COMMENTS": "IS&amp;T. Media Watermarking, Security, and Forensics, Part of IS&amp;T International Symposium on Electronic Imaging, EI'2016, Feb 2015, San Fransisco, United States", "reviews": [], "SUBJECTS": "cs.MM cs.CV cs.LG cs.NE", "authors": ["lionel pibre", "pasquet j\\'er\\^ome", "dino ienco", "marc chaumont"], "accepted": false, "id": "1511.04855"}, "pdf": {"name": "1511.04855.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for steganalysis is better than a Rich Model with an Ensemble Classifier, and is natively robust to the cover source-mismatch", "authors": ["Lionel PIBRE", "J\u00e9r\u00f4me PASQUET", "Dino IENCO", "Marc CHAUMONT"], "emails": ["marc.chaumont}@lirmm.fr"], "sections": [{"heading": null, "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "Author Biography", "text": "He obtained his master's degree in computer science in Montpellier. His master's degree enabled him to study data, visualization, machine learning and NLP. He did his internship in the LIRMM laboratory. His areas of work are multimedia security (steganography / steganalysis), segmentation and image tracking. The more he is able to do his doctoral thesis in the LIRMM laboratory, the more he will be able to write his doctoral thesis."}], "references": [{"title": "Breaking HUGO - The Process Discovery", "author": ["J. Fridrich", "J. Kodovsk\u00fd", "V. Holub", "M. Goljan"], "venue": "Proceedings of the 13th International Conference on Information Hiding, IH\u20192011, Prague, Czech Republic, May 2011, vol. 6958 of Lecture Notes in Computer Science, pp. 85\u2013101, Springer.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "On Completeness of Feature Spaces in Blind Steganalysis", "author": ["J. Kodovsk\u00fd", "J. Fridrich"], "venue": "Proceedings of the 10th ACM Workshop on Multimedia and Security, MM&Sec\u20192008, Oxford, United Kingdom, Sept. 2008, pp. 123\u2013132.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Rich Models for Steganalysis of Digital Images", "author": ["J. Fridrich", "J. Kodovsk\u00fd"], "venue": "IEEE Transactions on Information Forensics and Security, TIFS, vol. 7, no. 3, pp. 868\u2013882, June 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "LIBSVM: A Library for Support Vector Machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, vol. 2, pp. 27:1\u201327:27, 2011, Software available at http://www.csie.ntu.edu.tw/ cjlin/libsvm.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Ensemble Classifiers for Steganalysis of Digital Media", "author": ["J. Kodovsk\u00fd", "J. Fridrich", "V. Holub"], "venue": "IEEE Transactions on Information Forensics and Security, TIFS, vol. 7, no. 2, pp. 432\u2013444, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Steganalysis with Mismatched Covers: Do Simple Classifiers Help", "author": ["I. Lubenko", "A.D. Ker"], "venue": "Proceedings of the 14th ACM multimedia and Security Workshop, MM&Sec\u20192012, Coventry, United Kingdom, Sept. 2012, pp. 11\u201318.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Moving Steganography and Steganalysis from the Laboratory into the Real World", "author": ["A.D. Ker", "P. Bas", "R. B\u00f6hme", "R. Cogranne", "S. Craver", "T. Filler", "J. Fridrich", "T. Pevn\u00fd"], "venue": "Proceedings of the 1st ACM Workshop on Information Hiding and Multimedia Security, IH&MMSec\u20192013, Montpellier, France, June 2013, pp. 45\u201358, ACM.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Detecting Messages of Unknown Length", "author": ["T. Pevn\u00fd"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE 21th Annual Symposium on Electronic Imaging, SPIE\u20192011, San Francisco, California, USA, Feb. 2011, vol. 7880.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Selection-Channel-Aware Rich Model for Steganalysis of Digital Images", "author": ["T. Denemark", "V. Sedighi", "V. Holub", "R. Cogranne", "J. Fridrich"], "venue": "Proceedings of the IEEE International Workshop on Information Forensics and Security, WIFS\u20192014, Atlanta, GA, Dec. 2014, pp. 48\u201353.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Theoretical Model of the FLD Ensemble Classifier Based on Hypothesis Testing Theory", "author": ["R. Cogranne", "T. Denemark", "J. Fridrich"], "venue": "Proceedings of IEEE International Workshop on Information Forensics and Security, WIFS\u20192014, Atlanta, GA, Dec. 2014, pp. 167\u2013172.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Steganalysis by Ensemble Classifiers with Boosting by Regression, and Post-Selection of Features", "author": ["M. Chaumont", "S. Kouider"], "venue": "Proceedings of IEEE International Conference on Image Processing, ICIP\u20192012, Lake Buena Vista (suburb of Orlando), Florida, USA, Sept. 2012, pp. 1133\u2013 1136.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Steganalysis with Cover-Source Mismatch and a Small Learning Database", "author": ["J. Pasquet", "S. Bringay", "M. Chaumont"], "venue": "Proceedings of the 22nd European Signal Processing Conference 2014, EUSIPCO\u20192014, Lisbon, Portugal, Sept. 2014, pp. 2425\u20132429.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems 25, NIPS\u20192012, F. Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger, Eds., pp. 1097\u20131105. Curran Associates, Inc., 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep Learning for Steganalysis via Convolutional Neural Networks", "author": ["Yinlong Qian", "Jing Dong", "Wei Wang", "Tieniu Tan"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics 2015, Part of IS&T/SPIE Annual Symposium on Electronic Imaging, SPIE\u20192015, San Francisco, California, USA, Feb. 2015, vol. 9409, pp. 94090J\u201394090J\u2013 10.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Using High-Dimensional Image Models to Perform Highly Undetectable Steganography", "author": ["T. Pevn\u00fd", "T. Filler", "P. Bas"], "venue": "Proceedings of the 12th International Conference on Information Hiding, IH\u20192010, Calgary, Alberta, Canada, June 2010, vol. 6387 of Lecture Notes in Computer Science, pp. 161\u2013177, Springer.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Designing Steganographic Distortion Using Directional Filters", "author": ["V. Holub", "J. Fridrich"], "venue": "Proceedings of the IEEE International Workshop on Information Forensics and Security, WIFS\u20192012, Tenerife, Spain, Dec. 2012, pp. 234\u2013239.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Universal Distortion Function for Steganography in an Arbitrary Domain", "author": ["V. Holub", "J. Fridrich", "T. Denemark"], "venue": "EURASIP Journal on Information Security, JIS, vol. 2014, no. 1, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Break Our Steganographic System\u2019: The Ins and Outs of Organizing BOSS", "author": ["P. Bas", "T. Filler", "T. Pevn\u00fd"], "venue": "Proceedings of the 13th International Conference on Information Hiding, IH\u20192011, Prague, Czech Republic, May 2011, vol. 6958 of Lecture Notes in Computer Science, pp. 59\u201370, Springer.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Reducing the Dimensionality of Data with Neural Networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, July 2006.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Yoshua Bengio", "Aaron C. Courville", "Pascal Vincent"], "venue": "IEEE Transaction on Pattern Analysis and Machine Intelligence, PAMI, vol. 35, no. 8, pp. 1798\u20131828, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1828}, {"title": "Adaptive Steganalysis Against WOW Embedding Algorithm", "author": ["Weixuan Tang", "Haodong Li", "Weiqi Luo", "Jiwu Huang"], "venue": "Proceedings of the 2nd ACM Workshop on Information Hiding and Multimedia Security, IH&MMSec\u20192014, Salzburg, Austria, 2014, pp. 91\u201396.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Going from Small to Large Data in Steganalysis", "author": ["I. Lubenko", "A.D. Ker"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics III, Part of IS&T/SPIE 22th Annual Symposium on Electronic Imaging, SPIE\u20192012, San Francisco, California, USA, Feb. 2012, vol. 8303.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "A Mishmash of Methods for Mitigating the Model Mismatch Mess", "author": ["A.D. Ker", "T. Pevn\u00fd"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE 24th Annual Symposium on Electronic Imaging, SPIE\u20192014, San Francisco, California, USA, Feb. 2014, vol. 9028, pp. 90280I\u201390280I\u201315.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Study of Cover Source Mismatch in Steganalysis and Ways to Mitigate its Impact", "author": ["J. Kodovsk\u00fd", "V. Sedighi", "J. Fridrich"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE 24th Annual Symposium on Electronic Imaging, SPIE\u20192014, San Francisco, California, USA, Feb. 2014, vol. 9028, pp. 90280J\u201390280J\u2013 12.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "BOWS-2 Contest (Break Our Watermarking System)", "author": ["P. Bas", "T. Furon"], "venue": "2008, Organized between the 17th of July 2007 and the 17th of April 2008. http://bows2.eclille.fr/.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "A Comparative Study of +/-1 Steganalyzers", "author": ["G. Cancelli", "G.J. Do\u00ebrr", "M. Barni", "I.J. Cox"], "venue": "Proceedings of the IEEE 10th Workshop on Multimedia Signal Processing, MMSP\u20192008, 2008, pp. 791\u2013796.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Optimizing Pixel Predictors for  Steganalysis", "author": ["V. Holub", "J. Fridrich"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE 22th Annual Symposium on Electronic Imaging, SPIE\u20192012, San Francisco, California, USA, Feb. 2012, vol. 8303, pp. 830309\u2013 830309\u201313.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Random Projections of Residuals as an Alternative to Co-occurrences in Steganalysis", "author": ["V. Holub", "J. Fridrich", "T. Denemark"], "venue": "Proceedings of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE Annual Symposium on Electronic Imaging, SPIE\u20192013, San Francisco, California, USA, Feb. 2013, vol. 8665, pp. 86650L\u2013 86650L\u201311.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Steganalysis of Adaptive JPEG Steganography Using 2D Gabor Filters", "author": ["Xiaofeng Song", "Fenlin Liu", "Chunfang Yang", "Xiangyang Luo", "Yi Zhang"], "venue": "Proceedings of the 3rd ACM Workshop on Information Hiding and Multimedia Security, IH&MMSec\u201920015, Portland, Oregon, USA, June 2015, pp. 15\u201323.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2001}, {"title": "Low-Complexity Features for JPEG Steganalysis Using Undecimated DCT", "author": ["V. Holub", "J. Fridrich"], "venue": "IEEE Transactions on Information Forensics and Security, TIFS, vol. 10, no. 2, pp. 219\u2013228, Feb 2015.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Co-occurrence Steganalysis in High Dimensions", "author": ["T. Pevn\u00fd"], "venue": "Proceeding of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE 22th Annual Symposium on Electronic Imaging, SPIE\u20192012, San Francisco, California, USA, Feb. 2012, vol. 8303, pp. 83030B\u2013 83030B\u201313.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "The Challenges of Rich Features in Universal Steganalysis", "author": ["T. Pevn\u00fd", "A.D. Ker"], "venue": "Proceeding of SPIE Media Watermarking, Security, and Forensics, Part of IS&T/SPIE 23th Annual Symposium on Electronic Imaging, SPIE\u20192013, San Francisco, California, USA, Feb. 2013, vol. 8665, pp. 86650M\u201386650M\u201315.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Those features must be diverse [1], which means that they should capture the maximum of information modeling the image, and they also should be complete [2], which means that their values should be different between a cover and a stego.", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "Those features must be diverse [1], which means that they should capture the maximum of information modeling the image, and they also should be complete [2], which means that their values should be different between a cover and a stego.", "startOffset": 153, "endOffset": 156}, {"referenceID": 2, "context": "The best feature set to represent an image has so far been supplied by Rich Models [3].", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "Depending on the memory or computation requirements, the steganalyst can use an SVM [4], an Ensemble Classifier [5], or a Perceptron [6].", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "Depending on the memory or computation requirements, the steganalyst can use an SVM [4], an Ensemble Classifier [5], or a Perceptron [6].", "startOffset": 112, "endOffset": 115}, {"referenceID": 5, "context": "Depending on the memory or computation requirements, the steganalyst can use an SVM [4], an Ensemble Classifier [5], or a Perceptron [6].", "startOffset": 133, "endOffset": 136}, {"referenceID": 6, "context": "When analyzing the empirical security of an embedding algorithm in a laboratory environment [7], we select the \u201dclairvoyant scenario\u201d [8], i.", "startOffset": 92, "endOffset": 95}, {"referenceID": 7, "context": "When analyzing the empirical security of an embedding algorithm in a laboratory environment [7], we select the \u201dclairvoyant scenario\u201d [8], i.", "startOffset": 134, "endOffset": 137}, {"referenceID": 4, "context": "Until 2015, in the clairvoyant scenario, the best classifier was the Ensemble Classifier [5].", "startOffset": 89, "endOffset": 92}, {"referenceID": 8, "context": "Moreover, some improvements have been proposed in order to increase its efficiency, such as the use of embedding probabilities in order to better steganalyze the adaptive algorithms [9], tuning of false alarm probability [10], or treating the cover-source mismatch problem [11], where the best classifier is also the Ensemble Classifier [12].", "startOffset": 182, "endOffset": 185}, {"referenceID": 9, "context": "Moreover, some improvements have been proposed in order to increase its efficiency, such as the use of embedding probabilities in order to better steganalyze the adaptive algorithms [9], tuning of false alarm probability [10], or treating the cover-source mismatch problem [11], where the best classifier is also the Ensemble Classifier [12].", "startOffset": 221, "endOffset": 225}, {"referenceID": 10, "context": "Moreover, some improvements have been proposed in order to increase its efficiency, such as the use of embedding probabilities in order to better steganalyze the adaptive algorithms [9], tuning of false alarm probability [10], or treating the cover-source mismatch problem [11], where the best classifier is also the Ensemble Classifier [12].", "startOffset": 273, "endOffset": 277}, {"referenceID": 11, "context": "Moreover, some improvements have been proposed in order to increase its efficiency, such as the use of embedding probabilities in order to better steganalyze the adaptive algorithms [9], tuning of false alarm probability [10], or treating the cover-source mismatch problem [11], where the best classifier is also the Ensemble Classifier [12].", "startOffset": 337, "endOffset": 341}, {"referenceID": 12, "context": "Yet, in recent years, in different areas, the use of deep learning networks challenges traditional two step approaches (feature extraction, and use of a classifier) [13].", "startOffset": 165, "endOffset": 169}, {"referenceID": 13, "context": "[14] proposed, in 2015, to use deep learning to replace the traditional two step approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "obtained a detection percentage of only 3% to 4% lower than that obtained with the Ensemble Classifier [5], and SRM features [3].", "startOffset": 103, "endOffset": 106}, {"referenceID": 2, "context": "obtained a detection percentage of only 3% to 4% lower than that obtained with the Ensemble Classifier [5], and SRM features [3].", "startOffset": 125, "endOffset": 128}, {"referenceID": 14, "context": "The tested algorithms were HUGO [15], WOW [16], and S-UNIWARD [17], on the BOSSbase database [18].", "startOffset": 32, "endOffset": 36}, {"referenceID": 15, "context": "The tested algorithms were HUGO [15], WOW [16], and S-UNIWARD [17], on the BOSSbase database [18].", "startOffset": 42, "endOffset": 46}, {"referenceID": 16, "context": "The tested algorithms were HUGO [15], WOW [16], and S-UNIWARD [17], on the BOSSbase database [18].", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "The tested algorithms were HUGO [15], WOW [16], and S-UNIWARD [17], on the BOSSbase database [18].", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "Indeed, the dimension of the feature vector of the last convolution layer (layer 5) provides only 256 features, whereas the SRM (Spatial Rich Models) dimension of the feature vector provides 34671 [3].", "startOffset": 197, "endOffset": 200}, {"referenceID": 13, "context": "[14].", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Until recently [19], neural networks were considered as having a too long learning time, and as being less efficient than modern classifiers.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "Recently, due to recent advances in the neural network field [20], and to the computational power supplied by GPUs, deep learning approaches have been proposed as a natural extension of neural networks, and they are getting popular due to their high classification performance.", "startOffset": 61, "endOffset": 65}, {"referenceID": 18, "context": "Since 2006 [19], many adjustments have been proposed to improve the robustness and reduce the computational costs.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "In this paper, we recall the major concepts of a Convolutional Neural Networks (CNN), which is a deep learning network that has proved its efficiency in image classification competitions [13], and that was used by Qian et al.", "startOffset": 187, "endOffset": 191}, {"referenceID": 0, "context": "Then, a softmax function is connected to the outputs of the last layer in order to normalize the two outputs delivered by the network between [0,1].", "startOffset": 142, "endOffset": 147}, {"referenceID": 13, "context": "Convolutional Neural Network [14].", "startOffset": 29, "endOffset": 33}, {"referenceID": 2, "context": "There is no similar operation in the classical feature extraction process supplied by Rich Models [3], and to the best of our knowledge, in spatio-frequential decomposition.", "startOffset": 98, "endOffset": 101}, {"referenceID": 4, "context": "This is usually an interesting property that is exploited in the Ensemble Classifier through the majority vote [5], and that is also used in the Rich Models with the Min-Max features [3].", "startOffset": 111, "endOffset": 114}, {"referenceID": 2, "context": "This is usually an interesting property that is exploited in the Ensemble Classifier through the majority vote [5], and that is also used in the Rich Models with the Min-Max features [3].", "startOffset": 183, "endOffset": 186}, {"referenceID": 17, "context": "0 [18] consisting of 10 000 grey-level images of size 512\u00d7 512 coming from 7 different cameras, then we split each image in four in order to obtain 40 000 images of size 256\u00d7256.", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": "In our experiments, we embeded the messages (using the simulator) with S-UNIWARD [17] at 0.", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "The paper essentially demonstrates that a CNN is more efficient than an Ensemble Classifier, or an Ensemble Classifier informed on the selection channel (adaptive steganalysis scenario) [21, 9].", "startOffset": 186, "endOffset": 193}, {"referenceID": 8, "context": "The paper essentially demonstrates that a CNN is more efficient than an Ensemble Classifier, or an Ensemble Classifier informed on the selection channel (adaptive steganalysis scenario) [21, 9].", "startOffset": 186, "endOffset": 193}, {"referenceID": 0, "context": "The operations performed in the last layer are dot products, bias additions, and then a softmax in order to rescale the output values in [0,1].", "startOffset": 137, "endOffset": 142}, {"referenceID": 6, "context": "This scenario is a laboratory scenario used to empirically assess the security of a steganographic embedding algorithm [7].", "startOffset": 119, "endOffset": 122}, {"referenceID": 16, "context": "We embed with S-UNIWARD [17] at 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 2, "context": "The first steganalysis was done using Rich Models [3] and an Ensemble Classifier [5].", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "The first steganalysis was done using Rich Models [3] and an Ensemble Classifier [5].", "startOffset": 81, "endOffset": 84}, {"referenceID": 10, "context": "The one given on the Binghamton website10; in that case the learning set only consists of 10 000 images, and the one written in C++ and proposed in the paper [11] with the features selection, and parallelization options; in that case, the learning set consists of 60 000 images.", "startOffset": 158, "endOffset": 162}, {"referenceID": 20, "context": "e adaptive steganalysis [21], also named selection-channel-aware steganalysis [9].", "startOffset": 24, "endOffset": 28}, {"referenceID": 8, "context": "e adaptive steganalysis [21], also named selection-channel-aware steganalysis [9].", "startOffset": 78, "endOffset": 81}, {"referenceID": 8, "context": "In that scenario, authors from [9] report a detectability improvement of 1 to 4% with the Ensemble Classifier and SRM for detecting S-UNIWARD on the BossBase database.", "startOffset": 31, "endOffset": 34}, {"referenceID": 11, "context": "Only a few papers have assessed the cover-source mismatch in practice [12], and [22, 6].", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "Only a few papers have assessed the cover-source mismatch in practice [12], and [22, 6].", "startOffset": 80, "endOffset": 87}, {"referenceID": 5, "context": "Only a few papers have assessed the cover-source mismatch in practice [12], and [22, 6].", "startOffset": 80, "endOffset": 87}, {"referenceID": 22, "context": "Nevertheless, no satisfactory solution is currently available, even though there have been some attempts to understand the phenomenon [23, 24].", "startOffset": 134, "endOffset": 142}, {"referenceID": 23, "context": "Nevertheless, no satisfactory solution is currently available, even though there have been some attempts to understand the phenomenon [23, 24].", "startOffset": 134, "endOffset": 142}, {"referenceID": 24, "context": "Other experiments on BOWSBase [25] also confirmed that CNN is robust to the cover-source mismatch phenomenon, whereas RM+EC is not.", "startOffset": 30, "endOffset": 34}, {"referenceID": 25, "context": "mismatch was so good that the mismatch phenomenon was no longer present, and we thus obtained steganalysis results that were more related to the content complexity of the data-base [26] (Textured image databases are harder to steganalysis than homogenous ones).", "startOffset": 181, "endOffset": 185}, {"referenceID": 26, "context": "This strategy already shown its efficiency in [27].", "startOffset": 46, "endOffset": 50}, {"referenceID": 27, "context": "Some recent articles use such spatio-frequential decomposition (or a projection as in PSRM [28]) in order to compute Rich Models using Gabor filters [29] or DCT filters (DCTR features) [30].", "startOffset": 91, "endOffset": 95}, {"referenceID": 28, "context": "Some recent articles use such spatio-frequential decomposition (or a projection as in PSRM [28]) in order to compute Rich Models using Gabor filters [29] or DCT filters (DCTR features) [30].", "startOffset": 149, "endOffset": 153}, {"referenceID": 29, "context": "Some recent articles use such spatio-frequential decomposition (or a projection as in PSRM [28]) in order to compute Rich Models using Gabor filters [29] or DCT filters (DCTR features) [30].", "startOffset": 185, "endOffset": 189}, {"referenceID": 2, "context": "When looking more precisely at the second convolution layer, which applies a very unusual convolution approach, nothing similar could be found in recent papers dealing with feature extraction, such as histogram computation [3, 28], non-uniform quantization [31], feature selection [11], dimension reduction [32], etc.", "startOffset": 223, "endOffset": 230}, {"referenceID": 27, "context": "When looking more precisely at the second convolution layer, which applies a very unusual convolution approach, nothing similar could be found in recent papers dealing with feature extraction, such as histogram computation [3, 28], non-uniform quantization [31], feature selection [11], dimension reduction [32], etc.", "startOffset": 223, "endOffset": 230}, {"referenceID": 30, "context": "When looking more precisely at the second convolution layer, which applies a very unusual convolution approach, nothing similar could be found in recent papers dealing with feature extraction, such as histogram computation [3, 28], non-uniform quantization [31], feature selection [11], dimension reduction [32], etc.", "startOffset": 257, "endOffset": 261}, {"referenceID": 10, "context": "When looking more precisely at the second convolution layer, which applies a very unusual convolution approach, nothing similar could be found in recent papers dealing with feature extraction, such as histogram computation [3, 28], non-uniform quantization [31], feature selection [11], dimension reduction [32], etc.", "startOffset": 281, "endOffset": 285}, {"referenceID": 31, "context": "When looking more precisely at the second convolution layer, which applies a very unusual convolution approach, nothing similar could be found in recent papers dealing with feature extraction, such as histogram computation [3, 28], non-uniform quantization [31], feature selection [11], dimension reduction [32], etc.", "startOffset": 307, "endOffset": 311}, {"referenceID": 9, "context": "To close the discussion, we should also add that the last treatment of each layer is a normalization step, and that this type of processing can also be found in papers such as [33] or [10].", "startOffset": 184, "endOffset": 188}, {"referenceID": 4, "context": "The activation introduced non-linearity, which is also the case in the Ensemble Classifier through the majority vote [5], or in Rich Models with the Min-Max features [3].", "startOffset": 117, "endOffset": 120}, {"referenceID": 2, "context": "The activation introduced non-linearity, which is also the case in the Ensemble Classifier through the majority vote [5], or in Rich Models with the Min-Max features [3].", "startOffset": 166, "endOffset": 169}], "year": 2015, "abstractText": "Since the BOSS competition, in 2010, most steganalysis approaches use a learning methodology involving two steps: feature extraction, such as the Rich Models (RM), for the image representation, and use of the Ensemble Classifier (EC) for the learning step. In 2015, Qian et al. have shown that the use of a deep learning approach that jointly learns and computes the features, is very promising for the steganalysis. In this paper, we follow-up the study of Qian et al., and show that, due to intrinsic joint minimization, the results obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural Network (FNN), if well parameterized, surpass the conventional use of a RM with an EC. First, numerous experiments were conducted in order to find the best \u201dshape\u201d of the CNN. Second, experiments were carried out in the clairvoyant scenario in order to compare the CNN and FNN to an RM with an EC. The results show more than 16% reduction in the classification error with our CNN or FNN. Third, experiments were also performed in a cover-source mismatch setting. The results show that the CNN and FNN are naturally robust to the mismatch problem. In Addition to the experiments, we provide discussions on the internal mechanisms of a CNN, and weave links with some previously stated ideas, in order to understand the impressive results we obtained.", "creator": "LaTeX with hyperref package"}}}