{"id": "1511.05389", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2015", "title": "Learning to retrieve out-of-vocabulary words in speech recognition", "abstract": "Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech recognition systems used to process diachronic audio data. To help recovery of the PNs missed by the system, relevant OOV PNs can be retrieved out of the many OOVs by exploiting semantic context of the spoken content. In this paper, we propose two neural network models targeted to retrieve OOV PNs relevant to an audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b) Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models take document words as input and learn with an objective to maximise the retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new approach in which the input embedding layer is augmented with a context anchor layer. This layer learns to assign importance to input words and has the ability to capture (task specific) key-words in a bag-of-word neural network model. With experiments on French broadcast news videos we show that these two models outperform the baseline methods based on raw embeddings from LDA, Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives faster convergence during training.", "histories": [["v1", "Tue, 17 Nov 2015 13:18:07 GMT  (365kb,D)", "https://arxiv.org/abs/1511.05389v1", "Under review as a conference paper at ICLR 2016"], ["v2", "Fri, 4 Dec 2015 09:39:29 GMT  (397kb,D)", "http://arxiv.org/abs/1511.05389v2", "Under review as a conference paper at ICLR 2016; updated references, added appendix discussing more results"], ["v3", "Thu, 7 Jan 2016 19:32:55 GMT  (454kb,D)", "http://arxiv.org/abs/1511.05389v3", "Under review as a conference paper at ICLR 2016; updated references, added appendix discussing more results, added more discussion, replaced simple phone search results with KWS results"], ["v4", "Tue, 1 Mar 2016 14:03:44 GMT  (450kb,D)", "http://arxiv.org/abs/1511.05389v4", "Updated references, added appendix discussing more results; added more discussion, replaced simple phone search results with KWS results; added KWS results for both training phase, probably last update"]], "COMMENTS": "Under review as a conference paper at ICLR 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["imran sheikh", "irina illina", "dominique fohr", "georges linar\\`es"], "accepted": false, "id": "1511.05389"}, "pdf": {"name": "1511.05389.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Imran Sheikh", "Irina Illina", "Dominique Fohr"], "emails": ["dominique.fohr}@loria.fr", "georges.linares@univ-avignon.fr"], "sections": [{"heading": null, "text": "Many proper names (PNs) are out-of-vocabulary (OOV) words for speech recognition systems that are used to process diachronic audio data. To facilitate the recovery of missed PNs from the system, relevant OOV PNs can be retrieved from the many OOVs by using the semantic context of the spoken content. In this article, we propose two neural network models that aim to retrieve OOV PNs relevant to an audio document: (a) Document Level Continuous Bag of Words (D-CBOW), (b) Document Level Continuous Bag of Weighted Words (D-CBOW2). Both models take document words as input and learn to maximize the recovery of cooperative OOV-PNs. With the D-CBOW2 model, we propose a new approach to add these keywords to the input layer of the input layer."}, {"heading": "1 INTRODUCTION", "text": "This year it is more than ever before in the history of the city."}, {"heading": "1.1 RELATED WORK", "text": "The task of retrieving OOV and PNs relevant to an audio document has been presented before. Bigot et al. (2013); Senay et al. (2013) use an LDA / LSA context model per PN that limits the approach to common PNs. Sheikh et al. (2015b; a) presented methods that are based on probable topic models and address the problems in the ranking of PNs that arise due to bias in the probable topic models, methods that can easily be applied to audio documents with single or coherent events. Fohr & Fowler has applied word embedding to audio documents that appear one after the other."}, {"heading": "2 METHODS TO REPRESENT AND RETRIEVE OOV PROPER NAMES", "text": "As already mentioned, our task is to find OOV-PNs that are relevant to an audio document. To achieve this, we strive to learn a context vector space that captures the relationship between the vocabulary words & PNs and the OOV-PNs, using a diachronic text corpus from the Internet. During the test, the LVCSR hypothesis of the audio document is projected into the context space to derive relevant OOV-PNs. In this section, we first briefly introduce the basic LDA-based method, originally 1For a given audio document, several OV-PNs may be relevant, but only a few of them are actually present in the audio document.We refer to the actual OOV-PNs that are present in the audio document as target OOV-PNs in Sheikh et al. (2015b).Then, we present an extension of this method to follow the BOOV-WRP and BOD-2 models proposed."}, {"heading": "2.1 TOPIC SPACE REPRESENTATION BASED ON LDA", "text": "LDA topics are trained on the basis of the diachronic text corpus of (D) documents, whereby the size of the vocabulary (N), the number of topics (T) and the Dirichlet-Priors (\u03b2) are first selected. Theme model parameters \u03b8 and \u03c6 are then estimated with the help of the Gibbs sampling algorithm (Griffiths & Steyvers, 2004). \u03b8 = [\u03b8dt] D \u00b7 T is the distribution of topics for each document d, and \u03c6 = [\u03c6vt] N \u00b7 T is the distribution of topics on words from the vocabulary, both cross-thematic and cross-thematic. Let us derive the LVCSR word hypothesis after h and OOV PNs in diachronic corpus (and theme modelling vocabulary) according to v \u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0441\u043e\u0441\u0441\u0441\u0441\u0441\u043e\u0441\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0441\u0441\u043e\u0441\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043e\u0441\u043e\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043e\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043e\u0441\u0441\u0441\u0441\u0441"}, {"heading": "2.2 RAW WORD EMBEDDINGS FROM PARAGRAPH VECTOR AND SKIP-GRAM MODELS", "text": "Le & Mikolov (2014) proposed Paragraph Vector - a distributed model for the representation of sentences, paragraphs and documents. For our task, this model can represent test documents and OOV-PNs in a common vector space and we examine its performance to retrieve relevant OOV-PNs. K-dimensional vector representation of the LVCSR hypothesis of the audio document (h) is compared with the embeddings (v, \u00b7 i) for each of the OOV-PNs in order to calculate a score as follows: s \u2248 i {CosSim (h, v \u0441i)} (2), where CosSim (\u00b7) is the cosmic similarity measure. The score s is used to classify and retrieve OOV-PNs relevant to the verification of the documentation. We also examine a simple alternative to Paragraph Vectors (h, v \u0418i), in which during the training, the words are learned from all eight OOOV-PNs in the corrector."}, {"heading": "2.3 LEARNING OOV CONTEXT TO MAXIMISE RETRIEVAL PERFORMANCE", "text": "We propose two models that aim to retrieve OOV PNs relevant to an audio document. These models work at the document level and learn with the aim of maximizing the retrieval of the target OOV PNs in the document. We choose document-level input because it is suitable for processing LVCSR transcriptions of audio documents that are prone to noise due to word errors and do not have direct information about the location of OOVs."}, {"heading": "2.3.1 DOCUMENT LEVEL CONTINUOUS BAG OF WORDS (D-CBOW) CONTEXT MODEL", "text": "Figure 1 shows a run-up of the proposed D-CBOW model. The D-CBOW model records all IV words & PNs into a document as you type in. The context vector (cd) for an input document (d) is determined using the matrix vector product between the input word embedding matrix W IV and the input document vector. During the training, the simultaneous OOV PNs are set in the output document. (The cost function used to train the network shares similarity with that of the CBOW model model2Word embedding from the Skip-gram model.) During the test, the softmax probabilities at the output are used as values to propose the OOV-PNs in the original paper Mikolov et al. (2013). In Mikolov et al. (2013), we refer interested readers to Rong (2014) Word-2d embettings from the Skip model."}, {"heading": "2.3.2 DOCUMENT LEVEL CONTINUOUS BAG OF WEIGHTED WORDS (D-CBOW2) CONTEXT MODEL", "text": "Figure 2 shows a run-up of the proposed D-CBOW2 model. Like the D-CBOW model, the D-CBOW2 model records all IV words and PNs in a document as you type in. While the D-CBOW model assigns the OOV-PNs to the simultaneous OOV-PNs in the output document and the Softmax probabilities at the output during the test, the OOV-PNs are used as points to evaluate the OOV-PNs. While the D-CBOW model attaches the same importance to the input embeddings, the D-CBOW2 model learns to assign meaning to input embeddings. To achieve this, it has a context anchor vector that is learned even during the training."}, {"heading": "3 EXPERIMENTS AND RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 EXPERIMENT CORPUS", "text": "The data sets are collected from two different sources: (a) The French newspaper L'Express (http: / / www.lexpress.fr /) (b) The French website of the Euronews television channel (http: / / fr.euronews.com /). The L'Express data set contains text messages, while the Euronews data set contains text messages and news videos and their text transcriptions. In our study, the L'Express data set is used as a diachronic corpus to develop context / theme models, while the Euronews data set contains text messages and text transcriptions. The L'Express data set is used as a diachronic corpus to capture context / theme models relevant to Euronews videos. Euronews text documents referred to as \"validation\" in Table 1 are used as validation."}, {"heading": "3.2 EXPERIMENT SETUP", "text": "The automatic transcriptions of the test audio messages received from ANTS have an average Word Error Rate (WHO) of 40% compared to the reference transcriptions available from Euronews. In order to train the context / theme models, diachronic corpus words are lemmatised and filtered by removing PNs and non-PN words that occur less than 3 times. In addition, a stop list of common French words and non-content-related words is used. In addition, a POS-based filter is used to select words that are labelled as PN, noun, adjective, verb and acronym. PNs that are not present in the ANTS LVCSRlexicon are labelled as BOOV PNs. Context and theme models are trained with this filtered vocabulary. For comparison, the number of DA points and dimensions for the selection of the modality are selected."}, {"heading": "3.3 TRAINING THE D-CBOW GROUP OF MODELS", "text": "As discussed in Section 2.3.1 and Section 2.3.2, the D-CBOW and D-CBOW2 models will be trained in two phases, and the D-CBOW2 + model will also be trained in two phases. To control the training of the D-CBOW, D-CBOW2 and D-CBOW2 + models, an early stop criterion will be used (Bengio, 2012) based on the Validation Kit Error. The early stop will be applied in both the first and second training phases. It should be noted that this error is like a classification error and a measure of whether or not an OOV PN in the Validation Kit document has the highest production probability. The actual performance measures used to evaluate our OOV PN contingency task will be considered in more detail in the next section CW Section 2, and the convergence of the BOW-2 models will be considered as convergence."}, {"heading": "3.4 OOV PN RETRIEVAL PERFORMANCE", "text": "Figure 4 and Figure 5 show the performance of Recall and Mean Average Precision (MAP) (Manning et al., 2008) in retrieving OOV-PNs for the models discussed in Section 2. Figure 4 shows the performance of D-CBOW, D-CBOW2 and D-CBOW2 + after the end of the first training phase, while Figure 5 shows the performance after the end of the second training phase. Diagrams show the reference transcriptions (left) and the LVCSR transcriptions (right) of the Euronews audio test kit. X-axis represents the number of OOV-PNs selected from the diachronic corpus, i.e. the \"N\" in the retrieved Top-N results. Y-axis represents memory (top) and MAP (bottom) of the target OOV-PNs."}, {"heading": "4 DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 A NOTE ON RECALL AND MAP", "text": "After retrieving the relevant OOV-PNs, the most important OOV-PNs can be used to restore / recognize the destination OOV-PNs. To restore the destination OOV-PNs, one can use telephone matching (Pan et al., 2005) or additional voice recognition passport (Fohr & Illinois, 2015; Oger et al., 2008); or locating PNs in the language (Parada et al., 2010; Chen et al., 2013). In each of these approaches, the retrieval OOOV value can be used or not. Here, the callback and MAP curves make a difference."}, {"heading": "4.2 COMPARISON OF RETRIEVAL PERFORMANCE", "text": "In the second half of the year, which will be the first three months of the second half of the year, the first three months of the second half of the year will last from the second half of the year to the second half of the second half of the year, the second half of the second half of the year, the first half of the second half of the year, the second half of the second half of the year to the second half of the second half of the year."}, {"heading": "4.3 KEYWORD IMPORTANCE BY D-CBOW2 MODEL", "text": "In Table 2, we show the ability of the D-CBOW2 model to assign meaning to keywords in the input document in order to derive the target OOV PN. We have listed four Euronews video examples, the first column listing the target OOV PNs present in these videos, and for comparison, the words given by the D-CBOW2 and D-CBOW2 models (meaning more than 0.1, as calculated by Equation 3) are also shown from corresponding input references and manual transcriptions in the second and fifth columns, respectively, and for comparison, the values given by the D-CBOW2 and D-CBOW models are also shown. It can be seen that in the first two examples, the D-CBOW2 model extracts relevant keywords and indicates similar ranks as the D-CBOW model. In the third example, the key lengths given by the D-CBOW2 models are better influenced by the BOVW models than the BOD-BOD words."}, {"heading": "4.4 RECOVERY OF TARGET OOV PNS WITH AUTOMATIC KEYWORD SEARCH (KWS)", "text": "The recovery of the target OOV-PNs in a diachronic audio is done in two steps. First, a list of relevant OOV-PNs is retrieved with the models presented in this paper. Second, an automatic keyword search (KWS) is performed for each OOV-PN in the list of relevant OOV-PNs, on the entire LVCSR grid of the audio file. For this KWS, we use the approach proposed by Chen et al. (2013), which allows the search for OOV-words (in their phonetic form) in an LVCSRlattice. The OV-PN recovery performance is evaluated in relation to F1 score, calculated as: F1 = 2 \u0445 Precision Recall Recall Recall-tp + fp + fp-D models are relevant."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work is funded by the ContNomina project, which is supported by the French research agency ANR under the ANR-12-BS02-0009 contract. KWS experiments presented in this paper were carried out with the Grid '5000 testbed, which is supported by a scientific stakeholder group hosted by Inria, which includes CNRS, RENATER and several universities and other organisations (see https: / / www.grid5000.fr)."}, {"heading": "APPENDIX A DIFFERENCE IN OOV PN RETRIEVAL PERFORMANCE", "text": "TOGETHER AFTER THE FIRST AND SECOND TRAINING PHASE"}], "references": [{"title": "An audio indexing system for election video material", "author": ["C Alberti"], "venue": "In Acoustics, Speech and Signal Processing,", "citeRegEx": "Alberti,? \\Q2009\\E", "shortCiteRegEx": "Alberti", "year": 2009}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "author": ["Baroni", "Marco", "Dinu", "Georgiana", "Kruszewski", "Germ\u00e1n"], "venue": null, "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Practical recommendations for gradient-based training of deep architectures", "author": ["Bengio", "Yoshua"], "venue": "CoRR, abs/1206.5533,", "citeRegEx": "Bengio and Yoshua.,? \\Q2012\\E", "shortCiteRegEx": "Bengio and Yoshua.", "year": 2012}, {"title": "Multimedia data mining: state of the art and challenges", "author": ["Bhatt", "Chidansh Amitkumar", "Kankanhalli", "Mohan S"], "venue": "Multimedia Tools and Applications,", "citeRegEx": "Bhatt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bhatt et al\\.", "year": 2011}, {"title": "Person name recognition in ASR outputs using continuous context models", "author": ["Bigot", "Benjamin", "Senay", "Gr\u00e9gory", "Linar\u00e8s", "Georges", "Fredouille", "Corinne", "Dufour", "Richard"], "venue": "In Acoustics, Speech and Signal Processing,", "citeRegEx": "Bigot et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bigot et al\\.", "year": 2013}, {"title": "Quantifying the value of pronunciation lexicons for keyword search in lowresource languages", "author": ["Chen", "Guoguo", "S. Khudanpur", "D. Povey", "J. Trmal", "D. Yarowsky", "O. Yilmaz"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "A unified model for word sense representation and disambiguation", "author": ["Chen", "Xinxiong", "Liu", "Zhiyuan", "Sun", "Maosong"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Continuous word representation using neural networks for proper name retrieval from diachronic documents", "author": ["Fohr", "Dominique", "Illina", "Irina"], "venue": "In 16th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Fohr et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fohr et al\\.", "year": 2015}, {"title": "Modeling interestingness with deep neural networks", "author": ["Gao", "Jianfeng", "Pantel", "Patrick", "Gamon", "Michael", "He", "Xiaodong", "Deng", "Li", "Shen", "Yelong"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Gao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2014}, {"title": "Finding scientific topics", "author": ["Griffiths", "Thomas L", "Steyvers", "Mark"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Griffiths et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Griffiths et al\\.", "year": 2004}, {"title": "The Automatic News Transcription System: ANTS some Real Time experiments", "author": ["Illina", "Irina", "Fohr", "Dominique", "Mella", "Odile", "Cerisara", "Christophe"], "venue": "In 8th International Conference on Spoken Language Processing (INTERSPEECH\u20192004 - ICSLP),", "citeRegEx": "Illina et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Illina et al\\.", "year": 2004}, {"title": "Do important words in bag-of-words model of text relatedness help? In Text, Speech, and Dialogue, volume", "author": ["Islam", "Aminul", "Milios", "Evangelos", "Keelj", "Vlado"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "Islam et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Islam et al\\.", "year": 2015}, {"title": "Distributed representations of sentences and documents", "author": ["Le", "Quoc", "Mikolov", "Tomas"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Le et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Le et al\\.", "year": 2014}, {"title": "Combined low level and high level features for out-of-vocabulary word detection", "author": ["Lecouteux", "Benjamin", "Linar\u00e8s", "Georges", "Favre", "Benoit"], "venue": "In 10th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Lecouteux et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lecouteux et al\\.", "year": 2009}, {"title": "Dependencybased word embeddings", "author": ["Levy", "Omer", "Goldberg", "Yoav"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Two/too simple adaptations of word2vec for syntax problems", "author": ["Ling", "Wang", "Dyer", "Chris", "Black", "Alan", "Trancoso", "Isabel"], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Introduction to Information Retrieval", "author": ["Manning", "Christopher D", "Raghavan", "Prabhakar", "Sch\u00fctze", "Hinrich"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2008}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A guided tour to approximate string matching", "author": ["Navarro", "Gonzalo"], "venue": "ACM Comput. Surv.,", "citeRegEx": "Navarro and Gonzalo.,? \\Q2001\\E", "shortCiteRegEx": "Navarro and Gonzalo.", "year": 2001}, {"title": "Topic2vec: Learning distributed representations of topics", "author": ["Niu", "Li-Qiang", "Dai", "Xin-Yu"], "venue": "CoRR, abs/1506.08422,", "citeRegEx": "Niu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Niu et al\\.", "year": 2015}, {"title": "On-demand new word learning using world wide web", "author": ["Oger", "Stanislas", "Linar\u00e8s", "Georges", "B\u00e9chet", "Fr\u00e9d\u00e9ric", "Nocera", "Pascal"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Oger et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Oger et al\\.", "year": 2008}, {"title": "Named entity recognition from spoken documents using global evidences and external knowledge sources with applications on mandarin chinese", "author": ["Pan", "Yi-Cheng", "Liu", "Yu-Ying", "Lee", "Lin-Shan"], "venue": "In IEEE Workshop on Automatic Speech Recognition and Understanding,", "citeRegEx": "Pan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pan et al\\.", "year": 2005}, {"title": "A spoken term detection framework for recovering out-of-vocabulary words using the web", "author": ["Parada", "Carolina", "Sethy", "Abhinav", "Dredze", "Mark", "Jelinek", "Frederick"], "venue": "In 11th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Parada et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Parada et al\\.", "year": 2010}, {"title": "Glove: Global vectors for word representation", "author": ["Pennington", "Jeffrey", "Socher", "Richard", "Manning", "Christopher"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Learning Out-of-Vocabulary Words in Automatic Speech Recognition", "author": ["Qin", "Long"], "venue": "PhD thesis,", "citeRegEx": "Qin and Long.,? \\Q2013\\E", "shortCiteRegEx": "Qin and Long.", "year": 2013}, {"title": "Learning word representation considering proximity and ambiguity", "author": ["Qiu", "Lin", "Cao", "Yong", "Nie", "Zaiqing", "Yu", "Rui"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July", "citeRegEx": "Qiu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2014}, {"title": "word2vec parameter learning explained", "author": ["Rong", "Xin"], "venue": "CoRR, abs/1411.2738,", "citeRegEx": "Rong and Xin.,? \\Q2014\\E", "shortCiteRegEx": "Rong and Xin.", "year": 2014}, {"title": "TreeTagger: A part-of-speech tagger and lemmatizer for several languages", "author": ["Schmid", "Helmut"], "venue": null, "citeRegEx": "Schmid and Helmut.,? \\Q2014\\E", "shortCiteRegEx": "Schmid and Helmut.", "year": 2014}, {"title": "Word-lattice based spoken-document indexing with standard text indexers", "author": ["F. Seide", "K. Thambiratnam", "R.P. Yu"], "venue": "In IEEE Spoken Language Technology Workshop,", "citeRegEx": "Seide et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Seide et al\\.", "year": 2008}, {"title": "Person name spotting by combining acoustic matching and LDA topic models", "author": ["Senay", "Gr\u00e9gory", "Bigot", "Benjamin", "Dufour", "Richard", "Linar\u00e8s", "Georges", "Fredouille", "Corinne"], "venue": "In 14th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Senay et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Senay et al\\.", "year": 2013}, {"title": "Study of entity-topic models for OOV proper name retrieval", "author": ["Sheikh", "Imran", "Illina", "Irina", "Fohr", "Dominique"], "venue": "In 16th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Sheikh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sheikh et al\\.", "year": 2015}, {"title": "OOV proper name retrieval using topic and lexical context models", "author": ["Sheikh", "Imran", "Illina", "Irina", "Fohr", "Dominique", "Linar\u00e8s", "Georges"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Sheikh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sheikh et al\\.", "year": 2015}, {"title": "How diachronic text corpora affect context based retrieval of oov proper names for audio news", "author": ["Sheikh", "Imran", "Illina", "Irina", "Fohr", "Dominique"], "venue": "In (submitted to) Language Resources and Evaluation Conference (LREC)", "citeRegEx": "Sheikh et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sheikh et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 29, "context": "Large Vocabulary Continuous Speech Recognition (LVCSR) based automatic audio indexing approaches allow search, navigation, browsing and structuring of large audio-video datasets based on spoken content (Alberti et al., 2009; Seide et al., 2008), as opposed to phonetic audio mining approaches which mostly serve user query based audio document retrieval from relatively smaller databases (Bhatt & Kankanhalli, 2011).", "startOffset": 202, "endOffset": 244}, {"referenceID": 0, "context": "Large Vocabulary Continuous Speech Recognition (LVCSR) based automatic audio indexing approaches allow search, navigation, browsing and structuring of large audio-video datasets based on spoken content (Alberti et al., 2009; Seide et al., 2008), as opposed to phonetic audio mining approaches which mostly serve user query based audio document retrieval from relatively smaller databases (Bhatt & Kankanhalli, 2011). However, LVCSR processing of diachronic audio data, and specifically broadcast audio news, can be challenging due to the variations in linguistic content and vocabulary. Thus leading to Out-Of-Vocabulary (OOV) words for LVCSR. Even if good amount of training data is available, appending the LVCSR vocabulary and updating the Language Model (LM) is not always a feasible solution (Qin, 2013). Proper Names (PNs), which are important indexes for audio-video, have been found to be a major percentage of OOV words. In this paper, we focus on the problem of retrieval of OOV PNs relevant to an audio document. To retrieve OOV PNs relevant to an audio document we rely on semantic context. In training phase, diachronic text news with new (i.e., OOV) PNs are collected from the internet. These set of text documents, referred as diachronic text corpus, is used to learn a context vector space which captures relationship between the In-Vocabulary (IV) words & PNs and the OOV PNs. During test, the LVCSR hypothesis of the audio document is projected into the context space and then relevant OOV PNs are inferred. Recently it has been shown in Sheikh et al. (2015b) that Latent Dirichlet Allocation", "startOffset": 203, "endOffset": 1578}, {"referenceID": 18, "context": "Alternative methods to learn word and context representations (Mikolov et al., 2013; Pennington et al., 2014), based on predicting the context in which words appear, have become popular.", "startOffset": 62, "endOffset": 109}, {"referenceID": 24, "context": "Alternative methods to learn word and context representations (Mikolov et al., 2013; Pennington et al., 2014), based on predicting the context in which words appear, have become popular.", "startOffset": 62, "endOffset": 109}, {"referenceID": 2, "context": "These representations, also called embeddings, have been shown to perform effectively when applied as pre-trained features in a range of applications and tasks (Baroni et al., 2014).", "startOffset": 160, "endOffset": 181}, {"referenceID": 18, "context": "Both these models use pre-trained Skip-gram word embeddings (Mikolov et al., 2013) for IV words & PNs and learn with an objective to maximise the retrieval of the target OOV PNs in the document.", "startOffset": 60, "endOffset": 82}, {"referenceID": 18, "context": "Different extensions and variations in the Log-bilinear (LBL) model and specifically the CBOW/Skip-gram architecture (Mikolov et al., 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al.", "startOffset": 117, "endOffset": 139}, {"referenceID": 16, "context": ", 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014).", "startOffset": 47, "endOffset": 163}, {"referenceID": 26, "context": ", 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014).", "startOffset": 47, "endOffset": 163}, {"referenceID": 7, "context": ", 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014).", "startOffset": 47, "endOffset": 163}, {"referenceID": 4, "context": "Bigot et al. (2013); Senay et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Bigot et al. (2013); Senay et al. (2013) use one LDA/LSA context model per PN which restricts the approach to frequent PNs.", "startOffset": 0, "endOffset": 41}, {"referenceID": 4, "context": "Bigot et al. (2013); Senay et al. (2013) use one LDA/LSA context model per PN which restricts the approach to frequent PNs. Sheikh et al. (2015b;a) presented methods based on probabilistic topic models and addressed the problems in ranking PNs arising due to bias in the probabilistic topic models. These methods readily apply to audio documents with single or coherent events. Fohr & Illina (2015) applied word embeddings to audio documents with multiple events appearing one after another.", "startOffset": 0, "endOffset": 399}, {"referenceID": 1, "context": "The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al.", "startOffset": 77, "endOffset": 100}, {"referenceID": 1, "context": "The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al. (2015) for the task of text relatedness.", "startOffset": 77, "endOffset": 214}, {"referenceID": 1, "context": "The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al. (2015) for the task of text relatedness. The Deep Structured Semantic Model (DSSM) with convolutional-pooling structures presented in Gao et al. (2014) has been shown to capture keywords in text documents.", "startOffset": 77, "endOffset": 359}, {"referenceID": 31, "context": "proposed in Sheikh et al. (2015b). Then we present an extension of this method to raw Skip-gram and Paragraph Vector embeddings.", "startOffset": 12, "endOffset": 34}, {"referenceID": 18, "context": "(The cost function used to train the network shares similarity with that of CBOW model Word embeddings from Skip-gram model give better performance than those from the CBOW model proposed in the original work Mikolov et al. (2013).", "startOffset": 209, "endOffset": 231}, {"referenceID": 18, "context": "originally proposed in Mikolov et al. (2013), we refer the interested readers to Rong (2014).", "startOffset": 23, "endOffset": 45}, {"referenceID": 18, "context": "originally proposed in Mikolov et al. (2013), we refer the interested readers to Rong (2014).) During test, the softmax probabilities at the output are used as scores to rank and retrieve the OOV PNs.", "startOffset": 23, "endOffset": 93}, {"referenceID": 11, "context": "The words and PNs which occur in the lexicon of our Automatic News Transcription System (ANTS)(Illina et al., 2004) are tagged as IV and remaining PNs are tagged as OOV.", "startOffset": 94, "endOffset": 115}, {"referenceID": 33, "context": "This number and the target OOV PN coverage can be increased by augmenting text documents from additional sources (Sheikh et al., 2016), for instance from other news websites.", "startOffset": 113, "endOffset": 134}, {"referenceID": 11, "context": "The ANTS (Illina et al., 2004) LVCSR system is used to perform automatic segmentation and speech-to-text transcription of the test set (Euronews) audio news.", "startOffset": 9, "endOffset": 30}, {"referenceID": 17, "context": "Figure 4 and Figure 5 show the Recall and Mean Average Precision (MAP) (Manning et al., 2008) performance of retrieval of OOV PNs, for models discussed in Section 2.", "startOffset": 71, "endOffset": 93}, {"referenceID": 22, "context": "To recover the target OOV PNs one can use phone matching (Pan et al., 2005), or additional speech recognition pass (Fohr & Illina, 2015; Oger et al.", "startOffset": 57, "endOffset": 75}, {"referenceID": 21, "context": ", 2005), or additional speech recognition pass (Fohr & Illina, 2015; Oger et al., 2008)); or spotting PNs in speech (Parada et al.", "startOffset": 47, "endOffset": 87}, {"referenceID": 23, "context": ", 2008)); or spotting PNs in speech (Parada et al., 2010; Chen et al., 2013).", "startOffset": 36, "endOffset": 76}, {"referenceID": 6, "context": ", 2008)); or spotting PNs in speech (Parada et al., 2010; Chen et al., 2013).", "startOffset": 36, "endOffset": 76}, {"referenceID": 6, "context": ", 2010; Chen et al., 2013). In each of these approaches, the retrieval ranks/scores may or may not be used. This is where the recall and MAP curves make a difference. The recall value at an operating point (N in the top-N choice) is not sensitive to the rank of the retrieved OOV PNs whereas the MAP value, by definition, takes into account the retrieval ranks. For instance if we take top 5% (top 465 retrieved OOV PNs3) of the retrieved OOV PNs almost all the methods will have same recall, but the MAP will have differences. In Section 4.4 we try to analyse the effect of the recall and MAP of the retrieval task on recovery of the target OOV PNs. To recover the target OOV PNs in the audio documents we perform a keyword search on the LVCSR lattices using the approach proposed by Chen et al. (2013). This is a quick and simple approach to evaluate the retrieved list of top-N OOV PNs.", "startOffset": 8, "endOffset": 804}, {"referenceID": 33, "context": "This might appear as a small number but it must be noted that as we increase the diachronic corpora to increase coverage of target OOV PNs this number will also multiply (Sheikh et al., 2016).", "startOffset": 170, "endOffset": 191}, {"referenceID": 6, "context": "For this KWS we employ the approach proposed by Chen et al. (2013), which enables searching of OOV words (in their phonetic form) in an LVCSR", "startOffset": 48, "endOffset": 67}], "year": 2016, "abstractText": "Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech recognition systems used to process diachronic audio data. To help recovery of the PNs missed by the system, relevant OOV PNs can be retrieved out of the many OOVs by exploiting semantic context of the spoken content. In this paper, we propose two neural network models targeted to retrieve OOV PNs relevant to an audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b) Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models take document words as input and learn with an objective to maximise the retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new approach in which the input embedding layer is augmented with a context anchor layer. This layer learns to assign importance to input words and has the ability to capture (task specific) key-words in a bag-of-words neural network model. With experiments on French broadcast news videos we show that these two models outperform the baseline methods based on raw embeddings from LDA, Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives faster convergence during training.", "creator": "LaTeX with hyperref package"}}}