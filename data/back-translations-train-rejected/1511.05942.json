{"id": "1511.05942", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2015", "title": "Doctor AI: Predicting Clinical Events via Recurrent Neural Networks", "abstract": "Large amount of Electronic Health Record (EHR) data have been collected over millions of patients over multiple years. The rich longitudinal EHR data documented the collective experiences of physicians including diagnosis, medication prescription and procedures. We argue it is possible now to leverage the EHR data to model how physicians behave, and we call our model Doctor AI. Towards this direction of modeling clinical bahavior of physicians, we develop a successful application of Recurrent Neural Networks (RNN) to jointly forecast the future disease diagnosis and medication prescription along with their timing. Unlike a traditional classification model where a single target is of interest, our model can assess entire history of patients and make continuous and multilabel prediction based on patients' historical data. We evaluate the performance of the proposed method on a large real-world EHR data over 250K patients over 8 years. We observe Doctor AI achieves up to 79% recall@30, significantly higher than several baselines.", "histories": [["v1", "Wed, 18 Nov 2015 20:47:44 GMT  (471kb,D)", "http://arxiv.org/abs/1511.05942v1", null], ["v2", "Wed, 25 Nov 2015 12:40:27 GMT  (412kb,D)", "http://arxiv.org/abs/1511.05942v2", "ICLR 2016 submission. Updating the acknowledgment etc"], ["v3", "Mon, 14 Dec 2015 14:21:11 GMT  (319kb,D)", "http://arxiv.org/abs/1511.05942v3", "Updating the acknowledgment"], ["v4", "Wed, 6 Jan 2016 19:18:22 GMT  (331kb,D)", "http://arxiv.org/abs/1511.05942v4", "Updating the ICLR submission based on reviews"], ["v5", "Thu, 7 Jan 2016 18:23:06 GMT  (624kb,D)", "http://arxiv.org/abs/1511.05942v5", "Updating the ICLR submission based on reviews"], ["v6", "Wed, 17 Feb 2016 22:47:47 GMT  (320kb,D)", "http://arxiv.org/abs/1511.05942v6", "Updating"], ["v7", "Thu, 10 Mar 2016 13:46:11 GMT  (324kb,D)", "http://arxiv.org/abs/1511.05942v7", "Updating"], ["v8", "Sat, 19 Mar 2016 17:02:10 GMT  (323kb,D)", "http://arxiv.org/abs/1511.05942v8", "Updating"], ["v9", "Thu, 4 Aug 2016 02:52:55 GMT  (356kb,D)", "http://arxiv.org/abs/1511.05942v9", "Presented at 2016 Machine Learning and Healthcare Conference (MLHC 2016), Los Angeles, CA"], ["v10", "Tue, 30 Aug 2016 06:05:18 GMT  (355kb,D)", "http://arxiv.org/abs/1511.05942v10", "Presented at 2016 Machine Learning and Healthcare Conference (MLHC 2016), Los Angeles, CA"], ["v11", "Wed, 28 Sep 2016 19:11:19 GMT  (433kb,D)", "http://arxiv.org/abs/1511.05942v11", "Presented at 2016 Machine Learning and Healthcare Conference (MLHC 2016), Los Angeles, CA"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["edward choi", "mohammad taha bahadori", "andy schuetz", "walter f stewart", "jimeng sun"], "accepted": false, "id": "1511.05942"}, "pdf": {"name": "1511.05942.pdf", "metadata": {"source": "CRF", "title": "DOCTOR AI: PREDICTING CLINICAL EVENTS VIA RECURRENT NEURAL NETWORKS", "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun"], "emails": ["recall@30,"], "sections": [{"heading": "1 INTRODUCTION", "text": "The introduction of electronic health records (EHR) into healthcare has provided an enormous amount of high-quality data, creating an opportunity to perform complex clinical analyses that were too complex to perform efficiently; predicting future clinical events for patients is a particularly challenging but important task that seeks to predict the occurrence of various diseases over time, and what type of action physicians will take. Successful predictions will, in a sense, be synonymous with modeling the behavior of human physicians, not only enabling patient-specific care and timely interventions, but also reducing healthcare costs. Although parts of this problem, such as disease progression modelling, have been studied by many researchers over several decades, such as Heckerman; Chapman et al al al, 2001; Lange et al, 2015), most work does not achieve the required accuracy and scalability, lack of expert knowledge."}, {"heading": "2 METHODOLOGY", "text": "It is a question of the extent to which it is about a way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about, in which it is about the way in which it is about the way in which it is about, in which it is about the way in which it is about the way in which it is about, in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is not in which it is not in which it is not in which it is not in which it is in which it is not in which it is not in which it is in which it is not in which it is not in which it is not in which it is in which it is not in which it is not in which it is not in which it is in which it is not in which it is not in which it is not in which it is in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in"}, {"heading": "3 RELATED WORK", "text": "In this section, we give a brief overview of common approaches to modeling multi-label event data, with particular emphasis on the models applied to medical data.Discretization versus Continuous Time Modeling There are two main approaches to modeling point-process data: with or without time-binning. If the timeline is discredited, the point-process data can be converted into binary time series (or time series of counting data if binning is coarse) and analyzed using time-series analysis techniques (Truccolo et al., 2005; Bahadori et al., 2013; Ranganath et al., 2015). However, this approach is inefficient as it produces long time series, the elements of which are largely null. In addition, discretization leads to noise in the timestamps of visits. Finally, these models are often unable to model the duration until the next event."}, {"heading": "4 EXPERIMENTS", "text": "In this section, we describe the details of our experiments, the data sets we use and the baselines. During this section, we show the success of the proposed approach in predicting future events for patients."}, {"heading": "4.1 DATASET DESCRIPTION", "text": "We use a health data set provided by Sutter Health; its basic statistics are summarized in Table 1.78 and source of data The source population for this study was primarily patients from Sutter Palo Alto Medical Foundation (PAMF) Clinics, a multi-specialist group of practitioners that EHR has used for more than 8 years. The data set was extracted from a case study of heart failure codes within Sutter-PAMF. The data set consists of commands, problem lists and procedural modes. Data processing We used diagnostic codes, drug codes, and procedure code codes that are embedded in the ICD-9 codes codes, which were coded in the ICD group in which the commands, the diagnosticide codes, the diagnosticide codes codes codes, the diagnosticide codes codes codes, the diagnosticide codes codes codes codes, the diagnosticide codes codes codes codes codes codes codes codes, the codes codes codes codes codes codes codes codes codes codes codes, the codes codes codes codes codes codes codes codes codes codes, the codes codes codes codes codes codes codes codes codes, the codes codes codes codes codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes-codes"}, {"heading": "4.2 EVALUATION METRICS", "text": "To evaluate the performance of the algorithms used to predict the next events, we use the following top k recall: top k recall = # of the true positives in the top k predictions # of the true positives. This key figure is consistent with the differential diagnostic frame in which the machine proposes k possible codes and we measure the proportion of true codes that are correctly retrieved. We select k = 10, 20, 30 because, as shown in Table 1, each visit contains on average more than three codes. Therefore, selecting small k can lead to an inaccurate rating. The determination coefficient or R2 is a key figure used to evaluate the predictive performance of regression and prediction algorithms. It compares the accuracy of the prediction with respect to the simple prediction using the target variability. R2 = 1 \u2212 i (yi \u2212 i) is a key figure used to evaluate the predictive performance of regression and prediction algorithms."}, {"heading": "4.3 BASELINES", "text": "Some of the existing techniques, based on CTMC and latent spatial models, were not scalable enough to be trained in the entire dataset in a reasonable amount of time, so the comparison might not be fair. Intuitive baselines. We compare our algorithms with simple baselines based on experts \"intuition about the dynamics of events in the clinical setting. The first baseline is to use a patient's medical codes on his last visit as a prediction of his current visit. This baseline is competitive when the status of a patient with a chronic disease stabilizes over time. We can make this baseline stronger by using the top-k labels most frequently observed during visits prior to current visits. In the experiments, we observe that the second baseline is fairly competitive. Logistic and neural network time series models. A common method of performing prediction tasks is to use (xi \u2212 1, di \u2212 1) to predict the next event."}, {"heading": "4.4 RESULTS", "text": "Table 2 compares the results of different algorithms with RNN-based AI doctors and does not significantly improve logistical approaches. We report the results in three settings: If we are interested in (1) only predicting disease codes (Dx), (2) only predicting medications (Rx), and (3) collectively predicting Dx, Rx, and the time to the next visit. The results confirm that the proposed approach is capable of outperforming the basic algorithms by a large margin. Note that the recall values for the common task are lower than those for individual Dx or Rx predictions, because the hypotheses space for the common prediction task is larger. Comparing RNN-based and the most common past algorithms with the delayed multilayered perceptronal algorithms, we postulate that the status of patients in this data set depends on more than 5 delays. This may be due to the long-term data insufficiency."}, {"heading": "5 CONCLUSION", "text": "In this work, we have proposed Doctor AI, which is able to analyze patient records and predict future outcomes for patients. We have shown that with a system based on recurrent neural networks, we can achieve 64.30% recall @ 10. This is a significant improvement over baseline and indicates that the calculation algorithms are on track to be an assistant in improving the quality of healthcare. Qualitative analysis by a medical expert confirms that Doctor AI not only mimics the predictive power of human physicians, but also delivers diagnostic results that are clinically significant, as all the predicted codes were within the limits of medical possibilities, suggesting that it can be used as a differential diagnostic machine."}, {"heading": "A LEARNING THE SKIP-GRAM VECTORS FROM THE EHR", "text": "Learning efficient representations of medical codes (e.g. diagnostic codes, drug codes, and process codes) can lead to improved performance in many clinical applications. We used Skip-gram (Mikolov et al., 2013) to learn real multidimensional vectors to latent representation of medical codes from the EHR.We processed the Sutter PAMF dataset so that diagnostic codes, drug codes, process codes are spread in a temporal sequence. If there are multiple codes on a single visit, they were spread in a random sequence. Subsequently, using the context window size of 5 left and 5 right, we were able to project diagnostic codes, drug codes, and process codes into the same subdimensional space where similar or related codes are embedded close to each other. Thus, for example, hypertension, hyperlibitis, or hypertension can be compared to hypertension."}, {"heading": "B DETAILS OF THE BASELINES", "text": "rE \"i iwr rf\u00fc ide iioPnr,\" so he sasd in the ioPnlrsrsrteeoip rf\u00fc the ioPnlrp-ioP-iioS-iioioS-ioioioioioioioioiP-ioioioiiP-ioioiP-ioioiP-ioioioiP-ioioioiP-ioioioiiP-ioiioiiP-ioioiiP-ioioiP-ioioiP-ioiP-ioioiP-ioiP-ioiP-ioiP-ioioiP"}], "references": [{"title": "Fast structure learning in generalized stochastic processes with latent factors", "author": ["Bahadori", "Mohammad Taha", "Liu", "Yan", "Xing", "Eric P"], "venue": "In KDD, pp", "citeRegEx": "Bahadori et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bahadori et al\\.", "year": 2013}, {"title": "Theano: new features and speed improvements", "author": ["Bastien", "Fr\u00e9d\u00e9ric", "Lamblin", "Pascal", "Pascanu", "Razvan", "Bergstra", "James", "Goodfellow", "Ian J", "Bergeron", "Arnaud", "Bouchard", "Nicolas", "Bengio", "Yoshua"], "venue": "Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop,", "citeRegEx": "Bastien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "A simple algorithm for identifying negated findings and diseases in discharge summaries", "author": ["Chapman", "Wendy W", "Bridewell", "Will", "Hanbury", "Paul", "Cooper", "Gregory F", "Buchanan", "Bruce G"], "venue": "Journal of biomedical informatics,", "citeRegEx": "Chapman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Chapman et al\\.", "year": 2001}, {"title": "Constructing disease network and temporal progression model via context-sensitive hawkes process", "author": ["Choi", "Edward", "Du", "Nan", "Chen", "Robert", "Song", "Le", "Sun", "Jimeng"], "venue": "In ICDM,", "citeRegEx": "Choi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Chung", "Junyoung", "Gulcehre", "Caglar", "Cho", "KyungHyun", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1412.3555,", "citeRegEx": "Chung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "A semi-markov model for multistate and interval-censored data with multiple terminal events. application in renal transplantation", "author": ["Foucher", "Yohann", "Giral", "Magali", "Soulillou", "Jean-Paul", "Daures", "Jean-Pierre"], "venue": "Statistics in medicine,", "citeRegEx": "Foucher et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Foucher et al\\.", "year": 2007}, {"title": "Generating sequences with recurrent neural networks", "author": ["Graves", "Alex"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "Graves and Alex.,? \\Q2013\\E", "shortCiteRegEx": "Graves and Alex.", "year": 2013}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "author": ["Graves", "Alex", "Jaitly", "Navdeep"], "venue": "In ICML, pp", "citeRegEx": "Graves et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "A novel connectionist system for unconstrained handwriting recognition", "author": ["Graves", "Alex", "Liwicki", "Marcus", "Fern\u00e1ndez", "Santiago", "Bertolami", "Roman", "Bunke", "Horst", "Schmidhuber", "J\u00fcrgen"], "venue": null, "citeRegEx": "Graves et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2009}, {"title": "A tractable inference algorithm for diagnosing multiple diseases", "author": ["Heckerman", "David"], "venue": "In UAI,", "citeRegEx": "Heckerman and David.,? \\Q1990\\E", "shortCiteRegEx": "Heckerman and David.", "year": 1990}, {"title": "Long short-term memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Bayesian nonparametric hidden semi-markov models", "author": ["Johnson", "Matthew J", "Willsky", "Alan S"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Johnson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2013}, {"title": "Some different types of essential hypertension: their course and prognosis", "author": ["Keith", "Norman M", "Wagener", "Henry P", "Barker", "Nelson W"], "venue": "The American Journal of the Medical Sciences,", "citeRegEx": "Keith et al\\.,? \\Q1939\\E", "shortCiteRegEx": "Keith et al\\.", "year": 1939}, {"title": "Unifying visual-semantic embeddings with multimodal neural language models", "author": ["Kiros", "Ryan", "Salakhutdinov", "Ruslan", "Zemel", "Richard S"], "venue": "arXiv preprint arXiv:1411.2539,", "citeRegEx": "Kiros et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kiros et al\\.", "year": 2014}, {"title": "Essential hypertension and cognitive function", "author": ["Kuusisto", "Johanna", "Koivisto", "Keijo", "L Mykk\u00e4nen", "Helkala", "Eeva-Liisa", "Vanhanen", "Matti", "T H\u00e4nninen", "K Py\u00f6r\u00e4l\u00e4", "Riekkinen", "Paavo", "Laakso", "Markku"], "venue": "the role of hyperinsulinemia. Hypertension,", "citeRegEx": "Kuusisto et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Kuusisto et al\\.", "year": 1993}, {"title": "Latent Continuous Time Markov Chains for Partially-Observed Multistate Disease Processes", "author": ["Lange", "Jane"], "venue": "PhD thesis,", "citeRegEx": "Lange and Jane.,? \\Q2014\\E", "shortCiteRegEx": "Lange and Jane.", "year": 2014}, {"title": "A joint model for multistate disease processes and random informative observation times, with applications to electronic medical records", "author": ["Lange", "Jane M", "Hubbard", "Rebecca A", "Inoue", "Lurdes YT", "Minin", "Vladimir N"], "venue": "data. Biometrics,", "citeRegEx": "Lange et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lange et al\\.", "year": 2015}, {"title": "A simple way to initialize recurrent networks of rectified linear units", "author": ["Le", "Quoc V", "Jaitly", "Navdeep", "Hinton", "Geoffrey E"], "venue": "arXiv preprint arXiv:1504.00941,", "citeRegEx": "Le et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Le et al\\.", "year": 2015}, {"title": "Discovering latent network structure in point process data", "author": ["Linderman", "Scott", "Adams", "Ryan"], "venue": "In ICML, pp", "citeRegEx": "Linderman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Linderman et al\\.", "year": 2014}, {"title": "Multivariate hawkes processes", "author": ["Liniger", "Thomas Josef"], "venue": "PhD thesis, Diss., Eidgeno\u0308ssische Technische Hochschule ETH Zu\u0308rich, Nr", "citeRegEx": "Liniger and Josef.,? \\Q2009\\E", "shortCiteRegEx": "Liniger and Josef.", "year": 2009}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "In NIPS,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Continuous time bayesian networks", "author": ["Nodelman", "Uri", "Shelton", "Christian R", "Koller", "Daphne"], "venue": "In UAI,", "citeRegEx": "Nodelman et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2002}, {"title": "The survival filter: Joint survival analysis with a latent time series", "author": ["Ranganath", "Rajesh", "Perotte", "Adler", "Elhadad", "No\u00e9mie", "Blei", "David M"], "venue": "In UAI,", "citeRegEx": "Ranganath et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ranganath et al\\.", "year": 2015}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["Saxe", "Andrew M", "McClelland", "James L", "Ganguli", "Surya"], "venue": "arXiv preprint arXiv:1312.6120,", "citeRegEx": "Saxe et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Saxe et al\\.", "year": 2013}, {"title": "Diabetic cataract formation: potential role of glycosylation of lens crystallins", "author": ["Stevens", "Victor J", "Rouzer", "Carol A", "Monnier", "Vincent M", "Cerami", "Anthony"], "venue": null, "citeRegEx": "Stevens et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Stevens et al\\.", "year": 1978}, {"title": "Sequence to sequence learning with neural networks", "author": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc VV"], "venue": "In NIPS, pp", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects", "author": ["Truccolo", "Wilson", "Eden", "Uri T", "Fellows", "Matthew R", "Donoghue", "John P", "Brown", "Emery N"], "venue": "Journal of neurophysiology,", "citeRegEx": "Truccolo et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Truccolo et al\\.", "year": 2005}, {"title": "Estimation of space\u2013time branching process models in seismology using an em\u2013type", "author": ["Veen", "Alejandro", "Schoenberg", "Frederic P"], "venue": "algorithm. JASA,", "citeRegEx": "Veen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Veen et al\\.", "year": 2008}, {"title": "Learning to execute", "author": ["Zaremba", "Wojciech", "Sutskever", "Ilya"], "venue": "arXiv preprint arXiv:1410.4615,", "citeRegEx": "Zaremba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}, {"title": "Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes", "author": ["Zhou", "Ke", "Zha", "Hongyuan", "Song", "Le"], "venue": "In AISTATS, pp", "citeRegEx": "Zhou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2013}, {"title": "Nonlinear Hawkes Processes", "author": ["Zhu", "Lingjiong"], "venue": "PhD thesis,", "citeRegEx": "Zhu and Lingjiong.,? \\Q2013\\E", "shortCiteRegEx": "Zhu and Lingjiong.", "year": 2013}], "referenceMentions": [{"referenceID": 2, "context": "(Heckerman, 1990; Chapman et al., 2001; Lange et al., 2015), most works do not achieve the required accuracy and scalability, lack generality, or need excessive expert domain knowledge.", "startOffset": 0, "endOffset": 59}, {"referenceID": 16, "context": "(Heckerman, 1990; Chapman et al., 2001; Lange et al., 2015), most works do not achieve the required accuracy and scalability, lack generality, or need excessive expert domain knowledge.", "startOffset": 0, "endOffset": 59}, {"referenceID": 21, "context": "The two main class of techniques, continuous-time Markov chain based models (Nodelman et al., 2002; Lange et al., 2015; Johnson & Willsky, 2013), and intensity based point process modeling techniques such as Hawkes processes (Liniger, 2009; Zhu, 2013; Choi et al.", "startOffset": 76, "endOffset": 144}, {"referenceID": 16, "context": "The two main class of techniques, continuous-time Markov chain based models (Nodelman et al., 2002; Lange et al., 2015; Johnson & Willsky, 2013), and intensity based point process modeling techniques such as Hawkes processes (Liniger, 2009; Zhu, 2013; Choi et al.", "startOffset": 76, "endOffset": 144}, {"referenceID": 3, "context": ", 2015; Johnson & Willsky, 2013), and intensity based point process modeling techniques such as Hawkes processes (Liniger, 2009; Zhu, 2013; Choi et al., 2015) are expensive to generalize to nonlinear and multilabel settings.", "startOffset": 113, "endOffset": 158}, {"referenceID": 25, "context": "(Graves, 2013; Graves & Jaitly, 2014; Sutskever et al., 2014; Kiros et al., 2014; Zaremba & Sutskever, 2014).", "startOffset": 0, "endOffset": 108}, {"referenceID": 13, "context": "(Graves, 2013; Graves & Jaitly, 2014; Sutskever et al., 2014; Kiros et al., 2014; Zaremba & Sutskever, 2014).", "startOffset": 0, "endOffset": 108}, {"referenceID": 20, "context": "\u2022 We propose an efficient initialization scheme for RNNs using Skip-gram embedding (Mikolov et al., 2013) and show that it improves the performance of the RNN in our problem.", "startOffset": 83, "endOffset": 105}, {"referenceID": 17, "context": "The RNN units can be simple RNN units (Le et al., 2015) or more complex recurrent units such as Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997; Graves et al.", "startOffset": 38, "endOffset": 55}, {"referenceID": 8, "context": ", 2015) or more complex recurrent units such as Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997; Graves et al., 2009) or Gated Recurrent Units (GRU) (Chung et al.", "startOffset": 78, "endOffset": 131}, {"referenceID": 4, "context": ", 2009) or Gated Recurrent Units (GRU) (Chung et al., 2014).", "startOffset": 39, "endOffset": 59}, {"referenceID": 4, "context": "Although LSTM has drawn much attention from many researchers, GRU has recently shown to have similar performance as LSTM, while employing a simpler architecture (Chung et al., 2014).", "startOffset": 161, "endOffset": 181}, {"referenceID": 23, "context": "The values of all W \u2019s and U \u2019s were initialized to orthonormal matrices using singular value decomposition of matrices generated from the normal distribution (Saxe et al., 2013).", "startOffset": 159, "endOffset": 178}, {"referenceID": 20, "context": "(2) We initialize the weight Wemb with a matrix generated by Skip-gram algorithm (Mikolov et al., 2013), then refine the weight Wemb as we train the entire model.", "startOffset": 81, "endOffset": 103}, {"referenceID": 26, "context": "When the time axis is discretized, the point process data can be converted to binary time series (or time series of count data if binning is coarse) and analyzed via time series analysis techniques (Truccolo et al., 2005; Bahadori et al., 2013; Ranganath et al., 2015).", "startOffset": 198, "endOffset": 268}, {"referenceID": 0, "context": "When the time axis is discretized, the point process data can be converted to binary time series (or time series of count data if binning is coarse) and analyzed via time series analysis techniques (Truccolo et al., 2005; Bahadori et al., 2013; Ranganath et al., 2015).", "startOffset": 198, "endOffset": 268}, {"referenceID": 22, "context": "When the time axis is discretized, the point process data can be converted to binary time series (or time series of count data if binning is coarse) and analyzed via time series analysis techniques (Truccolo et al., 2005; Bahadori et al., 2013; Ranganath et al., 2015).", "startOffset": 198, "endOffset": 268}, {"referenceID": 21, "context": "Among the continuous-time models, there are two main techniques: continuoustime Markov chain based models (Nodelman et al., 2002; Foucher et al., 2007; Johnson & Willsky, 2013; Lange, 2014) and intensity function modeling techniques such as Cox and Hawkes processes (Liniger, 2009; Zhou et al.", "startOffset": 106, "endOffset": 189}, {"referenceID": 5, "context": "Among the continuous-time models, there are two main techniques: continuoustime Markov chain based models (Nodelman et al., 2002; Foucher et al., 2007; Johnson & Willsky, 2013; Lange, 2014) and intensity function modeling techniques such as Cox and Hawkes processes (Liniger, 2009; Zhou et al.", "startOffset": 106, "endOffset": 189}, {"referenceID": 29, "context": ", 2007; Johnson & Willsky, 2013; Lange, 2014) and intensity function modeling techniques such as Cox and Hawkes processes (Liniger, 2009; Zhou et al., 2013; Linderman & Adams, 2014; Choi et al., 2015).", "startOffset": 122, "endOffset": 200}, {"referenceID": 3, "context": ", 2007; Johnson & Willsky, 2013; Lange, 2014) and intensity function modeling techniques such as Cox and Hawkes processes (Liniger, 2009; Zhou et al., 2013; Linderman & Adams, 2014; Choi et al., 2015).", "startOffset": 122, "endOffset": 200}, {"referenceID": 1, "context": "The model was implemented with Theano (Bastien et al., 2012) and trained on a machine equipped with two Nvidia Tesla K80 GPUs.", "startOffset": 38, "endOffset": 60}, {"referenceID": 24, "context": "A human doctor would likely predict similar diseases to the ones predicted with Doctor AI, since old myocardial infarction and chronic ischemic heart disease can be associated with infections and diabetes (Stevens et al., 1978).", "startOffset": 205, "endOffset": 227}, {"referenceID": 12, "context": "In the fourth case, visual disturbances can be associated with migraines and essential hypertension (Keith et al., 1939).", "startOffset": 100, "endOffset": 120}, {"referenceID": 14, "context": "Further, essential hypertension may be linked to cognitive function (Kuusisto et al., 1993), which plays a role in anxiety disorders and dissociative and somatoform disorders.", "startOffset": 68, "endOffset": 91}, {"referenceID": 20, "context": "We specifically used Skip-gram (Mikolov et al., 2013) to learn real-valued multidimensional vectors to capture the latent representation of medical codes from the EHR.", "startOffset": 31, "endOffset": 53}], "year": 2017, "abstractText": "Large amount of Electronic Health Record (EHR) data have been collected over millions of patients over multiple years. The rich longitudinal EHR data documented the collective experiences of physicians including diagnosis, medication prescription and procedures. We argue it is possible now to leverage the EHR data to model how physicians behave, and we call our model Doctor AI. Towards this direction of modeling clinical bahavior of physicians, we develop a successful application of Recurrent Neural Networks (RNN) to jointly forecast the future disease diagnosis and medication prescription along with their timing. Unlike a traditional classification model where a single target is of interest, our model can assess entire history of patients and make continuous and multilabel prediction based on patients\u2019 historical data. We evaluate the performance of the proposed method on a large real-world EHR data over 250K patients over 8 years. We observe Doctor AI achieves up to 79% recall@30, significantly higher than several baselines.", "creator": "LaTeX with hyperref package"}}}