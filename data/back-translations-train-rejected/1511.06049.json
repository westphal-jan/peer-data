{"id": "1511.06049", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "What Objective Does Self-paced Learning Indeed Optimize?", "abstract": "Self-paced learning (SPL) has been attracting increasing attention in machine learning and computer vision. Albeit empirically substantiated to be effective, the investigation on its theoretical insight is still a blank. It is even unknown that what objective a general SPL regime converges to. To this issue, this study attempts to initially provide some new insights under this \"heuristic\" learning scheme. Specifically, we prove that the solving strategy on SPL exactly accords with a majorization minimization algorithm, a well known technique in optimization and machine learning, implemented on a latent objective. A more interesting finding is that, the loss function contained in this latent objective has a similar configuration with non-convex regularized penalty, an attractive topic in statistics and machine learning. In particular, we show that the previous hard and linear self-paced regularizers are equivalent to the capped norm and minimax concave plus penalties, respectively, both being widely investigated in statistics. Such connections between SPL and previous known researches enhance new insightful comprehension on SPL, like convergence and parameter setting rationality. The correctness of the proposed theory is substantiated by experimental results on synthetic and UCI data sets.", "histories": [["v1", "Thu, 19 Nov 2015 02:55:18 GMT  (249kb,D)", "http://arxiv.org/abs/1511.06049v1", "11 pages, 2 figures"], ["v2", "Tue, 1 Nov 2016 13:59:27 GMT  (205kb,D)", "http://arxiv.org/abs/1511.06049v2", "25 pages, 1 figures"]], "COMMENTS": "11 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["deyu meng", "qian zhao", "lu jiang"], "accepted": false, "id": "1511.06049"}, "pdf": {"name": "1511.06049.pdf", "metadata": {"source": "CRF", "title": "What Objective Does Self-paced Learning Indeed Optimize?", "authors": ["Deyu Meng", "Qian Zhao"], "emails": ["dymeng@mail.xjtu.edu.cn", "timmy.zhaoqian@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2 Related Work", "text": "Inspired by the intrinsic human / animal learning principle, Bengio et al. [1] formalized the basic definition of CL. The basic idea is to incorporate incremental samples into learning, introducing simple samples and gradually incorporating more complex samples when the learner is ready for them. These incremental samples, ranging from simple to complex, correspond to the curricula learned at different stages of human / animal growing up. This strategy, supported by empirical evaluation, is helpful in alleviating the local optimum problem in nonconvex optimization [15, 16].Self-pace learning, which is learned at different stages of human / animal growing up. Rather than using the above heuristic strategies, Kumar et al formulated the key principle of CL as a concise SPL model. Formally, in the face of a training dataset (D = xi, yi = 1) the label is represented in the label."}, {"heading": "3 SPL Model and Algorithm Revisit", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Axiomic Definition of SP-regularizer", "text": "Through the mathematical abstraction of the cognitive properties underlying a rational SPL regime, [17, 18] a formal definition of the SP ragularizer f (v; \u03bb) has been presented, which approximates the SPL model (1) as follows: Definition 1 (Automatic Regularizer). Suppose v is a weight variable, \"loss is and \u03bb is the age parameter. f (v, \u03bb) is called a gradual regularizer, if1. f (v, \u03bb) is convex with respect to v [0, 1]; 2. v\" is monotonically decreasing with respect to \"and it states that Limm\" \u2192 0 v."}, {"heading": "3.2 Revisit ASS Algorithm for Solving SPL", "text": "For the convenience of the terms, we briefly write L (yi, g (xi, w)) as \"i (w) /\" i (y, g (x, w))) as \"(w) /\" in sequence. In view of an SP regularizer f (v, \u03bb), we can then calculate the integrative function of v (v) (v, w), which is calculated by Eq. (3) as: F\u03bb (\") 0 v.\" (l) dl. (5) The following result can then be proved (the proof is provided in the appendix). Theorem 1. For v (f), the theory is calculated by an SP regularizer and F\u03bb (\"), with a fixed w.\" It applies that: F\u03bb (w), (w)), (f), (f), (f), \"()."}, {"heading": "3.3 Revisit SPL Model", "text": "For this purpose, we initially calculate the latent SPL losses under hard, linear and mixed SP regularizers, as introduced in (4), by Eq. (5). For this purpose, we first calculate the latent SPL losses under hard, linear and mixed SP regularizers, as follows: FH\u03bb (\") = {,\" < \u03bb, \"\" < \u03bb / 2, \"\u2265 \u03bb; FM\u03bb, \u03b3 (\") =, < 1 (\",\" < 1, \"\", \"\", \"\", \"\", \"\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\", \",\", \"\" \",\", \",\", \",\", \",\", \",\", \"\", \",\""}, {"heading": "3.4 Age Parameter Tuning", "text": "In the initial phase of SPL iteration, the age value is low, and only lossy samples can participate in the training process, which of course causes the problem of insufficient learning. However, in the late SPL training phase, the age will become much greater, and then outliers or meaningless, loud samples tend to learn. Such incorrect information tends to negatively affect the performance of the model learned. Therefore, it is necessary to end the SPL iteration at an appropriate intermediate age. The latent SPL target, which is gradually optimized in the SPL process, provides us with helpful clues about this problem. Especially in SPL implementation with gradually increasing age parameters, more and more samples are incremented into the learning process, which can be described as the following imaging function: \u03b3 (n) = n, where the age at which n training samples begin to participate in SPL training (i.e., n samples are of no importance vi)."}, {"heading": "3.5 Discussion on SPL Superiority", "text": "A natural question is why the latent SPL target is not directly optimized instead of the SPL model, and what is the superiority of the latter? In fact, we can easily see that an intrinsic property of the SPL is to divide the minimization of the robust but difficult-to-solve non-convex loss F\u03bb (\"w\") into two much simpler optimization problems in terms of sample importance v (solved by the closed solution of the SP regularizer) and model parameters w (solved by the weighted loss problem). Such a decomposition not only simplifies the solution of the problem, but also makes it easy to embed helpful prior knowledge of sample importance (ease) into the loss function of an SPL scheme. Here, we list some of these useful sample importance that can generally be achieved before learning: 1. Spatial / temporal smoothness prior to learning, prior to: Some spatially important samples / temporally adjacent sample proneness we may have relative importance to. \""}, {"heading": "4 Experiments", "text": "In this section we want to verify the correctness of the proven theoretical results by synthetic and UCI experiments."}, {"heading": "4.1 Synthetic Simulations", "text": "We constructed two synthetic data sets for substantiation. The first is a classification data set with 600 points, which is generated by the following distribution: 5 points i = 1 point (1 point), 5 points (1 point), 7 points (1 point), 7 points (1 point), 7 points (1 point), 7 points (1 point), 7 points (1 point), 7 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (1 point), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points), 8 points (points (points), 8 points (points), 8 points (points), 8 points (points (points), 8 points (points), 8 points (points (points), 8 points (points), 8 points (8 points (8), points (8 points), 8 points (8 points (8), points (8 points (8), points (8), points (8 points (8), points (8), points (8 points (8), points (8), points (8 points (8), points (8 points (8), points (8 points (8), points (8), points (8 points (8), points (8), points (8 points (8), points (8), points (8 points (8), points (8 points (8), points (8), points (8 points (8"}, {"heading": "4.2 UCI Experiments", "text": "s Problem 1 (D1), Mammographic Mass (D2), and SPECT Heart (D3) datasets. LR and SVC were used as basic methods, and hard, linear, and blended SPL systems were implemented to enhance their robustness. It is easy to see from the table the better performance of the SPL systems over the original LR and SVC in all experiments. Indeed, this performance improvement implies that all three datasets contain obvious noise to some extent, and therefore the noise suppressing the ability of the latent SPL object is not effective."}, {"heading": "5 Conclusion", "text": "On the one hand, we have shown that the ASS algorithm is generally used for solving SPL, and on the other hand, we have confirmed that the loss function contained in this latent SPL lens is exactly the same as the famous non-convex regulated system (NCRP), and its effectiveness, especially its robustness against outlier / heavy eyelets, the SPL function, can of course be explained with such an understanding. In our future study, we will explore the theories of MM and NCRP in greater depth to explore and model the theoretical / statistical properties of the SPL algorithms."}], "references": [{"title": "Curriculum learning", "author": ["Y. Bengio", "J. Louradour", "R. Collobert", "J. Weston"], "venue": "In ICML,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Self-paced learning for latent variable models", "author": ["M. Kumar", "B. Packer", "D. Koller"], "venue": "In NIPS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "How do humans teach: on curriculum learning and teaching dimension", "author": ["F. Khan", "X. Zhu", "B. Mutlu"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Baby steps: How \u201cless is more\u201d in unsupervised dependency parsing", "author": ["V.I. Spitkovsky", "H. Alshawi", "D. Jurafsky"], "venue": "In NIPS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Are all training examples equally valuable", "author": ["A. Lapedriza", "H. Pirsiavash", "Z. Bylinskii", "A. Torralba"], "venue": "In CoRR abs/1311.6510,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Shifting weights: Adapting object detectors from image to video", "author": ["K. Tang", "V. Ramanathan", "F. Li", "D. Koller"], "venue": "In NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Learning specific-class segmentation from diverse data", "author": ["M. Kumar", "H. Turki", "D. Preston", "D. Koller"], "venue": "In ICCV,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Learning the easy things first: Self-paced visual category discovery", "author": ["Y. Lee", "K. Grauman"], "venue": "In CVPR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Self-paced learning for long-term tracking", "author": ["J. Supan\u010di\u010d III", "D. Ramanan"], "venue": "In CVPR,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Parameter convergence for EM and MM algorithms", "author": ["F. Vaida"], "venue": "Statistica Sinica,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Analysis of multi-stage convex relaxation for sparse regularization", "author": ["T. Zhang"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "A general theory of concave regularization for high-dimensional sparse estimation problems", "author": ["C. Zhang", "T. Zhang"], "venue": "Statistical Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "A general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems", "author": ["P. Gong", "C. Zhang", "Z. Lu", "J. Huang", "J. Ye"], "venue": "In ICML,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Nearly unbiased variable selection under minimax concave penalty", "author": ["C. Zhang"], "venue": "Annals of Statistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Supervised learning with minimal effort", "author": ["E. Ni", "C. Ling"], "venue": "In Advances in Knowledge Discovery and Data Mining,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Teaching classification boundaries to humans", "author": ["S. Basu", "J. Christensen"], "venue": "In AAAI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Easy samples first: self-paced reranking for zeroexample multimedia search", "author": ["L. Jiang", "D. Meng", "T. Mitamura", "A. Hauptmann"], "venue": "In ACM MM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Self-paced learning for matrix factorization", "author": ["Q. Zhao", "D.Y. Meng", "L. Jiang", "Q. Xie", "Z.B. Xu", "A. Hauptman"], "venue": "In AAAI,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Self-paced learning with diversity", "author": ["L. Jiang", "D.Y. Meng", "S. Yu", "Z.Z. Lan", "S.G. Shan", "A. Hauptman"], "venue": "In NIPS,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Self-paced curriculum learning", "author": ["L. Jiang", "D.Y. Meng", "Q. Zhao", "S.G. Shan", "A. Hauptman"], "venue": "In AAAI,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Co-saliency detection via a self-paced multiple-instance learning framework", "author": ["D. Zhang", "D. Meng", "J. Han"], "venue": "In ICCV,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "CMU-Informedia@ TRECVID 2014 Multimedia Event Detection (MED)", "author": ["S. Yu", "L. Jiang", "Z. Mao", "X.J. Chang", "X.Z. Du", "C. Gan", "Z.Z. Lan", "Z.W. Xu", "X.C. Li", "Y. Cai", "A. Kumar", "Y. Miao", "L. Martin", "N. Wolfe", "S.C. Xu", "H. Li", "M. Lin", "Z.G. Ma", "Y. Yang", "D.Y. Meng", "S.G. Shan", "P.D. Sahin", "S. Burger", "F. Metze", "R. Singh", "B. Raj", "T. Mitamura", "R. Stern", "A. Hauptmann"], "venue": "In TRECVID Video Retrieval Evaluation Workshop,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Variable selection via nonconcave penalized likelihood and its oracle properties", "author": ["J. Fan", "R. Li"], "venue": "Journal of American Statistical Association,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "On the global convergence of majorization minimization algorithms for nonconvex optimization problems", "author": ["Y. Kang", "Z. Zhang", "W. Li"], "venue": "In arXiv: 1504.07791v2,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Optimization transfer using surrogate objective functions", "author": ["K. Lange", "D. Hunter", "I. Yang"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2000}, {"title": "The regression analysis of binary sequences (with discussion)", "author": ["DR Cox"], "venue": "Journal of the Royal Statistical Society: Series B,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1958}, {"title": "Statistical Learning Theory", "author": ["V. Vapnik"], "venue": "Wiley-Interscience, New York,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1998}, {"title": "Gauss and the invention of least squares", "author": ["Stephen M. Stigler"], "venue": "Annals of Statistics,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1981}], "referenceMentions": [{"referenceID": 0, "context": "Since being raised, curriculum learning (CL) [1] and self-paced learning (SPL) [2] have been attracting increasing attention in machine learning, computer vision and multimedia analysis circles.", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "Since being raised, curriculum learning (CL) [1] and self-paced learning (SPL) [2] have been attracting increasing attention in machine learning, computer vision and multimedia analysis circles.", "startOffset": 79, "endOffset": 82}, {"referenceID": 2, "context": "The philosophy under this paradigm is to simulate a learning scheme as the learning principle of humans/animals, which generally starts by learning easier aspects of an learning task, and then gradually takes more complex examples into training [3].", "startOffset": 245, "endOffset": 248}, {"referenceID": 3, "context": "Instead of heuristically designing a curriculum by ranking samples based on manually preset easiness measurements as CL presented [4, 5], the SPL research further attempted to formulate this ad-hoc idea as a concise SPL model through introducing a regularization term into the learning objective.", "startOffset": 130, "endOffset": 136}, {"referenceID": 4, "context": "Instead of heuristically designing a curriculum by ranking samples based on manually preset easiness measurements as CL presented [4, 5], the SPL research further attempted to formulate this ad-hoc idea as a concise SPL model through introducing a regularization term into the learning objective.", "startOffset": 130, "endOffset": 136}, {"referenceID": 5, "context": "Such amelioration guides a sound SPL regime to automatically optimize an appropriate curriculum by the model itself, which makes the model generalize well to diverse applications and avoid subjective \u201ceasiness\u201d measure setting problem [6, 7, 8, 9].", "startOffset": 235, "endOffset": 247}, {"referenceID": 6, "context": "Such amelioration guides a sound SPL regime to automatically optimize an appropriate curriculum by the model itself, which makes the model generalize well to diverse applications and avoid subjective \u201ceasiness\u201d measure setting problem [6, 7, 8, 9].", "startOffset": 235, "endOffset": 247}, {"referenceID": 7, "context": "Such amelioration guides a sound SPL regime to automatically optimize an appropriate curriculum by the model itself, which makes the model generalize well to diverse applications and avoid subjective \u201ceasiness\u201d measure setting problem [6, 7, 8, 9].", "startOffset": 235, "endOffset": 247}, {"referenceID": 8, "context": "Such amelioration guides a sound SPL regime to automatically optimize an appropriate curriculum by the model itself, which makes the model generalize well to diverse applications and avoid subjective \u201ceasiness\u201d measure setting problem [6, 7, 8, 9].", "startOffset": 235, "endOffset": 247}, {"referenceID": 9, "context": "Firstly, we prove that the ASS algorithm commonly utilized to solve the SPL problem exactly accords with the widely known majorization minimization (MM) [10] algorithm implemented on a latent SPL objective function.", "startOffset": 153, "endOffset": 157}, {"referenceID": 10, "context": ", the hard and linear SPL regimes are equivalent to the optimizations on losses with the capped-norm penalty [11, 12, 13] and minimax concave plus penalty (MCP) [14], respectively.", "startOffset": 109, "endOffset": 121}, {"referenceID": 11, "context": ", the hard and linear SPL regimes are equivalent to the optimizations on losses with the capped-norm penalty [11, 12, 13] and minimax concave plus penalty (MCP) [14], respectively.", "startOffset": 109, "endOffset": 121}, {"referenceID": 12, "context": ", the hard and linear SPL regimes are equivalent to the optimizations on losses with the capped-norm penalty [11, 12, 13] and minimax concave plus penalty (MCP) [14], respectively.", "startOffset": 109, "endOffset": 121}, {"referenceID": 13, "context": ", the hard and linear SPL regimes are equivalent to the optimizations on losses with the capped-norm penalty [11, 12, 13] and minimax concave plus penalty (MCP) [14], respectively.", "startOffset": 161, "endOffset": 165}, {"referenceID": 0, "context": "[1] formalized the fundamental definition of CL.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "This strategy, as supported by empirical evaluation, is helpful in alleviating the local optimum problem in nonconvex optimization [15, 16].", "startOffset": 131, "endOffset": 139}, {"referenceID": 15, "context": "This strategy, as supported by empirical evaluation, is helpful in alleviating the local optimum problem in nonconvex optimization [15, 16].", "startOffset": 131, "endOffset": 139}, {"referenceID": 1, "context": "[2] formulated the key principle of CL as a concise SPL model.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "min w,v\u2208[0,1]n E(w,v;\u03bb) = n \u2211", "startOffset": 8, "endOffset": 13}, {"referenceID": 16, "context": "where \u03bb is the age parameter for controlling the learning pace, and f(v, \u03bb) represents the selfpaced regularizer (SP-regularizer), whose intrinsic conditions have been theoretically abstracted by [17, 18].", "startOffset": 196, "endOffset": 204}, {"referenceID": 17, "context": "where \u03bb is the age parameter for controlling the learning pace, and f(v, \u03bb) represents the selfpaced regularizer (SP-regularizer), whose intrinsic conditions have been theoretically abstracted by [17, 18].", "startOffset": 196, "endOffset": 204}, {"referenceID": 16, "context": "Multiple variations of this SPL learning regime, like self-paced reranking [17], self-paced learning with diversity [19], self-paced curriculum learning [20] and self-paced multiple-instancelearning [21], have been proposed under the format (1).", "startOffset": 75, "endOffset": 79}, {"referenceID": 18, "context": "Multiple variations of this SPL learning regime, like self-paced reranking [17], self-paced learning with diversity [19], self-paced curriculum learning [20] and self-paced multiple-instancelearning [21], have been proposed under the format (1).", "startOffset": 116, "endOffset": 120}, {"referenceID": 19, "context": "Multiple variations of this SPL learning regime, like self-paced reranking [17], self-paced learning with diversity [19], self-paced curriculum learning [20] and self-paced multiple-instancelearning [21], have been proposed under the format (1).", "startOffset": 153, "endOffset": 157}, {"referenceID": 20, "context": "Multiple variations of this SPL learning regime, like self-paced reranking [17], self-paced learning with diversity [19], self-paced curriculum learning [20] and self-paced multiple-instancelearning [21], have been proposed under the format (1).", "startOffset": 199, "endOffset": 203}, {"referenceID": 5, "context": "and computer vision tasks, such as object detector adaptation [6], specific-class segmentation learning [7], visual category discovery [8], and long-term tracking [9].", "startOffset": 62, "endOffset": 65}, {"referenceID": 6, "context": "and computer vision tasks, such as object detector adaptation [6], specific-class segmentation learning [7], visual category discovery [8], and long-term tracking [9].", "startOffset": 104, "endOffset": 107}, {"referenceID": 7, "context": "and computer vision tasks, such as object detector adaptation [6], specific-class segmentation learning [7], visual category discovery [8], and long-term tracking [9].", "startOffset": 135, "endOffset": 138}, {"referenceID": 8, "context": "and computer vision tasks, such as object detector adaptation [6], specific-class segmentation learning [7], visual category discovery [8], and long-term tracking [9].", "startOffset": 163, "endOffset": 166}, {"referenceID": 21, "context": "Especially, the SPL paradigm has been integrated into the system developed by CMU Informedia team, and achieved the leading performance in challenging TRECVID MED/MER competition organized by NIST in 2014 [22].", "startOffset": 205, "endOffset": 209}, {"referenceID": 10, "context": "Typical ones include capped-norm based penalty [11, 12, 13], minimax concave plus (MCP) penalty [14] and smoothly clipped absolute deviation (SCAD) penalty [23].", "startOffset": 47, "endOffset": 59}, {"referenceID": 11, "context": "Typical ones include capped-norm based penalty [11, 12, 13], minimax concave plus (MCP) penalty [14] and smoothly clipped absolute deviation (SCAD) penalty [23].", "startOffset": 47, "endOffset": 59}, {"referenceID": 12, "context": "Typical ones include capped-norm based penalty [11, 12, 13], minimax concave plus (MCP) penalty [14] and smoothly clipped absolute deviation (SCAD) penalty [23].", "startOffset": 47, "endOffset": 59}, {"referenceID": 13, "context": "Typical ones include capped-norm based penalty [11, 12, 13], minimax concave plus (MCP) penalty [14] and smoothly clipped absolute deviation (SCAD) penalty [23].", "startOffset": 96, "endOffset": 100}, {"referenceID": 22, "context": "Typical ones include capped-norm based penalty [11, 12, 13], minimax concave plus (MCP) penalty [14] and smoothly clipped absolute deviation (SCAD) penalty [23].", "startOffset": 156, "endOffset": 160}, {"referenceID": 23, "context": "The mathematical forms of these NCRP terms in one dimension cases are listed as follows [24]: Capped\u2212 normpenalty : p \u03b3,\u03bb (t) = \u03b3min(|t|, \u03bb), \u03bb > 0; MCP : p \u03b3,\u03bb (t) = { \u03b3(|t| \u2212 t 2 2\u03b3\u03bb ), if |t| < \u03b3\u03bb \u03b3\u03bb 2 , if |t| \u2265 \u03b3\u03bb ;", "startOffset": 88, "endOffset": 92}, {"referenceID": 24, "context": "MM algorithms have wide applications in machine learning and statistical inference [25].", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "By mathematically abstracting the insightful properties underlying a rational SPL regime, [17, 18] presented a formal definition for the SP-ragularizer f(v;\u03bb) involved in the SPL model (1) as follows: Definition 1 (Self-paced regularizer).", "startOffset": 90, "endOffset": 98}, {"referenceID": 17, "context": "By mathematically abstracting the insightful properties underlying a rational SPL regime, [17, 18] presented a formal definition for the SP-ragularizer f(v;\u03bb) involved in the SPL model (1) as follows: Definition 1 (Self-paced regularizer).", "startOffset": 90, "endOffset": 98}, {"referenceID": 0, "context": "f(v, \u03bb) is convex with respect to v \u2208 [0, 1]; 2.", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "where v\u2217(\u03bb; `) = arg min v\u2208[0,1] v`+ f(v, \u03bb).", "startOffset": 27, "endOffset": 32}, {"referenceID": 1, "context": "(4) represents the hard, linear and mixture SP-regularizers proposed in [2], [17], and [18], respectively.", "startOffset": 72, "endOffset": 75}, {"referenceID": 16, "context": "(4) represents the hard, linear and mixture SP-regularizers proposed in [2], [17], and [18], respectively.", "startOffset": 77, "endOffset": 81}, {"referenceID": 17, "context": "(4) represents the hard, linear and mixture SP-regularizers proposed in [2], [17], and [18], respectively.", "startOffset": 87, "endOffset": 91}, {"referenceID": 0, "context": "Denote w as the model parameters in the k iteration of the ASS implementation on solving SPL, and then its two alternative search steps in the next iteration can be precisely explained as a standard MM scheme: Majorization step: To obtain each Q \u03bb (w|w k ), we only need to calculate v\u2217(\u03bb; `i(w)) by solving the following problem under the corresponding SP-regularizer f(vi, \u03bb): v\u2217(\u03bb; `i(w )) = min vi\u2208[0,1] vi`i(w ) + f(vi, \u03bb).", "startOffset": 402, "endOffset": 407}, {"referenceID": 19, "context": "Specifically, Prior 1 can be formulated as a graph Laplacian term vLv, where L is the Laplacian matrix on the data adjacent matrix; Prior 2 can be easily encoded as supplemental constraint vi > vj if the i sample is known more important than j one [20]; and Prior 3 can be realized by a \u2212l2,1 norm or \u2212l0.", "startOffset": 248, "endOffset": 252}, {"referenceID": 18, "context": "5,1 norm on v, as utilized in [19] and [21], respectively.", "startOffset": 30, "endOffset": 34}, {"referenceID": 20, "context": "5,1 norm on v, as utilized in [19] and [21], respectively.", "startOffset": 39, "endOffset": 43}, {"referenceID": 3, "context": "32; p2(X) = N([4, 4], 3); p2(1|X) = 1; p1(\u22121|X) = 0; \u03c03 = 0.", "startOffset": 14, "endOffset": 20}, {"referenceID": 3, "context": "32; p2(X) = N([4, 4], 3); p2(1|X) = 1; p1(\u22121|X) = 0; \u03c03 = 0.", "startOffset": 14, "endOffset": 20}, {"referenceID": 5, "context": "where \u03a91 = O([\u22127,\u22128], 4)\u2229{[x, y]|y < x},\u03a92 = O([6, 8], 4)\u2229{[x, y]|y > x},\u03a93 = {x, y|x, y \u2208 [\u2212180, 180]}, O(x0, r) represents a circle area with center x0 and radius r, N(\u03bc, \u03c3) denotes the Gaussian distribution with mean \u03bc and variance \u03c3 and U(\u03a9) represents the uniform distribution on \u03a9.", "startOffset": 47, "endOffset": 53}, {"referenceID": 7, "context": "where \u03a91 = O([\u22127,\u22128], 4)\u2229{[x, y]|y < x},\u03a92 = O([6, 8], 4)\u2229{[x, y]|y > x},\u03a93 = {x, y|x, y \u2208 [\u2212180, 180]}, O(x0, r) represents a circle area with center x0 and radius r, N(\u03bc, \u03c3) denotes the Gaussian distribution with mean \u03bc and variance \u03c3 and U(\u03a9) represents the uniform distribution on \u03a9.", "startOffset": 47, "endOffset": 53}, {"referenceID": 25, "context": "For classification experiments, we utilized the logistic regression (LR) [26] and support vector classification (SVC) [27], with log loss and hinge loss as objectives, respectively, as our baseline comparison methods.", "startOffset": 73, "endOffset": 77}, {"referenceID": 26, "context": "For classification experiments, we utilized the logistic regression (LR) [26] and support vector classification (SVC) [27], with log loss and hinge loss as objectives, respectively, as our baseline comparison methods.", "startOffset": 118, "endOffset": 122}, {"referenceID": 27, "context": "And for regression, we adopted the least square (LS) regression method [28], with LS loss for comparison.", "startOffset": 71, "endOffset": 75}], "year": 2015, "abstractText": "Self-paced learning (SPL) has been attracting increasing attention in machine learning and computer vision. Albeit empirically substantiated to be effective, the investigation on its theoretical insight is still a blank. It is even unknown that what objective a general SPL regime converges to. To this issue, this study attempts to initially provide some new insights under this \u201cheuristic\u201d learning scheme. Specifically, we prove that the solving strategy on SPL exactly accords with a majorization minimization algorithm, a well known technique in optimization and machine learning, implemented on a latent objective. A more interesting finding is that, the loss function contained in this latent objective has a similar configuration with non-convex regularized penalty, an attractive topic in statistics and machine learning. In particular, we show that the previous hard and linear self-paced regularizers are equivalent to the capped norm and minimax concave plus penalties, respectively, both being widely investigated in statistics. Such connections between SPL and previous known researches enhance new insightful comprehension on SPL, like convergence and parameter setting rationality. The correctness of the proposed theory is substantiated by experimental results on synthetic and UCI data sets.", "creator": "LaTeX with hyperref package"}}}