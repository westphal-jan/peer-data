{"id": "1511.06241", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Convolutional Clustering for Unsupervised Learning", "abstract": "The task of labeling data for training deep neural networks is daunting and tedious, requiring millions of labels to achieve the current state-of-the-art results. Such reliance on large amounts of labeled data can be relaxed by exploiting hierarchical features via unsupervised learning techniques. In this work, we propose to train a deep convolutional network based on an enhanced version of the k-means clustering algorithm, which reduces the number of correlated parameters in the form of similar filters, and thus increases test categorization accuracy. We call our algorithm convolutional k-means clustering. We further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data. Our experiments show that the proposed algorithm outperforms other techniques that learn filters unsupervised. Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test error of 1.4% on MNIST.", "histories": [["v1", "Thu, 19 Nov 2015 16:31:46 GMT  (425kb,D)", "http://arxiv.org/abs/1511.06241v1", "11 pages"], ["v2", "Tue, 16 Feb 2016 16:46:53 GMT  (435kb,D)", "http://arxiv.org/abs/1511.06241v2", "11 pages"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["aysegul dundar", "jonghoon jin", "eugenio culurciello"], "accepted": false, "id": "1511.06241"}, "pdf": {"name": "1511.06241.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["UNSUPERVISED LEARNING", "Aysegul Dundar", "Jonghoon Jin", "Eugenio Culurciello"], "emails": ["adundar@purdue.edu", "jhjin@purdue.edu", "euge@purdue.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In order to get around this problem, massive amounts of data need to be trained. In recent years, the number of trainings in the US has increased by more than one million, and the number of trainings in the US has doubled in recent years. (The number of trainings in the US has doubled in recent years.) In all these cases, it is necessary that the trainings of the trainings are designed in such a way that a higher number of trainings are necessary. (The number of trainings in the US has changed in recent years.) The task of processing data is becoming increasingly important in the context of deep neural networks for the detection of events. In all cases, it is necessary that a written label is necessary so that a higher-level training of algorithms can be used.) The task of labelling data requires expensive work. For example, we have spent several hundred hours creating ImageNet, and thousands of hours are needed to annotate ourselves."}, {"heading": "2 RELATED WORK", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "3 LEARNING FILTERS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 LEARNING FILTERS WITH K-MEANS", "text": "Our method for learning filters is based on the k-mean algorithm. The classical k-mean algorithm finds cluster centroids that minimize the distance between points in Euclidean space. In this context, the points are randomly extracted from the data vector w (i) Rn for i = 1, 2,..., m. However, the algorithm finds the dictionary as follows: s (i) j: = D (j) T w (i) if j = argmax l (i) Tw (i) Rn for i = 1, 2,..., m. The algorithm finds the dictionary as follows: s (i) j (j) T w (i) if j = argmax l (i) Tw (i), 0 otherwise D: = WST + D, D (j): D (j)."}, {"heading": "3.2 LEARNING CONVOLUTIONAL FILTERS WITH K-MEANS", "text": "To reduce redundancy between filters at adjacent sites, we propose a new input mask extraction method. (This method greatly reduces redundancy in the centrifuges produced by the k-mean algorithm and only holds the essential basis for them.) The standard k-mean algorithm extracts random patches from the input images whose dimensions correspond to those of the centrifuges. In contrast, the proposed method uses larger windows as inputs to decide which patch to cluster. The windows are selected to be two times larger than the filter size and randomly selected from the input images. The centrifuges of the k-mean algorithm entangle the entire window to calculate a similarity metric at each location of the extracted area. The patch corresponding to the one of the largest activation from the window is considered the most similar feature of the input images."}, {"heading": "3.3 EXPERIMENTAL RESULTS OF SINGLE LAYER NETWORK", "text": "In our experiments, we use the STL-10 dataset, which contains 96 RGB images in 10 categories (Coates et al., 2011). This dataset has 500 images per class for training and 800 for testing. In addition, it includes 100, 000 blank images for unattended learning algorithms, which are extracted from a similar but wider distribution of images. To learn the filters with k means, only blank data is used. Patches are randomly extracted from the raw images for training the filters with k means and conventional means."}, {"heading": "4 LEARNING CONNECTIONS", "text": "We are studying a way to get connections from one network layer to the next. These connections are of utmost importance because they are more efficient in the calculation. These incomplete connections use several groups, each with a limited share of the previous layers. We are using an economical connection matrix that limits the local receptive field. Therefore, we can avoid the poor performance of k-mean algorithms when the input data is high."}, {"heading": "4.1 EXPERIMENTAL RESULTS OF MULTI-LAYER NETWORKS", "text": "This year, there is a significant doubling in the first half of the year, starting in the second half of the year and beginning in the third half of the year in the second half of the year."}, {"heading": "5 FINAL CLASSIFICATION RESULTS", "text": "Finally, we compare our method with the competing methods published on the STL10 and MNIST datasets, focusing mainly on algorithms that learn filters unattended. Multi-dictionary approach (Coates & Ng, 2011b; Lin & Kung, 2014) is the concatenation of representations calculated at different levels (i.e. output values) as an image attribute vector, using the same learning parameters, pre-processing and encoding schemes as in our other experiments (Section 3.3)."}, {"heading": "5.1 STL-10", "text": "For the final classification results, we are using networks based on our experiments with two- and three-layer networks, but we are increasing the network size by replacing the step in the first layer with a two-layer max pooling, which increases the accuracy. We are further increasing the accuracy through the multilayer approach. Specifically, we are using a similar network of two-layer experiments for the two layers with multiditional network, in which we have learned 64 filters from 24 groups each in the first layer. We are concatenating this network with a single-layer network with 512 filters. The single-layer network also includes ReLU activation and max pooling to increase the dimension of output to 512-4-4-4. For the three layers with multiditional network, we are reaching the network from a three-layer network experiment in which we have created 32 filters from 192 groups. We are linking this network with a single-layer network with a single-layer network with a single-layer network with an equal layer network with a significant network 712-54 additional network in 2012."}, {"heading": "5.2 MNIST", "text": "We are conducting a series of experiments with the MNIST dataset. For testing purposes, we are using the standard 10,000 test samples and using different sizes of marked data for supervised training, as shown in Table 3. Training data is randomly sampled from the entire dataset by ensuring that each label is evenly distributed. For the unattended filter learning algorithm, we are using the entire dataset, while we are using only randomly extracted samples for training the connections and classifier. We are using the same dual-layer network used on the STL-10 dataset, except this time we are reducing the size of the hidden layer in the linear classifier to 256 and the concatenated single-layer network has 96 filters. The experimental results for this dataset can be found in Table 3."}, {"heading": "6 CONCLUSIONS", "text": "We have presented a novel framework that combines the strengths of an uncontrolled cluster algorithm, k-means, and Convolutionary Neural Networks when very little marked data is available; our framework modifies the k-means cluster algorithm so that when used with ConvNets, it learns filters that are less redundant in adjacent locations; in addition, we have proposed a supervised learning setup to learn the proper connections between the layers; the idea of local connectivity applied to ConvNets mitigates the curse of dimensionality in filter learning and makes the algorithm scalable; and the proposed framework eliminates the need for data brightening on each of the layers, including input during the encoding phase (whitening is applied while learning the dictionary); making the coding phase very easy compared to the others (Coates & Ng, 2011b; Hualgorithi suggested that our experiments perform better)."}, {"heading": "ACKNOWLEDGMENTS", "text": "The work supported by the Office of Naval Research (ONR) supports 14PR02106-01 P00004 and MURI N000141010278."}], "references": [{"title": "Unsupervised feature learning for rgb-d based object recognition", "author": ["Bo", "Liefeng", "Ren", "Xiaofeng", "Fox", "Dieter"], "venue": "In Experimental Robotics,", "citeRegEx": "Bo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bo et al\\.", "year": 2013}, {"title": "The importance of encoding versus training with sparse coding and vector quantization", "author": ["Coates", "Adam", "Ng", "Andrew Y"], "venue": "In ICML, pp", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Selecting receptive fields in deep networks", "author": ["Coates", "Adam", "Ng", "Andrew Y"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["Coates", "Adam", "Ng", "Andrew Y", "Lee", "Honglak"], "venue": "In In International Conference on AI and Statistics,", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "An analysis of the connections between layers of deep neural networks", "author": ["Culurciello", "Eugenio", "Jin", "Jonghoon", "Dundar", "Aysegul", "Bates", "Jordan"], "venue": "arXiv preprint arXiv:1306.0152,", "citeRegEx": "Culurciello et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Culurciello et al\\.", "year": 2013}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In CVPR, pp", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Discriminative unsupervised feature learning with convolutional neural networks", "author": ["Dosovitskiy", "Alexey", "Springenberg", "Jost Tobias", "Riedmiller", "Martin", "Brox", "Thomas"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Dosovitskiy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dosovitskiy et al\\.", "year": 2014}, {"title": "Improving neural networks by preventing coadaptation of feature detectors", "author": ["Hinton", "Geoffrey E", "Srivastava", "Nitish", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan R"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Deep metric learning using triplet network", "author": ["Hoffer", "Elad", "Ailon", "Nir"], "venue": "arXiv preprint arXiv:1412.6622,", "citeRegEx": "Hoffer et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hoffer et al\\.", "year": 2014}, {"title": "Direct modeling of complex invariances for visual object features", "author": ["Hui", "Ka Y"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Hui and Y.,? \\Q2013\\E", "shortCiteRegEx": "Hui and Y.", "year": 2013}, {"title": "Learning convolutional feature hierarchies for visual recognition", "author": ["Kavukcuoglu", "Koray", "Sermanet", "Pierre", "Boureau", "Y-Lan", "Gregor", "Karol", "Mathieu", "Micha\u00ebl", "Cun", "Yann L"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2010}, {"title": "Semisupervised learning with deep generative models", "author": ["Kingma", "Diederik P", "Mohamed", "Shakir", "Rezende", "Danilo Jimenez", "Welling", "Max"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "L\u00e9on", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks", "author": ["Lee", "Dong-Hyun"], "venue": "In Workshop on Challenges in Representation Learning, ICML,", "citeRegEx": "Lee and Dong.Hyun.,? \\Q2013\\E", "shortCiteRegEx": "Lee and Dong.Hyun.", "year": 2013}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["Lee", "Honglak", "Grosse", "Roger", "Ranganath", "Rajesh", "Ng", "Andrew Y"], "venue": "In ICML,", "citeRegEx": "Lee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "Stable and efficient representation learning with nonnegativity constraints", "author": ["Lin", "Tsung-Han", "Kung", "HT"], "venue": "In ICML, pp", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Efficient learning of sparse representations with an energy-based model", "author": ["Poultney", "Christopher", "Chopra", "Sumit", "Cun", "Yann L"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Poultney et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Poultney et al\\.", "year": 2006}, {"title": "Semisupervised learning with ladder network", "author": ["Rasmus", "Antti", "Valpola", "Harri", "Honkala", "Mikko", "Berglund", "Mathias", "Raiko", "Tapani"], "venue": "arXiv preprint arXiv:1507.02672,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "Contractive autoencoders: Explicit invariance during feature extraction", "author": ["Rifai", "Salah", "Vincent", "Pascal", "Muller", "Xavier", "Glorot", "Bengio", "Yoshua"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Rifai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rifai et al\\.", "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Multi-task bayesian optimization", "author": ["Swersky", "Kevin", "Snoek", "Jasper", "Adams", "Ryan P"], "venue": "In Advances in Neural Information Processing Systems, pp. 2004\u20132012,", "citeRegEx": "Swersky et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Swersky et al\\.", "year": 2013}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "arXiv preprint arXiv:1409.4842,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}, {"title": "Stacked what-where autoencoders", "author": ["Zhao", "Junbo", "Mathieu", "Michael", "Goroshin", "Ross", "Lecun", "Yann"], "venue": "arXiv preprint arXiv:1506.02351,", "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 22, "context": "In large-scale datasets, supervised methods have been successfully trained over the past few years due to the advances in parallel computing (Simonyan & Zisserman, 2014; Szegedy et al., 2014).", "startOffset": 141, "endOffset": 191}, {"referenceID": 5, "context": "Popular datasets such as ImageNet (Deng et al., 2009) contain more than a million labeled samples, and even larger datasets are already sought after by researchers in the field.", "startOffset": 34, "endOffset": 53}, {"referenceID": 12, "context": "Recent advances in Convolutional Neural Networks (ConvNets) combined with abundant amounts of labeled data have shown great promises in object recognition tasks to remedy this issue (Krizhevsky et al., 2012).", "startOffset": 182, "endOffset": 207}, {"referenceID": 0, "context": "Although unsupervised learning techniques using k-means algorithm were commonly used to train filters in several studies (Coates & Ng, 2011b; Bo et al., 2013), the network encoding structures present many similarities with ConvNets, such as the use of convolution and pooling in each layer.", "startOffset": 121, "endOffset": 158}, {"referenceID": 13, "context": "While early work of ConvNets used to rely on a \u2018non-complete\u2019 connection scheme (LeCun et al., 1998) to keep the number of connections within reasonable bounds, the trend has changed to fullyconnected layers in order to exploit the benefits of parallel computing (Krizhevsky et al.", "startOffset": 80, "endOffset": 100}, {"referenceID": 12, "context": ", 1998) to keep the number of connections within reasonable bounds, the trend has changed to fullyconnected layers in order to exploit the benefits of parallel computing (Krizhevsky et al., 2012; Simonyan & Zisserman, 2014).", "startOffset": 170, "endOffset": 223}, {"referenceID": 17, "context": "Earlier work suggested to use sparse coding and sparse modeling at patch level ignoring the fact that filters would be used in a convolutional manner (Poultney et al., 2006; Zeiler et al., 2010).", "startOffset": 150, "endOffset": 194}, {"referenceID": 15, "context": "To address this problem, convolutional Restricted Boltzmann Machines trained with contrastive divergence (Lee et al., 2009) and convolutional sparse coding (Kavukcuoglu et al.", "startOffset": 105, "endOffset": 123}, {"referenceID": 10, "context": ", 2009) and convolutional sparse coding (Kavukcuoglu et al., 2010) methods were proposed.", "startOffset": 40, "endOffset": 66}, {"referenceID": 4, "context": "In techniques that use unsupervised algorithms, random connection (Culurciello et al., 2013), and grouping similar features (Coates & Ng, 2011b) have been proposed; these results added additional layers and provided some improvement but not as significant as the ones obtained with supervised deep network.", "startOffset": 66, "endOffset": 92}, {"referenceID": 9, "context": ", 2009) and convolutional sparse coding (Kavukcuoglu et al., 2010) methods were proposed. Filters using k-means algorithm have gained significant attention in recent studies because of its simplicity and its competitive results when combined with the right pre-processing and encoding scheme (Coates & Ng, 2011a; Lin & Kung, 2014). In these studies, filters trained with the k-means algorithm are applied in a convolutional manner over the input maps to extract useful features. However, there has not been any attempt to reduce the redundancy between the filters learned with this algorithm, a problem that hampers efficiency and accuracy. As in almost all statistical learning problems, curse of dimensionality is a known issue in deep neural networks. In particular, studies show that k-means performs poorly after the first layer (Coates & Ng, 2011b). The number of filters of the first layer have low dimensions, on the other hand, the subsequent layers increase the number of network parameters exponentially. As an example to the curse of dimensionality problem, if we have 32\u00d7 32 RGB images, and we train 96 3\u00d7 5\u00d7 5 pixel filters in the first layer and convolve them with input images, we will get 96 \u00d7 28 \u00d7 28 feature maps as output. If we want to train fully connected filters in the second layer (as in the first layer filters), we would need to train 96\u00d7 5\u00d7 5 filters. The k-means algorithm fails to extract distinctive features and works poorly in such a high dimension. Therefore, for the mid level features, a smaller receptive field than fully connected layer should be preferred (Coates & Ng, 2011b). In the early work of ConvNets, LeCun et al. (1998) used parsimonious (not fully-connected) connection schemes to keep the number of connections within reasonable bounds and to force a break of symmetry in the network.", "startOffset": 41, "endOffset": 1669}, {"referenceID": 16, "context": "The connection setup uses 1D convolution across channels which is equivalent to the operation denoted as mlpconv layers in Lin et al. (2013). This layer has been used to enhance the abstraction ability of the local model in Lin et al.", "startOffset": 123, "endOffset": 141}, {"referenceID": 16, "context": "The connection setup uses 1D convolution across channels which is equivalent to the operation denoted as mlpconv layers in Lin et al. (2013). This layer has been used to enhance the abstraction ability of the local model in Lin et al. (2013), and to decrease the dimension of modules as well as to remove the computational bottlenecks in Szegedy et al.", "startOffset": 123, "endOffset": 242}, {"referenceID": 16, "context": "The connection setup uses 1D convolution across channels which is equivalent to the operation denoted as mlpconv layers in Lin et al. (2013). This layer has been used to enhance the abstraction ability of the local model in Lin et al. (2013), and to decrease the dimension of modules as well as to remove the computational bottlenecks in Szegedy et al. (2014).", "startOffset": 123, "endOffset": 360}, {"referenceID": 1, "context": "In our experiments, we use the STL-10 dataset that contains 96\u00d7 96 RGB images in 10 categories (Coates et al., 2011).", "startOffset": 95, "endOffset": 116}, {"referenceID": 12, "context": "After pooling, rectification linear unit (ReLU) activation function is used; similar to recent works in ConvNets (Krizhevsky et al., 2012).", "startOffset": 113, "endOffset": 138}, {"referenceID": 13, "context": "While fully-connected layers make use of all the features of the previous layer into the next one, we use non-complete connection (LeCun et al., 1998), which are more efficient in computation.", "startOffset": 130, "endOffset": 150}, {"referenceID": 7, "context": "We use a linear classifier with 2 layers with a hidden neuron of 512 and interleaved with dropout (Hinton et al., 2012).", "startOffset": 98, "endOffset": 119}, {"referenceID": 22, "context": "The connection matrix in this case decreases the dimension (size 1536 \u00d7 678) in a similar manner as Szegedy et al. (2014); this alleviates the computational bottlenecks.", "startOffset": 100, "endOffset": 122}, {"referenceID": 0, "context": "7% Bo et al. (2013) (2 layers + multi dict.", "startOffset": 3, "endOffset": 20}, {"referenceID": 0, "context": "7% Bo et al. (2013) (2 layers + multi dict.) 64.5% Lin & Kung (2014) (3 layers + multi dict.", "startOffset": 3, "endOffset": 69}, {"referenceID": 20, "context": "Algorithm Test Accuracy Swersky et al. (2013) 70.", "startOffset": 24, "endOffset": 46}, {"referenceID": 20, "context": "Algorithm Test Accuracy Swersky et al. (2013) 70.2% Hoffer & Ailon (2014) (triplet network) 70.", "startOffset": 24, "endOffset": 74}, {"referenceID": 6, "context": "7% Dosovitskiy et al. (2014) (exemplar convnets) 72.", "startOffset": 3, "endOffset": 29}, {"referenceID": 6, "context": "7% Dosovitskiy et al. (2014) (exemplar convnets) 72.8% Zhao et al. (2015) (semi-supervised auto-encoder) 74.", "startOffset": 3, "endOffset": 74}, {"referenceID": 7, "context": "As in previous comparisons, the linear classifier uses 2 layers with a hidden layer of 512 and interleaved with dropout (Hinton et al., 2012) with a rate of 0.", "startOffset": 120, "endOffset": 141}, {"referenceID": 23, "context": "Algorithm 600 1000 3000 Zhao et al. (2015) (auto-encoder) 8.", "startOffset": 24, "endOffset": 43}, {"referenceID": 19, "context": "76% Rifai et al. (2011) (constractive auto-encoder) 6.", "startOffset": 4, "endOffset": 24}, {"referenceID": 12, "context": "Algorithm 600 1000 3000 LeCun et al. (1998) (convnet) 7.", "startOffset": 24, "endOffset": 44}, {"referenceID": 12, "context": "Algorithm 600 1000 3000 LeCun et al. (1998) (convnet) 7.68% 6.45% 3.35% Lee (2013) (psuedo-label) 5.", "startOffset": 24, "endOffset": 83}, {"referenceID": 12, "context": "Algorithm 600 1000 3000 LeCun et al. (1998) (convnet) 7.68% 6.45% 3.35% Lee (2013) (psuedo-label) 5.03% 3.46% 2.69% Zhao et al. (2015) (semi-supervised auto-encoder) 4.", "startOffset": 24, "endOffset": 135}, {"referenceID": 11, "context": "50% Kingma et al. (2014) (generative models) 2.", "startOffset": 4, "endOffset": 25}, {"referenceID": 11, "context": "50% Kingma et al. (2014) (generative models) 2.59% 2.40% 2.18% Rasmus et al. (2015) (semi-supervised ladder) - 1.", "startOffset": 4, "endOffset": 84}], "year": 2015, "abstractText": "The task of labeling data for training deep neural networks is daunting and tedious, requiring millions of labels to achieve the current state-of-the-art results. Such reliance on large amounts of labeled data can be relaxed by exploiting hierarchical features via unsupervised learning techniques. In this work, we propose to train a deep convolutional network based on an enhanced version of the k-means clustering algorithm, which reduces the number of correlated parameters in the form of similar filters, and thus increases test categorization accuracy. We call our algorithm convolutional k-means clustering. We further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data. Our experiments show that the proposed algorithm outperforms other techniques that learn filters unsupervised. Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test error of 1.4% on MNIST.", "creator": "LaTeX with hyperref package"}}}