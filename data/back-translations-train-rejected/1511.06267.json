{"id": "1511.06267", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding For Image & Text Retrieval", "abstract": "Joint modeling of language and vision has been drawing increasing interest. A multimodal data representation allowing for bidirectional retrieval of images by sentences and vice versa is a key aspect of this modeling. In this paper we show that canonical correlation analysis (CCA) can be adapted to bidirectional retrieval by a simple task dependent asymmetric weighting, which solves optimally the retrieval problem in a least squares sense. While regularizing CCA is known to improve numerical stability as well as generalization performance, less attention has been brought to the efficient computation of the regularization path of CCA, which is key to model selection. In this paper we develop efficient algorithms to compute the full regularization path of CCA within the classical Tikhonov and the truncated SVD (T-SVD CCA) regularization frameworks. T-SVD CCA is new to the best of our knowledge, and its regularization path can be computed more efficiently than its Tikhonov counterpart.", "histories": [["v1", "Thu, 19 Nov 2015 17:29:00 GMT  (590kb)", "http://arxiv.org/abs/1511.06267v1", "submitted to ICLR 2016"], ["v2", "Thu, 3 Dec 2015 03:53:40 GMT  (797kb)", "http://arxiv.org/abs/1511.06267v2", "submitted to ICLR 2016; updated the paper to have data splits and scorings comparable with the literature"], ["v3", "Thu, 7 Jan 2016 16:20:50 GMT  (855kb)", "http://arxiv.org/abs/1511.06267v3", "submitted to ICLR 2016; updated the paper to have data splits and scorings comparable with the literature"], ["v4", "Tue, 9 Feb 2016 15:53:18 GMT  (882kb)", "http://arxiv.org/abs/1511.06267v4", null], ["v5", "Mon, 5 Dec 2016 21:06:43 GMT  (3016kb,D)", "http://arxiv.org/abs/1511.06267v5", "Under Review CVPR 2017"]], "COMMENTS": "submitted to ICLR 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["youssef mroueh", "etienne marcheret", "vaibhava goel"], "accepted": false, "id": "1511.06267"}, "pdf": {"name": "1511.06267.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["mroueh@us.ibm.com", "etiennem@us.ibm.com", "vgoel@us.ibm.com"], "sections": [{"heading": null, "text": "ar Xiv: 151 1.06 267v 1 [cs.L G] 19 Nov 2"}, {"heading": "1 INTRODUCTION: MULTIMODAL RETRIEVAL", "text": "Generative models such as deep recurrent networks for speech modelling combined with deep revolutionary neural networks on the image side have shown remarkable successes in captioning Karpathy & Li (2015); Mao et al. (2014); Vinyals et al. (2015); Socher et al. (2011). Image and text capture has been the focus of many recent work. Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al. (2014); Socher et al. (2014); Kulkarni et al. (2011); Farhadi et al. (2010)."}, {"heading": "1.1 THIS PAPER: CONTRIBUTIONS", "text": "The main contributions of this paper are: 1. Asymmetric and task-dependent correlation for CCA: We cast the bidirectional derivative problem as a least quadrilateral problem and motivate the execution in the CCA weighted space. This improves the performance of each task and achieves the state of the COCO benchmark with the unsupervised properties. 2. Efficient Tikhonov / Truncated SVD Regularization Path for CCA: While CCA is an old and widely studied problem that has been used as multimodal data representation in many machine learning applications, we found that computational processing is used for regulated SVD regularization Path for CCA."}, {"heading": "1.2 BIDIRECTIONAL RETRIEVAL AS A LEAST SQUARES PROBLEM", "text": "We start by formally defining the bidirectional retrieval tasks. In view of the pairs of high-dimensional dots (xi, yi) in which xi corresponds to the representation of an image given by a deep Convolutionary Neural Network, and yi a sentence embedding a corresponding caption, our goal is to index this multimodal data in a way that allows bidirectional retrieval of the image. In this section, we cast the retrievable tasks as a simple problem of the smallest squares. To reduce the variance of our estimators, we sit in the softened space of the data in X, and Y, i.e we look at the bidirectional mapping of the data spaces."}, {"heading": "1.3 SIMPLIFYING THE EXPRESSIONS WITH SINGULAR VALUE DECOMPOSITION", "text": "In this section, we simplify the image search and caption expressions given in Equations (3) and (4) by using the singular value decay of X and Y. Let X = Ux\u0445xV x be the SVD of X and Y = Uy\u0445yV y be the SVD of Y. It is easy to show that the whitened data is XC \u2212 1 2XX = XVx\u03a3 \u2212 1 x and uy = V y y y y y y. (6) Note that: T = C \u2212 1 y \u2212 1 y \u2212 y is the least whitened caption. (XY C \u2212 1 x) The whitened caption is the whitened caption."}, {"heading": "2 RETRIEVAL: FROM LEAST SQUARES TO CCA GAINING IN EFFICIENCY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 CANONICAL CORRELATION ANALYSIS", "text": "For data matrices X \u00b7 Rn \u00b7 mx and Y \u00b7 Rn \u00b7 my, let k = min (mx, my) the canonical correlation \u03c31,. \u03c3k, and their corresponding pairs of correlations weights {(ui, vi)} i = 1... k, columns of U Rmx \u00b7 k, and V Rmy \u00b7 k are the solution to the following maximization problem: max U CXXU = Ik, V CY Y Y Y Y Y V = IkTrace (U CXY V), where \u03c3i = u i CXY vi, i = 1. CCA finds the guidelines that are maximally correlated and these are orthonormally in the metric definition of each covariance matrix, respectively."}, {"heading": "2.2 BIDIRECTIONAL RETRIEVAL USING CCA DECOMPOSITION", "text": "x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x,"}, {"heading": "3 CCA REGULARIZATION PATH: TIKHONOV VERSUS TRUNCATED SVD REGULARIZATION", "text": "While CCA is a powerful statistical tool, less attention has been paid to efficiently calculating the full regulatory path of CCA in a learning context where we need to perform model selection using a validation set. For now, we have assumed that the covariances CXX and CY Y Y Y are not unique, and we have presented an SVD version of the Bjork-Golub algorithm in this context. CCA regulation not only allows numerical stability in the non-singular case, efficient model selection on a validation set enables better generalization characteristics and avoids overmatch. Tikhonov regulation is the most commonly used regulation in CCA and consists of replacing covariances with CXX + \u03b3xImx and CY + percyImy."}, {"heading": "3.1 TIKHONOV REGULARIZATION: REGULARIZING THE COVARIANCES", "text": "The regularized CCA problem can be written in this form: max U (CXX + \u03b3xImx) U = I, V (CY Y + \u03b3yImy) V = I Tr (U CXY V) (14) Algorithm 2 shows how the regularization path of CCA can be efficiently calculated. The computational complexity of the cross validation is determined by the computation of the SVD values of T within1Using thin SVD Py is not a complete orthonormal basis of Rmy. the loop that is C = min (mxm2y), O (mym 2 x). \u2212 If we have Nx and Ny values of \u03b3x and \u03b3y, the total complexity of NxNyC is. Note that this can be completely parallelized, as each SVD calculation is independent of the rest."}, {"heading": "3.2 TRUNCATED-SVD REGULARIZATION: TRUNCATING THE COVARIANCES", "text": "Let kx \u2264 mx and let Xkx the best kx-rank approximation to X-ratio the S-ratio ratio the S-ratio ratio ratio ratio the S-ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio ratio"}, {"heading": "4 RELATION TO PREVIOUS WORK", "text": "The common modeling of language and vision is a rapidly growing field of differentiation, we focus here on some recent work that uses bidirectional maps in the retrieval of tasks and their relationship to this work. Klein et al. (2015) and Gong et al. (2014) used CCA to build a common representation using cosine similarity, using a symmetrical weighting of the canonical weighting of CCA, i.e. for an image differentiation pair (x, y), a common embedding of the form (\u03b1U x, V y \u043a), using \u03b1 = 0 in the case of Klein et al. (2015) and \u03b1 > 0 in the case of Gong et al. (2014). Symmetrical weighting in Gong et al. (2014) was a heuristic discovery to improve performance and is not theoretically motivated as in the asymmetrical weighting of this paper. In fact, our experimental results show that asymmetrical weighting in Gong et al. (2014) was a heuristic discovery to improve performance and is not theoretically motivated as in the asymmetrical weighting of this paper."}, {"heading": "5 NUMERICAL RESULTS", "text": "We performed image descriptions and search tasks on the COCO benchmark Lin et al. (2014) with our task asymetrically weighted CCA as described in Table 1. Retrieval was performed with cosmic similarities in Equations (12) and (13). Training includes 82783 images, along with 5 captions each. Similar to Klein et al. (2015), we used the splits of Karpathy & Li (2015), and performed cross-validation splits of 5K images, and tested our models on 5 test splits of 5K images each, as well as 25 splits of 1K images each. We report for both tasks the recall rate to one result, or ten initial results (r @ 1,5,10), as well as the median order of first truth retrieval. Cross-validation was performed with the asymmetrically weighted SVD CCA."}, {"heading": "6 CONCLUSION", "text": "In this paper, we demonstrated how asymmetrical weighting and computationally efficient cross-validation of CCA improves the performance of bidirectional retrieval tasks. While the exposure of this paper was based on image and image captions, our methods are general and can be applied to any multimodal environment. In this paper, we solved CCA in its batch formulation, for handling larger data sets we can use the randomized SVD by Halko et al. (2011) or the subsampled CCA by Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al. (2015); Wang et al. (2015), SGDCCA (Linear and Deep CCA) was recently proposed and can be applied to our problem. It would be interesting to study an efficient model selection for the SGD-CCA (Vechastic Descent CCA et al. (2015); Wang et al. (2015), SCCA, SCCA and Deep CCA (2015)."}, {"heading": "A APPENDIX: PROOFS", "text": "Proof of Lemma 1, Py we have: maxP, Py y y y y. (2 x) Proof of Lemma 1, Py y y. (2 x) Proof of Lemma 1, Py. (2 x) Proof of Lemma 1, Py. (2 x) Proof of Lemma 1, Py. (2 x) Proof of Lemma 1, Py. (2 x) Proof Lemma 1, Py. (2 x) Proof Lemy. (2 x) Proof Lemma 1, Py. (2 x). Proof Lemma 1, Py. (2 x)."}, {"heading": "B EFFICIENCY OF T-SVD CCA VERSUS TIKHONOV CCA", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C OPTIMALITY OF THE TASK DEPENDENT ASYMMETRIC WEIGHTING", "text": "D AWT-SVD CCA REGULARIZATION THREAD"}], "references": [{"title": "Efficient dimensionality reduction for canonical correlation analysis", "author": ["Avron", "Haim", "Boutsidis", "Christos", "Toledo", "Sivan", "Zouzias", "Anastasios"], "venue": "SIAM J. Scientific Computing,", "citeRegEx": "Avron et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Avron et al\\.", "year": 2014}, {"title": "From captions to visual concepts and back", "author": ["Fang", "Hao", "Gupta", "Saurabh", "Iandola", "Forrest N", "Srivastava", "Rupesh K", "Deng", "Li", "Dollr", "Piotr", "Gao", "Jianfeng", "He", "Xiaodong", "Mitchell", "Margaret", "Platt", "John C", "Zitnick", "C. Lawrence", "Zweig", "Geoffrey"], "venue": "In CVPR,", "citeRegEx": "Fang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fang et al\\.", "year": 2015}, {"title": "Every picture tells a story: Generating sentences from images", "author": ["Farhadi", "Ali", "Hejrati", "Seyyed Mohammad Mohsen", "Sadeghi", "Mohammad Amin", "Young", "Peter", "Rashtchian", "Cyrus", "Hockenmaier", "Julia", "Forsyth", "David A"], "venue": null, "citeRegEx": "Farhadi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Farhadi et al\\.", "year": 2010}, {"title": "Numerical methods for computing angles between linear subspaces", "author": ["Golub", "Gene H", "Bjlirck", "He"], "venue": "Math. Comp,", "citeRegEx": "Golub et al\\.,? \\Q1973\\E", "shortCiteRegEx": "Golub et al\\.", "year": 1973}, {"title": "Improving image-sentence embeddings using large weakly annotated photo collections", "author": ["Gong", "Yunchao", "Wang", "Liwei", "Hodosh", "Micah", "Hockenmaier", "Julia", "Lazebnik", "Svetlana"], "venue": "In ECCV,", "citeRegEx": "Gong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2014}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["N. Halko", "P.G. Martinsson", "J.A. Tropp"], "venue": "SIAM Rev.,", "citeRegEx": "Halko et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Halko et al\\.", "year": 2011}, {"title": "The truncated svd as a method for regularization", "author": ["Hansen", "Per C"], "venue": "Technical report,", "citeRegEx": "Hansen and C.,? \\Q1986\\E", "shortCiteRegEx": "Hansen and C.", "year": 1986}, {"title": "Relations between two sets of variates", "author": ["H. Hotelling"], "venue": null, "citeRegEx": "Hotelling,? \\Q1936\\E", "shortCiteRegEx": "Hotelling", "year": 1936}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["Karpathy", "Andrej", "Li", "Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "Karpathy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2015}, {"title": "Deep fragment embeddings for bidirectional image sentence mapping", "author": ["Karpathy", "Andrej", "Joulin", "Armand", "Li", "Fei-Fei"], "venue": "In NIPS,", "citeRegEx": "Karpathy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2014}, {"title": "Unifying visual-semantic embeddings with multimodal neural language models", "author": ["Kiros", "Ryan", "Salakhutdinov", "Ruslan", "Zemel", "Richard S"], "venue": null, "citeRegEx": "Kiros et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kiros et al\\.", "year": 2014}, {"title": "Associating neural word embeddings with deep image representations using fisher vectors", "author": ["Klein", "Benjamin", "Lev", "Guy", "Sadeh", "Gil", "Wolf", "Lior"], "venue": "In CVPR,", "citeRegEx": "Klein et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2015}, {"title": "Baby talk: Understanding and generating simple image descriptions", "author": ["Kulkarni", "Girish", "Premraj", "Visruth", "Dhar", "Sagnik", "Li", "Siming", "Choi", "Yejin", "Berg", "Alexander C", "Tamara L"], "venue": "In CVPR,", "citeRegEx": "Kulkarni et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2011}, {"title": "Phrase-based image captioning", "author": ["Lebret", "Rmi", "Pinheiro", "Pedro O", "Collobert", "Ronan"], "venue": "In ICML,", "citeRegEx": "Lebret et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lebret et al\\.", "year": 2015}, {"title": "Microsoft coco: Common objects in context", "author": ["Lin", "Tsung-Yi", "Maire", "Michael", "Belongie", "Serge", "Hays", "James", "Perona", "Pietro", "Ramanan", "Deva", "Dollr", "Piotr", "Zitnick", "C. Lawrence"], "venue": "In ECCV,", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Finding linear structure in large datasets with scalable canonical correlation analysis", "author": ["Ma", "Zhuang", "Lu", "Yichao", "Foster", "Dean P"], "venue": "In ICML,", "citeRegEx": "Ma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2015}, {"title": "Explain images with multimodal recurrent neural networks", "author": ["Mao", "Junhua", "Xu", "Wei", "Yang", "Yi", "Wang", "Jiang", "Yuille", "Alan L"], "venue": "CoRR, abs/1410.1090,", "citeRegEx": "Mao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mao et al\\.", "year": 2014}, {"title": "Efficient estimation of word representations in vector space", "author": ["Mikolov", "Tomas", "Chen", "Kai", "Corrado", "Greg", "Dean", "Jeffrey"], "venue": "arXiv preprint,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "ICLR,", "citeRegEx": "Simonyan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2015}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["Socher", "Richard", "Lin", "Cliff Chiung-Yu", "Ng", "Andrew Y", "Manning", "Christopher D"], "venue": "In ICML,", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Zero-shot learning through cross-modal transfer", "author": ["Socher", "Richard", "Ganjoo", "Milind", "Manning", "Christopher D", "Ng", "Andrew"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Grounded compositional semantics for finding and describing images with sentences", "author": ["Socher", "Richard", "Karpathy", "Andrej", "Le", "Quoc V", "Manning", "Christopher D", "Ng", "Andrew Y"], "venue": "TACL,", "citeRegEx": "Socher et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2014}, {"title": "Canonical ridge and econometrics of joint production", "author": ["H.D. Vinod"], "venue": "Journal of Econometrics,", "citeRegEx": "Vinod,? \\Q1976\\E", "shortCiteRegEx": "Vinod", "year": 1976}, {"title": "Show and tell: A neural image caption generator", "author": ["Vinyals", "Oriol", "Toshev", "Alexander", "Bengio", "Samy", "Erhan", "Dumitru"], "venue": "In CVPR,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Stochastic optimization for deep cca via nonlinear orthogonal iterations", "author": ["Wang", "Weiran", "Arora", "Raman", "Srebro", "Nati", "Livescu", "Karen"], "venue": "In Allerton Conference,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "We see that this symmetric weighting boosts the performance for a particular \u03b1 = 1 as reported", "author": ["Klein"], "venue": "D AWT-SVD CCA REGULARIZATION PATHS", "citeRegEx": "Klein,? \\Q2015\\E", "shortCiteRegEx": "Klein", "year": 2015}], "referenceMentions": [{"referenceID": 6, "context": "Generative models such as deep recurrent networks for the language modeling, in conjunction with deep convolutional neural networks on the image side have shown remarkable success in the image captioning task Karpathy & Li (2015); Mao et al. (2014); Vinyals et al.", "startOffset": 231, "endOffset": 249}, {"referenceID": 6, "context": "Generative models such as deep recurrent networks for the language modeling, in conjunction with deep convolutional neural networks on the image side have shown remarkable success in the image captioning task Karpathy & Li (2015); Mao et al. (2014); Vinyals et al. (2015); Socher et al.", "startOffset": 231, "endOffset": 272}, {"referenceID": 6, "context": "Generative models such as deep recurrent networks for the language modeling, in conjunction with deep convolutional neural networks on the image side have shown remarkable success in the image captioning task Karpathy & Li (2015); Mao et al. (2014); Vinyals et al. (2015); Socher et al. (2011). Image and Text retrieval has been the focus of many recent works.", "startOffset": 231, "endOffset": 294}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al.", "startOffset": 0, "endOffset": 40}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al.", "startOffset": 0, "endOffset": 62}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al.", "startOffset": 0, "endOffset": 113}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al. (2014); Socher et al.", "startOffset": 0, "endOffset": 133}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al. (2014); Socher et al. (2014); Kulkarni et al.", "startOffset": 0, "endOffset": 155}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al. (2014); Socher et al. (2014); Kulkarni et al. (2011); Farhadi et al.", "startOffset": 0, "endOffset": 179}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al. (2014); Socher et al. (2014); Kulkarni et al. (2011); Farhadi et al. (2010). Given an image and sentence embeddings the goal is to design a multimodal representation that captures the correlation between the two modalities, and allows for bidirectional search in a joint embedding space.", "startOffset": 0, "endOffset": 202}, {"referenceID": 1, "context": "Fang et al. (2015); Klein et al. (2015); Lebret et al. (2015); Kiros et al. (2015; 2014); Karpathy et al. (2014); Gong et al. (2014); Socher et al. (2014); Kulkarni et al. (2011); Farhadi et al. (2010). Given an image and sentence embeddings the goal is to design a multimodal representation that captures the correlation between the two modalities, and allows for bidirectional search in a joint embedding space. In this paper we address the bidirectional retrieval problem and show that an asymmetric task dependent embedding of the images and sentences yields better performance on both retrieval tasks. Key to our representation is the careful analysis and usage of Canonical Correlation Analysis (CCA) in bidirectional retrieval, and the development of an efficient model selection for the regularized CCA embedding. We report our retrieval results on the COCO benchmark Lin et al. (2014).", "startOffset": 0, "endOffset": 894}, {"referenceID": 3, "context": "To this end we present two regularization algorithms for the batch CCA problem based on the Bjork Golub Algorithm Golub et al. (1973) (Algorithm 1), that make the computation of the full regularization path for CCA efficient.", "startOffset": 114, "endOffset": 134}, {"referenceID": 3, "context": "To this end we present two regularization algorithms for the batch CCA problem based on the Bjork Golub Algorithm Golub et al. (1973) (Algorithm 1), that make the computation of the full regularization path for CCA efficient. We present our cross validation algorithms within two regularization frameworks: Tikhonov Regularization (Algorithm 2) and truncated SVD regularization (Algorithm 3) . While Tikhonov regularization is more popular for regularized CCAVinod (1976), we also derive the regularization path for CCA using truncated SVD covariances.", "startOffset": 114, "endOffset": 472}, {"referenceID": 3, "context": "To this end we present two regularization algorithms for the batch CCA problem based on the Bjork Golub Algorithm Golub et al. (1973) (Algorithm 1), that make the computation of the full regularization path for CCA efficient. We present our cross validation algorithms within two regularization frameworks: Tikhonov Regularization (Algorithm 2) and truncated SVD regularization (Algorithm 3) . While Tikhonov regularization is more popular for regularized CCAVinod (1976), we also derive the regularization path for CCA using truncated SVD covariances. Truncated SVD is a popular regularizer for least squares regression problems Hansen (1986), but to our knowledge has not been utilized before in the CCA Context.", "startOffset": 114, "endOffset": 644}, {"referenceID": 19, "context": "We follow this general principle of mapping the space of the search to the space of the query rather than the converse as found in Socher et al. (2013). The solution of Problem (1) is given simply by T = C \u2212 1 2 ,\u22a4 XX CXY C \u2212 1 2 Y Y , hence for a query test sentence y we can find its corresponding image by finding :", "startOffset": 131, "endOffset": 152}, {"referenceID": 7, "context": "We review in this section Canonical Correlation Analysis due to Hotelling (1936). For data matrices X \u2208 Rx and Y \u2208 Ry , let k = min(mx,my) the canonical correlation \u03c31, .", "startOffset": 64, "endOffset": 81}, {"referenceID": 2, "context": "Lemma 1 (Golub et al. (1973)).", "startOffset": 9, "endOffset": 29}, {"referenceID": 0, "context": "While the original algorithm of Bjork and Golub uses the QR factorization of X and Y , we follow Avron et al. (2014) in exposing the algorithm fully with SVD.", "startOffset": 97, "endOffset": 117}, {"referenceID": 9, "context": "Klein et al. (2015), and Gong et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity.", "startOffset": 12, "endOffset": 31}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity. In both works a symmetric weighting of the CCA canonical weights was used, i.e for an image caption pair (x, y), a joint embedding of the form (\u03a3Ux,\u03a3V y), was used, where \u03b1 = 0, in Klein et al. (2015) case and \u03b1 > 0 in Gong et al.", "startOffset": 12, "endOffset": 302}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity. In both works a symmetric weighting of the CCA canonical weights was used, i.e for an image caption pair (x, y), a joint embedding of the form (\u03a3Ux,\u03a3V y), was used, where \u03b1 = 0, in Klein et al. (2015) case and \u03b1 > 0 in Gong et al. (2014) case.", "startOffset": 12, "endOffset": 339}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity. In both works a symmetric weighting of the CCA canonical weights was used, i.e for an image caption pair (x, y), a joint embedding of the form (\u03a3Ux,\u03a3V y), was used, where \u03b1 = 0, in Klein et al. (2015) case and \u03b1 > 0 in Gong et al. (2014) case. The symmetric weighting in Gong et al. (2014) was a heuristic found to improve performance and is not theoretically motivated as in the asymmetric weighting of this paper.", "startOffset": 12, "endOffset": 391}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity. In both works a symmetric weighting of the CCA canonical weights was used, i.e for an image caption pair (x, y), a joint embedding of the form (\u03a3Ux,\u03a3V y), was used, where \u03b1 = 0, in Klein et al. (2015) case and \u03b1 > 0 in Gong et al. (2014) case. The symmetric weighting in Gong et al. (2014) was a heuristic found to improve performance and is not theoretically motivated as in the asymmetric weighting of this paper. Indeed our experimental results show that asymmetric weighting gives higher performance and makes the image search and the image annotation on par in term of performance. A discussion of the optimality of the asymmetric weighting and an empirical study is given in Appendix C. Skip thought vectors introduced in Kiros et al. (2015) for representing sentences were used for bidirectional search in conjunction with VGG features Simonyan & Zisserman (2015) on the image side, with linear embeddings learned with a discriminative triplets loss, instead of a CCA loss.", "startOffset": 12, "endOffset": 849}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity. In both works a symmetric weighting of the CCA canonical weights was used, i.e for an image caption pair (x, y), a joint embedding of the form (\u03a3Ux,\u03a3V y), was used, where \u03b1 = 0, in Klein et al. (2015) case and \u03b1 > 0 in Gong et al. (2014) case. The symmetric weighting in Gong et al. (2014) was a heuristic found to improve performance and is not theoretically motivated as in the asymmetric weighting of this paper. Indeed our experimental results show that asymmetric weighting gives higher performance and makes the image search and the image annotation on par in term of performance. A discussion of the optimality of the asymmetric weighting and an empirical study is given in Appendix C. Skip thought vectors introduced in Kiros et al. (2015) for representing sentences were used for bidirectional search in conjunction with VGG features Simonyan & Zisserman (2015) on the image side, with linear embeddings learned with a discriminative triplets loss, instead of a CCA loss.", "startOffset": 12, "endOffset": 972}, {"referenceID": 4, "context": "(2015), and Gong et al. (2014) used CCA to build a joint representation using the cosine similarity. In both works a symmetric weighting of the CCA canonical weights was used, i.e for an image caption pair (x, y), a joint embedding of the form (\u03a3Ux,\u03a3V y), was used, where \u03b1 = 0, in Klein et al. (2015) case and \u03b1 > 0 in Gong et al. (2014) case. The symmetric weighting in Gong et al. (2014) was a heuristic found to improve performance and is not theoretically motivated as in the asymmetric weighting of this paper. Indeed our experimental results show that asymmetric weighting gives higher performance and makes the image search and the image annotation on par in term of performance. A discussion of the optimality of the asymmetric weighting and an empirical study is given in Appendix C. Skip thought vectors introduced in Kiros et al. (2015) for representing sentences were used for bidirectional search in conjunction with VGG features Simonyan & Zisserman (2015) on the image side, with linear embeddings learned with a discriminative triplets loss, instead of a CCA loss. A similar discriminative loss was used for building a joint image and text representation in Lebret et al. (2015). One advantage of CCA over the discriminative losses is that the batch solution can be found efficiently and does not need stochastic optimization, as well as the efficient model selection introduced in this paper providing a means to select the dimension of the joint embedding leading to better generalization properties.", "startOffset": 12, "endOffset": 1196}, {"referenceID": 13, "context": "We performed image annotation and search tasks on the COCO benchmark Lin et al. (2014) using our task dependent asymmetrically weighted CCA, as described in Table 1.", "startOffset": 69, "endOffset": 87}, {"referenceID": 11, "context": "Similarly to Klein et al. (2015), we used the splits from Karpathy & Li (2015), and performed cross-validation on 5 validation splits of 5K images, and tested our models on 5 testing splits of 5K images each, as well as 25 splits of 1K images each.", "startOffset": 13, "endOffset": 33}, {"referenceID": 11, "context": "Similarly to Klein et al. (2015), we used the splits from Karpathy & Li (2015), and performed cross-validation on 5 validation splits of 5K images, and tested our models on 5 testing splits of 5K images each, as well as 25 splits of 1K images each.", "startOffset": 13, "endOffset": 79}, {"referenceID": 10, "context": "For feature extraction we follow Klein et al. (2015), and use on the image side the VGG CNN representation Simonyan & Zisserman (2015), where each image is cropped in 10 ways into 224 by 224 pixel images: the four corners, the center, and their x-axis mirror image.", "startOffset": 33, "endOffset": 53}, {"referenceID": 10, "context": "For feature extraction we follow Klein et al. (2015), and use on the image side the VGG CNN representation Simonyan & Zisserman (2015), where each image is cropped in 10 ways into 224 by 224 pixel images: the four corners, the center, and their x-axis mirror image.", "startOffset": 33, "endOffset": 135}, {"referenceID": 10, "context": "For feature extraction we follow Klein et al. (2015), and use on the image side the VGG CNN representation Simonyan & Zisserman (2015), where each image is cropped in 10 ways into 224 by 224 pixel images: the four corners, the center, and their x-axis mirror image. The mean intensity of each crop is subtracted in each color channel, and then encoded by VGG19 (the final FC -4096 layer). The average of the resulting 10 feature vectors corresponding to each crop is used as the image representation. On the text side, we use two sentence embeddings: the first one proposed by Klein et al. (2015) consisting in averaging the word2vec Mikolov et al.", "startOffset": 33, "endOffset": 597}, {"referenceID": 10, "context": "For feature extraction we follow Klein et al. (2015), and use on the image side the VGG CNN representation Simonyan & Zisserman (2015), where each image is cropped in 10 ways into 224 by 224 pixel images: the four corners, the center, and their x-axis mirror image. The mean intensity of each crop is subtracted in each color channel, and then encoded by VGG19 (the final FC -4096 layer). The average of the resulting 10 feature vectors corresponding to each crop is used as the image representation. On the text side, we use two sentence embeddings: the first one proposed by Klein et al. (2015) consisting in averaging the word2vec Mikolov et al. (2013) representation of words in each sentence.", "startOffset": 33, "endOffset": 656}, {"referenceID": 10, "context": "For feature extraction we follow Klein et al. (2015), and use on the image side the VGG CNN representation Simonyan & Zisserman (2015), where each image is cropped in 10 ways into 224 by 224 pixel images: the four corners, the center, and their x-axis mirror image. The mean intensity of each crop is subtracted in each color channel, and then encoded by VGG19 (the final FC -4096 layer). The average of the resulting 10 feature vectors corresponding to each crop is used as the image representation. On the text side, we use two sentence embeddings: the first one proposed by Klein et al. (2015) consisting in averaging the word2vec Mikolov et al. (2013) representation of words in each sentence. Word2vec representations are available on code.google.com/p/word2vec/, we followed the recommendation of Klein et al. (2015) in preprocessing the word2vec vocabulary matrix of COCO with PCA, to ensure averaging uncorrelated channels in the sentence embedding.", "startOffset": 33, "endOffset": 823}, {"referenceID": 10, "context": "The second embedding we used are skip thought vectors introduced in Kiros et al. (2015), which encodes sentences to vectors using an LSTM.", "startOffset": 68, "endOffset": 88}, {"referenceID": 10, "context": "5 Mean Vec (vocabICA +CCA) Klein et al. (2015) 24.", "startOffset": 27, "endOffset": 47}, {"referenceID": 10, "context": "0 Skip thoughts +Triplets loss Kiros et al. (2015) 25.", "startOffset": 31, "endOffset": 51}, {"referenceID": 10, "context": "0 Skip thoughts +Triplets loss Kiros et al. (2015) 25.9 60 74.6 NA 33.8 67.7 82.1 NA GMM+HGLMM+CCA Klein et al. (2015) 25.", "startOffset": 31, "endOffset": 119}, {"referenceID": 10, "context": "0 Skip thoughts +Triplets loss Kiros et al. (2015) 25.9 60 74.6 NA 33.8 67.7 82.1 NA GMM+HGLMM+CCA Klein et al. (2015) 25.6 60.4 76.8 4.0 38.9 68.4 80.1 2.0 5K test images: BRNN Karpathy & Li (2015) 8.", "startOffset": 31, "endOffset": 199}, {"referenceID": 10, "context": "0 Skip thoughts +Triplets loss Kiros et al. (2015) 25.9 60 74.6 NA 33.8 67.7 82.1 NA GMM+HGLMM+CCA Klein et al. (2015) 25.6 60.4 76.8 4.0 38.9 68.4 80.1 2.0 5K test images: BRNN Karpathy & Li (2015) 8.9 24.9 36.3 19.5 11.8 32.5 45.4 12.2 Mean Vec (vocabICA + CCA ) Klein et al. (2015) 10.", "startOffset": 31, "endOffset": 285}, {"referenceID": 10, "context": "0 Skip thoughts +Triplets loss Kiros et al. (2015) 25.9 60 74.6 NA 33.8 67.7 82.1 NA GMM+HGLMM+CCA Klein et al. (2015) 25.6 60.4 76.8 4.0 38.9 68.4 80.1 2.0 5K test images: BRNN Karpathy & Li (2015) 8.9 24.9 36.3 19.5 11.8 32.5 45.4 12.2 Mean Vec (vocabICA + CCA ) Klein et al. (2015) 10.3 27.2 38.4 18.0 12.8 32.1 44.6 14.0 Mean Vec (vocabPCA+ AWT-CCA) 11.63 30.35 42.31 15 11.34 30.30 42.31 15 Skip thoughts (AWT-CCA) 11.61 31.70 44.42 14 12.37 32.08 44.37 14 Skip thoughts +Triplets loss Kiros et al. (2015) NA NA NA NA NA NA NA NA GMM+HGLMM + CCA Klein et al.", "startOffset": 31, "endOffset": 511}, {"referenceID": 10, "context": "0 Skip thoughts +Triplets loss Kiros et al. (2015) 25.9 60 74.6 NA 33.8 67.7 82.1 NA GMM+HGLMM+CCA Klein et al. (2015) 25.6 60.4 76.8 4.0 38.9 68.4 80.1 2.0 5K test images: BRNN Karpathy & Li (2015) 8.9 24.9 36.3 19.5 11.8 32.5 45.4 12.2 Mean Vec (vocabICA + CCA ) Klein et al. (2015) 10.3 27.2 38.4 18.0 12.8 32.1 44.6 14.0 Mean Vec (vocabPCA+ AWT-CCA) 11.63 30.35 42.31 15 11.34 30.30 42.31 15 Skip thoughts (AWT-CCA) 11.61 31.70 44.42 14 12.37 32.08 44.37 14 Skip thoughts +Triplets loss Kiros et al. (2015) NA NA NA NA NA NA NA NA GMM+HGLMM + CCA Klein et al. (2015) 11.", "startOffset": 31, "endOffset": 571}, {"referenceID": 11, "context": "We see in Table 2 that using off the shelf unsupervised features (VGG, word2vec, skip thoughts vectors), AWT-CCA achieves state of the art results at both image search and annotation, and competes with supervised features extraction such as GMM+HGLMM of Klein et al. (2015)2 .", "startOffset": 254, "endOffset": 274}, {"referenceID": 4, "context": "We solved in this paper CCA in its batch formulation, for handling larger scale datasets we can use the randomized SVD of Halko et al. (2011) or the subsampled CCA of Avron et al.", "startOffset": 122, "endOffset": 142}, {"referenceID": 0, "context": "(2011) or the subsampled CCA of Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al.", "startOffset": 32, "endOffset": 52}, {"referenceID": 0, "context": "(2011) or the subsampled CCA of Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al. (2015); Wang et al.", "startOffset": 32, "endOffset": 102}, {"referenceID": 0, "context": "(2011) or the subsampled CCA of Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al. (2015); Wang et al. (2015), SGDCCA (Linear and Deep CCA) was proposed recently and can be applied to our problem.", "startOffset": 32, "endOffset": 122}, {"referenceID": 0, "context": "(2011) or the subsampled CCA of Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al. (2015); Wang et al. (2015), SGDCCA (Linear and Deep CCA) was proposed recently and can be applied to our problem. It would be interesting to study an efficient model selection for the SGD-CCA such as early stopping and truncated SVD for a finer model selection. A simple extension to kernel CCA regularization of this present paper would be to leverage random Fourier features for approximating Kernel CCA Lopez-Paz et al. (2014). Truncated SVD-CCA would be particularly interesting in this setting since kx, ky would be balancing the regularization and the estimation error of the kernel by means of random features.", "startOffset": 32, "endOffset": 525}, {"referenceID": 0, "context": "(2011) or the subsampled CCA of Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al. (2015); Wang et al. (2015), SGDCCA (Linear and Deep CCA) was proposed recently and can be applied to our problem. It would be interesting to study an efficient model selection for the SGD-CCA such as early stopping and truncated SVD for a finer model selection. A simple extension to kernel CCA regularization of this present paper would be to leverage random Fourier features for approximating Kernel CCA Lopez-Paz et al. (2014). Truncated SVD-CCA would be particularly interesting in this setting since kx, ky would be balancing the regularization and the estimation error of the kernel by means of random features. Note that the 1K results on Mean Vec (ICA +CCA) of Klein et al. (2015) and the skip thought of Kiros et al.", "startOffset": 32, "endOffset": 784}, {"referenceID": 0, "context": "(2011) or the subsampled CCA of Avron et al. (2014). Stochastic Gradient Descent CCA Ma et al. (2015); Wang et al. (2015), SGDCCA (Linear and Deep CCA) was proposed recently and can be applied to our problem. It would be interesting to study an efficient model selection for the SGD-CCA such as early stopping and truncated SVD for a finer model selection. A simple extension to kernel CCA regularization of this present paper would be to leverage random Fourier features for approximating Kernel CCA Lopez-Paz et al. (2014). Truncated SVD-CCA would be particularly interesting in this setting since kx, ky would be balancing the regularization and the estimation error of the kernel by means of random features. Note that the 1K results on Mean Vec (ICA +CCA) of Klein et al. (2015) and the skip thought of Kiros et al. (2015) are not comparable to ours since they are reported on only 1K test set, we report the mean of 25 splits 1K test sets.", "startOffset": 32, "endOffset": 828}], "year": 2017, "abstractText": "Joint modeling of language and vision has been drawing increasing interest. A multimodal data representation allowing for bidirectional retrieval of images by sentences and vice versa is a key aspect of this modeling. In this paper we show that canonical correlation analysis (CCA) can be adapted to bidirectional retrieval by a simple task dependent asymmetric weighting, which solves optimally the retrieval problem in a least squares sense. While regularizing CCA is known to improve numerical stability as well as generalization performance, less attention has been brought to the efficient computation of the regularization path of CCA, which is key to model selection. In this paper we develop efficient algorithms to compute the full regularization path of CCA within the classical Tikhonov and the truncated SVD (T-SVD CCA) regularization frameworks. T-SVD CCA is new to the best of our knowledge, and its regularization path can be computed more efficiently than its Tikhonov counterpart.", "creator": "LaTeX with hyperref package"}}}