{"id": "1511.06306", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Robust Convolutional Neural Networks under Adversarial Noise", "abstract": "Recent studies have shown that Convolutional Neural Networks (CNNs) are vulnerable to a small perturbation of input called \"adversarial examples\". In this work, we propose a new feedforward CNN that improves robustness in the presence of adversarial noise. Our model uses stochastic additive noise added to the input image and to the CNN models. The proposed model operates in conjunction with a CNN trained with standard backpropagation algorithm. In particular, convolution, max-pooling, and ReLU layers are modified to benefit from the noise model. Our model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture. The proposed model outperforms the standard CNN by 13.12% on ImageNet and 7.37% on CIFAR-10 under adversarial noise at the expense of 0.28% of accuracy drop when used in the original dataset -- with no added noise.", "histories": [["v1", "Thu, 19 Nov 2015 18:51:08 GMT  (423kb,D)", "https://arxiv.org/abs/1511.06306v1", "10 pages"], ["v2", "Thu, 25 Feb 2016 16:30:04 GMT  (86kb,D)", "http://arxiv.org/abs/1511.06306v2", "8 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["jonghoon jin", "aysegul dundar", "eugenio culurciello"], "accepted": false, "id": "1511.06306"}, "pdf": {"name": "1511.06306.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["ADVERSARIAL NOISE", "Jonghoon Jin", "Aysegul Dundar", "Eugenio Culurciello"], "emails": ["jhjin@purdue.edu", "adundar@purdue.edu", "euge@purdue.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Convolutionary Neural Networks (CNNs) (LeCun et al., 1998) have shown great success in the field of visual and semantic understanding, and have been used to solve problems of visual recognition where difficult-to-describe objects or multiple semantic concepts are present in images. Given the widespread use of cameras on mobile phones worldwide, CNNs are already a candidate for categorizing user photos. Device manufacturers use different types of cameras, each with very different sensor noise statistics (Tian, 2000). Even newer phone cameras can record video at hundreds of frames per second, where more frames per second lead to higher image noise (Tian, 2000). Unfortunately, CNNs are susceptible to artificial noise and could easily be deceived by noise of just a few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014) This problem arises because CNNs are discriminatory models."}, {"heading": "2 CONVOLUTIONAL NEURAL NETWORKS WITH NOISE MODEL", "text": "The proposed feed model uses a noise distribution applied to each pixel. The following subsections explain the stochastic operation of each layer, including folding, pooling and nonlinear activation. Other operators used in standard CNNs can also be found in Appendix B.ar Xiv: 151 1.06 306v 2 [cs.L G] 25 Feb 2016"}, {"heading": "2.1 INPUT NOISE MODEL", "text": "As a result of our modeling, each pixel in R3 (channel, height, width) becomes a random variable X (channel, height, width) and follows a normal distribution with the mean of the original pixel value \u00b5Xijk and a constant variance of \u03c3 2 NXijk, \u00b5Xijk + N = \u21d2 Xijk \u00b2 N (\u00b5Xijk, \u03c32N) (1), with all input pixels having the same noise performance of \u03c32N. The conditional independence of noise, for the specified value \u00b5Xijk, among the pixels in the neighborhood helps us to simplify the model and make it scalable for deep networks. To clarify this, we have adopted the artificial noise distribution to improve the robustness of CNNs, and it is unrelated to natural image statistics."}, {"heading": "2.2 CONVOLUTION LAYER", "text": "While CNN inputs are modeled as random variables, all remaining parameters such as weights and distortions are fixed constants. Folding is a weighted sum of random variables and their moments of first and second order output of the folding layer are displayed in the equation 2.E [Y] = \u2211 \u03c9E [X] + b, V ar [Y] = \u2211 \u03c92V ar [X] (2) X and Y according to a single element of the input and output in the folding layers. \u03c9 and b are weights and distortions, and the pixel indexes i, j and k are omitted for conciseness reasons. We are interested in first- and second-order statistics because we want to stick to a parametric model in all layers that simplifies the overall calculations."}, {"heading": "2.3 RECTIFIED LINEAR UNIT LAYER", "text": "Rectified linear units (ReLU) (Krizhevsky et al., 2012) apply nonlinearity Y = max (X, \u03b8) in an elementary way. Then, as shown in Appendix A, the distribution of stochastic ReLU output Y is censored on the left, where Y = X > \u03b8 is otherwise specified as a single value \u03b8. Mean and variance (Greene, 2008) of output Y for the given normal distribution of input X are: E [Y] = E [Y | X = \u03b8] Pr (Y = \u03b8 | X) + E [Y | X > \u03b8] Pr (Y > \u03b8 | X) = \u03b8\u0438 (\u03b1) + (\u00b5X + \u03c3X\u03bb (\u03b1))) (1 \u2212 hua (\u03b1))) V ar [Y] = EX [V ar [Y | X]] + V arX [Y | X]]] = \u03b5xiv arX (Y \u2212 \u03b1 \u2212 sistic) + (\u03b1) quantity higher as a starting point."}, {"heading": "2.4 MAX-POOLING LAYER", "text": "The prediction from stochastic max pooling is calculated on the basis of the exact distribution of the maximum values of two normal distributions (Nadarajah & Kotz, 2008), whose variables are taken from a group S with elements in the pooling window. Pair-wise maximum operation in equation 4 is applied iteratively until no element in group S.E [Y] = \u00b5Xi\u03a6 (\u03b1) + \u00b5Xj\u03a6 (\u2212 \u03b1) + \u03b8\u03c6 (\u03b1) V ar [Y] = (\u03c32Xi + \u00b5 2 Xi) \u03a6 (\u03b1) + (\u03c3 2 Xj + \u00b5 2 Xj) \u03a6 (\u2212 \u03b1) + (\u00b5Xi + \u00b5Xj) success\u03c6 (\u03b1) \u2212 E [Y] 2 (4), where \u03b1 = (\u00b5Xi \u2212 \u00b5Xj) \u03b8 = \u03c32Xi + \u03c3 2 Xj. By approximating the output to a normal parametric distribution (see Appendix A), we will calculate the accuracy for the miscalculation of this method depending on the maximum order of magnitude in 2007 and (see Appendix A)."}, {"heading": "3 EXPERIMENTAL RESULTS", "text": "In fact, it is the case that most of them are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) In fact, it is the case that they are able to break the rules. (...) In fact, it is the case that they are able to do what they want. (...) It is the case that they are able to break the rules. (...) In fact, it is the case that they are able to determine themselves. (...) It is the case that they are able to determine themselves what they want. (...) It is the case that they do it as if they want it, as if they want it, as if they want it, that they want it, that they do not want it, that they do not want it, that they want it, that they do not want it, that they do not want it, that they do not want it. \"(...).\""}, {"heading": "4 CONCLUSION", "text": "The proposed model outperforms other methods in the literature and the gain in accuracy becomes more apparent in difficult classification tasks or more hostile noise. Our model uses a parametric model that makes our method scalable to a deep architecture such as AlexNet. This work provides a solution for overcoming the sensitivity of CNNs to hostile noise to avoid potential security problems in CNN applications."}, {"heading": "APPENDIX TO ROBUST CONVOLUTIONAL NEURAL NETWORKS UNDER ADVERSARIAL NOISE", "text": "An INPUT-OUTPUT DISTRIBUTIONAn example in Figure 1a illustrates the input and output distributions of a single neuron in the ReLU layer, where the strain at \u03b8 indicates the point mass probability for the deactivated range in relation to the threshold \u03b8. Output from the ReLU layer is a censored distribution, the approximation of which causes errors in the feedback computation.Figure 1b illustrates the input, output and approximated output distributions from the max pooling layer simulated with only two variables. The output distribution is bell-shaped, but its mode is tilted to the right. If the means of the two inputs are further apart, the resulting distribution is likely to be a normal distribution. In other words, the error between the exact distribution P (Y) and its approximated Gaussian P (Y) tends to increase in proportion to the mean values."}, {"heading": "B OTHER STOCHASTIC OPERATIONS", "text": "In addition to the main operations discussed above, the standard CNNs consist of other modules such as batch normalization (Ioffe & Szegedy, 2015), spatial average pooling (Lin et al., 2013), softmax (or log-softmax), and drop-out (Hinton et al., 2012).Spatial average pooling and batch normalization are linear functions and can be processed with the folding layer model.The average pooling used in the NIN architecture corresponds to a folding layer whose weights and distortions are replaced by average coefficients (1 / n) or Nuli."}, {"heading": "C PARAMETER TUNING", "text": "C.1 ADVERSARIAL EXAMPLESPrior to the experiment, adversarial examples have been generated by the fast gradient sign method proposed in Goodfellow et al. (2014). The method generates adversarial noise over natural images, in the direction of the opposite of a gradient. Although the difference between the original and the adversarial sample is imperceptible to human eyes, the disturbance causes the samples to exceed the decision limit and thus to be classified as different categories. Noise can be interpreted as an exceptional type of noise, although such examples are rarely observed in the natural environment. Considering that the pixels encoded in an 8-bit image are positive integers in the range of [0, 255], the smallest and most effective pixel intensity of the character should be a multiple of 1 / \u03c3C, whereby \u03c3C is a standard deviation used for channel normalization during data preprocessing."}, {"heading": "D MORE RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "E APPROXIMATION ERROR", "text": "The stochastic method, which is based on a parametric model, simplified the calculation, but it goes hand in hand with an approximation of the maximum pooling method and the ReLU layer, which is a limiting factor of the algorithm. From the earlier section, the maximum pooling method is expected to produce approximation errors with stochastic input model, the quantity of which depends on the arrangement of the elements. We tested the accuracy due to the approximation error in the simple and ordered maximum pooling method to verify the effectiveness of the sorting in the context of CNNs. A single column AlexNet has more maximum pooling layers with a larger pooling region than the NIN. Therefore, it is more susceptible to approximation errors and is used to observe the effectiveness of the sorting in the context of CNNs. We found that the sorted maximum pooling method spends most of the time comparing to the normal model's maximum pooling accuracy rather than drawing the exact distribution based on its high pooling accuracy."}], "references": [{"title": "Training with noise is equivalent to tikhonov regularization", "author": ["Chris M Bishop"], "venue": "Neural computation,", "citeRegEx": "Bishop.,? \\Q1995\\E", "shortCiteRegEx": "Bishop.", "year": 1995}, {"title": "Explaining and harnessing adversarial examples", "author": ["Ian J Goodfellow", "Jonathon Shlens", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1412.6572,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Econometric analysis", "author": ["William H Greene"], "venue": "Granite Hill Publishers,", "citeRegEx": "Greene.,? \\Q2008\\E", "shortCiteRegEx": "Greene.", "year": 2008}, {"title": "Towards deep neural network architectures robust to adversarial examples", "author": ["Shixiang Gu", "Luca Rigazio"], "venue": "arXiv preprint arXiv:1412.5068,", "citeRegEx": "Gu and Rigazio.,? \\Q2014\\E", "shortCiteRegEx": "Gu and Rigazio.", "year": 2014}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Learning with a strong adversary", "author": ["Ruitong Huang", "Bing Xu", "Dale Schuurmans", "Csaba Szepesv\u00e1ri"], "venue": "arXiv preprint arXiv:1511.03034,", "citeRegEx": "Huang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe and Szegedy.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy.", "year": 2015}, {"title": "One weird trick for parallelizing convolutional neural networks", "author": ["Alex Krizhevsky"], "venue": "arXiv preprint arXiv:1404.5997,", "citeRegEx": "Krizhevsky.,? \\Q2014\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["Alex Krizhevsky", "Geoffrey Hinton"], "venue": "Computer Science Department,", "citeRegEx": "Krizhevsky and Hinton.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Exact distribution of the max/min of two gaussian random variables", "author": ["Saralees Nadarajah", "Samuel Kotz"], "venue": "Very Large Scale Integration (VLSI) Systems, IEEE Transactions on,", "citeRegEx": "Nadarajah and Kotz.,? \\Q2008\\E", "shortCiteRegEx": "Nadarajah and Kotz.", "year": 2008}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Anh Nguyen", "Jason Yosinski", "Jeff Clune"], "venue": "arXiv preprint arXiv:1412.1897,", "citeRegEx": "Nguyen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2014}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein"], "venue": "arXiv preprint arXiv:1409.0575,", "citeRegEx": "Russakovsky et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Russakovsky et al\\.", "year": 2014}, {"title": "Advances in computation of the maximum of a set of gaussian random variables. Computer-Aided Design of Integrated Circuits and Systems", "author": ["Debjit Sinha", "Hai Zhou", "Narendra V Shenoy"], "venue": "IEEE Transactions on,", "citeRegEx": "Sinha et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2007}, {"title": "Intriguing properties of neural networks", "author": ["Christian Szegedy", "Wojciech Zaremba", "Ilya Sutskever", "Joan Bruna", "Dumitru Erhan", "Ian Goodfellow", "Rob Fergus"], "venue": "arXiv preprint arXiv:1312.6199,", "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "Noise analysis in CMOS image sensors", "author": ["Hui Tian"], "venue": "PhD thesis, Citeseer,", "citeRegEx": "Tian.,? \\Q2000\\E", "shortCiteRegEx": "Tian.", "year": 2000}, {"title": "ADVERSARIAL EXAMPLES Prior to the experiment, adversarial examples are being generated through the fast gradient sign method proposed in Goodfellow et al", "author": ["C PARAMETER TUNING C"], "venue": null, "citeRegEx": "C.1,? \\Q2014\\E", "shortCiteRegEx": "C.1", "year": 2014}], "referenceMentions": [{"referenceID": 10, "context": "Convolutional neural networks (CNNs) (LeCun et al., 1998) have shown great success in visual and semantic understanding.", "startOffset": 37, "endOffset": 57}, {"referenceID": 16, "context": "Device manufacturers use various types of cameras, each with very different sensor noise statistics (Tian, 2000).", "startOffset": 100, "endOffset": 112}, {"referenceID": 16, "context": "Also, recent phone cameras can record a video at hundreds of frames per second, where more frames per second translates into higher image noise (Tian, 2000).", "startOffset": 144, "endOffset": 156}, {"referenceID": 15, "context": "Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014).", "startOffset": 114, "endOffset": 182}, {"referenceID": 1, "context": "Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014).", "startOffset": 114, "endOffset": 182}, {"referenceID": 12, "context": "Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014).", "startOffset": 114, "endOffset": 182}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al.", "startOffset": 6, "endOffset": 20}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al.", "startOffset": 6, "endOffset": 109}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al. (2015) used adversarial perturbation during training but not has been applied to natural images or more challenging image classification tasks.", "startOffset": 6, "endOffset": 130}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al. (2015) used adversarial perturbation during training but not has been applied to natural images or more challenging image classification tasks. Similarly, Gu & Rigazio (2014) proposed a denoising model for adversary using auto-encoders.", "startOffset": 6, "endOffset": 298}, {"referenceID": 9, "context": "Rectified linear units (ReLU) (Krizhevsky et al., 2012) applies the non-linearity Y = max(X, \u03b8) in an element-wise manner.", "startOffset": 30, "endOffset": 55}, {"referenceID": 2, "context": "The mean and variance (Greene, 2008) of output Y for the given normal distribution of input X are: E [Y ] = E[Y |X = \u03b8]Pr(Y = \u03b8|X) + E[Y |X > \u03b8]Pr(Y > \u03b8|X) = \u03b8\u03a6(\u03b1) + (\u03bcX + \u03c3X\u03bb(\u03b1)) (1\u2212 \u03a6(\u03b1)) V ar [Y ] = EX [V ar[Y |X]] + V arX [E[Y |X]] = \u03c3 X(1\u2212\u03a6(\u03b1)) [ (1\u2212\u03b4(\u03b1))+(\u03b1\u2212\u03bb(\u03b1))\u03a6(\u03b1) ] (3)", "startOffset": 22, "endOffset": 36}, {"referenceID": 14, "context": "According to Sinha et al. (2007) and appendix E, the ordering of iterative max operation should be set in an ascending order by their means to minimize approximation error.", "startOffset": 13, "endOffset": 33}, {"referenceID": 5, "context": "4 LWA + BN (Huang et al., 2015) 89.", "startOffset": 11, "endOffset": 31}, {"referenceID": 1, "context": "3 \u2014 \u2014 \u2014 Adversarial training (Goodfellow et al., 2014) 88.", "startOffset": 29, "endOffset": 54}, {"referenceID": 7, "context": ", 2013) and the single column AlexNet (Krizhevsky, 2014) with the latest technique including dropout and batch normalization (Ioffe & Szegedy, 2015).", "startOffset": 38, "endOffset": 56}, {"referenceID": 1, "context": "The networks were trained with either standard or adversarial training (Goodfellow et al., 2014) for comparison.", "startOffset": 71, "endOffset": 96}, {"referenceID": 13, "context": "Their performance under adversarial noise was evaluated on CIFAR-10 and ImageNet classification datasets (Krizhevsky & Hinton, 2009; Russakovsky et al., 2014).", "startOffset": 105, "endOffset": 158}, {"referenceID": 1, "context": "The gradient sign method (Goodfellow et al., 2014) was used to generate adversarial examples that are more likely to appear in natural environment.", "startOffset": 25, "endOffset": 50}, {"referenceID": 12, "context": "CNNs\u2019 decision boundary is constructed based on sparsely populated training samples (Nguyen et al., 2014) in a high-dimension.", "startOffset": 84, "endOffset": 105}], "year": 2016, "abstractText": "Recent studies have shown that Convolutional Neural Networks (CNNs) are vulnerable to a small perturbation of input called \u201cadversarial examples\u201d. In this work, we propose a new feedforward CNN that improves robustness in the presence of adversarial noise. Our model uses stochastic additive noise added to the input image and to the CNN models. The proposed model operates in conjunction with a CNN trained with either standard or adversarial objective function. In particular, convolution, max-pooling, and ReLU layers are modified to benefit from the noise model. Our feedforward model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture. From CIFAR-10 and ImageNet test, the proposed model outperforms other methods and the improvement is more evident for difficult classification tasks or stronger adversarial noise.", "creator": "LaTeX with hyperref package"}}}