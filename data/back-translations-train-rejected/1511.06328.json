{"id": "1511.06328", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Manifold Regularized Discriminative Neural Networks", "abstract": "Unregularized deep neural networks (DNNs) can be easily overfit with a limited sample size. We argue that this is mostly due to the disriminative nature of DNNs which directly model the conditional probability (or score) of labels given the input. The ignorance of input distribution makes DNNs difficult to generalize to unseen data. Recent advances in regularization techniques, such as pretraining and dropout, indicate that modeling input data distribution (either explicitly or implicitly) greatly improves the generalization ability of a DNN. In this work, we explore the manifold hypothesis which assumes that instances within the same class lie in a smooth manifold. We accordingly propose two simple regularizers to a standard discriminative DNN. The first one, named Label-Aware Manifold Regularization, assumes the availability of labels and penalizes large norms of the loss function w.r.t. data points. The second one, named Label-Independent Manifold Regularization, does not use label information and instead penalizes the Frobenius norm of the Jacobian matrix of prediction scores w.r.t. data points, which makes semi-supervised learning possible. We perform extensive control experiments on fully supervised and semi-supervised tasks using the MNIST dataset and set the state-of-the-art results on it.", "histories": [["v1", "Thu, 19 Nov 2015 19:46:39 GMT  (498kb,D)", "https://arxiv.org/abs/1511.06328v1", "In submission to ICLR 2016"], ["v2", "Thu, 3 Dec 2015 17:11:25 GMT  (498kb,D)", "http://arxiv.org/abs/1511.06328v2", "In submission to ICLR 2016"], ["v3", "Thu, 7 Jan 2016 22:05:56 GMT  (676kb,D)", "http://arxiv.org/abs/1511.06328v3", "In submission to ICLR 2016"]], "COMMENTS": "In submission to ICLR 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["shuangfei zhai", "zhongfei zhang"], "accepted": false, "id": "1511.06328"}, "pdf": {"name": "1511.06328.pdf", "metadata": {"source": "CRF", "title": "MANIFOLD REGULARIZED DISCRIMINATIVE NEURAL NETWORKS", "authors": ["Shuangfei Zhai", "Zhongfei (Mark) Zhang"], "emails": ["szhai2@binghamton.edu,", "zhongfei@cs.binghamton.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is such that most of them will be able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they are able to"}, {"heading": "2 MODEL", "text": "Consider a multi-page classification problem with the data {(x1, y1),..., (xN l, yN l)}, where the observation and designation of the i-th instance is the number of instances described. We also assume a series of blank instances {xu1,..., xuNu}. A discriminatory model minimizes an objective function in the following form: 1N l N l l x x i = 1 '(yi, f (x l i))). J (\u03b8) + R (\u03b8), (1) where f (xli) and RK calculate the predicted value of xli belonging to each of the K-class;' is a loss function that indicates the compatibility between the ground truth yi and the prediction f (xli)."}, {"heading": "2.1 LABEL-AWARE MANIFOLD REGULARIZATION", "text": "In this version, we consider the fully monitored environment in which all data points are labeled. According to the multiple assumptions, the data points within each class are in a smooth multiplicity. Without any prior knowledge of the form of data multiplicity, we assume that shifting an observation by a tiny step should still keep it in the same multiplicity. Consequently, the loss function must be flat around each observation. In other words, the derivative of the loss function for entering x ('y, f (x))) should be small. This leads directly to a regularization in the form: R1 (\u03b8) = \u03bbN l N l N-l-i = 1-l-xli (yi, f (x-l-i; \u03b8))."}, {"heading": "2.2 LABEL-INDEPENDENT MANIFOLD REGULARIZATION", "text": "LAMR assumes the availability of fully labeled data, which prohibits its application to semi-monitored settings in which large portions of the data are not labeled. To this end, we propose a slightly different view of regulation, the idea being that we can consider f (x; \u03b8) as a representation of the data diversity on the label embedded in RK. Following a similar reasoning, we then encourage f (x; \u03b8), rather than the loss function, to be flat when moving input along the data diversity. While the same idea was proposed in Gu & Rigazio (2014) as a deep contractive network (DCN), we expand it further by observing that this regulation also applies to unlabeled data, which makes this view particularly interesting since we are now able to better explore data distribution using unlabeled data."}, {"heading": "2.3 STOCHASTIC APPROXIMATION", "text": "Although it is possible to express R1 (\u03b8) and R2 (\u03b8) in closed form for forward-facing neural networks, the resulting objective function for DNNs and structured architectures such as CNNs could be complicated, making the calculation of gradients w.r.t. model parameters inefficient. To solve this problem, we take a simple stochastic approximation of regularization terms. Let g: Rd 7 \u2192 R be a differentiable function. Consequently, we have: E [g (x +) a draw from an isotropic Gaussian distribution with variance \u03c32; then g (x +) \u2248 g (x) + T-xg (x), (4) according to the Taylor expansion of the first order. Consequently, we have: E [g (x +) \u2212 g (x)] a draw from an isotropic distribution with variance \u04452; then g [T-xg (x) a chastic distribution."}, {"heading": "2.4 CONNECTION WITH EXISTING REGULARIZERS", "text": "It is not the case that we emphasize the function of loss as LAMR. To see this, one has to look at the simplest case in which Pnoise = N (0, 2 noiseI), we can then use the second order Taylor Expansion as: 1N l. \"N l.\" L. \"L.\" L. \"L.\" L \".L\".L \".L\".L \".L\" L \".L\".L \".L\".L \".L\".L \".L.L.L\".L \".L\" L \".L\" L \"L\".L \"L\" L \".L\" L \".L\" L \".L\" L \".L\" L \"L\".L \"L\" L \".L\" L \"L\".L \"L\".L \"L\".L \"L\".L \"L\".L \"L\".L \"L\" L \".L\" L \".L\" L \"L\".L \"L\".L \"L\".L \"L\" L \".L\" L \".L\" L \".L\" L \".L\" L \"L\".L \".L\" L \"L\".L \"L\".L \"L\".L \"L\" L \".L\" L \"L\".L \"L\".L \"L\" L \".L\" L \"L\" L \"L\".L \"L\" L \"L\".L \"L\" L \".L\" L \"L\".L \"L\" L \"L\".L \"L\" L \".L\" L \"L\" L \"L\".L \"L\" L \"L\".L \"L\" L \"L\".L \"L\" L \".L\" L \"L\".L \"L\" L \"L\" L \"L\".L \"L\" L \"L\" L \".L\" L \"L\" L \"L\" L \".L\" L \"L\".L \".L\" L \"L\".L \"L\" L \".L\" L \".L\" L \"L\" L \".L\" L \"L\".L \"L\" L \".L\" L \"L\" L \".L\".L \""}, {"heading": "3 EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 SUPERVISED LEARNING", "text": "In the first series of experiments, we use the MNIST datasets to validate the regulatory effects in the supervised learning environment. We use the MNIST datasets to validate the results in the superordinate learning environment. MNIST consists of 50,000 training, 10,000 validation and 10,000 test images of the handwritten digits, each with the shape 28x28. W-track a three-layer feed network with the size 500 x 500 x 500 x 10, where 10 the size of the outputs varies. We use ReLU as a nonlinear activation function for each of the three hidden layers and a linear output layer (whose output f (xi; \u03b8) together with the one-on-residual hinges loss as in Tang (2013). Parameters are initialized following Glorot & Bengio and optimized with Adadelta pointer (2012) using a batch size of 100."}, {"heading": "3.2 SEMI-SUPERVISED LEARNING WITH LIMR", "text": "We look at the semi-supervised learning environment in which we use only a small portion of the labels from the training set. We use the same fully networked three layers as in Section 3.1. We follow the experimental settings as in Rifai et al. (2011a); we report the results in Table 4, which splits the performance of the classifier and an unnamed set. We use the validation of the selected ranges and \u03b2, and we find that it works well for all four ranges. We see that LIMR consistently increases the performance of the classifier using the unnamed data."}, {"heading": "4 CONCLUSION", "text": "We have proposed two regulators that leverage the diverse data to guide the learning of a discriminatory neural network. By promoting the flatness of the loss function or predictive values along the data diversity, we can significantly improve the generalizability of a DNN. In addition, our label-independent diverse regulation allows unlabeled data to be directly integrated into the supervised learning task and perform semi-supervised learning effectively. We have validated our proposed regulators on the MNIST, CIFAR10 and SVHN data sets and demonstrated their effectiveness."}], "references": [{"title": "Greedy layer-wise training of deep networks", "author": ["Bengio", "Yoshua", "Lamblin", "Pascal", "Popovici", "Dan", "Larochelle", "Hugo"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "Training with noise is equivalent to tikhonov regularization", "author": ["Bishop", "Chris M"], "venue": "Neural computation,", "citeRegEx": "Bishop and M.,? \\Q1995\\E", "shortCiteRegEx": "Bishop and M.", "year": 1995}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Glorot", "Xavier", "Bengio", "Yoshua"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "Glorot et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2010}, {"title": "Explaining and harnessing adversarial examples", "author": ["Goodfellow", "Ian J", "Shlens", "Jonathon", "Szegedy", "Christian"], "venue": "ICLR,", "citeRegEx": "Goodfellow et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2015}, {"title": "Towards deep neural network architectures robust to adversarial examples", "author": ["Gu", "Shixiang", "Rigazio", "Luca"], "venue": "arXiv preprint arXiv:1412.5068,", "citeRegEx": "Gu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gu et al\\.", "year": 2014}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Hinton", "Geoffrey E", "Salakhutdinov", "Ruslan R"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Semisupervised learning with deep generative models", "author": ["Kingma", "Diederik P", "Mohamed", "Shakir", "Rezende", "Danilo Jimenez", "Welling", "Max"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Dropout as data augmentation", "author": ["Konda", "Kishore", "Bouthillier", "Xavier", "Memisevic", "Roland", "Vincent", "Pascal"], "venue": "arXiv preprint arXiv:1506.08700,", "citeRegEx": "Konda et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Konda et al\\.", "year": 2015}, {"title": "The manifold tangent classifier", "author": ["Rifai", "Salah", "Dauphin", "Yann N", "Vincent", "Pascal", "Bengio", "Yoshua", "Muller", "Xavier"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Rifai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rifai et al\\.", "year": 2011}, {"title": "Higher order contractive auto-encoder", "author": ["Rifai", "Salah", "Mesnil", "Gr\u00e9goire", "Vincent", "Pascal", "Muller", "Xavier", "Bengio", "Yoshua", "Dauphin", "Yann", "Glorot"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Rifai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rifai et al\\.", "year": 2011}, {"title": "Contractive autoencoders: Explicit invariance during feature extraction", "author": ["Rifai", "Salah", "Vincent", "Pascal", "Muller", "Xavier", "Glorot", "Bengio", "Yoshua"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Rifai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rifai et al\\.", "year": 2011}, {"title": "Best practices for convolutional neural networks applied to visual document analysis", "author": ["Simard", "Patrice Y", "Steinkraus", "Dave", "Platt", "John C"], "venue": "In null,", "citeRegEx": "Simard et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Simard et al\\.", "year": 2003}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Intriguing properties of neural networks", "author": ["Szegedy", "Christian", "Zaremba", "Wojciech", "Sutskever", "Ilya", "Bruna", "Joan", "Erhan", "Dumitru", "Goodfellow", "Ian", "Fergus", "Rob"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Deep learning using linear support vector machines", "author": ["Tang", "Yichuan"], "venue": "arXiv preprint arXiv:1306.0239,", "citeRegEx": "Tang and Yichuan.,? \\Q2013\\E", "shortCiteRegEx": "Tang and Yichuan.", "year": 2013}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["Vincent", "Pascal", "Larochelle", "Hugo", "Lajoie", "Isabelle", "Bengio", "Yoshua", "Manzagol", "Pierre-Antoine"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Vincent et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}, {"title": "Dropout training as adaptive regularization", "author": ["Wager", "Stefan", "Wang", "Sida", "Liang", "Percy S"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Wager et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wager et al\\.", "year": 2013}, {"title": "Adadelta: An adaptive learning rate method", "author": ["Zeiler", "Matthew D"], "venue": "arXiv preprint arXiv:1212.5701,", "citeRegEx": "Zeiler and D.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler and D.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "In the past decade, we have witnessed several effective regularization techniques that help DNNs better generalize to unobserved data, most noticeably pretraining Hinton & Salakhutdinov (2006); Bengio et al. (2007) and dropout Srivastava et al.", "startOffset": 194, "endOffset": 215}, {"referenceID": 0, "context": "In the past decade, we have witnessed several effective regularization techniques that help DNNs better generalize to unobserved data, most noticeably pretraining Hinton & Salakhutdinov (2006); Bengio et al. (2007) and dropout Srivastava et al. (2014). In pretraining, several layers of either RBMs or regularized autoencoders are trained on unlabeled data.", "startOffset": 194, "endOffset": 252}, {"referenceID": 0, "context": "In the past decade, we have witnessed several effective regularization techniques that help DNNs better generalize to unobserved data, most noticeably pretraining Hinton & Salakhutdinov (2006); Bengio et al. (2007) and dropout Srivastava et al. (2014). In pretraining, several layers of either RBMs or regularized autoencoders are trained on unlabeled data. One then uses the weights of the stacked deep RBM/autoencoder as the initialization weights for a discriminative DNN, which is further trained on labeled dataset by adding an appropriate classifier layer on top. It is shown that pretrained weights perform very well as an implicit regularization as they prevent the model to get stuck in poor local optimums. The reason for its success is that with the pretrained RMB/autoencoder, the disriminative model gains (implicit) prior knowledge about the data distribution P (x), thus is able to generalize better to unobserved data. Dropout works by randomly masking out part of both the input and hidden units during the discriminative training with SGD. Konda et al. (2015) shows that the effectiveness of dropout can be understood by considering it as a kind of data augmentation Simard et al.", "startOffset": 194, "endOffset": 1078}, {"referenceID": 0, "context": "In the past decade, we have witnessed several effective regularization techniques that help DNNs better generalize to unobserved data, most noticeably pretraining Hinton & Salakhutdinov (2006); Bengio et al. (2007) and dropout Srivastava et al. (2014). In pretraining, several layers of either RBMs or regularized autoencoders are trained on unlabeled data. One then uses the weights of the stacked deep RBM/autoencoder as the initialization weights for a discriminative DNN, which is further trained on labeled dataset by adding an appropriate classifier layer on top. It is shown that pretrained weights perform very well as an implicit regularization as they prevent the model to get stuck in poor local optimums. The reason for its success is that with the pretrained RMB/autoencoder, the disriminative model gains (implicit) prior knowledge about the data distribution P (x), thus is able to generalize better to unobserved data. Dropout works by randomly masking out part of both the input and hidden units during the discriminative training with SGD. Konda et al. (2015) shows that the effectiveness of dropout can be understood by considering it as a kind of data augmentation Simard et al. (2003). From this perspective, dropout can be considered as implicitly modeling the data manifold by sampling from it.", "startOffset": 194, "endOffset": 1206}, {"referenceID": 0, "context": "In the past decade, we have witnessed several effective regularization techniques that help DNNs better generalize to unobserved data, most noticeably pretraining Hinton & Salakhutdinov (2006); Bengio et al. (2007) and dropout Srivastava et al. (2014). In pretraining, several layers of either RBMs or regularized autoencoders are trained on unlabeled data. One then uses the weights of the stacked deep RBM/autoencoder as the initialization weights for a discriminative DNN, which is further trained on labeled dataset by adding an appropriate classifier layer on top. It is shown that pretrained weights perform very well as an implicit regularization as they prevent the model to get stuck in poor local optimums. The reason for its success is that with the pretrained RMB/autoencoder, the disriminative model gains (implicit) prior knowledge about the data distribution P (x), thus is able to generalize better to unobserved data. Dropout works by randomly masking out part of both the input and hidden units during the discriminative training with SGD. Konda et al. (2015) shows that the effectiveness of dropout can be understood by considering it as a kind of data augmentation Simard et al. (2003). From this perspective, dropout can be considered as implicitly modeling the data manifold by sampling from it. Another motivation of our work is the recent findings of Szegedy et al. (2014), where the authors show that the prediction of a trained discriminative DNN could be greatly changed by adding to the", "startOffset": 194, "endOffset": 1397}, {"referenceID": 3, "context": "As a remedy, Goodfellow et al. (2015) proposes a way to generate adversarial examples (neighbors of sample data points that increase the loss function significantly) as the additional training data.", "startOffset": 13, "endOffset": 38}, {"referenceID": 15, "context": "In practice, we simulate the expectations in R\u0303 and R\u0303 by randomly sampling the Gaussian noise at each iteration of stochastic gradient descent (SGD), in the same way as Vincent et al. (2010). In theory, the stochastic approximation is more accurate when using a small \u03c3.", "startOffset": 170, "endOffset": 192}, {"referenceID": 9, "context": "Also, note that one variant of Dropout Srivastava et al. (2014) when mask out noise is only applied to the input layer can be analyzed in a similar way, and the readers are encouraged to see Wager et al.", "startOffset": 39, "endOffset": 64}, {"referenceID": 9, "context": "Also, note that one variant of Dropout Srivastava et al. (2014) when mask out noise is only applied to the input layer can be analyzed in a similar way, and the readers are encouraged to see Wager et al. (2013) for detailed discussions.", "startOffset": 39, "endOffset": 211}, {"referenceID": 8, "context": "Manifold Tangent Classifier (MTC) Rifai et al. (2011a): MTC is a semi-supervised classifier that considers the data manifold, which builds upon the Contractive Autoencoders (CAE) Rifai et al.", "startOffset": 34, "endOffset": 55}, {"referenceID": 3, "context": "Adversarial Training Goodfellow et al. (2015): Recently in Szegedy et al.", "startOffset": 21, "endOffset": 46}, {"referenceID": 3, "context": "Adversarial Training Goodfellow et al. (2015): Recently in Szegedy et al. (2014), the authors point out that the state-of-the-art DNNs can misclassify examples that are generated by adding to the training examples with certain small perturbations (adversarial examples).", "startOffset": 21, "endOffset": 81}, {"referenceID": 3, "context": "Adversarial Training Goodfellow et al. (2015): Recently in Szegedy et al. (2014), the authors point out that the state-of-the-art DNNs can misclassify examples that are generated by adding to the training examples with certain small perturbations (adversarial examples). To address this issue, Goodfellow et al. (2015) propose a strategy to generate adversarial examples and add them to the training set along training.", "startOffset": 21, "endOffset": 319}, {"referenceID": 8, "context": ", Rifai et al. (2011c)).", "startOffset": 2, "endOffset": 23}, {"referenceID": 8, "context": "Method Test error rate 8192\u00d7 8192 NN + Dropout Srivastava et al. (2014) 0.", "startOffset": 47, "endOffset": 72}, {"referenceID": 8, "context": "Method Test error rate 8192\u00d7 8192 NN + Dropout Srivastava et al. (2014) 0.95 500\u00d7 500\u00d7 2000 DBN + Dropout finetuning Srivastava et al. (2014) 0.", "startOffset": 47, "endOffset": 142}, {"referenceID": 8, "context": "Method Test error rate 8192\u00d7 8192 NN + Dropout Srivastava et al. (2014) 0.95 500\u00d7 500\u00d7 2000 DBN + Dropout finetuning Srivastava et al. (2014) 0.92 500\u00d7 500\u00d7 2000 DBM + Dropout finetuning Srivastava et al. (2014) 0.", "startOffset": 47, "endOffset": 212}, {"referenceID": 7, "context": "79 2000\u00d7 2000 Contractive Autoenconder Rifai et al. (2011b) 1.", "startOffset": 39, "endOffset": 60}, {"referenceID": 7, "context": "79 2000\u00d7 2000 Contractive Autoenconder Rifai et al. (2011b) 1.04 2000\u00d7 2000 Manifold Tangent Classifier Rifai et al. (2011a) 0.", "startOffset": 39, "endOffset": 125}, {"referenceID": 3, "context": "81 1600\u00d7 1600 Maxout NN + Adversarial Training Goodfellow et al. (2015) 0.", "startOffset": 47, "endOffset": 72}, {"referenceID": 3, "context": "When training on the full 60000 labeled dataset, we achieve a test error that is comparable with the state-of-the-art result in Goodfellow et al. (2013).", "startOffset": 128, "endOffset": 153}, {"referenceID": 3, "context": "Table 3: Error rates of CNN trained with LAMR, compared with state of the art model Goodfellow et al. (2013).", "startOffset": 84, "endOffset": 109}, {"referenceID": 7, "context": "We follow the experiment settings as in Rifai et al. (2011a); Kingma et al.", "startOffset": 40, "endOffset": 61}, {"referenceID": 6, "context": "(2011a); Kingma et al. (2014), where the 50000 training set is further split into one labeled set and one unlabeled set.", "startOffset": 9, "endOffset": 30}, {"referenceID": 6, "context": "(2011a); Kingma et al. (2014), where the 50000 training set is further split into one labeled set and one unlabeled set. We use the validation set the select \u03bb and \u03b2, and found that \u03bb = \u03b2 = 15 works well for all the four settings. We report the results in Table 4. We see that LIMR consistently boosts the performance of the classifier with the aid of unlabeled data. Compared with the state-of-the-art models, except for the case with only 100 labels, LIMR is comparable or better than pretraining based semi-supervised learning CAE and MTC. The deep generative model proposed by Kingma et al. (2014) works the best with very few labels in general, but it is beat by LIMR in the case of 3000 labels.", "startOffset": 9, "endOffset": 602}, {"referenceID": 6, "context": "# labels NN NN + LIMR CAE MTC Kingma et al. (2014) 100 32.", "startOffset": 30, "endOffset": 51}], "year": 2016, "abstractText": "Unregularized deep neural networks (DNNs) can be easily overfit with a limited sample size. We argue that this is mostly due to the disriminative nature of DNNs which directly model the conditional probability (or score) of labels given the input. The ignorance of input distribution makes DNNs difficult to generalize to unseen data. Recent advances in regularization techniques, such as pretraining and dropout, indicate that modeling input data distribution (either explicitly or implicitly) greatly improves the generalization ability of a DNN. In this work, we explore the manifold hypothesis which assumes that instances within the same class lie in a smooth manifold. We accordingly propose two simple regularizers to a standard discriminative DNN. The first one, named Label-Aware Manifold Regularization, assumes the availability of labels and penalizes large norms of the loss function w.r.t. data points. The second one, named Label-Independent Manifold Regularization, does not use label information and instead penalizes the Frobenius norm of the Jacobian matrix of prediction scores w.r.t. data points, which makes semi-supervised learning possible. We perform extensive control experiments on fully supervised and semi-supervised tasks using the MNIST, CIFAR10 and SVHN datasets and achieve excellent results.", "creator": "LaTeX with hyperref package"}}}