{"id": "1511.06348", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?", "abstract": "The use of Convolutional Neural Networks (CNN) in natural image classification systems has produced very impressive results. Combined with the inherent nature of medical images that make them ideal for deep-learning, further application of such systems to medical image classification holds much promise. However, the usefulness and potential impact of such a system can be completely negated if it does not reach a target accuracy. In this paper, we present a study on determining the optimum size of the training data set necessary to achieve high classification accuracy with low variance in medical image classification systems. The CNN was applied to classify axial Computed Tomography (CT) images into six anatomical classes. We trained the CNN using six different sizes of training data set (5, 10, 20, 50, 100, and 200) and then tested the resulting system with a total of 6000 CT images. All images were acquired from the Massachusetts General Hospital (MGH) Picture Archiving and Communication System (PACS). Using this data, we employ the learning curve approach to predict classification accuracy at a given training sample size. Our research will present a general methodology for determining the training data set size necessary to achieve a certain target classification accuracy that can be easily applied to other problems within such systems.", "histories": [["v1", "Thu, 19 Nov 2015 20:38:43 GMT  (2696kb)", "http://arxiv.org/abs/1511.06348v1", null], ["v2", "Thu, 7 Jan 2016 21:08:10 GMT  (2698kb)", "http://arxiv.org/abs/1511.06348v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["junghwan cho", "kyewook lee", "ellie shin", "garry choy", "synho do"], "accepted": false, "id": "1511.06348"}, "pdf": {"name": "1511.06348.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Junghwan Cho", "Kyewook Lee", "Ellie Shin", "Garry Choy"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 151 1,06 348v 1 [cs.L G] 19 Nov 201 5"}, {"heading": "1 INTRODUCTION", "text": "The rapidly growing amount of medical images and modalities that need to be taken into account poses a growing risk of human error and delayed diagnosis, and the current response to these concerns remains computerized recognition (CADe) and diagnostic (CADx) systems. However, despite the recent development and improvement of these systems, they remain limited in their potential by the use of handcrafted features (Shiraishi et al. (2011). This limitation suggests the potential of a profound approach that would rather allow the system to extract these features itself (Jones (2014)). While recent years have shown significant advances in image classification, problems with conventional neural networks (CNN), its potential in medical applications is only minimally explored (Ypsilantis et al), Hua et al al. (2015) Large medical image sets within a hospital have made significant advances in image classification based on conventional neural networks (CNN), its potential is related to the ability to learn."}, {"heading": "1.1 MEDICAL IMAGE UNIQUENESS", "text": "Compared to natural images, medical images have unique properties that fit well with machine learning. The potential of medical images is increased by the unique inherent properties of medical images, which make them ideal for machine learning. First, all images are standardized. Medical images are acquired from many different modalities (i.e., X-rays, ultrasound, computed tomography (CT), magnetic resonance imaging (MRI), positron emission tomography (PET), single photon emission computed tomography (SPECT), etc. However, all resulting images must be stored and archived in a single format. digital images and medical communication (DICOM) are in format. DICOM file metadata cover the field of image quality, matrix size, pixel pitch, slice thickness, image resolution, scan resolution, patient information, etc."}, {"heading": "2 MATERIAL AND METHOD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 DATA ACQUISITION", "text": "We first created a database of CT images of patients from the MGH Clinical PACS with the approval of the Institutional Review Board (IRB). We developed pre-processing software to comment and categorize these images into which body parts are divided: brain, neck, shoulder, chest, abdomen and pelvis. As can be seen in Figure 1 (A), we used only scans from regions that could be clearly defined as one of the above body parts. Gaps take into account transition regions that were not used for a training algorithm due to the lack of a clear regional definition. In the axial CT scan, each scan exhibits a different level of noise due to different radiation dosage and image reconstruction filters and different CT manufacturers. In addition, each image voxel has different pitches due to image reconstruction fields. The slice thickness of each image is thicker than the axial voxel pitch, so that voxels in general are axial pixels (= 0.3)."}, {"heading": "2.2 CONVOLUTIONAL NEURAL NETWORK", "text": "The body part classification problem is an important step in the initial classification process for the eventual classification of diseases and abnormal recognition problems. In addressing this problem, several aspects must be taken into account: First, anatomical structures and the details of body regions vary dramatically between patients (i.e., complex brain regions, small lung nodes and thin pleures in the chest, tightly arranged organs in the abdominal region); second, important bone structures in the shoulder and pelvis result in artifacts on medical images. As a result, it is possible that a huge learning dataset is required for our algorithm to achieve the desired accuracy. Accordingly, processing such large data requires a robust algorithm."}, {"heading": "2.3 LEARNING CURVE", "text": "The classification accuracy of deep learning classifiers is largely dependent on the size of high-quality initial training data sets = 1. Consequently, the study of how large a training sample set is in order to achieve the target accuracy for anatomical image classification is indispensable. Generally, the learning curve approach of modeling classification performance as a function of training sample size (x) can predict the sample size needed to train a particular image classification system. Generally, this curve model is presented as an inverse performance law function (Figure and al. (2012) Classification accuracy (y) is expressed as a function of training sample size (x) when an unknown parameter (b = b1, b2). The learning curve is modeled by the following equation: y = f (x; b) = 100 + b1 xb2), where x = the accuracy of training set size (x) is expressed."}, {"heading": "3 RESULTS AND DISCUSSIONS", "text": "In fact, most of them are able to play by the rules that they have shown in recent years, and they are able to play by the rules."}, {"heading": "4 CONCLUSION", "text": "While medical image analysis applications have only recently begun to be explored, the potential of such systems is immense due to the unique properties of medical images that make them ideal for deep learning. For example, all medical images are regulated for extremely high quality and also manually provided with a radiologist's report or a basic truth. These qualities are particularly ideal and necessary because such systems require exceptionally high sensitivity and specificity due to their importance to diagnosis and treatment planning. However, laws and guidelines make it very difficult to access such medical images. We present a learning curve extrapolation method to estimate the required training data size, the methodology of which is theoretically well formulated in the field of medical machine learning - just how large does our training data set need to be in order to solve a specific classification or recognition problem with high accuracy? We present a learning curve extrapolation method to estimate the required training data size, the methodology of which is well formulated in other areas and when applied to similar results."}], "references": [{"title": "Sample size planning for classification models", "author": ["Beleites", "Claudia", "Neugebauer", "Ute", "Bocklitz", "Thomas", "Krafft", "Christoph", "Popp", "J\u00fcrgen"], "venue": "Analytica chimica acta,", "citeRegEx": "Beleites et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Beleites et al\\.", "year": 2013}, {"title": "An adaptive nonlinear least-squares algorithm", "author": ["Dennis Jr.", "John E", "Gay", "David M", "Walsh", "Roy E"], "venue": "ACM Transactions on Mathematical Software (TOMS),", "citeRegEx": "Jr et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Jr et al\\.", "year": 1981}, {"title": "Sample size planning for developing classifiers using high-dimensional dna microarray", "author": ["Dobbin", "Kevin K", "Simon", "Richard M"], "venue": "data. Biostatistics,", "citeRegEx": "Dobbin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dobbin et al\\.", "year": 2007}, {"title": "How large a training set is needed to develop a classifier for microarray data", "author": ["Dobbin", "Kevin K", "Zhao", "Yingdong", "Simon", "Richard M"], "venue": "Clinical Cancer Research,", "citeRegEx": "Dobbin et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dobbin et al\\.", "year": 2008}, {"title": "Predicting sample size required for classification performance", "author": ["Figueroa", "Rosa L", "Zeng-Treitler", "Qing", "Kandula", "Sasikiran", "Ngo", "Long H"], "venue": "BMC medical informatics and decision making,", "citeRegEx": "Figueroa et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Figueroa et al\\.", "year": 2012}, {"title": "Computer-aided classification of lung nodules on computed tomography images via deep learning technique", "author": ["Hua", "Kai-Lung", "Hsu", "Che-Hao", "Hidayati", "Shintami Chusnul", "Cheng", "Wen-Huang", "Chen", "Yu-Jen"], "venue": "OncoTargets and therapy,", "citeRegEx": "Hua et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hua et al\\.", "year": 2015}, {"title": "Neuro-fuzzy and soft computing; a computational approach to learning and machine intelligence", "author": ["Jang", "Jyh-Shing Roger", "Sun", "Chuen-Tsai", "Mizutani", "Eiji"], "venue": null, "citeRegEx": "Jang et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Jang et al\\.", "year": 1997}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia", "Yangqing", "Shelhamer", "Evan", "Donahue", "Jeff", "Karayev", "Sergey", "Long", "Jonathan", "Girshick", "Ross", "Guadarrama", "Sergio", "Darrell", "Trevor"], "venue": "In Proceedings of the ACM International Conference on Multimedia,", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Anatomy-specific classification of medical images using deep convolutional nets", "author": ["Roth", "Holger R", "Lee", "Christopher T", "Shin", "Hoo-Chang", "Seff", "Ari", "Kim", "Lauren", "Yao", "Jianhua", "Lu", "Le", "Summers", "Ronald M"], "venue": "arXiv preprint arXiv:1504.04003,", "citeRegEx": "Roth et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2015}, {"title": "Improving computer-aided detection using convolutional neural networks and random view aggregation", "author": ["Roth", "Holger R", "Lu", "Le", "Liu", "Jiamin", "Yao", "Jianhua", "Seff", "Ari", "Kevin", "Cherry", "Kim", "Lauren", "Summers", "Ronald M"], "venue": "arXiv preprint arXiv:1505.03046,", "citeRegEx": "Roth et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2015}, {"title": "Computer-aided diagnosis and artificial intelligence in clinical imaging", "author": ["Shiraishi", "Junji", "Li", "Qiang", "Appelbaum", "Daniel", "Doi", "Kunio"], "venue": "In Seminars in nuclear medicine,", "citeRegEx": "Shiraishi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shiraishi et al\\.", "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "arXiv preprint arXiv:1409.4842,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Predicting response to neoadjuvant chemotherapy with pet imaging using convolutional neural networks", "author": ["Ypsilantis", "Petros-Pavlos", "Siddique", "Musib", "Sohn", "Hyon-Mok", "Davies", "Andrew", "Cook", "Gary", "Goh", "Vicky", "Montana", "Giovanni"], "venue": "PloS one,", "citeRegEx": "Ypsilantis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ypsilantis et al\\.", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "However, despite recent development and improvement of these systems, they remain limited in their potential by their use of hand-crafted features (Shiraishi et al. (2011)).", "startOffset": 148, "endOffset": 172}, {"referenceID": 8, "context": "However, despite recent development and improvement of these systems, they remain limited in their potential by their use of hand-crafted features (Shiraishi et al. (2011)). This limitation suggests the potential of a deep-learning approach, which would rather allow the system to extract these features itself (Jones (2014)).", "startOffset": 148, "endOffset": 325}, {"referenceID": 8, "context": "However, despite recent development and improvement of these systems, they remain limited in their potential by their use of hand-crafted features (Shiraishi et al. (2011)). This limitation suggests the potential of a deep-learning approach, which would rather allow the system to extract these features itself (Jones (2014)). However, while recent years have shown significant advances in image classification problems using Convolutional Neural Networks (CNN), its potential in medical applications has only been minimally explored (Ypsilantis et al. (2015), Hua et al.", "startOffset": 148, "endOffset": 560}, {"referenceID": 5, "context": "(2015), Hua et al. (2015)).", "startOffset": 8, "endOffset": 26}, {"referenceID": 5, "context": "(2015), Hua et al. (2015)). Large medical image data sets within a hospital Picture Archiving and Communication System (PACS) combined with advanced high performance parallel computing promises the capacity to accelerate a machine learning technique to more accurately detect clinical imaging findings and diagnose specific diseases (Roth et al. (2015b), Roth et al.", "startOffset": 8, "endOffset": 354}, {"referenceID": 5, "context": "(2015), Hua et al. (2015)). Large medical image data sets within a hospital Picture Archiving and Communication System (PACS) combined with advanced high performance parallel computing promises the capacity to accelerate a machine learning technique to more accurately detect clinical imaging findings and diagnose specific diseases (Roth et al. (2015b), Roth et al. (2015a)).", "startOffset": 8, "endOffset": 375}, {"referenceID": 1, "context": "have been introduced and explored in different applications (Figueroa et al. (2012), Beleites et al.", "startOffset": 61, "endOffset": 84}, {"referenceID": 0, "context": "(2012), Beleites et al. (2013), Dobbin & Simon (2007), Dobbin et al.", "startOffset": 8, "endOffset": 31}, {"referenceID": 0, "context": "(2012), Beleites et al. (2013), Dobbin & Simon (2007), Dobbin et al.", "startOffset": 8, "endOffset": 54}, {"referenceID": 0, "context": "(2012), Beleites et al. (2013), Dobbin & Simon (2007), Dobbin et al. (2008)).", "startOffset": 8, "endOffset": 76}, {"referenceID": 0, "context": "(2012), Beleites et al. (2013), Dobbin & Simon (2007), Dobbin et al. (2008)). Upon thorough evaluation and consideration of these approaches, we chose the learning curve method due to its shown promise and robustness within other applications (Figueroa et al. (2012)).", "startOffset": 8, "endOffset": 267}, {"referenceID": 10, "context": "Over the years, many deep convolutional neural network algorithms have been proposed for natural image classification, such as GoogLeNet (Szegedy et al. (2014)), AlexNet (Krizhevsky et al.", "startOffset": 138, "endOffset": 160}, {"referenceID": 8, "context": "(2014)), AlexNet (Krizhevsky et al. (2012)), ClarifaiNet (Zeiler & Fergus (2014)), VGGNet (Simonyan & Zisserman (2014)) etc.", "startOffset": 18, "endOffset": 43}, {"referenceID": 8, "context": "(2014)), AlexNet (Krizhevsky et al. (2012)), ClarifaiNet (Zeiler & Fergus (2014)), VGGNet (Simonyan & Zisserman (2014)) etc.", "startOffset": 18, "endOffset": 81}, {"referenceID": 8, "context": "(2014)), AlexNet (Krizhevsky et al. (2012)), ClarifaiNet (Zeiler & Fergus (2014)), VGGNet (Simonyan & Zisserman (2014)) etc.", "startOffset": 18, "endOffset": 119}, {"referenceID": 8, "context": "(2014)), AlexNet (Krizhevsky et al. (2012)), ClarifaiNet (Zeiler & Fergus (2014)), VGGNet (Simonyan & Zisserman (2014)) etc. After extensive review of these algorithm, we chose to implement and use GoogLeNet for our specific application because it is computationally efficient and provides high quality classification based on the Hebbian principle and multi-scale processing as compared to other convolutional neural networks (CNN). The typical CNN framework consists of several convolutional and sub-sampling layers, followed by a fully connected traditional multiple layer perceptron. The GoogLeNet uses 22 convolutional layers including 9 Inception modules and 4 different size of basis or kernel filters (i.e., 7 \u00d7 7, 5 \u00d7 5, 3 \u00d7 3, and 1 \u00d7 1). CNN algorithms can learn the basis vectors of images and extract useful higher-level features through a hierarchical process. Accordingly, feature maps were extracted by convolution from the learned basis vectors of input medical CT images since each body part has different anatomical structures (Roth et al. (2015a)).", "startOffset": 18, "endOffset": 1067}, {"referenceID": 4, "context": "Generally, this curve model is represented as an inverse power law function (Figueroa et al. (2012)) The classification accuracy (y) is expressed as a function of the training set size (x) where given unknown parameter (b = b1, b2).", "startOffset": 77, "endOffset": 100}, {"referenceID": 4, "context": "b1 and b2 represent the learning rate and decay rate respectively (Figueroa et al. (2012)).", "startOffset": 67, "endOffset": 90}, {"referenceID": 4, "context": "b1 and b2 represent the learning rate and decay rate respectively (Figueroa et al. (2012)). The model fit assumes that the classification accuracy (y) grows asymptotically to 100%, or maximum achievable performance. Using the observed classification accuracy at six different sizes of training sets (5, 10, 20, 50, 100, and 200), unknown parameters (b = [b1, b2] ) were estimated using weighted nonlinear regression (Jang et al. (1997)).", "startOffset": 67, "endOffset": 436}, {"referenceID": 1, "context": "The weighted nonlinear least-squares estimator is more appropriate than a regular nonlinear regression method to fit the learning curve when measurement errors do not all have the same variance (Dennis Jr et al. (1981)).", "startOffset": 202, "endOffset": 219}, {"referenceID": 7, "context": "Using the Caffe (Jia et al. (2014)) and GoogLeNet network implemented on DIGITS DevBox, we conducted six different experiments using varying sizes of training data sets and recorded the resulting classification accuracy.", "startOffset": 17, "endOffset": 35}], "year": 2017, "abstractText": "The use of Convolutional Neural Networks (CNN) in natural image classification systems has produced very impressive results. Combined with the inherent nature of medical images that make them ideal for deep-learning, further application of such systems to medical image classification holds much promise. However, the usefulness and potential impact of such a system can be completely negated if it does not reach a target accuracy. In this paper, we present a study on determining the optimum size of the training data set necessary to achieve high classification accuracy with low variance in medical image classification systems. The CNN was applied to classify axial Computed Tomography (CT) images into six anatomical classes. We trained the CNN using six different sizes of training data set (5, 10, 20, 50, 100, and 200) and then tested the resulting system with a total of 6000 CT images. All images were acquired from the Massachusetts General Hospital (MGH) Picture Archiving and Communication System (PACS). Using this data, we employ the learning curve approach to predict classification accuracy at a given training sample size. Our research will present a general methodology for determining the training data set size necessary to achieve a certain target classification accuracy that can be easily applied to other problems within such systems.", "creator": "LaTeX with hyperref package"}}}