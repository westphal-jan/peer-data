{"id": "1511.06437", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "A convnet for non-maximum suppression", "abstract": "Non-maximum suppression (NMS) is used in virtually all state-of-the-art object detection pipelines. While essential object detection ingredients such as features, classifiers and proposal methods have been extensively researched it it surprising how little work has aimed to systematically address NMS. The de-facto standard for NMS is based on greedy clustering with a fixed distance threshold, which forces to trade-off recall versus precision. We propose a convnet designed to perform NMS of a given set of detections. We report experiments on a synthetic setup, and results on crowded pedestrian detection scenes. Our approach overcomes the intrinsic limitations of greedy NMS, obtaining better recall and precision.", "histories": [["v1", "Thu, 19 Nov 2015 22:56:18 GMT  (6182kb,D)", "https://arxiv.org/abs/1511.06437v1", null], ["v2", "Thu, 3 Dec 2015 08:16:33 GMT  (7671kb,D)", "http://arxiv.org/abs/1511.06437v2", "Added results on additional dataset"], ["v3", "Fri, 8 Jan 2016 00:00:21 GMT  (7672kb,D)", "http://arxiv.org/abs/1511.06437v3", "Included comments from reviewers"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["jan hosang", "rodrigo benenson", "bernt schiele"], "accepted": false, "id": "1511.06437"}, "pdf": {"name": "1511.06437.pdf", "metadata": {"source": "CRF", "title": "A CONVNET FOR NON-MAXIMUM SUPPRESSION", "authors": ["Jan Hosang", "Rodrigo Benenson"], "emails": ["schiele}@mpi-inf.mpg.de"], "sections": [{"heading": null, "text": "While essential elements of object recognition, such as features, classifiers and application methods, have been extensively researched, surprisingly little work has been done to systematically address NMS. The de facto standard for NMS is based on greedy clustering with a fixed distance threshold that forces a trade-off between recall and precision. We propose a convnet designed to perform NMS on a specific set of detections; we report on experiments with a synthetic setup and results in crowded pedestrian areas; our approach overcomes the intrinsic limitations of greedy NMS and achieves better memory and precision."}, {"heading": "1 INTRODUCTION", "text": "The fact is that we are able to assert ourselves, that we are able to change the world, and that we are able to change the world in order to change it. \""}, {"heading": "1.1 RELATED WORK", "text": "Although it is a core component of detection (2015), little attention has been paid to global solutions, which, however, do not provide optimal results, but rather focus on design, classification solutions and object solutions (2015). However, object detection and detection (2012) requires a detailed examination of the individual image processing steps (2012), which are still used in the manner in which the detection systems of the Kunst R-CNN detector family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015). Alternatives such as mean shift (Dalal & Triggs, 2005; Wojek et al., 2008), agglomerative clustering classes (Bourdev et al., 2010) and heuristic variants (Sermanet al., 2014) have been considered, but they have yet to show consistent gains."}, {"heading": "2 BASE TYROLEAN NETWORK", "text": "The main intuition behind our proposed Tyrolean network (Tnet) is that the score card of a detector together with a map representing the overlap between adjacent hypotheses contains valuable information to perform better NMS than GreedyNMS (also see Figure 1). Thus, our network is a traditional vampire network, but with access to two slightly unusual inputs (described below), namely scnet map information and IoU maps. Figure 2 shows the parameter range (number of layers, number of units per layer) is inspired by AlexNet (Krizhevsky et al., 2012) and VGG (Simonyan & Zisserman, 2015). In our base Tnet, the first level 512 \u00d7 11 filters apply over each input layer, and 512 \u00d7 1 filters are used on layers 2, 3 and 4. ReLU non-linearities are used after each layer."}, {"heading": "2.1 TRAINING PROCEDURE", "text": "In fact, most people who have been involved in politics and business in recent years have chosen a different policy than another, \"he told the Deutsche Presse-Agentur.\" I don't think I can assert myself in politics, \"he told the Deutsche Presse-Agentur.\" I don't think I can assert myself in politics, \"he told the Deutsche Presse-Agentur.\" I don't think I can assert myself in politics. \"He added:\" I don't think I can assert myself in politics. \""}, {"heading": "3 CONTROLLED SETUP EXPERIMENTS", "text": "NMS is usually the last stage of an entire detection pipeline. Therefore, in a first series of experiments, we want to understand the problem independently of a particular detector and abstract the particularities of a given data set."}, {"heading": "3.1 OMNIST DATASET", "text": "To investigate this core aspect, we create the oMNIST toy data sets (\"Overlapping MNIST\"). These data are not designed to be particularly realistic, but rather to provide a detailed analysis of the NMS problem. Each image consists of one or two MNIST digits. To highlight the occlusion cases, we consider 1 / 5 single digit numbers and 4 / 5 double digit cases. The digits are located outside the center and if two digits are present, they overlap with the boundary field IoU. [0,2, 0,6] In addition, we imitate a detector by creating synthetic score cards. Each digital truth-detection card generates a disturbing bump with random magnitude in the area."}, {"heading": "3.2 RESULTS", "text": "The results are summarized in Table 1 and Figure 5. We summarize the curves over AR; the average recall over the precision range [0.5, 1.0]. The evaluation is done using the standard Pascal VOC protocol, with IoU > 0.5 (Everingham et al., 2015).GreedyNMS As can easily be seen in Figure 5, which varies the IoU thresholds for GreedyNMS, can be seen in Figure 4.Upper bound As the upper limit for any method based on score map information, we can calculate the overlap between adjacent hypotheses based on perfect segmentation masks in this toy scenario."}, {"heading": "4 PERSON DETECTION EXPERIMENTS", "text": "We are particularly interested in data sets that show different levels of occlusion (and therefore NMS is not trivial).We chose the PETS dataset, which has different levels of occlusion statistics and provides an appropriate volume of training and test data. In addition, we test the generalization of the trained model on the ParkingLot dataset.PETS We use 8 of the PETS sequences (Ferryman & Ellis, 2010), which we divide into 5 for training (S1L1-1, S1L2-2, S3L2-2).We use 8 of the PETS sequences (Ferryman & Ellis, 2010), 200 frames, which we divide into 5 for training (S2L2).The different videos show different densities of crowds."}, {"heading": "4.1 PETS RESULTS", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "5 CONCLUSION", "text": "For reasons of speed and simplicity, GreedyNMS ignores most of the available information in the detector response. Our proposed Tyrolean Network (Tnet) mines the patterns in the score card values and Bounding Box arrangements to exceed the performance of GreedyNMS. In terms of the detector task, our final results show that our approach provides both high memory and improved accuracy over any GreedyNMS threshold. These results confirm that Tnet overcomes the intrinsic limitations of GreedyNMS while maintaining practical test time speeds. Although the proposed architecture produces good results for the covered scenario, there is certainly room for further exploration of the parameter space of convector networks for NMS and exploration of other application areas (e.g. NMS for limit estimation or other detection datasets)."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We thank Siyu Tang and Anton Milan for providing the pre-trained DPM model and additional PETS ground truth notes."}, {"heading": "A DEEPMASK RESULTS ON PETS", "text": "To obtain segmentation masks on PETS, we train our reimplementation of DeepMask (Pinheiro et al., 2015) for all classes of the COCO training set. Our implementation is based on the FastRCNN network Girshick (2015). To generate instance segmentation on PETS, we enlarge the image by a factor of 2 and predict segments on detections. Figure 13 shows mask predictions for annotations on the PETS test set. It works well in cases of low occlusion (left and middle column), but under heavy occlusion, it makes errors by breaking the segment or merging the occluding and occluding person (see far right)."}], "references": [{"title": "On detection of multiple object instances using hough transforms", "author": ["Barinova", "Olga", "Lempitsky", "Victor", "Kholi", "Pushmeet"], "venue": null, "citeRegEx": "Barinova et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Barinova et al\\.", "year": 2012}, {"title": "Detecting people using mutually consistent poselet activations", "author": ["Bourdev", "Lubomir", "Maji", "Subhransu", "Brox", "Thomas", "Malik", "Jitendra"], "venue": "In ECCV,", "citeRegEx": "Bourdev et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bourdev et al\\.", "year": 2010}, {"title": "Detection evolution with multi-order contextual co-occurrence", "author": ["Chen", "Guang", "Ding", "Yuanyuan", "Xiao", "Jing", "Han", "Tony X"], "venue": "In CVPR,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Convolutional feature masking for joint object and stuff segmentation", "author": ["Dai", "Jifeng", "He", "Kaiming", "Sun", "Jian"], "venue": "In CVPR,", "citeRegEx": "Dai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2015}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "In CVPR,", "citeRegEx": "Dalal and Triggs,? \\Q2005\\E", "shortCiteRegEx": "Dalal and Triggs", "year": 2005}, {"title": "Discriminative models for multi-class object layout", "author": ["C. Desai", "D. Ramanan", "C. Fowlkes"], "venue": null, "citeRegEx": "Desai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Desai et al\\.", "year": 2011}, {"title": "Pedestrian detection: An evaluation of the state of the art", "author": ["Doll\u00e1r", "Piotr", "Wojek", "Christian", "Schiele", "Bernt", "Perona", "Pietro"], "venue": null, "citeRegEx": "Doll\u00e1r et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Doll\u00e1r et al\\.", "year": 2012}, {"title": "The pascal visual object classes challenge: A retrospective", "author": ["M. Everingham", "S.M.A. Eslami", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": null, "citeRegEx": "Everingham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2015}, {"title": "Object detection with discriminatively trained part-based models", "author": ["P. Felzenszwalb", "R. Girshick", "D. McAllester", "D. Ramanan"], "venue": null, "citeRegEx": "Felzenszwalb et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2010}, {"title": "Pets2010: Dataset and challenge", "author": ["J Ferryman", "Ellis", "Anna"], "venue": "In AVSS,", "citeRegEx": "Ferryman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferryman et al\\.", "year": 2010}, {"title": "Are we ready for autonomous driving? the kitti vision benchmark suite", "author": ["Geiger", "Andreas", "Lenz", "Philip", "Urtasun", "Raquel"], "venue": "In CVPR,", "citeRegEx": "Geiger et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Geiger et al\\.", "year": 2012}, {"title": "Fast R-CNN", "author": ["R. Girshick"], "venue": "In ICCV,", "citeRegEx": "Girshick,? \\Q2015\\E", "shortCiteRegEx": "Girshick", "year": 2015}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "In CVPR,", "citeRegEx": "Girshick et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2014}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In ICCV,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "What makes for effective detection proposals", "author": ["Hosang", "Jan", "Benenson", "Rodrigo", "Doll\u00e1r", "Piotr", "Schiele", "Bernt"], "venue": null, "citeRegEx": "Hosang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hosang et al\\.", "year": 2015}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia", "Yangqing", "Shelhamer", "Evan", "Donahue", "Jeff", "Karayev", "Sergey", "Long", "Jonathan", "Girshick", "Ross", "Guadarrama", "Sergio", "Darrell", "Trevor"], "venue": null, "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "In ICLR,", "citeRegEx": "Kingma and Ba,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2015}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Robust object detection with interleaved categorization and segmentation", "author": ["Leibe", "Bastian", "Leonardis", "Ale\u0161", "Schiele", "Bernt"], "venue": null, "citeRegEx": "Leibe et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Leibe et al\\.", "year": 2008}, {"title": "Microsoft coco: Common objects in context", "author": ["Lin", "Tsung-Yi", "Maire", "Michael", "Belongie", "Serge", "Hays", "James", "Perona", "Pietro", "Ramanan", "Deva", "Doll\u00e1r", "Piotr", "Zitnick", "C Lawrence"], "venue": "In ECCV,", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Face detection without bells and whistles", "author": ["M. Mathias", "R. Benenson", "M. Pedersoli", "L. Van Gool"], "venue": "In ECCV,", "citeRegEx": "Mathias et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mathias et al\\.", "year": 2014}, {"title": "Continuous energy minimization for multitarget tracking", "author": ["A. Milan", "S. Roth", "K. Schindler"], "venue": null, "citeRegEx": "Milan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Milan et al\\.", "year": 2014}, {"title": "Efficient non-maximum suppression", "author": ["Neubeck", "Alexander", "Van Gool", "Luc"], "venue": "In ICPR,", "citeRegEx": "Neubeck et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Neubeck et al\\.", "year": 2006}, {"title": "Single-pedestrian detection aided by multi-pedestrian detection", "author": ["W. Ouyang", "X. Wang"], "venue": "In CVPR,", "citeRegEx": "Ouyang and Wang,? \\Q2013\\E", "shortCiteRegEx": "Ouyang and Wang", "year": 2013}, {"title": "Human-debugging of machines", "author": ["Parikh", "Devi", "C. Zitnick"], "venue": "In NIPS WCSSWC,", "citeRegEx": "Parikh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Parikh et al\\.", "year": 2011}, {"title": "Multi-view and 3d deformable part models", "author": ["Pepik", "Bojan", "Stark", "Michael", "Gehler", "Peter", "Schiele", "Bernt"], "venue": null, "citeRegEx": "Pepik et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pepik et al\\.", "year": 2015}, {"title": "Learning to segment object candidates", "author": ["Pinheiro", "Pedro O", "Collobert", "Ronan", "Dollar", "Piotr"], "venue": "In NIPS,", "citeRegEx": "Pinheiro et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pinheiro et al\\.", "year": 2015}, {"title": "Faster R-CNN: Towards real-time object detection with region proposal networks", "author": ["S. Ren", "K. He", "R. Girshick", "J. Sun"], "venue": "In NIPS,", "citeRegEx": "Ren et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ren et al\\.", "year": 2015}, {"title": "Density-aware person detection and tracking in crowds", "author": ["Rodriguez", "Mikel", "Laptev", "Ivan", "Sivic", "Josef", "Audibert", "Jean-Yves"], "venue": "In ICCV,", "citeRegEx": "Rodriguez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rodriguez et al\\.", "year": 2011}, {"title": "Non-maximum suppression for object detection by passing messages between windows", "author": ["Rothe", "Rasmus", "Guillaumin", "Matthieu", "Van Gool", "Luc"], "venue": "In ACCV,", "citeRegEx": "Rothe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rothe et al\\.", "year": 2015}, {"title": "Recognition using visual phrases", "author": ["M.A. Sadeghi", "A. Farhadi"], "venue": "In CVPR,", "citeRegEx": "Sadeghi and Farhadi,? \\Q2011\\E", "shortCiteRegEx": "Sadeghi and Farhadi", "year": 2011}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Sermanet", "Pierre", "Eigen", "David", "Zhang", "Xiang", "Mathieu", "Michael", "Fergus", "Rob", "LeCun", "Yann"], "venue": "In ICLR,", "citeRegEx": "Sermanet et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sermanet et al\\.", "year": 2014}, {"title": "Part-based multiple-person tracking with partial occlusion handling", "author": ["Shu", "Guang", "Dehghan", "Afshin", "Oreifej", "Omar", "Hand", "Emily", "Shah", "Mubarak"], "venue": "In CVPR,", "citeRegEx": "Shu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shu et al\\.", "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "In ICLR,", "citeRegEx": "Simonyan and Zisserman,? \\Q2015\\E", "shortCiteRegEx": "Simonyan and Zisserman", "year": 2015}, {"title": "End-to-end people detection in crowded scenes", "author": ["Stewart", "Russell", "Andriluka", "Mykhaylo"], "venue": null, "citeRegEx": "Stewart et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Stewart et al\\.", "year": 2015}, {"title": "Counting people in the crowd using a generic head detector", "author": ["Subburaman", "Venkatesh Bala", "Descamps", "Adrien", "Carincotte", "Cyril"], "venue": "In AVSS,", "citeRegEx": "Subburaman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Subburaman et al\\.", "year": 2012}, {"title": "Detection and tracking of occluded people", "author": ["S. Tang", "M. Andriluka", "B. Schiele"], "venue": "In BMVC,", "citeRegEx": "Tang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2012}, {"title": "Learning people detectors for tracking in crowded scenes", "author": ["Tang", "Siyu", "Andriluka", "Mykhaylo", "Milan", "Anton", "Schindler", "Kaspar", "Roth", "Stefan", "Schiele", "Bernt"], "venue": "In ICCV,", "citeRegEx": "Tang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2013}, {"title": "Subgraph decomposition for multi-target tracking", "author": ["Tang", "Siyu", "Andres", "Bjoern", "Andriluka", "Mykhaylo", "Schiele", "Bernt"], "venue": "In CVPR,", "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "Auto-context and its application to high-level vision tasks and 3d brain image segmentation", "author": ["Tu", "Zhuowen", "Bai", "Xiang"], "venue": null, "citeRegEx": "Tu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tu et al\\.", "year": 2010}, {"title": "Object localization in imagenet by looking out of the window", "author": ["Vezhnevets", "Alexander", "Ferrari", "Vittorio"], "venue": "In BMVC,", "citeRegEx": "Vezhnevets et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vezhnevets et al\\.", "year": 2015}, {"title": "Robust real-time face detection", "author": ["P. Viola", "M. Jones"], "venue": "In IJCV,", "citeRegEx": "Viola and Jones,? \\Q2004\\E", "shortCiteRegEx": "Viola and Jones", "year": 2004}, {"title": "End-to-end integration of a convolutional network, deformable parts model and non-maximum suppression", "author": ["Wan", "Li", "Eigen", "David", "Fergus", "Rob"], "venue": "In CVPR,", "citeRegEx": "Wan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2015}, {"title": "Detecting partially occluded objects with an implicit shape model random field", "author": ["Wohlhart", "Paul", "Donoser", "Michael", "Roth", "Peter M", "Bischof", "Horst"], "venue": "In ACCV,", "citeRegEx": "Wohlhart et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wohlhart et al\\.", "year": 2012}, {"title": "Sliding-windows for rapid object class localization: A parallel technique", "author": ["Wojek", "Christian", "Dork\u00f3", "Gyuri", "Schulz", "Andr\u00e9", "Schiele", "Bernt"], "venue": "In DAGM,", "citeRegEx": "Wojek et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wojek et al\\.", "year": 2008}, {"title": "Object detection by labeling superpixels", "author": ["Yan", "Junjie", "Yu", "Yinan", "Zhu", "Xiangyu", "Lei", "Zhen", "Li", "Stan Z"], "venue": "In CVPR,", "citeRegEx": "Yan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yan et al\\.", "year": 2015}, {"title": "Describing the scene as a whole: Joint object detection, scene classification and semantic segmentation", "author": ["J. Yao", "S. Fidler", "R. Urtasun"], "venue": "In CVPR,", "citeRegEx": "Yao et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2012}, {"title": "To generate instance segmentations on PETS, we upscale the image by a factor of 2\u00d7 and predict segments on detections", "author": ["RCNN network Girshick"], "venue": "Figure 13 shows mask predictions for annotations on the PETS test set. It works well in low occlusion cases (left and middle column), however, under heavy occlusion it makes mistakes by collapsing the segment or merging the occluding and the occluded person (see right-most column).", "citeRegEx": "Girshick,? 2015", "shortCiteRegEx": "Girshick", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "The popular DPM (Felzenszwalb et al., 2010) and R-CNN family (Girshick et al.", "startOffset": 16, "endOffset": 43}, {"referenceID": 12, "context": ", 2010) and R-CNN family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015) follow this approach.", "startOffset": 25, "endOffset": 82}, {"referenceID": 11, "context": ", 2010) and R-CNN family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015) follow this approach.", "startOffset": 25, "endOffset": 82}, {"referenceID": 27, "context": ", 2010) and R-CNN family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015) follow this approach.", "startOffset": 25, "endOffset": 82}, {"referenceID": 14, "context": "Both object proposals (Hosang et al., 2015) and detection classifiers (Russakovsky et al.", "startOffset": 22, "endOffset": 43}, {"referenceID": 8, "context": "Clustering detections The decade old greedy NMS (GreedyNMS) is used in popular detectors such as V&J (Viola & Jones, 2004), DPM (Felzenszwalb et al., 2010), and is still used in the state-ofthe-art R-CNN detector family (Girshick et al.", "startOffset": 128, "endOffset": 155}, {"referenceID": 12, "context": ", 2010), and is still used in the state-ofthe-art R-CNN detector family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015).", "startOffset": 72, "endOffset": 129}, {"referenceID": 11, "context": ", 2010), and is still used in the state-ofthe-art R-CNN detector family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015).", "startOffset": 72, "endOffset": 129}, {"referenceID": 27, "context": ", 2010), and is still used in the state-ofthe-art R-CNN detector family (Girshick et al., 2014; Girshick, 2015; Ren et al., 2015).", "startOffset": 72, "endOffset": 129}, {"referenceID": 44, "context": "Alternatives such as mean-shift clustering (Dalal & Triggs, 2005; Wojek et al., 2008), agglomerative clustering (Bourdev et al.", "startOffset": 43, "endOffset": 85}, {"referenceID": 1, "context": ", 2008), agglomerative clustering (Bourdev et al., 2010), and heuristic variants (Sermanet et al.", "startOffset": 34, "endOffset": 56}, {"referenceID": 31, "context": ", 2010), and heuristic variants (Sermanet et al., 2014) have been considered, but they have yet to show consistent gains.", "startOffset": 32, "endOffset": 55}, {"referenceID": 1, "context": ", 2008), agglomerative clustering (Bourdev et al., 2010), and heuristic variants (Sermanet et al., 2014) have been considered, but they have yet to show consistent gains. Recently Tang et al. (2015); Rothe et al.", "startOffset": 35, "endOffset": 199}, {"referenceID": 1, "context": ", 2008), agglomerative clustering (Bourdev et al., 2010), and heuristic variants (Sermanet et al., 2014) have been considered, but they have yet to show consistent gains. Recently Tang et al. (2015); Rothe et al. (2015) proposed principled clustering approaches that provide globally optimal solutions, however the results reached are on par, but do not surpass, GreedyNMS.", "startOffset": 35, "endOffset": 220}, {"referenceID": 18, "context": "Linking detections to pixels The Hough voting framework enables more sophisticated reasoning amongst conflicting detections by linking the detections to local image evidence (Leibe et al., 2008; Barinova et al., 2012; Wohlhart et al., 2012).", "startOffset": 174, "endOffset": 240}, {"referenceID": 0, "context": "Linking detections to pixels The Hough voting framework enables more sophisticated reasoning amongst conflicting detections by linking the detections to local image evidence (Leibe et al., 2008; Barinova et al., 2012; Wohlhart et al., 2012).", "startOffset": 174, "endOffset": 240}, {"referenceID": 43, "context": "Linking detections to pixels The Hough voting framework enables more sophisticated reasoning amongst conflicting detections by linking the detections to local image evidence (Leibe et al., 2008; Barinova et al., 2012; Wohlhart et al., 2012).", "startOffset": 174, "endOffset": 240}, {"referenceID": 0, "context": ", 2008; Barinova et al., 2012; Wohlhart et al., 2012). Hough voting itself, however, provides low detection accuracy. Yao et al. (2012) and Dai et al.", "startOffset": 8, "endOffset": 136}, {"referenceID": 0, "context": ", 2008; Barinova et al., 2012; Wohlhart et al., 2012). Hough voting itself, however, provides low detection accuracy. Yao et al. (2012) and Dai et al. (2015) refine detections by linking them with semantic labelling; while Yan et al.", "startOffset": 8, "endOffset": 158}, {"referenceID": 0, "context": ", 2008; Barinova et al., 2012; Wohlhart et al., 2012). Hough voting itself, however, provides low detection accuracy. Yao et al. (2012) and Dai et al. (2015) refine detections by linking them with semantic labelling; while Yan et al. (2015) side-steps NMS all-together by defining the detection task directly as a labelling problem.", "startOffset": 8, "endOffset": 241}, {"referenceID": 36, "context": "Co-occurrence To better handle dense crowds or common object pairs, it has been proposed to use specialized 2-object detectors (Sadeghi & Farhadi, 2011; Tang et al., 2012; Ouyang & Wang, 2013), which then require a more careful NMS strategy to merge single-object with double-object detections.", "startOffset": 127, "endOffset": 192}, {"referenceID": 27, "context": "Similarly Rodriguez et al. (2011) proposed to adapt the NMS threshold using crowd density estimation.", "startOffset": 10, "endOffset": 34}, {"referenceID": 5, "context": "Desai et al. (2011) considered improving the NMS procedure by considering the spatial arrangement between detections of different classes.", "startOffset": 0, "endOffset": 20}, {"referenceID": 2, "context": "Auto-context uses the local (Tu & Bai, 2010; Chen et al., 2013) or global information (Vezhnevets & Ferrari, 2015) on the image to re-score detections.", "startOffset": 28, "endOffset": 63}, {"referenceID": 8, "context": "We report experiment applied over DPM (Felzenszwalb et al., 2010) detections.", "startOffset": 38, "endOffset": 65}, {"referenceID": 41, "context": "Detection convnets are commonly trained unaware of the NMS post-processing step; Wan et al. (2015) connected NMS with the loss to train the detection convnet, making the training truly end-to-end.", "startOffset": 81, "endOffset": 99}, {"referenceID": 41, "context": "Detection convnets are commonly trained unaware of the NMS post-processing step; Wan et al. (2015) connected NMS with the loss to train the detection convnet, making the training truly end-to-end. The used NMS is greedy and with fixed parameters. Stewart & Andriluka (2015) propose to use an LSTM to decide how many detections should be considered in a local region.", "startOffset": 81, "endOffset": 274}, {"referenceID": 41, "context": "Detection convnets are commonly trained unaware of the NMS post-processing step; Wan et al. (2015) connected NMS with the loss to train the detection convnet, making the training truly end-to-end. The used NMS is greedy and with fixed parameters. Stewart & Andriluka (2015) propose to use an LSTM to decide how many detections should be considered in a local region. The detections amongst the regions are then merged via traditional NMS. In contrast our convnet runs in a fully convolutional mode and requires no post-processing. Both Wan et al. (2015) and Stewart & Andriluka (2015) served as inspiration for the design of our training loss.", "startOffset": 81, "endOffset": 554}, {"referenceID": 41, "context": "Detection convnets are commonly trained unaware of the NMS post-processing step; Wan et al. (2015) connected NMS with the loss to train the detection convnet, making the training truly end-to-end. The used NMS is greedy and with fixed parameters. Stewart & Andriluka (2015) propose to use an LSTM to decide how many detections should be considered in a local region. The detections amongst the regions are then merged via traditional NMS. In contrast our convnet runs in a fully convolutional mode and requires no post-processing. Both Wan et al. (2015) and Stewart & Andriluka (2015) served as inspiration for the design of our training loss.", "startOffset": 81, "endOffset": 585}, {"referenceID": 17, "context": "The parameter range (number of layers, number of units per layer) is inspired by AlexNet (Krizhevsky et al., 2012) and VGG (Simonyan & Zisserman, 2015).", "startOffset": 89, "endOffset": 114}, {"referenceID": 26, "context": "The IoU layer values can be computed over bounding boxes (regressed by the sliding window detector), or over estimated instance segments (Pinheiro et al., 2015).", "startOffset": 137, "endOffset": 160}, {"referenceID": 8, "context": "The DPM (Felzenszwalb et al., 2010; Pepik et al., 2015) includes structured output learning to ensure the detection score falls off linearly with the overlap between detector window and annotation.", "startOffset": 8, "endOffset": 55}, {"referenceID": 25, "context": "The DPM (Felzenszwalb et al., 2010; Pepik et al., 2015) includes structured output learning to ensure the detection score falls off linearly with the overlap between detector window and annotation.", "startOffset": 8, "endOffset": 55}, {"referenceID": 8, "context": "The DPM (Felzenszwalb et al., 2010; Pepik et al., 2015) includes structured output learning to ensure the detection score falls off linearly with the overlap between detector window and annotation. Wan et al. (2015) explicitly include a fixed NMS procedure into the network loss during training so the detector is tuned towards the NMS at test time.", "startOffset": 9, "endOffset": 216}, {"referenceID": 8, "context": "The DPM (Felzenszwalb et al., 2010; Pepik et al., 2015) includes structured output learning to ensure the detection score falls off linearly with the overlap between detector window and annotation. Wan et al. (2015) explicitly include a fixed NMS procedure into the network loss during training so the detector is tuned towards the NMS at test time. We adopt from Stewart & Andriluka (2015) the idea of computing the loss by matching detections to annotations, but instead of regressing bounding", "startOffset": 9, "endOffset": 391}, {"referenceID": 13, "context": "Training parameters The model is trained from scratch, randomly initialized with MSRA (He et al., 2015), and optimized with Adam (Kingma & Ba, 2015).", "startOffset": 86, "endOffset": 103}, {"referenceID": 15, "context": "All experiments are implemented with the Caffe framework (Jia et al., 2014).", "startOffset": 57, "endOffset": 75}, {"referenceID": 38, "context": "Other NMS approaches such as (Tang et al., 2015; Rothe et al., 2015) also require training data to be adjusted.", "startOffset": 29, "endOffset": 68}, {"referenceID": 29, "context": "Other NMS approaches such as (Tang et al., 2015; Rothe et al., 2015) also require training data to be adjusted.", "startOffset": 29, "endOffset": 68}, {"referenceID": 13, "context": "Training parameters The model is trained from scratch, randomly initialized with MSRA (He et al., 2015), and optimized with Adam (Kingma & Ba, 2015). We use a learning rate of 10\u22124, a weight decay of 5 \u00b7 10\u22125, a momentum of 0.9, and gradient clipping at 1 000. The model is trained for 100 000 iterations with one image per iteration. All experiments are implemented with the Caffe framework (Jia et al., 2014). As pointed out in Mathias et al. (2014) the threshold for GreedyNMS requires to be carefully selected on the validation set of each task, the commonly used default IoU > 0.", "startOffset": 87, "endOffset": 452}, {"referenceID": 7, "context": "5 (Everingham et al., 2015).", "startOffset": 2, "endOffset": 27}, {"referenceID": 37, "context": "PETS has been previously used to study person detection (Tang et al., 2013), tracking (Milan et al.", "startOffset": 56, "endOffset": 75}, {"referenceID": 21, "context": ", 2013), tracking (Milan et al., 2014), and crowd density estimation (Subburaman et al.", "startOffset": 18, "endOffset": 38}, {"referenceID": 35, "context": ", 2014), and crowd density estimation (Subburaman et al., 2012).", "startOffset": 38, "endOffset": 63}, {"referenceID": 6, "context": "Standard pedestrian datasets such as Caltech (Doll\u00e1r et al., 2012) or KITTI Geiger et al.", "startOffset": 45, "endOffset": 66}, {"referenceID": 6, "context": "Standard pedestrian datasets such as Caltech (Doll\u00e1r et al., 2012) or KITTI Geiger et al. (2012) average less than two pedestrian per frame, making close-by detections a rare occurrence.", "startOffset": 46, "endOffset": 97}, {"referenceID": 32, "context": "ParkingLot We use the first ParkingLot (Shu et al., 2012) sequence to evaluate the generalization capabilities of the model.", "startOffset": 39, "endOffset": 57}, {"referenceID": 37, "context": "For our experiments we use the baseline DPM detector from (Tang et al., 2013).", "startOffset": 58, "endOffset": 77}, {"referenceID": 6, "context": "We are not aware of a detector (convnet or not) providing better results on PETSlike sequences (we considered some of the top detectors in (Doll\u00e1r et al., 2012)).", "startOffset": 139, "endOffset": 160}, {"referenceID": 26, "context": "We use our re-implementation of DeepMask (Pinheiro et al., 2015), trained on the Coco dataset (Lin et al.", "startOffset": 41, "endOffset": 64}, {"referenceID": 19, "context": ", 2015), trained on the Coco dataset (Lin et al., 2014).", "startOffset": 37, "endOffset": 55}], "year": 2016, "abstractText": "Non-maximum suppression (NMS) is used in virtually all state-of-the-art object detection pipelines. While essential object detection ingredients such as features, classifiers, and proposal methods have been extensively researched surprisingly little work has aimed to systematically address NMS. The de-facto standard for NMS is based on greedy clustering with a fixed distance threshold, which forces to trade-off recall versus precision. We propose a convnet designed to perform NMS of a given set of detections. We report experiments on a synthetic setup, and results on crowded pedestrian detection scenes. Our approach overcomes the intrinsic limitations of greedy NMS, obtaining better recall and precision.", "creator": "LaTeX with hyperref package"}}}