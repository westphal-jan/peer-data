{"id": "1511.06440", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Towards Principled Unsupervised Learning", "abstract": "General unsupervised learning is a long-standing conceptual problem in machine learning. Supervised learning is successful because it can be solved by the minimization of the training error cost function. Unsupervised learning is not as successful, because the unsupervised objective may be unrelated to the supervised task of interest. For an example, density modelling and reconstruction have often been used for unsupervised learning, but they did not produced the sought-after performance gains, because they have no knowledge of the sought-after supervised tasks.", "histories": [["v1", "Thu, 19 Nov 2015 23:04:23 GMT  (487kb,D)", "http://arxiv.org/abs/1511.06440v1", null], ["v2", "Thu, 3 Dec 2015 17:24:22 GMT  (489kb,D)", "http://arxiv.org/abs/1511.06440v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ilya sutskever", "rafal jozefowicz", "karol gregor", "danilo rezende", "tim lillicrap", "oriol vinyals"], "accepted": false, "id": "1511.06440"}, "pdf": {"name": "1511.06440.pdf", "metadata": {"source": "CRF", "title": "TOWARDS PRINCIPLED UNSUPERVISED LEARNING", "authors": ["Ilya Sutskever", "Rafal Jozefowicz", "Karol Gregor", "Danilo Rezende", "Tim Lillicrap", "Oriol Vinyals"], "emails": ["ilyasu@google.com", "rafalj@google.com", "karolg@google.com", "danilor@google.com", "countzero@google.com", "vinyals@google.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "It is not only the way in which it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question, to what extent it is concerned with the question,"}, {"heading": "2 RELATED WORK", "text": "There are a number of publications that considered matching statistics as an unattended learning signal. Casey's early work (1986) raises the problem of unattended OCR as a problem of decrypting a cipher where there is an unknown correlation of images to character identities that must be deduced from the known statistics of language, an idea that has been further explored in the context of machine translation (typically in the form of matching bigrams) (Knight et al., 2006; Huang et al., 2006; Snyder et al., 2010; Ravi & Knight, 2008) and in unattended lexicon induction (Fung & McKeown, 1997; Koehn & Knight, 2002; Haghighi et al., 2008; Mikolov et al., 2013b), in particular Knight et al. (2006) describes the link between unattended learning and language decoding."}, {"heading": "3 METHODS", "text": "In this section, we present various approaches to optimizing ODM costs."}, {"heading": "3.1 ODM COSTS AS GENERATIVE MODELS", "text": "The ODM costs can be formulated as the following generative model. Let P (x) be a model adapted to the marginal costs (x-x), and let PTB (y) be the distribution: PTB (y) = \u2211 x PTB (y-x) P (x) (4) The goal is to find a conditional PTB (y-x) (which FTB (x) corresponds to where the parameters are), so that PTB (y) corresponds to the marginal distribution y-x. If P (x) is an excellent model of x-x-D, then the costs Ey-D [\u2212 logPTB (y)] are exactly equivalent to the ODM costs of equation. 3, modulo is an additive constant. A similar generative model was presented by Knight et al. (2006). It is desirable to train generative models using the variable model D [\u2212 logPTB (y)."}, {"heading": "3.2 THE DUAL AUTOENCODER", "text": "We implemented the xyh generative model, but had difficulty getting reasonable results in our early experiments. We were able to achieve better results by designing a novel autoencoder model inspired by the xyh model, which we call the dual autoencoder, which is shown in Figure 2. It consists of two autoencoders whose \"innermost weights\" are shared with each other. Formally, the dual autoencoder has the format x \u2032 = f (WNf (WNf \u2212 1. f (W1f (B0x).)))) (8) (8) y \u2032 = f (A1f (WNf (WN \u2212 1.. f (W1y)))) (9), where f is the nonlinearity and the cost isL = Ex \u0445 D [L1, x \u2032) + Ey \u0445 D [L2 (y, y \u2032)]] (10), where the autoqs 1 and L2 are respectively on the Watible and W9 cards."}, {"heading": "3.3 GENERATIVE ADVERSARIAL NETWORKS TRAINING", "text": "The Generative Adversarial Network (Goodfellow et al., 2014) is a method of training a \"generator\" to generate samples that are statistically indistinguishable from a desired distribution; the generator is a neural network G that turns a source of noise z into samples from a specific distribution: z \u2192 G (z) (11) The GAN training algorithm maintains an adversary D (z) \u2192 [0, 1] whose goal is to distinguish between samples x from the data distribution and samples from the generator G (z), and the generator G learns to deceive the discriminator. Finally, if the GAN training is successful, G converts to a model so that the distribution of G (z) is indistinguishable from the target distribution. The Generative Adversarial Network provides a direct way to train generative models, and it has had considerable success in learning models of natural images (Denton et al., 2015). We use the GAN training method to differentiate our overarching adversarial samples [from]."}, {"heading": "4 EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 DUAL AUTOENCODERS ON MNIST PERMUTATION TASK", "text": "We start by researching the ODM costs by selecting a simple artificial task in which the distributions overX and Y have a rich internal structure, but whose relationship is simple. We chose Y as the distribution of the MNIST digits and X as the distribution of the MNIST digits, whose pixels are permutated (with the same permutation on all digits). See Figure 2. We call it the MNIST permutation task. The purpose of the task is to learn the unknown permutation using unmonitored data. We used a dual autoencoder, whose architecture is 784-100-100-784, in which the weights in the 100-100-100 subnetwork were divided between the two autoencoders. While the results were insensitive to the learning rate, it was important to use a random initialization, which is significantly smaller than those typically found for the training of neural network models, the results were obtained in an automated manner (i.e., without the G00sian, which is an automatic number 3, without the G00sian number of 0.00)."}, {"heading": "4.1.1 DUAL AUTOENCODER FOR CIPHERS", "text": "In this task, we get two text corpora that follow the same distribution, but where the characters (or words) of a corpora are encrypted. In detail, we convert a text file into a list of integers by randomly assigning characters (or words) integers and consistently using this mapping throughout the file. Despite its simplicity, this task offers us another way to evaluate our models. We used the dual autoencoder architecture as before, where the input (and desired output) is merged with a bag of 10 consecutive letters from a random set of text architecture."}, {"heading": "4.2 GENERATIVE ADVERSARIAL NETWORKS FOR MNIST CLASSIFICATION", "text": "Next, we evaluated the GAN-based model on an artificial OCR task constructed from the MNIST dataset (1). In this task, we used the text from The Origin of Species, which was downloaded from Project Gutenberg, and arbitrarily replaced each letter with a digit between 0 and 9 in a consistent manner. We call this sequence the MNIST label file. The goal of this problem was to replace each label with a random image of an MNIST number of the same class, giving us a very long sequence of images of the MNIST digits, which we call the MNIST image sequence. The goal of this problem was to assign an MLP that assigned its digits digits to 10-dimensional vectors without using any input-output examples. Formally, we trained an MLP-F to represent each MNIST digit in a 10-dimensional Vector classification."}, {"heading": "5 ONE-SHOT LEARNING AND DOMAIN ADAPTATION", "text": "If the function we want to learn, F, has a small number of parameters, then it should be possible to infer F from a very small number of examples - and in some cases from a single example.The ability to derive F from a single sample has a positive effect on domain matching: provided that the training distribution comes from domain D and that the test distribution comes from domain D. If we are able to immediately match a sample from x-D \u00b2 to an \"appropriate\" sample from D \u00b2, we will be able to classify samples from D \u00b2 without additional training: first the sample from D, then we will use a classifier that is able to correctly classify samples from D \u00b2. Such a domain fitting is attractive because it allows us to apply our functionF to inputs whose statistics differ significantly from the data distribution D \u00b2, and its unique snapshot means that the classifier from D \u00b2 can correctly respond to these inputs by correctly following the statistical inputs of ISx, the statistical inputs we expect to use Eq."}, {"heading": "6 DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 WHEN IS SUPERVISION NEEDED?", "text": "When does the ODM fully determine the best F? If the function class is too capable, then F can map any distribution via the inputs to any distribution via the outputs, making it impossible for the ODM costs to recover F. However, since the ODM costs are consistent, it is likely to improve generalization by excluding inappropriate functions from consideration. If the output range Y is small, the ODM costs will not provide enough information to be of significant help to the monitored costs. However, there is a setting in which the ODM cost function could in principle fully determine the best monitored function F. It should always be successful if the input distribution and output distribution contain extensive dependencies, while the function class F is selected from such a class that it is unable to change the dependencies of the distribution by time localization: a localized change in the input causes a localized change in the output.This setting is illustrated in Figure 6."}, {"heading": "6.2 LIMITATIONS", "text": "ODM-based training has a number of limitations. The output space must be large, and the \"common hidden structure\" of the two spaces must be sufficiently similar. The simple models used in this essay are unlikely to successfully learn correspondence between two spaces whose hidden hidden structures are not very similar. It is conceivable that if we manage to train more expressive generative models, they will be able to notice the natural correspondences between hidden structures that are not identical. The greater limitation of the model is caused by the lack of an extremely good method of adapting generative models. As these algorithms get better over time, it will be possible to optimize ODM costs in a wider variety of settings and in a more robust manner."}, {"heading": "7 CONCLUSIONS", "text": "In this paper, we demonstrated that ODM costs provide a generic approach to unsupervised learning that is fully consistent with the supervised cost function. Although we have not been able to develop a reliable method that, for example, can train an attention model Bahdanau et al. (2014) with the ODM goal, we have presented evidence that the ODM goal provides a meaningful type of training function without the use of input-output examples. We expect better techniques to optimize ODM costs to make them universally applicable and useful."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Greedy layer-wise training of deep networks", "author": ["Bengio", "Yoshua", "Lamblin", "Pascal", "Popovici", "Dan", "Larochelle", "Hugo"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "Text OCR by solving a cryptogram", "author": ["Casey", "Richard G"], "venue": "International Business Machines Incorporated, Thomas J. Watson Research Center,", "citeRegEx": "Casey and G.,? \\Q1986\\E", "shortCiteRegEx": "Casey and G.", "year": 1986}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["Coates", "Adam", "Ng", "Andrew Y", "Lee", "Honglak"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["Denton", "Emily", "Chintala", "Soumith", "Szlam", "Arthur", "Fergus", "Rob"], "venue": "arXiv preprint arXiv:1506.05751,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "A technical word-and term-translation aid using noisy parallel corpora across language groups", "author": ["Fung", "Pascale", "McKeown", "Kathleen"], "venue": "Machine translation,", "citeRegEx": "Fung et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Fung et al\\.", "year": 1997}, {"title": "Domain-adversarial training of neural networks", "author": ["Gani", "Yaroslav", "Ustinova", "Evgeniya", "Ajakan", "Hana", "Germain", "Pascal", "Larochelle", "Hugo", "Laviolette", "Fran\u00e7ois", "Marchand", "Mario", "Lempitsky", "Victor"], "venue": "arXiv preprint arXiv:1505.07818,", "citeRegEx": "Gani et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gani et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Learning bilingual lexicons from monolingual corpora", "author": ["Haghighi", "Aria", "Liang", "Percy", "Berg-Kirkpatrick", "Taylor", "Klein", "Dan"], "venue": "In ACL,", "citeRegEx": "Haghighi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2008}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Hinton", "Geoffrey E", "Salakhutdinov", "Ruslan R"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Hinton", "Geoffrey E", "Osindero", "Simon", "Teh", "Yee-Whye"], "venue": "Neural computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Cryptogram decoding for optical character recognition", "author": ["Huang", "Gary", "Learned-Miller", "Erik G", "McCallum", "Andrew"], "venue": "University of Massachusetts-Amherst Technical Report,", "citeRegEx": "Huang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2006}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2013}, {"title": "Unsupervised analysis for decipherment problems", "author": ["Knight", "Kevin", "Nair", "Anish", "Rathod", "Nishit", "Yamada", "Kenji"], "venue": "In Proceedings of the COLING/ACL on Main conference poster sessions,", "citeRegEx": "Knight et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Knight et al\\.", "year": 2006}, {"title": "Learning a translation lexicon from monolingual corpora", "author": ["Koehn", "Philipp", "Knight", "Kevin"], "venue": "In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition-Volume", "citeRegEx": "Koehn et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2002}, {"title": "Efficient estimation of word representations in vector space", "author": ["Mikolov", "Tomas", "Chen", "Kai", "Corrado", "Greg", "Dean", "Jeffrey"], "venue": "arXiv preprint arXiv:1301.3781,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Mikolov", "Tomas", "Le", "Quoc V", "Sutskever", "Ilya"], "venue": "arXiv preprint arXiv:1309.4168,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Attacking decipherment problems optimally with low-order n-gram models", "author": ["Ravi", "Sujith", "Knight", "Kevin"], "venue": "In proceedings of the conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Ravi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ravi et al\\.", "year": 2008}, {"title": "Learning representations by backpropagating", "author": ["Rumelhart", "David E", "Hinton", "Geoffrey E", "Williams", "Ronald J"], "venue": "errors. Nature,", "citeRegEx": "Rumelhart et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1986}, {"title": "A statistical model for lost language decipherment", "author": ["Snyder", "Benjamin", "Barzilay", "Regina", "Knight", "Kevin"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Snyder et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Snyder et al\\.", "year": 2010}, {"title": "Deep domain confusion: Maximizing for domain invariance", "author": ["Tzeng", "Eric", "Hoffman", "Judy", "Zhang", "Ning", "Saenko", "Kate", "Darrell", "Trevor"], "venue": "arXiv preprint arXiv:1412.3474,", "citeRegEx": "Tzeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tzeng et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 18, "context": "Each training case (xi, yi) imposes a soft constraint on F : F (xi) = yi (1) We solve these equations by local optimization with the backpropagation algorithm (Rumelhart et al., 1986).", "startOffset": 159, "endOffset": 183}, {"referenceID": 13, "context": "This idea has been further explored in the context of machine translation (typically in the form of matching bigrams) (Knight et al., 2006; Huang et al., 2006; Snyder et al., 2010; Ravi & Knight, 2008), and in unsupervised lexicon induction (Fung & McKeown, 1997; Koehn & Knight, 2002; Haghighi et al.", "startOffset": 118, "endOffset": 201}, {"referenceID": 11, "context": "This idea has been further explored in the context of machine translation (typically in the form of matching bigrams) (Knight et al., 2006; Huang et al., 2006; Snyder et al., 2010; Ravi & Knight, 2008), and in unsupervised lexicon induction (Fung & McKeown, 1997; Koehn & Knight, 2002; Haghighi et al.", "startOffset": 118, "endOffset": 201}, {"referenceID": 19, "context": "This idea has been further explored in the context of machine translation (typically in the form of matching bigrams) (Knight et al., 2006; Huang et al., 2006; Snyder et al., 2010; Ravi & Knight, 2008), and in unsupervised lexicon induction (Fung & McKeown, 1997; Koehn & Knight, 2002; Haghighi et al.", "startOffset": 118, "endOffset": 201}, {"referenceID": 8, "context": ", 2010; Ravi & Knight, 2008), and in unsupervised lexicon induction (Fung & McKeown, 1997; Koehn & Knight, 2002; Haghighi et al., 2008; Mikolov et al., 2013b).", "startOffset": 68, "endOffset": 158}, {"referenceID": 20, "context": "Similar ideas have recently been proposed for domain adaptation where a model learns to map the new distribution back onto the training distribution (Tzeng et al., 2014; Gani et al., 2015).", "startOffset": 149, "endOffset": 188}, {"referenceID": 6, "context": "Similar ideas have recently been proposed for domain adaptation where a model learns to map the new distribution back onto the training distribution (Tzeng et al., 2014; Gani et al., 2015).", "startOffset": 149, "endOffset": 188}, {"referenceID": 3, "context": "Other work used the k-means objective for pre-training (Coates et al., 2011), and this list of references is far from exhaustive.", "startOffset": 55, "endOffset": 76}, {"referenceID": 5, "context": ", 2010; Ravi & Knight, 2008), and in unsupervised lexicon induction (Fung & McKeown, 1997; Koehn & Knight, 2002; Haghighi et al., 2008; Mikolov et al., 2013b). Notably, Knight et al. (2006) discusses the connection between unsupervised learning and language decipherment, and formulates a generative model similar to the one presented in this work.", "startOffset": 113, "endOffset": 190}, {"referenceID": 4, "context": ", 2014; Gani et al., 2015). These approaches are closely related to the ODM cost, since they are concerned with transforming the new distribution back to the training distribution. There has been a lot of other work on unsupervised learning with neural networks, which is largely concerned with the concept of \u201cpre-training\u201d. In pre-training, we first train the model with an unsupervised cost function, and finish training the model with the supervised cost. This concept was introduced by Hinton et al. (2006) and Hinton & Salakhutdinov (2006) and later by Bengio et al.", "startOffset": 8, "endOffset": 512}, {"referenceID": 4, "context": ", 2014; Gani et al., 2015). These approaches are closely related to the ODM cost, since they are concerned with transforming the new distribution back to the training distribution. There has been a lot of other work on unsupervised learning with neural networks, which is largely concerned with the concept of \u201cpre-training\u201d. In pre-training, we first train the model with an unsupervised cost function, and finish training the model with the supervised cost. This concept was introduced by Hinton et al. (2006) and Hinton & Salakhutdinov (2006) and later by Bengio et al.", "startOffset": 8, "endOffset": 546}, {"referenceID": 1, "context": "(2006) and Hinton & Salakhutdinov (2006) and later by Bengio et al. (2007). Other work used the k-means objective for pre-training (Coates et al.", "startOffset": 54, "endOffset": 75}, {"referenceID": 1, "context": "(2006) and Hinton & Salakhutdinov (2006) and later by Bengio et al. (2007). Other work used the k-means objective for pre-training (Coates et al., 2011), and this list of references is far from exhaustive. More recent examples of unsupervised pre-training are the Skip-gram model (Mikolov et al., 2013a) and its generalization to sentences, the Skip-thought vectors model of Kiros et al. (2015). These models use well-motivated unsupervised objective functions that appear to be genuinely useful for a wide variety of language-processing tasks.", "startOffset": 54, "endOffset": 395}, {"referenceID": 13, "context": "A similar generative model was presented by Knight et al. (2006). It is desirable to train generative models using the variational autoencoder (VAE) of Kingma & Welling (2013).", "startOffset": 44, "endOffset": 65}, {"referenceID": 13, "context": "A similar generative model was presented by Knight et al. (2006). It is desirable to train generative models using the variational autoencoder (VAE) of Kingma & Welling (2013). However, VAE training forces y to be continuous, which is undesirable since many domains of interest are discrete.", "startOffset": 44, "endOffset": 176}, {"referenceID": 7, "context": "The Generative Adversarial Network (Goodfellow et al., 2014) is a procedure for training a \u201cgenerator\u201d to produce samples that are statistically indistinguishable from a desired distribution.", "startOffset": 35, "endOffset": 60}, {"referenceID": 4, "context": "The generative adversarial network offers a direct way of training generative models, and it had enjoyed considerable success in learning models of natural images (Denton et al., 2015).", "startOffset": 163, "endOffset": 184}, {"referenceID": 13, "context": "1 DUAL AUTOENCODER FOR CIPHERS We also tested the dual autoencoder on a character and a word cipher, tasks that were also considered by Knight et al. (2006). In this task, we are given two text corpora that follow the same distribution, but where the characters (or the words) of one of the corpora is scrambled.", "startOffset": 136, "endOffset": 157}], "year": 2015, "abstractText": "General unsupervised learning is a long-standing conceptual problem in machine learning. Supervised learning is successful because it can be solved by the minimization of the training error cost function. Unsupervised learning is not as successful, because the unsupervised objective may be unrelated to the supervised task of interest. For an example, density modelling and reconstruction have often been used for unsupervised learning, but they did not produced the sought-after performance gains, because they have no knowledge of the sought-after supervised tasks. In this paper, we present an unsupervised cost function which we name the Output Distribution Matching (ODM) cost, which measures a divergence between the distribution of predictions and distributions of labels. The ODM cost is appealing because it is consistent with the supervised cost in the following sense: a perfect supervised classifier is also perfect according to the ODM cost. Therefore, by aggressively optimizing the ODM cost, we are almost guaranteed to improve our supervised performance whenever the space of possible predictions is exponentially large. We demonstrate that the ODM cost works well on number of small and semiartificial datasets using no (or almost no) labelled training cases. Finally, we show that the ODM cost can be used for one-shot domain adaptation, which allows the model to classify inputs that differ from the input distribution in significant ways without the need for prior exposure to the new domain.", "creator": "LaTeX with hyperref package"}}}