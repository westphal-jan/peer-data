{"id": "1511.06728", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2015", "title": "Hand Pose Estimation through Semi-Supervised and Weakly-Supervised Learning", "abstract": "We propose a method for hand pose estimation based on a deep regressor trained on two different kinds of input. Raw depth data is fused with an intermediate representation in the form of a segmentation of the hand into parts. This intermediate representation contains important topological information and provides useful cues for reasoning about joint locations. The mapping from raw depth to segmentation maps is learned in a semi/weakly-supervised way from two different datasets: (i) a synthetic dataset created through a rendering pipeline including densely labeled ground truth (pixelwise segmentations); and (ii) a dataset with real images for which ground truth joint positions are available, but not dense segmentations. Loss for training on real images is generated from a patch-wise restoration process, which aligns tentative segmentation maps with a large dictionary of synthetic poses. The underlying premise is that the domain shift between synthetic and real data is smaller in the intermediate representation, where labels carry geometric and topological meaning, than in the raw input domain. Experiments on the NYU dataset show that the proposed training method decreases error on joints over direct regression of joints from depth data by 15.7%.", "histories": [["v1", "Fri, 20 Nov 2015 19:19:00 GMT  (4193kb)", "http://arxiv.org/abs/1511.06728v1", "10 pages, 7 figures, 4 tables"], ["v2", "Wed, 8 Jun 2016 13:31:05 GMT  (2926kb)", "http://arxiv.org/abs/1511.06728v2", "11 pages, 7 figures, 4 tables"], ["v3", "Thu, 9 Jun 2016 06:08:54 GMT  (2926kb)", "http://arxiv.org/abs/1511.06728v3", "11 pages, 7 figures, 4 tables"], ["v4", "Fri, 15 Sep 2017 09:24:57 GMT  (2997kb,D)", "http://arxiv.org/abs/1511.06728v4", "13 pages, 10 figures, 4 tables"]], "COMMENTS": "10 pages, 7 figures, 4 tables", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["natalia neverova", "christian wolf", "florian nebout", "graham taylor"], "accepted": false, "id": "1511.06728"}, "pdf": {"name": "1511.06728.pdf", "metadata": {"source": "CRF", "title": "Hand Pose Estimation through Weakly-Supervised Learning of a Rich Intermediate Representation", "authors": ["Natalia Neverova", "Christian Wolf", "Florian Nebout", "Graham Taylor"], "emails": ["christian.wolf}@liris.cnrs.fr", "2florian.nebout@awabot.com", "3gwtaylor@uoguelph.ca"], "sections": [{"heading": null, "text": "ar Xiv: 151 1.06 728v 1 [cs.C V] 2"}, {"heading": "1. Introduction", "text": "In fact, most of them are able to move to another world, in which they are able to move."}, {"heading": "2. Related work", "text": "This year is the highest in the history of the country."}, {"heading": "3. Joint regression with a rich intermediate", "text": "In our poorly monitored environment, however, the training data is divided into two parts: a set of real depth images and a set of associated depth images, and a second set of synthetic depth images with a set of associated basic truth label images. We are rendered with D (j) the Jth pixel in image D. The synthetic images were rendered from various 3D hand models using a rendering pipeline. As in [25], we also present different parameters and hand shape parameters. Variations in viewpoints and hand positions are achieved taking into account physical and physiological limitations. Unlike other poorly monitored or semi-monitored settings, we do not assume that any basic truth data is available for intermedia representation of the real training images. Segmentation of segments is extremely difficult and time consuming. Labeling a sufficiently large number of images is hardly practicable."}, {"heading": "3.1. Weakly supervised fine-tuning of the segmentation learner", "text": "The quality of the restored segmentation map is appreciated by comparing it with the individual segmentation items. In particular, a corresponding segmentation map is created, leading to a segmentation map. This noisy predicted map is restored through a restoration process described below. The quality of the restored segmentation map is appreciated by comparing it with the individual segmentation items. The quality of the restored segmentation map is described below. The quality of the restored segmentation map is appreciated by comparing it with the individual segmentation items."}, {"heading": "4. Architectures", "text": "The structure of segmentation is motivated by the idea of efficient image segmentation, which preserves the original resolution of the input, and is inspired by the OverFeat networks proposed for the detection and localization of objects. [22, 19] The learner consists of 3 conventional layers followed by a fully interconnected layer. Max pooling, which typically follows conventional layers, leads to downsampling of feature maps that destroy precise spatial information. Instead, we conduct pooling over 2 x 2 overlapping regions, which are achieved by shifting the maps in a single step."}, {"heading": "5. Experimental results", "text": "This year, it has come to the point where it will be able to get to the top of the leaderboard, \"he told the German Press Agency.\" We have never lost so much time as this year, \"he said.\" We have never lost so much time, \"he said."}, {"heading": "6. Conclusion", "text": "We presented a method for estimating hand positions based on an intermediate representation merged with raw depth input data. We showed that the additional structured information in this representation provides important clues for a common regression that leads to lower errors. A key component of the proposed method is the poorly supervised learning of depth to segment mapping from a mixture of densely labeled synthetic data and sparsely labeled real data. Weak monitoring is eliminated by patchwise alignment of real data with synthetic data performed in the intermediate space, taking advantage of its strong geometric and topological properties."}, {"heading": "7. Acknowledgements", "text": "This work was partly financed by the French Interabot Scholarship, a project of the type \"Investissement's d'Avenir / Briques Ge'ne \u0301 riques du Logiciel Embarque,\" and by the ANR project SoLStiCe (ANR-13-BS02-0002-01), a project of the scholarship programme \"ANR blanc.\" G. Taylor appreciates the support of NSERC and CFI."}, {"heading": "A. Comparison with graphical models", "text": "In this section, we will give more information about the graphical models we have implemented for comparison, which were mentioned in Section 5. We have implemented a CRF-like discrete energy function (see Table 2). The goal of the optimization problem is to regulate the patchwise restoration process as described in the main paper. Instead of choosing the closest neighbor in the patchspace for each pixel, as described in Equation (1), a solution is sought that meets certain coherence conditions over spatial neighborhoods. To this end, we create a global energy function E (x), which is defined on a 2D grid corresponding to the input image to restore: E (x) = patch (xi) + \u03b1 patch (xi) + x patch."}], "references": [{"title": "OpenGM: A c++ library for discrete graphical models", "author": ["T.B. Andres", "Beier", "J. Kappes"], "venue": "ArXiv e-prints,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Estimating 3D hand pose from a cluttered image", "author": ["V. Athitsos", "Z. Liu", "Y. Wu", "J. Yuan"], "venue": "CVPR. IEEE,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Articulated pose estimation by a graphical model with image dependent pairwise relations", "author": ["X. Chen", "A. Yuille"], "venue": "CVPR,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "NIPS BigLearn Workshop,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Model-based 3d hand pose estimation from monocular video", "author": ["M. de La Gorce", "D. Fleet", "N. Paragios"], "venue": "IEEE- Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Multi-task learning of facial landmarks and expression", "author": ["T. Devries", "K. Biswaranjan", "G. Taylor"], "venue": "14th Canadian Conference on Computer and Robot Vision (CRV),", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "N-Fields: Neural Network Nearest Neighbor Fields for Image Transforms", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "ACCV,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Depth-based hand pose estimation: methods, data, and challenges", "author": ["J.S.S. III", "G. Rogez", "Y. Yang", "J. Shotton", "D. Ramanan"], "venue": "ICCV,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv:1502.03167v3,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning human pose estimation features with convolutional networks", "author": ["A. Jain", "J. Tompson", "M. Andriluka", "G. Taylor", "C. Bregler"], "venue": "ICLR,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Hand pose estimation and hand shape classification using multi-layered randomized decision forests", "author": ["C. Keskin", "F. Kirac", "Y. Kara", "L. . Akarun"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Hand pose estimation and hand shape classification using multi-layered randomized decision forests", "author": ["C. Keskin", "F. Kira\u00e7", "Y. Kara", "L. Akarun"], "venue": "ECCV,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J.L. Ba"], "venue": "ICLR,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Hands deep in deep learning for hand pose estimation", "author": ["D. Kingma", "J.L. Ba"], "venue": "CVWW,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Structured labels in random forests for semantic labelling and object detection", "author": ["P. Kontschieder", "S. Bulo", "M. Pelillo", "H. Bischof"], "venue": "ICCV,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Modelbased hand pose estimation via spatial-temporal hand parsing and 3D fingertip localization", "author": ["H. Liang", "J. Yuan", "D. Thalmann", "Z. Zhang"], "venue": "In The Visual Computer,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "ICLR,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Fast approximate nearest neighbors with automatic algorithm configuration", "author": ["M. Muja", "D. Lowe"], "venue": "VISAPP, pages 331\u2013340,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Hand segmentation with structured convolutional learning", "author": ["N. Neverova", "C. Wolf", "G. Taylor", "F. Nebout"], "venue": "In ACCV,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Efficient model-based 3D tracking of hand articulations using Kinect", "author": ["I. Oikonomidis", "N. Kyriazis", "A. Argyros"], "venue": "BMVC, pages 101.1\u2013101.11,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Realtime and Robust Hand Tracking from Depth", "author": ["C. Qian", "X. Sun", "Y. Wei", "X. Tang", "J. Sun"], "venue": "CVPR,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "ICLR,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Conditional regression forests for human pose estimation", "author": ["J. Shotton"], "venue": "CVPR, pages 3394\u20133401,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["J. Shotton", "A. Fitzgibbon", "M. Cook", "T. Sharp", "M. Finocchio", "R. Moore", "A. Kipman", "A. Blake"], "venue": "CVPR, pages 1297\u20131304,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Interactive markerless articulated hand motion tracking using RGB and depth data", "author": ["S. Sridhar", "A. Oulasvirta", "C. Theobalt"], "venue": "ICCV,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate", "author": ["C. Szegedy", "W. Liu", "J. Yangqing", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. R"], "venue": "shift. arXiv:1502.03167v3,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Latent regression forest: Structured estimation of 3d hand posture", "author": ["D. Tang", "H. Chang", "A. Tejani", "T.-K. Kim"], "venue": "CVPR,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Opening the black box: Hierarchical sampling optimization for estimating human hand pose", "author": ["D. Tang", "J. Taylor", "K. Pushmeet", "C. Keskin", "T.-K. Kim", "J. Shotton"], "venue": "ICCV,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Real-time articulated hand pose estimation using semi-supervised transductive regression forests", "author": ["D. Tang", "T. Yu", "T.-K. Kim"], "venue": "ICCV,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "The vitruvian manifold: Inferring dense correspondences for one-shot human pose estimation", "author": ["J. Taylor", "J. Shotton", "T. Sharp", "A. Fitzgibbon"], "venue": "CVPR,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Joint training of a convolutional network and a graphical model for human pose estimation", "author": ["J. Tompson", "A. Jain", "Y. LeCun", "C. Bregler"], "venue": "NIPS,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Real-time continuous pose recovery of human hands using convolutional networks", "author": ["J. Tompson", "M. Stein", "Y. LeCun", "K. Perlin"], "venue": "SIGGRAPH,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "DeepPose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": "CVPR,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient hand pose estimation from a single depth image", "author": ["C. Xu", "L. Cheng"], "venue": "ICCV,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Transductive 3D shape segmentation using sparse reconstruction", "author": ["W. Xu", "Z. Shi", "M. Xu", "K. Zhou", "J. Wang", "B. Zhou", "J. Wang", "Z. Yuan"], "venue": "Transactions on Graphics,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Facial landmark detection by deep multi-task learning", "author": ["Z. Zhang", "P. Luo", "C.C. Loy", "X. Tang"], "venue": "Computer Vision\u2013 ECCV 2014, pages 94\u2013108. Springer,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 31, "context": "Experiments on the NYU dataset [32] show", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "While the estimation of full-body pose is now available at real-time in commercial products, at least in cooperative environments [24], the estimation of Figure 1: A rich intermediate representation is fused with raw input for hand joint regression.", "startOffset": 130, "endOffset": 134}, {"referenceID": 31, "context": "The input image is from the NYU dataset [32].", "startOffset": 40, "endOffset": 44}, {"referenceID": 23, "context": "Similar to earlier work [24, 12], we first construct an intermediate representation based on a segmentation into parts.", "startOffset": 24, "endOffset": 32}, {"referenceID": 11, "context": "Similar to earlier work [24, 12], we first construct an intermediate representation based on a segmentation into parts.", "startOffset": 24, "endOffset": 32}, {"referenceID": 31, "context": "While more recent work on body and hand pose estimation tends to perform direct regression from depth or color input to joint positions [32, 31, 3, 23], we argue that the intermediate representation is a powerful tool in the special context of training with multiple heterogeneous training sets.", "startOffset": 136, "endOffset": 151}, {"referenceID": 30, "context": "While more recent work on body and hand pose estimation tends to perform direct regression from depth or color input to joint positions [32, 31, 3, 23], we argue that the intermediate representation is a powerful tool in the special context of training with multiple heterogeneous training sets.", "startOffset": 136, "endOffset": 151}, {"referenceID": 2, "context": "While more recent work on body and hand pose estimation tends to perform direct regression from depth or color input to joint positions [32, 31, 3, 23], we argue that the intermediate representation is a powerful tool in the special context of training with multiple heterogeneous training sets.", "startOffset": 136, "endOffset": 151}, {"referenceID": 22, "context": "While more recent work on body and hand pose estimation tends to perform direct regression from depth or color input to joint positions [32, 31, 3, 23], we argue that the intermediate representation is a powerful tool in the special context of training with multiple heterogeneous training sets.", "startOffset": 136, "endOffset": 151}, {"referenceID": 23, "context": "While purely supervised training on synthetic data has proven to work well for full-body pose estimation [24, 12], hand pose estimation is known to require real data captured from depth sensors for training [29, 27, 32] due to low input resolution and data quality.", "startOffset": 105, "endOffset": 113}, {"referenceID": 11, "context": "While purely supervised training on synthetic data has proven to work well for full-body pose estimation [24, 12], hand pose estimation is known to require real data captured from depth sensors for training [29, 27, 32] due to low input resolution and data quality.", "startOffset": 105, "endOffset": 113}, {"referenceID": 28, "context": "While purely supervised training on synthetic data has proven to work well for full-body pose estimation [24, 12], hand pose estimation is known to require real data captured from depth sensors for training [29, 27, 32] due to low input resolution and data quality.", "startOffset": 207, "endOffset": 219}, {"referenceID": 26, "context": "While purely supervised training on synthetic data has proven to work well for full-body pose estimation [24, 12], hand pose estimation is known to require real data captured from depth sensors for training [29, 27, 32] due to low input resolution and data quality.", "startOffset": 207, "endOffset": 219}, {"referenceID": 31, "context": "While purely supervised training on synthetic data has proven to work well for full-body pose estimation [24, 12], hand pose estimation is known to require real data captured from depth sensors for training [29, 27, 32] due to low input resolution and data quality.", "startOffset": 207, "endOffset": 219}, {"referenceID": 23, "context": "Body part segmentation as an intermediate representation for joint estimation from depth images was successfully used in [24], where random forests were trained to perform pixel-wise classification.", "startOffset": 121, "endOffset": 125}, {"referenceID": 11, "context": "This was adapted to hand pose estimation in [12], where an additional pose clustering step was introduced.", "startOffset": 44, "endOffset": 48}, {"referenceID": 28, "context": "In [29], a random forest is learned, which performs different tasks at different levels: viewpoint clustering in higher levels, part segmentation in middle levels, and joint regression in lower levels.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "In follow-up work [27], a latent regression forest is learned, which automatically extracts a hierarchical and topological model of a human hand from data.", "startOffset": 18, "endOffset": 22}, {"referenceID": 31, "context": "Recent work estimates joint positions by regression with deep convolutional neural nets [32, 3, 31, 33, 10].", "startOffset": 88, "endOffset": 107}, {"referenceID": 2, "context": "Recent work estimates joint positions by regression with deep convolutional neural nets [32, 3, 31, 33, 10].", "startOffset": 88, "endOffset": 107}, {"referenceID": 30, "context": "Recent work estimates joint positions by regression with deep convolutional neural nets [32, 3, 31, 33, 10].", "startOffset": 88, "endOffset": 107}, {"referenceID": 32, "context": "Recent work estimates joint positions by regression with deep convolutional neural nets [32, 3, 31, 33, 10].", "startOffset": 88, "endOffset": 107}, {"referenceID": 9, "context": "Recent work estimates joint positions by regression with deep convolutional neural nets [32, 3, 31, 33, 10].", "startOffset": 88, "endOffset": 107}, {"referenceID": 9, "context": "Post-processing to enforce structural constraints is based on graphical models [10, 31, 3] or inverse kinematics [32].", "startOffset": 79, "endOffset": 90}, {"referenceID": 30, "context": "Post-processing to enforce structural constraints is based on graphical models [10, 31, 3] or inverse kinematics [32].", "startOffset": 79, "endOffset": 90}, {"referenceID": 2, "context": "Post-processing to enforce structural constraints is based on graphical models [10, 31, 3] or inverse kinematics [32].", "startOffset": 79, "endOffset": 90}, {"referenceID": 31, "context": "Post-processing to enforce structural constraints is based on graphical models [10, 31, 3] or inverse kinematics [32].", "startOffset": 113, "endOffset": 117}, {"referenceID": 13, "context": "In [14] a deep learning framework is regularized by a bottleneck layer, enforcing the network to model underlying structure of joint positions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "In a recent overview [8] the deep learning model were shown to perform the best among existing approaches, but still far from human performance.", "startOffset": 21, "endOffset": 24}, {"referenceID": 2, "context": "Graphical models \u2014 In [3], a graphical model is implemented with deep convolutional nets, which jointly estimate unary terms, given indications of joint types and positions, and binary terms, modelling relationships between joints.", "startOffset": 22, "endOffset": 25}, {"referenceID": 30, "context": "In [31], a deep full-body part detector is jointly learned with a Markov Random Field which models spatial priors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "[20] is based on pixelwise comparison of rendered and observed depth maps.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Inverse rendering of a generative model including shading and texture is used for model fitting in [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 15, "context": "In [16], ICP is employed for hand pose reconstruction and 3D fingertip localization under spatial and temporal constraints.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "A hybrid method [21] for real-time hand tracking uses a simple hand model consisting of a number of spheres.", "startOffset": 16, "endOffset": 20}, {"referenceID": 24, "context": "In [25], a person-specific and hybrid generative/discriminative model is built for a system using five RGB cameras plus a ToF camera.", "startOffset": 3, "endOffset": 7}, {"referenceID": 29, "context": "In [30], a correspondence between depth pixels and vertices of an articulated 3D model is learned.", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "In [2], approximate directed Chamfer distances are used to align observed edge images with a synthetic dataset.", "startOffset": 3, "endOffset": 6}, {"referenceID": 34, "context": "Patchwise alignment of segmentations in a transductive learning setting has been performed on 3D meshes [35], matching real unlabelled shape segments to shapes from a large labelled database.", "startOffset": 104, "endOffset": 108}, {"referenceID": 5, "context": "Our method can be viewed as a kind of multitask learning, a topic actively pursued by the deep vision community [6, 36].", "startOffset": 112, "endOffset": 119}, {"referenceID": 35, "context": "Our method can be viewed as a kind of multitask learning, a topic actively pursued by the deep vision community [6, 36].", "startOffset": 112, "endOffset": 119}, {"referenceID": 6, "context": "Our work bears a certain resemblance to the recently proposed N-Fields [7].", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "However, whereas in [7], NN-search is performed in a feature space learned by deep networks, our method performs NN-search in a patch space corresponding to semantic segmentation learned by deep networks.", "startOffset": 20, "endOffset": 23}, {"referenceID": 14, "context": "This part of our work bears also some similarity to the way label information is integrated in structured prediction forests [15], although no patch alignment with a dictionary is carried out there.", "startOffset": 125, "endOffset": 129}, {"referenceID": 24, "context": "As in [25], we also sample different pose parameters and hand shape parameters.", "startOffset": 6, "endOffset": 10}, {"referenceID": 28, "context": "In contrast to other weakly-supervised or semisupervised settings, for instance [29], we do not suppose that any ground truth data for the intermediate representation is available for the real training images.", "startOffset": 80, "endOffset": 84}, {"referenceID": 23, "context": "We do, however, rely on ground truth for joint positions, which can be obtained in several ways: In [24], external motion capture using markers is employed.", "startOffset": 100, "endOffset": 104}, {"referenceID": 31, "context": "In [32], training data is acquired in a multi-view setting from three different", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "As also reported in [25], the range of poses which can occur in natural motion is extremely large, making full global matching with pose datasets difficult.", "startOffset": 20, "endOffset": 24}, {"referenceID": 6, "context": "This integration bears some similarity to [7], where information of nearest neighbor searches is integrated over a local window, albeit through averaging a continuous mapping.", "startOffset": 42, "endOffset": 45}, {"referenceID": 14, "context": "It is also similar to the patchwise integration performed in structured prediction forests [15].", "startOffset": 91, "endOffset": 95}, {"referenceID": 21, "context": "The structure of the segmentation learner fs is motivated by the idea of performing efficient pixelwise image segmentation preserving original resolution of the input, and is inspired by OverFeat networks which were proposed for object detection and localization [22, 19].", "startOffset": 263, "endOffset": 271}, {"referenceID": 18, "context": "The structure of the segmentation learner fs is motivated by the idea of performing efficient pixelwise image segmentation preserving original resolution of the input, and is inspired by OverFeat networks which were proposed for object detection and localization [22, 19].", "startOffset": 263, "endOffset": 271}, {"referenceID": 25, "context": "Structurally, it resembles an inception unit [26, 17] where the output of the first convolutional layer after max pooling as passed through several parallel feature extractors capturing information at different levels of localization.", "startOffset": 45, "endOffset": 53}, {"referenceID": 16, "context": "Structurally, it resembles an inception unit [26, 17] where the output of the first convolutional layer after max pooling as passed through several parallel feature extractors capturing information at different levels of localization.", "startOffset": 45, "endOffset": 53}, {"referenceID": 8, "context": "Both learners have ReLU activation functions at each layer and employ batch normalization [9].", "startOffset": 90, "endOffset": 93}, {"referenceID": 12, "context": "Finally, the regression learner is trained by gradient descent using the Adam [13] update rule.", "startOffset": 78, "endOffset": 82}, {"referenceID": 31, "context": "We evaluated the proposed method on the NYU Hand Pose Dataset, which was published in [32] and is publicly avail-", "startOffset": 86, "endOffset": 90}, {"referenceID": 13, "context": "[14] 12.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "0[8] 19.", "startOffset": 1, "endOffset": 4}, {"referenceID": 13, "context": "[14] 27.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] 30.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] 34.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[32] 7.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "0[14] -", "startOffset": 1, "endOffset": 5}, {"referenceID": 33, "context": "Xu and Cheng [34] 58.", "startOffset": 13, "endOffset": 17}, {"referenceID": 7, "context": "0[8] Keskin et al.", "startOffset": 1, "endOffset": 4}, {"referenceID": 10, "context": "[11] 72.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "5[8] -", "startOffset": 1, "endOffset": 4}, {"referenceID": 3, "context": "ConvNets were implemented using the Torch7 library [4].", "startOffset": 51, "endOffset": 54}, {"referenceID": 17, "context": "NN-search using KD-trees was performed using the FLANN library [18].", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "The second best model, cascade regression, was inspired by the work of [33], where the initial rough estimation of hand joints positions is then improved by zooming in We should note here, that the quality of network outputs can be further improved by optimization through inverse kinematics, as it has been done, for example, in [32].", "startOffset": 71, "endOffset": 75}, {"referenceID": 31, "context": "The second best model, cascade regression, was inspired by the work of [33], where the initial rough estimation of hand joints positions is then improved by zooming in We should note here, that the quality of network outputs can be further improved by optimization through inverse kinematics, as it has been done, for example, in [32].", "startOffset": 330, "endOffset": 334}, {"referenceID": 27, "context": "In a recent work [28] on optimization of hand pose estimation formulated as an inverse kinematics problem, the authors report performance similar to [32] in terms of 2D UV-error (no error in mm provided).", "startOffset": 17, "endOffset": 21}, {"referenceID": 31, "context": "In a recent work [28] on optimization of hand pose estimation formulated as an inverse kinematics problem, the authors report performance similar to [32] in terms of 2D UV-error (no error in mm provided).", "startOffset": 149, "endOffset": 153}, {"referenceID": 0, "context": "Inference was performed through message passing using the open-GM library [1], and the hyper-parameter \u03b1 was opti-", "startOffset": 74, "endOffset": 77}], "year": 2017, "abstractText": "We propose a method for hand pose estimation based on a deep regressor trained on two different kinds of input. Raw depth data is fused with an intermediate representation in the form of a segmentation of the hand into parts. This intermediate representation contains important topological information and provides useful cues for reasoning about joint locations. The mapping from raw depth to segmentation maps is learned in a semi/weakly-supervised way from two different datasets: (i) a synthetic dataset created through a rendering pipeline including densely labeled ground truth (pixelwise segmentations); and (ii) a dataset with real images for which ground truth joint positions are available, but not dense segmentations. Loss for training on real images is generated from a patch-wise restoration process, which aligns tentative segmentation maps with a large dictionary of synthetic poses. The underlying premise is that the domain shift between synthetic and real data is smaller in the intermediate representation, where labels carry geometric and topological meaning, than in the raw input domain. Experiments on the NYU dataset [32] show that the proposed training method decreases error on joints over direct regression of joints from depth data by 15.7%.", "creator": "LaTeX with hyperref package"}}}