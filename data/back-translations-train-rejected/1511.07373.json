{"id": "1511.07373", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2015", "title": "What is the plausibility of probability?(revised 2003, 2015)", "abstract": "We present and examine a result related to uncertainty reasoning, namely that a certain plausibility space of Cox's type can be uniquely embedded in a minimal ordered field. This, although a purely mathematical result, can be claimed to imply that every rational method to reason with uncertainty must be based on sets of extended probability distributions, where extended probability is standard probability extended with infinitesimals.", "histories": [["v1", "Mon, 23 Nov 2015 19:24:17 GMT  (29kb)", "http://arxiv.org/abs/1511.07373v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["stefan arnborg", "gunnar sj\\\"odin"], "accepted": false, "id": "1511.07373"}, "pdf": {"name": "1511.07373.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["stefan@nada.kth.se", "sjodin@sics.se"], "sections": [{"heading": null, "text": "ar Xiv: 151 1.07 373v 1 [cs.A I] 2 3N ovHowever, this assertion must be supported by an argument of a non-mathematical type, since pure mathematics tells us nothing about the world. We propose such an argument and relate it to results from the literature of uncertainty and statistics. In an additional retrospective section, we discuss some developments in the field of countable additivity, partial-ordered domains and robustness, as well as philosophical substances of the Cox / Jaynes approach since 2003. We also show that the most general partial plausibility calculation that can be embedded in a ring can be presented as a series of extended probability distributions or, in algebraic terms, as a subdirect sum of ordered fields. In other words, the robust Bayesian approach is universal. This result is exemplary by linking Dempster-Shafer's theory of evidence with robust Bayesian analyses. Keywords: belief, probability, Bayesiveness, Bayesiveness."}, {"heading": "1 Introduction", "text": "We will consider plausibility spaces of the type we define for the domain of plausibility principles with the auxiliary functions Q, S and G for calculating the plausibility of conjunctions, supplements and disjunctions, respectively. However, the domain of plausibility principles with the auxiliary principles and some uncertainty principles is referred to as a plausibility space in which an event with plausibility value a is equally or less plausible than one with value b. A system of conditional propositions or events with plausibility values is a possible plausibility space in which the domain questions the real numbers and the functions F and G are multiplication and addition. Extended probability is standard probability extended with infinite probability values. We will motivate one definition, prove two theories and justify a claim."}, {"heading": "2 Symbols and Plausibilities.", "text": "The methods of definition and induction are attributed, from Aristotle, to Socrates [46], and were further developed by Aristotle and the Stoic philosophers. Although the current English translations of Aristotle contain words such as symbol, usefulness and probability, it is clear that Aristotle was not very interested in mathematics and could not give quantitative models of decision problems. Thus, his terms do not reflect a detailed and precise understanding of modern Bayesian decision theory: \"Find out what you think is a good life and consider the probabilities of your possible actions to achieve it. Then follow the course of action, which is most likely to produce results in a good life.\" Two thousand years later, Thomas Bayes was the first to apply the newly invented calculus of probability to a problem."}, {"heading": "3 Coherence, or Dutch Book avoidance", "text": "We have not presented the common assumptions of most existing theories of plausibility completely, but only in an orderly manner. [17, 15, 13, 41] But more is needed before the probability appears inevitable in a form that we know. What is required are some means to derive limitations on sets of plausibility from different conditional statements. Without such limitations, we can easily define plausibility spaces that do not correspond to probability. Basically, there are two ways to proceed. One, pursued by de Finetti to construct a game situation in which various plausibilities are put together by a bookmaker according to his beliefs. A bookmaker who offers a set of bets under which a player can choose a combination that gives positive payout in each situation, seems to have made his bets from a globally incoherent set of beliefs. Several essays show, with important differences in detail, that each set of beliefs is equal, each coherent, each coherent."}, {"heading": "4 Embeddability, Denseness,", "text": "The reasoning examined in Section 3 must be supplemented by some arguments linking the plausibility of events that are not linked by propositional identities. In Cox's work, this is done by regularity assumptions: the auxiliary functions F and S should be defined on an interval of real numbers and obey the assumption of associativity and differentiation at that interval. Implicit in this assumption seems to be the idea that the functions F and S are universal, and any plausibility problem should be solvable with the same functions F and S. Criticism of Cox's work assumes that this assumption either does not exist [20, 21] or is ignored. Statistics based on derivatives of probability as universal uncertainty often mention similar assumptions, but surprisingly often these are somewhat glossed, the most important exceptions being [9, 17, 41, 49]. We make a sketch review of some of the assumptions that have been proposed."}, {"heading": "5 Common sense assumptions entail extended robust probability.", "text": "The best known ordered fields are Q and R. However, there are ordered fields that contain more than the real numbers. An example is the field of rational functions R (B) in a variable. These functions can be added and multiplied with each other, and if they are by the lexicographic order of their values and derivatives of the order 1, 2... in which we obtain an ordered field. This field contains all real numbers (as constant functions), but there are no lowest upper and largest lower limits and therefore cannot be embedded in the field of realities. The variable numbers can be considered infinitesimal, positive but smaller than any positive real number. There are many ordered fields that are superfields of realities, and there is even a unique maximum ordered field described by Conway."}, {"heading": "6 Pragmatics", "text": "If we develop a methodology in which users are allowed to define epistemic states as sets of extended probability distributions, we will soon find ourselves in a situation in which these users are encouraged to define things they cannot possibly understand. Extended Robust Bayes allows us to create extremely complex system descriptions in which we have to work with polytopes in high-dimensional or even infinite spaces instead of points. [3] Even simple things are not so easy to do with such models. [3] The most interesting aspect of the above analysis is that it points to a possible maximum generality in uncertainty management, but in any specific application this generality probably needs to be curtailed. Is full generality really necessary? There are strong claims in the literature that this is not the case. There are also strong assertions that conventional Bayesianism, which uses only a probability distribution and where probabilities are standard, is insufficient, is therefore a pragmatic approach to consider."}, {"heading": "6.1 Extended Probability", "text": "Is an augmented probability required or is a standard probability appropriate? An augmented probability is not entirely inevitable, in the sense that each finite augmented probability model corresponds to a standard probability model [4]. But in some cases, an augmented probability appears useful as a pragmatic simplification of a modeling problem and for obtaining natural problem descriptions. It seems clear that there is a phase in cognitive assessments where qualitative and magnitude can be argued [26], followed by a quantitative phase where more quantitative reasoning occurs. In AI reasoning research, many non-probabilistic methods have been proposed, and it seems that many of them can be described in terms of an augmented probability [7, 8]. Non-standard analytical approaches have been propagated as an alternative to measurement-theoretical arguments in stochastic processes. Although no immediate response from user communities has followed, this is still a promising direction [34] to arrive at a number of assumptions in the literature."}, {"heading": "7 Summary and Conclusions", "text": "Many of the objections to Bayesian methods stem from the sometimes very complex analytical models preferred by theoretical statisticians, and many practitioners have seen alternative methods such as neural networks as a way around statistics. Unfortunately (or fortunately), this is largely an illusion. There is no fundamental reason why the models used could not be based on other types of models such as neural networks, linguistic coding, or case-based reasoning, and indeed efforts have been made to treat these techniques as special types of Bayesian models [23, 38]. As explained above, there is no easy way around the normative claims of the Robust Extended Bayes Method. Thus, if an alternative method is applied, it will sooner or later have to be evaluated on the standard scale of rationality. Bayesian methods contain a high degree of freedom in the sense that there are no \"correct\" models or model sets on which the conclusions about real or inner world phenomena must be assessed based on, but must be accepted as valid models."}, {"heading": "Acknowledgments", "text": "Reviewers of earlier versions of this paper have greatly influenced it by pointing out questionable statements (some have since been deleted, others elaborated) and several relevant related papers in many disciplines. SA is indebted to David Draper for discussing the importance and approach of including countable additives in the Cox / Jaynes framework, which also prompted me to conclude this unpublished manuscript and add a retrospective section (after the bibliography) below."}, {"heading": "8 Retrospect", "text": "Various versions of this manuscript have been inadvertently indexed by search engines and are quoted by other papers. This is the last version from 2003, with very few changes made in 2015: typos removed and a few arguments worked out too briefly. Nothing has been added to reflect developments since 2003, except in this retrospective section. Several aspects of the possible polishing of the development of Cox / Jaynes have been published, for an overview see see the introductory sections of [48]. Obviously, little effort has been made to analyze extended probability ranges and partially ordered ranges of plausibility, but there are a few results that need to be verified. I will mention these results only lightly in our algebraic framework. Some papers argue that we have made quite a number of assumptions compared to other papers in the same area. But, on closer inspection, this is just an effect of our need to talk explicitly about assumptions and discuss several alternative assumptions."}, {"heading": "8.1 Countable additivity", "text": "In the work of Terenin and Draper [48] a new aspect is taken up, namely the countable additivity of probabilities, which has several equivalent definitions linked to its name, is that for all events C and all kinds of mutually fragmented events (egg) that we actually need to know (Ei | C) = P (Ai | C) = 0, and they claim that it is trivially equivalent to the previous definition. The latter seems more comprehensible than the first and could possibly serve as a \"compelling assumption\" within the Cox / Jaynes framework, as approximated by the case in [48].Although one usually assumes or postulates that this assumption is fulfilled (as others do)."}, {"heading": "8.2 Partially ordered domains and robustness", "text": "This year is the highest in the history of the country."}, {"heading": "8.2.1 Representing rings as subdirect sums", "text": "This year it is more than ever before."}, {"heading": "8.2.2 Robustness examples", "text": "In fact, the fact is that most of them are able to determine themselves how they have behaved, and that they are able to determine themselves, to determine what they want."}, {"heading": "8.3 Philosophy", "text": "A number of philosophical papers have appeared on the justification of research based on Cox's and de Finettis. An article by John D Norton [35] requires assumptions in several groups, gives counter arguments to some of them, and suggests that each group is selected according to the needs of each individual application. This seems a reasonable idea, but it takes a lot of effort to find out what these subgroups actually mean in terms of the resulting uncertainty, and my experience is that finding the specific needs in an area is difficult as the game is really compelling to make a decision already made."}, {"heading": "A Proof of Theorem 1", "text": "Let us remember the definition of an ordered field: It is a structure R = (D, <, \u00b7, 1, 0), where D is a domain ranging from <, \u00b7 and + are total functions from D2 to D that meet the properties of associativity and symmetry, and where \u00b7 b \u00b7 distributions exceed +. Furthermore, it has an additive inversion, i.e. the equation a + x = b can be solved for x, and the equation a \u00b7 x = b can be solved for x if a 6 = 0. The element 1 of D is a unit for \u00b7 and 0 is a unit for +. The function + increases and increases for arguments that are larger (by <) than 0. Fields are special cases of rings and integral domains. An ordered integral domain fulfills the rules of a field, except that we have no solubility for x of a \u00b7 x = b.We will show how an ordered plausibility space is nested into an ordered field."}, {"heading": "B Proof of Theorem 2", "text": "Most of the properties of an ordered plausibility space are direct consequences of our stated assumptions. The non-trivial part is to show that the given laws must apply to F, G, and S. This follows from a sequence of lemmas, each showing how an algebraic law follows the corresponding law of propositional logic. We only specify them and prove some of them: Lemma 15 For all x x x x x x D, S (x)) = x.Proof: If x = A | B, then x = B = A | B = S (x).Lemma 16 For all x, y, z, and D (x \u00b7 y) \u00b7 z) = x \u00b7 D (y \u00b7 z) = (y \u00b7 z).Proof: If we have worked out a model in which a \u00b7 (b \u00b7 c) \u00b7 c occurs for some plausibility a, b, and c, then we will not accept two."}], "references": [{"title": "Lectures on Functional Equations and their Applications", "author": ["J. Acz\u00e9l"], "venue": "Academic Press,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1966}, {"title": "Probability and the logic of conditionals", "author": ["E. Adams"], "venue": "J. Hintikka and P. Suppes, editors, Aspects of Inductive Logic, pages 265\u2013316. North Holland, Amsterdam,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1966}, {"title": "Learning in prevision space", "author": ["S. Arnborg"], "venue": "Gert de Cooman, Fabio G. Cozman, Serafin Moral, and Peter Walley, editors, Proceedings of the First International Symposium on Imprecise Probabilities and their Applications, pages 8\u201314. Gent University,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Bayes rules in finite models", "author": ["S. Arnborg", "G. Sj\u00f6din"], "venue": "Proc. European Conference on Artificial Intelligence, pages 571\u2013575, Berlin,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "On the foundations of Bayesianism", "author": ["S. Arnborg", "G. Sj\u00f6din"], "venue": "Ali Mohammad-Djarafi, editor, Bayesian Inference and Maximum Entropy Methods in Science and Engineering, 20th International Workshop, Gif-sur-Yvette, 2000, pages 61\u201371. American Institute of Physics,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Robust Bayesianism: Relation to evidence theory", "author": ["Stefan Arnborg"], "venue": "Journal of Advances in Information Fusion,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Nonmonotonic reasoning, conditional objects and possibility theory", "author": ["S. Benferhat", "D. Dubois", "H. Prade"], "venue": "Artificial Intelligence, 92:259\u2013 276,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1997}, {"title": "Belief functions and default reasoning", "author": ["S. Benferhat", "A. Saffiotti", "P. Smets"], "venue": "Artificial Intelligence, 122:1\u201369,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2000}, {"title": "Subdirect unions in universal algebra", "author": ["G. Birkhoff"], "venue": "Bull. Amer. Math. Soc., 50,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1944}, {"title": "A case of combination of evidence in the Dempster-Shafer theory inconsistent with evaluation of probabilities", "author": ["Andrzej K. Brodzik", "Robert H. Enders"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "On Numbers and Games", "author": ["J.H. Conway"], "venue": "Academic Press,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1976}, {"title": "Probability, frequency, and reasonable expectation", "author": ["R.T. Cox"], "venue": "Am. Jour. Phys., 14:1\u201313,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1946}, {"title": "Identical foundation of probability theory and fuzzy set theory", "author": ["D. de Brucq", "O. Colot", "A.Sombo"], "venue": "FUSION", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Upper and lower probabilities induced by a multi-valued mapping", "author": ["A.P. Dempster"], "venue": "Annals of Mathematical Statistics, 38:325\u2013339,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1967}, {"title": "Theories of Probability", "author": ["T.L. Fine"], "venue": "Academic Press,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1973}, {"title": "The Boxer, the Wrestler, and the Coin Flip: A paradox of robust Bayesian inference and belief functions", "author": ["Andrew Gelman"], "venue": "The American Statistician,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "On the scoring approach to admissibility of uncertainty measures in expert systems", "author": ["I. Goodman", "H.T. Nguyen", "G. Rogers"], "venue": "J. Math. Analysis Appl., 159:550\u2013594,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1991}, {"title": "A counterexample to theorems of Cox and Fine", "author": ["J. Halpern"], "venue": "Journal of AI research, 10:67\u201385,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Cox\u2019s theorem revisited", "author": ["J. Halpern"], "venue": "Journal of AI research, 11:429\u2013435,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1999}, {"title": "Scaled boolean algebras", "author": ["M. Hardy"], "venue": "Advances in Applied Mathematics, 29:243\u2013292,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2002}, {"title": "Toward a probabilistic formalization of case-based inference", "author": ["E. H\u00fcllermeier"], "venue": "D. Thomas, editor, Proceedings of the 16th International Joint  Conference on Artificial Intelligence (IJCAI-99- Vol1), pages 248\u2013253, S.F., July 31\u2013August 6", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Ethics", "author": ["D.S. Hutchinson"], "venue": "P. Barnes, editor, Aristotle, Cambridge,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "Probability Theory: The Logic of Science", "author": ["E.T. Jaynes"], "venue": "Cambridge University Press,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}, {"title": "Recognition-primed decisions", "author": ["G.A. Klein"], "venue": "W. Rouse, editor, Advances in Man-Machine systems research, pages 47\u201392, Greenwich,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1989}, {"title": "Intuitive probability on finite sets", "author": ["C.H. Kraft", "J.W. Pratt", "A. Seidenberg"], "venue": "Annals of Mathematical Statistics, 30:408\u2013419,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1959}, {"title": "Bayesian Statistics: a Review", "author": ["D.V. Lindley"], "venue": "SIAM,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1971}, {"title": "Scoring rules and the inevitability of probability (with discussion)", "author": ["D.V. Lindley"], "venue": "Internat. Stat. Rev, 50:1\u201326,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1982}, {"title": "Algebra", "author": ["S. MacLane", "G. Birkhoff"], "venue": "The MacMillan Company, New York,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1967}, {"title": "Subdirect sums of rings", "author": ["Neal H. McCoy"], "venue": "Bull. Amer. Math. Soc.,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1947}, {"title": "Subrings of direct sums", "author": ["N.H. McCoy"], "venue": "Amer. J. Math., 60,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1938}, {"title": "Theory of Rings", "author": ["N.H. McCoy"], "venue": "McMillan Company,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1964}, {"title": "Radically Elementary Probability Theory", "author": ["E. Nelson"], "venue": "Princeton University Press,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1987}, {"title": "Probability disassembled", "author": ["John D. Norton"], "venue": "British Journal for the Philosophy of Science,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2007}, {"title": "The Uncertain Reasoner\u2019s Companion", "author": ["J.B. Paris"], "venue": "Cambridge University Press,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1994}, {"title": "Rough Sets", "author": ["Z. Pawlak"], "venue": "Kluwer, Dordrecht,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1992}, {"title": "Pattern Recognition and Neural Networks", "author": ["B. Ripley"], "venue": "Cambridge University Press,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1996}, {"title": "Conditioning, likelihood and coherence: A review of some foundational concepts", "author": ["J. Robins", "L. Wasserman"], "venue": "J. American Statistical Ass., 95:1340\u20131345,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2000}, {"title": "Introduction to Model Theory and to the Metamathematics of Algebra", "author": ["A. Robinson"], "venue": "North- Holland,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1963}, {"title": "Foundations of Statistics", "author": ["L.J. Savage"], "venue": "John Wiley & Sons, New York,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1954}, {"title": "Probability disassembled", "author": ["Schervish", "Seidenfeld", "Kadane"], "venue": "Z Wahrscheinlichkeitstheorie,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1984}, {"title": "Convex extensions of partially ordered rings", "author": ["Niels Schwartz"], "venue": "In Ge\u0301ome\u0301trie alge\u0301brique et analytique re\u0301elle,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2004}, {"title": "A mathematical theory of evidence", "author": ["G. Shafer"], "venue": "Princeton University Press,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1976}, {"title": "Probability Theory \u2013 it\u2019s only a Game", "author": ["G Shafer", "V. Vovk"], "venue": "MIT Press,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2001}, {"title": "Logic", "author": ["R. Smith"], "venue": "P. Barnes, editor, Aristotle, Cambridge,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1995}, {"title": "The vulnerability of the transferable belief model to Dutch books", "author": ["P. Snow"], "venue": "Artificial Intelligence, 105:345\u2013354,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1998}, {"title": "Rigorizing and Extending the Cox-Jaynes Derivation of Probability: Implications for Statistical Practice", "author": ["Alexander Terenin", "David Draper"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2015}, {"title": "Measures of uncertainty in expert systems", "author": ["P. Walley"], "venue": "Artificial Intelligence, 83:1\u201358,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1996}, {"title": "A logic of extended probability", "author": ["N. Wilson"], "venue": "Gert de Cooman, Fabio G. Cozman, Serafin Moral, and Peter Walley, editors, Proceedings of the First International Symposium on Imprecise Probabilities and their Applications, pages 397\u2013 404. Gent University,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1999}, {"title": "The roles of fuzzy logic and soft computing in the conception, design and deployment of intelligent systems", "author": ["L.A. Zadeh"], "venue": "Lecture Notes in Computer Science, 1198:183\u2013210,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1997}], "referenceMentions": [{"referenceID": 11, "context": "We consider plausibility spaces of the type defined by Cox[13], with auxiliary functions F , S and G used for computing plausibilities of conjunctions, complements and disjunctions, respectively.", "startOffset": 58, "endOffset": 62}, {"referenceID": 0, "context": "Standard probability is one possible plausibility space, where the domain is the real numbers in [0, 1] and the functions F and G are multiplication and addition, respectively.", "startOffset": 97, "endOffset": 103}, {"referenceID": 36, "context": "The auxiliary argumentation required to support our claims is similar to inference principles in statistics, like the Sufficiency, Likelihood and Conditionality principles[39].", "startOffset": 171, "endOffset": 175}, {"referenceID": 24, "context": "There are two papers that analyze a similar question and lead to different but related and compatible conclusions, namely Kraft et al[27] and Hardy[22].", "startOffset": 133, "endOffset": 137}, {"referenceID": 19, "context": "There are two papers that analyze a similar question and lead to different but related and compatible conclusions, namely Kraft et al[27] and Hardy[22].", "startOffset": 147, "endOffset": 151}, {"referenceID": 43, "context": "The methods of definition and induction are attributed, by Aristotle, to Socrates[46], and were developed further by Aristotle and the Stoic philosophers.", "startOffset": 81, "endOffset": 85}, {"referenceID": 21, "context": "Nevertheless, Aristotle is the first to give a surviving qualitative version of the Bayesian decision making principle in his Nichomachean ethics[24]: \u201c Find out what you think is a good life, and consider the probabilities of your possible actions to achieve this.", "startOffset": 145, "endOffset": 149}, {"referenceID": 38, "context": "The plausibility assignment leading to such a situation is considered incoherent, and under various assumptions several arguments exist that end up in concluding that probability or a set of probability distributions is the only coherent plausibility space [41, 28, 15, 45].", "startOffset": 257, "endOffset": 273}, {"referenceID": 25, "context": "The plausibility assignment leading to such a situation is considered incoherent, and under various assumptions several arguments exist that end up in concluding that probability or a set of probability distributions is the only coherent plausibility space [41, 28, 15, 45].", "startOffset": 257, "endOffset": 273}, {"referenceID": 42, "context": "The plausibility assignment leading to such a situation is considered incoherent, and under various assumptions several arguments exist that end up in concluding that probability or a set of probability distributions is the only coherent plausibility space [41, 28, 15, 45].", "startOffset": 257, "endOffset": 273}, {"referenceID": 11, "context": "We will use here the alternative approach devised by Cox[13] which avoids the betting scenario and instead analyses how plausibilities of combined events can be defined, and what properties the plausibility combination functions must have in order to avoid that an events plausibility will depend on which of several possible derivations is used.", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "Cox[13] assumes that the domain of plausibility values is an interval of real values, which without loss of generality can be assumed to be [0, 1], with 0 for falsity and 1 for truth.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "Cox[13] assumes that the domain of plausibility values is an interval of real values, which without loss of generality can be assumed to be [0, 1], with 0 for falsity and 1 for truth.", "startOffset": 140, "endOffset": 146}, {"referenceID": 0, "context": "We can state an assumption made implicitly by Cox here (the function G was introduced by Acz\u00e9l[1] in a related investigation):", "startOffset": 94, "endOffset": 97}, {"referenceID": 34, "context": "In rough and fuzzy set theory[37, 51], the meanings of symbols are taken to be ambiguous, in the sense that even with full information we cannot definitely say, e.", "startOffset": 29, "endOffset": 37}, {"referenceID": 48, "context": "In rough and fuzzy set theory[37, 51], the meanings of symbols are taken to be ambiguous, in the sense that even with full information we cannot definitely say, e.", "startOffset": 29, "endOffset": 37}, {"referenceID": 46, "context": "The ambiguity problem has in many articles been claimed to be an obstacle to probabilistic uncertainty management[49].", "startOffset": 113, "endOffset": 117}, {"referenceID": 14, "context": "We have now stated the common assumptions of most existing theories of plausibility[17, 15, 13, 41].", "startOffset": 83, "endOffset": 99}, {"referenceID": 11, "context": "We have now stated the common assumptions of most existing theories of plausibility[17, 15, 13, 41].", "startOffset": 83, "endOffset": 99}, {"referenceID": 38, "context": "We have now stated the common assumptions of most existing theories of plausibility[17, 15, 13, 41].", "startOffset": 83, "endOffset": 99}, {"referenceID": 11, "context": "Several papers show, with important differences in detail, that every coherent belief set is equivalent to a probability model[15, 13, 41, 29].", "startOffset": 126, "endOffset": 142}, {"referenceID": 38, "context": "Several papers show, with important differences in detail, that every coherent belief set is equivalent to a probability model[15, 13, 41, 29].", "startOffset": 126, "endOffset": 142}, {"referenceID": 26, "context": "Several papers show, with important differences in detail, that every coherent belief set is equivalent to a probability model[15, 13, 41, 29].", "startOffset": 126, "endOffset": 142}, {"referenceID": 16, "context": "The coherence concept can also be applied to some domains not totally but partially ordered, and Goodman, Ngyuen and Rogers[19] show that some plausibilty measures not coherent under the total order assumption, among others the standard version of DS-theory, are coherent under the latter assumption.", "startOffset": 123, "endOffset": 127}, {"referenceID": 12, "context": "Despite the subtle distinction, the weaker assumption would lead to completely different conclusions[14] since non-strict monotonicity does not entail cancellation laws.", "startOffset": 100, "endOffset": 104}, {"referenceID": 17, "context": "As an example, a model is discussed by Halpern[20] that has only a few events.", "startOffset": 46, "endOffset": 50}, {"referenceID": 11, "context": "In [13], it is plainly assumed (as pointed out in [47]) that the auxiliary function F has certain regularity properties:", "startOffset": 3, "endOffset": 7}, {"referenceID": 44, "context": "In [13], it is plainly assumed (as pointed out in [47]) that the auxiliary function F has certain regularity properties:", "startOffset": 50, "endOffset": 54}, {"referenceID": 0, "context": "Associativity and differentiability assumption: The function F is defined on [0, 1], and is associative and twice continously differentiable; the auxiliary function S is continuously differentiable and S(S(x)) = x", "startOffset": 77, "endOffset": 83}, {"referenceID": 11, "context": "The differentiability part is implicit \u2013 as was common when Cox wrote his paper \u2013 but is a standard assumption made to justify switching the order of differentiation which occurs in the derivations of [13], and also in [25].", "startOffset": 201, "endOffset": 205}, {"referenceID": 22, "context": "The differentiability part is implicit \u2013 as was common when Cox wrote his paper \u2013 but is a standard assumption made to justify switching the order of differentiation which occurs in the derivations of [13], and also in [25].", "startOffset": 219, "endOffset": 223}, {"referenceID": 17, "context": "In the criticisms of Cox\u2019s work, this assumption has either been assumed not to exist[20, 21] or been ignored[36].", "startOffset": 85, "endOffset": 93}, {"referenceID": 18, "context": "In the criticisms of Cox\u2019s work, this assumption has either been assumed not to exist[20, 21] or been ignored[36].", "startOffset": 85, "endOffset": 93}, {"referenceID": 33, "context": "In the criticisms of Cox\u2019s work, this assumption has either been assumed not to exist[20, 21] or been ignored[36].", "startOffset": 109, "endOffset": 113}, {"referenceID": 14, "context": "these are somewhat glossed over, the main exceptions being [9, 17, 41, 49].", "startOffset": 59, "endOffset": 74}, {"referenceID": 38, "context": "these are somewhat glossed over, the main exceptions being [9, 17, 41, 49].", "startOffset": 59, "endOffset": 74}, {"referenceID": 46, "context": "these are somewhat glossed over, the main exceptions being [9, 17, 41, 49].", "startOffset": 59, "endOffset": 74}, {"referenceID": 0, "context": "4,5]: For every conditional event there exists a standard event with the same plausibility, and for every number r \u2208 [0, 1] there is a standard event with probability r.", "startOffset": 117, "endOffset": 123}, {"referenceID": 46, "context": "Embeddability assumption[49]: Inference should not depend on how the events participating in calculations are embedded in a larger event plausibility system.", "startOffset": 24, "endOffset": 28}, {"referenceID": 33, "context": "An alternative assumption used to derive Cox\u2019s result is given by Paris[36]:", "startOffset": 71, "endOffset": 75}, {"referenceID": 33, "context": "Denseness assumption[36]: For all real values x, y, z and each \u01eb > 0, there are events A, B, C such that |(A|BCD)\u2212 x|, |(B|CD)\u2212 y| and |(C|D)\u2212 z| are all less than \u01eb.", "startOffset": 20, "endOffset": 24}, {"referenceID": 17, "context": "In response to [20], we developed very weak assumptions binding the different parts of a system of events together[4, 5].", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "In response to [20], we developed very weak assumptions binding the different parts of a system of events together[4, 5].", "startOffset": 114, "endOffset": 120}, {"referenceID": 4, "context": "In response to [20], we developed very weak assumptions binding the different parts of a system of events together[4, 5].", "startOffset": 114, "endOffset": 120}, {"referenceID": 3, "context": "Refinability assumption*[4]: In a plausibility model with a conditional event of plausibility p, it must be possible to introduce a new subcase B of a non-false event A with plausibility value p given to B|A.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "Somewhat surprisingly, Cox\u2019s result on rescalability of the plausibility space to standard probability follows from refinability and the assumptions in section 2 for models that have a finite number of plausibility values and an ordered plausibility space[4].", "startOffset": 255, "endOffset": 258}, {"referenceID": 4, "context": "Even more surprisingly, the same result cannot be proved for infinite plausibility spaces (non-provability follows from a counter-example[5]).", "startOffset": 137, "endOffset": 140}, {"referenceID": 1, "context": "This idea goes back to Adams[2] and has been found to give a very basic uncertainty management that seems to incorporate many uncertainty calculi as special cases (several are analyzed using extended but not necessarily Bayesian probability in [7]).", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "This idea goes back to Adams[2] and has been found to give a very basic uncertainty management that seems to incorporate many uncertainty calculi as special cases (several are analyzed using extended but not necessarily Bayesian probability in [7]).", "startOffset": 244, "endOffset": 247}, {"referenceID": 47, "context": "The combination of robust and extended probability has been analyzed by Wilson[50].", "startOffset": 78, "endOffset": 82}, {"referenceID": 4, "context": "Our motivation for accepting extended probability is the existence of infinite plausibility models that are refinable and embedded in the real numbers, but whose plausibility spaces are not rescalable to standard probability[5].", "startOffset": 224, "endOffset": 227}, {"referenceID": 4, "context": "Closedness assumption*[5]: The functions F , S and G have the following additional properties:", "startOffset": 22, "endOffset": 25}, {"referenceID": 10, "context": "There are many ordered fields that are superfields of the reals, and there is even a unique maximal ordered field No, described by Conway[12].", "startOffset": 137, "endOffset": 141}, {"referenceID": 37, "context": "The concepts of infinitesimals and infinite numbers in non-standard analysis[40] are closely related to extended probability.", "startOffset": 76, "endOffset": 80}, {"referenceID": 2, "context": "Even simple things cannot easily be done with such models[3].", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "Is extended probability needed or is standard probability adequate? Extended probability is not completely unavoidable, in the sense that every finite extended probability model is equivalent to a standard probability model[4].", "startOffset": 223, "endOffset": 226}, {"referenceID": 23, "context": "It seems clear that there is a phase in cognitive assessments where qualitative and order-of-magnitude reasoning is done[26], followed by a quantitative phase where more quantitative reasoning occurs.", "startOffset": 120, "endOffset": 124}, {"referenceID": 6, "context": "In AI reasoning research, many non-probabilistic methods have been proposed, and it seems as if many of them can be described in terms of extended probability[7, 8].", "startOffset": 158, "endOffset": 164}, {"referenceID": 7, "context": "In AI reasoning research, many non-probabilistic methods have been proposed, and it seems as if many of them can be described in terms of extended probability[7, 8].", "startOffset": 158, "endOffset": 164}, {"referenceID": 31, "context": "Although no immediate reaction followed from the user communities, this is still a promising direction[34].", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "Archimedean assumption: Fine[17] assumes that for every non-zero probability e, with ne = G((n \u2212 1)e, e) and 1\u00b7e = e, there is anN such thatNe > S(e).", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "Separability assumption: Arnborg and Sj\u00f6din[5] define a separable model as one in which, for every x < y and c, there are n, m such that x < c < y, with x = F (x, x) and x = x.", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "This is introduced as a weaker assumption than continuity of the auxiliary function F introduced in [1].", "startOffset": 100, "endOffset": 103}, {"referenceID": 20, "context": "There is no principled reason why models used could not be based on other types of models like neural networks, linguistic coding or case based reasoning, and indeed efforts have been made to view these techniques as special types of Bayesian models[23, 38].", "startOffset": 249, "endOffset": 257}, {"referenceID": 35, "context": "There is no principled reason why models used could not be based on other types of models like neural networks, linguistic coding or case based reasoning, and indeed efforts have been made to view these techniques as special types of Bayesian models[23, 38].", "startOffset": 249, "endOffset": 257}], "year": 2015, "abstractText": "We present and examine a result related to uncertainty reasoning, namely that a certain plausibility space of Cox\u2019s type can be uniquely embedded in a minimal ordered field. This, although a purely mathematical result, can be claimed to imply that every rational method to reason with uncertainty must be based on sets of extended probability distributions, where extended probability is standard probability extended with infinitesimals. This claim must be supported by some argumentation of non-mathematical type, however, since pure mathematics does not tell us anything about the world. We propose one such argumentation, and relate it to results from the literature of uncertainty and statistics. In an added retrospective section we discuss some developments in the area regarding countable additivity, partially ordered domains and robustness, and philosophical stances on the Cox/Jaynes approach since 2003. We also show that the most general partially ordered plausibility calculus embeddable in a ring can be represented as a set of extended probability distributions or, in algebraic terms, is a subdirect sum of ordered fields. In other words, the robust Bayesian approach is universal. This result is exemplified by relating Dempster-Shafer\u2019s evidence theory to robust Bayesian analysis.", "creator": "LaTeX with hyperref package"}}}