{"id": "1511.07710", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Nov-2015", "title": "Searching for Objects using Structure in Indoor Scenes", "abstract": "To identify the location of objects of a particular class, a passive computer vision system generally processes all the regions in an image to finally output few regions. However, we can use structure in the scene to search for objects without processing the entire image. We propose a search technique that sequentially processes image regions such that the regions that are more likely to correspond to the query class object are explored earlier. We frame the problem as a Markov decision process and use an imitation learning algorithm to learn a search strategy. Since structure in the scene is essential for search, we work with indoor scene images as they contain both unary scene context information and object-object context in the scene. We perform experiments on the NYU-depth v2 dataset and show that the unary scene context features alone can achieve a significantly high average precision while processing only 20-25\\% of the regions for classes like bed and sofa. By considering object-object context along with the scene context features, the performance is further improved for classes like counter, lamp, pillow and sofa.", "histories": [["v1", "Tue, 24 Nov 2015 14:05:28 GMT  (11596kb,D)", "http://arxiv.org/abs/1511.07710v1", "Appeared in British Machine Vision Conference (BMVC) 2015"]], "COMMENTS": "Appeared in British Machine Vision Conference (BMVC) 2015", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["varun k nagaraja", "vlad i morariu", "larry s davis"], "accepted": false, "id": "1511.07710"}, "pdf": {"name": "1511.07710.pdf", "metadata": {"source": "CRF", "title": "NAGARAJA et al.: SEARCHING FOR OBJECTS USING STRUCTURE IN INDOOR SCENES 1 Searching for Objects using Structure in Indoor Scenes", "authors": ["Varun K. Nagaraja", "Vlad I. Morariu", "Larry S. Davis"], "emails": ["varun@umiacs.umd.edu", "morariu@umiacs.umd.edu", "lsd@umiacs.umd.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of us are able to survive on our own without having to orient ourselves in a different direction."}, {"heading": "2 Related Work", "text": "Many techniques reduce the number of image windows to limit the computation time for object recognition. For example, object suggestion techniques [4, 16] rank regions in an image based on their likelihood of containing an object. Ranking can be used to prioritize regions for operating an object classifier, depending on the available computation budget. Such object suggestion techniques only use low image information and do not use the scene structure. Some techniques use the classifier iteratively in some windows and find the next set of windows to be processed based on the feedback of the classifier and / or the spatial context. Lampert et al al. [11] trim the window space using a branch and bound algorithm. Butko and Movellan [5] use a partially observable Markov decision process to set a digital fovea (a center of fixation) to identify a single target in an image that uses no spatial contexts."}, {"heading": "3 Sequential Exploration", "text": "The most common formalism for sequential decision-making is the Markov Decision Process (MDP). An MDP is characterized by a series of states that take a series of measures that maximize the cumulative function of reward. If the transition probabilities are unknown, reinforcement learning techniques are used to interact with the problem and find examples of the probabilities. Our problem is to locate objects of a query class (q) by exploring as few image regions as possible. Let R determine the number of indices of the regions in the image and t correspond to a step index. Let Rte determine the set of indices of the image regions studied and R\\ Rte the set of indices of the unexplored image regions in one step."}, {"heading": "3.1 Data subset selection", "text": "Due to the presence of a large number of background regions, the training process can become very slow. Therefore, we need to select a subset of background regions so that the training time becomes tractable while maintaining performance. A popular approach to tracking the background is hard negative mining, an iterative process in which the training data is progressively enriched with the false positive examples produced by the classifier in an iteration. Instead, we use a data subset selection technology motivated by the theory of Optimal Experiment Design (OED), which is motivated by the theory of Optimal Experiment Design (OED). In the face of a linear regression model, the goal of the OED is to select samples in such a way that the variance in the regression coefficients is minimized. A smaller variance in the coefficients indicates that the prediction error on the test set is low and the linear regression data does not exceed the training model with such a sub-order."}, {"heading": "4 Experiments and Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Dataset", "text": "We demonstrate our approach using the NYU depth v2 [15] dataset. We use the RCNN-Depth module from Gupta et al. [9] for the region classification. Your region suggestion module is a modified Multiscale Combinatorial Grouping (MCG) [4] technique with depth characteristics. Your feature extraction module is RCNN [7], which includes CNNs that match the depth images. The dataset is divided into three partitions - 381 images for the training, 414 images for the validation and 654 images for the test. As RCNN is trained on the training splitter, the performance of the detectors on the images of the training set is extremely good and does not reflect the behaviour of the detectors on the test set. Therefore, we run the detectors on the validation set, get soil truth markers for the detections, and this set forms the training set for learning search strategies."}, {"heading": "4.2 Sequential Exploration", "text": "Dre rf\u00fc rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the r"}, {"heading": "5 Conclusion", "text": "We have proposed a search method for detecting objects of a particular class in an image by processing as few image regions as possible. Our experiments show that simple scene context properties of regions can achieve a significantly high average precision after processing only 20-25% of regions for classes such as bed, bedside table and sofa. By including object-object context, performance for classes such as bar, lamp, pillow and sofa continues to improve. Our sequential search process brings a negligible effort compared to the time spent extracting CNN features, so reducing the number of regions directly leads to an increase in the processing speed of the object recognition process."}, {"heading": "6 Acknowledgements", "text": "This research was supported by the contract N00014-13-C-0164 of the Office of Naval Research by a subcontract of the United Technologies Research Center. GPUs used for this research were generously donated by NVIDIA Corporation. We thank Hal Daum\u00e9 III for his help with the Vowpal Wabbit Code and Saurabh Gupta for his help with his RCNN Depth Code."}], "references": [{"title": "Apprenticeship learning via inverse reinforcement learning", "author": ["Pieter Abbeel", "Andrew Y Ng"], "venue": "In ICML,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Searching for objects driven by context", "author": ["Bogdan Alexe", "Nicolas Heess", "YW Teh", "Vittorio Ferrari"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Cost-Sensitive Top-down / Bottom-up Inference for Multiscale Activity Recognition", "author": ["Mohamed R Amer", "Dan Xie", "Mingtian Zhao", "Sinisa Todorovic", "Song-Chun Zhu"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Multiscale Combinatorial Grouping", "author": ["Pablo Arbelaez", "Jordi Pont-Tuset", "Jonathan T Barron", "Ferran Marques", "Jitendra Malik"], "venue": "In CVPR,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Optimal scanning for faster object detection", "author": ["Nicholas J. Butko", "Javier R. Movellan"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Efficient programmable learning to search", "author": ["Hal Daum\u00e9 III", "John Langford", "Stephane Ross"], "venue": "arXiv preprint arXiv:1406.1837,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Ross Girshick", "Jeff Donahue", "Trevor Darrell", "Jitendra Malik"], "venue": "In CVPR,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "An active search strategy for efficient object detection", "author": ["Abel Gonzalez-Garcia", "Alexander Vezhnevets", "Vittorio Ferrari"], "venue": "In CVPR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Learning Rich Features from RGB-D Images for Object Detection and Segmentation", "author": ["Saurabh Gupta", "Ross Girshick", "P Arbel\u00e1ez", "J Malik"], "venue": "In ECCV,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "D-Optimality for Regression Designs: A Review", "author": ["R.C. St. John", "N.R. Draper"], "venue": "NAGARAJA et al.: SEARCHING FOR OBJECTS USING STRUCTURE IN INDOOR SCENES", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1975}, {"title": "Beyond sliding windows: Object localization by efficient subwindow search", "author": ["Christoph H Lampert", "Matthew B Blaschko", "Thomas Hofmann"], "venue": "In CVPR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei a Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski", "Stig Petersen", "Charles Beattie", "Amir Sadik", "Ioannis Antonoglou", "Helen King", "Dharshan Kumaran", "Daan Wierstra", "Shane Legg", "Demis Hassabis"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Optimal Design of Experiments", "author": ["Friedrich Pukelsheim"], "venue": "Society for Industrial and Applied Mathematics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1993}, {"title": "A Reduction of Imitation Learning and Structured Prediction", "author": ["St\u00e9phane Ross", "Geoffrey J Gordon", "J Andrew Bagnell"], "venue": "In AISTATS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Indoor Segmentation and Support Inference from RGBD Images", "author": ["Nathan Silberman", "Pushmeet Kohli", "Derek Hoiem", "Rob Fergus"], "venue": "In ECCV,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}], "referenceMentions": [{"referenceID": 6, "context": "The current prevalent object detection framework [7] is a pipeline of two main stages: the object proposal stage and the feature extraction/classification stage.", "startOffset": 49, "endOffset": 52}, {"referenceID": 11, "context": "The true reward function is unknown for our sequential exploration problem since the underlying distribution from which a spatial arrangement of objects in an image is generated is unknown, analogous to a game generated by a hidden emulator [12].", "startOffset": 241, "endOffset": 245}, {"referenceID": 0, "context": "Learning an optimal policy in such situations is known as imitation learning [1] where an oracle predicts the actions it would take at a state and the search policy learns to imitate the oracle and predict similar actions.", "startOffset": 77, "endOffset": 80}, {"referenceID": 13, "context": "[14] that trains a classifier as the search policy on a dataset of features extracted at states and actions taken by the oracle (labels), where the states are generated by running the policy iteratively over the training data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Hence we illustrate our technique on the indoor scene dataset, NYU depth v2 [15].", "startOffset": 76, "endOffset": 80}, {"referenceID": 8, "context": "[9] showed that RCNN [7] trained with depth information greatly improved object detection performance.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[9] showed that RCNN [7] trained with depth information greatly improved object detection performance.", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "For example, object proposal techniques [4, 16] rank regions in an image based on their likelihood of containing an object.", "startOffset": 40, "endOffset": 47}, {"referenceID": 10, "context": "[11] prune the space of windows using a branch and bound algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Butko and Movellan [5] use a Partially Observable Markov Decision Process to sequentially place a digital fovea (a center of fixation) to detect a single target in an image.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "[2] use only spatial context to choose a set of windows to be processed.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] use both spatial context and the classifier scores of previously explored regions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] propose an explore-exploit strategy that schedules processes of top-down inference using activity context and bottom-up inference using activity parts.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "In imitation learning [1], rather than specifying a reward function, an oracle demonstrates the action to take and the policy learns to imitate the oracle.", "startOffset": 22, "endOffset": 25}, {"referenceID": 13, "context": "[14] propose an imitation learning algorithm called DAgger (Dataset Aggregation) that does not make the i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] where a developer writes a single predict function that encodes the algorithm for the testing stage and the training is done by making repeated calls to this predict function.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "We use a modified MCG [4, 9] for region proposal generation and RCNN-depth [9] for region classification.", "startOffset": 22, "endOffset": 28}, {"referenceID": 8, "context": "We use a modified MCG [4, 9] for region proposal generation and RCNN-depth [9] for region classification.", "startOffset": 22, "endOffset": 28}, {"referenceID": 8, "context": "We use a modified MCG [4, 9] for region proposal generation and RCNN-depth [9] for region classification.", "startOffset": 75, "endOffset": 78}, {"referenceID": 14, "context": "[15] for performing support inference.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Instead we use a data subset selection technique motivated by the theory of Optimal Experiment Design (OED) [13].", "startOffset": 108, "endOffset": 112}, {"referenceID": 9, "context": "The D-optimal criterion [10] is more popular due to the availability of off-the-shelf implementations and also, it simplifies the determinant minimization of an inverse to maximizing the determinant of the covariance matrix.", "startOffset": 24, "endOffset": 28}, {"referenceID": 14, "context": "1 Dataset We demonstrate our approach on the NYU depth v2 dataset [15].", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "[9] for the region classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Their region proposal module is a modified Multiscale Combinatorial Grouping (MCG) [4] technique that incorporates depth features.", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": "Their feature extraction module is RCNN [7] which includes CNNs fine-tuned on the depth images.", "startOffset": 40, "endOffset": 43}], "year": 2015, "abstractText": "To identify the location of objects of a particular class, a passive computer vision system generally processes all the regions in an image to finally output few regions. However, we can use structure in the scene to search for objects without processing the entire image. We propose a search technique that sequentially processes image regions such that the regions that are more likely to correspond to the query class object are explored earlier. We frame the problem as a Markov decision process and use an imitation learning algorithm to learn a search strategy. Since structure in the scene is essential for search, we work with indoor scene images as they contain both unary scene context information and object-object context in the scene. We perform experiments on the NYU-depth v2 dataset and show that the unary scene context features alone can achieve a significantly high average precision while processing only 20-25% of the regions for classes like bed and sofa. By considering object-object context along with the scene context features, the performance is further improved for classes like counter, lamp, pillow and sofa.", "creator": "LaTeX with hyperref package"}}}