{"id": "1511.07788", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Nov-2015", "title": "Spoken Language Translation for Polish", "abstract": "Spoken language translation (SLT) is becoming more important in the increasingly globalized world, both from a social and economic point of view. It is one of the major challenges for automatic speech recognition (ASR) and machine translation (MT), driving intense research activities in these areas. While past research in SLT, due to technology limitations, dealt mostly with speech recorded under controlled conditions, today's major challenge is the translation of spoken language as it can be found in real life. Considered application scenarios range from portable translators for tourists, lectures and presentations translation, to broadcast news and shows with live captioning. We would like to present PJIIT's experiences in the SLT gained from the Eu-Bridge 7th framework project and the U-Star consortium activities for the Polish/English language pair. Presented research concentrates on ASR adaptation for Polish (state-of-the-art acoustic models: DBN-BLSTM training, Kaldi: LDA+MLLT+SAT+MMI), language modeling for ASR &amp; MT (text normalization, RNN-based LMs, n-gram model domain interpolation) and statistical translation techniques (hierarchical models, factored translation models, automatic casing and punctuation, comparable and bilingual corpora preparation). While results for the well-defined domains (phrases for travelers, parliament speeches, medical documentation, movie subtitling) are very encouraging, less defined domains (presentation, lectures) still form a challenge. Our progress in the IWSLT TED task (MT only) will be presented, as well as current progress in the Polish ASR.", "histories": [["v1", "Tue, 24 Nov 2015 16:28:16 GMT  (635kb)", "http://arxiv.org/abs/1511.07788v1", "Marasek K., Wo{\\l}k K., Korzinek D., Brocki {\\L}., Spoken Language Translation for Polish, Proceedings of Forum Acuscticum 2014, Krak\\'ow. arXiv admin note: substantial text overlap witharXiv:1509.08909"]], "COMMENTS": "Marasek K., Wo{\\l}k K., Korzinek D., Brocki {\\L}., Spoken Language Translation for Polish, Proceedings of Forum Acuscticum 2014, Krak\\'ow. arXiv admin note: substantial text overlap witharXiv:1509.08909", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["krzysztof marasek", "{\\l}ukasz brocki", "danijel korzinek", "krzysztof wo{\\l}k", "ryszard gubrynowicz"], "accepted": false, "id": "1511.07788"}, "pdf": {"name": "1511.07788.pdf", "metadata": {"source": "CRF", "title": "Spoken Language Translation for Polish", "authors": ["Krzysztof Marasek", "Krzysztof Wo\u0142k", "Danijel Koroinek", "\u0141ukasz Brocki", "Ryszard Gubrynowicz"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "It is one of the biggest challenges for automatic speech recognition (ASR) and machine translation (MT), with application scenarios ranging from portable translators for tourists, lectures and presentations for translators, to live transmissions of messages and broadcasts with live transmissions. Polish, one of the West Slavic languages as they occur in real life, poses a challenge for statistical machine translation (SMT) and automatic speech recognition (ASR)."}, {"heading": "2. Polish data preparation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Acoustic data", "text": "It is not as if we are in a position to find a solution that helps people to get their problems under control."}, {"heading": "2.2. Monolingual text data", "text": "In order to train language models (LMs), a large collection of text data is required. LMs are required for both ASR and SMT. In ASR, they are used to evaluate hypotheses generated by the decoder, while in SMT, they are used for both languages in the language pair: to analyze and synthesize grammatically correct sentences. In ASR, they should be as large as possible; sizes of hundreds of millions and even billions of tokens are not uncommon for these tasks; the main goal is to present as many words in as many contexts in order to achieve substantial statistical significance; the size of the speech corpus also strongly correlates with the target vocabulary; given the infected nature of the Polish language, the vocabulary for the corresponding problem in English is many times larger. Unfortunately, the amount of digitized text data in Polish is also much smaller than in English, making the quality of such language models even verbatim."}, {"heading": "3. Parallel data preparation", "text": "A parallel corpus contains the same text data in two or more languages. There are several problems with such corpus, and just as in the case of the acoustic corpus, alignment of parallel data streams plays a significant role in the quality of education. Secondly, a system based on film subtitles, because they can be regarded as an example of natural human dialogues. Finally, a system with a broader domain, based on TED lectures, was also prepared. Polish data in the TED talks (15 MB) totaled almost 2 million words, which were not tokenized."}, {"heading": "3.1. Polish stem extraction", "text": "Since the target language was English in the form of normal sentences, it was not necessary to introduce models for transforming the stems into the corresponding grammatical shapes. [8] These tools can be used for: \u2022 tokenization \u2022 morphosyntactic analysis \u2022 text transformation into the presented vectorsThe following two components were also included: \u2022 MACA - a universal framework used to link the various morphological data \u2022 WCRFT - this framework combines conditional random fields and staggered taggingThese tools provide continuous output in XML format. This includes the surface shape of the token, strains and morphosyntactic tags."}, {"heading": "3.2. English data preparation", "text": "The English data preparation was much less complex than the Polish data. We used a tool to clean the English data by eliminating foreign words, strange symbols, etc. Compared to the Polish data, the English data contained significantly fewer errors. However, some problems had to be fixed. The most problematic were parts of text in other languages and strange Unicode symbols."}, {"heading": "4. ASR techniques", "text": "In fact, most of them are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves."}, {"heading": "5. SMT techniques", "text": "A series of experiments were conducted to evaluate different versions of our SMT systems, which included a number of steps: corpora processing, which included: tokenization, purification, factorization, lowercase conversion, splitting, and final cleaning after splitting; tuning for each experiment, which was evaluated using a set of metrics; baseline system, which was performed using the Moses Open Source SMT toolkit with its Experiment Management System (EMS); and SRI Language Modeling Toolkit (SRILM), which was performed with an interpolated version of Kneser Key discrediting (interpolated & linked)."}, {"heading": "5.1. TED results", "text": "The experiments with TED, which were carried out using test data from 2010-2013, are listed in Table III and Table IV for the Polish, English and Polish translations, respectively, and are measured using the metrics BLEU, NIST, TER and METEOR [14]. Note that a lower value of the TER metric is better, while the other metrics are better when their values are higher. BASE stands for basic system without improvements, COR is a system with corrected spelling in Polish data, INF is a system with infinitive forms in Polish, SVO is a system with the subject-verb-object order in a sentence, and BEST stands for the best result we have achieved."}, {"heading": "5.2. EuroParl and OpenSubtitles results", "text": "For the EuroParl and OPUS OpenSubtitles, we conducted experiments with phrase systems and factor systems enriched with POS tags. Compound splitting and true-casing were optional, and some language models were selected based on their perplexity measurement and then interpolated linearly. Table V shows partial results of our experiments. We used the abbreviations E (EuroParl) and O (OpenSubtitles), if there is no additional suffix, this means that test was a phrase-based trained system, suffix F (e.g. TF) means that we used factored model, T refers to data that was genuine, and C means that a compound splitter was used. If the suffix I is, we used unfinished forms of all Polish data, and the suffix S refers to changes in the word system to match the SVO scheme. In EuroParl experiments, suffix L stands for the higher domain number we have achieved by Google + domain translation."}, {"heading": "5.3. EMEA results", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they live."}, {"heading": "5.4. Speech-to-speech results", "text": "Previous experiments looked at the performance of ASR and SMT as individual systems, but ultimately the system should be used in a speech-to-speech way, which means that we would get audio as input and expect text and / or audio in a language other than output; the errors in this process would not only be a sum of errors underlying tasks, as the errors in earlier steps would cause unforeseen consequences for the following. For example, a word missing from the ASR output would cause the SMT system to fail in an unpredictable way; another problem is caused by the fact that SMT expects fully punctuated and uppercase text, but ASR only returns a string of words in smaller font. To measure the performance of the SMT system, we selected three sets of 24 sentences from the Euronews development group: the original hand-checked transcript, the normalized, undotted and lowercase version of the same transcript, and finally the result of ASR."}, {"heading": "6. System setup", "text": "Both the SMT and ASR systems discussed in previous chapters have the ability to perform online calculations and work in near real-time. Therefore, the U-Star project developed a set of standardized protocols specifically for S2S translation. The backend system is based on an XML-like markup language called MCML (Modality Conversion Markup Language), the purpose of which is to convert information from one modality (usually language or text in a particular language) to another. Requests to the system function because REST calls MCML documents that serve as the basis for communication. The system architecture is based on a series of Tomcat servers that forward the information requests from the clients to the respective engines. Organization of the servers is tree-like in structure and allows for swinging when any language is already available."}, {"heading": "7. Results and conclusions", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "Acknowledgement", "text": "The research that led to these results was funded by the Seventh Framework Programme of the European Union (FP7 / 2007-2013) under Funding Agreement No 287658."}], "references": [{"title": "Gubrynowicz, User-centered design for a voice portal, in Aspects of Natural Language", "author": ["Krzysztof Marasek", "\u0141ukasz Brocki", "Danijel Korzinek", "Krzysztof Szklanny", "Ryszard"], "venue": "Processing, pp", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Cylwik, Jurisdic: Polish speech database for taking dictation of legal texts", "author": ["Gra\u017cyna Demenko", "Stefan Grocholewski", "Katarzyna Klessa", "Jerzy Og\u00f3rkiewicz", "Agnieszka Wagner", "Marek Lange", "Daniel Sledzinski", "Natalia"], "venue": "LREC,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "polish-to-english translation system for the iwslt", "author": ["Krzysztof Marasek", "Ted"], "venue": "Proceedings IWSLT 2012,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "A historical perspective of speech recognition", "author": ["Xuedong Huang", "James Baker", "Raj Reddy"], "venue": "Communications of the ACM,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Korpus ipi pan, Wersja wstepna", "author": ["Adam Przepi\u00f3rkowski"], "venue": "Instytut Podstaw Informatyki, Polska Akademia Nauk, Warszawa,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Real-time statistical speech translation, in New Perspectives in Information", "author": ["Krzysztof Wo\u0142k", "Krzysztof Marasek"], "venue": "Systems and Technologies,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Open  source toolkit for statistical machine translation, in Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions", "author": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens", "Moses"], "venue": "Association for Computational Linguistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "The kaldi speech recognition", "author": ["Daniel Povey", "Arnab Ghoshal", "Gilles Boulianne", "Lukas Burget", "Ondrej Glembek", "Nagendra Goel", "Mirko Hannemann", "Petr Motlicek", "Yanmin Qian", "Petr Schwarz"], "venue": "toolkit, in Proc. ASRU,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Polish \u00e2 english speech statistical machine translation systems for the iwslt", "author": ["Krzysztof Wo\u0142k", "Krzysztof Marasek"], "venue": "Proceedings of the 10th International Workshop on Spoken Language Translation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Srilm-an extensible language modeling toolkit", "author": ["Andreas Stolcke"], "venue": "in INTERSPEECH,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Scalable modified Kneser- Ney language model estimation, in Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, So a, Bulgaria", "author": ["Kenneth Heafield", "Clark", "Philipp Koehn"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Alignment of the polish-english parallel text for a statistical machine translation", "author": ["Krzysztof Wo\u0142k", "Krzysztof Marasek"], "venue": "Computer Technology and Application,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Munich- edinburgh-stuttgart submissions of osm systems at wmt13", "author": ["Nadir Durrani", "Alexander Fraser", "Helmut Schmid", "Hassan Sajjad", "Rich\u00e1rd Farkas"], "venue": "Proceedings of the Eighth Workshop on Statistical Machine Translation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Factored translation models", "author": ["Philipp Koehn", "Hieu Hoang"], "venue": "in EMNLP-CoNLL. Citeseer,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Intricacies of collins' parsing model", "author": ["Daniel M Bikel"], "venue": "Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "A simple, fast, and effective reparameterization of ibm model 2., in HLT-NAACL", "author": ["Chris Dyer", "Victor Chahuneau", "Noah A Smith"], "venue": "Citeseer,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "A comparative study of witten bell and kneser-ney smoothing methods for statistical machine translation", "author": ["AS M Mahmudul Hasan", "Saria Islam", "M Arifur Rahman"], "venue": "Journal of Information Technology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Several research projects have emerged in the last couple of years dealing with the topics of automation in the telephony environment [2], transcription of legal documents [3] and recently speech-to- speech translation in different settings [4].", "startOffset": 134, "endOffset": 137}, {"referenceID": 1, "context": "Several research projects have emerged in the last couple of years dealing with the topics of automation in the telephony environment [2], transcription of legal documents [3] and recently speech-to- speech translation in different settings [4].", "startOffset": 172, "endOffset": 175}, {"referenceID": 2, "context": "Several research projects have emerged in the last couple of years dealing with the topics of automation in the telephony environment [2], transcription of legal documents [3] and recently speech-to- speech translation in different settings [4].", "startOffset": 241, "endOffset": 244}, {"referenceID": 3, "context": "A good corpus size is measured in at least tens or hundreds of hours, but significant improvements were noticed with as much as 2000 hours [5].", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "All the language models were trained both well known sources like the IPI PAN corpus [7]", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "The Polish data in the TED talks (15 MB) included almost 2 million words that were not tokenized [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "This included the removal of long sentences (set to 80 tokens) using the Moses toolkit scripts [9].", "startOffset": 95, "endOffset": 98}, {"referenceID": 5, "context": "pl was used [8].", "startOffset": 12, "endOffset": 15}, {"referenceID": 7, "context": "The system used in this paper is based on the Kaldi Speech Recognition toolkit [10], which is a WFST based ASR engine containing many of the state-of- the-art methods and algorithms for ASR, including: cepstral-mean normalization (CMN), linear discriminant analysis (LDA) and maximum likelihood linear transformation (MLLT) feature transformation, vocal tract length normalization (VTLN), subspace Gaussian mixture modelling (SGMM), feature space maximum likelihood linear regression (fMLLR) adaptation, training using maximum mutual information (MMI) criterion and speaker adaptive training (SAT), artificial neural network (ANN) and deep neural net- work (DNN) based models.", "startOffset": 79, "endOffset": 83}, {"referenceID": 8, "context": "The baseline system testing was done using the Moses open source SMT toolkit with its Experiment Management System (EMS) [11].", "startOffset": 121, "endOffset": 125}, {"referenceID": 9, "context": "The SRI Language Modeling Toolkit (SRILM) [12] with an interpolated version of the Kneser-Key discounting (interpolate & kndiscount) was used for 5-gram language model training.", "startOffset": 42, "endOffset": 46}, {"referenceID": 10, "context": "KenLM [13] was used to binarize the language model, with a lexical reordering set to use the msd-bidirectional-fe model.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "They are measured by the BLEU, NIST, TER and METEOR metrics [14].", "startOffset": 60, "endOffset": 64}, {"referenceID": 12, "context": "It combines both translation and reordering, deals with the short and long-distance re- ordering, and does not ask for a reordering limit [15].", "startOffset": 138, "endOffset": 142}, {"referenceID": 13, "context": "We evaluate the part of speech tagged data in correlation with the English language segment as a basis for the factored phrase models [16].", "startOffset": 134, "endOffset": 138}, {"referenceID": 14, "context": "In this case, we applied the Collins [17] statistical parser of the natural language in the Experiment 05.", "startOffset": 37, "endOffset": 41}, {"referenceID": 15, "context": "The Experiment 07 applies Dyer's Fast Align [18], which is actually an alternative for the GIZA++.", "startOffset": 44, "endOffset": 48}, {"referenceID": 16, "context": "The nth order smoothed model is de ned recursively as a linear interpolation between the n-th order maximum likelihood model and the (n-1)th order smooth model [20].", "startOffset": 160, "endOffset": 164}, {"referenceID": 8, "context": "Lastly, for Experiment 12 we used the same settings as for out of domain corpora in IWSLT'13 [11].", "startOffset": 93, "endOffset": 97}], "year": 2015, "abstractText": "Spoken language translation (SLT) is becoming more important in the increasingly globalized world, both from a social and economic point of view. It is one of the major challenges for automatic speech recognition (ASR) and machine translation (MT), driving intense research activities in these areas. While past research in SLT, due to technology limitations, dealt mostly with speech recorded under controlled conditions, today's major challenge is the translation of spoken language as it occurs in real life. Considered application scenarios range from portable translators for tourists, lectures and presentations translation, to broadcast news and shows with live captioning. We would like to present PJIIT's experiences in the SLT gained from the Eu-Bridge 7th framework project and the U-Star consortium activities for the Polish/English language pair. Presented research concentrates on ASR adaptation for Polish (state-of-the-art acoustic models: DBN-BLSTM training, Kaldi: LDA+MLLT+SAT+MMI), language modeling for ASR and MT (text normalization, RNN-based LMs, n-gram model domain interpolation) and statistical translation techniques (hierarchical mod-els, factored translation models, automatic casing and punctuation, comparable and bilingual corpora preparation). While results for the well-de ned domains (phrases for travellers, parliament speeches, medical documentation, movie subtitling) are very encouraging, less de ned domains (presentation, lectures) still form a challenge. Our progress in the IWSLT TED task (MT only) will be presented, as well as current progress in the Polish ASR.", "creator": null}}}