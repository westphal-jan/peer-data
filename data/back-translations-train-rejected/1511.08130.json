{"id": "1511.08130", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Nov-2015", "title": "A Roadmap towards Machine Intelligence", "abstract": "The development of intelligent machines is one of the biggest unsolved challenges in computer science. In this paper, we propose some fundamental properties these machines should have, focusing in particular on communication and learning. We discuss a simple environment that could be used to incrementally teach a machine the basics of natural-language-based communication, as a prerequisite to more complex interaction with human users. We also present some conjectures on the sort of algorithms the machine should support in order to profitably learn from the environment.", "histories": [["v1", "Wed, 25 Nov 2015 17:32:18 GMT  (144kb,D)", "http://arxiv.org/abs/1511.08130v1", null], ["v2", "Fri, 26 Feb 2016 20:03:43 GMT  (146kb,D)", "http://arxiv.org/abs/1511.08130v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["tomas mikolov", "armand joulin", "marco baroni"], "accepted": false, "id": "1511.08130"}, "pdf": {"name": "1511.08130.pdf", "metadata": {"source": "CRF", "title": "A Roadmap towards Machine Intelligence", "authors": ["Tomas Mikolov", "Armand Joulin", "Marco Baroni"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "A machine capable of performing complex tasks without requiring laborious programming would be enormously useful for almost any human effort, from performing mini-jobs to supporting basic research. Given the current availability of powerful hardware and large amounts of machine-readable data, the time seems ripe for the development of intelligent machines. We think that a fundamental reason is that solving AI problems at once is too complex to pursue at once. In recent decades, the computer community has preferred to focus on solving problems that are important for specific applications."}, {"heading": "2 Desiderata for an intelligent machine", "text": "Instead of trying to formally characterize intelligence, here we propose a series of desiderata that we believe are critical to a machine's ability to help itself in its efforts for humans. The guiding principles that we implicitly took into account in formulating desiderata are to minimize the complexity of the machine and maximize the interpretability of its behavior by humans."}, {"heading": "2.1 Ability to communicate", "text": "In fact, it is such that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is"}, {"heading": "2.2 Ability to learn", "text": "symbolic AI research (Haugeland, 1985) was probably based on the assumption that it would be possible to program an intelligent machine largely by hand. We believe that it is indisputable that a machine that is supposed to help us in a variety of scenarios, many of which were not foreseen by its developers, should be equipped with the ability to learn. A machine that does not learn cannot adapt or change on the basis of experience, as it will respond in the same way to a particular situation throughout its life. However, if the machine makes a mistake that we want to correct, it needs to change its behavior - hence learning is a mandatory component. Along with learning, motivation develops. Learning allows the machine to adapt to the external environment and help it produce results that maximize the function defined by its motivation. Since we want to develop machines that are useful to humans, the motivational component should be directly controlled by the communication channel, thus enabling it to produce results that maximize the function defined by its motivation."}, {"heading": "3 A simulated ecosystem to educate commu-", "text": "In this section, we describe a simulated environment that is designed to teach an intelligent machine language and how to use it to learn to operate in the world. The simulated ecosystem should be considered a \"kindergarten\" that provides basic education to intelligent machines, and we want the machines trained in this controlled environment to later be connected to the real world to learn how to help people with their various needs. I / O channels are generated by an automatic mechanism, since complexity should be manageable from the outset, but testing and developing new machine learning techniques would be difficult and slow down. The environment must be challenging enough to force the machine to develop complex learning strategies (essentially, it should \"learn how to learn\"). At the same time, complexity should be manageable, i.e. a person placed in a similar environment should not find it unreasonably difficult to communicate and act within a language that is not yet familiar with the communication that takes place within it, and the communication that is still in a language."}, {"heading": "3.1 High-level description of the ecosystem", "text": "It is one of the greatest challenges in the history of the European Union that the EU Accession Academy, for which the EU Accession Academy has applied, is located."}, {"heading": "3.2 Examples from early stages of the simulation", "text": "The following examples assume that the learner has already learned how to focus attention on the teacher and the repetition of strings, and show how the teacher has learned from these basic skills to solve relatively complex environmental problems by taking advantage of interactive communication.The examples illustrate specific examples from a larger series of studies that include similar templates that include a variety of objects, obstacles, and possible actions.The examples presented do not aim to cover all the learning-enhancing strategies addressed in the ecosystem.In the illustrative exchanges below, we present the input to the learner (messages from the teacher and the environment) as well as the bias addressed by T: and R: respectively in the left column and right column (messages addressed to the teacher)."}, {"heading": "3.3 Interacting with the trained intelligent machine", "text": "Finally, we offer a motivational example of how an intelligent machine trained in our ecosystem could later become useful in the real world. We look at a scenario in which the machine works as an assistant to Alice, an elderly man living alone. Bob is Alice's son, and he also interacts with the machine. We assume that the machine was taught as part of its training on how to issue Internet commands and process their results. In the sample dialog, we give a general idea of how the machine would interact with the Internet without trying to define the syntax of that interaction precisely. Most importantly, the example illustrates how the machine does not store all the knowledge it needs to perform its duties, as it can retrieve useful information from the Web on demand, and the reason that it defines the syntax of that interaction."}, {"heading": "4 Towards the development of intelligent ma-", "text": "In this section, we describe some of our ideas and opinions on how to build intelligent machines that would benefit from the learning environment we describe. Although we do not yet have a concrete proposal on exactly how such machines should be implemented, we will discuss some characteristics and components that we consider necessary to support the desired functionality. We do not claim to be exhaustive, we just want to offer some food for thought. As in the previous sections, we try to keep the complexity of the machine to a minimum, and only look at the characteristics that seem essential."}, {"heading": "4.1 Types of learning", "text": "There are many types of behavior that we collectively call learning, and it is useful to distinguish between them to clarify further discussions. Let's say our goal is to build an intelligent machine that works as a translator between two languages. First, we will teach the machine basic communication skills in our simulated environment so that it can respond to user requests. Then, we will begin to teach it how to translate different words. There are different kinds of learning that happen here. To master basic communication skills, the machine needs to understand the concept of positive and negative reward and develop complex strategies to deal with novel linguistic inputs. This may require the discovery of algorithms, and the ability to remember facts, skills, and even learning strategies."}, {"heading": "4.2 Long-term memory and compositional learning skills", "text": "We see a particular type of long-term memory as a key component of the intelligent machine. This long-term memory should be able to store facts and algorithms that correspond to the skills learned and be accessed on demand. In fact, even the ability to learn should be seen as a set of skills stored in the memory. If the learning skills are triggered by the current situation, they should compose new, permanent structures in the memory from the existing ones. In addition, the machine should have the ability to expand itself. Without being able to store previously acquired facts and skills, the machine could not deal with more trivial mappings, such as the memory of solving a task that was previously encountered. Moreover, it is often the case that the solution to a new task is related to previous ones."}, {"heading": "4.3 Computational properties of intelligent machines", "text": "This year it has come to the point where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase of uncertainty, in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in a phase where we are in which we are in a phase where we are in a phase where we are in a phase where we are in which we are in a phase where we are in which we are in a phase where we are in which we are in a phase where we are in which we are in a phase where we are in a phase where we are in which we are in a phase where we are in which we are in which we are in a phase where we are in which we are in which we are in which we are in a phase where we are in which we are in a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase where we are in which we are in which we are in which we are in which we are in which we are in a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a phase of a"}, {"heading": "5 Related ideas", "text": "This year, it has reached the point where it will be able to leave the country in which it is in order to found a country in which it is able to leave it."}, {"heading": "6 Conclusion", "text": "We defined basic desiderata for an intelligent machine and emphasized learning and communication as its basic skills. Contrary to current machine learning practice, where the emphasis is on modelling individual skills in isolation, we believe that all aspects of intelligence should be dealt with holistically within a single system. We proposed a simulated environment in which the intelligent machine must acquire new facts and skills through communication in natural language. In this environment, the machine must learn to perform increasingly ambitious tasks, naturally inclined to develop complex linguistic and argumentative skills. We also presented some conjectures about the characteristics of the computer system on which the intelligent machine could be based, including learning algorithmic patterns from some examples without strong supervision and developing a long-term memory that would store both data and learned skills. We tried to put this in contrast to the currently accepted paradigms of machine learning, to show that the current techniques we must strive for, and do not suffice with new ones."}, {"heading": "Acknowledgments", "text": "We thank Gemma Boleda, Le \u0301 on Bottou, Yann LeCun, Gabriel Synnaeve, Arthur Szlam, Nicolas Usunier, Laurens van der Maaten, Wojciech Zaremba and others from Facebook's AI research team for many stimulating discussions. An early version of this proposal has been discussed in several research groups since 2013 under the name Incremental Learning of Algorithms (Mikolov, 2013)."}], "references": [{"title": "A framework for learning predictive", "author": ["R. Ando", "T. Zhang"], "venue": null, "citeRegEx": "Ando and Zhang,? \\Q2005\\E", "shortCiteRegEx": "Ando and Zhang", "year": 2005}, {"title": "Curriculum learning", "author": ["Y. Bengio", "J. Louradour", "R. Collobert", "J. Weston"], "venue": "Proceedings of ICML, pages 41\u201348, Montreal, Canada.", "citeRegEx": "Bengio et al\\.,? 2009", "shortCiteRegEx": "Bengio et al\\.", "year": 2009}, {"title": "From machine learning to machine reasoning: an essay", "author": ["L. Bottou"], "venue": "Machine Learning, 94:133\u2013149.", "citeRegEx": "Bottou,? 2014", "shortCiteRegEx": "Bottou", "year": 2014}, {"title": "Learning to win by reading manuals in a Monte-Carlo framework", "author": ["S. Branavan", "D. Silver", "R. Barzilay"], "venue": "Journal of Artificial Intelligence Research, 43:661\u2013704.", "citeRegEx": "Branavan et al\\.,? 2012", "shortCiteRegEx": "Branavan et al\\.", "year": 2012}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Machine Learning, 28:41\u201375.", "citeRegEx": "Caruana,? 1997", "shortCiteRegEx": "Caruana", "year": 1997}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D. Chen", "R. Mooney"], "venue": "Proceedings of AAAI, pages 859\u2013865, San Francisco, CA.", "citeRegEx": "Chen and Mooney,? 2011", "shortCiteRegEx": "Chen and Mooney", "year": 2011}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "Journal of Machine Learning Research, 12:2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Finding structure in time", "author": ["J.L. Elman"], "venue": "Cognitive science, 14(2):179\u2013 211.", "citeRegEx": "Elman,? 1990", "shortCiteRegEx": "Elman", "year": 1990}, {"title": "The Language of Thought", "author": ["J. Fodor"], "venue": "Crowell Press, New York.", "citeRegEx": "Fodor,? 1975", "shortCiteRegEx": "Fodor", "year": 1975}, {"title": "Visual Turing test for computer vision systems", "author": ["D. Geman", "S. Geman", "N. Hallonquist", "L. Younes"], "venue": "Proceedings of the National Academy of Sciences, 112(12):3618\u20133623.", "citeRegEx": "Geman et al\\.,? 2015", "shortCiteRegEx": "Geman et al\\.", "year": 2015}, {"title": "General game playing: Overview of the AAAI competition", "author": ["M. Genesereth", "N. Love", "B. Pell"], "venue": "AI Magazine, 26(2):62\u201372.", "citeRegEx": "Genesereth et al\\.,? 2005", "shortCiteRegEx": "Genesereth et al\\.", "year": 2005}, {"title": "Neural turing machines", "author": ["A. Graves", "G. Wayne", "I. Danihelka"], "venue": "http://arxiv.org/abs/1410.5401.", "citeRegEx": "Graves et al\\.,? 2014", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Learning to transduce with unbounded memory", "author": ["E. Grefenstette", "K. Hermann", "M. Suleyman", "P. Blunsom"], "venue": "Proceedings of NIPS, Montreal, Canada. In press. 35", "citeRegEx": "Grefenstette et al\\.,? 2015", "shortCiteRegEx": "Grefenstette et al\\.", "year": 2015}, {"title": "Artificial Intelligence: The Very Idea", "author": ["J. Haugeland"], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Haugeland,? 1985", "shortCiteRegEx": "Haugeland", "year": 1985}, {"title": "Surfaces and Essences: Analogy as the Fuel and Fire of Thinking", "author": ["D. Hofstadter", "E. Sander"], "venue": "Basic Books, New York.", "citeRegEx": "Hofstadter and Sander,? 2013", "shortCiteRegEx": "Hofstadter and Sander", "year": 2013}, {"title": "Inferring algorithmic patterns with stackaugmented recurrent nets", "author": ["A. Joulin", "T. Mikolov"], "venue": "Proceedings of NIPS, Montreal, Canada. In press.", "citeRegEx": "Joulin and Mikolov,? 2015", "shortCiteRegEx": "Joulin and Mikolov", "year": 2015}, {"title": "Reinforcement learning: A survey", "author": ["L.P. Kaelbling", "M.L. Littman", "A.W. Moore"], "venue": "Journal of artificial intelligence research, pages 237\u2013 285.", "citeRegEx": "Kaelbling et al\\.,? 1996", "shortCiteRegEx": "Kaelbling et al\\.", "year": 1996}, {"title": "Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Thought", "author": ["G. Lakoff", "M. Johnson"], "venue": "Basic Books, New York.", "citeRegEx": "Lakoff and Johnson,? 1999", "shortCiteRegEx": "Lakoff and Johnson", "year": 1999}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, 521:436\u2013444.", "citeRegEx": "LeCun et al\\.,? 2015", "shortCiteRegEx": "LeCun et al\\.", "year": 2015}, {"title": "The Winograd schema challenge", "author": ["H.J. Levesque", "E. Davis", "L. Morgenstern"], "venue": "Proceedings of KR, pages 362\u2013372, Rome, Italy.", "citeRegEx": "Levesque et al\\.,? 2012", "shortCiteRegEx": "Levesque et al\\.", "year": 2012}, {"title": "Symbol interdependency in symbolic and embodied cognition", "author": ["M. Louwerse"], "venue": "Topics in Cognitive Science, 3:273\u2013302.", "citeRegEx": "Louwerse,? 2011", "shortCiteRegEx": "Louwerse", "year": 2011}, {"title": "Walk the talk: Connecting language, knowledge, and action in route instructions", "author": ["M. MacMahon", "B. Stankiewicz", "B. Kuipers"], "venue": "Proceedings of AAAI, pages 1475\u20131482, Boston, MA.", "citeRegEx": "MacMahon et al\\.,? 2006", "shortCiteRegEx": "MacMahon et al\\.", "year": 2006}, {"title": "Incremental learning of algorithms", "author": ["T. Mikolov"], "venue": "Unpublished manuscript.", "citeRegEx": "Mikolov,? 2013", "shortCiteRegEx": "Mikolov", "year": 2013}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A. Rusu", "J. Veness", "M. Bellemare", "A. Graves", "M. Riedmiller", "A. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis"], "venue": "Nature, 518:529\u2013533.", "citeRegEx": "Mnih et al\\.,? 2015", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Minds, Brains, and Computers: Perspectives in Cognitive Science and Artificial Intelligence", "author": ["R. Morelli", "M. Brown", "D. Anselmi", "K. Haberlandt", "D. Lloyd"], "venue": null, "citeRegEx": "Morelli et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Morelli et al\\.", "year": 1992}, {"title": "Language understanding for text-based games using deep reinforcement learning", "author": ["K. Narasimhan", "T. Kulkarni", "R. Barzilay"], "venue": "Proceedings of EMNLP, pages 1\u201311, Lisbon, Portugal.", "citeRegEx": "Narasimhan et al\\.,? 2015", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Software agents: An overview", "author": ["H. Nwana"], "venue": "Knowledge Engineering Review, 11(2):1\u201340.", "citeRegEx": "Nwana,? 1996", "shortCiteRegEx": "Nwana", "year": 1996}, {"title": "A field guide to genetic programming", "author": ["R. Poli", "W. Langdon", "N. McPhee", "J. Koza"], "venue": "http://www.gp-field-guide.org.uk.", "citeRegEx": "Poli et al\\.,? 2008", "shortCiteRegEx": "Poli et al\\.", "year": 2008}, {"title": "The algorithmic beauty of plants", "author": ["P. Prusinkiewicz", "A. Lindenmayer"], "venue": "Springer Science & Business Media.", "citeRegEx": "Prusinkiewicz and Lindenmayer,? 2012", "shortCiteRegEx": "Prusinkiewicz and Lindenmayer", "year": 2012}, {"title": "CHILD: A first step towards continual learning", "author": ["M. Ring"], "venue": "Machine Learning, 28:77\u2013104.", "citeRegEx": "Ring,? 1997", "shortCiteRegEx": "Ring", "year": 1997}, {"title": "Artificial Intelligence: A Modern Approach, 3d ed", "author": ["S. Russell", "P. Norvig"], "venue": "Pearson Education, New York.", "citeRegEx": "Russell and Norvig,? 2009", "shortCiteRegEx": "Russell and Norvig", "year": 2009}, {"title": "Optimal ordered problem solver", "author": ["J. Schmidhuber"], "venue": "Machine Learning, 54(3):211\u2013254.", "citeRegEx": "Schmidhuber,? 2004", "shortCiteRegEx": "Schmidhuber", "year": 2004}, {"title": "Multiagent Systems", "author": ["Y. Shoham", "K. Leyton-Brown"], "venue": "Cambridge University Press, Cambridge.", "citeRegEx": "Shoham and Leyton.Brown,? 2009", "shortCiteRegEx": "Shoham and Leyton.Brown", "year": 2009}, {"title": "Lifelong machine learning systems: Beyond learning algorithms", "author": ["D. Silver", "Q. Yang", "L. Li"], "venue": "Proceedings of the AAAI Spring Symposium on Lifelong Machine Learning, pages 49\u201355, Stanford, CA.", "citeRegEx": "Silver et al\\.,? 2013", "shortCiteRegEx": "Silver et al\\.", "year": 2013}, {"title": "A formal theory of inductive inference", "author": ["R.J. Solomonoff"], "venue": "Part I. Information and control, 7(1):1\u201322. 37", "citeRegEx": "Solomonoff,? 1964", "shortCiteRegEx": "Solomonoff", "year": 1964}, {"title": "The discovery of algorithmic probability", "author": ["R.J. Solomonoff"], "venue": "Journal of Computer and System Sciences, 55(1):73\u201388.", "citeRegEx": "Solomonoff,? 1997", "shortCiteRegEx": "Solomonoff", "year": 1997}, {"title": "Progress in incremental machine learning", "author": ["R.J. Solomonoff"], "venue": "NIPS Workshop on Universal Learning Algorithms and Optimal Search, Whistler, BC. Citeseer.", "citeRegEx": "Solomonoff,? 2002", "shortCiteRegEx": "Solomonoff", "year": 2002}, {"title": "Social language learning", "author": ["L. Steels"], "venue": "Tokoro, M. and Steels, L., editors, The Future of Learning, pages 133\u2013162. IOS, Amsterdam.", "citeRegEx": "Steels,? 2003", "shortCiteRegEx": "Steels", "year": 2003}, {"title": "What triggers the emergence of grammar", "author": ["L. Steels"], "venue": "In Proceedings of EELC,", "citeRegEx": "Steels,? \\Q2005\\E", "shortCiteRegEx": "Steels", "year": 2005}, {"title": "Reinforcement Learning: An Introduction", "author": ["R. Sutton", "A. Barto"], "venue": "MIT Press, Cambridge, MA.", "citeRegEx": "Sutton and Barto,? 1998", "shortCiteRegEx": "Sutton and Barto", "year": 1998}, {"title": "Cognitive foundations for knowledge representation in AI", "author": ["J. Tenenbaum"], "venue": "Presented at the AAAI Spring Symposium on Knowledge Representation and Reasoning.", "citeRegEx": "Tenenbaum,? 2015", "shortCiteRegEx": "Tenenbaum", "year": 2015}, {"title": "Learning to interpret natural language commands through human-robot dialog", "author": ["J. Thomason", "S. Zhang", "R. Mooney", "P. Stone"], "venue": "Proceedings IJCAI, pages 1923\u20131929, Buenos Aires, Argentina.", "citeRegEx": "Thomason et al\\.,? 2015", "shortCiteRegEx": "Thomason et al\\.", "year": 2015}, {"title": "Computing machinery and intelligence", "author": ["A. Turing"], "venue": "Mind, 59:433\u2013460.", "citeRegEx": "Turing,? 1950", "shortCiteRegEx": "Turing", "year": 1950}, {"title": "Towards AIcomplete question answering: A set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "T. Mikolov"], "venue": "http:// arxiv.org/abs/1502.05698.", "citeRegEx": "Weston et al\\.,? 2015", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Natural Theories of Mind", "author": ["A. Whiten"], "venue": null, "citeRegEx": "Whiten,? \\Q1991\\E", "shortCiteRegEx": "Whiten", "year": 1991}, {"title": "Artificial human companion", "author": ["Wikipedia"], "venue": "https://en.wikipedia. org/w/index.php?title=Artificial_human_companion&oldid= 685507143. Accessed 15-October-2015. 38", "citeRegEx": "Wikipedia,? 2015a", "shortCiteRegEx": "Wikipedia", "year": 2015}, {"title": "Turing test", "author": ["Wikipedia"], "venue": "https://en.wikipedia.org/w/index. php?title=Turing_test&oldid=673582926. Accessed 30-July-2015.", "citeRegEx": "Wikipedia,? 2015b", "shortCiteRegEx": "Wikipedia", "year": 2015}, {"title": "Procedures as a representation for data in a computer program for understanding natural language", "author": ["T. Winograd"], "venue": "Technical Report AI 235, Massachusetts Institute of Technology. 39", "citeRegEx": "Winograd,? 1971", "shortCiteRegEx": "Winograd", "year": 1971}], "referenceMentions": [{"referenceID": 8, "context": "In particular, we are not making claims about the internal representations of the machine being based on an interpretable \u201clanguage of thought\u201d (Fodor, 1975).", "startOffset": 144, "endOffset": 157}, {"referenceID": 13, "context": "Arguably, the main flaw of \u201cgood old\u201d symbolic AI research (Haugeland, 1985) lied in the assumption that it would be possible to program an intelligent machine largely by hand.", "startOffset": 59, "endOffset": 76}, {"referenceID": 44, "context": "The Learner can then discover that these agents are similar to it, developing a \u201ctheory of mind\u201d (Whiten, 1991) in order to guide them.", "startOffset": 97, "endOffset": 111}, {"referenceID": 28, "context": "We might also be inspired by string rewriting systems, for example some versions of the L-systems (Prusinkiewicz and Lindenmayer, 2012).", "startOffset": 98, "endOffset": 135}, {"referenceID": 29, "context": "Like any serious roadmap towards AI, ours owes a large debt to the seminal ideas of Turing (1950). Note that, while Turing\u2019s paper is most often cited for the \u201cimitation game\u201d proposal, there are other very interesting ideas in it, worthy of more attention from curious readers, especially in the last section on learning machines.", "startOffset": 86, "endOffset": 98}, {"referenceID": 18, "context": "There has been a recent revival of interest in tasks measuring computational intelligence, spurred by the empirical advances of powerful machinelearning architectures such as multi-layered neural networks (LeCun et al., 2015), and by the patent inadequacy of the classic version of Turing test (Wikipedia, 2015b).", "startOffset": 205, "endOffset": 225}, {"referenceID": 46, "context": ", 2015), and by the patent inadequacy of the classic version of Turing test (Wikipedia, 2015b).", "startOffset": 76, "endOffset": 94}, {"referenceID": 17, "context": "There has been a recent revival of interest in tasks measuring computational intelligence, spurred by the empirical advances of powerful machinelearning architectures such as multi-layered neural networks (LeCun et al., 2015), and by the patent inadequacy of the classic version of Turing test (Wikipedia, 2015b). For example, Levesque et al. (2012) propose to test systems on their ability to resolve coreferential ambiguities (The trophy would not fit in the brown suitcase because it was too big.", "startOffset": 206, "endOffset": 350}, {"referenceID": 9, "context": "Geman et al. (2015) propose a \u201cvisual\u201d Turing test in which a computational system is asked to answer a set of increasingly specific questions about objects, attributes and relations in a picture (Is there a person in the blue region? Is the person carrying something? Is the person interacting with any other object? ).", "startOffset": 0, "endOffset": 20}, {"referenceID": 9, "context": "Geman et al. (2015) propose a \u201cvisual\u201d Turing test in which a computational system is asked to answer a set of increasingly specific questions about objects, attributes and relations in a picture (Is there a person in the blue region? Is the person carrying something? Is the person interacting with any other object? ). Similar initiatives differ from ours in that they focus on a specific set of skills (coreference, image parsing) rather than testing if an agent can learn new skills. Moreover, these are traditional evaluation benchmarks, unlike the hybrid learning/evaluation ecosystem we are proposing. The idea of developing an AI living in a controlled synthetic environment and interacting with other agents through natural language is quite old. The Blocks World of Winograd (1971) is probably the most important example of early research in this vein.", "startOffset": 0, "endOffset": 792}, {"referenceID": 32, "context": "Interaction also plays a central role in the study of multiagent systems (Shoham and Leyton-Brown, 2009).", "startOffset": 73, "endOffset": 104}, {"referenceID": 21, "context": "We have several points of contact with the semantic parsing literature, such as navigation tasks in an artificial world (MacMahon et al., 2006) and reward-based learning from natural language instructions (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013).", "startOffset": 120, "endOffset": 143}, {"referenceID": 5, "context": ", 2006) and reward-based learning from natural language instructions (Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013).", "startOffset": 69, "endOffset": 121}, {"referenceID": 30, "context": "Interaction also plays a central role in the study of multiagent systems (Shoham and Leyton-Brown, 2009). However, the emphasis in this research tradition is on how conflict resolution and distributed problem solving evolve in typically large groups of simple, mostly scripted agents. For example, traffic modeling is a classic application scenario for multiagent systems. This is very different from our emphasis on linguistic interaction for the purposes of training a single agent that should become independently capable of very complex behaviours. Tenenbaum (2015), like us, emphasizes the need to focus on basic abilities that form the core of intelligence.", "startOffset": 74, "endOffset": 570}, {"referenceID": 41, "context": "ural environments by interacting with humans (Thomason et al., 2015) or improving performance on real-life video-games by consulting the instruction manual (Branavan et al.", "startOffset": 45, "endOffset": 68}, {"referenceID": 3, "context": ", 2015) or improving performance on real-life video-games by consulting the instruction manual (Branavan et al., 2012), are certainly landmarks of intelligence.", "startOffset": 95, "endOffset": 118}, {"referenceID": 33, "context": "The last twenty years have witnessed several related proposals on learning to learn (Thrun and Pratt, 1997), lifelong learning (Silver et al., 2013) and continual learning (Ring, 1997).", "startOffset": 127, "endOffset": 148}, {"referenceID": 29, "context": ", 2013) and continual learning (Ring, 1997).", "startOffset": 31, "endOffset": 43}, {"referenceID": 29, "context": ", 2013) and continual learning (Ring, 1997). Much of this work is theoretical in nature and focuses on algorithms rather than on empirical challenges for the proposed models. Still, the general ideas being pursued are in line with our program. Ring (1997), in particular, defines a continual-learning agent whose experiences \u201coccur sequentially, and what it learns at one time step while solving one task, it can use later, perhaps to solve a completely different task.", "startOffset": 32, "endOffset": 256}, {"referenceID": 29, "context": ", 2013) and continual learning (Ring, 1997). Much of this work is theoretical in nature and focuses on algorithms rather than on empirical challenges for the proposed models. Still, the general ideas being pursued are in line with our program. Ring (1997), in particular, defines a continual-learning agent whose experiences \u201coccur sequentially, and what it learns at one time step while solving one task, it can use later, perhaps to solve a completely different task.\u201d Ring\u2019s desiderata for the continual learner are remarkably in line with ours. It is \u201can autonomous agent. It senses, takes actions, and responds to the rewards in its environment. It learns behaviors and skills while solving its tasks. It learns incrementally. There is no fixed training set; learning occurs at every time step; and the skills the agent learns now can be used later. It learns hierarchically. Skills it learns now can be built upon and modified later. It is a black box. The internals of the agent need not be understood or manipulated. All of the agent\u2019s behaviors are developed through training, not through direct manipulation. Its only interface to the world is through its senses, actions, and rewards. It has no ultimate, final task. What the agent learns now may or may not be useful later, depending on what tasks come next.\u201d Ring\u2019s example, a set of increasingly complex mazes where an agent must discover food by reinforcement learning, is also somewhat related to our setup. Mitchell et al. (2015) discuss NELL, the most fully realized concrete implementation of a lifelong learning architecture.", "startOffset": 32, "endOffset": 1497}, {"referenceID": 0, "context": "In this latter respect, this project is close to multi-task learning (Ando and Zhang, 2005; Caruana, 1997; Collobert et al., 2011), that focuses on the idea of parameter sharing across tasks.", "startOffset": 69, "endOffset": 130}, {"referenceID": 4, "context": "In this latter respect, this project is close to multi-task learning (Ando and Zhang, 2005; Caruana, 1997; Collobert et al., 2011), that focuses on the idea of parameter sharing across tasks.", "startOffset": 69, "endOffset": 130}, {"referenceID": 6, "context": "In this latter respect, this project is close to multi-task learning (Ando and Zhang, 2005; Caruana, 1997; Collobert et al., 2011), that focuses on the idea of parameter sharing across tasks.", "startOffset": 69, "endOffset": 130}, {"referenceID": 31, "context": "The idea of incremental learning, motivated by the same considerations as in the papers we just mentioned, also appears in Solomonoff (2002), a work which has much earlier roots in research on program induction (Solomonoff, 1964, 1997; Schmidhuber, 2004).", "startOffset": 211, "endOffset": 254}, {"referenceID": 27, "context": "Genetic programming (Poli et al., 2008) also focuses on the reuse of previously found sub-solutions, speeding up the search procedure in this way.", "startOffset": 20, "endOffset": 39}, {"referenceID": 39, "context": "We share many ideas with the reinforcement learning framework (Sutton and Barto, 1998).", "startOffset": 62, "endOffset": 86}, {"referenceID": 16, "context": "Our proposal is however markedly different from standard reinforcement learning work(Kaelbling et al., 1996) in several respects.", "startOffset": 84, "endOffset": 108}, {"referenceID": 6, "context": "complex skills, an idea that has also previously been studied in the context of recurrent neural network training by Elman (1990). Note that we expect the intelligent machine to develop incrementally more complex skills during its lifetime; this does not necessarily require the training data to be precisely ordered, which was the focus of these previous works.", "startOffset": 117, "endOffset": 130}, {"referenceID": 6, "context": "complex skills, an idea that has also previously been studied in the context of recurrent neural network training by Elman (1990). Note that we expect the intelligent machine to develop incrementally more complex skills during its lifetime; this does not necessarily require the training data to be precisely ordered, which was the focus of these previous works. The idea of incremental learning, motivated by the same considerations as in the papers we just mentioned, also appears in Solomonoff (2002), a work which has much earlier roots in research on program induction (Solomonoff, 1964, 1997; Schmidhuber, 2004).", "startOffset": 117, "endOffset": 504}, {"referenceID": 2, "context": "Our proposal is also related to that of Bottou (2014), in its vision of compositional machine learning.", "startOffset": 40, "endOffset": 54}, {"referenceID": 2, "context": "Our proposal is also related to that of Bottou (2014), in its vision of compositional machine learning. We share many ideas with the reinforcement learning framework (Sutton and Barto, 1998). In reinforcement learning, the agent chooses actions in an environment in order to maximize some cumulative reward over time. Reinforcement learning is particularly popular for problems where the agent can collect information only by interacting with the environment. Given how broad this definition is, our framework could be considered as a particular instance of it. Our proposal is however markedly different from standard reinforcement learning work(Kaelbling et al., 1996) in several respects. For example, we focus on strategies to encourage agents to solve tasks by reusing previously learned knowledge, we aim at limiting the number of trials an agent has to accomplish a certain goal, we maximize average reward, which favors efficient agents, and we allow the agent to interact with the environment between tasks to prepare itself for the next task. Mnih et al. (2015) recently presented a single neural network architecture capable of learning a set of classic Atari games using only pixels and game", "startOffset": 40, "endOffset": 1072}, {"referenceID": 42, "context": "spirit, Weston et al. (2015) present a set of question answering tasks based on synthetically generated stories.", "startOffset": 8, "endOffset": 29}, {"referenceID": 11, "context": "One could think of solving sequence-manipulation problems such as those presented in this paper with relatively small extensions of established machine learning techniques (Graves et al., 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015).", "startOffset": 172, "endOffset": 246}, {"referenceID": 12, "context": "One could think of solving sequence-manipulation problems such as those presented in this paper with relatively small extensions of established machine learning techniques (Graves et al., 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015).", "startOffset": 172, "endOffset": 246}, {"referenceID": 15, "context": "One could think of solving sequence-manipulation problems such as those presented in this paper with relatively small extensions of established machine learning techniques (Graves et al., 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015).", "startOffset": 172, "endOffset": 246}, {"referenceID": 15, "context": "structure can form a simple kind of long-term memory and learn to memorize and repeat sequences in the reversed order, but not in the original one (Joulin and Mikolov, 2015).", "startOffset": 147, "endOffset": 173}, {"referenceID": 22, "context": "the very reason why algorithmic tasks were originally proposed by Mikolov (2013). We hope that this paper will motivate the design of the genuinely", "startOffset": 66, "endOffset": 81}, {"referenceID": 22, "context": "(Mikolov, 2013).", "startOffset": 0, "endOffset": 15}], "year": 2015, "abstractText": "The development of intelligent machines is one of the biggest unsolved challenges in computer science. In this paper, we propose some fundamental properties these machines should have, focusing in particular on communication and learning. We discuss a simple environment that could be used to incrementally teach a machine the basics of natural-language-based communication, as a prerequisite to more complex interaction with human users. We also present some conjectures on the sort of algorithms the machine should support in order to profitably learn from the environment.", "creator": "LaTeX with hyperref package"}}}