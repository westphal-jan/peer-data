{"id": "1511.08574", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Nov-2015", "title": "A Stochastic Process Model of Classical Search", "abstract": "Among classical search algorithms with the same heuristic information, with sufficient memory A* is essentially as fast as possible in finding a proven optimal solution. However, in many situations optimal solutions are simply infeasible, and thus search algorithms that trade solution quality for speed are desirable. In this paper, we formalize the process of classical search as a metalevel decision problem, the Abstract Search MDP. For any given optimization criterion, this establishes a well-defined notion of the best possible behaviour for a search algorithm and offers a theoretical approach to the design of algorithms for that criterion. We proceed to approximately solve a version of the Abstract Search MDP for anytime algorithms and thus derive a novel search algorithm, Search by Maximizing the Incremental Rate of Improvement (SMIRI). SMIRI is shown to outperform current state-of-the-art anytime search algorithms on a parametrized stochastic tree model for most of the tested parameter values.", "histories": [["v1", "Fri, 27 Nov 2015 07:34:41 GMT  (239kb,D)", "http://arxiv.org/abs/1511.08574v1", "Submitted to ICAPS 2016"]], "COMMENTS": "Submitted to ICAPS 2016", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["dimitri klimenko", "hanna kurniawati", "marcus gallagher"], "accepted": false, "id": "1511.08574"}, "pdf": {"name": "1511.08574.pdf", "metadata": {"source": "CRF", "title": "A Stochastic Process Model of Classical Search", "authors": ["Dimitri Klimenko", "Hanna Kurniawati"], "emails": ["dimitri.klimenko@uqconnect.edu.au", "hannakur@uq.edu.au", "marcusg@uq.edu.au"], "sections": [{"heading": null, "text": "In this paper, we formalize the process of classical search as a meta-level decision problem, the Abstract Search MDP. For each given optimization criterion, we establish a clearly defined idea of the best possible behavior for a search algorithm and offer a theoretical approach to the design of algorithms for that criterion. We proceed to approximately solve a version of the Abstract Search MDP for always available algorithms and derive from it a novel search algorithm, Search by Maximizing the Incremental Rate of Improvement (SMIRI). It is shown that SMIRI always outperforms the current search algorithms on a parameterized stochastic tree model for most of the parameter values tested."}, {"heading": "1 Introduction", "text": "Since the early 1960s, the general idea of best-first search has been fundamental to the design of many sound search algorithms. Of particular note is A * (Hart et al., 1968), which remains ubiquitous. On a fundamental level, all best-first search algorithms work in the same way: They gradually build a search tree in which nodes represent states in the state space of the problem, and edges represent state transitions. The central atomic task in this process is edge expansion, i.e. the addition of a new node to the search tree over a previously unvisited edge. The design of each best-first search algorithm boils down to a single fundamental question - how does the algorithm decide which edge to extend Xiv: 151 1.08 574v 1 [cs.A] 2 7in each iteration? There are trade-offs between the cost of solutions and the time needed to solve them."}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Metareasoning and Models of Search", "text": "Although we like search algorithms to show perfect rationality, in the real world this is not practical due to the high complexity of the calculations of many decision problems. In order to develop the most rational agent among limited computational resources, metareasoning applies decision theory principles. The basic idea is simple - as with decisions at object level, when choosing between calculations an agent should choose the one that has the most expected benefit. Matheson (1968) showed that metareasoning can be formalized by combining an object model with a model of calculations to form the metallic decision problem. The Decision-Theoretic A * algorithm (Russell and Wefald, 1988) applies metareasoning to the real problem search, but the benefit estimation used in DTA * cannot obey the standard axioms of probability and benefit theory, and thus the approach lacks solid theoretical grounding (Russell and Wefald, 1988)."}, {"heading": "2.2 Existing Algorithms", "text": "As mentioned in Section 1, different requirements in terms of solution quality and execution time lead to a spectrum of very different search algorithms to meet them. * The A * algorithm dominates one extreme within this spectrum - when used with a permissible heuristic, A * ensures with complete certainty that the solution it returns will be optimal. Furthermore, Dechter and Pearl (1985) show that A * (to the tie-breaking criterion) is essentially the fastest general algorithm that can provide this warranty - other algorithms can only work better by \"cheating\" certain problem instances. However, despite many adjustments of A *, the problem of computational complexity remains elusive. For many types of problems, the time it takes to find an optimal solution will grow exponentially (or worse!) with the size of the problem, no matter how good the search algorithm is. The only way to avoid this basic problem is to equalize the coalgorithm within the optimum algorithm that requires."}, {"heading": "3 Framework", "text": "To define the ASMDP - the proposed meta-level decision problem for classical search - we first define the search problem and the abstract search problem on which it is based."}, {"heading": "3.1 The Classical Search Problem", "text": "Here we are using a simplified version of the extensive form game (Osborne and Rubinstein, 1994, p. 89), so that the definition can easily be extended to all perfect information games, including MDPs and stochastic games. This definition is based on the idea of a story that is a sequence of actions. In particular, for a given set of possible actions A we use A \u2264 \u03c9 to denote the set of all possible stories; this can be divided into the set of all infinite stories that we call a search tree; definition 1. A search tree T is a sequence of stories that meet the following requirements: \u2022 The empty sequence or root c is a sequence of events, e.g. h a a. At the heart of each problem is a graph structure that we call a search tree; definition 1. A search tree T is a sequence of stories that meet the following sequence: \u2022 The empty sequence or root c is a sequence of events < > is a member of T. \u2022 Each preselection of a sequence is also an infinite problem T. In each case T is also an infinite problem."}, {"heading": "3.2 The Abstract Search Problem", "text": "This is a subtle problem that needs to be solved (Russell and Wefald, 1991): any information obtained solely as a result of a calculation is information that is already illegal from the point of view of usefulness and probability theory. This fundamental problem is quite difficult; it remains an area of active research that is sometimes referred to as \"logical uncertainty\" (Soares and Fallenstein, 2015). To address the problem, we rephrase the problem into a standard question of environmental uncertainty to which Bayesian probability and decision theory can be applied. The idea is based on the simple observation that a search algorithm never fully utilizes the available information on the states in the search tree. Therefore, a search algorithm operates only on an abstract representation of a state that we call abstract state residence in the feature space F."}, {"heading": "3.3 The Abstract Search MDP (ASMDP)", "text": "In the context of the tree generation process as defined in the previous paragraph, the search process can be seen as part of the problem (= Partially Observable Markov Decision Process (POMDP), in which the agent is unaware of the true underlying problem, but can observe the abstract states within his search scheme. However, to avoid directly solving the complete POMDP search tree, we instead apply the concept of sufficient information states (House Law, 2000) to define the ASMDP. Due to the Markov premise (Section 3.2), the structure of the search tree and the observed characteristic values within that tree are sufficient statistics. In the face of action set A, a partial search tree is a set of finite stories H < and this is also a search tree (per definition 1). A partial realization (H, bH) of an abstract problem G is a partial search tree H and a partial search tree is a partial H."}, {"heading": "4 Approximately Solving the ASMDP", "text": "Although the ASMDP results lie in a well-defined idea of what constitutes an optimal search algorithm, most general-purpose MDP solvers should either strive for a better solution (most generic MDP solvers are too slow to handle the ASMDP), the idea is similar to the multi-arm index policy (Gittins and Jones, 1979): it independently calculates a single quantity for each action and selects the measures with the largest index. Our index policy is derived from the notion of an incremental rate of improvement, known as the rate at which the cost Cinc introduced improves over time (i.e., \"the rate of improvement\"), but only in the near future (i.e. \"incremental\"). 1To derive an approximate solution for the ASMDP, we note that an optimal ASMDP policy (i.e. an optimal search should only be expanded)."}, {"heading": "5 Search by Maximizing the Incremental Rate of Improvement", "text": "In order to make practical use of the near-optimal policy of section 4, we need an efficient method of calculating the maximum incremental improvement rate for each equivalence class of edges e = (C, x, a); where C = Cinc \u2212 g (n) is limited to the cost limit relative to the parent node of the outedge, x is the abstract state of that node, and a is the action along the edge. If the cost of the path g () and abstract states x are limited to finite sets, algorithm 1 describes how the precalculation of r values occurs in polynomial time. The key idea is that the relative costs along a path can only increase; therefore, they can be reduced by dynamic programming along its initial reasoning. Specifically, line 1 loops in increasing order of C, ensuring that r values of descending edge types are always calculated before they begin."}, {"heading": "6 Experiments", "text": "8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,"}, {"heading": "7 Discussion", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "8 Conclusion", "text": "Overall, the experimental results for SMIRI are not intended to evaluate the SMIRI algorithm, but rather to demonstrate the effectiveness of classical search methods - they require pre-processing time and are limited to areas where the possible path costs (up to Cmax) and the abstract states are finite quantities. However, such pre-processing costs can become insignificant when compared with a large search problem or amortized across many search criteria that share an abstract model. Furthermore, one possible approach that could solve both of these problems is functional approach methods that could be used to capture the structure of r-DP. A major problem with the results is that they are limited to an artificial problem rather than typical benchmark problems from the literature. It would be very informative to examine the performance of SMIRI in more realistic problem domains, and in particular those with non-uniform marginal costs to demonstrate the effectiveness of the estimated search effectiveness. However, the main purpose of the paper is not to justify the SMIRI's evaluation, but rather to demonstrate the effectiveness of SMIRI."}], "references": [{"title": "An analysis of time-dependent planning", "author": ["Thomas L. Dean", "Mark S. Boddy"], "venue": "In Proc. AAAI. St. Paul, MN, August 21-26,", "citeRegEx": "Dean and Boddy.,? \\Q1988\\E", "shortCiteRegEx": "Dean and Boddy.", "year": 1988}, {"title": "Generalized best-first search strategies and the optimality of a", "author": ["Rina Dechter", "Judea Pearl"], "venue": "J. ACM,", "citeRegEx": "Dechter and Pearl.,? \\Q1985\\E", "shortCiteRegEx": "Dechter and Pearl.", "year": 1985}, {"title": "A dynamic allocation index for the discounted multiarmed bandit problem", "author": ["J.C. Gittins", "D.M. Jones"], "venue": null, "citeRegEx": "Gittins and Jones.,? \\Q1979\\E", "shortCiteRegEx": "Gittins and Jones.", "year": 1979}, {"title": "Anytime heuristic search: First results", "author": ["Eric A. Hansen", "Shlomo Zilberstein", "Victor A. Danilchenko"], "venue": "Technical Report 97-50,", "citeRegEx": "Hansen et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hansen et al\\.", "year": 1997}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["Peter E. Hart", "Nils J. Nilsson", "Bertram Raphael"], "venue": "IEEE Trans. Systems Science and Cybernetics,", "citeRegEx": "Hart et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Hart et al\\.", "year": 1968}, {"title": "Value-function approximations for partially observable markov decision processes", "author": ["Milos Hauskrecht"], "venue": "JAIR, 13:33\u201394,", "citeRegEx": "Hauskrecht.,? \\Q2000\\E", "shortCiteRegEx": "Hauskrecht.", "year": 2000}, {"title": "Selecting computations: Theory and applications", "author": ["Nicholas Hay", "Stuart J. Russell", "David Tolpin", "Solomon Eyal Shimony"], "venue": "In Proc. of UAI, August 14-18,", "citeRegEx": "Hay et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hay et al\\.", "year": 2012}, {"title": "Searching for an optimal path in a tree with random costs", "author": ["Richard M. Karp", "Judea Pearl"], "venue": "Artif. Intell.,", "citeRegEx": "Karp and Pearl.,? \\Q1983\\E", "shortCiteRegEx": "Karp and Pearl.", "year": 1983}, {"title": "Estimating the efficiency of backtrack programs", "author": ["Donald E. Knuth"], "venue": "Math. Comp.,", "citeRegEx": "Knuth.,? \\Q1975\\E", "shortCiteRegEx": "Knuth.", "year": 1975}, {"title": "An analysis of alpha-beta pruning", "author": ["Donald E. Knuth", "Ronald W. Moore"], "venue": "Artif. Intell.,", "citeRegEx": "Knuth and Moore.,? \\Q1975\\E", "shortCiteRegEx": "Knuth and Moore.", "year": 1975}, {"title": "Depth-first iterative-deepening: An optimal admissible tree search", "author": ["Richard E. Korf"], "venue": "Artif. Intell.,", "citeRegEx": "Korf.,? \\Q1985\\E", "shortCiteRegEx": "Korf.", "year": 1985}, {"title": "Time complexity of iterative-deepening-a", "author": ["Richard E. Korf", "Michael Reid", "Stefan Edelkamp"], "venue": "Artif. Intell.,", "citeRegEx": "Korf et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Korf et al\\.", "year": 2001}, {"title": "And-or graphs, theorem-proving graphs and bi-directional graphs", "author": ["Robert Kowalski"], "venue": "In Machine Intelligence 7, Proceedings of the Seventh Machine Intelligence Workshop,", "citeRegEx": "Kowalski.,? \\Q1972\\E", "shortCiteRegEx": "Kowalski.", "year": 1972}, {"title": "Predicting the size of ida*\u2019s search", "author": ["Levi H.S. Lelis", "Sandra Zilles", "Robert C. Holte"], "venue": "tree. Artif. Intell.,", "citeRegEx": "Lelis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lelis et al\\.", "year": 2013}, {"title": "Predicting optimal solution cost with conditional probabilities predicting optimal solution cost", "author": ["Levi H.S. Lelis", "Roni Stern", "Ariel Felner", "Sandra Zilles", "Robert C. Holte"], "venue": "Ann. Math. Artif. Intell.,", "citeRegEx": "Lelis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lelis et al\\.", "year": 2014}, {"title": "Ara*: Anytime a* with provable bounds on suboptimality", "author": ["Maxim Likhachev", "Geoffrey J. Gordon", "Sebastian Thrun"], "venue": "NIPS", "citeRegEx": "Likhachev et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Likhachev et al\\.", "year": 2003}, {"title": "The economic value of analysis and computation", "author": ["James E. Matheson"], "venue": "IEEE Trans. Systems Science and Cybernetics,", "citeRegEx": "Matheson.,? \\Q1968\\E", "shortCiteRegEx": "Matheson.", "year": 1968}, {"title": "Optimal allocation of very limited search resources", "author": ["David Mutchler"], "venue": "In Proc. AAAI. Philadelphia, PA, August 11-15,", "citeRegEx": "Mutchler.,? \\Q1986\\E", "shortCiteRegEx": "Mutchler.", "year": 1986}, {"title": "Pathology on game trees: A summary of results", "author": ["Dana S. Nau"], "venue": "In Proc. AAAI. Stanford University, August 18-21,", "citeRegEx": "Nau.,? \\Q1980\\E", "shortCiteRegEx": "Nau.", "year": 1980}, {"title": "A course in game theory", "author": ["Martin J Osborne", "Ariel Rubinstein"], "venue": "MIT press,", "citeRegEx": "Osborne and Rubinstein.,? \\Q1994\\E", "shortCiteRegEx": "Osborne and Rubinstein.", "year": 1994}, {"title": "Studies in semi-admissible heuristics", "author": ["Judea Pearl", "Jin H. Kim"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Pearl and Kim.,? \\Q1982\\E", "shortCiteRegEx": "Pearl and Kim.", "year": 1982}, {"title": "Heuristic search viewed as path finding in a graph", "author": ["Ira Pohl"], "venue": "Artif. Intell.,", "citeRegEx": "Pohl.,? \\Q1970\\E", "shortCiteRegEx": "Pohl.", "year": 1970}, {"title": "The joy of forgetting: Faster anytime search via restarting", "author": ["Silvia Richter", "Jordan Tyler Thayer", "Wheeler Ruml"], "venue": "In Proc. ICAPS", "citeRegEx": "Richter et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Richter et al\\.", "year": 2010}, {"title": "Decision-theoretic control of reasoning: General theory and an application to game-playing", "author": ["Stuart Russell", "Eric Wefald"], "venue": "Technical Report UCB/CSD-88-435,", "citeRegEx": "Russell and Wefald.,? \\Q1988\\E", "shortCiteRegEx": "Russell and Wefald.", "year": 1988}, {"title": "Artificial Intelligence - A Modern Approach (3", "author": ["Stuart J. Russell", "Peter Norvig"], "venue": "internat. ed.). Pearson Education,", "citeRegEx": "Russell and Norvig.,? \\Q2010\\E", "shortCiteRegEx": "Russell and Norvig.", "year": 2010}, {"title": "Do the right thing - studies in limited rationality", "author": ["Stuart J. Russell", "Eric Wefald"], "venue": null, "citeRegEx": "Russell and Wefald.,? \\Q1991\\E", "shortCiteRegEx": "Russell and Wefald.", "year": 1991}, {"title": "Questions of reasoning under logical uncertainty", "author": ["Nate Soares", "Benja Fallenstein"], "venue": "Technical Report 2015-1, Machine Intelligence Research Institute,", "citeRegEx": "Soares and Fallenstein.,? \\Q2015\\E", "shortCiteRegEx": "Soares and Fallenstein.", "year": 2015}, {"title": "Potential-based bounded-cost search and anytime nonparametric a", "author": ["Roni Stern", "Ariel Felner", "Jur van den Berg", "Rami Puzis", "Rajat Shah", "Ken Goldberg"], "venue": "Artif. Intell.,", "citeRegEx": "Stern et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Stern et al\\.", "year": 2014}, {"title": "Potential search: A boundedcost search algorithm", "author": ["Roni Tzvi Stern", "Rami Puzis", "Ariel Felner"], "venue": "In Proc. ICAPS", "citeRegEx": "Stern et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Stern et al\\.", "year": 2011}, {"title": "Bounded suboptimal search: A direct approach using inadmissible estimates", "author": ["Jordan Tyler Thayer", "Wheeler Ruml"], "venue": "IJCAI", "citeRegEx": "Thayer and Ruml.,? \\Q2011\\E", "shortCiteRegEx": "Thayer and Ruml.", "year": 2011}, {"title": "Better parameter-free anytime search by minimizing time between solutions", "author": ["Jordan Tyler Thayer", "J. Benton", "Malte Helmert"], "venue": "In Proc. SOCS", "citeRegEx": "Thayer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Thayer et al\\.", "year": 2012}, {"title": "Anytime nonparametric A", "author": ["Jur van den Berg", "Rajat Shah", "Arthur Huang", "Kenneth Y. Goldberg"], "venue": "In Proc. AAAI", "citeRegEx": "Berg et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Berg et al\\.", "year": 2011}, {"title": "Predicting the performance of ida* using conditional distributions", "author": ["Uzi Zahavi", "Ariel Felner", "Neil Burch", "Robert C. Holte"], "venue": "JAIR, 37:41\u201383,", "citeRegEx": "Zahavi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zahavi et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 4, "context": "Of particular note is A* (Hart et al., 1968), which remains ubiquitous.", "startOffset": 25, "endOffset": 44}, {"referenceID": 6, "context": "However, some researchers have taken more formal approaches to such questions; of particular note is recent work (Hay et al., 2012) which formulates the Bayesian selection problem as a metalevel decision problem.", "startOffset": 113, "endOffset": 131}, {"referenceID": 16, "context": "Matheson (1968) showed that metareasoning", "startOffset": 0, "endOffset": 16}, {"referenceID": 23, "context": "The Decision-Theoretic A* algorithm (Russell and Wefald, 1988) applies metareasoning to real-time problem-solving search, but the utility estimates used in DTA* cannot obey the standard axioms of probability and utility theory and thus the approach lacks solid theoretical grounding (Russell and Wefald, 1988).", "startOffset": 36, "endOffset": 62}, {"referenceID": 23, "context": "The Decision-Theoretic A* algorithm (Russell and Wefald, 1988) applies metareasoning to real-time problem-solving search, but the utility estimates used in DTA* cannot obey the standard axioms of probability and utility theory and thus the approach lacks solid theoretical grounding (Russell and Wefald, 1988).", "startOffset": 283, "endOffset": 309}, {"referenceID": 6, "context": "More recent work (Hay et al., 2012) has formalized the metalevel decision problem for Bayesian selection problems.", "startOffset": 17, "endOffset": 35}, {"referenceID": 7, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem.", "startOffset": 11, "endOffset": 67}, {"referenceID": 9, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem.", "startOffset": 11, "endOffset": 67}, {"referenceID": 18, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem.", "startOffset": 11, "endOffset": 67}, {"referenceID": 10, "context": "(2001) were able to accurately predict the number of nodes expanded by the Iterative Deepening A* algorithm (Korf, 1985) on a number of different problems.", "startOffset": 108, "endOffset": 120}, {"referenceID": 7, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem. One exception is the modelling by Mutchler (1986) of search with severely limited edge expansions, who showed theoretically that a simple best-first search algorithm was approximately optimal in a simple random tree model.", "startOffset": 12, "endOffset": 173}, {"referenceID": 7, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem. One exception is the modelling by Mutchler (1986) of search with severely limited edge expansions, who showed theoretically that a simple best-first search algorithm was approximately optimal in a simple random tree model. The aforementioned prior works have offered interesting domains to study the behaviour of search algorithms, and we continue this trend by formulating a novel random tree model that should be more representative of classical search problems. On the other hand another line of research focused on predicting the sizes of search trees has resulted in much more realistic models of search problems, primarily due to a focus on predicting real-world performance. The earliest work on this problem is that of Knuth (1975); later, Korf et al.", "startOffset": 12, "endOffset": 863}, {"referenceID": 7, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem. One exception is the modelling by Mutchler (1986) of search with severely limited edge expansions, who showed theoretically that a simple best-first search algorithm was approximately optimal in a simple random tree model. The aforementioned prior works have offered interesting domains to study the behaviour of search algorithms, and we continue this trend by formulating a novel random tree model that should be more representative of classical search problems. On the other hand another line of research focused on predicting the sizes of search trees has resulted in much more realistic models of search problems, primarily due to a focus on predicting real-world performance. The earliest work on this problem is that of Knuth (1975); later, Korf et al. (2001) were able to accurately predict the number of nodes expanded by the Iterative Deepening A* algorithm (Korf, 1985) on a number of different problems.", "startOffset": 12, "endOffset": 890}, {"referenceID": 7, "context": "algorithms (Karp and Pearl, 1983; Knuth and Moore, 1975; Nau, 1980) rather than to formulate a metalevel decision problem. One exception is the modelling by Mutchler (1986) of search with severely limited edge expansions, who showed theoretically that a simple best-first search algorithm was approximately optimal in a simple random tree model. The aforementioned prior works have offered interesting domains to study the behaviour of search algorithms, and we continue this trend by formulating a novel random tree model that should be more representative of classical search problems. On the other hand another line of research focused on predicting the sizes of search trees has resulted in much more realistic models of search problems, primarily due to a focus on predicting real-world performance. The earliest work on this problem is that of Knuth (1975); later, Korf et al. (2001) were able to accurately predict the number of nodes expanded by the Iterative Deepening A* algorithm (Korf, 1985) on a number of different problems. This work was later extended by Zahavi et al. (2010) to increase its accuracy, by using conditional distributions over what Zahavi et al.", "startOffset": 12, "endOffset": 1092}, {"referenceID": 21, "context": "For a long time, the best-performing algorithm for this purpose was Weighted A* (Pohl, 1970); this approach multiples the heuristic in A* by a constant factor of w , resulting in an algorithm that typically runs faster than A\u2217 but is w -admissible.", "startOffset": 80, "endOffset": 92}, {"referenceID": 12, "context": "However, it tends to waste time exploring equally meritorious solutions in parallel, even when any one of those solutions would be acceptable (Kowalski, 1972; Pearl and Kim, 1982).", "startOffset": 142, "endOffset": 179}, {"referenceID": 20, "context": "However, it tends to waste time exploring equally meritorious solutions in parallel, even when any one of those solutions would be acceptable (Kowalski, 1972; Pearl and Kim, 1982).", "startOffset": 142, "endOffset": 179}, {"referenceID": 1, "context": "Moreover, Dechter and Pearl (1985) demonstrate that A* is (down to the tie-breaking criterion) essentially the fastest general algorithm that can make this guarantee\u2014other algorithms can only do better by \u201ccheating\u201d on specific problem instances.", "startOffset": 10, "endOffset": 35}, {"referenceID": 29, "context": "Explicit Estimation Search (EES) (Thayer and Ruml, 2011) resolves this issue by maintaining multiple queues, so as to maintain admissibility while focusing search effort on particular candidates.", "startOffset": 33, "endOffset": 56}, {"referenceID": 28, "context": "The most prominent algorithm for this criterion is Potential Search (Stern et al., 2011), which aims to expand the node with the highest probability of having a path cost below the bound.", "startOffset": 68, "endOffset": 88}, {"referenceID": 0, "context": "In this paper, we focus on the design of anytime algorithms (Dean and Boddy, 1988), which quickly find initial solutions and then gradually improve upon them.", "startOffset": 60, "endOffset": 82}, {"referenceID": 3, "context": "A number of anytime heuristic search algorithms have been proposed in the literature; the most basic is Anytime Weighted A* (Hansen et al., 1997), which is Weighted A* but continues to search after a solution is found, and prunes nods that cannot lead to an improvement.", "startOffset": 124, "endOffset": 145}, {"referenceID": 15, "context": "Anytime Repairing A* (Likhachev et al., 2003) adapts this by also decreasing the weight every time a solution is found.", "startOffset": 21, "endOffset": 45}, {"referenceID": 28, "context": "Finally, the latest state-of-the-art anytime algorithms have made further improvements by obviating the need for tuning the weight parameters; these are APTS/ANA* (Stern et al., 2011; van den Berg et al., 2011), an anytime version of Potential Search, and AEES (Thayer et al.", "startOffset": 163, "endOffset": 210}, {"referenceID": 30, "context": ", 2011), an anytime version of Potential Search, and AEES (Thayer et al., 2012), an anytime version of EES.", "startOffset": 58, "endOffset": 79}, {"referenceID": 24, "context": "Note that we represent the problem by a tree of histories, the complete search tree, rather than the usual state-space graph (Russell and Norvig, 2010).", "startOffset": 125, "endOffset": 151}, {"referenceID": 25, "context": "Decision-theoretic analysis of classical search may appear to be straightforward, but in reality there is a subtle issue that needs to be resolved (Russell and Wefald, 1991): any information obtained solely as the result of a computation is information that, from the point of view of utility and probability theory, that agent already had.", "startOffset": 147, "endOffset": 173}, {"referenceID": 26, "context": "This fundamental issue is a rather difficult one; it continues to be an area of active research, sometimes referred to as the question of \u201clogical uncertainty\u201d (Soares and Fallenstein, 2015).", "startOffset": 160, "endOffset": 190}, {"referenceID": 13, "context": "This idea can be seen as building upon the \u201ctype system\u201d idea of Lelis et al. (2013) by viewing abstract states as residing in an arbitrary space, and viewing the type system as representing a whole class of problems rather than just one.", "startOffset": 65, "endOffset": 85}, {"referenceID": 5, "context": "However, to avoid solving the full-blown POMDP directly, we instead apply the concept of sufficient information states (Hauskrecht, 2000) to define the ASMDP.", "startOffset": 119, "endOffset": 137}, {"referenceID": 2, "context": "The idea is analogous to index policies (Gittins and Jones, 1979) in multi-armed bandits: it independently computes a single quantity for each action and selects the action with the greatest index.", "startOffset": 40, "endOffset": 65}, {"referenceID": 30, "context": "1Thayer et al. (2012) have argued against maximizing the rate of improvement, but their argument applies to long-term improvement and not the short-term criterion used by SMIRI.", "startOffset": 1, "endOffset": 22}, {"referenceID": 27, "context": "\u2022 Anytime Potential Search (APTS/ANA*), as per Stern et al. (2014), which selects the node with maximal C\u2212g(n) h(n) .", "startOffset": 47, "endOffset": 67}, {"referenceID": 27, "context": "\u2022 Anytime Generalized Potential Search (AGPTS), as per Stern et al. (2014). For AGPTS, we explicitly precomputed a table for the potential PTC (n) for all n and C .", "startOffset": 55, "endOffset": 75}, {"referenceID": 30, "context": "\u2022 Anytime Explicit Estimation Search (AEES), as per Thayer et al. (2012). For AEES, we precomputed an unbiased inadmissible heuristic \u0125 \u2261 d\u0302 by calculating the expected value of the shortest-cost path from any node given h.", "startOffset": 52, "endOffset": 73}, {"referenceID": 22, "context": "5, 1 per Richter et al. (2010).", "startOffset": 9, "endOffset": 31}, {"referenceID": 29, "context": "exception was EES, which can be several times slower per expansion if node generation operations are cheap (Thayer and Ruml, 2011).", "startOffset": 107, "endOffset": 130}, {"referenceID": 7, "context": "5, as with the random tree model of Karp and Pearl (Karp and Pearl, 1983) Overall, SMIRI and APTS/ANA* are quite clearly the bestperforming algorithms, particularly for the hardest test cases.", "startOffset": 51, "endOffset": 73}, {"referenceID": 29, "context": "The idea of minimising search effort is one of the key motivations for AEES (Thayer and Ruml, 2011), but unfortunately it performed significantly worse than SMIRI or APTS and sometimes ARA*.", "startOffset": 76, "endOffset": 99}, {"referenceID": 7, "context": "5, as with the random tree model of Karp and Pearl (Karp and Pearl, 1983) Overall, SMIRI and APTS/ANA* are quite clearly the bestperforming algorithms, particularly for the hardest test cases. By contrast, ARA* performed poorly for these cases, suggesting that for difficult problems it is much better to use algorithms that don\u2019t rely on parameter tuning. As can be seen in cases 1, 2, and 3, APTS appears to level off at highercost solutions than SMIRI, and thus is likely could be far slower to attain solutions of similar quality than SMIRI. More critically, there is a significant disparity between APTS and AGPTS, which is a significant theoretical concern for APTS, because if one follows the theoretical derivation given by Stern et al. (2014) AGPTS does the \u201ccorrect thing\u201d in always selecting for maximum potential PTC , whereas the linear-relative assumption APTS relies on clearly fails for the random tree model we have used.", "startOffset": 36, "endOffset": 752}, {"referenceID": 27, "context": "More critically, the results for AGPTS demonstrate that the good performance for APTS comes in spite of the justification by Stern et al. for selecting on the basis of potential, and not because of it. This is highlighted by the benchmarking results of Thayer et al. (2012), which show AEES significantly outperforming APTS in all but one domain.", "startOffset": 125, "endOffset": 274}, {"referenceID": 14, "context": "probabilistic models of deterministic search (Lelis et al., 2014) indicate that such models can be effectively applied in estimating the performance of search algorithms, and there is little reason to believe that the additional step of applying metareasoning to such models is fundamentally flawed.", "startOffset": 45, "endOffset": 65}, {"referenceID": 14, "context": "Nevertheless, the success of probabilistic prediction methods for tree search in domains with cyclic graphs (Lelis et al., 2014) indicates that such models can be useful even if they don\u2019t account for those factors.", "startOffset": 108, "endOffset": 128}], "year": 2015, "abstractText": "Among classical search algorithms with the same heuristic information, with sufficient memory A* is essentially as fast as possible in finding a proven optimal solution. However, in many situations optimal solutions are simply infeasible, and thus search algorithms that trade solution quality for speed are desirable. In this paper, we formalize the process of classical search as a metalevel decision problem, the Abstract Search MDP. For any given optimization criterion, this establishes a well-defined notion of the best possible behaviour for a search algorithm and offers a theoretical approach to the design of algorithms for that criterion. We proceed to approximately solve a version of the Abstract Search MDP for anytime algorithms and thus derive a novel search algorithm, Search by Maximizing the Incremental Rate of Improvement (SMIRI). SMIRI is shown to outperform current state-of-the-art anytime search algorithms on a parametrized stochastic tree model for most of the tested parameter values.", "creator": "LaTeX with hyperref package"}}}