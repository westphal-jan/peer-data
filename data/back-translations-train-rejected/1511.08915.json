{"id": "1511.08915", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2015", "title": "Column-Oriented Datalog Materialization for Large Knowledge Graphs (Extended Technical Report)", "abstract": "The evaluation of Datalog rules over large Knowledge Graphs (KGs) is essential for many applications. In this paper, we present a new method of materializing Datalog inferences, which combines a column-based memory layout with novel optimization methods that avoid redundant inferences at runtime. The pro-active caching of certain subqueries further increases efficiency. Our empirical evaluation shows that this approach can often match or even surpass the performance of state-of-the-art systems, especially under restricted resources.", "histories": [["v1", "Sat, 28 Nov 2015 17:16:55 GMT  (46kb,D)", "https://arxiv.org/abs/1511.08915v1", null], ["v2", "Thu, 11 Feb 2016 16:12:55 GMT  (49kb,D)", "http://arxiv.org/abs/1511.08915v2", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["jacopo urbani", "ceriel jacobs", "markus kr\\\"otzsch"], "accepted": false, "id": "1511.08915"}, "pdf": {"name": "1511.08915.pdf", "metadata": {"source": "META", "title": "Column-Oriented Datalog Materialization for Large Knowledge Graphs", "authors": ["Jacopo Urbani", "Ceriel Jacobs", "Markus Kr\u00f6tzsch"], "emails": ["jacopo@cs.vu.nl", "c.j.h.jacobs@vu.nl", "markus.kroetzsch@tu-dresden.de"], "sections": [{"heading": "Introduction", "text": "In fact: There are many types of people who are able to take themselves into account. (...) There are people who are able, are able, are able to act. (...) There are people who are able, are able, are able, are able, are able to act. (...) There are people who are able, are able, are able, are able to act. (...) There are people who are able, are able, are able, are able to act. \"(...) There are people who are able, are able, are able, are able, are able to act.\" (...) There are people who are able, are able, are able, are able to act. \"(...) There are people who are able, are able, are able, are able, are able to act.\" (...) There are people who are able, are able to act. \""}, {"heading": "Preliminaries", "text": "We define Datalog in the usual way r is an expression of B1 in which we are more intense. (DB 1) We assume that a fixed signature consisting of an infinite number of constant symbols, an infinite number of predicates and an infinite set of variable symbols (z, v, w for variables; and a, b, c for constants. Expressions such as t, x and a denote finite list of such entities. An atom is an expression p (t) with p, p, v, w for variables; and a, c for constants such as t, c for constants. Expressions such as t, x, and a denote list of such entities is an expression p (t)."}, {"heading": "Semi-Naive Evaluation", "text": "Our goal is to calculate the materialization P \u221e (I) using a variant of the well-known method of semi-na\u00efve evaluation (SNE) (Abiteboul, Hull, and Vianu 1995), which is based on a finer-grained concept of the derivative approach. However, in each step of the algorithm, we apply a rule that is applied to the previously derived facts. We do this fairly, so that each rule is applied arbitrarily frequently. This differs from standard SNE, where all rules are applied in parallel in each step. We write the rule [i] for the rule that is applied in step i, and believe that it is derived for the set of new facts with predicate p. Note that p = prediction of the rule [i] is not the head. In addition, we define for the numbers 0 \u2264 i \u2264 j, the sentences [i, j] p] p."}, {"heading": "Column-Oriented Datalog Materialization", "text": "To turn this into an efficient algorithm, we use a column-based storage layout called nex.Our algorithms distinguish the data structures used to store the initial knowledge (EDB layer) from which derivatives (IDB layer) are used (IDB layer) as shown in the illustration. Our work is inspired by column-based databases (Idreos et al. 2012), an alternative to traditional row-based databases for efficiently storing large volumes of data. Their superior performance in analytical queries is compensated by lower performance for data updates."}, {"heading": "Dynamic Optimization", "text": "An important advantage of our approach is that we can exclude individual blocks when applying a rule, based on all the information currently available. We now present three different optimization techniques that aim to do just that. In any case, we assume that we have performed i-derivative steps and want to apply rule r of form (7) in step i + 1, and that j < i + 1 was the last step in which r was applied. We look at each of the m versions of the SNE rule (9) separately, starting by collecting for each IDB atom qk (sk) in the body of r the relevant range of non-empty tables. We also note which rule [o] was used to create this table in step o."}, {"heading": "Mismatching Rules", "text": "This happens when there are different constant symbols in the two atoms. In such a case, it is clear that none of the IDB facts in \u2206 oqk can contribute to concordances of qk (sk), so we can remove o from the list of blocks that are eligible for that body atom. In such a case, rule (3) can always ignore conclusions from rule (6), since the constants hasPart and owl: inverseOf do not match. We can even apply this optimization if the head of rule [o] is consistent with the body atom qk (sk) by evaluating the information contained in the partial results obtained when calculating the connection (10) from left to right."}, {"heading": "Redundant Rules", "text": "A rule is trivially redundant if its head-atom occurs in its body. Such rules need not be applied the other way round, since they can only elicit duplicate conclusions. Although trivially redundant rules are unlikely in practice, the combination of two rules often takes this form. Namely, if the head of rule [o] is united with qk (sk), we can resolve rule r with rule [o], i.e., apply backwards concatenation to obtain a rule of form: ro = p (t) \u2190 e1 (t1),., en (tn), q1 (s1),.., qk \u2212 1 (sk \u2212 1), body rule [o], qk + 1 (sk + 1),.. qm (sm). (12), where body rule [o] is a variant of the body of the rule [o] to which a more general unifier has been applied."}, {"heading": "Subsumed Rules", "text": "Many other optimizations can be realized with our novel memory layout. As a final example, we present an optimization that we have not yet implemented, but which we think is worth mentioning because it is theoretically sound and can point to a promising direction for future work. Namely, we consider the case where some of the conclusions of rule r have already been produced by another rule since the last application of r in step J. We say that rule r1 is subsumed by rule r2 when for all facts I, r1 (I) r2 (I) r2 (I). It is easy to calculate this based on the known method of verifying the subsumption of conjunctive queries (Abiteboul, Hull and Vianu 1995). If this case is detected, r1 can be ignored during materialization, which leads to another form of static optimization. However, this is rare in practice (a more common case is that a specific type of application of rule r2 is subsumed by r1."}, {"heading": "Memoization", "text": "The application of a rule with m IDB body atoms requires the evaluation of the m SNE rules of the form (9). Most of the associated relationships \u2206 [lk, uk] qk cover (almost) all the conclusions of the respective IDB atom, starting with lk = 0. Even if optimizations can eliminate many blocks in this range, the algorithm can devote considerable resources to calculating these optimizations and the remaining on-demand concatenation that may still be required. These costs occur for each application of the rule, even if there were no new inferences for qk since the last calculation. Therefore, rules with fewer IDB body atoms can be evaluated more quickly. In particular, rules with only one IDB body atom require only a single SNE rule using the limited range of blocks. [j, i] q1. To make this favorable situation, we can pre-calculate the extensions of selected IDB body atoms and then treat these atoms as part of the EDB."}, {"heading": "Evaluation", "text": "In this section we evaluate our approach based on a prototype implementation called VLog et al. \"Our main goal is to optimize materialization under limited resources.\" It is not our main goal to advance materialization under limited resources, we perform all evaluations on a laptop computer. \"We have the same data that was also used to evaluate RDFox (Motik et al. 2014).\" Datasets and database programs are available online.2 The datasets we have used are the cultural heritage ontology Claros (Motik et al. 2014), which DBpedia-KG extracts from the library (Motik et al.) The datasets and database programs we have used are the cultural heritage ontology Claros (Motik et al. 2014), which DBpedia KG extracts from the library (Motik et al.)"}, {"heading": "Discussion and Conclusions", "text": "We have introduced a new column-oriented approach to performing the materialization of datalog in memory over large KGs. Our goal was to perform this task efficiently and to minimize memory usage and CPU performance. Our evaluation shows that it is a viable alternative to existing datalog engines, resulting in competitive runtimes with significantly reduced memory usage. Our evaluation also identified some challenges that need to be addressed in future work. First, we observed that executing large connections can become problematic when many tables need to be scanned to remove duplicates, which was the main reason why the calculation could not be completed on time for some large datasets. Second, our implementation currently does not utilize multiple processors, and it will be interesting to see how techniques of intra- / interfractible parallelism can be applied in this environment. Third, we plan to investigate mechanisms for efficiently merging conclusions back into the input."}, {"heading": "Appendix: Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 1", "text": "First, note that the naive approach (8) leads to a unique model in which all the rules (I) are applied. (I) Remember that the latter rule was defined by applying all the rules at each step. (I) Now, let's look at an arbitrary, fair sequence of individual rules (1). (I) Each of these rules is applied naively as in (8). (I) It should be noted that it is also complete in the sense that P). (I) Since we apply rules fairly, there is a sequence of derivatives i1 < i2 < i3 < i2 < i2 < i3 <. as each rule is applied in every interval of the form. (I) It is a sequence of derivatives i1 < i2 < i2 < i2 < i2 < i2 < i3 < i3 < ii."}, {"heading": "Proof of Theorem 2", "text": "This assertion follows directly from the definitions. Consider in detail Rk and rule [o] as in the claim of the theorem. Moreover, Rm is the set of all complete rule field concordances that could be calculated without taking into account any optimization. Rk. / Rm Rm, i.e. Rm contains only tuples that are compatible with Rk. According to the assumption in the theorem, the atom qk (sk) \u03c3 does not unite with the ruling head [o]. Therefore \u2206 oqk does not contain a fact that is compatible with Rk, i.e. Rk. / \u0445oqk = \u2205 (the connection here is intended to combine the positions according to the terms used in qk (sk). This implies that Rm. / \u0445oqk = \u0438, and thus \u0441oqk need not be taken into account in order to find concordances of qk (sk) in the compatibility of Rm."}, {"heading": "Proof of Theorem 3", "text": "The assertion is again quite straightforward, but we spell it out in detail for completeness. Suppose we apply a q rule of form (7) in step i + 1 after it was last applied in step j. We use a similar notation for (partial) connections as in the proof of theorem 2 in the previous section. Furthermore, we let the rule [o] be of the following form: rule [o] = qk (t) \u2190 e \"1 (t\" 1),., e \"n\" (t \"n\"), q \"1 (s\" 1),., q \"m\" (s \"m\"). As shown in theorem 1, \"qk\" is the same set of facts that would arise by evaluating a naive version of rule [o] in step o, i.e., by using a compilation of form mpqk (t \"), p.\""}], "references": [{"title": "D", "author": ["Abadi"], "venue": "J.; Marcus, A.; Madden, S.; and Hollenbach, K.", "citeRegEx": "Abadi et al. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Integrating compression and execution in column-oriented database systems", "author": ["Madden Abadi", "D. Ferreira 2006] Abadi", "S. Madden", "M. Ferreira"], "venue": "In Proceedings of SIGMOD,", "citeRegEx": "Abadi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2006}, {"title": "Schema-agnostic query rewriting for SPARQL 1.1", "author": ["Bischoff"], "venue": "In Proc. 13th Int. Semantic Web Conf. (ISWC\u201914),", "citeRegEx": "Bischoff,? \\Q2014\\E", "shortCiteRegEx": "Bischoff", "year": 2014}, {"title": "OWLIM: a family of scalable semantic repositories", "author": ["Bishop"], "venue": "Semantic Web Journal 2(1):33\u201342", "citeRegEx": "Bishop,? \\Q2011\\E", "shortCiteRegEx": "Bishop", "year": 2011}, {"title": "DBpedia \u2013 A crystallization point for the Web of Data", "author": ["Bizer"], "venue": "J. of Web Semantics", "citeRegEx": "Bizer,? \\Q2009\\E", "shortCiteRegEx": "Bizer", "year": 2009}, {"title": "and Koenig", "author": ["B. Bonet"], "venue": "S., eds.", "citeRegEx": "Bonet and Koenig 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Ontology-based querying with Bio2RDF\u2019s linked open data", "author": ["Cruz-Toledo Callahan", "A. Dumontier 2013] Callahan", "J. Cruz-Toledo", "M. Dumontier"], "venue": "J. of Biomedical Semantics 4(S-1)", "citeRegEx": "Callahan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Callahan et al\\.", "year": 2013}, {"title": "LUBM: A benchmark for OWL knowledge base systems. Web Semantics: Science, Services and Agents on the World Wide Web 3:158\u2013182", "author": ["Pan Guo", "Y. Heflin 2005] Guo", "Z. Pan", "J. Heflin"], "venue": null, "citeRegEx": "Guo et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2005}, {"title": "F", "author": ["Hoffart, J.", "Suchanek"], "venue": "M.; Berberich, K.; and Weikum, G.", "citeRegEx": "Hoffart et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "M", "author": ["S. Idreos", "F. Groffen", "N. Nes", "S. Manegold", "K.S. Mullender", "Kersten"], "venue": "L.", "citeRegEx": "Idreos et al. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimizing enterprise-scale OWL 2 RL reasoning in a relational database system", "author": ["Wu Kolovski", "V. Eadon 2010] Kolovski", "Z. Wu", "G. Eadon"], "venue": "In Proc. 9th Int. Semantic Web Conf. (ISWC\u201910),", "citeRegEx": "Kolovski et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kolovski et al\\.", "year": 2010}, {"title": "M", "author": ["Kr\u00f6tzsch"], "venue": "2011. Efficient rule-based inferencing for OWL EL. In Walsh, T., ed., Proc. 22nd Int. Joint Conf. on Artificial Intelligence (IJCAI\u201911), 2668\u2013", "citeRegEx": "Kr\u00f6tzsch 2011", "shortCiteRegEx": null, "year": 2673}, {"title": "OWL 2 Web Ontology Language: Profiles", "author": ["Motik"], "venue": null, "citeRegEx": "Motik,? \\Q2009\\E", "shortCiteRegEx": "Motik", "year": 2009}, {"title": "Parallel materialisation of Datalog programs in centralised, main-memory RDF systems", "author": ["Motik"], "venue": "In Proc. AAAI\u201914,", "citeRegEx": "Motik,? \\Q2014\\E", "shortCiteRegEx": "Motik", "year": 2014}, {"title": "Combining rewriting and incremental materialisation maintenance for datalog programs with equality", "author": ["Motik"], "venue": "In Proc. 24th Int. Joint Conf. on Artificial Intelligence", "citeRegEx": "Motik,? \\Q2015\\E", "shortCiteRegEx": "Motik", "year": 2015}, {"title": "Handling owl:sameAs via rewriting", "author": ["Motik"], "venue": null, "citeRegEx": "Motik,? \\Q2015\\E", "shortCiteRegEx": "Motik", "year": 2015}, {"title": "Incremental update of datalog materialisation: the backward/forward algorithm", "author": ["B. Motik", "Y. Nenov", "R. Piro", "I. Horrocks"], "venue": null, "citeRegEx": "Motik et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Motik et al\\.", "year": 2015}, {"title": "The RDF3X engine for scalable management of RDF data", "author": ["T. Neumann", "G. Weikum"], "venue": "VLDB J. 19(1):91\u2013113", "citeRegEx": "2010", "shortCiteRegEx": "2010", "year": 2010}, {"title": "Marvin: Distributed reasoning over large-scale Semantic Web data", "author": ["E. Oren", "S. Kotoulas", "G. Anadiotis", "R. Siebes", "A. ten Teije", "F. van Harmelen"], "venue": "J. of Web Semantics", "citeRegEx": "2009", "shortCiteRegEx": "2009", "year": 2009}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S. Russell", "P. Norvig"], "venue": null, "citeRegEx": "2003", "shortCiteRegEx": "2003", "year": 2003}, {"title": "WebPIE: A Web-scale Parallel Inference Engine using MapReduce", "author": ["J. Urbani", "S. Kotoulas", "J. Maassen", "F. Van Harmelen", "H. Bal"], "venue": "Journal of Web Semantics", "citeRegEx": "2012", "shortCiteRegEx": "2012", "year": 2012}, {"title": "Dynamite: Parallel materialization of dynamic RDF data", "author": ["J. Urbani", "A. Margara", "C. Jacobs", "F. van Harmelen", "H. Bal"], "venue": "In The Semantic Web\u2013ISWC", "citeRegEx": "2013", "shortCiteRegEx": "2013", "year": 2013}, {"title": "Hybrid reasoning on OWL RL", "author": ["J. Urbani", "R. Piro", "F. van Harmelen", "H. Bal"], "venue": "Semantic Web 5(6):423\u2013447", "citeRegEx": "2014", "shortCiteRegEx": "2014", "year": 2014}, {"title": "Column-oriented Datalog materialization for large knowledge graphs", "author": ["J. Urbani", "C. Jacobs", "M. Kr\u00f6tzsch"], "venue": "In Proc", "citeRegEx": "2016", "shortCiteRegEx": "2016", "year": 2016}, {"title": "Wikidata: A free collaborative knowledge base. Commun", "author": ["D. Vrande\u010di\u0107", "M. Kr\u00f6tzsch"], "venue": null, "citeRegEx": "2014", "shortCiteRegEx": "2014", "year": 2014}, {"title": "Parallel materialization of the finite RDFS closure for hundreds of millions of triples", "author": ["J. Weaver", "J.A. Hendler"], "venue": "In Proc. 8th Int. Semantic Web Conf. (ISWC\u201909),", "citeRegEx": "2009", "shortCiteRegEx": "2009", "year": 2009}], "referenceMentions": [], "year": 2016, "abstractText": "The evaluation of Datalog rules over large Knowledge Graphs (KGs) is essential for many applications. In this paper, we present a new method of materializing Datalog inferences, which combines a column-based memory layout with novel optimization methods that avoid redundant inferences at runtime. The pro-active caching of certain subqueries further increases efficiency. Our empirical evaluation shows that this approach can often match or even surpass the performance of state-of-the-art systems, especially under restricted resources.", "creator": "LaTeX with hyperref package"}}}