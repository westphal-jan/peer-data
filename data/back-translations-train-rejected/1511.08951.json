{"id": "1511.08951", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2015", "title": "MidRank: Learning to rank based on subsequences", "abstract": "We present a supervised learning to rank algorithm that effectively orders images by exploiting the structure in image sequences. Most often in the supervised learning to rank literature, ranking is approached either by analyzing pairs of images or by optimizing a list-wise surrogate loss function on full sequences. In this work we propose MidRank, which learns from moderately sized sub-sequences instead. These sub-sequences contain useful structural ranking information that leads to better learnability during training and better generalization during testing. By exploiting sub-sequences, the proposed MidRank improves ranking accuracy considerably on an extensive array of image ranking applications and datasets.", "histories": [["v1", "Sun, 29 Nov 2015 00:47:19 GMT  (538kb,D)", "http://arxiv.org/abs/1511.08951v1", "To appear in ICCV 2015"]], "COMMENTS": "To appear in ICCV 2015", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["basura fernando", "efstratios gavves", "damien muselet", "tinne tuytelaars"], "accepted": false, "id": "1511.08951"}, "pdf": {"name": "1511.08951.pdf", "metadata": {"source": "CRF", "title": "MidRank: Learning to rank based on subsequences", "authors": ["Basura Fernando", "Efstratios Gavves", "Damien Muselet", "Jean Monnet", "Tinne Tuytelaars"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This year it will be able to introduce the aforementioned brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated csrteBnlrc\u00fce."}, {"heading": "2 Related work", "text": "These methods are limited to pairwise loss functions. Pairwise methods, however, do not explicitly calculate the differences between two input elements at once and learn a binary decision function that outputs whether one element precedes the other or vice versa. Of course, pairwise methods do not use structural information that goes beyond what an element pair can provide. List-wise methods [7, 39, 41, 42, 36, 40], on the other hand, formulate a loss on whole lists, enabling them to use more relevant ranking metrics such as the NDCG or the KendallTau.We present MidRank, which belongs to a fourth family of learning processes positioned between pairwise and list-wise."}, {"heading": "3 MidRank", "text": "We start from a series of ordered image sequences. Each sequence arranges the images according to a predetermined criterion, e.g. images ranging from the happiest to the most dissatisfied face or from the oldest to the most modern car. Our goal is to learn from the data in a controlled way a ranking, so that we can order a new list of invisible images according to the same criterion. Basic notations. Our training set consists of N ordered image sequences, D = {Xi, Yi, 'i}, i = 1,...., N. Xi stands for an image sequence [xi1, x i 2,..., x i] that contains \"i images in which\" i can speak for different sequences Xi. Yi is a permutation vector Yi = [\u03c0 (1),..., \u03c0 (' i)], and represents that the correct sequence of images in the sequence is xi\u03c0 (1) x i (2) \u00b7 xi\u043c ('i)."}, {"heading": "3.1 Ranking sequences", "text": "Let's say a new list of never-before-seen images, X \u2032 = [x \u2032 1,..., q \u2032 \"\u2032. We define a ranking score function z (X \u2032, Y \u2032) that gives the highest score for the correct order of images Y.\" Given a reasonable loss function \u03b4 (\u00b7, \u00b7), our learning objective is the parameters for our ranking function. The score function z (X \u2032, Y \") should be applicable to any length that a new sequence X\" might have. To this end, we split the sequence X \"into a series of sub-sequences of a certain length."}, {"heading": "3.2 Training \u03bb-subsequence rankers", "text": "After splitting an unrestricted ranking problem into a combination of restricted, length-specific subsequence ranking problems, however, we need a learning algorithm to optimize \u03d1. (1) and eq. (3) Therefore, we train the parameters \u03d1 for a certain subsequence length, such as the following: The loss function Li (\u03bb) j measures the loss of the j-th subsequence of the length of the i-th original sequence. (4) We need both positive and negative subsequences. In training, we stomp subsequences of standardized lengths. Although we can reduce positive subsequences of all possible lengths, in practice we concentrate on subsequences up to a length of 7-10. In order to generate negative subsequences, we correct these subsequences."}, {"heading": "3.3 Ranking-friendly feature maps", "text": "We discuss three different representations for X (\u03bb).Mean pair-by-pair difference representation. Herbrich et al. [18] eloquently demonstrated that the difference in vector representation yields accurate results for learning a pair-by-pair precedence. (However, for this representation, we have such a difference (X, Y) = 1 | {(i, j) \u2212 sequential difference representation is perhaps the most popular choice in the Learning-to-Rank literature. [18, 34, 27, 24, 10] In the specific case of \u03bb = 2, we end with the standard SVM [19] and SVR [34] Lernobjectiv. Stacked representation."}, {"heading": "3.4 Multi-length MidRank", "text": "So far, we have concentrated on partial sequences of fixed length \u03bb. A natural extension is to look at several partial sequence lengths, since different lengths are likely to capture different aspects of the sample sequences and partial sequences. To train a multi-length ranking, we simply look at each length in equivalents (4) separately, namely \u03bb = 2, 3, 4,.., L. To derive the final ranking order from this, we need to merge the results of the different rankings. To this end, we propose a weighted majority voting scheme. For each test instance X \u2032 we get one ranking per \u03bb and the respective ranking value from z (\u00b7). As a result, we have rankings for each of the L \u2212 1 rankings. Then, each image in the test sequence receives a vote for its respective position, which is returned by each ranking. In addition, each image receives a vote result proportional to the ranking result from z (\u00b7), and thus the reliability of the ranking for the placement of this image at the respective position."}, {"heading": "4 Efficient inference", "text": "The solution of eq. (3) requires an explicit search across the space of all possible permutations in Y, which amounts to l! For a successful and practical conclusion, we must solve this combinatorial problem. Inspired by random forests [6] and the most appropriate search strategies [3], we propose the following greedy search algorithm. For a visual illustration of the algorithm, we refer to Figure 2. We proceed from an initial ranking solution Y (0) obtained from a less precise but manageable ranking algorithm (e.g. RankSVM). Given the fact that Y (0) creates a series of permutations designated by {Y (1)}, so that the new permutations are achieved by swapping only a pair of elements of Y (0)."}, {"heading": "5 Experiments", "text": "To compare MidRank with other monitored Learning Torank algorithms, we select three monitored image re-ranking applications, namely ranking public figures (Section 5.2), arranging images based on interest (Section 5.3), and chronological order of auto-images (Section 5.4). Next, we analyze the characteristics and efficiency of MidRank under various parameters in Section 5.5."}, {"heading": "5.1 Evaluation criteria & implementation details", "text": "We evaluate all methods with respect to the following ranking indicators. First, we use the normalized discounted cumulative result NDCG, which is commonly used to evaluate ranking algorithms [25]. The discounted cumulative gain at position k is defined as DCG @ k = \u2211 k i = 1 2reli \u2212 1 log2 (i + 1), with reli being the relevance of the image at position i. To obtain the normalized DCG, the DCG @ k value is divided by the ideal DCG value. NDCG, whose range is [0, 1] is strongly non-linear. For example, it goes from 0.940 to 0.950 for a significant improvement in the sequence. We also use the Kendall tau, which better captures how close we are to the perfect ranking. KendallTau accuracy is defined as KT = l + \u2212 l \u2212 0.5 l (l \u2212 1). We stand for the number of pairs in the sequence."}, {"heading": "5.2 Ranking Public Figures", "text": "The data set consists of images of eight public figures and eleven visual attributes of them, such as big lips, white and chubby. Our goal is to learn rankings for these attributes. As there are 8 public figures, we report the results of the longest possible test sequence size consisting of 8 images. For each of the 11 attributes, we sample 10,000 train sequences of length 8 and 20,000 test sequences, a total of 220,000 test sequences for all attributes. We use the standard GIST characteristics provided with the data set. Results are reported by taking the average across all eleven attributes and across all test sequences. See the results in Table 1. We find that MidRank significantly improves the accuracy of the ranking for all evaluation criteria. For Kendall-Tau, MidRank brings an absolute improvement of + 10.5%. It is worth noting that this individual function in the middle of the ranking 7 was the best."}, {"heading": "5.3 Ranking Interestingness", "text": "We look at tensile and test sequences of size 20. It is not possible to consider much longer sequences because the comment pool for interest in this data set is limited. In practice, it would be difficult even for people to evaluate more than 20 images based on interest. We use the scene category data set from [26], the images of which were later commented on in terms of interest around [17]. We extract GIST [26] characteristics and construct 10,000 tensile sequences and 20,000 test sequences. Note that this is a difficult task as interest is a subjective criterion that can be assigned to many different factors within an image. See results in Table 1. We note that even for this data set MidRank has significantly better accuracy than the competitive methods for all evaluation criteria. For visual results obtained from our method, see Figure 3 (random example). As we can see, MidRank gives a visual return that comes very close to the truth."}, {"heading": "5.4 Chronological ordering of cars", "text": "As a final application, we consider the task of rearranging images chronologically. We use the vehicle data set of [21]. The chronology of the cars is in the range of 1920, 1921,..., 1999. As an image representation, we use 64-Gaussian Fisher vectors [28], which were calculated on dense SIFT characteristics after they were reduced to 64 dimensions with PCA. To control dimensionality, we also reduce Fisher vectors with PCA to 1000 dimensions. Similar to the previous experiment, we produce 10,000 training sequences and 20,000 test sequences of length 20. See also the results in Table 1. Again, MidRank achieves significantly better results than the competing methods for all evaluation criteria and in particular for the Kendall-tau accuracy (+ 7.1%). We show some visual results in Fig. 3. We also experimented with training sequence lengths of 5, 10, 15, 20 and test sequence lengths of 5, 10, 20, 80. Due to the brevity of the test, however, we have very few practical results between the cases."}, {"heading": "5.5 Detailed analysis of MidRank", "text": "It is also interesting to see that all three evaluation measures are consistent (see Figure 4). Next, we evaluate the relationship between MidRank accuracy and training sequence. We use size 20 sequences for training and testing generated from the auto data set. We evaluate different ranking functions from size 3 to 8. We plot the results in Fig. 4 (a). For all ranking measures, the best evaluation is size 7. Interestingly, ranking performance gradually increases to the point where the training sequence size increases. This indicates that MidRank ranking modeling is limited to moderately large sequences that work better than very large ones. Small MidRank models are easy to train (small training errors), but solve a relatively simple ranking sub-problem. In contrast, large MidRank models are more difficult to train (major training errors). Our experiments suggest that sequences are best for mid-ranking methods."}, {"heading": "6 Conclusion", "text": "In this paper we present a method of supervised ranking learning, MidRank, which learns from sub-sequences. We present a novel stacked differential vector representation and an effective ranking algorithm, which uses sub-sequences during learning. The proposed method achieves significant improvements over state-of-the-art pair-wise and list-wise ranking methods. Furthermore, we show that MidRank enables better learning of ranking functions in multiple image order tasks by using structural information and regularity in sub-sequences. The authors acknowledge the support of the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016), the PARIS project (IWT-SBO-No.110067), the iMinds project HiViz and the ANR project SoLStiCe (ANR-13-BS02-0002-01)."}], "references": [{"title": "Good practice in large-scale learning for image classification", "author": ["Z. Akata", "F. Perronnin", "Z. Harchaoui", "C. Schmid"], "venue": "PAMI, 36:507\u2013520", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Three things everyone should know to improve object retrieval", "author": ["R. Arandjelovi\u0107", "A. Zisserman"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2911\u20132918. IEEE", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Shape indexing using approximate nearest-neighbour search in high-dimensional spaces", "author": ["J.S. Beis", "D.G. Lowe"], "venue": "CVPR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1997}, {"title": "Tres observaciones sobre el algebra lineal", "author": ["D. Birkhoff"], "venue": "Universidad Nacional de Tucuman Revista , Serie A, 5:147151", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1946}, {"title": "A theoretical analysis of feature pooling in visual recognition", "author": ["Y. Boureau", "J. Ponce", "Y. LeCun"], "venue": "ICML", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine Learning, 45(1):5\u2013 32", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning to rank: from pairwise approach to listwise approach", "author": ["Z. Cao", "T. Qin", "T. Liu", "M. Tsai", "H. Li"], "venue": "ICML", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Probabilistic retrieval based on staged logistic regression", "author": ["W.S. Cooper", "F.C. Gey", "D.P. Dabney"], "venue": "SIGIR", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1992}, {"title": "Linear ranking analysis", "author": ["W. Deng", "J. Hu", "J. Guo"], "venue": "CVPR", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to rank using high-order information", "author": ["P. Dokania", "A. Behl", "C. Jawahar", "M. Kumar"], "venue": "ECCV", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to rank based on subsequences", "author": ["B. Fernando", "E. Gavves", "D. Muselet", "T. Tuytelaars"], "venue": "ICCV", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Modeling video evolution for action recognition", "author": ["B. Fernando", "E. Gavves", "J. Oramas", "A. Ghodrati", "T. Tuytelaars"], "venue": "CVPR", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Color features for dating historical color", "author": ["B. Fernando", "D. Muselet", "R. Khan", "T. Tuytelaars"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Location recognition over large time lags", "author": ["B. Fernando", "T. Tommasi", "T. Tuytelaars"], "venue": "Computer Vision and Image Understanding, 139:21\u201328", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Mining multiple queries for image retrieval: On-the-fly learning of an object-specific mid-level representation", "author": ["B. Fernando", "T. Tuytelaars"], "venue": "ICCV", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Interestingness prediction by robust learning to rank", "author": ["Y. Fu", "T. Hospedales", "T. Xiang", "S. Gong", "Y. Yao"], "venue": "ECCV", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "The interestingness of images", "author": ["M. Gygli", "H. Grabner", "H. Riemenschneider", "F. Nater", "L. Van Gool"], "venue": "ICCV", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Large margin rank boundaries for ordinal regression", "author": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "NIPS, pages 115\u2013132", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Training linear svms in linear time", "author": ["T. Joachims"], "venue": "SIGKDD", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Style-aware mid-level representation for discovering visual connections in space and time", "author": ["Y.J. Lee", "A. Efros", "M. Hebert"], "venue": "ICCV", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Mcrank: Learning to rank using multiple classification and gradient boosting", "author": ["P. Li", "Q. Wu", "C.J. Burges"], "venue": "NIPS, pages 897\u2013904", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Beyond comparing image pairs: Setwise active learning for relative attributes", "author": ["L. Liang", "K. Grauman"], "venue": "CVPR", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Optimizing ranking measures for compact binary code learning", "author": ["G. Lin", "C. Shen", "J. Wu"], "venue": "ECCV", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to rank for information retrieval", "author": ["T.-Y. Liu"], "venue": "Foundations and Trends in Information Retrieval, 3(3):225\u2013 331", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "author": ["A. Oliva", "A. Torralba"], "venue": "IJCV, 42(3):145\u2013175", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "Relative attributes", "author": ["D. Parikh", "K. Grauman"], "venue": "ICCV", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}, {"title": "Improving the fisher kernel for large-scale image classification", "author": ["F. Perronnin", "J. S\u00e1nchez", "T. Mensink"], "venue": "ECCV", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "and T", "author": ["K. Rematas", "B. Fernando", "T. Tommasi"], "venue": "Tuytelaars. Does evolution cause a domain shift? In International Workshop on Visual Domain Adaptation and Dataset Bias - ICCV 2013", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "The linear ordering problem: Instances", "author": ["T. Schiavinotto", "T. St\u00fctzle"], "venue": "search space analysis and algorithms. Journal of Mathematical Modelling and Algorithms, 3(4):367\u2013402", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "Large scale learning to rank", "author": ["D. Sculley"], "venue": "NIPS", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical programming, 127(1):3\u201330", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning to rank using privileged information", "author": ["V. Sharmanska", "N. Quadrianto", "C.H. Lampert"], "venue": "ICCV", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "A tutorial on support vector regression", "author": ["A.J. Smola", "B. Sch\u00f6lkopf"], "venue": "Statistics and computing, 14(3):199\u2013222", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2004}, {"title": "Ranking domainspecific highlights by analyzing edited videos", "author": ["M. Sun", "A. Farhadi", "S.M. Seitz"], "venue": "ECCV", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Softrank: optimizing non-smooth rank metrics", "author": ["M. Taylor", "J. Guiver", "S. Robertson", "T. Minka"], "venue": "Proceedings of the 2008 International Conference on Web Search and Data Mining, pages 77\u201386. ACM", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning to rank 3d features", "author": ["O. Tuzel", "M. Liu", "Y. Taguchi", "A. Raghunathan"], "venue": "ECCV", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Person reidentification by video ranking", "author": ["T. Wang", "S. Gong", "X. Zhu", "S. Wang"], "venue": "ECCV", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Adapting boosting for information retrieval measures", "author": ["Q. Wu", "C.J. Burges", "K.M. Svore", "J. Gao"], "venue": "Information Retrieval, 13(3):254\u2013270", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2010}, {"title": "Listwise approach to learning to rank: theory and algorithm", "author": ["F. Xia", "T.-Y. Liu", "J. Wang", "W. Zhang", "H. Li"], "venue": "ICML, pages 1192\u20131199. ACM", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2008}, {"title": "Adarank: a boosting algorithm for information retrieval", "author": ["J. Xu", "H. Li"], "venue": "SIGIR", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "A support vector method for optimizing average precision", "author": ["Y. Yue", "T. Finley", "F. Radlinski", "T. Joachims"], "venue": "ACM SIGIR, pages 271\u2013278. ACM", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 34, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 41, "endOffset": 45}, {"referenceID": 37, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 72, "endOffset": 76}, {"referenceID": 26, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 99, "endOffset": 103}, {"referenceID": 22, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 121, "endOffset": 125}, {"referenceID": 8, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 152, "endOffset": 155}, {"referenceID": 36, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 177, "endOffset": 181}, {"referenceID": 23, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 204, "endOffset": 208}, {"referenceID": 32, "context": "Some applications include video analysis [35], person re-identification [38], zeroshot recognition [27], active learning [23], dimensionality reduction [9], 3D feature analysis [37], binary code learning [24], learning from privileged information [33],", "startOffset": 247, "endOffset": 251}, {"referenceID": 15, "context": "interestingness prediction [16] and action recognition using rank pooling [12].", "startOffset": 27, "endOffset": 31}, {"referenceID": 11, "context": "interestingness prediction [16] and action recognition using rank pooling [12].", "startOffset": 74, "endOffset": 78}, {"referenceID": 14, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 89, "endOffset": 96}, {"referenceID": 1, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 89, "endOffset": 96}, {"referenceID": 16, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 144, "endOffset": 148}, {"referenceID": 20, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 163, "endOffset": 179}, {"referenceID": 13, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 163, "endOffset": 179}, {"referenceID": 28, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 163, "endOffset": 179}, {"referenceID": 12, "context": "In this context, we re-order the top-k retrieved images for example from an image search [15, 2] based on some criteria such as interestingness [17] or chronology [21, 14, 29, 13].", "startOffset": 163, "endOffset": 179}, {"referenceID": 6, "context": "Especially when complex and structured data is involved, considering only pairs during training may confuse the learning of rankers as shown in [7, 25, 42].", "startOffset": 144, "endOffset": 155}, {"referenceID": 24, "context": "Especially when complex and structured data is involved, considering only pairs during training may confuse the learning of rankers as shown in [7, 25, 42].", "startOffset": 144, "endOffset": 155}, {"referenceID": 41, "context": "Especially when complex and structured data is involved, considering only pairs during training may confuse the learning of rankers as shown in [7, 25, 42].", "startOffset": 144, "endOffset": 155}, {"referenceID": 6, "context": "Treatment of pairs of images as independent and identically distributed random variables during training is not ideal [7].", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "To exploit the structure in long sequences, list-wise methods [7, 36, 39, 40, 41, 42] optimize for ranking losses defined over sequences.", "startOffset": 62, "endOffset": 85}, {"referenceID": 35, "context": "To exploit the structure in long sequences, list-wise methods [7, 36, 39, 40, 41, 42] optimize for ranking losses defined over sequences.", "startOffset": 62, "endOffset": 85}, {"referenceID": 38, "context": "To exploit the structure in long sequences, list-wise methods [7, 36, 39, 40, 41, 42] optimize for ranking losses defined over sequences.", "startOffset": 62, "endOffset": 85}, {"referenceID": 39, "context": "To exploit the structure in long sequences, list-wise methods [7, 36, 39, 40, 41, 42] optimize for ranking losses defined over sequences.", "startOffset": 62, "endOffset": 85}, {"referenceID": 40, "context": "To exploit the structure in long sequences, list-wise methods [7, 36, 39, 40, 41, 42] optimize for ranking losses defined over sequences.", "startOffset": 62, "endOffset": 85}, {"referenceID": 41, "context": "To exploit the structure in long sequences, list-wise methods [7, 36, 39, 40, 41, 42] optimize for ranking losses defined over sequences.", "startOffset": 62, "endOffset": 85}, {"referenceID": 24, "context": "More specifically, as the number of wrong permutations grows exponentially with respect to the sequence length, list-wise methods often end up with a more difficult learning problem [25].", "startOffset": 182, "endOffset": 186}, {"referenceID": 29, "context": "Third, we introduce an accurate and efficient polynomial time testing algorithm for the NPhard [30] linear ordering problem to re-rank images in moderately sized sequences.", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "We evaluate our method on three different applications: ranking images of famous people according to relative visual attributes [27], ranking images according to how interesting they are [16] and ranking car images according to the chronology [21].", "startOffset": 128, "endOffset": 132}, {"referenceID": 15, "context": "We evaluate our method on three different applications: ranking images of famous people according to relative visual attributes [27], ranking images according to how interesting they are [16] and ranking car images according to the chronology [21].", "startOffset": 187, "endOffset": 191}, {"referenceID": 20, "context": "We evaluate our method on three different applications: ranking images of famous people according to relative visual attributes [27], ranking images according to how interesting they are [16] and ranking car images according to the chronology [21].", "startOffset": 243, "endOffset": 247}, {"referenceID": 10, "context": "This paper extends our the conference paper [11].", "startOffset": 44, "endOffset": 48}, {"referenceID": 7, "context": "Point-wise methods [8], which process each element in the sequence individually, are easy to train but prone to over-fitting.", "startOffset": 19, "endOffset": 22}, {"referenceID": 17, "context": "Pair-wise methods [18, 19, 31] compute the differences between two input elements at a time and learn a binary decision function that outputs whether one element precedes the other or vice-versa.", "startOffset": 18, "endOffset": 30}, {"referenceID": 18, "context": "Pair-wise methods [18, 19, 31] compute the differences between two input elements at a time and learn a binary decision function that outputs whether one element precedes the other or vice-versa.", "startOffset": 18, "endOffset": 30}, {"referenceID": 30, "context": "Pair-wise methods [18, 19, 31] compute the differences between two input elements at a time and learn a binary decision function that outputs whether one element precedes the other or vice-versa.", "startOffset": 18, "endOffset": 30}, {"referenceID": 6, "context": "List-wise methods [7, 39, 41, 42, 36, 40], on the other hand formulate a loss on whole lists, thus being able to optimize more relevant ranking measures like the NDCG or the KendallTau.", "startOffset": 18, "endOffset": 41}, {"referenceID": 38, "context": "List-wise methods [7, 39, 41, 42, 36, 40], on the other hand formulate a loss on whole lists, thus being able to optimize more relevant ranking measures like the NDCG or the KendallTau.", "startOffset": 18, "endOffset": 41}, {"referenceID": 40, "context": "List-wise methods [7, 39, 41, 42, 36, 40], on the other hand formulate a loss on whole lists, thus being able to optimize more relevant ranking measures like the NDCG or the KendallTau.", "startOffset": 18, "endOffset": 41}, {"referenceID": 41, "context": "List-wise methods [7, 39, 41, 42, 36, 40], on the other hand formulate a loss on whole lists, thus being able to optimize more relevant ranking measures like the NDCG or the KendallTau.", "startOffset": 18, "endOffset": 41}, {"referenceID": 35, "context": "List-wise methods [7, 39, 41, 42, 36, 40], on the other hand formulate a loss on whole lists, thus being able to optimize more relevant ranking measures like the NDCG or the KendallTau.", "startOffset": 18, "endOffset": 41}, {"referenceID": 39, "context": "List-wise methods [7, 39, 41, 42, 36, 40], on the other hand formulate a loss on whole lists, thus being able to optimize more relevant ranking measures like the NDCG or the KendallTau.", "startOffset": 18, "endOffset": 41}, {"referenceID": 9, "context": "In [10] Dokania et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 38, "context": "MidRank is also different from existing methods that use multiple weak rankers, such as LambdaMART [39] and AdaRank [41], which propose a linear combination of weak rankers, with iterative re-weighting of the training samples and rankers during training.", "startOffset": 99, "endOffset": 103}, {"referenceID": 40, "context": "MidRank is also different from existing methods that use multiple weak rankers, such as LambdaMART [39] and AdaRank [41], which propose a linear combination of weak rankers, with iterative re-weighting of the training samples and rankers during training.", "startOffset": 116, "endOffset": 120}, {"referenceID": 18, "context": "(3) is a generalization of the inference in pairwise ranking methods, like RankSVM [19], where \u03bb = 2.", "startOffset": 83, "endOffset": 87}, {"referenceID": 19, "context": "(3) is similar in spirit to convolutional neural network models [20], which decompose the input of unconstrained size to a series of overlapping operations.", "startOffset": 64, "endOffset": 68}, {"referenceID": 0, "context": "However, this would create a heavily imbalanced dataset, which might influence the generalization of the learnt rankers [1].", "startOffset": 120, "endOffset": 123}, {"referenceID": 31, "context": "(4) we use the stochastic dual coordinate ascent (SDCA) method [32], which can handle imbalanced or very large training problems [32].", "startOffset": 63, "endOffset": 67}, {"referenceID": 31, "context": "(4) we use the stochastic dual coordinate ascent (SDCA) method [32], which can handle imbalanced or very large training problems [32].", "startOffset": 129, "endOffset": 133}, {"referenceID": 17, "context": "[18] eloquently showed that the difference of vector representation yields accurate results for learning a pairwise ranking function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "The mean pairwise difference representation is perhaps the most popular choice in the learning-to-rank literature [18, 34, 19, 27, 24, 10].", "startOffset": 114, "endOffset": 138}, {"referenceID": 33, "context": "The mean pairwise difference representation is perhaps the most popular choice in the learning-to-rank literature [18, 34, 19, 27, 24, 10].", "startOffset": 114, "endOffset": 138}, {"referenceID": 18, "context": "The mean pairwise difference representation is perhaps the most popular choice in the learning-to-rank literature [18, 34, 19, 27, 24, 10].", "startOffset": 114, "endOffset": 138}, {"referenceID": 26, "context": "The mean pairwise difference representation is perhaps the most popular choice in the learning-to-rank literature [18, 34, 19, 27, 24, 10].", "startOffset": 114, "endOffset": 138}, {"referenceID": 23, "context": "The mean pairwise difference representation is perhaps the most popular choice in the learning-to-rank literature [18, 34, 19, 27, 24, 10].", "startOffset": 114, "endOffset": 138}, {"referenceID": 9, "context": "The mean pairwise difference representation is perhaps the most popular choice in the learning-to-rank literature [18, 34, 19, 27, 24, 10].", "startOffset": 114, "endOffset": 138}, {"referenceID": 18, "context": "In the specific case of \u03bb = 2 we end up with the standard rank SVM [19] and the SVR [34] learning objectives.", "startOffset": 67, "endOffset": 71}, {"referenceID": 33, "context": "In the specific case of \u03bb = 2 we end up with the standard rank SVM [19] and the SVR [34] learning objectives.", "startOffset": 84, "endOffset": 88}, {"referenceID": 3, "context": "An interesting property of stacked representations comes from the field of combinatorial geometry [4].", "startOffset": 98, "endOffset": 101}, {"referenceID": 3, "context": "From combinatorial geometry we know that all permutations of a vector are vertices of a Birkhoff polytope [4].", "startOffset": 106, "endOffset": 109}, {"referenceID": 17, "context": "Inspired from [18] and the stacked representations, we can also represent a sequence of images as \u03c8(X,Y) = [(x\u03c0(1) \u2212 x\u03c0(2)) T , .", "startOffset": 14, "endOffset": 18}, {"referenceID": 5, "context": "Inspired by random forests [6] and the best-bin-first search strategies [3], we propose the following greedy search algorithm.", "startOffset": 27, "endOffset": 30}, {"referenceID": 2, "context": "Inspired by random forests [6] and the best-bin-first search strategies [3], we propose the following greedy search algorithm.", "startOffset": 72, "endOffset": 75}, {"referenceID": 24, "context": "First, we use the normalized discounted cumulative gain NDCG, commonly used to evaluate ranking algorithms [25].", "startOffset": 107, "endOffset": 111}, {"referenceID": 0, "context": "NDCG, whose range is [0, 1], is strongly non-linear.", "startOffset": 21, "endOffset": 27}, {"referenceID": 33, "context": "We compare our MidRank with point-wise methods such as SVR [34], McRank [22], pair-wise methods such as RankSVM [19], Relative Attributes [27] and CRR [31].", "startOffset": 59, "endOffset": 63}, {"referenceID": 21, "context": "We compare our MidRank with point-wise methods such as SVR [34], McRank [22], pair-wise methods such as RankSVM [19], Relative Attributes [27] and CRR [31].", "startOffset": 72, "endOffset": 76}, {"referenceID": 18, "context": "We compare our MidRank with point-wise methods such as SVR [34], McRank [22], pair-wise methods such as RankSVM [19], Relative Attributes [27] and CRR [31].", "startOffset": 112, "endOffset": 116}, {"referenceID": 26, "context": "We compare our MidRank with point-wise methods such as SVR [34], McRank [22], pair-wise methods such as RankSVM [19], Relative Attributes [27] and CRR [31].", "startOffset": 138, "endOffset": 142}, {"referenceID": 30, "context": "We compare our MidRank with point-wise methods such as SVR [34], McRank [22], pair-wise methods such as RankSVM [19], Relative Attributes [27] and CRR [31].", "startOffset": 151, "endOffset": 155}, {"referenceID": 40, "context": "We also compare with list-wise methods such as AdaRank [41], LambdaMART [39], ListNET [7] and", "startOffset": 55, "endOffset": 59}, {"referenceID": 38, "context": "We also compare with list-wise methods such as AdaRank [41], LambdaMART [39], ListNET [7] and", "startOffset": 72, "endOffset": 76}, {"referenceID": 6, "context": "We also compare with list-wise methods such as AdaRank [41], LambdaMART [39], ListNET [7] and", "startOffset": 86, "endOffset": 89}, {"referenceID": 26, "context": "Table 1: Evaluating ranking methods on three datasets and applications: ranking public figures using relative attributes of [27], ranking scenes according to how interesting they look [17] and ranking cars according to their manufacturing date [21].", "startOffset": 124, "endOffset": 128}, {"referenceID": 16, "context": "Table 1: Evaluating ranking methods on three datasets and applications: ranking public figures using relative attributes of [27], ranking scenes according to how interesting they look [17] and ranking cars according to their manufacturing date [21].", "startOffset": 184, "endOffset": 188}, {"referenceID": 20, "context": "Table 1: Evaluating ranking methods on three datasets and applications: ranking public figures using relative attributes of [27], ranking scenes according to how interesting they look [17] and ranking cars according to their manufacturing date [21].", "startOffset": 244, "endOffset": 248}, {"referenceID": 39, "context": "ListMLE [40].", "startOffset": 8, "endOffset": 12}, {"referenceID": 18, "context": "For the efficient inference, we initialize the parent node with the solution obtained from the pair-wise RankSVM [19].", "startOffset": 113, "endOffset": 117}, {"referenceID": 26, "context": "First we evaluate MidRank on ranking public figure images with respect to relative visual attributes [27], using the features and the train/test splits provided by [27].", "startOffset": 101, "endOffset": 105}, {"referenceID": 26, "context": "First we evaluate MidRank on ranking public figure images with respect to relative visual attributes [27], using the features and the train/test splits provided by [27].", "startOffset": 164, "endOffset": 168}, {"referenceID": 25, "context": "We use the scene categories dataset from [26], whose images were later annotated with respect to interestingness by [17].", "startOffset": 41, "endOffset": 45}, {"referenceID": 16, "context": "We use the scene categories dataset from [26], whose images were later annotated with respect to interestingness by [17].", "startOffset": 116, "endOffset": 120}, {"referenceID": 25, "context": "We extract GIST [26] features and construct 10,000 train sequences and 20,000 test sequences.", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "We use the car dataset of [21].", "startOffset": 26, "endOffset": 30}, {"referenceID": 27, "context": "As image representation we use 64-Gaussian Fisher vectors [28] computed on dense SIFT features, after being reduced to 64 dimensions with PCA.", "startOffset": 58, "endOffset": 62}, {"referenceID": 4, "context": ": (a) max pooling of difference vectors as in [5], (b) Mean pairwise difference representations, (c) the full stacked difference vector representation between all elements i, j in a sequence, (d) the stacked representation, and (e) the stacked difference vector representation.", "startOffset": 46, "endOffset": 49}], "year": 2015, "abstractText": "We present a supervised learning to rank algorithm that effectively orders images by exploiting the structure in image sequences. Most often in the supervised learning to rank literature, ranking is approached either by analyzing pairs of images or by optimizing a list-wise surrogate loss function on full sequences. In this work we propose MidRank, which learns from moderately sized sub-sequences instead. These sub-sequences contain useful structural ranking information that leads to better learnability during training and better generalization during testing. By exploiting sub-sequences, the proposed MidRank improves ranking accuracy considerably on an extensive array of image ranking applications and datasets.", "creator": "LaTeX with hyperref package"}}}