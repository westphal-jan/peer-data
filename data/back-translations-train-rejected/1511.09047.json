{"id": "1511.09047", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2015", "title": "Solving Transition-Independent Multi-agent MDPs with Sparse Interactions (Extended version)", "abstract": "In cooperative multi-agent sequential decision making under uncertainty, agents must coordinate to find an optimal joint policy that maximises joint value. Typical algorithms exploit additive structure in the value function, but in the fully-observable multi-agent MDP setting (MMDP) such structure is not present. We propose a new optimal solver for transition-independent MMDPs, in which agents can only affect their own state but their reward depends on joint transitions. We represent these dependencies compactly in conditional return graphs (CRGs). Using CRGs the value of a joint policy and the bounds on partially specified joint policies can be efficiently computed. We propose CoRe, a novel branch-and-bound policy search algorithm building on CRGs. CoRe typically requires less runtime than the available alternatives and finds solutions to problems previously unsolvable.", "histories": [["v1", "Sun, 29 Nov 2015 17:18:10 GMT  (277kb,D)", "https://arxiv.org/abs/1511.09047v1", "This article is an extended version of the paper that was published under the same title in the Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI16), held in Phoenix, Arizona USA on February 12-17, 2016"], ["v2", "Thu, 11 Feb 2016 21:15:43 GMT  (872kb,D)", "http://arxiv.org/abs/1511.09047v2", "This article is an extended version of the paper that was published under the same title in the Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI16), held in Phoenix, Arizona USA on February 12-17, 2016"]], "COMMENTS": "This article is an extended version of the paper that was published under the same title in the Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI16), held in Phoenix, Arizona USA on February 12-17, 2016", "reviews": [], "SUBJECTS": "cs.AI cs.MA", "authors": ["joris scharpff", "diederik m roijers", "frans a oliehoek", "matthijs t j spaan", "mathijs m de weerdt"], "accepted": false, "id": "1511.09047"}, "pdf": {"name": "1511.09047.pdf", "metadata": {"source": "CRF", "title": "Solving Transition-Independent Multi-agent MDPs with Sparse Interactions (Extended version)\u2217", "authors": ["Joris Scharpff", "Diederik M. Roijers", "Frans A. Oliehoek", "Matthijs T. J. Spaan", "Mathijs M. de Weerdt"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "2 Related work", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "3 Model", "text": "We see a (fully observable) transition probability, which is the product of the local transition probability, as a reward that we accept."}, {"heading": "4 Conditional Return Graphs", "text": "It is about the question to what extent it is a matter of reactionary action that is able to reform itself, and about the question to what extent it is to be reformed if it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed. (...) It is about the question to what extent it is to be reformed."}, {"heading": "5 CoRe Example", "text": "We present a two-agent example problem in which both agents have actions a, b and c, but each action can only be performed once within a 2-step horizon. Agent 2 action c2 is the only stochastic action (to facilitate exposure) with results c and c, and corresponding probabilities 0.75 and 0.25. There is only one interaction, between actions a1 and a2, and the reward depends on whether the action is set from f1 to f1 or not. Thus, we have an interaction reward function with rewards R1,2 (f1), {a2}, f1), andR1,2 (f1), {a1, a2}, and local rewards R2. Without concrete rewards, we show the CRGs and CoRe.Figure 2 illustrates the two CRGs."}, {"heading": "6 Evaluation", "text": "In our experiments, we find optimal strategies for the Maintenance Planning Problem (MPP, see the introduction) that minimize the impact of joint actions on (time-dependent) maintenance costs and economic losses due to traffic obstructions. In this problem, agents represent contractors participating in a mechanism, so it is essential that the planning is performed optimally. Each of these tasks can only be performed once and agents can perform exactly one task at a given time (or do nothing). Individual rewards are given by maintenance costs that depend on task and time, while interaction programs are replaced by time-based maintenance costs. Maintenance costs are task and time-dependent, while interaction processes are model-based."}, {"heading": "7 Conclusions and Future Work", "text": "In this work, we focus on the optimal (and more central) solution to the problem, where agents are rewarded only through interaction. We divide individual and interactive rewards per agent into conditional return curves, a compact and efficient data structure when interactions are sparse and / or non-recurring. We propose to reduce the program's runtime and solve instances that were previously considered insoluble."}, {"heading": "Acknowledgements", "text": "This research is supported by the projects NWO DTC-NCAP (# 612.001.109), Next Generation Infrastructures, Almende BV and NWO VENI (# 639.021.336)."}, {"heading": "Appendix: Proof of Theorem 2", "text": "In this appendix we prove the correctness of the CoRe algorithm (Re = Re = Re 2). We define multiple notational abbreviations for convenience. For two (sub) sets of agents A, B, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A."}], "references": [{"title": "Traffic Light Control by Multiagent Reinforcement Learning Systems, chapter Interactive Collaborative Information Systems, pages 475\u2013510", "author": ["Bakker et al", "B. 2010] Bakker", "S. Whiteson", "L. Kester", "F. Groen"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Decentralized Markov decision processes with event-driven interactions", "author": ["Becker et al", "R. 2004] Becker", "S. Zilberstein", "V. Lesser"], "venue": "In Proceedings of the Int. Conf. on Autonomous Agents and Multiagent Systems,", "citeRegEx": "al. et al\\.,? \\Q2004\\E", "shortCiteRegEx": "al. et al\\.", "year": 2004}, {"title": "Transition-independent decentralized Markov decision processes", "author": ["Becker et al", "R. 2003] Becker", "S. Zilberstein", "V. Lesser", "C.V. Goldman"], "venue": "In Proceedings of the Int. Conf. on Autonomous Agents and Multiagent", "citeRegEx": "al. et al\\.,? \\Q2003\\E", "shortCiteRegEx": "al. et al\\.", "year": 2003}, {"title": "Optimal coordinated planning amongst self-interested agents with private state", "author": ["Cavallo et al", "R. 2006] Cavallo", "D.C. Parkes", "S. Singh"], "venue": "In Proceedings of Uncertainty in Artificial Intelligence", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Solving sparse delayed coordination problems in multiagent reinforcement learning", "author": ["De Hauwere et al", "2012] De Hauwere", "Y.-M", "P. Vrancx", "A. Now\u00e9"], "venue": "In Adaptive and Learning Agents,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Producing efficient error-bounded solutions for transition independent decentralized MDPs", "author": ["Dibangoye et al", "J.S. 2013] Dibangoye", "C. Amato", "A. Doniec", "F. Charpillet"], "venue": "In Proceedings of the Int. Conf. on Autonomous", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Multiagent planning with factored MDPs", "author": ["Guestrin et al", "C. 2002a] Guestrin", "D. Koller", "R. Parr"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "al. et al\\.,? \\Q2002\\E", "shortCiteRegEx": "al. et al\\.", "year": 2002}, {"title": "Contextspecific multiagent coordination and planning with factored MDPs", "author": ["Guestrin et al", "C. 2002b] Guestrin", "S. Venkataraman", "D. Koller"], "venue": "In Proceedings of the Eighteenth National Conference on Artificial", "citeRegEx": "al. et al\\.,? \\Q2002\\E", "shortCiteRegEx": "al. et al\\.", "year": 2002}, {"title": "SPUDD: Stochastic planning using decision diagrams", "author": ["Hoey et al", "J. 1999] Hoey", "R. St-Aubin", "A. Hu", "C. Boutilier"], "venue": "Proceedings of Uncertainty in Artificial Intelligence", "citeRegEx": "al. et al\\.,? \\Q1999\\E", "shortCiteRegEx": "al. et al\\.", "year": 1999}, {"title": "Sparse cooperative Q-learning", "author": ["Kok", "Vlassis", "J.R. 2004] Kok", "N. Vlassis"], "venue": "In Proceedings of the Int. Conf. on Machine Learning,", "citeRegEx": "Kok et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kok et al\\.", "year": 2004}, {"title": "Computing factored value functions for policies in structured MDPs", "author": ["Koller", "Parr", "D. 1999] Koller", "R. Parr"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence,", "citeRegEx": "Koller et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1999}, {"title": "Learning of coordination: Exploiting sparse interactions in multiagent systems", "author": ["Melo", "Veloso", "F.S. 2009] Melo", "M. Veloso"], "venue": "In Proceedings of The 8th Int. Conf. on Autonomous Agents and Multiagent Systems-", "citeRegEx": "Melo et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Melo et al\\.", "year": 2009}, {"title": "Decentralized MDPs with sparse interactions", "author": ["Melo", "Veloso", "F.S. 2011] Melo", "M. Veloso"], "venue": "Artificial Intelligence,", "citeRegEx": "Melo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Melo et al\\.", "year": 2011}, {"title": "GSMDPs for multi-robot sequential decision-making", "author": ["Messias et al", "J.V. 2013] Messias", "M.T.J. Spaan", "P.U. Lima"], "venue": "In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence,", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Solving very large weakly coupled Markov decision processes", "author": ["Meuleau et al", "N. 1998] Meuleau", "M. Hauskrecht", "Kim", "K.-E", "L. Peshkin", "L.P. Kaelbling", "T.L. Dean", "C. Boutilier"], "venue": "Proceedings of the Fifteenth", "citeRegEx": "al. et al\\.,? \\Q1998\\E", "shortCiteRegEx": "al. et al\\.", "year": 1998}, {"title": "Offline planning for communication by exploiting structured interactions in decentralized MDPs", "author": ["Mostafa", "Lesser", "H. 2009] Mostafa", "V. Lesser"], "venue": "In Proceedings of the International Joint Conference on Web", "citeRegEx": "Mostafa et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mostafa et al\\.", "year": 2009}, {"title": "Networked distributed POMDPs: A synthesis of distributed constraint optimization and POMDPs", "author": ["Nair et al", "R. 2005] Nair", "P. Varakantham", "M. Tambe", "M. Yokoo"], "venue": "Proceedings of the Twentieth National Conference", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "Incremental clustering and expansion for faster optimal planning in decentralized POMDPs", "author": ["Oliehoek et al", "F.A. 2013a] Oliehoek", "M.T.J. Spaan", "C. Amato", "S. Whiteson"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Exploiting locality of interaction in factored DecPOMDPs", "author": ["Oliehoek et al", "F.A. 2008] Oliehoek", "M.T.J. Spaan", "S. Whiteson", "N. Vlassis"], "venue": "In Proceedings of the Int. Conf. on Autonomous Agents and Multiagent Systems,", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Factored upper bounds for multiagent planning problems under uncertainty with non-factored value functions", "author": ["Oliehoek et al", "F.A. 2015] Oliehoek", "M.T.J. Spaan", "S.J. Witwicki"], "venue": "In Proc. of International Joint Conference", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Approximate solutions for factored Dec-POMDPs with many agents", "author": ["Oliehoek et al", "F.A. 2013b] Oliehoek", "S. Whiteson", "M.T.J. Spaan"], "venue": "In Proceedings of the Int. Conf. on Autonomous Agents and Multiagent Systems,", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Bounded approximations for linear multi-objective planning under uncertainty", "author": ["Roijers et al", "D.M. 2014] Roijers", "J. Scharpff", "M.T.J. Spaan", "F.A. Oliehoek", "M. De Weerdt", "S. Whiteson"], "venue": "In Proceedings of the Int. Conf", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Planning under uncertainty for coordinating infrastructural maintenance", "author": ["Scharpff et al", "J. 2013] Scharpff", "M.T.J. Spaan", "M. de Weerdt", "L. Volker"], "venue": "In Proceedings of the Int. Conf. on Automated Planning and Schedul-", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Decentralized planning under uncertainty for teams of communicating agents", "author": ["Spaan et al", "M.T.J. 2006] Spaan", "G.J. Gordon", "N. Vlassis"], "venue": "In Proceedings of the Int. Conf. on Autonomous Agents and Multiagent Systems", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Letting loose a SPIDER on a network of POMDPs: Generating quality guaranteed policies", "author": ["Varakantham et al", "P. 2007] Varakantham", "J. Marecki", "Y. Yabu", "M. Tambe", "M. Yokoo"], "venue": "Proceedings of the Int", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Influence-based policy abstraction for weakly-coupled Dec-POMDPs", "author": ["Witwicki", "Durfee", "S.J. 2010] Witwicki", "E.H. Durfee"], "venue": "In Proceedings of the Int. Conf. on Automated Planning and Scheduling,", "citeRegEx": "Witwicki et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Witwicki et al\\.", "year": 2010}], "referenceMentions": [], "year": 2016, "abstractText": "In cooperative multi-agent sequential decision making under uncertainty, agents must coordinate to find an optimal joint policy that maximises joint value. Typical algorithms exploit additive structure in the value function, but in the fully-observable multi-agent MDP (MMDP) setting such structure is not present. We propose a new optimal solver for transition-independent MMDPs, in which agents can only affect their own state but their reward depends on joint transitions. We represent these dependencies compactly in conditional return graphs (CRGs). Using CRGs the value of a joint policy and the bounds on partially specified joint policies can be efficiently computed. We propose CoRe, a novel branch-and-bound policy search algorithm building on CRGs. CoRe typically requires less runtime than the available alternatives and finds solutions to previously unsolvable problems.", "creator": "LaTeX with hyperref package"}}}