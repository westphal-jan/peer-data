{"id": "1511.09128", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2015", "title": "Aspect-based Opinion Summarization with Convolutional Neural Networks", "abstract": "This paper considers Aspect-based Opinion Summarization (AOS) of reviews on particular products. To enable real applications, an AOS system needs to address two core subtasks, aspect extraction and sentiment classification. Most existing approaches to aspect extraction, which use linguistic analysis or topic modeling, are general across different products but not precise enough or suitable for particular products. Instead we take a less general but more precise scheme, directly mapping each review sentence into pre-defined aspects. To tackle aspect mapping and sentiment classification, we propose two Convolutional Neural Network (CNN) based methods, cascaded CNN and multitask CNN. Cascaded CNN contains two levels of convolutional networks. Multiple CNNs at level 1 deal with aspect mapping task, and a single CNN at level 2 deals with sentiment classification. Multitask CNN also contains multiple aspect CNNs and a sentiment CNN, but different networks share the same word embeddings. Experimental results indicate that both cascaded and multitask CNNs outperform SVM-based methods by large margins. Multitask CNN generally performs better than cascaded CNN.", "histories": [["v1", "Mon, 30 Nov 2015 01:46:15 GMT  (287kb)", "http://arxiv.org/abs/1511.09128v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["haibing wu", "yiwei gu", "shangdi sun", "xiaodong gu"], "accepted": false, "id": "1511.09128"}, "pdf": {"name": "1511.09128.pdf", "metadata": {"source": "CRF", "title": "Aspect-based Opinion Summarization with Convolutional Neural Networks", "authors": ["Haibing Wu", "Yiwei Gu", "Shangdi Sun", "Xiaodong Gu"], "emails": ["xdgu}@fudan.edu.cn"], "sections": [{"heading": null, "text": "For real applications, an AOS system must address two central sub-tasks: aspect extraction and sentiment classification. Most existing approaches to aspect extraction that use linguistic analysis or topic modeling are generic for different products, but not precise enough or suitable for specific products. Instead, we take a less generic but more precise scheme, mapping each review set directly into predefined aspects. To address aspect extraction and sentiment classification, we propose two methods based on Convolutional Neural Network (CNN), cascaded CNN and multitask CNN. Cascaded CNN contains two levels of Convolutionary Networks. Several Level 1 CNNs deal with aspect mapping, and a single CNN on Level 2 deals with sentiment classification. Multitask CNN also contains several aspects of CNNs and one CNN sentiment, but different networks share the same word embedding. Experimental results indicate that both cascaded and multifunctional CNM intersect better in general."}, {"heading": "1 Introduction", "text": "These reviews are valuable for companies to improve their products and for individual consumers to make informed decisions. Unfortunately, reading all product reviews is difficult, especially for popular products with large volumes of aspects of review texts. Therefore, it is essential to provide coherent and concise summaries of user reviews. This has led to a new set of research findings on aspects that are based on aspects that summarize users \"opinions (AOS) (Hu and Liu, 2004). In the face of a series of product reviews, an AOS system extracts aspects that are discussed in the reviews and predicts the reviewers\" perceptions of these aspects. Figure 1 presents an exemplary summary of smartphone reviews. The smartphone aspects, such as battery life and screen, with the hyperlinks and numbers of positive and negative opinions, are illustrated in a structured way. Standard AOS typically includes two components subtasks, aspect extraction and sensing."}, {"heading": "2 Related Work", "text": "It has attracted a lot of attention with the advent of implicit aspects of online user generated assessments. Deep learning and representation learning, which was initially very successful in computer vision, has also achieved some success in Natural Language Processing (NLP). An AOS system must take into account two key aspects, aspects of extraction or sensation classification. A number of papers on aspects of extraction of aspects detects aspects that use aspects of linguistic expressions (e.g. 2011) or supervised sequence that use labeling such as CRFs and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al, 2007; Yang and Cardie, 2012) This scheme is very limited in many aspects."}, {"heading": "3 Methodology", "text": "The aspect mapper maps these sentences into predefined aspect categories. In this step, only sentences that belong to the predefined aspects are extracted and maintained, and the sentiment classifier then predicts the polarity of each of these extracted sentences as positive or negative. After each sentence has been labeled with aspect and emotion, the final opinion aggregator counts the number of positive and negative opinion-forming sentences that correspond to CrawledSentences Sentences Sentences with aspect-labeled sentences, and gives the hyperlinks to those sentces.The sentence segment in our system is a standard tool for segmenting sentences, NLTK point sentenceTokenizer.1 The aspect mapper and sentiment classifier we use is a C or CNN-M When the sentence is inserted into the network, it maps the first aspects of associated sentences."}, {"heading": "3.1 Cascaded CNN", "text": "In fact, most of us are able to move to another world, where we can move to another world."}, {"heading": "3.2 Multitask CNN", "text": "The architecture of our designed M-CNN is Figure 4. M-CNN also includes C aspect mappers and a feeling classifier. But unlike C-CNN, aspect mappers and sentiment classifier share word embedding layer in M-CNN. So the word embedding parameter) 1 (W is distributed across different tasks, while other parameters, i.e.) 2 (iW and) 3 (iW (i = 1, 2,..., C + 1), are task specific.Conventional multilearning task optimizes model parameters), () 3 () 2 () 1 (WWW by minimizing the loss functions of all tasks. This results in slightly worse results in our experiments. Instead, we sequentially set task i as the main task, and set the other tasks as auxiliary tasks. The goal is to optimize the main task we perform with the help of auxiliary tasks."}, {"heading": "4 Experiments", "text": "Since there is no such benchmark corpus, we create an Amazon Smartphone Review (ASR) dataset and make it publicly available for research purposes. ASR contains 300,000 smartphone reviews provided by amazon.com. We comment on 12,700 sets of 1679 reviews related to five predefined aspects, {battery, screen, camera, speaker, running speed}. Sentences associated with at least one aspect are also labeled as expressions of positive or negative sentiment. The number of sentences associated with each aspect is shown in Table 1. Evaluation metrics. We use precision, recall and F1 score to evaluate the performance of aspect mapping and classification accuracy for word classification. All comparisons are performed with 5x cross-validation, meaning the overall results are averaged across five folders."}, {"heading": "4.1 Results for Aspect Mapping", "text": "Table 3 presents the results of our CNN-based methods versus SVM-based methods for Aspect Mapping. It is clear that our C-CNN and M-CNN with randomly initialized Word embedding perform better in all five aspects than SVM with tp. Comparing, for example, C-CNN with SVM, the increases in the F1 score are 2.7% (71.7% vs. 74.4%), 1.5% (68.1% vs. 69.6%), 1.7% (72.1% vs. 73.8%), 2.4% (73.2% 75.6%) and 0.5% (79.4% vs. 79.9%). In terms of precision, CNN methods also beat SVMs with large margins, while their recovery performances are scarce. M-CNN generally performs better than C-CNN, but does not show significant superiority. In terms of battery, running speed, speaker, and camera, M-CNN scores higher than C-CNN, but with overall screen vs. 77.7% CNN (lower than CNN)."}, {"heading": "4.2 Results for Sentiment Classification", "text": "Table 4 shows the classification accuracy of our CNN-based methods versus SVM-based mood classification methods. The performance of the various methods for this task is generally consistent with their performance in aspect mapping tasks. SVM with tp yields an accuracy of 80.3%. Again, both C-CNN and M-CNN significantly outperform SVM + tp. Accuracy differences are + 2.1% (80.3% vs. 82.4%) and 2.6% (80.3% vs. 82.9%), respectively. CCNN + w2v and M-CNN + w2v achieve an accuracy of 83.5% (vs. 82.4% for C-CNN) and 84.1% (vs. 82.9% for M-CNN), implying the power of unattended pre-training of word embedding. M-CNN + w2v achieves the highest accuracy of all rated methods."}, {"heading": "5 Conclusions", "text": "In this article, we have introduced an aspect-based opinion summary system for specific products. Our system maps each review set directly into predefined aspects, which is particularly suitable for some vertical e-commerce websites that sell only certain products, or if the user only cares about opinions on certain product aspects. To attack aspect mapping and sentiment classification tasks, we have proposed two revolutionary network-based approaches, C-CNN and M-CNN. Both C-CNN and M-CNN contain multiple aspect mappers and a single sentiment classifier. The difference is that word embedding at M-CNN is shared across different tasks. Empirical results imply the superiority of our CNN-based methods over SVM-based methods; MCNN tends to perform better than C-CNN, although it does not exhibit significant superiority."}, {"heading": "Acknowledgements", "text": "This work was partially supported by the National Natural Science Foundation of China under grant 61371148 and the Shanghai National Natural Science Foundation under grant 12ZR1402500."}], "references": [{"title": "Sentiment classification based on supervised latent n-gram analysis", "author": ["Dmitriy Bespalov", "Bing Bai", "Yanjun Qi", "Ali Shokoufandeh."], "venue": "Proceedings of CIKM 2011.", "citeRegEx": "Bespalov et al\\.,? 2011", "shortCiteRegEx": "Bespalov et al\\.", "year": 2011}, {"title": "Identifying expressions of opinion in context", "author": ["Eric Breck", "Yejin Choi", "Claire Cardie."], "venue": "Proceedings of IJCAI 2007.", "citeRegEx": "Breck et al\\.,? 2007", "shortCiteRegEx": "Breck et al\\.", "year": 2007}, {"title": "An unsupervised aspect-sentiment model for online reviews", "author": ["Samuel Brody", "Noemie Elhadad."], "venue": "Proceedings of NAACL 2010.", "citeRegEx": "Brody and Elhadad.,? 2010", "shortCiteRegEx": "Brody and Elhadad.", "year": 2010}, {"title": "Aspect extraction with automated prior knowledge learning", "author": ["Zhiyuan Chen", "Arjun Mukherjee", "Bing Liu."], "venue": "Proceedings of ACL 2014.", "citeRegEx": "Chen et al\\.,? 2014", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Content models with attitude", "author": ["Sauper Christina", "Aria Haghighi", "Regina Barzilay"], "venue": "In Proceedings of ACL", "citeRegEx": "Christina et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Christina et al\\.", "year": 2011}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "Leon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research 1 (2000): 1\u201348.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Enhanced sentiment learning using twitter hashtags and smileys", "author": ["Dmitry Davidov", "Oren Tsur", "Ari Rappoport."], "venue": "Proceedings of COLING 2010.", "citeRegEx": "Davidov et al\\.,? 2010", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Mining opinion features in customer reviews", "author": ["Minqing Hu", "Bing Liu"], "venue": "In Proceedings AAAI", "citeRegEx": "Hu and Liu.,? \\Q2004\\E", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Opinion mining with deep recurrent neural networks", "author": ["Ozan Irsoy", "Claire Cardie."], "venue": "Proceedings of EMNLP 2014.", "citeRegEx": "Irsoy and Cardie.,? 2014", "shortCiteRegEx": "Irsoy and Cardie.", "year": 2014}, {"title": "Extracting opinion targets in a single- and cross-domain setting with conditional random fields", "author": ["Niklas Jakob", "Iryna Gurevych."], "venue": "Proceedings of", "citeRegEx": "Jakob and Gurevych.,? 2010", "shortCiteRegEx": "Jakob and Gurevych.", "year": 2010}, {"title": "A novel lexicalized HMM-based learning framework for web opinion mining", "author": ["Wei Jin", "Hay H. Hung."], "venue": "Proceedings of ICML 2009.", "citeRegEx": "Jin and Hung.,? 2009", "shortCiteRegEx": "Jin and Hung.", "year": 2009}, {"title": "Aspect and sentiment unification model for online review analysis", "author": ["Yohan Jo", "Alice H. Oh."], "venue": "Proceedings of WSDM 2011.", "citeRegEx": "Jo and Oh.,? 2011", "shortCiteRegEx": "Jo and Oh.", "year": 2011}, {"title": "Generalizing dependency features for opinion mining", "author": ["Mahesh Joshi", "Carolyn Penstein-Rose."], "venue": "Proceedings of ACL-IJCNLP 2009.", "citeRegEx": "Joshi and Penstein.Rose.,? 2009", "shortCiteRegEx": "Joshi and Penstein.Rose.", "year": 2009}, {"title": "A hierarchical aspect-sentiment model for online reviews", "author": ["Suin Kim", "Jianwen Zhang", "Zheng Chen", "Alice Oh", "Shixia Liu."], "venue": "Proceedings of AAAI 2013.", "citeRegEx": "Kim et al\\.,? 2013", "shortCiteRegEx": "Kim et al\\.", "year": 2013}, {"title": "A Convolutional Neural Network for Modelling Sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom."], "venue": "Proceedings of ACL 2014.", "citeRegEx": "Kalchbrenner et al\\.,? 2014", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of EMNLP 2014.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Extracting aspect-evaluation and aspect-of relations in opinion mining", "author": ["Nozomi Kobayashi", "Kentaro Inui", "Yuji Matsumoto."], "venue": "Proceedings of EMNLP-CoNLL 2007.", "citeRegEx": "Kobayashi et al\\.,? 2007", "shortCiteRegEx": "Kobayashi et al\\.", "year": 2007}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton."], "venue": "Proceedings of NIPS 2012.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Representation learning using multi-task deep neural networks for semantic classification and information retrieval", "author": ["Xiaodong Liu", "Jianfeng Gao", "Xiaodong He", "Li Deng", "Kevin Duh", "Ye-Yi Wang."], "venue": "Proceedings of NAACL 2015.", "citeRegEx": "Liu et al\\.,? 2015", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Proceedings of NIPS 2013.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "On the design of LDA models for aspect-based opinion mining", "author": ["Samaneh Moghaddam", "Martin Ester."], "venue": "Proceedings of CIKM 2012.", "citeRegEx": "Moghaddam and Ester.,? 2012", "shortCiteRegEx": "Moghaddam and Ester.", "year": 2012}, {"title": "Aspect extraction through semi-supervised modeling", "author": ["Arjun Mukherjee", "Bing Liu."], "venue": "Proceedings of ACL 2012.", "citeRegEx": "Mukherjee and Liu.,? 2012", "shortCiteRegEx": "Mukherjee and Liu.", "year": 2012}, {"title": "Rectified linear units improve restricted Boltzmann machines", "author": ["Vinod Nair", "Geoffrey E. Hinton."], "venue": "Proceedings of ICML 2010.", "citeRegEx": "Nair and Hinton.,? 2010", "shortCiteRegEx": "Nair and Hinton.", "year": 2010}, {"title": "Dependency tree-based sentiment classification using CRFs with hidden variables", "author": ["Tetsuji Nakagawa", "Kentaro Inui", "Sadao Kurohashi."], "venue": "Proceedings of NAACL 2010.", "citeRegEx": "Nakagawa et al\\.,? 2010", "shortCiteRegEx": "Nakagawa et al\\.", "year": 2010}, {"title": "Examining the role of linguistic knowledge", "author": ["Vincent Ng", "Sajib Dasgupta", "S.M. Niaz Arifin"], "venue": null, "citeRegEx": "Ng et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2006}, {"title": "Deep convolutional neural networks for sentiment analysis of short texts", "author": ["Cicero Nogueira dos Santos", "Maira Gatti."], "venue": "Proceedings of COLING 2014.", "citeRegEx": "Santos and Gatti.,? 2014", "shortCiteRegEx": "Santos and Gatti.", "year": 2014}, {"title": "Classifying relations by ranking with convolutional neural networks", "author": ["Cicero Nogueira dos Santos", "Bing Xiang", "Bowen Zhou."], "venue": "Proceedings of ACL 2015.", "citeRegEx": "Santos et al\\.,? 2015", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "A study of information retrieval weighting schemes for sentiment analysis", "author": ["Georgios Paltoglou", "Mike Thelwall."], "venue": "Proceedings of ACL 2010.", "citeRegEx": "Paltoglou and Thelwall.,? 2010", "shortCiteRegEx": "Paltoglou and Thelwall.", "year": 2010}, {"title": "Thumbs up? Sentiment classification using machine learning techniques", "author": ["Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan."], "venue": "Proceedings of EMNLP 2002.", "citeRegEx": "Pang et al\\.,? 2002", "shortCiteRegEx": "Pang et al\\.", "year": 2002}, {"title": "Opinion word expansion and target extraction through double propagation", "author": ["Guang Qiu", "Bing Liu", "Jiajun Bu", "Chun Chen."], "venue": "Computational Linguistics, 37 (1):9\u201327.", "citeRegEx": "Qiu et al\\.,? 2011", "shortCiteRegEx": "Qiu et al\\.", "year": 2011}, {"title": "Feature subsumption for opinion analysis", "author": ["Ellen Riloff", "Siddharth Patwardhan", "Janyce Wiebe."], "venue": "Proceedings of EMNLP 2006.", "citeRegEx": "Riloff et al\\.,? 2006", "shortCiteRegEx": "Riloff et al\\.", "year": 2006}, {"title": "Building a sentiment summarizer for local service reviews", "author": ["Blair-Goldensohn Sasha", "Kerry Hannan", "Ryan McDonald", "Tyler Neylon", "George A. Reis."], "venue": "Workshop at WWW 2008.", "citeRegEx": "Sasha et al\\.,? 2008", "shortCiteRegEx": "Sasha et al\\.", "year": 2008}, {"title": "Automatic aggregation by joint modeling of aspects and values", "author": ["Christina Sauper", "Regina Barzilay."], "venue": "Journal Artificial Intelligence Research, 46:89\u2013127.", "citeRegEx": "Sauper and Barzilay.,? 2013", "shortCiteRegEx": "Sauper and Barzilay.", "year": 2013}, {"title": "Learning semantic representations using convolutional neural networks for web search", "author": ["Yelong Shen", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Gregoire Mesnil."], "venue": "Proceedings of WWW 2014.", "citeRegEx": "Shen et al\\.,? 2014", "shortCiteRegEx": "Shen et al\\.", "year": 2014}, {"title": "A latent semantic model with convolutional-pooling structure for information retrieval", "author": ["Yelong Shen", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Gregoire Mesnil."], "venue": "Proceedings of CIKM 2014.", "citeRegEx": "Shen et al\\.,? 2014", "shortCiteRegEx": "Shen et al\\.", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich."], "venue": "Proceedings of ECCV 2014.", "citeRegEx": "Szegedy et al\\.,? 2014", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Modeling online reviews with multi-grain topic models", "author": ["Ivan Titov", "Ryan McDonald."], "venue": "Proceedings of WWW 2008.", "citeRegEx": "Titov and McDonald.,? 2008", "shortCiteRegEx": "Titov and McDonald.", "year": 2008}, {"title": "Reducing overweighting in supervised term weighting for sentiment analysis", "author": ["Haibing Wu", "Xiaodong Gu."], "venue": "Proceedings of COLING 2014.", "citeRegEx": "Wu and Gu.,? 2014", "shortCiteRegEx": "Wu and Gu.", "year": 2014}, {"title": "Extracting opinion expressions with semi-markov conditional random fields", "author": ["Bishan Yang", "Claire Cardie."], "venue": "Proceedings of EMNLP-CoNLL 2012.", "citeRegEx": "Yang and Cardie.,? 2012", "shortCiteRegEx": "Yang and Cardie.", "year": 2012}, {"title": "Relation classification via convolutional deep neural network", "author": ["Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao."], "venue": "Proceedings of COLING 2014.", "citeRegEx": "Zeng et al\\.,? 2014", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}, {"title": "Movie review mining and summarization", "author": ["Li Zhuang", "Feng Jing", "Xiao-Yan Zhu."], "venue": "Proceedings of CIKM 2006.", "citeRegEx": "Zhuang et al\\.,? 2006", "shortCiteRegEx": "Zhuang et al\\.", "year": 2006}, {"title": "Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid", "author": ["Wayne X. Zhao", "Jing Jiang", "Hongfei Yan", "Xiaoming Li."], "venue": "Proceedings of EMNLP 2010.", "citeRegEx": "Zhao et al\\.,? 2010", "shortCiteRegEx": "Zhao et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 7, "context": "This has bred a new line of research on Aspect-based Opinion Summarization (AOS) (Hu and Liu, 2004).", "startOffset": 81, "endOffset": 99}, {"referenceID": 7, "context": "part-ofspeech and dependency relations) (Hu and Liu, 2004; Joshi and Rose, 2009; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al.", "startOffset": 40, "endOffset": 136}, {"referenceID": 40, "context": "part-ofspeech and dependency relations) (Hu and Liu, 2004; Joshi and Rose, 2009; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al.", "startOffset": 40, "endOffset": 136}, {"referenceID": 29, "context": "part-ofspeech and dependency relations) (Hu and Liu, 2004; Joshi and Rose, 2009; Zhuang et al., 2006; Wu et al., 2009; Qiu et al., 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al.", "startOffset": 40, "endOffset": 136}, {"referenceID": 10, "context": ", 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al., 2007; Yang and Cardie, 2012).", "startOffset": 53, "endOffset": 166}, {"referenceID": 9, "context": ", 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al., 2007; Yang and Cardie, 2012).", "startOffset": 53, "endOffset": 166}, {"referenceID": 8, "context": ", 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al., 2007; Yang and Cardie, 2012).", "startOffset": 53, "endOffset": 166}, {"referenceID": 1, "context": ", 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al., 2007; Yang and Cardie, 2012).", "startOffset": 53, "endOffset": 166}, {"referenceID": 38, "context": ", 2011) or supervised sequence labeling such as CRFs (Jin and Hung, 2009; Jakob and Gurevych, 2010; Irsoy and Cardie, 2014; Breck et al., 2007; Yang and Cardie, 2012).", "startOffset": 53, "endOffset": 166}, {"referenceID": 36, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 4, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 2, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 41, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 11, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 20, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 3, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 21, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 13, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 32, "context": "Another line of related work applies variants of standard topic modeling such as LDA (Titov and McDonald, 2008; Christina et al., 2011; Brody and Elhadad, 2010; Zhao et al., 2010; Jo and Oh, 2011; Moghaddam and Ester, 2012; Chen et al., 2014; Mukherjee and Liu, 2012; Kim et al., 2013; Sauper and Barzilay, 2013).", "startOffset": 85, "endOffset": 312}, {"referenceID": 28, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 24, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 30, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 6, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 27, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 23, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 0, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 37, "context": "Most prior work used traditional machine learning with complicated feature engineering (Pang et al., 2002; Ng et al., 2006; Riloff et al., 2006; Davidov et al., 2010; Paltoglou and Thelwall, 2010; Nakagawa et al., 2010; Bespalov et al., 2011; Wu and Gu, 2014).", "startOffset": 87, "endOffset": 259}, {"referenceID": 14, "context": "Very recently, some researchers applied deep convolutional neural networks to sentence sentiment classification and reported considerably better results than traditional approaches (Kalchbrenner et al., 2014; Santos and Gatti, 2014; Kim, 2014).", "startOffset": 181, "endOffset": 243}, {"referenceID": 25, "context": "Very recently, some researchers applied deep convolutional neural networks to sentence sentiment classification and reported considerably better results than traditional approaches (Kalchbrenner et al., 2014; Santos and Gatti, 2014; Kim, 2014).", "startOffset": 181, "endOffset": 243}, {"referenceID": 15, "context": "Very recently, some researchers applied deep convolutional neural networks to sentence sentiment classification and reported considerably better results than traditional approaches (Kalchbrenner et al., 2014; Santos and Gatti, 2014; Kim, 2014).", "startOffset": 181, "endOffset": 243}, {"referenceID": 17, "context": "Convolutional neural network (CNN) is currently underpinning the cutting edge in computer vision (Krizhevsky et al., 2012; Szegedy et al., 2014).", "startOffset": 97, "endOffset": 144}, {"referenceID": 35, "context": "Convolutional neural network (CNN) is currently underpinning the cutting edge in computer vision (Krizhevsky et al., 2012; Szegedy et al., 2014).", "startOffset": 97, "endOffset": 144}, {"referenceID": 5, "context": "It has also achieved state-of-the-art results in many traditional NLP tasks (Collobert et al., 2011) and other NLP areas such as information retrieval (Shen et al.", "startOffset": 76, "endOffset": 100}, {"referenceID": 33, "context": ", 2011) and other NLP areas such as information retrieval (Shen et al., 2014) and relation classification (Zeng et al.", "startOffset": 58, "endOffset": 77}, {"referenceID": 39, "context": ", 2014) and relation classification (Zeng et al., 2014; Santos et al., 2015).", "startOffset": 36, "endOffset": 76}, {"referenceID": 26, "context": ", 2014) and relation classification (Zeng et al., 2014; Santos et al., 2015).", "startOffset": 36, "endOffset": 76}, {"referenceID": 19, "context": "CNN models for specific NLP tasks often use unsupervised pre-trained word vectors (Mikolov et al., 2013) as initialization, which are then improved by optimizing supervised objectives.", "startOffset": 82, "endOffset": 104}, {"referenceID": 5, "context": "For example, (Collobert et al., 2011) tackled part-of-speech tagging, chunking, and named entity recognition tasks using a multitask sequence labeller.", "startOffset": 13, "endOffset": 37}, {"referenceID": 18, "context": "(Liu et al., 2015) trained a multi-task deep neural network for query classification and web search ranking.", "startOffset": 0, "endOffset": 18}, {"referenceID": 5, "context": "This layer applies max-over-time pooling (Collobert et al. 2011) to each of the feature maps produced by convolutional layers:", "startOffset": 41, "endOffset": 64}, {"referenceID": 22, "context": "We use rectified linear units (Nair and Hinton, 2010) as activation functions for convolutional layer, and sigmoid function for output layer.", "startOffset": 30, "endOffset": 53}], "year": 2015, "abstractText": "This paper considers Aspect-based Opinion Summarization (AOS) of reviews on particular products. To enable real applications, an AOS system needs to address two core subtasks, aspect extraction and sentiment classification. Most existing approaches to aspect extraction, which use linguistic analysis or topic modelling, are general across different products but not precise enough or suitable for particular products. Instead we take a less general but more precise scheme, directly mapping each review sentence into pre-defined aspects. To tackle aspect mapping and sentiment classification, we propose two Convolutional Neural Network (CNN) based methods, cascaded CNN and multitask CNN. Cascaded CNN contains two levels of convolutional networks. Multiple CNNs at level 1 deal with aspect mapping task, and a single CNN at level 2 deals with sentiment classification. Multitask CNN also contains multiple aspect CNNs and a sentiment CNN, but different networks share the same word embeddings. Experimental results indicate that both cascaded and multitask CNNs outperform SVM-based methods by large margins. Multitask CNN generally performs better than cascaded CNN.", "creator": "Microsoft\u00ae Word 2013"}}}