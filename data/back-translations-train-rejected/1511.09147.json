{"id": "1511.09147", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2015", "title": "Scaling POMDPs For Selecting Sellers in E-markets-Extended Version", "abstract": "In multiagent e-marketplaces, buying agents need to select good sellers by querying other buyers (called advisors). Partially Observable Markov Decision Processes (POMDPs) have shown to be an effective framework for optimally selecting sellers by selectively querying advisors. However, current solution methods do not scale to hundreds or even tens of agents operating in the e-market. In this paper, we propose the Mixture of POMDP Experts (MOPE) technique, which exploits the inherent structure of trust-based domains, such as the seller selection problem in e-markets, by aggregating the solutions of smaller sub-POMDPs. We propose a number of variants of the MOPE approach that we analyze theoretically and empirically. Experiments show that MOPE can scale up to a hundred agents thereby leveraging the presence of more advisors to significantly improve buyer satisfaction.", "histories": [["v1", "Mon, 30 Nov 2015 04:00:48 GMT  (773kb,D)", "https://arxiv.org/abs/1511.09147v1", null], ["v2", "Wed, 9 Dec 2015 21:28:08 GMT  (152kb,D)", "http://arxiv.org/abs/1511.09147v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["athirai a irissappane", "frans a oliehoek", "jie zhang"], "accepted": false, "id": "1511.09147"}, "pdf": {"name": "1511.09147.pdf", "metadata": {"source": "CRF", "title": "Scaling POMDPs For Selecting Sellers in E-markets\u2014Extended Version", "authors": ["Athirai A. Irissappane", "Frans A. Oliehoek", "Jie Zhang"], "emails": ["athirai001@e.ntu.edu.sg", "frans.oliehoek@liverpool.ac.uk", "zhangj@ntu.edu.sg"], "sections": [{"heading": "1 Introduction", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city, in a country, in a country, in a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a"}, {"heading": "2 Background", "text": "This paper relies mainly on POMDPs, which can be used to present decision-making problems under uncertainty regarding states, actions, transactions, observations and rewards. We refer to Kaelbling et al. (1998), Spain (2012), to allow a comprehensive introduction to POMDPs. Here, we try to convey the most basic intuitions by briefly describing the number of state factors, such as the quality levels of each vendor (qj), each consultant (ui {trustworthy, untrustworthy) and the status of the transaction (not started, satisfactory, unsatisfactory, finished)."}, {"heading": "3 A SingleExpert Baseline", "text": "In this paper, we propose techniques to exploit the structure present in (settings like) the SALE POMDP. At this point, we introduce a basic algorithm as an intuitive starting point for the more advanced method we propose in the next section. This baseline, called SingleExpert, is basically a method of applying the SALE POMDP to major problems. That is, when confronted with a SALE POMDP instance with many vendors and consultants, we can randomly select a subset of agents small enough to model and solve it as the SALE POMDP and use the resulting policies. Since the qj and ui variables do not interfere with each other, the definition of such a sub-POMDP (SP) is trivial, since it merely amounts to deleting all unselected government variables and policies and observations that affect them."}, {"heading": "4 Mixture of POMDP Experts (MOPE)", "text": "While we argue that SingleExpert may have its merits, we clearly want to develop methods that can leverage large pools of potential vendors and consultants. To achieve this, we are introducing the Mixture of POMDP Experts (MOPE) framework. SingleExpert exploits a particular property of trust-building domains: the construction of an SP is possible because the state variables encoding vendor and consultant qualities do not interfere with each other and cannot be influenced by actions. In fact, the interaction of these variables results only in the views of the agent, which manifest themselves as correlations generated by the coupling of observations. For example, when we ask consultants i about vendor j and receive bad observations, it not only increases the likelihood that the vendor is of low quality (qj = low) and consultants ui = trustworthy, but also of (qj = high, ui = untrustworthy). The MOPE framework aims to further deepen these views by piling them into larger clusters, using them as a single solution."}, {"heading": "4.1 MOPE Algorithm Overview", "text": "Algorithm 1 gives a brief overview of the MOPE framework. We first form the SPs by randomly selecting a subset of salesmen and consultants (Mk in line 1). Each SP is solved to find the optimal policy and thus its maximum expected total remuneration V-k (line 2) 1. If SPs have the same composition of agents (number of salesmen and consultants), the found V-k can be reused among them. Therefore, in our implementation, we always choose such uniformly composed SPs. We define V as a set of voices v collected by each SP. Each voice v = (a, q) is a sentence representing the action proposed by the SP and the associated Q-value q.In order to maintain the beliefs about all state factors, it is possible to maintain the local convictions in each SP in parallel."}, {"heading": "4.2 Dividing into Sub-POMDPs", "text": "In practice, we cannot solve the problem by taking the best measures we can."}, {"heading": "4.4 Belief Update", "text": "Although we can maintain and perform exact faith updates at the global level, i.e. taking into account all state factors, such an exact conclusion is complex when applied to the Bayes rule and does not extend to more than 10 actors. Therefore, we propose to apply the approximate inference methods. In particular, we apply Factored Frontier (FF) (Murphy and Wei\u00df 2001), which maintains faith in a fully factored form, i.e. as a product of marginal state factors xi: b (s) = \u044b | s = 1 b (xi). Thus, the beliefs for each SP can be extracted directly via bk (s) = \u0109xi-Xk b-B (xi), with Xk denoting the amount of state factors that are part of the sub-POMDP-Mk. While FF is a simple algorithm and other options are possible, it allows us to spread variables through the network and our experiments indicate that FF works well."}, {"heading": "5 Experiments", "text": "In fact, we are able to assert ourselves, we are able to assert ourselves in the world, we are able to assert ourselves in the world, and we are able to assert ourselves in the world, we are able to assert ourselves in the world."}, {"heading": "5.1 Influence of using Factored Frontier (FF)", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "6 Related Work", "text": "In fact, it is the case that most of them are in a position to go into a different world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they"}, {"heading": "7 Conclusion and Future Work", "text": "We propose the Mixture of POMDP Experts (MOPE) technique to solve the scalability problems in solving large POMDP problems for e-marketplaces. MOPE works by splitting the large POMDP problem into mathematically viable smaller sub-POMDPs and then aggregating the actions of sub-POMDPs. Extensive evaluations show that MOPE achieves a reasonable approach to the POMDP for small problems and can scale up to a hundred agents by effectively exploiting the presence of more consultants to achieve significantly higher buyer satisfaction. We also show that MOPE improves the scalability of a POMDP model in the sensor network domain. We conduct experiments to select the best shareholder hierarchy to be used in the MOPE approach. However, whether empirically a good hierarchy for other problems (with the exception of selection problems for vendors) will be possible through POPs, we would like to analyze the open question of OPPs rather than the open question of whether the work will be possible."}, {"heading": "Acknowledgments", "text": "This work is supported by the A * STAR SERC Scholarship (1224104047) awarded to Dr. Jie Zhang, NWO Innovational Research Incentives Scheme Veni # 639.021.336, awarded to Dr. Frans A. Oliehoek and the Institute of Media Innovation at Nanyang Technological University."}], "references": [{"title": "and Baxter", "author": ["D. Aberdeen"], "venue": "J.", "citeRegEx": "Aberdeen and Baxter 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "F", "author": ["C. Amato", "Oliehoek"], "venue": "A.", "citeRegEx": "Amato and Oliehoek 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "C", "author": ["R. Becker", "S. Zilberstein", "V. Lesser", "Goldman"], "venue": "V.", "citeRegEx": "Becker et al. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "and Poole", "author": ["C. Boutilier"], "venue": "D.", "citeRegEx": "Boutilier and Poole 1996", "shortCiteRegEx": null, "year": 1996}, {"title": "M", "author": ["A.R. Cassandra", "L.P. Kaelbling", "Littman"], "venue": "L.", "citeRegEx": "Cassandra. Kaelbling. and Littman 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "2000", "author": ["Dietterich", "T. G"], "venue": "Ensemble methods in machine learning. In Multiple Classifier Systems, volume", "citeRegEx": "Dietterich 2000", "shortCiteRegEx": null, "year": 1857}, {"title": "E", "author": ["Z. Feng", "Hansen"], "venue": "A.", "citeRegEx": "Feng and Hansen 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "and Zilberstein", "author": ["C.V. Goldman"], "venue": "S.", "citeRegEx": "Goldman and Zilberstein 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Multiagent planning with factored MDPs", "author": ["Koller Guestrin", "C. Parr 2001a] Guestrin", "D. Koller", "R. Parr"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Guestrin et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Guestrin et al\\.", "year": 2001}, {"title": "Solving factored POMDPs with linear value functions", "author": ["Koller Guestrin", "C. Parr 2001b] Guestrin", "D. Koller", "R. Parr"], "venue": "In Proceedings of the IJCAI Workshop on Planning under Uncertainty and Incomplete Information,", "citeRegEx": "Guestrin et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Guestrin et al\\.", "year": 2001}, {"title": "and Feng", "author": ["E.A. Hansen"], "venue": "Z.", "citeRegEx": "Hansen and Feng 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "and Zhang", "author": ["A.A. Irissappane"], "venue": "J.", "citeRegEx": "Irissappane and Zhang 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "P", "author": ["A.A. Irissappane", "J. Zhang", "F.A. Oliehoek", "Dutta"], "venue": "S.", "citeRegEx": "Irissappane et al. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "F", "author": ["Irissappane, A.A.", "Oliehoek"], "venue": "A.; and Zhang, J.", "citeRegEx": "Irissappane. Oliehoek. and Zhang 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "A", "author": ["L.P. Kaelbling", "M.L. Littman", "Cassandra"], "venue": "R.", "citeRegEx": "Kaelbling. Littman. and Cassandra 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "and Friedman", "author": ["D. Koller"], "venue": "N.", "citeRegEx": "Koller and Friedman 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "W", "author": ["H. Kurniawati", "D. Hsu", "Lee"], "venue": "S.", "citeRegEx": "Kurniawati. Hsu. and Lee 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "L", "author": ["M.L. Littman", "A.R. Cassandra", "Kaelbling"], "venue": "P.", "citeRegEx": "Littman. Cassandra. and Kaelbling 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "T", "author": ["N. Meuleau", "M. Hauskrecht", "K.-E. Kim", "L. Peshkin", "L.P. Kaelbling", "Dean"], "venue": "L.; and Boutilier, C.", "citeRegEx": "Meuleau et al. 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "and Weiss", "author": ["K. Murphy"], "venue": "Y.", "citeRegEx": "Murphy and Weiss 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings", "author": ["Nair"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Nair,? \\Q2003\\E", "shortCiteRegEx": "Nair", "year": 2003}, {"title": "A", "author": ["Oliehoek, F.A.", "Gokhale"], "venue": "A.; and Zhang, J.", "citeRegEx": "Oliehoek. Gokhale. and Zhang 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "S", "author": ["F.A. Oliehoek", "M.T. Spaan", "Witwicki"], "venue": "J.", "citeRegEx": "Oliehoek. Spaan. and Witwicki 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "L", "author": ["F.A. Oliehoek", "S.J. Witwicki", "Kaelbling"], "venue": "P.", "citeRegEx": "Oliehoek. Witwicki. and Kaelbling 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Point-based value iteration: An anytime algorithm for POMDPs", "author": ["Gordon Pineau", "J. Thrun 2003] Pineau", "G. Gordon", "S. Thrun"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Pineau et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Pineau et al\\.", "year": 2003}, {"title": "and Boutilier", "author": ["P. Poupart"], "venue": "C.", "citeRegEx": "Poupart and Boutilier 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "and Boutilier", "author": ["P. Poupart"], "venue": "C.", "citeRegEx": "Poupart and Boutilier 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "The Advisor-POMDP: A principled approach to trust through reputation in electronic markets", "author": ["Cohen Regan", "K. Poupart 2005] Regan", "R. Cohen", "P. Poupart"], "venue": "In Proceedings of the International Conference on Privacy, Security and Trust (PST)", "citeRegEx": "Regan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Regan et al\\.", "year": 2005}, {"title": "and Veness", "author": ["D. Silver"], "venue": "J.", "citeRegEx": "Silver and Veness 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "M", "author": ["Spaan"], "venue": "T. J.", "citeRegEx": "Spaan 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "C", "author": ["T.S. Veiga", "M.T. Spaan", "P.U. Lima", "Brodley"], "venue": "E.; and Stone, P.", "citeRegEx": "Veiga et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Young", "author": ["J.D. Williams"], "venue": "S.", "citeRegEx": "Williams and Young 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "E", "author": ["S.J. Witwicki", "Durfee"], "venue": "H.", "citeRegEx": "Witwicki and Durfee 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Preventing HIV spread in homeless populations using PSINET", "author": ["Yadav"], "venue": "In Proceedings of the 27th Conference on Innovative Applications of Artificial Intelli-", "citeRegEx": "Yadav,? \\Q2015\\E", "shortCiteRegEx": "Yadav", "year": 2015}], "referenceMentions": [], "year": 2017, "abstractText": "In multiagent e-marketplaces, buying agents need to select good sellers by querying other buyers (called advisors). Partially Observable Markov Decision Processes (POMDPs) have shown to be an effective framework for optimally selecting sellers by selectively querying advisors. However, current solution methods do not scale to hundreds or even tens of agents operating in the e-market. In this paper, we propose the Mixture of POMDP Experts (MOPE) technique, which exploits the inherent structure of trust-based domains, such as the seller selection problem in e-markets, by aggregating the solutions of smaller sub-POMDPs. We propose a number of variants of the MOPE approach that we analyze theoretically and empirically. Experiments show that MOPE can scale up to a hundred agents thereby leveraging the presence of more advisors to significantly improve buyer satisfaction.", "creator": "LaTeX with hyperref package"}}}