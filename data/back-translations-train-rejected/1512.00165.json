{"id": "1512.00165", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2015", "title": "Learning Using 1-Local Membership Queries", "abstract": "Classic machine learning algorithms learn from labelled examples. For example, to design a machine translation system, a typical training set will consist of English sentences and their translation. There is a stronger model, in which the algorithm can also query for labels of new examples it creates. E.g, in the translation task, the algorithm can create a new English sentence, and request its translation from the user during training. This combination of examples and queries has been widely studied. Yet, despite many theoretical results, query algorithms are almost never used. One of the main causes for this is a report (Baum and Lang, 1992) on very disappointing empirical performance of a query algorithm. These poor results were mainly attributed to the fact that the algorithm queried for labels of examples that are artificial, and impossible to interpret by humans.", "histories": [["v1", "Tue, 1 Dec 2015 07:40:49 GMT  (648kb,D)", "http://arxiv.org/abs/1512.00165v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["galit bary"], "accepted": false, "id": "1512.00165"}, "pdf": {"name": "1512.00165.pdf", "metadata": {"source": "CRF", "title": "Learning Using Local Membership Queries", "authors": ["Galit Bary", "Shai Shalev-Shwartz", "Amit Daniely", "Alon Gonen", "Nir Rosenfled", "Yoav Wald", "Yossi Arjevani", "Nomi Vinokurov"], "emails": [], "sections": [{"heading": null, "text": "Learning Using Local Membership QueriesGalit BarySubmitted in partial fulfillment of the requirements of the degree of Master of ScienceUnder the supervision of Prof. Shai Shalev-ShwartzAmit DanielySeptember 2015Rachel and Selim Benin School of Computer Science and EngineeringThe Hebrew University of Jerusalem Israelar Xiv: 151 2.00 165v 1 [cs.L G] 1D ec2 015AbstractClassic machine learning algorithms learn from labeled examples. For example, to design a machine translation system, a typical training set will be English sets and their translation to French. There is a stronger model in which the algorithm can also query for labels of new examples it creates. For example, in the translation task the algorithm can create a new English sentence, and request its translation from the user during the training. This combination of examples and queries, which resemble human learning patterns, has been extensively investigated. However, despite many theoretical results, we have never been rigorous enough to use empirical information almost."}, {"heading": "Acknowledgments", "text": "I would like to thank my consultant Prof. Shai Shalev-Shwartz for having me in his excellent team and for his support and inspiration. I would also like to thank Amit Daniely for his guidance and care, his extensive knowledge and patience were invaluable and it was a privilege to work with him. To Alon Gonen, Nir Rosenfled, Yoav Wald, Yossi Arjevani, Nomi Vinokurov and Avishai Wagner for their remarkable friendship and advice, to the NLP laboratory and especially to Effi Levi for all his help with empirical work and to my office workers Zahi Ajami and Dikla Cohn for their wonderful company. I would like to thank my parents for all the love and support over the years, and to the Weisberg family for their help, especially Susan for their editorial comments. Last but not least, I would like to thank my husband Dov for his continued support, which is expressed on so many levels - me in difficult times, by designing my house and encouraging my designs."}, {"heading": "1 Introduction 6", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Previous Work 8", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 PAC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8", "text": "2.2 Member requests.................................................................................................................................................."}, {"heading": "3 Setting 12", "text": "3.1 The PAC model.............................................. 12 3.2 (local) membership enquiry model..................................."}, {"heading": "4 Learning DNFs with Evident Examples Using 1-local MQ 13", "text": "4.1 Definitions and notations..................................................................................................................."}, {"heading": "5 Experiments 23", "text": ".)......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "1 Introduction", "text": "We can focus on two types of input: the first type of input is when a parent of a child points to a cat and a state, \"Look, a cat!\" The second type of input is an answer to the child's frequently asked question, \"What is that?,\" which the child can ask when it sees a cat, but also when it sees a dog, a mouse, a rabbit, or another small animal. These two types of input were the basis for the learning model originally proposed in the celebrated paper \"A theory of the learnable\" (Valiant, 1984). In Valiant's learning model, learning has access to two sources of information - EXAMPLES and ORACLE. The learning algorithm can call EXAMPLES to obtain an example with its label (sampled from nature)."}, {"heading": "2 Previous Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 PAC", "text": "Valiant's Model of Learning (Valiant, 1984) formulates the problem of learning a concept on the basis of examples. Examples are selected according to a fixed but unknown and arbitrary distribution across the instance space. It is the task of the learner to find a prediction rule. The requirement is that the prediction rule is highly likely to apply to all but a small fraction of the instances. In this model, some positive results are known - i.e. concept classes that have proven to be PAC learnable. Perhaps the most significant example is the class of half spaces. Other examples are relatively weak classes such as DNFs and CNFs with a constant number of terms (Valiant, 1984) and ranking trees (Ehrenfeucht and Haussler, 1989) for a constant k.Despite these positive outcomes, most PAC learning problems are probably intractable. In fact, almost no positive results are known beyond the above-mentioned results."}, {"heading": "2.2 Membership Queries", "text": "The PAC model is a \"passive\" model in which the learner receives a random dataset of examples and their names, and then issues a classifier. A stronger version would be an active model in which the learner gathers information about the world by asking questions and getting answers. Several types of active models have been suggested: Membership Query Synthesis, Stream-Based Selective Sampling, and Pool-Based Sampling (Settles, 2010). Our work lies in the area of Membership Queries (MQ) models presented in (Valiant, 1984). In this model, the learner may ask for the label of a particular example he chooses (even examples that are not included in the given sample).This model has proven to be stronger in several scenarios. Some examples of concept classes that have proven to be PAC-capable of learning are only available when membership queries are available."}, {"heading": "2.3 Baum and Lang", "text": "As described above, the work of Baum and Lang (1992) was to apply a variation of the MQ algorithm to learn a linear classifier, which uses the idea that two examples, one positive and one negative, are given. It is possible to find an approximate separation between the positive and the negative examples. Their experiments were evaluated in practice. The task they chose is the task of binary classification. The algorithm received two positive and one negative examples."}, {"heading": "2.4 Local Membership Queries", "text": "Most of them have left the whole framework of membership behind and focused on the other types of active learning: stream-based and pool-based. The idea is to filter existing examples out of an incomplete data set created from a random subset of the question."}, {"heading": "2.5 Other Related Work", "text": "In Section 5, we cite some experimental evidence that the use of additional information from the user is helpful. There have been other papers on the same line. Druck et al. (2009) suggest a pool-based approach to active learning, in which the user provides labels for input features, not instances. Users are asked to provide a \"label\" for input features, in which a labeled input feature indicates that a particular feature is highly indicative of a particular label. Subsequently, Settles (2011) presented an interface for active learning comments, in which users label instances and features at the same time. At any time, an instance and a list of features for each label is presented on the screen. Users can choose whether to label the instance as indicative, select a feature from the list, or add a new feature of their choice."}, {"heading": "3 Setting", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 The PAC Model", "text": "Our framework is an extension of the PAC model (probably roughly correct) q of learning. Before we introduce it, we will briefly review PAC learning. We will consider only the binary classification, where the instance space X is \"Xn\" t \"1, 1un and the label space Y is\" t0 \"q.\" A learning problem is defined by a hypothesis of class H \"t0, 1uX. We assume that the learner is a training setS\" tpx1, h \"px1qq, px2, h\" px2qq, \".,\" pxm, \"h\" pxmqqu P \"pX\" Yqm, where the xi's are based on an unknown distribution D on X and h \": X\" Y is an unknown hypothesis. We will focus on the so-called realizable case, in which h \"pxmqqu\" learning ability in class H. \"The learner returns (a description of the hypothesis:\" The goal X \"is similar to Yq."}, {"heading": "3.2 (Local) Membership Queries Model", "text": "Membership query learning is an extension of the PAC model, in which the learning algorithm q is allowed to query the labels of specific examples in the domain collection. A membership query is a call to an ORACLE that receives some x P X as input and returns h \u2039 pxq. This is called a \"membership query,\" because the ORACLE 1, if x is positively labeled in the series of examples, has a probability of success by repetition to 1. \"Definition 3 (Membership-Query Learning Algorithm) We say that a learning algorithm A learns with membership queries H when a function mA pn, q-Poly'n, so that for each distribution D over X, each h-Query learning algorithm 0 when A-Query learning query is queried."}, {"heading": "4 Learning DNFs with Evident Examples Using 1-local MQ", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Definitions and Notations", "text": "\"We will not be surprised that there is such a thing if we identify a small number of terms with\" true \"and\" false. \"\" We will denote from hF the function derived from the DNF formula F. \"We will look at the hypotheses.\" \"We will look at the DNF formula F-1.\" \"We will take the hypotheses (e.g. a DNF formula with a small but non-negligible probability that we will take the convention that is small, at least 1n2 and non-negligible.\" \"All our results can easily be applied to the case where\" small \"and non-negligible probabilities are.\" \"We will take the convention that is small and non-negligible.\" We will take the convention that is small, that is small and non-negligible, at least 1n3."}, {"heading": "4.2 Upper Bounds", "text": "\"We will present two learning algorithms that use 1-LQ, and prove that each of these algorithms will learn the class HDNF with respect to the distribution patterns defined above.\" \"We will use the class HDNF with respect to the distribution patterns 1, 1, 2, 3, 4, 5, 5, 5, 5, 5, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11"}, {"heading": "S1 and S2", "text": "P x \"Drh\" pxq \"h\" pxq \"h\" pxqs \"P x\" D rh \"pxq\" 1 ^ h \"pxq\" 0s \"P x\" D rh \"pxq\" 0 ^ h \"pxq\" 1s \"0 '4\" 4"}, {"heading": "4.3 A Lower Bound", "text": "In this section, we provide evidence that the use of queries within our upper limits is crucial. We will show that the problem of learning poly-sized decision trees can be reduced to the problem of learning DNFs w.r.t., which is realized by a small DNF with obvious examples. Since learning decision trees are widely regarded as insoluble (in fact, even learning the much smaller class of logpnq-juntas is considered difficult), this reduction serves as an indication that the problems we find difficult without membership in queries.Definition 11 A decision tree about t '1, 1un is a binary tree with labels that are chosen by x1., xn on the internal nodes and labels of t0, 1u on the leaves. Each internal node left branch is considered as \"1 branch; the right branch is the first branch. Each decision tree about n variables induces a function h: t, 1tun, 1u in the following way:\""}, {"heading": "5 Experiments", "text": "Member queries are a means by which we can use human knowledge to improve the performance of learning tasks. People have a very extensive knowledge and understanding of many of the problems that the ML community is working on. They can provide much more information than just the category of the object or an answer to a \"yes\" or \"no\" question. This knowledge is often basic and can be acquired without the use of an expert (e.g. through crowd sourcing). In this section, we will ask for additional information. Specifically, we were faced with a situation where we had a large number of characteristics and that these characteristics had an interpretation that is easy to understand. For each example in the sample group, the user is only asked to name each example."}, {"heading": "5.1 Is the additional data useful?", "text": "The first goal of this experiment is to show that, for at least some tasks, important parts of this thought process are easily accessible, i.e. that the commentators \"knowledge can be retrieved by asking simple questions. The second goal is to show that using this additional knowledge can help to significantly reduce the number of tagged examples that are required. We will formulate the above objectives using the concept of error separation. Let's be the classifier returned by the algorithm. We will break down LDph-q as the sum of the approximation error (the error of the best linear classifier) and the estimation error (the difference between LDph-q and the approximation error): LDphSq\" App'est where app \"min hPH LDphq and est\" LDphSq'min hPH LDphq's approximation is still an error (the difference between LDph-q and the approximation error)."}, {"heading": "5.2 Experimental setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.1 Sentiment Analysis", "text": "Sentiment Analysis (SA) is the Natural Language Processing task of identifying the setting of a particular text (usually whether it is positive, neutral or negative), a task that has been explored in the NLP community at different levels of scale for many years. It began as a document-level classification task (Pang and Lee, 2004), and then shifted focus to handling the sentence level (Hu and Liu, 2004; Kim and Hovy, 2004), with the newest focus being on sentiment analysis of microblog data such as Twitter. Working with these informal text genres, where users post their opinions, emotions and reviews on virtually anything, presents new challenges for processing natural language that goes beyond working with more traditional text genres such as news wire or product ratings. In fact, classical approaches to sentiment analysis (Pang and Lee, 2008) are not directly applicable to tweets, emotions and reviews of just about anything, and while most of them are short of large product grains, we focus on relatively large or very social feelings."}, {"heading": "5.2.3 Pre-processing", "text": "Tweets may contain, in addition to plain text, URL addresses, references to other Twitter users (appearing as @ \u0103username\u0105) or content tags (also referred to as hashtags) assigned by the tweeter (# \u0103tag\u0105). During pre-editing, we performed the following standard manipulations: \u2022 Words were changed to lowercase letters and punctuation marks were removed (apart from a set of fixed smileys) \u2022 Every hyperlink was replaced by the meta-word URL \u2022 Every word that started with @, i.e. a username in Twitter syntax, was replaced by the meta word USR. \u2022 The hashtag character 1 # 1 was removed from each tag to get a simple word."}, {"heading": "5.2.4 Language Model", "text": "We used the simple language models of n-grams (in our case unique specimens, bigrams and trigrams), i.e. each tweet is represented in t0, 1ud as a sparse vector, where d corresponds to the size of the dictionary and the i-th coordinate is only 1 if the i-th word occurs in the tweet. We performed a standard section of rare n-grams 7."}, {"heading": "5.2.5 Scoring", "text": "This scoring function is used in the SemEFPq task and is, overall, a very common scoring function for NLP tasks. The F1 score is the harmonious mean of Precision and Recall. Each label has its F1 score. For the positive label, precision is the number of tweets correctly divided by the total number of tweets that were marked as positive: PPOS \"TPTP\" FP 5The original label had 4 classes - [objective, positive, negative or neutral], but because Turks tended to confuse the lens with the neutral, the two classes were combined in the last task. 6This labeling method was originally intended for two separate tasks. The first is when a tweet contains a marked instance of a word or phrase to identify the mood of that instance (i.e., whether the word is negative or positive). The second is the determination of the overall mood of the entire tweet without the use of the 7 words of the FPOS."}, {"heading": "5.2.6 The algorithm", "text": "We compare two variants for the attribute space: the use of the entire attribute space (after truncating the rare n-grams) and the use of the \"query-acquired\" attribute space, which, for example, contains only features that users have selected as positive or negative. Information about the data and number of features is in Table 2. We used a simple Naive Bayes classifier with a small smoothing parameter. We also checked other classification algorithms - random forests, logistical regression, and multi-class SVM (with 1 regulation and 2 regulation), but the results of the Naive Bayes predictor were highest for both attribute spaces."}, {"heading": "5.3 Results", "text": "The results we will present are the results of the universal model. The test results of the other language models (Unigram + Bigram and Unigram + Bigram + Trigram) are nearly identical for both characteristic spaces, and the training values are expected to be higher with the complexity of the model. As our training set contains only about 8000 instances, we have decided to present the results of the simplest model, so that the number of characteristics would be comparable with the number of instances. The results of both variants are presented in Figure 2. As can be seen from the test results, our algorithm outperforms the other variant, which does not use any additional information. The difference in test performance is approximately constant across different training variables. To return to our assertions - regarding the approximation error: Looking at the final results of the training (possible using the larger training set), one can see that both variants are almost identical in all measurements."}, {"heading": "5.3.1 Precision and Recall", "text": "Other interesting features can be seen in the precision and retrieval diagrams (Figure 3): for example, if you look at the results of positive samples (a & b), you can see that the improvement in the results from using the query model is almost entirely due to the improvement in the accuracy values: if we use only 10% of the data, the query model reaches a test accuracy of 0.77, while the query-slowed model only reaches a test accuracy of 0.71, even when using the entire data set."}, {"heading": "5.3.2 Over-fitting", "text": "When we use the naive bayes algorithm, we estimate Ppf | cq for each characteristic f and each label c. This term measures how much the appearance of f contributes to the correct label 8 being c. With these terms, we can sort the characteristics according to an order that conveys their informativeness. As our characteristics are words (or bigrams or trgrams), we can gain some interesting insights by looking at the most informative characteristics that each variant uses. If we look at only the top 20 characteristics of the list, the selected characteristics of both variants are almost identical. However, if we take a closer look, we can see how the algorithm that uses the entire feature space selects some significant characteristics that clearly fit over the training data. Some examples are: \"nick,\" \"lloyd,\" and \"justin\" in the unigramic model, \"saturday8by the only naive assuzing all the independent build that label clearly fits over the training data.\" This is the most appropriate, in fact, the classification is given to the rider."}, {"heading": "5.4 Comparing to other Feature Selection Methods", "text": "One question that can be raised is whether improving the results is just an effect of the feature selection itself or that the fact that the features were selected through a query process is the important part. To answer this, we compared our algorithm with the use of other automatic feature selection techniques. We reviewed two methods of feature selection - filtering and reverse elimination. For each training, the number of features that the method should select was equal to the number of features selected by the users on this set. Results are shown in Figure 4. Training results of the automatic feature selection techniques are much lower than training results when using the entire feature space (and much more similar to our method already for small training sets). This fact is reasonable as we use a much smaller hypotheses class. If we look at the test results, it is evident that the use of other feature selection techniques significantly improves the test value compared to our selection, but still does not fall short of any feature selection."}, {"heading": "6 Conclusion and Future Work", "text": "We have presented both theoretical and empirical evidence that local membership surveys are useful and beneficial. In the theoretical setup, we have shown that even single-local surveys are stronger than the vanilla PAC model for a probably natural problem. In the empirical setup, we have shown that significantly better results can be achieved by providing additional information from users. Furthermore, the data was generated in the experiment using crowdsourcing and by asking very simple questions, showing that additional knowledge can be an easy task. Today, the use of the MQ model is almost non-existent in practice. Even the more popular models of active learning, pool-based or power-based, are relatively rare. For example, in a recent survey on annotation projects for natural language processing tasks, only 20% of respondents reported ever actively learning (Tomanek and Olsson, 2009)."}], "references": [{"title": "Learning regular sets from queries and counterexamples", "author": ["D. Angluin"], "venue": "Information and computation,", "citeRegEx": "Angluin,? \\Q1987\\E", "shortCiteRegEx": "Angluin", "year": 1987}, {"title": "When won t membership queries help", "author": ["D. Angluin", "M. Kharitonov"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Angluin and Kharitonov,? \\Q1995\\E", "shortCiteRegEx": "Angluin and Kharitonov", "year": 1995}, {"title": "Malicious omissions and errors in answers to membership queries", "author": ["D. Angluin", "M. Kri\u0137is", "R.H. Sloan", "G. Tur\u00e1n"], "venue": "Machine Learning,", "citeRegEx": "Angluin et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Angluin et al\\.", "year": 1997}, {"title": "Randomly fallible teachers: Learning monotone dnf with an incomplete membership oracle", "author": ["D. Angluin", "D.K. Slonim"], "venue": "Machine Learning,", "citeRegEx": "Angluin and Slonim,? \\Q1994\\E", "shortCiteRegEx": "Angluin and Slonim", "year": 1994}, {"title": "Learning using local membership queries. arXiv preprint arXiv:1211.0996", "author": ["P. Awasthi", "V. Feldman", "V. Kanade"], "venue": null, "citeRegEx": "Awasthi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Awasthi et al\\.", "year": 2012}, {"title": "Agnostic active learning", "author": ["Balcan", "M.-F", "A. Beygelzimer", "J. Langford"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Balcan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2006}, {"title": "Robust sentiment detection on twitter from biased and noisy data", "author": ["L. Barbosa", "J. Feng"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "Barbosa and Feng,? \\Q2010\\E", "shortCiteRegEx": "Barbosa and Feng", "year": 2010}, {"title": "Neural net algorithms that learn in polynomial time from examples and queries", "author": ["E.B. Baum"], "venue": "Neural Networks, IEEE Transactions", "citeRegEx": "Baum,? \\Q1991\\E", "shortCiteRegEx": "Baum", "year": 1991}, {"title": "Query learning can work poorly when a human oracle is used", "author": ["E.B. Baum", "K. Lang"], "venue": "In International Joint Conference on Neural Networks,", "citeRegEx": "Baum and Lang,? \\Q1992\\E", "shortCiteRegEx": "Baum and Lang", "year": 1992}, {"title": "Learning with errors in answers to membership queries", "author": ["L. Bisht", "N.H. Bshouty", "L. Khoury"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Bisht et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bisht et al\\.", "year": 2008}, {"title": "Learning with unreliable boundary queries", "author": ["A. Blum", "P. Chalasani", "S.A. Goldman", "D.K. Slonim"], "venue": "In Proceedings of the eighth annual conference on Computational learning theory,", "citeRegEx": "Blum et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1995}, {"title": "Fast learning of k-term dnf formulas with queries", "author": ["A. Blum", "S. Rudich"], "venue": "In Proceedings of the twenty-fourth annual ACM symposium on Theory of computing,", "citeRegEx": "Blum and Rudich,? \\Q1992\\E", "shortCiteRegEx": "Blum and Rudich", "year": 1992}, {"title": "Exact learning boolean functions via the monotone theory", "author": ["N.H. Bshouty"], "venue": "Information and Computation,", "citeRegEx": "Bshouty,? \\Q1995\\E", "shortCiteRegEx": "Bshouty", "year": 1995}, {"title": "More data speeds up training time in learning halfspaces over sparse vectors", "author": ["A. Daniely", "N. Linial", "S. Shalev-Shwartz"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Daniely et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2013}, {"title": "From average case complexity to improper learning complexity", "author": ["A. Daniely", "N. Linial", "S. Shalev-Shwartz"], "venue": "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Daniely et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2014}, {"title": "Complexity theoretic limitations on learning dnf\u2019s", "author": ["A. Daniely", "S. Shalev-Shwatz"], "venue": "arXiv preprint arXiv:1404.3378", "citeRegEx": "Daniely and Shalev.Shwatz,? \\Q2014\\E", "shortCiteRegEx": "Daniely and Shalev.Shwatz", "year": 2014}, {"title": "Analysis of a greedy active learning strategy", "author": ["S. Dasgupta"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Dasgupta,? \\Q2004\\E", "shortCiteRegEx": "Dasgupta", "year": 2004}, {"title": "Enhanced sentiment learning using twitter hashtags and smileys", "author": ["D. Davidov", "O. Tsur", "A. Rappoport"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Active learning by labeling features", "author": ["G. Druck", "B. Settles", "A. McCallum"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume", "citeRegEx": "Druck et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Druck et al\\.", "year": 2009}, {"title": "Learning decision trees from random examples", "author": ["A. Ehrenfeucht", "D. Haussler"], "venue": "Information and Computation,", "citeRegEx": "Ehrenfeucht and Haussler,? \\Q1989\\E", "shortCiteRegEx": "Ehrenfeucht and Haussler", "year": 1989}, {"title": "On the power of membership queries in agnostic learning", "author": ["V. Feldman"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Feldman,? \\Q2009\\E", "shortCiteRegEx": "Feldman", "year": 2009}, {"title": "Boosting a weak learning algorithm by majority", "author": ["Y. Freund"], "venue": "Information and computation,", "citeRegEx": "Freund,? \\Q1995\\E", "shortCiteRegEx": "Freund", "year": 1995}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Hu and Liu,? \\Q2004\\E", "shortCiteRegEx": "Hu and Liu", "year": 2004}, {"title": "An efficient membership-query algorithm for learning dnf with respect to the uniform distribution", "author": ["J. Jackson"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Jackson,? \\Q1994\\E", "shortCiteRegEx": "Jackson", "year": 1994}, {"title": "Cryptographic limitations on learning boolean formulae and finite automata", "author": ["M. Kearns", "L. Valiant"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Kearns and Valiant,? \\Q1994\\E", "shortCiteRegEx": "Kearns and Valiant", "year": 1994}, {"title": "Determining the sentiment of opinions", "author": ["Kim", "S.-M", "E. Hovy"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Kim et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2004}, {"title": "Cryptographic hardness for learning intersections of halfspaces", "author": ["A.R. Klivans", "A Sherstov"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Klivans and Sherstov,? \\Q2006\\E", "shortCiteRegEx": "Klivans and Sherstov", "year": 2006}, {"title": "Twitter sentiment analysis: The good the bad and the omg! Icwsm, 11:538\u2013541", "author": ["E. Kouloumpis", "T. Wilson", "J. Moore"], "venue": null, "citeRegEx": "Kouloumpis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kouloumpis et al\\.", "year": 2011}, {"title": "Learning decision trees using the fourier spectrum", "author": ["E. Kushilevitz", "Y. Mansour"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Kushilevitz and Mansour,? \\Q1993\\E", "shortCiteRegEx": "Kushilevitz and Mansour", "year": 1993}, {"title": "Semeval-2013 task 2: Sentiment analysis in twitter", "author": ["P. Nakov", "Z. Kozareva", "A. Ritter", "S. Rosenthal", "V. Stoyanov", "T. Wilson"], "venue": null, "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Twitter as a corpus for sentiment analysis and opinion mining", "author": ["A. Pak", "P. Paroubek"], "venue": "In LREC,", "citeRegEx": "Pak and Paroubek,? \\Q2010\\E", "shortCiteRegEx": "Pak and Paroubek", "year": 2010}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Pang and Lee,? \\Q2004\\E", "shortCiteRegEx": "Pang and Lee", "year": 2004}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and trends in information retrieval,", "citeRegEx": "Pang and Lee,? \\Q2008\\E", "shortCiteRegEx": "Pang and Lee", "year": 2008}, {"title": "An interactive algorithm for asking and incorporating feature feedback into support vector machines", "author": ["H. Raghavan", "J. Allan"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Raghavan and Allan,? \\Q2007\\E", "shortCiteRegEx": "Raghavan and Allan", "year": 2007}, {"title": "Interactive feature selection", "author": ["H. Raghavan", "O. Madani", "R. Jones"], "venue": "In IJCAI,", "citeRegEx": "Raghavan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Raghavan et al\\.", "year": 2005}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin,", "citeRegEx": "Settles,? \\Q2010\\E", "shortCiteRegEx": "Settles", "year": 2010}, {"title": "Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances", "author": ["B. Settles"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Settles,? \\Q2011\\E", "shortCiteRegEx": "Settles", "year": 2011}, {"title": "Learning with queries but incomplete information", "author": ["R.H. Sloan", "G. Tur\u00e1n"], "venue": "In Proceedings of the seventh annual conference on Computational learning theory,", "citeRegEx": "Sloan and Tur\u00e1n,? \\Q1994\\E", "shortCiteRegEx": "Sloan and Tur\u00e1n", "year": 1994}, {"title": "A web survey on the use of active learning to support annotation of text data", "author": ["K. Tomanek", "F. Olsson"], "venue": "In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing,", "citeRegEx": "Tomanek and Olsson,? \\Q2009\\E", "shortCiteRegEx": "Tomanek and Olsson", "year": 2009}, {"title": "A theory of the learnable", "author": ["L.G. Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant,? \\Q1984\\E", "shortCiteRegEx": "Valiant", "year": 1984}], "referenceMentions": [{"referenceID": 8, "context": "One of the main causes for this is a report (Baum and Lang, 1992) on very disappointing empirical performance of a query algorithm.", "startOffset": 44, "endOffset": 65}, {"referenceID": 4, "context": "In this work we study a new model of local membership queries (Awasthi et al., 2012), which tries to resolve the problem of artificial queries.", "startOffset": 62, "endOffset": 84}, {"referenceID": 39, "context": "These two types of input were the basis for the learning model originally suggested in the celebrated paper \u201cA theory of the learnable\u201d (Valiant, 1984).", "startOffset": 136, "endOffset": 151}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 11, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 12, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 23, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces .", "startOffset": 123, "endOffset": 620}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces .", "startOffset": 123, "endOffset": 700}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces . Their algorithm had very poor results, which was attributed to the fact that the algorithm created artificial and unnatural examples, which resulted in a noisy labeling. We elaborate on this experiment and criticize its conclusions in section 2. A suggested solution to the problem of unnatural examples was proposed by Awasthi et al. (2012). They suggested a mid-way model of learning with queries, but only restricted ones.", "startOffset": 123, "endOffset": 1068}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces . Their algorithm had very poor results, which was attributed to the fact that the algorithm created artificial and unnatural examples, which resulted in a noisy labeling. We elaborate on this experiment and criticize its conclusions in section 2. A suggested solution to the problem of unnatural examples was proposed by Awasthi et al. (2012). They suggested a mid-way model of learning with queries, but only restricted ones. The queries that their model allows the algorithm to ask are only local queries, i.e., queries that are close in some sense to examples from the sample set. Hopefully, examples which are similar to natural examples will also appear to be natural, or at least close to natural, and in any case will be far from appearing random or artificial. In their work, Awasti et al. started to investigate the power and the limitations of this model of local queries. They proved positive results on learning sparse polynomials with Oplogpnqqlocal queries under what they defined as locally smooth distributions1, which in some sense generalize the uniform and product distributions. They also proposed an algorithm that learns DNF formulas under the uniform distribution in quasi-polynomial time using only Oplogpnqq-local queries. The exciting ideas of Awasthi et al. (2012) leave many directions for future work.", "startOffset": 123, "endOffset": 2017}, {"referenceID": 33, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 34, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 36, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 18, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 39, "context": "1 PAC Valiant\u2019s Probably Approximately Correct (PAC) model of learning (Valiant, 1984) formulates the problem of learning a concept from examples.", "startOffset": 71, "endOffset": 86}, {"referenceID": 39, "context": "More examples include relatively weak classes such as DNFs and CNFs with constantly many terms (Valiant, 1984), and rank k decision trees (Ehrenfeucht and Haussler, 1989) for a constant k.", "startOffset": 95, "endOffset": 110}, {"referenceID": 19, "context": "More examples include relatively weak classes such as DNFs and CNFs with constantly many terms (Valiant, 1984), and rank k decision trees (Ehrenfeucht and Haussler, 1989) for a constant k.", "startOffset": 138, "endOffset": 170}, {"referenceID": 24, "context": "For example, learning automatons, logarithmic depth circuits, and intersections of polynomially many halfspaces are all intractable, assuming the security of various cryptographic schemes (Kearns and Valiant, 1994; Klivans et al., 2006).", "startOffset": 188, "endOffset": 236}, {"referenceID": 14, "context": "In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard.", "startOffset": 3, "endOffset": 80}, {"referenceID": 15, "context": "In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard.", "startOffset": 3, "endOffset": 80}, {"referenceID": 13, "context": "In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard.", "startOffset": 3, "endOffset": 80}, {"referenceID": 35, "context": "Several types of active models have been proposed: the Membership Query Synthesis, Stream-Based Selective Sampling, and Pool-Based Sampling (Settles, 2010).", "startOffset": 140, "endOffset": 155}, {"referenceID": 39, "context": "Our work is in the area of the \u201cMembership Queries\u201d (MQ) model which was presented in (Valiant, 1984).", "startOffset": 86, "endOffset": 101}, {"referenceID": 0, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 170, "endOffset": 185}, {"referenceID": 11, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 238, "endOffset": 261}, {"referenceID": 12, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 326, "endOffset": 341}, {"referenceID": 7, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 386, "endOffset": 398}, {"referenceID": 23, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 460, "endOffset": 475}, {"referenceID": 21, "context": "The last of these results was built upon Freund\u2019s boosting algorithm (Freund, 1995) and the Fourier-based technique for learning using membership queries due to (Kushilevitz and Mansour, 1993).", "startOffset": 69, "endOffset": 83}, {"referenceID": 28, "context": "The last of these results was built upon Freund\u2019s boosting algorithm (Freund, 1995) and the Fourier-based technique for learning using membership queries due to (Kushilevitz and Mansour, 1993).", "startOffset": 161, "endOffset": 192}, {"referenceID": 1, "context": ", in the case of learning DNF and CNF formulas (Angluin and Kharitonov, 1995), and in the case of distribution free agnostic learning (although in the distribution-specific agnostic setting membership queries do increase the power of the learner) (Feldman, 2009).", "startOffset": 47, "endOffset": 77}, {"referenceID": 20, "context": ", in the case of learning DNF and CNF formulas (Angluin and Kharitonov, 1995), and in the case of distribution free agnostic learning (although in the distribution-specific agnostic setting membership queries do increase the power of the learner) (Feldman, 2009).", "startOffset": 247, "endOffset": 262}, {"referenceID": 7, "context": "A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991).", "startOffset": 38, "endOffset": 59}, {"referenceID": 7, "context": "A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991). This algorithm uses the idea that given two examples, one positive and one negative, and a query oracle, it is possible to find an approximately accurate separating halfspace by using a binary search on the line between the positive and negative examples.", "startOffset": 38, "endOffset": 162}, {"referenceID": 7, "context": "A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991). This algorithm uses the idea that given two examples, one positive and one negative, and a query oracle, it is possible to find an approximately accurate separating halfspace by using a binary search on the line between the positive and negative examples. Their experiment attempts to evaluate this idea in practice. The task that they chose is the task of binary digit classification. The algorithm would receive two examples, one positive and one negative (say, an image of the digit 4 and an image of the digit 7) and would return the weights of the halfspace. The generalization error of the halfspace would then be tested on other examples from the data. The query technique they used in the experiment is different than in the original algorithm: \u201cA direct implementation of this algorithm would repeatedly flash images on the screen during the binary search and would require the test subject to type in the correct label for each image. Because this process seemed likely to be error prone, we instead provided an interface that permitted the test subject to scan through the input space using the mouse and then click on an image that seemed to lie right at the edge of recognizability\u201d (from Baum and Lang (1992)).", "startOffset": 38, "endOffset": 1386}, {"referenceID": 8, "context": "Figure 1: An example taken from (Baum and Lang, 1992): the images the user saw on the screen for the digits 5 and 7", "startOffset": 32, "endOffset": 53}, {"referenceID": 33, "context": "This work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al.", "startOffset": 89, "endOffset": 104}, {"referenceID": 5, "context": "This work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al. (2006); Dasgupta (2004) and more).", "startOffset": 105, "endOffset": 126}, {"referenceID": 5, "context": "This work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al. (2006); Dasgupta (2004) and more).", "startOffset": 105, "endOffset": 143}, {"referenceID": 8, "context": "This framework deals with the problem raised by (Baum and Lang, 1992).", "startOffset": 48, "endOffset": 69}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ.", "startOffset": 35, "endOffset": 61}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al.", "startOffset": 35, "endOffset": 149}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al.", "startOffset": 35, "endOffset": 169}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al.", "startOffset": 35, "endOffset": 193}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al. (2008)).", "startOffset": 35, "endOffset": 214}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al. (2008)). The third method is to restrict the examples that the learning algorithm can query to examples that are similar to examples drawn from the distribution. This is formalized in the work of Awasthi et al. (2012). They present the concept of learning using only local membership queries.", "startOffset": 35, "endOffset": 425}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances.", "startOffset": 0, "endOffset": 20}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously.", "startOffset": 0, "endOffset": 343}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously. At any point in time, an instance and a list of features for each label is presented on the screen. The user can choose to either label the instance, choose a feature from the list as being indicative, or add a new feature of his or her choice. Another similar work is of Raghavan and Allan (2007) and Raghavan et al.", "startOffset": 0, "endOffset": 756}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously. At any point in time, an instance and a list of features for each label is presented on the screen. The user can choose to either label the instance, choose a feature from the list as being indicative, or add a new feature of his or her choice. Another similar work is of Raghavan and Allan (2007) and Raghavan et al. (2005). They studied the problem of tandem learning where they combine uncertainty sampling for instances along with co-occurrence-based interactive feature selection.", "startOffset": 0, "endOffset": 783}, {"referenceID": 31, "context": "It started off from being a document level classification task (Pang and Lee, 2004), and then the focus shifted to handling the sentence level (Hu and Liu, 2004; Kim and Hovy, 2004).", "startOffset": 63, "endOffset": 83}, {"referenceID": 22, "context": "It started off from being a document level classification task (Pang and Lee, 2004), and then the focus shifted to handling the sentence level (Hu and Liu, 2004; Kim and Hovy, 2004).", "startOffset": 143, "endOffset": 181}, {"referenceID": 32, "context": "Indeed, classical approaches to Sentiment Analysis (Pang and Lee, 2008) are not directly applicable to tweets.", "startOffset": 51, "endOffset": 71}, {"referenceID": 30, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 27, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 17, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 6, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 29, "context": "We worked with the data set from SemEval (Nakov et al., 2013), a shared task for Sentiment Analysis of Tweets .", "startOffset": 41, "endOffset": 61}, {"referenceID": 38, "context": ", in a recent survey of annotation projects for natural language processing tasks, only 20% of the respondents stated they had ever decided to use active learning (Tomanek and Olsson, 2009).", "startOffset": 163, "endOffset": 189}, {"referenceID": 4, "context": "Some examples of open questions: Is the use of 2-local queries stronger than the use of 1-local queries on a natural environment? What are the limitations of a model that uses Op1q-local queries with comparison to the model of (Awasthi et al., 2012) that uses logpnq-local queries?", "startOffset": 227, "endOffset": 249}], "year": 2015, "abstractText": "Classic machine learning algorithms learn from labelled examples. For example, to design a machine translation system, a typical training set will consist of English sentences and their translation to French. There is a stronger model, in which the algorithm can also query for labels of new examples it creates. E.g, in the translation task, the algorithm can create a new English sentence, and request its translation from the user during training. This combination of examples and queries, that resembles human learning patterns, has been widely studied. Yet, despite many theoretical results, query algorithms are almost never used. One of the main causes for this is a report (Baum and Lang, 1992) on very disappointing empirical performance of a query algorithm. These poor results were mainly attributed to the fact that the algorithm queried for labels of examples that are artificial, and impossible to interpret by humans. In this work we study a new model of local membership queries (Awasthi et al., 2012), which tries to resolve the problem of artificial queries. In this model, the algorithm is only allowed to query the labels of examples which are close to examples from the training set. E.g., in translation, the algorithm can change individual words in a sentence it has already seen, and then ask for the translation. In this model, the examples queried by the algorithm will be close to natural examples and hence, hopefully, will not appear as artificial or random. In this work we focus on 1-local membership queries (i.e., queries of distance 1 from an example in the training sample). We show that 1-local membership queries are already stronger than the standard learning model. We also present an experiment on a well known NLP task of sentiment analysis. In this experiment, the users were asked to provide, in a way that resembles 1-local queries, more information than merely indicating the label. We present results that illustrate that this extra information is beneficial in practice.", "creator": "LaTeX with hyperref package"}}}