{"id": "1512.00355", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2015", "title": "Taxonomy grounded aggregation of classifiers with different label sets", "abstract": "We describe the problem of aggregating the label predictions of diverse classifiers using a class taxonomy. Such a taxonomy may not have been available or referenced when the individual classifiers were designed and trained, yet mapping the output labels into the taxonomy is desirable to integrate the effort spent in training the constituent classifiers. A hierarchical taxonomy representing some domain knowledge may be different from, but partially mappable to, the label sets of the individual classifiers. We present a heuristic approach and a principled graphical model to aggregate the label predictions by grounding them into the available taxonomy. Our model aggregates the labels using the taxonomy structure as constraints to find the most likely hierarchically consistent class. We experimentally validate our proposed method on image and text classification tasks.", "histories": [["v1", "Tue, 1 Dec 2015 17:32:16 GMT  (127kb,D)", "http://arxiv.org/abs/1512.00355v1", "Under review by AISTATS 2016"]], "COMMENTS": "Under review by AISTATS 2016", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["amrita saha", "sathish indurthi", "shantanu godbole", "subendhu rongali", "vikas c raykar"], "accepted": false, "id": "1512.00355"}, "pdf": {"name": "1512.00355.pdf", "metadata": {"source": "CRF", "title": "Taxonomy grounded aggregation of classifiers with different label sets", "authors": ["Amrita Saha", "Sathish Indurthi", "Shantanu Godbole", "Subendhu Rongali", "Vikas C. Raykar"], "emails": [], "sections": [{"heading": null, "text": "We describe the problem of aggregating the identification predictions of different classifiers by means of a class taxonomy. Such taxonomy may not have been present or referenced in the design and training of the individual classifiers, but it is desirable to integrate the output labels into the taxonomy in order to integrate the effort required to train the constituent classifiers. A hierarchical taxonomy that represents a certain domain knowledge may differ from the label sets of the individual classifiers, but may be partially assignable to it. We present a heuristic approach and a basic graphical model for aggregating the identification predictions by grounding in the available taxonomy. Our model aggregates the labels by means of the taxonomy structure as constraints to find the most likely hierarchically consistent class."}, {"heading": "1 Introduction", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country."}, {"heading": "2 Notation and problem statement", "text": "This paper deals with classification problems in which class names are hierarchically arranged in class taxonomies. (The hierarchy imposes a parent-child relationship between classes. (1) An instance that belongs in a specific class also belongs in all its ancestral classes. (2) A class taxonomy [23] is formally defined as a pair (C, 2) in which the parent-child relationship between classes is defined. (2) The relationship between the two classes ci and cj is a subclass of cj. (2) The relationship between classes is a subclass of cj. (3) The relationship between classes is satisfactory."}, {"heading": "3 Score propagation in the class taxonomy", "text": "We will first present a heuristic solution by transferring the values of the classifier upwards from a particular class to all its ancestors in the taxonomy by navigating the IS-A hierarchy upwards. The values of several classifiers at a node are then summarized by addition. Then, the final path is estimated by traversing the taxonomy from the root and ending at a class based on the entropy of the children. Concretely (see Figure 2 for illustration) \u2022 First, we construct an induced subgraph with classes CI = {C1."}, {"heading": "4 The proposed probabilistic graphical model for aggregating classifiers", "text": "The heuristic method assumes that all classifiers have the same performance and then aggregate the values. In this section, we throw out the label aggregation problem as an inference problem in an appropriately defined graphical model (for a given instance x).The proposed graphical model (or Bayean network) has two types of nodes, discrete binary nodes that correspond to hierarchically organized classes in taxonomy, and continuous nodes that correspond to the m classifier results (see Figure 3, which is the graphical model that corresponds to the induced sub-graph in Figure 2).Each class c in taxonomy corresponds to a binary discrete node z (c), which is the true (unknown) binary designation of the instance x for class c in taxonomy. All discrete nodes z1,."}, {"heading": "5 Extensions", "text": "Instead of the bi-normal distribution, we have the following two parameters that define the conditional probability distribution at each classification node: \u03b1jk: = Pr [y j k = 1 | zk = 1] and \u03b2jk: = Pr [y j k = 0 | zk = 0].The EM algorithm for estimating the classification parameters - In \u00a7 3, we estimate the parameters using a separate validation group. Sometimes, we do not have access to a labeled validation group. This is especially true if we are interested in aggregating the crowdsourced labels, where the goal is to estimate the true labels. In such scenarios, we can estimate the model parameters directly using the Expectation Maximization (EM) algorithm (EM algorithm [4] is an efficient iterative method for estimating the parameters in the presence of missing / hidden data."}, {"heading": "6 Experimental Validation", "text": "It is indeed the case that we will be able to set out to find a solution that is capable of resolving the problems that we have got to grips with."}, {"heading": "7 Conclusion", "text": "In this paper, we formulate the problem of aggregation of labels from several flat classification systems into a possible different hierarchical system on pages 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,"}], "references": [{"title": "On integrating catalogs", "author": ["Rakesh Agrawal", "Ramakrishnan Srikant"], "venue": "In Proceedings of the 10th international conference on World Wide Web,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Probabilistic networks and expert systems: Exact computational methods for Bayesian networks", "author": ["R. G Cowell", "A.P. Dawid", "S.L. Lauritzen", "D.J. Speigelhalter"], "venue": "Springer,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "Journal of the Royal Statistical Society: Series B, 39(1):1\u201338,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1977}, {"title": "Hierarchical classification of web content", "author": ["S. Dumais", "H. Chen"], "venue": "Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 256\u2013263,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "The Pascal Visual Object Classes (VOC) Challenge", "author": ["M. Everingham", "L. Van Gool", "C. Williams", "J. Winn", "A. Zisserman"], "venue": "International Journal of Computer Vision, 88(2):303\u2013338,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition", "author": ["Donahue J", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "CoRR, abs/1310.1531,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Hierarchically classifying documents using very few words", "author": ["D. Koller", "M. Sahami"], "venue": "Proceedings of the Fourteenth International Conference on Machine Learning, pages 170\u2013178,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Evaluation measures for hierarchical classification: a unified view and novel approaches", "author": ["A. Kosmopoulos", "I. Partalas", "E. Gaussier", "G. Paliouras", "I. Androutsopoulos"], "venue": "Data Mining and Knowledge Discovery, 29(3):820\u2013865,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Propagation of probabilities, means, and variances in mixed graphical association models", "author": ["S.L. Lauritzen"], "venue": "Journal of the American Statistical Association, 87(420):1098\u20131108,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1992}, {"title": "RCV1: A New Benchmark Collection for Text Categorization Research", "author": ["D.D. Lewis", "Y. Yang", "T. Rose", "F. Li"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Large scale diagnostic code classification for medical patient records", "author": ["L.V. Lita", "S. Yu", "R.S. Niculescu", "J. Bi"], "venue": "IJCNLP, pages 877\u2013882,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "WordNet: A Lexical Database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM, 38(11):39\u201341,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "From large scale image categorization to entrylevel categories", "author": ["V. Ordonez", "J. Deng", "Y. Choi", "A.C. Berg", "T.L. Berg"], "venue": "IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Taci: Taxonomy-aware catalog integration", "author": ["Panagiotis Papadimitriou", "Panayiotis Tsaparas", "Ariel Fuxman", "Lise Getoor"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Lshtc: A benchmark for large-scale text classification", "author": ["I. Partalas", "A. Kosmopoulos", "N. Baskiotis", "T. Artieres", "G. Paliouras", "E. Gaussier", "I. Androutsopoulos", "M.-R. Amini", "P. Galinari"], "venue": "arXiv preprint arXiv:1503.08581,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning from crowds", "author": ["V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy"], "venue": "Journal of Machine Learning Research, 11:1297\u20131322, April", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Cross-training: learning probabilistic mappings between topics", "author": ["Sunita Sarawagi", "Soumen Chakrabarti", "Shantanu Godbole"], "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "and A", "author": ["C.N. Silla Jr"], "venue": "A. Freitas. A survey of hierarchical classification across different application domains. Data Mining and Knowledge Discovery, 22(1-2):31\u2013 72,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Going Deeper with Convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CoRR, abs/1409.4842,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Transforming classifier scores into accurate multiclass probability estimates", "author": ["B. Zadrozny", "C. Elkan"], "venue": "Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 694\u2013699,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 10, "context": "In several real-world classification problems (for example visual object recognition [12], text categorization [9, 19], web content classification [5], US Patent codes, ICD [1] codes of diseases [15] etc.", "startOffset": 85, "endOffset": 89}, {"referenceID": 7, "context": "In several real-world classification problems (for example visual object recognition [12], text categorization [9, 19], web content classification [5], US Patent codes, ICD [1] codes of diseases [15] etc.", "startOffset": 111, "endOffset": 118}, {"referenceID": 17, "context": "In several real-world classification problems (for example visual object recognition [12], text categorization [9, 19], web content classification [5], US Patent codes, ICD [1] codes of diseases [15] etc.", "startOffset": 111, "endOffset": 118}, {"referenceID": 3, "context": "In several real-world classification problems (for example visual object recognition [12], text categorization [9, 19], web content classification [5], US Patent codes, ICD [1] codes of diseases [15] etc.", "startOffset": 147, "endOffset": 150}, {"referenceID": 13, "context": "In several real-world classification problems (for example visual object recognition [12], text categorization [9, 19], web content classification [5], US Patent codes, ICD [1] codes of diseases [15] etc.", "startOffset": 195, "endOffset": 199}, {"referenceID": 10, "context": "As a motivating example we consider the task of visual object recognition [12, 7]\u2014given an image (or a region in the image) the task is to predict the most likely object in the image.", "startOffset": 74, "endOffset": 81}, {"referenceID": 5, "context": "As a motivating example we consider the task of visual object recognition [12, 7]\u2014given an image (or a region in the image) the task is to predict the most likely object in the image.", "startOffset": 74, "endOffset": 81}, {"referenceID": 10, "context": "Considerable amount of research effort and also CPU time(especially in the case of convolutional neural network based approaches [12, 24] which takes weeks to months to train) has been spent on training these classifiers.", "startOffset": 129, "endOffset": 137}, {"referenceID": 22, "context": "Considerable amount of research effort and also CPU time(especially in the case of convolutional neural network based approaches [12, 24] which takes weeks to months to train) has been spent on training these classifiers.", "startOffset": 129, "endOffset": 137}, {"referenceID": 14, "context": "For this domain we use the Wordnet [16] 2 , which is a DAG structured class", "startOffset": 35, "endOffset": 39}, {"referenceID": 9, "context": "For example the CIFAR-100 dataset [11] has 100 class labels, the PASCAL-VOC datset [6] has 20 class labels, and the latest ImageNet ILSVRC challenge dataset [21] has 1000 class labels.", "startOffset": 34, "endOffset": 38}, {"referenceID": 4, "context": "For example the CIFAR-100 dataset [11] has 100 class labels, the PASCAL-VOC datset [6] has 20 class labels, and the latest ImageNet ILSVRC challenge dataset [21] has 1000 class labels.", "startOffset": 83, "endOffset": 86}, {"referenceID": 19, "context": "For example the CIFAR-100 dataset [11] has 100 class labels, the PASCAL-VOC datset [6] has 20 class labels, and the latest ImageNet ILSVRC challenge dataset [21] has 1000 class labels.", "startOffset": 157, "endOffset": 161}, {"referenceID": 14, "context": "WordNet [16] is a large lexical database of english ar X iv :1 51 2.", "startOffset": 8, "endOffset": 12}, {"referenceID": 21, "context": "Related work\u2014There is a rich literature in the area of hierarchical classification (see [23] for a survey), which deals with training classifiers by explicitly accounting for the class hierarchy.", "startOffset": 88, "endOffset": 92}, {"referenceID": 18, "context": "While sophisticated techniques exist for binary, categorical and ordinal labels [20] to the best of our knowledge there are no methods for labels", "startOffset": 80, "endOffset": 84}, {"referenceID": 0, "context": "Another area of research related to our problem setting is that of integrating (or mapping) label-sets into each other as in the case of e-commerce catalog integration [2, 22, 18].", "startOffset": 168, "endOffset": 179}, {"referenceID": 20, "context": "Another area of research related to our problem setting is that of integrating (or mapping) label-sets into each other as in the case of e-commerce catalog integration [2, 22, 18].", "startOffset": 168, "endOffset": 179}, {"referenceID": 16, "context": "Another area of research related to our problem setting is that of integrating (or mapping) label-sets into each other as in the case of e-commerce catalog integration [2, 22, 18].", "startOffset": 168, "endOffset": 179}, {"referenceID": 21, "context": "Formally a class taxonomy [23] is defined as a pair (C,\u227a), where C = {c1, .", "startOffset": 26, "endOffset": 30}, {"referenceID": 23, "context": "For real valued scores they can be converted to probabilities via the soft-max function or via some calibration techniques [25].", "startOffset": 123, "endOffset": 127}, {"referenceID": 0, "context": "If this is not true then we can approximate the mappings using class mapping techniques [2, 22, 18].", "startOffset": 88, "endOffset": 99}, {"referenceID": 20, "context": "If this is not true then we can approximate the mappings using class mapping techniques [2, 22, 18].", "startOffset": 88, "endOffset": 99}, {"referenceID": 16, "context": "If this is not true then we can approximate the mappings using class mapping techniques [2, 22, 18].", "startOffset": 88, "endOffset": 99}, {"referenceID": 1, "context": "The graphical model which we have described is a mixed discrete-gaussian network [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 11, "context": "For such networks exact inference algorithms exist [13], which permits the local computation on the junction tree of exact probabilities, means and variances.", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": "The EM algorithm [4] is an efficient iterative procedure to estimate the parameters in presence of missing/hidden data.", "startOffset": 17, "endOffset": 20}, {"referenceID": 15, "context": "We can appropriately modify our termination strategy to account for this by suitable backing off the path using ideas in [17].", "startOffset": 121, "endOffset": 125}, {"referenceID": 19, "context": "Datasets\u2014For visual object recognition we use a subset of images from the ImageNet ILSVRC2014 detection challenge dataset [21].", "startOffset": 122, "endOffset": 126}, {"referenceID": 12, "context": "For our text categorization experiments, we used the benchmark Reuters Corpus Volume 1 (RCV1) news articles dataset [14].", "startOffset": 116, "endOffset": 120}, {"referenceID": 6, "context": "For object detection, we take the activations of the sixth hidden layer of a deep convolutional neural network as features and then train a linear multi-class SVM with these features [8].", "startOffset": 183, "endOffset": 186}, {"referenceID": 8, "context": "There is a rich literature on evaluation measures for hierarchical classification (see [10] for a review).", "startOffset": 87, "endOffset": 91}, {"referenceID": 8, "context": "For our evaluation we choose the Lowest Common Ancestor (LCA) based precision (PLCA), recall (RLCA) and F1-score (FLCA) measures as recommended in [10].", "startOffset": 147, "endOffset": 151}, {"referenceID": 15, "context": "For the object recognition dataset we also show results for an alternate termination strategy described in \u00a7 5 which decides the terminal node by backing off to a suitable entry level class [17].", "startOffset": 190, "endOffset": 194}, {"referenceID": 0, "context": "We plan to integrate ideas from catalog integration [2] directly into our graphical model.", "startOffset": 52, "endOffset": 55}], "year": 2015, "abstractText": "We describe the problem of aggregating the label predictions of diverse classifiers using a class taxonomy. Such a taxonomy may not have been available or referenced when the individual classifiers were designed and trained, yet mapping the output labels into the taxonomy is desirable to integrate the effort spent in training the constituent classifiers. A hierarchical taxonomy representing some domain knowledge may be different from, but partially mappable to, the label sets of the individual classifiers. We present a heuristic approach and a principled graphical model to aggregate the label predictions by grounding them into the available taxonomy. Our model aggregates the labels using the taxonomy structure as constraints to find the most likely hierarchically consistent class. We experimentally validate our proposed method on image and text classification tasks.", "creator": "LaTeX with hyperref package"}}}