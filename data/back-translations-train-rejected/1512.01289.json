{"id": "1512.01289", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2015", "title": "Predicting and visualizing psychological attributions with a deep neural network", "abstract": "Judgements about personality based on facial appearance are strong effectors in social decision making and are known to impact on areas from presidential elections to jury decisions. Recent work has shown that it is possible to predict perception of memorability, trustworthiness, intelligence and other attributes in human face images. The most successful of these approaches requires face images expertly annotated with key facial landmarks. We demonstrate a Convolutional Neural Network (CNN) model that is able perform the same task without the need for landmark features thereby greatly increasing efficiency. The model has high accuracy, surpassing human level performance in some cases. Furthermore, we use a deconvolutional approach to visualize important features for perception of 22 attributes and show that these can be described as a composites of their positive and negative components by separately visualizing both.", "histories": [["v1", "Fri, 4 Dec 2015 00:24:16 GMT  (2353kb,D)", "http://arxiv.org/abs/1512.01289v1", null], ["v2", "Sat, 24 Dec 2016 01:06:35 GMT  (2862kb,D)", "http://arxiv.org/abs/1512.01289v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["edward grant", "stephan sahm", "mariam zabihi", "marcel van gerven"], "accepted": false, "id": "1512.01289"}, "pdf": {"name": "1512.01289.pdf", "metadata": {"source": "CRF", "title": "Predicting psychological attributions from face photographs with a deep neural network", "authors": ["Edward Grant", "Stephan Sahm", "Mariam Zabihi", "Marcel van Gerven"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Facial attributions for intelligence, attractiveness, dominance and trustworthiness have been shown to have a strong effect on social decision-making, with far-reaching consequences from choosing between presidential candidates and jury decisions in criminal trials [1, 2].Nevertheless, it is difficult to reliably predict how a face will be perceived. However, some of the best current methods require images that are hand-annotated, which is time-consuming [3].Given the success of CNNs in image recognition tasks [4], the CNN model is a natural choice for visual mapping of psychological characteristics. In addition, we require images that are commented by hand to be tagged with facial characteristics, which requires visual visualization [cs.C V] 4D ecsuperior performance in visualization tasks, CNNs are able to learn visual characteristics from image data and do not require additional human mapping of psychological characteristics. In addition, we require work modeling the attributes perception of Khosla has been."}, {"heading": "2 Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Dataset", "text": "Our sample set consisted of a commented subset of the 10K face database of Bainbridge et al. [11], consisting of 2222 face photos as RGB images with psychological and demographic labels. These data were collected in the form of an evaluation of 15 participants by psychological characteristics and 13 participants by demographic characteristics."}, {"heading": "2.2 Preprocessing", "text": "For the gender, the ratings were already binary and the classes were balanced by randomly removing images from the larger class. Images were cropped square and resized to 60 x 60 pixels. Images were centered zero by subtracting the mean pixel value from all images."}, {"heading": "2.3 Training the Network", "text": "The network consisted of three sinuous layers, two fully connected layers and a Softmax layer. Training was performed using stochastic gradient descent with a pulse of 0.9, a batch size of 60, a learning rate of 0.005 and a weight drop of 0.001. Models were trained with MatConvNet [12] on a Tesla K80 GPU. See Figure 1 for a more detailed description of the network structure."}, {"heading": "2.4 Performance Measures", "text": "Two measurements were calculated: CNN's results are characterized by the probability of an image belonging to the positive or negative class, which was estimated at 50% and then compared with the actual binarization of the image (individually for each assignment); the fraction of the correct predictions was used to determine the accuracy; a linear support vector machine (SVM) was trained on the same data as the baseline and received corresponding accuracy measurements; and the individual human accuracy was calculated using an exit strategy over the given (binarized) dataset. Correlation values refer to standard correlation coefficients; they were calculated between CNN output probabilities and continuous human assessment from the dataset; again, the individual human correlation was calculated using a \"leave-one-out\" method over the (continuous) dataset for each assignment; while accuracy values show the accuracy of predictions, the respective correlations between the true and the variations within the data were determined."}, {"heading": "2.5 Statistics", "text": "CNN's performance was tested for its significance in two ways: whether it was significantly different from the random distribution, and secondly, from human performance. CNN's performance scores were consistent enough to be considered reasonably constant, which means that we assume that CNN's training produces exactly the same predictive results twice - no randomness is involved. Accordingly, the statistical tests only estimate the initial distributions or distributions of human performance. Once these distributions are available, CNN performance is identical to the quantity of the respective score. As we are interested in significant improvements, all tests are correct. In this study, the p value for a significant improvement will be lower than the alpha level of 5%. Accuracy measurement as defined above counts the percentage of correct binary predictions. The random baseline is the mean value of a corresponding number of independent coin flips."}, {"heading": "2.6 Visualizing Features Using Deconvolution", "text": "In this method, the target images were initially propagated forward through the network and the location with the maximum activation for all pools was stored. Activation of the target attribute was returned through deconvolution through the network. At each pooling layer, an approximate reversal to the pooling process was performed by mashing the image and placing the RGB pixel values at the location where the maximum activation was previously stored during the pooling process. Target activation is caused by positive and negative predictions from the previous layer, so deconvolution visualizes an image with positive and negative characteristics. To visualize separately features that contribute positively and negatively to an assignment forecast, we set the negative characteristics in the last layer to zero to visualize the positive characteristics and set the positive to zero to visualize the negative characteristics. This is possible because the final layer predisposition prior to the Softmax operator output sets the weighted sum of the previous layers to zero."}, {"heading": "3 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Performance of the CNN, Human and SVM Classifiers", "text": "CNN accuracy was higher than SVM accuracy in all cases. The average CNN accuracy across all attributions is 71.86% with a standard deviation of 0.080. For correlations, the mean is 0.511 and the standard deviation is 0.163. CNN accuracy and correlations between CNN predictions and human ratings are significantly better than chance for all attributions. Compared to human correlations, a significant improvement was observed in 14 attributions: attractive, caring, general, confident, selfish, emotional, friendly, happy, interesting, friendly, responsible, sociable and trustworthy."}, {"heading": "3.2 Visualization of CNN Features Involved in Attribution", "text": "Table 2 illustrates the CNN characteristics involved in the mapping. Here, we identify a number of prominent characteristics of the visualizations. As expected, the CNN characteristics for a happy mapping look very much like a smile. In contrast, the negative characteristics focus on the eyes and a downward-facing mouth. These two characteristics compete with each other to provide a prediction of happiness. Some of the mapping characteristics we visualize have already been studied and we find a general coherence between previous results and the CNN characteristics visualizations. The CNN characteristics that are important for gender discrimination focus on the eyes and lips. This is consistent with existing evidence that gender perception can be modulated by subtle changes in the color of the lips and eyes in a gender-neutral image. Todorov et al. show that there is a significant correlation between human facial features and perceived trustworthiness. These characteristics are mainly located in the center of the face, including the nasal bone."}, {"heading": "4 Discussion", "text": "This work shows that deep neural networks can be used to accurately predict personality traits from facial images that even exceed the performance of the human level in some cases. Coherence between attribution traits and the traits used by humans is interesting, but not unexpected. CNNs and humans use common structures in natural images to unfold their vision. Furthermore, one can see that all traits are important, while for others the positive and negative traits are important, while the human visual system is organized in a hierarchy of traits of increasing complexity."}, {"heading": "5 Acknowledgments", "text": "We would like to thank Wilma Bainbridge for the Human Faces 10k record and Umut Gu \ufffd c \ufffd for providing the deconfnet code."}], "references": [{"title": "Predicting political elections from rapid and unreflective face judgments", "author": ["Charles C Ballew", "Alexander Todorov"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Looking like a leader\u2013facial shape predicts perceived height and leadership ability", "author": ["Daniel E Re", "David W Hunter", "Vinet Coetzee", "Bernard P Tiddeman", "Dengke Xiao", "Lisa M DeBruine", "Benedict C Jones", "David I Perrett"], "venue": "PloS ONE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Modifying the memorability of face photographs", "author": ["Aditya Khosla", "Wilma A. Bainbridge", "Antonio Torralba", "Aude Oliva"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Unfakeable facial configurations affect strategic choices in trust games with or without information about past behavior", "author": ["Constantin Rezlescu", "Brad Duchaine", "Christopher Y Olivola", "Nick Chater"], "venue": "PloS ONE,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Perceived intelligence is associated with measured intelligence in men but not women", "author": ["Karel Kleisner", "Veronika Chv\u00e1talov\u00e1", "Jaroslav Flegr"], "venue": "PloS ONE,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D Zeiler", "Rob Fergus"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Understanding deep image representations by inverting them", "author": ["Aravindh Mahendran", "Andrea Vedaldi"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "author": ["Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1312.6034,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Anh Nguyen", "Jason Yosinski", "Jeff Clune"], "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "The intrinsic memorability of face photographs", "author": ["Wilma A Bainbridge", "Phillip Isola", "Aude Oliva"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Matconvnet \u2013 convolutional neural networks for matlab", "author": ["Andrea Vedaldi", "Karel Lenc"], "venue": "In Proceeding of the International Conference on Multimedia (ACM),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "A sex difference in facial contrast and its exaggeration by cosmetics", "author": ["Richard Russell"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Lip colour affects perceived sex typicality and attractiveness of human", "author": ["Ian D Stephen", "Angela M McKeegan"], "venue": "faces. Perception,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Evaluating face trustworthiness: a model based approach", "author": ["Alexander Todorov", "Sean G Baron", "Nikolaas N Oosterhof"], "venue": "Social Cognitive and Affective Neuroscience,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream", "author": ["Umut G\u00fc\u00e7l\u00fc", "Marcel AJ van Gerven"], "venue": "The Journal of Neuroscience,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Facial attributions for intelligence, attractiveness, dominance and trustworthiness have been shown to exhibit a strong effect on social decision making, with far reaching consequences from choosing between presidential candidates to jury decisions in criminal legal cases [1, 2].", "startOffset": 273, "endOffset": 279}, {"referenceID": 1, "context": "Facial attributions for intelligence, attractiveness, dominance and trustworthiness have been shown to exhibit a strong effect on social decision making, with far reaching consequences from choosing between presidential candidates to jury decisions in criminal legal cases [1, 2].", "startOffset": 273, "endOffset": 279}, {"referenceID": 2, "context": "Some of the best current methods require images hand-annotated with facial landmark features, which is time consuming [3].", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "Given the success of CNNs in image recognition tasks [4], the CNN model is a natural choice for visual attribution of psychological characteristics.", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "who introduced a method for characterising face images using key facial points, histogram information, SIFT features and hand annotated landmark facial features [3].", "startOffset": 161, "endOffset": 164}, {"referenceID": 4, "context": "showed that perceived trustworthiness is not significantly correlated with measured trustworthiness [5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 5, "context": "showed that perceived intelligence is associated with measured intelligence in men but not women [6].", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "These methods can broadly be divided into approaches that require a target image to be forward propagated through the network before the activity of a target feature detector can be projected back into image space [7, 8] and image free approaches that generate an image that maximises a class score [9, 10].", "startOffset": 214, "endOffset": 220}, {"referenceID": 7, "context": "These methods can broadly be divided into approaches that require a target image to be forward propagated through the network before the activity of a target feature detector can be projected back into image space [7, 8] and image free approaches that generate an image that maximises a class score [9, 10].", "startOffset": 214, "endOffset": 220}, {"referenceID": 8, "context": "These methods can broadly be divided into approaches that require a target image to be forward propagated through the network before the activity of a target feature detector can be projected back into image space [7, 8] and image free approaches that generate an image that maximises a class score [9, 10].", "startOffset": 299, "endOffset": 306}, {"referenceID": 9, "context": "These methods can broadly be divided into approaches that require a target image to be forward propagated through the network before the activity of a target feature detector can be projected back into image space [7, 8] and image free approaches that generate an image that maximises a class score [9, 10].", "startOffset": 299, "endOffset": 306}, {"referenceID": 6, "context": "To accomplish feature visualization we use the deconvnet proposed by Zeiler and Fergus [7].", "startOffset": 87, "endOffset": 90}, {"referenceID": 10, "context": "Our example set comprised the annotated subset of the 10K face database collected by Bainbridge et al [11].", "startOffset": 102, "endOffset": 106}, {"referenceID": 11, "context": "The models were trained using MatConvNet [12] on a Tesla K80 GPU.", "startOffset": 41, "endOffset": 45}, {"referenceID": 6, "context": "Attribution features were visualized using a deconvnet [7].", "startOffset": 55, "endOffset": 58}, {"referenceID": 12, "context": "This coheres with existing evidence that gender perception can be modulated by subtly changing the color of the lips and eyes in a gender neutral image [13, 14].", "startOffset": 152, "endOffset": 160}, {"referenceID": 13, "context": "This coheres with existing evidence that gender perception can be modulated by subtly changing the color of the lips and eyes in a gender neutral image [13, 14].", "startOffset": 152, "endOffset": 160}, {"referenceID": 14, "context": "A longer narrower nose indicated increased perceived trustworthiness In addition the shape of the cheekbones was found to be important [15].", "startOffset": 135, "endOffset": 139}, {"referenceID": 15, "context": "In addition, CNNs are loosely inspired by real neural structures and similar to CNNs there is strong evidence that the human visual system is organized in a hierarchy of feature detectors of increasing complexity [16].", "startOffset": 213, "endOffset": 217}], "year": 2017, "abstractText": "Judgements about personality based on facial appearance are strong effectors in social decision making and are known to impact on areas from presidential elections to jury decisions. Recent work has shown that it is possible to predict perception of memorability, trustworthiness, intelligence and other attributes in human face images. The most successful of these approaches requires face images expertly annotated with key facial landmarks. We demonstrate a Convolutional Neural Network (CNN) model that is able perform the same task without the need for landmark features thereby greatly increasing efficiency. The model has high accuracy, surpassing human level performance in some cases. Furthermore, we use a deconvolutional approach to visualize important features for perception of 22 attributes and show that these can be described as a composites of their positive and negative components by separately visualizing both.", "creator": "LaTeX with hyperref package"}}}