{"id": "1512.01409", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Dec-2015", "title": "What Makes it Difficult to Understand a Scientific Literature?", "abstract": "In the artificial intelligence area, one of the ultimate goals is to make computers understand human language and offer assistance. In order to achieve this ideal, researchers of computer science have put forward a lot of models and algorithms attempting at enabling the machine to analyze and process human natural language on different levels of semantics. Although recent progress in this field offers much hope, we still have to ask whether current research can provide assistance that people really desire in reading and comprehension. To this end, we conducted a reading comprehension test on two scientific papers which are written in different styles. We use the semantic link models to analyze the understanding obstacles that people will face in the process of reading and figure out what makes it difficult for human to understand a scientific literature. Through such analysis, we summarized some characteristics and problems which are reflected by people with different levels of knowledge on the comprehension of difficult science and technology literature, which can be modeled in semantic link network. We believe that these characteristics and problems will help us re-examine the existing machine models and are helpful in the designing of new one.", "histories": [["v1", "Fri, 4 Dec 2015 14:01:32 GMT  (412kb)", "http://arxiv.org/abs/1512.01409v1", "Accepted by SKG2015"]], "COMMENTS": "Accepted by SKG2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mengyun cao", "jiao tian", "dezhi cheng", "jin liu", "xiaoping sun"], "accepted": false, "id": "1512.01409"}, "pdf": {"name": "1512.01409.pdf", "metadata": {"source": "CRF", "title": "What Makes it Difficult to Understand a Scientific Literature?", "authors": ["Mengyun Cao", "Jiao Tian", "Dezhi Cheng", "Jin Liu", "Xiaoping Sun"], "emails": ["caomengyun@kg.ict.ac.cn", "tianjiao@kg.ict.ac.cn", "chengdezhi@kg.ict.ac.cn", "sunxiaoping@ict.ac.cn", "jinliu@whu.edu.cn", "Sun(sunxiaoping@ict.ac.cn)"], "sections": [{"heading": null, "text": "In fact, it is the case that most of them are able to move into another world, in which they are able to move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they, in which they are able to move, in which they, in which they, in which they are able to move, in which they are able"}, {"heading": "A. Example", "text": "A semantic network is a network consisting of entities and their relationships."}, {"heading": "B. Semantic link network based knowledge modelling", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "C. Reading and Comprehension modelling", "text": "Then we can use the above modeling tools to model a case of reading and understanding. We'll use an example in Fig. 2 to show how this work.In Fig. 2, an author A has a paper P that is read by a reader B. So, here A is used to represent the semantic link network knowledge of the author along with his thesis. We'll also use A (P) to represent the semantic link network derived from author A. And there's a semantic link networkA (P) and A (P1) is derived from P1 and not from P. So an extension is applied as A (P) (P) A (P1).The process can be modeled as follows: (1) A is built. (2) A (P1) is built (P1)."}, {"heading": "A. Experiment Processes", "text": "Our experiment is carried out over two days (at least 6 hours a day) without the young participants having to do much preparation work beforehand. On the first day, we handed over the electronic and printed version of P1 to all participants. Then, we had the participants read paragraph by paragraph without tools such as a dictionary and in the meantime noted down their questions and the core of each paragraph. Afterwards, D selected some questions to be answered. On the second day, we noted down all questions and answers from D. We did the same with P2. We removed repeated questions for the same paper in the same group. Finally, for P1, we collected a total of 90 questions from G1 and 26 from G2; for P2, 83 questions from G1 and 53 from G2. Finally, by analysing the available materials, we tried to classify all the questions and summarize some features in the comprehension processes and showed them in the following sections."}, {"heading": "B. Analysis and Classification", "text": "This year, it has come to the point that it has never been as far as this year."}, {"heading": "C. Semantic link network modelling", "text": "In Table II and III, we can see that the most important types of questions are related to knowledge inside and outside the paper. We can use the modeling method in Section II to describe these problems. Figure 3 shows what the knowledge outside the paper is and what the knowledge inside the paper is. Assuming that the paper contains a sentence S. \"A well-defined problem is a problem whose solution needs to be verified by a Turing Machine tester,\" be R reader and A author, then: 1) Semantic mapping to the nodes in this piece of knowledge. Type 1 questions can be modeled as w (R) = orw (R) w (A) for a word or phrase w (A). In Figure 3, for example, there are three semantic mappings that link the words and phrases of the sentence to the nodes in this piece of knowledge.2) Knowledge constructed inside the paper is a semantic paper network because the paper network within the paper (S) is constructed as the iP within the paper."}, {"heading": "3) Knowledge outside the paper and reader knowledge", "text": "There is a semantic linkage network A (w) by the author Aabout the word w = \"Turing Machine\" (Turing Machine), which can be described in detail in Fig.1. Here we use a shaded area in the left corner to represent such a network. Knowledge is outside the paper, because the sentences in the paper reader R can NOT be used to build such a piece of knowledge or a semantic linkage network to represent the model of the Turing machine that resembles A (w).Formally, we can define this problem in such a way that R (w) R (w) R (R) R (s) R (s) R (s) R (s) R (s) R (s) before reading, because A (w) A (w) A (P0) and P0 is another resource. R (w) R (w) R (w) R (s) R (s) R (s) R (s) R (s) R (s) R (s) R (s) is possible, then we have A (w) before the text A (w) w (P)."}, {"heading": "D. Characteristics and problems", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city and in which it is a country."}], "references": [{"title": "Word Segmentation for Chinese Novels", "author": ["Q. Likun", "Y. Zhang"], "venue": "Proceeding of 29 AAAI Conference on Artificial Intelligence", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Flors: Fast and simple domain adaptation for part-of-speech tagging.\" Transactions of the Association for Computational Linguistics", "author": ["S. Tobias", "H. Sch\u00fctze"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Improving readability through extractive summarization for learners with reading difficulties", "author": ["K. Nandhini", "S.R. Balasundaram"], "venue": "Egyptian Informatics, Journal, vol.14,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "The inversion of functions defined by Turing machines", "author": ["J. McCarthy"], "venue": "Automata studies, pp. 177-181", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1956}, {"title": "Teaching Machines to Read and Comprehend", "author": ["K.M. Hermann", "T. Ko\u010disk\u00fd", "E. Grefenstette", "L. Espeholt", "W. Kay", "M. Suleyman", "P. Blunsom"], "venue": "arXiv preprint arXiv:1506.03340", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "L", "author": ["R. Collobert", "J. Weston"], "venue": "Bottou, et al.. \u201dNatural language processing (almost) from scratch\u201d, The Journal of Machine Learning Research, vol. 12, pp. 2493-2537", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed representations of sentences and documents.", "author": ["Q.V. Le", "T. Mikolov"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "B", "author": ["K. Cho"], "venue": "van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, Y. Bengio. \"Learning phrase representations using RNN encoder-decoder for statistical machine translation\". arXiv preprint arXiv:1406.1078", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "The Knowledge Grid", "author": ["H. Zhuge"], "venue": "World Scientific Publishing Co., Singapore, 2004 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "A framework for semantic link discovery over relational data", "author": ["O. Hassanzadeh", "A. Kementsietsidis", "L. Lim", "R.J. Miller", "M.M. Wang"], "venue": "In Proceedings of the 18th ACM conference on Information and knowledge management", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": " N", "author": ["M. Palmer", "D. Gildea"], "venue": "Xue. \"Semantic role labeling\". Synthesis Lectures on Human Language Technologies, 3(1), 1-103", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Injecting Logical Background Knowledge into Embeddings for Relation Extraction", "author": ["T. Rockt\u00e4schel", "S. Singh", "S. Riedel"], "venue": "Proceedings of the 2015 Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Recursive neural networks can learn logical semantics", "author": ["S.R. Bowman", "C. Potts"], "venue": "ACL-IJCNLP 2015,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": " O", "author": ["T. Berners-Lee", "J. Hendler"], "venue": "Lassila. \"The semantic web\". Scientific American, 284(5), pp.28-37", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "Probabilistic topic models", "author": ["M. Steyvers", "T. Griffiths"], "venue": "Handbook of latent semantic analysis,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": " A", "author": ["J. Otero", "J. Lecentsn"], "venue": "C. Graesser, (Eds.). ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Communities and Emerging Semantics in Semantic Link Network: Discovery and Learning", "author": ["H. Zhuge"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol.21, no.6, pp. 785-799", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Interactive Semantics", "author": ["H. Zhuge"], "venue": "Artificial Intelligence, 174", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Semantic linking through spaces for cyber-physical-socio intelligence: A methodology", "author": ["H. Zhuge"], "venue": "Artificial Intelligence, 175", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "A proposal for the Dartmouth summer research project on artificial intelligence", "author": ["J. McCarthy", "M.L. Minsky", "N Rochester"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1955}], "referenceMentions": [{"referenceID": 19, "context": "The term Artificial Intelligence (AI) was coined by John McCarthy in 1955 [25] and gradually developed into a formal discipline.", "startOffset": 74, "endOffset": 78}, {"referenceID": 2, "context": "For example, the state-of-the-art results on automatic summarization are not quiet readable yet [6].", "startOffset": 96, "endOffset": 99}, {"referenceID": 14, "context": "Recently, statistics machine learning methods such as topic models [20] and deep neural network (NN) models [16][17][18] have achieved significant progress on many sub NLP tasks [20].", "startOffset": 67, "endOffset": 71}, {"referenceID": 10, "context": "Recently, statistics machine learning methods such as topic models [20] and deep neural network (NN) models [16][17][18] have achieved significant progress on many sub NLP tasks [20].", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "Recently, statistics machine learning methods such as topic models [20] and deep neural network (NN) models [16][17][18] have achieved significant progress on many sub NLP tasks [20].", "startOffset": 112, "endOffset": 116}, {"referenceID": 12, "context": "Recently, statistics machine learning methods such as topic models [20] and deep neural network (NN) models [16][17][18] have achieved significant progress on many sub NLP tasks [20].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "Recently, statistics machine learning methods such as topic models [20] and deep neural network (NN) models [16][17][18] have achieved significant progress on many sub NLP tasks [20].", "startOffset": 178, "endOffset": 182}, {"referenceID": 0, "context": "For example, the F1-score of word segmentation for Chinese novels can reach more than 90% by using a common noun entities mining method [4], a new model for PoS tagging can achieve more than 90% accuracy on different domains [5].", "startOffset": 136, "endOffset": 139}, {"referenceID": 1, "context": "For example, the F1-score of word segmentation for Chinese novels can reach more than 90% by using a common noun entities mining method [4], a new model for PoS tagging can achieve more than 90% accuracy on different domains [5].", "startOffset": 225, "endOffset": 228}, {"referenceID": 4, "context": "Teaching machine to read and comprehend is even possible [8].", "startOffset": 57, "endOffset": 60}, {"referenceID": 15, "context": "There are in fact already many psychological works on science text comprehension properties [21].", "startOffset": 92, "endOffset": 96}, {"referenceID": 8, "context": "To model this argument, we adopt a semantic link network model [14] to describe the semantics and knowledge in the text of a scientific paper.", "startOffset": 63, "endOffset": 67}, {"referenceID": 13, "context": "The constraints of semantic link network are not as strict as what has been coined in the Semantic Web languages [19], which gives", "startOffset": 113, "endOffset": 117}, {"referenceID": 3, "context": "This article was written by John McCarthy in 1956 [7].", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "This article introduces some deep NN and classical methods for answering Cloze form queries [8], and that may difficult to understand for people who have no contact with these methods.", "startOffset": 92, "endOffset": 95}, {"referenceID": 17, "context": "Guidance is an efficient way to increase the efficiency of understanding [23].", "startOffset": 73, "endOffset": 77}, {"referenceID": 9, "context": "That is, make machine be able to set up semantic link networks and then setting up mappings from texts to those semantic link networks automatically [15][22][24].", "startOffset": 149, "endOffset": 153}, {"referenceID": 16, "context": "That is, make machine be able to set up semantic link networks and then setting up mappings from texts to those semantic link networks automatically [15][22][24].", "startOffset": 153, "endOffset": 157}, {"referenceID": 18, "context": "That is, make machine be able to set up semantic link networks and then setting up mappings from texts to those semantic link networks automatically [15][22][24].", "startOffset": 157, "endOffset": 161}], "year": 2015, "abstractText": "* Abstract\u2014In the artificial intelligence area, one of the ultimate goals is to make computers understand human language and offer assistance. In order to achieve this ideal, researchers of computer science have put forward a lot of models and algorithms attempting at enabling the machine to analyze and process human natural language on different levels of semantics. Although recent progress in this field offers much hope, we still have to ask whether current research can provide assistance that people really desire in reading and comprehension. To this end, we conducted a reading comprehension test on two scientific papers which are written in different styles. We use the semantic link models to analyze the understanding obstacles that people will face in the process of reading and figure out what makes it difficult for human to understand a scientific literature. Through such analysis, we summarized some characteristics and problems which are reflected by people with different levels of knowledge on the comprehension of difficult science and technology literature, which can be modelled in semantic link network. We believe that these characteristics and problems will help us re-examine the existing machine models and are helpful in the designing of new one.", "creator": "Microsoft\u00ae Word 2010"}}}