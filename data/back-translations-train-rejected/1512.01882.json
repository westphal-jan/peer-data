{"id": "1512.01882", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Dec-2015", "title": "THCHS-30 : A Free Chinese Speech Corpus", "abstract": "Speech data is crucially important for speech recognition research. There are quite some speech databases that can be purchased at prices that are reasonable for most research institutes. However, for young people who just start research activities or those who just gain initial interest in this direction, the cost for data is still an annoying barrier. We support the `free data' movement in speech recognition: research institutes (particularly supported by public funds) publish their data freely so that new researchers can obtain sufficient data to kick of their career. In this paper, we follow this trend and release a free Chinese speech database THCHS-30 that can be used to build a full- edged Chinese speech recognition system. We report the baseline system established with this database, including the performance under highly noisy conditions.", "histories": [["v1", "Mon, 7 Dec 2015 02:07:21 GMT  (140kb,D)", "http://arxiv.org/abs/1512.01882v1", null], ["v2", "Thu, 10 Dec 2015 13:35:33 GMT  (142kb,D)", "http://arxiv.org/abs/1512.01882v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.SD", "authors": ["dong wang", "xuewei zhang"], "accepted": false, "id": "1512.01882"}, "pdf": {"name": "1512.01882.pdf", "metadata": {"source": "META", "title": "THCHS-30 : A Free Chinese Speech Corpus", "authors": ["Dong Wang", "Xuewei Zhang"], "emails": ["wangdong99@mails.tsinghua.edu.cn"], "sections": [{"heading": null, "text": "Speech data is critical to speech recognition research. There are a number of language databases that can be purchased at prices that are reasonable for most research institutes, but the cost of databases is still a tiresome barrier for young people who are just starting out with research, or those who are only just starting out in this direction. We support the movement of \"free data\" in speech recognition: research institutes (especially with public funding) release their data so that new researchers have enough data to launch their careers. In this paper, we follow this trend and publish a free Chinese language database THCHS-30 that can build a full-fledged Chinese speech recognition system. We report on the basic system established with this database, including performance under very loud conditions. Keywords: TCMSD database; THCHS-30; speech recognition; deep neural network."}, {"heading": "1 Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1 Speech recognition and data", "text": "Automatic Speech Recognition (ASR) has been an active field of research for several decades. Traditional ASR systems are based on the hidden Markov model (HMM) to represent the temporal dynamics of speech signals and the Gaussian mixing model (GMM) to represent distributions of signals within a stationary short period of time, which usually corresponds to a pronunciation unit, such as a telephone. This HMMGMM paradigm has dominated ASR research for almost three decades, until a few years ago when deep learning was introduced and a revolutionary success was achieved. Although several variants have been proposed, the most popular approach to deep learning for ASR is the so-called HMM-DNN hybrid architecture, in which the * correspondence between individual domains. tsinghua.edu.cn Center for Language and Language Technology, Research Institute of Information Technology, Tsinghua University, ROOM-303, BLDG FIT, Beijing Volume List, the list of available factors to China."}, {"heading": "1.2 Data is blocking research", "text": "There are, in fact, some language databases for ASR research, such as the TIMIT database [7], designed for small-scale telephone detection, the WSJ database [8], designed for large-scale continuous voice detection in broadcast messaging, the switchboard database [9], designed for large-scale detection of telephone conversions, and the AMI database [10], which consists of session recordings. These databases can be purchased from the institutes that compiled the data, but more generally from commercial organizations, including LDC [1] and ELRA [2]. For Chinese, the most popular database is the RAS 863 corpus [11], which includes continuous reading of speeches by more than 80 speakers, resulting in [1] https: / / www.ldc.upenn.edu / [2] http: / catalog.elra.info / ar Xiv: 100 commercial 152882v s.D are available for commercial hours."}, {"heading": "1.3 Free data movement", "text": "We advocate a movement of \"free data\" in the linguistic community. Data should not be private property when collected by public institutions such as universities and publicly funded research groups. As the collection and commentary is supported by public funds, the data should be free for people who pay for the fund, or even for broader people, if freedom will lead to more benefits for the people who originally paid for research. It is a shame that research projects supported by public funds use taxpayer money to build private resources. Moreover, even commercial companies should consider publishing free data, because freedom ultimately benefits the industrial sector: free data will trigger more research in this area and thus provide more opportunities for novel technological development and professional staff. Finally, the development of the Internet accumulates large amounts of voice data and the development of ASR technology allows cheaper annotations for this data. This makes the cost of data collection less expensive than before, and thus free data is more readily available."}, {"heading": "1.4 Our release", "text": "In order to respect the creed that \"public research should publish data\" and break the data monopoly to protect the initial interest of individual researchers in this field of research, the Center for Speech and Language Technologies (CSLT) at Tsinghua University recently released free databases. The first database we have published is THUYG-20, which is used to train Uighur language recognition systems. [12] This publication is published in collaboration with Xinjiang University and the Tsinghua AI Cloud Research Center (AICRC) [9]. In this paper, we continue the process of free expression. We publish a Chinese database that was recorded 15 years ago by the first author [13]. This database consists of 35 hours of recorded speech signals from 50 participants. Coupled with the language signals, we provide the full set of resources, including lexicon, LM and the educational recipe, so that new practitioners can use these resources to establish a more comprehensive Chinese language recognition system."}, {"heading": "2 Features of THCHS-30", "text": "In this section we describe the THCHS-30 Language Database. This database was created in 2000 - 2001 by [6] http: / / www.voxforge.org / [7] http: / / www.openslr.org / 12 / [8] http: / / www.nb.no / sbfil / talegjenkjenning / [9] http: / / data.cslt.org / thuyg20 / README.htmlthe first author when he was a master student, supervised by Prof. Xiaoyan Zhu [13]. The design goal was to provide a supplementary data source for the 863 database to maximize phone coverage. The new database was designated as TCMSD (Tsinghua Continuous Mandarin Speech Database) and has remained a private use since its creation. We publish the data 15 years later, with the permission of the license holder, Prof. Zhu. The database has been renamed THCHS-30, which we will publish \"the same THCHS Database,\" which stands for THG30 and will shortly be in this section."}, {"heading": "2.1 Speech signals", "text": "THCHS-30 comprises more than 30 hours of voice signals recorded by a single carbon microphone, under the condition of the silent office. Most participants are young colleagues and speak fluent Mandarin. The sampling rate of the recording is 16 000 Hz, and the sample size is 16 bit. The sentences (text input during recording) of THCHS30 were selected from a large amount of messages, with the aim of extending the 863 database by more telephone coverage. We selected 1000 sentences for recording. Table 1 reports on the coverage of two- and three-phone phones with / without THCHS-30 (reproduced from [13]). It is evident that THCHS-30 actually improves the phone coverage of the 863 databases.The recordings are divided into four groups according to the recording text: A (sentence number from 1 to 250), B (sentence number from 251 to 500), C (sentence number from 501 to 750), group 93 to sentence number A, and group A to 24C comprises the statements."}, {"heading": "2.2 Additional resources", "text": "To help build a practical Chinese ASR system, the THCHS-30 release includes some additional resources, including encyclopaedias, language models, training recipes and some useful tools. Additional noise data will also be provided."}, {"heading": "2.2.1 Lexicon and LM", "text": "We publish two language models and associated dictionaries: the word-based LM comprises 48k words and is based on word 3 grams, and the phone-based LM comprises 218 Chinese tone knob initials and is based on phone 3 grams. The word LM was trained on a text collection randomly selected from the Chinese gigaword corpus [10]. The training text comprises 772,000 sentences with 18 million words and 115 million Chinese characters. The phone LM was trained on a much smaller text collection with 2 million characters. The reason for using smaller text data for the phone LM training is that we want to keep linguistic information in the model as little as possible so that the resulting performance more directly reflects the quality of acoustic models. [14]"}, {"heading": "2.2.2 Scripts and recipe", "text": "The recipe and some auxiliary scripts are also published to train a complete Chinese ASR system with THCHS-30. The scripts are based on the framework of the Kaldi toolkit [15]. The training process is essentially similar to the wsj s5 GPU recipe provided by Kaldi, although some modifications have been made to make it suitable for Chinese ASR."}, {"heading": "2.2.3 Noise data", "text": "We are also interested in ASR tasks under noisy conditions and therefore provide a noisy version of THCHS-30: All training and test data have been corrupted (separately) by three types of noise: white noise, car noise and cafeteria noise. We focus on the 0 db condition, which means that the energy of the noise and the speech signals are equal (i.e. very loud).The embedding of the noise was done by a simple wave mixture in which the sound signals come from the public DEMAND noise memory [11]."}, {"heading": "2.3 Call for challenge", "text": "Since THCHS-30 is public and free, anyone can download it, build their systems and compare their results with others. To promote research, we call for a challenge based on the resources provided, including two tasks: major vocabulary recognition and phone recognition. Although the former is more practical, the latter can test acoustic modelling approaches in a more focused way. For each task, we also compete for performance in terms of 0 db noise with the three types of noise: white, car and cafeteria. [10] https: / / catalog.ldc.upenn.edu / LDC2003T09 [11] http: / / parole.loria.fr / DEMAND /"}, {"heading": "3 Baseline system", "text": "We describe our basic system built with THCHS-30 and report on the performance under various conditions that we have called for as a challenge. We treat these results as the basis for the competition; any improvement by any authors will be posted on the competition website [12]."}, {"heading": "3.1 Framework and setting", "text": "Figure 1: Architecture of the THCHS-30 base system. We use the Kaldi toolkit to train the hybrid acoustic models HMM-DNN. The architecture of the system is shown in Figure 1. Following this architecture, a monophonic GMM system was first trained with the standard 13-dimensional MFCCs plus the first and second order derivatives. The cepstral mean normalization (CMN) was used to reduce the channel effect. A three-voice GMM system was then constructed based on the monophonic system with features transformed by LDA and MLLT. The final GMM system was used to generate the state alignment for the subsequent DNN training. The DNN system was trained on the alignments provided by the GMM system. The features were 40-dimensional FBanks, and adjacent frames were reduced by a 200-frame DNN window on each side of the DNS (5)."}, {"heading": "3.2 Preliminary results", "text": "The performance of the DNN system, which is based on clean training data, is illustrated in Table 3, where the word ASR task is evaluated in terms of character error rate (CER) and the telephone ASR task in terms of telephone error rate (PER). Table 3 reports on the test results for both clean language and 0 db loud language. It is evident that performance is much lower with loud language than with clean language, especially when it comes to white noise. Note that CER and PER are rather low compared to those obtained with many standard databases (e.g. 863 databases), even with clean language. This is largely attributed to the \"anomaly\" of the test data: in order to achieve maximum phone coverage, the sentences selected for THCHS-30 are rather strange in both pronunciation and spelling, making the recognition task extremely challenging, and resolving the specificity may require some special techniques for making phones more aggressive."}, {"heading": "3.3 Noise cancellation with DAE", "text": "The significant deterioration in the performance of noise data can be addressed in several ways, for example, multiple state training [17] and noisy training [18, 19]. Although promising, these approaches require a retraining of the DNN model and are therefore not suitable for dealing with new noise types. It has been shown that this model is very powerful in learning processes and can be used to recover noise-corrupted input [20]."}, {"heading": "4 Conclusions", "text": "The aim of the paper is to publish a free 30-hour Chinese language database THCHS-30. Additional resources such as lexicographs, LMs and training recipes will also be published to help new researchers build their first ASR systems. We demonstrated the construction process and presented the basic results on both clean and loud data. As far as we know, this is the first free Chinese language database that can be used to build a practical Chinese ASR system. We hope that this publication will attract morepotential researchers into this promising field, especially young researchers whose initial interest would otherwise be negated by the high license fee of commercial databases."}, {"heading": "Acknowledgement", "text": "This research was supported by the National Science Foundation of China (NSFC) under Project No. 61371136, and the MESTDC PhD Foundation Project No. 20130002120011. It was also supported by Sinovoice and Huilan Ltd. References 1. Li Deng, Jinyu Li, Jui-Ting Huang, Kaisheng Yao, Dong Yu, Franksilk, Michael L. Seltzer, Geoff Zweig, Xiaodong He, Jason Williams, Yifan Gong, and Alex Acero, \"Recent advances in deep learning for speech research at microsoft,\" Acoustics, Speech and Signal Processing (ICASSP)."}], "references": [{"title": "Recent advances in deep learning for speech research at microsoft,", "author": ["Li Deng", "Jinyu Li", "Jui-Ting Huang", "Kaisheng Yao", "Dong Yu", "Frank Seide", "Michael L. Seltzer", "Geoff Zweig", "Xiaodong He", "Jason Williams", "Yifan Gong", "Alex Acero"], "venue": "Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "A historical perspective of speech recognition,", "author": ["Xuedong Huang", "James Baker", "Raj Reddy"], "venue": "Communications of the ACM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Automatic Speech Recognition A Deep Learning", "author": ["Dong Yu", "Li Deng"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "A fast learning method for multilayer perceptrons in automatic speech recognition systems,", "author": ["Chenghao Cai", "Yanyan Xu", "Dengfeng Ke", "Kaile Su"], "venue": "Journal of Robotics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Discriminative learning in sequential pattern recognition,", "author": ["Xiaodong He", "Li Deng", "Wu Chou"], "venue": "IEEE SIGNAL PROCESSING MAGAZINE,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "The design of wall street journal-based csr corpus,", "author": ["D. Paul", "J. Baker"], "venue": "Proceedings of the International Conference on Spoken Language Systems (ICSLP),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1992}, {"title": "Switchboard: telephone speech corpus for research and development,", "author": ["J.J. Godfrey", "E.C. Holliman", "J. McDaniel"], "venue": "in Acoustics, Speech, and Signal Processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1992}, {"title": "The ami system for the transcription of speech in meetings,", "author": ["Thomas Hain", "Vincent Wan", "Lukas Burget", "Martin Karafiat", "John Dines", "Jithendra Vepa", "Giulia Garau", "Mike Lincoln"], "venue": "in Acoustics, Speech and Signal Processing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Rasc863-a chinese speech corpus with four regional accents,", "author": ["Aijun Li", "Zhigang Yin", "Tianqing Wang", "Qiang Fang", "Fang Hu"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Thugy20: A free uyghur speech database,", "author": ["Askar Rouze", "Shi Yin", "Zhiyong Zhang", "Dong Wang", "Askar Humdulla", "Fang Zheng"], "venue": "NCMMSC", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "TCMSD: a new chinese continuous speech database,", "author": ["Dong Wang", "Dalei Wu", "Xiaoyan Zhu"], "venue": "in International Conference on Chinese Computing (ICCC\u201901),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}, {"title": "SRILM-an extensible language modeling toolkit,", "author": ["Andreas Stolcke"], "venue": "in ICSLP2002,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Sequence-discriminative training of deep neural networks,\u201d  Wang and Zhang  Page 6 of 6", "author": ["K. Vesely", "A. Ghosal", "L. Burget", "D. Povey"], "venue": "Proceedings of the 14th Annual Conference of the International Speech Communication Association,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Feature learning in deep neural networks - a study on speech recognition tasks,", "author": ["Dong Yu", "Michael L Seltzer", "Jinyu Li", "Jui-Ting Huang", "Frank Seide"], "venue": "in Proc. of International Conference on Learning Representations,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Noisy training for deep neural networks,", "author": ["Xiangtao Meng", "Chao Liu", "Zhiyong Zhang", "Dong Wang"], "venue": "in Proc. of ChinaSIP 2014,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Noisy training for deep neural networks in speech recognition,", "author": ["Shi Yin", "Chao Liu", "Zhiyong Zhang", "Yiye Lin", "Dong Wang", "Javier Tejedor", "Thomas Fang Zheng", "Yinguo Li"], "venue": "EURASIP Journal on Audio, Speech, and Music Processing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Extracting and composing robust features with denoising autoencoders,", "author": ["Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "Proceedings of the 25th international conference on Machine learning", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Recurrent neural networks for noise reduction in robust asr.,", "author": ["Andrew L Maas", "Quoc V Le", "Tyler M O\u2019Neil", "Oriol Vinyals", "Patrick Nguyen", "Andrew Y Ng"], "venue": "in INTERSPEECH. Citeseer,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Reverberant speech recognition based on denoising autoencoder.,", "author": ["Takaaki Ishii", "Hiroki Komiyama", "Takahiro Shinozaki", "Yasuo Horiuchi", "Shingo Kuroiwa"], "venue": "INTERSPEECH,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Music removal by denoising autoencoder in speech recognition,", "author": ["Mengyuan Zhao", "Dong Wang", "Zhiyong Zhang", "Xuewei Zhang"], "venue": "in APSIPA2015,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Readers can refer to [1, 2, 3, 4, 5, 6] for details about DNNbased ASR methods.", "startOffset": 21, "endOffset": 39}, {"referenceID": 1, "context": "Readers can refer to [1, 2, 3, 4, 5, 6] for details about DNNbased ASR methods.", "startOffset": 21, "endOffset": 39}, {"referenceID": 2, "context": "Readers can refer to [1, 2, 3, 4, 5, 6] for details about DNNbased ASR methods.", "startOffset": 21, "endOffset": 39}, {"referenceID": 3, "context": "Readers can refer to [1, 2, 3, 4, 5, 6] for details about DNNbased ASR methods.", "startOffset": 21, "endOffset": 39}, {"referenceID": 4, "context": "Readers can refer to [1, 2, 3, 4, 5, 6] for details about DNNbased ASR methods.", "startOffset": 21, "endOffset": 39}, {"referenceID": 5, "context": ", the TIMIT database [7] that was designed for small-scale phone recognition, the WSJ database [8] that was designed for large-scale continuous speech recognition on the domain of broadcast news, the Switchboard database [9] that was designed for large-scale recognition for telephone conversions, and the AMI database [10] that consists of meeting recordings.", "startOffset": 95, "endOffset": 98}, {"referenceID": 6, "context": ", the TIMIT database [7] that was designed for small-scale phone recognition, the WSJ database [8] that was designed for large-scale continuous speech recognition on the domain of broadcast news, the Switchboard database [9] that was designed for large-scale recognition for telephone conversions, and the AMI database [10] that consists of meeting recordings.", "startOffset": 221, "endOffset": 224}, {"referenceID": 7, "context": ", the TIMIT database [7] that was designed for small-scale phone recognition, the WSJ database [8] that was designed for large-scale continuous speech recognition on the domain of broadcast news, the Switchboard database [9] that was designed for large-scale recognition for telephone conversions, and the AMI database [10] that consists of meeting recordings.", "startOffset": 319, "endOffset": 323}, {"referenceID": 8, "context": "For Chinese, the most popular database is the RAS 863 corpus [11], which involves continuous reading speech of more than 80 speakers, resulting in", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "The first database we published is THUYG-20, which is used for training Uyghur speech recognition systems [12].", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "We publish a Chinese database that was recorded by the first author 15 years ago [13].", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "Xiaoyan Zhu [13].", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "Table 1 reports the bi-phone and tri-phone coverage with/without THCHS-30 (reproduced from [13]).", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "The two LMs were trained with the SRILM tool [14].", "startOffset": 45, "endOffset": 49}, {"referenceID": 12, "context": "The final GMM system was used to generate state alignment for the subsequent DNN training [16].", "startOffset": 90, "endOffset": 94}, {"referenceID": 13, "context": "3 Noise cancellation with DAE The significant performance degradation on noisy data can be addressed in multiple ways, for example, multiple condition training [17] and noisy training [18, 19].", "startOffset": 160, "endOffset": 164}, {"referenceID": 14, "context": "3 Noise cancellation with DAE The significant performance degradation on noisy data can be addressed in multiple ways, for example, multiple condition training [17] and noisy training [18, 19].", "startOffset": 184, "endOffset": 192}, {"referenceID": 15, "context": "3 Noise cancellation with DAE The significant performance degradation on noisy data can be addressed in multiple ways, for example, multiple condition training [17] and noisy training [18, 19].", "startOffset": 184, "endOffset": 192}, {"referenceID": 16, "context": "It has been shown that this model is very powerful in learning lowdimensional representations and can be used to recover noise-corrupted input [20].", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "In [21], DAE is extended to a deep recurrent structure and has been employed to recover clean speech in noisy conditions for ASR.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "A recent study employs DAE in de-reverberation [22], and", "startOffset": 47, "endOffset": 51}, {"referenceID": 19, "context": "our work also showed that it can be used for removing music corruption [23].", "startOffset": 71, "endOffset": 75}, {"referenceID": 15, "context": "The noisy data generation process follows a scheme similar to the one in [19], where a particular SNR is sampled for each clean utterance, following a Gaussian distribution whose mean is 0 db.", "startOffset": 73, "endOffset": 77}], "year": 2017, "abstractText": "Speech data is crucially important for speech recognition research. There are quite some speech databases that can be purchased at prices that are reasonable for most research institutes. However, for young people who just start research activities or those who just gain initial interest in this direction, the cost for data is still an annoying barrier. We support the \u2018free data\u2019 movement in speech recognition: research institutes (particularly supported by public funds) publish their data freely so that new researchers can obtain sufficient data to kick off their career. In this paper, we follow this trend and release a free Chinese speech database THCHS-30 that can be used to build a full-fledged Chinese speech recognition system. We report the baseline system established with this database, including the performance under highly noisy conditions.", "creator": "LaTeX with hyperref package"}}}