{"id": "1512.02560", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2015", "title": "Deep Learning for Single and Multi-Session i-Vector Speaker Recognition", "abstract": "The promising performance of Deep Learning (DL) in speech recognition has motivated the use of DL in other speech technology applications such as speaker recognition. Given i-vectors as inputs, the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on Deep Belief Networks (DBN) and Deep Neural Networks (DNN) to discriminatively model each target speaker. In order to have more insight into the behavior of DL techniques in both single and multi-session speaker enrollment tasks, some experiments have been carried out in this paper in both scenarios. Additionally, the parameters of the global model, referred to as universal DBN (UDBN), are normalized before adaptation. UDBN normalization facilitates training DNNs specifically with more than one hidden layer. Experiments are performed on the NIST SRE 2006 corpus. It is shown that the proposed impostor selection algorithm and UDBN adaptation process enhance the performance of conventional DNNs 8-20 % and 16-20 % in terms of EER for the single and multi-session tasks, respectively. In both scenarios, the proposed architectures outperform the baseline systems obtaining up to 17 % reduction in EER.", "histories": [["v1", "Tue, 8 Dec 2015 17:34:49 GMT  (1125kb,D)", "http://arxiv.org/abs/1512.02560v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["omid ghahabi", "javier hernando"], "accepted": false, "id": "1512.02560"}, "pdf": {"name": "1512.02560.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for Single and Multi-Session i-Vector Speaker Recognition", "authors": ["Omid Ghahabi", "Javier Hernando"], "emails": ["omid.ghahabi@upc.edu;", "javier.hernando@upc.edu)."], "sections": [{"heading": null, "text": "This is not the first time that this type of learning has become state-of-the-art in text-independent speaker recognition, thus increasing the overall performance of the system. On the other hand, the success of deep learning techniques in speech processing, particularly in speech recognition, is being driven forward. [8], has inspired the community to classify these techniques in loudspeaker recognition. Three most commonly used techniques are restricted Boltzmann machines (RBM), and Deep Neural Networks (DNN)."}, {"heading": "II. DEEP LEARNING", "text": "In fact, it is so that most of them are able to survive themselves. (...) It is not so that they are able to survive themselves. (...) It is so that they are able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) (...) () (...) () (...) () () (...) () () () (...) () () () () (...) () () ()) () () () ()) () () ()) () () () () ()) () () () ()) () () () () () () () () () () () ()) () () () () () ()) () () ()) () () ()) () () ()) ()) () ()) () () () () ()) () ()) () () ()) () () ()) () () () ()) () ()) () () ()) () () () () () () ()) () () ()) () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () ("}, {"heading": "III. DEEP LEARNING FOR I-VECTORS", "text": "The success of the i-vector approach in speech recognition and DL techniques in speech processing applications encourages the research community to combine these techniques for speech recognition. [17] - [19], [21], [22], [24], [43], [11], [17] - [19], [19]. In order to gain more insight into the behavior of DL techniques on i-vectors, the authors extend the preliminary study developed in [17], [18]. An i-vector [1] is a low vector, typically between 400 and 600, representing speech expression."}, {"heading": "IV. BALANCED TRAINING", "text": "The problem is, however, that the amount of positive and negative data in this case is highly unbalanced, resulting in a bias towards the majority class. Some of the simplest ways to deal with unbalanced data problems are examined in [45] - [47] - [49] -. One of the simplest commonly used methods is data collection. Majority class data is corroborated and, on the contrary, minority class data is overamplified. The effectiveness of these techniques depends to a large extent on the data structure. In the proposed approach in Fig. 3, the amount of stackers is reduced in two steps, namely selection and clustering. On the other hand, the amount of target samples is increased either by replication or combination. Afterwards, balanced target and imitation samples are evenly distributed among the minibatches.Impostor selection and clusteringThe aim is to reduce the large number of negative samples."}, {"heading": "B. Target Replication or Combination", "text": "In order to balance positive and negative samples, the number of target samples is increased by as many as the number of stacker centroids obtained in Section IV-A. Replica target i vectors do not have the exact same effect in the DNN preparation process due to the sampling noise generated in RBM training. [42] In addition, in replicated versions, both in adaptation and in monitored learning stages, the target and stacker classes are equally weighted when updating network parameters. In multi-session tasks, the available i-vectors of each target speaker can be combined, i.e. the average of all n i vectors is considered a new target i-vector. Once the number of positive and negative samples is balanced, they are evenly distributed among the individual minibatches. In other words, each mailing contains the number of target batches but not the same number of minibatches."}, {"heading": "V. UNIVERSAL DBN AND ADAPTATION", "text": "This year, the number of people who have chosen such a project has doubled, many times more than those who have chosen such a project."}, {"heading": "VI. EXPERIMENTAL RESULTS", "text": "The block diagram of Fig. 3 has been implemented for both single and multi-session verification tasks. The effectiveness of two main contributions suggested in the figure is shown in this section."}, {"heading": "A. Baseline and Dataset", "text": "All experiments in this paper are conducted on the NIST SRE 2006 evaluation [31]. In both training and test phases signals have about two minutes of total speech duration. The entire core condition was used for the single-session task, in which there are 816 target models and 51,068 studies. On the other hand, there are 8 talking pages per target speaker in the multi-session task and the protocol contains 699 target models and 31,080 studies. NIST SRE 2004 and 2005 are used as background data. It is worth noting that in the case of NIST 2005 only the speech signals of speakers who do not appear in NIST SRE 2006 are used. Frequency Filtering (FF) features are used in the experiments. FFs, such as MFCCs, are a decorrelated version of Log Filter Bank Energies (FBE)."}, {"heading": "B. Single-Session Experiments", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "C. Multi-Session Experiments", "text": "The same configuration for each session task is also applied for the multi-session one. The number of minibatches is set to 3. In each minibatch, all 8 target i-vectors associated with 8 cheat cluster centrifuges are set as if the size of each minibatch and the total number of immigrants were 16 and 24. Since the combination of i-vectors of each target does not help the training of the networks, we replicate the target i-vectors in each minibatch as shown in the figure. We start with the training of the networks with the same parameters tuned for each session experiment."}, {"heading": "VII. CONCLUSION", "text": "In this work, a hybrid system based on Deep Belief Networks (DBN) and Deep Neural Networks (DNN) was proposed to model target speakers with available i-vectors in a discriminatory manner. To gain a better understanding of the behavior of these techniques for both single and multiple speaker login tasks, the experiments were conducted in both scenarios. Two main contributions were proposed to make DNNs more efficient in this particular task. First, the most informative stackers were selected and grouped into clusters to ensure a balanced training. Second, each DNN was initialized with the specific loudspeaker parameters, which were adapted to a global model called Universal DBN (UDBN). The parameters of the UDBN were normalized prior to the adaptation, facilitating the training of DNNs specifically with more than one hidden layer. Experiments are performed on the NIST RE Scenario 2006-Scenario%, and both were shown to work in both of the proposed corpus 17."}], "references": [{"title": "Front-end factor analysis for speaker verification", "author": ["N. Dehak", "P. Kenny", "R. Dehak", "P. Dumouchel", "P. Ouellet"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 4, pp. 788\u2013798, May 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic linear discriminant analysis for inferences about identity", "author": ["S.J.D. Prince", "J.H. Elder"], "venue": "IEEE 11th International Conference on Computer Vision, 2007. ICCV 2007, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Bayesian speaker verification with heavy tailed priors", "author": ["P. Kenny"], "venue": "Speaker and Language Recognition Workshop (IEEE Odyssey), 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Investigation of full-sequence training of deep belief networks for speech recognition", "author": ["A. Mohamed", "D. Yu", "L. Deng"], "venue": "Proc. Interspeech, 2010, p. 28462849.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Context-dependent pretrained deep neural networks for large-vocabulary speech recognition", "author": ["G.E. Dahl", "D. Yu", "L. Deng", "A. Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, Jan. 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Acoustic modeling using deep belief networks", "author": ["A. Mohamed", "G.E. Dahl", "G. Hinton"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 14\u201322, Jan. 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for acoustic modeling in speech recognition", "author": ["G. Hinton", "L. Deng", "D. Yu", "G. Dahl", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath"], "venue": "IEEE Signal Processing Magazine, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Context Dependent Phone Models For LSTM RNN Acoustic Modelling", "author": ["A. Senior", "H. Sak", "I. Shafran"], "venue": "Proc. ICASSP, 2015, pp. 4585\u20134589.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Preliminary investigation of boltzmann machine classifiers for speaker recognition", "author": ["T. Stafylakis", "P. Kenny", "M. Senoussaoui", "P. Dumouchel"], "venue": "Proc. Odyssey, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "First attempt of boltzmann machines for speaker verification", "author": ["M. Senoussaoui", "N. Dehak", "P. Kenny", "R. Dehak", "P. Dumouchel"], "venue": "Proc. Odyssey, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "PLDA using gaussian restricted boltzmann machines with application to speaker verification", "author": ["T. Stafylakis", "P. Kenny", "M. Senoussaoui", "P. Dumouchel"], "venue": "Proc. Interspeech, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Speaker recognition by means of deep belief networks", "author": ["V. Vasilakakis", "S. Cumani", "P. Laface"], "venue": "Biometric Technologies in Forensic Science, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "STC speaker recognition system for the NIST i-vector challenge", "author": ["S. Novoselov", "T. Pekhovsky", "K. Simonchik"], "venue": "Odyssey: The Speaker and Language Recognition Workshop, 2014, pp. 231\u2013240.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Restricted boltzmann machine supervectors for speaker recognition", "author": ["O. Ghahabi", "J. Hernando"], "venue": "Proc. ICASSP, 2015, pp. 4804\u20134808.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised feature learning for audio classification using convolutional deep belief networks", "author": ["H. Lee", "Y. Largman", "P. Pham", "A. Ng"], "venue": "Advances in neural information processing systems, vol. 22, pp. 10961104, 2009.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Feature classification by means of deep belief networks for speaker recognition", "author": ["P. Safari", "O. Ghahabi", "J. Hernando"], "venue": "Proc. EUSIPCO, 2015, pp. 2162\u20132166.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep belief networks for i-vector based speaker recognition", "author": ["O. Ghahabi", "J. Hernando"], "venue": "Proc. ICASSP, May 2014, pp. 1700\u20131704.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "i-vector modeling with deep belief networks for multi-session speaker recognition", "author": ["O. Ghahabi", "J. Hernando"], "venue": "Proc. Odyssey, 2014, pp. 305\u2013310.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Global impostor selection for DBNs in multi-session i-vector speaker recognition", "author": ["O. Ghahabi", "J. Hernando"], "venue": "Advances in Speech and Language Technologies for Iberian Languages, Lecture Notes in Artificial Intelligence. Springer International Publishing, Nov. 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Using deep belief networks for vector-based speaker recognition", "author": ["W.M. Campbell"], "venue": "Proc. Interspeech, 2014, pp. 676\u2013680.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "A novel scheme for speaker recognition using a phonetically-aware deep neural network", "author": ["Y. Lei", "N. Scheffer", "L. Ferre", "M. Mclaren"], "venue": "Proc. ICASSP, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep neural networks for extracting baum-welch statistics for speaker recognition", "author": ["P. Kenny", "V. Gupta", "T. Stafylakis", "P. Ouellet", "J. Alam"], "venue": "Proc. Odyssey, 2014, pp. 293\u2013298.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Improving speaker recognition performance in the domain adaptation challenge using deep neural networks", "author": ["D. Garcia-Romero", "Xiaohui Zhang", "A. McCree", "D. Povey"], "venue": "2014 IEEE Spoken Language Technology Workshop (SLT), Dec. 2014, pp. 378\u2013383.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Advances In Deep Neural Network Approaches To Speaker Recognition", "author": ["M. Mclaren", "Y. Lei", "L. Ferre"], "venue": "Proc. ICASSP, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Neural Network Approaches to Speaker and Language Recognition", "author": ["F. Richardson", "D. Reynolds", "N. Dehak"], "venue": "IEEE Signal Processing Letters, vol. 22, no. 10, pp. 1671\u20131675, Oct. 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep neural networks for small footprint text-dependent speaker verification", "author": ["E. Variani", "Xin Lei", "E. McDermott", "I. Lopez Moreno", "J. Gonzalez- Dominguez"], "venue": "2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2014, pp. 4052\u20134056.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep feature for text-dependent speaker verification", "author": ["Yuan Liu", "Yanmin Qian", "Nanxin Chen", "Tianfan Fu", "Ya Zhang", "Kai Yu"], "venue": "Speech Communication, vol. 73, pp. 1\u201313, Oct. 2015.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Hierarchical speaker clustering methods for the nist i-vector challenge", "author": ["E. Khoury", "L. El Shafey", "M. Ferras", "S. Marcel"], "venue": "Odyssey: The Speaker and Language Recognition Workshop, 2014, pp. 254\u2013259.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R. Salakhutdinov"], "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, July 2006.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y-W. Teh"], "venue": "Neural Computation, vol. 18, no. 7, pp. 1527\u20131554, May 2006.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}, {"title": "Modeling spectral envelopes using restricted boltzmann machines and deep belief networks for statistical parametric speech synthesis", "author": ["Z-H. Ling", "L. Deng", "D. Yu"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 21, no. 10, pp. 2129\u20132139, 2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep belief networks based voice activity detection", "author": ["X-L. Zhang", "J. Wu"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 21, no. 4, pp. 697\u2013710, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep Convolutional Neural Networks for Large-scale Speech Tasks", "author": ["Tara N. Sainath", "Brian Kingsbury", "George Saon", "Hagen Soltau", "Abdelrahman Mohamed", "George Dahl", "Bhuvana Ramabhadran"], "venue": "Neural Networks, vol. 64, pp. 39\u201348, Apr. 2015.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Learning for Acoustic Modeling in Parametric Speech Generation: A systematic review of existing techniques and future trends", "author": ["Zhen-Hua Ling", "Shi-Yin Kang", "Heiga Zen", "A. Senior", "M. Schuster", "Xiao- Jun Qian", "H.M. Meng", "Li Deng"], "venue": "IEEE Signal Processing Magazine, vol. 32, no. 3, pp. 35\u201352, May 2015.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Exploring Strategies for Training Deep Neural Networks", "author": ["H. Larochelle", "Y. Bengio", "J. Louradour", "P. Lamblin"], "venue": "Journal of Machine Learning Research, vol. 10, pp. 1\u201340, June 2009.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "The Difficulty of Training Deep Architectures and the Effect of Unsupervised Pre-Training", "author": ["E. Dumitru", "P. Manzagol", "Y. Bengio", "S. Bengio", "P. Vincent"], "venue": "The Twelfth International Conference on Artificial Intelligence and Statistics (AIST ATS09), pp. 153\u2013160.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 0}, {"title": "Why Does Unsupervised Pre-training Help Deep Learning", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P. Manzagol", "P. Vincent", "S. Bengio"], "venue": "J. Mach. Learn. Res., vol. 11, pp. 625\u2013660, Mar. 2010.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "A practical guide to training restricted boltzmann machines", "author": ["G.E. Hinton"], "venue": "Neural Networks: Tricks of the Trade, number 7700 in Lecture Notes in Computer Science, pp. 599\u2013619. Springer Berlin Heidelberg, Jan. 2012.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "A Unified Deep Neural Network for Speaker and Language Recognition", "author": ["R. Fred", "R. Douglas", "N. Dehak"], "venue": "arXiv:1504.00923 [cs, stat], 2015, arXiv: 1504.00923.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2015}, {"title": "A study of interspeaker variability in speaker verification", "author": ["P. Kenny", "P. Ouellet", "N. Dehak", "V. Gupta", "P. Dumouchel"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 16, no. 5, pp. 980\u2013988, July 2008.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning from imbalanced data", "author": ["H. He", "E.A. Garcia"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 21, no. 9, pp. 1263\u20131284, Sept. 2009.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}, {"title": "Cost-sensitive learning methods for imbalanced data", "author": ["N. Thai-Nghe", "Z. Gantner", "L. Schmidt-Thieme"], "venue": "The 2010 International Joint Conference on Neural Networks (IJCNN), July 2010, pp. 1\u20138.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2010}, {"title": "Supervised neural network modeling: An empirical investigation into learning from imbalanced data with labeling errors", "author": ["T.M. Khoshgoftaar", "J. Van Hulse", "A. Napolitano"], "venue": "IEEE Transactions on Neural Networks, vol. 21, no. 5, pp. 813\u2013830, May 2010.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics", "author": ["V. Lpez", "A. Fernndez", "S. Garca", "V. Palade", "F. Herrera"], "venue": "Information Sciences, vol. 250, pp. 113\u2013141, Nov. 2013.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "MWMOTE-majority weighted minority oversampling technique for imbalanced data set learning", "author": ["S. Barua", "M.M. Islam", "Xin Yao", "K. Murase"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 26, no. 2, pp. 405\u2013425, Feb. 2014.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2014}, {"title": "Data-driven background dataset selection for SVM-based speaker verification", "author": ["M. McLaren", "R. Vogt", "B. Baker", "S. Sridharan"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 18, no. 6, pp. 1496\u20131506, Aug. 2010.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2010}, {"title": "Time and frequency filtering of filter-bank energies for robust HMM speech recognition", "author": ["C. Nadeu", "D. Macho", "J. Hernando"], "venue": "Speech Communication, vol. 34, no. 12, pp. 93\u2013114, Apr. 2001.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "THE recent compact representation of speech utterances known as i-vector [1] has become the state-of-the-art in the text-independent speaker recognition.", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "Given speaker labels for the background data, there are also some post-processing techniques such as Probabilistic Linear Discriminant Analysis (PLDA) [2], [3] to compensate speaker and session variabilities and, therefore, to increase the overall performance of the system.", "startOffset": 151, "endOffset": 154}, {"referenceID": 2, "context": "Given speaker labels for the background data, there are also some post-processing techniques such as Probabilistic Linear Discriminant Analysis (PLDA) [2], [3] to compensate speaker and session variabilities and, therefore, to increase the overall performance of the system.", "startOffset": 156, "endOffset": 159}, {"referenceID": 3, "context": ", [4]\u2013[8]), has inspired the community to make use of those techniques in speaker recognition as well.", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": ", [4]\u2013[8]), has inspired the community to make use of those techniques in speaker recognition as well.", "startOffset": 6, "endOffset": 9}, {"referenceID": 8, "context": "Different combinations of RBMs have been used in [9], [10] to classify i-vectors and in [11] to learn speaker and channel factor subspaces in a PLDA simulation.", "startOffset": 49, "endOffset": 52}, {"referenceID": 9, "context": "Different combinations of RBMs have been used in [9], [10] to classify i-vectors and in [11] to learn speaker and channel factor subspaces in a PLDA simulation.", "startOffset": 54, "endOffset": 58}, {"referenceID": 10, "context": "Different combinations of RBMs have been used in [9], [10] to classify i-vectors and in [11] to learn speaker and channel factor subspaces in a PLDA simulation.", "startOffset": 88, "endOffset": 92}, {"referenceID": 11, "context": "RBMs and DBNs have been used to extract a compact representation of speech signals from acoustic features [12] and i-vectors [13].", "startOffset": 106, "endOffset": 110}, {"referenceID": 12, "context": "RBMs and DBNs have been used to extract a compact representation of speech signals from acoustic features [12] and i-vectors [13].", "startOffset": 125, "endOffset": 129}, {"referenceID": 13, "context": "in [14] as a non-linear transformation and dimension reduction stage for GMM supervectors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "DBNs have been used in [15] as unsupervised feature extractors and in [16] as speaker feature classifiers.", "startOffset": 23, "endOffset": 27}, {"referenceID": 15, "context": "DBNs have been used in [15] as unsupervised feature extractors and in [16] as speaker feature classifiers.", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "Furthermore, in [17]\u2013[19] they have been integrated in an adaptation process to provide a better initialization for DNNs.", "startOffset": 16, "endOffset": 20}, {"referenceID": 18, "context": "Furthermore, in [17]\u2013[19] they have been integrated in an adaptation process to provide a better initialization for DNNs.", "startOffset": 21, "endOffset": 25}, {"referenceID": 19, "context": "DNNs have been utilized to extract Baum-Welch statistics for supervector and i-vector extraction [20]\u2013[23].", "startOffset": 97, "endOffset": 101}, {"referenceID": 22, "context": "DNNs have been utilized to extract Baum-Welch statistics for supervector and i-vector extraction [20]\u2013[23].", "startOffset": 102, "endOffset": 106}, {"referenceID": 23, "context": "DNN bottleneck features are recently employed in the i-vector framework [24], [25].", "startOffset": 72, "endOffset": 76}, {"referenceID": 24, "context": "DNN bottleneck features are recently employed in the i-vector framework [24], [25].", "startOffset": 78, "endOffset": 82}, {"referenceID": 25, "context": "Additionally, different types of i-vectors represented by DNN architectures are proposed in [26], [27].", "startOffset": 92, "endOffset": 96}, {"referenceID": 26, "context": "Additionally, different types of i-vectors represented by DNN architectures are proposed in [26], [27].", "startOffset": 98, "endOffset": 102}, {"referenceID": 16, "context": "The main attention of the National Institute of Standard and Technology (NIST) over the last two years to combine i-vectors with new machine learning techniques [28], [29] encouraged the authors to extend the prior works developed in [17], [18].", "startOffset": 234, "endOffset": 238}, {"referenceID": 17, "context": "The main attention of the National Institute of Standard and Technology (NIST) over the last two years to combine i-vectors with new machine learning techniques [28], [29] encouraged the authors to extend the prior works developed in [17], [18].", "startOffset": 240, "endOffset": 244}, {"referenceID": 16, "context": "The top layer pre-training proposed in [17] is not used in this work.", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": ", [13], [30]) is employed.", "startOffset": 2, "endOffset": 6}, {"referenceID": 27, "context": ", [13], [30]) is employed.", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "Since 2006 [32], [33], DL has become a new area of research in many applications of machine learning and signal processing.", "startOffset": 11, "endOffset": 15}, {"referenceID": 29, "context": "Since 2006 [32], [33], DL has become a new area of research in many applications of machine learning and signal processing.", "startOffset": 17, "endOffset": 21}, {"referenceID": 6, "context": ", [7], [8], [34]\u2013[36]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": ", [7], [8], [34]\u2013[36]).", "startOffset": 7, "endOffset": 10}, {"referenceID": 30, "context": ", [7], [8], [34]\u2013[36]).", "startOffset": 12, "endOffset": 16}, {"referenceID": 32, "context": ", [7], [8], [34]\u2013[36]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 33, "context": "For classification tasks, cross entropy is often used as the loss function and the softmax is commonly used as the activation function at the output layer [37].", "startOffset": 155, "endOffset": 159}, {"referenceID": 34, "context": "Recently, it has been shown that there are more efficient techniques for parameter initialization [38]\u2013[40].", "startOffset": 98, "endOffset": 102}, {"referenceID": 36, "context": "Recently, it has been shown that there are more efficient techniques for parameter initialization [38]\u2013[40].", "startOffset": 103, "endOffset": 107}, {"referenceID": 4, "context": "One of those techniques consists in initializing DNN with DBN parameters, which it is often referred to as unsupervised pre-training or just hybrid DBNDNN [5], [41].", "startOffset": 155, "endOffset": 158}, {"referenceID": 34, "context": "It has empirically been shown that this pretraining stage can set the weights of the network closer to an optimum solution than random initialization [38]\u2013[40].", "startOffset": 150, "endOffset": 154}, {"referenceID": 36, "context": "It has empirically been shown that this pretraining stage can set the weights of the network closer to an optimum solution than random initialization [38]\u2013[40].", "startOffset": 155, "endOffset": 159}, {"referenceID": 29, "context": "There is an efficient greedy layer wised algorithm to train DBN parameters [33].", "startOffset": 75, "endOffset": 79}, {"referenceID": 4, "context": "RBM training is based on maximum likelihood criterion using the stochastic gradient descent algorithm [5], [33].", "startOffset": 102, "endOffset": 105}, {"referenceID": 29, "context": "RBM training is based on maximum likelihood criterion using the stochastic gradient descent algorithm [5], [33].", "startOffset": 107, "endOffset": 111}, {"referenceID": 28, "context": "The gradient is estimated by an approximated version of the Contrastive Divergence (CD) algorithm which is called CD-1 [32], [33].", "startOffset": 119, "endOffset": 123}, {"referenceID": 29, "context": "The gradient is estimated by an approximated version of the Contrastive Divergence (CD) algorithm which is called CD-1 [32], [33].", "startOffset": 125, "endOffset": 129}, {"referenceID": 28, "context": "More theoretical and practical details can be found in [32], [33], [42].", "startOffset": 55, "endOffset": 59}, {"referenceID": 29, "context": "More theoretical and practical details can be found in [32], [33], [42].", "startOffset": 61, "endOffset": 65}, {"referenceID": 37, "context": "More theoretical and practical details can be found in [32], [33], [42].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "The whole training algorithm is given in [14].", "startOffset": 41, "endOffset": 45}, {"referenceID": 16, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 202, "endOffset": 206}, {"referenceID": 18, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 207, "endOffset": 211}, {"referenceID": 20, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 213, "endOffset": 217}, {"referenceID": 21, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 219, "endOffset": 223}, {"referenceID": 23, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 225, "endOffset": 229}, {"referenceID": 26, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 231, "endOffset": 235}, {"referenceID": 38, "context": "The success of the i-vector approach in speaker recognition and DL techniques in speech processing applications has encouraged the research community to combine those techniques for speaker recognition [17]\u2013[19], [21], [22], [24], [27], [43].", "startOffset": 237, "endOffset": 241}, {"referenceID": 20, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 61, "endOffset": 65}, {"referenceID": 21, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 67, "endOffset": 71}, {"referenceID": 23, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 73, "endOffset": 77}, {"referenceID": 26, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 79, "endOffset": 83}, {"referenceID": 38, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 85, "endOffset": 89}, {"referenceID": 8, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 129, "endOffset": 132}, {"referenceID": 10, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 133, "endOffset": 137}, {"referenceID": 16, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 139, "endOffset": 143}, {"referenceID": 18, "context": "DL techniques can be used in the i-vector extraction process [21], [22], [24], [27], [43], or applied after i-vector computation [9]\u2013[11], [17]\u2013 [19].", "startOffset": 145, "endOffset": 149}, {"referenceID": 16, "context": "In order to have more insight into the behavior of DL techniques on i-vectors, in this work the authors extend the preliminary study developed in [17], [18].", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "In order to have more insight into the behavior of DL techniques on i-vectors, in this work the authors extend the preliminary study developed in [17], [18].", "startOffset": 152, "endOffset": 156}, {"referenceID": 0, "context": "An i-vector [1] is a low rank vector, typically between 400 and 600, representing a speech utterance.", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "More details can be found in [1].", "startOffset": 29, "endOffset": 32}, {"referenceID": 39, "context": "It is worth noting that as the minimum divergence training algorithm [44] is used in the i-vector extraction process, i-vectors will have a standard normal distribution N (0, 1).", "startOffset": 69, "endOffset": 73}, {"referenceID": 40, "context": "Some of the most straightforward ways to deal with unbalanced data problem are explored in [45]\u2013[47] [48], [49].", "startOffset": 91, "endOffset": 95}, {"referenceID": 42, "context": "Some of the most straightforward ways to deal with unbalanced data problem are explored in [45]\u2013[47] [48], [49].", "startOffset": 96, "endOffset": 100}, {"referenceID": 43, "context": "Some of the most straightforward ways to deal with unbalanced data problem are explored in [45]\u2013[47] [48], [49].", "startOffset": 101, "endOffset": 105}, {"referenceID": 44, "context": "Some of the most straightforward ways to deal with unbalanced data problem are explored in [45]\u2013[47] [48], [49].", "startOffset": 107, "endOffset": 111}, {"referenceID": 45, "context": "The selection method is inspired from a data-driven background data selection technique proposed in [50].", "startOffset": 100, "endOffset": 104}, {"referenceID": 45, "context": "The number of times each impostor is selected as a support vector, in all training SVM models, is called impostor support vector frequency [50].", "startOffset": 139, "endOffset": 143}, {"referenceID": 45, "context": "Those N impostors which are close to each target i-vector are treated like support vectors in [50].", "startOffset": 94, "endOffset": 98}, {"referenceID": 37, "context": "Replicated target i-vectors will not act exactly the same as each other in the pre-training process of DNNs due to the sampling noise created in RBM training [42].", "startOffset": 158, "endOffset": 162}, {"referenceID": 16, "context": "Hence, they can be used for unsupervised training of a global model referred to as Universal DBN (UDBN) [17].", "startOffset": 104, "endOffset": 108}, {"referenceID": 34, "context": "It is shown that pre-training techniques can initialize DNNs better than simply random numbers [38]\u2013[40].", "startOffset": 95, "endOffset": 99}, {"referenceID": 36, "context": "It is shown that pre-training techniques can initialize DNNs better than simply random numbers [38]\u2013[40].", "startOffset": 100, "endOffset": 104}, {"referenceID": 16, "context": "In this case, we have proposed in [17] to adapt UDBN parameters to the balanced data obtained for each target speaker.", "startOffset": 34, "endOffset": 38}, {"referenceID": 35, "context": "The study in [39] has shown that pre-training is robust with respect to the random initialization seed.", "startOffset": 13, "endOffset": 17}, {"referenceID": 16, "context": "In contrast to [17], [18], in this work we normalize the UDBN parameters before adaptation.", "startOffset": 15, "endOffset": 19}, {"referenceID": 17, "context": "In contrast to [17], [18], in this work we normalize the UDBN parameters before adaptation.", "startOffset": 21, "endOffset": 25}, {"referenceID": 16, "context": "The top layer pre-training proposed in [17] is not used in this work.", "startOffset": 39, "endOffset": 43}, {"referenceID": 46, "context": "Frequency Filtering (FF) features [51] are used in the experiments.", "startOffset": 34, "endOffset": 38}, {"referenceID": 46, "context": "FFs, like MFCCs, are decorrelated version of log Filter Bank Energies (FBE) [51].", "startOffset": 76, "endOffset": 80}, {"referenceID": 46, "context": "It has been shown that FF features achieve a performance equal to or better than MFCCs [51].", "startOffset": 87, "endOffset": 91}, {"referenceID": 16, "context": "01) used in the prior work [17].", "startOffset": 27, "endOffset": 31}, {"referenceID": 4, "context": "As the input i-vectors are real-valued, a Gaussian-Bernoulli RBM (GRBM) [5], [42] is used to train the connection weights between the visible and the first hidden layer units.", "startOffset": 72, "endOffset": 75}, {"referenceID": 37, "context": "As the input i-vectors are real-valued, a Gaussian-Bernoulli RBM (GRBM) [5], [42] is used to train the connection weights between the visible and the first hidden layer units.", "startOffset": 77, "endOffset": 81}, {"referenceID": 16, "context": "Unlike in [17] and [18] where the authors used the UDBN parameters as such, in this work we normalize the connection weights so that the maximum absolute value is 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 17, "context": "Unlike in [17] and [18] where the authors used the UDBN parameters as such, in this work we normalize the connection weights so that the maximum absolute value is 0.", "startOffset": 19, "endOffset": 23}], "year": 2015, "abstractText": "The promising performance of Deep Learning (DL) in speech recognition has motivated the use of DL in other speech technology applications such as speaker recognition. Given ivectors as inputs, the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on Deep Belief Networks (DBN) and Deep Neural Networks (DNN) to discriminatively model each target speaker. In order to have more insight into the behavior of DL techniques in both single and multi-session speaker enrollment tasks, some experiments have been carried out in this paper in both scenarios. Additionally, the parameters of the global model, referred to as universal DBN (UDBN), are normalized before adaptation. UDBN normalization facilitates training DNNs specifically with more than one hidden layer. Experiments are performed on the NIST SRE 2006 corpus. It is shown that the proposed impostor selection algorithm and UDBN adaptation process enhance the performance of conventional DNNs 8-20% and 16-20% in terms of EER for the single and multi-session tasks, respectively. In both scenarios, the proposed architectures outperform the baseline systems obtaining up to 17% reduction in EER.", "creator": "LaTeX with hyperref package"}}}