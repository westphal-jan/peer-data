{"id": "1512.02831", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Dec-2015", "title": "Bigger Buffer k-d Trees on Multi-Many-Core Systems", "abstract": "A buffer k-d tree is a k-d tree variant for massively-parallel nearest neighbor search. While providing valuable speed-ups on modern many-core devices in case both a large number of reference and query points are given, buffer k-d trees are limited by the amount of points that can fit on a single device. In this work, we show how to modify the original data structure and the associated workflow to make the overall approach capable of dealing with massive data sets. We further provide a simple yet efficient way of using multiple devices given in a single workstation. The applicability of the modified framework is demonstrated in the context of astronomy, a field that is faced with huge amounts of data.", "histories": [["v1", "Wed, 9 Dec 2015 12:28:12 GMT  (148kb,D)", "http://arxiv.org/abs/1512.02831v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.DS cs.LG", "authors": ["fabian gieseke", "cosmin eugen oancea", "ashish mahabal", "christian igel", "tom heskes"], "accepted": false, "id": "1512.02831"}, "pdf": {"name": "1512.02831.pdf", "metadata": {"source": "CRF", "title": "Bigger Buffer k-d Trees on Multi-Many-Core Systems", "authors": ["Fabian Gieseke", "Cosmin Eugen Oancea", "Ashish Mahabal", "Christian Igel", "Tom Heskes"], "emails": ["f.gieseke@cs.ru.nl", "t.heskes@cs.ru.nl", "cosmin.oancea@di.ku.dk", "igel@di.ku.dk", "aam@astro.caltech.edu"], "sections": [{"heading": "1 Motivation", "text": "Many techniques have been proposed in the literature aimed at speeding up the search, typically using spatial search structures, approximation schemes and parallel implementations. A current trend in the field of big data analytics is the use of massively parallel devices such as graphics processor units (GPUs) to accelerate the compatibilities involved. While such modern multi-core devices can significantly reduce practical runtime, obtaining speeds via standard CPU-based execution is often not easy and requires careful adaptation of sequential implementations."}, {"heading": "2 Background", "text": "For the sake of completeness, we provide the background for massively parallel programming on GPUs as well as for the classic k-d tree-based neighborhood search. Further, we outline the key ideas of the buffer k-d tree extension."}, {"heading": "2.1 Architecture and Programming Model", "text": "Modern many-core devices such as GPUs offer massive parallelism and can now also be used for so-called general-purpose computations such as matrix multiplication. Unlike standard CPU-based systems, GPUs rely on simplified control units and a memory subsystem that does not attempt to provide the illusion of a unified access price to memory. GPU architectures typically consist of a number of vector processors, several specialized functional units, and a lot of fast memory split between registers, L1 and L2 data caches, scratchpad, and read-only memory. Each vector processor consists of several execution units that run in lock, i.e. multiple data (simd) modes in a single statement, and each execution unit is further multithreaded to hide memory latencies."}, {"heading": "2.2 Massively-Parallel Nearest Neighbor Computations", "text": "In fact, the fact is that most of them are able to put themselves at the top of society in the way that they have put themselves at the top of the society in which they find themselves."}, {"heading": "3 Processing Bigger Trees", "text": "One problem that has not been solved so far is the fact that the memory of modern GPUs is still relatively small compared to the host storage.3 This limits the number of data points that can be processed. We will now describe modifications that allow the buffer k-d trees to scale to huge data sets that no longer fit on a GPU."}, {"heading": "3.1 Construction Phase", "text": "In fact, the topmost tree and the complete leaf structure (which stores the rearranged reference points) must be made available to all threads during the execution of ProcessAllBuffers. We begin to focus on the space needed for the topmost tree. From a practical perspective, a small leaf tree is usually beneficial compared to a complete leaf used for processing GPUs without increasing the total runtime. We start by focusing on the space needed for the topmost tree."}, {"heading": "3.2 Query Phase", "text": "The idea is to leave the sheet structure on the host system and process the buffers on the host system. (1) The sheet structure, which blocks the sheet structure on the host system, can essentially only be achieved by blocking all the reference points in the associated sheet. (2) The sheet structure, which contains all the n restructured reference points, is processed in a massively parallel manner in which each thread compares a particular query to all the reference points in the associated sheet. In view of the modified memory layout, one can now process the sheets in the chunks in the following way: The sheet structure, which contains all the n restructured reference points, is converted into 1 < N n chunks C1,., CN (e.g. N = 10) Each chunk Cj contains the points of the sheet structure at positions k = CLj, C R j."}, {"heading": "4 Experiments", "text": "The purpose of the experiments listed below is to analyze the efficiency of the modified workflow and to outline the potential of the overall approach in the context of large-scale scenarios. For a detailed experimental comparison, including an analysis of the different processing phases and the influence of parameters related to the buffer k-d-tree framework, refer to our previous paper [11].6 Depending on the architecture, the induced copy processes could become a major bottleneck. However, this drawback can be reduced by increasing the size of the buffer k-d-tree so that more calculations are required for each data transfer from disk to device."}, {"heading": "4.1 Experimental Setup", "text": "In fact, it is such that most of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight"}, {"heading": "4.2 Modified Workflow", "text": "While the modified workflow allows the use of buffer k-d trees for massive data sets that do not fit into the memory of the many core devices, it may also cause some overhead compared to its original version, as it requires processing and reduced workload per core call. Moreover, the \"naive\" use of multiple GPUs is worse than filling the input queue with new queries. We are now examining both potential drawbacks. The main modification is processing the leaf structure in case it does not fit into the memory."}, {"heading": "4.3 Large-Scale Applications", "text": "To demonstrate the potential of the modified frame, we will consider two large-scale tasks: (1) the application of close neighbor models based on very large training sets, and (2) large-scale density-based outlier detection. (2) The first scenario addresses the closest neighbor models based on very large training sets. (3) The models have been successfully used for various tasks in astronomy, including remote galaxy detection or estimation of physical parameters. (4) For experimental comparison, we will consider scenarios with a large number of training and testing patterns. (4) We will consider up to n = 106 training points and up to m = 5 test points. (4) For both tree phases, we will set suitable tree phases in advance. (4)"}, {"heading": "5 Conclusions", "text": "The key idea is to process both the reference points and the query points into blocks, the latter being relatively easy to implement (even with multiple many-core devices), but processing the reference points into blocks is more difficult. As our work shows, the overhead caused by the uncontrolled processing of the reference points can be effectively eliminated by dovetailing the computing and copying operations with each other. Experiments with raw material hardware show that a single workstation is sufficient to efficiently process millions of reference and query points. Future work could focus on scenarios based on even larger reference sets (e.g. hundreds of billions of points), which could also require the efficient construction of the buffer tree k-d. Furthermore, similar (unconnected) buffer techniques could be useful to achieve efficient, massive parallel implementations for other techniques (e.g. hundreds of points) that might require the buffer tree to be efficiently constructed."}], "references": [{"title": "Multidimensional binary search trees used for associative searching", "author": ["J. Bentley"], "venue": "Communications of the ACM 18(9), 509\u2013517", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1975}, {"title": "Cover trees for nearest neighbor", "author": ["A. Beygelzimer", "S. Kakade", "J. Langford"], "venue": "Proceedings of the 23rd International Conference on Machine Learning. pp. 97\u2013 104. ACM", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Time bounds for selection", "author": ["M. Blum", "R.W. Floyd", "V. Pratt", "R.L. Rivest", "R.E. Tarjan"], "venue": "Journal of Computer and System Sciences 7(4), 448\u2013461", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1973}, {"title": "A graphics hardware accelerated algorithm for nearest neighbor search", "author": ["B. Bustos", "O. Deussen", "S. Hiller", "D. Keim"], "venue": "Computational Science \u2013 ICCS 2006. Lecture Notes in Computer Science, vol. 3994, pp. 196\u2013199. Springer", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Accelerating nearest neighbor search on manycore systems", "author": ["L. Cayton"], "venue": "Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium. pp. 402\u2013413. IEEE", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "The catalina real-time transient survey", "author": ["S.G. Djorgovski", "A.J. Drake", "A.A. Mahabal", "M.J. Graham", "C. Donalek", "R. Williams", "E.C. Beshore", "S.M. Larson", "J. Prieto", "M. Catelan", "E. Christensen", "R.H. McNaught"], "venue": "The First Year of MAXI: Monitoring Variable X-ray Sources", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "First results from the catalina real-time transient survey", "author": ["A.J. Drake", "S.G. Djorgovski", "A. Mahabal", "E. Beshore", "S. Larson", "M.J. Graham", "R. Williams", "E. Christensen", "M. Catelan", "A. Boattini", "A. Gibbs", "R. Hill", "R. Kowalski"], "venue": "The Astrophysical Journal 696(1), 870\u2013884", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Modeling light curves for improved classification", "author": ["J. Faraway", "A. Mahabal", "J. Sun", "X. Wang", "W. Yi", "L. Zhang"], "venue": "eprint arXiv:1401.3211", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "An algorithm for finding best matches in logarithmic expected time", "author": ["J. Friedman", "J. Bentley", "R. Finkel"], "venue": "ACM Transactions on Mathematical Software 3(3), 209\u2013226", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1977}, {"title": "K-nearest neighbor search: Fast GPU-based implementations and application to high-dimensional feature matching", "author": ["V. Garcia", "E. Debreuve", "F. Nielsen", "M. Barlaud"], "venue": "Proceedings of the 17th IEEE International Conference on Image Processing. pp. 3757\u20133760. IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Buffer k-d trees: Processing massive nearest neighbor queries on GPUs", "author": ["F. Gieseke", "J. Heinermann", "C. Oancea", "C. Igel"], "venue": "Proceedings of the 31st International Conference on Machine Learning (ICML 2014). JMLR W&CP. vol. 32, pp. 172\u2013180", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "The Elements of Statistical Learning", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": "Springer, 2 edn.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "On GPU-based nearest neighbor queries for large-scale photometric catalogs in astronomy", "author": ["J. Heinermann", "O. Kramer", "K.L. Polsterer", "F. Gieseke"], "venue": "KI 2013: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol. 8077, pp. 86\u201397. Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Approximate nearest neighbors: Towards removing the curse of dimensionality", "author": ["P. Indyk", "R. Motwani"], "venue": "Proceedings of the 30th Annual ACM Symposium on Theory of Computing. pp. 604\u2013613. ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1998}, {"title": "Nearest neighbor density ratio estimation for large-scale applications in astronomy", "author": ["J. Kremer", "F. Gieseke", "K. Steenstrup Pedersen", "C. Igel"], "venue": "Astronomy and Computing 12, 67\u201372", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Discovery, classification, and scientific exploration of transient events from the catalina real-time transient survey", "author": ["A.A. Mahabal", "S.G. Djorgovski", "A.J. Drake", "C. Donalek", "M.J. Graham", "R.D. Williams", "Y. Chen", "B. Moghaddam", "M. Turmon", "E. Beshore", "S. Larson"], "venue": "Bulletin of the Astronmical Society of India 39(3), 387\u2013408", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Implementation of a parallel tree method on a GPU", "author": ["N. Nakasato"], "venue": "Journal of Computational Science 3(3), 132\u2013141", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast GPU-based locality sensitive hashing for k-nearest neighbor computation", "author": ["J. Pan", "D. Manocha"], "venue": "Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. pp. 211\u2013220. ACM", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Finding new high-redshift quasars by asking the neighbours", "author": ["K. Polsterer", "P. Zinn", "F. Gieseke"], "venue": "Monthly Notices of the Royal Astronomical Society 428(1), 226\u2013235", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "GPU-accelerated nearest neighbor search for 3D registration", "author": ["D. Qiu", "S. May", "A. N\u00fcchter"], "venue": "Proceedings of the 7th International Conference on Computer Vision Systems. pp. 194\u2013203. Springer", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "On machine-learned classification of variable stars with sparse and noisy time-series data", "author": ["J.W. Richards", "D.L. Starr", "N.R. Butler", "J.S. Bloom", "J.M. Brewer", "A. Crellin-Quick", "J. Higgins", "R. Kennedy", "M. Rischard"], "venue": "The Astrophysical Journal 733(1)", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "OpenCL in Action: How to Accelerate Graphics and Computation", "author": ["M. Scarpino"], "venue": "Manning", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Parallel search of k-nearest neighbors with synchronous operations", "author": ["N. Sismanis", "N. Pitsianis", "X. Sun"], "venue": "IEEE Conference on High Performance Extreme Computing. pp. 1\u20136. IEEE", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Nearest neighbour regression outperforms model-based prediction of specific star formation rate", "author": ["K. Stensbo-Smidt", "C. Igel", "A. Zirm", "K. Steenstrup Pedersen"], "venue": "IEEE International Conference on Big Data 2013. pp. 141\u2013144. IEEE", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Introduction to Data Mining", "author": ["P.N. Tan", "M. Steinbach", "V. Kumar"], "venue": "AddisonWesley", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Parallel k-nearest neighbor search on graphics hardware", "author": ["W. Wang", "L. Cao"], "venue": "Proceedings of the 2010 3rd International Symposium on Parallel Architectures, Algorithms and Programming. pp. 291\u2013294. IEEE", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Typical are include the use of spatial search structures, approximation schemes, and parallel implementations [1,2,5,10,14,18].", "startOffset": 110, "endOffset": 126}, {"referenceID": 1, "context": "Typical are include the use of spatial search structures, approximation schemes, and parallel implementations [1,2,5,10,14,18].", "startOffset": 110, "endOffset": 126}, {"referenceID": 4, "context": "Typical are include the use of spatial search structures, approximation schemes, and parallel implementations [1,2,5,10,14,18].", "startOffset": 110, "endOffset": 126}, {"referenceID": 9, "context": "Typical are include the use of spatial search structures, approximation schemes, and parallel implementations [1,2,5,10,14,18].", "startOffset": 110, "endOffset": 126}, {"referenceID": 13, "context": "Typical are include the use of spatial search structures, approximation schemes, and parallel implementations [1,2,5,10,14,18].", "startOffset": 110, "endOffset": 126}, {"referenceID": 17, "context": "Typical are include the use of spatial search structures, approximation schemes, and parallel implementations [1,2,5,10,14,18].", "startOffset": 110, "endOffset": 126}, {"referenceID": 10, "context": "Recently, we have proposed a modification of the classical k-d tree data structure, called buffer k-d tree, which aims at combining the benefits of both spatial search structures and massively-parallel devices [11].", "startOffset": 210, "endOffset": 214}, {"referenceID": 21, "context": "The GPU programming model typically reflects this hardware organization: For example, expressing a parallel computation in OpenCL [22] requires the user to write a kernel that will be run simultaneously by many threads.", "startOffset": 130, "endOffset": 134}, {"referenceID": 11, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Various other approaches have been proposed in the literature that aim at taking advantage of the computational resources provided by GPUs in combination with other techniques [4,18,23].", "startOffset": 176, "endOffset": 185}, {"referenceID": 17, "context": "Various other approaches have been proposed in the literature that aim at taking advantage of the computational resources provided by GPUs in combination with other techniques [4,18,23].", "startOffset": 176, "endOffset": 185}, {"referenceID": 22, "context": "Various other approaches have been proposed in the literature that aim at taking advantage of the computational resources provided by GPUs in combination with other techniques [4,18,23].", "startOffset": 176, "endOffset": 185}, {"referenceID": 12, "context": ", in the context of ray tracing) [13,17,20,26], these approaches are not suited for nearest neighbor search in moderate-sized feature spaces (i.", "startOffset": 33, "endOffset": 46}, {"referenceID": 16, "context": ", in the context of ray tracing) [13,17,20,26], these approaches are not suited for nearest neighbor search in moderate-sized feature spaces (i.", "startOffset": 33, "endOffset": 46}, {"referenceID": 19, "context": ", in the context of ray tracing) [13,17,20,26], these approaches are not suited for nearest neighbor search in moderate-sized feature spaces (i.", "startOffset": 33, "endOffset": 46}, {"referenceID": 25, "context": ", in the context of ray tracing) [13,17,20,26], these approaches are not suited for nearest neighbor search in moderate-sized feature spaces (i.", "startOffset": 33, "endOffset": 46}, {"referenceID": 10, "context": ", d > 3), except for the recently proposed buffer k-d tree extension [11].", "startOffset": 69, "endOffset": 73}, {"referenceID": 0, "context": "K-d trees can be constructed as follows [1,9]: For a given point", "startOffset": 40, "endOffset": 45}, {"referenceID": 8, "context": "K-d trees can be constructed as follows [1,9]: For a given point", "startOffset": 40, "endOffset": 45}, {"referenceID": 10, "context": "Figure 1: A buffer k-d tree [11]: The gray elements are stored on GPU.", "startOffset": 28, "endOffset": 32}, {"referenceID": 10, "context": "The main idea of the buffer k-d tree extension is to delay the processing of the queries by buffering similar patterns prior to their common processing [11].", "startOffset": 152, "endOffset": 156}, {"referenceID": 10, "context": "Algorithm 1 LazySearch [11]", "startOffset": 23, "endOffset": 27}, {"referenceID": 10, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "be stored on the GPU given the original implementation [11]\u2014this limits the amount of reference patterns that can be processed.", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "For instance, given a reference set P \u2282 R with two million points, top trees of height h = 8 or h = 9 are usually optimal [11].", "startOffset": 122, "endOffset": 126}, {"referenceID": 2, "context": "In addition, the top tree can be built efficiently via linear-time median finding [3], which results in \u00d8(h log n) time for the whole construction phase.", "startOffset": 82, "endOffset": 85}, {"referenceID": 21, "context": "Note that we also allocate two associated memory buffers on the host (pinned memory [22]) to achieve efficient concurrent compute and copy operations.", "startOffset": 84, "endOffset": 88}, {"referenceID": 21, "context": "The iterative compute-and-copy processing of the chunks can be implemented via two (OpenCL) command queues [22]: For the first chunk, phase (1) and (3) are instantiated via command queue A, whereas the copy process (2) is instantiated via command queue B (non-blocking for both (1) and (2)).", "startOffset": 107, "endOffset": 111}, {"referenceID": 10, "context": "For a detailed experimental comparison including an analysis of the different processing phases and the influence of parameters related to the buffer k-d tree framework, we refer to our previous work [11].", "startOffset": 200, "endOffset": 204}, {"referenceID": 10, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "In addition, we consider a new dataset derived from the Catalina Realtime Transient Survey (crts) [7,6,16].", "startOffset": 98, "endOffset": 106}, {"referenceID": 5, "context": "In addition, we consider a new dataset derived from the Catalina Realtime Transient Survey (crts) [7,6,16].", "startOffset": 98, "endOffset": 106}, {"referenceID": 15, "context": "In addition, we consider a new dataset derived from the Catalina Realtime Transient Survey (crts) [7,6,16].", "startOffset": 98, "endOffset": 106}, {"referenceID": 20, "context": "9 In particular, we make use of the amplitude, Stetsonj , Stetsonk, Skew, fprmid35, fprmid50, fprmid65, fprmid80, shov, maxdiff [21,8].", "startOffset": 128, "endOffset": 134}, {"referenceID": 7, "context": "9 In particular, we make use of the amplitude, Stetsonj , Stetsonk, Skew, fprmid35, fprmid50, fprmid65, fprmid80, shov, maxdiff [21,8].", "startOffset": 128, "endOffset": 134}, {"referenceID": 11, "context": "Huge Nearest Neighbor Models: The first scenario addresses nearest neighbor models [12] that are based on very large training sets.", "startOffset": 83, "endOffset": 87}, {"referenceID": 18, "context": "Such models have been successfully been applied for various tasks in astronomy including the detection of distant galaxies or the estimation of physical parameters [19,24,15].", "startOffset": 164, "endOffset": 174}, {"referenceID": 23, "context": "Such models have been successfully been applied for various tasks in astronomy including the detection of distant galaxies or the estimation of physical parameters [19,24,15].", "startOffset": 164, "endOffset": 174}, {"referenceID": 14, "context": "Such models have been successfully been applied for various tasks in astronomy including the detection of distant galaxies or the estimation of physical parameters [19,24,15].", "startOffset": 164, "endOffset": 174}, {"referenceID": 24, "context": "[25].", "startOffset": 0, "endOffset": 4}], "year": 2015, "abstractText": "A buffer k-d tree is a k-d tree variant for massively-parallel nearest neighbor search. While providing valuable speed-ups on modern many-core devices in case both a large number of reference and query points are given, buffer k-d trees are limited by the amount of points that can fit on a single device. In this work, we show how to modify the original data structure and the associated workflow to make the overall approach capable of dealing with massive data sets. We further provide a simple yet efficient way of using multiple devices given in a single workstation. The applicability of the modified framework is demonstrated in the context of astronomy, a field that is faced with huge amounts of data.", "creator": "LaTeX with hyperref package"}}}