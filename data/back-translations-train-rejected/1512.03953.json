{"id": "1512.03953", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Dec-2015", "title": "Active Distance-Based Clustering using K-medoids", "abstract": "k-medoids algorithm is a partitional, centroid-based clustering algorithm which uses pairwise distances of data points and tries to directly decompose the dataset with $n$ points into a set of $k$ disjoint clusters. However, k-medoids itself requires all distances between data points that are not so easy to get in many applications. In this paper, we introduce a new method which requires only a small proportion of the whole set of distances and makes an effort to estimate an upper-bound for unknown distances using the inquired ones. This algorithm makes use of the triangle inequality to calculate an upper-bound estimation of the unknown distances. Our method is built upon a recursive approach to cluster objects and to choose some points actively from each bunch of data and acquire the distances between these prominent points from oracle. Experimental results show that the proposed method using only a small subset of the distances can find proper clustering on many real-world and synthetic datasets.", "histories": [["v1", "Sat, 12 Dec 2015 19:33:52 GMT  (295kb,D)", "http://arxiv.org/abs/1512.03953v1", "12 pages, 3 figures, PAKDD 2016"]], "COMMENTS": "12 pages, 3 figures, PAKDD 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehrdad ghadiri", "amin aghaee", "mahdieh soleymani baghshah"], "accepted": false, "id": "1512.03953"}, "pdf": {"name": "1512.03953.pdf", "metadata": {"source": "CRF", "title": "Active Distance-Based Clustering using K-medoids", "authors": ["Amin Aghaee", "Mehrdad Ghadiri", "Mahdieh Soleymani Baghshah", "M. Soleymani Baghshah"], "emails": ["aghaee@ce.sharif.edu", "ghadiri@ce.sharif.edu", "soleymani@sharif.edu"], "sections": [{"heading": null, "text": "Keywords: Active k-medoids, Active clustering, Distance-based clustering, Centroid-based clustering."}, {"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Related Work", "text": "Active learning is a machine learning paradigm that seeks to do learning by labeling a few samples that are more important to the end result of learning. In fact, most of the monitored learning algorithms require a large amount of labeled samples, and collecting those labeled samples may require an undue amount of time and effort. The active cluster problem has received a lot of attention recently. So far, it has been proposed to actively implement some known cluster methods in which important samples can be interpreted as highly informative. In the active cluster problem, a query is a pair of data whose similarity needs to be determined. The purpose of the active cluster approach is to reduce the number of required queries by actively selecting them rather than by random selection."}, {"heading": "3 Proposed Method", "text": "This year, \"he said,\" we've never waited so long to be in a position to be in a position, \"he said.\" We've never waited so long to be in a position to be in a position, \"he said.\" We've never had to do so much, \"he said.\" We've never waited so long to be in a position to be in a position, \"he said."}, {"heading": "4 Empirical results", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "5 Conclusion", "text": "In this thesis, we present an innovative method of active distance-based clustering. Its goal is to cluster n points from a metric dataset into k clusters using the least possible number of distances. We design a recursive model that creates a tree and splits data with a branching factor b, unless the number of objects is less than a threshold th. Then, it actively selects some pairs of similarities and asks for the oracle. Then, it tries to make an upper limit estimate for unknown distances using the triangular inequality. Finally, it clusters data using a simple k-medoid algorithm. We execute our algorithm using some synthesized and real datasets. To show privileges of our method and compare the results, we also implement an algorithm that selects randomly pairs of distances and estimates unknown ones using the Floyd-Warshall algorithm."}], "references": [{"title": "Parallelising the k-medoids clustering problem using space-partitioning", "author": ["A. Arbelaez", "L. Quesada"], "venue": "In Proceedings of the Sixth Annual Symposium on Combinatorial Search,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "k-means++: the advantages of careful seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "In Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Uci machine learning repository", "author": ["A. Asuncion", "D. Newman"], "venue": "datasets. https: //archive.ics.uci.edu/ml/datasets.html,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Active semi-supervision for pairwise constrained clustering", "author": ["S. Basu", "A. Banerjee", "R.J. Mooney"], "venue": "In Proceedings of the Fourth SIAM International Conference on Data", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Active image clustering with pairwise constraints from humans", "author": ["A. Biswas", "D.W. Jacobs"], "venue": "International Journal of Computer Vision,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Introduction to Algorithms", "author": ["T.H. Cormen", "C.E. Leiserson", "R.L. Rivest", "C. Stein"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Active clustering: Robust and efficient hierarchical clustering using adaptively selected similarities", "author": ["B. Eriksson", "G. Dasarathy", "A. Singh", "R.D. Nowak"], "venue": "In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Active semi-supervised fuzzy clustering", "author": ["N. Grira", "M. Crucianu", "N. Boujemaa"], "venue": "Pattern Recognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Finding Groups in Data: An Introduction to Cluster Analysis", "author": ["L. Kaufman", "P.J. Rousseeuw"], "venue": "John Wiley,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1990}, {"title": "Efficient active algorithms for hierarchical clustering", "author": ["A. Krishnamurthy", "S. Balakrishnan", "M. Xu", "A. Singh"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Active density-based clustering", "author": ["S.T. Mai", "X. He", "N. Hubig", "C. Plant", "C. B\u00f6hm"], "venue": "IEEE 13th International Conference on Data", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Deep learning from temporal coherence in video", "author": ["H. Mobahi", "R. Collobert", "J. Weston"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Columbia object image library (coil 100)", "author": ["S. Nayar", "S.A. Nene", "H. Murase"], "venue": "Department of Comp. Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1996}, {"title": "Information theoretic measures for clusterings comparison: is a correction for chance necessary", "author": ["X.V. Nguyen", "J. Epps", "J. Bailey"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin, Madison,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Spectral clustering on a budget", "author": ["O. Shamir", "N. Tishby"], "venue": "In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "K-means v/s k-medoids: A comparative study", "author": ["S.S. Singh", "N. Chauhan"], "venue": "In National Conference on Recent Trends in Engineering & Technology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Support vector machine active learning with applications to text classification", "author": ["S. Tong", "D. Koller"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2001}, {"title": "Fundamental clustering problems suite (fcps)", "author": ["A. Ultsch"], "venue": "Technical report, Technical report, University of Marburg,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Active clustering of biological sequences", "author": ["K. Voevodski", "M. Balcan", "H. R\u00f6glin", "S. Teng", "Y. Xia"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Improving constrained clustering with active query selection", "author": ["V. Vu", "N. Labroche", "B. Bouchon-Meunier"], "venue": "Pattern Recognition,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Constrained k-means clustering with background knowledge", "author": ["K. Wagstaff", "C. Cardie", "S. Rogers", "S. Schr\u00f6dl"], "venue": "In Proceedings of the Eighteenth International Conference on Machine Learning (ICML", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "Active spectral clustering", "author": ["X. Wang", "I. Davidson"], "venue": "ICDM", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Active spectral clustering via iterative uncertainty reduction", "author": ["F.L. Wauthier", "N. Jojic", "M.I. Jordan"], "venue": "In The 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201912,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Active clustering with model-based uncertainty reduction", "author": ["C. Xiong", "D.M. Johnson", "J.J. Corso"], "venue": "CoRR, abs/1402.1783,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Ucr time series classification archive", "author": ["Eamonn Keogh", "G. Batista"], "venue": "http://www.cs.ucr.edu/~eamonn/time_series_ data/,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "In [3], some usages and applications of k-medoids algorithm are discussed.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "Furthermore, as reported by [3], medoid queries also arise in the sensor networks and many other fields.", "startOffset": 28, "endOffset": 31}, {"referenceID": 19, "context": "For example, the sequence similarity of proteins [23] or similarity of face images [7] which needs to be obtained from human as an oracle, may be difficult to be responded.", "startOffset": 49, "endOffset": 53}, {"referenceID": 4, "context": "For example, the sequence similarity of proteins [23] or similarity of face images [7] which needs to be obtained from human as an oracle, may be difficult to be responded.", "startOffset": 83, "endOffset": 86}, {"referenceID": 10, "context": "The active version of some of the well known clustering algorithms have been recently presented in [14,26].", "startOffset": 99, "endOffset": 106}, {"referenceID": 22, "context": "The active version of some of the well known clustering algorithms have been recently presented in [14,26].", "startOffset": 99, "endOffset": 106}, {"referenceID": 14, "context": "most informative ones, most uncertain ones, or the ones that have a large effect in the results [18].", "startOffset": 96, "endOffset": 100}, {"referenceID": 10, "context": "Until now, the active version of some well known clustering methods has been proposed in [14,26].", "startOffset": 89, "endOffset": 96}, {"referenceID": 22, "context": "Until now, the active version of some well known clustering methods has been proposed in [14,26].", "startOffset": 89, "endOffset": 96}, {"referenceID": 17, "context": "The purpose of the active learning approach is reducing the number of required queries via active selection of them instead of random selection [21].", "startOffset": 144, "endOffset": 148}, {"referenceID": 20, "context": "The existing active clustering methods can be categorized into constraintbased and distance-based ones [24] .", "startOffset": 103, "endOffset": 107}, {"referenceID": 20, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 24, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 7, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 22, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 4, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 3, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 21, "context": "Some constraint-based methods for active clustering have been proposed in [24,28,11,26,7,6,25].", "startOffset": 74, "endOffset": 94}, {"referenceID": 10, "context": "Distance-based methods for active clustering have been recently attended in [14,10,13,19,27,23].", "startOffset": 76, "endOffset": 95}, {"referenceID": 6, "context": "Distance-based methods for active clustering have been recently attended in [14,10,13,19,27,23].", "startOffset": 76, "endOffset": 95}, {"referenceID": 9, "context": "Distance-based methods for active clustering have been recently attended in [14,10,13,19,27,23].", "startOffset": 76, "endOffset": 95}, {"referenceID": 15, "context": "Distance-based methods for active clustering have been recently attended in [14,10,13,19,27,23].", "startOffset": 76, "endOffset": 95}, {"referenceID": 23, "context": "Distance-based methods for active clustering have been recently attended in [14,10,13,19,27,23].", "startOffset": 76, "endOffset": 95}, {"referenceID": 19, "context": "Distance-based methods for active clustering have been recently attended in [14,10,13,19,27,23].", "startOffset": 76, "endOffset": 95}, {"referenceID": 10, "context": "In [14], an algorithm for active DBSCAN clustering is presented.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "Moreover, an updating technique is introduced in [14] that update clustering after a query.", "startOffset": 49, "endOffset": 53}, {"referenceID": 15, "context": "In [19,27], distance-based algorithms are presented for active spectral clustering in which a perturbation theory approach is used to select queries.", "startOffset": 3, "endOffset": 10}, {"referenceID": 23, "context": "In [19,27], distance-based algorithms are presented for active spectral clustering in which a perturbation theory approach is used to select queries.", "startOffset": 3, "endOffset": 10}, {"referenceID": 22, "context": "A constraint-based algorithm has also been presented in [26] for active spectral clustering that uses an approach based on maximum expected error reduction to select queries.", "startOffset": 56, "endOffset": 60}, {"referenceID": 19, "context": "An active clustering method for k-median clustering has also been proposed in [23].", "startOffset": 78, "endOffset": 82}, {"referenceID": 8, "context": "As mentioned above, many clustering algorithms such as K-medoids, PAM [12], and some other distance-based methods, calculate an n \u00d7 n distance matrix at first and perform the clustering algorithm on this distance matrix.", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "According to [20], the time complexity of the k-medoids algorithm is O ( kn ) for n data points and k clusters in each iteration.", "startOffset": 13, "endOffset": 17}, {"referenceID": 1, "context": "NORM-10 [4] contains 10000 data points having 20 features.", "startOffset": 8, "endOffset": 11}, {"referenceID": 11, "context": "We converted samples in NEC animal [15] and ALOI200 [1] dataset into 32 \u00d7 32 grayscale images.", "startOffset": 35, "endOffset": 39}, {"referenceID": 2, "context": "seeds 210 7 3 21945 [5]", "startOffset": 20, "endOffset": 23}, {"referenceID": 2, "context": "fisheriris 150 4 3 11175 [5]", "startOffset": 25, "endOffset": 28}, {"referenceID": 25, "context": "Trace 200 275 4 19900 [29]", "startOffset": 22, "endOffset": 26}, {"referenceID": 2, "context": "multi-features 2000 649 10 1999000 [5]", "startOffset": 35, "endOffset": 38}, {"referenceID": 18, "context": "TwoDiamonds(s) 800 2 2 319600 [22]", "startOffset": 30, "endOffset": 34}, {"referenceID": 18, "context": "EngyTime(s) 4096 2 2 8386560 [22]", "startOffset": 29, "endOffset": 33}, {"referenceID": 12, "context": "COIL100 7200 1024 100 25916400 [16]", "startOffset": 31, "endOffset": 35}, {"referenceID": 1, "context": "NORM10(s) 10000 20 10 49995000 [4]", "startOffset": 31, "endOffset": 34}, {"referenceID": 11, "context": "NEC animal 4371 1024 60 9550635 [15]", "startOffset": 32, "endOffset": 36}, {"referenceID": 10, "context": "Although active version of some clustering algorithms like DBSCAN and spectral clustering have been introduced in [14,26], these clustering algorithms are substantially different from the k-medoids algorithm.", "startOffset": 114, "endOffset": 121}, {"referenceID": 22, "context": "Although active version of some clustering algorithms like DBSCAN and spectral clustering have been introduced in [14,26], these clustering algorithms are substantially different from the k-medoids algorithm.", "startOffset": 114, "endOffset": 121}, {"referenceID": 13, "context": "One of the most common measures for comparison of clustering algorithms is normalized mutual information (NMI) [17].", "startOffset": 111, "endOffset": 115}], "year": 2015, "abstractText": "k-medoids algorithm is a partitional, centroid-based clustering algorithm which uses pairwise distances of data points and tries to directly decompose the dataset with n points into a set of k disjoint clusters. However, k-medoids itself requires all distances between data points that are not so easy to get in many applications. In this paper, we introduce a new method which requires only a small proportion of the whole set of distances and makes an effort to estimate an upperbound for unknown distances using the inquired ones. This algorithm makes use of the triangle inequality to calculate an upper-bound estimation of the unknown distances. Our method is built upon a recursive approach to cluster objects and to choose some points actively from each bunch of data and acquire the distances between these prominent points from oracle. Experimental results show that the proposed method using only a small subset of the distances can find proper clustering on many real-world and synthetic datasets.", "creator": "LaTeX with hyperref package"}}}