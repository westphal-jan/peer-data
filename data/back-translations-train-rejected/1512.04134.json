{"id": "1512.04134", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Dec-2015", "title": "Evaluation of Pose Tracking Accuracy in the First and Second Generations of Microsoft Kinect", "abstract": "Microsoft Kinect camera and its skeletal tracking capabilities have been embraced by many researchers and commercial developers in various applications of real-time human movement analysis. In this paper, we evaluate the accuracy of the human kinematic motion data in the first and second generation of the Kinect system, and compare the results with an optical motion capture system. We collected motion data in 12 exercises for 10 different subjects and from three different viewpoints. We report on the accuracy of the joint localization and bone length estimation of Kinect skeletons in comparison to the motion capture. We also analyze the distribution of the joint localization offsets by fitting a mixture of Gaussian and uniform distribution models to determine the outliers in the Kinect motion data. Our analysis shows that overall Kinect 2 has more robust and more accurate tracking of human pose as compared to Kinect 1.", "histories": [["v1", "Sun, 13 Dec 2015 22:58:55 GMT  (9121kb,D)", "http://arxiv.org/abs/1512.04134v1", "10 pages, IEEE International Conference on Healthcare Informatics 2015 (ICHI 2015)"]], "COMMENTS": "10 pages, IEEE International Conference on Healthcare Informatics 2015 (ICHI 2015)", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["qifei wang", "gregorij kurillo", "ferda ofli", "ruzena bajcsy"], "accepted": false, "id": "1512.04134"}, "pdf": {"name": "1512.04134.pdf", "metadata": {"source": "CRF", "title": "Evaluation of Pose Tracking Accuracy in the First and Second Generations of Microsoft Kinect", "authors": ["Qifei Wang", "Gregorij Kurillo", "Ferda Ofli", "Ruzena Bajcsy"], "emails": ["gregorij}@eecs.berkeley.edu", "fofli@qf.org.qa", "bajcsy@eecs.berkeley.edu"], "sections": [{"heading": null, "text": "Although the methods for capturing and extracting the human pose from the image data have been in place for several years, advances in sensor technologies (infrared sensors) and computing power (e.g. GPUs) are very high, creating new systems that enable robust and relatively accurate capturing of human movement. An important milestone in the widespread application of these technologies was the release of Microsoft's Kinect camera [1] for the Xbox 360 game console, followed by the release of Kinect for the Software Development Kit (SDK)."}, {"heading": "II. RELATED WORK", "text": "In fact, most of them are able to survive on their own if they do not put themselves in a position to survive on their own."}, {"heading": "III. ACQUISITION SYSTEMS", "text": "In this section we give more details on the experimental setup and a brief overview of the technology behind each Kinect system. For experimental evaluation, the movements were recorded simultaneously by Kinect 1, Kinect 2 and a marker-based optical motion detection system that served as the baseline. The two Kinects were mounted together and mounted on a tripod at a height of approximately 1.5 m. All three systems were geometrically calibrated and synchronized with the procedure described below before data collection."}, {"heading": "A. Motion Capture System (MoCap)", "text": "The motion data was recorded using the PhaseSpace (San Leandro, CA, USA) Impulse X2 system with 8 infrared stereo cameras positioned around the recording space of approximately 4 m x 4 m. The system provides 3D positions of LED markers with an accuracy and frequency of up to 960 Hz. For this study, a recording rate of 480 Hz was selected. For each subject, 43 markers were attached to standard body markers using Velcro fasteners on a motion capture suit. To obtain the skeleton from the marker data, a rigid kinematic structure was dynamically fitted into the 3D point cloud. We used the PhaseSpace Recap2 software to obtain the skeleton for each subject based on collected calibration data consisting of a sequence of individual joint rotations. The built-in algorithm determines the length of the body segments based on the skeleton, which are linked to a set of 29 different body parts, each of which are connected to a marker."}, {"heading": "B. Kinect 1", "text": "Kinect 1 sensor has recording rates of up to 30 Hz for color and depth data with resolutions of 640 x 480 pixels and 320 x 240 pixels, respectively. Depth data is obtained using a structured light approach, in which a pseudo-andomous infrared spot pattern is projected onto the scene when captured by a thermal imaging camera. Stereo triangulation is used to obtain the 3D position of the points from their projections. This approach provides robust 3D reconstruction even in low light conditions. Depth accuracy decreases with the square of the distance, with a typical accuracy of about 1-4 cm in the range of 1-4 m [12]. To obtain a dense depth map, surface interpolation is applied based on the depth values recorded at the data points. The fixed density of the points limits the accuracy when they move away from the camera, as the points are synchronized by the people making the decision of the Kinect's distance, the surfaces of the tracker are often based on the time of the tracker."}, {"heading": "C. Kinect 2", "text": "The Kinect 2 sensor has high-resolution colors (1920 x 1080 pixels) and higher depth data resolution (512 x 424 pixels) compared to Kinect 1. Depth acquisition is based on the Time-of-Flight (ToF) principle, which measures the distance to points on the surface by calculating the phase shift of modulated infrared light. Thus, the intensity of the captured image is proportional to the distance of the points in 3D space. ToF technology, unlike structured light, naturally provides a dense depth map, but the results may suffer from various artefacts caused by the reflection of the light signal from the scene geometry and the reflection properties of the observed materials. Kinect 2 \"depth accuracy is relatively constant within a specific acquisition volume, but depends on the vertical and horizontal shift, as the light pulses from the center of the camera are stretched to the depth of the scanner [2 reported to the depth of the camera at 14 mm]."}, {"heading": "D. Calibration and Data Acquisition", "text": "To capture the database, we connected the two Kinect cameras to a single PC running Windows 8.1, with Kinect 1 connected via USB 2.0 and Kinect 2 via USB 3.0 to a separate PCI bus. Such an arrangement enabled both sensors to capture at the full frame rate of 30 Hz. The skeletal data from both cameras was extracted in real time via Microsoft Kinect SDK v1.8 and Kinect for Windows SDK v2.0 for Kinect 1 and Kinect 2, respectively. Timed synchronization of the recorded data was done using the Network Time Protocol (NTP), and the Motion Capture Server provided the time stamps for the Kinect PC over the local network. Meinberg NTP Client Software (Meinberg Radio Clocks GmbH, Bad Pyrmont, Germany) was installed on the Windows computer to obtain more accurate clock synchronization values."}, {"heading": "E. Data Processing", "text": "The rest of the analysis was done in MATLAB (MathWorks, Natick, MA). First, the skeletal sequences from the Kinect cameras were mapped to capture the coordinate space using the rigid transformation obtained from the calibration, then we aligned the sequences using the timestamps and tried all the data points on the timestamps of Kinect 2 to compare the common localization in the same time instances. Figure 1 shows the three skeletal configurations projected into the motion capture space after calibration, and after the spatial transformation and time alignment we received three sequences of 3D joint positions for Kinect 1, Kinect 2 and motion capture. As the three skeletal configurations have different arrangements and number of joints, we were classified all 20 common joints that we are ignored."}, {"heading": "IV. EXPERIMENTS", "text": "In this section, we describe the experimental protocol for evaluating data accuracy. As described in Section III, the movement data was captured by the setup consisting of Kinect 1, Kinect 2 and the Motion Capture System. We selected 12 different exercises (Table I, Fig. 2), consisting of six sitting (and seated) exercises and six standing exercises. In the first set, subjects interacted with the chair, while no props were used in the second set. We analyzed the two sets of exercises separately. We recorded the movement data in 10 subjects (average age: 27). Prior to the recording, each subject was instructed to perform the exercise via video. We first drew the motion setting sequence for the subsequent skeletal adjustment. Each recording of the exercise consisted of five repetitions, with the exception of jogging, where the subjects had to perform ten jogging steps."}, {"heading": "V. RESULTS AND DISCUSSION", "text": "In this section, we present a detailed analysis of the accuracy of pose tracking on Kinect 1 and Kinect 2 compared to the motion detection system we use as a starting point. All reported results are the averages of all subjects. Seated or standing pose scores represent the averages of all exercises performed while sitting or standing."}, {"heading": "A. Joint Position Accuracy", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "B. Bone Length Accuracy", "text": "Another important parameter for evaluating Kinect pose tracking performance is bone length. As previously mentioned, the Kinect tracking algorithm cannot specifically predefine or calibrate the anthropometric values of the body / bone segments. On the other hand, the human skeleton can be interpreted as a kinematic structure with rigid segments, so we expect the bone length to remain relatively constant. Therefore, the size of the variance (and SD) of the bone length over time can be interpreted as a measure of the frostiness of the extracted kinematic model. For the Kinect skeleton, we define the bone length as the l2 distance between the positions of two consecutive joints. On the other hand, the bone length for motion detection is determined during the calibration phase and remains constant during the motion sequence. Figures 12 and 13 show the mean values and SD of the bone length difference of Kinect 1 and Kinect 2 in comparison to the larger length of the Kinect."}, {"heading": "C. Summary of Findings", "text": "99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99"}, {"heading": "VI. CONCLUSION", "text": "In this paper, we compared the estimate of the human pose for the first and second generation of Microsoft Kinect with the standard motion capture technology. Results of our analysis showed that overall, Kinect 2 exhibits higher accuracy in collective estimation, while offering skeletal tracking that is more robust against occlusion and body rotation. Only the lower legs were tracked with large offsets, possibly due to ToF artifacts. This phenomenon was not observed in Kinect 1, which uses structured light for depth sensing. Kinect 1 observed the largest offsets in the pelvic area, as others have noted. Our analyses show that Kinect 1 can be exchanged with Kinect 2 for the majority of movements. Furthermore, by applying a mixture of Gaussian and uniform distribution models, we were able to evaluate the robustness of the pose tracking. We showed that joint position SDs can be reduced by 30% to 40% by using a mixed classification model."}], "references": [{"title": "Microsoft Kinect sensor and its effect", "author": ["Z. Zhang"], "venue": "MultiMedia, IEEE, vol. 19, no. 2, pp. 4\u201310, Feb 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["J. Shotton", "A. Fitzgibbon", "M. Cook", "T. Sharp", "M. Finocchio", "R. Moore", "A. Kipman", "A. Blake"], "venue": "Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Washington, DC, USA: IEEE Computer Society, 2011, pp. 1297\u20131304.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A review on technical and clinical impact of microsoft Kinect on physical therapy and rehabilitation", "author": ["H.M. Hondori", "M. Khademi"], "venue": "Journal of Medical Engineering, vol. 2014, p. 16, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Evaluation of an inexpensive depth camera for passive in-home fall risk assessment", "author": ["E.E. Stone", "M. Skubic"], "venue": "Proceedings of 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops, 2011, pp. 71\u201377.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Systematic review of Kinect applications in elderly care and stroke rehabilitation", "author": ["D. Webster", "O. Celik"], "venue": "Journal of Neuroengineering and Rehabilitation, vol. 11, p. 24, 2014.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Design and evaluation of an interactive exercise coaching system for older adults: Lessons learned", "author": ["F. Ofli", "G. Kurillo", "S. Obdrzalek", "R. Bajcsy", "H. Jimison", "M. Pavel"], "venue": "IEEE Journal of Biomedical and Health Informatics, p. 15, Epub ahead of print. 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Using Kinect sensor in observational methods for assessing postures at work", "author": ["J.A. Diego-Mas", "J. Alcaide-Marzal"], "venue": "Applied Ergonomics, vol. 45, no. 4, pp. 976\u2013985, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Pose estimation with a Kinect for ergonomic studies: Evaluation of the accuracy using a virtual mannequin", "author": ["P. Plantard", "E. Auvinet", "A.-S. Pierres", "F. Multon"], "venue": "Sensors, vol. 15, no. 1, pp. 1785\u20131803, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1803}, {"title": "Estimating anthropometry with microsoft Kinect", "author": ["M. Robinson", "M.B. Parkinson"], "venue": "Proceedings of the 2nd International Digital Human Modeling Symposium, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Enhanced computer vision with microsoft Kinect sensor: A review", "author": ["J. Han", "L. Shao", "D. Xu", "J. Shotton"], "venue": "IEEE Transactions on Cybernetics, vol. 43, no. 5, pp. 1318\u20131334, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Accuracy and resolution of Kinect depth data for indoor mapping applications", "author": ["K. Khoshelham", "S.O. Elberink"], "venue": "Sensors, vol. 12, no. 2, pp. 1437\u20131454, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "3D with Kinect", "author": ["J. Smisek", "M. Jancosek", "T. Pajdla"], "venue": "Proceedings of IEEE International Conference on Computer Vision Workshops (ICCV Workshops), Nov 2011, pp. 1154\u20131160.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Metrological comparison between Kinect I and Kinect II sensors", "author": ["H. Gonzalez-Jorge", "P. Rodr\u0131\u0301guez-Gonz\u00e0lvez", "J. Mart\u0131\u0301nez-S\u00e0nchez", "D. Gonz\u00e0lez-Aguilera", "P. Arias", "M. Gesto", "L. D\u0131\u0301az-Vilari\u00f1o"], "venue": "Measurement, vol. 70, pp. 21\u201326, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Evaluating and improving the depth accuracy of Kinect for Windows v2", "author": ["L. Yang", "L. Zhang", "H. Dong", "A. Alelaiwi", "A. El Saddik"], "venue": "Sensors Journal, IEEE, p. 11, Epub ahead of print. 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Accuracy and robustness of kinect pose estimation in the context of coaching of elderly population", "author": ["S. Obdrzalek", "G. Kurillo", "F. Ofli", "R. Bajcsy", "E. Seto", "H. Jimison", "M. Pavel"], "venue": "Proceedings of Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Aug 2012, pp. 1188\u20131193.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Validity of the Microsoft Kinect for assessment of postural control", "author": ["R.A. Clark", "Y.-H. Pua", "K. Fortin", "C. Ritchie", "K.E. Webster", "L. Denehy", "A.L. Bryant"], "venue": "Gait & Posture, vol. 36, no. 3, pp. 372 \u2013 377, 2012.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Evaluation of upper extremity reachable workspace using kinect camera", "author": ["G. Kurillo", "A. Chen", "R. Bajcsy", "J.J. Han"], "venue": "Technology and Health Care, vol. 21, no. 6, pp. 641\u2013656, Nov. 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Accuracy assessment of Kinect body tracker in instant posturography for balance disorders", "author": ["H. Funaya", "T. Shibata", "Y. Wada", "T. Yamanaka"], "venue": "Proceedings of 7th International Symposium on Medical Information and Communication Technology (ISMICT), March 2013, pp. 213\u2013217.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Validity and reliability of the Kinect within functional assessment activities: Comparison with standard stereophotogrammetry", "author": ["B. Bonnech\u00e8re", "B. Jansen", "P. Salvia", "H. Bouzahouene", "L. Omelina", "F. Moiseev", "V. Sholukha", "J. Cornelis", "M. Rooze", "S. Van Sint Jan"], "venue": "Gait & Posture, vol. 39, no. 1, pp. 593 \u2013 598, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Accuracy of the Microsoft Kinect sensor for measuring movement in people with Parkinson\u015b disease", "author": ["B. Galna", "G. Barry", "D. Jackson", "D. Mhiripiri", "P. Olivier", "L. Rochester"], "venue": "Gait & Posture, vol. 39, no. 4, pp. 1062 \u2013 1068, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Pose estimation with a Kinect for ergonomic studies: Evaluation of the accuracy using a virtual mannequin", "author": ["P. Plantard", "E. Auvinet", "A.-S.L. Pierres", "F. Multon"], "venue": "Sensors, vol. 15, no. 1, pp. 1785\u20131803, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1803}, {"title": "The validity of the first and second generation Microsoft Kinect for identifying joint center locations during static postures", "author": ["X. Xu", "R.W. McGorry"], "venue": "Applied Ergonomics, vol. 49, pp. 47 \u2013 54, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "An important milestone for wide adoption of these technologies was the release of Microsoft Kinect camera [1] for the gaming console Xbox 360 in 2010, followed by", "startOffset": 106, "endOffset": 109}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Many researchers and commercial developers embraced the Kinect in wide range of applications that took advantage of its real-time 3D acquisition capabilities and provided skeletal tracking, such as in physical therapy and rehabilitation [3], fall detection [4] and exercise in elderly [5], [6], ergonomics [7],", "startOffset": 237, "endOffset": 240}, {"referenceID": 3, "context": "Many researchers and commercial developers embraced the Kinect in wide range of applications that took advantage of its real-time 3D acquisition capabilities and provided skeletal tracking, such as in physical therapy and rehabilitation [3], fall detection [4] and exercise in elderly [5], [6], ergonomics [7],", "startOffset": 257, "endOffset": 260}, {"referenceID": 4, "context": "Many researchers and commercial developers embraced the Kinect in wide range of applications that took advantage of its real-time 3D acquisition capabilities and provided skeletal tracking, such as in physical therapy and rehabilitation [3], fall detection [4] and exercise in elderly [5], [6], ergonomics [7],", "startOffset": 285, "endOffset": 288}, {"referenceID": 5, "context": "Many researchers and commercial developers embraced the Kinect in wide range of applications that took advantage of its real-time 3D acquisition capabilities and provided skeletal tracking, such as in physical therapy and rehabilitation [3], fall detection [4] and exercise in elderly [5], [6], ergonomics [7],", "startOffset": 290, "endOffset": 293}, {"referenceID": 6, "context": "Many researchers and commercial developers embraced the Kinect in wide range of applications that took advantage of its real-time 3D acquisition capabilities and provided skeletal tracking, such as in physical therapy and rehabilitation [3], fall detection [4] and exercise in elderly [5], [6], ergonomics [7],", "startOffset": 306, "endOffset": 309}, {"referenceID": 7, "context": "[8] and anthropometry [9], computer vision [10], and many", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[8] and anthropometry [9], computer vision [10], and many", "startOffset": 22, "endOffset": 25}, {"referenceID": 9, "context": "[8] and anthropometry [9], computer vision [10], and many", "startOffset": 43, "endOffset": 47}, {"referenceID": 10, "context": "Khoshelman and Elbernik [11] examined the accuracy of depth acquisition in Kinect 1, and found that the depth error ranges from a few millimeters up to about 4 cm at the maximum range.", "startOffset": 24, "endOffset": 28}, {"referenceID": 11, "context": "[12] proposed a geometrical model and calibration method to improve the accuracy of Kinect 1 for 3D measurements.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] who reported that the precision of both systems is similar", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] who reported on the spatial distribution of the depth accuracy in regard to the vertical and horizontal displacement.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] performed accuracy and robustness analysis of the Kinect skeletal tracking in six exercises for elderly population.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] examined the clinical feasibility of using Kinect for postural control assessment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Several other works have examined the body tracking accuracy for specific applications in physical therapy, such as for example upper extremity function evaluation [17], assessment of balance disorders [18], full-", "startOffset": 164, "endOffset": 168}, {"referenceID": 17, "context": "Several other works have examined the body tracking accuracy for specific applications in physical therapy, such as for example upper extremity function evaluation [17], assessment of balance disorders [18], full-", "startOffset": 202, "endOffset": 206}, {"referenceID": 18, "context": "body functional assessment [19], and movement analysis in Parkinson\u2019s disease [20].", "startOffset": 27, "endOffset": 31}, {"referenceID": 19, "context": "body functional assessment [19], and movement analysis in Parkinson\u2019s disease [20].", "startOffset": 78, "endOffset": 82}, {"referenceID": 20, "context": "[21] performed an extensive evaluation of Kinect 1 skeletal tracking accuracy for ergonomic assessment.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "McGorry [22] is to date the only work that reported on the evaluation of Kinect 2 skeletal tracking alongside an optical motion capture system.", "startOffset": 8, "endOffset": 12}, {"referenceID": 11, "context": "The accuracy of the depth decreases with the square of the distance with typical accuracy ranging from about 1-4 cm in the range of 1-4 m [12].", "startOffset": 138, "endOffset": 142}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "various poses from a motion capture database [1].", "startOffset": 45, "endOffset": 48}, {"referenceID": 13, "context": "The depth accuracy of Kinect 2 is relatively constant within a specific capture volume, however it depends on the vertical and horizontal displacement as the light pulses are scattered away from the center of the camera [14].", "startOffset": 220, "endOffset": 224}], "year": 2015, "abstractText": "Microsoft Kinect camera and its skeletal tracking capabilities have been embraced by many researchers and commercial developers in various applications of real-time human movement analysis. In this paper, we evaluate the accuracy of the human kinematic motion data in the first and second generation of the Kinect system, and compare the results with an optical motion capture system. We collected motion data in 12 exercises for 10 different subjects and from three different viewpoints. We report on the accuracy of the joint localization and bone length estimation of Kinect skeletons in comparison to the motion capture. We also analyze the distribution of the joint localization offsets by fitting a mixture of Gaussian and uniform distribution models to determine the outliers in the Kinect motion data. Our analysis shows that overall Kinect 2 has more robust and more accurate tracking of human pose as compared to Kinect 1.", "creator": "LaTeX with hyperref package"}}}