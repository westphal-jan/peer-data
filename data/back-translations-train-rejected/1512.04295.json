{"id": "1512.04295", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Dec-2015", "title": "Origami: A 803 GOp/s/W Convolutional Network Accelerator", "abstract": "Today advanced computer vision (CV) systems of ever increasing complexity are being deployed in a growing number of application scenarios with strong real-time and power constraints. Current trends in CV clearly show a rise of neural network-based algorithms, which have recently broken many object detection and localization records. These approaches are very flexible and can be used to tackle many different challenges by only changing their parameters. In this paper, we present the first convolutional network accelerator which is scalable to network sizes that are currently only handled by workstation GPUs, but remains within the power envelope of embedded systems. The architecture has been implemented on 3.09 mm2 core area in UMC 65 nm technology, capable of a throughput of 274 GOp/s at 369 GOp/s/W with an external memory bandwidth of just 525 MB/s full-duplex - a decrease of more than 90% from previous work.", "histories": [["v1", "Mon, 14 Dec 2015 13:06:43 GMT  (685kb)", "http://arxiv.org/abs/1512.04295v1", null], ["v2", "Tue, 19 Jan 2016 22:56:41 GMT  (6233kb,D)", "http://arxiv.org/abs/1512.04295v2", "14 pages"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG cs.NE", "authors": ["lukas cavigelli", "luca benini"], "accepted": false, "id": "1512.04295"}, "pdf": {"name": "1512.04295.pdf", "metadata": {"source": "CRF", "title": "Origami: A Convolutional Network Accelerator", "authors": ["L. Cavigelli", "D. Gschwend", "C. Mayer", "S. Willi", "B. Muheim", "L. Benini"], "emails": ["benini}@iis.ee.ethz.ch,", "muheim}@ee.ethz.ch"], "sections": [{"heading": null, "text": "Current trends in the CV clearly show an increase in neural network-based algorithms that have recently broken many object detection and localization records. These approaches are very flexible and can be used to address many different challenges simply by changing their parameters. In this paper, we present the first revolutionary network accelerator that is scalable to network sizes that are currently only processed by workstation GPUs but remain within the performance range of embedded systems. The architecture has been implemented to 3.09 mm2 core range of UMC 65nm technology, capable of achieving a throughput of 274 GOp / s at 369 GOp / s / W with an external storage bandwidth of only 525 MB / s full duplex - a decrease of more than 90% over previous work areas. Categories and Subject Descriptors B.7.1 [Integrated Circuits]: Unique Design Algorithms - Signaling Algorithms V6, Selection2 [S6]"}, {"heading": "1. INTRODUCTION", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to change the world, and that we are able to change the world without destroying it."}, {"heading": "2. CONVOLUTIONAL NETWORKS", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2.1 Computational Effort", "text": "The evaluation of most real-world Convolutionary Networks is very demanding from a mathematical point of view. ConvNet, as mentioned above, has a real-time usage rate of 227 GOp / s at 30 frames / s, which is not possible with any available implementation, even on the latest commercially available mobile processors. Considering the hardware acceleration of algorithms in a fast-changing area such as deep learning, long-term usability must also be taken into account. As the structure of networks changes from application to application and over time, better activation features and pooling operations are found every year, so an overall accelerator is soon obsolete, but we can accelerate the commonality of all networks: convolution operation. Fortunately, this is also the most time-consuming part for well-optimized software implementations, with 89% of the total computing time for CPU and 79% for GPU implementations, as shown in Figure 1."}, {"heading": "3. PREVIOUS WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Software Implementations", "text": "Acceleration of Convolutionary Neural Networks has been discussed in many papers. There are very fast and user-friendly frameworks that are publicly available, such as Torch [11], Caffe [12], and cuDNN [13], especially due to the need to train the networks efficiently, and these and other optimized implementations can be used to maintain a performance baseline on desktop workstations and CUDA-compatible embedded processors such as the Tegra K1. On a GTX780 desktop GPU, performance for some specific problems can reach up to 3059 GOp / s and about 1800 GOp / s on meaningful ConvNets. On the Tegra K1, up to 96 GOp / s can be achieved, with 76 GOp / s achieved with an actual ConvNet. On both platforms, an energy efficiency of about 7 GOp / s / s / W can be achieved taking into account the performance of the entire platform and 14.4 GOp / s with different power measurements [10]."}, {"heading": "3.2 FPGA Implementations", "text": "A popular architecture is the one that began as CNP [14] and was further improved and renamed NeuFlow [15], [16], and later nn-X [17]. Released in 2009, the CNP achieved 12 GOp / s at 15W on a Spartan 3A DSP 3400 FPGA using 18-bit fixed-point arithmetic for multiplications. It is noteworthy that it is standalone, can perform all the operations required in ConvNets, and has a soft CPU. It also features a compiler that converts network implementations with Torch directly into CNP instructions. NeuFlow scaled CNP to multiple conversion engines that follow the data flow paradigm and enable runtime reconnection of the various processing blocks. The work released in 2011 includes a Virtex 6 VLX240T to rebuild 147 GOp / 11W networked storage with a new B16 MB of computing power."}, {"heading": "3.3 ASIC Implementations", "text": "In 2012, an ASIC implementation of NeuFlow [16], implemented in IBM 45nm SOI technology and using a chip area of 12.5 mm2, was published. It achieves an output of approximately 300 GOp / s at 0.6W operation at 400 MHz with an external memory bandwidth of GB / s full duplex. In order to extend the limits of what is possible in terms of energy efficiency, simulation results (pre-silicon) in ST 28nm FDSOI were recently published [18]. The process core was evaluated for individual rotations of various sizes suitable for ConvNets, reaching 37 GOp / s at 206 GOp / s at 0.8V and 1.39 GOp / s at 1375 GOp / s / W at 0.4V in the same implementation."}, {"heading": "3.4 Discussion", "text": "These existing implementations show that hardware accelerators are feasible for ConvNets with high energy efficiency, resulting in significant improvements over software implementations.However, none of the architectures is suitable for high performance applications due to memory interface limitations. The ASIC implementation of neuFlow has 299 I / O pins, around 300 GOp / s. Applying the above-mentioned ConvNet scene designation to larger images such as Full HD frames requires 5190 GOp / s to obtain 20 frames / s, and there is also a trend toward even more complex ConvNets. Simply scaling this architecture would require more than 5000 I / O pins, or about 110GB / s full duplex memory bandwidth, if based on the nn-X architecture. This problem is not specific to the new Flow / nn-X implementation, but to all architectures we know of."}, {"heading": "4. ARCHITECTURE & IMPLEMENTATION", "text": "An overarching diagram of the ASIC architecture shows Figure 2. It consists of data supply units for the filter weights and an image window, and four processing channels that calculate the sum of the products and accumulate the results. Data supplied by circuits runs mostly at a slower frequency that is compatible with the I / O drivers, while the data processing units operate at a faster clock frequency. In previous work, waves were executed by loading a filter, loading an input image, and performing a single fold to produce an output image. With our architecture, we aim to minimize the I / O bandwidth by taking advantage of the fact that we can load filters, load images, and run turns to generate output images after summarizing the results - effectively reducing the I / O ratio by a factor of nearly a quarter."}, {"heading": "4.1 Concept of Operation", "text": "Since we still want to keep the throughput per range high, we need to ensure that the required amount of SRAM and register memory is kept as small as possible, with no significant impact on performance. Therefore, we only store a moving, pixel-wide and maximum pixel-high spatial window of all input images in SRAM, as shown in Figure 4. The resulting memory has words of length bit. The current pixel working area is always kept in registers and is moved down one pixel row for one input image at a time, loading new pixels from SRAM at each cycle. As soon as it reaches the bottom of the image, it jumps back up and one pixel to the right, bringing the processing units to a standstill for () cycles. Actual calculations are made in running processing chains. Each processing chain comes with a sum of products (SoP) and a channel size of Summer (ChSum)."}, {"heading": "4.2 Fixed-Point Analysis", "text": "To determine the optimal data width for our design, we performed a fixed-point analysis based on our ConvNet reference. We replaced all folding operations in our software model with fixed-point versions thereof, and evaluated the resulting accuracy based on input, output, and weight data width. Quality was classified based on the accuracy of 150 test images per pixel released during training. We used the other 565 images of the Stanford Background Data Set [19] to train the network.Our results showed that a 12-bit output length was sufficient to keep implementation loss below a 0.5% drop in accuracy. Since the folding layers are repeatedly applied between them with low processing, we chose the same signal width for the input, although we could have further reduced it."}, {"heading": "4.3 Throughput", "text": "The peak throughput of this architecture is given by \u2044. At the edges of an image, no valid folding results can be calculated, so the core must wait until the necessary data is transferred to the device. These waiting times occur at the beginning for columns and at the beginning of each new line for cycles. Therefore, the effective throughput depends on the size of the image: () () For our reference network and the selected conversion parameters, this factor is 0.96, 0.91 and 0.82 for levels 1... 3, or in the case of a pixel input frame. for larger images, this is significantly improved, e.g. for an image, Stage 3 receives an efficiency factor of 0.91. However, the height of the input image is limited to 512 pixels due to the memory size of the image bank. If larger images are to be processed, they must be divided into horizontal strips with an overlap of rows."}, {"heading": "4.4 Implementation Summary", "text": "The ASIC is called ORIGAMI and was taped using UMC 65nm CMOS technology. The design includes several test measure designs, including scan chains and built-in self-tests for SRAM. The fast clock was generated by XORing two phase shifted 350MHz clock signals. Key values of the ASIC were shown in Table 3.After all these design decisions, the resulting final division of the range was shown in Figure 5."}, {"heading": "5. RESULTS & DISCUSSION", "text": "rf\u00fc ide eeirmtlrsrteeaeVnlrsrtee\u00fceegnn rf\u00fc ide rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the"}, {"heading": "6. CONCLUSION & FUTURE WORK", "text": "We have introduced the first ConvNet accelerator that is scalable to multiTOp / s performance by significantly improving the external storage bottleneck of previous architectures, is more area efficient than previously reported results, and has the lowest power consumption ever reported when I / O current and external memory are included. Further work with newer technologies, programmable logic, and further configurability to build an entire high-performance low-power system are planned in addition to studies in the ConvNet learning phase to adapt networks to very precise accelerators during training."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was funded by Armasuisse Science & Technology and the ERC MultiTherman project (ERC-AdG-291125)."}], "references": [{"title": "Video surveillance: past, present, and now the future [DSP Forum", "author": ["F. Porikli", "F. Bremond", "S.L. Dockstader", "J. Ferryman", "A. Hoogs", "B.C. Lovell", "S. Pankanti", "B. Rinner", "P. Tu", "P.L. Venetianer"], "venue": "IEEE Signal Process. Mag., vol. 30, pp. 190\u2013198, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Proc. NIPS\u201912, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Going Deeper with Convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "arXiv:1409.4842, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "arXiv:1312.6229, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Deepface: Closing the gap to human-level performance in face verification", "author": ["Y. Taigman", "M. Yang"], "venue": "Proc. IEEE CVPR\u201913, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Microsoft COCO: Common Objects in Context", "author": ["T.-Y. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "arXiv:1405.0312, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Internet inter-domain traffic", "author": ["C. Labovitz", "S. Iekel-Johnson", "D. McPherson", "J. Oberheide", "F. Jahanian"], "venue": "ACM SIGCOMM Computer Communication Review, vol. 40. p. 75, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "IEEE Trans. PAMI, 2013.  Figure 6: Post-layout chip graphic", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Accelerating Real-Time Embedded Scene Labeling with Convolutional Networks", "author": ["L. Cavigelli", "M. Magno", "L. Benini"], "venue": "Proc. DAC\u201915, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["R. Collobert"], "venue": "Proc. NIPSW\u201911, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Caffe: An Open Source Convolutional Architecture for Fast Feature Embedding.", "author": ["Y. Jia"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "cuDNN: Efficient Primitives for Deep Learning", "author": ["S. Chetlur", "C. Woolley", "P. Vandermersch", "J. Cohen", "J. Tran", "B. Catanzaro", "E. Shelhamer"], "venue": "arXiv:1410.0759, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "CNP: An FPGA-based processor for Convolutional Networks", "author": ["C. Farabet", "C. Poulet", "J.Y. Han", "Y. LeCun"], "venue": "Proc. IEEE FPL\u201909, 2009, vol. 1, no. 1, pp. 32\u201337.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "NeuFlow: A runtime reconfigurable dataflow processor for vision", "author": ["C. Farabet", "B. Martini", "B. Corda", "P. Akselrod", "E. Culurciello", "Y. LeCun"], "venue": "Proc. IEEE CVPRW\u201911, 2011, pp. 109\u2013116.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "NeuFlow: Dataflow vision processing system-on-a-chip", "author": ["P.H. Pham", "D. Jelaca", "C. Farabet", "B. Martini", "Y. LeCun", "E. Culurciello"], "venue": "Midwest Symposium on Circuits and Systems, 2012, pp. 1044\u20131047.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks", "author": ["V. Gokhale", "J. Jin", "A. Dundar", "B. Martini", "E. Culurciello"], "venue": "Proc. IEEE CVPR\u201914, 2014, pp. 682\u2013687.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "A Ultra-Low-Energy Convolution Engine for Fast Brain-Inspired Vision in Multicore Clusters", "author": ["F. Conti", "L. Benini"], "venue": "Proc. DATE\u201915, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Decomposing a scene into geometric and semantically consistent regions", "author": ["S. Gould", "R. Fulton", "D. Koller"], "venue": "Proc. IEEE ICCV\u201909, 2009.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "DRAM or no-DRAM ? Exploring Linear Solver Architectures for Image Domain Warping in 28 nm CMOS", "author": ["M. Schaffner", "F.K. G\u00fcrkaynak", "A. Smolic", "L. Benini"], "venue": "Proc. IEEE DATE\u201915, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION Today computer vision technologies are used with great success in many application areas, solving real-world problems in entertainment systems, robotics and surveillance [1].", "startOffset": 183, "endOffset": 186}, {"referenceID": 1, "context": "These \u201cdeep learning\u201d techniques are achieving record-breaking results on very challenging problems and datasets, outperforming more mature concepts trying to model the specific problem at hand [2]\u2013[4] or joining forces with them [5].", "startOffset": 194, "endOffset": 197}, {"referenceID": 3, "context": "These \u201cdeep learning\u201d techniques are achieving record-breaking results on very challenging problems and datasets, outperforming more mature concepts trying to model the specific problem at hand [2]\u2013[4] or joining forces with them [5].", "startOffset": 198, "endOffset": 201}, {"referenceID": 4, "context": "These \u201cdeep learning\u201d techniques are achieving record-breaking results on very challenging problems and datasets, outperforming more mature concepts trying to model the specific problem at hand [2]\u2013[4] or joining forces with them [5].", "startOffset": 230, "endOffset": 233}, {"referenceID": 2, "context": "Facebook, Google, Baidu, Microsoft, IBM), pushing towards deploying services based on braininspired machine learning to their customers within a production environment [3], [5], [6].", "startOffset": 168, "endOffset": 171}, {"referenceID": 4, "context": "Facebook, Google, Baidu, Microsoft, IBM), pushing towards deploying services based on braininspired machine learning to their customers within a production environment [3], [5], [6].", "startOffset": 173, "endOffset": 176}, {"referenceID": 5, "context": "Facebook, Google, Baidu, Microsoft, IBM), pushing towards deploying services based on braininspired machine learning to their customers within a production environment [3], [5], [6].", "startOffset": 178, "endOffset": 181}, {"referenceID": 0, "context": "This permits a new generation of distributed computer vision systems, which can bring huge value to a vast range of applications by reducing the costly data transmission, forwarding only the desired information [1], [7].", "startOffset": 211, "endOffset": 214}, {"referenceID": 6, "context": "This permits a new generation of distributed computer vision systems, which can bring huge value to a vast range of applications by reducing the costly data transmission, forwarding only the desired information [1], [7].", "startOffset": 216, "endOffset": 219}, {"referenceID": 1, "context": "Typical filter sizes range from to , sometimes even [2], [4], [9].", "startOffset": 52, "endOffset": 55}, {"referenceID": 3, "context": "Typical filter sizes range from to , sometimes even [2], [4], [9].", "startOffset": 57, "endOffset": 60}, {"referenceID": 7, "context": "Typical filter sizes range from to , sometimes even [2], [4], [9].", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "While we keep our implementation runtime-configurable to a large extent, we use the ConvNet presented in [10] as a reference for performance evaluation.", "startOffset": 105, "endOffset": 109}, {"referenceID": 9, "context": "There are very fast and user-friendly frameworks publicly available such as Torch [11], Caffe [12] and cuDNN [13], in particular also due to the need to train the networks efficiently.", "startOffset": 82, "endOffset": 86}, {"referenceID": 10, "context": "There are very fast and user-friendly frameworks publicly available such as Torch [11], Caffe [12] and cuDNN [13], in particular also due to the need to train the networks efficiently.", "startOffset": 94, "endOffset": 98}, {"referenceID": 11, "context": "There are very fast and user-friendly frameworks publicly available such as Torch [11], Caffe [12] and cuDNN [13], in particular also due to the need to train the networks efficiently.", "startOffset": 109, "endOffset": 113}, {"referenceID": 8, "context": "4 GOp/s/W with differential power measurements can be obtained [10].", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "A popular architecture is the one which started as CNP [14] and was further improved and renamed to NeuFlow [15], [16] and later on nn-X [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 13, "context": "A popular architecture is the one which started as CNP [14] and was further improved and renamed to NeuFlow [15], [16] and later on nn-X [17].", "startOffset": 108, "endOffset": 112}, {"referenceID": 14, "context": "A popular architecture is the one which started as CNP [14] and was further improved and renamed to NeuFlow [15], [16] and later on nn-X [17].", "startOffset": 114, "endOffset": 118}, {"referenceID": 15, "context": "A popular architecture is the one which started as CNP [14] and was further improved and renamed to NeuFlow [15], [16] and later on nn-X [17].", "startOffset": 137, "endOffset": 141}, {"referenceID": 8, "context": "Input size 240 320 117 157 55 75 Input channels 3 16 64 Output channels 16 64 256 # Operations 346 MOp 1682 MOp 5428 MOp # Filter values 2352 50176 802816 Figure 1: Computation time spent in different stages of our reference scene labeling ConvNet from [10].", "startOffset": 253, "endOffset": 257}, {"referenceID": 14, "context": "3 ASIC Implementations In 2012 an ASIC implementation of NeuFlow was published [16].", "startOffset": 79, "endOffset": 83}, {"referenceID": 16, "context": "To push the limits of what is possible in terms of energy efficiency, simulation (pre-silicon) results in ST 28nm FDSOI have recently been published [18].", "startOffset": 149, "endOffset": 153}, {"referenceID": 12, "context": "2 Fixed-Point Analysis Previous work is not conclusive on the required precision for ConvNets, 16 and 18 bit are the most common values [14], [15], [17], [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 13, "context": "2 Fixed-Point Analysis Previous work is not conclusive on the required precision for ConvNets, 16 and 18 bit are the most common values [14], [15], [17], [18].", "startOffset": 142, "endOffset": 146}, {"referenceID": 15, "context": "2 Fixed-Point Analysis Previous work is not conclusive on the required precision for ConvNets, 16 and 18 bit are the most common values [14], [15], [17], [18].", "startOffset": 148, "endOffset": 152}, {"referenceID": 16, "context": "2 Fixed-Point Analysis Previous work is not conclusive on the required precision for ConvNets, 16 and 18 bit are the most common values [14], [15], [17], [18].", "startOffset": 154, "endOffset": 158}, {"referenceID": 17, "context": "We used the other 565 images of the Stanford backgrounds dataset [19] to train the network.", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "7 MB/GOp for the neuFlow ASIC [16] or 20 MB/GOp for nn-X [17].", "startOffset": 30, "endOffset": 34}, {"referenceID": 15, "context": "7 MB/GOp for the neuFlow ASIC [16] or 20 MB/GOp for nn-X [17].", "startOffset": 57, "endOffset": 61}, {"referenceID": 16, "context": "490 GOp/s/W for the NeuFlow ASIC, and 207 GOp/s/W or even 1375 GOp/s/W in [18].", "startOffset": 74, "endOffset": 78}, {"referenceID": 18, "context": "If we consider only the energy used for the data interface of these architectures and assume LPDDR3 memory and a 28 nm implementation, an energy usage of 21 pJ/bit for memory module and PHY with a reasonable output load is realistic with a very high page hit rate and a perfectly-dimensioned memory (based on [20] and the Micron System Power Calculator with values for LPDDR3).", "startOffset": 309, "endOffset": 313}, {"referenceID": 16, "context": "The implementation of [18] suffers from the same issues, their superior energy efficiency in the processing core is gained with FDSOI technology which could also be applied to our architecture.", "startOffset": 22, "endOffset": 26}], "year": 2015, "abstractText": "Today advanced computer vision (CV) systems of ever increasing complexity are being deployed in a growing number of application scenarios with strong real-time and power constraints. Current trends in CV clearly show a rise of neural network-based algorithms, which have recently broken many object detection and localization records. These approaches are very flexible and can be used to tackle many different challenges by only changing their parameters. In this paper, we present the first convolutional network accelerator which is scalable to network sizes that are currently only handled by workstation GPUs, but remains within the power envelope of embedded systems. The architecture has been implemented on 3.09 mm core area in UMC 65 nm technology, capable of a throughput of 274 GOp/s at 369 GOp/s/W with an external memory bandwidth of just 525 MB/s full-duplex \u2013 a decrease of more than 90% from previous work.", "creator": "Microsoft\u00ae Word 2010"}}}