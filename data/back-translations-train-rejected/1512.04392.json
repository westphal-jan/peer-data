{"id": "1512.04392", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Dec-2015", "title": "Automatic Incident Classification for Big Traffic Data by Adaptive Boosting SVM", "abstract": "Modern cities experience heavy traffic flows and congestions regularly across space and time. Monitoring traffic situations becomes an important challenge for the Traffic Control and Surveillance Systems (TCSS). In advanced TCSS, it is helpful to automatically detect and classify different traffic incidents such as severity of congestion, abnormal driving pattern, abrupt or illegal stop on road, etc. Although most TCSS are equipped with basic incident detection algorithms, they are however crude to be really useful as an automated tool for further classification. In literature, there is a lack of research for Automated Incident Classification (AIC). Therefore, a novel AIC method is proposed in this paper to tackle such challenges. In the proposed method, traffic signals are firstly extracted from captured videos and converted as spatial-temporal (ST) signals. Based on the characteristics of the ST signals, a set of realistic simulation data are generated to construct an extended big traffic database to cover a variety of traffic situations. Next, a Mean-Shift filter is introduced to suppress the effect of noise and extract significant features from the ST signals. The extracted features are then associated with various types of traffic data: one normal type (inliers) and multiple abnormal types (outliers). For the classification, an adaptive boosting classifier is trained to detect outliers in traffic data automatically. Further, a Support Vector Machine (SVM) based method is adopted to train the model for identifying the categories of outliers. In short, this hybrid approach is called an Adaptive Boosting Support Vector Machines (AB-SVM) method. Experimental results show that the proposed AB-SVM method achieves a satisfied result with more than 92% classification accuracy on average.", "histories": [["v1", "Mon, 14 Dec 2015 16:23:59 GMT  (699kb)", "http://arxiv.org/abs/1512.04392v1", null], ["v2", "Mon, 28 Dec 2015 08:28:16 GMT  (504kb)", "http://arxiv.org/abs/1512.04392v2", "27 pages, 8 figures"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["li-li wang", "henry y t ngan", "nelson h c yung"], "accepted": false, "id": "1512.04392"}, "pdf": {"name": "1512.04392.pdf", "metadata": {"source": "CRF", "title": "Automatic Incident Classification for Big Traffic Data by Adaptive Boosting SVM", "authors": ["Li-Li Wang", "Henry Y.T. Ngan", "Nelson H.C. Yung"], "emails": ["llwang_hk@126.com,", "ytngan@hkbu.edu.hk,", "ypl.nyung@gmail.com"], "sections": [{"heading": null, "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "3.1 OD based on AdaBoost", "text": "Adaptive Increase (AdaBoost) is a specific method of machine learning used to train a number of weak classifiers (= J = 2.5).During the training process for AdaBoost, the weights of the training samples are adaptively updated after each iteration.The weights of the training samples wrongly classified by the current component classifier are increased, while the weights of the training samples are decreased with correct classification. \u2212 K Finally, the weak classifiers are combined linearly to form a strong classifier expressed by the current component classifier. G (H) IG = maxF value (H, G, JG, K value) IG (4), where h. Weak learner is, v denotes a feature vector in the PCA space, and G means that the fifth component of v is used as an input feature of v."}, {"heading": "3.2 Abnormal incidents classification based on SVMs", "text": "In machine learning, SVM technology [33] is widely used for classification problems. > > Compared to neural networks, SVM techniques are easy to implement and provide satisfactory classification results in a variety of applications, such as semantic image classification [34], handwritten recognition [35], and so on. In AB-SVM, we use SVMs [15] to classify abnormal traffic behavior in traffic data. \u2212 Experimental results show that the hybrid model performs superior to AIC. Let C use the set of abnormal traffic categories and a = & 1,..., 2 \"where L denotes the total number of outlier classes. \u2212 Given the M training samples from abnormal traffic signals, (*, P), (* b, Pb) where &'b is the set of input signals in RD, and the Label of input signals in D and D."}, {"heading": "3.3 Testing based on the trained AB-SVM classifier", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they are able to"}], "references": [{"title": "Empirical approaches to outlier detection in intelligent transportation systems data", "author": ["E.S. Park", "S. Turner", "C.H. Spiegelman"], "venue": "Transportation Research Record: Journal of the Transportation Research Board, vol. 1840, pp. 21-30, 2003.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1840}, {"title": "A survey of outlier detection methodologies", "author": ["V.J. Hodge", "J. Austin"], "venue": "Artificial Intelligence Review, vol. 22, pp. 85-126, 2004.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Performance evaluation for motif-based patterned texture defect detection", "author": ["H.Y. Ngan", "G.K. Pang", "N.H. Yung"], "venue": "Automation Science and Engineering, IEEE Transactions on, vol. 7, pp. 58-72, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparative study of outlier detection for large-scale traffic data by one-class SVM and kernel density estimation", "author": ["H.Y. Ngan", "N.H. Yung", "A.G. Yeh"], "venue": "IS&T/SPIE Electronic Imaging, 2015, pp. 94050I-94050I-10.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Distance-based k-nearest Neighbors Outlier Detection Method in Large-scale Traffic Data", "author": ["T.T. Dang", "H.Y.T. Ngan", "W.Liu"], "venue": "Proceedings of 2015 IEEE International Conference on Digital Signal Processing, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Procedures for detecting outlying observations in samples", "author": ["F.E. Grubbs"], "venue": "Technometrics, vol. 11, pp. 1-21, 1969.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1969}, {"title": "Outliers in statistical data vol", "author": ["V. Barnett", "T. Lewis"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Outlier detection using clustering methods: a data cleaning application", "author": ["A. Loureiro", "L. Torgo", "C. Soares"], "venue": "Proceedings of KDNet Symposium on Knowledge-based systems for the Public Sector, 2004.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Outlier detection: A survey,", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM Computing Surveys,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "A training algorithm for optimal margin classifiers,", "author": ["B.E. Boser", "I.M. Guyon", "V.N. Vapnik"], "venue": "Proceedings of the fifth annual workshop on Computational learning theory,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1992}, {"title": "An empirical comparison of supervised learning", "author": ["R. Caruana", "A. Niculescu-Mizil"], "venue": "Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Sharing features: efficient boosting procedures for multiclass object detection,", "author": ["A. Torralba", "K.P. Murphy", "W.T. Freeman"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Daily activity pattern recognition by using support vector machines with multiple classes,", "author": ["M. Allahviranloo", "W. Recker"], "venue": "Transportation Research Part B: Methodological,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "The class imbalance problem: A systematic study,", "author": ["N. Japkowicz", "S. Stephen"], "venue": "Intelligent data analysis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Addressing the curse of imbalanced training sets: one-sided selection,", "author": ["M. Kubat", "S. Matwin"], "venue": "in ICML,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1997}, {"title": "Using random forest to learn imbalanced data,", "author": ["C. Chen", "A. Liaw", "L. Breiman"], "venue": "University of California,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Outlier detection in traffic data based on the dirichlet process mixture model,", "author": ["H.Y.T. Ngan", "N.H.C. Yung", "Anthony G.O. Yeh"], "venue": "IET Intelligent Transport Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Freeway incident detection: technologies and techniques,", "author": ["J. Luk", "C. Han", "D.A. Chin"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Automated detection of lane-blocking freeway incidents using artificial neural networks,\" Transportation", "author": ["R.L. Cheu", "S.G. Ritchie"], "venue": "Research Part C: Emerging Technologies,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1995}, {"title": "Development and adaptation of constructive probabilistic neural network in freeway incident detection,", "author": ["X. Jin", "R.L. Cheu", "D. Srinivasan"], "venue": "Transportation Research Part C: Emerging Technologies,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "Support vector machine models for freeway incident detection,\" in Intelligent Transportation", "author": ["R.L. Cheu", "D. Srinivasan", "E.T. Teh"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Incident detection using support vector machines,", "author": ["F. Yuan", "R.L. Cheu"], "venue": "Transportation Research Part C: Emerging Technologies,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "An Automatic Incident of Freeway Detection Algorithm Based on Support Vector Machine,\" in Intelligence Information Processing and Trusted Computing (IPTC)", "author": ["Z. Zhou", "L.-y. Zhou"], "venue": "International Symposium on,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Thoughts on hypothesis boosting,", "author": ["M. Kearns"], "venue": "Unpublished manuscript,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1988}, {"title": "Cryptographic limitations on learning Boolean formulae and finite automata,", "author": ["M. Kearns", "L. Valiant"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1994}, {"title": "The strength of weak learnability,", "author": ["R.E. Schapire"], "venue": "Machine learning,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1990}, {"title": "Fast rotation invariant multi-view face detection based on real adaboost,\" in Automatic Face and Gesture Recognition, 2004. Proceedings", "author": ["B. Wu", "H. Ai", "C. Huang", "S. Lao"], "venue": "Sixth IEEE International Conference on,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2004}, {"title": "Pisarevsky, \"Empirical analysis of detection cascades of boosted classifiers for rapid object detection,\" in Pattern Recognition", "author": ["R. Lienhart", "A. Kuranov"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2003}, {"title": "Statistical learning theory vol", "author": ["V.N. Vapnik", "V. Vapnik"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1998}, {"title": "A Novel Algorithm for Imbalance Data Classification Based on Neighborhood Hypergraph,", "author": ["F. Hu", "X. Liu", "J. Dai", "H. Yu"], "venue": "The Scientific World Journal,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Feature fusion within local region using localized maximum-margin learning for scene categorization,", "author": ["J. Qin", "N.H. Yung"], "venue": "Pattern Recognition,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Model selection for the LS-SVM. Application to handwriting recognition,", "author": ["M.M. Adankon", "M. Cheriet"], "venue": "Pattern Recognition,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "On the algorithmic implementation of multi-class SVMs,", "author": ["K. Krammer", "Y. Singer"], "venue": "Proc. of JMLR,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "Comparing support vector machines with Gaussian kernels to radial basis function classifiers,", "author": ["B. Scholkopf", "K.-K. Sung", "C.J. Burges", "F. Girosi", "P. Niyogi", "T. Poggio"], "venue": "Signal Processing, IEEE Transactions on,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1997}, {"title": "Which is the best multiclass SVM method? An empirical study,\" in Multiple Classifier", "author": ["K.-B. Duan", "S.S. Keerthi"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2005}, {"title": "LIBSVM: a library for support vector machines,", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "In recent years, studies have been published for outlier detection (OD) [1-5].", "startOffset": 72, "endOffset": 77}, {"referenceID": 1, "context": "In recent years, studies have been published for outlier detection (OD) [1-5].", "startOffset": 72, "endOffset": 77}, {"referenceID": 2, "context": "In recent years, studies have been published for outlier detection (OD) [1-5].", "startOffset": 72, "endOffset": 77}, {"referenceID": 3, "context": "In recent years, studies have been published for outlier detection (OD) [1-5].", "startOffset": 72, "endOffset": 77}, {"referenceID": 4, "context": "In recent years, studies have been published for outlier detection (OD) [1-5].", "startOffset": 72, "endOffset": 77}, {"referenceID": 5, "context": "In [6, 7], the purpose of an OD is to identify data points appearing inconsistent with the majority of the data (inliers).", "startOffset": 3, "endOffset": 9}, {"referenceID": 6, "context": "In [6, 7], the purpose of an OD is to identify data points appearing inconsistent with the majority of the data (inliers).", "startOffset": 3, "endOffset": 9}, {"referenceID": 0, "context": "in many areas, for example, [1] suggested aircraft engine rotation defect detection, heart-rate monitors and fabric defect detection, or [3] mentioned traffic abnormality detection.", "startOffset": 28, "endOffset": 31}, {"referenceID": 2, "context": "in many areas, for example, [1] suggested aircraft engine rotation defect detection, heart-rate monitors and fabric defect detection, or [3] mentioned traffic abnormality detection.", "startOffset": 137, "endOffset": 140}, {"referenceID": 7, "context": "The common unsupervised methods include clustering-based method [8], distance-based method [9], and density-based method [10].", "startOffset": 64, "endOffset": 67}, {"referenceID": 8, "context": "The common unsupervised methods include clustering-based method [8], distance-based method [9], and density-based method [10].", "startOffset": 91, "endOffset": 94}, {"referenceID": 7, "context": "The clustering-based approach [8] defines an observation as an outlier if it deviates from the overall clustering pattern.", "startOffset": 30, "endOffset": 33}, {"referenceID": 8, "context": "The distance-based approach [9] assumes an observation is an outlier if the distances of a certain percentage of samples from a datum are larger than a given threshold.", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "To identify the category of each outlier, one can resort to supervised learning approach [11-15].", "startOffset": 89, "endOffset": 96}, {"referenceID": 10, "context": "To identify the category of each outlier, one can resort to supervised learning approach [11-15].", "startOffset": 89, "endOffset": 96}, {"referenceID": 11, "context": "To identify the category of each outlier, one can resort to supervised learning approach [11-15].", "startOffset": 89, "endOffset": 96}, {"referenceID": 12, "context": "To identify the category of each outlier, one can resort to supervised learning approach [11-15].", "startOffset": 89, "endOffset": 96}, {"referenceID": 11, "context": "In the literature, SVM [14] and adaptive boosting techniques [15] are the most popular methods and have achieved better classification performance than others.", "startOffset": 23, "endOffset": 27}, {"referenceID": 12, "context": "In the literature, SVM [14] and adaptive boosting techniques [15] are the most popular methods and have achieved better classification performance than others.", "startOffset": 61, "endOffset": 65}, {"referenceID": 13, "context": "In [16], SVM-based method was successfully applied to recognize daily activity pattern for the forecasting purpose of travel demand.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "Adaptive boosting technique [15] as an ensemble method is capable of training a strong classifier by combining a series of", "startOffset": 28, "endOffset": 32}, {"referenceID": 12, "context": "This method has been proven [15] to boost classification accuracy.", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "If the imbalanced data set is used for learning, the performance of the learning algorithm(s) would degrade significantly [17], as most methods tend to build the classifiers from the majority category of data.", "startOffset": 122, "endOffset": 126}, {"referenceID": 15, "context": "The commonly used methods include performing data redistribution [18] or classifier modification [19].", "startOffset": 65, "endOffset": 69}, {"referenceID": 16, "context": "The commonly used methods include performing data redistribution [18] or classifier modification [19].", "startOffset": 97, "endOffset": 101}, {"referenceID": 17, "context": "As discussed in our previous work [20], big traffic data are easily contaminated with noise during data collection.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "Traffic incident is one of the major reasons [21] to traffic congestions.", "startOffset": 45, "endOffset": 49}, {"referenceID": 19, "context": "Among these algorithms, machine learning algorithms [22-27] are most popular and widely investigated.", "startOffset": 52, "endOffset": 59}, {"referenceID": 20, "context": "Among these algorithms, machine learning algorithms [22-27] are most popular and widely investigated.", "startOffset": 52, "endOffset": 59}, {"referenceID": 21, "context": "Among these algorithms, machine learning algorithms [22-27] are most popular and widely investigated.", "startOffset": 52, "endOffset": 59}, {"referenceID": 22, "context": "Among these algorithms, machine learning algorithms [22-27] are most popular and widely investigated.", "startOffset": 52, "endOffset": 59}, {"referenceID": 23, "context": "Among these algorithms, machine learning algorithms [22-27] are most popular and widely investigated.", "startOffset": 52, "endOffset": 59}, {"referenceID": 24, "context": "Among these algorithms, machine learning algorithms [22-27] are most popular and widely investigated.", "startOffset": 52, "endOffset": 59}, {"referenceID": 19, "context": "In [22], multi-layer feedforward ANN (MLFANN) was used to detect incidents and showed better AID performance.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "In [23], Jin et.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "To further improve AID performance, SVM [24-26] was investigated to detect outliers.", "startOffset": 40, "endOffset": 47}, {"referenceID": 22, "context": "To further improve AID performance, SVM [24-26] was investigated to detect outliers.", "startOffset": 40, "endOffset": 47}, {"referenceID": 23, "context": "To further improve AID performance, SVM [24-26] was investigated to detect outliers.", "startOffset": 40, "endOffset": 47}, {"referenceID": 21, "context": "Experimental results in [24] show that SVM can generate better AID performance than ANN.", "startOffset": 24, "endOffset": 28}, {"referenceID": 22, "context": "In [25], Yuan and Cheu", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "This concept is first proposed by Kearns and Valiant in 1988 and 1989 [27, 28].", "startOffset": 70, "endOffset": 78}, {"referenceID": 25, "context": "This concept is first proposed by Kearns and Valiant in 1988 and 1989 [27, 28].", "startOffset": 70, "endOffset": 78}, {"referenceID": 26, "context": "The initial one was proposed by Freund in 1995 [29].", "startOffset": 47, "endOffset": 51}, {"referenceID": 27, "context": "In order to adapt to the weak learners, adaptive boosting (AdaBoost) algorithms, such as Real AdaBoost [30], Gentle AdaBoost [31] and others, were developed.", "startOffset": 103, "endOffset": 107}, {"referenceID": 28, "context": "In order to adapt to the weak learners, adaptive boosting (AdaBoost) algorithms, such as Real AdaBoost [30], Gentle AdaBoost [31] and others, were developed.", "startOffset": 125, "endOffset": 129}, {"referenceID": 29, "context": "Due to the outstanding performance of adaptive boosting methods, they have been applied to solve imbalanced dataset problems [32].", "startOffset": 125, "endOffset": 129}, {"referenceID": 30, "context": "In the field of machine learning, SVM technique [33] is widely used for classification problem.", "startOffset": 48, "endOffset": 52}, {"referenceID": 31, "context": "Compared with neural networks, SVM techniques are easy to be implemented and to offer satisfactory classification results in a wide variety of application domains, such as semantic image classification [34], handwritten recognition [35], and so on.", "startOffset": 202, "endOffset": 206}, {"referenceID": 32, "context": "Compared with neural networks, SVM techniques are easy to be implemented and to offer satisfactory classification results in a wide variety of application domains, such as semantic image classification [34], handwritten recognition [35], and so on.", "startOffset": 232, "endOffset": 236}, {"referenceID": 12, "context": "In the AB-SVM, we apply SVMs [15] to classify abnormal traffic behaviors in traffic data.", "startOffset": 29, "endOffset": 33}, {"referenceID": 33, "context": "By introducing Lagrange multipliers &: ' M and dual transformation [36-38], the model parameters ( , [, j, :) are obtained.", "startOffset": 67, "endOffset": 74}, {"referenceID": 34, "context": "By introducing Lagrange multipliers &: ' M and dual transformation [36-38], the model parameters ( , [, j, :) are obtained.", "startOffset": 67, "endOffset": 74}, {"referenceID": 35, "context": "By introducing Lagrange multipliers &: ' M and dual transformation [36-38], the model parameters ( , [, j, :) are obtained.", "startOffset": 67, "endOffset": 74}], "year": 2015, "abstractText": "Modern cities experience heavy traffic flows and congestions regularly across space and time. Monitoring traffic situations becomes an important challenge for the Traffic Control and Surveillance Systems (TCSS). In advanced TCSS, it is helpful to automatically detect and classify different traffic incidents such as severity of congestion, abnormal driving pattern, abrupt or illegal stop on road, etc. Although most TCSS are equipped with basic incident detection algorithms, they are however crude to be really useful as an automated tool for further classification. In literature, there is a lack of research for Automated Incident Classification (AIC). Therefore, a novel AIC method is proposed in this paper to tackle such challenges. In the proposed method, traffic signals are firstly extracted from captured videos and converted as spatial-temporal (ST) signals. Based on the characteristics of the ST signals, a set of realistic simulation data are generated to construct an extended big traffic database to cover a variety of traffic situations. Next, a Mean-Shift filter is introduced to suppress the effect of noise and extract significant features from the ST signals. The extracted features are then associated with various types of traffic data: one normal type (inliers) and multiple abnormal types (outliers). For the classification, an adaptive boosting classifier is trained to detect outliers in traffic data automatically. Further, a Support Vector Machine (SVM) based method is adopted to train the model for identifying the categories of outliers. In short, this hybrid approach is called an Adaptive Boosting Support Vector Machines (AB-SVM) method. Experimental results show that the proposed AB-SVM method achieves a satisfied result with more than 92% classification accuracy on average.", "creator": "PScript5.dll Version 5.2.2"}}}