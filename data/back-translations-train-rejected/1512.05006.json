{"id": "1512.05006", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Dec-2015", "title": "BayesDB: A probabilistic programming system for querying the probable implications of data", "abstract": "Is it possible to make statistical inference broadly accessible to non-statisticians without sacrificing mathematical rigor or inference quality? This paper describes BayesDB, a probabilistic programming platform that aims to enable users to query the probable implications of their data as directly as SQL databases enable them to query the data itself. This paper focuses on four aspects of BayesDB: (i) BQL, an SQL-like query language for Bayesian data analysis, that answers queries by averaging over an implicit space of probabilistic models; (ii) techniques for implementing BQL using a broad class of multivariate probabilistic models; (iii) a semi-parametric Bayesian model-builder that auomatically builds ensembles of factorial mixture models to serve as baselines; and (iv) MML, a \"meta-modeling\" language for imposing qualitative constraints on the model-builder and combining baseline models with custom algorithmic and statistical models that can be implemented in external software. BayesDB is illustrated using three applications: cleaning and exploring a public database of Earth satellites; assessing the evidence for temporal dependence between macroeconomic indicators; and analyzing a salary survey.", "histories": [["v1", "Tue, 15 Dec 2015 23:09:41 GMT  (8163kb,D)", "http://arxiv.org/abs/1512.05006v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["vikash mansinghka", "richard tibbetts", "jay baxter", "pat shafto", "baxter eaves"], "accepted": false, "id": "1512.05006"}, "pdf": {"name": "1512.05006.pdf", "metadata": {"source": "CRF", "title": "BayesDB: A probabilistic programming system for querying the probable implications of data", "authors": ["Vikash Mansinghka", "Richard Tibbetts", "Jay Baxter"], "emails": ["vkm@mit.edu", "tibbetts@mit.edu", "jbaxter@mit.edu", "p.shafto@louisville.edu", "b0eave01@louisville.edu"], "sections": [{"heading": null, "text": "Acknowledgements: VKM would like to thank Alexey Radul, Feras Saad and Taylor Campbell for their helpful discussions and contributions to a prototype implementation supported by DARPA (under the XDATA and PPAML programs), IARPA (under the 2015-15061000003 research contract), the Office of Naval Research (under the N000141310333 research contract), the Army Research Office (under contract number W911NF-131-0212), the Bill & Melinda Gates Foundation, and donations from Analog Devices and Google."}, {"heading": "1. Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "1.1 A conceptual illustration", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. Example Analyses", "text": "This section describes three applications of the current BayesDB prototype: 1. Research and cleaning up a public database of terrestrial satellites; 2. Evaluation of evidence of dependencies between indicators of global poverty; 3. Analysis of data from a salary survey. BQL and MML constructs are introduced via real-world applications; a discussion of their formal interpretation is offered in later sections."}, {"heading": "2.1 Exploring and cleaning a public database of Earth satellites", "text": "The Union of Concerned Scientists maintains a database of 1000 terrestrial satellites. It includes kinematic, material, electrical, political, functional and economic characteristics such as dry matter, launch date, orbit type, country of operation and purpose for most satellites. Here we show a sequence of interactions with a snapshot of this database using BayesDB's bayeslite implementation."}, {"heading": "2.1.1 Inspecting the data.", "text": "The first step is to create a population from the raw data: CREATE POPULATION Satellites FROM ucs _ database.csvA natural query consists of finding the International Space Station, a known satellite: SELECT * FROM Satellites WHERE Name LIKE 'International Space Station%' Variable Value Name International Space Station (ISS...) Land _ des _ Operator Multinational Operator _ Owner NASA / Multinational Users Government _ Purpose Scientific Research Class _ of _ Orbit _ LEO Type _ of _ Orbit _ Intermediate Perigee _ km _ 401 Apogee _ km _ 422 Eccentricity 0.00155 Period _ minutes _ 92.8 Launch _ Mass _ kg NaN _ Dry _ watts _ Mass _ watts _ LEO Type _ of _ Orbit _ Intermediate Perigee _ km _ 401 Apogee _ km _ 422 Eccentricity _ Univerle _ minutes _ Univerle _ Univerle _ Univerle _ Univerle _ minutes _ Univerle _ Univerle _ Univerle _ Univerle _ Universelect _ Univerle _ Univerle _ km _ Universelect _ Univerle _ km _ Universelect _ km _ Universelect _ km _ km _ Universelect _ Univerle _ Univerle _ km _ Universelect _ km _ Universelect _ km _ km _ Universelect _ km _ km _ Universelect _ km _ km _ Universelect _ km _ Universelect _ Univerle _ km _ km _ Universelect _ km _ Universelect _ Univerle _ km _ km _ Universelect _ Univerle _ km _ Universelect _ km _ Universelect _ km _ Universelect _ km _ km _ Universelect _ km _ Universelect _ km _ Universelect _ km _ Universelect _ km _ km _ Universelect _ Universelect _ minutes Universelect _ Universelect _ Univerle _ Universelect _ Univerle _ Univerle _ Univerle _ Univerle _ Univerle _ Univerle"}, {"heading": "2.1.2 Building baseline models.", "text": "The next two MML statements form a collection of 16 models, which require a total of approximately 4 minutes of analysis time.INITIALIZE 16 MODELS FOR SATELS; ANALYZE satellites FOR 4 MINUTES WAIT; each of the 16 models is a separate GPM generated by an independent Markov chain for approximate posterior samples in the previously described semi-parametric factor mixing metmodel. This number of models and the scope of the calculation is typical of the exploratory analyses performed with our prototype implementation; this is sufficient for approximately 100 complete passes of all latent variables."}, {"heading": "2.1.3 Answering hypotheticals.", "text": "The satellite database should, in principle, contain the answers to a broad class of hypothetical or \"what if\" questions. For example, the following question is asked: Suppose you receive a report indicating the presence of a previously undetected satellite in geosynchronous orbit with a dry mass of 500 kilograms. Answering this question requires knowledge of satellite technology, orbital mechanics and the geopolitics of the satellite industry. It is easy to answer this question with BQL. The most important step is to create a synthetic population of satellites that reflect the given constraints."}, {"heading": "2.1.4 Identifying predictive relationships between variables.", "text": "An important exploratory task is to identify those variables in the database that appear to predict each other. This is closely related to the key question of confirmatory analysis of the evidence for a predictive relationship between two particular variables. To quantify the evidence for (or against) a predictive relationship between two pairs of variables, BQL relies on information theory. The notion of dependence between two variables A and B is assumed to be mutual information; the amount of evidence for dependence is then the probability that the mutual information between A and B is nonzero. If the population models are determined by posteriors in a meta model - as is the case with MML - this probability approaches the posterior probability (or strength of evidence) that the mutual information is null. ESTIMATE DEPENDENCE PROBILITY FROM PAIRWISE COLUMNS OF satellites."}, {"heading": "2.1.5 Detecting multivariate anomalies.", "text": "Another key aspect of exploratory analysis is the identification of anomalous values, including both (univariate) outliers and multivariate anomalies. Anomalies can occur due to errors in data acquisition, bugs in upstream pre-processing software (including binning of continuous variables or translation between various discrete results), and runtime failures. Anomalies can also occur due to real surprises or changes in the external environment. BQL allows multivariate anomalies to be detected by evaluating the predictive probability density of each measurement, and ordering from least to most likely."}, {"heading": "2.1.6 Inferring missing values.", "text": "A key application of predictive modeling is to derive point predictions from missing measurements. This may be necessary to purify data prior to downstream processing. It may also be of intrinsic interest, e.g. for classification problems. The satellite database contains many missing values. Here we show an INFER query that indicates missing orbit types and provides both a point estimate and the reliability in this point estimate: INFER EXPLICIT expected _ life, perigee _ km, period _ minutes, class _ of _ orbit, PREDICT type _ of _ orbit AS inferred _ orbit _ type CONFIDENCE inferred _ orbit _ type _ conf FROM satellites WHERtype _ of _ orbit IS NULL; this form of INFER uses the EXPLICIT modifier, which includes both predicted values and their associated reliability values in the output showing a visualization of the results 3."}, {"heading": "2.1.7 Integrating a kinematic model for elliptical orbits.", "text": "In fact, it is as if most of us are able to keep to the rules that they have imposed on themselves, and that they are able to keep to the rules that they have imposed on themselves. (...) It is not as if they keep to the rules. (...) It is not as if they keep to the rules. (...) It is as if they keep to the rules. (...) It is as if they keep to the rules. (...) It is as if they keep to the rules. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are able. (...)"}, {"heading": "2.1.8 Combing random forests, causal models, and nonparametric Bayes.", "text": "Since MML supports model composition, it is easy to create hybrid models that incorporate techniques from sub-areas of machine learning that seem to conflict. Figure 6 shows the transcript of a full MML session that builds such a hybrid model. Random forests are used to classify orbits into types; Kepler's laws are used to relate periods, perigee, and apogee; and the semi-parametric Bayesian meta-model is used for all remaining variables (with two variables associated with outdated data types). Later sections of this paper explain how these three modeling approaches are combined to answer individual BQL queries."}, {"heading": "2.2 Assessing the evidence for dependencies between indicators of global poverty", "text": "In the early 21st century, the solution to extreme poverty is widely believed to be achieved around the world by empowering individuals to eradicate poverty. Governments and NGOs promote this process through a variety of interventions, many of which combine material support with policy change. In principle, policy should be driven by a quantitative data-driven understanding of international economic development. In practice, international economic data is sparse, unreliable, and highly aggregated; these data constraints create significant barriers to understanding the situational context of successful or unsuccessful interventions and policies."}, {"heading": "2.2.1 Exploring the Data with SQL", "text": "The raw form of the data consists of about 500 Excel tables, each containing longitudinal data for 300 countries over a period of over 100 years. However, the data set contains only 2 million observations, or 97% of the data is missing. Figure 7 shows key indicators for the data around size, missing data sets and the relationship between data availability and countries, data sets and years. Primary data is modelled in SQL as a tabular structure. This relatively normalized representation easily models the sparse matrix and allows us to use a combination of SQL and Python data science tools to build our population structures. Figure 7 \"s histograms show the breadth and also the variability of the data. The histogram by year in Figure 7a shows that the data is complete only for recent history, and that some predicted data persists into the future, and that data for some indicators is only available every 10 years."}, {"heading": "2.2.2 Detecting Basic and Longitudinal Dependence", "text": "Our analysis focuses on the 53 variables with the most complete data for the years 1999-2008. It is easy to create an interplay of models for this subset: GUESS POPULATION SCHEMA FOR dense _ gapminder; INITIALIZE 64 MODELS FOR dense _ gapminder; ANALYZE todo FOR 300 MINUTES WAIT; The probability of dependence Heatmap, the results are in Figure 8. Indicators such as total population and urban percentage form blocks that contain their values for every 10 years contained in the data set. This also shows that the standard GPM was able to extract the temporal dependence in these indicators. In other cases, such as measurements of the number of people killed in floods, the year-by-year dependence is much weaker. The heatmap also shows the dependence between indicators, such as the block in the upper right corner, the 2002 fertility indicators, and the year of urbanization on the basis of the year 8G for fertility dependence."}, {"heading": "2.2.3 Measuring the Similarity of Countries", "text": "In order to help in the delivery of international assistance and the design and analysis of interventions, policymakers often want to better understand the similarities between countries. BQL enables us to formulate these questions in general or on the basis of specific attributes. Figure 10 shows country similarities for different indicators. As expected, a change in the interest indicator can lead to very different similarity structures. Analyses that require a single global similarity metric cannot address this context-specific structure. The authors are involved in an ongoing research partnership with the Bill and Melinda Gates Foundation, which aims to integrate the Gapminder data with other relevant sources, including qualitative knowledge from domain experts, and to use it to advance empirically based policies and tools."}, {"heading": "2.3 Analyzing a salary survey", "text": "Surveys are a common source of multivariate data and a potentially attractive application for BayesDB. Here we show a preliminary analysis of a web-managed anonymous salary survey. Participants shared their compensation details with information about their titles, years of service, benefits, employer and geography."}, {"heading": "2.4 Controlling Models with Qualitative Assumptions", "text": "In this case, the initial analysis of the remuneration data concludes that geographical location (state, region) is not a factor in the remuneration. Domain experts suggest that this is not plausible, that the cost of living and the competitive market in different cities are an essential factor in the remuneration of survey participants. The following code can be used to apply this qualitative assumption: AGE METAMODELL FOR salary, equality, base, bonus DEPENDENT"}, {"heading": "ON state;", "text": "After a qualitative limitation is applied, the probability of dependence changes. Not only are the squares that imply this dependency colored to 1.0, but other columns have also been reoriented in their modelling. In particular, given this assumption, there seems to be more evidence of dependence between the 2012-2013 measures and core indicators, such as years in the job, bonus, the presence of capital participation, etc., and there seems to be less evidence that the job title influences the most important remuneration variables."}, {"heading": "3. The Bayesian Query Language", "text": "The Bayesian Query Language (BQL) formalizes Bayesian data analysis without exposing end-user parameters, pros and cons. This section describes the statistical operations implemented by the core BQL command set, and describes the modelling formalism used to implement BQL."}, {"heading": "3.1 Generative Population Models", "text": "BQL programs are run using a set whose index cannot be related to actual ratios; GPMs can be built in two ways: 1. Directly specified as external software libraries; 2. Derived from data about a probable inference in a metamodel used in BayesDB's Metamodeling Language.GPMs can respond to requests about the common distribution of the underlying data that generate the process as a whole or about the predictive distribution for a particular member of the population.The population can be thought of as a table in which individual members are represented by row indexes.Each GPM induces a random table with a finite number of columns and an infinite number of rows in which each cell contains a random variable. BQL treats each BayesDB component as a model of the data generation process underlying its associated observation table. It is sometimes useful to ask a GPM about hypothetical members of the population."}, {"heading": "3.1.1 An interface to generative population models", "text": "It ensures that the storage of data for the random variables for both the global latent variables and the local latent variables depends on the specified distribution. (rj) It ensures that the data for the global latent variables and the local latent variables can be derived from the specified distribution. (rj) It ensures that the data for the global latent variables and the local latent variables can be derived from the specific distribution. (rj) It ensures that the global latent variables and the local latent variables can differ from the specific distribution. (rj) It ensures that the global latent variables and the local latent variables can differ from the specific distribution. (rj) It can differ from the specific distribution. (rk) It can differ from the distribution. (rj)"}, {"heading": "3.1.2 Weighted collections of generative population models.", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "3.3 Model and data independence", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "4. Modeling with the Meta-Modeling Language", "text": "BayesDB also provides the Meta-Modeling Language (MML), a probabilistic programming language for creating models of data tables. MML programs consist of modeling tactics that control the behavior of an automatic modeling engine. These tactics take several forms: statistical data types; initialization of weighted collections of random models; roughly Bayesian model collection updating; qualitative assertions of dependence and independence between variables; and the use of custom statistical models for certain conditional distributions. All of these tactics are currently being implemented in the sense of a unifying semi-parametric Bayesian model that takes into account all unspecified aspects."}, {"heading": "4.1 Statistical datatypes", "text": "These metadata restrict the probability models used for each column and can also be used to select suitable visualizations. It is easy to support several different types of data: 1. Categorical values from a closed set. This type of data contains a dictionary that maps the raw data (often strings) to canonical numerical indices for efficient storage and processing, and this information can also be used to inform modeling tactics. In the current version of MML, for example, closed group categorical variables are generatively modelled via a multinomial component model with a symmetrical dirichlet in front of the parameters (Mansinghka et al., 2015). Discriminative closed category column models could potentially use a multinomial logit link function or schematize a suitable multi-class classification schematization.2. Binary data of this kind are generatively modelled using a symmetrical learning-beta2015 Bernini model."}, {"heading": "4.2 Bayesian generative population meta-models", "text": "Some data generators can be learned from data. Often, the learning mechanism is based on approximate probable conclusions in a metamodel: a probable model defined over a space of data generators, each of which is also a separate probable model. So far, all BayesDB metamodels have been Markov chain metamodels. These metamodels maintain internally a single sample from an approximate back range and provide a Markov chain transition operator that updates this sample stochastically. 1. G = (cj, x, cj) = initialize (Meta schema =) initializes a new metamodel with arbitrary parameters and an associated tabular data store. 2. Integrate (id = r, values = {(cj, cj)) = Specific is the ability to assign to the population (Meta schema =)."}, {"heading": "4.2.1 Controlling inference via INITIALIZE and ANALYZE.", "text": "These capabilities are revealed by two commands: 1. INITIALIZE k MODELS FOR populationThis command creates models by scanning their structure and parameters from the underlying GPM's prior. This is implemented by delegation to initialize the entire MML schema so far. 2. ANALYZE [Variable Subset OF] population FOR timelimitThis command roughly performs a Bayean update of the models in the weighted collection by delegating the infer () procedure from the underlying GPM to the underlying GPM. Here is a typical call: ANALYZE my _ population FOR 10 MINUTESIf no variable subset is provided, an analysis of all the latent variables associated with each GPM in the weighted collection is performed. Fine-grained control is also possible with variable subset specifiers that select specific portions of paper that exceed this latent PM range."}, {"heading": "4.3 Qualitative constraints", "text": "The BayesDB MML provides constructs to specify qualitative constraints on dependency and independence relationships (Pearl, 1988), and the modelling machine attempts to enforce these constraints in all GPMs1. These constraints are specified as follows: ALTER METAMODEL FOR population ENSURE colA IS [NOT] MARGINAL DEPENDENT"}, {"heading": "ON colB", "text": "It is also possible to INITIALIZE and ANALYZE models that do not respect the restrictions and then enforce them retrospectively: OLD MODELS FOR THE PEOPLE ensure that COLA IS [NOT] MARGINALLY DEPENDENT."}, {"heading": "ON colB", "text": "These commands allow domain experts to apply qualitative knowledge to make better use of sparse data, which can be critical to improving the analysis and credibility of models in the eyes of domain experts, as well as the possibility that incorrect or unwarranted knowledge influences the results of analysis, which can reduce credibility in the eyes of statisticians or domain skeptics who want to see all assumptions empirically verified in an analysis.1. The current implementation does not attempt to uncover contradictions."}, {"heading": "4.4 Incorporating foreign statistical models", "text": "A crucial aspect of MML is that it enables experts to override the automatic modelling machinery using tailor-made statistical models. Feedback networks of such models can be specified as follows: ALTER SCHEMA FOR population MODEL output variables GIVEN input variables USING FOREIGN PREDICTOR FROM source fileCurrently, these models are believed to be discriminatory. They are only needed to simulate from a probability distribution via the output variables induced by the inputs and to evaluate the probability density induced by this distribution."}, {"heading": "4.5 A semi-parametric factorial mixture GPM", "text": "The current implementation of MML implements all of the above commands in terms of approximate conclusions in individual, unusually flexible, semi-parametric Bayesian metamodels. This GPM is closely related to CrossCat (Mansinghka et al., 2015).The CrossCat model is a factorial dirichlet-process-blending model in which variables are mapped to specific dirichlet-process mixtures by inference in another dirichlet-process-blending model across the column.The version used to implement MML adds two key components: 1. Deterministic constraints in the model structure. Users can set constraints on marginal dependence or independence from variables."}, {"heading": "4.5.1 A \u201cdivide-and-conquer\u201d generative process", "text": "The generative process inducing the standard GPM can be described with the following notation: Name Description \u03b1D Concentration Hyperparameter for CRP (= \"Hyperparameter\" for column d (\"datatyp-dependent\") zd Slice (\"column partition\") mapped to column d \"Concentration Hyperparameter for\" CRP, \"which maps the rows for\" slice v yvr cluster \"to\" slice v. \"Model parameters for column d\" c \"(\" datatyp-dependent \") ~ xc\" (\", d\") Values in cluster c for column d, \"i.e.\" x \"(r, d) | y\" ud \"An indicator such as ud = 1\" iff \"d\" is modeled by a foreign predictor (d). The set of input dimensions for the foreign predictor is conditionally modelable d. \""}, {"heading": "4.5.2 The joint density", "text": "These include the \u00b2 \u00b2 (p) \u00b2 (p) \u00b2 (p), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (p), p (\u00b2), p (p), p (p), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (\u00b2), p (p), p (\u00b2), p (p), p (p), p (\u00b2), p (p), p (p), p (p), p (p), p (\u00b2), p (p), p (p), p (\u00b2), p (p), p (p), p (p), p (p), p (p), p (p), p (\u00b2 (p), p (p), p (p), p (p), p (p (\u00b2), p (p), p (p), p (p), p (p), p (p), p (p (\u00b2), p (p), p (p), p (p (p), p (p), p (p (p), p (p), (p), p (p (p), p (p), (p (p), (p (p), (p), (p (p), (p (p), (p (p) (p), (p (p), (p (p), (p (p), (p (p), (p (p), (p (p), (p (p), (p (p), (p (p), (p (p), (p (p (p), (p), (p (p), (p (p), (p (p (p), (p (p), (p (p (p), (p (p), (p (p), (p (p), (p (p (p), (p (p), (p (p (p), (p (p (p), (p (p) (p (p (p"}, {"heading": "4.5.3 Inference via sequential Monte Carlo with Gibbs proposals and Gibbs rejuvenation", "text": "This year, it will be able to come out on top, \"he said in an interview with\" Welt am Sonntag, \"in which he discussed the\" world \"and the\" world. \""}, {"heading": "5. Discussion", "text": "This paper describes BayesDB, a probabilistic programming platform that enables users to directly query the likely effects of statistical data. Query language can solve statistical inference problems such as detecting predictive relationships between variables, inferring missing values, simulating probable observations, and identifying statistically similar database entries. Statisticians and domain experts can integrate (non) dependency limitations and custom models using a qualitative language for probabilistic models. By default, the meta-model frees users from the need to know how to choose modeling approaches, remove data sets with missing values, identify outliers, or optimize model parameters. Prototype implementation is suitable for analyzing complex, heterogeneous data tables with up to tens of thousands of rows and hundreds of variables."}, {"heading": "5.1 Related work in probabilistic programming", "text": "Most probabilistic programming languages are designed to specify models (Goodman et al., 2008; Stan Development Team, 2015; Milch et al., 2007; Pfeffer, 2009), which differs fundamentally from BQL and MML: 1. In BQL, probabilistic models are never explicitly specified; instead, an implicit set of models is averaged (or sampled) as needed. With MML, users set constraints on an algorithm for model discovery and do not have to select explicit models. These constraints generally do not uniquely identify the structure of the model that is ultimately used. In contrast, in languages such as Stan (Stan Development Team, 2015), each program corresponds to a specific probabilistic model whose structure is determined by the program source. Tabular (Gordon et al, 2014) uses a probabilistic language designed for embedding in spreadsheets."}, {"heading": "5.2 Related work in probabilistic databases", "text": "BayesDB takes a complementary approach to several current projects that integrate aspects of probabilistic inference with databases.The most closely related systems are MauveDB (Deshpande and Madden, 2006) and BBQ (Deshpande et al., 2004), which offer model-based views that allow the user to perform standard SQL queries on the results of statistical models.These models must be explicitly specified as part of the schema, which is useful for some machine learning applications, but does not address the core problems of the application preference, such as data exploration, data cleansing, and confirmation analysis.Both systems also use limited model classes that can easily introduce substantial ad-hoc predictive outcomes. Other systems such as MLBase (Kraska et al., 2013) and GraphLab (Low et al., 2012) aim to simplify the development and use of machine learning algorithms on a scale."}, {"heading": "5.2.1 Uncertain data versus uncertain inference", "text": "Database research has proposed several probabilistic databases aimed at simplifying the management and retrieval of data that is \"insecure\" or \"inaccurate\" (Dalvi et al., 2009). This \"data insecurity\" differs from the inferential uncertainty that motivates BayesDB. Even if the data is known with certainty, it is rarely possible to unequivocally identify a single model that can be used with absolute certainty. Second, any probable model is likely to have uncertain implications. Extensions to BayesDB, which augment GPMs with likely coherent treatment of data insecurity, are an important area for future research."}, {"heading": "5.3 Limitations and future work", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "5.4 Conclusion", "text": "Traditional databases protect data consumers from \"having to know how the data in the machine is organized\" Codd (1970) and provide automated data representation and retrieval algorithms good enough for a broad application class. Although this abstraction barrier is only imperfectly attained, it has proved useful enough to serve as a foundation for several generations of software and data systems. This decoupling of the task specification from implementation allowed for improved performance and reliability - individual database indexes and in some cases entire database systems - without having to notify end users. BayesDB also created a simple conceptual vocabulary and a query language for data management and data processing that was far more widespread than the system program knowledge required for its implementation. BayesDB aimed to isolate consumers of statistical conclusions from the concepts of modeling and statistics, and provide a qualitative, currently complex interface for solving problems."}], "references": [{"title": "An introduction to mcmc for machine learning", "author": ["Christophe Andrieu", "Nando De Freitas", "Arnaud Doucet", "Michael I Jordan"], "venue": "Machine learning,", "citeRegEx": "Andrieu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2003}, {"title": "A relational model of data for large shared data banks", "author": ["Edgar F Codd"], "venue": "Communications of the ACM,", "citeRegEx": "Codd.,? \\Q1970\\E", "shortCiteRegEx": "Codd.", "year": 1970}, {"title": "Elements of information theory", "author": ["Thomas M Cover", "Joy A Thomas"], "venue": null, "citeRegEx": "Cover and Thomas.,? \\Q2012\\E", "shortCiteRegEx": "Cover and Thomas.", "year": 2012}, {"title": "Probabilistic databases: diamonds in the dirt", "author": ["Nilesh Dalvi", "Christopher R\u00e9", "Dan Suciu"], "venue": "Communications of the ACM,", "citeRegEx": "Dalvi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dalvi et al\\.", "year": 2009}, {"title": "Mauvedb: supporting model-based user views in database systems", "author": ["Amol Deshpande", "Samuel Madden"], "venue": "In Proceedings of the 2006 ACM SIGMOD international conference on Management of data,", "citeRegEx": "Deshpande and Madden.,? \\Q2006\\E", "shortCiteRegEx": "Deshpande and Madden.", "year": 2006}, {"title": "Model-driven data acquisition in sensor networks", "author": ["Amol Deshpande", "Carlos Guestrin", "Samuel R Madden", "Joseph M Hellerstein", "Wei Hong"], "venue": "In Proceedings of the Thirtieth international conference on Very large data bases-Volume", "citeRegEx": "Deshpande et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Deshpande et al\\.", "year": 2004}, {"title": "Bayesian Data Analysis", "author": ["Andrew Gelman", "John B. Carlin", "Hal S. Stern", "Donald B. Rubin"], "venue": null, "citeRegEx": "Gelman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Gelman et al\\.", "year": 1995}, {"title": "Church: a language for generative models", "author": ["Noah D. Goodman", "Vikash K. Mansinghka", "Daniel Roy", "Keith Bonawitz", "Joshua B. Tenenbaum"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "Tabular: a schema-driven probabilistic programming language", "author": ["Andrew D Gordon", "Thore Graepel", "Nicolas Rolland", "Claudio Russo", "Johannes Borgstrom", "John Guiver"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "Gordon et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 2014}, {"title": "Mcdb: a monte carlo approach to managing uncertain data", "author": ["Ravi Jampani", "Fei Xu", "Mingxi Wu", "Luis Leopoldo Perez", "Christopher Jermaine", "Peter J Haas"], "venue": "In Proceedings of the 2008 ACM SIGMOD international conference on Management of data,", "citeRegEx": "Jampani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Jampani et al\\.", "year": 2008}, {"title": "Mlbase: A distributed machine-learning system", "author": ["Tim Kraska", "Ameet Talwalkar", "John C Duchi", "Rean Griffith", "Michael J Franklin", "Michael I Jordan"], "venue": "In CIDR,", "citeRegEx": "Kraska et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kraska et al\\.", "year": 2013}, {"title": "Distributed graphlab: a framework for machine learning and data mining in the cloud", "author": ["Yucheng Low", "Danny Bickson", "Joseph Gonzalez", "Carlos Guestrin", "Aapo Kyrola", "Joseph M Hellerstein"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Low et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Low et al\\.", "year": 2012}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["Vikash Mansinghka", "Daniel Selsam", "Yura Perov"], "venue": "arXiv preprint arXiv:1404.0099,", "citeRegEx": "Mansinghka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mansinghka et al\\.", "year": 2014}, {"title": "Crosscat: A fully bayesian nonparametric method for analyzing heterogeneous, high dimensional data", "author": ["Vikash Mansinghka", "Patrick Shafto", "Eric Jonas", "Cap Petschulat", "Max Gasner", "Joshua Tenenbaum"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Mansinghka et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mansinghka et al\\.", "year": 2015}, {"title": "Natively probabilistic computation", "author": ["Vikash Kumar Mansinghka"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "Mansinghka.,? \\Q2009\\E", "shortCiteRegEx": "Mansinghka.", "year": 2009}, {"title": "Generalized linear models, volume 37", "author": ["Peter McCullagh", "John A Nelder"], "venue": "CRC press,", "citeRegEx": "McCullagh and Nelder.,? \\Q1989\\E", "shortCiteRegEx": "McCullagh and Nelder.", "year": 1989}, {"title": "Dremel: interactive analysis of web-scale datasets", "author": ["Sergey Melnik", "Andrey Gubarev", "Jing Jing Long", "Geoffrey Romer", "Shiva Shivakumar", "Matt Tolton", "Theo Vassilakis"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Melnik et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Melnik et al\\.", "year": 2010}, {"title": "blog: Probabilistic models with unknown objects", "author": ["Brian Milch", "Bhaskara Marthi", "Stuart Russell", "David Sontag", "Daniel L Ong", "Andrey Kolobov"], "venue": "Statistical relational learning,", "citeRegEx": "Milch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2007}, {"title": "Dynamic bayesian networks: representation, inference and learning", "author": ["Kevin Patrick Murphy"], "venue": "PhD thesis,", "citeRegEx": "Murphy.,? \\Q2002\\E", "shortCiteRegEx": "Murphy.", "year": 2002}, {"title": "The gaussian process density sampler", "author": ["Iain Murray", "David MacKay", "Ryan P Adams"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Murray et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Murray et al\\.", "year": 2009}, {"title": "Markov chain sampling methods for dirichlet process mixture models", "author": ["R. Neal"], "venue": null, "citeRegEx": "Neal.,? \\Q1998\\E", "shortCiteRegEx": "Neal.", "year": 1998}, {"title": "Probabilistic reasoning in intelligent systems: Networks of plausible inference", "author": ["Judea Pearl"], "venue": null, "citeRegEx": "Pearl.,? \\Q1988\\E", "shortCiteRegEx": "Pearl.", "year": 1988}, {"title": "Bayesianism and causality, or, why i am only a half-bayesian", "author": ["Judea Pearl"], "venue": "In Foundations of bayesianism,", "citeRegEx": "Pearl.,? \\Q2001\\E", "shortCiteRegEx": "Pearl.", "year": 2001}, {"title": "Figaro: An object-oriented probabilistic programming language. Charles River Analytics", "author": ["Avi Pfeffer"], "venue": "Technical Report,", "citeRegEx": "Pfeffer.,? \\Q2009\\E", "shortCiteRegEx": "Pfeffer.", "year": 2009}, {"title": "The infinite gaussian mixture model", "author": ["C. Rasmussen"], "venue": "In Advances in Neural Processing Systems", "citeRegEx": "Rasmussen.,? \\Q2000\\E", "shortCiteRegEx": "Rasmussen.", "year": 2000}, {"title": "Artificial intelligence: A modern approach", "author": ["Stuart Russell", "Peter Norvig"], "venue": null, "citeRegEx": "Russell and Norvig.,? \\Q2003\\E", "shortCiteRegEx": "Russell and Norvig.", "year": 2003}, {"title": "ACM, 2013", "author": ["Sameer Singh", "Thore Graepel. Automated probabilistic modeling for relational data. In Proceedings of the ACM of Information", "Knowledge Management CIKM"], "venue": "URL http://research.microsoft.com/apps/pubs/default.aspx?id=200220.", "citeRegEx": "Singh et al\\.,? 2013", "shortCiteRegEx": "Singh et al\\.", "year": 2013}, {"title": "Sequential Monte Carlo methods in practice", "author": ["Adrian Smith", "Arnaud Doucet", "Nando de Freitas", "Neil Gordon"], "venue": "Springer Science & Business Media,", "citeRegEx": "Smith et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2013}, {"title": "Matchbox: large scale online bayesian recommendations", "author": ["David H Stern", "Ralf Herbrich", "Thore Graepel"], "venue": "In Proceedings of the 18th international conference on World wide web,", "citeRegEx": "Stern et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Stern et al\\.", "year": 2009}, {"title": "Low assumptions, high dimensions", "author": ["L. Wasserman"], "venue": "Rationality, Markets and Morals,", "citeRegEx": "Wasserman.,? \\Q2011\\E", "shortCiteRegEx": "Wasserman.", "year": 2011}, {"title": "Spark: cluster computing with working sets", "author": ["Matei Zaharia", "Mosharaf Chowdhury", "Michael J Franklin", "Scott Shenker", "Ion Stoica"], "venue": "In Proceedings of the 2nd USENIX conference on Hot topics in cloud computing,", "citeRegEx": "Zaharia et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zaharia et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 13, "context": "The default modeling assumptions that BayesDB makes are suitable for a broad class of problems (Mansinghka et al., 2015; Wasserman, 2011), but statisticians can customize these assumptions when necessary.", "startOffset": 95, "endOffset": 137}, {"referenceID": 29, "context": "The default modeling assumptions that BayesDB makes are suitable for a broad class of problems (Mansinghka et al., 2015; Wasserman, 2011), but statisticians can customize these assumptions when necessary.", "startOffset": 95, "endOffset": 137}, {"referenceID": 6, "context": "BayesDB also enables domain experts that lack statistical expertise to perform qualitative model checking (Gelman et al., 1995) and encode simple forms of qualitative prior knowledge.", "startOffset": 106, "endOffset": 127}, {"referenceID": 25, "context": "This is directly useful for predictive modeling and also decision-theoretic choice implemented using Monte Carlo estimation of expected utility (Russell and Norvig, 2003).", "startOffset": 144, "endOffset": 170}, {"referenceID": 2, "context": "b = mutual-information(G, colA = ci, colB = cj) The mutual information between two columns can be estimated by the standard reduction to KL divergence (Cover and Thomas, 2012).", "startOffset": 151, "endOffset": 175}, {"referenceID": 13, "context": "The current prototype implementation of BayesDB uses a standard Gibbs sampler for a Dirichlet process mixture model (Mansinghka et al., 2015; Neal, 1998; Rasmussen, 2000) to sample {(\u03c6l, \u03c0l)}|{X (r,c)}, with K + = 1000 by default.", "startOffset": 116, "endOffset": 170}, {"referenceID": 20, "context": "The current prototype implementation of BayesDB uses a standard Gibbs sampler for a Dirichlet process mixture model (Mansinghka et al., 2015; Neal, 1998; Rasmussen, 2000) to sample {(\u03c6l, \u03c0l)}|{X (r,c)}, with K + = 1000 by default.", "startOffset": 116, "endOffset": 170}, {"referenceID": 24, "context": "The current prototype implementation of BayesDB uses a standard Gibbs sampler for a Dirichlet process mixture model (Mansinghka et al., 2015; Neal, 1998; Rasmussen, 2000) to sample {(\u03c6l, \u03c0l)}|{X (r,c)}, with K + = 1000 by default.", "startOffset": 116, "endOffset": 170}, {"referenceID": 1, "context": "The relational model enabled sharing and infrastructure reuse because interactions with the data, queries, are expressed in a notation (most popularly SQL) that is independent of the physical representation of the data (Codd, 1970).", "startOffset": 219, "endOffset": 231}, {"referenceID": 13, "context": "For example, in the current version of MML, closed-set categorical variables are modeled generatively via a multinomial component model with a symmetric Dirichlet prior on the parameters (Mansinghka et al., 2015).", "startOffset": 187, "endOffset": 212}, {"referenceID": 13, "context": "Data of this type is generatively modeled using an asymmetric BetaBernoulli model (Mansinghka et al., 2015) that can better handle sparse or marginally biased variables than a symmetric alternative.", "startOffset": 82, "endOffset": 107}, {"referenceID": 15, "context": "model (McCullagh and Nelder, 1989).", "startOffset": 6, "endOffset": 34}, {"referenceID": 21, "context": "3 Qualitative constraints The BayesDB MML provides constructs for specifying qualitative constraints on the dependence and independence relationships (Pearl, 1988).", "startOffset": 150, "endOffset": 163}, {"referenceID": 13, "context": "This GPM is closely related to CrossCat (Mansinghka et al., 2015).", "startOffset": 40, "endOffset": 65}, {"referenceID": 14, "context": "A generative model for this constrained process can be given trivially by embedding the unconstrained generative process in the inner loop of a rejection sampler for {cm} (Mansinghka, 2009; Murray et al., 2009).", "startOffset": 171, "endOffset": 210}, {"referenceID": 19, "context": "A generative model for this constrained process can be given trivially by embedding the unconstrained generative process in the inner loop of a rejection sampler for {cm} (Mansinghka, 2009; Murray et al., 2009).", "startOffset": 171, "endOffset": 210}, {"referenceID": 0, "context": "Additionally, clients can control the frequency and target latent variables for rejuvenation kernels based on Gibbs sampling, turning the overall scheme into a resamplemove algorithm (Andrieu et al., 2003; Smith et al., 2013).", "startOffset": 183, "endOffset": 225}, {"referenceID": 27, "context": "Additionally, clients can control the frequency and target latent variables for rejuvenation kernels based on Gibbs sampling, turning the overall scheme into a resamplemove algorithm (Andrieu et al., 2003; Smith et al., 2013).", "startOffset": 183, "endOffset": 225}, {"referenceID": 27, "context": "incorporate(id = r, values = {(cj , x(r,cj))}) Each row is incorporated via a single Gibbs step that numerically marginalizes out all the latent variables associated with the row (Smith et al., 2013; Murphy, 2002).", "startOffset": 179, "endOffset": 213}, {"referenceID": 18, "context": "incorporate(id = r, values = {(cj , x(r,cj))}) Each row is incorporated via a single Gibbs step that numerically marginalizes out all the latent variables associated with the row (Smith et al., 2013; Murphy, 2002).", "startOffset": 179, "endOffset": 213}, {"referenceID": 12, "context": "This allows for a limited form of inference programming (Mansinghka et al., 2014), as follows.", "startOffset": 56, "endOffset": 81}, {"referenceID": 12, "context": "This allows for a limited form of inference programming (Mansinghka et al., 2014), as follows. By varying the slice, cluster, or foreign_predictor variables, clients can instruct the GPM to only perform inference on a specific subset of the latent variables. Computational effort can thus be focused on those latent variables that are most relevant for a given analysis, rather than uniformly distributed across all latent variables in the GPM. This is most useful when the queries of interest focus on a subset of the variables, or when the clusters are well-separated. The prototype implementation of BayesDB uses row-cluster, column-slice, clusterparameter, and column-hyperparameter transition operators from Mansinghka et al. (2015). The only modification is that the log joint density now includes terms for enforcing each of the (in)dependence constraints, and also terms for the likelihood induced by each foreign predictor, as described above.", "startOffset": 57, "endOffset": 738}, {"referenceID": 7, "context": "1 Related work in probabilistic programming Most probabilistic programming languages are intended for model specification (Goodman et al., 2008; Stan Development Team, 2015; Milch et al., 2007; Pfeffer, 2009).", "startOffset": 122, "endOffset": 208}, {"referenceID": 17, "context": "1 Related work in probabilistic programming Most probabilistic programming languages are intended for model specification (Goodman et al., 2008; Stan Development Team, 2015; Milch et al., 2007; Pfeffer, 2009).", "startOffset": 122, "endOffset": 208}, {"referenceID": 23, "context": "1 Related work in probabilistic programming Most probabilistic programming languages are intended for model specification (Goodman et al., 2008; Stan Development Team, 2015; Milch et al., 2007; Pfeffer, 2009).", "startOffset": 122, "endOffset": 208}, {"referenceID": 8, "context": "Tabular (Gordon et al., 2014), a probabilistic language designed for embedding into spreadsheets that applies user-specified factor graph models defined in terms of observed and latent variables to datasets represented as sub-tables, seems closest in structure to BQL.", "startOffset": 8, "endOffset": 29}, {"referenceID": 4, "context": "The most closely related systems are MauveDB (Deshpande and Madden, 2006) and BBQ (Deshpande et al.", "startOffset": 45, "endOffset": 73}, {"referenceID": 5, "context": "The most closely related systems are MauveDB (Deshpande and Madden, 2006) and BBQ (Deshpande et al., 2004).", "startOffset": 82, "endOffset": 106}, {"referenceID": 10, "context": "Other systems such as MLBase (Kraska et al., 2013) and GraphLab (Low et al.", "startOffset": 29, "endOffset": 50}, {"referenceID": 11, "context": ", 2013) and GraphLab (Low et al., 2012) aim to simplify at-scale development and deployment of machine learning algorithms.", "startOffset": 21, "endOffset": 39}, {"referenceID": 9, "context": ", 2013) and its ancestor, MCDB (Jampani et al., 2008), provide SQL operators for efficient Monte Carlo sampling.", "startOffset": 31, "endOffset": 53}, {"referenceID": 3, "context": "1 Uncertain data versus uncertain inference The database research community has proposed several probabilistic databases that aim to simplify the management and querying of data that is \u201cuncertain\u201d or \u201cimprecise\u201d (Dalvi et al., 2009).", "startOffset": 213, "endOffset": 233}, {"referenceID": 16, "context": "For example, it may be possible to build versions suitable for ad-hoc exploration of distributed databases such as Dremel (Melnik et al., 2010) or Spark (Zaharia et al.", "startOffset": 122, "endOffset": 143}, {"referenceID": 30, "context": ", 2010) or Spark (Zaharia et al., 2010).", "startOffset": 17, "endOffset": 39}, {"referenceID": 28, "context": "For example, it seems appealing to jointly model populations of web browsing sessions and web assets with low-dimensional latent space models (Stern et al., 2009).", "startOffset": 142, "endOffset": 162}], "year": 2015, "abstractText": "Is it possible to make statistical inference broadly accessible to non-statisticians without sacrificing mathematical rigor or inference quality? This paper describes BayesDB, a probabilistic programming platform that aims to enable users to query the probable implications of their data as directly as SQL databases enable them to query the data itself. This paper focuses on four aspects of BayesDB: (i) BQL, an SQL-like query language for Bayesian data analysis, that answers queries by averaging over an implicit space of probabilistic models; (ii) techniques for implementing BQL using a broad class of multivariate probabilistic models; (iii) a semi-parametric Bayesian model-builder that auomatically builds ensembles of factorial mixture models to serve as baselines; and (iv) MML, a \u201cmeta-modeling\u201d language for imposing qualitative constraints on the model-builder and combining baseline models with custom algorithmic and statistical models that can be implemented in external software. BayesDB is illustrated using three applications: cleaning and exploring a public database of Earth satellites; assessing the evidence for temporal dependence between macroeconomic indicators; and analyzing a salary survey.", "creator": "LaTeX with hyperref package"}}}