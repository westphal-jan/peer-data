{"id": "1512.05849", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Dec-2015", "title": "Modeling Progress in AI", "abstract": "Participants in recent discussions of AI-related issues ranging from intelligence explosion to technological unemployment have made diverse claims about the nature, pace, and drivers of progress in AI. However, these theories are rarely specified in enough detail to enable systematic evaluation of their assumptions or to extrapolate progress quantitatively, as is often done with some success in other technological domains. After reviewing relevant literatures and justifying the need for more rigorous modeling of AI progress, this paper contributes to that research program by suggesting ways to account for the relationship between hardware speed increases and algorithmic improvements in AI, the role of human inputs in enabling AI capabilities, and the relationships between different sub-fields of AI. It then outlines ways of tailoring AI progress models to generate insights on the specific issue of technological unemployment, and outlines future directions for research on AI progress.", "histories": [["v1", "Fri, 18 Dec 2015 04:17:39 GMT  (228kb)", "http://arxiv.org/abs/1512.05849v1", "AAAI 2016 Workshop on AI, Ethics, and Society"]], "COMMENTS": "AAAI 2016 Workshop on AI, Ethics, and Society", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["miles brundage"], "accepted": false, "id": "1512.05849"}, "pdf": {"name": "1512.05849.pdf", "metadata": {"source": "CRF", "title": "Modeling Progress in AI", "authors": ["Miles Brundage"], "emails": ["miles.brundage@asu.edu"], "sections": [{"heading": null, "text": "In recent years, it has been shown that the number of people able to remain in the EU has decreased by more than a fifth in the last ten years."}, {"heading": "Analysis of Relevant Literatures", "text": "Although there is no reliable literature yet that theoretically or empirically evaluates, let alone extrapolates, the state of the art in artificial intelligence (Hernandez-Orallo, 2014), much of the literature is relevant to the research program for modeling AI progress proposed in this paper. In this section, we explain some of the results of such literature, how it helps us think about the progress of artificial intelligence and what limitations it has."}, {"heading": "AI Evaluation Literature", "text": "First, as summarized by Hernandez-Orallo (2014), many different methods have been proposed to evaluate the intelligence of AI-based artifacts - what we can call the \"evaluation literature.\" Hernandez-Orallo distinguishes between \"task\" assessments and \"ability\" assessments, the former assessing the performance of agents on a relatively specific task (e.g. a specific vision benchmark) and the latter measuring the performance of agents on a broader range of tasks (e.g. vision or perception in general), although he notes that there is indeed continuity between these levels of analysis. Of particular relevance to the current discussion Hernandez-Orallo points to an important analogy that we will include in the next section, namely between the \"factors\" used to distinguish intelligence in the literature of human psychometry (e.g. Carroll, 1993), such as literacy and visual processing and the distinction between parts of AI, such as natural language processing and computer vision."}, {"heading": "Technology Forecasting Literature", "text": "Beyond the subject of evaluation, there is also a literature on predicting the progress of artificial intelligence in particular and on technological prediction in general (commonly referred to as \"prediction literature\" here). Grace and Cristiano (2015) find at least 9 surveys on the progress of artificial intelligence. Armstrong and Sotala (2012), Armstrong et al. (2014) and Bostrom (2014) analyze previous predictions of the future progress of artificial intelligence. In particular, such prediction efforts typically focus on a particular benchmark, \"artificial intelligence at the human level\" (or deviations from it). Problems associated with such a focus (e.g. that artificial intelligence already exceeds humans in some areas) are discussed, among others, by some of the respondents to the Kruel survey (2011). For purposes such as predicting technological unemployment, it is important to anticipate advances in artificial intelligence that are short, exceed or orthogonal."}, {"heading": "AI Risk Literature", "text": "Next, there is a growing literature on long-term risks associated with artificial intelligence (Bostrom, 2014). At the service of assessing the nature and magnitude of future risks from advanced artificial intelligence systems, various researchers (e.g. Bostrom, 2014; Yudkowsky, 2013; Yampolskiy, 2015) have analyzed the potential for artificial intelligence to grow rapidly. Concepts and tools used by such researchers are relevant to at least some types of artificial intelligence progress modeling - for example, Bostrom (2014) develops formulations that relate the recalcitrance of intelligence enhancements and the optimization power applied to enhancing intelligence to artificial intelligence advancement that could be expanded in future work. However, these ideas are generally more applicable to the purposes for which they were developed (analysis of future catastrophic risks) than the use of formulas that address the economic consequences of artificial intelligence and the optimization capability of human intelligence beyond that they often embody (or embody)."}, {"heading": "Technology Roadmapping Literature", "text": "Finally, there is literature on technological roadmapping methods (Roper et al., 2011) that can be helpful in the development of AI progress models, and there are roadmaps for the future of related areas such as robotics (e.g. Robotics VO, 2013). Such roadmaps are often created by military personnel (e.g. US Department of Defense, 2013) to help with long-term analysis. However, such roadmaps rarely contain detailed methodological information and often appear to be based on intuition as the basis for assigning milestones to technical progress, e.g. 5, 10, and 15-year-old milestones (these milestones are typically qualitative as well). Furthermore, different roadmaps use different metrics for progress and break down fields such as robotics into different sub-areas without using the kind of principle-guided approach proposed in this paper and discussed in more detail in the next section. Also relevant to our analysis is the fact that there is no roadmap for the author's knowledge to detail yet."}, {"heading": "Toward Rigorous Modeling of AI Progress", "text": "Given the limitations of previous work, this section proposes ways to build on the aforementioned literature and model AI progress more rigorously, starting in particular by examining the different levels and analytical units that could be considered in such modelling; examining the relationship between hardware and software advances; analysing the human contribution to AI performance from the perspective of AI progress modelling; and proposing ways to address the diversity of AI sub-areas and the problem of developing integrated AI systems."}, {"heading": "Levels and Units of Analysis", "text": "AI advances can be modeled at different levels - for example, at the level of a particular example agent for a wide range of tasks, the conceptual progress shown in the literature, the performance of human-machine systems, or the performance of a number of different actors for different tasks in which they are specialized. The purpose of a particular exercise in progress modeling is critical to determining the appropriate level of analysis. For example, when trying to determine whether or not a customer service representative's job can plausibly be automated, it is important to check whether certain tasks / skills can be easily integrated into a single agent - the fact that one system demonstrates impressive natural language processing, for example, and another does not imply that these skills can be integrated to automate the perceptual and linguistic aspects of the worker's work that affect both perception and language."}, {"heading": "Hardware and Software Progress", "text": "In fact, it is so that most people are able to behave in a way as they have done in the past. (...) It is not so that they have behaved in a way as they have done in the past. (...) It is so that they are able to take themselves into duty. (...) It is so that they do not do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...). (...). \"(...).\" (...). \"(...).\" (...). \"(.\" (.). \"(...).\" (. \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (. \"(.).\" (.). \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (.). \"(.).\" (.). \"(.).\" (. (.). \"(.).. (.). (.).\" (.). (.). (.). \"(. (.).). (.). (.\" (.).). \"(.). (. (.).). (.).\" (. (.).). (.).). (.). (.). (.). (.). (.). (.).). (.). (.). (.). (.).). (."}, {"heading": "AI Sub-Fields and System Architecture", "text": "The motivation for this section is the common claim that progress in the sub-areas of AI systems has been rapid, while progress in general intelligent integrated systems has been more limited (Dietterich and Horvitz, 2015). But even with such available benchmarks, it is not obvious how to model the relationship of progress in AI sub-areas to progress in general intelligence, or how to model progress in the development of integrated agency architectures (e.g. Bellemare et al., 2012). But even with such benchmarks, it is not obvious how to model the relationship of progress in AI sub-areas to progress in general intelligence."}, {"heading": "AI Progress and the Future of Work", "text": "Previous work has examined the potentially huge impact of artificial intelligence on the economy (Brynjolfsson and McAfee, 2014; Vardi, 2015). However, given the many technical and social uncertainties, considerable uncertainty remains about the exact nature and timing of these impacts. Different theories about what it is like to automate different tasks (and thus different models of AI progress) suggest different conclusions about the nature and magnitude of these impacts. Therefore, in this section we examine these divergent theories of automation difficulties and suggest approaches to modeling AI progress that could provide new insights into the future of work."}, {"heading": "Theories of Automation Difficulty", "text": "Murnane and Levy (2004) differentiate between routine and non-routine tasks, with the former being more prone to automation. However, Frey and Osborne (2013) note that social intelligence, creative intelligence, and perception and manipulation are \"bottlenecks\" in the automation of certain tasks over the next two decades. Author (2013) notes that novel tasks in the workplace are less prone to automation than long-established ones. Brynjolfsson and McAfee (2014) focus on creativity as a differentiator between the degree of vulnerability of future jobs, while noting the considerable uncertainty in any such assessment. Rus (2015) suggests that different types of perception and manipulation tasks are suitable for humans, unlike machines, Contra Frey and Osborne's (2013) rather categorical distinction, and she adds that abstraction and creativity are in the list of hard-to-automate skills."}, {"heading": "Tailored Progress Modeling Approaches", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "Future Directions", "text": "The above analysis suggests the need for additional research on a variety of different aspects of AI progress. Below, we group some directions of future research according to whether they are primarily conceptual, empirical, or normative, although there is overlap between them."}, {"heading": "Conceptual", "text": "In the above section, \"Toward Rigorous Modeling of AI Progress,\" some initial possibilities for conceptualizing and ultimately quantitative modelling of AI progress were proposed, but did not take into account the full range of relevant literature. Unanswered questions include: What lessons can be learned from the literature on natural intelligence when it comes to how (not) progress in AI is to be assessed, and in particular the intractability (Bostrom, 2014) of various research problems? Are different models required for conceptualizing AI in the short term than in the longer term during a future intelligence explosion (or lack thereof)? And are there more useful ways to represent the relations between sub-areas of AI and the challenge of building integrated AI systems than those discussed above?"}, {"heading": "Empirical", "text": "The above analysis raised a number of questions that need to be examined empirically in order to be answered. In each dimension of the AI progress discussed, the empirical question arises as to how the rate of progress was historical and how it is linked to the postulated independent variables (research effort, hardware acceleration, data availability, etc.). In order to concretize the models proposed here, additional data on such factors would need to be collected and in many cases elements of progress quantified that are so far only qualitatively indicated in the literature. In addition, the development of a comprehensive map of current research efforts in various sub-areas would require additional data collection and analysis, e.g. through bibliometric analysis and analysis of financing trends. Finally, with regard to the economic dimensions of AI, questions about consumer demand for various human / agent capabilities were raised that would need to be examined empirically in order to find suitable metrics for modelling progress."}, {"heading": "Normative", "text": "Anticipating plausible developments in artificial intelligence and their implications, while difficult, is part of the ethical responsibility of the AI community (Brundage, shortly). The questions discussed in this paper raise several questions about such responsibilities - for example, should progress in some areas be accelerated, slowed down, or otherwise modulated? What responsibilities exist outside the AI community for businesses, policymakers, consumers, and others to influence the speed / nature of progress in artificial intelligence? Should, as some (Russell, 2014) suggest, the objectives of the artificial intelligence sector be redefined in a way that reflects the need for systems to be demonstrably aligned with human values? If so, what metrics would be appropriate to capture this dimension of progress in artificial intelligence?"}, {"heading": "Conclusion", "text": "This paper has defended a research programme aimed at rigorously modelling AI progress, and made some preliminary contributions to it. Existing efforts to take into account AI progress have proved limited in important respects, and controversy has been found in the literature about the economic implications of AI, indicating the need for further research. Approaches to thinking about and ultimately quantitative modelling of various aspects of AI progress have been outlined in areas such as the software-hardware relationship, the role of human input, and the relationships between AI sub-domains. Finally, research directions have been outlined that could shed more light on the nature, pace, and drivers of AI progress and its normative dimensions. Overall, modelling of AI progress seems to be an area ripe for further investigation and one that is of considerable social urgency."}, {"heading": "Acknowledgments", "text": "The author would like to acknowledge the helpful comments of David Guston, Joanna Bryson, Erik Fisher, Mark Gubrud, Daniel Dewey, Katja Grace, Kaj Sotala, Brad Knox, Vincent Mueller, Beau Cronin, Adi Wiezel, David Dalrymple, Adam Elkus, an anonymous reviewer, and others who commented on earlier versions of these ideas."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Participants in recent discussions of AI-related issues ranging from intelligence explosion to technological unemployment have made diverse claims about the nature, pace, and drivers of progress in AI. However, these theories are rarely specified in enough detail to enable systematic evaluation of their assumptions or to extrapolate progress quantitatively, as is often done with some success in other technological domains. After reviewing relevant literatures and justifying the need for more rigorous modeling of AI progress, this paper contributes to that research program by suggesting ways to account for the relationship between hardware speed increases and algorithmic improvements in AI, the role of human inputs in enabling AI capabilities, and the relationships between different sub-fields of AI. It then outlines ways of tailoring AI progress models to generate insights on the specific issue of technological unemployment, and outlines future directions for research on AI progress.", "creator": "Word"}}}