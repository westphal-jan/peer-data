{"id": "1512.06034", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Dec-2015", "title": "Ontology-driven Information Extraction", "abstract": "Homogeneous unstructured data (HUD) are collections of unstructured documents that share common properties, such as similar layout, common file format, or common domain of values. Building on such properties, it would be desirable to automatically process HUD to access the main information through a semantic layer -- typically an ontology -- called semantic view. Hence, we propose an ontology-based approach for extracting semantically rich information from HUD, by integrating and extending recent technologies and results from the fields of classical information extraction, table recognition, ontologies, text annotation, and logic programming. Moreover, we design and implement a system, named KnowRex, that has been successfully applied to curriculum vitae in the Europass style to offer a semantic view of them, and be able, for example, to select those which exhibit required skills.", "histories": [["v1", "Fri, 18 Dec 2015 16:56:02 GMT  (182kb,D)", "http://arxiv.org/abs/1512.06034v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.IR", "authors": ["weronika t adrian", "nicola leone", "marco manna"], "accepted": false, "id": "1512.06034"}, "pdf": {"name": "1512.06034.pdf", "metadata": {"source": "CRF", "title": "Ontology-driven Information Extraction", "authors": ["Weronika T. Adrian", "Nicola Leone", "Marco Manna"], "emails": [], "sections": [{"heading": null, "text": "Keywords: unstructured data, ontologies, semantic information extraction, table recognition, semantic views"}, {"heading": "1 Introduction", "text": "In fact, the fact is that most of us are able to survive ourselves, and that they are able to survive themselves, \"he told the Deutsche Presse-Agentur in an interview with\" Frankfurter Allgemeine Zeitung \"(Friday).\" I don't think we will be able to change the world, \"he told the Deutsche Presse-Agentur.\" But I believe that we will be able to change the world, and that we will be able to change the world. \""}, {"heading": "2 System Overview", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "3 Automatic curriculum analysis", "text": "To test our framework, we have chosen the European standard style for Curriculum Vitae documents called Europass (see Figure 3), but this choice ensures that the input documents have a similar two-column layout and organization of data. Despite some differences between individual Europass documents * * $* $$* $* $* $* $* $* * * (4) and we can assume a specific template consisting of: (i) a two-column layout, (ii) the same file format (actually a PDF that does not contain information about sections / subsections that need to be reconstructed at runtime), (iii) a fixed set of labels (in the left column!), (iv) a common domain of values (personal information, education, work experience, etc.).The problem for the recruiters and the goal of our system is to extract appropriate information from a collection of documents and enter it into the target database."}, {"heading": "4 The Design Phase in KnowRex", "text": "During the design phase, a KnowRex project is configured to perform operations on a collection of HUD to obtain information desired by the user in a specific form. To do this, the designer should think about what he has and what he wants to receive (see Figure 4). The first is to identify a template that represents a vague concept for describing the common features of HUD. A template must be formalized in the form of an object model, elements of which are extracted by various components (two-dimensional processing tools, annotations, and semantic descriptors), and the target scheme is typically formalized as an ontology or database schema. The designer configures the system and arranges the external tools so that the object model can be built. Then, they write logic rules that map the object model into a target schema. The result of the design phase is used at runtime to process the actual documents to generate the semantic view."}, {"heading": "4.1 Definition of the Target Schema", "text": "This step is crucial for defining a desired output of the system. The designer must decide how to organize the information extracted from the documents. The target scheme can be either for a relational database or for an ontology. For the target database, we can only look at the part of the relevant information. Let's assume the following target scheme for the considered use case: Candidate (Id, Name, Surname, Phone, Email, Address, Gender, Nationality, License); Work experience (Id, Company, BusinessSector, StartDate, EndDate); candWE (IdCandidate, IdWorkExperience). The scheme should be consistent and realistic, i.e. it should be easy to fill in manually, just by analyzing the input documents."}, {"heading": "4.2 Definition of the Object Model", "text": "In fact, it is such that it is a way in which people are able to unfold, to unfold, to unfold, to unfold, to unfold, to reinvent, to unfold, to reinvent, to explore, to unfold, to explore, to unfold, to unfold, to unfold, to unfold, to unfold, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to explore, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to invent, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold, to unfold,"}, {"heading": "4.3 Arrangement of the Semantic Annotators", "text": "In this step, the designer selects the commentators to use, then selects classes to search for, and configures each commentator: provides an assignment from the output of the tool to the object model, and defines the specific properties of the tool. In the case of Europass CV analysis, we have selected: StanfordNER, a custom commentator for recognizing email addresses and data, a dictionary-based commentator for recognizing capabilities defined in the European e-Competence Framework 3,3. See http: / / www.ecompetences.eu /.and a label commentator based on pattern recognition that recognizes typical Europass CVs. Decisions on the placement of commenters are made experimentally. Sometimes it is beneficial to use more than one tool to recognize the same category. The resulting potential redundancy is not harmful, but the callback can improve."}, {"heading": "4.4 Two-dimensional Document Analysis", "text": "Knowing the context in which a particular phrase appears is helpful for semantic information extraction. In some input data formats, such as pdf documents, information about the structure is lost; visible to the human eye, it is not obvious to a machine. Therefore, we need to restore the structure in order to get a meaningful representation of the input documents. To this end, this step configures an external two-dimensional processor and a refinement module within KnowRex. As a two-dimensional processor, we have used Quablo (http: / / www.quablo.eu /), which can recognize a series of regular tables within a pdf document. The representation obtained with this tool is then improved by a special module that works with domain concepts, such as labels from the Europass template. The module creates an improved structure by merging suitable cells (for example, when a label extends over two cells, these templates will be merged into two-dimensional (and) the two-dimensional (plus) cells of the two-dimensional (plus) templates containing the two-dimensional (plus) objects."}, {"heading": "4.5 Semantic Descriptors Specification", "text": "In fact, it is as if it will be able to put itself at the top, in the way it has been in the past. \"It is as if it has been able to put itself at the top,\" he says. \"It is as if it has been able to put itself at the top,\" he says. \"But it is not as if it has been able to put itself at the top,\" he says, \"but it is not as if it has been able to put itself at the top.\""}, {"heading": "4.6 Defining a Mapping from Object Model to Target Schema", "text": "The design phase in KnowRex is completed with the definition of a mapping of object model classes to the concepts of the target schema. This mapping, which is written in the form of database rules, is used for the automatic creation of a semantic view of the (structured) input documents during the runtime phase. In the head of the rules are concepts from the target schema and in the body - objects from the object model (and auxiliary objects such as candidate ID). Partially, the object model is assigned to the target schema as follows: Candidate (Id, N, S, P, E, A, G, Nt, D, L): - ID: cv _ candidate _ id (Id), PI: personalInformation (N, S, A, P, E, Nt, D, G), CDL: CandidateDrivingLicence (L).workExperience (WExpId, Company, BusinessSector, Start, End): C: Enterprise (WessPhase, the workflows are translated into ED)."}, {"heading": "5 The Runtime Phase of the System", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "6 Discussion and Conclusion", "text": "We have described an ontology-based approach to gathering and organizing semantic information from HUD, implemented in a system called KnowRex, which was tested on Europass-style curricula and saved as pdf files. Broadly speaking, the design phase was completed in two man weeks. Based on our preliminary analysis of over 80 resumes, the two-dimensional structure recognition and recall of external commentators were the biggest bottlenecks. Quablo worked well for about 50% of the documents when the Europass template was first configured, and a further 20% of the documents achieved satisfactory results through small adjustments to the tool (margin tolerance, etc.) While the precision of the semantic commentators is satisfactory, their sometimes low recall can be compensated by adapting dictionary-based commentators. Logical rules (semantic descriptors and mapping rules) worked as expected on the found objects without loss of flexibility, and are appropriate for different scenarios."}, {"heading": "Acknowledgement", "text": "The work was supported by the Calabria Region as part of the project \"THT - Talent Hunter Technology\" (CUP: J84E07000540005)."}], "references": [{"title": "Ontology guided information extraction from unstructured text", "author": ["R. Anantharangachar", "S. Ramani", "S. Rajagopalan"], "venue": "CoRR abs/1302.1335", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Introduction to information extraction: Basic notions and current trends", "author": ["W.T. Balke"], "venue": "Datenbank-Spektrum 12(2), 81\u201388", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "A Survey of Web Information Extraction Systems", "author": ["C.H. Chang", "M. Kayed", "M.R. Girgis", "K.F. Shaalan"], "venue": "IEEE Trans. on Kn. and Data Eng. 18(10), 1411\u20131428", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Aggregating semantic annotators", "author": ["L. Chen", "S. Ortona", "G. Orsi", "M. Benedikt"], "venue": "Proc. VLDB Endow. 6(13), 1486\u20131497", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "A Comparative Study of Information Extraction Strategies", "author": ["R. Feldman", "Y. Aumann", "M. Finkelstein-Landau", "E. Hurvitz", "Y. Regev", "A. Yaroshevich"], "venue": "Proc. of CICLing, Mexico City, Mexico. pp. 21\u201334", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Little knowledge rules the web: Domain-centric result page extraction", "author": ["T. Furche", "G. Gottlob", "G. Grasso", "G. Orsi", "C. Schallhart", "C. Wang"], "venue": "Web Reasoning and Rule Systems, LNCS, vol. 6902, pp. 61\u201376", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Information extraction from text", "author": ["J. Jiang"], "venue": "Mining Text Data, pp. 11\u201341", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "An ontology-based retrieval system using semantic indexing", "author": ["S. Kara", "O. Alan", "O. Sabuncu", "S. Akpinar", "N.K. Cicekli", "F.N. Alpaslan"], "venue": "Information Systems 37(4), 294 \u2013 305", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Ontology based information extraction from text", "author": ["V. Karkaletsis", "P. Fragkou", "G. Petasis", "E. Iosif"], "venue": "Knowledge-Driven Multimedia Information Extraction and Ontology Evolution, LNCS, vol. 6050, pp. 89\u2013109", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "The H\u0131L\u03b5X system for semantic information extraction", "author": ["M. Manna", "E. Oro", "M. Ruffolo", "M. Alviano", "N. Leone"], "venue": "Trans. on Large-Scale Data- and KnowledgeCentered Systems V, vol. 7100, pp. 91\u2013125", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Ontology-based web information extraction", "author": ["Q. Mo", "Chen", "Y.h."], "venue": "Communications and Information Processing, CCIS, vol. 288, pp. 118\u2013126", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Disjunctive logic programming with types and objects: The DLV+ system", "author": ["F. Ricca", "N. Leone"], "venue": "J. Applied Logic 5(3), 545\u2013573", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 4, "context": "The problem of identifying and extracting information from unstructured documents is widely studied in the field of information and knowledge management, and is referred to as Information Extraction (IE) [5,3,7,2].", "startOffset": 204, "endOffset": 213}, {"referenceID": 2, "context": "The problem of identifying and extracting information from unstructured documents is widely studied in the field of information and knowledge management, and is referred to as Information Extraction (IE) [5,3,7,2].", "startOffset": 204, "endOffset": 213}, {"referenceID": 6, "context": "The problem of identifying and extracting information from unstructured documents is widely studied in the field of information and knowledge management, and is referred to as Information Extraction (IE) [5,3,7,2].", "startOffset": 204, "endOffset": 213}, {"referenceID": 1, "context": "The problem of identifying and extracting information from unstructured documents is widely studied in the field of information and knowledge management, and is referred to as Information Extraction (IE) [5,3,7,2].", "startOffset": 204, "endOffset": 213}, {"referenceID": 8, "context": "More recently, some works have shown the promise of deducing and encoding formal knowledge in the form of ontologies [9,8,1,6].", "startOffset": 117, "endOffset": 126}, {"referenceID": 7, "context": "More recently, some works have shown the promise of deducing and encoding formal knowledge in the form of ontologies [9,8,1,6].", "startOffset": 117, "endOffset": 126}, {"referenceID": 0, "context": "More recently, some works have shown the promise of deducing and encoding formal knowledge in the form of ontologies [9,8,1,6].", "startOffset": 117, "endOffset": 126}, {"referenceID": 5, "context": "More recently, some works have shown the promise of deducing and encoding formal knowledge in the form of ontologies [9,8,1,6].", "startOffset": 117, "endOffset": 126}, {"referenceID": 10, "context": "Our approach follows the line of combining several techniques to obtain comprehensive results [11,4].", "startOffset": 94, "endOffset": 100}, {"referenceID": 3, "context": "Our approach follows the line of combining several techniques to obtain comprehensive results [11,4].", "startOffset": 94, "endOffset": 100}, {"referenceID": 9, "context": "The notion of semantic descriptors introduced in Section 4 has been inherited from HiLeX [10].", "startOffset": 89, "endOffset": 93}, {"referenceID": 11, "context": "To define it, we have used the ontology language OntoDLP [12] in which one can define object types, relation types and express relationships between objects.", "startOffset": 57, "endOffset": 61}], "year": 2015, "abstractText": "Homogeneous unstructured data (HUD) are collections of unstructured documents that share common properties, such as similar layout, common file format, or common domain of values. Building on such properties, it would be desirable to automatically process HUD to access the main information through a semantic layer \u2013 typically an ontology \u2013 called semantic view. Hence, we propose an ontology-based approach for extracting semantically rich information from HUD, by integrating and extending recent technologies and results from the fields of classical information extraction, table recognition, ontologies, text annotation, and logic programming. Moreover, we design and implement a system, named KnowRex, that has been successfully applied to curriculum vitae in the Europass style to offer a semantic view of them, and be able, for example, to select those which exhibit required skills.", "creator": "LaTeX with hyperref package"}}}