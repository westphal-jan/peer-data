{"id": "1512.06945", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2015", "title": "Restricted Predicates for Hypothetical Datalog", "abstract": "Hypothetical Datalog is based on an intuitionistic semantics rather than on a classical logic semantics, and embedded implications are allowed in rule bodies. While the usual implication (i.e., the neck of a Horn clause) stands for inferring facts, an embedded implication plays the role of assuming its premise for deriving its consequence. A former work introduced both a formal framework and a goal-oriented tabled implementation, allowing negation in rule bodies. While in that work positive assumptions for both facts and rules can occur in the premise, negative assumptions are not allowed. In this work, we cover this subject by introducing a new concept: a restricted predicate, which allows negative assumptions by pruning the usual semantics of a predicate. This new setting has been implemented in the deductive system DES.", "histories": [["v1", "Tue, 22 Dec 2015 03:16:55 GMT  (29kb)", "http://arxiv.org/abs/1512.06945v1", "In Proceedings PROLE 2015,arXiv:1512.06178"]], "COMMENTS": "In Proceedings PROLE 2015,arXiv:1512.06178", "reviews": [], "SUBJECTS": "cs.DB cs.AI cs.LO", "authors": ["fernando s\\'aenz-p\\'erez"], "accepted": false, "id": "1512.06945"}, "pdf": {"name": "1512.06945.pdf", "metadata": {"source": "CRF", "title": "Restricted Predicates for Hypothetical Datalog", "authors": ["Fernando S\u00e1enz-P\u00e9rez"], "emails": ["fernan@sip.ucm.es"], "sections": [{"heading": null, "text": "Marisa Navarro (ed.): Proceedings PROLE 2015 EPTCS 200, 2015, pp. 64-79, doi: 10.4204 / EPTCS.200.5c \u00a9 F. Sa'enz-Pe \"rez This work is licensed under the Creative Commons Attribution License.Restricted Predicates for Hypothetical DatalogFernando Sa\" enz-Pe \"rez\" Facultad de Informa \"tica Universidad Complutense de MadridMadrid, Spainfernan @ sip.ucm.esHypothetical Datalog is based on an intuitionist semantics and not on a classical logical semantics, and embedded implications are allowed in regulatory bodies. While the usual implication (i.e. the neck of a horn clause) stands for derivative facts, an embedded implication plays the role of its prediction for the derivation of its consequences. An earlier work introduced both a formal framework and a target on this work, we can include both the negative one, and the negative one, in the work related to this rule work, while the negative one can also include the negative one, in the work as well."}, {"heading": "1 Introduction", "text": "They are also known as \"what-if\" queries and help managers make decisions about scenarios that have changed somewhat in relation to a current state. Such queries are used, for example, to decide which resources need to be added, changed or removed in order to optimize some criteria (i.e., a cost function, an idea that relates well to optimization technologies).Current applications include OLAP environments [27], business intelligence [11], and e-commerce [26].Even the major relational database providers include (fairly limited) approaches to hypothetical queries, such as the model clause in Oracle SQL, data warehousing [16].While such systems and applications are inherited from relational databases and restrict the use of negation and recursion, previous work on logical programming completely enters the transmission system."}, {"heading": "2 Introductory Example", "text": "In logical programming, in the context of deductive databases, the term relation is used interchangeably with predicate, rule with clause, and term query with target. Furthermore, we identify two components of a deductive database: the Extensive Database (EDB), which is composed of predicates defined only by facts, and the Intensive Database (IDB), which is composed of predicates defined by at least one rule. Henceforth, all examples written in true type can actually be executed in DES. Before introducing the example and others in the next sections, we recall the concrete syntax of hypothetical queries and expand the premise to include limiting rules. These limiting rules will be useful to answer questions with embedded implications that are not possible in [4] or [17]."}, {"heading": "2.1 Concrete Syntax", "text": "The syntax of a hypothetical query in the DES system is as follows: rule 1 /\\... /\\ ruleN = > target, where each rule can be a regular (common) rule or a constraining rule. A constraining rule has a head in the form -atom, where atom is an atom. In fact, the body is empty (not even a neck symbol) and the atom is grounded to ensure safety [24] (rules and queries must also be safe).Such a hypothetical query represents this, provided that the current database is extended by the regular rules in R = {rulei | 1 \u2264 i \u2264 N} and that the meaning of the constraining rules in R is removed from their corresponding predicates, then the target is calculated with respect to such a modified current database. Note that the implication symbol = > (intuitionistic implication to the right) is not used for either the so-called literary implication or the implication."}, {"heading": "2.2 A University Example", "text": "Following an example from [4], we look at an extended and customized rules-based system for describing a higher education policy (> grad). EDB is made up of: Student (S) (which means S is a student), Course (C) (C is a course), and Take (S, C) (Student S takes Course C). And IDB is: Grade (S) (Student S is eligible for graduation). EDB contains facts as: Student (adam). Student (scott). Take (adam, eng). Take (scott, eng). Take (scott, eng). Take the answer: Student (s). Take (scott, lp). Take Course (lp). Take (tony, eng)."}, {"heading": "3 Restricted Predicates: Informal Semantics", "text": "In fact, it is such that most of them will be able to move to another world, in which they are able, in which they are able, in which they are able to live, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they live, that they are"}, {"heading": "4 Formal Framework", "text": "This section introduces some formal background information to describe the hypothetical datalog approach we are considering as an extension of the dysfunctional horn logic following [4, 5]. At this point, we recall and adapt the formal framework already outlined in [17] and present the syntax of language, security conditions, the concept of stratifiable program, and an operative semantic extract that extends [17] with negative assumptions as limiting rules. [17] The main difference between the contents presented here is the inclusion of restricted predicates. [17]"}, {"heading": "4.1 Syntax", "text": "The syntax of logic is the first order and includes a universe of constant symbols, a set of variables, and a set of predicate symbols (P). For concrete symbols, we write variables that begin with uppercase letters and the rest of symbols that begin with lowercase letters. Removing function symbols from logic is a condition for the finiteness of answers, a natural requirement of database users. A rule has the form A \u2190 R, where the premise R is either a regular atom or a limiting atom, and \u03c6 is a conjunction of goals. Furthermore, since we consider a hypothetical system, a goal can also take the form G \u2190 R, a construction known as an embedded implication, where the premise R is an assumption and takes the form of a rule. Furthermore, [5] by first allowing the premise to be a conjunction of rules that is a conjunction of rules, and secondly, by restricting the Ri to either a rule, and vice versa premise to Ri, we extend the premise to Ri."}, {"heading": "4.2 Predicate Dependency Graph and Stratification", "text": "The introduction of negation in the words of the body clauses adds another problem: the possibility of having more than one minimum model [24]. Stratification is a syntactic condition for programs that ensures that only one minimum model can be assigned to a program. Predicates in the program are divided into layers so that negation does not occur through recursion. In order to build a layering (i.e. a mapping between predicate symbols and natural numbers), a device called a predicate dependency graph (PDG) is usually useful. A PDG represents the positive and negative dependencies between predicates. Definition 2 (Dependencies) A predicate P positive (negative or resp.) depends on Q if P is the predicate symbol of A in a rule (both a program rule and a rule in a premise)."}, {"heading": "4.3 Stratified Inference", "text": "The following logical conclusion is applied in the sequence of multiple occurrences of the same program: \"It is a system with the following fundamental differences.\" (\"It is a system in which duplicates, integrity constraints, premises with multiple rules, and the enforcement of variable implications in premises can be defined.\" (\"It is a system in which the information is derived from the bottom layer and its derivatives extended to the next layer.\") \"Conclusions are required, which are constructed by the axioms derived from the bottom layer, and the rules defining the predicates belonging to the first layer.\" (\"It is an empty set for the first layer.\") Here we look at programs that are both safe and stratifiable. (\"It is not possible to draw conclusions about the second layer.\")"}, {"heading": "5 Implementation", "text": "In the last section, an operational semantics has been introduced that builds the semantics of the entire database in a purely bottom-up manner. At this point, we recall some implementation details [17] and adjust them to support negative assumptions and limited predicates. Therefore, we consider a top-down, bottom-up fixed-point calculation with tables, as implemented in the deductive system DES [19], which follows the ideas found in [8, 23], which is implemented in Prolog and included for the first time in version 3.2 (February 2013) hypothetical datalog. Version 3.6 (March 2014) improved this by allowing negative assumptions as well as the dynamic construction of the GDG and stratification. Next, we describe the implementation of tables, negative assumptions in premises and some optimizations."}, {"heading": "5.1 Tabling", "text": "Although there has been some work on implementations [25] as far as we know, there is no implementation of hypothetical databases based on tables that allow both embedded implications and stratified negation. Tabling faces some well-known problems with logical programming systems [12, 22] and in particular with deductive databases (e.g., [20, 18]). Systems that implement the deduced instances (responses) to targets (responses) in a response table and a call table (each in the order of already available derivatives) store the target calls along the resolution and a response table in stores (bottom). 1 Release in des.sourceforge.net lists all of their historical objectives."}, {"heading": "5.2 An Example", "text": "Following an analogue example to the one in section III.B in [17]: Route (X, Y) \u2190 connected (X, Y), Route (X, Y), Route (X, Y), Route (X, Z), Route (Z, Y), Route (X, Y), Route (X), Station (Y), Route (X, Y), for which the PDG < {Station, Connected, Route, No Route}, {Route, Route, Route, Route, Route, No Route, Station, Route, Station, Station, Route, Layering is {(Station, 1), (Connected, 1), (No Route, 2)} Consider then, in addition to this database, the predicate closed / 1, which lists stations that must be closed at some point due to the execution. The following rule allows to know what the possible connections under such assumption are: Restricted Route (X, Y), Route (2, Route (A, B), Route, Route, 2, Route, Route, B, Route (2, Route, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, 1.1, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A,"}, {"heading": "5.3 Implementing Tabling", "text": "DES implements implications in the prologue, as described in [17]. If one remembers that each time an implication is to be solved, a new context is created by adding the rules and facts in the premise to the current database, the same program point is reached to solve the implication based on the fixed point calculation (according to a new iteration), then the database is not changed, because the program rules for the premise are already loaded and marked for that context. Entries in the call and response tables are marked accordingly, so that the result for a given context can also be identified. Solving a target g in a layer greater than 1 is done by layered calculation, as described in [17], i.e. solving the layer by layer describes the meaning of the predicates involved, on which g depends negatively, and the solution g with the results for other predicates already stored in the answer table."}, {"heading": "5.3.1 Solving Restricted Predicates", "text": "In fact, it is that it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it"}, {"heading": "5.3.2 Dynamic PDG and Stratification", "text": "Section 4.2 introduced the construction of the predicate dependency graph by taking into account all rules defined in the program (> r), including those in the history of embedded implications. However, a more refined approach can be considered by building a PDG and stratification for each context. Indeed, rules that are not part of a given context can introduce negative dependencies that imply solving the full meaning of a given predicate rather than just taking into account its actual context. For example, see rules p (X) \u2190 t (X) and q (X) \u2190 (Y) \u2190 (Y) n (Y) n (Y) n (Y)."}, {"heading": "5.3.3 Reusing Answers from Previous Contexts", "text": "This is a conservative approach, but previous calculations in earlier contexts can be reused to avoid some recalculations, i.e. the reuse of entries in the answer table. For the target-only database, which consists of only a single layer, this reuse is safe, since only additions to the answer table are possible. Thus, queries can be made from the answer table from the first context to the current one. However, if the negation is involved in this limited database, some already derived information may not be correct in a previous context. Consider, for example, the program that consists of the determined rules (1, []): p \u00b2 q and (2, []: r \u00b2 q \u00b2 p. The target p succeeds in the original context, but fails in the context [2] in solving the conclusion p. A simple implementation to address this problem is simply to avoid the larger layers than those that are directly transferred to another layer."}, {"heading": "6 Conclusions and Future Work", "text": "This paper has presented a novel add-on to deductive databases: hypothetical rules with negative assumptions in the premise of embedded implications that extend both [5] and [17]; the work [5] has been expanded to include restrictive rules in the premise (not just facts), while maintaining the extensions in [17] (duplicates and strong constraints); [17] has also been expanded by providing the novel concept of restricted predicates as a means of circumventing the meaning of predicates based on negative assumptions; in addition, a dynamic construction of the PDG has been proposed, as well as further optimization for the intersection of calculations; we have described an implementation of our proposal as part of the publicly available DES system. Since SQL queries are translated into DES in data rules, this technique also supports negative assumptions in SQL queries (version 3.10, January 2015); as future work, we note that the optimization for unforeseeable hypotheses should be transferred to the current ones."}], "references": [{"title": "An extended constraint deductive database: Theory and implementation", "author": ["Gabriel Aranda", "Susana Nieva", "Fernando Saenz-Perez", "Jaime Sanchez-Hernandez"], "venue": "Journal of Logic and Algebraic Programming", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Incorporating Hypothetical Views and Extended Recursion into SQL Database Systems", "author": ["Gabriel Aranda", "Susana Nieva", "Fernando Saenz-Perez", "Jaime S\u00e1nchez-Hern\u00e1ndez"], "venue": "editors: LPAR-19, EPiC Series", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Hypothetical Datalog: Negation and Linear Recursion", "author": ["Anthony J. Bonner"], "venue": "Proceedings of the PODS ACM Symposium,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1989}, {"title": "Hypothetical Datalog: Complexity and Expressibility", "author": ["Anthony J. Bonner"], "venue": "Theoretical Computer Science", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1990}, {"title": "Adding Negation-as-Failure to Intuitionistic Logic Programming", "author": ["Anthony J. Bonner", "L. Thorne McCarty"], "venue": "editors: Proc. of the North American Conference on Logic Programming,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1990}, {"title": "A Practical Approach to Hypothetical Database Queries", "author": ["Henning Christiansen", "Troels Andreasen"], "venue": "In: Transactions and Change in Logic Databases,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Extension Tables: Memo Relations in Logic Programming", "author": ["Suzanne W. Dietrich"], "venue": "IEEE Symp. on Logic Programming,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1987}, {"title": "N-Prolog: An Extension of Prolog with Hypothetical Implication II - Logical Foundations, and Negation as Failure", "author": ["Dov M. Gabbay"], "venue": "JLP", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1985}, {"title": "Classical Negation in Logic Programs and Disjunctive Databases", "author": ["Michael Gelfond", "Vladimir Lifschitz"], "venue": "New Generation Computing", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1991}, {"title": "What-if Simulation Modeling in Business Intelligence", "author": ["Matteo Golfarelli", "Stefano Rizzi"], "venue": "IJDWM", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "An improved continuation call-based implementation of tabling", "author": ["Pablo Chico de Guzm\u00e1n", "Manuel Carro", "Manuel V. Hermenegildo", "Cl\u00e1udio Silva", "Ricardo Rocha"], "venue": "Proc. of the 10th International Conference on Practical Aspects of Declarative Languages,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Clausal Intuitionistic Logic I - Fixed-Point Semantics", "author": ["L. Thorne McCarty"], "venue": "JLP", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "A Theory of Modules for Logic Programming", "author": ["Dale Miller"], "venue": "In: Symp. Logic Programming,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1986}, {"title": "Uniform Proofs as a Foundation for Logic Programming", "author": ["Dale Miller", "Gopalan Nadathur", "Frank Pfenning", "Andre Scedrov"], "venue": "Annals of Pure and Applied Logic", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1991}, {"title": "Implementing Tabled Hypothetical Datalog", "author": ["Fernando S\u00e1enz-P\u00e9rez"], "venue": "Proceedings of the 25th IEEE International Conference on Tools with Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Tabling with Support for Relational Features in a Deductive Database", "author": ["Fernando S\u00e1enz-P\u00e9rez"], "venue": "Electronic Communications of the EASST 55,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "A Deductive Database with Datalog and SQL Query Languages", "author": ["Fernando S\u00e1enz-P\u00e9rez", "Rafael Caballero", "Yolanda"], "venue": "Garc\u0131\u0301a-Ruiz", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Embedding Expert Knowledge and Hypothetical Data Bases into a Data Base System", "author": ["Michael Stonebraker", "Kenneth Keller"], "venue": "Proceedings of the 1980 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1980}, {"title": "OLDT Resolution with Tabulation", "author": ["Hisao Tamaki", "Taisuke Sato"], "venue": "Third International Conference on Logic Programming,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1986}, {"title": "Database and Knowledge-Base Systems, Vols. I (Classical Database Systems) and II (The New Technologies)", "author": ["Jeffrey D. Ullman"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1988}, {"title": "The EKS-V1 System", "author": ["Laurent Vieille", "Petra Bayer", "Volker K\u00fcchenhoff", "Alexandre Lefebvre", "Rainer Manthey"], "venue": "editor:  LPAR,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1992}, {"title": "Applying Hypothetical Queries to E-Commerce Systems to Support Reservation and Personal Preferences", "author": ["Yu Zhang", "Huajun Chen", "Hao Sheng", "Zhaohui Wu"], "venue": "Proc. of IDEAS \u201907,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Hypothetical Queries on Multidimensional Dataset", "author": ["Guoliang Zhou", "Hong Chen", "Yansong Zhang"], "venue": "editors: Proc. of BIFE,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}], "referenceMentions": [{"referenceID": 22, "context": "Current applications include OLAP environments [27], business intelligence [11], and e-commerce [26].", "startOffset": 47, "endOffset": 51}, {"referenceID": 9, "context": "Current applications include OLAP environments [27], business intelligence [11], and e-commerce [26].", "startOffset": 75, "endOffset": 79}, {"referenceID": 21, "context": "Current applications include OLAP environments [27], business intelligence [11], and e-commerce [26].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "These approaches [13, 14, 9] fit into intuitionistic logic programming, an extension of logic programming including both embedded implications and negation.", "startOffset": 17, "endOffset": 28}, {"referenceID": 12, "context": "These approaches [13, 14, 9] fit into intuitionistic logic programming, an extension of logic programming including both embedded implications and negation.", "startOffset": 17, "endOffset": 28}, {"referenceID": 7, "context": "These approaches [13, 14, 9] fit into intuitionistic logic programming, an extension of logic programming including both embedded implications and negation.", "startOffset": 17, "endOffset": 28}, {"referenceID": 2, "context": "In particular, Hypothetical Datalog [3, 5] has been a proposal thoroughly studied from semantic and complexity point-of-views.", "startOffset": 36, "endOffset": 42}, {"referenceID": 4, "context": "In particular, Hypothetical Datalog [3, 5] has been a proposal thoroughly studied from semantic and complexity point-of-views.", "startOffset": 36, "endOffset": 42}, {"referenceID": 14, "context": "A recent work on tabled Hypothetical Datalog [17] extended [5] by adding a number of extensions: First, allowing to include rules in embedded implication premises, with the intention to allow the user to assume not only facts but also rules.", "startOffset": 45, "endOffset": 49}, {"referenceID": 4, "context": "A recent work on tabled Hypothetical Datalog [17] extended [5] by adding a number of extensions: First, allowing to include rules in embedded implication premises, with the intention to allow the user to assume not only facts but also rules.", "startOffset": 59, "endOffset": 62}, {"referenceID": 14, "context": "However, while [17] allows to locally add tuples (in the context of an embedded implication) to the database, it lacks the ability to locally delete tuples in the same context.", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "In [4] support for such deletions are provided, though only for facts.", "startOffset": 3, "endOffset": 6}, {"referenceID": 14, "context": "In this paper, we extend [17] by allowing deletions of tuples, not only for facts as data providers as in [4], but also for rules.", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "In this paper, we extend [17] by allowing deletions of tuples, not only for facts as data providers as in [4], but also for rules.", "startOffset": 106, "endOffset": 109}, {"referenceID": 14, "context": "All the features in [17] that extended [5] are preserved in this new deletion setting.", "startOffset": 20, "endOffset": 24}, {"referenceID": 4, "context": "All the features in [17] that extended [5] are preserved in this new deletion setting.", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "Note that intuitionistic implication is not transitive as the classical logic implication [5].", "startOffset": 90, "endOffset": 93}, {"referenceID": 14, "context": "net), completing the implementation described in [17] with support for negation in bodies and restricted predicates in premises.", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "Though there have been some works regarding implementations [25], as far as we know there has not been an implementation of hypothetical Datalog with intensional deletions.", "startOffset": 60, "endOffset": 64}, {"referenceID": 17, "context": "With respect to related work, Date [7] explains the idea behind such \u201cwhat-if\u201d statements, an approach that was firstly proposed in [21] for relational databases.", "startOffset": 132, "endOffset": 136}, {"referenceID": 1, "context": "A recent work [2] also develops this idea by generating database scripts that implement a fixpoint computation for building SQL materialized views as tables.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "In [6], an approach to hypothetical database query evaluation based on counterfactual reasoning is proposed.", "startOffset": 3, "endOffset": 6}, {"referenceID": 13, "context": ", [15]), which lead to the implementation of \u03bbProlog.", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "A more recent work [1] proposes HH\u00ac(C) as a constraint database framework including negation, but with no negative assumptions.", "startOffset": 19, "endOffset": 22}, {"referenceID": 3, "context": "These restricting rules will be useful for answering questions with embedded implications that are neither possible in [4] nor in [17].", "startOffset": 119, "endOffset": 122}, {"referenceID": 14, "context": "These restricting rules will be useful for answering questions with embedded implications that are neither possible in [4] nor in [17].", "startOffset": 130, "endOffset": 134}, {"referenceID": 19, "context": "For facts, the body is empty (no neck symbol either) and the atom is ground to ensure safety [24] (rules and queries must be safe as well).", "startOffset": 93, "endOffset": 97}, {"referenceID": 3, "context": "Borrowing an example from [4], we consider an extended and adapted rule-based system for describing a university policy.", "startOffset": 26, "endOffset": 29}, {"referenceID": 14, "context": "Another option is to avoid cycles by using the following strong constraint (which are defined in [17]):", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "Example 6 Consider a query as: \u201dIf Pete had not taken eng, could he have graduated?\u201d, which is equivalent to say: \u201dIf take(pete,eng) were deleted from the database, could we infer grad(pete)?\u201d This query cannot be solved with the former proposal in [17] but is supported in [4].", "startOffset": 249, "endOffset": 253}, {"referenceID": 3, "context": "Example 6 Consider a query as: \u201dIf Pete had not taken eng, could he have graduated?\u201d, which is equivalent to say: \u201dIf take(pete,eng) were deleted from the database, could we infer grad(pete)?\u201d This query cannot be solved with the former proposal in [17] but is supported in [4].", "startOffset": 274, "endOffset": 277}, {"referenceID": 3, "context": "In turn, this is neither supported by [4] nor by [17].", "startOffset": 38, "endOffset": 41}, {"referenceID": 14, "context": "In turn, this is neither supported by [4] nor by [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 8, "context": "By contrast, this situation in classical negation results in contradiction [10].", "startOffset": 75, "endOffset": 79}, {"referenceID": 19, "context": "This is a similar requirement as done for stratified negation [24] and will be formalized in Section 4.", "startOffset": 62, "endOffset": 66}, {"referenceID": 3, "context": "This section introduces some formal background to describe the approach to hypothetical Datalog we are considering, as an extension of function-free Horn logic following [4, 5].", "startOffset": 170, "endOffset": 176}, {"referenceID": 4, "context": "This section introduces some formal background to describe the approach to hypothetical Datalog we are considering, as an extension of function-free Horn logic following [4, 5].", "startOffset": 170, "endOffset": 176}, {"referenceID": 14, "context": "Here, we recall and adapt the formal framework already presented in [17], presenting the syntax of the language, safety conditions, the notion of stratifiable program, and an operational semantics excerpt that extends [17] with negative assumptions as restricting rules.", "startOffset": 68, "endOffset": 72}, {"referenceID": 14, "context": "Here, we recall and adapt the formal framework already presented in [17], presenting the syntax of the language, safety conditions, the notion of stratifiable program, and an operational semantics excerpt that extends [17] with negative assumptions as restricting rules.", "startOffset": 218, "endOffset": 222}, {"referenceID": 14, "context": "[17] is the inclusion of restricted predicates.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Moreover, we extend [5] by, first, allowing the premise to be a conjunction of rules \u2227 Ri as an assumption, and, second, allowing each Ri to be a either a regular or a restricting rule.", "startOffset": 20, "endOffset": 23}, {"referenceID": 4, "context": "As an embedded implication behaves different from a regular implication [5], it receives a different syntax symbol: \u21d2.", "startOffset": 72, "endOffset": 75}, {"referenceID": 14, "context": "Strong constraints are also supported in this new setting as rules with no head [17], and in the following we assume databases (as a set of rules and constraints) that are safe (with respect to query answers) and consistent (with respect to constraints) [17].", "startOffset": 80, "endOffset": 84}, {"referenceID": 14, "context": "Strong constraints are also supported in this new setting as rules with no head [17], and in the following we assume databases (as a set of rules and constraints) that are safe (with respect to query answers) and consistent (with respect to constraints) [17].", "startOffset": 254, "endOffset": 258}, {"referenceID": 19, "context": "Introducing negation in literals of body clauses adds another issue: The possibility to have more than one minimal model [24].", "startOffset": 121, "endOffset": 125}, {"referenceID": 14, "context": "This fact is propagated to the construction of the predicate dependency graph and the stratification for a program [17].", "startOffset": 115, "endOffset": 119}, {"referenceID": 4, "context": "Following [5] we define a logical inference system for stratified intuitionistic logic programming, with the following main differences: Allowing duplicates, integrity constraints, premises with multiple rules, and enforcing encapsulation of variables in premises.", "startOffset": 10, "endOffset": 13}, {"referenceID": 14, "context": "In [17], the definition of such an inference system can be found by using the adapted notion of inference expression in Definition 3 above.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "Like all Gentzen-style inference systems, ds : A \u2192 A enjoys monotonicity, idempotence and inflationaryness [17], where A denotes the set of inference expressions for programs.", "startOffset": 107, "endOffset": 111}, {"referenceID": 19, "context": "The negative information is deduced by applying the closed world assumption (CWA) [24] to inference expressions.", "startOffset": 82, "endOffset": 86}, {"referenceID": 14, "context": "Definition 13 in [17] describes the unified stratified semantics as the bottom-up construction of the semantics, stratum by stratum, in which the inductive step A s+1 = cwa(ds+1(A s)) for s \u2265 0 builds the semantics of the database in a finite number of steps (the number of strata is finite and no function symbols are allowed).", "startOffset": 17, "endOffset": 21}, {"referenceID": 14, "context": "Here, we recall some implementation details from [17] and adapt it to support negative assumptions and restricted predicates.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "So, we consider a top-down-driven, bottom-up fixpoint computation with tabling as implemented in the deductive system DES [19], which follows the ideas found in [8, 23].", "startOffset": 122, "endOffset": 126}, {"referenceID": 6, "context": "So, we consider a top-down-driven, bottom-up fixpoint computation with tabling as implemented in the deductive system DES [19], which follows the ideas found in [8, 23].", "startOffset": 161, "endOffset": 168}, {"referenceID": 18, "context": "So, we consider a top-down-driven, bottom-up fixpoint computation with tabling as implemented in the deductive system DES [19], which follows the ideas found in [8, 23].", "startOffset": 161, "endOffset": 168}, {"referenceID": 20, "context": "Though there have been some works regarding implementations [25], as far as we know there has not been an implementation of hypothetical Datalog based on tabling and allowing both embedded implications and stratified negation.", "startOffset": 60, "endOffset": 64}, {"referenceID": 10, "context": "It has been applied to different fields (logic programming systems [12, 22]) and in particular to deductive databases (e.", "startOffset": 67, "endOffset": 75}, {"referenceID": 15, "context": ", [20, 18]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 14, "context": "Filling the answer and call tables is due to the so-called memo function which proceeds by tabled SLDNF resolution as detailed in [17].", "startOffset": 130, "endOffset": 134}, {"referenceID": 14, "context": "The goal dependency graph is specified in [17] as the function gdg(\u2206,\u03c6) which is applied to a program \u2206 and goal \u03c6 , returning the pair of nodes and arcs < N,A >.", "startOffset": 42, "endOffset": 46}, {"referenceID": 14, "context": "We refer here to [17] for the definitions of the stratified meaning of a program restricted to a goal (Definition 19), the fixpoint of the database built with \u2294 n\u22650, and the meaning of a tabled goal (Definition 20).", "startOffset": 17, "endOffset": 21}, {"referenceID": 14, "context": "B in [17]: route(X ,Y )\u2190 connected(X ,Y )\u2228 connected(Y,X) route(X ,Y )\u2190 route(X ,Z)\u2227 route(Z,Y ) no route(X ,Y )\u2190 station(X)\u2227 station(Y )\u2227\u00acroute(X ,Y ) for which its PDG is < {station, connected, route, no route}, {route \u2190 connected, route \u2190 route, no route \u2190 station, no route \u00ac \u2190 route}>, and a stratification is {(station,1), (connected,1), (route,1), (no route,2)}.", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "DES implements implications in Prolog as described in [17].", "startOffset": 54, "endOffset": 58}, {"referenceID": 14, "context": "Solving a goal g in a stratum greater than 1 proceeds by stratified computation as described in [17], i.", "startOffset": 96, "endOffset": 100}, {"referenceID": 14, "context": "B in [17]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": "When solving the query q(X), the following PDG and strata are computed for the new context [1] due to the assumption in rule (1,[]), which can be displayed by enabling verbose output (with /verbose on).", "startOffset": 91, "endOffset": 94}, {"referenceID": 0, "context": "Info: Building hypothetical computation context [1] for: p(Y) :- t(Y), not r(Y).", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "The goal p succeeds in the initial context [], but fails in the context [2] when solving the conclusion p.", "startOffset": 72, "endOffset": 75}, {"referenceID": 4, "context": "This work has presented a novel add-on to deductive databases: hypothetical rules with negative assumptions in the premise of embedded implications, extending both [5] and [17].", "startOffset": 164, "endOffset": 167}, {"referenceID": 14, "context": "This work has presented a novel add-on to deductive databases: hypothetical rules with negative assumptions in the premise of embedded implications, extending both [5] and [17].", "startOffset": 172, "endOffset": 176}, {"referenceID": 4, "context": "The work [5] has been extended with restricting rules in the premise (not only facts), retaining also the extensions in [17] (duplicates and strong constraints).", "startOffset": 9, "endOffset": 12}, {"referenceID": 14, "context": "The work [5] has been extended with restricting rules in the premise (not only facts), retaining also the extensions in [17] (duplicates and strong constraints).", "startOffset": 120, "endOffset": 124}, {"referenceID": 14, "context": "Also, [17] has been extended by providing the novel concept of restricted predicates as a means to prune the meaning of predicates due to negative assumptions.", "startOffset": 6, "endOffset": 10}], "year": 2015, "abstractText": "Hypothetical Datalog is based on an intuitionistic semantics rather than on a classical logic semantics, and embedded implications are allowed in rule bodies. While the usual implication (i.e., the neck of a Horn clause) stands for inferring facts, an embedded implication plays the role of assuming its premise for deriving its consequence. A former work introduced both a formal framework and a goal-oriented tabled implementation, allowing negation in rule bodies. While in that work positive assumptions for both facts and rules can occur in the premise, negative assumptions are not allowed. In this work, we cover this subject by introducing a new concept: a restricted predicate, which allows negative assumptions by pruning the usual semantics of a predicate. This new setting has been implemented in the deductive system DES.", "creator": "LaTeX with hyperref package"}}}