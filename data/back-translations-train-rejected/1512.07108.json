{"id": "1512.07108", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2015", "title": "Recent Advances in Convolutional Neural Networks", "abstract": "In the last few years, deep learning has lead to very good performance on a variety of problems, such as object recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Due to the lack of training data and computing power in early days, it is hard to train a large high-capacity convolutional neural network without overfitting. Recently, with the rapid growth of data size and the increasing power of graphics processor unit, many researchers have improved the convolutional neural networks and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. Besides, we also introduce some applications of convolutional neural networks in computer vision.", "histories": [["v1", "Tue, 22 Dec 2015 14:54:34 GMT  (1693kb,D)", "http://arxiv.org/abs/1512.07108v1", "review, journal"], ["v2", "Tue, 5 Jul 2016 11:39:16 GMT  (578kb,D)", "http://arxiv.org/abs/1512.07108v2", "review, journal"], ["v3", "Mon, 1 Aug 2016 01:54:59 GMT  (439kb,D)", "http://arxiv.org/abs/1512.07108v3", "review, journal"], ["v4", "Sat, 6 Aug 2016 12:38:35 GMT  (438kb,D)", "http://arxiv.org/abs/1512.07108v4", "review, journal"], ["v5", "Thu, 5 Jan 2017 05:45:53 GMT  (3100kb,D)", "http://arxiv.org/abs/1512.07108v5", "review, journal"], ["v6", "Thu, 19 Oct 2017 16:34:35 GMT  (4099kb,D)", "http://arxiv.org/abs/1512.07108v6", "Pattern Recognition, Elsevier"]], "COMMENTS": "review, journal", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jiuxiang gu", "zhenhua wang", "jason kuen", "lianyang ma", "amir shahroudy", "bing shuai", "ting liu", "xingxing wang", "gang wang"], "accepted": false, "id": "1512.07108"}, "pdf": {"name": "1512.07108.pdf", "metadata": {"source": "CRF", "title": "Recent Advances in Convolutional Neural Networks", "authors": ["Jiuxiang Gu", "Zhenhua Wang", "Jason Kuen", "Lianyang Ma", "Amir Shahroudy", "Bing Shuai", "Ting Liu", "Xingxing Wang", "Gang Wang"], "emails": ["jxgu@ntu.edu.sg;", "wzh@ntu.edu.sg;", "jasonkuen@ntu.edu.sg;", "lyma@ntu.edu.sg;", "amir3@ntu.edu.sg;", "BSHUAI001@e.ntu.edu.sg;", "LIUT0016@e.ntu.edu.sg;", "wangxx@ntu.edu.sg;", "WangGang@ntu.edu.sg)."], "sections": [{"heading": null, "text": "Index Terms - Convolutional Neural Network, Deep learning.I. INTRODUCTIONAL NETWORKS show the basic network.eUs (CNN) is first introduced by LeCun et al. in [1] and then improved in [2]. They developed a multi-layered artificial neural network called LeNet5, which can classify handwritten numerals. Like other neural networks, LeNet-5 works with several layers and can be trained using the back-propagation algorithm [3]. It can obtain effective representations of the original image, which allows visual patterns to be detected directly from raw pixels with little to no pre-processing. However, due to the lack of large training data and computing power during this time, LeNet-5 cannot respond well to more complex problems, such as large-scale image and video classification. Since 2006, many methods have been developed to overcome the difficulties in forming deep neural networks."}, {"heading": "II. BASIC CNN COMPONENTS", "text": "There are numerous variants of CNN architectures in the literature. However, their basic components are very similar. The basic CNN architecture usually consists of three types of layers, namely convolutional layers, pool layers and fully networked layers. Fig 1 shows the architecture of LeNet-5 [1], designed by Yann LeCun.The convolutional layer aims to learn the representation of inputs. As shown in Fig 1, convolutional layer consists of several function boards. Each neuron of a function board is associated with a neighborhood of neurons in the previous layer. Such a neighborhood is referred to as a receptive field in the previous layer."}, {"heading": "A. Convolutional layer", "text": "It works well for abstraction if instances of latent concepts are linearly separable. Here, we present two works aimed at improving their representational capacity: Network In Network (NIN) is a general network structure proposed by Lin et al. [15] It replaces the linear filter of the revolutionary layer with a micro-network, e.g., multi-layer perceptron layer in the paper, which makes it possible to approximate more abstract representations of latent concepts. Formally, the features of the revolutionary layers are as follows: fi, j, kwkwwm, j, j, j, j, j, i, i, i, i."}, {"heading": "B. Pooling layer", "text": "It reduces the computing load by reducing the number of connections between different levels. (In this section we will introduce some newer pooling methods, which in CNNs.1) Lp pooling allows a better generalization than maximum pooling. (In this section we will introduce some newer pooling methods, which in the [19], [20], indicate that Lp pooling can be a better generalization than maximum pooling. (...) N i = 1, xIi = 1, where {xI1} is a series of input nodes. (If Lp = 1, Lp = 2, Lp = 2, Lp = 2, L2 = reduced.) Finally, if p = 2, Lp = 2, Lp reduces to max pooling.2) Mixed pooling."}, {"heading": "C. Activation function", "text": "In this section we will introduce the latest activation functions in CNNs.1) ReLU: ReLU is one of the most notable unsaturated activation functions. ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are defined as: ReLU activation functions are not defined as: ReLU activation functions are defined as: ReLU activation functions are not defined as: ReLU activation functions are defined as: ReLU activation functions are not defined as negative parts, they are reduced as positive parts, they are not reduced as positive parts, LU activation functions are not defined as positive parts, LU are not defined as positive parts."}, {"heading": "D. Loss function", "text": "It is important to choose a suitable loss function for a specific task. We present three representative ones in this subsection: Softmax loss = max loss = max loss, hinge loss and contrastive losses (1) Softmax loss: Softmax loss is a commonly used loss function, which is essentially a combination of multinomial logistic loss and Softmax. Given is a training set {(i), y (i), and y (i) is its class designation. The prediction a (i) j of the j-th class for i-th input is transformed with the following Softmax function: pij = e a (i) j / K \u2212 1, the comparison class l = 0 ea (i) l (13) Softmax turns the predictions into non-negative values and normalizes them to obtain a probability distribution across classes."}, {"heading": "E. Regularization", "text": "Subsequently, we present some effective regulation techniques: Dropout [6], [40], [41] and DropConnect [21]. Dropout is first introduced by Hinton et al. [6], and it has proven to be very effective when it comes to reducing indebtedness. (6) Dropout is applied to fully connected layers. Dropout output is r = a (Wv), where v = 1, v2, vn] T is the output of the feature extractor, (a) No-Drop Out (c) DropConnectFig. 3: Illustration of No-Drop-Fig-Fig."}, {"heading": "F. Optimization", "text": "In this subsection we will discuss some key techniques for optimizing CNNs.1) Weights Initialization: Building a deep CNN model is difficult because in general the model has an enormous amount of parameters and the loss function is not convex. To achieve rapid convergence in training, correct initialization is one of the most important requirements. The bias parameters can be set to zero, while the weight parameters should be carefully initialized to break the symmetry between hidden units of the same layer. Unlike us, if we simply initialize all weights to the same value, e.g. zero or one, each hidden unit of the same layer will receive exactly the same signal. The most commonly used initialization method is the random setting of weights according to Gaussian Distributions [4], [6], [8], [43]. Glorot and Bengio [44] suggest a normalized initialization."}, {"heading": "IV. FAST PROCESSING OF CNNS", "text": "As computer vision and machine learning challenges mount, models of deep neural networks are becoming more complex, and these powerful models require more data for training to avoid overadjustment. Meanwhile, the big training data also presents new challenges, such as how to train the networks in a practical time. In this section, we present some fast processing methods of CNNs."}, {"heading": "A. FFT", "text": "Mathieu et al. [25] perform the revolutionary operation in the Fourier domain with FFTs. Using FFT-based methods has many advantages. Firstly, the Fourier transformations of filters can be reused because the filters are intertwined with multiple images in a mini-batch. Secondly, the Fourier transformations of the output channels can only be reused once per output channel and image when gradients are backpropagated both to filters and to input images. Finally, summing can be performed via input channels in the Fourier domain, so that inverse Fourier transformations are required only once per output channel and image. Some GPU-based libraries have already been developed to speed up the training and testing process, such as cuDNN [56] and fbfft [57]. However, using FFT to perform convolution requires additional memories to store the characteristics cards of the filters as are common in the domain."}, {"heading": "B. Matrix Factorization", "text": "Considering a m \u00b7 n matrix A of rank r, there is a factorization A = B \u00b7 C, where B is a m \u00b7 r complete column rank matrix and C is a r \u00b7 n complete row rank matrix. Thus, we can replace A with B and C. To reduce the parameters of A by a fraction p, it is crucial to ensure that mr + rn < pmn, i.e., the rank of A should satisfy the methods of r < pmn / (m + n). To achieve this, [59] the low-grade matrix factorization applies to the final weight layer in a deep CNN, resulting in an acceleration of 30-50% in training time with little loss of accuracy. Similarly [60], Vameter Parameter applies vameter decomposition to each level of a deep CNN to reduce the model size by 71% with less than 1% relative accuracy."}, {"heading": "V. APPLICATIONS OF CNNS", "text": "In this section, we present some recent work that CNNs use to achieve state-of-the-art performance, including image classification, object tracking, estimation, text recognition, visual validity recognition, action detection and scene captioning. Image ClassificationCNNs have long been used in image classification networks [68-71]. Compared with other methods, CNNs can achieve better classification accuracy in large databases [4], [8], [73] due to their ability to learn common features and classification systems. The breakthrough of large format image classification comes in 2012. Alex Krizhevsky et al. [4] develops the AlexNet classes and achieves the best performance in ILSVRC 2012. Following the success of AlexNet, several papers have achieved significant improvements in classification accuracy by either reducing the size of the filters or expanding the network depth. [8] [74] The structure of a hierarchical hierarchy is a large hierarchy strategy."}, {"heading": "B. Object tracking", "text": "The success of object tracking greatly depends on how robust the representation of the appearance of the target is against several challenges such as point of view changes, lighting changes and occlusions. CNNs have recently attracted a lot of attention in the computer vision community as well as visual tracking field. There are several attempts to use CNNs for visual tracking. Fan et al. [93] use CNN as a base learner, learning a separate class-specific network to track objects. In [93], the authors design a CNN tracker with a shift-variant architecture. Such an architecture plays a key role in transforming the CNN model from a detector into a tracker. Functions are learned during offline training. Unlike traditional trackers that only extract local spatial structures, this CNN-based tracking method extracts both spatial and temporal structures by taking into account the images of two consecutive frames."}, {"heading": "C. Pose estimation", "text": "As the breakthrough in deep structural learning, many current works pay more attention to learning multiple levels of representations and abstractions based on two widely used methods, [102] Human-body-pose estimation task has been achieved with CNNs. Like other visual recognition tasks, the current performance of CNNs to the task of estimating the human body 104 is a significant improvement due to the large learning capacity of CNNs and the availability of more comprehensive training possibilities. [DeepPose [97] is the first application of CNNs to the estimation of the human body. In this work, the estimation of the pose is formulated as a CNN-based regression problem for body coordinates. A cascade of 7-layered CNNs are presented to reason over the pose in a holistic way. In contrast to the previous work, which usually explicitly sketch graphic models and partial detectors, the DeepPose describes a holistic view of the human pose by completing the entire context of the body image."}, {"heading": "D. Text detection and recognition", "text": "The role of text recognition in picture-to-end text spotting, which integrates both text recognition and text recognition, has long been extensively studied. Traditionally, optical character recognition (OCR 110) has been the main focus. OCR techniques mainly perform text recognition on images in more constrained visual environments (e.g., clean background, well-aligned text). Lately, the focus on text recognition has shifted to scene images, due to the growing trend of high-level visual understanding in computer vision. Scene images are taken in unconstrained environments where there is a large amount of appearance variation that poses major difficulties for existing OCR techniques. Such a concern can be mitigated by the use of stronger and richer representations, such as those learned from CNN models. Along the line of improving the performance of text recognition with CNN, some works are suggested (the work can be categorized in three types)."}, {"heading": "F. Action recognition", "text": "Action recognition, the behavioral analysis of human subjects and classification of their activities based on their visual appearance and motion dynamics, is effectively one of the most challenging problems in computer vision. In general, this problem can be divided into two major groups: Action analysis in still images and in videos. For both of these two groups, effective CNN-based methods are proposed. In this subsection, we briefly present the latest advances in these two groups.1) Action Recognition in Still Images: The work of [129] has shown that the results of the last layers of a trained CNN can be used as a general visual feature for a variety of tasks. The same intuition is used for action detection by [8], [130] in which they use the outputs of the penultimate layer of a trained CNN to present complete images of actions as well as the human bounding boxes in them, and achieve a high level of performance in the action classification. Gkioxari et al al al al al al al al al al al al al al al al al al al al al al al."}, {"heading": "G. Scene Labeling", "text": "In fact, most of them are only a very small group, able to play by the rules without being able to play by the rules."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we give a comprehensive overview of the recent progress of CNNs. We have discussed CNN's improvements under various aspects, namely layer design, activation, loss function, regularization, optimization, and fast computation. We focus on the application of CNNs in computer vision tasks and present some CNN-based work that delivers state-of-the-art performance, including image classification, object tracking, pose estimation, text recognition, visual recognition, action detection, and scene labeling. Although CNN has achieved great success in experimental evaluation, there is still a lack of theoretical evidence as to why it works. It is desirable to make more efforts to investigate the basic principles of CNNs. We hope that this paper will not only provide a better understanding of CNNs, but also facilitate future research activities and application developments in the CNNs field."}, {"heading": "ACKNOWLEDGMENT", "text": "This research was conducted at the Rapid-Rich Object Search (ROSE) Lab at Nanyang Technological University, Singapore. ROSE Lab is supported by the National Research Foundation, Prime Ministers Office, Singapore, through its IDM Futures Funding Initiative and managed by the Office of Interactive and Digital Media."}], "references": [{"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278\u20132324, 1998.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1998}, {"title": "Handwritten digit recognition with a backpropagation network", "author": ["B.B. Le Cun", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Advances in neural information processing systems. Citeseer, 1990.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1990}, {"title": "Theory of the backpropagation neural network", "author": ["R. Hecht-Nielsen"], "venue": "International Joint Conference on Neural Networks, 1989, pp. 593\u2013 605.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1989}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "ICML, 2010, pp. 807\u2013814.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving neural networks by preventing coadaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "ECCV, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "ICLR, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CoRR, vol. abs/1409.4842, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "End-to-end text recognition with convolutional neural networks", "author": ["T. Wang", "D. Wu", "A. Coates", "A. Ng"], "venue": "International Conference on Pattern Recognition (ICPR), 2012, pp. 3304\u20133308.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Linear spatial pyramid matching using sparse coding for image classification", "author": ["J. Yang", "K. Yu", "Y. Gong", "T. Huang"], "venue": "CVPR, 2009.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "A theoretical analysis of feature pooling in visual recognition", "author": ["Y. Boureau", "J. Ponce", "Y. LeCun"], "venue": "ICML, 2010, pp. 111\u2013118.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M. Ranzato", "F.J. Huang", "Y. Boureau", "Y. LeCun"], "venue": "CVPR, 2007.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Deep learning using linear support vector machines", "author": ["Y. Tang"], "venue": "arXiv preprint arXiv:1306.0239, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "CoRR, vol. abs/1312.4400, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Rethinking the Inception Architecture for Computer Vision", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": "2015, arXiv:1512.00567v1.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "A model of neuronal responses in visual area mt", "author": ["E.P. Simoncelli", "D.J. Heeger"], "venue": "Vision research, vol. 38, no. 5, pp. 743\u2013761, 1998.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Complex cell pooling and the statistics of natural images", "author": ["A. Hyv\u00e4rinen", "U. K\u00f6ster"], "venue": "Network: Computation in Neural Systems, vol. 18, no. 2, pp. 81\u2013100, 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Signal recovery from pooling representations", "author": ["J.B. Estrach", "A. Szlam", "Y. Lecun"], "venue": "ICML, 2014, pp. 307\u2013315.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Learned-norm pooling for deep feedforward and recurrent neural networks", "author": ["C. Gulcehre", "K. Cho", "R. Pascanu", "Y. Bengio"], "venue": "Machine Learning and Knowledge Discovery in Databases. Springer, 2014, pp. 530\u2013546.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Regularization of neural networks using dropconnect", "author": ["L. Wan", "M. Zeiler", "S. Zhang", "Y.L. Cun", "R. Fergus"], "venue": "ICML, 2013, pp. 1058\u20131066.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Mixed pooling for convolutional neural networks", "author": ["D. Yu", "H. Wang", "P. Chen", "Z. Wei"], "venue": "Rough Sets and Knowledge Technology. Springer, 2014, pp. 364\u2013375.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "CoRR, vol. abs/1301.3557, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Spectral representations for convolutional neural networks", "author": ["O. Rippel", "J. Snoek", "R.P. Adams"], "venue": "arXiv preprint arXiv:1506.03767, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast training of convolutional networks through ffts", "author": ["M. Mathieu", "M. Henaff", "Y. LeCun"], "venue": "arXiv preprint arXiv:1312.5851, 2013.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Computer Vision\u2013 ECCV 2014, 2014, pp. 346\u2013361.  12", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised discovery of mid-level discriminative patches", "author": ["S. Singh", "A. Gupta", "A. Efros"], "venue": "ECCV, pp. 73\u201386, 2012.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-scale orderless pooling of deep convolutional activation features", "author": ["Y. Gong", "L. Wang", "R. Guo", "S. Lazebnik"], "venue": "ECCV, 2014.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Aggregating local image descriptors into compact codes", "author": ["H. J\u00e9gou", "F. Perronnin", "M. Douze", "J. Sanchez", "P. Perez", "C. Schmid"], "venue": "PAMI, vol. 34, no. 9, pp. 1704\u20131716, 2012.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Rectifier nonlinearities improve neural network acoustic models", "author": ["A.L. Maas", "A.Y. Hannun", "A.Y. Ng"], "venue": "ICML, 2013.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1502.01852, 2015.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1852}, {"title": "Empirical evaluation of rectified activations in convolutional network", "author": ["B. Xu", "N. Wang", "T. Chen", "M. Li"], "venue": "arXiv preprint arXiv:1505.00853, 2015.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast and accurate deep network learning by exponential linear units (elus)", "author": ["D.-A. Clevert", "T. Unterthiner", "S. Hochreiter"], "venue": "arXiv preprint arXiv:1511.07289, 2015.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1302.4389, 2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving deep neural networks with probabilistic maxout units", "author": ["J.T. Springenberg", "M. Riedmiller"], "venue": "arXiv preprint arXiv:1312.6116, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Solving large scale linear prediction problems using stochastic gradient descent algorithms", "author": ["T. Zhang"], "venue": "Proceedings of the twenty-first international conference on Machine learning. ACM, 2004, p. 116.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "The mnist database of handwritten digits", "author": ["Y. LeCun", "C. Cortes", "C.J. Burges"], "venue": "1998.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning a similarity metric discriminatively, with application to face verification", "author": ["S. Chopra", "R. Hadsell", "Y. LeCun"], "venue": "CVPR, 2005.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2005}, {"title": "Deephash: Getting regularization, depth and fine-tuning right", "author": ["J. Lin", "O. Morere", "V. Chandrasekhar", "A. Veillard", "H. Goh"], "venue": "arXiv preprint arXiv:1501.04711, 2015.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Fast dropout training", "author": ["S. Wang", "C. Manning"], "venue": "ICML, 2013.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive dropout for training deep neural networks", "author": ["J. Ba", "B. Frey"], "venue": "Advances in Neural Information Processing Systems, 2013, pp. 3084\u20133092.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient object localization using convolutional networks", "author": ["J. Tompson", "R. Goroshin", "A. Jain", "Y. LeCun", "C. Bregler"], "venue": "arXiv preprint arXiv:1411.4280, 2014.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}, {"title": "Part-based r-cnns for fine-grained category detection", "author": ["N. Zhang", "J. Donahue", "R. Girshick", "T. Darrell"], "venue": "ECCV, 2014, pp. 834\u2013849.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio"], "venue": "International conference on artificial intelligence and statistics, 2010, pp. 249\u2013256.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2010}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "Proceedings of the ACM International Conference on Multimedia. ACM, 2014, pp. 675\u2013678.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["L. Bottou"], "venue": "Proceedings of COMPSTAT, 2010, pp. 177\u2013186.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "Fast training of object detection using stochastic gradient descent", "author": ["R.G.J. Wijnhoven", "P.H.N. de With"], "venue": "ICPR, 2010, pp. 424\u2013 427.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2010}, {"title": "Parallelized stochastic gradient descent", "author": ["M. Zinkevich", "M. Weimer", "L. Li", "A.J. Smola"], "venue": "Advances in neural information processing systems, 2010, pp. 2595\u20132603.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2010}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["B. Recht", "C. Re", "S. Wright", "F. Niu"], "venue": "Advances in Neural Information Processing Systems, 2011, pp. 693\u2013701.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep learning of representations: Looking forward", "author": ["Y. Bengio"], "venue": "Statistical Language and Speech Processing. Springer, 2013, pp. 1\u2013 37.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G. Corrado", "R. Monga", "K. Chen", "M. Devin", "M. Mao", "A. Senior", "P. Tucker", "K. Yang", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, 2012, pp. 1223\u20131231.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2012}, {"title": "Gpu asynchronous stochastic gradient descent to speed up neural network training", "author": ["T. Paine", "H. Jin", "J. Yang", "Z. Lin", "T. Huang"], "venue": "arXiv preprint arXiv:1312.6186, 2013.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2013}, {"title": "A fast parallel sgd for matrix factorization in shared memory systems", "author": ["Y. Zhuang", "W.-S. Chin", "Y.-C. Juan", "C.-J. Lin"], "venue": "Proceedings of the 7th ACM conference on Recommender systems. ACM, 2013, pp. 249\u2013256.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2013}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167, 2015.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2015}, {"title": "cudnn: Efficient primitives for deep learning", "author": ["S. Chetlur", "C. Woolley", "P. Vandermersch", "J. Cohen", "J. Tran", "B. Catanzaro", "E. Shelhamer"], "venue": "arXiv preprint arXiv:1410.0759, 2014.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "Fast convolutional nets with fbfft: A gpu performance evaluation", "author": ["N. Vasilache", "J. Johnson", "M. Mathieu", "S. Chintala", "S. Piantino", "Y. LeCun"], "venue": "arXiv preprint arXiv:1412.7580, 2014.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2014}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "CoRR, vol. abs/1312.6229, 2013.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2013}, {"title": "Low-rank matrix factorization for deep neural network training with high-dimensional output targets", "author": ["T.N. Sainath", "B. Kingsbury", "V. Sindhwani", "E. Arisoy", "B. Ramabhadran"], "venue": "ICASSP, 2013.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2013}, {"title": "Restructuring of deep neural network acoustic models with singular value decomposition.", "author": ["J. Xue", "J. Li", "Y. Gong"], "venue": "in INTER- SPEECH,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2013}, {"title": "Predicting parameters in deep learning", "author": ["M. Denil", "B. Shakibi", "L. Dinh", "N. de Freitas"], "venue": "Advances in Neural Information Processing Systems, 2013, pp. 2148\u20132156.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2013}, {"title": "Exploiting linear structure within convolutional networks for efficient evaluation", "author": ["E.L. Denton", "W. Zaremba", "J. Bruna", "Y. LeCun", "R. Fergus"], "venue": "Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, 2014, pp. 1269\u2013 1277.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2014}, {"title": "Speeding up convolutional neural networks with low rank expansions", "author": ["M. Jaderberg", "A. Vedaldi", "A. Zisserman"], "venue": "arXiv preprint arXiv:1405.3866, 2014.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient scalar quantization of exponential and laplacian random variables", "author": ["G.J. Sullivan"], "venue": "Information Theory, IEEE Transactions on, vol. 42, no. 5, pp. 1365\u20131374, 1996.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 1996}, {"title": "Compressing deep convolutional networks using vector quantization", "author": ["Y. Gong", "L. Liu", "M. Yang", "L. Bourdev"], "venue": "arXiv preprint arXiv:1412.6115, 2014.", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2014}, {"title": "Approximate nearest neighbor search by residual vector quantization", "author": ["Y. Chen", "T. Guan", "C. Wang"], "venue": "Sensors, vol. 10, no. 12, pp. 11 259\u2013 11 273, 2010.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2010}, {"title": "Sequential scalar quantization of color images", "author": ["R. Balasubramanian", "C.A. Bouman", "J.P. Allebach"], "venue": "Journal of Electronic Imaging, vol. 3, no. 1, pp. 45\u201359, 1994.", "citeRegEx": "67", "shortCiteRegEx": null, "year": 1994}, {"title": "Face recognition: A convolutional neural-network approach", "author": ["S. Lawrence", "C.L. Giles", "A.C. Tsoi", "A.D. Back"], "venue": "Neural Networks, IEEE Transactions on, vol. 8, no. 1, pp. 98\u2013113, 1997.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 1997}, {"title": "Best practices for convolutional neural networks applied to visual document analysis", "author": ["P.Y. Simard", "D. Steinkraus", "J.C. Platt"], "venue": "null. IEEE, 2003, p. 958.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2003}, {"title": "Large-scale learning with svm and convolutional for generic object categorization", "author": ["F.J. Huang", "Y. LeCun"], "venue": "CVPR, 2006, pp. 284\u2013291.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2006}, {"title": "Flexible, high performance convolutional neural networks for image classification", "author": ["D.C. Ciresan", "U. Meier", "J. Masci", "L. Maria Gambardella", "J. Schmidhuber"], "venue": "IJCAI Proceedings-International Joint Conference on Artificial Intelligence, vol. 22, no. 1, 2011, p. 1237.", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2011}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L. Li", "K. Li", "F. Li"], "venue": "CVPR, 2009, pp. 248\u2013255.", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2009}, {"title": "The pascal visual object classes challenge: A retrospective", "author": ["M. Everingham", "S.A. Eslami", "L. Van Gool", "C.K. Williams", "J. Winn", "A. Zisserman"], "venue": "IJCV, vol. 111, no. 1, pp. 98\u2013136, 2014.", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic hierarchies for image annotation: A survey", "author": ["A.-M. Tousch", "S. Herbin", "J.-Y. Audibert"], "venue": "Pattern Recognition, vol. 45, no. 1, pp. 333\u2013345, 2012.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2012}, {"title": "Discriminative transfer learning with tree-based priors", "author": ["N. Srivastava", "R.R. Salakhutdinov"], "venue": "Advances in Neural Information Processing Systems, 2013, pp. 2094\u20132102.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning fine-grained features via a cnn tree for large-scale classification", "author": ["Z. Wang", "X. Wang", "G. Wang"], "venue": "arXiv preprint arXiv:1511.04534, 2015.", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2015}, {"title": "Error-driven incremental learning in deep convolutional neural network for largescale image classification", "author": ["T. Xiao", "J. Zhang", "K. Yang", "Y. Peng", "Z. Zhang"], "venue": "Proceedings of the ACM International Conference on Multimedia. ACM, 2014, pp. 177\u2013186.", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2014}, {"title": "Hd-cnn: Hierarchical deep convolutional neural network for image classification", "author": ["Z. Yan", "V. Jagadeesh", "D. DeCoste", "W. Di", "R. Piramuthu"], "venue": "arXiv preprint arXiv:1410.0736, 2014.  13", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated flower classification over a large number of classes", "author": ["M.-E. Nilsback", "A. Zisserman"], "venue": "ICVGIP, 2008, pp. 722\u2013729.", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2008}, {"title": "The caltech-ucsd birds-200-2011 dataset", "author": ["C. Wah", "S. Branson", "P. Welinder", "P. Perona", "S. Belongie"], "venue": "2011.", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2011}, {"title": "Birdsnap: Large-scale fine-grained visual categorization of birds", "author": ["T. Berg", "J. Liu", "S.W. Lee", "M.L. Alexander", "D.W. Jacobs", "P.N. Belhumeur"], "venue": "CVPR, 2014, pp. 2019\u20132026.", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2014}, {"title": "Novel dataset for fine-grained image categorization", "author": ["A. Khosla", "N. Jayadevaprakash", "B. Yao", "L. Fei-Fei"], "venue": "CVPR, 2011.", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2011}, {"title": "A large-scale car dataset for fine-grained categorization and verification", "author": ["L. Yang", "P. Luo", "C.C. Loy", "X. Tang"], "venue": "CVPR, 2015.", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2015}, {"title": "Fine-grained visual comparisons with local learning", "author": ["A. Yu", "K. Grauman"], "venue": "CVPR, 2014, pp. 192\u2013199.", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2014}, {"title": "Improved bird species recognition using pose normalized deep convolutional nets", "author": ["S. Branson", "G. Van Horn", "P. Perona", "S. Belongie"], "venue": "British Machine Vision Conference, 2014.", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2014}, {"title": "Selective search for object recognition", "author": ["J.R. Uijlings", "K.E. van de Sande", "T. Gevers", "A.W. Smeulders"], "venue": "International journal of computer vision, vol. 104, no. 2, pp. 154\u2013171, 2013.", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep lac: Deep localization, alignment and classification for fine-grained recognition", "author": ["D. Lin", "X. Shen", "C. Lu", "J. Jia"], "venue": "CVPR, 2015, pp. 1666\u20131674.", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2015}, {"title": "Mutual-informationbased registration of medical images: a survey", "author": ["J.P. Pluim", "J.A. Maintz", "M. Viergever"], "venue": "Medical Imaging, IEEE Transactions on, vol. 22, no. 8, pp. 986\u20131004, 2003.", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning features and parts for fine-grained recognition", "author": ["J. Krause", "T. Gebru", "J. Deng", "L.-J. Li", "L. Fei-Fei"], "venue": "ICPR, 2014, pp. 26\u201333.", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2014}, {"title": "Fine-grained recognition without part annotations", "author": ["J. Krause", "H. Jin", "J. Yang", "L. Fei-Fei"], "venue": "CVPR, 2015, pp. 5546\u20135555.", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2015}, {"title": "The application of two-level attention models in deep convolutional neural network for fine-grained image classification", "author": ["T. Xiao", "Y. Xu", "K. Yang", "J. Zhang", "Y. Peng", "Z. Zhang"], "venue": "CVPR, 2015.", "citeRegEx": "91", "shortCiteRegEx": null, "year": 2015}, {"title": "Bilinear cnn models for fine-grained visual recognition", "author": ["T.-Y. Lin", "A. RoyChowdhury", "S. Maji"], "venue": "arXiv preprint arXiv:1504.07889, 2015.", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2015}, {"title": "Human tracking using convolutional neural networks", "author": ["J. Fan", "W. Xu", "Y. Wu", "Y. Gong"], "venue": "Neural Networks, IEEE Transactions on, vol. 21, no. 10, pp. 1610\u20131623, 2010.", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2010}, {"title": "Deeptrack: Learning discriminative feature representations by convolutional neural networks for visual tracking", "author": ["H. Li", "Y. Li", "F. Porikli"], "venue": "Proceedings of the British Machine Vision Conference, 2014.", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2014}, {"title": "Cnntracker: Online discriminative object tracking via deep convolutional neural network", "author": ["Y. Chen", "X. Yang", "B. Zhong", "S. Pan", "D. Chen", "H. Zhang"], "venue": "Applied Soft Computing, 2015.", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2015}, {"title": "Online tracking by learning discriminative saliency map with convolutional neural network", "author": ["S. Hong", "T. You", "S. Kwak", "B. Han"], "venue": "arXiv preprint arXiv:1502.06796, 2015.", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2015}, {"title": "Deeppose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": "CVPR, 2014, pp. 1653\u20131660.", "citeRegEx": "97", "shortCiteRegEx": null, "year": 2014}, {"title": "Articulated pose estimation with flexible mixtures-of-parts", "author": ["Y. Yang", "D. Ramanan"], "venue": "CVPR. IEEE, 2011, pp. 1385\u20131392.", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2011}, {"title": "Beyond physical connections: Tree models in human pose estimation", "author": ["F. Wang", "Y. Li"], "venue": "CVPR, 2013, pp. 596\u2013603.", "citeRegEx": "99", "shortCiteRegEx": null, "year": 2013}, {"title": "Poselet conditioned pictorial structures", "author": ["L. Pishchulin", "M. Andriluka", "P. Gehler", "B. Schiele"], "venue": "CVPR, 2013, pp. 588\u2013595.", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2013}, {"title": "Modec: Multimodal decomposable models for human pose estimation", "author": ["B. Sapp", "B. Taskar"], "venue": "CVPR, 2013, pp. 3674\u20133681.", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2013}, {"title": "Clustered pose and nonlinear appearance models for human pose estimation.", "author": ["S. Johnson", "M. Everingham"], "venue": "in BMVC,", "citeRegEx": "102", "shortCiteRegEx": "102", "year": 2010}, {"title": "Learning human pose estimation features with convolutional networks", "author": ["A. Jain", "J. Tompson", "M. Andriluka", "G.W. Taylor", "C. Bregler"], "venue": "April 2014.", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2014}, {"title": "Joint training of a convolutional network and a graphical model for human pose estimation", "author": ["J.J. Tompson", "A. Jain", "Y. LeCun", "C. Bregler"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 1799\u20131807.", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2014}, {"title": "Signature verification using a siamese time delay neural network", "author": ["J. Bromley", "J.W. Bentz", "L. Bottou", "I. Guyon", "Y. LeCun", "C. Moore", "E. S\u00e4ckinger", "R. Shah"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence, vol. 7, no. 04, pp. 669\u2013688, 1993.", "citeRegEx": "105", "shortCiteRegEx": null, "year": 1993}, {"title": "Articulated pose estimation by a graphical model with image dependent pairwise relations", "author": ["X. Chen", "A.L. Yuille"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 1736\u20131744.", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2014}, {"title": "Parsing occluded people by flexible compositions", "author": ["X. Chen", "A. Yuille"], "venue": "CVPR, 2015.", "citeRegEx": "107", "shortCiteRegEx": null, "year": 2015}, {"title": "Combining local appearance and holistic view: Dual-source deep neural networks for human pose estimation", "author": ["X. Fan", "K. Zheng", "Y. Lin", "S. Wang"], "venue": "CVPR, 2015.", "citeRegEx": "108", "shortCiteRegEx": null, "year": 2015}, {"title": "Modeep: A deep learning framework using motion features for human pose estimation", "author": ["A. Jain", "J. Tompson", "Y. LeCun", "C. Bregler"], "venue": "ACCV, 2014, pp. 302\u2013315.", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2014}, {"title": "Text detection with convolutional neural networks", "author": ["M. Delakis", "C. Garcia"], "venue": "VISAPP, 2008.", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2008}, {"title": "Robust seed localization and growing with deep convolutional features for scene text detection", "author": ["H. Xu", "F. Su"], "venue": "ICMR, 2015, pp. 387\u2013394.", "citeRegEx": "111", "shortCiteRegEx": null, "year": 2015}, {"title": "Robust scene text detection with convolution neural network induced mser trees", "author": ["W. Huang", "Y. Qiao", "X. Tang"], "venue": "ECCV, 2014.", "citeRegEx": "112", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic discrimination of text and non-text natural images", "author": ["C. Zhang", "C. Yao", "B. Shi", "X. Bai"], "venue": "ICDAR, 2015.", "citeRegEx": "113", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-digit number recognition from street view imagery using deep convolutional neural networks", "author": ["I.J. Goodfellow", "J. Ibarz", "S. Arnoud", "V. Shet"], "venue": "ICLR, 2014.", "citeRegEx": "114", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep structured output learning for unconstrained text recognition", "author": ["M. Jaderberg", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "ICLR, 2015.", "citeRegEx": "115", "shortCiteRegEx": null, "year": 2015}, {"title": "Reading scene text in deep convolutional sequences", "author": ["P. He", "W. Huang", "Y. Qiao", "C.C. Loy", "X. Tang"], "venue": "CoRR, vol. abs/1506.04395, 2015.", "citeRegEx": "116", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to forget: Continual prediction with lstm", "author": ["F.A. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "Neural computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2000}, {"title": "An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition", "author": ["B. Shi", "X. Bai", "C. Yao"], "venue": "CoRR, vol. abs/1507.05717, 2015.", "citeRegEx": "118", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep features for text spotting", "author": ["M. Jaderberg", "A. Vedaldi", "A. Zisserman"], "venue": "ECCV, 2014, pp. 512\u2013528.", "citeRegEx": "119", "shortCiteRegEx": null, "year": 2014}, {"title": "Reading text in the wild with convolutional neural networks", "author": ["M. Jaderberg", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "IJCV, pp. 1\u201320, 2015.", "citeRegEx": "120", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep networks for saliency detection via local estimation and global search", "author": ["L. Wang", "H. Lu", "X. Ruan", "M.-H. Yang"], "venue": "CVPR, 2015.", "citeRegEx": "121", "shortCiteRegEx": null, "year": 2015}, {"title": "Saliency detection by multi-context deep learning", "author": ["R. Zhao", "W. Ouyang", "H. Li", "X. Wang"], "venue": "CVPR, June 2015.", "citeRegEx": "122", "shortCiteRegEx": null, "year": 2015}, {"title": "Visual saliency based on multiscale deep features", "author": ["G. Li", "Y. Yu"], "venue": "CVPR, June 2015.", "citeRegEx": "123", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicting eye fixations using convolutional neural networks", "author": ["N. Liu", "J. Han", "D. Zhang", "S. Wen", "T. Liu"], "venue": "CVPR, 2015.", "citeRegEx": "124", "shortCiteRegEx": null, "year": 2015}, {"title": "Supercnn: A superpixelwise convolutional neural network for salient object detection", "author": ["S. He", "R.W. Lau", "W. Liu", "Z. Huang", "Q. Yang"], "venue": "IJCV, pp. 1\u201315, 2015.", "citeRegEx": "125", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale optimization of hierarchical features for saliency prediction in natural images", "author": ["E. Vig", "M. Dorr", "D. Cox"], "venue": "CVPR, 2014.", "citeRegEx": "126", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep gaze i: Boosting saliency prediction with feature maps trained on imagenet", "author": ["M. Kmmerer", "L. Theis", "M. Bethge"], "venue": "ICLR, 2015.", "citeRegEx": "127", "shortCiteRegEx": null, "year": 2015}, {"title": "End-to-end convolutional network for saliency prediction", "author": ["J. Pan", "X. Gir-i Nieto"], "venue": "CVPR, 2015.", "citeRegEx": "128", "shortCiteRegEx": null, "year": 2015}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "2014.", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "CVPR, 2014, pp. 1717\u20131724.", "citeRegEx": "130", "shortCiteRegEx": null, "year": 2014}, {"title": "Actions and attributes from wholes and parts", "author": ["G. Gkioxari", "R. Girshick", "J. Malik"], "venue": "2014.", "citeRegEx": "131", "shortCiteRegEx": null, "year": 2014}, {"title": "Poselet conditioned pictorial structures", "author": ["L. Pishchulin", "M. Andriluka", "P. Gehler", "B. Schiele"], "venue": "CVPR, 2013, pp. 588\u2013595.", "citeRegEx": "132", "shortCiteRegEx": null, "year": 2013}, {"title": "Contextual action recognition with r*cnn", "author": ["G. Gkioxari", "R.B. Girshick", "J. Malik"], "venue": "CoRR, vol. abs/1505.01197, 2015.", "citeRegEx": "133", "shortCiteRegEx": null, "year": 2015}, {"title": "3d convolutional neural networks for human action recognition", "author": ["S. Ji", "W. Xu", "M. Yang", "K. Yu"], "venue": "PAMI, vol. 35, no. 1, pp. 221\u2013231, 2013.", "citeRegEx": "134", "shortCiteRegEx": null, "year": 2013}, {"title": "C3D: generic features for video analysis", "author": ["D. Tran", "L.D. Bourdev", "R. Fergus", "L. Torresani", "M. Paluri"], "venue": "CoRR, vol. abs/1412.0767, 2014.", "citeRegEx": "135", "shortCiteRegEx": null, "year": 2014}, {"title": "Large-scale video classification with convolutional neural networks", "author": ["A. Karpathy", "G. Toderici", "S. Shetty", "T. Leung", "R. Sukthankar", "L. Fei-Fei"], "venue": "CVPR, 2014, pp. 1725\u20131732.", "citeRegEx": "136", "shortCiteRegEx": null, "year": 2014}, {"title": "Two-stream convolutional networks for action recognition in videos", "author": ["K. Simonyan", "A. Zisserman"], "venue": "Advances in Neural Information Processing Systems 27, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Weinberger, Eds., 2014, pp. 568\u2013576.", "citeRegEx": "137", "shortCiteRegEx": null, "year": 2014}, {"title": "P-CNN: pose-based CNN features for action recognition", "author": ["G. Ch\u00e9ron", "I. Laptev", "C. Schmid"], "venue": "CoRR, vol. abs/1506.03607, 2015.  14", "citeRegEx": "138", "shortCiteRegEx": null, "year": 2015}, {"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["J. Donahue", "L. Anne Hendricks", "S. Guadarrama", "M. Rohrbach", "S. Venugopalan", "K. Saenko", "T. Darrell"], "venue": "June 2015.", "citeRegEx": "139", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "PAMI, pp. 1915\u20131929, 2013.", "citeRegEx": "140", "shortCiteRegEx": null, "year": 1915}, {"title": "Indoor semantic segmentation using depth information", "author": ["C. Couprie", "C. Farabet", "L. Najman", "Y. LeCun"], "venue": "arXiv preprint arXiv:1301.3572, 2013.", "citeRegEx": "141", "shortCiteRegEx": null, "year": 2013}, {"title": "Recurrent convolutional neural networks for scene labeling", "author": ["P. Pinheiro", "R. Collobert"], "venue": "Proceedings of The 31st International Conference on Machine Learning, 2014, pp. 82\u201390.", "citeRegEx": "142", "shortCiteRegEx": null, "year": 2014}, {"title": "Integrating parametric and non-parametric models for scene labeling", "author": ["B. Shuai", "G. Wang", "Z. Zuo", "B. Wang", "L. Zhao"], "venue": "CVPR, 2015, pp. 4249\u20134258.", "citeRegEx": "143", "shortCiteRegEx": null, "year": 2015}, {"title": "Quaddirectional 2d-recurrent neural networks for image labeling", "author": ["B. Shuai", "Z. Zuo", "W. Gang"], "venue": "Signal Processing Letters, 2015.", "citeRegEx": "144", "shortCiteRegEx": null, "year": 2015}, {"title": "Dag-recurrent neural networks for scene labeling", "author": ["B. Shuai", "Z. Zuo", "G. Wang", "B. Wang"], "venue": "arXiv preprint arXiv:1509.00552, 2015.", "citeRegEx": "145", "shortCiteRegEx": null, "year": 2015}, {"title": "Feedforward semantic segmentation with zoom-out features", "author": ["M. Mostajabi", "P. Yadollahpour", "G. Shakhnarovich"], "venue": "CVPR, 2015.", "citeRegEx": "146", "shortCiteRegEx": null, "year": 2015}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "CVPR, 2015.", "citeRegEx": "147", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "author": ["L.-C. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "ICLR, 2015.", "citeRegEx": "148", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "in [1] and improved in [2].", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "in [1] and improved in [2].", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "Like other neural networks, LeNet-5 has multiple layers and can be trained with the backpropagation algorithm [3].", "startOffset": 110, "endOffset": 113}, {"referenceID": 3, "context": ", AlexNet [4], is similar to LeNet-5 but with a deeper structure.", "startOffset": 10, "endOffset": 13}, {"referenceID": 4, "context": "ReLU [5] is used as the nonlinear activation function and Dropout [6] is used to reduce overfitting.", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "ReLU [5] is used as the nonlinear activation function and Dropout [6] is used to reduce overfitting.", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "Among them, three representative works are ZFNet [7], VGGNet [8] and GoogleNet [9].", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "Among them, three representative works are ZFNet [7], VGGNet [8] and GoogleNet [9].", "startOffset": 61, "endOffset": 64}, {"referenceID": 8, "context": "Among them, three representative works are ZFNet [7], VGGNet [8] and GoogleNet [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 0, "context": "1 shows the architecture of LeNet-5 [1] which is introduced by Yann LeCun.", "startOffset": 36, "endOffset": 39}, {"referenceID": 0, "context": "1: The architecture of LeNet-5 network, which works well on digit classification task (Adapted from [1]).", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": "The typical activation functions are sigmoid, tanh and ReLU [5].", "startOffset": 60, "endOffset": 63}, {"referenceID": 9, "context": "The typical pooling operations are average pooling [10] and max pooling [11\u201313].", "startOffset": 51, "endOffset": 55}, {"referenceID": 10, "context": "The typical pooling operations are average pooling [10] and max pooling [11\u201313].", "startOffset": 72, "endOffset": 79}, {"referenceID": 11, "context": "The typical pooling operations are average pooling [10] and max pooling [11\u201313].", "startOffset": 72, "endOffset": 79}, {"referenceID": 12, "context": "The typical pooling operations are average pooling [10] and max pooling [11\u201313].", "startOffset": 72, "endOffset": 79}, {"referenceID": 3, "context": "For classification tasks, softmax regression is commonly used as it generates a well-formed probability distribution of the outputs [4].", "startOffset": 132, "endOffset": 135}, {"referenceID": 13, "context": "Another commonly used method is SVM, which can be combined with CNNs to solve different classification tasks [14].", "startOffset": 109, "endOffset": 113}, {"referenceID": 14, "context": "[15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] which can be seen as a logical culmination of NIN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] uses variable filter sizes to capture different visual patterns of different sizes, and approximates the optimal sparse structure by the inception module.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "In their recent paper [16], to find high performance networks with a relatively modest computation cost, they propose several design principles to scale up CNNs according to their experimental evaluation.", "startOffset": 22, "endOffset": 26}, {"referenceID": 16, "context": "1) Lp Pooling: Lp pooling is a biologically inspired pooling process modelled on complex cells [17], [18].", "startOffset": 95, "endOffset": 99}, {"referenceID": 17, "context": "1) Lp Pooling: Lp pooling is a biologically inspired pooling process modelled on complex cells [17], [18].", "startOffset": 101, "endOffset": 105}, {"referenceID": 18, "context": "been theoretically analysed in [19], [20], which suggests that Lp pooling provides better generalization than max pooling.", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "been theoretically analysed in [19], [20], which suggests that Lp pooling provides better generalization than max pooling.", "startOffset": 37, "endOffset": 41}, {"referenceID": 5, "context": "2) Mixed Pooling: Inspired by random Dropout [6] and DropConnect [21], Yu et al.", "startOffset": 45, "endOffset": 48}, {"referenceID": 20, "context": "2) Mixed Pooling: Inspired by random Dropout [6] and DropConnect [21], Yu et al.", "startOffset": 65, "endOffset": 69}, {"referenceID": 21, "context": "[22] propose a mixed pooling method which is the combination of max pooling and average pooling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Experiments in [22] show that mixed pooling can better address the overfitting performs and it performs better than max pooling and average pooling.", "startOffset": 15, "endOffset": 19}, {"referenceID": 22, "context": "3) Stochastic pooling: Stochastic pooling [23] ensures that the non-maximal activations of feature maps are also possible to be utilized.", "startOffset": 42, "endOffset": 46}, {"referenceID": 23, "context": "4) Spectral pooling: Spectral pooling [24] performs dimensionality reduction by cropping the representation of input in frequency domain.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": ", [25]) that employ FFT for convolution kernels.", "startOffset": 2, "endOffset": 6}, {"referenceID": 25, "context": "[26].", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "6) Multi-scale Orderless Pooling: Inspired by [27], Gong et al.", "startOffset": 46, "endOffset": 50}, {"referenceID": 27, "context": "[28] use multi-scale orderless pooling (MOP) to improve the invariance of CNNs without degrading their discriminative power.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "The activations of local patches are aggregated by VLAD encoding [29], which aim to capture more local, fine-grained details of the image as well as enhancing invariance.", "startOffset": 65, "endOffset": 69}, {"referenceID": 4, "context": "1) ReLU: Rectified linear unit (ReLU) [5] is one of the most notable non-saturated activation functions.", "startOffset": 38, "endOffset": 41}, {"referenceID": 3, "context": "It has been shown that deep networks can be trained efficiently using ReLU even without pre-training [4].", "startOffset": 101, "endOffset": 104}, {"referenceID": 29, "context": "introduce leaky ReLU (LReLU) [30] which is defined as:", "startOffset": 29, "endOffset": 33}, {"referenceID": 30, "context": "[31] propose Parametric Rectified Linear Unit (PReLU) which adaptively", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "is Randomized Leaky Rectified Linear Unit (RReLU) [32].", "startOffset": 50, "endOffset": 54}, {"referenceID": 31, "context": "[32] also evaluates ReLU, LReLU, PReLU and RReLU on standard image classification task, and concludes that incorporating a non-zero slop for negative part in rectified activation units could consistently improve the performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "5) ELU: [33] introduces Exponential Linear Unit (ELU) which enables faster learning of deep neural networks and leads to higher classification accuracies.", "startOffset": 8, "endOffset": 12}, {"referenceID": 33, "context": "6) Maxout: Maxout [34] is an alternative non-linear function that takes the maximum response across multiple channels at each spatial position.", "startOffset": 18, "endOffset": 22}, {"referenceID": 33, "context": "As stated in [34], the maxout function is defined as:", "startOffset": 13, "endOffset": 17}, {"referenceID": 34, "context": "7) Probout: [35] proposes a probabilistic variant of maxout called probout.", "startOffset": 12, "endOffset": 16}, {"referenceID": 35, "context": "(15) is Hinge-Loss (L1-Loss), while if p = 2, it is the Squared Hinge-Loss (L2-Loss) [36].", "startOffset": 85, "endOffset": 89}, {"referenceID": 13, "context": "[14] investigates and compares the performance of softmax with L2-SVMs in deep networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "The results on MNIST [37] demonstrate the superiority of L2-SVM over softmax.", "startOffset": 21, "endOffset": 25}, {"referenceID": 37, "context": "3) Contrastive loss: Contrastive loss [38] is commonly used to train Siamese network.", "startOffset": 38, "endOffset": 42}, {"referenceID": 38, "context": "[39] find that the recall rate quickly collapses when using this function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "In the following subsection, we introduce some effective regularization techniques: Dropout [6], [40], [41] and DropConnect [21].", "startOffset": 92, "endOffset": 95}, {"referenceID": 39, "context": "In the following subsection, we introduce some effective regularization techniques: Dropout [6], [40], [41] and DropConnect [21].", "startOffset": 97, "endOffset": 101}, {"referenceID": 40, "context": "In the following subsection, we introduce some effective regularization techniques: Dropout [6], [40], [41] and DropConnect [21].", "startOffset": 103, "endOffset": 107}, {"referenceID": 20, "context": "In the following subsection, we introduce some effective regularization techniques: Dropout [6], [40], [41] and DropConnect [21].", "startOffset": 124, "endOffset": 128}, {"referenceID": 5, "context": "[6], and it has been proven to be very effective in reducing overfitting.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In [6], they apply Dropout to fully-connected layers.", "startOffset": 3, "endOffset": 6}, {"referenceID": 39, "context": "[40] proposes a fast Dropout method which can perform fast Dropout training by sampling from or integrating a Gaussian approximation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[41] proposes an adaptive Dropout method, where the Dropout probability for each hidden variable is computed using a binary belief network that shares parameters with the deep network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "In [42], they find that applying standard Dropout before 1 \u00d7 1 convolutional layer generally increases training time but does not prevent overfitting.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "2) DropConnect: DropConnect [21] takes the idea of Dropout a step further.", "startOffset": 28, "endOffset": 32}, {"referenceID": 3, "context": "The most commonly used initialization method is to randomly set the weights according to Gaussian distributions [4],", "startOffset": 112, "endOffset": 115}, {"referenceID": 5, "context": "[6], [8], [43].", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[6], [8], [43].", "startOffset": 5, "endOffset": 8}, {"referenceID": 42, "context": "[6], [8], [43].", "startOffset": 10, "endOffset": 14}, {"referenceID": 43, "context": "Glorot and Bengio [44] propose a normalized", "startOffset": 18, "endOffset": 22}, {"referenceID": 44, "context": "One of its variants is called \u201cXavier\u201d in Caffe [45].", "startOffset": 48, "endOffset": 52}, {"referenceID": 30, "context": "[31] derive a robust initialization method that particularly considers the rectifier nonlinearities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": ", [9]) to converge while the \u201cXavier\u201d method [44] cannot.", "startOffset": 2, "endOffset": 5}, {"referenceID": 43, "context": ", [9]) to converge while the \u201cXavier\u201d method [44] cannot.", "startOffset": 45, "endOffset": 49}, {"referenceID": 45, "context": "Instead of computing E[J(\u03b8t)], stochastic gradient descent (SGD) [47], [48] estimates the gradients on the basis of a single randomly picked example (x, y) from the training set:", "startOffset": 65, "endOffset": 69}, {"referenceID": 46, "context": "Instead of computing E[J(\u03b8t)], stochastic gradient descent (SGD) [47], [48] estimates the gradients on the basis of a single randomly picked example (x, y) from the training set:", "startOffset": 71, "endOffset": 75}, {"referenceID": 47, "context": "Parallelized SGD methods [49\u201351] improve SGD to be suitable for parallel, large-scale machine learning.", "startOffset": 25, "endOffset": 32}, {"referenceID": 48, "context": "Parallelized SGD methods [49\u201351] improve SGD to be suitable for parallel, large-scale machine learning.", "startOffset": 25, "endOffset": 32}, {"referenceID": 49, "context": "Parallelized SGD methods [49\u201351] improve SGD to be suitable for parallel, large-scale machine learning.", "startOffset": 25, "endOffset": 32}, {"referenceID": 50, "context": "[52] use another asynchronous SGD procedure called Downpour SGD to speed up the large-scale distributed training process on clusters with many CPUs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "[53] basically combines asynchronous SGD with GPUs to accelerate the training time by several times compared to training on a single machine.", "startOffset": 0, "endOffset": 4}, {"referenceID": 52, "context": "[54] also uses multiple GPUs to asynchronously calculate gradients and update the global", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "3) Batch Normalization: Batch Normalization is proposed by Sergey Ioffe and Christian Szeged [55], which aims to accelerate the entire training process of deep neural networks.", "startOffset": 93, "endOffset": 97}, {"referenceID": 53, "context": "In [55], they suggest that the Internal Covariate Shift, i.", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "[25] carry out the convolutional operation in the Fourier domain with FFTs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "There have already been some GPU-based libraries developed to speed up the training and testing process, such as cuDNN [56] and fbfft [57].", "startOffset": 119, "endOffset": 123}, {"referenceID": 55, "context": "There have already been some GPU-based libraries developed to speed up the training and testing process, such as cuDNN [56] and fbfft [57].", "startOffset": 134, "endOffset": 138}, {"referenceID": 56, "context": "This is especially costly when the striding parameter is larger than 1, which is common in many state-of-art networks, such as the early layers in [58] and [9].", "startOffset": 147, "endOffset": 151}, {"referenceID": 8, "context": "This is especially costly when the striding parameter is larger than 1, which is common in many state-of-art networks, such as the early layers in [58] and [9].", "startOffset": 156, "endOffset": 159}, {"referenceID": 57, "context": "To this end, [59] applies the low-rank matrix factorization to the final weight layer in a deep CNN, resulting about 30-50% speedup in training time at little loss in accuracy.", "startOffset": 13, "endOffset": 17}, {"referenceID": 58, "context": "Similarly, [60] applies singular value decomposition on each layer of a deep CNN to reduce the", "startOffset": 11, "endOffset": 15}, {"referenceID": 59, "context": "Inspired by [61] which demonstrates the redundancy in the parameters of deep neural networks, Denton et al.", "startOffset": 12, "endOffset": 16}, {"referenceID": 60, "context": "[62] and Jaderberg et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 61, "context": "[63] independently investigate the redundancy within the convolutional filters and develop approximations to reduced the required computations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 62, "context": "Similar to scalar quantization where a large set of numbers is mapped to a smaller set [64], VQ quantizes groups of numbers together rather than addressing them one at a time.", "startOffset": 87, "endOffset": 91}, {"referenceID": 59, "context": "[61] demonstrate the presence of redundancy in neural network parameters, and use VQ to significantly reduce the number of dynamic parameters in deep models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 63, "context": "[65] investigate the information theoretical vector quantization methods for compressing the parameters of CNNs, and they obtain parameter prediction results similar to those of [61].", "startOffset": 0, "endOffset": 4}, {"referenceID": 59, "context": "[65] investigate the information theoretical vector quantization methods for compressing the parameters of CNNs, and they obtain parameter prediction results similar to those of [61].", "startOffset": 178, "endOffset": 182}, {"referenceID": 64, "context": ", residual quantization [66], scalar quantization [67]).", "startOffset": 24, "endOffset": 28}, {"referenceID": 65, "context": ", residual quantization [66], scalar quantization [67]).", "startOffset": 50, "endOffset": 54}, {"referenceID": 66, "context": "CNNs have been applied in image classification for a long time [68\u201371].", "startOffset": 63, "endOffset": 70}, {"referenceID": 67, "context": "CNNs have been applied in image classification for a long time [68\u201371].", "startOffset": 63, "endOffset": 70}, {"referenceID": 68, "context": "CNNs have been applied in image classification for a long time [68\u201371].", "startOffset": 63, "endOffset": 70}, {"referenceID": 69, "context": "CNNs have been applied in image classification for a long time [68\u201371].", "startOffset": 63, "endOffset": 70}, {"referenceID": 3, "context": "Compared with other methods, CNNs can achieve better classification accuracy on large scale datasets [4], [8], [72], [73] due to their capability of joint feature learning and classifier learning.", "startOffset": 101, "endOffset": 104}, {"referenceID": 7, "context": "Compared with other methods, CNNs can achieve better classification accuracy on large scale datasets [4], [8], [72], [73] due to their capability of joint feature learning and classifier learning.", "startOffset": 106, "endOffset": 109}, {"referenceID": 70, "context": "Compared with other methods, CNNs can achieve better classification accuracy on large scale datasets [4], [8], [72], [73] due to their capability of joint feature learning and classifier learning.", "startOffset": 111, "endOffset": 115}, {"referenceID": 71, "context": "Compared with other methods, CNNs can achieve better classification accuracy on large scale datasets [4], [8], [72], [73] due to their capability of joint feature learning and classifier learning.", "startOffset": 117, "endOffset": 121}, {"referenceID": 3, "context": "[4] develop the AlexNet and achieve the best performance in ILSVRC 2012.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "After the success of AlexNet, several works have made significant improvements in classification accuracy by either reducing filter size [7] or expanding the network depth [8], [9].", "startOffset": 137, "endOffset": 140}, {"referenceID": 7, "context": "After the success of AlexNet, several works have made significant improvements in classification accuracy by either reducing filter size [7] or expanding the network depth [8], [9].", "startOffset": 172, "endOffset": 175}, {"referenceID": 8, "context": "After the success of AlexNet, several works have made significant improvements in classification accuracy by either reducing filter size [7] or expanding the network depth [8], [9].", "startOffset": 177, "endOffset": 180}, {"referenceID": 72, "context": "Building a hierarchy of classifiers is a common strategy for image classification with a large number of classes [74].", "startOffset": 113, "endOffset": 117}, {"referenceID": 73, "context": "[75]", "startOffset": 0, "endOffset": 4}, {"referenceID": 73, "context": "Similar to [75], [76] builds a tree structure to learn finegrained features for subcategory recognition.", "startOffset": 11, "endOffset": 15}, {"referenceID": 74, "context": "Similar to [75], [76] builds a tree structure to learn finegrained features for subcategory recognition.", "startOffset": 17, "endOffset": 21}, {"referenceID": 75, "context": "[77] proposes a training method that grows a network not only incrementally but also hierarchically.", "startOffset": 0, "endOffset": 4}, {"referenceID": 76, "context": "[78] introduces a hierarchical deep CNNs (HD-CNNs)", "startOffset": 0, "endOffset": 4}, {"referenceID": 77, "context": "There are already some finegrained image datasets (such as Flower [79], Birds [80], [81], Dogs [82], Cars [83] and Shoes [84]).", "startOffset": 66, "endOffset": 70}, {"referenceID": 78, "context": "There are already some finegrained image datasets (such as Flower [79], Birds [80], [81], Dogs [82], Cars [83] and Shoes [84]).", "startOffset": 78, "endOffset": 82}, {"referenceID": 79, "context": "There are already some finegrained image datasets (such as Flower [79], Birds [80], [81], Dogs [82], Cars [83] and Shoes [84]).", "startOffset": 84, "endOffset": 88}, {"referenceID": 80, "context": "There are already some finegrained image datasets (such as Flower [79], Birds [80], [81], Dogs [82], Cars [83] and Shoes [84]).", "startOffset": 95, "endOffset": 99}, {"referenceID": 81, "context": "There are already some finegrained image datasets (such as Flower [79], Birds [80], [81], Dogs [82], Cars [83] and Shoes [84]).", "startOffset": 106, "endOffset": 110}, {"referenceID": 82, "context": "There are already some finegrained image datasets (such as Flower [79], Birds [80], [81], Dogs [82], Cars [83] and Shoes [84]).", "startOffset": 121, "endOffset": 125}, {"referenceID": 83, "context": "[85] propose a method which detects parts and extracts CNN features from multiple posenormalized regions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[43] propose a part-based R-CNN which can learn whole-object and part detectors.", "startOffset": 0, "endOffset": 4}, {"referenceID": 84, "context": "They use selective search [86] to generate the part proposals, and apply nonparametric geometric constraints to more accurately localize parts.", "startOffset": 26, "endOffset": 30}, {"referenceID": 85, "context": "[87] incorporate part localization, alignment, and classification into one recognition system which is called Deep LAC.", "startOffset": 0, "endOffset": 4}, {"referenceID": 86, "context": "Their system is composed of three sub-networks: localization sub-network is used to estimate the part location, alignment sub-network receives the location as input and performs template alignment [88], and classification sub-network takes pose aligned part images as input to predict the category label.", "startOffset": 197, "endOffset": 201}, {"referenceID": 87, "context": "[89] use the ensemble of localized learned feature representations for fine-grained classification,", "startOffset": 0, "endOffset": 4}, {"referenceID": 88, "context": "In their latest paper [90].", "startOffset": 22, "endOffset": 26}, {"referenceID": 89, "context": "[91] applies visual attention in CNN for fine-grained classification.", "startOffset": 0, "endOffset": 4}, {"referenceID": 90, "context": "[92] proposes bilinear models for fine-grained image classification.", "startOffset": 0, "endOffset": 4}, {"referenceID": 91, "context": "[93] use CNN as a base learner.", "startOffset": 0, "endOffset": 4}, {"referenceID": 91, "context": "In [93], the authors design a CNN tracker with a shift-variant architecture.", "startOffset": 3, "endOffset": 7}, {"referenceID": 92, "context": "[94] propose a target-specific CNN for object tracking, where the CNN is trained incrementally during tracking with new examples obtained online.", "startOffset": 0, "endOffset": 4}, {"referenceID": 92, "context": "Instead of learning one complicated and powerful CNN model for all the appearance observations in the past, [94] uses a relatively small number of filters in the CNN within a framework equipped with a temporal adaptation mechanism.", "startOffset": 108, "endOffset": 112}, {"referenceID": 93, "context": "In [95], a CNN object tracking method is proposed to address limitations of handcrafted features and shallow classifier structures in object tracking problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 94, "context": "[96] propose a visual tracking algorithm based on a pre-trained CNN, where the network is trained originally for large-scale image classification and the learned represen-", "startOffset": 0, "endOffset": 4}, {"referenceID": 95, "context": "DeepPose [97] is the first application of CNNs to human pose estimation problem.", "startOffset": 9, "endOffset": 13}, {"referenceID": 96, "context": "From the experiments, DeepPose can outperform the deformable part models based methods [98\u2013100] on two widely used datasets, FLIC [101] and LSP [102].", "startOffset": 87, "endOffset": 95}, {"referenceID": 97, "context": "From the experiments, DeepPose can outperform the deformable part models based methods [98\u2013100] on two widely used datasets, FLIC [101] and LSP [102].", "startOffset": 87, "endOffset": 95}, {"referenceID": 98, "context": "From the experiments, DeepPose can outperform the deformable part models based methods [98\u2013100] on two widely used datasets, FLIC [101] and LSP [102].", "startOffset": 87, "endOffset": 95}, {"referenceID": 99, "context": "From the experiments, DeepPose can outperform the deformable part models based methods [98\u2013100] on two widely used datasets, FLIC [101] and LSP [102].", "startOffset": 130, "endOffset": 135}, {"referenceID": 100, "context": "From the experiments, DeepPose can outperform the deformable part models based methods [98\u2013100] on two widely used datasets, FLIC [101] and LSP [102].", "startOffset": 144, "endOffset": 149}, {"referenceID": 101, "context": "[103] present a CNN based end-to-end learning approach for fullbody human pose estimation, in which CNN part detectors and an Markov Random Field (MRF)-like spatial model are jointly trained, and pair-wise potentials in the graph are computed using convolutional priors.", "startOffset": 0, "endOffset": 5}, {"referenceID": 102, "context": "[104] use a multi-resolution CNN to compute heat-map for each body part.", "startOffset": 0, "endOffset": 5}, {"referenceID": 101, "context": "Different from [103], Tompson et al.", "startOffset": 15, "endOffset": 20}, {"referenceID": 102, "context": "[104] learn the body part prior model and implicitly the structure of the spatial model.", "startOffset": 0, "endOffset": 5}, {"referenceID": 102, "context": "As an extension of [104], Tompson et al.", "startOffset": 19, "endOffset": 24}, {"referenceID": 41, "context": "[42] propose a", "startOffset": 0, "endOffset": 4}, {"referenceID": 103, "context": "This refinement model, which is a Siamese network [105], is jointly trained in cascade with the off-the-shelf model [104].", "startOffset": 50, "endOffset": 55}, {"referenceID": 102, "context": "This refinement model, which is a Siamese network [105], is jointly trained in cascade with the off-the-shelf model [104].", "startOffset": 116, "endOffset": 121}, {"referenceID": 102, "context": "In a similar work with [104], Chen et al.", "startOffset": 23, "endOffset": 28}, {"referenceID": 104, "context": "[106], [107] also combine graphical model with CNN.", "startOffset": 0, "endOffset": 5}, {"referenceID": 105, "context": "[106], [107] also combine graphical model with CNN.", "startOffset": 7, "endOffset": 12}, {"referenceID": 106, "context": "There is also a pose estimation method called dual-source CNN [108]", "startOffset": 62, "endOffset": 67}, {"referenceID": 102, "context": "Based on the work [104], Jain et al.", "startOffset": 18, "endOffset": 23}, {"referenceID": 107, "context": "[109] also", "startOffset": 0, "endOffset": 5}, {"referenceID": 108, "context": "The works can be coarsely categorized into three types: (1) text detection and localization without recognition, (2) text recognition on cropped text images, and (3) end-to-end text spotting that integrates both text detection and recognition: 1) Text detection: One of the pioneering works to apply CNN for scene text detection is [110].", "startOffset": 332, "endOffset": 337}, {"referenceID": 108, "context": "The CNN model employed by [110] learns on cropped text patches and non-text scene patches to discriminate between the two.", "startOffset": 26, "endOffset": 31}, {"referenceID": 109, "context": "To reduce the search space for text detection, [111] proposes to obtain a set of character candidates via Maximally Stable Extremal Regions (MSER) and filter the candidates by CNN classification.", "startOffset": 47, "endOffset": 52}, {"referenceID": 110, "context": "for text detection is [112].", "startOffset": 22, "endOffset": 27}, {"referenceID": 110, "context": "In [112], CNN is used to distinguish text-like MSER components from non-text components, and cluttered text components are split by applying CNN in a sliding window manner followed by Non-Maximal Suppression (NMS).", "startOffset": 3, "endOffset": 8}, {"referenceID": 111, "context": "Other than localization of text, there is an interesting work [113] that makes use of CNN to determine whether the input image contains text, without telling where the text is exactly located.", "startOffset": 62, "endOffset": 67}, {"referenceID": 111, "context": "In [113], text candidates are obtained using MSER which are then passed into a CNN to generate visual features, and lastly the global features of the images are constructed by aggregating the CNN features in a Bag-ofWords (BoW) framework.", "startOffset": 3, "endOffset": 8}, {"referenceID": 112, "context": "2) Text recognition: [114] proposes a CNN model with multiple softmax classifiers in its final layer, which is formulated in such a way that each classifier is responsible for character prediction at each sequential location in the multi-digit input image.", "startOffset": 21, "endOffset": 26}, {"referenceID": 113, "context": "As an attempt to recognize text without using lexicon and dictionary, [115] introduces a novel Conditional Random Fields (CRF)-like CNN model to jointly learn character sequence prediction and bigram generation", "startOffset": 70, "endOffset": 75}, {"referenceID": 114, "context": "In [116], CNN extracts rich visual features from character-level image patches obtained via sliding window, and the sequence labelling is carried out by an enhanced RNN variant called Long Short-Term Memory (LSTM) [117].", "startOffset": 3, "endOffset": 8}, {"referenceID": 115, "context": "In [116], CNN extracts rich visual features from character-level image patches obtained via sliding window, and the sequence labelling is carried out by an enhanced RNN variant called Long Short-Term Memory (LSTM) [117].", "startOffset": 214, "endOffset": 219}, {"referenceID": 116, "context": "The method presented in [118] is very similar to [116], except that in [118], lexicon can be taken into consideration to enhance text recognition performance.", "startOffset": 24, "endOffset": 29}, {"referenceID": 114, "context": "The method presented in [118] is very similar to [116], except that in [118], lexicon can be taken into consideration to enhance text recognition performance.", "startOffset": 49, "endOffset": 54}, {"referenceID": 116, "context": "The method presented in [118] is very similar to [116], except that in [118], lexicon can be taken into consideration to enhance text recognition performance.", "startOffset": 71, "endOffset": 76}, {"referenceID": 9, "context": "3) End-to-end text spotting: For end-to-end text spotting, [10] applies a CNN model originally trained for character classification to perform text detection.", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "Going in a similar direction as [10], the CNN model proposed in [119] enables feature sharing across the four different subtasks of an end-to-end text spotting system: text detection, character case-sensitive and insensitive classification, and bigram classification.", "startOffset": 32, "endOffset": 36}, {"referenceID": 117, "context": "Going in a similar direction as [10], the CNN model proposed in [119] enables feature sharing across the four different subtasks of an end-to-end text spotting system: text detection, character case-sensitive and insensitive classification, and bigram classification.", "startOffset": 64, "endOffset": 69}, {"referenceID": 118, "context": "[120] makes use of CNNs in a very comprehensive way to perform end-to-end text spotting.", "startOffset": 0, "endOffset": 5}, {"referenceID": 118, "context": "In [120], the major subtasks of its proposed system, namely text bounding box filtering, text bounding box regression, and text recognition are each tackled by a separate CNN model.", "startOffset": 3, "endOffset": 8}, {"referenceID": 119, "context": "Multi-contextual information is a crucial prior in visual saliency prediction, and it has been used concurrently with CNN in most of the considered works [121\u2013125].", "startOffset": 154, "endOffset": 163}, {"referenceID": 120, "context": "Multi-contextual information is a crucial prior in visual saliency prediction, and it has been used concurrently with CNN in most of the considered works [121\u2013125].", "startOffset": 154, "endOffset": 163}, {"referenceID": 121, "context": "Multi-contextual information is a crucial prior in visual saliency prediction, and it has been used concurrently with CNN in most of the considered works [121\u2013125].", "startOffset": 154, "endOffset": 163}, {"referenceID": 122, "context": "Multi-contextual information is a crucial prior in visual saliency prediction, and it has been used concurrently with CNN in most of the considered works [121\u2013125].", "startOffset": 154, "endOffset": 163}, {"referenceID": 123, "context": "Multi-contextual information is a crucial prior in visual saliency prediction, and it has been used concurrently with CNN in most of the considered works [121\u2013125].", "startOffset": 154, "endOffset": 163}, {"referenceID": 119, "context": "[121] intro-", "startOffset": 0, "endOffset": 5}, {"referenceID": 120, "context": "In [122], the", "startOffset": 3, "endOffset": 8}, {"referenceID": 121, "context": "The CNN model adopted in [123] is pre-trained on large-scale image classification dataset and then shared among different contextual levels for feature extraction.", "startOffset": 25, "endOffset": 30}, {"referenceID": 120, "context": "Similar to [122], [123], the CNN model used in [124] for saliency prediction are shared across three CNN streams, with each stream taking input of a different contextual", "startOffset": 11, "endOffset": 16}, {"referenceID": 121, "context": "Similar to [122], [123], the CNN model used in [124] for saliency prediction are shared across three CNN streams, with each stream taking input of a different contextual", "startOffset": 18, "endOffset": 23}, {"referenceID": 122, "context": "Similar to [122], [123], the CNN model used in [124] for saliency prediction are shared across three CNN streams, with each stream taking input of a different contextual", "startOffset": 47, "endOffset": 52}, {"referenceID": 123, "context": "[125] derives a spatial kernel and a range kernel to", "startOffset": 0, "endOffset": 5}, {"referenceID": 124, "context": "There are also CNN-based saliency prediction approaches [126\u2013128] that do not consider multi-contextual information.", "startOffset": 56, "endOffset": 65}, {"referenceID": 125, "context": "There are also CNN-based saliency prediction approaches [126\u2013128] that do not consider multi-contextual information.", "startOffset": 56, "endOffset": 65}, {"referenceID": 126, "context": "There are also CNN-based saliency prediction approaches [126\u2013128] that do not consider multi-contextual information.", "startOffset": 56, "endOffset": 65}, {"referenceID": 124, "context": "In [126], an ensemble of CNNs is derived from a large number of randomly instantiated CNN models, to generate good features for saliency detection.", "startOffset": 3, "endOffset": 8}, {"referenceID": 124, "context": "The CNN models instantiated in [126] are however not deep enough because the maximum number of layers is capped at three.", "startOffset": 31, "endOffset": 36}, {"referenceID": 125, "context": "By using a pre-trained and deeper CNN model with 5 convolutional layers, [127] (Deep Gaze) learns a separate saliency model to jointly combine the responses from every CNN layer and predict saliency values.", "startOffset": 73, "endOffset": 78}, {"referenceID": 126, "context": "[128] is the only work making use of CNN to perform visual saliency prediction in an end-to-end manner, which means the CNN model accepts raw pixels as input and produces saliency map as output.", "startOffset": 0, "endOffset": 5}, {"referenceID": 126, "context": "[128] argues that the success of the proposed end-to-end method is attributed to its not-so-deep CNN architecture which attempts to prevent overfitting.", "startOffset": 0, "endOffset": 5}, {"referenceID": 127, "context": "1) Action Recognition in Still Images: The work of [129] has shown the output of last few layers of a trained CNN can be used as a general visual feature descriptor for a variety of tasks.", "startOffset": 51, "endOffset": 56}, {"referenceID": 7, "context": "The same intuition is utilized for action recognition by [8], [130], in which they use the outputs of the penultimate layer of a pre-trained CNN to represent full images of actions as well as the human bounding boxes inside them, and achieve a high level of performance in action classification.", "startOffset": 57, "endOffset": 60}, {"referenceID": 128, "context": "The same intuition is utilized for action recognition by [8], [130], in which they use the outputs of the penultimate layer of a pre-trained CNN to represent full images of actions as well as the human bounding boxes inside them, and achieve a high level of performance in action classification.", "startOffset": 62, "endOffset": 67}, {"referenceID": 129, "context": "[131] add a part detection to this framework.", "startOffset": 0, "endOffset": 5}, {"referenceID": 130, "context": "Their part detector is a CNN based extension to the original Poselet [132] method.", "startOffset": 69, "endOffset": 74}, {"referenceID": 131, "context": "CNN based representation of contextual information is utilized for action recognition in [133].", "startOffset": 89, "endOffset": 94}, {"referenceID": 132, "context": "[134] propose to consider the temporal axis in a similar manner as other spatial axes and introduce a network of 3D convolutional layers to be applied on video inputs.", "startOffset": 0, "endOffset": 5}, {"referenceID": 133, "context": "[135] study the performance, efficiency, and effectiveness of this approach and show its strengths compared to other approaches.", "startOffset": 0, "endOffset": 5}, {"referenceID": 134, "context": "Another approach to apply CNNs on videos is to keep the convolutions in 2D and fuse the feature maps of consecutive frames, as proposed by [136].", "startOffset": 139, "endOffset": 144}, {"referenceID": 135, "context": "One more step forward for better action recognition via CNNs is to separate the representation to spatial and temporal variations and train individual CNNs for each of them, as proposed by Simonyan and Zisserman [137].", "startOffset": 212, "endOffset": 217}, {"referenceID": 136, "context": "[138] utilize the two stream CNN on the localized parts of the human body and show the aggregation of part-based local CNN descriptors can effectively improve the performance of action recognition.", "startOffset": 0, "endOffset": 5}, {"referenceID": 137, "context": "[139] studies different configurations of applying LSTM units as the sequence learner in this framework.", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "The recent advance of Convolutional Neural Networks (CNNs) [1], [4] has revolutionized the computer vision community due to their outstanding performance in a wide variety of tasks.", "startOffset": 59, "endOffset": 62}, {"referenceID": 3, "context": "The recent advance of Convolutional Neural Networks (CNNs) [1], [4] has revolutionized the computer vision community due to their outstanding performance in a wide variety of tasks.", "startOffset": 64, "endOffset": 67}, {"referenceID": 138, "context": "[140] have pioneered to apply CNNs to scene labeling tasks.", "startOffset": 0, "endOffset": 5}, {"referenceID": 139, "context": "network is also successfully applied to RGB-D scene labeling [141].", "startOffset": 61, "endOffset": 66}, {"referenceID": 140, "context": "[142] develop the recurrent CNNs.", "startOffset": 0, "endOffset": 5}, {"referenceID": 143, "context": "[143\u2013 145] train the parametric CNNs by sampling image patches, which speeds up the training time dramatically.", "startOffset": 0, "endOffset": 10}, {"referenceID": 141, "context": "They find that patch-based CNNs suffer from local ambiguity problems, and [143] solve it by integrating global beliefs.", "startOffset": 74, "endOffset": 79}, {"referenceID": 142, "context": "[144] and [145] use the recurrent neural networks to model the contextual dependencies among image features, and dramatically boost the labeling performance.", "startOffset": 0, "endOffset": 5}, {"referenceID": 143, "context": "[144] and [145] use the recurrent neural networks to model the contextual dependencies among image features, and dramatically boost the labeling performance.", "startOffset": 10, "endOffset": 15}, {"referenceID": 144, "context": "[146] apply the local and proximal features from a ConvNet and apply the Alex-net [4] to obtain the distant and global features, and their concatenation gives rise to the zoom-out features.", "startOffset": 0, "endOffset": 5}, {"referenceID": 3, "context": "[146] apply the local and proximal features from a ConvNet and apply the Alex-net [4] to obtain the distant and global features, and their concatenation gives rise to the zoom-out features.", "startOffset": 82, "endOffset": 85}, {"referenceID": 145, "context": "[147] train a fully convolutional Network (FCN) to directly map the input images to dense label maps.", "startOffset": 0, "endOffset": 5}, {"referenceID": 146, "context": "[148] also apply the pre-trained deep CNNs to emit the labels of pixels.", "startOffset": 0, "endOffset": 5}], "year": 2015, "abstractText": "In the last few years, deep learning has lead to very good performance on a variety of problems, such as object recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Due to the lack of training data and computing power in early days, it is hard to train a large high-capacity convolutional neural network without overfitting. Recently, with the rapid growth of data size and the increasing power of graphics processor unit, many researchers have improved the convolutional neural networks and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. Besides, we also introduce some applications of convolutional neural networks in computer vision.", "creator": "TeX"}}}