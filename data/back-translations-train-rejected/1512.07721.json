{"id": "1512.07721", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2015", "title": "Measuring pattern retention in anonymized data -- where one measure is not enough", "abstract": "In this paper, we explore how modifying data to preserve privacy affects the quality of the patterns discoverable in the data. For any analysis of modified data to be worth doing, the data must be as close to the original as possible. Therein lies a problem -- how does one make sure that modified data still contains the information it had before modification? This question is not the same as asking if an accurate classifier can be built from the modified data. Often in the literature, the prediction accuracy of a classifier made from modified (anonymized) data is used as evidence that the data is similar to the original. We demonstrate that this is not the case, and we propose a new methodology for measuring the retention of the patterns that existed in the original data. We then use our methodology to design three measures that can be easily implemented, each measuring aspects of the data that no pre-existing techniques can measure. These measures do not negate the usefulness of prediction accuracy or other measures -- they are complementary to them, and support our argument that one measure is almost never enough.", "histories": [["v1", "Thu, 24 Dec 2015 05:36:02 GMT  (418kb)", "http://arxiv.org/abs/1512.07721v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["sam fletcher", "md zahidul islam"], "accepted": false, "id": "1512.07721"}, "pdf": {"name": "1512.07721.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Sam Fletcher", "Md Zahidul Islam"], "emails": ["safletcher@csu.edu.au", "zislam@csu.edu.au"], "sections": [{"heading": null, "text": "In this paper, we examine how changing data to protect privacy affects the quality of the patterns that can be seen in the data. To be worth analyzing modified data, the data must be as close as possible to the original. Therein lies a problem - how can you ensure that modified data still contains the information that it had before the modification? This question is not the same as asking whether the modified data can be turned into a more accurate classifier. Often, in the literature, the predictive accuracy of a classifier that consists of modified (anonymized) data is used as proof that the data is similar to the original. We show that this is not the case, and propose a new method for measuring the retention of patterns that existed in the original data. We then use our methodology to design three measures that can be easily implemented, measuring each aspect of the data that no pre-existing techniques can measure."}, {"heading": "1. Introduction", "text": "In fact, most people who are able to survive themselves are able to survive themselves, and they are able to survive themselves, \"he said in an interview with the\" New York Times, \"which was about whether they consider themselves able to survive themselves, or whether they are able to survive themselves.\" I don't think they are able to survive themselves, \"he told the\" New York Times, \"adding,\" I don't think they will be able to survive themselves. \""}, {"heading": "1.1. Problem Statement", "text": "In this paper, we frame the problem from the data owner's perspective, where the data owner cannot find valuable patterns that want to make their data available to the public in a way that protects the privacy of each individual in the data; they do not want to back up and maintain a server in which the results of disturbed patterns lead to questions asked by the public; nor do they want to define value groupings for each of the attributes contained in the data. In this paper, we will focus on the scenario in which noise is added to the values of individuals. We use both continuous (i.e. numerical) and discrete (i.e. categorical) data, where the specific method of anonymization is not the focus, but the focus is on measuring the usefulness of the data once the anonymization method has been applied; the problem facing the data owner is how much degradation occurs in the data when privacy techniques are applied to their data, so they can use data-modified patterns."}, {"heading": "1.2. Our Contribution", "text": "Our contribution can be summarized as follows: \u2022 We propose a novel method of measuring the data retention of adatasets after it has been modified (or synthetic data generated from it), with a method of preserving privacy. \u2022 We implement and test three measures that use our methodology and demonstrate their sensitivity to changes in data retention. \u2022 Using a thought experiment, we show that other pre-existing metrics are not sensitive to changes in data retention, whereas our metrics are. 1Read as a mathematical symbol for the selection. For example, \u03c3p (q) is the subset of elements in q for which p is applicable. \u2022 We present either a statement such as Y = y or a set of statements such as X. In this case, all statements in p must be true for one element in q to be included in data retention. \u2022 We provide a correlation measurement matrix of our three and three already existing metrics."}, {"heading": "2. A Methodology for Measuring Pattern Retention", "text": "While the predication of data sets is an excellent measure of the usefulness of a classifier or model, predication can then be taken with the accuracy (30, 31], care if one extends its use to the privacy domain. Therefore, it has been common in the past to develop patterns to preserve privacy in order to have their effect on the quality (usefulness) of the data measured with predictive accuracy. (14, 32, 15, 7] This requires the application of a method of data analysis to the anonymized data M to create a classifier, or to discover a collection of patterns using a different technique, and then to test the ability for this collection of patterns3 ZM to accurately predict what the code can do at http: / csusap.csu.edu.au / or you can send us an e-mail. 3Note that a classifier semantically is the same thing as a collection of patterns as a collection of cedcanbe a collection of patterns when canbe and in sequences."}, {"heading": "3. Implementations of the Methodology", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Pattern Accuracy", "text": "Since Pattern Accuracy is a simple measurement that compares D and M. As its name might suggest, it is very similar to predictive accuracy \u2212 Pattern Accuracy in that it measures the average accuracy of a sample collection Y in predicting the class value of some data. However, rather than predicting the class value of some test data T, it predicts the class values of the modified data M. If the predictive accuracy of M is actually written as \u03b1 (ZM | T), then the pattern Accuracy of M is written as \u03b1 (ZD | M). In a privacy preservation scenario, it is about comparing the performance of M with D, so prediction is accuracy (ZD | T) \u2212 \u03b1 (ZM | T), and the pattern accuracy equivalent of cell (ZD | D) \u2212 \u03b1."}, {"heading": "3.2. Pattern Support Distance (PSD)", "text": "The \"support\" of a pattern is the number of rows in a dataset covering a pattern [21, 22], and can be represented as | \u03c3X (D) if the support of patternX is described in datasetD. Whether Y is correctly predicted is irrelevant when measuring patterns. However, to measure support for X in D compared to M, we can calculate that the user can use his domain knowledge to make specific evaluations of the status of each X. This can of course be repeated for all X patterns. To summarize the total support of ZD for a dataset M, the mean difference can be calculated: PSD = 1 | \u00d7 | D | ZD (D)."}, {"heading": "3.3. Pattern Label Distance (PLD)", "text": "When this happens, it is possible that the distribution of markings (i.e. Y) will change in such a way that it will meet the conditions of another pattern Xj-ZD (i.e. r-Xj (M)). The purpose of a pattern is often to predict Y-marking, and therefore it is important to know how much this marking might have changed in M-marking, since Xi and Xj can predict different class markings and a maximum of one of these predictions for a record r. But it is also possible that the two patterns predict the same class, which cannot lead to a change in the pattern marking of M compared to D (at least as far as the usual pattern)."}, {"heading": "4. Related Utility Measures", "text": "As mentioned in paragraph 1, it is common in the literature that the effects of a method of maintaining privacy are quantified using prediction accuracy (paragraph 1). Other commonly used metrics are F-measure [17] and AUC [18], where in turn ZM is compared with T (fig 1 for a graphical representation of these data and classifiers). We use prediction accuracy, F-measure and AUC in our experiments. Formally, prediction accuracy can be compared with T (fig 1 | T). Precision: Prediction accuracy (f-measure and AUC). Prediction accuracy: Precision: Precision: Precision: Precision: Precision: Precision: FX: Precision: Precision: Precision: Precision: Precision: FX: Precision: Precision:. \""}, {"heading": "5. A Thought Experiment", "text": "We use a thought experiment to demonstrate the sensitivity of our measurements to changes in data that are not detected by existing measurements. We use the toy data and classifiers shown in Figure 1. The patterns in ZD have 8 With this notation, we can actually rewrite the prediction accuracy in TP + TN TP + TN + FP + FN, which is described in Table 2, along with their support and confidence. After modifying D with a method to maintain privacy, the result is M as shown in Figure 1. The classifier ZM was then created from these modified data; we present the samples in Table 3. We then evaluate the quality of M based on six measurements: our three implementations of our proposed methodology, as well as prediction accuracy, AUC and F measurement. The results have occurred in Table 4.Several things have occurred here. First, the prediction accuracy was completely incapable to recognize any changes in M compared to the user's actual M, and that it is not possible to respect the fact that M is in D."}, {"heading": "D 0.00 0.00 0.00 0.67 0.67 0.80", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "M 0.50 0.08 0.34 0.67 0.50 0.67", "text": "As we can see visually in Fig. 1, ZM is radically different from ZD. Due to the changes in M, the patterns discovered in M are very different from the patterns discovered in D. Our proposed methodology solves the problem of quantifying the visual intuition one has about the differences between ZM and ZD. Pattern Accuracy, PSD and PLD were all able to accurately detect the differences between D and M that they are meant to identify: the overall retention of ZD patterns, the changes in support of the patterns, and the changes in class marker distribution of the patterns. AUC and F measurement were able to detect some changes, but it is important to recognize that these changes do not constitute a link between ZD and ZM. Both measures began by calculating the true and false predictions of the positive and negative predictions of ZD using T, and then made similar calculations of ZM using T."}, {"heading": "6. Experiment Methodology", "text": "To evaluate empirically our three metrics, we perform the following experiments and present the results in Section 7. For our experiments, the patterns are generated from decision trees. Note that the patterns could simply be created manually, generated by another classifier, filtered for interest by any number of metrics, hand-picked from a list of generated patterns, or created by other means, the patterns in the form X \u2192 y.We use 17 data sets publicly available in the UCI Machine Learning Repository [19]. To generate a collection of patterns for each data set (i.e. ZD), we run the CART algorithm [29] with a minimum sheet size (i.e. minimum support threshold) of | D | \u00d7 0.02 and a maximum tree depth of 12. Generating patterns this way, we create a set of realistic patterns for each data set (i.e. ZD), with patterns also varying in length (i.e. the number of conditions in X)."}, {"heading": "6.1. Privacy-Preservation Techniques", "text": "To simulate different modifications of a dataset, we add noise to the data in two simple ways. Each type of noise represents a different scenario or: where attribute and multi-attribute (i.e. multivariate) distributions are flattened (i.e. made more uniform); and where attribute distributions and most multi-attribute distributions are preserved. We simulate these scenarios using additive noise. Let's use these two scenarios to examine what a user can learn from our three implementations of our proposed methodology, and how they compare prediction accuracy, AUC and F measurement. The two types of noise additions we use are listed below."}, {"heading": "6.2. Pearson\u2019s Correlation Coefficient", "text": "By comparing the results of each measurement with increasing noise, we calculate the correlation of the measurement variables to each other for each data set using Pearson's correlation coefficient (i.e. Pearson's r value) [38]. We calculate their correlation for each data set separately; the coefficient has a range of \u2212 1 \u2264 r \u2264 1, with a result close to 1 indicating a high positive correlation (as one measurement variable increases, so the other results), a result close to -1 indicating a high negative correlation (as one measurement variable increases, the other decreases), and a result close to 0 indicating a low correlation (the result of one measurement variable has little effect on the result of the other). In order to standardize the results of different measurements, we consider the difference between the result of each measurement on M as compared to D. In other words, for each noise level we subtract the result that the measurement was reached when there was no noise. \"This has no impact on our proposed measurement variables on M as compared to D.\" In other words, for each noise level, we subtract the result that the measurement was reached when there was no noise when there was no noise. \""}, {"heading": "7. Results", "text": "To demonstrate the information a user can learn about individual pattern retention, Fig. 2 presents the support and Chi-squared histogram pattern shown in Table 1 as the UN increases. In this example, we can see that the four patterns are affected quite differently by the noise addition. \u2022 Some of the observations a data scientist could make about these four patterns are: \u2022 X3 has changed from the representation of over 8000 of the 30162 records in Adultto, which represent only 3000 records in the modified version of Adult, to the UN reaching 30%. \u2022 Despite this massive change in support, the distribution of the class label in X3 is actually exactly the same at all noise levels. \u2022 The same cannot be said for X2, where a massive change in support (from 1000 to about 4000) was accompanied by a massive change in the distribution of class labels as well. - If this observation leads the user to be further investigated, they would find that the prediction of X2 was sufficient to herald the change in the full distribution."}, {"heading": "7.1. Correlations between utility measures", "text": "s correlation coefficient [38], as described in Fig. 6.2, and Prediction9That, pattern accuracy error = 1 \u2212 pattern accuracy.10One observation we can make about Table 6 is that, in contrast to Fig. 3, the correlations do not always coincide with each other. Just because prediction accuracy decreases does not mean, for example, that the F measurement also decreases. Another observation is that prediction accuracy, F measurement, and AUC have very weak correlations with any of our implementations that are noisy."}, {"heading": "8. Discussion", "text": "None of our proposed measures can tell a user whether M can be turned into a good classifier. They don't try! If a user wants to learn this, he can apply machine learning algorithms to M and see if the resulting classifier performs well by using metrics such as predictive accuracy. However, this won't tell him whether these machine learning algorithms have found the same patterns that existed in D. This is the point at which our proposed methodology - and our implementations of this methodology - comes into play. Predictive accuracy, PSD, and PLD should not be interpreted as an exhaustive measurement of all aspects of pattern retention. Rather, they are examples of quantifying specific effects that a method of maintaining privacy on data can have. It is the responsibility of the data knowledge that performs the anonymization of D to assess what characteristics of a data set are relevant or may change, or how they may be modified."}], "references": [{"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine learning ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "Knowledge discovery through SysFor: a systematically developed forest of multiple decision trees", "author": ["M.Z. Islam", "H. Giggins"], "venue": "in: Ninth Australasian Data Mining Conference-Volume 121, Australian Computer Society, Inc., Ballarat, Australia", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Privacy preserving mining of association rules", "author": ["A. Evfimievski", "R. Srikant", "R. Agrawal", "J. Gehrke"], "venue": "Information Systems 29 (4) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Frequent pattern mining: current status and future directions", "author": ["J. Han", "H. Cheng", "D. Xin", "X. Yan"], "venue": "Data Mining and Knowledge Discovery 15 (1) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Privacy-preserving Data Mining", "author": ["R. Agrawal", "R. Srikant"], "venue": "in: Proceedings of the 2000 ACM SIGMOD Conference on Management of Data, Dallas, Texas", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "On the design and quantification of privacy preserving data mining algorithms", "author": ["D. Agrawal", "C. Aggarwal"], "venue": "in: Proceedings of the twentieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems., ACM", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Privacy preserving data mining: A noise addition framework using a novel clustering technique", "author": ["M.Z. Islam", "L. Brankovic"], "venue": "Knowledge-Based Systems 24 (8) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Random projection-based multiplicative data perturbation for privacy preserving distributed data mining", "author": ["K. Liu", "H. Kargupta", "J. Ryan"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 18 (1) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "k-anonymity: A model for protecting privacy", "author": ["L. Sweeney"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 10 (05) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "ldiversity: Privacy beyond k-anonymity", "author": ["A. Machanavajjhala", "D. Kifer", "J. Gehrke", "M. Venkitasubramaniam"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD) 1 (1) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Differential Privacy", "author": ["C. Dwork"], "venue": "in: Automata, languages and programming, Vol. 4052, Springer Berlin Heidelberg, Venice, Italy", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "Theory of Cryptography ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Mechanism Design via Differential Privacy", "author": ["F. McSherry", "K. Talwar"], "venue": "48th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "The cost of privacy: destruction of data-mining utility in anonymized data publishing", "author": ["J. Brickell", "V. Shmatikov"], "venue": "in: Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Top-down specialization for information and privacy preservation", "author": ["B. Fung", "K. Wang", "P. Yu"], "venue": "in: Proceedings of the 21st International Conference on Data Engineering, IEEE", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Data mining: concepts and techniques", "author": ["J. Han", "M. Kamber", "J. Pei"], "venue": "Morgan Kaufmann Publishers", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "The meaning and use of the area under a receiver operating characteristic (ROC) curve", "author": ["J. Hanley", "B. McNeil"], "venue": "Radiology 143 (1) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1982}, {"title": "M", "author": ["K. Bache"], "venue": "Lichman, UCI Machine Learning Repository ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Selecting the right interestingness measure for association patterns", "author": ["P.-N. Tan", "V. Kumar", "J. Srivastava"], "venue": "in: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, Vol. 2, ACM Press, New York, USA", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2002}, {"title": "Generality is predictive of prediction accuracy", "author": ["G. Webb", "D. Brain"], "venue": "in: Proceedings of the 2002 Pacific Rim Knowledge Acquisition Workshop ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Hiding Association Rules by Using Confidence and Support", "author": ["E. Dasseni", "V. Verykios", "A.K. Elmagarmid", "E. Bertino"], "venue": "in: Information Hiding, Purdue University, Springer Berlin Heidelberg", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Small is beautiful: discovering the minimal set of unexpected patterns", "author": ["B. Padmanabhan", "A. Tuzhilin"], "venue": "in: Proceedings of the 6th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Peculiarity oriented multidatabase mining", "author": ["N. Zhong", "Y. Yao", "M. Ohshima"], "venue": "IEEE Transactions on Knowledge and Data Engineering 15 (4) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Interestingness measures for data mining: a survey", "author": ["L. Geng", "H.J. Hamilton"], "venue": "ACM Computing Surveys 38 (3) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Selecting the right objective measure for association analysis", "author": ["P.-N. Tan", "V. Kumar", "J. Srivastava"], "venue": "Information Systems 29 (4) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "A clustering of interestingness measures", "author": ["B. Vaillant", "P. Lenca", "S. Lallich"], "venue": "in: Discovery Science, Springer Berlin Heidelberg", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "Measuring Information Quality for Privacy Preserving Data Mining", "author": ["S. Fletcher", "M.Z. Islam"], "venue": "International Journal of Computer Theory and Engineering 7 (1) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Classification and regression trees", "author": ["L. Breiman", "J. Friedman", "C. Stone", "R. Olshen"], "venue": "Chapman & Hall/CRC", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1984}, {"title": "An experimental comparison of performance measures for classification", "author": ["C. Ferri", "J. Hern\u00e1ndez-Orallo", "R. Modroiu"], "venue": "Pattern Recognition Letters 30 (1) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "A systematic analysis of performance measures for classification tasks", "author": ["M. Sokolova", "G. Lapalme"], "venue": "Information Processing &Management 45 (4) ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Quality evaluation of an anonymized dataset", "author": ["S. Fletcher", "M.Z. Islam"], "venue": "in: 22nd International Conference on Pattern Recognition, IEEE, Stockholm, Sweden", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Data Swapping: Balancing Privacy Against Precision in Mining for Logic Rules", "author": ["V. Estivill-Castro", "L. Brankovic"], "venue": "Data Warehousing and Knowledge Discovery (DaWaK \u201999) ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1999}, {"title": "The quadratic-chi histogram distance family", "author": ["O. Pele", "M. Werman"], "venue": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 6312 LNCS (PART 2) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Comparing classification results between n-ary and binary problems", "author": ["M. Felkin"], "venue": "in: Quality Measures in Data Mining, Springer Berlin Heidelberg", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2007}, {"title": "Measuring classifier performance: acoherent alternative to the area under the ROC curve", "author": ["D.J. Hand"], "venue": "Machine Learning 77 (1) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "AUC: A misleading measure of the performance of predictive distribution models", "author": ["J.M. Lobo", "A. Jim\u00e9nez-valverde", "R. Real"], "venue": "Global Ecology and Biogeography 17 (2) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "On lines and planes of closest fit to systems of points in space", "author": ["K. Pearson"], "venue": "The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2 (11) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1901}], "referenceMentions": [{"referenceID": 0, "context": "Data mining techniques such as decision forests [1, 2], association rule mining [3] and frequent pattern mining [4] are applied to these datasets in order to extract patterns, where the patterns are usually in the form X \u2192 y.", "startOffset": 48, "endOffset": 54}, {"referenceID": 1, "context": "Data mining techniques such as decision forests [1, 2], association rule mining [3] and frequent pattern mining [4] are applied to these datasets in order to extract patterns, where the patterns are usually in the form X \u2192 y.", "startOffset": 48, "endOffset": 54}, {"referenceID": 2, "context": "Data mining techniques such as decision forests [1, 2], association rule mining [3] and frequent pattern mining [4] are applied to these datasets in order to extract patterns, where the patterns are usually in the form X \u2192 y.", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "Data mining techniques such as decision forests [1, 2], association rule mining [3] and frequent pattern mining [4] are applied to these datasets in order to extract patterns, where the patterns are usually in the form X \u2192 y.", "startOffset": 112, "endOffset": 115}, {"referenceID": 4, "context": "include additive noise [5, 6, 7] and multiplicative noise [8].", "startOffset": 23, "endOffset": 32}, {"referenceID": 5, "context": "include additive noise [5, 6, 7] and multiplicative noise [8].", "startOffset": 23, "endOffset": 32}, {"referenceID": 6, "context": "include additive noise [5, 6, 7] and multiplicative noise [8].", "startOffset": 23, "endOffset": 32}, {"referenceID": 7, "context": "include additive noise [5, 6, 7] and multiplicative noise [8].", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "This is the approach k-anonymity [9] and its sibling techniques (e.", "startOffset": 33, "endOffset": 36}, {"referenceID": 9, "context": "l-diversity [10]) use.", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "Differential privacy [11, 12, 13] is the most well-known technique to use this approach.", "startOffset": 21, "endOffset": 33}, {"referenceID": 11, "context": "Differential privacy [11, 12, 13] is the most well-known technique to use this approach.", "startOffset": 21, "endOffset": 33}, {"referenceID": 12, "context": "Differential privacy [11, 12, 13] is the most well-known technique to use this approach.", "startOffset": 21, "endOffset": 33}, {"referenceID": 13, "context": "In order to assess the utility of a dataset modified to preserve privacy, it is currently common practice [14, 15, 7] to use a variety of data mining techniques (such as decision forests) to discover patterns in the modified dataset M , and then see if those patterns can correctly predict the labels of future records.", "startOffset": 106, "endOffset": 117}, {"referenceID": 14, "context": "In order to assess the utility of a dataset modified to preserve privacy, it is currently common practice [14, 15, 7] to use a variety of data mining techniques (such as decision forests) to discover patterns in the modified dataset M , and then see if those patterns can correctly predict the labels of future records.", "startOffset": 106, "endOffset": 117}, {"referenceID": 6, "context": "In order to assess the utility of a dataset modified to preserve privacy, it is currently common practice [14, 15, 7] to use a variety of data mining techniques (such as decision forests) to discover patterns in the modified dataset M , and then see if those patterns can correctly predict the labels of future records.", "startOffset": 106, "endOffset": 117}, {"referenceID": 15, "context": "Records used in this way are often known as the \u201ctest dataset\u201d, T [16].", "startOffset": 66, "endOffset": 70}, {"referenceID": 16, "context": "Other measures such as F-measure [17] and AUC [18] can be similarly used.", "startOffset": 46, "endOffset": 50}, {"referenceID": 17, "context": "Table 1: A selection of patterns discovered in the \u201cAdult\u201d dataset [19].", "startOffset": 67, "endOffset": 71}, {"referenceID": 18, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 189, "endOffset": 197}, {"referenceID": 19, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 189, "endOffset": 197}, {"referenceID": 20, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 210, "endOffset": 214}, {"referenceID": 21, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 228, "endOffset": 232}, {"referenceID": 22, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 246, "endOffset": 250}, {"referenceID": 23, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 304, "endOffset": 320}, {"referenceID": 24, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 304, "endOffset": 320}, {"referenceID": 25, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 304, "endOffset": 320}, {"referenceID": 26, "context": "What makes a pattern valuable can vary depending on the needs of the user, and measures have been developed to assess different aspects of patterns, such as a pattern\u2019s support or coverage [20, 21], confidence [22], conciseness [23], peculiarity [24], or many other aspects depending on the user\u2019s needs [25, 26, 27, 28].", "startOffset": 304, "endOffset": 320}, {"referenceID": 27, "context": "In our experiments, we arbitrarily use the CART decision tree algorithm [29] to generate a collection of patterns.", "startOffset": 72, "endOffset": 76}, {"referenceID": 15, "context": "A \u201cpattern\u201d can be defined as a rule X \u2192 y \u2208 Y , where X is an antecedent, representing a set of conditions in the form a = av that when met, predicts that a consequent Y will equal y [16].", "startOffset": 184, "endOffset": 188}, {"referenceID": 28, "context": "While Prediction Accuracy is an excellent measure when evaluating the utility of a classifier or model [30, 31], care needs to be taken when extending its use to the privacy-preservation domain.", "startOffset": 103, "endOffset": 111}, {"referenceID": 29, "context": "While Prediction Accuracy is an excellent measure when evaluating the utility of a classifier or model [30, 31], care needs to be taken when extending its use to the privacy-preservation domain.", "startOffset": 103, "endOffset": 111}, {"referenceID": 13, "context": "It has been common in the past for privacy-preservation techniques to have their effect on the quality (utility) of the data measured with prediction accuracy [14, 32, 15, 7].", "startOffset": 159, "endOffset": 174}, {"referenceID": 30, "context": "It has been common in the past for privacy-preservation techniques to have their effect on the quality (utility) of the data measured with prediction accuracy [14, 32, 15, 7].", "startOffset": 159, "endOffset": 174}, {"referenceID": 14, "context": "It has been common in the past for privacy-preservation techniques to have their effect on the quality (utility) of the data measured with prediction accuracy [14, 32, 15, 7].", "startOffset": 159, "endOffset": 174}, {"referenceID": 6, "context": "It has been common in the past for privacy-preservation techniques to have their effect on the quality (utility) of the data measured with prediction accuracy [14, 32, 15, 7].", "startOffset": 159, "endOffset": 174}, {"referenceID": 13, "context": "A solution to (1) is for the data owner to build a ZM and ZD with every possible data mining technique they think is worth checking [14].", "startOffset": 132, "endOffset": 136}, {"referenceID": 13, "context": "If this solution is not used, then a user must either trust the implicit assumption that other data mining techniques will perform similarly, or release the collection of patterns ZM that they did test, and not release M to the public at all [14].", "startOffset": 242, "endOffset": 246}, {"referenceID": 30, "context": "To the best of our knowledge, aside from our preliminary investigation [32], no solution to (2) currently exists in the literature.", "startOffset": 71, "endOffset": 75}, {"referenceID": 30, "context": "Pattern Accuracy Introduced by us in a 2014 conference [32] and not published in a journal until now, Pattern Accuracy is a simple measure that compares D and M .", "startOffset": 55, "endOffset": 59}, {"referenceID": 19, "context": "Pattern Support Distance (PSD) The \u201csupport\u201d of a pattern is the number of records in a dataset that a pattern covers [21, 22], and can be represented as |\u03c3X(D)| when describing the support of patternX in datasetD.", "startOffset": 118, "endOffset": 126}, {"referenceID": 20, "context": "Pattern Support Distance (PSD) The \u201csupport\u201d of a pattern is the number of records in a dataset that a pattern covers [21, 22], and can be represented as |\u03c3X(D)| when describing the support of patternX in datasetD.", "startOffset": 118, "endOffset": 126}, {"referenceID": 15, "context": "as T ), and so most data mining algorithms automatically remove them from ZD [16].", "startOffset": 77, "endOffset": 81}, {"referenceID": 4, "context": "The aim of privacy preservation is to (1) make any individual record difficult to identify, while (2) leaving the patterns as unaffected as possible [5, 33, 7].", "startOffset": 149, "endOffset": 159}, {"referenceID": 31, "context": "The aim of privacy preservation is to (1) make any individual record difficult to identify, while (2) leaving the patterns as unaffected as possible [5, 33, 7].", "startOffset": 149, "endOffset": 159}, {"referenceID": 6, "context": "The aim of privacy preservation is to (1) make any individual record difficult to identify, while (2) leaving the patterns as unaffected as possible [5, 33, 7].", "startOffset": 149, "endOffset": 159}, {"referenceID": 15, "context": "The consequent of any pattern X is usually the most common class label to occur out of all the records in \u03c3X(D), with any other class labels being ignored [16].", "startOffset": 155, "endOffset": 159}, {"referenceID": 32, "context": "To avoid these problems, we use the Chi-squared histogram distance [34] to measure differences in the distribution of Y between \u03c3X(D) and \u03c3X(M):", "startOffset": 67, "endOffset": 71}, {"referenceID": 18, "context": "\u201cConfidence\u201d refers to the certainty or reliability of a pattern \u2013 that is, how frequent the most frequent label is [20].", "startOffset": 116, "endOffset": 120}, {"referenceID": 32, "context": "It should be noted that Chi-squared histogram distance is invariant to the number of records [34], and so the support of a pattern (both in D and M) does not affect the result.", "startOffset": 93, "endOffset": 97}, {"referenceID": 16, "context": "This is often a concern with popular measures such as AUC [18] and F-measure [17], where non-binary class attributes need to be treated with care [35].", "startOffset": 58, "endOffset": 62}, {"referenceID": 33, "context": "This is often a concern with popular measures such as AUC [18] and F-measure [17], where non-binary class attributes need to be treated with care [35].", "startOffset": 146, "endOffset": 150}, {"referenceID": 15, "context": "1, it is common in the literature for a privacypreserving technique\u2019s impact on data utility to be quantified using Prediction Accuracy: that is, by comparing \u03b1(ZM |T ) to \u03b1(ZD|T ) [16].", "startOffset": 181, "endOffset": 185}, {"referenceID": 16, "context": "Other common measures are F-measure [17] and AUC [18], where again ZM is compared to ZD using T (refer to Fig.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "Meanwhile, AUC [18] is shorthand for \u201cArea under the ROC curve\u201d, with \u201cROC\u201d in turn being short for \u201cReceiver Operating Characteristic\u201d.", "startOffset": 15, "endOffset": 19}, {"referenceID": 34, "context": "It has become popular in the machine learning community as of late, despite some problems it has when comparing different classifiers [36, 37].", "startOffset": 134, "endOffset": 142}, {"referenceID": 35, "context": "It has become popular in the machine learning community as of late, despite some problems it has when comparing different classifiers [36, 37].", "startOffset": 134, "endOffset": 142}, {"referenceID": 17, "context": "We use 17 datasets publicly available in the UCI Machine Learning Repository [19].", "startOffset": 77, "endOffset": 81}, {"referenceID": 27, "context": "ZD), we run the CART algorithm [29], with a minimum leaf size (i.", "startOffset": 31, "endOffset": 35}, {"referenceID": 36, "context": "Pearson\u2019s r value) [38].", "startOffset": 19, "endOffset": 23}, {"referenceID": 36, "context": "The correlations are calculated using Pearson\u2019s correlation coefficient [38] as described in Sect.", "startOffset": 72, "endOffset": 76}], "year": 2015, "abstractText": "In this paper, we explore how modifying data to preserve privacy affects the quality of the patterns discoverable in the data. For any analysis of modified data to be worth doing, the data must be as close to the original as possible. Therein lies a problem \u2013 how does one make sure that modified data still contains the information it had before modification? This question is not the same as asking if an accurate classifier can be built from the modified data. Often in the literature, the prediction accuracy of a classifier made from modified (anonymized) data is used as evidence that the data is similar to the original. We demonstrate that this is not the case, and we propose a new methodology for measuring the retention of the patterns that existed in the original data. We then use our methodology to design three measures that can be easily implemented, each measuring aspects of the data that no pre-existing techniques can measure. These measures do not negate the usefulness of prediction accuracy or other measures \u2013 they are complementary to them, and support our argument that one measure is almost never enough.", "creator": "LaTeX with hyperref package"}}}