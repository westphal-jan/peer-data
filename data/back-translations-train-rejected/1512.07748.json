{"id": "1512.07748", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2015", "title": "Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips", "abstract": "This paper discusses real-time alignment of audio signals of music performance to the corresponding score (a.k.a. score following) which can handle tempo changes, errors and arbitrary repeats and/or skips (repeats/skips) in performances. This type of score following is particularly useful in automatic accompaniment for practices and rehearsals, where errors and repeats/skips are often made. Simple extensions of the algorithms previously proposed in the literature are not applicable in these situations for scores of practical length due to the problem of large computational complexity. To cope with this problem, we present two hidden Markov models of monophonic performance with errors and arbitrary repeats/skips, and derive efficient score-following algorithms with an assumption that the prior probability distributions of score positions before and after repeats/skips are independent from each other. We confirmed real-time operation of the algorithms with music scores of practical length (around 10000 notes) on a modern laptop and their tracking ability to the input performance within 0.7 s on average after repeats/skips in clarinet performance data. Further improvements and extension for polyphonic signals are also discussed.", "histories": [["v1", "Thu, 24 Dec 2015 08:21:48 GMT  (592kb,D)", "http://arxiv.org/abs/1512.07748v1", "12 pages, 8 figures, version accepted in IEEE/ACM Transactions on Audio, Speech, and Language Processing"]], "COMMENTS": "12 pages, 8 figures, version accepted in IEEE/ACM Transactions on Audio, Speech, and Language Processing", "reviews": [], "SUBJECTS": "cs.SD cs.LG cs.MM", "authors": ["tomohiko nakamura", "eita nakamura", "shigeki sagayama"], "accepted": false, "id": "1512.07748"}, "pdf": {"name": "1512.07748.pdf", "metadata": {"source": "CRF", "title": "Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips", "authors": ["Tomohiko Nakamura", "Shigeki Sagayama"], "emails": ["Nakamura@ipc.i.u-tokyo.ac.jp).", "(enakamura@am.kuis.kyoto-u.ac.jp).", "(sagayama@meiji.ac.jp)."], "sections": [{"heading": null, "text": "In recent years, it has become clear that most of them are people who are not able to deny themselves, but people who are able to deny themselves, and people who are able to deny themselves. In recent years, it has been shown that these people are able to deny themselves, and that they are able to deny themselves, that they are able to do what they need to do."}, {"heading": "II. SCORE FOLLOWING FOR PERFORMANCES WITH ERRORS", "text": "A. Diversity in Audio Performance and Statistical Approach The following score is generally challenging because audio signals from musical performances vary widely, even when the same score is used. The following lists four typical sources of diversity in monophonic audio performance. (a) Acoustic Variations: Spectral properties of audio performances depend on musical instruments and are not stationary. In addition, audio performances usually differ from those caused by the surrounding environment and musical instruments (e.g. resonance, background noise, breathing sounds and other acoustics). (b) Temporal variations: The tempo of performance and duration of notes presented differ from those indicated in scores due to their ability, physical limitations of musical instruments and musical expressions. Thus, performances are often made at a slow pace during practice to avoid mistakes. (c) Performing errors: Performing errors may arise due to poor performance or poor performance skills."}, {"heading": "B. Performance HMM", "text": "We represent the performance score with N musical events, each of which represents a note or a remainder. An interpreter reads the score from event to event and produces a sound that corresponds to an event. This process of performance can be modeled with a hierarchical HMM with two levels. [20], [21], which we call Performance HMM, and the performance is described as transitions between the top states, and the bottom level expresses the temporal structure of the audio signal in a played event. Events correspond to states (top states) of the top level HMM (top HMM), and the performance is described as transitions between the top states. Let us leave z (Top) t = 0, \u00b7 \u00b7, N \u2212 1 describe the random variable that describes the top state in the top range (t = 0, \u00b7 \u00b7, T \u2212 1)."}, {"heading": "C. Emission Probability and Substitution Error", "text": "From here to sec. II-E we consider the power HMM with L = 1 for simplicity, but the case for L > 1 can be treated in a similar way. To extract tone information from the input signal, we need an appropriate tone reproduction. Comparing some tone characteristics in [7], [22] results in the order of magnitude of a constant Q transformation (CQT) [23] with a quality factor set to a semitone, the best result of the following tone reproduction for monophonic tone input. In addition, normalization quantities of CQTs such as D \u2212 1 d = 0 yd = 1 can make them insensitive to dynamic deviations. Although it may be thought that normalization makes it difficult to distinguish pauses from tones, the difference in spectral form between pauses and tones can support discrimination: the CQT of a pitched sound has clear peaks at its fundamental frequency and harmonics, while the QTTs are relatively flat at pauses."}, {"heading": "D. Transition Probability and Deletion and Insertion Errors", "text": "Transition probabilities at the top level aj, i represent the frequency of transitions between events. If performances do not contain insertion and deletion errors, aj, i = 0 except i = j + 1. We can express an insertion error and a deletion error with a self-transition and a transition to the second highest state corresponding to aj, j and aj, j + 2. The self-transition probability a (i) 0.0 of the lowest state 0 of the top state i describes the expected duration of the corresponding event di, which is calculated as a product of the note value of the event and the recorded tempo: di = \u221e k = 1 k (a) 0.0) k \u2212 1 (1 \u2212 a (i) 0.0) = 1 \u2212 a (i) 0.0. (5) If di is shorter than a processing time interval, we set a (i) 0.0 = 0. This probable representation of the event duration describes the temporal fluctuations of the music."}, {"heading": "E. Pauses between Notes", "text": "Pauses between notes can be introduced into the performance HMM by adding an additional lower state with index 1, which we call pause state (Fig. 2). The occurrence of the pause is expressed as a transition to the pause state, which corresponds to a (i) 0.1. The duration of the additional pause is represented by the self-transition probability of the pause state a (i) 1.1, which can be set similarly to Equation (5). We set a (i) 1.0 = 0 and \u03c0 (i) 1 = 0 for all i. We assume that b (i) 1 (yt) = N (yt | \u00b5 \u2212 1, \u03a3 \u2212 1)."}, {"heading": "F. Estimation of Score Positions", "text": "For the convenience of estimating Score Positions, we convert the performance of HMM into an equivalent standard HMM = target value. Its state corresponds to a lowest state of the performance of HMM and is marked with (i, l). \u2212 The standard HMM iparameterized by emission probabilities b (i, l) (yt), initial probabilities p (i, l), and transition probabilities a (i, l), defined by b (i, l) (yt): b (i) l (yt), \u03c0 (i), \u03c0 (i) l, anda (i), andre (i), andre (j), andre (j), andre (j), andre (j), andre (j), andre (j), andre (j), andre (re), re re re (re, re re re (i), re (re), re (re), re (re, re (n), andre (n), andre (n), andre (re, re (n), andre (n), andre (re, re, re (re), andre (n), andre (n), andre (n, andre, andre (n), andre (n), andre (n, andre, andre, andre (i), andre (n, andre, andre (i), andre (i), andre (i), andre (andre, andre (i), andre (i), andre (andre, andre, andre (i), andre (andre, andre, andre (andre, andre), andre (andre (andre, andre), andre (andre (andre), andre (andre (andre, andre), andre (andre (andre), andre (andre (andre, re, andre), andre (andre (andre), andre (andre (andre, andre, andre), andre (andre (andre), andre (andre (andre, andre), andre (and"}, {"heading": "B. Reduction of Computational Complexity by Factorizing Probabilities of Repeats/Skips", "text": "One method to reduce computational complexity while all transitions lead to satisfaction is to introduce some constraints on transition probabilities. In [13], the reduction in computational complexity is achieved by assuming that the probability of a repetition / skip from an event to an event i is then written as the product of two probabilities sj and ri. sj is the probability that an event j stops before a repetition / skip, and ri is the probability of a repetition / skip of an event i. The transition probability of the upper HMM is then written asaj, i = a (nbh) j, i + sjri."}, {"heading": "C. Explicit Description of Silent Breaks at Repeats/Skips", "text": "We can achieve a similar reduction in computational complexity by applying a different assumption about arbitrary repetitions / jumps. Performers often take silent pauses during repetitions / jumps to prepare for the resumption of performance. In fact, 59 of 63 repetitions / jumps are accompanied by the probability of the self-transition of the lowest state of break state a (N) 0.0, and its value is determined similarly to Equation (5). Repetitions / jumps are presented as two-step transitions over the break state (Fig. 3). Stopping (summarizing) a performance is expressed as transitions to (from) the break state a, the probability of which is indicated by sj (ri)."}, {"heading": "IV. EXPERIMENTAL EVALUATION OF THE PROPOSED SCORE-FOLLOWING ALGORITHMS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Processing Time", "text": "Processing time depends on the number of N events and practically does not depend on other score content and signal contents. We used synthetic scores from 10 to 106 events1 and a random signal of two seconds with a sampling rate of 16 kHz as audio input. Normalized CQTs were calculated with a screen length of 128 ms and a hopsize of 20 ms. Their center frequencies ranged from 55 to 7040 Hz at a semitone interval, and the quality factor was set to 16, which is approximately a semitone. Algorithms were implemented in C + + on a computer with a 3.30 GHz CPU (Intel (R) Core (TM) i3-2120 CPU) and 8 GB of memory running Debian. Processing times of over 100 images with standard errors are suggested for the algorithms in Figure 4."}, {"heading": "B. Score-Following Accuracy for Performances with Errors", "text": "The question that arises is to what extent it is a way in which people are able to survive themselves, and in which people are able to survive themselves, and in which people are able to survive themselves, and in which people are able to understand, understand, understand, understand, understand and understand what they are doing, and understand what they have to do to understand and understand, why people are able to change and change the world, and why they are able to change and change the world, and why they are able to change the world, and to change the world, and to change the world, and to change the world, and to change the world, and to change the world, to change the world, to change the world, and to change the world, and to change the world, and to change the world, and to change the world, and to change the world, and to change the world, and to change the world, and to change the world."}, {"heading": "C. Score-Following Accuracy for Performances with Errors and Repeats/Skips", "text": "It has been the case this year that we are at a stage where we are not yet able to find a solution that we are able to find a solution."}, {"heading": "V. DISCUSSIONS", "text": "A. Improvement of the proposed algorithms We are now discussing possible extensions of the proposed algorithms. Hold and repeat positions are not entirely random, and their distributions show certain tendencies in the actual performances. [13] For example, the performers often continue from the first beat and from the beginning of the movements, reflecting the understanding of the performers of musical structures. These tendencies can be incorporated into sj, ri in our performance HMMs, and the accuracy and follow-up times of the proposed algorithms would improve [13]. Another method of improving the proposed algorithms is to refine the model of the duration of the listed events. To this end, we can assign several lowest states that introduce the duration [20], [24], [25] or explicitly their probability distribution [6]. This refinement is compatible with the proposed methods to reduce the compression costs, since they can be used independently of the topology of the lowest MM."}, {"heading": "B. Extension to Polyphonic Music", "text": "Although we have limited ourselves to monophonic performances, let's briefly discuss the polyphonic case. We can construct a performance HMM for polyphonic scores similar to the monophonic case. By linking top states with musical events (chords, notes, and rests) in a polyphonic score, the top HMM can be used without modification, and insertions and deletions of chords, pauses between chords, and repetitions / jumps can be inserted in the same way. Importantly, the current methods for reducing computational complexity can be applied to the polyphonic case, since it is independent of the details of the lower HMMs. On the other hand, we need to expand the lower HMMs to include chords. In particular, errors can occur on each note in a chord, and there is a combinatorial large number of possible error forms for a large chord. Although we prepare spectral templates for all possible forms of played chords, and mixing errors may be similar to Eq in terms of mixing errors in a rule of 4."}, {"heading": "VI. CONCLUSION", "text": "To solve the problem of the high computational costs of following arbitrary repetitions / jumps, we introduced two HMMs that describe a probability of repetitions / jumps with a probability of stop positions and a probability of repetitive positions, and derived efficient algorithms from them. We demonstrated real-time editing of the algorithms with scores from practical length (O (103) to O (104) events. Experimental evaluations with clarinet data showed that the Antescofo algorithms outperformed in terms of accuracy of score sequence and traceability of repetitions / jumps. Furthermore, we briefly discussed methods for improving the proposed algorithms and extending them to polyphonic inputs."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We thank Yuu Mizuno and Kosuke Suzuki for their participation in the early stages of this work, Naoya Ito for her clarinet playing and Hirokazu Kameoka for useful discussions. This research was partially supported by JSPS Research Fellowships for Young Scientists No. 15J0992 (T. N.) and JSPS Grant-inAid No. 15K16054 (E. N.) and No. 26240025 (S. S. S.)."}, {"heading": "A. List of important parameters", "text": "Important parameters of the proposed models are listed in Tab. VI."}, {"heading": "B. Derivation of the No-Break Algorithm for L > 1", "text": "Assuming that the transition probability of repetitions / jumps can be described as a product of sj and ri, the transition probability of the standard HMM is rewritten a (j, l), (i, l) for j / nbh (i), (i, l) = e (j) l \"sjri\u03c0 (i) l,\" (18) and Equation (9) for t \"1,\" (i, l) = b \"(i, l) (yt) (j\" nbh (i) l \"= 0, \u00b7, L \u2212 1\u03b1t \u2212 1, (i, l \u00b2) a\" (j, l \u00b2), (i, l \"contained\" (i, l) (yt \"esnbh\" (i) l, l \"l\" esh \"(i) l, l,\" l, l \"l\" s \"(l\"), l \"s\" (l \"), l.\""}, {"heading": "C. Derivation of the Break Algorithm for L > 1", "text": "Consider the performance of HMM with the break state and with L bottom states in each top state = 21 (Sec. III-C, silent breaks at repeats / skips can be introduced as top state N (the break state) and arbitrary repeats / skips are described with two-step transitions via the break state. Since the transition chances of the standard HMM a), (i, l) is zero, unless j (i) l. \"(9) for t 1 and i 6 = N can be rewritten as\u03b1t, (i, l) and b.\" (i, l. \"). (i, l.\"). (i, l. \")............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}], "references": [{"title": "An on-line algorithm for real-time accompaniment", "author": ["R.B. Dannenberg"], "venue": "Proc. Int. Computer Music Conf., pp. 193\u2013198, 1984.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1984}, {"title": "The synthetic performer in the context of live performance", "author": ["B. Vercoe"], "venue": "Proc. Int. Computer Music Conf., pp. 199\u2013200, 1984.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1984}, {"title": "Automatic page turning for musicians via real-time machine listening", "author": ["A. Arzt", "G. Widmer", "S. Dixon"], "venue": "Proc. European Conf. Artificial Intelligence, pp. 241\u2013245, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Score following: State of the art and new developments", "author": ["N. Orio", "S. Lemouton", "D. Schwarz", "N. Schnell"], "venue": "Proc. New Interfaces for Musical Expression, pp. 36\u201341, 2003.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Modeling form for on-line following of musical performances", "author": ["B. Pardo", "W. Birmingham"], "venue": "Proc. AAAI, vol. 2, pp. 1018\u20131023, 2005.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "A coupled duration-focused architecture for real-time musicto-score alignment", "author": ["A. Cont"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 32, pp. 974\u2013987, June 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparative study of tonal acoustic features for a symbolic level music-to-score alignment", "author": ["C. Joder", "S. Essid", "G. Richard"], "venue": "Proc. IEEE Workshop Applications Signal Process. Audio Acoust., pp. 409\u2013412, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "A state space model for online polyphonic audio-score alignment", "author": ["Z. Duan", "B. Pardo"], "venue": "Proc. Int. Conf. Acoust. Speech Signal Process., pp. 197\u2013200, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Realtime audio-to-score alignment using particle filter for coplayer music robots", "author": ["T. Otsuka", "K. Nakadai", "T. Takahashi", "T. Ogata", "H.G. Okuno"], "venue": "EURASIP J. Applied Signal Process., vol. 2011, no. 384651, pp. 1\u201313, 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "A conditional random field framework for robust and scalable audio-to-score matching", "author": ["C. Joder", "S. Essid", "G. Richard"], "venue": "IEEE Trans. Acoust., Speech, and Language Process., vol. 19, no. 8, pp. 2385\u2013 2397, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "A unified approach to real time audioto-score and audio-to-audio alignment using sequential Montecarlo inference techniques", "author": ["N. Montecchio", "A. Cont"], "venue": "Proc. Int. Conf. Acoust. Speech Signal Process., pp. 193\u2013196, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Acoustic score following to musical performance with errors and arbitrary repeats and skips for automatic accopaniment", "author": ["T. Nakamura", "E. Nakamura", "S. Sagayama"], "venue": "Proc. Sound and Music Computing Conf., pp. 299\u2013304, Aug. 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Outerproduct hidden Markov model and polyphonic MIDI score following", "author": ["E. Nakamura", "T. Nakamura", "Y. Saito", "N. Ono", "S. Sagayama"], "venue": "J. New Music Res., vol. 43, no. 2, pp. 183\u2013201, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Robust polyphonic MIDI score following with hidden Markov models", "author": ["D. Schwarz", "N. Orio", "N. Schnell"], "venue": "Proc. Int. Computer Music Conf., 2004.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "A Piano Duo Performance Support System to Motivate Children\u2019s Practice at Home", "author": ["C. Oshima", "K. Nishimoto", "M. Suzuki"], "venue": "Trans. Info. Process. Soc. Japan, vol. 46, no. 1, pp. 157\u2013170, 2005. in Japanese.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Merged-output hidden Markov model for score following of MIDI performance with ornaments, desynchronized voices, repeats and skips", "author": ["E. Nakamura", "Y. Saito", "N. Ono", "S. Sagayama"], "venue": "Proc. Joint Conf. of 40th Int. Computer Music Conf. and 11th Sound and Music Computing Conf., pp. 1185\u20131192, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "A stochastic temporal model of polyphonic MIDI performance with ornaments", "author": ["E. Nakamura", "N. Ono", "S. Sagayama", "K. Watanabe"], "venue": "preparation. [arXiv:1404.2314].", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2314}, {"title": "Handling repeats and jumps in score-performance synchronization", "author": ["C. Fremerey", "M. M\u00fcller", "M. Clausen"], "venue": "Proc. Int. Symposium Music Info. Retrieval, pp. 243\u2013248, 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Aligning semi-improvised music audio with its lead sheet", "author": ["Z. Duan", "B. Pardo"], "venue": "Proc. Int. Symposium Music Info. Retrieval, pp. 513\u2013 518, 2011.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Score following using spectral analysis and hidden Markov models", "author": ["N. Orio", "F. D\u00e9chelle"], "venue": "Proc. Int. Computer Music Conf., vol. 1001, pp. 1708\u20131710, 2001.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}, {"title": "Realtime audio to score alignment for polyphonic music instruments, using sparse non-negative constraints and hierarchical HMMs", "author": ["A. Cont"], "venue": "Proc. Int. Conf. Acoust. Speech Signal Process., vol. 5, pp. 245\u2013248, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning optimal features for polyphonic audio-to-score alignment", "author": ["C. Joder", "S. Essid", "G. Richard"], "venue": "IEEE Trans. Acoust., Speech, and Language Process., vol. 21, pp. 2118\u20132128, Oct 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "An efficient algorithm for the calculation of a constant Q transform", "author": ["J. Brown", "M. Puckette"], "venue": "J. Acoust. Soc. Am., vol. 92, pp. 2698\u20132701, 1992.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1992}, {"title": "Score-performance matching using HMMs", "author": ["P. Cano", "A. Loscos", "J. Bonada"], "venue": "Proc. Int. Computer Music Conf., pp. 441\u2013444, 1999.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1999}, {"title": "Automatic segmentation of acoustic musical signals using hidden Markov models", "author": ["C. Raphael"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 21, no. 4, pp. 360\u2013370, 1999.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1999}, {"title": "Timbre replacement of harmonic and drum components for music audio signals", "author": ["T. Nakamura", "H. Kameoka", "K. Yoshii", "M. Goto"], "venue": "Proc. Int. Conf. Acoust. Speech Signal Process., pp. 7520\u20137524, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Soundprism: An online system for scoreinformed source separation of music audio", "author": ["Z. Duan", "B. Pardo"], "venue": "IEEE J. Sel. Topics. Signal Process., vol. 5, no. 6, pp. 1205\u20131215, 2011.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}, {"title": "Evaluation of realtime audio-to-score alignment", "author": ["A. Cont", "D. Schwarz", "N. Schnell", "C. Raphael"], "venue": "Proc. Int. Symposium Music Info. Retrieval, 2007.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Real-time alignment of an audio signal of a music performance to a given score, also known as score following, has been gathering attention since its first appearance in 1984 [1], [2].", "startOffset": 175, "endOffset": 178}, {"referenceID": 1, "context": "Real-time alignment of an audio signal of a music performance to a given score, also known as score following, has been gathering attention since its first appearance in 1984 [1], [2].", "startOffset": 180, "endOffset": 183}, {"referenceID": 2, "context": "Score following is a basic technique for realtime musical applications such as automatic accompaniment, automatic score page-turning [3] and automatic captioning to music videos.", "startOffset": 133, "endOffset": 136}, {"referenceID": 3, "context": "Many studies of score following have been carried out (see [4] for a review and [5]\u2013[13] for recent progress).", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "Many studies of score following have been carried out (see [4] for a review and [5]\u2013[13] for recent progress).", "startOffset": 80, "endOffset": 83}, {"referenceID": 12, "context": "Many studies of score following have been carried out (see [4] for a review and [5]\u2013[13] for recent progress).", "startOffset": 84, "endOffset": 88}, {"referenceID": 3, "context": "Treatment of errors in score following is discussed in some studies [4], [5], [13], [14].", "startOffset": 68, "endOffset": 71}, {"referenceID": 4, "context": "Treatment of errors in score following is discussed in some studies [4], [5], [13], [14].", "startOffset": 73, "endOffset": 76}, {"referenceID": 12, "context": "Treatment of errors in score following is discussed in some studies [4], [5], [13], [14].", "startOffset": 78, "endOffset": 82}, {"referenceID": 13, "context": "Treatment of errors in score following is discussed in some studies [4], [5], [13], [14].", "startOffset": 84, "endOffset": 88}, {"referenceID": 4, "context": "Score-following algorithms that can follow repeats/skips have been proposed in [5], [11], [15].", "startOffset": 79, "endOffset": 82}, {"referenceID": 10, "context": "Score-following algorithms that can follow repeats/skips have been proposed in [5], [11], [15].", "startOffset": 84, "endOffset": 88}, {"referenceID": 14, "context": "Score-following algorithms that can follow repeats/skips have been proposed in [5], [11], [15].", "startOffset": 90, "endOffset": 94}, {"referenceID": 12, "context": "The authors have presented a new type of hidden Markov model (HMM) that describes musical instrument digital interface (MIDI) performances with errors and arbitrary repeats/skips, and derived a computationally efficient algorithm for the HMM [13].", "startOffset": 242, "endOffset": 246}, {"referenceID": 0, "context": "Although monophonic score following has been addressed since [1], [2], ar X iv :1 51 2.", "startOffset": 61, "endOffset": 64}, {"referenceID": 1, "context": "Although monophonic score following has been addressed since [1], [2], ar X iv :1 51 2.", "startOffset": 66, "endOffset": 69}, {"referenceID": 11, "context": "IV) was reported in our previous conference paper [12].", "startOffset": 50, "endOffset": 54}, {"referenceID": 0, "context": "Errors are categorized into pitch errors (substitution errors), dropping notes (deletion errors), adding extra notes (insertion errors) [1].", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "Although it is out of the scope of this paper, there are other sources of variety in music performance such as ornaments [6], [13], [16], [17] and improvisation [18], [19].", "startOffset": 121, "endOffset": 124}, {"referenceID": 12, "context": "Although it is out of the scope of this paper, there are other sources of variety in music performance such as ornaments [6], [13], [16], [17] and improvisation [18], [19].", "startOffset": 126, "endOffset": 130}, {"referenceID": 15, "context": "Although it is out of the scope of this paper, there are other sources of variety in music performance such as ornaments [6], [13], [16], [17] and improvisation [18], [19].", "startOffset": 132, "endOffset": 136}, {"referenceID": 16, "context": "Although it is out of the scope of this paper, there are other sources of variety in music performance such as ornaments [6], [13], [16], [17] and improvisation [18], [19].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "Although it is out of the scope of this paper, there are other sources of variety in music performance such as ornaments [6], [13], [16], [17] and improvisation [18], [19].", "startOffset": 161, "endOffset": 165}, {"referenceID": 18, "context": "Although it is out of the scope of this paper, there are other sources of variety in music performance such as ornaments [6], [13], [16], [17] and improvisation [18], [19].", "startOffset": 167, "endOffset": 171}, {"referenceID": 3, "context": "Recent score-following systems commonly use probabilistic models such as HMM to capture the variety of audio performances, and their effectiveness has been well confirmed [4] (and references in the Introduction).", "startOffset": 171, "endOffset": 174}, {"referenceID": 19, "context": "This process of performance can be modeled with a hierarchical HMM with two levels [20], [21], which we call the performance HMM.", "startOffset": 83, "endOffset": 87}, {"referenceID": 20, "context": "This process of performance can be modeled with a hierarchical HMM with two levels [20], [21], which we call the performance HMM.", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "In the comparison of some audio features in [7], [22], the magnitude of a constant-Q transform (CQT) [23] with a quality factor set to one semitone yielded the best result of score following for monophonic audio input.", "startOffset": 44, "endOffset": 47}, {"referenceID": 21, "context": "In the comparison of some audio features in [7], [22], the magnitude of a constant-Q transform (CQT) [23] with a quality factor set to one semitone yielded the best result of score following for monophonic audio input.", "startOffset": 49, "endOffset": 53}, {"referenceID": 22, "context": "In the comparison of some audio features in [7], [22], the magnitude of a constant-Q transform (CQT) [23] with a quality factor set to one semitone yielded the best result of score following for monophonic audio input.", "startOffset": 101, "endOffset": 105}, {"referenceID": 0, "context": "Here w k,0 \u2208 [0, 1] is a mixture weight of pitch k of bottom state 0 of top state i, which satisfies \u2211 k\u2208K w (i) k,0 = 1 for all i.", "startOffset": 13, "endOffset": 19}, {"referenceID": 4, "context": "The model is a generalization of the performance models in previous studies [5], [11], [15].", "startOffset": 76, "endOffset": 79}, {"referenceID": 10, "context": "The model is a generalization of the performance models in previous studies [5], [11], [15].", "startOffset": 81, "endOffset": 85}, {"referenceID": 14, "context": "The model is a generalization of the performance models in previous studies [5], [11], [15].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "In [13], reduction of the computational complexity is achieved with an assumption that the probability of score positions where performers stop before repeats/skips (stop positions) is the same regardless of where they resume performing after repeats/skips (resumption positions).", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "[6], [20], [24], [25]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "[6], [20], [24], [25]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 23, "context": "[6], [20], [24], [25]).", "startOffset": 11, "endOffset": 15}, {"referenceID": 24, "context": "[6], [20], [24], [25]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "timbre editing of music signals [26]).", "startOffset": 32, "endOffset": 36}, {"referenceID": 4, "context": "\u201cBaseline\u201d represents a simple extension of the algorithms proposed in previous studies [5], [11], [15].", "startOffset": 88, "endOffset": 91}, {"referenceID": 10, "context": "\u201cBaseline\u201d represents a simple extension of the algorithms proposed in previous studies [5], [11], [15].", "startOffset": 93, "endOffset": 97}, {"referenceID": 14, "context": "\u201cBaseline\u201d represents a simple extension of the algorithms proposed in previous studies [5], [11], [15].", "startOffset": 99, "endOffset": 103}, {"referenceID": 26, "context": "1) Data Preparation: To evaluate the score-following accuracy for performances with errors, we conducted an experiment using the Bach10 dataset [27].", "startOffset": 144, "endOffset": 148}, {"referenceID": 12, "context": "Their probability values were obtained from the MIDI piano performances during practice in [13]: 0.", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "0047 in the simulation, where the probability of the perfect 12th pitch error was substituted by that of the octave pitch errors obtained in [13].", "startOffset": 141, "endOffset": 145}, {"referenceID": 9, "context": "It has been reported that learning them from audio performances improves the accuracy [10], [22], and thus we learned the parameters \u03bck and \u03a3k from audio signals.", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": "It has been reported that learning them from audio performances improves the accuracy [10], [22], and thus we learned the parameters \u03bck and \u03a3k from audio signals.", "startOffset": 92, "endOffset": 96}, {"referenceID": 5, "context": "The break algorithm (\u201cBreak\u201d) and the no-break algorithm (\u201cNo-Break\u201d) without the pause states are compared to Antescofo [6].", "startOffset": 121, "endOffset": 124}, {"referenceID": 5, "context": "We compared the proposed algorithms with Antescofo [6], which is one of the most known score-following systems applied to various musical pieces and used in the most severe artistic situations.", "startOffset": 51, "endOffset": 54}, {"referenceID": 27, "context": "The PPR has been used with \u2206 = 2000 ms in MIREX [30], [31].", "startOffset": 54, "endOffset": 58}, {"referenceID": 5, "context": "\u201cPROPOSED (sj = 0)\u201d (\u201cANTESCOFO\u201d) DENOTES THE break algorithm WITH sj = 0 (ANTESCOFO [6], RESPECTIVELY).", "startOffset": 85, "endOffset": 88}, {"referenceID": 12, "context": "The stop and resumption positions are not completely random, and their distributions have certain tendencies in actual performances [13].", "startOffset": 132, "endOffset": 136}, {"referenceID": 12, "context": "These tendencies can be incorporated in sj , ri in our performance HMMs, and the accuracy and following times of the proposed algorithms would improve [13].", "startOffset": 151, "endOffset": 155}, {"referenceID": 19, "context": "For this purpose, we can assign multiple bottom states to model the duration [20], [24], [25] or explicitly introduce its probability distribution [6].", "startOffset": 77, "endOffset": 81}, {"referenceID": 23, "context": "For this purpose, we can assign multiple bottom states to model the duration [20], [24], [25] or explicitly introduce its probability distribution [6].", "startOffset": 83, "endOffset": 87}, {"referenceID": 24, "context": "For this purpose, we can assign multiple bottom states to model the duration [20], [24], [25] or explicitly introduce its probability distribution [6].", "startOffset": 89, "endOffset": 93}, {"referenceID": 5, "context": "For this purpose, we can assign multiple bottom states to model the duration [20], [24], [25] or explicitly introduce its probability distribution [6].", "startOffset": 147, "endOffset": 150}], "year": 2015, "abstractText": "This paper discusses real-time alignment of audio signals of music performance to the corresponding score (a.k.a. score following) which can handle tempo changes, errors and arbitrary repeats and/or skips (repeats/skips) in performances. This type of score following is particularly useful in automatic accompaniment for practices and rehearsals, where errors and repeats/skips are often made. Simple extensions of the algorithms previously proposed in the literature are not applicable in these situations for scores of practical length due to the problem of large computational complexity. To cope with this problem, we present two hidden Markov models of monophonic performance with errors and arbitrary repeats/skips, and derive efficient score-following algorithms with an assumption that the prior probability distributions of score positions before and after repeats/skips are independent from each other. We confirmed real-time operation of the algorithms with music scores of practical length (around 10000 notes) on a modern laptop and their tracking ability to the input performance within 0.7 s on average after repeats/skips in clarinet performance data. Further improvements and extension for polyphonic signals are also discussed. Keywords\u2014Score following, audio-to-score alignment, arbitrary repeats and skips, fast Viterbi algorithm, hidden Markov model, music signal processing", "creator": "LaTeX with hyperref package"}}}