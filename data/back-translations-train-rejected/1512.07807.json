{"id": "1512.07807", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2015", "title": "Visualizations Relevant to The User By Multi-View Latent Variable Factorization", "abstract": "A main goal of data visualization is to find mappings to the 2D/3D display which are relevant to the user. Assuming user interaction data, or other auxiliary data about the items or their relationships, the goal is to identify which aspects in the primary data support the user\\'s input and, equally importantly, which aspects of the user\\'s potentially noisy input have support in the primary data. For solving the problem, we introduce a multi-view embedding in which a latent factorization identifies which aspects in the two data views (primary data and user data) are related and which are specific to only one of them. The factorization is a generative model in which the display is parameterized as a part of the factorization and the other factors explain away the aspects not expressible in a two-dimensional display. Functioning of the model is demonstrated on several data sets.", "histories": [["v1", "Thu, 24 Dec 2015 12:53:39 GMT  (711kb,D)", "https://arxiv.org/abs/1512.07807v1", "IEEE International Conference on Acoustic, Speech and Signal Processing 2016"], ["v2", "Mon, 25 Jan 2016 12:12:10 GMT  (597kb,D)", "http://arxiv.org/abs/1512.07807v2", "IEEE International Conference on Acoustic, Speech and Signal Processing 2016"]], "COMMENTS": "IEEE International Conference on Acoustic, Speech and Signal Processing 2016", "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["seppo virtanen", "homayun afrabandpey", "samuel kaski"], "accepted": false, "id": "1512.07807"}, "pdf": {"name": "1512.07807.pdf", "metadata": {"source": "CRF", "title": "VISUALIZATIONS RELEVANT TO THE USER BY MULTI-VIEW LATENT VARIABLE FACTORIZATION", "authors": ["Seppo Virtanen", "Homayun Afrabandpey", "Samuel Kaski"], "emails": [], "sections": [{"heading": null, "text": "In fact, you will be able to move to another world, you will have to move to another world, you will have to move to another world, you will be able to move to another world, you will have to move to another world, you will have to move to another world, you will have to move to another world, you will be able to create a new world, you will be able to create a new world, you will be able to create a new world, you will be able to create a new world, you will be able to create a new world, you will be able to create a new world, you will be able to create a new world, you will be able to create a new world."}, {"heading": "2.1. Data visualization and two-view learning", "text": "To learn visualization, we introduce three vector-weighted (factored) latent variables for each item, the z variables are divided by the two views, and the z (D) and z (F) are specific to their respective views. With these latent variables, we construct the latent (mean) distributions aspi, j \u00b2 exp (\u2212 | zi \u2212 zj | | 2 \u2212 | z (D) i \u2212 z (D) j | | 2), (2) qi, j \u00b2 exp (\u2212 zi \u2212 zj | | 2 \u2212 | z (F) i \u2212 z (F) j | | 2), where | \u00b7 | is the euclidean distance. The idea is that the common latent variables capture dependencies (common common common common common common variation) between the two data sets, whereas the data capture specific latent variables that capture latent variables as latent variables."}, {"heading": "2.2. Group-sparse formulation", "text": "The model can be written more compactly by concatenating the latent variables, yi = [zi, z (D) i, z (F) i] and the dataset-specific binary indicator variables b (D) k and b (F) k, for k = 1,.., K, which represent the latent variables as either active (one) or inactive (zero) in the corresponding dataset. We note that the explicit factorization of latent space in Equation 2 is useful to understand the structure of the multiview model and the role of the various latent variables. However, learning with a model that has fixed factorized latent variables leads to serious identification problems for any local learning algorithm. One approach to alleviating this problem is to adopt a common latent spatial formulation and to loosen the binary indicator variables with the latent variable W (D)."}, {"heading": "2.3. Data setup and visualization", "text": "In this thesis, D denotes the data that the user wishes to visualize. They can come directly as observations of similarity between item pairs, which form counter data di, j, or they can come as feature vectors xi, from which the similarities are calculated as d, i, j = exp (\u2212 xi \u2212 xj | 2 / 2). F denotes data provided by the user or measured by the user (more details below); they can come directly as counter data fi, j, or calculated from feature vectors fi, as for the data xi.The first option for the types of data that the user can visualize is data on pastoral similarities of the data elements. The user data can be collected in an interactive data analysis session, where fi, j is the number of times in which items i and j were considered to be similar, or derived from categories."}, {"heading": "3.1. Reuters Corpus Volume 1", "text": "We used a subset of the RCV1-v2 corpus, which was first used by [13]. The subset is a document-term matrix containing N = 9, 625 documents divided into four categories, \"C15,\" \"ECAT,\" \"GCAT\" and \"MCAT.\" For each document, feature vectors are generated by the standard TF-IDF weight scheme. For details about the RCV1 corpus, see [14]. Figure 2 shows that our method finds the relevant structure clearly by containing well-separated class-specific clusters. In this figure, categories are represented by the colors of the dots: red, green, blue and cyan represent \"C15,\" \"GCAT\" and \"MCAT.\" Some of the relevant structure is visible in the relevant latent variables (Fig. 2e), and also in the irrelevant classes."}, {"heading": "3.2. Multi-labelling", "text": "To show that different aspects of the same data set can be visualized for different users, depending on what is relevant to them, we simulate two users who are interested in different aspects and give different feedbacks (labellings). We used the abalone data from the UCI repository. This is a classification data set that aims to predict the age of the abalone from physical measurements. The number of rings within the shell is a significant factor in determining the age of an abalone. We have divided the numbers into three categories, in which the first group contains 3 to 9 rings, the second group contains 10 to 16 rings and finally the last group contains 17 to 23 rings.We ignored the ring numbers, which are less than 5 samples.This resulted in only 9 discarded data sets, which are in the total number of 4177.The first user is interested in the age and characteristics of similarity according to ring numbers. The second user is interested."}], "references": [{"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Neural computation, vol. 15, no. 6, pp. 1373\u2013 1396, 2003.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "A global geometric framework for nonlinear dimensionality reduction", "author": ["Joshua B Tenenbaum", "Vin De Silva", "John C Langford"], "venue": "Science, vol. 290, no. 5500, pp. 2319\u20132323, 2000.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Nonlinear dimensionality reduction by locally linear embedding", "author": ["Sam T Roweis", "Lawrence K Saul"], "venue": "Science, vol. 290, no. 5500, pp. 2323\u20132326, 2000.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "Stochastic neighbor embedding", "author": ["Geoffrey E Hinton", "Sam T Roweis"], "venue": "Advances in Neural Information Processing Systems, 2002, pp. 833\u2013840.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Dimensionality reduction: A comparative review", "author": ["L.J.P. van der Maaten", "E.O. Postma", "H.J. van den Herik"], "venue": "Tech. Rep. TiCC-TR 2009-005, Tilburg University, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Information retrieval perspective to nonlinear dimensionality reduction for data visualization", "author": ["Jarkko Venna", "Jaakko Peltonen", "Kristian Nybo", "Helena Aidos", "Samuel Kaski"], "venue": "The Journal of Machine Learning Research, vol. 11, pp. 451\u2013490, 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "msne: Multiview stochastic neighbor embedding", "author": ["Bo Xie", "Yang Mu", "Dacheng Tao", "Kaiqi Huang"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, vol. 41, no. 4, pp. 1088\u20131096, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiple relational embedding", "author": ["Roland Memisevic", "Geoffrey E Hinton"], "venue": "Advances in neural information processing systems, 2004, pp. 913\u2013920.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Generative modeling for maximizing precision and recall in information visualization", "author": ["Jaakko Peltonen", "Samuel Kaski"], "venue": "International Conference on Artificial Intelligence and Statistics, 2011, pp. 579\u2013587.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Information retrieval perspective to interactive data visualization", "author": ["Jaakko Peltonen", "Max Sandholm", "Samuel Kaski"], "venue": "EuroVis-Short Papers, 2013, pp. 49\u201353.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "International application of a new probability algorithm for the diagnosis of coronary artery disease", "author": ["Robert Detrano", "Andras Janosi", "Walter Steinbrunn", "Matthias Pfisterer", "Johann-Jakob Schmid", "Sarbjit Sandhu", "Kern H Guppy", "Stella Lee", "Victor Froelicher"], "venue": "The American journal of cardiology, vol. 64, no. 5, pp. 304\u2013310, 1989.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1989}, {"title": "UCI machine learning repository", "author": ["M. Lichman"], "venue": "2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Manifold adaptive experimental design for text categorization", "author": ["Deng Cai", "Xiaofei He"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 24, no. 4, pp. 707\u2013719, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Rcv1: A new benchmark collection for text categorization research", "author": ["David D Lewis", "Yiming Yang", "Tony G Rose", "Fan Li"], "venue": "The Journal of Machine Learning Research, vol. 5, pp. 361\u2013397, 2004.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Examples of these methods include Laplacian eigenmap [1], Isomap [2], locally linear embedding [3] and stochastic neighbor embedding [4].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "Examples of these methods include Laplacian eigenmap [1], Isomap [2], locally linear embedding [3] and stochastic neighbor embedding [4].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "Examples of these methods include Laplacian eigenmap [1], Isomap [2], locally linear embedding [3] and stochastic neighbor embedding [4].", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "Examples of these methods include Laplacian eigenmap [1], Isomap [2], locally linear embedding [3] and stochastic neighbor embedding [4].", "startOffset": 133, "endOffset": 136}, {"referenceID": 4, "context": "For a comparison of several methods see [5].", "startOffset": 40, "endOffset": 43}, {"referenceID": 5, "context": "It has turned out that most of the methods are not able to do that well, but by formulating the cost functions in terms of misses and false positives, a desired tradeoff between the two can be optimized for the visualization [6].", "startOffset": 225, "endOffset": 228}, {"referenceID": 6, "context": "SNE has earlier been formulated for multiple views, as multi-view stochastic neighbor embedding (mSNE) [7].", "startOffset": 103, "endOffset": 106}, {"referenceID": 7, "context": "A related model called multiple relational embedding [8] introduced view-specific mappings that can switch latent variables off from the views and hence could implement view-specific \u201cexplaining away.", "startOffset": 53, "endOffset": 56}, {"referenceID": 3, "context": "This insight underlies stochastic neighbor embedding and related further developments [4, 6, 9].", "startOffset": 86, "endOffset": 95}, {"referenceID": 5, "context": "This insight underlies stochastic neighbor embedding and related further developments [4, 6, 9].", "startOffset": 86, "endOffset": 95}, {"referenceID": 8, "context": "This insight underlies stochastic neighbor embedding and related further developments [4, 6, 9].", "startOffset": 86, "endOffset": 95}, {"referenceID": 9, "context": "We used three different data sets for comparison: scientific articles from [10], Reuters Corpus Volume 1 (RCV1), and Heart Disease data set [11] from the UCI repository [12].", "startOffset": 75, "endOffset": 79}, {"referenceID": 10, "context": "We used three different data sets for comparison: scientific articles from [10], Reuters Corpus Volume 1 (RCV1), and Heart Disease data set [11] from the UCI repository [12].", "startOffset": 140, "endOffset": 144}, {"referenceID": 11, "context": "We used three different data sets for comparison: scientific articles from [10], Reuters Corpus Volume 1 (RCV1), and Heart Disease data set [11] from the UCI repository [12].", "startOffset": 169, "endOffset": 173}, {"referenceID": 12, "context": "We used a subset of RCV1-v2 corpus, first used by [13].", "startOffset": 50, "endOffset": 54}, {"referenceID": 13, "context": "For details about the RCV1 corpus see [14].", "startOffset": 38, "endOffset": 42}], "year": 2016, "abstractText": "A main goal of data visualization is to find, from among all the available alternatives, mappings to the 2D/3D display which are relevant to the user. Assuming user interaction data, or other auxiliary data about the items or their relationships, the goal is to identify which aspects in the primary data support the user\u2019s input and, equally importantly, which aspects of the user\u2019s potentially noisy input have support in the primary data. For solving the problem, we introduce a multi-view embedding in which a latent factorization identifies which aspects in the two data views (primary data and user data) are related and which are specific to only one of them. The factorization is a generative model in which the display is parameterized as a part of the factorization and the other factors explain away the aspects not expressible in a two-dimensional display. Functioning of the model is demonstrated on several data sets.", "creator": "LaTeX with hyperref package"}}}