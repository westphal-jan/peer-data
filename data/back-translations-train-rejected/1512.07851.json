{"id": "1512.07851", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2015", "title": "Context-Based Prediction of App Usage", "abstract": "In this paper we propose a new algorithm for dynamically predicting a set of apps that the user is likely to use. A set of app icons (usually four) are presented on a special dock, called Prediction Bar, and dynamically change according to the user's habits at a given time, location, and device state (headphone connected, bluetooth active, and so on). The goal of the algorithm is, given the context information, to actively help the user navigate to the desired app as well as to provide a personalized feeling. We propose an efficient online algorithm that is executed on the device, which is based on the Passive-Aggressive online algorithmic framework, adapted to maximize the AUC at each round. We concluded the paper with a large scale empirical study on the performance of the algorithm on a real users' data.", "histories": [["v1", "Thu, 24 Dec 2015 16:27:40 GMT  (473kb,D)", "https://arxiv.org/abs/1512.07851v1", null], ["v2", "Mon, 25 Jan 2016 19:39:40 GMT  (473kb,D)", "http://arxiv.org/abs/1512.07851v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["joseph keshet", "adam kariv", "arnon dagan", "dvir volk", "joey simhon"], "accepted": false, "id": "1512.07851"}, "pdf": {"name": "1512.07851.pdf", "metadata": {"source": "CRF", "title": "Context-Based Prediction of App Usage", "authors": ["Joseph Keshet", "Adam Kariv", "Arnon Dagan", "Dvir Volk", "Joey Simhon"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that most of the people who stay in the city go into another world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they"}, {"heading": "2 Related Work", "text": "The work in [11] was one of the first. The authors proposed an app predictor based on Bayesian Networks and contextual information such as time, location and user profile. They rated their results based on the average prediction rate on the IDIAP / Nokia MDC dataset [13], which contained a small group of 38 users. Similarly, the author suggested predicting the next app based on usage history. They also rated their results on the MDC dataset. Yahoo Aviate Team used Bayesian Networks as a learning algorithm and rated it on a larger group of 480 active users, comparing their system to other standard learning algorithms [1]. They are one of the few groups that investigate the cold start problem when no user data is available."}, {"heading": "3 Problem Setting", "text": "In this section, we set the notation and formally define the problem of online prediction of app usage. Our goal is to predict the most likely apps that the user will use based on their location, activity, time, device status, and so on. Therefore, input to the system is a primitive, x-X function that represents the user's contextual information as a vector of n real numbers, where X-Rn is the domain of possible contextual information. Specific representation and description of the functions are given in Section 6.We refer to the number of apps that the user has installed as A, and their number as a vector of K = | A. The Prediction Bar bar presents a number of k apps (currently k = 4), and it is assumed that the user can click on one of the k apps in a given context (k \u2264 K) with high probability. Our goal is to find a function that prints the set of k apps that the user clicks on in a context context context context-related to the context-related apps."}, {"heading": "4 Automatic App Usage Prediction", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "5 Learning Apparatus", "text": "We saw in the previous section that the use of the 0-1 cost function, \u03b3 (a, a) = I [a / a] = maximizing, to assess performance favors the group of k most used apps over other predictions, resulting in a static prediction that does not reflect the user's current context-based use of the app. We turn to another measure of evaluation. The decision threshold for the recipient's operational characteristic (ROC) is a graphical graph of the true positive rate (a) as a function of the false positive rate (a / a). The points of the curve are reached by raising the decision threshold from the most positive trusted to the most negative. Hence, the choice of the threshold represents a trade-off between various operational settings that correspond to the cost functions that are weighted differently to false positive and false negative errors. Assuming a flat previous cost function, it is appropriate to maximize average performance over all settings."}, {"heading": "5.1 A Large Margin Algorithm for App Ranking", "text": "Building on techniques used to learn multiclass [4] and structured prediction classifiers [21, 22], our set of prediction functions distills into a classifier in this vector space, which aims to separate the relevant apps from irrelevant ones. We focus on the following linear prediction functions: f\u03b8 (x, a) = \u03b8 (x, a), (9), where the prediction functions are the model parameters, and vice versa: X \u00b7 A \u2192 Rd is a series of functions called functions or function charts. Each function receives an input function primitive xand an app a and returns a scalar that should be intuitively correlated with the application of app a in the context of x. For example, such a function could be how often the app a has been clicked within a radius of 50 meters around the location xyz."}, {"heading": "5.2 An On-line Algorithm", "text": "We now describe an online algorithm to learn the parameters while immediately maximizing the AUC context =. This is a variant of passive-aggressive algorithm (+ 1). \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "5.3 Analysis", "text": "We show that our online algorithm achieves a high cumulative AUC after T-rounds, defined as the following: A-UC = 1T-UC = 1T-UV-UV = 1 I-UV-UV-UV-UV-UV-UV = 1 I-UV-UV-UV-UV = 1 I-UV-UV-UV-UV-UV-UV-UV = 1-UV-UV-UV-UV-UV = 1-UV-UV-UV-UV-UV-UV-UV-UV-UV = 1-UV-UV-UV-UV-UV-UV-UV-UV-UV-UV-UV = 1-UV-UV-1-UV-1-UV-1-UV-1-1-UV-1-1-UV-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1"}, {"heading": "6 Feature Primitives and Feature Functions", "text": "All of our features are based on basic primitives measured from the device. Feature primitives refer to X-X-dependent functions (wa-X-Rn), which are the time and date of the device, the location of the device, and hardware-related signals (e.g. headphone connected display, current Wi-Fi network, Bluetooth devices, etc.).On top of the feature primitives, we design a series of feature functions that allow us to include the prospective app in the feature design.The idea is that each function creates a vector of the feature primitives x that describes the context information, and an app takes a as input and returns a scalar that should be based on whether the app matches the user's preferences in the context x.The function forms the context vector x together with a proposed app to a vector of fixed dimension in R.Our feature functions have two types of contextual descriptions, and before we go to the actual features:"}, {"heading": "6.1 Contextual Features", "text": "Contextual functions represent the state of the device, and they are defined as a set of functions based on the function primitives, such as day of the week, headphones connected, and know location are used and described in detail below. While the contextual function does not depend on a particular app, they are weighed separately by each app. It means that we expect a high weight if the feature day of the week is equal to Saturday for the app BestParking.We now describe the context feature vector that all apps have in common. The first set of functions is time-based and includes the following characteristics. Hour of the day: {0, 1,..,., 23} 2nd day of the week: {Mon, Tue,.., Sun} 3rd part of the day: {Dawn, Morning, noon, afternoon,...} 4th weekend: {yes, no}, where the weekend days are separated."}, {"heading": "6.2 App-dependent Features", "text": "The second representation of the functions includes non-linear functions, which are calculated separately for each app. We have three functions. Let Ta be the number of timestamps used by the app a. These are absolute time values. The first function scales the current time t relative to the previous timestamps of the app a: \u03c61, h (x, a) = 1 | Ta | \u2211 ts Ta 0.5 (1 + e \u2212 (t \u2212 ts) 2 / 2h2) for h in {1, 1.5, 3} days. This function gives current apps for which t \u2212 ts are in sequence h.The next set of functions is similar, but refers to the relative times within a day. That is, if an app is clicked every day at 9: 30, the score would be high if it is used again at about the same time."}, {"heading": "7 Experimental Results", "text": "In this section, we present the performance of our algorithm against other algorithms with different ratings. We start by comparing the accuracy and convergence of the proposed algorithm with other algorithms and with different ratings. We then verify our results with different user numbers over different time periods. We continue an experiment that checks the accuracy and convergence of the online algorithm over time. We conclude with results on the impact of the app ranking on its accuracy. The data was collected from a group of 1,000 randomly selected users who were active users of EverythingMe Launcher for 180 days. This set included 5,181,312 app click centers. On each of these datasets, we executed the three prediction algorithms - kMFU (using k = 4), Frecency (using p = 0.1, T = 60days) and AUC-PA (using C = 0.02)."}, {"heading": "7.1 App prediction performance", "text": "We start by comparing the performance of the online algorithm with the kMFU algorithm and the Frecency algorithm. We randomly selected 1000 devices and extracted their data for a period of 180 days. Specifically, we extracted the context information at times corresponding to app click events. Then, for each such event, we extract a vector of feature primitives and feature functions and forecast a set of 4 apps using kMFU, Frecency and AUC-PA. We compared the predictions of the algorithms with the app actually clicked on. The performance results are shown in Figure 2. We present 3 evaluation variables: (a) Precision - for each device, we count the times at which the predicted app is also the app clicked, and then the average across all devices; (b) per app precision - for each device and for each app, we verified the precision that we then calculated apps over all AUC and AUC devices (AUC only); and for each device, AUC only, we can calculate the AUC (AUC)."}, {"heading": "7.2 Prediction Quality Over Time", "text": "In the next experiment, we analyze the quality of the prediction over the entire period. We use the same randomly selected group of 1000 devices and calculate the (a) accuracy per app and (b) AUC in a moving window of one week. That is, each point in the following graph represents a period of one week, starting 3 days before and ending 3 days after. We look at the performance of the algorithms since they were installed on the device and after, that is, we want to understand the behavior over time and how it converges over time. This is a very important problem, especially to understand how quickly the prediction would be relevant to new users (the cold start problem).We can see that all algorithms achieve stable performance in the first few days and maintain the same performance over the entire period. AUC-PA consistently outperforms Frecency and kMFU in both the AUC and the precision of apps."}, {"heading": "7.3 Performance versus the usage-rank", "text": "This last experiment demonstrates AUC-PA's ability to predict using the long tail of less-used apps. As previously mentioned, the average user will use an average of 17.6 second-tier apps over the course of a month (i.e. those not positioned in the app dock or on the home screen), so we rank each app and device - 0 for the most-used app, 1 for the second-most-used app, and so on. Next, we evaluate the predictive accuracy of all n-ranked apps on all devices. As expected, kMFU performs very well in the 0-3 rankings and very poorly in the rest. This is a direct consequence of the fact that it always returns the k-most-used apps, k = 4 in our setting. Frequency performs slightly worse on the most-used apps and slightly better on the worst-rated apps, although by the time we reach 10th place, we score fairly poorly on the AUC, with less-used apps showing significantly better results on the PA while the PA scores are lower."}, {"heading": "8 Discussion", "text": "In this article, we have presented an algorithm for predicting the apps that the user is likely to use based on the contextual information of the device (time, location, etc.), designed to optimize user personalization and promote prediction of less-used apps in an appropriate context by aiming to maximize AUC rather than just the raw clicks. The algorithm runs efficiently on the device online and continuously updates its hypothesis to handle changes in the user's preferences over time. We have also shown in a series of experiments that the algorithm performs well when evaluated with AUC or when evaluated with normalized precision (frequently and rarely used apps are weighted equally). We have also shown that the algorithm converges on average within a few days. Most recently, we have shown that the algorithm achieves a high prediction rate when evaluated with AUC, or when it is weighted with AUC, or when it is weighted with frequently used apps."}], "references": [{"title": "Predicting the next app that you are going to use", "author": ["Ricardo Baeza-Yates", "Di Jiang", "Fabrizio Silvestri", "Beverly Harrison"], "venue": "In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "The area above the ordinal dominance graph and the area below the receiver operating characteristic graph", "author": ["Donald Bamber"], "venue": "Journal of mathematical psychology,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1975}, {"title": "Online passive-aggressive algorithms", "author": ["Koby Crammer", "Ofer Dekel", "Joseph Keshet", "Shai Shalev-Shwartz", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "On the algorithmic implementation of multiclass kernel-based vector machines", "author": ["Koby Crammer", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "Where and what: Using smartphones to predict next locations and applications in daily life", "author": ["Trinh Minh Tri Do", "Daniel Gatica-Perez"], "venue": "Pervasive and Mobile Computing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Where to go from here? mobility prediction from instantaneous information", "author": ["Vincent Etter", "Mohamed Kafsi", "Ehsan Kazemi", "Matthias Grossglauser", "Patrick Thiran"], "venue": "Pervasive and Mobile Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "An introduction to ROC analysis", "author": ["Tom Fawcett"], "venue": "Pattern recognition letters,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Accessrank: predicting what users will do next", "author": ["Stephen Fitchett", "Andy Cockburn"], "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "The meaning and use of the area under a receiver operating characteristic (ROC) curve", "author": ["James A Hanley", "Barbara J McNeil"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1982}, {"title": "Toward personalized context recognition for mobile users: A semisupervised bayesian HMM approach", "author": ["Baoxing Huai", "Enhong Chen", "Hengshu Zhu", "Hui Xiong", "Tengfei Bao", "Qi Liu", "Jilei Tian"], "venue": "ACM Trans. Knowl. Discov. Data,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Predicting mobile application usage using contextual information", "author": ["Ke Huang", "Chunhui Zhang", "Xiaoxiao Ma", "Guanling Chen"], "venue": "In Proceedings of the 2012 ACM Conference on Ubiquitous Computing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "A support vector method for multivariate performance measures", "author": ["Thorsten Joachims"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "The mobile data challenge: Big data for mobile computing research", "author": ["Juha K Laurila", "Daniel Gatica-Perez", "Imad Aad", "Olivier Bornet", "Trinh-Minh-Tri Do", "Olivier Dousse", "Julien Eberle", "Markus Miettinen"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1924}, {"title": "On the existence of a spectrum of policies that subsumes the least recently used (lru) and least frequently used (lfu) policies", "author": ["Donghee Lee", "Jongmoo Choi", "Jong-Hun Kim", "Sam H Noh", "Sang Lyul Min", "Yookun Cho", "Chong Sang Kim"], "venue": "In ACM SIGMETRICS Performance Evaluation Review,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Mining temporal profiles of mobile applications for usage prediction", "author": ["Zhung-Xun Liao", "Po-Ruey Lei", "Tsu-Jou Shen", "Shou-Chung Li", "Wen-Chih Peng"], "venue": "In Data Mining Workshops (ICDMW),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Mining GPS data for mobility patterns: A survey", "author": ["Miao Lin", "Wen-Jing Hsu"], "venue": "Pervasive and Mobile Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Which app will you use next?: collaborative filtering with interactional context", "author": ["Nagarajan Natarajan", "Donghyuk Shin", "Inderjit S Dhillon"], "venue": "In Proceedings of the 7th ACM conference on Recommender systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Practical prediction and prefetch for faster access to applications on mobile phones", "author": ["Abhinav Parate", "Matthias B\u00f6hmer", "David Chu", "Deepak Ganesan", "Benjamin M Marlin"], "venue": "In Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Learning structured models with the auc loss and its generalizations", "author": ["Nir Rosenfeld", "Ofer Meshi", "Amir Globerson", "Daniel Tarlow"], "venue": "In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro", "Andrew Cotter"], "venue": "Mathematical programming,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Max-margin markov networks", "author": ["B. Taskar", "C. Guestrin", "D. Koller"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Large margin methods for structured and interdependent output variables", "author": ["I. Tsochantaridis", "T. Joachims", "T. Hofmann", "Y. Altun"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Contextual patterns in mobile service usage", "author": ["Hannu Verkasalo"], "venue": "Personal and Ubiquitous Computing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Preference, context and communities: a multifaceted approach to predicting smartphone app usage patterns", "author": ["Ye Xu", "Mu Lin", "Hong Lu", "Giuseppe Cardone", "Nicholas Lane", "Zhenyu Chen", "Andrew Campbell", "Tanzeem Choudhury"], "venue": "In Proceedings of the 2013 International Symposium on Wearable Computers,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "AppJoy: personalized mobile application discovery", "author": ["Bo Yan", "Guanling Chen"], "venue": "In Proceedings of the 9th international conference on Mobile systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Fast app launching for mobile devices using predictive user context", "author": ["Tingxin Yan", "David Chu", "Deepak Ganesan", "Aman Kansal", "Jie Liu"], "venue": "In Proceedings of the 10th international conference on Mobile systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Prophet: What app you wish to use next", "author": ["Xun Zou", "Wangsheng Zhang", "Shijian Li", "Gang Pan"], "venue": "In Proceedings of the 2013 ACM conference on Pervasive and ubiquitous computing adjunct publication,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "On the average, there are 97 installed apps on typical smartphone according to the logs of EverythingMe, and similarly, there are 96 installed apps according to Yahoo Aviate\u2019s logs [1].", "startOffset": 181, "endOffset": 184}, {"referenceID": 2, "context": "It is based on the Passive-Aggressive online algorithmic framework [3], adapted to maximize the AUC at each round.", "startOffset": 67, "endOffset": 70}, {"referenceID": 11, "context": "While there exists algorithms to maximize the AUC, such as [12, 19], they are different from the algorithm proposed here in several aspects.", "startOffset": 59, "endOffset": 67}, {"referenceID": 18, "context": "While there exists algorithms to maximize the AUC, such as [12, 19], they are different from the algorithm proposed here in several aspects.", "startOffset": 59, "endOffset": 67}, {"referenceID": 11, "context": "Firstly, the algorithms [12, 19] are batch algorithms.", "startOffset": 24, "endOffset": 32}, {"referenceID": 18, "context": "Firstly, the algorithms [12, 19] are batch algorithms.", "startOffset": 24, "endOffset": 32}, {"referenceID": 11, "context": "Secondly, the algorithms [12, 19] are based on structural support vector machine (SSVM) [22].", "startOffset": 25, "endOffset": 33}, {"referenceID": 18, "context": "Secondly, the algorithms [12, 19] are based on structural support vector machine (SSVM) [22].", "startOffset": 25, "endOffset": 33}, {"referenceID": 21, "context": "Secondly, the algorithms [12, 19] are based on structural support vector machine (SSVM) [22].", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "The interested reader can find more ideas in [1].", "startOffset": 45, "endOffset": 48}, {"referenceID": 10, "context": "The work in [11] was one of the first.", "startOffset": 12, "endOffset": 16}, {"referenceID": 12, "context": "They evaluated their results using average prediction rate on the IDIAP/Nokia MDC dataset [13], which contains a small group of 38 users.", "startOffset": 90, "endOffset": 94}, {"referenceID": 26, "context": "Similarly, in [27] the author proposed a light-weighted Bayesian methods to predict the next app based on the app usage history.", "startOffset": 14, "endOffset": 18}, {"referenceID": 0, "context": "Yahoo Aviate team used Bayesian Networks as a learning algorithm and evaluated it on a larger set of 480 active users, and compare their system to other standard learning algorithm [1].", "startOffset": 181, "endOffset": 184}, {"referenceID": 9, "context": "In [10] the temporal user\u2019s behavior was also taken into account by using an HMM-based sequence prediction.", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "Some authors [25, 15], however, proposed to identify the usage patterns and user rating, without taking into account usage context.", "startOffset": 13, "endOffset": 21}, {"referenceID": 14, "context": "Some authors [25, 15], however, proposed to identify the usage patterns and user rating, without taking into account usage context.", "startOffset": 13, "endOffset": 21}, {"referenceID": 14, "context": "Interestingly, in [15] the authors propose to detect the periodicity patterns of usage by the Fourier transform, and then scoring them by Chebyshev\u2019s inequality.", "startOffset": 18, "endOffset": 22}, {"referenceID": 24, "context": "Both [25, 17] are based on the adaptation of a collaborative filtering algorithm as an app prediction algorithm.", "startOffset": 5, "endOffset": 13}, {"referenceID": 16, "context": "Both [25, 17] are based on the adaptation of a collaborative filtering algorithm as an app prediction algorithm.", "startOffset": 5, "endOffset": 13}, {"referenceID": 23, "context": "The work presented in [24] leverages the user-specific models by patterns of community app behaviors, guided by user similarities.", "startOffset": 22, "endOffset": 26}, {"referenceID": 22, "context": "See, for example, [23, 8, 6, 5, 16], and the many refereces therein.", "startOffset": 18, "endOffset": 35}, {"referenceID": 7, "context": "See, for example, [23, 8, 6, 5, 16], and the many refereces therein.", "startOffset": 18, "endOffset": 35}, {"referenceID": 5, "context": "See, for example, [23, 8, 6, 5, 16], and the many refereces therein.", "startOffset": 18, "endOffset": 35}, {"referenceID": 4, "context": "See, for example, [23, 8, 6, 5, 16], and the many refereces therein.", "startOffset": 18, "endOffset": 35}, {"referenceID": 15, "context": "See, for example, [23, 8, 6, 5, 16], and the many refereces therein.", "startOffset": 18, "endOffset": 35}, {"referenceID": 25, "context": "Another set of works concerns a smart caching mechanism for fast app pre-loading [26, 18].", "startOffset": 81, "endOffset": 89}, {"referenceID": 17, "context": "Another set of works concerns a smart caching mechanism for fast app pre-loading [26, 18].", "startOffset": 81, "endOffset": 89}, {"referenceID": 13, "context": "This algorithm was originally used for cache management [14], and adapted to an algorithm for predicting users\u2019 behavior [8].", "startOffset": 56, "endOffset": 60}, {"referenceID": 7, "context": "This algorithm was originally used for cache management [14], and adapted to an algorithm for predicting users\u2019 behavior [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "In our case a better evaluation metric would be the area under the receiver operating characteristic curve (AUC) [7].", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "The AUC can be defined as [2, 9] AUC = P[f\u03b8(x, a) > f\u03b8(x, a)], (5) where x \u2208 X and xa,\u2212 \u2208 Xa,\u2212.", "startOffset": 26, "endOffset": 32}, {"referenceID": 8, "context": "The AUC can be defined as [2, 9] AUC = P[f\u03b8(x, a) > f\u03b8(x, a)], (5) where x \u2208 X and xa,\u2212 \u2208 Xa,\u2212.", "startOffset": 26, "endOffset": 32}, {"referenceID": 3, "context": "1 A Large Margin Algorithm for App Ranking Building on techniques used for learning multiclass [4] and structured prediction classifiers [21, 22], our set of prediction functions distills to a classifier in this vector-space which is aimed at separating the relevant apps from irrelevant ones.", "startOffset": 95, "endOffset": 98}, {"referenceID": 20, "context": "1 A Large Margin Algorithm for App Ranking Building on techniques used for learning multiclass [4] and structured prediction classifiers [21, 22], our set of prediction functions distills to a classifier in this vector-space which is aimed at separating the relevant apps from irrelevant ones.", "startOffset": 137, "endOffset": 145}, {"referenceID": 21, "context": "1 A Large Margin Algorithm for App Ranking Building on techniques used for learning multiclass [4] and structured prediction classifiers [21, 22], our set of prediction functions distills to a classifier in this vector-space which is aimed at separating the relevant apps from irrelevant ones.", "startOffset": 137, "endOffset": 145}, {"referenceID": 21, "context": "This is a convex function in its parameters and its solution can be found using the cutting plane method [22] or by stochastic sub-gradient descent [20].", "startOffset": 105, "endOffset": 109}, {"referenceID": 19, "context": "This is a convex function in its parameters and its solution can be found using the cutting plane method [22] or by stochastic sub-gradient descent [20].", "startOffset": 148, "endOffset": 152}, {"referenceID": 2, "context": "It is a variant of the Passive-Aggressive algorithm [3] for maximizing the AUC which we call AUC-PA.", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "The solution of this optimization problem is [3]", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "The proof of the theorem relies on Lemma 1 and Theorem 4 in [3].", "startOffset": 60, "endOffset": 63}, {"referenceID": 2, "context": "Lemma 1 in [3] implies that,", "startOffset": 11, "endOffset": 14}], "year": 2016, "abstractText": "There are around a hundred installed apps on an average smartphone. The high number of apps and the limited number of app icons that can be displayed on the device\u2019s screen requires a new paradigm to address their visibility to the user. In this paper we propose a new online algorithm for dynamically predicting a set of apps that the user is likely to use. The algorithm runs on the user\u2019s device and constantly learns the user\u2019s habits at a given time, location, and device state. It is designed to actively help the user to navigate to the desired app as well as to provide a personalized feeling, and hence is aimed at maximizing the AUC. We show both theoretically and empirically that the algorithm maximizes the AUC, and yields good results on a set of 1,000 devices.", "creator": "LaTeX with hyperref package"}}}