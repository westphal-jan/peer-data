{"id": "1512.08133", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Dec-2015", "title": "The Utility of Abstaining in Binary Classification", "abstract": "We explore the problem of binary classification in machine learning, with a twist - the classifier is allowed to abstain on any datum, professing ignorance about the true class label without committing to any prediction. This is directly motivated by applications like medical diagnosis and fraud risk assessment, in which incorrect predictions have potentially calamitous consequences. We focus on a recent spate of theoretically driven work in this area that characterizes how allowing abstentions can lead to fewer errors in very general settings. Two areas are highlighted: the surprising possibility of zero-error learning, and the fundamental tradeoff between predicting sufficiently often and avoiding incorrect predictions. We review efficient algorithms with provable guarantees for each of these areas. We also discuss connections to other scenarios, notably active learning, as they suggest promising directions of further inquiry in this emerging field.", "histories": [["v1", "Sat, 26 Dec 2015 19:02:00 GMT  (630kb,D)", "http://arxiv.org/abs/1512.08133v1", "Short survey"]], "COMMENTS": "Short survey", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["akshay balsubramani"], "accepted": false, "id": "1512.08133"}, "pdf": {"name": "1512.08133.pdf", "metadata": {"source": "CRF", "title": "The Utility of Abstaining in Binary Classification", "authors": ["Akshay Balsubramani"], "emails": ["abalsubr@cs.ucsd.edu"], "sections": [{"heading": "1 Introduction", "text": "Consider a general practitioner who treats a patient with unusual or ambiguous symptoms. Often, the general practitioner does not have the ability or device to safely diagnose such a disease, but can refer the patient to a specialist or hospital. Therefore, the general practitioner is faced with a difficult decision: either he makes a potentially incorrect diagnosis and acts on it (which can sometimes have disastrous consequences), or he avoids committing to such a diagnosis and instead passes it on to the patient (which will almost certainly cost additional time and resources).Such a situation motivates the study of prediction algorithms that are not only able to form a hypothesis about the correct prediction, but also completely abandon a prediction if they are not secure enough. In machine learning, these algorithms are often formulated as classifiers, and the field of classification with abstention.In this manuscript, we examine the problem of binary classification, which the classifier may contain."}, {"heading": "1.1 Outline", "text": "We will look at the proven potential benefits of dispensing with two different scenarios: the first, discussed in Section 2, is an online learning model that is free from distributional assumptions on the data, similar to the classic error-bound model [Lit88]; the second, discussed in Section 3, is a standardized statistical learning model in which the algorithm is initially given the chance to train on a set of labeled data, and the data is extracted as an IID (independently and identically distributed) from a fixed distribution; the absence option in general and each of the above models are closely related to the well-studied paradigm of active learning, which aims to minimize the amount of data required by a learner."}, {"heading": "1.2 Preliminaries", "text": "We consider a standardized binary classification in which there are blank data points to be exaggerated. If the labels are deterministic, we can assume that they are generated by a map h: X 7 \u2192 Y, so that for all labeled data points (xi, yi) we have yi = h: xi. The goal is to determine a classifier (a hypothesis) h: X 7 \u2192 {\u2212 1, + 1} in which the classifier can predict either one of the two permissible labels or the output of what is called absence. The latter can be interpreted as \"not knowing,\" an explanation of ignorance about which label is correct without being able to commit to either at all. In this case, the risk of predicting the labeling of the given date is considered excessive."}, {"heading": "2 Abstaining in the KWIK Model", "text": "In this section, we describe a general model that has influenced recent advances in abstention literature. It will serve to provide useful insights into the possibilities of abstention, even in a very general environment."}, {"heading": "2.1 KWIK: Formulation", "text": "The KWIK model (\"Knows What It Knows\") [LLWS11] is a non-distributional method for formulating the online solvability of problems with zero overall erroneous predictions. Algorithms that achieve this must be confident enough to identify all the points where they may make a false prediction and output it, while still predicting (correctly) on a non-trivial number of examples. The name of the model refers to this self-confidence that it requires from algorithms and that distinguishes it from the otherwise similar Mistake Bound (MB) model. First, we consider the outstanding features of the popular MB model as a useful reference point for further investigation."}, {"heading": "2.1.1 The Mistake Bound Model", "text": "The Mistake Bound (MB) binary classification model [Lit88] is a general framework for the study of online binary classification algorithms (msxt), in which the learning algorithm receives unlabeled data points, which are selected individually (by an opponent in the worst case).At the beginning of turn t, the algorithm has the hypothesis ht and sees an unlabeled point xt. It then predicts a label ht (xt) = y t Y after which the true label is revealed, and the algorithm then makes all the necessary internal modifications to update its hypothesis ht + 1. The next point xt + 1 is then chosen, and the process repeats itself. In this model, the results of interest are tied to the total number of errors."}, {"heading": "2.1.2 The KWIK Model", "text": "This year, it has come to the point where it has never come to the point where it will be able to find a solution that is capable of finding a solution, that is able to find a solution, and that is able to find a solution that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, and that is able to find a solution that is able to find a solution."}, {"heading": "2.2 KWIK: Algorithmic Building Blocks", "text": "As we have seen, the KWIK definition is extremely general. Remarkably, however, there are efficient KWIK algorithms for several non-trivial problems, which are largely derived from a few generic algorithms that provide insight into the kind of reasoning that is fruitful in this non-distributive environment. We therefore present some of these representative \"building block\" algorithms with the associated evidence ideas."}, {"heading": "2.2.1 Enumeration", "text": "The most ubiquitous and central such method, the enumeration algorithm, works in the feasible case when H is finite, and is applied as an algorithm 1.Algorithm 1 Enumeration 1: V \u2190 H 2: for i = 1, 2,.. do 3: if h (xi) is equal, then 4: Select any h (xi) V and forecast h (xi) 5: otherwise 6: Output and get the label yi 7: V \u2190 {h (xi) = yi} 8: if | V | = 1 then 9: Exit with the final output VThe algorithm gets a version range V of the hypotheses that is consistent with all the data seen so far by revealing V according to more data. This is a very natural strategy for making conservative predictions."}, {"heading": "2.2.2 Other Basic KWIK Algorithms", "text": "To emphasize the usefulness of KWIK, we will briefly refer to a few other basic algorithms within this framework. \u2022 All of these algorithms are efficient - they run in polynomial time. \u2022 KWIK: The algorithm simply dispenses with the first T examples to obtain IID Bernoulli distributed labels to estimate the bias, and then predicts each example according to the empirical estimate of the bias of the bias. \u2022 KWIK: \"The distribution of an n-sided is the distribution of an n-sided die: This is the multinomic distribution of the above coin learning problems. It can be solved by reducing it to n\" one-vs.-rest \"coin learning problems, and the algorithm is the same as for the coin learning case."}, {"heading": "2.3 Allowing a Few Mistakes in KWIK", "text": "Although KWIK has proven to be very useful in recent years, the restriction that the learner must make absolutely no mistakes is in many cases a bit extreme. As we will see, admitting a few mistakes within the framework of this can drastically improve non-voting rates."}, {"heading": "2.3.1 Enumeration With a Few Mistakes", "text": "The vertex calculation method of algorithm 1 has recently been extended to allow errors for some predefined parameters k, which in turn are made in an attractively simple and generic manner [SZB10]. (Note: This newer algorithm, which we do not use in our presentation, is still consistent with the original KWIK framework of algorithm 1, because this algorithm has the zero error property.) Algorithm 2 has an instructive interpretation as a generalization of algorithm 1. Like its predecessor, it has a version space V and ends when enough data is available to make this a singleton containing h data. (When an unlabeled date xi comes, a vote is made on the hypotheses in V."}, {"heading": "2.3.2 Tractable Relaxed Enumeration for Linear Separators", "text": "The problem is that the data can be separated with Marge, Minx, x, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,"}, {"heading": "3 Abstaining in Statistical Learning", "text": "We are now slightly changing the course to examine the effect of the absence option in a standardized statistical learning setting, in which blank data points xi are drawn from a predetermined distribution. This can be considered a variation of the PAC model (probably roughly correct) that is standard in learning theory. As mentioned earlier, this setting is more restrictive than the KWIK model, imposing an additional IID assumption on the data generation process, and also dealing with the batch case in which we begin to track the algorithm's performance after seeing m-labels, rather than also penalizing the algorithm for its performance at the beginning of the learning process. Predictably, these more restrictive assumptions lead to a wider range of stronger results than is known for the KWIK case. These results are now being introduced into the standard batch learning setting."}, {"heading": "3.1 An Algorithm for Zero-Error Learning", "text": "It is a non-trivial (and current) result that this is possible even in a general environment. However, we will see how it can be done, and use the resulting algorithm as a starting point to use some powerful newer results in this vein.Recall that this zero error scenario KWIK analogy (no errors) was addressed by algorithm 1, the enumeration algorithms as a starting point to use some powerful newer results in this vein.Recall that this zero error scenario KWIK analogy (no errors) was addressed by algorithm 1, it turns out that an almost identical algorithm can be used for the realizable learning situation. This was introduced in recent work as the Consistent Selective Strategy (CSS)."}, {"heading": "3.3 Characterizing the Abstain-Error Tradeoff", "text": "The discussion here is the IID setting analogous to that in paragraph 2.3.The trade-off is illustrated in Figure 3.2, which is the trade-off of risk coverage. Coverage is simply the probability that an algorithm predicts rather than abstains from voting, and is therefore exactly the supplement to the probability of absence PrD (VP) that we have previously used. Risk is a generalization of the probability of error to arbitrary loss functions. For our purposes hereinafter, it may be taken as a synonym for error probability - and is therefore exactly the supplement to the PrD (VP) coverage. Risk is a generalization of the probability of error to arbitrary loss functions. For our purposes hereinafter, it may be taken as a synonym for error probability. The compromise for each algorithm is schematically represented by the dashed curve in the figure: low risk can only be achieved at the expense of coverage, if the algorithm is not represented by the upper algorithm."}, {"heading": "3.4 Relaxing CSS for the Non-Realizable Case", "text": "Although we do not know the basic absence of errors in this area, we have relied on it being a fairly representative definition of data distribution. (...) It is the case that we do not know the definition of errors in this area (...). (...) It is as if the definition of errors in this area (...) the definition of errors here is not necessarily calculated as in conversion space V. (...) It is possible that the IID assumption on the data means that S is fairly representative of the data distribution. (...) If we loosen the definition of V to include all low training errors (...), we can trust that we include them since the definition of V. (...) It is as if we cancel the definition of V. (...) It is as if we loosen the definition of V to include all low training errors. (...) We can trust that we cancel the definition of V. (...)"}, {"heading": "3.5 Aggregating Classifiers to Exploit the Tradeoff", "text": "We now turn to a conceptually elegant prediction that exploits the trade-off in the statistical learning environment by addressing a weighted majority (WM) of classifiers in H. We have so far investigated two algorithms that generalize the zero error strategy in various settings to address the trade-off: the relaxed CSS of Algorithm 4 and the relaxed survey strategy of Algorithm 2. Verifying these algorithms will motivate the new World Cup tuning method that we cover in this section. Algorithm 4 generalizes CSS to the unrealizable case - essential to loosen the strict training requirement in the version of CSS, rather than generalizing the hypotheses in H. Independent, Algorithm 2 to allow some errors in the return to fewer absentencies - by addressing the goal conflict - by loosening the requirement in the version for a prediction."}, {"heading": "4 Connections to Active Learning", "text": "Active Learning [Set12] is a well-motivated, supervised learning paradigm in which the learner tries to minimize the number of labels required by requesting labels at their own discretion. As mentioned in Section 2.2.1, there is a natural correlation between an output and a label request, linking absent results with active learning. We have already scattered brief references to these correlations, but will now devote this section to explaining how the work outlined in this manuscript relates to active learning. An important goal of active learning in the feasible case is to learn an error hypothesis that uses only O (polylog (1 /)) labels, which represents exponentially fewer labels than are required by default supervised learning, for which labels (1 /) are required [Das11]. This is an ambitious but sometimes achievable goal, as the canonical example of the search for a specific threshold algorithm in a FS12 has shown."}, {"heading": "4.1 Zero-Error Learning", "text": "The online error-free enumeration algorithm (Alg. 1) developed for the KWIK setting is independently known as the CAL algorithm, after the authors first introduced it in [CAL94], and is the precursor to a significant strand of theoretically motivated active learning [BBL06, BDL09, BHLZ10]. This is somewhat surprising because it is extremely conservative when it comes to minimizing the number of label requirements. In fact, one of the biggest outstanding problems in active learning is designing and analyzing algorithms that are more \"aggressive\" in their label query than the more \"gentle\" CAL [Das11]. There is little mention of this link to active learning in the existing KWIK literature. However, in Section 3 we observed that the CSS algorithm is exactly analogous to the enumeration in the IID data setting of statistical learning."}, {"heading": "4.2 Agnostic Learning", "text": "The idea of algorithm 4 - loosening the strict requirements for the consistency of version space training sets in CSS and considering all hypotheses h with a sufficiently low Q (h) instead - led to great progress in active learning when it was successfully applied to CAL in [BBL06]. The implementation trick for algorithm 4 outlined above - minimizing the empirical risk of a hypothetical data set as a means of detecting unanimity between hypotheses in a relaxed version room - has also appeared several times in abstinence-related literature and active learning [EYW10, SZB10, BHLZ10, DHM07, BBL06]. The \"excess error\" is assumed to be well-mannered in the analysis of the relaxed CSS algorithm; such assumptions about the same amount have been partially investigated in active learning as the Tsybakov noise conditions [T04], which have been derived with favorable learning algorithms."}, {"heading": "5 Future Work and Conclusion", "text": "In this context, it should be noted that this is a case in which a toy has been used in comparison with most real world applications, and in which constant efforts have been made to make the resulting algorithms more tractable. It is also an unnecessarily brittle idea, such as the construction of Figure 3.1. Another application-related open problem is to refute the insights into the work discussed here in order to determine the relative costs of the absence and errors of a prediction."}, {"heading": "Acknowledgments", "text": "I would like to thank my committee - David Kriegman, Sanjoy Dasgupta and Kamalika Chaudhuri - for their time and feedback at various stages of the audit process, as well as Yoav Freund, who first introduced me to this area and for various helpful suggestions."}], "references": [{"title": "Large-scale bandit problems and kwik learning", "author": ["Jacob Abernethy", "Kareem Amin", "Moez Draief", "Michael Kearns"], "venue": "In ICML,", "citeRegEx": "Abernethy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2013}, {"title": "Active learning using smooth relative regret approximations with applications", "author": ["Nir Ailon", "Ron Begleiter", "Esther Ezra"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "Ailon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ailon et al\\.", "year": 2012}, {"title": "The multiplicative weights update method: a metaalgorithm and applications", "author": ["Sanjeev Arora", "Elad Hazan", "Satyen Kale"], "venue": "Theory of Computing,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "A discriminative model for semi-supervised learning", "author": ["Maria-Florina Balcan", "Avrim Blum"], "venue": "J. ACM,", "citeRegEx": "Balcan and Blum.,? \\Q2010\\E", "shortCiteRegEx": "Balcan and Blum.", "year": 2010}, {"title": "Agnostic active learning without constraints", "author": ["Alina Beygelzimer", "Daniel Hsu", "John Langford", "Tong Zhang"], "venue": "In NIPS,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2010}, {"title": "Improving generalization with active learning", "author": ["David A. Cohn", "Les E. Atlas", "Richard E. Ladner"], "venue": "Machine Learning,", "citeRegEx": "Cohn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1994}, {"title": "On optimum recognition error and reject tradeoff", "author": ["C. Chow"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Chow.,? \\Q1970\\E", "shortCiteRegEx": "Chow.", "year": 1970}, {"title": "Two faces of active learning", "author": ["Sanjoy Dasgupta"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "Dasgupta.,? \\Q2011\\E", "shortCiteRegEx": "Dasgupta.", "year": 2011}, {"title": "A general agnostic active learning algorithm", "author": ["Sanjoy Dasgupta", "Daniel Hsu", "Claire Monteleoni"], "venue": null, "citeRegEx": "Dasgupta et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2007}, {"title": "Analysis of perceptron-based active learning", "author": ["Sanjoy Dasgupta", "Adam Tauman Kalai", "Claire Monteleoni"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Dasgupta et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2009}, {"title": "On the foundations of noise-free selective classification", "author": ["Ran El-Yaniv", "Yair Wiener"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "El.Yaniv and Wiener.,? \\Q2010\\E", "shortCiteRegEx": "El.Yaniv and Wiener.", "year": 2010}, {"title": "Active learning via perfect selective classification", "author": ["Ran El-Yaniv", "Yair Wiener"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "El.Yaniv and Wiener.,? \\Q2012\\E", "shortCiteRegEx": "El.Yaniv and Wiener.", "year": 2012}, {"title": "Generalization bounds for averaged classifiers", "author": ["Yoav Freund", "Yishay Mansour", "Robert Schapire"], "venue": "The Annals of Statistics,", "citeRegEx": "Freund et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Freund et al\\.", "year": 2004}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Yoav Freund", "Robert E. Schapire"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Freund and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1997}, {"title": "Selective sampling using the query by committee algorithm", "author": ["Yoav Freund", "H. Sebastian Seung", "Eli Shamir", "Naftali Tishby"], "venue": "Machine Learning,", "citeRegEx": "Freund et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1997}, {"title": "Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy", "author": ["Ludmila I. Kuncheva", "Christopher J. Whitaker"], "venue": "Machine Learning,", "citeRegEx": "Kuncheva and Whitaker.,? \\Q2003\\E", "shortCiteRegEx": "Kuncheva and Whitaker.", "year": 2003}, {"title": "The perceptron algorithm versus winnow: Linear versus logarithmic mistake bounds when few input variables are relevant (technical note)", "author": ["Jyrki Kivinen", "Manfred K. Warmuth", "Peter Auer"], "venue": "Artif. Intell.,", "citeRegEx": "Kivinen et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Kivinen et al\\.", "year": 1997}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["Nick Littlestone"], "venue": "In Machine Learning,", "citeRegEx": "Littlestone.,? \\Q1988\\E", "shortCiteRegEx": "Littlestone.", "year": 1988}, {"title": "Knows what it knows: a framework for self-aware learning", "author": ["Lihong Li", "Michael L. Littman", "Thomas J. Walsh", "Alexander L. Strehl"], "venue": "Machine Learning,", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Hit-and-run from a corner", "author": ["L\u00e1szl\u00f3 Lov\u00e1sz", "Santosh Vempala"], "venue": "SIAM J. Comput.,", "citeRegEx": "Lov\u00e1sz and Vempala.,? \\Q2006\\E", "shortCiteRegEx": "Lov\u00e1sz and Vempala.", "year": 2006}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K. Warmuth"], "venue": "In FOCS,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1989\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1989}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K. Warmuth"], "venue": "Inf. Comput.,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "Active Learning. Synthesis Lectures on Artificial Intelligence and Machine Learning", "author": ["Burr Settles"], "venue": null, "citeRegEx": "Settles.,? \\Q2012\\E", "shortCiteRegEx": "Settles.", "year": 2012}, {"title": "Agnostic kwik learning and efficient approximate reinforcement learning", "author": ["Istv\u00e1n Szita", "Csaba Szepesv\u00e1ri"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "Szita and Szepesv\u00e1ri.,? \\Q2011\\E", "shortCiteRegEx": "Szita and Szepesv\u00e1ri.", "year": 2011}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Shalev.Shwartz.,? \\Q2012\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2012}, {"title": "Trading off mistakes and don\u2019t-know predictions", "author": ["Amin Sayedi", "Morteza Zadimoghaddam", "Avrim Blum"], "venue": null, "citeRegEx": "Sayedi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sayedi et al\\.", "year": 2010}, {"title": "Optimal aggregation of classiers in statistical learning", "author": ["Alexandre Tsybakov"], "venue": "The Annals of Statistics,", "citeRegEx": "Tsybakov.,? \\Q2004\\E", "shortCiteRegEx": "Tsybakov.", "year": 2004}, {"title": "Agnostic selective classification", "author": ["Yair Wiener", "Ran El-Yaniv"], "venue": null, "citeRegEx": "Wiener and El.Yaniv.,? \\Q2011\\E", "shortCiteRegEx": "Wiener and El.Yaniv.", "year": 2011}, {"title": "Exploring compact reinforcement-learning representations with linear regression", "author": ["Thomas J. Walsh", "Istvan Szita", "Carlos Diuk", "Michael L. Littman"], "venue": null, "citeRegEx": "Walsh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Walsh et al\\.", "year": 2009}], "referenceMentions": [], "year": 2015, "abstractText": "We explore the problem of binary classification in machine learning, with a twist the classifier is allowed to abstain on any datum, professing ignorance about the true class label without committing to any prediction. This is directly motivated by applications like medical diagnosis and fraud risk assessment, in which incorrect predictions have potentially calamitous consequences. We focus on a recent spate of theoretically driven work in this area that characterizes how allowing abstentions can lead to fewer errors in very general settings. Two areas are highlighted: the surprising possibility of zero-error learning, and the fundamental tradeoff between predicting sufficiently often and avoiding incorrect predictions. We review efficient algorithms with provable guarantees for each of these areas. We also discuss connections to other scenarios, notably active learning, as they suggest promising directions of further inquiry in this emerging field.", "creator": "LaTeX with hyperref package"}}}