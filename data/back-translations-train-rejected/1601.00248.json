{"id": "1601.00248", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jan-2016", "title": "Contrastive Entropy: A new evaluation metric for unnormalized language models", "abstract": "Perplexity(per word) is the most widely used metric for evaluating language models. This is mostly due to a its ease of computation, lack of dependence on external tools like speech recognition pipeline and a good theoretical justification for why it should work. Despite this, there has been no dearth of criticism for this metric. Most of this criticism center around lack of correlation with extrinsic metrics like word error rate(WER), dependence upon shared vocabulary for model comparison and unsuitability for un-normalized language model evaluation. In this paper we address the last problem of inability to evaluate un-normalized models by introducing a new discriminative evaluation metric that predicts model's performance based on its ability to discriminate between test sentences and their deformed version. Due to its discriminative formulation, this approach can work with un-normalized probabilities while retaining perplexity's ease of computation. We show a strong correlation between our new metric and perplexity across a range of models on WSJ datasets. We also hypothesize a stronger correlation between WER and our new metric vis-a-vis perplexity due to similar discriminative objective.", "histories": [["v1", "Sun, 3 Jan 2016 05:47:42 GMT  (207kb,D)", "https://arxiv.org/abs/1601.00248v1", null], ["v2", "Thu, 31 Mar 2016 13:53:47 GMT  (84kb,D)", "http://arxiv.org/abs/1601.00248v2", "submitted to INTERSPEECH 2016"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kushal arora", "anand rangarajan"], "accepted": false, "id": "1601.00248"}, "pdf": {"name": "1601.00248.pdf", "metadata": {"source": "CRF", "title": "Contrastive Entropy: A new evaluation metric for unnormalized language models", "authors": ["Kushal Arora", "Anand Rangarajan"], "emails": ["anand}@cise.ufl.edu"], "sections": [{"heading": "1. Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2. Sentence level cross entropy rate", "text": "The perplexity defined in Equation (2) can also be regarded as an exposed cross-entropy rate, H (p, m), with cross-entropy approximated asH (p, m; T) = \u2212 1 n log (m (T)). (3) ar Xiv: 160 1.00 248v 2 [cs.C L] 31 Mar 201 6This approximation can be derived as a continuous, infinite stream of words leading to the following expression for cross-entropy rate: H (p, m) = lim l \u2192 \u2212 1 l [cs.C L] 31 Mar 201 6This approximation can be logged as a protocol (m (w l 1) leading to the following expression for cross-entropy rate. (4) where W l1 is a set of all the sentences of length l Well, provided that the language is to be ergodic and stationary, the Shannon-McMillan-Breiman theorem [9] states that (4) is a single sequence long enough."}, {"heading": "3. Contrastive Entropy and Contrastive Entropy Ratio", "text": "In fact, it is not that we are able to hide if we are not able to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position where we are."}, {"heading": "4. Sentence-level RNNLM", "text": "We have the ability to use this type of language to maximize the boundaries between a valid proposition and its distorted spread. (t) We can use the following equations (t \u2212 1) T s (t \u2212 1) T s (t \u2212 1) T s (t) s (t) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s (n) s \"s (n) s (s) s\" s (n) s (s) s (n) s (s) s (s) s (n) s (s) s (s) s (s) s (n) s (s) s (s) s (s) s (s) s (n (s) s (s) s (s) s (s (s) s (s) s (s (s) s (n (s) s (s) s (s (s) n (s) s (s) n (s (s) s (s) n (s) s (s) s (s) s (s (s) n (s) s (s) n (s) n (s) s (s) s (s) s (s) n (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s (s) s) s (s (s) s (s) s (s) s (s) s) s (s) s (s (s (s) s (s) s) s (s (s) s (s) n (s) s (s (s) s (s) n (s) n (s (s) n (s (s) n (s) n (s) n (s) n (s) n (s) n (s (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s"}, {"heading": "6. Conclusion", "text": "In this paper, we proposed new evaluation criteria that can be used to evaluate non-normalized language models, and demonstrated their effectiveness in comparing sentence-level models with each other and word-level models using examples. Since both WHO and contrastive entropy are discriminatory metrics, we believe that contrastive entropy should have a better correlation with WHO compared to helplessness. We also proposed a discriminatively trained sentence-level formulation of recurrent neural networks that exceeded the current state of RNN models on our new metric. We suspect that this formulation of RNN will do a better job in discriminatory tasks such as grid reassessment compared to standard RNN and other traditional language modeling techniques. We conclude that a metric is only useful if it can measure improvements in real-world applications. Further experiments that are required to evaluate the correlation of contradictory entropy data sets with metrics on the MS-BLACK scale and the actual data sets on the N."}, {"heading": "7. References", "text": "[1] R. Iyer, M. Ostendorf, and M. Meteer, \"Analyzing andpredicting language model improvements,\" in Automatic Speech Recognition and Understanding, 1997. Proceedings., 1997 IEEE Workshop on. IEEE, 1997, pp. 254- 261. [2] S. F. Chen, D. Beeferman, and R. Rosenfeld, \"Evaluation metrics for language models,\" 1998. [3] P. Clarkson, T. Robinson et al., \"Towards improved language model evaluation measures,\" in EUROSPEECH, 1999. [4] N. A. Smith, and J. Eisner, \"Contrastive estimation: Training log-linear models on unlabeled data,\" in Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics, 2005, pp."}], "references": [{"title": "Analyzing and predicting language model improvements", "author": ["R. Iyer", "M. Ostendorf", "M. Meteer"], "venue": "Automatic Speech Recognition and Understanding, 1997. Proceedings., 1997 IEEE Workshop on. IEEE, 1997, pp. 254\u2013 261.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Evaluation metrics for language models", "author": ["S.F. Chen", "D. Beeferman", "R. Rosenfeld"], "venue": "1998.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Towards improved language model evaluation measures.", "author": ["P. Clarkson", "T. Robinson"], "venue": "EUROSPEECH,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Contrastive estimation: Training log-linear models on unlabeled data", "author": ["N.A. Smith", "J. Eisner"], "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics, 2005, pp. 354\u2013362.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Unnormalized exponential and neural network lan-  guage models", "author": ["A. Sethy", "S. Chen", "E. Arisoy", "B. Ramabhadran"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 2015, pp. 5416\u20135420.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Whole-sentence exponential language models: a vehicle for linguisticstatistical integration", "author": ["R. Rosenfeld", "S.F. Chen", "X. Zhu"], "venue": "Computer Speech & Language, vol. 15, no. 1, pp. 55\u201373, 2001.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "A discriminative language model with pseudo-negative samples.", "author": ["D. Okanohara", "J. Tsujii"], "venue": "ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "Proceedings of the 25th international conference on Machine learning. ACM, 2008, pp. 160\u2013167.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "A sandwich proof of the Shannon-McMillan-Breiman theorem", "author": ["P.H. Algoet", "T.M. Cover"], "venue": "The annals of probability, pp. 899\u2013909, 1988.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1988}, {"title": "Recurrent neural network based language model.", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": "INTERSPEECH,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Y. Bengio"], "venue": "Proceedings of the Python for Scientific Computing Conference (SciPy), Jun. 2010, oral Presentation.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Srilm-an extensible language modeling toolkit.", "author": ["A. Stolcke"], "venue": "in INTERSPEECH,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "RNNLM-recurrent neural network language modeling toolkit", "author": ["T. Mikolov", "S. Kombrink", "A. Deoras", "L. Burget", "J. Cernocky"], "venue": "Proc. of the 2011 ASRU Workshop, 2011, pp. 196\u2013201.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "This makes PPL a good substitute for WER when evaluating n-grams models, but for more complex language models the correlation is not so strong [1].", "startOffset": 143, "endOffset": 146}, {"referenceID": 0, "context": "[1] proposed a decision tree based metric that uses additional features like word length, POS tags and phonetic length of words to improve the WER correlation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] proposed a new metric M-ref which attempts to learn the likelihood curve between WER and perplexity.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] attempted to use entropy in conjunction with perplexity\u2014 empirically learning the mixing coefficients.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Our approach is inspired by Contrastive Estimation [4] and stems from the philosophical starting point that a superior language model should be able to distinguish better between the sentence from the test set and its deformed version.", "startOffset": 51, "endOffset": 54}, {"referenceID": 4, "context": "While we use an unnormalized sentence level model as an example in this paper this technique should work for all models where partition function is intractable, for example unnormalized Model M and feed forward neural network language model (NNLM) from [5] or sentence level models like [6], [7] and [8].", "startOffset": 253, "endOffset": 256}, {"referenceID": 5, "context": "While we use an unnormalized sentence level model as an example in this paper this technique should work for all models where partition function is intractable, for example unnormalized Model M and feed forward neural network language model (NNLM) from [5] or sentence level models like [6], [7] and [8].", "startOffset": 287, "endOffset": 290}, {"referenceID": 6, "context": "While we use an unnormalized sentence level model as an example in this paper this technique should work for all models where partition function is intractable, for example unnormalized Model M and feed forward neural network language model (NNLM) from [5] or sentence level models like [6], [7] and [8].", "startOffset": 292, "endOffset": 295}, {"referenceID": 7, "context": "While we use an unnormalized sentence level model as an example in this paper this technique should work for all models where partition function is intractable, for example unnormalized Model M and feed forward neural network language model (NNLM) from [5] or sentence level models like [6], [7] and [8].", "startOffset": 300, "endOffset": 303}, {"referenceID": 8, "context": "where W l 1 is a set of all the sentences of length l Now, assuming the language to be ergodic and stationary, the Shannon-McMillan-Breiman Theorem [9] states that (4) can be approximated as a single sequence that is long enough, hence", "startOffset": 148, "endOffset": 151}, {"referenceID": 9, "context": "This new model is simply an unfolded Recurrent Neural Network Language Model [10] build at sentence level and trained to maximize the margin between a valid sentence and its distorted version.", "startOffset": 77, "endOffset": 81}, {"referenceID": 7, "context": "[8] and Okanohara et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] for language modeling and by Smith and Eisner [4] for POS tagging.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[7] for language modeling and by Smith and Eisner [4] for POS tagging.", "startOffset": 50, "endOffset": 53}, {"referenceID": 10, "context": "This simplistic sentence level recurrent neural network model is implemented in python using Theano [11] and is available at https://github.", "startOffset": 100, "endOffset": 104}, {"referenceID": 11, "context": "The results were generated using the open source language modeling SRILM toolkit [12] for n-gram models and the RNNLM toolkit [13] for the RNN language model.", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "The results were generated using the open source language modeling SRILM toolkit [12] for n-gram models and the RNNLM toolkit [13] for the RNN language model.", "startOffset": 126, "endOffset": 130}], "year": 2016, "abstractText": "Perplexity (per word) is the most widely used metric for evaluating language models. Despite this, there has been no dearth of criticism for this metric. Most of these criticisms center around lack of correlation with extrinsic metrics like word error rate (WER), dependence upon shared vocabulary for model comparison and unsuitability for unnormalized language model evaluation. In this paper, we address the last problem and propose a new discriminative entropy based intrinsic metric that works for both traditional word level models and unnormalized language models like sentence level models. We also propose a discriminatively trained sentence level interpretation of recurrent neural network based language model (RNN) as an example of unnormalized sentence level model. We demonstrate that for word level models, contrastive entropy shows a strong correlation with perplexity. We also observe that when trained at lower distortion levels, sentence level RNN considerably outperforms traditional RNNs on this new metric.", "creator": "LaTeX with hyperref package"}}}