{"id": "1601.00901", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jan-2016", "title": "Joint learning of ontology and semantic parser from text", "abstract": "Semantic parsing methods are used for capturing and representing semantic meaning of text. Meaning representation capturing all the concepts in the text may not always be available or may not be sufficiently complete. Ontologies provide a structured and reasoning-capable way to model the content of a collection of texts. In this work, we present a novel approach to joint learning of ontology and semantic parser from text. The method is based on semi-automatic induction of a context-free grammar from semantically annotated text. The grammar parses the text into semantic trees. Both, the grammar and the semantic trees are used to learn the ontology on several levels -- classes, instances, taxonomic and non-taxonomic relations. The approach was evaluated on the first sentences of Wikipedia pages describing people.", "histories": [["v1", "Tue, 5 Jan 2016 16:56:28 GMT  (676kb,D)", "http://arxiv.org/abs/1601.00901v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["janez starc", "dunja mladeni\\'c"], "accepted": false, "id": "1601.00901"}, "pdf": {"name": "1601.00901.pdf", "metadata": {"source": "CRF", "title": "Joint learning of ontology and semantic parser from text", "authors": ["Janez STARC", "Dunja MLADENI\u0106"], "emails": ["janez.starc@ijs.si"], "sections": [{"heading": null, "text": "Keywords: ontological learning, semantic parsing, grammar induction, context-free grammar"}, {"heading": "1. Introduction", "text": "This year it is more than ever before in the history of the city, where it is so far that it is a place, where it is a place, where it is a place."}, {"heading": "2. Grammar induction", "text": "In this section, we propose a semi-automatic bootstrapping procedure for grammar induction that searches for the most common patterns and constructs new production rules from them. One of the biggest challenges is to design the induction in a way that minimizes human engagement and maximizes the quality of semantic trees. Input into the process illustrated in Figure 2 is a set of predefined seed grammar rules (see Section 2.5) and a series of sentences in a layered representation (see Section 2.1) from the dataset. The output of the process is a larger set of rules that form the induced grammar. A rule is added to the grammar on each iteration. At the beginning of each iteration, the sentences are parsed with a top-down parser. The output of a single sentence is a semantic sentence that forms a semantic tree."}, {"heading": "2.1. Textual data representation", "text": "The input text data must be properly structured to work best with the proposed algorithms. Superficial NLP tools such as sentence splitting, word tokenization, so-called entity recognition, could help to maintain this structure; the basic unit is a sentence represented by multiple layers, an example is in Table 1. Each layer consists of multiple tokens extending over one or more words; the base layer is the lexical layer in which each token represents a single word; all other layers are generated from the annotations; some annotations, such as named entities, may extend over multiple words; some of the words may have no annotation, so they get a zero token; it is critical that all algorithms know how to handle a particular layer. For example, the parser must not break a multi-word annotation apart; some layers that end with the seasonology may be derived."}, {"heading": "2.2. Grammar Definition", "text": "Our context-free grammar G is defined by a factor of 5: G = (V, \u03c3, P, S, R), where \u2022 V is a set of non-terminals. Each non-terminal represents a semantic class, for example < Person >, < Color >, < Organization >. There is also a universal non-terminal < \u043c > that can be replaced by any other non-terminal. The same non-terminal replaces all occurrences in a rule. It is used to represent multiple rules with one notation. The grammar is still context-free. See seeding rule examples in Section 2.5. \u2022 \u03c3 is a set of terminals. Terminal is an existing non-zero symbol from each sentence layer. We refer to a terminal with value {layer}. For example, [Place] {named entity}, Phil Madeira {instance}. If the terminal comes from the lexical layer, the production layer < if the < represents a layer."}, {"heading": "2.3. Parser", "text": "The parsing function requires the development of a recursive descendant parser with traceability, which is a top-down pattern that first looks at the higher sentence structure and then goes down the parse tree to identify the details of the sentence (see Figure 3). The recursive structure of the program closely follows the structure of the parse tree. The recursive function Parse (see Algorithm 1) takes a term as input and returns a non-terminal parse tree as output. The parse node contains the class of the node (non-terminal), the rule parsing the node, and the list of child nodes."}, {"heading": "2.4. Rule induction", "text": "Vrlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "2.5. Seed rules", "text": "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "3. Ontology induction", "text": "This section describes how to use grammar and manipulate semantic trees to discover ontological components in the text data."}, {"heading": "3.1. Ontology induction from grammar", "text": "We propose a method for mapping grammar components to ontological components. In particular, classes, instances and taxonomic relationships are extracted. First, we distinguish between instances and classes in grammar. Classes are represented by all non-terminals and terminals that come from a class-populated layer, for example, from Table 1. Instances may already exist in the instance layer, or they are created from rules whose right side contains only tokens from the lexical layer. These tokens represent the label of the new instance. For example, rule < profession >: = software engineer is a candidate for example extraction. In addition, we distinguish between class and instance rules. Class rules have a single symbol representing a class on the right. Class rules represent a subclass relationship."}, {"heading": "3.2. Relation extraction from semantic trees", "text": "We propose a method to learn relationships from semantic trees, which attempts to solve the same problem as the classical methods of relation extraction. In view of a dataset of positive relation examples, which represent a relation type, e.g. birthPlace, the goal is to discover new invisible relationships. The method is based on the assumption that a relationship between entities in the shortest path between them is expressed in the semantic tree [14]. The relationship may have one, two or even more entities. Each entity is assigned to the layer, which corresponds to the entity type, corresponding particle trees and relation examples. In view of a relationship from the training set, we first try to identify the theorem, which contains each entity of the relationship. The relationship may have one, two or even more entities. Each entity is assigned to the layer entity type, assigned to the entity entity type, assigned to an entity. For example, strings of the lexical layer assigned to an entity, an entity to be assigned to an entity, that includes an entity, an entity assigned to an entity, an entity."}, {"heading": "4. Experiments", "text": "In this section, we present experiments to evaluate the proposed approach. We have conducted experiments with the Wikipedia DBpedia dataset (Section 4.1). First, we have induced a grammar to the Wikipedia dataset (Section 4.2) to show its properties and the scalability of the approach. In the next experiment, we present a method for discovering less prominent cases (Section 4.3). The last experiment demonstrates an application of semantic parsing - supervised learning of DBpedia relationships (Section 4.4)."}, {"heading": "4.1. Datasets", "text": "The data sets for experiments were developed from the English Wikipedia and knowledge bases DBpedia [10] and Freebase [7]. DBpedia provides structured information about Wikipedia articles scratched from their info boxes. Initial sentences of Wikipedia pages describing people were taken as textual data sets, while DBpedia relationships expressing facts about the same people were taken as data sets for supervised relationship learning. Note that each DBpedia instance has a Wikipedia page. A number of person instances were identified by querying DBpedia for instances that have a person class. For the textual data collections, Wikipedia pages representing these entities, the in-house Wikipedia markup parserts3 was evaluated to turn the markup into plain text. In addition, the links to other Wikipedia pages that have a person class were identified by queries. \"Here is an example of a June 24, 1964 Nobel laureate physicist, Francis Ford, who was born in Vienna, Austria."}, {"heading": "4.2. Grammar Induction Experiments", "text": "This year, the time has come for most of them not to be able to regenerate until they are able to regenerate."}, {"heading": "4.3. Instance extraction", "text": "In this section, we present an experiment with a method for discovering new instances that appear in the long tail of the null nodes. Note that the majority of instances have already been included in ontology by the method in Section 3.1. Less prominent instances are extracted to increase the coverage of the semantic parse.The term and the class of the zero node form an isa relationship. The class of the node represents the class of the relationship. Terms are converted into instances, which are initially generalized at the level of the level of the level (see Section 2.1).The aim is to exclude non-atomic terms that do not constitute instances. Therefore, only terms that consist of a wiki link token or exclusively of lexical tokens are retained, and the relationships are sorted by their frequency. We note that the accuracy of the relationships with frequency decreases. Therefore, relationships that occurred less than three times were excluded."}, {"heading": "4.4. Relation extraction", "text": "In this section, we present an experiment of relation extraction methods presented in Section 3.2. Input for monitoring is the DBpedia relation dataset from Section 4.1. The subject (the first argument) of each relationship is a person DBpedia instance-person Wikipedia page. At the beginning, the first sentence of this Wikipedia page is identified in the textual dataset. If the object (the last argument) of this relationship corresponds to a sub-term of this sentence, then the relationship is suitable for experimentation. We distinguish three types of values in objects. DBpedia resources are compared with the wiki link layer. Dates get the format used in English Wikipedia. They are compared against the lexical layer, and so are the relationship between the relations that have 200 or more legitimate relationships. This is 74 out of 119 relationships. The macro average number of suitable relationships per relationship is 17.7%."}, {"heading": "5. Related Work", "text": "There are many well-known approaches to ontological learning and semantic parsing, but to the best of our knowledge this is the first paper to jointly learn an ontology and a semantic parser. In the following sections we make comparisons to other work on semantic parsing, ontological learning, grammar induction and others."}, {"heading": "5.1. Semantic parsing", "text": "The goal of semantic analysis is to assign the text to the meaning of representations. Several approaches have used combinatorial categorical grammar (CCG) and lambda calculation as meaning representations. CCG grammar closely links syntax and semantics with a lexicon in which each entry consists of a single rule. Likewise, our context-free grammar contains production rules. Some of these rules do not contain lexical tokens (grammar is not lexicalized), the ability to express relationships with a single rule."}, {"heading": "5.2. Ontology Learning", "text": "Many ontological learning approaches address the same ontological components as our approach. However, their goal is to learn only the most important concepts for a particular area, while our goal is to learn all concepts (including instances, such as certain organizations) so that they can be used in the representation of meaning. [23] summarizes that the learning mechanisms are based on either statistics, linguistics, or logic. Our approach is unique because part of our ontology is constructed from grammar. Many approaches use lexicosyntactic patterns for ontological learning. These are often based on dependency parses, as in [3,24]. Our approach is not based on linguistic pre-processing, making it suitable for non-standardized texts and poorly equipped languages. Our approach also builds patterns, but in the form of grammar rules. Instead of lexicosyntactic patterns containing linguistic combination models, our approach explores semantic patterns, which will sometimes contain a structure similar to those of semantic classes."}, {"heading": "5.3. Grammar induction", "text": "Our goal was to develop a semi-automatic method that would create a grammar suitable for our scenario, in which an ontology is extracted and text is parsed into semantic trees. [28] In a study of [28] several papers on grammar induction are compared. According to their classification, our method falls into unattended text-based (not negative examples of sentences) methods. Many of these methods induce context-free grammars, but their emphasis is more on learning syntactical structures than on semantics. This is evident in valuation strategies where their parsa trees are compared with golden parsa trees in treetops, such as the Penn tree bank [29], which are commented according to syntactical guidelines. Furthermore, our grammar should not be limited to a specific form, such as Chomsky normal form or Greibach normal form, but may contain arbitrary context-free rules. Several algorithms, such as our, use the 2nd Grammatics Strategy to update the Grammatics after each Grammatics 3 grammar where the grammar Induction is updated."}, {"heading": "5.4. Other Approaches", "text": "Another semi-automatic approach has been developed for the knowledge base population [36]. The task of the knowledge base population is only concerned with the extraction of instances and relationships in the face of ontology. In our work we also extract the backbone of ontology - classes and taxonomic relationships. Also, many other approaches focus on only one aspect of knowledge extraction, such as taxonomy extraction [37,38] or relation extraction [14,39]. Combining these approaches can lead to cumbersome concept match problems. [40] This problem has also been observed by OntoUSP, whose system attempts to overcome this by unattended creation and population of probable grammar to solve problems. However, the results are logical hierarchies that are not related to an existing grouping."}, {"heading": "6. Discussion", "text": "The approach was evaluated by building an ontology that represents biographies of people.The first sentences of the people Wikipedia pages and the combination of DBpedia and Freebase were used as a dataset.This dataset was suitable for our approach because the text is endowed with human-marked annotations that are already associated with ontology. In other cases, a designated unit of disambiguation would be required to obtain the annotation.The next trait of the dataset that is suitable for our approach is the homogeneous writing style.Otherwise, if the style were more heterogeneous, users would have to participate in more iterations to achieve the same level of coverage.Users \"participation can be considered a cost, but on the other hand, it allows them to learn about the dataset without reading it completely. Users do not learn as much about specific facts as they can learn about the second order as the types of these relationships can be represented."}, {"heading": "Acknowledgements", "text": "This work was supported by the Slovenian Research Agency and the European Commission's ICT Programme under XLike (FP7-ICT-288342-STREP) and XLime (FP7-ICT-611346)."}], "references": [{"title": "Machine reading", "author": ["Oren Etzioni", "Michele Banko", "Michael J Cafarella"], "venue": "In AAAI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Text2onto. In Natural language processing and information systems, pages 227\u2013238", "author": ["Philipp Cimiano", "Johanna V\u00f6lker"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Evaluating the Generation of Domain Ontologies in the Knowledge Puzzle Project", "author": ["Amal Zouaq", "Roger Nkambou"], "venue": "IEEE Trans. on Knowl. and Data Eng.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Populating the Semantic Web by Macro-reading Internet Text", "author": ["Tom M. Mitchell", "Justin Betteridge", "Andrew Carlson", "Estevam Hruschka", "Richard Wang"], "venue": "In Proceedings of the 8th International Semantic Web Conference,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Large-scale Semantic Parsing via Schema Matching and Lexicon Extension", "author": ["Qingqing Cai", "Alexander Yates"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Expanding the Scope of the ATIS Task: The ATIS-3 Corpus", "author": ["Deborah A. Dahl", "Madeleine Bates", "Michael Brown", "William Fisher", "Kate Hunicke-Smith", "David Pallett", "Christine Pao", "Alexander Rudnicky", "Elizabeth Shriberg"], "venue": "In Proceedings of the Workshop on Human Language Technology,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1994}, {"title": "Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Curriculum learning", "author": ["Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 26th annual international conference on machine learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Parsing Beyond Context-Free Grammars", "author": ["Laura Kallmeyer"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "DBpedia - a large-scale, multilingual knowledge base extracted from wikipedia", "author": ["Jens Lehmann", "Robert Isele", "Max Jakob", "Anja Jentzsch", "Dimitris Kontokostas", "Pablo N. Mendes", "Sebastian Hellmann", "Mohamed Morsey", "Patrick van Kleef", "S\u00f6ren Auer", "Christian Bizer"], "venue": "Semantic Web Journal,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Techniques for automatic memoization with applications to context-free parsing", "author": ["Peter Norvig"], "venue": "Comput. Linguist.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "A new top-down parsing algorithm to accommodate ambiguity and left recursion in polynomial time", "author": ["Richard A. Frost", "Rahmatullah Hafiz"], "venue": "SIGPLAN Not.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Efficient string matching: An aid to bibliographic search", "author": ["Alfred V. Aho", "Margaret J. Corasick"], "venue": "Commun. ACM,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1975}, {"title": "A shortest path dependency kernel for relation extraction", "author": ["Razvan C. Bunescu", "Raymond J. Mooney"], "venue": "In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Lexical generalization in CCG grammar induction for semantic parsing", "author": ["Tom Kwiatkowski", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Learning a compositional semantics for Freebase with an open predicate vocabulary", "author": ["Jayant Krishnamurthy", "Tom M Mitchell"], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Learning dependency-based compositional semantics", "author": ["Percy Liang", "Michael I Jordan", "Dan Klein"], "venue": "Computational Linguistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Large-scale semantic parsing without question-answer pairs", "author": ["Siva Reddy", "Mirella Lapata", "Mark Steedman"], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["John M Zelle", "Raymond J Mooney"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1996}, {"title": "Semantic Parsing on Freebase from Question-Answer Pairs", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang"], "venue": "In EMNLP,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Scalable semantic parsing with partial ontologies", "author": ["Eunsol Choi", "Tom Kwiatkowski", "Luke Zettlemoyer"], "venue": "In Proceedings of the 2015 Association for Computational Linguistics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Ontology learning from text: A look back and into the future", "author": ["Wilson Wong", "Wei Liu", "Mohammed Bennamoun"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Acquisition of OWL DL axioms from lexical resources", "author": ["Johanna V\u00f6lker", "Pascal Hitzler", "Philipp Cimiano"], "venue": "In The Semantic Web: Research and Applications,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Semi-automatic ontology extension using spreading activation", "author": ["Wei Liu", "Albert Weichselbraun", "Arno Scharl", "Elizabeth Chang"], "venue": "Journal of Universal Knowledge Management,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "User-centred ontology learning for knowledge management", "author": ["Christopher Brewster", "Fabio Ciravegna", "Yorick Wilks"], "venue": "In Natural Language Processing and Information Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2002}, {"title": "ATOLL\u2014A framework for the automatic induction of ontology lexica", "author": ["Sebastian Walter", "Christina Unger", "Philipp Cimiano"], "venue": "Data & Knowledge Engineering,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "A survey of grammatical inference methods for natural language learning", "author": ["Arianna D\u2019Ulizia", "Fernando Ferri", "Patrizia Grifoni"], "venue": "Artificial Intelligence Review,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Building a large annotated corpus of English: The Penn Treebank", "author": ["Mitchell P Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini"], "venue": "Computational linguistics,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1993}, {"title": "Fast unsupervised incremental parsing", "author": ["Yoav Seginer"], "venue": "In Annual Meeting-Association For Computational Linguistics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Unsupervised learning of natural languages", "author": ["Zach Solan", "David Horn", "Eytan Ruppin", "Shimon Edelman"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2005}, {"title": "A psychologically plausible and computationally effective approach to learning syntax", "author": ["Stephen Watkinson", "Suresh Manandhar"], "venue": "In Proceedings of the 2001 workshop on Computational Natural Language Learning-Volume", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2001}, {"title": "Unsupervised induction of stochastic context-free grammars using distributional clustering", "author": ["Alexander Clark"], "venue": "In Proceedings of the 2001 workshop on Computational Natural Language Learning-Volume", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2001}, {"title": "UnsuParse: unsupervised Parsing with unsuper- November 2015 vised Part of Speech Tagging", "author": ["Christian H\u00e4nig", "Stefan Bordag", "Uwe Quasthoff"], "venue": "In LREC,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2008}, {"title": "Mladeni\u0107. Semi-automatic rule construction for semantic linking of relation arguments", "author": ["Janez Starc", "Dunja"], "venue": "In Proceedings of the 17th International Multiconference Information Society - IS 2014,,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "Interactive knowledge base population", "author": ["Travis Wolfe", "Mark Dredze", "James Mayfield", "Paul McNamee", "Craig Harman", "Tim Finin", "Benjamin Van Durme"], "venue": "arXiv preprint arXiv:1506.00301,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "A graph-based algorithm for inducing lexical taxonomies from scratch", "author": ["Roberto Navigli", "Paola Velardi", "Stefano Faralli"], "venue": "In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Three,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Semantic taxonomy induction from heterogenous evidence", "author": ["Rion Snow", "Daniel Jurafsky", "Y. Andrew Ng"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2006}, {"title": "Kernel methods for relation extraction", "author": ["Dmitry Zelenko", "Chinatsu Aone", "Anthony Richardella"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2003}, {"title": "Unsupervised ontology induction from text", "author": ["Hoifung Poon", "Pedro Domingos"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2010}, {"title": "A deep architecture for semantic parsing", "author": ["Phil Blunsom", "Nando de Freitas", "Edward Grefenstette", "Karl Moritz Hermann"], "venue": "In Proceedings of the ACL 2014 Workshop on Semantic Parsing,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "One of the ultimate goals of Natural Language Processing (NLP) is machine reading [1], the automatic, unsupervised understanding of text.", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "Traditional methods for ontology learning [2,3] are only concerned with discovering the salient concepts from text.", "startOffset": 42, "endOffset": 47}, {"referenceID": 2, "context": "Traditional methods for ontology learning [2,3] are only concerned with discovering the salient concepts from text.", "startOffset": 42, "endOffset": 47}, {"referenceID": 3, "context": "Thus, they work in a macro-reading fashion [4], where the goal is to extract facts from a large collection of texts, but not necessarily all of them, as opposed to a micro-reading fashion, where the goal is to extract every fact from the input text.", "startOffset": 43, "endOffset": 46}, {"referenceID": 4, "context": "Semantic parsing datasets have been created by either selecting texts that can be expressed with a given meaning representation, like Free917 dataset [5], or by manually deriving the meaning representation given the text, like Atis dataset [6].", "startOffset": 150, "endOffset": 153}, {"referenceID": 5, "context": "Semantic parsing datasets have been created by either selecting texts that can be expressed with a given meaning representation, like Free917 dataset [5], or by manually deriving the meaning representation given the text, like Atis dataset [6].", "startOffset": 240, "endOffset": 243}, {"referenceID": 6, "context": "While Free917 uses Freebase [7], which is a very big multi-domain ontology, it is not possible to represent an arbitrary sentence with Freebase or any other existing ontology.", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "The grammar induction method works on the premise of curriculum learning [8], where the parser first learns to parse simple sentences, then proceeds to learn more complex ones.", "startOffset": 73, "endOffset": 76}, {"referenceID": 8, "context": "Furthermore, it has been shown by [9] that CFGs are expressive enough to model almost every language phenomena.", "startOffset": 34, "endOffset": 37}, {"referenceID": 9, "context": "These sentences are already annotated with links to other pages, which are also instances of DBpedia knowledge base [10].", "startOffset": 116, "endOffset": 120}, {"referenceID": 10, "context": "Memoization [11] is used to reduce the complexity from exponential time to O(n3) [12], where n is the length of the sentence.", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "Memoization [11] is used to reduce the complexity from exponential time to O(n3) [12], where n is the length of the sentence.", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "Aho-Corasick string matching algorithm [13] is selected for matching for its ability to match all the rules simultaneously.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "The method is based on the assumption that a relation between entities is expressed in the shortest path between them in the semantic tree [14].", "startOffset": 139, "endOffset": 143}, {"referenceID": 9, "context": "The datasets for experiments were constructed from English Wikipedia and knowledge bases DBpedia [10] and Freebase [7].", "startOffset": 97, "endOffset": 101}, {"referenceID": 6, "context": "The datasets for experiments were constructed from English Wikipedia and knowledge bases DBpedia [10] and Freebase [7].", "startOffset": 115, "endOffset": 118}, {"referenceID": 14, "context": "Using the Standford OpenNLP [15] on plain texts we obtained sentence and token splits, and named-entity annotation.", "startOffset": 28, "endOffset": 32}, {"referenceID": 15, "context": "Several approaches have used Combinatory categorial grammar (CCG) and lambda calculus as a meaning representation [16,17].", "startOffset": 114, "endOffset": 121}, {"referenceID": 16, "context": "Several approaches have used Combinatory categorial grammar (CCG) and lambda calculus as a meaning representation [16,17].", "startOffset": 114, "endOffset": 121}, {"referenceID": 17, "context": "Other approaches use dependency-based compositional semantics [18], ungrounded graphs [19], etc.", "startOffset": 62, "endOffset": 66}, {"referenceID": 18, "context": "Other approaches use dependency-based compositional semantics [18], ungrounded graphs [19], etc.", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "Early semantic parsers were trained on datasets, such as Geoquery [20] and Atis [6], that map sentences to domain-specific databases.", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "Early semantic parsers were trained on datasets, such as Geoquery [20] and Atis [6], that map sentences to domain-specific databases.", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "Later on datasets for question answering based on Freebase were created \u2013 Free917 [5] and WebQuestions [21] These datasets contain short questions from multiple domains, and since the meaning representations are formed of Freebase concepts, they allow reasoning over Freebase\u2019s ontology, which is much richer than databases in GeoQuery and Atis.", "startOffset": 82, "endOffset": 85}, {"referenceID": 20, "context": "Later on datasets for question answering based on Freebase were created \u2013 Free917 [5] and WebQuestions [21] These datasets contain short questions from multiple domains, and since the meaning representations are formed of Freebase concepts, they allow reasoning over Freebase\u2019s ontology, which is much richer than databases in GeoQuery and Atis.", "startOffset": 103, "endOffset": 107}, {"referenceID": 16, "context": "To overcome this limitation [17] developed a open vocabulary semantic parser.", "startOffset": 28, "endOffset": 32}, {"referenceID": 21, "context": "In a very similar fashion, [22] defines underspecified entities, types and relations, when the corresponding concept does not exist in Freebase.", "startOffset": 27, "endOffset": 31}, {"referenceID": 22, "context": "As survey by [23] summarizes, the learning mechanisms are based either on statistics, linguistics, or logic.", "startOffset": 13, "endOffset": 17}, {"referenceID": 2, "context": "These are often based on dependency parses, like in [3,24].", "startOffset": 52, "endOffset": 58}, {"referenceID": 23, "context": "These are often based on dependency parses, like in [3,24].", "startOffset": 52, "endOffset": 58}, {"referenceID": 24, "context": "A similar bootstrapping semi-automatic approach to ontology learning was developed in [25], where the user validates lexicalizations of a particular relation to learn new instances, and in [26], where the user validates newly identified terms, while in our approach the user validates grammar rules to learn the composition of whole sentences.", "startOffset": 86, "endOffset": 90}, {"referenceID": 25, "context": "A similar bootstrapping semi-automatic approach to ontology learning was developed in [25], where the user validates lexicalizations of a particular relation to learn new instances, and in [26], where the user validates newly identified terms, while in our approach the user validates grammar rules to learn the composition of whole sentences.", "startOffset": 189, "endOffset": 193}, {"referenceID": 26, "context": "A similar approach with combining DBpedia with Wikipedia for superised learning has been taken in [27], however their focus is more on lexicalization of relations and classes.", "startOffset": 98, "endOffset": 102}, {"referenceID": 27, "context": "A survey by [28] compares several papers on grammar induction.", "startOffset": 12, "endOffset": 16}, {"referenceID": 28, "context": "This is evident in evaluation strategies, where their parse trees are compared against golden parse trees in treebanks, like Penn treebank [29], which are annotated according to syntactic policies.", "startOffset": 139, "endOffset": 143}, {"referenceID": 29, "context": "Whereas our method adds a rule after all sentences are parsed, The Incremental Parsing algorithm [30] updates the grammar after each sentence.", "startOffset": 97, "endOffset": 101}, {"referenceID": 30, "context": "This is also done in ADIOS method [31], where it has been shown that order of sentences affects the grammar.", "startOffset": 34, "endOffset": 38}, {"referenceID": 31, "context": "Our method employs frequency analysis and human supervision to control the grammar construction, while others use Minimum Description Length principle [32], clustering of sequences [33], or significance of word co-occurrences [34].", "startOffset": 151, "endOffset": 155}, {"referenceID": 32, "context": "Our method employs frequency analysis and human supervision to control the grammar construction, while others use Minimum Description Length principle [32], clustering of sequences [33], or significance of word co-occurrences [34].", "startOffset": 181, "endOffset": 185}, {"referenceID": 33, "context": "Our method employs frequency analysis and human supervision to control the grammar construction, while others use Minimum Description Length principle [32], clustering of sequences [33], or significance of word co-occurrences [34].", "startOffset": 226, "endOffset": 230}, {"referenceID": 34, "context": "Related work linking short terms to ontology concepts [35] is designed similarly as our approach in terms of bootstrapping procedure to induce patterns.", "startOffset": 54, "endOffset": 58}, {"referenceID": 35, "context": "Another bootstrapping semi-automatic approach was developed for knowledge base population [36].", "startOffset": 90, "endOffset": 94}, {"referenceID": 36, "context": "Also, many other approaches focus only on one aspect of knowledge extraction, like taxonomy extraction [37,38] or relation extraction [14,39].", "startOffset": 103, "endOffset": 110}, {"referenceID": 37, "context": "Also, many other approaches focus only on one aspect of knowledge extraction, like taxonomy extraction [37,38] or relation extraction [14,39].", "startOffset": 103, "endOffset": 110}, {"referenceID": 13, "context": "Also, many other approaches focus only on one aspect of knowledge extraction, like taxonomy extraction [37,38] or relation extraction [14,39].", "startOffset": 134, "endOffset": 141}, {"referenceID": 38, "context": "Also, many other approaches focus only on one aspect of knowledge extraction, like taxonomy extraction [37,38] or relation extraction [14,39].", "startOffset": 134, "endOffset": 141}, {"referenceID": 39, "context": "This problem was also observed by [40].", "startOffset": 34, "endOffset": 38}, {"referenceID": 40, "context": "Furthermore, they can be used for more interpretable representation of meaning, like the automaton representation in Figure 6, compared to some other methods, like the one based on neural networks [41].", "startOffset": 197, "endOffset": 201}], "year": 2016, "abstractText": "Semantic parsing methods are used for capturing and representing semantic meaning of text. Meaning representation capturing all the concepts in the text may not always be available or may not be sufficiently complete. Ontologies provide a structured and reasoning-capable way to model the content of a collection of texts. In this work, we present a novel approach to joint learning of ontology and semantic parser from text. The method is based on semi-automatic induction of a context-free grammar from semantically annotated text. The grammar parses the text into semantic trees. Both, the grammar and the semantic trees are used to learn the ontology on several levels \u2013 classes, instances, taxonomic and non-taxonomic relations. The approach was evaluated on the first sentences of Wikipedia pages describing people.", "creator": "LaTeX with hyperref package"}}}