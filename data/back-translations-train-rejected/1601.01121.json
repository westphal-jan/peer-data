{"id": "1601.01121", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jan-2016", "title": "A pragmatic approach to multi-class classification", "abstract": "We present a novel hierarchical approach to multi-class classification which is generic in that it can be applied to different classification models (e.g., support vector machines, perceptrons), and makes no explicit assumptions about the probabilistic structure of the problem as it is usually done in multi-class classification. By adding a cascade of additional classifiers, each of which receives the previous classifier's output in addition to regular input data, the approach harnesses unused information that manifests itself in the form of, e.g., correlations between predicted classes. Using multilayer perceptrons as a classification model, we demonstrate the validity of this approach by testing it on a complex ten-class 3D gesture recognition task.", "histories": [["v1", "Wed, 6 Jan 2016 09:55:17 GMT  (884kb,D)", "http://arxiv.org/abs/1601.01121v1", "European Symposium on artificial neural networks (ESANN), Apr 2015, Bruges, Belgium. 2015"]], "COMMENTS": "European Symposium on artificial neural networks (ESANN), Apr 2015, Bruges, Belgium. 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["thomas kopinski", "st\\'ephane magand", "uwe handmann", "alexander gepperth"], "accepted": false, "id": "1601.01121"}, "pdf": {"name": "1601.01121.pdf", "metadata": {"source": "CRF", "title": "A pragmatic approach to multi-class classification", "authors": ["Thomas Kopinski", "St\u00e9phane Magand", "Uwe Handmann", "Alexander Gepperth"], "emails": ["firstname.lastname@hochschule-ruhrwest.de", "alexander.gepperth@ensta.fr"], "sections": [{"heading": null, "text": "I. INTRODUCTIONThis contribution is in the context of classification, in particular multi-class classification (MCC), where an input data vector must be assigned one of several output classes. Although there is a lot of work on binary classification, its basics and applications, the same cannot be said for MCC. This is probably because the statistical theory behind the binary case [1] cannot be generalized trivially [2], which makes model and hyperparameter selection in the MCC much more complex to handle. On a purely application-oriented level, there are a variety of models that have been proposed for performing MCC, although the reported performance is generally very similar, or, where they differ, the differences are highly task-dependent and show no trend towards generally \"better\" or \"worse\" methods. Furthermore, almost all proposed methods suffer from either prohibitive training complexity, unclear assumptions about the problem, or difficult-to-adjust parameters."}, {"heading": "A. Related work", "text": "When it comes to the question of how this development came about, it is the case that most people who are in a position to decide for themselves what they want and what they do not want."}, {"heading": "B. Contribution and novelty", "text": "Instead of making a priori assumptions about distributions or conditional independence properties, we try to learn such properties from data and use this knowledge for improved accuracy. In the specific case of a first-stage MLP classifier trained in a difficult hand gesture recognition task, we investigate how the addition of another MLP level based on first-stage class output activities (COAs) can affect performance. Our basic assumption is that the selective class correlations in the COAs observed in Fig. 1, which we assume will exist for each problem, contain useful information that the second-stage MLP can extract and make usable. Furthermore, for the well-known MNIST classification benchmark for handwritten digits, we show that the addition of this second level does not always significantly improve performance, but that it does not cause worsene.The novelty of our approach consists in its simplicity and applicability, as well as in its structure and applicability."}, {"heading": "II. METHODS", "text": "In this section, we essentially present two different training techniques, one of which can be extended n times depending on the task. Therefore, the data set must be prepared accordingly, which is covered separately for each approach. Furthermore, we present the databases that are used for all experiments in paragraph IV."}, {"heading": "A. Training in output neurons", "text": "This paragraph describes the cascading of two MLPs, the basic idea being to have the first MLP classify a feature vector, and the second MLP classify the vector of the output neurons of the first MLP. Training is carried out sequentially, and care must be taken to prevent overfitting, since each MLP is trained in a purely supervised manner. The procedure consists of three stages A, B and C, which are schematically shown in Figure 2. First, the entire data set must be randomly divided into three sets of equal size D1, D2 and D3. In a first step, an MLP, here referred to as MLP1, is trained with standard parameters (see Sec. III) on D1. Once MLP1 has been converged, the formation of the second MLP is referred to as MLP2. Training begins on Dataset D2."}, {"heading": "B. Training in output neurons plus features", "text": "We extend the approach presented in the previous section in such a way that the formation of MLP2 (and also the evaluation) is based on the neuron values of the initial layer of MLP1, but also on the characteristics of the sample itself, i.e., the input to MLP1. Again, the entire process comprises three stages A, B and C and is schematically represented in sets D1, D2 and D3, highlighting the main differences to the methodology in Fig. 2. The data set is divided in an analogous manner into the approach described in Sec. II-A into three sets of equal size D1, D2 and D3."}, {"heading": "C. Hand Gesture Database and Descriptors", "text": "We record data on 16 people, each of whom has 10 different hand positions (see Figure 5). A data sample is stored as a so-called point cloud, which describes a person's hand shape through a vector of real x-y-z coordinates. For each gesture, 3,000 samples are recorded, resulting in up to 30,000 samples per person and a total database of 480,000 samples. To create a deviation in the data, each participant is asked during the recording phase to rotate and translate his hand in all possible directions. In addition, for each gesture, we define three different distance ranges, in which the participant is asked to perform the hand gestures to ensure sufficient sample coverage for different distances. In summary, this results in an alphabet of ten hand positions: counting 1-5 and fist, stop, grip, L, dot, indicated by a-j (see Figure 5)."}, {"heading": "III. MLP STRUCTURE", "text": "Within the scope of the experiments, each MLP comprises an input, hide and output layer, with each layer completely connected to its successor (see Fig. 4). The output layer depends on the size of the classification task, since each class is represented by a neuron. Depending on the training technique used, the input layer varies in size. During the first stage, the input layer of the first MLP always corresponds to the size of the characteristic vector. For the second stage, this varies depending on the technique used, since the input layer is formed either by the output vector alone or by the output vector linked to the characteristic vector. Therefore, the input layer of MLP1 during training and testing and the size m or m + n for MLP2, the number of classes + length of the characteristic vector depends on the technique. When applying the extension of the method described in Sec. II., the output layer for each of the MLP1 can be different from the number of the neurons covered in the number or the number of the data size of the MLP2."}, {"heading": "IV. EXPERIMENTS", "text": "All methods have been implemented using the FANN library (see [22]). The training algorithm is RPROP, the activation function is the sigmoid function in both hidden and output layers. The remaining MLP parameters are standard parameters, which we do not vary in the course of our experiments, as we have conducted a series of initial tests to determine the correct parameters for the described methodology. A complete parameter search goes beyond the scope of this article. We have conducted a series of experiments, all divided into two different test phases (phase 1 and phase 2), in order to directly compare the effects of our techniques on the classification performance of each MLP. The results are presented in the confusion matrices, which allow us to compare the overall performance of the MLPs, the performance of each class, and the correlations between all classes."}, {"heading": "A. Experiment 1 - output neurons only", "text": "In the first experiment, we tested the effect of the technique described in paragraph II-A. We randomly divided the entire database into three subsets D1-D3 (two for training and one for testing), with both MLPs having 100 neurons in the hidden layer and were trained to subset D1 and D2, respectively, until they converged. Results are shown in Fig. 6 and Fig. 7. Overall, the performance of MLP1 (trained on the trait vectors) is about 91.80%, and MLP2 (trained on the output vector of MLP2) is about 91.98%, which is an improvement of about 0.2%. Overall, moderate improvements are observed in almost all cases, and two cases are subject to negligible performance decreases (< 0.001%)."}, {"heading": "B. Experiment 2 - output neurons plus features", "text": "In the second experiment, we tested the effect of the technique described in paragraph II-B, as opposed to small improvements in cases where the entire database was divided into three subsets D1-D3 (two for training and one for testing), both MLPs have 80 neurons in the hidden layer and were trained on subsets D1 and D2, respectively, until they converged; the results are in Fig. 8 and Fig. 9. The total performance of MLP1 (trained on the trait vectors) is about 90.0% and about 91.0% for MLP2 (trained on the merged vector), which is an improvement of about 1.0%."}, {"heading": "C. Experiment 3 - output neurons plus features with multiple MLPs", "text": "The third experiment evaluates the effect of the advanced technique described in paragraph II-B. The main difference is that we randomly divided the entire database into three subsets D1-D3 (two for training and one for testing) instead of just one. Therefore, we must first feed each sample into both MLPs and calculate their output vectors, which are then linked to the feature vector to form the new input vector for MLP2 during training and testing. Results of this advanced technique are in Fig. 10 and Fig. 11. The total performance of MLP1 (trained on the feature vectors) is about 91.0% and about 93.0% for MLP2 (trained on the merged vector), representing an overall improvement of about 2.0%."}, {"heading": "D. Experiment 4 - MNIST", "text": "As a supplementary exercise, we test our approach using the well-known handwritten MNIST numerical database [23], using the fusion strategy from paragraph II-B. Without parameter tuning, we observe a classification of 93%, which does not improve noticeably by adding the second MLP. On the other hand, no deterioration in performance is observed either. It seems that the problem here is that since we are forced to divide the data set into three parts, we can use fewer training examples than other approaches, which perhaps explains the lack of improvement."}, {"heading": "V. DISCUSSION AND OUTLOOK", "text": "In this article, we present a multi-class classification scheme that should be more useful in practical applications. As there are no explicit assumptions about the type of classification task, there are no additional parameters beyond those that would need to be matched for binary classification training in any case, in this case MLPs. No significant theoretical modeling of the classification task needs to be done, as we rely on the capacity of the second MLP to extract these characteristics to the best of their abilities. Furthermore, we find that the overall improvements are modest, i.e., in the range of \u2264 5%. However, in an application it is often not the overall classification rate that matters, i.e. the behavior of the classifier for specific \"difficult\" classes that we observe is a strong benefit from the use of our two-step approach such as the performance of > 20%, which is very important in practice."}], "references": [{"title": "Pattern recognition and machine learning", "author": ["C. Bishop"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Svm multiclasses, th\u00e9orie et applications (in french)", "author": ["Y. Guermeur"], "venue": "Universit\u00e9 Nancy 1, Tech. Rep. HDR thesis, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "On the learnability and design of output codes for multiclass problems", "author": ["K. Crammer", "Y. Singer"], "venue": "Machine Learning, vol. 47, no. 2, pp. 201\u2013233, 2002.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Multicategory support vector machines : Theory and application to the classification of microarray data and satellite radiance data", "author": ["Y. Lee", "Y. Lin", "G. Wahba"], "venue": "Journal of the American Statistical Association, vol. 99, no. 465, pp. 67\u201381, 2004.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": "ICML\u201904, 2004, pp. 823\u2013830.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "A new method for multiclass support vector machines", "author": ["D. Anguita", "S. Ridella", "D. Sterpi"], "venue": "IJCNN\u201904, 2004, pp. 407\u2013412.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Kernel logistic regression and the import vector machine", "author": ["J. Zhu", "T. Hastie"], "venue": "Journal of Computational and Graphical Statistics, vol. 14, no. 1, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Extracting support data for a given task", "author": ["B. Schlkopf", "C. Burges", "V. Vapnik"], "venue": "1995, pp. 252\u2013257.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "In defense of one-vs-all classification", "author": ["R. Rifkin", "A. Klautau"], "venue": "Journal of Machine Learning Research, vol. 5, pp. 101\u2013141, 2003.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Another approach to polychotomous classification", "author": ["J. Friedman"], "venue": "Department of Statistics, Stanford University, Tech. Rep., 1996.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Support vector machines for multi-class classification", "author": ["E. Mayoraz", "E. Alpaydin"], "venue": "IDIAP, Tech. Rep. 98-06, 1998.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "Pairwise classification and support vector machines", "author": ["U. Kreel"], "venue": "Advances in Kernel Methods, Support Vector Learning. The MIT Press, Cambridge, MA, 1999, pp. 255\u2013268.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "Classification by pairwise coupling", "author": ["T. Hastie", "R. Tibshirani"], "venue": "The Annals of Statistics, vol. 26, no. 2, pp. 451\u2013471, 1998.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "Improved pairwise coupling classification with correcting classifiers", "author": ["M. Moreira", "E. Mayoraz"], "venue": "ECML\u201998, 1998, pp. 160\u2013171.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1998}, {"title": "Multi-class svm classifier based on pairwise coupling", "author": ["Z. Li", "S. Tang", "S. Yan"], "venue": "SVM\u201902, 2002, pp. 321\u2013333.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Round robin classification", "author": ["J. F\u00fcrnkranz"], "venue": "Journal of Machine Learning Research, vol. 2, pp. 721\u2013747, 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "K-SVCR. a support vector machine for multi-class classification", "author": ["C. Angulo", "X. Parra", "A. Catal"], "venue": "Neurocomputing, vol. 55, no. 1-2, pp. 57\u2013 77, 2003.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Dendogram-based svm for multi-class classification", "author": ["K.B. Deslem", "Y. Bennani"], "venue": "Journal of Computing and Information Technology - CIT, vol. 14, no. 4, pp. 283\u2013289, 2006.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Large margin dags for multiclass classification", "author": ["J. Platt", "N. Cristianini", "J. Shawe-Taylor"], "venue": "NIPS, 2000, pp. (547\u2013553.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2000}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods", "author": ["J. Platt"], "venue": "Advances in large margin classifiers, vol. 10, no. 3, pp. 61\u201374, 1999.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Neural network based data fusion for hand pose recognition with multiple tof sensors", "author": ["T. Kopinski", "S. Geisler", "U. Handmann", "A. Gepperth"], "venue": "International Conference on Artificial Neural Networks 2014, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Implementation of a fast artificial neural network library (fann)", "author": ["S. Nissen"], "venue": "Report, Department of Computer Science University of Copenhagen (DIKU), vol. 31, 2003.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Intelligent Signal Processing. IEEE Press, 2001, pp. 306\u2013351.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "This is probably due to the fact that the statistical theory behind the binary case[1] cannot be trivially generalized[2], making model and hyperparameter selection much more complex to treat in MCC.", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "This is probably due to the fact that the statistical theory behind the binary case[1] cannot be trivially generalized[2], making model and hyperparameter selection much more complex to treat in MCC.", "startOffset": 118, "endOffset": 121}, {"referenceID": 2, "context": "\u201dDirect\u201d models include extensions of large margin classifiers such as M-SVMs [3], [4], [5], [6], multinomial kernel regression[7] and even multilayer perceptrons (MLPs) if classification is treated as a regression problem.", "startOffset": 78, "endOffset": 81}, {"referenceID": 3, "context": "\u201dDirect\u201d models include extensions of large margin classifiers such as M-SVMs [3], [4], [5], [6], multinomial kernel regression[7] and even multilayer perceptrons (MLPs) if classification is treated as a regression problem.", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "\u201dDirect\u201d models include extensions of large margin classifiers such as M-SVMs [3], [4], [5], [6], multinomial kernel regression[7] and even multilayer perceptrons (MLPs) if classification is treated as a regression problem.", "startOffset": 88, "endOffset": 91}, {"referenceID": 5, "context": "\u201dDirect\u201d models include extensions of large margin classifiers such as M-SVMs [3], [4], [5], [6], multinomial kernel regression[7] and even multilayer perceptrons (MLPs) if classification is treated as a regression problem.", "startOffset": 93, "endOffset": 96}, {"referenceID": 6, "context": "\u201dDirect\u201d models include extensions of large margin classifiers such as M-SVMs [3], [4], [5], [6], multinomial kernel regression[7] and even multilayer perceptrons (MLPs) if classification is treated as a regression problem.", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "In this contribution, we focus on decomposition approaches as there seems to be no evidence at all that they perform worse than \u201ddirect\u201d MCC[2], and in fact are often much more computationally efficient[2].", "startOffset": 140, "endOffset": 143}, {"referenceID": 1, "context": "In this contribution, we focus on decomposition approaches as there seems to be no evidence at all that they perform worse than \u201ddirect\u201d MCC[2], and in fact are often much more computationally efficient[2].", "startOffset": 202, "endOffset": 205}, {"referenceID": 7, "context": "There are two main decomposition approaches: first of all, there is the \u201done-versus-all\u201d (OVA) [8], [9] approach which trains one binary classifier to distinguish one class from all the other classes.", "startOffset": 95, "endOffset": 98}, {"referenceID": 8, "context": "There are two main decomposition approaches: first of all, there is the \u201done-versus-all\u201d (OVA) [8], [9] approach which trains one binary classifier to distinguish one class from all the other classes.", "startOffset": 100, "endOffset": 103}, {"referenceID": 9, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 60, "endOffset": 64}, {"referenceID": 10, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 78, "endOffset": 82}, {"referenceID": 13, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 84, "endOffset": 88}, {"referenceID": 14, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 90, "endOffset": 94}, {"referenceID": 15, "context": "On the other hand, there is the \u201done-vs-one\u201d (OVO) approach [10], [11], [12], [13], [14], [15], [16] which trains a binary classifier for each pair of classes.", "startOffset": 96, "endOffset": 100}, {"referenceID": 16, "context": "The main drawback of this approach are the limited number of samples available for each pairwise classifier, (although there are more complex formulations that fix this[17]), and the assumption that a pairwise classifier will have a weak response when presented with classes unknown to it.", "startOffset": 168, "endOffset": 172}, {"referenceID": 17, "context": "Lastly, there are more complex graph-based approaches[18], [19] that construct decision trees, at each node of which there is a binary classifier that determines the progress in the tree until a leaf is reached.", "startOffset": 53, "endOffset": 57}, {"referenceID": 18, "context": "Lastly, there are more complex graph-based approaches[18], [19] that construct decision trees, at each node of which there is a binary classifier that determines the progress in the tree until a leaf is reached.", "startOffset": 59, "endOffset": 63}, {"referenceID": 19, "context": "As this is not possible in general for discriminatively trained classifiers, some sort of calibration procedure (often the technique from [20]) is used to obtain normalized \u201dprobabilities\u201d from classifier outputs, although this makes more or less strong assumptions about the data.", "startOffset": 138, "endOffset": 142}, {"referenceID": 20, "context": "For a more in-depth specification of this feature transformation please refer to [21].", "startOffset": 81, "endOffset": 85}, {"referenceID": 21, "context": "All methods were implemented using the FANN library (see [22]).", "startOffset": 57, "endOffset": 61}, {"referenceID": 22, "context": "As a supplementary exercise, we test our approach on the well-known MNIST hand-written digit database[23], using the fusion strategy from Sec.", "startOffset": 101, "endOffset": 105}], "year": 2016, "abstractText": "We present a novel hierarchical approach to multiclass classification which is generic in that it can be applied to different classification models (e.g., support vector machines, perceptrons), and makes no explicit assumptions about the probabilistic structure of the problem as it is usually done in multi-class classification. By adding a cascade of additional classifiers, each of which receives the previous classifier\u2019s output in addition to regular input data, the approach harnesses unused information that manifests itself in the form of, e.g., correlations between predicted classes. Using multilayer perceptrons as a classification model, we demonstrate the validity of this approach by testing it on a complex ten-class 3D gesture recognition task.", "creator": "LaTeX with hyperref package"}}}