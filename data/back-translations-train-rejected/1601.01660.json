{"id": "1601.01660", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jan-2016", "title": "An Automaton Learning Approach to Solving Safety Games over Infinite Graphs", "abstract": "We propose a method to construct finite-state reactive controllers for systems whose interactions with their adversarial environment are modeled by infinite-duration two-player games over (possibly) infinite graphs. The proposed method targets safety games with infinitely many states or with such a large number of states that it would be impractical---if not impossible---for conventional synthesis techniques that work on the entire state space. We resort to constructing finite-state controllers for such systems through an automata learning approach, utilizing a symbolic representation of the underlying game that is based on finite automata. Throughout the learning process, the learner maintains an approximation of the winning region (represented as a finite automaton) and refines it using different types of counterexamples provided by the teacher until a satisfactory controller can be derived (if one exists). We present a symbolic representation of safety games (inspired by regular model checking), propose implementations of the learner and teacher, and evaluate their performance on examples motivated by robotic motion planning in dynamic environments.", "histories": [["v1", "Thu, 7 Jan 2016 20:42:19 GMT  (97kb,D)", "http://arxiv.org/abs/1601.01660v1", null]], "reviews": [], "SUBJECTS": "cs.FL cs.LG cs.LO", "authors": ["daniel neider", "ufuk topcu"], "accepted": false, "id": "1601.01660"}, "pdf": {"name": "1601.01660.pdf", "metadata": {"source": "CRF", "title": "An Automaton Learning Approach to Solving Safety Games over Infinite Graphs", "authors": ["Daniel Neider", "Ufuk Topcu"], "emails": [], "sections": [{"heading": null, "text": "This year, the time has come again: the EU Commission has taken a series of measures to accelerate the EU accession negotiations with Turkey, in order to get the EU accession negotiations under way."}, {"heading": "II. RATIONAL SAFETY GAMES", "text": "This section recaps the infinite duration in which two player safety games (A, F, I) have a basic concepts of automation theory and the introduction of rational safety games (A, F, E). (D, A, E, E) A safety game is played in an arena. (V, V1, E) We allow V0 and V1 to be numbered. (A, F, I) We write the successes of a series X, V, E (X) = {y, x, y).We look at safety games with initial slots defined as triples G. (A, F, I) consisting of a set of X, X, X, X, X, X, X. (X, Y).We look at safety games with initial slots. (A, F, I) consisting of a series of slots."}, {"heading": "III. THE LEARNING FRAMEWORK", "text": "Our learning framework is an extension of the ICE framework proposed by Garg et. al. [6], which deals with learning loops of positive and negative data as well as implications. Learning takes place between a teacher who has knowledge (explicit or implicit) of the rational safety game in question and a learner whose goal is to learn a DFA that accepts a winning amount but is agnostic to the game. We assume that the teacher announces the alphabet of the game before the actual learning begins - this type of query is often referred to as equivalence or correctness query. Although the teacher does not know a winning amount (the overall goal is to learn a counterpart), he can fall back on the conditions (1) - (4) of the definition."}, {"heading": "If C passes all four checks, the teacher replies \u201cyes\u201d. The", "text": "It is easy to see that the language of a conjecture is actually a winning amount if the teacher answers \"yes\" (since it meets all the conditions of definition 1). The meaning of a positive counter-example is that any conjecture must accept it but has been rejected. Likewise, a negative counter-example indicates that any conjecture must reject it but has been accepted. An existential implication counter-example (u, A) means that any conjecture that u accepts must accept at least one positive conjecture L (A) that has been violated by the current conjecture. Finally, a universal implication counter-example (u, A) means that any conjecture that u accepts must accept all v, L (A). At this point, it is important to note that the definition 4 is sound (in particular, both types of conjecture are exemplary) well defined."}, {"heading": "IV. A GENERIC TEACHER", "text": "(A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A (A) (A) (A (A) (A) (A) (A) (A (A) (A) (A (A) (A) (A) (A (A) (A) (A) (A) (A) (A) (A (A) (A) (A) (A) (A) (A) (A (A) (A) (A) (A) (A) (A (A) (A) (A) (A"}, {"heading": "V. A LEARNER FOR RATIONAL SAFETY GAMES", "text": "In fact, it is as if it were a pure study piece, able to adapt itself to the needs of the pupils. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...) It is as if it were a pure study piece. (...)"}, {"heading": "A. The formula \u03d5Unin", "text": "We break down the construction of the universal implication into smaller parts. Broadly speaking, for each universal implication we construct q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q (A). For the rest, let us fix a universal implication of the universal implication that occurs as the antecedent of a universal implication. As a preparatory step, we present auxiliary Boolean variables that track the runs of the words of the pref (Uni) to see when the ante of a universal implication is accepted."}, {"heading": "B. Correctness of the Learner", "text": "We now outline a proof of correctness for the learner - we refer the reader to Appendix B for detailed proof. First, we explain that he has the desired properties. Lemma 2: Let him be a sample, n \u2265 1, and Sn are defined as above. Then, the following statements hold: (1) If M | = Sn, then AM is a DFA with n states that are in agreement with S. (2) If there is a DFA that has n states and is in agreement with S, then Sn is satisfactory."}, {"heading": "VI. EXPERIMENTS", "text": "To demonstrate the feasibility of our learning approach, we have implemented a Java prototype using the BRICS automation library [16] and Microsoft's Z3 [17] Constraint Solver. Source code, including the games used in the experiments, is available at http: / / preview.tinyurl.com / n7a7byy. In addition to the learner of Section V, we have implemented a learner based on the popular RPNI algorithm [18], which is a polynomic age algorithm for learning DFAs from positive and negative words. For this learner, we modified the RPNI algorithm to construct a consistent DFA from existential and universal implications alongside positive and negative words (a detailed representation can be found in Appendix C). Unlike Algorithm 2, our modified version of RPNI cannot guarantee the smallest consistent DFAs, so the result is not complete, but the result of a quick DFAs in general."}, {"heading": "A. Examples", "text": "We will consider the following examples. Diagonal game: A robot moves on an infinite, discrete two-dimensional grid world from one cell to an adjacent cell. Player 0 controls the vertical movement of the robot, while Player 1 controls the horizontal movement. Both players move the robot alternately, and Player 0 has the goal of staying within a game of two cells around the diagonal.Box game: A version of the diagonal game in which Player 0 has the goal of staying within a horizontal strip of width. Solitary Box Game: A version of the box game in which Player 0 is the only player and has control of the horizontal and vertical movement. Evasion game: Two robots move alternately on an infinite, two-dimensional grid. Each robot is controlled by a player. Player 0 is the goal of avoiding collision with Player 1, and has control of the horizontal and the vertical movement."}, {"heading": "B. Scalability Benchmarks", "text": "In order to assess the scalability of our technique in the face of increasing numbers of inputs, we modified the game in Example 1 so that the safe region is now determined by two parameters, k and k \u00b2, and contains all positions in the interval [k, k \u00b2] (we assume k < k \u00b2 and fix k = 1). In this new environment, the number of states of the AF machine increases when k \u00b2 increases, because the machine has to count in irregular order to check the position of the robot.Figure 2 shows the total time it takes to learn a winning amount, depending on the parameter k \u00b2. To put the runtimes into perspective, it also shows the size of the games.On the scalability benchmark suite, the RPNI learner was about an order of magnitude faster than the SAT learner and can calculate a winning amount for games up to a total size of 50,000. On the other hand, the SAT learner calculated a winning amount for games up to 10,000 points for our combined work were insufficient for a practical size of 10,000."}, {"heading": "VII. CONCLUSION", "text": "We developed an automatic learning method for constructing finite, reactive controllers for systems whose interaction with their environment is modelled by endless state games. We focused on the practically interesting family of safety games, used a symbolic representation of the underlying game, developed specific implementations of the learner and the teacher, and demonstrated the feasibility of the method through a series of problems motivated by robot motion planning."}, {"heading": "APPENDIX A CONSTRUCTING CONSISTENT DFAS USING CONSTRAINT SOLVERS", "text": "The key component of our learner is an algorithm that, based on an example of S, generates a smallest DFA consistent with S. In the following, we describe in detail how the formula \"Sn\" is constructed. In order to provide a more coherent representation, we repeat parts of Section V; as a beneficial side effect, this repetition allows us to provide further explanations of the formulas presented in Section V. In addition, in order to provide a more concise and accessible description, we define a slightly different formula that reproduces the course of AM on words that occur in the sample (in Pos, Neg, and as an antecedent of an implication)."}, {"heading": "W = Pos \u222aNeg \u222aAnte(Ex ) \u222aAnte(Uni),", "text": "The idea is that all positive and negative words, as well as all words that occur as antecedent of an existential or universal implication, are based on \"Q\" (F), \"Q\" (F), \"Q\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\", \"F\", \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F), \"F\" (F). (F), \"F (F),\" F \"(F),\" F \"(F),\" F \"(F). (F),\" F \"(F),\" F (F), \"(F),\" F \"(F),\" (F), \"(F),\" (F \"(F),\" (F), \"F\" (F \"(F),\" (F), \"(F\" (F), \"(F),\" F \"(F\" (F), \"(F),\" (F \"(F),\" (F \"(F),\" (F), \"(F),\" (F \"(F),\" (F \"(F),\" (F \"(F),\" (F), \"(F)."}, {"heading": "APPENDIX B CORRECTNESS OF THE SAT LEARNER", "text": "This year, the time has come for such a process to take place in the first half of the year, in which such a process will take place."}, {"heading": "APPENDIX C RPNI LEARNER", "text": "The RPNI learner works in a restricted environment where each vertex of the arena has a finite (but not necessarily limited) number of outgoing edges (i.e., E ({v}) is finite for all v \u0394V. This means that implications are counter-examples of the form (u, A), where L (A) is finite. The RPNI learner works identically to the SAT learner, but uses a different method to construct a consistent DFA from a sample. While the SAT learner uses a constraint solver for this task (see Algorithm 2), the RPNI learner uses a modified version of the popular RPNI algorithm [18], which is a polynomial time euristics for learning positive and negative words (we have adapted the RPNI algorithm so that it learns DFAs not only from positive and negative words, but also from universal and implications)."}, {"heading": "A. The RPNI Algorithm", "text": "The RPNI algorithm is a so-called passive learning algorithm for regular languages (a fixed order). It takes two years to be successful, finite sentences such as Pos-1 and Neg-3, which satisfy all terms in time and space. (However, it turns out that the RPNI algorithm often produces \"small\" automatons in practice.) The RPNI algorithm operates on predefined sets of Pos and Neg as follows: It constructs the prefix tree acceptor of the Set Pos (i.e.), which accepts exactly the Set Pos."}, {"heading": "B. Adapting the Generic State Merging Algorithm", "text": "It is not as if the idea of the RPNI algorithm, namely the construction of the prefix tree of the set pos, the prefix tree acceptor acceptance of a limited set X (i.e.) is a part of DFA5 that assumes exactly the set X. It is defined as follows. Definition 7: It is an alphabet acceptor that is the prefix tree acceptor acceptance of the partial DFA acceptance."}, {"heading": "C. Correctness of the RPNI learner", "text": "The correctness of the RPNI learner is based on the correctness of algorithm 3, which will be defined in the next paragraph.Lemma 9: Faced with a non-contradictory sample S, algorithm 3 constructs a DFA that is consistent with S. The resulting automaton comprises at most | V | states.Proof of Lemma 9: The proof that algorithm 3 constructs a DFA that is consistent with the given sample S is simple: the function init constructs an initial DFA that is consistent with S (see Lemma 8), and a merger is only maintained if the combined DFA passes the test (i.e., it is still consistent); therefore, the final DFA is also guaranteed to be consistent. Since the initial DFA has a state and the fusion of states reduces the number of states, the final DFA has at most consistency."}], "references": [{"title": "Infinite games played on finite graphs", "author": ["R. McNaughton"], "venue": "Ann. Pure Appl. Logic, vol. 65, no. 2, pp. 149\u2013184, 1993.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "A simple inductive synthesis methodology and its applications", "author": ["S. Itzhaky", "S. Gulwani", "N. Immerman", "M. Sagiv"], "venue": "OOPSLA 2010. ACM, 2010, pp. 36\u201346.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Slugs GR(1) synthesizer", "author": ["R. Ehlers", "V. Raman", "C. Finucane"], "venue": "2014, available at https://github.com/LTLMoP/slugs/.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Acacia+, a tool for ltl synthesis", "author": ["A. Bohy", "V. Bruy\u00e8re", "E. Filiot", "N. Jin", "J.-F. Raskin"], "venue": "CAV, 2012, pp. 652\u2013657.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Regular model checking", "author": ["A. Bouajjani", "B. Jonsson", "M. Nilsson", "T. Touili"], "venue": "CAV 2000, ser. LNCS, vol. 1855. Springer, 2000, pp. 403\u2013418.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "ICE: A robust framework for learning invariants", "author": ["P. Garg", "C. L\u00f6ding", "P. Madhusudan", "D. Neider"], "venue": "CAV 2014, ser. LNCS, vol. 8559. Springer, 2014, pp. 69\u201387.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Complexity of automaton identification from given data", "author": ["E.M. Gold"], "venue": "Information and Control, vol. 37, no. 3, pp. 302\u2013320, 1978.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1978}, {"title": "Learning regular sets from queries and counterexamples", "author": ["D. Angluin"], "venue": "Inf. Comput., vol. 75, no. 2, pp. 87\u2013106, 1987.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1987}, {"title": "An automata-theoretic approach to infinite-state systems", "author": ["O. Kupferman", "N. Piterman", "M.Y. Vardi"], "venue": "Time for Verification, Essays in Memory of Amir Pnueli, ser. LNCS, vol. 6200. Springer, 2010, pp. 202\u2013259.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "A constraint-based approach to solving games on infinite graphs", "author": ["T.A. Beyene", "S. Chaudhuri", "C. Popeea", "A. Rybalchenko"], "venue": "POPL 2014. ACM, 2014, pp. 221\u2013234.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Reachability games on automatic graphs", "author": ["D. Neider"], "venue": "CIAA 2010, ser. LNCS, vol. 6482. Springer, 2010, pp. 222\u2013230.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Small strategies for safety games", "author": ["\u2014\u2014"], "venue": "ATVA 2011, ser. LNCS, vol. 6996. Springer, 2011, pp. 306\u2013320.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Finite presentations of infinite structures: Automata and interpretations", "author": ["A. Blumensath", "E. Gr\u00e4del"], "venue": "Theory Comput. Syst., vol. 37, no. 6, pp. 641\u2013674, 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Regular model checking using solver technologies and automata learning", "author": ["D. Neider", "N. Jansen"], "venue": "NFM 2013, ser. LNCS, vol. 7871. Springer, 2013, pp. 16\u201331.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Exact DFA identification using SAT solvers", "author": ["M. Heule", "S. Verwer"], "venue": "ICGI 2010, ser. LNCS, vol. 6339. Springer, 2010, pp. 66\u201379.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "dk.brics.automaton \u2013 finite-state automata and regular expressions for Java", "author": ["A. M\u00f8ller"], "venue": "2010, http://www.brics.dk/automaton/.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Z3: an efficient SMT solver", "author": ["L.M. de Moura", "N. Bj\u00f8rner"], "venue": "TACAS 2008, ser. LNCS, vol. 4963. Springer, 2008, pp. 337\u2013340.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "We model the interaction between a controlled system and its possibly adversarial environment as a two-player game over a graph [1].", "startOffset": 128, "endOffset": 131}, {"referenceID": 1, "context": "learning takes place in a setting akin to counterexample-guided inductive synthesis (CEGIS) [2] between a teacher, who has knowledge about the safety game in question, and a learner, whose objective is to identify a controller using information disclosed by the teacher in response to (incorrect) conjectures.", "startOffset": 92, "endOffset": 95}, {"referenceID": 2, "context": "Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.", "startOffset": 132, "endOffset": 135}, {"referenceID": 3, "context": "Additionally, in situations where a complete description of the game is not available in a format amenable to existing game solvers [3], [4], there may still exist human experts (or automated oracles, as in Section IV) who have sufficient insight into how the controlled system should behave and can act as teacher.", "startOffset": 137, "endOffset": 140}, {"referenceID": 4, "context": "Hence, one of our main contributions is a symbolic representation of safety games, called rational safety games, that follows the idea of regular model checking [5] in that it represent sets of vertices by regular languages and edges by so-called rational relations.", "startOffset": 161, "endOffset": 164}, {"referenceID": 5, "context": "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal", "startOffset": 37, "endOffset": 40}, {"referenceID": 6, "context": "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal", "startOffset": 126, "endOffset": 129}, {"referenceID": 7, "context": "Following the ICE learning framework [6] and partially deviating from the classical learning frameworks for regular languages [7], [8], the counterexample may be one of the following four types: positive, negative, existential implication and universal", "startOffset": 131, "endOffset": 134}, {"referenceID": 8, "context": "in the past, predominantly in the case of games over pushdown graphs [9].", "startOffset": 69, "endOffset": 72}, {"referenceID": 9, "context": "Also, a constraint-based approach to solving games over infinite graphs has recently been proposed [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "Learning-based techniques for games over infinite graphs have already been studied in the context of reachability games [11]; in fact, our symbolic representation of safety games is a generalization of the representation proposed there.", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "In the context of safety games, recent work [12] has already demonstrated the ability of learning-based approaches to extract small reactive controllers from a priori constructed controllers with possibly large number of states.", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": ", infinite duration two-person games on graphs) as popularized by McNaughton [1].", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "We follow the idea of regular model checking [5], an approach in verification, and represent sets of vertices by regular languages and edges by so-called rational relations.", "startOffset": 45, "endOffset": 48}, {"referenceID": 12, "context": "(This definition of rational relations is simplified from that in [13] but sufficient for our purpose.", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "[6], which deals with learning loop invariants from positive and negative data as well as", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "The learning proceeds in a CEGIS-style loop [2].", "startOffset": 44, "endOffset": 47}, {"referenceID": 6, "context": "It is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold\u2019s passive learning [7] or Angluin\u2019s active learning [8], are insufficient in our setting.", "startOffset": 173, "endOffset": 176}, {"referenceID": 7, "context": "It is important to note that classical learning frameworks for regular languages that involve learning from positive and negative data only, such as Gold\u2019s passive learning [7] or Angluin\u2019s active learning [8], are insufficient in our setting.", "startOffset": 206, "endOffset": 209}, {"referenceID": 5, "context": "[6] argue comprehensively why implications needed in a robust invariant learning framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": ", the corresponding decision problem is NP-complete) already in the absence of implications [7].", "startOffset": 92, "endOffset": 95}, {"referenceID": 13, "context": "Our encoding of transitions and final states follows an idea from [14] (independently due to [15]).", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "Our encoding of transitions and final states follows an idea from [14] (independently due to [15]).", "startOffset": 93, "endOffset": 97}, {"referenceID": 13, "context": "A description of \u03c6 n and \u03c6 Neg n can also be found in [14].", "startOffset": 54, "endOffset": 58}, {"referenceID": 15, "context": "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft\u2019s Z3 [17] constraint solver.", "startOffset": 132, "endOffset": 136}, {"referenceID": 16, "context": "In order to demonstrate the feasibility of our learning approach, we implemented a Java prototype using the BRICS automaton library [16] and Microsoft\u2019s Z3 [17] constraint solver.", "startOffset": 156, "endOffset": 160}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "We propose a method to construct finite-state reactive controllers for systems whose interactions with their adversarial environment are modeled by infinite-duration twoplayer games over (possibly) infinite graphs. The proposed method targets safety games with infinitely many states or with such a large number of states that it would be impractical\u2014 if not impossible\u2014for conventional synthesis techniques that work on the entire state space. We resort to constructing finitestate controllers for such systems through an automata learning approach, utilizing a symbolic representation of the underlying game that is based on finite automata. Throughout the learning process, the learner maintains an approximation of the winning region (represented as a finite automaton) and refines it using different types of counterexamples provided by the teacher until a satisfactory controller can be derived (if one exists). We present a symbolic representation of safety games (inspired by regular model checking), propose implementations of the learner and teacher, and evaluate their performance on examples motivated by robotic motion planning in dynamic environments.", "creator": "LaTeX with hyperref package"}}}