{"id": "1601.01799", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jan-2016", "title": "Dense Bag-of-Temporal-SIFT-Words for Time Series Classification", "abstract": "Time series classification is an application of particular interest with the increase of data to monitor. Classical techniques for time series classification rely on point-to-point distances. Recently, Bag-of-Words approaches have been used in this context. Words are quantized versions of simple features extracted from sliding windows. The SIFT framework has proved efficient for image classification. In this paper, we design a time series classification scheme that builds on the SIFT framework adapted to time series to feed a Bag-of-Words. We then refine our method by studying the impact of normalized Bag-of-Words, as well as densely extract point descriptors. Proposed adjustements achieve better performance. The evaluation shows that our method outperforms classical techniques in terms of classification.", "histories": [["v1", "Fri, 8 Jan 2016 09:06:44 GMT  (922kb,D)", "http://arxiv.org/abs/1601.01799v1", null], ["v2", "Wed, 13 Jan 2016 08:12:54 GMT  (1157kb,D)", "http://arxiv.org/abs/1601.01799v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["adeline bailly", "simon malinowski", "romain tavenard", "thomas guyet", "laetitia chapel"], "accepted": false, "id": "1601.01799"}, "pdf": {"name": "1601.01799.pdf", "metadata": {"source": "CRF", "title": "Dense Bag-of-Temporal-SIFT-Words for Time Series Classification", "authors": ["Adeline Bailly", "Simon Malinowski", "Romain Tavenard", "Laetitia Chapel", "Thomas Guyet"], "emails": [], "sections": [{"heading": null, "text": "Keywords: Time Series Classification, Bag-of-Words, SIFT, Dense Characteristics, BoTSW, D-BoTSW"}, {"heading": "1 Introduction", "text": "In recent years, we have obtained a number of interesting examples of applications, such as medicine [24], environmental modeling [7], speech recognition [12]. A wide range of algorithms have been proposed to solve this problem. Combining the kNN classification is one of the most popular methods, as it achieves a high classification accuracy [20]. However, this method has a high calculation rate, which makes its use in the real world more difficult. Combining the kNN classification with the DTW is one of the most popular methods, as it achieves a high classification rate."}, {"heading": "2 Related work", "text": "Our approach to classifying time series builds on two well-known methods of computer vision: local features are extracted from time series using a SIFT-based approach, and a global representation of time series is created using Bag-of-Words. This section first introduces the most advanced distance-based methods of time series classification, and then presents previous work using Bag-of-Words approaches to classifying time series."}, {"heading": "2.1 Distance-based time series classification", "text": "Early work has focused on the use of dedicated metrics to evaluate similarity between time series. In [20] Ratanamahatana and Keogh compare dynamic time warping to Euclidean distance when used with a simple kNN classifier. While the former benefits from its robustness against time distortions to achieve high accuracy, ED is known to have much lower computing costs. Cuturi [5] shows that while DTW is well suited to retrieve tasks by focusing on the best possible alignment between time series, it fails to accurately quantify the dissimilarity between non-matching sequences (supported by the fact that DTW-derived kernels are not positively defined). Therefore, he introduces the Global Alignment Kernel, which takes into account all possible orientations to create a reliable dissimilarity that can be used at the core of the standard kernel method."}, {"heading": "2.2 Bag-of-Words for time series classification", "text": "Inspired by the use of text modules and computer visions, we have investigated the use of dead ends for the classification of time series [2,3,14,21,24]. This work is based on two main operations: the conversion of time series into dead ends and the construction of a classifier for these dead ends. Usually, standard techniques such as random formats, neural networks or nodes for classification are used. However, many different ways of converting time series into dead ends have been introduced, including a framework for the classification of dead ends."}, {"heading": "3 Bag-of-Temporal-SIFT-Words (BoTSW) method", "text": "The proposed method is based on three main steps: (i) extraction of key points in time series; (ii) description of these key points by gradient size on a particular scale; and (iii) representation of time series by a BoW, with the words of the quantified version corresponding to the description of key points, shown in Figure 1 and detailed below."}, {"heading": "3.1 Keypoints extraction in time series", "text": "The first step of our method is to extract key points in time series. Two approaches are described here: the first is based on scale-space-extreme detection (as in [1]) and the second suggests a dense scale-space-extreme detection. Following the SIFT framework, key points in time series are identified as local extremes in terms of scale and (temporal) location. These scale-space extremes are identified using a DoG function and form a list of scale-invariant key points. Let L (t, \u03c3) see the convolution (p) of a Gauss function G (t, \u03c3) of the width series with a time series S (t): L (t, \u03c3) = G (t) where G (t) is the constellation (t) of the key series."}, {"heading": "3.2 Description of the extracted keypoints", "text": "The next step in our process is the description of the key points. A key point in time index t and scale j is described by gradient sizes of L (\u00b7, kjsc\u03c30) by t. To this end, nb blocks of size a are selected around the key point. Gradients are calculated at each point of each block and weighted using a Gaussian window of standard deviation a \u00d7 nb2, so that points that are further away from the detected key point in time have a smaller influence. Subsequently, each block is described by two values: the sum of the positive gradients and the sum of the negative gradients. This results in a characteristic vector of dimension 2 \u00b7 nb."}, {"heading": "3.3 Bag-of-Temporal-SIFT-Words for time series classification", "text": "The number of occurrences of each word in a time series is calculated. (D) BoTSW representation of a time series is the \"2-normalized histogram\" (i.e. the frequency vector) of the word occurrence. To reduce the impact of this word normalization, we compare two normalization schemes for BoW: Signed Square Root Normalization (SSR) and Inverse Document Frequency normalization (IDF). These normalizations are commonly used in image normalizations that precede normalization and precede normalization. [Signed Square Root Normalization (SSR) and Inverse Document Frequency normalization (IDF)."}, {"heading": "4 Experiments and results", "text": "In this section, we examine the effects of both dense keypoint extraction and bag-of-word normalization on classification performance, and then compare our results with those obtained using standard time series classification techniques. For reasons of reproducibility, the C + + source code used for (D-) BoTSW in these experiments is available for download1. To provide descriptive timings for our methods, we executed it on a PC for a specific set of parameters, using the Cricket X [11] dataset, which consists of 390 training time series and 390 test series. Each time series in the dataset has a length of 300. Extraction and description of dense keypoints takes about 1 second for all time series in the dataset. Afterwards, 35 seconds are needed to learn a k mean and adjust a linear SVM classifier using training data. Finally, the test period of all TSD series takes less than 1 second."}, {"heading": "4.1 Experimental setup", "text": "In fact, it is so that it will be able to erenie.n the aforementioned hsci-eaJnlhsrcnlhSrc\u00fce."}, {"heading": "4.2 Experiments on dense extraction", "text": "Fig. 2 shows a pair-by-pair comparison of error rates between BoTSW and its dense counterpart D-BoTSW for all records in the UCR repository. A point on the diagonal means that the error rates obtained are the same. A point above the diagonal illustrates a case where D-BoTSW has a lower error rate than BoTSW. Wilcoxon signed rankings for the p value of the test and Win / Tie / Lose values are given in the lower right corner of the figure. Win / Tie / Lose values indicate that D-BoTSW performs better than BoTSW for 61 records, an equivalent performance for 4 records and a worse one for 21 records. Wilcoxon tests show that this difference is significant (below we will use a significance level of 10% for all statistical tests). D-BoTSW improves the classification of a majority of the data sets, which means that most of the points are within the margin of improvement."}, {"heading": "4.3 Experiments on BoW normalization", "text": "As shown in Figure 3, both SSR and IDF normalizations improve classification performance (although the improvement in the use of IDF is not statistically significant).Therefore, reducing the impact of widely represented code words leads to a more accurate classification with D-BoTSW.IDF normalizations only lead to a small improvement in classification accuracy: Win / Tie / Lose score versus non-normalized D-BoSTW is 38 / 14 / 34. On the contrary, SSR normalizations significantly improve classification accuracy, with a Win / Tie / Lose score of 61 / 10 / 15 versus non-normalized D-BoSTW. This is supported by Figure 4, in which the two normalization schemes are balanced (with all SSR schemes balanced with normalization)."}, {"heading": "4.4 Comparison with state-of-the-art methods", "text": "Below, we refer to the dense SSR normalized BoTSW as D-BoTSW, as this setup is the one that provides the best classification performance. We now compare D-BoTSW with the most popular state-of-the-art methods for classifying time series. We use published error rates for TSBF (45 records) [3], SAX-VSM (51 records) [21], SMTS (45 records) [15], and BoP (20 records).As BoP [14] only provides the classification performance for 20 records, we have decided not to make paired comparisons between D-BoTSW and PPPP.P."}, {"heading": "5 Conclusion", "text": "In this paper, we introduced the D-BoTSW technique, which converts time series into histograms of quantified local characteristics; the combination of SIFT key points and bag-of-words has been widely used and is considered the standard technique in the image area, but has never been studied for the classification of time series; we conducted extensive experiments and demonstrated that dense keypoint extraction and SSR normalization of bag-of-words results in the best performance of our method; we compared the results with standard techniques for classifying time series: D-BoTSW has comparable performance with PROP with lower time complexity and clearly outperforms all other techniques; we believe that classification performance could be further improved by taking more time information into account; and the effects of quantification losses in our representation are reduced; in fact, only local time information is embedded in our model and the global structure of time series is ignored; and more detailed BoTSW representations have been proposed for the standard set of 9.18."}, {"heading": "Acknowledgments", "text": "This work was partly financed by the ANR ASTERIX project (ANR-13-JS020005-01), the Brittany Region and the CNES-TOSCA project VEGIDAR."}], "references": [{"title": "Bag-of-Temporal-SIFT-Words for Time Series Classification", "author": ["Adeline Bailly", "Simon Malinowski", "Romain Tavenard", "Thomas Guyet", "Laetitia Chapel"], "venue": "ECMLPKDD Workshop on Advanced Analytics and Learning on Temporal Data,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Learning a symbolic representation for multivariate time series classification", "author": ["Mustafa G. Baydogan", "George Runger"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "A Bag-of-Features Framework to Classify Time Series", "author": ["Mustafa G. Baydogan", "George Runger", "Eugene Tuv"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "sDTW: Computing DTW Distances using Locally Relevant Constraints based on Salient Feature Alignments", "author": ["Kasim S. Candan", "Rosaria Rossini", "Maria L. Sapino"], "venue": "Proceedings of the International Conference on Very Large DataBases,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Fast global alignment kernels", "author": ["Marco Cuturi"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Classification trees for time series", "author": ["Ahlame Douzal-Chouakria", "C\u00e9cile Amblard"], "venue": "Elsevier Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Temporal kernels for the identification of grassland management using time series of high spatial resolution satellite images", "author": ["Pauline Dusseux", "Thomas Corpetti", "Laurence Hubert-Moy"], "venue": "In Geoscience and Remote Sensing Symposium (IGARSS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Negative evidences and co-occurrences in image retrieval: the benefit of PCA and whitening", "author": ["Herv\u00e9 J\u00e9gou", "Ondrej Chum"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Aggregating local descriptors into a compact image representation", "author": ["Herv\u00e9 J\u00e9gou", "Matthijs Douze", "Cordelia Schmid", "Patrick P\u00e9rez"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Creating Efficient Codebooks for Visual Recognition", "author": ["Frederic Jurie", "Bill Triggs"], "venue": "International Conference on Computer Vision,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "The UCR Time Series Classification/Clustering", "author": ["Eamonn Keogh", "Qiang Zhu", "Bing Hu", "Yuan Hao", "Xiaopeng Xi", "Li Wei", "Choti- rat A. Ratanamahatana"], "venue": "Home- page,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Convolutional networks for images, speech, and time series", "author": ["Yann Le Cun", "Yoshua Bengio"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "A symbolic represen- tation of time series, with implications for streaming algorithms", "author": ["Jessica Lin", "Eamonn Keogh", "Stefano Lonardi", "Bill Chiu"], "venue": "In Proceedings of the ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Rotation-invariant similarity in time series using bag-of-patterns representation", "author": ["Jessica Lin", "Rohan Khade", "Yuan Li"], "venue": "International Journal of Information Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Time series classification with ensembles of elastic distance measures", "author": ["Jason Lines", "Anthony Bagnall"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Object Recognition from Local Scale-Invariant Features", "author": ["David G. Lowe"], "venue": "In Pro- ceedings of the International Conference on Computer Vision,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["David G. Lowe"], "venue": "Inter- national Journal of Computer Vision,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Fisher kernels on visual vocabularies for image categorization", "author": ["Florent Perronnin", "Christopher Dance"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Large-Scale Image Retrieval with Compressed Fisher Vectors", "author": ["Florent Perronnin", "Yan Liu", "Jorge Sanchez", "Herv\u00e9 Poirier"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Everything you know about dy- namic time warping is wrong", "author": ["Chotirat A. Ratanamahatana", "Eamonn Keogh"], "venue": "In Proceedings of the Workshop on Mining Temporal and Sequential Data,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "SAX-VSM: Interpretable Time Series Classifi- cation Using SAX and Vector Space Model", "author": ["Pavel Senin", "Sergey Malinchik"], "venue": "Proceedings of the IEEE International Conference on Data Mining,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Video Google: A text retrieval approach to object matching in videos", "author": ["Josef Sivic", "Andrew Zisserman"], "venue": "In Proceedings of the International Conference on Com- puter Vision,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "Evaluation of local spatio-temporal features for action recognition", "author": ["Heng Wang", "Muhammad M. Ullah", "Alexander Klaser", "Ivan Laptev", "Cordelia Schmid"], "venue": "In Proceedings of the British Machine Vision Conference,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Bag- of-Words Representation for Biomedical Time Series Classification", "author": ["Jim Wang", "Ping Liu", "Mary F.H. She", "Saeid Nahavandi", "Addas Kouzani"], "venue": "Biomedical Signal Processing and Control,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "A Scale-Invariant Local Descriptor for Event Recog- nition in 1D Sensor Signals", "author": ["Jierui Xie", "Mandis Beigi"], "venue": "In Proceedings of the IEEE International Conference on Multimedia and Expo,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Time series shapelets: a new primitive for data mining", "author": ["Lexiang Ye", "Eamonn Keogh"], "venue": "In Proceedings of the ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "In [1], we designed a Bag-of-Words approach based on an adaptation of this framework to time series classification.", "startOffset": 3, "endOffset": 6}, {"referenceID": 23, "context": "1 Introduction Classification of time series has received an important amount of interest over the past years due to many real-life applications, such as medicine [24], environmental modeling [7], speech recognition [12].", "startOffset": 163, "endOffset": 167}, {"referenceID": 6, "context": "1 Introduction Classification of time series has received an important amount of interest over the past years due to many real-life applications, such as medicine [24], environmental modeling [7], speech recognition [12].", "startOffset": 192, "endOffset": 195}, {"referenceID": 11, "context": "1 Introduction Classification of time series has received an important amount of interest over the past years due to many real-life applications, such as medicine [24], environmental modeling [7], speech recognition [12].", "startOffset": 216, "endOffset": 220}, {"referenceID": 19, "context": "The combination of the kNN classifier with DTW is one of the most popular method since it achieves high classification accuracy [20].", "startOffset": 128, "endOffset": 132}, {"referenceID": 1, "context": "For these reasons, it has been adapted to time series data in some recent works [2,3,14,21,24].", "startOffset": 80, "endOffset": 94}, {"referenceID": 2, "context": "For these reasons, it has been adapted to time series data in some recent works [2,3,14,21,24].", "startOffset": 80, "endOffset": 94}, {"referenceID": 13, "context": "For these reasons, it has been adapted to time series data in some recent works [2,3,14,21,24].", "startOffset": 80, "endOffset": 94}, {"referenceID": 20, "context": "For these reasons, it has been adapted to time series data in some recent works [2,3,14,21,24].", "startOffset": 80, "endOffset": 94}, {"referenceID": 23, "context": "For these reasons, it has been adapted to time series data in some recent works [2,3,14,21,24].", "startOffset": 80, "endOffset": 94}, {"referenceID": 16, "context": "Particularly, the Scale-Invariant Feature Transform (SIFT) framework has led to widely used descriptors [17].", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "In [1], we built on this framework to design a BoW approach for time series classification where words correspond to quantized versions of local features.", "startOffset": 3, "endOffset": 6}, {"referenceID": 21, "context": "This approach can be seen as an adaptation of [22], which uses SIFT features associated with visual words, to time series.", "startOffset": 46, "endOffset": 50}, {"referenceID": 19, "context": "In [20], Ratanamahatana and Keogh compare Dynamic Time Warping to Euclidean Distance when used with a simple kNN classifier.", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "Cuturi [5] shows that, although DTW is well-suited to retrieval tasks since it focuses on the best possible alignment between time series, it fails at precisely quantifying dissimilarity between non-matching sequences (which is backed by the fact that DTW-derived kernel is not positive definite).", "startOffset": 7, "endOffset": 10}, {"referenceID": 14, "context": "Lines and Bagnall [15] propose an ensemble classifier based on elastic distance measures (including DTW), named Proportional Elastic Ensemble (PROP).", "startOffset": 18, "endOffset": 22}, {"referenceID": 25, "context": "Instead of building classification decision on similarities between time series, Ye and Keogh [26] use a decision tree in which the partitioning of time series is performed with respect to the presence (or absence) of discriminant sub-sequences (named shapelets) in the series.", "startOffset": 94, "endOffset": 98}, {"referenceID": 5, "context": "Douzal and Amblard [6] define a dedicated metric for time series which is then used in a classification tree.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "2 Bag-of-Words for time series classification Inspired by text mining, information retrieval and computer vision communities, recent works have investigated the use of Bag-of-Words for time series classification [2,3,14,21,24].", "startOffset": 212, "endOffset": 226}, {"referenceID": 2, "context": "2 Bag-of-Words for time series classification Inspired by text mining, information retrieval and computer vision communities, recent works have investigated the use of Bag-of-Words for time series classification [2,3,14,21,24].", "startOffset": 212, "endOffset": 226}, {"referenceID": 13, "context": "2 Bag-of-Words for time series classification Inspired by text mining, information retrieval and computer vision communities, recent works have investigated the use of Bag-of-Words for time series classification [2,3,14,21,24].", "startOffset": 212, "endOffset": 226}, {"referenceID": 20, "context": "2 Bag-of-Words for time series classification Inspired by text mining, information retrieval and computer vision communities, recent works have investigated the use of Bag-of-Words for time series classification [2,3,14,21,24].", "startOffset": 212, "endOffset": 226}, {"referenceID": 23, "context": "2 Bag-of-Words for time series classification Inspired by text mining, information retrieval and computer vision communities, recent works have investigated the use of Bag-of-Words for time series classification [2,3,14,21,24].", "startOffset": 212, "endOffset": 226}, {"referenceID": 2, "context": "[3] propose a framework to classify time series denoted TSBF where local features such as mean, variance and extremum values are computed on sliding windows.", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "In [24], discrete wavelet coefficients are extracted on sliding windows and then quantized into words using k-means.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "In [14,21], words are constructed using the Symbolic Aggregate approXimation (SAX) representation [13] of time series.", "startOffset": 3, "endOffset": 10}, {"referenceID": 20, "context": "In [14,21], words are constructed using the Symbolic Aggregate approXimation (SAX) representation [13] of time series.", "startOffset": 3, "endOffset": 10}, {"referenceID": 12, "context": "In [14,21], words are constructed using the Symbolic Aggregate approXimation (SAX) representation [13] of time series.", "startOffset": 98, "endOffset": 102}, {"referenceID": 20, "context": "In [21], Senin and Malinchik combine SAX with Vector Space Model to form the SAX-VSM method.", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "In [2], Baydogan and Runger design a symbolic representation of multivariate time series (MTS), called SMTS, where MTS are transformed into a feature matrix, whose rows are feature vectors containing a time index, the values and the gradient of time series at this time index (on all dimensions).", "startOffset": 3, "endOffset": 6}, {"referenceID": 16, "context": "One of the most powerful local feature for image is SIFT [17].", "startOffset": 57, "endOffset": 61}, {"referenceID": 24, "context": "Xie and Beigi [25] use similar keypoint detection for time series.", "startOffset": 14, "endOffset": 18}, {"referenceID": 3, "context": "In [4], extraction and description of time series keypoints in a SIFT-like framework is used to reduce the complexity of DTW: features are used to match anchor points from two different time series and prune the search space when searching for the optimal path for DTW.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "Two approaches are described here: the first one is based on scale-space extrema detection (as in [1]) and the second one proposes a dense extraction scheme.", "startOffset": 98, "endOffset": 101}, {"referenceID": 15, "context": "Lowe [16] proposes the Difference-of-Gaussians (DoG) function to detect scalespace extrema in images.", "startOffset": 5, "endOffset": 9}, {"referenceID": 9, "context": "Previous researches have shown that accurate classification could be achieved by using densely extracted local features [10,23].", "startOffset": 120, "endOffset": 127}, {"referenceID": 22, "context": "Previous researches have shown that accurate classification could be achieved by using densely extracted local features [10,23].", "startOffset": 120, "endOffset": 127}, {"referenceID": 7, "context": "These normalizations are commonly used in image retrieval and classification based on histograms [8,9,19,22].", "startOffset": 97, "endOffset": 108}, {"referenceID": 8, "context": "These normalizations are commonly used in image retrieval and classification based on histograms [8,9,19,22].", "startOffset": 97, "endOffset": 108}, {"referenceID": 18, "context": "These normalizations are commonly used in image retrieval and classification based on histograms [8,9,19,22].", "startOffset": 97, "endOffset": 108}, {"referenceID": 21, "context": "These normalizations are commonly used in image retrieval and classification based on histograms [8,9,19,22].", "startOffset": 97, "endOffset": 108}, {"referenceID": 8, "context": "[9] and Perronin et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[19] show that reducing the influence of frequent codewords before `2 normalization could be profitable.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "They apply a power \u03b1 \u2208 [0, 1] on their global representation.", "startOffset": 23, "endOffset": 29}, {"referenceID": 8, "context": "5, which leads to near-optimal results [9,19].", "startOffset": 39, "endOffset": 45}, {"referenceID": 18, "context": "5, which leads to near-optimal results [9,19].", "startOffset": 39, "endOffset": 45}, {"referenceID": 10, "context": "To provide illustrative timings for our methods, we ran it on a personal computer, for a given set of parameters, using dataset Cricket X [11] that is made of 390 training time series and 390 test ones.", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "1 Experimental setup Experiments are conducted on the 86 currently available datasets from the UCR repository [11], the largest online database for time series classification.", "startOffset": 110, "endOffset": 114}, {"referenceID": 16, "context": "6 and ksc = 2 , as these values have shown to produce stable results [17].", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "The UCR repository provides error rates for the 86 datasets with Euclidean distance 1NN (EDNN) and Dynamic Time Warping 1NN (DTWNN) [20].", "startOffset": 132, "endOffset": 136}, {"referenceID": 2, "context": "We use published error rates for TSBF (45 datasets) [3], SAX-VSM (51 datasets) [21], SMTS (45 datasets) [2], PROP (46 datasets) [15] and BoP (20 datasets).", "startOffset": 52, "endOffset": 55}, {"referenceID": 20, "context": "We use published error rates for TSBF (45 datasets) [3], SAX-VSM (51 datasets) [21], SMTS (45 datasets) [2], PROP (46 datasets) [15] and BoP (20 datasets).", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "We use published error rates for TSBF (45 datasets) [3], SAX-VSM (51 datasets) [21], SMTS (45 datasets) [2], PROP (46 datasets) [15] and BoP (20 datasets).", "startOffset": 104, "endOffset": 107}, {"referenceID": 14, "context": "We use published error rates for TSBF (45 datasets) [3], SAX-VSM (51 datasets) [21], SMTS (45 datasets) [2], PROP (46 datasets) [15] and BoP (20 datasets).", "startOffset": 128, "endOffset": 132}, {"referenceID": 13, "context": "As BoP [14] only provides classification performance for 20 datasets, we decided not to plot pairwise comparison of error rates between D-BoTSW and BoP.", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "Error rates (ER) obtained with D-BoTSW are reported in Table 1, together with baseline scores publicly available at [11].", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "Moreover, more detailed global representations for sets of features than the standard BoW have been proposed in the computer vision community [9,18], and such global features could be used in our framework.", "startOffset": 142, "endOffset": 148}, {"referenceID": 17, "context": "Moreover, more detailed global representations for sets of features than the standard BoW have been proposed in the computer vision community [9,18], and such global features could be used in our framework.", "startOffset": 142, "endOffset": 148}], "year": 2017, "abstractText": "The SIFT framework has shown to be accurate in the image classification context. In [1], we designed a Bag-of-Words approach based on an adaptation of this framework to time series classification. It relies on two steps: SIFT-based features are first extracted and quantized into words; histograms of occurrences of each word are then fed into a classifier. In this paper, we investigate techniques to improve the performance of Bag-of-Temporal-SIFT-Words: dense extraction of keypoints and normalization of Bag-of-Words histograms. Extensive experiments show that our method significantly outperforms most state-of-the-art techniques for time series classification.", "creator": "LaTeX with hyperref package"}}}