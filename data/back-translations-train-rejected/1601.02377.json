{"id": "1601.02377", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2016", "title": "Implicit Look-alike Modelling in Display Ads: Transfer Collaborative Filtering to CTR Estimation", "abstract": "User behaviour targeting is essential in online advertising. Compared with sponsored search keyword targeting and contextual advertising page content targeting, user behaviour targeting builds users' interest profiles via tracking their online behaviour and then delivers the relevant ads according to each user's interest, which leads to higher targeting accuracy and thus more improved advertising performance. The current user profiling methods include building keywords and topic tags or mapping users onto a hierarchical taxonomy. However, to our knowledge, there is no previous work that explicitly investigates the user online visits similarity and incorporates such similarity into their ad response prediction. In this work, we propose a general framework which learns the user profiles based on their online browsing behaviour, and transfers the learned knowledge onto prediction of their ad response. Technically, we propose a transfer learning model based on the probabilistic latent factor graphic models, where the users' ad response profiles are generated from their online browsing profiles. The large-scale experiments based on real-world data demonstrate significant improvement of our solution over some strong baselines.", "histories": [["v1", "Mon, 11 Jan 2016 10:12:17 GMT  (857kb)", "http://arxiv.org/abs/1601.02377v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["weinan zhang", "lingxi chen", "jun wang"], "accepted": false, "id": "1601.02377"}, "pdf": {"name": "1601.02377.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Weinan Zhang", "Lingxi Chen", "Jun Wang"], "emails": ["w.zhang@cs.ucl.ac.uk", "lingxi.chen@cs.ucl.ac.uk", "j.wang@cs.ucl.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 160 1,02 377v 1 [cs.L G] 11 Jan 20"}, {"heading": "1 Introduction", "text": "According to IAB's 2014 Internet Advertising Revenue Report [22], 51% of the online advertising budget is spent on keyword targeting and contextual advertising, while 39% is spent on ad advertising (demographic user orientation and behavioural targeting), and the left 10% is spent on other ad formats such as classified ads. As ad exchanges [19] and mobile advertising increase, user targeting has become indispensable in online advertising. Compared with sponsored search or contextual advertising, user behavior is explicitly targeted to user profiles and recognises their interest segments through tracking of their online behavior, such as browsing history, search terms and ad clicks, etc. Based on user profiles, advertisers can identify users with similar interests in known customers and then deliver relevant ads to them. Such technology is referred to as \"modeling\" [17], which provides a higher level of advertising efficiency [17]."}, {"heading": "2 Related Work", "text": "Ad Response Prediction aims to predict the likelihood that a particular user will respond to an ad in a particular context [4,18]. Such a context can be either a search term [8], website content [2] or other types of real-time information related to the underlying user [31]. From a modeling perspective, many predictions are based on linear models, such as logistic regression [24,14] and Bayian probit regression [8]. Despite the advantage of high learning efficiency, these linear models suffer from the lack of feature interaction and combination [9]."}, {"heading": "3 Implicit Look-alike Modelling", "text": "In performance-driven online advertising, we usually have two types of observations of underlying user behavior: one based on their browsing behavior (interacting with websites) and one based on their ad responses, such as conversions or clicks, toward ad ads (interacting with ads). However, there are two predictive tasks for users to understand: - Web Browsing Prediction (CF task). Each user's online browsing behavior is logged as a list of previously visited publishers (domains or URLs). A common task of using the data is to use collaborative filtering (CF) [28.23] to infer the user profile that is then used to predict whether the user wants to visit a particular new publisher (domains or URLs). Formally, we refer to the dataset for CF as Dc and an observation is called (xc, yc, yc)."}, {"heading": "3.1 The Joint Conditional Likelihood", "text": "In our solution, the predictive models of the CF task and the CTR task are learned together. Specifically, we build a common framework for data discrimination. We designate the parameter set of the common model with the preceding P (B), and the conditional probability of an observed data instance is the probability of predicting the correct binary name taking into account the characteristics P (Y | X; E). As such, the conditional probability of the two data sets results in the probability of predicting the correct binary name P (Y, Y). Max imitation of an a posteriori (MAP) estimate results in the maximum probability of P (Y, Y), DcP (Y, Y), DcP (Y, Y), DCP (Y, Y) and not the previous estimation of the characteristics c (Y, Y), but the probability (Y, Y)."}, {"heading": "3.2 CF Prediction", "text": "For the CF task, we use a factoring machine [23] as our predictive model. We further define the characteristics xc (xu, xp), where xu \u2261 {xui} is the characteristic set for a user and xp \u2261 {xpj} is the weight vector of the Ic-dimensional user characteristics and the Jc-dimensional publisher characteristics. Each user characteristic xui or publisher characteristic x p is associated with a Dimensional Latent Vector vci or v c j. Thus, V c-dimensional latent vector c + Jc is the weight vector of the Ic-dimensional user characteristics and the Jc-dimensional publisher characteristics."}, {"heading": "3.3 CTR Task Prediction Model", "text": "For an instance of data (xr, yr) in the CTR task dataset Dr > u > r > r (xu, xp, xa), its properties can be divided into three categories: the user functions xu (cookie, location, time, device, browser, OS, etc.), the ad functions xp (domain, URL, etc.) and the ad functions xa (ad disk position, creative, creative size, campaign, etc.) Each feature has a potential impact on another in a different category. For example, a mobile phone user might prefer square ads to banner ads; users would like to click on the ad on the sports web pages during afternoon time.Just like the CF prediction, we use the factoring engine and the model parameter is therefore an influence parameter (wr0, w, V r, V r r)."}, {"heading": "3.4 Dual-Task Bridge", "text": "In order to model the interdependence between the two tasks, the weights of user characteristics and user characteristics in the CTR task are assumed to be generative; furthermore, they are assumed to be generated by the counterparts in the CF task (as a previous task). (8), where the latent vectors of the CTR task are generated from the counterparts of the CF task: vri N (v c i, 2 V d I), where i is the index of a user or a publisher. (2 V d is similarly defined.) The rationality behind the above model is that user interest in website content is relatively general and the ad page displayed can be regarded as a special type of website content."}, {"heading": "3.5 Learning the Model", "text": "In view of the detailed implementation of the MAP solution (equation (1)) components in equations (11) and (13) for each data instance (x, y), the gradient update of equations (3) and (6) for (xc, yc), (xr, yr) and (xr, yr) is Dr.), (14) where P (y | x; as well as (3) and (6) for (xc, yc), (xc) and (xr, yr). Dr, respectively; \u03b7 is the learning rate; \u03b2 is the instance weight parameter, depending on which task the instance belongs to, as specified in equation (11). The detailed gradient for each specific parameter can be routinely calculated and is omitted here due to the side limitation."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Dataset", "text": "Our experiments are conducted on the basis of a real data set provided by Adform, a global digital media advertising technology company based in Copenhagen, Denmark. It consists of two weeks of online ad logs of various campaigns in March 2015. Specifically, there are 42.1M user domain browsing events and 154.0K ad display / click events. To insert the data into the common model, we group useful data features into three categories: user characteristics xu (user cookie, hour, browser, OS, user agent and screen size), publisher characteristics xp (domain, URL, exchange, ad slot and slot size), ad characteristics xa (advertiser and campaign). Detailed unique ad numbers for each attribute are given below. Attributes user cookie hour browser o user agent screen size domain unique number 18170 1,140 unique ad number 180,637 48,355 unique attributes we have a relationship with a user-cookie hour browser o user-agent screen size domain unique number 1,170-48,465 unique attributes in each attribute:"}, {"heading": "4.2 Experiment Protocol", "text": "We are conducting a two-step experiment to verify the effectiveness of our proposed models. First, in a very clean environment, we are focusing only on user cookies and domains to verify that knowledge of user behavior when surfing web pages can be transferred to model their behavior when clicking on ads on these web pages. Second, we are starting to append various features in the first setting to observe the change in performance and to verify which features lead to better transfer learning. Specifically, we are trying to insert a single feature into the default setting: 1. appended user feature xu, 2. appended publisher feature xp, 3. appended ad feature xa. Finally, all features are incorporated into the model to perform transfer learning. For each trial phase, there are three data sets: CF data set (Dc), CTR data set (Dr) and Joint data set (Dc), each data set is split into two parts of the training data set."}, {"heading": "4.3 Evaluation Metrics", "text": "To evaluate the performance of the proposed model, the range below the ROC curve (AUC) [8] and the mean square error (RMSE) [13] are used as performance indicators. As we focus on improving ad click performance, we report only on the performance of the CTR estimation task."}, {"heading": "4.4 Compared Models", "text": "We implement the following models for experimental comparison. - Base: This basic model takes into account only the ad-CTR task, without any transfer learning. Parameters are learned by the max\u0443 method (xr, yr) and Dr-P (y-r-xr-\u044b) P method.2 It is common practice to perform negative down sampling to balance the labels in the ad-CTR estimation [9]. Calibration methods [3] are then used to eliminate the model bias."}, {"heading": "4.5 Result", "text": "Basic Setting Performance. Figure 2 shows the AUC and RMSE performance of Joint Base, Disjoint and Joint and the improvement of Joint over the hyperparameter \u03b1 in Eq. (11) based on the basic experiment setting. As can be clearly observed, Joint consistently outperforms the baselines base and disjoint on AUC and RMSE for a large region of \u03b1, i.e., [0,1, 0,7], demonstrating the effectiveness of our model to transfer knowledge from web browsing data to display data. Note that if \u03b1 = 0, the CF side model does not learn wc, but Joint still outperforms Disjoint and Base. This is due to the different precedence of wr and V r in Joint compared to those of Disjoint and Base.Moreover, if \u03b1 = 1, i.e. no learning on CTR task, the performance of Joint is back to the original estimate, i.e. both AUC and RMSE are."}, {"heading": "5 Conclusion", "text": "In this paper, we proposed a transfer-learning framework with factoring machines to create implicit, similar models for predicting user behavior, successfully transferring knowledge from the abundant data of surfing behavior on the user's website. The main novelty of this work lies in the joint training on the two tasks and the creation of knowledge transfer based on the nonlinear factorization machine model for creating the user profile and other functional profiles. Extensive experiments on a large real dataset demonstrated the effectiveness of our model and some insights into recognizing the specific characteristics that contribute to the transfer of learning. In future work, we plan to investigate the use of user profiles based on the learned latent vector for each user. We also plan to expand our model to include cross-domain referral problems."}, {"heading": "Acknowledgement", "text": "We thank Adform for allowing us to use their data in experiments, and Thomas Furmston for his feedback on the paper. Weinan thanks the Chinese Scholarship Council for supporting the research."}], "references": [{"title": "Scalable distributed inference of dynamic user interests for behavioral targeting", "author": ["A. Ahmed", "Y. Low", "M. Aly", "V. Josifovski", "A.J. Smola"], "venue": "KDD", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "A semantic approach to contextual advertising", "author": ["A. Broder", "M. Fontoura", "V. Josifovski", "L. Riedel"], "venue": "SIGIR. pp. 559\u2013566. ACM", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "An empirical comparison of supervised learning algorithms", "author": ["R. Caruana", "A. Niculescu-Mizil"], "venue": "ICML. pp. 161\u2013168. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Modeling delayed feedback in display advertising", "author": ["O. Chapelle"], "venue": "KDD. pp. 1097\u2013 1105. ACM", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "A simple and scalable response prediction for display advertising", "author": ["O Chapelle"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Transferring naive bayes classifiers for text classification", "author": ["W. Dai", "G.R. Xue", "Q. Yang", "Y. Yu"], "venue": "AAAI", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Scalable hands-free transfer learning for online advertising", "author": ["B. Dalessandro", "D. Chen", "T. Raeder", "C. Perlich", "M. Han Williams", "F. Provost"], "venue": "KDD", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Web-scale bayesian clickthrough rate prediction for sponsored search advertising in microsoft\u2019s bing search engine", "author": ["T. Graepel", "J.Q. Candela", "T. Borchert", "R. Herbrich"], "venue": "ICML. pp. 13\u201320", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Practical lessons from predicting clicks on ads at facebook", "author": ["X. He", "J. Pan", "O. Jin", "T. Xu", "B. Liu", "T. Xu", "Y. Shi", "A. Atallah", "R. Herbrich", "S Bowers"], "venue": "ADKDD. pp. 1\u20139. ACM", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Collaborative filtering via gaussian probabilistic latent semantic analysis", "author": ["T. Hofmann"], "venue": "SIGIR. pp. 259\u2013266. ACM", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Machine learning: discriminative and generative, vol", "author": ["T. Jebara"], "venue": "755. Springer Science & Business Media", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "3 idiots approach for display advertising challenge", "author": ["Y.C. Juan", "Y. Zhuang", "W.S. Chin"], "venue": "Internet and Network Economics, pp. 254\u2013265. Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": "Computer (8), 30\u201337", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Estimating conversion rate in display advertising from past performance data", "author": ["Lee", "K.c.", "B. Orten", "A. Dasdan", "W. Li"], "venue": "KDD. pp. 768\u2013776. ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Transfer learning for collaborative filtering via a ratingmatrix generative model", "author": ["B. Li", "Q. Yang", "X. Xue"], "venue": "ICML. pp. 617\u2013624. ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Logistic regression with an auxiliary data source", "author": ["X. Liao", "Y. Xue", "L. Carin"], "venue": "ICML. pp. 505\u2013512. ACM", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "A feature-pair-based associative classification approach to look-alike modeling for conversion-oriented user-targeting in tail campaigns", "author": ["A. Mangalampalli", "A. Ratnaparkhi", "A.O. Hatch", "A. Bagherjeiran", "R. Parekh", "V. Pudi"], "venue": "WWW. pp. 85\u201386. ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "The design of advertising exchanges", "author": ["R.P. McAfee"], "venue": "Review of Industrial Organization 39(3), 169\u2013185", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Ad exchanges: Research issues", "author": ["S. Muthukrishnan"], "venue": "Internet and network economics, pp. 1\u201312. Springer", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Predicting response in mobile advertising with hierarchical importance-aware factorization machine", "author": ["R.J. Oentaryo", "E.P. Lim", "D.J.W. Low", "D. Lo", "M. Finegold"], "venue": "WSDM", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 22(10), 1345\u20131359", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Factorization machines", "author": ["S. Rendle"], "venue": "ICDM. pp. 995\u20131000. IEEE", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Predicting clicks: estimating the clickthrough rate for new ads", "author": ["M. Richardson", "E. Dominowska", "R. Ragno"], "venue": "WWW. pp. 521\u2013530. ACM", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Riedl"], "venue": "WWW. pp. 285\u2013295. ACM", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Collaborative filtering recommender systems", "author": ["J.B. Schafer", "D. Frankowski", "J. Herlocker", "S. Sen"], "venue": "The adaptive web, pp. 291\u2013324. Springer", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Transfer learning for reinforcement learning domains: A survey", "author": ["M.E. Taylor", "P. Stone"], "venue": "J. Mach. Learn. Res. 10, 1633\u20131685", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Unifying user-based and item-based collaborative filtering approaches by similarity fusion", "author": ["J. Wang", "A.P. De Vries", "M.J. Reinders"], "venue": "SIGIR", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "How much can behavioral targeting help online advertising? In: WWW", "author": ["J. Yan", "N. Liu", "G. Wang", "W. Zhang", "Y. Jiang", "Z. Chen"], "venue": "pp. 261\u2013270. ACM", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "Coupled group lasso for web-scale ctr prediction in display advertising", "author": ["L. Yan", "W.J. Li", "G.R. Xue", "D. Han"], "venue": "ICML. pp. 802\u2013810", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Real-time bidding for online advertising: measurement and analysis", "author": ["S. Yuan", "J. Wang", "X. Zhao"], "venue": "ADKDD. p. 3. ACM", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Real-time bidding benchmarking with ipinyou dataset", "author": ["W. Zhang", "S. Yuan", "J. Wang"], "venue": "arXiv preprint arXiv:1407.7073", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 18, "context": "With the rise of ad exchanges [19] and mobile advertising, user behaviour targeting has now become essential in online advertising.", "startOffset": 30, "endOffset": 34}, {"referenceID": 16, "context": "Such technology is referred as look-alike modelling [17], which efficiently provides higher targeting accuracy and thus brings more customers to the advertisers [29].", "startOffset": 52, "endOffset": 56}, {"referenceID": 27, "context": "Such technology is referred as look-alike modelling [17], which efficiently provides higher targeting accuracy and thus brings more customers to the advertisers [29].", "startOffset": 161, "endOffset": 165}, {"referenceID": 0, "context": "topic distributions [1] or clustering users onto a (hierarchical) taxonomy [29].", "startOffset": 20, "endOffset": 23}, {"referenceID": 27, "context": "topic distributions [1] or clustering users onto a (hierarchical) taxonomy [29].", "startOffset": 75, "endOffset": 79}, {"referenceID": 30, "context": "Normally, these inferred user interest segments are then used as target restriction rules or as features leveraged in predicting users\u2019 ad response [32].", "startOffset": 148, "endOffset": 152}, {"referenceID": 27, "context": ", the user interest segments building, is performed independently and with little attention of its latter use of ad response prediction [29,7], which is suboptimal.", "startOffset": 136, "endOffset": 142}, {"referenceID": 6, "context": ", the user interest segments building, is performed independently and with little attention of its latter use of ad response prediction [29,7], which is suboptimal.", "startOffset": 136, "endOffset": 142}, {"referenceID": 3, "context": ", click) to an ad in a given context [4,18].", "startOffset": 37, "endOffset": 43}, {"referenceID": 17, "context": ", click) to an ad in a given context [4,18].", "startOffset": 37, "endOffset": 43}, {"referenceID": 7, "context": "Such context can be either a search keyword [8], webpage content [2], or other kinds of real-time information related to the underlying user [31].", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "Such context can be either a search keyword [8], webpage content [2], or other kinds of real-time information related to the underlying user [31].", "startOffset": 65, "endOffset": 68}, {"referenceID": 29, "context": "Such context can be either a search keyword [8], webpage content [2], or other kinds of real-time information related to the underlying user [31].", "startOffset": 141, "endOffset": 145}, {"referenceID": 22, "context": "From the modelling perspective, many user response prediction solutions are based on linear models, such as logistic regression [24,14] and Bayesian probit regression [8].", "startOffset": 128, "endOffset": 135}, {"referenceID": 13, "context": "From the modelling perspective, many user response prediction solutions are based on linear models, such as logistic regression [24,14] and Bayesian probit regression [8].", "startOffset": 128, "endOffset": 135}, {"referenceID": 7, "context": "From the modelling perspective, many user response prediction solutions are based on linear models, such as logistic regression [24,14] and Bayesian probit regression [8].", "startOffset": 167, "endOffset": 170}, {"referenceID": 8, "context": "Despite the advantage of high learning efficiency, these linear models suffer from the lack of feature interaction and combination [9].", "startOffset": 131, "endOffset": 134}, {"referenceID": 8, "context": "Thus non-linear models such as tree models [9] and latent vector models [30,20] are proposed to catch the data non-linearity and interactions between features.", "startOffset": 43, "endOffset": 46}, {"referenceID": 28, "context": "Thus non-linear models such as tree models [9] and latent vector models [30,20] are proposed to catch the data non-linearity and interactions between features.", "startOffset": 72, "endOffset": 79}, {"referenceID": 19, "context": "Thus non-linear models such as tree models [9] and latent vector models [30,20] are proposed to catch the data non-linearity and interactions between features.", "startOffset": 72, "endOffset": 79}, {"referenceID": 11, "context": "Recently the authors in [12] proposed to first learn combination features from gradient boosting decision trees (GBDT) and,", "startOffset": 24, "endOffset": 28}, {"referenceID": 21, "context": "based on the tree leaves as features, learn a factorisation machine (FM) [23] to build feature interactions to improve ad click prediction performance.", "startOffset": 73, "endOffset": 77}, {"referenceID": 24, "context": "Collaborative Filtering (CF) on the other hand is a technique for personalised recommendation [26].", "startOffset": 94, "endOffset": 98}, {"referenceID": 23, "context": "Besides the user(item)based approaches [25,28], latent factor models, such as probabilistic latent semantic analysis [10], matrix factorisation [13] and factorisation machines [23], are widely used model-based approaches.", "startOffset": 39, "endOffset": 46}, {"referenceID": 26, "context": "Besides the user(item)based approaches [25,28], latent factor models, such as probabilistic latent semantic analysis [10], matrix factorisation [13] and factorisation machines [23], are widely used model-based approaches.", "startOffset": 39, "endOffset": 46}, {"referenceID": 9, "context": "Besides the user(item)based approaches [25,28], latent factor models, such as probabilistic latent semantic analysis [10], matrix factorisation [13] and factorisation machines [23], are widely used model-based approaches.", "startOffset": 117, "endOffset": 121}, {"referenceID": 12, "context": "Besides the user(item)based approaches [25,28], latent factor models, such as probabilistic latent semantic analysis [10], matrix factorisation [13] and factorisation machines [23], are widely used model-based approaches.", "startOffset": 144, "endOffset": 148}, {"referenceID": 21, "context": "Besides the user(item)based approaches [25,28], latent factor models, such as probabilistic latent semantic analysis [10], matrix factorisation [13] and factorisation machines [23], are widely used model-based approaches.", "startOffset": 176, "endOffset": 180}, {"referenceID": 12, "context": "Such latent factors have good generalisation and can be leveraged to predict the users\u2019 preference on unobserved items [13].", "startOffset": 119, "endOffset": 123}, {"referenceID": 20, "context": "Transfer Learning deals with the learning problem where the learning data of the target task is expensive to get, or easily outdated, via transferring the knowledge learned from other tasks [21].", "startOffset": 190, "endOffset": 194}, {"referenceID": 5, "context": "It has been proven to work on a variety of problems such as classification [6], regression [16] and collaborative filtering [15].", "startOffset": 75, "endOffset": 78}, {"referenceID": 15, "context": "It has been proven to work on a variety of problems such as classification [6], regression [16] and collaborative filtering [15].", "startOffset": 91, "endOffset": 95}, {"referenceID": 14, "context": "It has been proven to work on a variety of problems such as classification [6], regression [16] and collaborative filtering [15].", "startOffset": 124, "endOffset": 128}, {"referenceID": 25, "context": "Different from multi-task learning, where the data from different tasks are assumed to drawn from the same distribution [27], transfer learning methods may allow for arbitrary source and target tasks.", "startOffset": 120, "endOffset": 124}, {"referenceID": 6, "context": "In online advertising field, the authors in a recent work [7] proposed a transfer learning scheme based on logistic regression prediction models, where the parameters of ad click prediction model were restricted with a regularisation term from the ones of user web browsing prediction model.", "startOffset": 58, "endOffset": 61}, {"referenceID": 6, "context": ", conversions or clicks, towards display ads (the interactions with the ads) [7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 26, "context": "A common task of using the data is to leverage collaborative filtering (CF) [28,23] to infer the user\u2019s profile, which is then used to predict whether the user is interested in visiting any given new publisher.", "startOffset": 76, "endOffset": 83}, {"referenceID": 21, "context": "A common task of using the data is to leverage collaborative filtering (CF) [28,23] to infer the user\u2019s profile, which is then used to predict whether the user is interested in visiting any given new publisher.", "startOffset": 76, "endOffset": 83}, {"referenceID": 4, "context": "The task is to build a click-through rate (CTR) prediction model [5] to estimate how likely it is that the user will", "startOffset": 65, "endOffset": 68}, {"referenceID": 12, "context": "Just like most solutions on CF recommendation [13,10] and CTR estimation [24,14], in this discriminative framework, \u0398 is only concerned with the mapping from the features to the labels (the conditional probabilities) rather than modelling the prior distribution of features [11].", "startOffset": 46, "endOffset": 53}, {"referenceID": 9, "context": "Just like most solutions on CF recommendation [13,10] and CTR estimation [24,14], in this discriminative framework, \u0398 is only concerned with the mapping from the features to the labels (the conditional probabilities) rather than modelling the prior distribution of features [11].", "startOffset": 46, "endOffset": 53}, {"referenceID": 22, "context": "Just like most solutions on CF recommendation [13,10] and CTR estimation [24,14], in this discriminative framework, \u0398 is only concerned with the mapping from the features to the labels (the conditional probabilities) rather than modelling the prior distribution of features [11].", "startOffset": 73, "endOffset": 80}, {"referenceID": 13, "context": "Just like most solutions on CF recommendation [13,10] and CTR estimation [24,14], in this discriminative framework, \u0398 is only concerned with the mapping from the features to the labels (the conditional probabilities) rather than modelling the prior distribution of features [11].", "startOffset": 73, "endOffset": 80}, {"referenceID": 10, "context": "Just like most solutions on CF recommendation [13,10] and CTR estimation [24,14], in this discriminative framework, \u0398 is only concerned with the mapping from the features to the labels (the conditional probabilities) rather than modelling the prior distribution of features [11].", "startOffset": 274, "endOffset": 278}, {"referenceID": 21, "context": "For the CF task, we use a factorisation machine [23] as our prediction model.", "startOffset": 48, "endOffset": 52}, {"referenceID": 7, "context": "To evaluate the performance of proposed model, area under the ROC curve (AUC) [8] and root mean square error (RMSE) [13] are adopted as performance metrics.", "startOffset": 78, "endOffset": 81}, {"referenceID": 12, "context": "To evaluate the performance of proposed model, area under the ROC curve (AUC) [8] and root mean square error (RMSE) [13] are adopted as performance metrics.", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "2 It is common to perform negative down sampling to balance the labels in ad CTR estimation [9].", "startOffset": 92, "endOffset": 95}, {"referenceID": 2, "context": "Calibration methods [3] are then leveraged to eliminate the model bias.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "\u2013 DisjointLR: The transfer learning model proposed in [7] is considered as stateof-the-art transfer learning methods in display advertising.", "startOffset": 54, "endOffset": 57}], "year": 2016, "abstractText": "User behaviour targeting is essential in online advertising. Compared with sponsored search keyword targeting and contextual advertising page content targeting, user behaviour targeting builds users\u2019 interest profiles via tracking their online behaviour and then delivers the relevant ads according to each user\u2019s interest, which leads to higher targeting accuracy and thus more improved advertising performance. The current user profiling methods include building keywords and topic tags or mapping users onto a hierarchical taxonomy. However, to our knowledge, there is no previous work that explicitly investigates the user online visits similarity and incorporates such similarity into their ad response prediction. In this work, we propose a general framework which learns the user profiles based on their online browsing behaviour, and transfers the learned knowledge onto prediction of their ad response. Technically, we propose a transfer learning model based on the probabilistic latent factor graphic models, where the users\u2019 ad response profiles are generated from their online browsing profiles. The large-scale experiments based on real-world data demonstrate significant improvement of our solution over some strong baselines.", "creator": "LaTeX with hyperref package"}}}