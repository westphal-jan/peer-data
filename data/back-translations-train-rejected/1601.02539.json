{"id": "1601.02539", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2016", "title": "Investigating gated recurrent neural networks for speech synthesis", "abstract": "Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feed-forward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.", "histories": [["v1", "Mon, 11 Jan 2016 17:54:53 GMT  (26kb,D)", "http://arxiv.org/abs/1601.02539v1", "Accepted by ICASSP 2016"]], "COMMENTS": "Accepted by ICASSP 2016", "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["zhizheng wu", "simon king"], "accepted": false, "id": "1601.02539"}, "pdf": {"name": "1601.02539.pdf", "metadata": {"source": "CRF", "title": "INVESTIGATING GATED RECURRENT NETWORKS FOR SPEECH SYNTHESIS", "authors": ["Zhizheng Wu", "Simon King"], "emails": ["zhizheng.wu@ed.ac.uk"], "sections": [{"heading": null, "text": "Index terms - speech synthesis, acoustic modelling, recursive network, gated recurrent network, long-term short-term memory"}, {"heading": "1. INTRODUCTION", "text": "Statistical parametric language synthesis (SPSS) has evolved steadily in its naturalness over the last decade, as the Blizzard Challenges series [1] demonstrates. However, the quality of synthetic language produced by SPSS is still far below that of natural human language and cannot compete with the best waveform selection systems [2]. As proposed in [3], acoustic modeling, which captures the complex relationship between linguistic and acoustic representations, is a central limiting factor and is at the heart of this work."}, {"heading": "1.1. Relation to prior work", "text": ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"}, {"heading": "1.2. The novelty of this work", "text": "We are trying to get a better understanding of the \"black box\" LSTM architecture, and our results lead us to propose a simplified architecture for speech modeling. First, we are giving an analysis of the \"Forge Gate\" and the memory cell in the LSTM architecture. Specifically, we are visualizing the activation of the Forge Gate to understand when the Forge Gate resets the state of the memory cell and how the Forge Gate relates to the language structure. Second, we are analyzing the importance of each LSTM component for speech synthesis and proposing a simplified architecture. To our knowledge, this is the first attempt to visually analyze the LSTM architecture in predicting a language parameter sequence. Second, we are analyzing the importance of each LSTM component for speech synthesis and proposing a simplified architecture."}, {"heading": "2. LONG SHORT-TERM MEMORY", "text": "Standard RNNs are difficult to train because of the known disappearing or exploding gradient problems [22, 23]. To address the problem of the disappearing gradient, the LSTM architecture was proposed, the basic idea of which was presented in [24]. However, the most common architecture was described in [25] and formulated as follows: it = \u03b4 (W ixt + R iht \u2212 1 + p i ct \u2212 1 + bi) ft = \u03b4 (W fxt + R fht \u2212 1 + p f ct \u2212 1 + bf) ct = ft ct \u2212 1 + it g (Wcxt + Rcht \u2212 1 + bc) ot = \u03b4 (W oxt + R oht \u2212 1 + po ct + bo) ht = ot g (ct) In these formulations, ft, ct, ot, and ht can prevent the entrance gate, cell gate, cell state, exit gate and block exit from being given time and the main exit given time."}, {"heading": "3. GATED RECURRENT NEURAL NETWORKS", "text": "In this section, we present several variants of the LSTM and propose a simplified version that only has the forget-me-not; it therefore has significantly fewer parameters and lower computing costs. Since all of these variants share the concept of a memory cell with gates with the LSTM, we will refer to them as gated recurrent neural networks."}, {"heading": "3.1. Four variants on the LSTM", "text": "To assess the importance of each component, we start with four variants of the LSTM architecture, each of which removes one component from the LSTM architecture so that we can understand how much each component contributes to performance. Differences to the vanilla LSTM are: \u2022 No Peep Holes (NPH): Set pi, pf, po to zero \u2022 No Input Gate (NIG): it = 1 \u2022 No-Forge-Gate (NFG): ft = 1 \u2022 No Output Gate (NOG): ot = 1In the NFG variant, the past cell state still contributes to the current cell state, but without being controlled or scaled by the Forge-Gate. Note that when you remove the input, forget or output gate, the number of parameters is reduced."}, {"heading": "3.2. Gated Recurrent Unit (GRU)", "text": "As an alternative to the LSTM, the Gated Recurrent Unit (GRU) architecture was proposed in [26]. In [27], it was found that the GRU performs better than the LSTM in some tasks. The GRU is formulated as follows: rt = \u03b4 (W rxt + R rht \u2212 1 + b r) zt = \u03b4 (W zxt + R zht \u2212 1 + b z) h-t = g (W hxt + rt (Rhht \u2212 1) + bh) ht = zt ht \u2212 1 + (1 \u2212 zt) h-tFrom these formulas, we can determine that the GRU architecture is similar to the LSTM, but without a separate memory cell. The GRU does not use peep hole connections and output activation functions, and combines the input and output to form an update gate to achieve an equilibrium between prior ht \u2212 1 activation and candidate activation h-t."}, {"heading": "3.3. Simplified LSTM (S-LSTM)", "text": "As we will see in the experiments reported in the next section, we can propose an even simpler variant that removes output gate, output gate, and peep hole connections and replaces the input gate with the forge gate in the form of 1 \u2212 ft. Thus, only the forge gate remains. This simplest variant can be written as follows: ft = \u03b4 (W fxt + R fht \u2212 1 + b f) ct = ft ct \u2212 1 + (1 \u2212 ft) g (Wcxt + Rcht \u2212 1 + bc) ht = g (ct) The simplified architecture is similar to the GRU except that it uses a memory cell state. The cell state is controlled only by the forge gate that oscillates between past cell state and current block input."}, {"heading": "4. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Experimental setup", "text": "The sampling rate was 48 kHz, and we used the STRAIGHT vocoder [28] to extract 60-dimensional Mel-Cepstral coefficients (MCCs), 25 band aperodities (BAPs) and basic frequencies (F0) on the log scale, all in a 5 ms frame step. All systems used the same acoustic characteristics. F0 was interpolated linearly before modeling, and a binary voiceless / voiceless characteristic was used to record intonation information. Dynamic characteristics for MCCs, BAPs, and F0 were also calculated, the acoustic characteristics were normalized before modeling, and the mean and variant range was restored in generation time."}, {"heading": "4.2. Analysis of LSTM", "text": "The averaged activations (over the 256 units) of the Forgegate as a function of the frame index are shown in Fig. 1. The red solid line is the averaged activation of the Forgegate; the blue dashed lines show phoneme boundaries. It is clear that the peaks of the Forgegate activation course show a strong agreement with the phoneme boundaries; within a phoneme, the contribution of past cell states decays linearly. Forgegate captures some important temporal structures of language; this is not surprising since the phoneme boundaries are explicitly represented in the linguistic characteristics entered. The memory cell should maintain its state over time [20] and could thus store the trend of the trajectory to be predicted. To analyze the relationship between the cell states and the MCC trajectories, we compressed the correlation between the cell states and the first cell state corresponding to the MCC-1 cell."}, {"heading": "4.3. Objective results", "text": "Although objective measures do not always correlate with human perception, they provide a way to fine-tune the systems and roughly predict the performance of the model. Objective results are given in Table 2. Compared to LSTM, NIG, NOG and NPH all achieve similar objective distortion, with significantly fewer parameters and shorter generation time: entry gate, exit gate and peep hole connections are not necessary. NFG significantly increases distortion: forget-me-not is important. This finding is in line with [20]. Although the GRU system achieves a similar performance to the LSTM system: although it has even fewer parameters, it achieves a similar performance to NIG, NOG or NPH. This is also consistent with studies on other tasks [27, 21]. Although S-LSTM slightly increases the distortion of the MCD from 4.14 dB to 4.19 dB compared to LSTM, it achieves a similar performance on other measurements."}, {"heading": "4.4. Subjective results", "text": "Subjective preference tests were conducted using 30 paid native English speakers and each listener was asked to listen to 20 pairs of synthesized expressions, the phrase being the same in both points within a pair and selected at random from the 72 test sets 1. For each pair, the listener was asked to choose which sounded more natural; a \"neutral\" option was allowed if the listener had no preferences.The preference results are in Table 1. Compared to the LSTM system, all systems except NFG have no significant preference difference.The NFG system only achieves a preference value of 20.3% when paired with the LSTM preferred in 74.3% of the time.As with the objective results in Table 2, we conclude that the Forgetgate is the only critical component in the LSTM architecture; the input gate, output gate and peep hole connections can be omitted."}, {"heading": "5. CONCLUSIONS", "text": "We have analyzed the Forge Gate and the cell state of the LSTM architecture and examined the performance of several variants of the LSTM. We conclude that: \u2022 The Forge Gate can learn the temporal structure of the language; its activation is highly consistent with telephone boundaries. \u2022 The memory cell maintains a state over time that corresponds to the shape of the trajectory to be predicted. \u2022 For this task, the Forge Gate is the only critical component of the LSTM; other components can be omitted without diminishing naturalness. From these results, we propose a simplified LSTM architecture that uses only the critical Forge Gate. The simplified LSTM has significantly fewer parameters than the vanilla LSTM, but achieves similar performance in both objective and subjective assessments."}, {"heading": "6. REFERENCES", "text": "In recent years, it has become clear that these two countries are a country in which it is a country in which it is not a state, but rather a country in which it is a state, in which it is not a state, in which it is a state, in which it is a country, in which it is a state, in which it is a state, in which it is a country, in which it is a country, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a country, in which it is a state, in which it is a state, in which it is a state, in which it is a state, in which it is a country, in which it is a state in which it is a state, in which it is a country, in which it is a state in which it is a state, in which it is a state, in which it is a country in which it is a state, in which it is a state, in which it is a country in which it is a state, in which it is a country in which it is a state, in which it is a state in which it is a state in which it is a state, in which it is a state in which it is a state in which it is a state in which it is a state, in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in which it is a state in"}], "references": [{"title": "Measuring a decade of progress in text-tospeech", "author": ["Simon King"], "venue": "Loquens, vol. 1, no. 1, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Unit selection in a concatenative speech synthesis system using a large speech database", "author": ["Andrew J Hunt", "Alan W Black"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 1996.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1996}, {"title": "Statistical parametric speech synthesis", "author": ["Heiga Zen", "Keiichi Tokuda", "Alan W Black"], "venue": "Speech Communication, vol. 51, no. 11, pp. 1039\u20131064, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Statistical parametric speech synthesis using deep neural networks", "author": ["Heiga Zen", "Andrew Senior", "Mike Schuster"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining a vector space representation of linguistic context with a deep neural network for text-to-speech synthesis", "author": ["Heng Lu", "Simon King", "Oliver Watts"], "venue": "Proc. the 8th ISCA Speech Synthesis Workshop (SSW), 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "On the training aspects of deep neural network (DNN) for parametric TTS synthesis", "author": ["Yao Qian", "Yuchen Fan", "Wenping Hu", "Frank K Soong"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Fusion of multiple parameterisations for DNN-based sinusoidal speech synthesis with multi-task learning", "author": ["Qiong Hu", "Zhizheng Wu", "Korin Richmond", "Junichi Yamagishi", "Yannis Stylianou", "Ranniery Maia"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards minimum perceptual error training for DNN-based speech synthesis", "author": ["Cassia Valentini-Botinhao", "Zhizheng Wu", "Simon King"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Multidistribution deep belief network for speech synthesis", "author": ["Shiyin Kang", "Xiaojun Qian", "Helen Meng"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep mixture density networks for acoustic modeling in statistical parametric speech synthesis", "author": ["Heiga Zen", "Andrew Senior"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Modelling acoustic feature dependencies with artificial neural networks: Trajectory-rnade", "author": ["Benigno Uria", "Iain Murray", "Steve Renals", "Cassia Valentini"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep neural networks employing multi-task learning and stacked bottleneck features for speech synthesis", "author": ["Zhizheng Wu", "Cassia Valentini-Botinhao", "Oliver Watts", "Simon King"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Minimum trajectory error training for deep neural networks, combined with stacked bottleneck features", "author": ["Zhizheng Wu", "Simon King"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence generation error (SGE) minimization based deep neural networks training for text-to-speech synthesis", "author": ["Yuchen Fan", "Yao Qian", "Frank K. Soong", "Lei He"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "An RNN-based prosodic information synthesizer for Mandarin text-to-speech", "author": ["Sin-Horng Chen", "Shaw-Hwa Hwang", "Yih-Ru Wang"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 6, no. 3, pp. 226\u2013239, 1998.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "An investigation of recurrent neural network architectures for statistical parametric speech synthesis", "author": ["Sivanand Achanta", "Tejas Godambe", "Suryakanth V. Gangashetty"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks", "author": ["Raul Fernandez", "Asaf Rendel", "Bhuvana Ramabhadran", "Ron Hoory"], "venue": "Proc. Interspeech, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "TTS synthesis with bidirectional LSTM based recurrent neural networks", "author": ["Yuchen Fan", "Yao Qian", "Fenglong Xie", "Frank K. Soong"], "venue": "Proc. Interspeech, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis", "author": ["Heiga Zen", "Hasim Sak"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Lstm: A search space odyssey", "author": ["Klaus Greff", "Rupesh Kumar Srivastava", "Jan Koutn\u0131\u0301k", "Bas R Steunebrink", "J\u00fcrgen Schmidhuber"], "venue": "arXiv preprint arXiv:1503.04069, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "An empirical exploration of recurrent network architectures", "author": ["Rafal Jozefowicz", "Wojciech Zaremba", "Ilya Sutskever"], "venue": "Proc. IEEE Int. Conf. on Machine Learning (ICML), 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Yoshua Bengio", "Patrice Simard", "Paolo Frasconi"], "venue": "IEEE Transactions on Neural Networks, vol. 5, no. 2, pp. 157\u2013 166, 1994.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1994}, {"title": "On the difficulty of training recurrent neural networks", "author": ["Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1211.5063, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Framewise phoneme classification with bidirectional lstm and other neural network architectures", "author": ["Alex Graves", "J\u00fcrgen Schmidhuber"], "venue": "Neural Networks, vol. 18, no. 5, pp. 602\u2013610, 2005.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1406.1078, 2014.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1412.3555, 2014.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Restructuring speech representations using a pitch-adaptive time\u2013frequency smoothing and an instantaneous-frequency-based F0 extraction: Possible role of a repetitive structure in sounds", "author": ["Hideki Kawahara", "Ikuyo Masuda-Katsuse", "Alain de Cheveign\u00e9"], "venue": "Speech communication, vol. 27, no. 3, pp. 187\u2013207, 1999.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1999}, {"title": "Speech parameter generation algorithms for HMM-based speech synthesis", "author": ["Keiichi Tokuda", "Takayoshi Yoshimura", "Takashi Masuko", "Takao Kobayashi", "Tadashi Kitamura"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2000.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "Statistical parametric speech synthesis (SPSS) has quite steadily advanced in naturalness in the past decade, as witnessed by the series of Blizzard Challenges [1].", "startOffset": 160, "endOffset": 163}, {"referenceID": 1, "context": "However, the quality of synthetic speech produced by SPSS is still far below that of the natural human speech, and cannot compete with the best unit selection systems, which concatenate waveforms [2].", "startOffset": 196, "endOffset": 199}, {"referenceID": 2, "context": "As suggested in [3], acoustic modelling, which captures the complex relationship between linguistic and acoustic representations, is a key limiting factor and is the focus of this work.", "startOffset": 16, "endOffset": 19}, {"referenceID": 3, "context": "In [4, 5, 6, 7, 8], feed-forward neural networks are employed to map a linguistic representation derived from input text directly to acoustic features.", "startOffset": 3, "endOffset": 18}, {"referenceID": 4, "context": "In [4, 5, 6, 7, 8], feed-forward neural networks are employed to map a linguistic representation derived from input text directly to acoustic features.", "startOffset": 3, "endOffset": 18}, {"referenceID": 5, "context": "In [4, 5, 6, 7, 8], feed-forward neural networks are employed to map a linguistic representation derived from input text directly to acoustic features.", "startOffset": 3, "endOffset": 18}, {"referenceID": 6, "context": "In [4, 5, 6, 7, 8], feed-forward neural networks are employed to map a linguistic representation derived from input text directly to acoustic features.", "startOffset": 3, "endOffset": 18}, {"referenceID": 7, "context": "In [4, 5, 6, 7, 8], feed-forward neural networks are employed to map a linguistic representation derived from input text directly to acoustic features.", "startOffset": 3, "endOffset": 18}, {"referenceID": 8, "context": "In [9], a deep belief network (DBN) was used to model the relationship between linguistic and acoustic representations jointly.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "In [10] and [11], mixture density networks (MDNs) and realvalued neural autoregressive density estimators (RNADEs) were proposed, respectively, to predict acoustic feature distributions given input linguistic features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [10] and [11], mixture density networks (MDNs) and realvalued neural autoregressive density estimators (RNADEs) were proposed, respectively, to predict acoustic feature distributions given input linguistic features.", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "To include temporal constraints, we proposed to include contextual information by stacking low-dimensional bottleneck features from multiple consecutive frames [12].", "startOffset": 160, "endOffset": 164}, {"referenceID": 12, "context": "Still in the DNN framework, minimum trajectory error training [13] or sequence error training criterion [14] have been proposed to minimise the utterance-level trajectory error rather than the frame-by-frame error.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Still in the DNN framework, minimum trajectory error training [13] or sequence error training criterion [14] have been proposed to minimise the utterance-level trajectory error rather than the frame-by-frame error.", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "In [15], a standard RNN was employed to predict prosodic information for speech synthesis.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "In [16], two variants on standard RNNs, the Elman RNN and clockwork RNN, were investigated for speech synthesis.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "In [17], an LSTM was employed to model the F0 contour.", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "In [18], a bidirectional LSTM was employed to map a sequence of linguistic features to the corresponding sequence of acoustic features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "In [19], an LSTM with a recurrent output layer was proposed to perform sequence mapping from linguistic to acoustic representations.", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "The analysis was inspired by the studies in [20, 21], and we focus on the speech synthesis application.", "startOffset": 44, "endOffset": 52}, {"referenceID": 20, "context": "The analysis was inspired by the studies in [20, 21], and we focus on the speech synthesis application.", "startOffset": 44, "endOffset": 52}, {"referenceID": 21, "context": "Standard RNNs are hard to train due to the well-known vanishing or exploding gradient problems [22, 23].", "startOffset": 95, "endOffset": 103}, {"referenceID": 22, "context": "Standard RNNs are hard to train due to the well-known vanishing or exploding gradient problems [22, 23].", "startOffset": 95, "endOffset": 103}, {"referenceID": 23, "context": "To address the vanishing gradient problem, the LSTM architecture was proposed, the basic idea of which was presented in [24].", "startOffset": 120, "endOffset": 124}, {"referenceID": 24, "context": "The most commonly used architecture was described in [25], and is formulated as,", "startOffset": 53, "endOffset": 57}, {"referenceID": 19, "context": "The central idea of the LSTM is the so-called memory cell c which maintains its state over time, and the gating units which are used to regulate the information flow into and out of the memory cell [20].", "startOffset": 198, "endOffset": 202}, {"referenceID": 19, "context": "However, as discussed in [20, 21], the architecture might not be optimal for all the tasks, and the relative importance of each component is not at all clear.", "startOffset": 25, "endOffset": 33}, {"referenceID": 20, "context": "However, as discussed in [20, 21], the architecture might not be optimal for all the tasks, and the relative importance of each component is not at all clear.", "startOffset": 25, "endOffset": 33}, {"referenceID": 25, "context": "As an alternative to the LSTM, the Gated Recurrent Unit (GRU) architecture was proposed in [26].", "startOffset": 91, "endOffset": 95}, {"referenceID": 26, "context": "In [27], the GRU was found to achieve better performance than the LSTM on some tasks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "The sampling rate was 48 kHz, and we used the STRAIGHT vocoder [28] to extract 60-dimensional Mel-Cepstral Coefficients (MCCs), 25 band aperiodicities (BAPs), and fundamental frequency (F0) on log-scale, all at 5-ms frame step.", "startOffset": 63, "endOffset": 67}, {"referenceID": 28, "context": "At generation time, maximum likelihood parameter generation algorithm [29] was applied to smooth parameter trajectories.", "startOffset": 70, "endOffset": 74}, {"referenceID": 19, "context": "The memory cell should maintains its state over time [20] and so could store the trend of the trajectory to be predicted.", "startOffset": 53, "endOffset": 57}, {"referenceID": 19, "context": "This finding is consistent with [20].", "startOffset": 32, "endOffset": 36}, {"referenceID": 26, "context": "This is also consistent with studies on other tasks [27, 21].", "startOffset": 52, "endOffset": 60}, {"referenceID": 20, "context": "This is also consistent with studies on other tasks [27, 21].", "startOffset": 52, "endOffset": 60}], "year": 2016, "abstractText": "Recently, recurrent neural networks (RNNs) as powerful sequence models have re-emerged as a potential acoustic model for statistical parametric speech synthesis (SPSS). The long short-term memory (LSTM) architecture is particularly attractive because it addresses the vanishing gradient problem in standard RNNs, making them easier to train. Although recent studies have demonstrated that LSTMs can achieve significantly better performance on SPSS than deep feedforward neural networks, little is known about why. Here we attempt to answer two questions: a) why do LSTMs work well as a sequence model for SPSS; b) which component (e.g., input gate, output gate, forget gate) is most important. We present a visual analysis alongside a series of experiments, resulting in a proposal for a simplified architecture. The simplified architecture has significantly fewer parameters than an LSTM, thus reducing generation complexity considerably without degrading quality.", "creator": "LaTeX with hyperref package"}}}