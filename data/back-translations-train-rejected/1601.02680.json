{"id": "1601.02680", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Dec-2015", "title": "Using SVM to pre-classify government purchases", "abstract": "The Brazilian government often misclassifies the goods it buys. That makes it hard to audit government expenditures. We cannot know whether the price paid for a ballpoint pen (code #7510) was reasonable if the pen was misclassified as a technical drawing pen (code #6675) or as any other good. This paper shows how we can use machine learning to reduce misclassification. I trained a support vector machine (SVM) classifier that takes a product description as input and returns the most likely category codes as output. I trained the classifier using 20 million goods purchased by the Brazilian government between 1999-04-01 and 2015-04-02. In 83.3% of the cases the correct category code was one of the three most likely category codes identified by the classifier. I used the trained classifier to develop a web app that might help the government reduce misclassification. I open sourced the code on GitHub; anyone can use and modify it.", "histories": [["v1", "Mon, 7 Dec 2015 02:34:43 GMT  (245kb,D)", "http://arxiv.org/abs/1601.02680v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["thiago marzag\\~ao"], "accepted": false, "id": "1601.02680"}, "pdf": {"name": "1601.02680.pdf", "metadata": {"source": "CRF", "title": "Using SVM to pre-classify government purchases", "authors": ["Thiago Marzag\u00e3o"], "emails": ["thiago.marzagao@cade.gov.br"], "sections": [{"heading": null, "text": "We cannot know whether the price paid for a ballpoint pen (code # 7510) was appropriate if the pen was misclassified as a technical pen (code # 6675) or as any other good. This essay shows how we can use machine learning to reduce misclassifications. I trained an SVM (Support Vector Machine) classifier that uses a product description as input and returns the most likely category codes as output. I trained the classifier on 20 million goods purchased by the Brazilian government between 1999-04-01 and 2015-04-02. In 83.3% of the cases, the correct category code was one of the three most likely category codes identified by the classifier. I used the trained classifier to develop a web app that could help the government reduce misclassification."}, {"heading": "1. Problem", "text": "The Brazilian government classifies the goods it purchases according to a particular taxonomy: the CATMAT (catalogue of materials). When the government buys a new product, the person responsible for the classification must select one of the 560 CATMAT classes. Cognitive stress is severe, especially if the person is new to CATMAT. 1Data scientist at Conselho Administrativo de Defesa Econo mica.ar Xiv: 160 1.02 680v 1 [cs.L G] 7D-Ecresult is a misclassification. For example, this price is too low for the 30,774 goods classified as wheeled vehicles (CATMAT class # 2320) between 1999-04-01 and 2015-04-02, 17,469 less than R $1,000 (US $250 after 2015-12-01).This price seems too low for a vehicle on wheels. When we inspect the product descriptions, we see that it is a misclassification: Spare parts # 2530, vehicles # 2510, are incorrect # 2510, vehicles are frequently mislabelled."}, {"heading": "2. Machine-based classification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Basic idea", "text": "The idea is to semi-automate the process: we want to suggest probable classes to the person who classifies the goods (the user of our app), and he or she can choose between the proposed classes or ignore them and choose another class. \"The user says that a public hospital buys insulin syringes. The hospital will then describe the product in detail on the invitation to submit an offer - say, as a\" disposable insulin syringe with 0.5 mL and ultra-thin (6mm) needle. \"The user feeds this description to the SVM classifier, who then suggests three CATMAT classes: # 6515 (medical and surgical equipment and supplies), # 6550 (supplies for medical diagnostics and testing), and # 6640 (laboratory equipment and supplies). The user chooses one of these classes or, alternatively, discards two classes that cannot be classified."}, {"heading": "2.2 Support Vector Machines", "text": "In this context, it should be noted that this project is a project which is, first and foremost, a project."}, {"heading": "3. Data", "text": "Before we set out, we must collect, clean and process the data. All the data are in the Comprasnet database.6 The descriptions are in the D-ITEM COMPRA table. CATMAT classes 8 are in the F-ITEM COMPRA table. A common key makes it possible to discard the cases whose description and / or class we leave. I have also discarded the cases that correspond to the benefits (about 10% of the total), because the benefits are too unique and idiotic."}, {"heading": "4. Results", "text": "Our SVM classifier achieved an accuracy of 83.3%.10 The errors seem to have two main causes: First, the misclassification in the training data. The SVM classifier learns from imperfect examples. As we have already discussed, half of the goods currently classified as wheeled vehicles (CATMAT Class # 2320) are actually spare parts (CATMAT Classes # 2510, # 2520, # 2530 and # 2590). Second, class frequency. CATMAT classes that are purchased more frequently tend to be classified more accurately by the SVM classifier. This is expected: There are more training samples for these classes, so the classifier has a greater number of descriptions to learn from. In fact, there is a negative linear correlation between class frequency and misclassification rate (-0.36, with p < 0.0001).11"}, {"heading": "5. Web app", "text": "The user interface is very simple: there is a single input form in which the user writes or inserts the description of the goods purchased (as shown, for example, on the invitation to submit bids), then clicks on \"Submit\" and is shown the three most likely CATMAT classes. In the following example, we entered the description of an air conditioner and received back three CATMAT classes: # 4120 (air conditioners), with a probability of 58%; # 4130 (air conditioning and cooling components), with a probability of 22%; and # 6550 (medical diagnostics and testing supplies), with a probability of 4%. Here is the first class - the most likely - the right one. 10The code I used can be found at http: / / thiagomarzagao.com / papers. See code for details on the model parameters."}], "references": [{"title": "Natural Language Processing with Python.", "author": ["Bird", "Steven", "Edward Loper", "Ewan Klein"], "venue": null, "citeRegEx": "Bird et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bird et al\\.", "year": 2009}, {"title": "A training algorithm for optimal margin classifiers.", "author": ["Boser", "Bernhard", "Isabelle Guyon", "Vladimir Vapnik"], "venue": "Proceedings of the Annual Conference on Computational Learning", "citeRegEx": "Boser et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Boser et al\\.", "year": 1992}, {"title": "Support vector networks.", "author": ["Cortes", "Corrina", "Vladimir Vapnik"], "venue": "Machine Learning,", "citeRegEx": "Cortes et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 1995}, {"title": "The elements of statistical learning: data mining, inference, and prediction", "author": ["Hastie", "Trevor", "Robert Tibshirani", "Jerome Friedman."], "venue": "Springer.", "citeRegEx": "Hastie et al\\.,? 2009", "shortCiteRegEx": "Hastie et al\\.", "year": 2009}, {"title": "Introduction to information retrieval", "author": ["Manning", "Raghavan", "Prabhakar Raghavan", "Hinrich Sch\u00fctze."], "venue": "Cambridge University.", "citeRegEx": "Manning et al\\.,? 2008", "shortCiteRegEx": "Manning et al\\.", "year": 2008}, {"title": "Scikit-learn: Machine Learning in Python", "author": ["Pedregosa"], "venue": "Journal of Machine Learning Research, 12: 2825-2830.", "citeRegEx": "Pedregosa,? 2011", "shortCiteRegEx": "Pedregosa", "year": 2011}, {"title": "Probabilistic outputs for support vector machines and comparison to regularized likelihood methods", "author": ["Platt", "John."], "venue": "A.J. Smola, P.L. Bartlett, B. Sch\u00f6lkopf, and D. Schuurmans, editors, Advances in Large Margin Classifiers. MIT Press.", "citeRegEx": "Platt and John.,? 2000", "shortCiteRegEx": "Platt and John.", "year": 2000}, {"title": "Pattern recognition using generalized portrait method.", "author": ["Vapnik", "Vladimir", "Aleksandr Lerner"], "venue": "Automation and Remote Control,", "citeRegEx": "Vapnik et al\\.,? \\Q1963\\E", "shortCiteRegEx": "Vapnik et al\\.", "year": 1963}, {"title": "Probability estimates for multi-class classification by pairwise coupling.", "author": ["Wu", "Ting-Fan", "Chih-Jen Lin", "Ruby Weng"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Wu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2002}], "referenceMentions": [], "year": 2016, "abstractText": "The Brazilian government often misclassifies the goods it buys. That makes it hard to audit government expenditures. We cannot know whether the price paid for a ballpoint pen (code #7510) was reasonable if the pen was misclassified as a technical drawing pen (code # 6675) or as any other good. This paper shows how we can use machine learning to reduce misclassification. I trained a support vector machine (SVM) classifier that takes a product description as input and returns the most likely category codes as output. I trained the classifier using 20 million goods purchased by the Brazilian government between 1999-04-01 and 2015-04-02. In 83.3% of the cases the correct category code was one of the three most likely category codes identified by the classifier. I used the trained classifier to develop a web app that might help the government reduce misclassification. I open sourced the code on GitHub; anyone can use and modify it.", "creator": "LaTeX with hyperref package"}}}