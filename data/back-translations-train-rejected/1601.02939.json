{"id": "1601.02939", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jan-2016", "title": "The minimal hitting set generation problem: algorithms and computation", "abstract": "Finding inclusion-minimal \"hitting sets\" for a given collection of sets is a fundamental combinatorial problem with applications in domains as diverse as Boolean algebra, computational biology, and data mining. Much of the algorithmic literature focuses on the problem of *recognizing* the collection of minimal hitting sets; however, in many of the applications, it is more important to *generate* these hitting sets. We survey twenty algorithms from across a variety of domains, considering their history, classification, useful features, and computational performance on a variety of synthetic and real-world inputs. We also provide a suite of implementations of these algorithms with a ready-to-use, platform-agnostic interface based on Docker containers and the AlgoRun framework, so that interested computational scientists can easily perform similar tests with inputs from their own research areas on their own computers or through a convenient Web interface.", "histories": [["v1", "Tue, 5 Jan 2016 19:24:25 GMT  (814kb,D)", "http://arxiv.org/abs/1601.02939v1", null]], "reviews": [], "SUBJECTS": "cs.DS cs.AI cs.CC", "authors": ["andrew gainer-dewar", "paola vera-licona"], "accepted": false, "id": "1601.02939"}, "pdf": {"name": "1601.02939.pdf", "metadata": {"source": "CRF", "title": "The minimal hitting set generation problem: algorithms and computation", "authors": ["Andrew Gainer-Dewar", "Paola Vera-Licona"], "emails": [], "sections": [{"heading": null, "text": "Much of the algorithmic literature focuses on the problem of detecting the collection of minimal hit sets, but in many applications it is more important to generate these hit sets. We study twenty algorithms across a wide range of areas, taking into account their history, classification, useful features and computing power using a variety of synthetic and real inputs. We also offer a range of implementations of these algorithms with a ready-to-use platform agnostic interface based on Docker containers and the AlgoRun framework, so interested computer scientists can easily perform similar tests with inputs from their own research fields on their own computers or via a convenient web interface."}, {"heading": "1 Introduction", "text": "Attach a family S of sentences S1, S2,.. A percussive sentence T of S is a sentence that intersects each of the sentences Si; T is a minimum percussive sentence (hereinafter \"MHS\") when no proper subset of T is a percussive sentence of S. The problem of generating the collection of MHSes for a particular sentence family is of interest in a variety of areas, and it has been explicitly investigated (among a variety of names) in the contexts of combinatorics (Section 2.1, [1]), Boolean algebra (Section 2.2, [2, 3, 4]), error diagnosis (Section 2.3, 6, 8, 9, 10, 11]), data mining (Section 2.5, 13, 14, 15]), and computational biology (Section 2.4, [16, 18, 19, 20, 21]), among others."}, {"heading": "2 Cognate problems", "text": "There are many important issues in numerous areas that can be reduced or translated into MHS issues."}, {"heading": "2.1 Combinatorics", "text": "A hypergraph is simple when none of its edges is a subset of any other edge. Of course, the hypergraph H = (V, E) can be identified with the set family E, so the theory of the hypergraph is similar to that of the set families. Readers interested in the complete theory of the hypergraph should examine Berge Monograph 1984 [22]. The hypergraph H = (V, E) can, of course, be identified with the set family E, so that the theory of the hypergraph is similar to that of the set families. Readers interested in the complete theory of the hypergraph should examine Berge Monograph 1984 [22] on the subject. In the finite hypergraph setting, a (minimum) striking set of E is called the (minimum) transverse property of H. The collection of all the transversals of H is its transverse hypergraph TrH. TrH is sometimes also referred to as the dual of H, because in the case that is simple, Trr (H)."}, {"heading": "2.2 Boolean algebra", "text": "The fact is that we will be able to find ourselves in the position we are in."}, {"heading": "2.3 Model-based fault diagnosis", "text": "Modern technical systems can include an incredible number of interconnected components; for example, the recently retired NASA Space Shuttle reportedly had over 2.5 million moving parts. If such a system does not function as intended, it is not possible to verify or replace each part and each connection; therefore diagnostic procedures are required to limit attention to a subset of components that may have caused the observed failure. In a celebrated 1987 paper [5], Reiter developed the basis for a formal theory of model-based diagnosis (MBD), which we will briefly introduce. Consider a system consisting of some finite V components, each of which may be either active or inactive during a particular transaction or activity. We perform a series of observations of the transactions of the system, recording which components are active and whether the behavior is normal or abnormal. If any of the observed transactions is abnormal, we assume that these transactions are due to one or more components being defective."}, {"heading": "2.4 Computational biology", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "2.5 Data mining", "text": "A number of problems in data mining can be formalized in relation to the MHS generation. We examine two of them here. (In) frequent item set discovery A fundamental problem in data mining, introduced by Agrawal et al. in [33] and further developed in [34], is the discovery of common item sets in a database of transactions. We assume the formal setting of the problem presented by Boros et al. in [35]. Attach a finite set A of m transactions, each of which is a finite subset of a set of n items. Attach an integral threshold of 1 \u2264 t \u2264 m. A set of items is t-frequent when at least t transactions are supersets of C and t-uncommon transactions. Each one of these is a finite subset of a set of n items. Attach an integral threshold threshold of 1 \u2264 t \u2264 m. A set of items is t-frequent when at least t transactions are supersets of C and t-uncommon transactions are minimum. Each of them is a finite subset of a set of n items. Attach an integral threshold threshold of 1 \u2264 t \u2264 t \u2264 m. A set of items is t-frequent when at least t transactions are supersets of C and t-uncommon transactions are minimum."}, {"heading": "2.6 Minimal Sudoku puzzles", "text": "The Sudoku puzzle family is widely used in newspapers and magazines and is played by millions of families worldwide. A Sudoku instance is a 9 x 9 grid of cells, some of which already contain digits (\"clues\") from the range 1-9; one solution is to match digits to the remaining cells so that each of the nine 3 x 3 grid cells and each row and column of the entire puzzle contains each digit exactly once. An example of seventeen clues is in Fig. 1. Of course, not every possible placement of clues in the grid results in a valid puzzle. There may be inherent contradictions, e.g. two identical clues in the same column, so that the puzzle has no solutions. There may also be ambiguities where more than one solution is possible. A mathematical question of particular interest then is: What is the smallest number of clues in a uniquely valid Sudoku puzzle? Many of these puzzles with 17 clues are then known, but never identified with 16 clues."}, {"heading": "3 Complexity results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Asymptotic complexity", "text": "Before considering specific algorithms for the MHS generation, we should consider the current state of knowledge about the asymptotic complexity of the problem. Since Karp's groundbreaking 1972 paper [42], it has been known that the problem of determining whether a particular set family has a hit set no larger than a few k is NP-complete. However, we are more concerned with capturing all the hit sets than with the existence of a single one, so we are looking at two other separate but related problems."}, {"heading": "3.1.1 Recognition problem", "text": "Much of the literature on complexity analysis focuses on \"decision problems,\" which must be answered with \"yes\" or \"no.\" In [4], Fredman and Khachiyan present an algorithm (discussed in Section 4.2.2) that does not check this temporally (logn) (for n the sum of the hyperedges in F and G. This time limit is remarkable in that it is quasi-polynomic - it is worse than a polynomic limit, but better than an exponential limit, or even certain sub-exponential limits. The BM algorithm introduced by Boros and Makino in [43] improves this limit in parallel cases. It has long been an open problem to determine whether detection is possible in polynomial time."}, {"heading": "3.1.2 Generation problem", "text": "s look at the example of the matching graph Mn = {(1, 2), (3, 4),.., (2n \u2212 1, 2n)} as a set of family. A minimum hit set contains the choice of one of the two elements of each edge; therefore, there are obviously 2n of them. Therefore, simply writing this result takes at least o (2n) time, so no algorithm can generally execute polynomial time in sub-exponential time. This is not necessarily to say that the MHS generation problem is insolvable; rather, it suggests that it is inappropriate to analyze its complexity input-polynomially by introducing polynomiality exclusively in relation to the input size.Johnson et al. Algorithm has introduced a formalism to deal with this problem."}, {"heading": "3.2 Tractable cases", "text": "Crucially, the complexity results in Section 3.1 concern the performance of algorithms in general, i.e. for the class of all possible hypergraphs or set families. Another strand of research focused on demonstrating that substantially better complexity results are possible in such limited cases."}, {"heading": "3.2.1 Fixed-parameter tractability", "text": "In some cases, algorithms are available that \"hide\" part of the complexity of the problem with respect to a particular parameter of the hypergraph. If we use k as the parameter of interest and n as the number of edges of the hypergraph, we can find an algorithm that generates all MHSes in the time f (k) \u00b7 nO (1) for any function f (i.e., the time is polynomic in n as soon as k is fixed, although it can be arbitrarily dependent on k). In this case, we say that the problem with respect to this parameter k is tractable with fixed parameters (\"FPT\"), since the fixation k yields a complexity function that polynomically depends on the results of tractability without fixed parameters, for the problem of transverse hypergraph detection with a variety of parameters, including vertex parameters ([46, 3, 47, 47, 47, 48, the hyper set, or other parameters] [the intersection size] [48] and the intersection size."}, {"heading": "3.2.2 Acyclicity", "text": "A graph is acyclic if it contains no cycles - that is, if no non-repetitive path in the edges leads back to where it begins. Beeri et al. introduced [52], in the context of the investigation of relational database schemas, a concept of cyclicity in hypergraphs that is now known as \u03b1-cyclicality. Fagin subsequently introduced [53] the terms \u03b2-cyclicity and \u03b3-cyclicality, which are successively more restrictive and correspond to desirable traceability problems in databases. Eiter showed that transversal detection in polynomial time is solvable for \u03b2-acyclic hypergraphs in [54] and for \u03b1-acyclic hypergraphs in [49]."}, {"heading": "3.3 Limited nondeterminism", "text": "Another important question for complexity studies is how their solution improves with non-determinism - i.e., whether the algorithm is given access to some \"free\" information - and the crucial question is how many non-deterministic bits are required to achieve a better solution. Kavvadias and Stavropoulos showed in [55] that the detection problem is in the class co-NP [log2 n] for n of the total number of edges in H and TrH, which means that only O (log2 n) non-deterministic bits are needed to show that two hypergraphs are not transversals from each other. Since log2 n is subpolynmic, this suggests that the detection problem is not as severe as the known NP-complete problems."}, {"heading": "4 Existing algorithms", "text": "A wide range of algorithms is designed to generate MHSes (either explicitly or in the language of the various related issues). If we knit away the details of the different domains and applications by casting all algorithms in the language of the MHS generation, we find that they naturally fall into a few high-level categories: specify iteration applications that work through the input set family one sentence at a time, build MHSes as they go; divide and conquer approaches that divide the input family into fragmented subfamilies, find their MHSes separately, and then combine them; MHS approaches that build candidate MHSes one element at a time by tracking the un-hit sets as they go; and complete coverage approaches that enhance the divide-and-cross approach with a technical hypergram that allows for a more efficient recombination solution. We examine these categories, including some published algorithms for each one."}, {"heading": "4.1 Set iteration approaches", "text": "One kind of approach to calculating sets of a set family S is to start with a small subfamily of S \"(S, find the MHS for S,\" and then iteratively add more sets to S \"and update the MHS collection. The methods in this section all follow this approach; they differ in the way they select the subfamilies S\" and in the details of how they update the MHS collection."}, {"heading": "4.1.1 Berge (1984)", "text": "In fact, most of them are able to abide by the rules that they have established in their country of origin."}, {"heading": "4.1.3 Wotawa (2001)", "text": "Wotawa returned to Reiter's approach in [8], reviewed the HS-DAG algorithm of [60] (see Section 4.1.2) and adjusted it to reduce the number of required set containment checks. These improvements make the DAG generalization unnecessary, so that the underlying data structure is again a turnpike, as originally intended by Reiter. We will call the algorithm HST (for Hitting Set Tree). Authors are not aware of any formal complexity analysis of this algorithm. It is only possible to use HST to search for turnpike of limited cardinality by simply limiting the depth of the search tree. A Python implementation of this algorithm by the authors of [7] is available in the repository."}, {"heading": "4.1.4 Dong and Li (2005)", "text": "Although their work was largely independent of the literature on hypergraph transversals, they developed an algorithm that is thematically very similar to Berge. Their algorithm contains some optimizations for minimizing in Equation (2) to speed up the loop step. We will refer to the algorithm as DL (for its authors). However, the runtime of Berge is dominated by the need to search the intermediate transversals, not by the complexity of their generation, so DL optimization should not be expected to improve the worst-case behavior of Bergen. Hagen shows in [2, 45] that Takata's time limits on mountains in [59] also apply to DL, so it is not output polynomia. Nevertheless, DL optimization works well for families with relatively few sentences, so it is useful as a subroutine for the use of other algorithms."}, {"heading": "4.1.6 Kavvadias and Stavropoulos (2005)", "text": "Returning to the explicit study of hypergraph transversals, Kavvadias and Stavropoulos introduced in [62] another algorithm that aims to reduce the memory requirements of mountains by two optimizations. Firstly, they process the input-set family to combine elements that only occur in the same sets. Secondly, they carefully reorganize the processing steps so that many intermediate steps can be forgotten without compromising the correctness of the algorithm, so that they can output MHSes early in the course of the algorithm and then discard them. We will call this algorithm KS (for its authors). Furthermore, the algorithm is designed to run in polynomic memory by avoiding the regeneration of candidates that meet sets. Hagen shows in [2, 45] that KS does not run in the output polynomial time. Furthermore, it shows that its complexity (the log family is not the log-where the log-in the set is)."}, {"heading": "4.2 Divide and conquer approaches", "text": "Another way to calculate the MHS of a set family S is to divide S into several subfamilies, find their MHS separately (possibly recurring until the subfamilies are sufficiently small), and then combine the results. Algorithms in this section all follow this approach; they differ primarily in how they partition S."}, {"heading": "4.2.1 Lin and Jiang (2003)", "text": "In [9], Lin and Jiang return to the problem of model-based diagnosis. They put the problem within the boolean algebra framework, but their algorithm is a simple example of the approach of sharing and conquering. We will refer to this algorithm as BOOL (since Lin and Jiang call it the \"Boolean algorithm\"), and its recursive decomposition algorithm proceeds as follows. 1. Let S be a finite set family. If | S | < 2, it is trivial to find the MHSes of S directly. Therefore, we assume that | S | \u2265 2.2. If there is an element e that is present in every sentence s \u00b2 S, we construct a new set family S \u00b2. Recursively, we find the MHSes of S \u00b2, we add the MHSes of S \u00b2 and return the algorithms of S \u00b2. 3. If there is a set of s \u00b2 s, we leave the unique element S \u00b2 and a new set family S \u00b2."}, {"heading": "4.2.2 Fredman and Khachiyan (1996)", "text": "The two algorithms both proceed by selecting an element that does not contain that element separately with recursive calls, and then combining the results with each other. However, they first apply several algebraically motivated degeneration tests. However, if they are successful, an element can be found that is present in many (specifically: logarithmically many) sets but missing from many others. Considering the sets that do not contain this element separately, the problem is broken down into two large disjunctive sub-problems that can be viewed recursively; the large size of each sub-problem ensures that the recursion does not go too deep."}, {"heading": "4.2.3 Abreu and Gemund (2009)", "text": "Abreu and Gemund have presented such an algorithm in [10], using an approach similar to that of BOOL, but looking at the elements in a sequence determined by statistical heuristics, and also defining mechanisms to stop the algorithm at an early stage to obtain a subset of approximately minimum strokes. We will call this algorithm STACCATO (the name used by its authors in [10]).The authors of [10] claim that for a sentence family with N sentences and M total elements, the algorithm guarantees to find a strokes of cardinality sets C in O (((M \u00b7 (N + logM))) C. The authors of Worst-case time and O (C \u00b7 M) space, where the expected times are determined on the basis of their heuristic and experimentally tested algorithms, find a strokes of cardinality sets C in O (M \u00b7 N (+ M) C)."}, {"heading": "4.2.5 Knuth (2011)", "text": "Binary decision diagrams (BDDs) are a graph-based structure for displaying Boolean functions and hypergraphs originally introduced by Bryant in [66]. Given a specified S family, it is mathematically expensive to compress S into a BDD or to decompress this BDD back to S. Nevertheless, BDDs are a powerful data structure for certain combinatorial algorithms. Many logical operations on hypergraphs, such as the \"and\" operations of definition 4.1, are inexpensive to perform on their BDDs. In Exercises 236 and 237 of [67, paragraph 7.1.4], Knuth asks the reader to develop an algorithm for generating MHS using BDD operations, and in the solutions he presents, a simple one. We refer to this algorithm as Knuth. The authors are not aware of any formal complexity analysis of KNUTH, and Knuth claims that the worst possible runtime is unknown."}, {"heading": "4.2.6 Toda (2013)", "text": "In 2013, Toda improved the KNUTH algorithm in [68] by inserting a variation of the BDD data structure - the Zero-suppressed Binary Decision Diagram (ZDD). After compressing a given set of family S into a ZDD, Toda recursively applies a simple Divide-and-Conquer algorithm to obtain a BDD of all hit groups of S. He then uses a minimization algorithm to obtain a ZDD of the MHSes of S, which he eventually decompresses. We will refer to this algorithm as HTC-BDD (the name given to him by Toda).Toda gives a formal complexity analysis of HTC-BDD in [68], but the resulting limits are expressed in terms of the intermediate values of BDD and ZDD data structures, and are with limits such as those known for FK-A and FK-B-compression, not to exceed the list of DD, where it is interesting to consider the DD output of a very DD."}, {"heading": "4.2.7 Cardoso and Abreu (2014)", "text": "Cardoso and Abreu have revised the STACCATO approach in [6]. They present several optimizations to reduce wasteful computation. In addition, their new algorithm is being disseminated using the widely used Map Reduce paradigm, so that in principle it can be used on very large distributed computer systems that forward messages. It is also designed so that early termination provides a useful approximate result; a collection of hits is obtained, although they may not be minimal and some are missing. We will refer to this algorithm as MHS2 (the name given to it by the authors).The authors are not aware of any formal analysis of the complexity of MHS2. A C + + implementation of the algorithm by the authors of [6] is available in the repository."}, {"heading": "4.3 MHS buildup approaches", "text": "The third type of approach to calculating MHSes in a specified family S is to construct sets of elements that are expected or guaranteed to be subsets of MHSes, then the elements are added until they are set on sets.This approach fits into the standard scheme of \"traceability\" of combinatorial algorithms. The approaches in this section all follow this approach; they differ primarily in the conditions used to identify the problem of the MHS generation and the strategies used to avoid redundant calculations. (2007) H\u00e9bert et al. Let's take an approach in [69] that brings insights from data extraction to bear the problem of the MHS generation. We follow the explanation of the algorithm in [70] that avoids the algebraic complexity of the originals. We will refer to this algorithm as MTMiner (the name given to its software by its authors); it is also called Breto, and Hr\u00e9x (for any literature)."}, {"heading": "4.3.2 Murakami and Uno (2014)", "text": "Murakami and Uno take a slightly different approach in [61] two new algorithms. We refer to these algorithms as MMCS and RS (the names given to them by their authors), both relying on a crucial observation that enables an efficient bottom-up search for minimum perceptions. First, we need two definitions. For a given set of sentences S, a sub-MHS is a sentence M that contains a subset of some MHS of S. For a given group E of elements of S, an element e-HSE is crucial in E if there is at least one sentence s-S that contains e but no other elements of E.Then we have the following statement that appears in various forms in cf. [69, 61]: A sentence M of elements of a sentence family S is a sub-MHS if and only if each m-MHS is critical in M."}, {"heading": "4.4 Full cover approaches", "text": "A fourth approach to tackling the problem is indeed possible. (...) A first step in the right direction is done. (...) A second step in the right direction is done. (...) A third step in the right direction is done. (...) A third step in the right direction is done. (...) A first step in the right direction is done. (...) A second step in the right direction is done. (...) A third step in the right direction is done. (...) A third step in the right direction is done. (...) A third step in the right direction is done. (...) A third step in the right direction is done. (...) A third step in the right direction is done. \"(...) A third step in the right direction is done.\" (...) A third step in the right direction. \"(...) A third step in the right direction.\" (...) A third step in the other direction. \"(...) A third step in the other direction.\" (...) A third step in the right direction. \""}, {"heading": "4.4.2 Elbassioni (2008)", "text": "Following [50, 46] Elbassioni presents two parallel decomposition approaches to the problem of transversal recognition in [71]. The first is essentially a rearrangement of FK-B to make the search tree wider and flatter so that the parallel calculation is efficient; the second is a variant of a complete decomposition algorithm; in a transverse T of a hypergraph H with vertex replacement V, it will under certain circumstances use C (T) = {V\\ {i} | i {T} (4) as a complete cover of TrH to dissect the problem. (It also takes into account a special case similar to the FK algorithms.) We will refer to this algorithm as pELB (for the parallel algorithm of Elbassioni).Elbassioni shows that this algorithm runs in polylogarithmic time, so that it reduces the polylogarithm in quasipolynomial space for any hypergraph."}, {"heading": "4.4.3 Boros and Makno (2009)", "text": "Boros and Makino present in [43] a complete coverage algorithm that improves the asymptotic complexity limits of [71] for transversal detection. To do this, in addition to the one in Equation (4), they introduce another complete cover that they integrate into a FK-like recursive framework for duality testing. Attach a hypergraph H and an edge e-H; then Boros and Makino can achieve very strong limits for the parallel runtime. We will call this algorithm pBM (for the parallel algorithm of Boros and Makino) by carefully selecting when to use a full cover of Equation (4) or Equation (5). Attach a hypergraph H with n-corners and x-edges for which TrH has very strong edges."}, {"heading": "4.5 Other", "text": "Some authors have used approaches that translate the problem of the MHS generation into other areas for which special algorithms already exist."}, {"heading": "4.5.1 Primary decomposition of squarefree monomial ideals", "text": "The MHS generation problem can be translated into a problem in computer algebra. Fix a set family S = {s1, s2,.., sn} with the underlying element proposition E = i si = {e1,.., em} To each element ei associate an available xi in a polynomial ring via Q. To each set si associate a monomial mi = ej si xj. (For example, the set {1, 2, 5} becomes the monomic x1x2x5). We can then construct a monomial ideal generated by the monimial ms that encodes the set family algebraically. By constructing IS IS is square. It then turns out that the generators of the associated primes of IS correspond exactly to the minimal hit propositions of H. We will refer to this approach as PrimDecomp.This approach used by Jarrah et algebraic in [19] a compilation biology used in the application."}, {"heading": "4.5.2 Integer programming", "text": "The MHS generation problem can be interpreted as an integer programming problem. Fix a set family S = {s1, s2,..., sn} with the underlying element set E = i si = {e1,.., em} We explain n variables xi, each of which can contain values from {0, 1}. A subset T of the vertices then corresponds to an assignment x of the x variables. For each set si we then impose exactly the MHS generation problem. (In fact, Boros et al. in [74] have shown that the MHS generation corresponds to a striking set if it meets all of these constraints. Enumerating minimum assignments that meet the constraints is then exactly the MHS generation problem."}, {"heading": "4.6 Feature comparison", "text": "Table 1 summarizes the most important features of the algorithms presented in section 4."}, {"heading": "4.7 Algorithm miscellany", "text": "A genetic algorithm for finding many (but not necessarily all) small (but not necessarily minimal) hit sets is investigated by Li and Yunfei in [15]. In [14], Vinterbo and \u00d8hrn investigate the more sophisticated problem of finding weighted r-approximated hit sets, which are sentences that hit a fraction of 0 \u2264 r \u2264 1 of the target groups of appropriately assigned weights; they also apply a genetic algorithm with promising results.Jelassi et al. consider the effectiveness of pre-processing methods in [75]. They find that it is worthwhile for many common classes of set families to calculate a new family S from the S family that combines elements that only occur in the same quantities to so-called generalized nodes. (This optimization was also used by Kavvadias and Stavropoulos in [62] for their algorithm Irred, which is then applied to their known MHS algorithm 61, but may not be applied to their known MHS-interest)."}, {"heading": "5 Time-performance comparison of the algorithms", "text": "Numerous previous work has included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13]. However, we note that a new, comprehensive overview is needed for several reasons: 1. Each published comparison involves only a few algorithms, and differences in data sets and environment result in incompatibility of results; therefore, it is not possible to compile a systematic overview of the relative performance of these algorithms. 2. Many existing comparisons overlook published algorithms in areas that are far removed from the experience of the authors. An algorithm designed for monotonous dualization, for example, may prove useful for data mining, but authors in this area may not be aware of this due to translational problems in the literature. 3. Most existing comparisons are not published alongside the working code and do not provide methodological details, so the results can be reproduced or extended. (Murakami and Uno's work in [61] is a notable exception, and indeed their publicly available implementations are used for several algorithms here)."}, {"heading": "5.1 Methodology", "text": "We have compiled a repository of software implementations of existing algorithms, each wrapped in a Docker container that uses the Algorun framework and uses standardized JSON formats for input and output. Details, code, and containers are available at https: / / github.com / VeraLiconaResearchGroup / MHSGenerationAlgorithms, including complete instructions for reproducing the experimental environment and running new experiments. These containers are easy to deploy on any computer that supports the Docker container environment; they do not require compiling code or downloading libraries. Interesting readers are encouraged to perform similar experiments with their own datasets. We have executed each implemented algorithm on a variety of input set families (discussed extensively in Section 5.2), and each of these containers was allowed to run for up to one hour (3600 s) before downloading its libraries. Interested readers are encouraged to perform similar experiments with their own datasets."}, {"heading": "5.2 Data sets used for time-performance comparison", "text": "We have focused on data sets that provide large, heterogeneous set families, since these cases highlight the performance differences between algorithms; for smaller families, the differences can be negligible in practice. Accident Anonymised information on several hundred thousand accidents in Flanders in the period 1991-2000. Originally published in [76]. Transferred by the authors of [61] to a group whose sets are the complementarity of maximum frequent set groups with fixed thresholds, these 1000 threshold values are set for sums {70, 90, 110, 130, 200}; MHSes of this set family then correspond to minimal rare set groups. All set families have 441 underlying elements; the number of set groups ranges from 81 (for subjects = 200) to 10968 (for t = 70). This formulation was downloaded from [77].ecoli Metabolic reaction networks of E. coli."}, {"heading": "5.3 Results", "text": "Below we present the results of the benchmarking experiments with the data sets described in Section 5.2. All experiments were conducted on a workstation with an Intel Xeon E5-2630v3 processor with eight cores at 2.4 GHz (with hyperthreading enabled, allowing 16 simultaneous threads) and 32 GB of ECC DDR4 RAM. Each algorithm was allowed to run for up to 3,600 seconds; algorithms that were not completed during this time are marked with -, while algorithms that crashed due to memory depletion are marked with!."}, {"heading": "5.3.1 Full enumeration", "text": "First, we look at the general problem of enumerating all MHS of a particular set family. The time results for the complete enumeration cases are listed in Tables 4 to 6, with the algorithms sorted in approximately increasing order of velocity."}, {"heading": "5.3.2 Multithreaded full enumeration", "text": "Although many of the published algorithms are serial, some can be paralleled. For the algorithms that had multi-thread implementations available, we tested t-threads (1, 2, 4, 6, 8, 12, 16) on our machine with eight true cores and hyperthreading support. Timing results for selected cases full of enumerations with different numbers of threads are shown in tables 7 and 8."}, {"heading": "5.3.3 Cutoff enumeration", "text": "In many applications, only small MHS are relevant. Here, we look at the list of MHS that are no larger than some \"cutoff\" c; we have set benchmarks for c {5, 7, 10} that use the algorithms that support cutoff mode. Timing results for selected cutoff enumeration cases are given in Tables 9 and 10."}, {"heading": "5.4 Discussion", "text": "As shown in Section 5.3, the algorithms MMCS and RS of 61] and HTC-BDD of 68] are very useful. They are much faster than their competitors across a variety of input systems families.HTC-BDD is extremely fast on inputs for which it ends, and outperforms its nearest competitors by a factor of 4 to 10 on many inputs. However, it needs to be found quickly if many such families need to be processed on our workstation. Moreover, it does not support truncated enumeration. Therefore, we recommend HTC-BDD for situations where all MHSes of moderate size need to be combined - for example, when many such families need to be processed."}, {"heading": "6 Conclusion", "text": "The computational complexity of this task has been an open problem for a long time. However, since many applications (see section 2) depend on the generation of MHS, a multitude of algorithms (see section 4) have been developed to solve them in numerous pure and applied fields of research. We have presented extensive benchmarks (see section 5.3) comparing the computation time of nearly two dozen of these algorithms on a multitude of inputs from the real world. These experiments agree that the MMC and RS algorithms (see section 4.3.2) of Murakami and Uno [61] and the HTC BDD algorithm (see section 4.2.6) of Toda [68] are much faster than other available algorithms via a multitude of inputs. We have provided our benchmarking framework and code in easy-to-install algorithms (see section 4.2.6) of Toda [68]."}], "references": [{"title": "Computational aspects of monotone dualization: A brief survey", "author": ["T. Eiter", "K. Makino", "G. Gottlob"], "venue": "Discrete Applied Mathematics 156 (11) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Algorithmic and computational complexity issues of MONET", "author": ["M. Hagen"], "venue": "Dr. rer. nat., Friedrich-Schiller- Universit\u00e4t Jena ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient read-restricted monotone CNF/DNF dualization by learning with membership queries", "author": ["C. Domingo", "N. Mishra", "L. Pitt"], "venue": "Machine learning 37 (1) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "On the complexity of dualization of monotone disjunctive normal forms", "author": ["M.L. Fredman", "L. Khachiyan"], "venue": "Journal of Algorithms 21 (3) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "A theory of diagnosis from first principles", "author": ["R. Reiter"], "venue": "Artificial intelligence 32 (1) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1016}, {"title": "Mhs2: A map-reduce heuristic-driven minimal hitting set search algorithm", "author": ["N. Cardoso", "R. Abreu"], "venue": "in: J. a. M. Louren\u00c3\u011fo, E. Farchi (Eds.), Multicore Software Engineering, Performance, and Tools, Vol. 8063 of Lecture Notes in Computer Science, Springer Berlin Heidelberg", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "A variant of reiter\u2019s hitting-set algorithm", "author": ["F. Wotawa"], "venue": "Information Processing Letters 79 (1) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1016}, {"title": "The computation of hitting sets: Review and new algorithms", "author": ["L. Lin", "Y. Jiang"], "venue": "Information Processing Letters 86 (4) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1016}, {"title": "A", "author": ["R. Abreu"], "venue": "J. van Gemund, A low-cost approximate minimal hitting set algorithm and its application to model-based diagnosis., in: SARA, Vol. 9", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "T", "author": ["I. Pill"], "venue": "Quaritsch, Optimizations for the boolean approach to computing minimal hitting sets., in: ECAI", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Mining border descriptions of emerging patterns from dataset pairs", "author": ["G. Dong", "J. Li"], "venue": "Knowledge and Information Systems 8 (2) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "A fast algorithm for computing hypergraph transversals and its application in mining emerging patterns", "author": ["J. Bailey", "T. Manoukian", "K. Ramamohanarao"], "venue": "in: Proceedings of the Third IEEE International Conference on Data Mining, IEEE", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "Minimal approximate hitting sets and rule templates", "author": ["S. Vinterbo", "A. \u00d8hrn"], "venue": "International Journal of approximate reasoning 25 (2) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1016}, {"title": "Computing minimal hitting sets with genetic algorithm", "author": ["L. Li", "J. Yunfei"], "venue": "Tech. rep., DTIC Document ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "OCSANA: optimal combinations of interventions from network analysis", "author": ["P. Vera-Licona", "E. Bonnet", "E. Barillot", "A. Zinovyev"], "venue": "Bioinformatics 29 (12) ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimal drug combinations and minimal hitting sets", "author": ["A. Vazquez"], "venue": "BMC systems biology 3 (1) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Computing complex metabolic intervention strategies using constrained minimal cut sets", "author": ["O. H\u00e4dicke", "S. Klamt"], "venue": "Metabolic engineering 13 (2) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Reverse-engineering of polynomial dynamical systems", "author": ["A.S. Jarrah", "R. Laubenbacher", "B. Stigler", "M. Stillman"], "venue": "Advances in Applied Mathematics 39 (4) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "A pathway-based design of rational combination therapies for cancer", "author": ["P. Vera-Licona", "A. Zinovyev", "E. Bonnet", "I. Kuperstein", "O. Kel", "A. Kel", "T. Dubois", "G. Tucker", "E. Barillot"], "venue": "european journal of cancer 48 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1016}, {"title": "Discovery of regulatory interactions through perturbation: inference and experimental design", "author": ["T.E. Ideker", "V. Thorsson", "R.M. Karp"], "venue": "in: Pacific symposium on biocomputing, Vol. 5", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "Hypergraphs: combinatorics of finite sets", "author": ["C. Berge"], "venue": "Vol. 45, Elsevier", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1984}, {"title": "Monotone boolean functions", "author": ["A.D. Korshunov"], "venue": "Russian Mathematical Surveys 58 (5) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "On elementary flux modes in biochemical reaction systems at steady state", "author": ["S. Schuster", "C. Hilgetag"], "venue": "Journal of Biological Systems 2 (02) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1994}, {"title": "Elementary mode analysis: a useful metabolic pathway analysis tool for characterizing cellular metabolism", "author": ["C.T. Trinh", "A. Wlaschin", "F. Srienc"], "venue": "Applied microbiology and biotechnology 81 (5) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Elementary flux modes in a nutshell: Properties", "author": ["J. Zanghellini", "D.E. Ruckerbauer", "M. Hanscho", "C. Jungreuthmayer"], "venue": "calculation and applications, Biotechnology journal 8 (9) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Minimal cut sets in biochemical reaction networks", "author": ["S. Klamt", "E.D. Gilles"], "venue": "Bioinformatics 20 (2) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "Computing knock-out strategies in metabolic networks", "author": ["U.-U. Haus", "S. Klamt", "T. Stephen"], "venue": "Journal of Computational Biology 15 (3) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "A theoretical framework for detecting signal transfer routes in signalling networks", "author": ["I. Zevedei-Oancea", "S. Schuster"], "venue": "Computers & Chemical Engineering 29 (3) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}, {"title": "Elementary signaling modes predict the essentiality of signal transduction network components", "author": ["R.-S. Wang", "R. Albert"], "venue": "BMC systems biology 5 (1) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Reverse engineering of molecular networks from a common combinatorial approach", "author": ["B. DasGupta", "P. Vera-Licona", "E. Sontag"], "venue": "in: M. Elloumi, A. Y. Zomaya (Eds.), Algorithms in Computational Molecular Biology: Techniques, Approaches and Applications, Wiley Online Library", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "The nci60 human tumour cell line anticancer drug screen", "author": ["R.H. Shoemaker"], "venue": "Nature Reviews Cancer 6 (10) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "Mining association rules between sets of items in large databases", "author": ["R. Agrawal", "T. Imieli\u0144ski", "A. Swami"], "venue": "in: ACM SIGMOD Record, Vol. 22-2, ACM", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1993}, {"title": "Fast discovery of association rules", "author": ["R. Agrawal", "H. Mannila", "R. Srikant", "H. Toivonen", "A.I. Verkamo"], "venue": "in: U. M. Fayyad, G. Piatestky-Shapiro, P. Smyth, R. Uthursamy (Eds.), Advances in knowledge discovery and data mining, AAAI/MIT Press", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1996}, {"title": "On maximal frequent and minimal infrequent sets in binary matrices", "author": ["E. Boros", "V. Gurvich", "L. Khachiyan", "K. Makino"], "venue": "Annals of Mathematics and Artificial Intelligence 39 (3) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2003}, {"title": "On an algorithm for finding all interesting sentences extended abstract", "author": ["H. Mannila", "H. Toivoneny"], "venue": "in: Proceedings of the 13th European Meeting on Cybernetics and Systems Research, Citeseer", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1996}, {"title": "Sampling large databases for association", "author": ["H. Toivonen"], "venue": "rules, in: VLDB,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1996}, {"title": "A transversal hypergraph approach for the frequent itemset hiding problem", "author": ["E.C. Stavropoulos", "V.S. Verykios", "V. Kagklis"], "venue": "Knowledge and Information Systems ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Data mining", "author": ["D. Gunopulos", "H. Mannila", "R. Khardon", "H. Toivonen"], "venue": "hypergraph transversals, and machine learning, in: Proceedings of the sixteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems, ACM", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1997}, {"title": "On the complexity of generating maximal frequent and minimal infrequent sets", "author": ["E. Boros", "V. Gurvich", "L. Khachiyan", "K. Makino"], "venue": "in: STACS 2002, Springer", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2002}, {"title": "There is no 16-clue Sudoku: Solving the Sudoku minimum number of clues problem via hitting set enumeration", "author": ["G. McGuire", "B. Tugemann", "G. Civario"], "venue": "Experimental Mathematics 23 (2) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "Reducibility among combinatorial problems", "author": ["R.M. Karp"], "venue": "in: R. E. Miller, J. W. Thatcher, J. D. Bohlinger (Eds.), Complexity of Computer Computations, The IBM Research Symposia Series, Springer US", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1972}, {"title": "A fast and simple parallel algorithm for the monotone duality problem", "author": ["E. Boros", "K. Makino"], "venue": "in: Automata, Languages and Programming, Springer", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2009}, {"title": "On generating all maximal independent sets", "author": ["D.S. Johnson", "M. Yannakakis", "C.H. Papadimitriou"], "venue": "Information Processing Letters 27 (3) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1988}, {"title": "Lower bounds for three algorithms for transversal hypergraph generation", "author": ["M. Hagen"], "venue": "Discrete Applied Mathematics 157 (7) ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}, {"title": "Computing many maximal independent sets for hypergraphs in parallel", "author": ["L. Khachiyan", "E. Boros", "V. Gurvich", "K. Elbassioni"], "venue": "Parallel processing letters 17 (02) ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2007}, {"title": "Generating all maximal independent sets of bounded-degree hypergraphs", "author": ["N. Mishra", "L. Pitt"], "venue": "in: Proceedings of the tenth annual conference on Computational learning theory, ACM", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1997}, {"title": "Some fixed-parameter tractable classes of hypergraph duality and related problems", "author": ["K. Elbassioni", "M. Hagen", "I. Rauf"], "venue": "in: Parameterized and Exact Computation, Springer", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2008}, {"title": "New results on monotone dualization and generating hypergraph transversals", "author": ["T. Eiter", "G. Gottlob", "K. Makino"], "venue": "SIAM Journal on Computing 32 (2) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2003}, {"title": "A global parallel algorithm for the hypergraph transversal problem", "author": ["L. Khachiyan", "E. Boros", "K. Elbassioni", "V. Gurvich"], "venue": "Information Processing Letters 101 (4) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2007}, {"title": "A new algorithm for the hypergraph transversal problem", "author": ["L. Khachiyan", "E. Boros", "K. Elbassioni", "V. Gurvich"], "venue": "in: COCOON, Springer", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2005}, {"title": "On the desirability of acyclic database schemes", "author": ["C. Beeri", "R. Fagin", "D. Maier", "M. Yannakakis"], "venue": "Journal of the ACM (JACM) 30 (3) ", "citeRegEx": "52", "shortCiteRegEx": null, "year": 1983}, {"title": "Degrees of acyclicity for hypergraphs and relational database schemes", "author": ["R. Fagin"], "venue": "Journal of the ACM (JACM) 30 (3) ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1983}, {"title": "Identifying the minimal transversals of a hypergraph and related problems", "author": ["T. Eiter", "G. Gottlob"], "venue": "SIAM Journal on Computing 24 (6) ", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1995}, {"title": "Monotone boolean dualization is in co-NP [log 2", "author": ["D.J. Kavvadias", "E.C. Stavropoulos"], "venue": "Information Processing Letters 85 (1) ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 1016}, {"title": "Complexity of identification and dualization of positive boolean functions", "author": ["J.C. Bioch", "T. Ibaraki"], "venue": "Information and Computation 123 (1) ", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1995}, {"title": "Left-to-right multiplication for monotone boolean dualization", "author": ["E. Boros", "K. Elbassioni", "K. Makino"], "venue": "SIAM Journal on Computing 39 (7) ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2010}, {"title": "A worst-case analysis of the sequential method to list the minimal hitting sets of a hypergraph", "author": ["K. Takata"], "venue": "SIAM Journal on Discrete Mathematics 21 (4) ", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2007}, {"title": "A correction to the algorithm in Reiter\u2019s theory of diagnosis", "author": ["R. Greiner", "B.A. Smith", "R.W. Wilkerson"], "venue": "Artificial Intelligence 41 (1) ", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1016}, {"title": "Efficient algorithms for dualizing large-scale hypergraphs", "author": ["K. Murakami", "T. Uno"], "venue": "Discrete Applied Mathematics 170 ", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2014}, {"title": "E", "author": ["D.J. Kavvadias"], "venue": "C. Stavropoulos, An efficient algorithm for the transversal hypergraph generation., J. Graph Algorithms Appl. 9 (2) ", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2005}, {"title": "An efficient implementation of a quasi-polynomial algorithm for generating hypergraph transversals and its application in joint generation", "author": ["L. Khachiyan", "E. Boros", "K. Elbassioni", "V. Gurvich"], "venue": "Discrete Applied Mathematics 154 (16) ", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2006}, {"title": "M", "author": ["M. Hagen", "P. Horatschek"], "venue": "Mundhenk, Experimental comparison of the two Fredman-Khachiyanalgorithms., in: ALENEX, SIAM", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2009}, {"title": "Parallel computation of the minimal elements of a poset", "author": ["C.E. Leiserson", "M. Moreno Maza", "L. Li", "Y. Xie"], "venue": "in: Proceedings of the 4th International Workshop on Parallel and Symbolic Computation, ACM", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2010}, {"title": "Graph-based algorithms for boolean function manipulation", "author": ["R.E. Bryant"], "venue": "Computers, IEEE Transactions on 100 (8) ", "citeRegEx": "66", "shortCiteRegEx": null, "year": 1986}, {"title": "Combinatorial Algorithms: Part 1", "author": ["D.E. Knuth"], "venue": "Vol. 4A of The Art of Computer Programming, Addison-Wesley, Boston", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2011}, {"title": "Hypergraph transversal computation with binary decision diagrams", "author": ["T. Toda"], "venue": "in: 12th International Symposium, SEA 2013, Rome, Italy, June 5-7, 2013, Springer", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2013}, {"title": "A data mining formalization to improve hypergraph minimal transversal computation", "author": ["C. H\u00e9bert", "A. Bretto", "B. Cr\u00e9milleux"], "venue": "Fundamenta Informaticae 80 (4) ", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2007}, {"title": "I", "author": ["K.M. Elbassioni", "M. Hagen"], "venue": "Rauf, A lower bound for the hbc transversal hypergraph generation., Fundam. Inform. 130 (4) ", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2014}, {"title": "On the complexity of monotone dualization and generating minimal hypergraph transversals", "author": ["K.M. Elbassioni"], "venue": "Discrete Applied Mathematics 156 (11) ", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2008}, {"title": "Alexander duality for monomial ideals and their resolutions", "author": ["E. Miller"], "venue": "available from http://arxiv. org/abs/math/9812095 ", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1998}, {"title": "Dual-bounded generating problems: All minimal integer solutions for a monotone system of linear inequalities", "author": ["E. Boros", "K. Elbassioni", "V. Gurvich", "L. Khachiyan", "K. Makino"], "venue": "SIAM Journal on Computing 31 (5) ", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2002}, {"title": "Concise representation of hypergraph minimal transversals: Approach and application on the dependency inference problem", "author": ["M.N. Jelassi", "C. Largeron", "S. Ben Yahia"], "venue": "in: Research Challenges in Information Science (RCIS), 2015 IEEE 9th International Conference on, IEEE", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2015}, {"title": "Profiling of high-frequency accident locations by use of association rules", "author": ["K. Geurts", "G. Wets", "T. Brijs", "K. Vanhoof"], "venue": "Transportation Research Record: Journal of the Transportation Research Board 1840 ", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2003}, {"title": "T", "author": ["K. Murakami"], "venue": "Uno, Hypergraph dualization repository ", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2014}, {"title": "S", "author": ["A. Von Kamp"], "venue": "Schuster, Metatool 5.0: fast and flexible elementary modes analysis, Bioinformatics 22 (15) ", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2006}, {"title": "The logic of EGFR/ErbB signaling: theoretical properties and analysis of high-throughput data", "author": ["R. Samaga", "J. Saez-Rodriguez", "L.G. Alexopoulos", "P.K. Sorger", "S. Klamt"], "venue": "PLoS Comput Biol 5 (8) ", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "1, [1]), Boolean algebra (Section 2.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "2, [2, 3, 4]), fault diagnosis (Section 2.", "startOffset": 3, "endOffset": 12}, {"referenceID": 2, "context": "2, [2, 3, 4]), fault diagnosis (Section 2.", "startOffset": 3, "endOffset": 12}, {"referenceID": 3, "context": "2, [2, 3, 4]), fault diagnosis (Section 2.", "startOffset": 3, "endOffset": 12}, {"referenceID": 4, "context": "3, [5, 6, 7, 8, 9, 10, 11]), data mining (Section 2.", "startOffset": 3, "endOffset": 26}, {"referenceID": 5, "context": "3, [5, 6, 7, 8, 9, 10, 11]), data mining (Section 2.", "startOffset": 3, "endOffset": 26}, {"referenceID": 6, "context": "3, [5, 6, 7, 8, 9, 10, 11]), data mining (Section 2.", "startOffset": 3, "endOffset": 26}, {"referenceID": 7, "context": "3, [5, 6, 7, 8, 9, 10, 11]), data mining (Section 2.", "startOffset": 3, "endOffset": 26}, {"referenceID": 8, "context": "3, [5, 6, 7, 8, 9, 10, 11]), data mining (Section 2.", "startOffset": 3, "endOffset": 26}, {"referenceID": 9, "context": "3, [5, 6, 7, 8, 9, 10, 11]), data mining (Section 2.", "startOffset": 3, "endOffset": 26}, {"referenceID": 10, "context": "5, [12, 13, 14, 15]), and computational biology (Section 2.", "startOffset": 3, "endOffset": 19}, {"referenceID": 11, "context": "5, [12, 13, 14, 15]), and computational biology (Section 2.", "startOffset": 3, "endOffset": 19}, {"referenceID": 12, "context": "5, [12, 13, 14, 15]), and computational biology (Section 2.", "startOffset": 3, "endOffset": 19}, {"referenceID": 13, "context": "5, [12, 13, 14, 15]), and computational biology (Section 2.", "startOffset": 3, "endOffset": 19}, {"referenceID": 14, "context": "4, [16, 17, 18, 19, 20, 21]), among others.", "startOffset": 3, "endOffset": 27}, {"referenceID": 15, "context": "4, [16, 17, 18, 19, 20, 21]), among others.", "startOffset": 3, "endOffset": 27}, {"referenceID": 16, "context": "4, [16, 17, 18, 19, 20, 21]), among others.", "startOffset": 3, "endOffset": 27}, {"referenceID": 17, "context": "4, [16, 17, 18, 19, 20, 21]), among others.", "startOffset": 3, "endOffset": 27}, {"referenceID": 18, "context": "4, [16, 17, 18, 19, 20, 21]), among others.", "startOffset": 3, "endOffset": 27}, {"referenceID": 19, "context": "4, [16, 17, 18, 19, 20, 21]), among others.", "startOffset": 3, "endOffset": 27}, {"referenceID": 20, "context": "Readers interested in the full theory of hypergraphs should consult Berge\u2019s 1984 monograph [22] on the subject.", "startOffset": 91, "endOffset": 95}, {"referenceID": 0, "context": "Interested readers can consult the recent survey of Eiter [1] and Ph.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "thesis of Hagen [2] for more details about this subject.", "startOffset": 16, "endOffset": 19}, {"referenceID": 21, "context": "(See [23] for an extensive survey.", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "thesis of Hagen [2], which gives this problem the picturesque name monet.", "startOffset": 16, "endOffset": 19}, {"referenceID": 4, "context": "In a celebrated 1987 paper [5], Reiter developed the foundation for a formal theory of model-based diagnosis (MBD), which we will introduce briefly.", "startOffset": 27, "endOffset": 30}, {"referenceID": 22, "context": "The notion of elementary flux modes (\u201cEFMs\u201d) was introduced by Schuster and Hilgetag in [24]; subsequent work has developed numerous techniques from linear algebra and computational geometry to find the EFMs.", "startOffset": 88, "endOffset": 92}, {"referenceID": 23, "context": "see the recent surveys [25, 26] for overview of the problem, the methods and software which are used to solve it, and various applications.", "startOffset": 23, "endOffset": 31}, {"referenceID": 24, "context": "see the recent surveys [25, 26] for overview of the problem, the methods and software which are used to solve it, and various applications.", "startOffset": 23, "endOffset": 31}, {"referenceID": 25, "context": "In [27], Klamt and Gilles focus on blocking a target reaction through cut sets, which they define as a set of reactions whose removal from the network leaves no feasible balanced flux distribution involving the target reaction.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "developed in [28] a specialized version of the FK-A algorithm (cf.", "startOffset": 13, "endOffset": 17}, {"referenceID": 27, "context": "Biological signaling networks typically [29] exhibit a natural decomposition into input, intermediate, and output nodes; engineering and control of these networks then typically depends on adjusting the input and intermediate layers to obtain some outcome at the outputs.", "startOffset": 40, "endOffset": 44}, {"referenceID": 28, "context": "As an analogous of elementary flux modes (\u201cEFMs\u201d) in metabolic networks, in [30], Wang and Albert introduced the notion of elementary signaling modes (ESMs).", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": "introduced the OCSANA framework to study this problem in [16].", "startOffset": 57, "endOffset": 61}, {"referenceID": 14, "context": "Since discovery of hitting sets is a crucial step in the algorithm, the authors of [16] performed an experimental comparison.", "startOffset": 83, "endOffset": 87}, {"referenceID": 29, "context": "Broadly, the biological reverse-engineering problem is that of \u201canalyzing a given system in order to identify, from biological data, the components of the system and their relationships\u201d [31].", "startOffset": 187, "endOffset": 191}, {"referenceID": 29, "context": "See [31] for a comparative survey of these two approaches and the relative performance of the specialized algorithms developed for each; we give here only a brief overview of each.", "startOffset": 4, "endOffset": 8}, {"referenceID": 19, "context": "introduce a method to infer the topology of a network of gene regulatory interactions in [21].", "startOffset": 89, "endOffset": 93}, {"referenceID": 17, "context": "introduce another method to infer the topology of a gene regulatory network in [19] which focuses on time series data within a single experiment.", "startOffset": 79, "endOffset": 83}, {"referenceID": 15, "context": "This application has been studied in detail by Vazquez in [17], using a greedy algorithm to search for very small effective combinations from the NCI60 collection ([32]) of 45334 drugs and 60 cancer cell lines.", "startOffset": 58, "endOffset": 62}, {"referenceID": 30, "context": "This application has been studied in detail by Vazquez in [17], using a greedy algorithm to search for very small effective combinations from the NCI60 collection ([32]) of 45334 drugs and 60 cancer cell lines.", "startOffset": 164, "endOffset": 168}, {"referenceID": 31, "context": "in [33] and developed further in [34], is the discovery of frequent itemsets in a database of transactions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 32, "context": "in [33] and developed further in [34], is the discovery of frequent itemsets in a database of transactions.", "startOffset": 33, "endOffset": 37}, {"referenceID": 33, "context": "in [35].", "startOffset": 3, "endOffset": 7}, {"referenceID": 34, "context": "This connection is explored by Manilla and Toivonen in [36]; more algorithmic details are given by Toivonen in [37].", "startOffset": 55, "endOffset": 59}, {"referenceID": 35, "context": "This connection is explored by Manilla and Toivonen in [36]; more algorithmic details are given by Toivonen in [37].", "startOffset": 111, "endOffset": 115}, {"referenceID": 36, "context": "in [38].", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "Furthermore, so-called \u201cjoint-generation\u201d algorithms inspired by the FK algorithms of Fredman and Khachiyan [4] (cf.", "startOffset": 108, "endOffset": 111}, {"referenceID": 37, "context": "in [39] and its complexity implications explored by Boros et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 38, "context": "in [40].", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "in [13].", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "4, [12]) and BMR (Section 4.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "5, [13]), were developed for this purpose.", "startOffset": 3, "endOffset": 7}, {"referenceID": 39, "context": "In [41], McGuire et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 6, "context": "They use an algorithm similar to HST from [8], discussed in detail in Section 4.", "startOffset": 42, "endOffset": 45}, {"referenceID": 40, "context": "It has been known since Karp\u2019s seminal 1972 paper [42] that the problem of determining whether a given set family has a hitting set of size no greater than some k is NP-complete.", "startOffset": 50, "endOffset": 54}, {"referenceID": 3, "context": "Fredman and Khachiyan present in [4] an algorithm (discussed in Section 4.", "startOffset": 33, "endOffset": 36}, {"referenceID": 41, "context": "The BM algorithm introduced by Boros and Makino in [43] improves on this bound in parallel cases.", "startOffset": 51, "endOffset": 55}, {"referenceID": 42, "context": "introduced a formalism to deal with this issue in [44].", "startOffset": 50, "endOffset": 54}, {"referenceID": 43, "context": "Unfortunately, this is not known to be achieved by any current algorithm, and Hagen showed in [45] that several important algorithms are not output-polynomial.", "startOffset": 94, "endOffset": 98}, {"referenceID": 42, "context": "introduced two suitable formalisms in [44].", "startOffset": 38, "endOffset": 42}, {"referenceID": 42, "context": "Crucially, if an algorithm runs with polynomial delay, it is guaranteed to run in output-polynomial total time, but incremental-polynomial time gives no such guarantee ([44]).", "startOffset": 169, "endOffset": 173}, {"referenceID": 44, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 178, "endOffset": 197}, {"referenceID": 2, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 178, "endOffset": 197}, {"referenceID": 45, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 178, "endOffset": 197}, {"referenceID": 46, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 178, "endOffset": 197}, {"referenceID": 45, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 178, "endOffset": 197}, {"referenceID": 47, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 237, "endOffset": 249}, {"referenceID": 46, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 237, "endOffset": 249}, {"referenceID": 48, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 237, "endOffset": 249}, {"referenceID": 49, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 305, "endOffset": 313}, {"referenceID": 46, "context": "Fixed-parameter tractability results have been obtained for the transversal hypergraph recognition problem with a wide variety of parameters, including vertex degree parameters ([46, 3, 47, 48, 47]), hyperedge size or number parameters ([49, 48, 50]), and hyperedge intersection or union size parameters ([51, 48]).", "startOffset": 305, "endOffset": 313}, {"referenceID": 50, "context": "introduced in [52] a notion of acyclicity in hypergraphs, now known as \u03b1-acyclicity, in the context of the study of relational database schemes.", "startOffset": 14, "endOffset": 18}, {"referenceID": 51, "context": "Fagin subsequently introduced in [53] the notions of \u03b2-acyclicity and \u03b3-acyclicity, which are successively more restrictive and correspond to desirable tractability problems in databases.", "startOffset": 33, "endOffset": 37}, {"referenceID": 52, "context": "Eiter showed that the transversal recognition is solvable in polynomial time for \u03b2-acyclic hypergraphs in [54] and for \u03b1-acyclic hypergraphs in [49].", "startOffset": 106, "endOffset": 110}, {"referenceID": 47, "context": "Eiter showed that the transversal recognition is solvable in polynomial time for \u03b2-acyclic hypergraphs in [54] and for \u03b1-acyclic hypergraphs in [49].", "startOffset": 144, "endOffset": 148}, {"referenceID": 53, "context": "Kavvadias and Stavropoulos showed in [55] that the recognition problem is in the class co-NP[log2 n] for n the total number of edges in H and TrH, meaning that only O ( log2 n ) nondeterministic bits are required to demonstrate that two hypergraphs are not transversals of each other.", "startOffset": 37, "endOffset": 41}, {"referenceID": 54, "context": "[56]) that an algorithm for the transversal hypergraph recognition problem (cf.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "1 Berge (1984) The first systematic algorithm for computing transversals of hypergraphs was presented by Berge in [22], a monograph on the theory of hypergraphs.", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "As suggested in [18], Berge\u2019s algorithm can be adapted to search only for MHSes of cardinality bounded by some k by simply discarding candidates larger than k at Lines 4 and 5 in each stage of the algorithm.", "startOffset": 16, "endOffset": 20}, {"referenceID": 55, "context": "in [58].", "startOffset": 3, "endOffset": 7}, {"referenceID": 56, "context": "Takata showed in [59] that there exists a family of hypergraphs for which no edge ordering yields output-polynomial running time, and thus that Berge is not output-polynomial in general, even if the edge ordering is optimal.", "startOffset": 17, "endOffset": 21}, {"referenceID": 55, "context": "demonstrate in [58], however, that the worst case is still sub-exponential.", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "3, Reiter introduced the formal theory of model-based diagnosis as an application of MHS enumeration in [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 57, "context": "in [60] that this algorithm is incomplete; the hitting sets it generates are guaranteed to be minimal, but in certain circumstances some MHSes may be missed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 6, "context": "3 Wotawa (2001) Wotawa returned to Reiter\u2019s approach in [8], reviewing the HS-DAG algorithm of [60] (see Section 4.", "startOffset": 56, "endOffset": 59}, {"referenceID": 57, "context": "3 Wotawa (2001) Wotawa returned to Reiter\u2019s approach in [8], reviewing the HS-DAG algorithm of [60] (see Section 4.", "startOffset": 95, "endOffset": 99}, {"referenceID": 10, "context": "4 Dong and Li (2005) Dong and Li considered in [12] the \u201cemerging patterns problem\u201d discussed in Section 2.", "startOffset": 47, "endOffset": 51}, {"referenceID": 1, "context": "Hagen shows in [2, 45] that Takata\u2019s time bounds on Berge in [59] apply to DL as well, so it is not output-polynomial.", "startOffset": 15, "endOffset": 22}, {"referenceID": 43, "context": "Hagen shows in [2, 45] that Takata\u2019s time bounds on Berge in [59] apply to DL as well, so it is not output-polynomial.", "startOffset": 15, "endOffset": 22}, {"referenceID": 56, "context": "Hagen shows in [2, 45] that Takata\u2019s time bounds on Berge in [59] apply to DL as well, so it is not output-polynomial.", "startOffset": 61, "endOffset": 65}, {"referenceID": 58, "context": "A C implementation of this algorithm by the authors of [61] is available in the repository.", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "developed in [13] an algorithm which decomposes the input set family more carefully than Berge\u2019s algorithm.", "startOffset": 13, "endOffset": 17}, {"referenceID": 10, "context": "Rather than simply considering one new set at a time, their approach attempts to partition the set family into components with few sets, then use the DL algorithm of [12] as a subroutine to compute their MHSes before combining them using equation (1).", "startOffset": 166, "endOffset": 170}, {"referenceID": 1, "context": "Hagen shows in [2, 45] that BMR is not output-polynomial.", "startOffset": 15, "endOffset": 22}, {"referenceID": 43, "context": "Hagen shows in [2, 45] that BMR is not output-polynomial.", "startOffset": 15, "endOffset": 22}, {"referenceID": 58, "context": "A C implementation of this algorithm by the authors of [61] is available in the repository.", "startOffset": 55, "endOffset": 59}, {"referenceID": 59, "context": "6 Kavvadias and Stavropoulos (2005) Returning to the explicit study of hypergraph transversals, Kavvadias and Stavropoulos introduced in [62] another algorithm, which seeks to reduce the memory requirements of Berge with two optimizations.", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "Hagen shows in [2, 45] that KS does not run in output-polynomial time.", "startOffset": 15, "endOffset": 22}, {"referenceID": 43, "context": "Hagen shows in [2, 45] that KS does not run in output-polynomial time.", "startOffset": 15, "endOffset": 22}, {"referenceID": 59, "context": "A Pascal implementation of this algorithm by the authors of [62] is available in the repository.", "startOffset": 60, "endOffset": 64}, {"referenceID": 7, "context": "1 Lin and Jiang (2003) Lin and Jiang return in [9] to the problem of model-based diagnosis.", "startOffset": 47, "endOffset": 50}, {"referenceID": 9, "context": "The Boolean algorithm was subsequently optimized by Pill and Quaritsch in [11].", "startOffset": 74, "endOffset": 78}, {"referenceID": 3, "context": "2 Fredman and Khachiyan (1996) Fredman and Khachiyan introduced two iterative algorithms in [4] to study the recognition version of the MHS problem in the Boolean algebra context.", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "We will refer to these two algorithms as FK-A and FK-B (\u201cFK\u201d for the authors, who use the names A and B in [4]).", "startOffset": 107, "endOffset": 110}, {"referenceID": 60, "context": "The algorithm is modified in [63] to improve its runtime slightly and adapt it to MHS generation.", "startOffset": 29, "endOffset": 33}, {"referenceID": 60, "context": "As a result, most authors (including [63]) have disregarded FK-B in comparative studies.", "startOffset": 37, "endOffset": 41}, {"referenceID": 61, "context": "However, analysis in [64] suggests that this assumption may be inaccurate.", "startOffset": 21, "endOffset": 25}, {"referenceID": 26, "context": "apply this approach in [28], as discussed in Section 2.", "startOffset": 23, "endOffset": 27}, {"referenceID": 8, "context": "Abreu and Gemund presented such an algorithm in [10].", "startOffset": 48, "endOffset": 52}, {"referenceID": 8, "context": "We will refer to this algorithm as STACCATO (the name used by its authors in [10]).", "startOffset": 77, "endOffset": 81}, {"referenceID": 8, "context": "The authors of [10] claim that, for a set family with N sets andM total elements, the algorithm guarantees to find a hitting set of cardinality C in O ( (M \u00b7 (N + logM)) ) worst-case time and O(C \u00b7M) space, with improved expected times based on their heuristic and tested experimentally.", "startOffset": 15, "endOffset": 19}, {"referenceID": 62, "context": "cast this issue in a very abstract setting in [65], developing a framework to parallelize any algorithm that searches for minimal elements of a poset and then applying it to the lattice of hitting sets of a set family.", "startOffset": 46, "endOffset": 50}, {"referenceID": 62, "context": "We will refer to this algorithm as ParTran (the name used by its authors in [65]).", "startOffset": 76, "endOffset": 80}, {"referenceID": 62, "context": "A Cilk++ implementation of this algorithm by the authors of [65] is available in the repository.", "startOffset": 60, "endOffset": 64}, {"referenceID": 63, "context": "5 Knuth (2011) Binary decision diagrams (BDDs) are a graph-based structure for representing boolean functions and hypergraphs originally introduced by Bryant in [66].", "startOffset": 161, "endOffset": 165}, {"referenceID": 65, "context": "A C implementation of this algorithm by the author of [68] is available in the repository.", "startOffset": 54, "endOffset": 58}, {"referenceID": 65, "context": "6 Toda (2013) In 2013, Toda improved on the KNUTH algorithm in [68] by incorporating a variation on the BDD data structure\u2013the zero-suppressed binary decision diagram (ZDD).", "startOffset": 63, "endOffset": 67}, {"referenceID": 65, "context": "Toda gives a formal complexity analysis of HTC-BDD in [68], but the resulting bounds are expressed in terms of the intermediate BDD and ZDD data structures and are incommensurable with bounds like those known for FK-A and FK-B.", "startOffset": 54, "endOffset": 58}, {"referenceID": 65, "context": "A C implementation of this algorithm by the author of [68] is available in the repository.", "startOffset": 54, "endOffset": 58}, {"referenceID": 5, "context": "7 Cardoso and Abreu (2014) Cardoso and Abreu revisted the STACCATO approach in [6].", "startOffset": 79, "endOffset": 82}, {"referenceID": 5, "context": "A C++ implementation of the algorithm by the authors of [6] is available in the repository.", "startOffset": 56, "endOffset": 59}, {"referenceID": 66, "context": "take an approach in [69] that brings insights from data mining to bear on the MHS generation problem.", "startOffset": 20, "endOffset": 24}, {"referenceID": 67, "context": "We follow the explanation of the algorithm in [70], which avoids the algebraic complexity of the original.", "startOffset": 46, "endOffset": 50}, {"referenceID": 67, "context": "[70]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 67, "context": "However, Hagen shows in [70] that this bound is incorrect.", "startOffset": 24, "endOffset": 28}, {"referenceID": 14, "context": "The second author and collaborators apply this approach as a \u201cgreedy algorithm\u201d in [16] to", "startOffset": 83, "endOffset": 87}, {"referenceID": 66, "context": "A C++ implementation of this algorithm by the authors of [69] is available in the repository.", "startOffset": 57, "endOffset": 61}, {"referenceID": 58, "context": "2 Murakami and Uno (2014) Murakami and Uno take a somewhat different approach in [61] in two new algorithms.", "startOffset": 81, "endOffset": 85}, {"referenceID": 66, "context": "[69, 61]:", "startOffset": 0, "endOffset": 8}, {"referenceID": 58, "context": "[69, 61]:", "startOffset": 0, "endOffset": 8}, {"referenceID": 58, "context": "Then MMCS runs in O(k) time per iteration of its main loop, but the authors of [61] do not give bounds for the number of iterations required.", "startOffset": 79, "endOffset": 83}, {"referenceID": 58, "context": "However, the shd program distributed by the authors of [61] does not support either of these modes.", "startOffset": 55, "endOffset": 59}, {"referenceID": 58, "context": "A C implementation of MMCS and RS by the authors of [61] is available in the repository.", "startOffset": 52, "endOffset": 56}, {"referenceID": 48, "context": "introduced the full cover decomposition approach in [50, 46].", "startOffset": 52, "endOffset": 60}, {"referenceID": 44, "context": "introduced the full cover decomposition approach in [50, 46].", "startOffset": 52, "endOffset": 60}, {"referenceID": 48, "context": "2 Elbassioni (2008) Following up on [50, 46], Elbassioni presents in [71] two parallel decomposition approaches for the transversal recognition problem.", "startOffset": 36, "endOffset": 44}, {"referenceID": 44, "context": "2 Elbassioni (2008) Following up on [50, 46], Elbassioni presents in [71] two parallel decomposition approaches for the transversal recognition problem.", "startOffset": 36, "endOffset": 44}, {"referenceID": 68, "context": "2 Elbassioni (2008) Following up on [50, 46], Elbassioni presents in [71] two parallel decomposition approaches for the transversal recognition problem.", "startOffset": 69, "endOffset": 73}, {"referenceID": 68, "context": "(The exact bounds are cumbersome to state but may be found in [71].", "startOffset": 62, "endOffset": 66}, {"referenceID": 41, "context": "3 Boros and Makno (2009) Boros and Makino present in [43] a full cover algorithm which improves on the asymptotic complexity bounds of [71] for transversal recognition.", "startOffset": 53, "endOffset": 57}, {"referenceID": 68, "context": "3 Boros and Makno (2009) Boros and Makino present in [43] a full cover algorithm which improves on the asymptotic complexity bounds of [71] for transversal recognition.", "startOffset": 135, "endOffset": 139}, {"referenceID": 17, "context": "in [19] for an application in computational biology.", "startOffset": 3, "endOffset": 7}, {"referenceID": 69, "context": "They calculate the associated primes of IS using Alexander duality [72] as provided in Macaulay2 [73].", "startOffset": 67, "endOffset": 71}, {"referenceID": 70, "context": "in [74] that MHS generation is equivalent to the general problem of enumerating minimal solutions to the linear system Ax = b for 0 \u2264 x \u2264 c where A is a binary matrix, x is a binary vector, and b and c are all-ones vectors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "7 Algorithm miscellany A genetic algorithm for finding many (but not necessarily all) small (but not necessarily minimal) hitting sets is studied by Li and Yunfei in [15].", "startOffset": 166, "endOffset": 170}, {"referenceID": 12, "context": "Vinterbo and \u00d8hrn study in [14] the more refined problem of finding weighted r-approximate hitting sets, which are sets which hit some fraction 0 \u2264 r \u2264 1 of the target sets according to assigned weights; they also apply a genetic algorithm with promising results.", "startOffset": 27, "endOffset": 31}, {"referenceID": 71, "context": "consider the efficacy of pre-processing methods in [75].", "startOffset": 51, "endOffset": 55}, {"referenceID": 59, "context": "(This optimization was also used by Kavvadias and Stavropoulos in [62] for their algorithm KS.", "startOffset": 66, "endOffset": 70}, {"referenceID": 58, "context": ") Their algorithm Irred-Engine performs this preprocessing, applies a known MHS algorithm (in their case, MMCS from [61]) to the resulting family S\u2032, and then expands the results into MHSes for the original S.", "startOffset": 116, "endOffset": 120}, {"referenceID": 58, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 62, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 59, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 66, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 61, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 10, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 5, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 11, "context": "Numerous previous papers have included experimental comparisons of some algorithms, including [61, 65, 62, 69, 64, 12, 6, 13].", "startOffset": 94, "endOffset": 125}, {"referenceID": 58, "context": "(Murakami and Uno\u2019s work in [61] is a notable exception, and indeed their publicly-available implementations are used for several algorithms here.", "startOffset": 28, "endOffset": 32}, {"referenceID": 72, "context": "Originally published in [76].", "startOffset": 24, "endOffset": 28}, {"referenceID": 58, "context": "Converted by the authors of [61] into a set family whose sets are the complements of maximal frequent itemsets with specified threshold 1000\u03b8 for \u03b8 \u2208 {70, 90, 110, 130, 150, 200}; MHSes of this set family then correspond to minimal infrequent itemsets.", "startOffset": 28, "endOffset": 32}, {"referenceID": 73, "context": "This formulation was downloaded from [77].", "startOffset": 37, "endOffset": 41}, {"referenceID": 74, "context": "Reaction networks for producing acetate, glucose, glycerol, and succinate, along with the combined network, were analyzed to find their \u201celementary modes\u201d using Metatool [78], which are given as set families.", "startOffset": 170, "endOffset": 174}, {"referenceID": 75, "context": "Two cell signalling networks (EGFR from [79] and HER2+ from [20]) were analyzed to find their \u201celementary pathways\u201d using OCSANA, which are given as set families.", "startOffset": 40, "endOffset": 44}, {"referenceID": 18, "context": "Two cell signalling networks (EGFR from [79] and HER2+ from [20]) were analyzed to find their \u201celementary pathways\u201d using OCSANA, which are given as set families.", "startOffset": 60, "endOffset": 64}, {"referenceID": 58, "context": "3, the algorithms MMCS and RS from [61] and HTC-BDD from [68] are far faster than their competitors across a variety of input set families.", "startOffset": 35, "endOffset": 39}, {"referenceID": 65, "context": "3, the algorithms MMCS and RS from [61] and HTC-BDD from [68] are far faster than their competitors across a variety of input set families.", "startOffset": 57, "endOffset": 61}, {"referenceID": 5, "context": "7) of Cardoso and Abreu [6] shows a 2.", "startOffset": 24, "endOffset": 27}, {"referenceID": 58, "context": "2) of Murakami and Uno [61] shows a 4.", "startOffset": 23, "endOffset": 27}, {"referenceID": 41, "context": "3) of Boros and Makino [43] was too slow to yield useful results.", "startOffset": 23, "endOffset": 27}, {"referenceID": 58, "context": "2) of Murakami and Uno [61] and the HTC-BDD algorithm (cf.", "startOffset": 23, "endOffset": 27}, {"referenceID": 65, "context": "6) of Toda [68] are far faster than other available algorithms across a variety of inputs.", "startOffset": 11, "endOffset": 15}], "year": 2016, "abstractText": "Finding inclusion-minimal hitting sets for a given collection of sets is a fundamental combinatorial problem with applications in domains as diverse as Boolean algebra, computational biology, and data mining. Much of the algorithmic literature focuses on the problem of recognizing the collection of minimal hitting sets; however, in many of the applications, it is more important to generate these hitting sets. We survey twenty algorithms from across a variety of domains, considering their history, classification, useful features, and computational performance on a variety of synthetic and real-world inputs. We also provide a suite of implementations of these algorithms with a ready-to-use, platform-agnostic interface based on Docker containers and the AlgoRun framework, so that interested computational scientists can easily perform similar tests with inputs from their own research areas on their own computers or through a convenient Web interface.", "creator": "LaTeX with hyperref package"}}}