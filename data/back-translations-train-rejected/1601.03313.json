{"id": "1601.03313", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jan-2016", "title": "Political Speech Generation", "abstract": "In this report we present a system that can generate political speeches for a desired political party. Furthermore, the system allows to specify whether a speech should hold a supportive or opposing opinion. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson &amp; Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. Sequences of words are generated based on probabilities obtained from two underlying models: A language model takes care of the grammatical correctness while a topic model aims for textual consistency. Both models were trained on the Convote dataset which contains transcripts from US congressional floor debates. Furthermore, we present a manual and an automated approach to evaluate the quality of generated speeches. In an experimental evaluation generated speeches have shown very high quality in terms of grammatical correctness and sentence transitions.", "histories": [["v1", "Wed, 13 Jan 2016 16:58:05 GMT  (29kb)", "http://arxiv.org/abs/1601.03313v1", "15 pages, class project"], ["v2", "Wed, 20 Jan 2016 15:47:13 GMT  (29kb)", "http://arxiv.org/abs/1601.03313v2", "15 pages, class project"]], "COMMENTS": "15 pages, class project", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["valentin kassarnig"], "accepted": false, "id": "1601.03313"}, "pdf": {"name": "1601.03313.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["vkassarnig@umass.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 1.03 313v 1 [cs.C L] 13 Jan 20In this report, we present a system that can generate political speeches for a desired political party. In addition, the system allows to determine whether a speech should have a supportive or contrary opinion. It is based on a combination of several modern NLP methods discussed in this report, including n-gram, Justeson & Katz POS tag filters, recursive neural networks, and latent dirichlet allocation. Word sequences are generated based on probabilities derived from two underlying models: a language model ensures grammatical correctness, while a theme model aims at text consistency. Both models were trained on the Convote dataset, which contains transcripts from debates in the US Congress. In addition, we present a manual and an automated approach to evaluate the quality of generated speeches."}, {"heading": "1 Introduction", "text": "Many political speeches have the same structures and characteristics, regardless of the actual topic. Phrases and arguments keep recurring, pointing to a particular political affiliation or opinion. We want to use these remarkable patterns to train a system that generates new speeches. As there are major differences between political parties, we want the system to take into account the political affiliation and opinion of the intended speaker. The aim is to create speeches in which no one can see the difference from handwritten speeches. In this report, we first discuss related works that deal with similar or related methods, then we describe and analyze the data set we use. Next, we present the methods by which we implement our system, and we describe methods that have not been used in the final implementation, then we describe an experiment that has been carried out and how we evaluate the results, and finally we close our work and give an outlook. In the appendix to this report, we include the speeches produced from the experiment."}, {"heading": "2 Related work", "text": "This year it is more than ever before."}, {"heading": "3 Data set", "text": "The most important data source for this project is the Convote dataset [25], which contains a total of 3,857 speech segments from 53 debates in the US Congress in 2005. Each speech segment can be related to its debate, speaker, speaker party, and speaker voice, which serves as the basic label for the speech. Originally, the dataset was created as part of the Get out the vote project [18]. The authors used the dataset to form a classifier to determine whether a speech constitutes support or rejection of a bill. They not only analyzed the speeches individually, but also examined similarities and discrepancies with the opinions of other speakers. That is, they identified references in the speech segments, determined the objectives of these references, and decided whether a reference constitutes agreement or rejection. However, we focus only on the individual speech segments and disregarded references. For our work, we have single-sentence speeches, HTML tags, and corrected sentence characters removed, and then we can divide all of the Y into four, to allow us to divide a simple sentence."}, {"heading": "4 Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Language Model", "text": "We use a simple statistical language model based on n-grams. In particular, we use 6-grams. That is, for each sequence of six consecutive words, we calculate the probability that we will see the sixth word given to the previous five words. In this way, we can very quickly determine all the words that can occur after the previous five and how likely each of them is."}, {"heading": "4.2 Topic Model", "text": "For our theme model, we use a Justeson and Katz (J & K) POS tag filter for two- and three-word terms [10]. As suggested by WordHoard, we expanded the list of POS tag patterns with the sequence noun-conjunction noun. We determined the POS tags for each sentence in the corpus, and then identified all two- and three-word terms that match one of the patterns. For POS tagging, we used the maximum treebank-pos tagging model from the Natural Language Toolkit (NLTK) for Python. It uses the maximum entropy model and was trained on the subset of Penn Tree Bank Corpus [24]. Some of the terms are very general and appear very frequently in all classes. To find those terms that occur most frequently in a particular class, we calculate a significance value Z by the ratio of probability to see a word in a particular class, with these terms representing a larger meaning than a corpus (1.0)."}, {"heading": "4.3 Speech Generation", "text": "From the language model of the selected class, we get the probabilities for every 5 gram that begins a speech. From this distribution, we first select one of the 5 grams at random and use it as the beginning of our opening sentence. Then, the system begins to predict word by word until it predicts the symbol that indicates the end of the speech. To predict the next word, we first determine what topics are the previously generated speech, by checking each topic term when it appears in the speech. For each occurring term, we calculate the topic coverage TC in our speech. Topic coverage is an indicator of how well a particular topic t is represented in a speech. The following equation shows the definition of topic coverage: TC (S, c) = # Incidents of t in all speeches in the class cWe rank all topic coverage values that we select based on the topic coverage values."}, {"heading": "5 Alternative Methods", "text": "In this section, we present some alternative approaches that have been pursued in the context of this project, which have not yielded sufficiently good results and have therefore not been pursued further."}, {"heading": "5.1 Recurrent Neural Networks", "text": "Our approach was very much based on the online tutorial by Denny Britz [26]. The RNN takes a sequence of words as input and prints out the next word. We limited the vocabulary to the 6000 most common words. Words were represented by uniformly coded feature vectors. The RNN had 50 hidden layers and used Tanh as an activation function. To assess the error, we used the cross-entropy loss function. Furthermore, we used stochastic gradient descent (SGD) to minimize loss and back propagation through time (BPTT) to calculate the progressive.After 100 time periods of the network (about 14 hours), the results were still quite poor. Most of the sentences generated were grammatically incorrect. There are many options to improve the performance of RNNs, but due to the good performance this n-training has shown, we have opted for the time-intensive approach for this project not to further clean and clean."}, {"heading": "5.2 Latent Dirichlet Allocation", "text": "As an alternative to the J & K POS tag filter, we used LDA as a theme model. Specifically, we used the approach of Lau et al. [2], i.e. we removed all occurrences of stop words, replaced the remaining words, replaced the 1000 most common bigrams with individual tokens, and deleted the 200 most common terms from the vocabulary before using ordinary LDA. Since our data set contains language segments from 53 different debates, we set the number of underlying topics to 53. Some of the results were significant topics, but the majority contained no useful information. Table 4 shows some examples of good and bad results from LDA. It is evident that the extracted terms of the bad examples are very general and do not necessarily indicate a meaningful topic."}, {"heading": "5.3 Sentence-based approach", "text": "The idea of the sentence-based approach is to select whole sentences from the training data and concatenate them in a meaningful way. We start by randomly selecting a speech of the desired class and taking the first sentence of it. However, this will be the first sentence of our speech. Then, we select 20 speeches at random from the same class. We compare our first sentence with each sentence in these 20 speeches by calculating a measure of similarity. The next sentence is then determined by the successor of the sentence with the highest similarity. In the case that no sentence has sufficient similarity (similarity value below the threshold), we simply take the successor of our last sentence by selecting 20 speeches at random and comparing each sentence with the last to find the most similar sentence. This is repeated until we find the language termination by mark or the generated language at a certain length.The crucial part of this method is the similarity between two sentences at random."}, {"heading": "6 Experiments", "text": "This section describes the experimental setup with which we evaluated our system. In addition, we present two different approaches for evaluating the quality of generated speeches."}, {"heading": "6.1 Setup", "text": "In order to test our applied methods, we performed an experimental evaluation. In this experiment, we generated ten speeches, five for class DN and five for class RY. We set the weighting factor \u03bb to 0.5, which means that the topic and the language model have an equal impact on predicting the next word. Afterwards, the quality of the generated speeches was evaluated. We used two different evaluation methods: a manual evaluation and an automatic evaluation. Both methods are described in more detail in the following paragraphs of this section. The generated speeches can be found in the appendix to this report."}, {"heading": "6.2 Manual Evaluation", "text": "For the manual evaluation, we have defined a list of evaluation criteria, i.e. a generated speech is evaluated by evaluating each criterion and scoring it with a score between 0 and 3. Table 5 lists all evaluation criteria and describes the significance of the various scores."}, {"heading": "6.3 Automatic Evaluation", "text": "Automatic evaluation aims to evaluate both the grammatical correctness and the consistency of the speech in terms of its content. To evaluate grammatical correctness, we identify its POS tags for each sentence of the speech. Then, we check all sentences of the entire corpus to see if you have the same sequence of POS tags. To have a sentence with the same POS tag structure does not necessarily mean that the grammar is correct. Neither does the absence of a matching sentence imply the presence of an error. But it points in a certain direction. In addition, we let the system output the sentence for which it could not find a matching sentence, so that we can evaluate these sentences manually. To evaluate the content of the generated speech, we determine the mix of topics covered by the speech and arrange them according to their topic coverage. This gives us information about the primary topic and secondary topics. Then we do the same thing for each speech in our dataset, the same class that listened to and the speech that generated."}, {"heading": "7 Results", "text": "In this section we present the results of our experiments. Table 6 shows the results of the manual evaluation. Note that each criterion is between 0 and 3, resulting in a maximum overall score of 12. The overall score achieved ranges from 5 to 10 with an average of 8.1. In particular, grammatical correctness and sentence transitions were very good. Each criterion scored an average of 2.3 out of 3. Speech content provided the lowest scores. This indicates that the topic model may need improvement.Table 7 shows the results of the automatic evaluation. The automatic evaluation pretty much confirms the results of the manual evaluation. Most speeches that scored high in the manual evaluation also performed well in the automatic evaluation. In addition, it confirms that the grammatical correctness of the speeches is very good overall, while the content is slightly behind."}, {"heading": "8 Conclusion", "text": "We have shown that n-grams and J & K POS Tag Filters are very effective as language and theme models for this task. We have shown how these models can be combined into a system that delivers good results. In addition, we have presented various methods for evaluating the quality of generated texts. In an experimental evaluation, our system has performed very well, especially grammatical correctness and sentence transitions of most speeches were very good. However, there are no comparable systems that allow direct comparisons.Despite the good results, it is very unlikely that these methods will actually be used to generate speeches for politicians."}, {"heading": "Appendix", "text": "Speeches generated from experiments"}, {"heading": "DN#1", "text": "START Mr. Speaker, I thank my colleague on the Regulatory Committee. I fully support this resolution and urge my colleagues to support this bill and urge my colleagues to support the bill. Mr. Speaker, supporting this rule and supporting this bill is good for small businesses. It's great for American small businesses, for the high street, for job creation. We have an economy that has created nearly 2 million jobs in recent months: clothing, textiles, transportation and equipment, electronic components and equipment, chemicals, industrial and commercial equipment and computers, instruments, photographic equipment, metals, food, wood and wood products. Practically any state in the Union can claim at least one of these industrial sectors. In fact, a young girl, lucy, wanted to ensure that the economy would continue to grow. This should not be done with borrowed money, at a safe time. It should be done with a growing economy."}, {"heading": "DN#2", "text": "START Mr. Speaker, for years, honest but unhappy consumers have had the opportunity to seek bankruptcy protection and settle their reasonable and valid debts. As to how the system should work, the bankruptcy court assesses various factors such as income, assets and debts to determine what debts can be paid and how consumers can get back on their feet."}, {"heading": "DN#3", "text": "START Mr. Speaker, I am returning the balance of my time, and I would like, at last, to commend the chairman of the committee, there will be strict oversight of the Justice Department on a regular and timely basis, and the answer to how many violations of civil liberties have been proven is not one. Repeatedly, they have said that there are no violations of civil liberties that the inspector general has been able to uncover. Furthermore, I have resisted prematurely repealing or extending the sunset before this Congress, because I thought it was important that oversight be done as long as possible so that Congress can vote and make a decision. Mr. Speaker, I reserve the balance of my time, and I would like to thank the gentleman from Texas for putting together this package and for all the work that he and his staff put into this law. This was an important thing for us, and I think that we have put forward a good law at the end of this dark age, and the Lord says: because I sometimes deal with these centers to limit the costs."}, {"heading": "DN#4", "text": "Mr. START spokesman, for years, honest but unhappy consumers have had the opportunity to lobby for bankruptcy protection and pay off their reasonable and valid debts. As the system is supposed to work, the bankruptcy court assesses various factors such as income, assets and debt to determine what debts can be paid and how consumers can get back on their feet, they need money to pay for childcare, they need transportation, it allows them to be restored, and we think that would certainly be very helpful, and then it also allows faith organizations to offer job training. We think that this is crucial and has great potential. At this point in time, Brazil requires 23 percent of their fuel supply to be ethanol. We could certainly reach 7 or 8 percent in this country. Mr. Speaker, this is a very modest proposal. I think it is important that this resolution is considered quickly so that the members can be appointed to the working group and can start work and prepare a report by June 2006."}, {"heading": "DN#5", "text": "START mr. speaker, I give myself the remaining time. mr. speaker, I rise today in support of the rule on h.r. 418. Our nation's immigration policy has been of the utmost concern in recent years, and for good reason. With between eight and twelve million illegal aliens in the United States, the late Ronald Wilson reagan anchored these three words as part of American policy: trust, but check. Legislation on the ground today is about checking. I say as someone who opposed a trade agreement with China that this law provides the surveillance capacity needed to understand what is happening in international trade. Simply put, madam speaker, if you want to cut these things, you can insert it into your program. if you don't like that, better go out and lobby against what they're doing in vitro fertilization clinics across the U.S., about 2 percent are discarded annually - that's about 8,000 - to 11,000 class actions that could be used for research."}, {"heading": "RY#1", "text": "START Mr. Speaker, I give 2 minutes to the lord of Illinois (mr. hyde), my dear friend, with whom I agree on some things, but not on this issue, even though most of the bill I know, with the lord of California (mr. lantos) and the lord of virginity with her very clever deputy, gives a chance to help the consumer and declare his energy independence. I would also like to point out that this law is far from perfect. In many ways, it is troubling. This Congress has demonstrably lax oversight of the government, and there is a difference. END"}, {"heading": "RY#2", "text": "START mr. speaker, the gentleman is absolutely right. The amazing thing about me as I listened to the Republicans in the last hour is when they tried to make the analogy to their households and talk about their children. and one of the most significant broken promises is in providing higher educational opportunities for minorities and low-income students. I am so proud of the fact that every Iraqi schoolchild on the opening day of school had received a book bag with the U.S. seal, pencils, pads, all sorts of things, free of charge. I had just returned from Iraq, and they were there on the first day of this new Congress, the Republican majority demonstrating publicly what has been evident for some time, their arrogance, their short-sighted focus on their political life instead of deciding how we govern."}, {"heading": "RY#3", "text": "A month ago, the House of Representatives rejected this bill because it failed to address the priorities of the American people: good jobs, safe communities, quality education, and access to health care. With over 7 million Americans out of work, the bill cuts $437 million from education and employment services, the lowest level of adult education grants in a decade. This bill also cuts the Community College Initiative, the president's initiative for community colleges, an effort to train workers for high-skilled, high-paying jobs, cuts $125 million from funding provided last year, and refuses the help the president spoke of to provide continued education to 100,000 Americans to help them get a new job. This bill also lowers job-search assistance by 11 percent, and cuts $245 million from state unemployment insurance and employment agencies that help 1.9 million people. This bill is no better than the 95 percent cost of going to college each year, though the cost of college increases."}, {"heading": "RY#4", "text": "START mr. speaker, I return 2 minutes to the Gentlewoman from California (mrs. capps) pointed out after the knowledge was available and continued to track the use of this compound as an adjunct to the fuels of our cars. these communities are now stuck with the cost of either cleaning up this drinking water supply, finding an alternative source and dealing with it, and they need to do. now to suggest that we are going to give seniors to keep them in nursing homes with Alzheimer's and Parkinson's disease, just cut further. Give more tax breaks to the richest tenth of 1 percent. They call it the death tax. I think that's a mistake in the bill. That leads to the second point. The bill explicitly mentions weight gain and obesity. Well, I think most of us have a sense of what obesity is. Weight gain is an entirely different issue, and weight gain can't occur through obesity, not through the combination of many medical reasons; we can put calorie counts into one another."}, {"heading": "RY#5", "text": "START mr. speaker, I yield 2 minutes to the gentleman from texas (ms. jackson-lee), the gentleman from new jersey (mr. andrews), for the leadership he has shown on this issue. here we are again, mr. speaker. year after year trying to get in federal court. What it also does is provide the opportunity for those who can secure their local attorney to bring them to a state court and burden them with the responsibility of finding some high-priced consultants they can't afford to buy groceries. Seven million more people, an increase of 12 percent, and what does this combination of reconciliation to give tax cuts to people making more than $500,000. footnote right. what about the committees of jurisdiction already in Congress. And what about creating a circus atmosphere that drains resources from this Congress is incomprehensible. shameful, the House will have no opportunity to vote on the hurried-mendez legislation, independently of gentlemen already in Congress. And what about creating a depleted environment that drains resources from this congress, is incomprehensible. shameful, the House will have no opportunity to do so because Republicans can't do it, because Republicans have partially blocked it."}], "references": [{"title": "Latent Dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "On collocations and topic models", "author": ["J.H. Lau", "T. Baldwin", "D. Newman"], "venue": "ACM Transactions on Speech and Language Processing (TSLP),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "A study using n-gram features for text categorization", "author": ["J. Frnkranz"], "venue": "Austrian Research Institute for Artifical Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "N-gram-based text categorization", "author": ["W.B. Cavnar", "J.M. Trenkle"], "venue": "Ann Arbor MI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "From n-grams to collocations: An evaluation of Xtract", "author": ["Smadja", "F. A", "June"], "venue": "In Proceedings of the 29th annual meeting on Association for Computational Linguistics (pp. 279-284)", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1991}, {"title": "Rapid incremental parsing with repair", "author": ["Abney", "October"], "venue": "In Proceedings of the 6th New OED Conference: Electronic Text Research (pp", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "Topical n-grams: Phrase and topic discovery, with an application to information retrieval", "author": ["X. Wang", "A. McCallum", "Wei", "October"], "venue": "In Data Mining,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Topic modeling: beyond bag-of-words", "author": ["Wallach", "H. M", "June"], "venue": "In Proceedings of the 23rd international conference on Machine learning (pp. 977-984)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Technical terminology: some linguistic properties and an algorithm for identification in text", "author": ["J.S. Justeson", "S.M. Katz"], "venue": "Natural language engineering,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1995}, {"title": "Simplex NPs clustered by head: a method for identifying significant topics within a document", "author": ["N. Wacholder"], "venue": "In The Computational Treatment of Nominals: Proceedings of the Workshop (pp. 70-79)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "A correlated topic model of science", "author": ["D.M. Blei", "J.D. Lafferty"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Building applied natural language generation systems", "author": ["E. Reiter", "R. Dale"], "venue": "Natural Language Engineering,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "Choosing words in computer-generated weather forecasts", "author": ["E. Reiter", "S. Sripada", "J. Hunter", "J. Yu", "I. Davy"], "venue": "Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "The modelexplainer", "author": ["B. Lavoie", "O. Rambow", "Reiter", "June"], "venue": "In Proceedings of the 8th international workshop on natural language generation (pp. 9-12)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1996}, {"title": "Bilingual generation of job descriptions from quasi-conceptual forms", "author": ["D.E. Caldwell", "Korelsky", "October"], "venue": "In Proceedings of the fourth conference on Applied natural language processing (pp. 1-6). Association for Computational Linguistics", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1994}, {"title": "Get out the vote: determining support or opposition from congressional floor-debate transcripts", "author": ["Matt Thomas", "Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "Political ideology detection using recursive neural networks. In Association for Computational Linguistics", "author": ["M. Iyyer", "P. Enns", "J. Boyd-Graber", "P. Resnik"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Affective norms for english words (ANEW): Stimuli, instruction manual and affective ratings. Technical report C-1", "author": ["M. Bradley", "P. Lang"], "venue": "The Center for Research in Psychophysiology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "Testing the Etch-a-Sketch Hypothesis: A Computational Analysis of Mitt Romney\u2019s Ideological Makeover During the 2012 Primary vs. General Elections", "author": ["J. Gross", "B. Acree", "Y. Sim", "N.A. Smith"], "venue": "APSA", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "[1] present in their paper a model which is known as latent Dirichlet allocation (LDA).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] claim that collocations empirically enhance topic models.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Frnkranz [3] has studied the usage of n-grams in the text-categorization domain.", "startOffset": 9, "endOffset": 12}, {"referenceID": 3, "context": "Cavnar and Trenkle [4] have also used an n-gram-based approach for text categorization.", "startOffset": 19, "endOffset": 22}, {"referenceID": 4, "context": "Smadja [5] presents a tool, Xtract, which implements methods to extracts variable-length collocations.", "startOffset": 7, "endOffset": 10}, {"referenceID": 5, "context": "In the third stage they enrich the collocations with syntactical information obtained from Cass [6].", "startOffset": 96, "endOffset": 99}, {"referenceID": 6, "context": "Wang et al [7] propose a topical n-gram model that is capable of extracting meaningful phrases and topics.", "startOffset": 11, "endOffset": 14}, {"referenceID": 7, "context": "It combines the bigram topic model [8] and LDA collocation model [9].", "startOffset": 35, "endOffset": 38}, {"referenceID": 8, "context": "Justeson and Katz [10] present a method to extract technical terms from documents.", "startOffset": 18, "endOffset": 22}, {"referenceID": 9, "context": "Wacholder [11] presents an approach for identifying significant topics within a document.", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "Blei and Lafferty [12] propose their Correlated Topic model (CTM).", "startOffset": 18, "endOffset": 22}, {"referenceID": 16, "context": "[19] apply Recursive Neural Networks (RNN) to political ideology detection.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "They performed experiments on two different dataset: the Convote dataset [25] and the Ideological Books Corpus (IBC) [21].", "startOffset": 117, "endOffset": 121}, {"referenceID": 11, "context": "The paper Building Applied Natural Language Generation Systems [13] discusses the main requirements and tasks of NLG systems.", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "For example SumTime-Mousam [14] generates a textual weather forecast based on numerical weather simulations.", "startOffset": 27, "endOffset": 31}, {"referenceID": 13, "context": "Another example is the ModelExplainer system [15] which takes as input a specification of an object-oriented class model and produces as output a text describing the model.", "startOffset": 45, "endOffset": 49}, {"referenceID": 14, "context": "Other NLG systems are used as authoring aid for example to help personnel officers to write job descriptions [16] or to help technical authors produce instructions for using software [17].", "startOffset": 109, "endOffset": 113}, {"referenceID": 15, "context": "The dataset was originally created in the course of the project Get out the vote [18].", "startOffset": 81, "endOffset": 85}, {"referenceID": 8, "context": "For our topic model we use a Justeson and Katz (J&K) POS tag filter for two- and three-word terms [10].", "startOffset": 98, "endOffset": 102}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "In this report we present a system that can generate political speeches for a desired political party. Furthermore, the system allows to specify whether a speech should hold a supportive or opposing opinion. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson & Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. Sequences of words are generated based on probabilities obtained from two underlying models: A language model takes care of the grammatical correctness while a topic model aims for textual consistency. Both models were trained on the Convote dataset which contains transcripts from US congressional floor debates. Furthermore, we present a manual and an automated approach to evaluate the quality of generated speeches. In an experimental evaluation generated speeches have shown very high quality in terms of grammatical correctness and sentence transitions.", "creator": "LaTeX with hyperref package"}}}