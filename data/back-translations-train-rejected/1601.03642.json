{"id": "1601.03642", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jan-2016", "title": "Creativity in Machine Learning", "abstract": "Recent machine learning techniques can be modified to produce creative results. Those results did not exist before; it is not a trivial combination of the data which was fed into the machine learning system. The obtained results come in multiple forms: As images, as text and as audio.", "histories": [["v1", "Tue, 12 Jan 2016 23:28:07 GMT  (1110kb,D)", "http://arxiv.org/abs/1601.03642v1", "5 pages, 4 figures"]], "COMMENTS": "5 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["martin thoma"], "accepted": false, "id": "1601.03642"}, "pdf": {"name": "1601.03642.pdf", "metadata": {"source": "CRF", "title": "Creativity in Machine Learning", "authors": ["Martin Thoma", "Tom Mitchel [Mit"], "emails": ["info@martin-thoma.de"], "sections": [{"heading": null, "text": "This paper gives a comprehensive overview of their emergence and gives some examples. It is intended to be a summary of the current work and to provide some starting points for people who are new to machine learning. I. INTRODUCTIONAccording to [Gad06], creativity is \"the ability to use one's imagination to produce new ideas, do things, etc.\" and imagination is \"the ability to form images or ideas in the head.\" Recent advances in machine learning lead to results that the author would intuitively call creative. Below, a high-level overview of several of these algorithms is described. This paper is structured as follows: Section II introduces the reader to machine learning on a very simple and superficial level, Section III gives examples of creativity with images, Section IV gives examples of machines that produce textual content, and Section V gives examples of machine learning and music. A discussion follows in Section VI."}, {"heading": "II. BASICS OF MACHINE LEARNING", "text": "The traditional approach to solving problems with the software is to program machines to do so. The task is divided into as simple subtasks as possible, the subtasks are analyzed, and the machine is instructed to process the input using human-designed algorithms to produce the desired output. However, for some tasks such as object recognition, this approach is not feasible. There are ways to many different objects, different lighting situations, variations in the rotation and arrangement of a scene in which a human thinks about and models them all. However, with the Internet, cheap computers, crowd-sourcing platforms such as Wikipedia and many websites, services such as Amazon Mechanical Turk and several other changes in the past, a lot of data has been provided."}, {"heading": "A. Google DeepDream", "text": "A similar idea was used by [VKMT13]. Consider, for example, a neural network trained to detect different images like bananas, a technique that turns the network upside down and starts with random noise. To analyze how the network looks at bananas, the random noise image is gradually optimized to produce the output \"banana.\" In addition, the changes can be limited in such a way that the statistics of the input image must be similar to natural images. An example of this is that adjacent pixels are correlated. Another technique is to amplify the output of layers, as described in [MOT15]: \"Whatever you see there, I want more of it!\" This feedback creates a loop like a small network that looks like a bird's web. \"The effect on the detection system is hard to estimate.\""}, {"heading": "B. Artistic Style Imitation", "text": "A key idea of neural networks is that they learn different representations of the data in each layer. In the case of CNNs, this can easily be visualized, as has been done in various papers [ZF14]. Normally, it is noted that the network has learned to build edge detectors in the first layer and more complex structures in the upper layers. Gatys, Ecker and Bethge showed in [GEB15] that with a skillful selection of characteristics, it is possible to separate the general style of an image from the content of an image in terms of local appearance. They reinforce their claim by applying the style of different artists to any image of their choice.3 (a) original image (b) still image (c) Apply the artistic style of Van Gogh's \"Starry Night\" to the photo of a Scottish highland catalogue. Figure 4: The algorithm takes both the original image and the still image to produce the result."}, {"heading": "C. Drawing Robots", "text": "Patrick Tresset and Frdric Fol Leymarie developed a system called AIKON (Automatic IKONic Drawing) that can automatically create sketches for portraits [TL05]. AIKON takes a digital photo, recognizes faces on them and sketches them with a pen plotter. Tresset and Leymaire use k-means clustering [KMN + 02] to segment regions of the photo with similar color, which in turn get a similar shade. Such a drawing robot could use machine learning techniques known from computer vision to recognize humans. It could use self-learning techniques to draw results that are most similar to the impression of the artist. However, the system described in [TL05] does not seem to be a machine computer program as defined by Tom Mitchell [Mit97]."}, {"heading": "IV. TEXT DATA", "text": "Digital text is the first form of natural communication in which computers were involved. It is used in the form of chats, websites, on collaborative projects such as Wikipedia, in scientific literature. Of course, it was also used in pre-digital times: in newspapers, in novels, in dramas, in religious texts such as the Bible, in books for education, in notes from conversations. This list could be continued and most of these types of texts are now also available in digital form. This digital form can be used to teach machines to generate similar texts.The simplest language model that is useful is an n-gram model. This model uses sequences of length n to model language. It can be used to obtain the probability of a third word, given the previous two words. In this way, a complete text word by word can be generated. Refinements and enhancements of this model are being discussed in the field of natural language processing, with neurons at the NLP level being correct."}, {"heading": "A. Similar Texts Generation", "text": "Karpathy trained several characters using different sets of data and gave an excellent introduction [Kar15b]. He trained them using Paul Graham's essays, all of Shakespeare's works, the Hutter Prize [H\u00fctte] 100 MB of data set from raw Wikipedia articles, the raw LATEX source file of a book on algebraic stacks and geometry, and Linux C code.With this training data, the models can generate similar texts.New works that look like Shakespeare plays, new Wikipedia articles, new Linux code, and new essays on algebraic geometry can thus be automatically generated.At first glance, they seem more authentic.The syntax was used mostly correctly, the formatting looks as expected, the sentences are grammatically correct. However, looking at the larger context, it is easy to see that the algorithm has no insight into what it does. It really matches patterns well, but it does not follow a central theme, which means that in each case the C-context will be used."}, {"heading": "B. Chatbots", "text": "Chatbots are computer programs that participate in chat rooms as autonomous agents, meaning they have similar permissions and capabilities to ordinary human users, but users can trigger a series of commands for the bot to give them valuable information or traits. A special category of chatbots are those that actively participate in conversation, which is not usually the case. One of the earliest programs in this category is ELIZA, a bot developed by Joseph Weizenbaum in the 1960s [Wei76]. This program had implemented a series of patterns to which it would respond psychologically in an apparently intelligent way.This means that the program quite often simply repeats the last sentence and adds something meaningless. According to [Curpedia 14], Weizenbaum once found his secretary - who was aware that it was a computer program - in chatting with the machine. When he looked over her shoulder, she asked him, \"Would you think of leaving the room?\" Today, the vast amount of human help being accessed by Wikipedia is always similar to the vast amount of chatbots that WikiLeaks have."}, {"heading": "V. AUDIO DATA", "text": "Common tasks of machine learning involving audio data are speech recognition, speaker identification, song identification. This leads to some rarer but interesting topics: the composition of music, the synthesis of audio as art. While the composition could be considered in Section IV, we will now examine the work done in audio synthesis."}, {"heading": "A. Emily Howell", "text": "David Cope started a project called \"Experiments in Musical Intelligence\" (EMI or Emmy for short) in 1984 [Cope]. Cope mentions that EMI was more useful to him when he used the system to \"use his syntactic dictionary and rule base to create small phrase-size textures as next possibilities.\" [Cope] In 2003, Cope launched a new project based on EMI: Emily Howell [Cop13]. This program is capable of \"creating both highly authentic replications and novel musical compositions.\" The reader may want to listen to [Cop12] to get an idea of the beauty of the music produced. According to Cope, an essential part of the music is \"a set of instructions for creating other, but highly related, self-replications.\" Emmy Copy was programmed to find these instructions."}, {"heading": "B. GRUV", "text": "Recurrent neural networks - LSTM networks, to be precise - are used in [NV15] along with gated recurrent units (GRU) to build a network that can be trained to generate music. Instead of taking notes or MIDI files directly, Nayebi and Vitelli used raw audio waveforms as input. These audio waveforms are feature vectors that are modeled for the time steps 0, 1,..., t \u2212 1, t. The network receives these feature vectors X1,..., Xt and must predict the following feature vector Xt + 1. This means it continues the music. Since the input is continuous, the problem was modeled as a regression task. Discrete Fourier Transformation (DFT) was used on chunks of the length N of the music to obtain features in the frequency domain. An implementation is found in [VN15] and a demonstration is found in [Vit15]."}, {"heading": "C. Audio Synthesization", "text": "Using the techniques described above, 5 neural networks can be trained to produce note by note. However, it is desirable to let several notes play at the same time. Daniel Johnson applied this idea and some others. He wrote a very good introduction to neural networks for music composition that explains these ideas [Joh15b]. Sample compositions are also available there. He also provided the code for his Biaxial Recurrent Neural Network at [Joh15a]."}, {"heading": "VI. DISCUSSION", "text": "What do these examples mean for our understanding of creativity? Does it affect how much we value art? Could we better define art and creativity after achieving these and similar results? I think we could adjust our understanding of creativity in the same way we adjusted our understanding of algorithmically hard problems after Deep Blue's victory over reigning chess world champion Garry Kasparov in 1997. However, it is now obvious that machine learning cannot compete with human artists. Today's state of the art, which is based solely on machine learning, does not follow a central theme and lacks planning capability. Although clever algorithms for composing music have been implemented, it seems that there is still a lot of monitoring at play."}, {"heading": "A. Shakespeare", "text": "DUKE VINCENTIO: Well, your mind is in the care of both sides and you. Second, Lord, you would be governed after this hall, and my beautiful nuances began to be conveyed by the fact that I have the noble souls whose hearts I have at the heart of wars.Clown: Come, sir, I will make your worship come true. VIOLA: I will drink it. Oh, I think you will approach it, and on the day you would get little rain, you would never feed it, and if you are only a chain and subject to its death, I should not sleep. Second, Senator, you are away from this misery that weighs on my soul, fragile and strong should be buried if I destroyed the earth and the thoughts of many statesmen."}, {"heading": "B. Wikipeda", "text": "His generals were the powerful rulers of Portugal in the [[Protestant imminence]], which was, so to speak, located directly in the Cantonese communication that followed a ceremony and inspired imprisonment, education and training. [[Antioch, Perth, October 25 | 21]], the emperor returned to discover that the Kingdom of Costa Rica had failed to bring about the [[Thrales]], a famous German movement based on a more subservient, non-doctrinal and sexual position of power, near Italy, to conquer India in the conflict, and that the Hungarian National Party had signed the [[liberalization and intrigue]]. (http: / www.panny.com / 7878787878787878.com)"}, {"heading": "C. Linux Code, 1", "text": "/ * 7 * Increment the size file of the new incorrect UI _ > > FILTER group information * & sel > Inc. * / static int indicate _ policy (void) {int error; if (fd = = MARN _ EPT) {/ * * The kernel blank will include it in userspace. * / if (ss- > segment < mem _ total) unblock _ graph _ and _ set _ blocked (); elseret = 1; goto bail;} segaddr = in _ SB (in.addr); selector = seg / 16; setup _ works = true; for (i = 0; i < blocks; i + +) {seq = buf [i +]; bd- > bd- > bd.next + i * search; if (fd) {current = ltltltltltltltltltltltltltltltltltltltltltltltltltltltltltltU;} rw- > name = \"jbbregs.\""}], "references": [{"title": "Experiments in music intelligence (emi),", "author": ["D. Cope"], "venue": null, "citeRegEx": "Cope,? \\Q1987\\E", "shortCiteRegEx": "Cope", "year": 1987}, {"title": "Now then,", "author": ["A. Curtis"], "venue": "BBC, Jul. 2014. [Online]. Available: http://www.bbc.co.uk/blogs/adamcurtis/entries/", "citeRegEx": "Curtis,? \\Q2014\\E", "shortCiteRegEx": "Curtis", "year": 2014}, {"title": "A neural algorithm of artistic style,", "author": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"], "venue": "arXiv preprint arXiv:1508.06576,", "citeRegEx": "Gatys et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gatys et al\\.", "year": 2015}, {"title": "Long short-term memory,", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "Deep residual learning for image recognition,", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Biaxial recurrent neural network for music composition,", "author": ["D. Johnson"], "venue": "GitHub, Aug", "citeRegEx": "Johnson,? \\Q2015\\E", "shortCiteRegEx": "Johnson", "year": 2015}, {"title": "An efficient k-means clustering algorithm: analysis and implementation,", "author": ["T. Kanungo", "D. Mount", "N. Netanyahu", "C. Piatko", "R. Silverman", "A. Wu"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Kanungo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kanungo et al\\.", "year": 2002}, {"title": "Inceptionism: Going deeper into neural networks,", "author": ["A. Mordvintsev", "C. Olah", "M. Tyka"], "venue": "googleresearch.blogspot.co.uk, Jun", "citeRegEx": "Mordvintsev et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mordvintsev et al\\.", "year": 2015}, {"title": "Neural Networks and Deep Learning", "author": ["M.A. Nielsen"], "venue": "Determination Press,", "citeRegEx": "Nielsen,? \\Q2015\\E", "shortCiteRegEx": "Nielsen", "year": 2015}, {"title": "GRUV: Algorithmic music generation using recurrent neural networks,", "author": ["A. Nayebi", "M. Vitelli"], "venue": null, "citeRegEx": "Nayebi and Vitelli,? \\Q2015\\E", "shortCiteRegEx": "Nayebi and Vitelli", "year": 2015}, {"title": "Style transfer for headshot portraits,", "author": ["Y. Shih"], "venue": "[Online]. Available: https://www.youtube.com/watch?v=", "citeRegEx": "Shih,? \\Q2014\\E", "shortCiteRegEx": "Shih", "year": 2014}, {"title": "Style transfer for headshot portraits,", "author": ["Y. Shih", "S. Paris", "C. Barnes", "W.T. Freeman", "F. Durand"], "venue": "ACM Transactions on Graphics (TOG), vol. 33,", "citeRegEx": "Shih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shih et al\\.", "year": 2014}, {"title": "Algorithmic music generation with recurrent neural networks,", "author": ["M. Vitelli"], "venue": null, "citeRegEx": "Vitelli,? \\Q2015\\E", "shortCiteRegEx": "Vitelli", "year": 2015}, {"title": "Hoggles: Visualizing object detection features,", "author": ["C. Vondrick", "A. Khosla", "T. Malisiewicz", "A. Torralba"], "venue": "Computer Vision (ICCV),", "citeRegEx": "Vondrick et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Vondrick et al\\.", "year": 2013}, {"title": "A neural conversational model,", "author": ["O. Vinyals", "Q. Le"], "venue": "arXiv preprint arXiv:1506.05869,", "citeRegEx": "Vinyals and Le,? \\Q2015\\E", "shortCiteRegEx": "Vinyals and Le", "year": 2015}, {"title": "Computer Power and Human Reason: From Judgement to Calculation", "author": ["J. Weizenbaum"], "venue": "W.H.Freeman & Co Ltd,", "citeRegEx": "Weizenbaum,? \\Q1976\\E", "shortCiteRegEx": "Weizenbaum", "year": 1976}, {"title": "Visualizing and understanding convolutional networks,", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Vision\u2013ECCV", "citeRegEx": "Zeiler and Fergus,? \\Q2014\\E", "shortCiteRegEx": "Zeiler and Fergus", "year": 2014}], "referenceMentions": [], "year": 2016, "abstractText": "Recent machine learning techniques can be modified to produce creative results. Those results did not exist before; it is not a trivial combination of the data which was fed into the machine learning system. The obtained results come in multiple forms: As images, as text and as audio. This paper gives a high level overview of how they are created and gives some examples. It is meant to be a summary of the current work and give people who are new to machine learning some starting points.", "creator": "LaTeX with hyperref package"}}}