{"id": "1601.04105", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2016", "title": "Learning the Semantics of Structured Data Sources", "abstract": "Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs. However, they rarely provide a semantic model to describe their contents. Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data. Such models are the key ingredients to automatically publish the data into knowledge graphs. Manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem. Most of the related work focuses on semantic annotation of the data fields (source attributes). However, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical.", "histories": [["v1", "Sat, 16 Jan 2016 00:55:25 GMT  (5164kb,D)", "http://arxiv.org/abs/1601.04105v1", "Web Semantics: Science, Services and Agents on the World Wide Web, 2016"]], "COMMENTS": "Web Semantics: Science, Services and Agents on the World Wide Web, 2016", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mohsen taheriyan", "craig a knoblock", "pedro szekely", "jose luis ambite"], "accepted": false, "id": "1601.04105"}, "pdf": {"name": "1601.04105.pdf", "metadata": {"source": "CRF", "title": "Learning the Semantics of Structured Data Sources", "authors": ["Mohsen Taheriyan", "Craig A. Knoblock", "Pedro Szekely", "Jos\u00e9 Luis Ambite"], "emails": ["mohsen@isi.edu", "knoblock@isi.edu", "pszekely@isi.edu", "ambite@isi.edu"], "sections": [{"heading": null, "text": "Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs automatically contain an enormous amount of structured data that can be used to build and expand knowledge graphs. However, they rarely provide a semantic model to describe their contents. Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and relationships within the data. Such models are the key components for automatically publishing the data in knowledge graphs. Manually modelling the semantics of data sources requires considerable effort and expertise, and while desirable, the automatic creation of these models is a difficult problem. Most of the related work focuses on the semantic annotation of the data fields (source attributes). The construction of a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical. We present a novel approach that automatically evaluates knowledge from a domain-semantic source to the pre-semantic and the domain-semantic models."}, {"heading": "1. Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "2. Motivating Example", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to fight, to move, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "3. Learning Semantic Models", "text": "Let O have the domain Ontology15 and {sm (s1), sm (s2), \u00b7 \u00b7, sm (sn)} is a set of well-known semantic models that correspond to the data sources {s1, s2, \u00b7, sn}. Given the sample data from a new source s (a1, a2, \u00b7 \u00b7, am) is named the target source where {a1, a2, \u00b7 \u00b7, am} are the source attributes, our goal is to automatically calculate a semantic model sm (s) that captures the intended meaning of source s. In our example, sm (dma) and sm (npg) are the known semantic models, and the source slides are the new source for which we want to automatically learn semantic modeling. The main idea is that data sources in the same domain usually provide overlapping data."}, {"heading": "3.1. Learning Semantic Types of Source Attributes", "text": "This year it is more than ever before."}, {"heading": "3.2. Building A Graph from Known Semantic Models, Semantic Types, and Domain Ontology", "text": "In fact, most of them will be able to get to the top without being able to get to the top."}, {"heading": "3.3. Mapping Source Attributes to the Graph", "text": "This year it is so far that it will be able to call the mentioned rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the \"rf the rf the rf the\" rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the r"}, {"heading": "3.4. Generating and Ranking Semantic Models", "text": "ndU \"s nvo nde nlrheeueecnS,\" so rf\u00fc ide rf\u00fc ide nlrf\u00fc rf\u00fc ide nlrf\u00fc-eaeaeaeaeaJnlrh-eaJnlrh-eaJnlrrf\u00fc nlrf\u00fc ide nlrf\u00fc-eaeaJnlrrh-eaeaeaeJnlrh-eaeaeJnlrh-nlrf\u00fc nlrrf\u00fc ide nlrrrrrf\u00fc-eaeaeaeaeaeaeaeaeaeaeaeeeeSrh-nlrrrrrrf\u00fc nlrrrrrrrf\u00fc ide nlrrrrrreaeaeaeaeaeaeaeaeaeaeeaeaeeSrteeaeeeaeeeeeeeeeecrh-nlrh-nlrrrteeeeeeeeeeaeecrh-rh-nlrteeaeaeaeeaeeerteeerteaeaerrrreeaeaerrrreeeeeaeeeerrrreeeeeaeaeaeaeeerrrreeaeaeaeaeeeeeerrrreeaeaeaeaeeeeerrrrreaeaeaeaeaeaeaeaeaeaeeeeeeeeeeerrrrrrh-eaeaeaeaeaeeaeaeaeaeaeaeeerrrrrrh-eaeaeaeaeaeaeaeaeaeaeaeeaeaeaeaeaeeaeae"}, {"heading": "4. Evaluation", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "4.1. Scenario 1", "text": "In the first scenario, we assumed that each source attribute would be commented on with its correct semantic type. The goal was to see how well our approach learns the attribute relationships using the correct semantic types. Figure 9 illustrates the average precision and retrieval of all learned semantic models (sm \"(s1), \u00b7 \u00b7, sm\" (s29) for each Mj (j. \"0.. 28\") for each dataset. Since the correct semantic types are given, we excluded their corresponding triples in the calculation of precision and recall. That is, we compared only the links between the class nodes in the gold state models with the links between the class nodes in the articulated models. We call such linkages internal linkages that are created between the class nodes in semantic models. The total number of linkages in the datasets is sed444, which corresponds to sources 331."}, {"heading": "4.2. Scenario 2", "text": "In the second half of the year, the number of people in employment in the US will fall by more than a third."}, {"heading": "5. Related Work", "text": "In fact, it is the case that most of them are able to move into another world, in which they are able to move, in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which"}, {"heading": "6. Discussion", "text": "This year, it is time for us to set out to find a solution that paves the way to the future."}, {"heading": "Acknowledgements", "text": "This research was supported in part by the National Science Foundation under grant number 1117913 and in part by the Defense Advanced Research Projects Agency (DARPA) through AFRL contract numbers FA8750-14-C0240 and FA8750-16-C-0045. The U.S. government is authorized to reproduce and distribute copies for government purposes, regardless of the copyright comments contained therein. The views and conclusions contained herein are those of the authors and should not be interpreted to necessarily represent the official guidelines or endorsements of NSF, DARPA, AFRL or the U.S. government. We thank the anonymous critics for their valuable comments and suggestions for improving the paper. We are also grateful to Yinyi Chen for her help in creating the gold standard models for our review."}], "references": [{"title": "Principles of Data Integration", "author": ["A. Doan", "A. Halevy", "Z. Ives"], "venue": "Morgan Kauffman", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "A", "author": ["L. Han", "T. Finin", "C. Parr", "J. Sachs"], "venue": "Joshi, RDF123: From Spreadsheets to RDF", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Semantics Enhanced Services: METEOR-S", "author": ["A.P. Sheth", "K. Gomadam", "A. Ranabahu"], "venue": "SAWSDL and SA-REST, IEEE Data Eng. Bulletin 31 (3) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "XLWrap - Querying and Integrating Arbitrary Spreadsheets with SPARQL", "author": ["A. Langegger", "W. W\u00f6\u00df"], "venue": "in: A. Bernstein, D. R. Karger, T. Heath, L. Feigenbaum, D. Maynard, E. Motta, K. Thirunarayan (Eds.), International Semantic Web Conference, Vol. 5823 of Lecture Notes in Computer Science, Springer", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "A", "author": ["S.S. Sahoo", "W. Halb", "S. Hellmann", "K. Idehen", "T.T. Jr", "S. Auer", "J. Sequeda"], "venue": "Ezzat, A Survey of Current Approaches for Mapping of Relational Databases to RDF ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Automated Mapping Generation for Converting Databases into Linked Data", "author": ["S. Polfliet", "R. Ichise"], "venue": "in: A. Polleres, H. Chen (Eds.), ISWC Posters&Demos, Vol. 658 of CEUR Workshop Proceedings, CEUR-WS.org", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Annotating and Searching Web Tables Using Entities", "author": ["G. Limaye", "S. Sarawagi", "S. Chakrabarti"], "venue": "Types and Relationships, PVLDB 3 (1) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "RDOTE - Transforming Relational Databases into Semantic Web Data", "author": ["K.N. Vavliakis", "T.K. Grollios", "P.A. Mitkas"], "venue": "in: A. Polleres, H. Chen (Eds.), ISWC Posters & Demos, Vol. 658 of CEUR Workshop Proceedings, CEUR-WS.org", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "J", "author": ["L. Ding", "D. DiFranzo", "A. Graves", "J. Michaelis", "X. Li", "D.L. McGuinness"], "venue": "A. Hendler, TWC Data-gov Corpus: Incrementally Generating Linked Government Data from data.gov, in: M. Rappa, P. Jones, J. Freire, S. Chakrabarti (Eds.), WWW, ACM", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "\u00d3scar Corcho", "author": ["V. Saquicela", "L.M.V. Bl\u00e1zquez"], "venue": "Lightweight Semantic Annotation of Geospatial RESTful Services, in: Proceedings of the 8th Extended Semantic Web Conference (ESWC)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Recovering Semantics of Tables on the Web", "author": ["P. Venetis", "A. Halevy", "J. Madhavan", "M. Pa\u015fca", "W. Shen", "F. Wu", "G. Miao", "C. Wu"], "venue": "Proc. VLDB Endow. 4 (9) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Understanding Tables on the Web", "author": ["J. Wang", "H. Wang", "Z. Wang", "K.Q. Zhu"], "venue": "in: P. Atzeni, D. W. Cheung, S. Ram (Eds.), ER, Vol. 7532 of Lecture Notes in Computer Science, Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Semantic Message Passing for Generating Linked Data from Tables", "author": ["V. Mulwad", "T. Finin", "A. Joshi"], "venue": "in: The Semantic Web - ISWC 2013, Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Assigning Semantic Labels to Data Sources", "author": ["R. Krishnamurthy", "A. Mittal", "C.A. Knoblock", "P. Szekely"], "venue": "in: Proceedings of the 12th Extended Semantic Web Conference (ESWC)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "A Scalable Approach to Learn Semantic Models of Structured Sources", "author": ["M. Taheriyan", "C.A. Knoblock", "P. Szekely", "J.L. Ambite"], "venue": "in: Semantic Computing (ICSC), 2014 IEEE International Conference on", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "A Graph-based Approach to Learn Semantic Descriptions of Data Sources", "author": ["M. Taheriyan", "C.A. Knoblock", "P. Szekely", "J.L. Ambite"], "venue": "in: Procs. 12th International Semantic Web Conference (ISWC)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "A Data Model for Cross-domain Data Representation", "author": ["S. Hennicke", "M. Olensky", "V.D. Boer", "A. Isaac", "J. Wielemaker"], "venue": "The Europeana Data Model in the Case of Archival and Museum Data, in: Schriften zur Informationswissenschaft 58, Proceedings des 12. Internationalen Symposiums der Informationswissenschaft ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "The CIDOC Conceptual Reference Module: An Ontological Approach to Semantic Interoperability of Metadata", "author": ["M. Doerr"], "venue": "AI Mag. 24 (3) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "R2RML: RDB to RDF Mapping Language", "author": ["S. Das", "S. Sundara", "R. Cyganiak"], "venue": "W3C Recommendation 27 September 2012, http://www.w3.org/TR/r2rml/ ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Semi- Automatically Mapping Structured Sources into the Semantic Web", "author": ["C. Knoblock", "P. Szekely", "J.L. Ambite", "A. Goel", "S. Gupta", "K. Lerman", "M. Muslea", "M. Taheriyan", "P. Mallick"], "venue": "in: Proc. 9th Extended Semantic Web Conference", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Connecting the Smithsonian American Art Museum to the Linked Data Cloud", "author": ["P. Szekely", "C.A. Knoblock", "F. Yang", "X. Zhu", "E. Fink", "R. Allen", "G. Goodlander"], "venue": "in: Proceedings of the 10th Extended Semantic Web Conference (ESWC), Montpellier", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Exploiting Semantics of Web Services for Geospatial Data Fusion", "author": ["P. Szekely", "C.A. Knoblock", "S. Gupta", "M. Taheriyan", "B. Wu"], "venue": "in: Proceedings of the SIGSPATIAL International Workshop on Spatial Semantics and Ontologies ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Semi- Automatically Modeling Web APIs to Create Linked APIs", "author": ["M. Taheriyan", "C.A. Knoblock", "P. Szekely", "J.L. Ambite"], "venue": "in: Proceedings of the Linked APIs for the Semantic Web Workshop (LAPIS)", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Rapidly Integrating Services into the Linked Data Cloud", "author": ["M. Taheriyan", "C.A. Knoblock", "P. Szekely", "J.L. Ambite"], "venue": "in: ISWC, Boston, MA", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Testing Statistical Hypotheses", "author": ["E.L. Lehmann", "J.P. Romano"], "venue": "3rd Edition, Springer Texts in Statistics, Springer, New York", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Steiner Problem in Networks - A Survey", "author": ["P. Winter"], "venue": "Networks 17 ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1987}, {"title": "An Approximate Solution for the Steiner Problem in Graphs", "author": ["H. Takahashi", "A. Matsuyama"], "venue": "Math.Japonica 24 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1980}, {"title": "A Fast Algorithm for Steiner Trees", "author": ["L.T. Kou", "G. Markowsky", "L. Berman"], "venue": "Acta Informatica 15 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1981}, {"title": "A Faster Approximation Algorithm for the Steiner Problem in Graphs", "author": ["K. Mehlhorn"], "venue": "Information Processing Letters 27 (3) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1988}, {"title": "Keyword Searching and Browsing in Databases Using BANKS", "author": ["G. Bhalotia", "A. Hulgeri", "C. Nakhe", "S. Chakrabarti", "S. Sudarshan"], "venue": "in: Proceedings of the 18th International Conference on Data Engineering", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2002}, {"title": "Mean reciprocal rank", "author": ["N. Craswell"], "venue": "in: Encyclopedia of Database Systems", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Relational and XML Data Exchange", "author": ["M. Arenas", "P. Barcelo", "L. Libkin", "F. Murlak"], "venue": "Morgan & Claypool, San Rafael, CA", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Schema Matching and Mapping", "author": ["Z. Bellahsene", "A. Bonifati", "E. Rahm"], "venue": "1st Edition, Springer", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2011}, {"title": "A Survey of Approaches to Automatic Schema Matching", "author": ["E. Rahm", "P.A. Bernstein"], "venue": "VLDB Journal 10 (4) ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2001}, {"title": "iMAP: Discovering Complex Semantic Matches between Database Schemas", "author": ["R. Dhamankar", "Y. Lee", "A. Doan", "A. Halevy", "P. Domingos"], "venue": "in: International Conference on Management of Data (SIGMOD), New York, NY", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2004}, {"title": "Clio: Schema Mapping Creation and Data Exchange", "author": ["R. Fagin", "L.M. Haas", "M. Hern\u00e1ndez", "R.J. Miller", "L. Popa", "Y. Velegrakis"], "venue": "in: Conceptual Modeling: Foundations and Applications", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "Data Exchange: Semantics and Query Answering", "author": ["R. Fagin", "P.G. Kolaitis", "R.J. Miller", "L. Popa"], "venue": "Theoretical Computer Science 336 (1) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "++Spicy: an OpenSource Tool for Second-Generation Schema  Mapping and Data Exchange", "author": ["B. Marnette", "G. Mecca", "P. Papotti", "S. Raunich", "D. Santoro"], "venue": "in: Procs. VLDB, Seattle, WA", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "B", "author": ["B. Alexe"], "venue": "ten Cate, P. G. Kolaitis, W.-C. Tan, Designing and Refining Schema Mappings via Data Examples, in: Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201911, ACM, New York, NY, USA", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}, {"title": "A Semantic Approach to Discovering Schema Mapping Expressions", "author": ["Y. An", "A. Borgida", "R.J. Miller", "J. Mylopoulos"], "venue": "in: Proceedings of the 23rd International Conference on Data Engineering (ICDE), Istanbul, Turkey", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2007}, {"title": "D2R MAP - A Database to RDF Mapping Language", "author": ["C. Bizer"], "venue": "in: WWW (Posters)", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2003}, {"title": "D2R Server - Publishing Relational Databases on the Semantic Web", "author": ["C. Bizer", "R. Cyganiak"], "venue": "in: Poster at the 5th International Semantic Web Conference", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2006}, {"title": "D2RQ - Treating Non-RDF Databases as Virtual RDF Graphs", "author": ["C. Bizer", "A. Seaborne"], "venue": "in: ISWC2004 (posters)", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2004}, {"title": "Triplifying Wikipedia\u2019s Tables", "author": ["E. Mu\u00f1oz", "A. Hogan", "A. Mileo"], "venue": "in: A. L. Gentile, Z. Zhang, C. d\u2019Amato, H. Paulheim (Eds.), LD4IE@ISWC, Vol. 1057 of CEUR Workshop Proceedings, CEUR-WS.org", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2013}, {"title": "DBpedia: A Nucleus for a Web of Open Data", "author": ["S. Auer", "C. Bizer", "G. Kobilarov", "J. Lehmann", "R. Cyganiak", "Z. Ives"], "venue": "in: Proceedings of the 6th International The Semantic Web and 2Nd Asian Conference on Asian Semantic Web Conference, ISWC\u201907/ASWC\u201907, Springer-Verlag, Berlin, Heidelberg", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2007}, {"title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data", "author": ["Z. Syed", "T. Finin"], "venue": "in: Agents and Artificial Intelligence, Springer", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge", "author": ["K. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "in: Proceedings of the 2008 ACM SIG- MOD International Conference on Management of Data, SIG- MOD \u201908, ACM, New York, NY, USA", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2008}, {"title": "Discovering Concept Coverings in Ontologies of Linked Data Sources", "author": ["R. Parundekar", "C.A. Knoblock", "J.L. Ambite"], "venue": "in: Proceedings of the 11th International Semantic Web Conference (ISWC), Boston, MA", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning Semantic Definitions of Online Information Sources", "author": ["M.J. Carman", "C.A. Knoblock"], "venue": "Journal of Artificial Intelligence Research 30 (1) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2007}, {"title": "Ontology Mapping: The State of the Art", "author": ["Y. Kalfoglou", "M. Schorlemmer"], "venue": "Knowl. Eng. Rev. 18 (1) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2003}, {"title": "Ontology Matching: State of the Art and Future Challenges", "author": ["S. Pavel", "J. Euzenat"], "venue": "IEEE Trans. on Knowl. and Data Eng. 25 (1) ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2013}, {"title": "Leveraging Linked Data to Infer Semantic Relations within Structured Sources", "author": ["M. Taheriyan", "C. Knoblock", "P. Szekely", "J.L. Ambite", "Y. Chen"], "venue": "in: Proceedings of the 6th International Workshop on Consuming Linked Data (COLD)", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Publishing these sources into LOD involves constructing source descriptions that represent the intended meaning of the data by specifying mappings between the sources and the domain ontology [1].", "startOffset": 191, "endOffset": 194}, {"referenceID": 1, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 2, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 3, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 4, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 5, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 6, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 7, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 8, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 9, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 10, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 11, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 12, "context": "In Semantic Web research, there is much work on mapping data sources to ontologies [2\u201313], but most focus on semantic labeling or are very limited in automatically inferring the relationships.", "startOffset": 83, "endOffset": 89}, {"referenceID": 13, "context": "Given sample data from the new source, we use a labeling technique [14] to annotate each source attribute with a set of candidate semantic types from the ontology.", "startOffset": 67, "endOffset": 71}, {"referenceID": 14, "context": "This work builds on top of our previous work on learning semantic models of sources [15, 16].", "startOffset": 84, "endOffset": 92}, {"referenceID": 15, "context": "This work builds on top of our previous work on learning semantic models of sources [15, 16].", "startOffset": 84, "endOffset": 92}, {"referenceID": 16, "context": "We evaluated our approach on a set of museum data sources modeled using two wellknown data models in the cultural heritage domain: Europeana Data Model (EDM) [17], and CIDOC Conceptual Reference Model (CIDOC-CRM) [18].", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "We evaluated our approach on a set of museum data sources modeled using two wellknown data models in the cultural heritage domain: Europeana Data Model (EDM) [17], and CIDOC Conceptual Reference Model (CIDOC-CRM) [18].", "startOffset": 213, "endOffset": 217}, {"referenceID": 18, "context": "They can also be formalized using mapping languages such as R2RML[19], which can be used for converting data sources into RDF and publishing them into the Linked Open Data (LOD) cloud or any other knowledge graph.", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "We have implemented our approach in Karma [20], our data modeling and integration framework.", "startOffset": 42, "endOffset": 46}, {"referenceID": 20, "context": "[21] used Karma to model the data from Smithsonian American Art Museum4 and then publish it into the Linked Open Data cloud.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Karma is also able to build semantic models for Web services and then exploits the created semantic models to build APIs that directly communicate at the semantic level [22\u201324].", "startOffset": 169, "endOffset": 176}, {"referenceID": 22, "context": "Karma is also able to build semantic models for Web services and then exploits the created semantic models to build APIs that directly communicate at the semantic level [22\u201324].", "startOffset": 169, "endOffset": 176}, {"referenceID": 23, "context": "Karma is also able to build semantic models for Web services and then exploits the created semantic models to build APIs that directly communicate at the semantic level [22\u201324].", "startOffset": 169, "endOffset": 176}, {"referenceID": 20, "context": "In this example, the goal is to model a set of museum data sources using EDM5, AAC6, SKOS7, Dublin Core Metadata Terms8, FRBR9, FOAF, ORE10, and ElementsGr211 ontologies and then use the created semantic models to publish their data as RDF [21].", "startOffset": 240, "endOffset": 244}, {"referenceID": 13, "context": "[14] to learn semantic types of source attributes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "For attributes with numeric data, the algorithm uses statistical hypothesis testing [25] to analyze the distribution of numeric values.", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "Score(m): The final score is the combination the values confidence(m), coherence(m), and sizeReduction(m), which are all in the range [0, 1].", "startOffset": 134, "endOffset": 140}, {"referenceID": 0, "context": "compute the final score as the weighted sum of them: score(m) = w1 confidence(m) + w2 coherence(m) + w3 sizeReduction(m), where w1, w2, and w3 are the weights, decimal values in the range [0, 1] summing up to 1.", "startOffset": 188, "endOffset": 194}, {"referenceID": 25, "context": "This problem is known as the Steiner Tree problem [26].", "startOffset": 50, "endOffset": 54}, {"referenceID": 25, "context": "The general Steiner tree problem is NP-complete, however, there are several approximation algorithms [26\u201329] that can be used to gain a polynomial runtime complexity.", "startOffset": 101, "endOffset": 108}, {"referenceID": 26, "context": "The general Steiner tree problem is NP-complete, however, there are several approximation algorithms [26\u201329] that can be used to gain a polynomial runtime complexity.", "startOffset": 101, "endOffset": 108}, {"referenceID": 27, "context": "The general Steiner tree problem is NP-complete, however, there are several approximation algorithms [26\u201329] that can be used to gain a polynomial runtime complexity.", "startOffset": 101, "endOffset": 108}, {"referenceID": 28, "context": "The general Steiner tree problem is NP-complete, however, there are several approximation algorithms [26\u201329] that can be used to gain a polynomial runtime complexity.", "startOffset": 101, "endOffset": 108}, {"referenceID": 29, "context": "rithms [30] to compute the top-k Steiner trees.", "startOffset": 7, "endOffset": 11}, {"referenceID": 19, "context": "Karma [20] provides a user friendly graphical interface enabling users to interactively build the semantic models.", "startOffset": 6, "endOffset": 10}, {"referenceID": 30, "context": "To evaluate the labeling algorithm, we use mean reciprocal rank (MRR) [31], which is useful when we consider top k semantic types.", "startOffset": 70, "endOffset": 74}, {"referenceID": 13, "context": "[14] contains a detailed analysis of the performance of the labeling algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "The problem of describing semantics of data sources is at the core of data integration [1] and exchange [32].", "startOffset": 87, "endOffset": 90}, {"referenceID": 31, "context": "The problem of describing semantics of data sources is at the core of data integration [1] and exchange [32].", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "One way to define these mappings is local-asview (LAV) descriptions where every source is defined as a view over the domain schema [1].", "startOffset": 131, "endOffset": 134}, {"referenceID": 32, "context": "In traditional data integration, the mapping generation problem is usually decomposed in a schema matching phase followed by schema mapping phase [33].", "startOffset": 146, "endOffset": 150}, {"referenceID": 33, "context": "Schema matching [34] finds correspondences between elements of the source and target schemas.", "startOffset": 16, "endOffset": 20}, {"referenceID": 34, "context": "For example, iMAP [35] discovers complex correspondences by using a set of special-purpose searchers, ranging from data overlap, to machine learning and equation discovery techniques.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "This is analogous to the semantic labeling step in our work [14], where we learn a labeling function to learn candidate semantic types for a source attribute.", "startOffset": 60, "endOffset": 64}, {"referenceID": 35, "context": "There has been much research in schema mapping, from the seminal work on Clio [36], which provided a practical system and furthered the theoretical foundations of data exchange [37] to more recent systems that support additional schema constraints [38].", "startOffset": 78, "endOffset": 82}, {"referenceID": 36, "context": "There has been much research in schema mapping, from the seminal work on Clio [36], which provided a practical system and furthered the theoretical foundations of data exchange [37] to more recent systems that support additional schema constraints [38].", "startOffset": 177, "endOffset": 181}, {"referenceID": 37, "context": "There has been much research in schema mapping, from the seminal work on Clio [36], which provided a practical system and furthered the theoretical foundations of data exchange [37] to more recent systems that support additional schema constraints [38].", "startOffset": 248, "endOffset": 252}, {"referenceID": 38, "context": "[39] generate schema mappings from examples of source data tuples and the corresponding tuples over the target schema.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[40] generate declarative mapping expressions between two tables with different schemas starting from element correspondences.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Their work is similar to our previous semiautomatic approach to build the semantic models [20], where we derive a graph from the domain ontology and the learned semantic types.", "startOffset": 90, "endOffset": 94}, {"referenceID": 4, "context": "Several approaches have been proposed to generate semantic web data from databases and spreadsheets [5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 40, "context": "D2R [41, 42] and D2RQ [43] are mapping languages that enable the user to define mapping rules between tables of relational databases and target ontologies in order to publish semantic data in RDF format.", "startOffset": 4, "endOffset": 12}, {"referenceID": 41, "context": "D2R [41, 42] and D2RQ [43] are mapping languages that enable the user to define mapping rules between tables of relational databases and target ontologies in order to publish semantic data in RDF format.", "startOffset": 4, "endOffset": 12}, {"referenceID": 42, "context": "D2R [41, 42] and D2RQ [43] are mapping languages that enable the user to define mapping rules between tables of relational databases and target ontologies in order to publish semantic data in RDF format.", "startOffset": 22, "endOffset": 26}, {"referenceID": 18, "context": "R2RML [19] is a another mapping language, which is a W3C recommendation for expressing customized mappings from relational databases to RDF datasets.", "startOffset": 6, "endOffset": 10}, {"referenceID": 7, "context": "RDOTE [8] is a tool that provides a graphical user interface to facilitate mapping relational databases into ontologies.", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "RDF123 [2] and XLWrap [4] are other tools to define mappings from spreadsheets to RDF graphs.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "RDF123 [2] and XLWrap [4] are other tools to define mappings from spreadsheets to RDF graphs.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "Polfliet and Ichise [6] use string similarity between the column names and the names of the properties in the ontology to find a mapping between the table columns and the ontology.", "startOffset": 20, "endOffset": 23}, {"referenceID": 11, "context": "[12] detect the header of Web tables and use them along with the values of the rows to map", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] used YAGO21 to annotate web tables and generate binary relationships using machine", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11] presented a scalable approach to describe the semantics of tables on the Web.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "[44] mine RDF triples from the Wikipedia tables by linking the cell values to the resources available in DBPedia [45].", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "[44] mine RDF triples from the Wikipedia tables by linking the cell values to the resources available in DBPedia [45].", "startOffset": 113, "endOffset": 117}, {"referenceID": 12, "context": "[13] used Wikitology [46], an ontology which combines some existing manually built knowledge systems such as DBPedia and Free-", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[13] used Wikitology [46], an ontology which combines some existing manually built knowledge systems such as DBPedia and Free-", "startOffset": 21, "endOffset": 25}, {"referenceID": 46, "context": "base [47], to link cells in a table to Wikipedia entities.", "startOffset": 5, "endOffset": 9}, {"referenceID": 47, "context": "[48] previously developed an approach to automatically generate conjunctive and disjunctive mappings between the ontologies of linked data sources by exploiting existing linked data instances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "Carman and Knoblock [49] use known source descriptions to learn a semantic description that precisely describes the relationship between the inputs and outputs of a source, expressed as a Datalog rule.", "startOffset": 20, "endOffset": 24}, {"referenceID": 19, "context": "In our earlier Karma work [20], we build a graph from learned semantic types and a domain ontology and use this graph to map a source to the ontology interactively.", "startOffset": 26, "endOffset": 30}, {"referenceID": 14, "context": "The most closely related work [15, 16] on exploiting known semantic models to learn a model for a new unknown source.", "startOffset": 30, "endOffset": 38}, {"referenceID": 15, "context": "The most closely related work [15, 16] on exploiting known semantic models to learn a model for a new unknown source.", "startOffset": 30, "endOffset": 38}, {"referenceID": 49, "context": "In recent years, ontology matching has received much attention in the Semantic Web community [50, 51].", "startOffset": 93, "endOffset": 101}, {"referenceID": 50, "context": "In recent years, ontology matching has received much attention in the Semantic Web community [50, 51].", "startOffset": 93, "endOffset": 101}, {"referenceID": 47, "context": "[48].", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "We can also exploit LOD to disambiguate the relationships between the attributes [52].", "startOffset": 81, "endOffset": 85}], "year": 2016, "abstractText": "Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs. However, they rarely provide a semantic model to describe their contents. Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data. Such models are the key ingredients to automatically publish the data into knowledge graphs. Manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem. Most of the related work focuses on semantic annotation of the data fields (source attributes). However, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical. We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source. This model represents the semantics of the new source in terms of the concepts and relationships defined by the domain ontology. Given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source. Then, we compute the top k candidate semantic models and suggest to the user a ranked list of the semantic models for the new source. The approach takes into account user corrections to learn more accurate semantic models on future data sources. Our evaluation shows that our method generates expressive semantic models for data sources and services with minimal user input. These precise models make it possible to automatically integrate the data across sources and provide rich support for source discovery and service composition. They also make it possible to automatically publish semantic data into knowledge graphs.", "creator": "LaTeX with hyperref package"}}}