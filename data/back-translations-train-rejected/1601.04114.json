{"id": "1601.04114", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2016", "title": "Training Recurrent Neural Networks by Diffusion", "abstract": "This work presents a new algorithm for training recurrent neural networks (although ideas are applicable to feedforward networks as well). The algorithm is derived from a theory in nonconvex optimization related to the diffusion equation. The contributions made in this work are two fold. First, we show how some seemingly disconnected mechanisms used in deep learning such as smart initialization, annealed learning rate, layerwise pretraining, and noise injection (as done in dropout and SGD) arise naturally and automatically from this framework, without manually crafting them into the algorithms. Second, we present some preliminary results on comparing the proposed method against SGD. It turns out that the new algorithm can achieve similar level of generalization accuracy of SGD in much fewer number of epochs.", "histories": [["v1", "Sat, 16 Jan 2016 02:24:17 GMT  (1131kb,D)", "http://arxiv.org/abs/1601.04114v1", null], ["v2", "Thu, 4 Feb 2016 23:22:52 GMT  (1132kb,D)", "http://arxiv.org/abs/1601.04114v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hossein mobahi"], "accepted": false, "id": "1601.04114"}, "pdf": {"name": "1601.04114.pdf", "metadata": {"source": "CRF", "title": "Training Recurrent Neural Networks by Diffusion", "authors": ["Hossein Mobahi"], "emails": ["hmobahi@csail.mit.edu"], "sections": [{"heading": "1 Introduction", "text": "This is a problem, however, that we are currently unable to apply objective optimization methods, which are often used in combination with other techniques such as intelligent initialization [Sutskever et al., 2013], layerwise pretraining [Bengio et al., 2007], dropout [Hinton et al., 2012b], annealed learning rate, and curriculum learning [Bengio et al., 2009].The difficulty in training deep networks is mainly attributed to their optimization landscape. [Dauphal], general learning rate, and curriculum learning [Bengio et al., 2009]."}, {"heading": "2 Optimization by Diffusion and Continuation", "text": "The optimality of using the diffusion equation to generate intermediate optimization problems is examined in our earlier work [Mobahi and Fisher III, 2015]. In short, it is a relaxation of a time evolution process that converts an objective function into its convex envelope curve [> envelope, 1999], which is a nonlinear partial differential equation that lacks a closed form, but once linearized, results in the thermal equation (a special type of diffusion equation), d dt g (x, t), s.t. g (x, 0) = f (x). (1) Here f is the original objective function, and g is its time evolution according to the thermal equation. Here x is the Laplace operator w.r.t. the variable x. Diffusion is a powerful tool for simplifying the objective function. (For example, the number of the local minimum Ackley number in this function [1987] is the Ackley number."}, {"heading": "3 Diffused Activation Functions", "text": "Similar forms of smoothed ReLU and signs are used by [Zhang et al., 2015] with a fixed \u03c3 = 1 \u221a 2\u03c0 to demonstrate the learning ability of deepening networks. 2All the listed diffuse functions are exact with the exception of tanh. Unfortunately, tanh? k\u03c3 does not have a closed form. We use the approximation tanh (y) \u2248 erf (\u221a \u03c0 2 y). Note that we know the exact diffuse form for erf as shown in the table. By wrapping both sides with k\u03c3, we obtain [tanh? k\u03c3] (y) \u2248 erf (\u221a 2 y) \u2248 erf (\u221a 2 \u04452 \u0445).Thus, the R.H.S. of the latter form can be wrapped with tanh (y) erf (tanh) by wrapping both sides."}, {"heading": "4 Training RNNs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 RNN Cost Function", "text": "In a set of S-training sequences, each is of the length T. Tag the s'te episode by < (xs, 1, ys, 1),.. (xs, T, ys, T) >. The problem of expiring learning by an RNN can be described as follows: min a, b, m0, U, V, W S \u00b2 s = 1 T \u00b2 s (h (ns, t) \u2212 ys, t (2) s.t. ns, t, W h (ms, t) + b (3) ms, t, Uxs, t + V h (ms, t \u00b2 s) + a, (4), where a, b, m0, W, U and V are the weights of the net. Tag the dimension of xs, t and ys, t, t, t, t, t, x \u00b2 m \u00b2 s, x \u00b2 s, x \u00b2 s, x \u00b2, x \u00b2 s, x \u00b2, x \u00b2, x \u00b2, x \u00b2, x \u00b2, x \u00b2, x, x \u00b2, x \u00b2, x, x \u00b2, x \u00b2, x \u00b2, x, s, x \u00b2, x \u00b2, x \u00b2, x, t, t (2), t (3) s.t. ns, t, t, t and ys, t (3) + b (3) ms, t, t, t, t, Uxs, t, t, t, t, t, t, t, t, t + V h (m, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, x, t, t, t, t, t, t, t, t, t, x, t, t, t, t, t, t, x \u00b2, t, x \u00b2, t, t, t, t, t, (m \u00b2, t, t, t, t, x, t, t, t, t \u00b2, s), x, s, x, s, x, x, x \u00b2, x \u00b2, x, x \u00b2, x, x, s, x, s, x \u00b2, x \u00b2, x, s, x, x \u00b2, x \u00b2,"}, {"heading": "4.2 Diffused Cost", "text": "If the objective function is developed according to the diffusion equation (1), the diffuse lens has a closed shape (2). Specifically, it is obtained by merging the original lens with the Gaussian nucleus, which can formally be expressed as follows: Place all the optimization variables in a long vector w, i.e. w, vec (a, b, m0, U, V, M, N). (5) After calculating this merger, the variables in w can be replaced by their original designations, according to the arrangements in w, vec (a, b, m0, U, V, W, M, N).Denote the diffuse form of the activation functions in f \u2212 t, i.e. the arrangements made in w in w, b, m0, W, W, W, V, M, N."}, {"heading": "4.3 Approximate Diffused Cost", "text": "The ideal solution requires S \u00b7 T auxiliary variables for ns, t and ms, t. This is impractical because S is often large, so we will use an approximate formulation here. Instead of solving them for the optimal ns, t and ms, t, we will approach them as follows: ns, t = W h, \u03c3 (ms, t) + b, ms, t = Uxs, t + V h, \u03c3 (ms, t \u2212 1) + a. (6) This allows us to eliminate the variables ns, t and ms, t from the remaining optimization. Simplified optimization problem is as follows: S \u00b2 s = 1 (T \u00b2 t = 1% h (ns, t) \u2212 ys, t \u00b2 h \u00b2 h \u00b2 h (ns, t), 2 \u2212 year \u00b2 h \u00b2 (ns, t), 2 \u2212 year \u00b2 h \u00b2 (n, t)."}, {"heading": "5 Properties of Diffused Cost", "text": "The optimization problem arising from the formation of a deep network is often a challenge. Therefore, local optimization methods (e.g. SGD) are used with a combination of some helpful techniques. Although these techniques seem to be detached from each other, some of them automatically result from the diffuse cost function. Therefore, these techniques could be combined under a simple theory. These methods and their connection to the diffuse cost are discussed below."}, {"heading": "5.1 Careful Initialization", "text": "Local optimization methods are generally sensitive to initializations when it comes to non-convex cost functions. Deep learning is no exception [Sutskever et al., 2013]; a recent study shows that the performance of deep networks and recurring networks depends crucially on initialization [Safran and Shamir, 2015]. In contrast, the diffusion algorithm is deterministic and almost independent of initialization3 for two reasons: First, the cost function becomes unimodal after sufficient smoothing and has a global minimum in the case of convexity. In fact, the minimization of the strongly smoothed function matches its central mass [Mobahi, 2012]. Therefore, diffusion offers an interesting deterministic initialization. Second, the update rules are completely deterministic (unless one chooses to use SGD instead of GD for local optimization in algorithm 1) and no notion of randomness is involved in the updates."}, {"heading": "5.2 Annealed Learning Rate", "text": "Any iteration of the gradient descent essentially sees the first order Taylor extension of the cost function g (x) at the current estimate of the solution point x0. The linear approximation has a good accuracy only within a small neighborhood of x0, say the radius \u03c1. By forcing the accuracy by limiting the multiplier method, we arrive at the following problem, min x x g (x0) + (x \u2212 x0) T-g (x0) s.t. (7) Using the Lagrange method, however, the solution of this optimization results in x \u00b2 = x0 \u2212 (x0). The Radius Grid Grid Grid Grid Grid Grid Grid Grid Grid (x0) Grid Grid Grid Grid Grid Grid (grid 0) Grid Grid Grid Grid Grid (grid 0) Grid Grid Grid. Grid Grid Grid (grid 0) Grid (grid) Grid."}, {"heading": "5.3 Noise Injection", "text": "The known dropout is a specific type of noise injection: in each iteration, it eliminates a random subset of nodes during the whole learning [Hinton et al., 2012b]. Stochasticity in SGD is another relevant example. It is known that SGD achieves a better generalization compared to a complete gradient descent. Although these schemes differ in detail, e.g. the distribution of noise or how it is applied to the learning process, they share the same idea of noise injection in the learning process. It turns out that the diffuse cost function also has this property to see that one could recall the definition of the diffuse cost function of (5): g (w; clinical), [f? clinically], [f? clinically] f (w) clinically."}, {"heading": "5.4 Layerwise Pretraining", "text": "We argue that when the network is large enough, it focuses only on short-term dependencies, and when it gradually shrinks towards zero, longer-term dependencies are gradually learned. To see why this happens, let's examine, for example, the partial gradient of A g, which is in the form of T = 1 rtM t (see Appendix B for derivatives and the definition of rt), where M t, I + V diag (h) (mt \u2212 1))) M t \u2212 1 and M1, I. The resolution of the recursion in M t results in M t = I + V diag (h \u00b2) (mt \u2212 1)) + V h \u00b2 (mt \u2212 1) V h \u00b2 (mt \u2212 2) +..... If we do, all the sigmoid-like activation functions listed in (3) can become flat and their gradient disappears h \u00b2 0. This means that by choosing V large enough, one can find a small layer that is diag \u00b2 large."}, {"heading": "5.5 Choice of the Activation Function", "text": "To implement the method, we must obtain the explicit expressions of h-\u03c3 and h-2\u03c3 for a given activation function h. For example, suppose we specify h (x) = erf (ax), where a is a parameter that determines the sharpness of the activation function. Note that lima \u2192 erf (ax) = character (x) and erf (270 x) \u2248 tanh (x). The shape of h-\u03c3 can already be derived from Table 3, which is repeated below, h-e-4\u03c0 (x) = erf (ax) = 1 + 2 (a\u03c3) 2). (11) In the following, we will focus only on h-2\u03c3. Unfortunately, h-2 (x) lacks a closed form expression. However, note that erf2 (x) \u2248 1 \u2212 4\u03c0 x2. This approximation has a reasonably good accuracy, as shown in Figure 3."}, {"heading": "6 Preliminary Results", "text": "Here we present a comparison between SGD and the proposed diffusion frame. Hyperparameters of both methods are carefully searched to ensure a fair comparison. We use erf as an activation function. The task is to learn the addition of two numbers, and is adapted to [Martens and Sutskever, 2011]. The network consists of 10 hidden units and has two inputs and one output. One of the input units reads a sequence of 10 real numbers, and the other a sequence of 10 binary numbers. Binary numbers are zero everywhere except in two random places. The task is to add the values from the first sequence at the two places marked by the second sequence. We trained the network by 1000 sequences, and the generalization is calculated from a test set of 100 sequences. The result is shown in the diagrams. The horizontal axis shows the generalization error, and the vertical axis shows how many generalization errors it takes to reach."}, {"heading": "7 Related Works & Future Directions", "text": "In fact, it is so that most of the people who are in the city are not able to identify themselves, \"he told the German Press Agency.\" But it is not as if, \"he said.\" But it is as if. \"\" It is as if. \"\" It is as if. \"\" It is as if, \"he said.\" \"It is as if.\" \"But it is as if.\" \"\" It is as if. \"\" \"..\" \"\" \"..\" \"\" \"..\" \"\" \"..\" \"\" \".\" \"\" It is as if. \"\" \"\" \"\". \"\" \"\". \"\" \"\" \".\" \"\" \"\" \"It is as if.\" \"\" \".\" \"\" \"\" \"..\" \"\" \"\" \"\" \"\". \"\" \"\" \"\" \"..\" \"\" \"\" \"\". \"\" \"\" \"\""}, {"heading": "8 Acknowledgment", "text": "Hossein Mobahi is grateful to John W. Fisher, William T. Freeman, Yann LeCun and Yoshua Bengio for comments and discussions, and Peter Bartlett and Fei Sha for references to [Duchi et al., 2012, Chen et al., 2014]. Hossein Mobahi is grateful to Kate Saenko for discussions in earlier stages of this work."}, {"heading": "A Diffused RNN Training Cost", "text": "(T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T (T) (T) (T (T) (T) (T) (T) (T) (T (T) (T) (T (T) (T) (T) (T) (T (T (T) (T) (T (T) (T) (T) (T (T) (T) (T) (T) (T (T) (T) (T (T) (T (T) (T) (T) (T (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T) (T"}, {"heading": "B Gradient of Diffused Cost", "text": "This refers to the elementary product of two matrices. \u2212 dg db = = mt (mt) (mt) (mt) (mt) (mt) (t) (25) = t (t) (t) (t) (t) (t) (t) (t) (t) (mt) (mt) (mt) (mt) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t (t) (t) (t) (t) (t (t) (t) (t) (t (t) (t) (t) (t (t) (t) (t) (t) (t (t) (t) (t) (t) (t) (t) (t) (t (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t) (t (t) (t) (t) (t) (t) (t) (t (t) (t) (t) (t (t) (t) (t (t) (t) (t (t) (t) (t (t) (t (t) (t) (t (t) (t (t) (t) (t (t) (t) (t (t) (t (t) (t (t) (t) (t (t) (t) (t (t) (t) (t) (t (t) (t) (t) (t (t (t) (t) (t) (t (t (t) (t) (t) (t) (t) (t (t) (t) (t) (t) (t (t (t) (t) (t) (t (t (t) (t (t (t) (t) (t (t) (t) (t (t (t) (t (t (t) (t) (t (t) (t) (t) (t) (t (t) (t (t"}, {"heading": "C Bounding Linearization Error", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau et al", "D. 2014] Bahdanau", "K. Cho", "Y. Bengio"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Greedy layer-wise training of deep networks", "author": ["Bengio et al", "Y. 2007] Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Marginalized denoising auto-encoders for nonlinear representations", "author": ["Chen et al", "M. 2014] Chen", "K.Q. Weinberger", "F. Sha", "Y. Bengio"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization", "author": ["Dauphin et al", "Y.N. 2014] Dauphin", "R. Pascanu", "C. Gulcehre", "K. Cho", "S. Ganguli", "Y. Bengio"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Randomized smoothing for stochastic optimization", "author": ["Duchi et al", "J.C. 2012] Duchi", "P.L. Bartlett", "M.J. Wainwright"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Train faster, generalize better: Stability of stochastic gradient descent. CoRR, abs/1509.01240", "author": ["Hardt et al", "M. 2015] Hardt", "B. Recht", "Y. Singer"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "On graduated optimization for stochastic non-convex problems. CoRR, abs/1503.03712", "author": ["Hazan et al", "E. 2015] Hazan", "K.Y. Levy", "S. Shalev-Shwartz"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["Hinton et al", "G.E. 2012a] Hinton", "L. Deng", "D. Yu", "G.E. Dahl", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T.N. Sainath", "B. Kingsbury"], "venue": "IEEE Signal Process. Mag.,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors. CoRR, abs/1207.0580", "author": ["Hinton et al", "G.E. 2012b] Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Generalization bounds for neural networks through tensor factorization. CoRR, abs/1506.08473", "author": ["Janzamin et al", "M. 2015] Janzamin", "H. Sedghi", "A. Anandkumar"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky et al", "A. 2012] Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Learning recurrent neural networks with hessian-free optimization", "author": ["Martens", "Sutskever", "J. 2011] Martens", "I. Sutskever"], "venue": "In ICML,", "citeRegEx": "Martens et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martens et al\\.", "year": 2011}, {"title": "On the Link Between Gaussian Homotopy Continuation and Convex Envelope", "author": ["Mobahi", "Fisher III", "H. 2015] Mobahi", "J.W. Fisher III"], "venue": null, "citeRegEx": "Mobahi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mobahi et al\\.", "year": 2015}, {"title": "Adding gradient noise improves learning for very deep networks. CoRR, abs/1511.06807", "author": ["Neelakantan et al", "A. 2015] Neelakantan", "L. Vilnis", "Q.V. Le", "I. Sutskever", "L. Kaiser", "K. Kurach", "J. Martens"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Annealed gradient descent for deep learning", "author": ["Pan", "Jiang", "H. 2015] Pan", "H. Jiang"], "venue": "In Proc. of 31th Conference on Uncertainty in Artificial Intelligence (UAI", "citeRegEx": "Pan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pan et al\\.", "year": 2015}, {"title": "On the saddle point problem for non-convex optimization. CoRR, abs/1405.4604", "author": ["Pascanu et al", "R. 2014] Pascanu", "Y.N. Dauphin", "S. Ganguli", "Y. Bengio"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "On the quality of the initial basin in overspecified neural networks. CoRR, abs/1511.04210", "author": ["Safran", "Shamir", "I. 2015] Safran", "O. Shamir"], "venue": null, "citeRegEx": "Safran et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Safran et al\\.", "year": 2015}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["Sutskever et al", "I. 2013] Sutskever", "J. Martens", "G. Dahl", "G. Hinton"], "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML-13)", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Sequence to sequence learning with neural networks", "author": ["Sutskever et al", "I. 2014] Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "`1regularized neural networks are improperly learnable in polynomial time", "author": ["Zhang et al", "Y. 2015] Zhang", "J.D. Lee", "M.I. Jordan"], "venue": "CoRR, abs/1510.03528", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}], "referenceMentions": [], "year": 2017, "abstractText": "This work presents a new algorithm for training recurrent neural networks (although ideas are applicable to feedforward networks as well). The algorithm is derived from a theory in nonconvex optimization related to the diffusion equation. The contributions made in this work are two fold. First, we show how some seemingly disconnected mechanisms used in deep learning such as smart initialization, annealed learning rate, layerwise pretraining, and noise injection (as done in dropout and SGD) arise naturally and automatically from this framework, without manually crafting them into the algorithms. Second, we present some preliminary results on comparing the proposed method against SGD. It turns out that the new algorithm can achieve similar level of generalization accuracy of SGD in much fewer number of epochs.", "creator": "LaTeX with hyperref package"}}}