{"id": "1601.04149", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2016", "title": "$\\mathbf{D^3}$: Deep Dual-Domain Based Fast Restoration of JPEG-Compressed Images", "abstract": "In this paper, we design a Deep Dual-Domain ($\\mathbf{D^3}$) based fast restoration model to remove artifacts of JPEG compressed images. It leverages the large learning capacity of deep networks, as well as the problem-specific expertise that was hardly incorporated in the past design of deep architectures. For the latter, we take into consideration both the prior knowledge of the JPEG compression scheme, and the successful practice of the sparsity-based dual-domain approach. We further design the One-Step Sparse Inference (1-SI) module, as an efficient and light-weighted feed-forward approximation of sparse coding. Extensive experiments verify the superiority of the proposed $D^3$ model over several state-of-the-art methods. Specifically, our best model is capable of outperforming the latest deep model for around 1 dB in PSNR, and is 30 times faster.", "histories": [["v1", "Sat, 16 Jan 2016 10:38:43 GMT  (2035kb,D)", "http://arxiv.org/abs/1601.04149v1", null], ["v2", "Fri, 1 Apr 2016 03:19:10 GMT  (1527kb,D)", "http://arxiv.org/abs/1601.04149v2", null], ["v3", "Sat, 9 Apr 2016 19:25:08 GMT  (1527kb,D)", "http://arxiv.org/abs/1601.04149v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["zhangyang wang", "ding liu", "shiyu chang", "qing ling", "yingzhen yang", "thomas s huang"], "accepted": false, "id": "1601.04149"}, "pdf": {"name": "1601.04149.pdf", "metadata": {"source": "CRF", "title": "D: Deep Dual-Domain Based Fast Restoration of JPEG-Compressed Images", "authors": ["Zhangyang Wang", "Ding Liu", "Shiyu Chang", "Qing Ling", "Thomas S. Huang"], "emails": ["t-huang1}@illinois.edu", "qingling@mail.ustc.edu.cn"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to play by the rules they have imposed on themselves."}, {"heading": "2. Related Work", "text": "Most previous work exclusively restored compressed images either in the pixel domain [2] or in the DCT domain [26], but an isolated quantization error of a single DCT coefficient can be transferred to all pixels of the same block. An aggressively quantized DCT coefficient can cause further structured errors in the pixel domain that correlate with the latent signal. On the other hand, the compression process sets most radio frequency coefficients to zero, making it impossible to recover details only from the DCT domain. Given their complementary properties, the dual domain model was proposed in [25]. While the spatial redundancies in the pixel domain were exploited by a scholarly dictionary [2], the remaining redundancies in the DCT domain showed terse sketches."}, {"heading": "3.1. Sparsity-based Dual-Domain Formulation", "text": "Considering a training set of JPEG-compressed images, pixel domain blocks and blocks, the individual exam inputs (JPEG-encoded) are drawn for the training, together with their (quantified) DCT coefficient blocks, the individual exam contents (JPEG-encoded) for the individual exam contents (JPEG-coefficient blocks) are constructed from the training data (JPEG-encoded) and pixel domains, and the following optimization model is then solved during the test phase."}, {"heading": "3.3. One-Step Sparse Inference Module", "text": "The implementation of SC analysis and synthesis modules appears to be the core of D3. While the synthesis process is naturally forward-looking by multiplying the dictionary, it is less easy to transform the sparse analysis (or inference) process into a forward-looking network. We take (2) as an example, while the same solution applies to (4). Such a sparse follow-up problem could be solved by the iterative shrink and threshold algorithm (ISTA) [5], updating each iteration of this network as follows: \u03b1k + 1 = s\u03bb (\u03b1 k + \u03a6T (yT) (yt \u2212 imperative shrink and threshold algorithm [5), with the superior shrink and threshold algorithms an essential shrink function (u is a vector and ui is its third element, i = 1, 2, 2): [-] and threshold algorithms [-]."}, {"heading": "3.4. Model Overview", "text": "By connecting the 1-SI module (7), we are ready to obtain the SC analysis and synthesis modules, as shown in Fig. 2. By comparing Fig. 2 with Eqn. (2) (or (4), it is easy to notice the analytical relationships between DA and \u03a6T (or \u0432 T), DS and \u03a6 (or \u0432) and \u03b8 and \u03bb (or \u03b3). In fact, these network hyperparameters could well be initialized using the sparse coding parameters that would be easy to obtain. The entire D3 model, which consists of four completely interconnected weight layers (except the diagonal layers), is then trained from end to end. 1In (8), we easily misuse notations and use them as vectors of the same dimension as u. The entire D3 model, which consists of four completely interconnected weight layers (except the diagonal layers), is then built from end to end."}, {"heading": "3.5. Complexity Analysis", "text": "From the clear correspondences between the thrift-based formulation and the D3 model, we immediately derive the dimensions of the weight layers, as shown in Table 1."}, {"heading": "3.5.1 Time Complexity", "text": "During the training, deep learning with the help of gradient descend scales is linear in time and space with the number of tensile samples. We are primarily concerned with the time complexity during the test (inference), which is more relevant for practical application. Since all learnable layers in the D3 model are completely connected, the derivative process of D3 is nothing more than a series of matrix multiplications. Multiplication times are counted as: p\u03a6m (DA in stage I) + 2p\u0445 (two diagonal layers) + p\u03a6m (DS in stage I) + p\u0441m (DA in stage II) + 2p\u0445 (two diagonal layers) + p\u0441m (DS in stage II). The 2D DCT and IDCT layers each take on 12m Log (m) multiplications [26]. Therefore, the total inference time complexity of D3 is total p\u0441\u0442\u0430l: CD3 = (+ p\u0445 + \u00b2) (m) (m) AR (m m)."}, {"heading": "3.5.2 Parameter Complexity", "text": "The total number of free parameters in D3 is: ND3 = 2p\u03a6m + p\u03a6 + 2p\u0441m + p\u0442 = 2 (p\u03a6 + p\u0442) (m + 1). (11) For comparison, the AR-CNN model [12] contains: Nconv = \u2211 d l = 1 nl \u2212 1 \u00b7 nl \u00b7 s2l. (12)"}, {"heading": "3.6. Remark: A Hidden Gem", "text": "A hidden gem in the design process of D3 is the discovery of inner connections between popular deep network modules and well-studied sparse encoding algorithms. The current model concerns the solution of conventional sparse encoding (2). By imposing an additional non-negative constraint on \u03b1, (2) becomes a non-negative sparse encoding problem that is significant in many visual recognition tasks [2]. Following the same routine in Section 3.3, the only change in the 1-SI module occurs in the threshold operator: \u03b1 = r\u03bb (\u03a6yt), with [r\u03bb (u)] i = [ui \u2212 \u03bbi] +. (13) The new r\u03bb is exactly a ReLU [22] neuron with a translation bias. If we replace the formulation (2) with the revolutionary sparse encoding model (7), DA is replaced by a revolutionary layer in Fig. 2."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Implementation and Setting", "text": "We use the disjoint training set (200 frames) and the test set (200 frames) of the BSDS500 database [3] Q = Q, like our training set; its validation set (100 frames) is used for the validation that follows [12]. To train the D3 model, we first divide each original image into overlapping 8 \u00d7 8 fields and subtract the pixel values by 128 as in the JPEG process. We then run JPEG encoders with a specific quality factor Q to generate the corresponding compressed samples. While JPEG works with non-overlapping fields, we emphasize that the training packages are overlapped and extracted from arbitrary positions. For a test image, we stamp 8 \u00d7 8 blocks with a step of 4 and apply the D3 model in a patch manner."}, {"heading": "4.2. Restoration Performance Comparison", "text": "We include the following two relevant, state-of-the-art methods for comparison: \u2022 Sparsity-based dual-domain method (S-D2) = 25] could be considered the \"flat\" counterpart to D3. \u2022 It has surpassed most traditional methods, such as BM3D [10] and DicTV [8], with which we cannot compare again. Therefore, the parameter complexity of S-D2 cannot be precisely compressed. \u2022 In particular, its dictatorial atoms are adaptively selected by a nearby algorithm; the number of selected atoms for each test can be varied. Therefore, the parameter complexity of S-D2 cannot be precisely defined. \u2022 We have the latest model that resolves JPEG compression of artifacts. In [12] the authors show its advantage over SA-DCT [14], RTF and SR-CNN."}, {"heading": "4.3. Running Time Comparison", "text": "Traditional television and digital cinema use frame rate standards such as 24p (i.e. 24 frames per second), 25p and 30p. New standards require much higher frame rates. High-end High Definition (HD) TV systems use, for example, 50p or 60p; the Ultra HD (UHD) TV standard advocates 100p / 119.88p / 120p; the HEVC format could reach the maximum frame rate of 300p [1]. To this end, higher time efficiency is desirable as well as improved performance.We compare the averaged test times of AR-CNN and the proposed D3 models in Table 3 on 29 frames of the LIVE29 dataset, all using the same machine and software environment 5. The time costs of AR-CNN and D3-256 running on each individual image are also shown in Figure 6. Our best model, D3-256, takes approximately 12 times faster than the difference of AR-T, with both times not exceeding 30 times faster."}, {"heading": "5. Conclusion", "text": "We introduce Deep Dual Domain Segmentation. (D3) based on fast restoration model to remove artifacts in JPEG compressed images. [1] The successful combination of JPEG prior knowledge and scant encoding skills helps our proposed deep architecture to be highly effective and efficient. In the future, we aim to further reduce the complexity of D3 and extend our model to other related applications, such as denoization and superresolution. [1] https: / en.wikipedia.org / wiki / Frame _ rate /. [2] M. Aharon, M. Elad, and A. Bruckstein. K-svd: An algo-rithm for designing overcomplete dictionaries."}], "references": [{"title": "K-svd: An algorithm for designing overcomplete dictionaries for sparse representation", "author": ["M. Aharon", "M. Elad", "A. Bruckstein"], "venue": "TSP, 54(11):4311\u20134322", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Contour detection and hierarchical image segmentation", "author": ["P. Arbelaez", "M. Maire", "C. Fowlkes", "J. Malik"], "venue": "TPAMI, 33(5):898\u2013916", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Review of proposed high efficiency video coding (hevc) standard", "author": ["E.A. Ayele", "S. Dhok"], "venue": "International Journal of Computer Applications, 59(15):1\u20139", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Iterative thresholding for sparse approximations", "author": ["T. Blumensath", "M.E. Davies"], "venue": "Journal of Fourier Analysis and Applications, 14(5-6):629\u2013654", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "A total variation-based jpeg decompression model", "author": ["K. Bredies", "M. Holler"], "venue": "SIAM Journal on Imaging Sciences, 5(1):366\u2013393", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast convolutional sparse coding", "author": ["H. Bristow", "A. Eriksson", "S. Lucey"], "venue": "CVPR, pages 391\u2013398. IEEE", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Reducing artifacts in jpeg decompression via a learned dictionary", "author": ["H. Chang", "M.K. Ng", "T. Zeng"], "venue": "TSP, 62(3):718\u2013 728", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "A learningbased approach to reduce jpeg artifacts in image matting", "author": ["I. Choi", "S. Kim", "M.S. Brown", "Y.-W. Tai"], "venue": "ICCV, pages 2880\u20132887. IEEE", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Image denoising by sparse 3-d transform-domain collaborative filtering", "author": ["K. Dabov", "A. Foi", "V. Katkovnik", "K. Egiazarian"], "venue": "TIP, 16(8):2080\u20132095", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Recklessly approximate sparse coding", "author": ["M. Denil", "N. de Freitas"], "venue": "arXiv preprint arXiv:1208.0959,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Compression artifacts reduction by a deep convolutional network", "author": ["C. Dong", "Y. Deng", "C.C. Loy", "X. Tang"], "venue": "ICCV", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning a deep convolutional network for image super-resolution", "author": ["C. Dong", "C.C. Loy", "K. He", "X. Tang"], "venue": "ECCV, pages 184\u2013199. Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Pointwise shapeadaptive dct for high-quality denoising and deblocking of grayscale and color images", "author": ["A. Foi", "V. Katkovnik", "K. Egiazarian"], "venue": "TIP, 16(5):1395\u20131411", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning fast approximations of sparse coding", "author": ["K. Gregor", "Y. LeCun"], "venue": "ICML, pages 399\u2013406", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Projective dictionary pair learning for pattern classification", "author": ["S. Gu", "L. Zhang", "W. Zuo", "X. Feng"], "venue": "NIPS, pages 793\u2013 801", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional neural networks at constrained time cost", "author": ["K. He", "J. Sun"], "venue": "CVPR, pages 5353\u20135360", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep unfolding: Model-based inspiration of novel deep architectures", "author": ["J.R. Hershey", "J.L. Roux", "F. Weninger"], "venue": "arXiv preprint arXiv:1409.2574", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Loss-specific training of non-parametric image restoration models: A new state of the art", "author": ["J. Jancsary", "S. Nowozin", "C. Rother"], "venue": "ECCV, pages 112\u2013125. Springer", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Image deblocking via sparse representation", "author": ["C. Jung", "L. Jiao", "H. Qi", "T. Sun"], "venue": "Signal Processing: Image Communication, 27(6):663\u2013677", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Tackling box-constrained optimization via a new projected quasi-newton approach", "author": ["D. Kim", "S. Sra", "I.S. Dhillon"], "venue": "SIAM Journal on Scientific Computing, 32(6):3548\u20133563", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS, pages 1097\u20131105", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Regression-based prediction for blocking artifact reduction in jpeg-compressed images", "author": ["K. Lee", "D.S. Kim", "T. Kim"], "venue": "TIP, 14(1):36\u201348", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "Inter-block soft decoding of jpeg images with sparsity and graph-signal smoothness priors", "author": ["X. Liu", "G. Cheung", "X. Wu", "D. Zhao"], "venue": "ICIP. IEEE", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Data-driven sparsity-based restoration of jpeg-compressed images in dual transform-pixel domain", "author": ["X. Liu", "X. Wu", "J. Zhou", "D. Zhao"], "venue": "CVPR", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "JPEG: Still image data compression standard", "author": ["W.B. Pennebaker", "J.L. Mitchell"], "venue": "Springer Science & Business Media", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1993}, {"title": "Efficient regression priors for reducing image compression artifacts", "author": ["R. Rothe", "R. Timofte", "L. Van Gool"], "venue": "IEEE ICIP", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "and A", "author": ["H.R. Sheikh", "Z. Wang", "L. Cormack"], "venue": "C. Bovik. Live image quality assessment database release 2", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "Real-time compression artifact reduction via robust nonlinear filtering", "author": ["M.-Y. Shen", "C.-C. Jay Kuo"], "venue": "ICIP, volume 2, pages 565\u2013569. IEEE", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning efficient sparse and low rank models", "author": ["P. Sprechmann", "A. Bronstein", "G. Sapiro"], "venue": "TPAMI", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Supervised sparse analysis and synthesis operators", "author": ["P. Sprechmann", "R. Litman", "T.B. Yakar", "A.M. Bronstein", "G. Sapiro"], "venue": "NIPS, pages 908\u2013916", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "JMLR, 15(1):1929\u20131958", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Image quality assessment: from error visibility to structural similarity", "author": ["Z. Wang", "A.C. Bovik", "H.R. Sheikh", "E.P. Simoncelli"], "venue": "TIP, 13(4):600\u2013612", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2004}, {"title": "Deeply improved sparse coding for image super-resolution", "author": ["Z. Wang", "D. Liu", "J. Yang", "W. Han", "T. Huang"], "venue": "ICCV", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Quality assessment of deblocked images", "author": ["C. Yim", "A.C. Bovik"], "venue": "TIP, 20(1):88\u201398", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 24, "context": "Lossy compression, such as JPEG [26] and HEVC-MSP [4], is widely adopted in image and video codecs for saving both bandwidth and in-device storage.", "startOffset": 32, "endOffset": 36}, {"referenceID": 2, "context": "Lossy compression, such as JPEG [26] and HEVC-MSP [4], is widely adopted in image and video codecs for saving both bandwidth and in-device storage.", "startOffset": 50, "endOffset": 53}, {"referenceID": 10, "context": "These artifacts not only degrade perceptual visual quality, but also adversely affect various low-level image processing routines that take compressed images as input [12].", "startOffset": 167, "endOffset": 171}, {"referenceID": 23, "context": "As practical image compression methods are not information theoretically optimal [25], the resulting compression code streams still possess residual redundancies, which makes the restoration of the original signals possible.", "startOffset": 81, "endOffset": 85}, {"referenceID": 24, "context": "Quantization is applied on the DCT coefficients of every block, with pre-known quantization levels [26].", "startOffset": 99, "endOffset": 103}, {"referenceID": 0, "context": "In contrast to the tradition of assuming noise to be white and signal independent [2], the non-linearity of quantization operations makes quantization noises non-stationary and signal-dependent.", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "Early works [6, 23] utilized filteringbased methods to remove simple artifacts.", "startOffset": 12, "endOffset": 19}, {"referenceID": 21, "context": "Early works [6, 23] utilized filteringbased methods to remove simple artifacts.", "startOffset": 12, "endOffset": 19}, {"referenceID": 6, "context": "Sparsitybased image restoration approaches have been discussed in [8, 9, 20, 24, 27] to produce sharpened images, but they are often accompanied with artifacts along edges, and unnatural smooth regions.", "startOffset": 66, "endOffset": 84}, {"referenceID": 7, "context": "Sparsitybased image restoration approaches have been discussed in [8, 9, 20, 24, 27] to produce sharpened images, but they are often accompanied with artifacts along edges, and unnatural smooth regions.", "startOffset": 66, "endOffset": 84}, {"referenceID": 18, "context": "Sparsitybased image restoration approaches have been discussed in [8, 9, 20, 24, 27] to produce sharpened images, but they are often accompanied with artifacts along edges, and unnatural smooth regions.", "startOffset": 66, "endOffset": 84}, {"referenceID": 22, "context": "Sparsitybased image restoration approaches have been discussed in [8, 9, 20, 24, 27] to produce sharpened images, but they are often accompanied with artifacts along edges, and unnatural smooth regions.", "startOffset": 66, "endOffset": 84}, {"referenceID": 25, "context": "Sparsitybased image restoration approaches have been discussed in [8, 9, 20, 24, 27] to produce sharpened images, but they are often accompanied with artifacts along edges, and unnatural smooth regions.", "startOffset": 66, "endOffset": 84}, {"referenceID": 23, "context": "In [25], Liu et.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "[12] first introduced deep learning techniques [22] into this problem, by specifically adapting their SR-CNN model in [13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[12] first introduced deep learning techniques [22] into this problem, by specifically adapting their SR-CNN model in [13].", "startOffset": 47, "endOffset": 51}, {"referenceID": 11, "context": "[12] first introduced deep learning techniques [22] into this problem, by specifically adapting their SR-CNN model in [13].", "startOffset": 118, "endOffset": 122}, {"referenceID": 27, "context": "Low-complexity or even real-time attenuation of compression artifacts is highly desirable [29].", "startOffset": 90, "endOffset": 94}, {"referenceID": 13, "context": "The inference process of traditional approaches, for example, sparse coding, usually involves iterative optimization algorithms, whose inherently sequential structure as well as the data-dependent complexity and latency often constitute a major bottleneck in the computational efficiency [15].", "startOffset": 288, "endOffset": 292}, {"referenceID": 15, "context": "However, to maintain their competitive performances, deep networks show demands for increased width (numbers of filters) and depth (number of layers), as well as smaller strides, all leading to growing computational costs [17].", "startOffset": 222, "endOffset": 226}, {"referenceID": 23, "context": "Our major innovation is to explicitly combine both the prior knowledge in the JPEG compression scheme and the successful practice of dual-domain sparse coding [25], for designing a task-specific deep architecture.", "startOffset": 159, "endOffset": 163}, {"referenceID": 9, "context": "Furthermore, we introduce a One-Step Sparse Inference (1-SI) module, that acts as a highly efficient and light-weighted approximation of the sparse coding inference [11].", "startOffset": 165, "endOffset": 169}, {"referenceID": 23, "context": "Our work is inspired by the prior wisdom in [25].", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "Most previous works restored compressed images in either the pixel domain [2] or the DCT domain [26] solely.", "startOffset": 74, "endOffset": 77}, {"referenceID": 24, "context": "Most previous works restored compressed images in either the pixel domain [2] or the DCT domain [26] solely.", "startOffset": 96, "endOffset": 100}, {"referenceID": 23, "context": "In view of their complementary characteristics, the dualdomain model was proposed in [25].", "startOffset": 85, "endOffset": 89}, {"referenceID": 0, "context": "While the spatial redundancies in the pixel domain were exploited by a learned dictionary [2], the residual redundancies in the DCT domain were also utilized to directly restore DCT coefficients.", "startOffset": 90, "endOffset": 93}, {"referenceID": 20, "context": "To date, deep learning [22] has shown impressive results on both high-level and low-level vision problems.", "startOffset": 23, "endOffset": 27}, {"referenceID": 11, "context": "[13] showed the great potential of end-to-end trained networks in image super resolution (SR).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "Their recent work [12] proposed a four-layer convolutional network that was tuned based on SR-CNN, named Artifacts Reduction Convolutional Neural Networks (AR-CNN), which was effective in dealing with various compression artifacts.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "In [15], the authors leveraged fast trainable regressors and constructed feed-forward network approximations of the learned sparse models.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "Similar views were adopted in [30] to develop a fixed-complexity algorithm for solving structured sparse and robust low rank models.", "startOffset": 30, "endOffset": 34}, {"referenceID": 16, "context": "The paper [18] summarized the methodology of \u201cdeep unfolding\u201d.", "startOffset": 10, "endOffset": 14}, {"referenceID": 32, "context": "Very recently, [34] proposed deeply improved sparse coding for SR, which can be incarnated as an end-to-end neural network.", "startOffset": 15, "endOffset": 19}, {"referenceID": 23, "context": "We first review the sparsity-based dual-domain restoration model established in [25].", "startOffset": 80, "endOffset": 84}, {"referenceID": 24, "context": "One noteworthy point is the inequality constraint, where q and q represents the (pre-known) quantization intervals according to the JPEG quantization table [26].", "startOffset": 156, "endOffset": 160}, {"referenceID": 23, "context": "The authors of [25] simply set them all equal, which may hamper the performance.", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "The subsequent two layers aim to enforce DCT domain sparsity, where we refer to the concepts of analysis and synthesis dictionaries in sparse coding [16].", "startOffset": 149, "endOffset": 153}, {"referenceID": 19, "context": "We design the following signaldependent, box-constrained [21] loss:", "startOffset": 57, "endOffset": 61}, {"referenceID": 3, "context": "Such a sparse inference problem could be solved by the iterative shrinkage and thresholding algorithm (ISTA) [5], each iteration of which updates as follows:", "startOffset": 109, "endOffset": 112}, {"referenceID": 13, "context": "The learned ISTA (LISTA) [15] parameterized encoder further proposed a natural network implementation of ISTA.", "startOffset": 25, "endOffset": 29}, {"referenceID": 16, "context": "The similar unfolding methodology has been lately exploited in [18], [30], [31].", "startOffset": 63, "endOffset": 67}, {"referenceID": 28, "context": "The similar unfolding methodology has been lately exploited in [18], [30], [31].", "startOffset": 69, "endOffset": 73}, {"referenceID": 29, "context": "The similar unfolding methodology has been lately exploited in [18], [30], [31].", "startOffset": 75, "endOffset": 79}, {"referenceID": 10, "context": "Our major motivation lies in the same observation as in [12] that overly deep networks could adversely affect the performance in low-level", "startOffset": 56, "endOffset": 60}, {"referenceID": 13, "context": "Even only two iterations are kept as in [15], we end up with a six-layer network, that suffers from both difficulties in training [12] and fragility in generalization [32] for this task.", "startOffset": 40, "endOffset": 44}, {"referenceID": 10, "context": "Even only two iterations are kept as in [15], we end up with a six-layer network, that suffers from both difficulties in training [12] and fragility in generalization [32] for this task.", "startOffset": 130, "endOffset": 134}, {"referenceID": 30, "context": "Even only two iterations are kept as in [15], we end up with a six-layer network, that suffers from both difficulties in training [12] and fragility in generalization [32] for this task.", "startOffset": 167, "endOffset": 171}, {"referenceID": 32, "context": "We further rewrite (6) as [34] did1:", "startOffset": 26, "endOffset": 30}, {"referenceID": 20, "context": "The unit-threshold neuron s1 could in essence be viewed as a double-sided and translated variant of ReLU [22].", "startOffset": 105, "endOffset": 109}, {"referenceID": 9, "context": "A related form to (7) was obtained in [11] on a different case of non-negative sparse coding.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "The 2D DCT and IDCT each takes 12m log(m) multiplications [26] .", "startOffset": 58, "endOffset": 62}, {"referenceID": 23, "context": "It is obvious that the sparse coding inference [25] has dramatically higher time complexity.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "We are also interested in the inference time complexity of other competitive deep models, especially AR-CNN [12].", "startOffset": 108, "endOffset": 112}, {"referenceID": 15, "context": "For their fully convolutional architecture, the total complexity [17] is:", "startOffset": 65, "endOffset": 69}, {"referenceID": 10, "context": "(11) As a comparison, the AR-CNN model [12] contains:", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "By enforcing an extra nonnegative constraint on \u03b1, (2) becomes the non-negative sparse coding problem that is found to be meaningful in many visual recognition tasks [2].", "startOffset": 166, "endOffset": 169}, {"referenceID": 20, "context": "The new r\u03bb is exactly a ReLU [22] neuron with a translation bias \u03bb.", "startOffset": 29, "endOffset": 33}, {"referenceID": 5, "context": "Similarly, if we substitute the formulation (2) with the convolutional sparse coding model [7], DA in Fig.", "startOffset": 91, "endOffset": 94}, {"referenceID": 1, "context": "We use the disjoint training set (200 images) and test set (200 images) of BSDS500 database [3], as our training set; its validation set (100 images) is used for validation, which follows [12].", "startOffset": 92, "endOffset": 95}, {"referenceID": 10, "context": "We use the disjoint training set (200 images) and test set (200 images) of BSDS500 database [3], as our training set; its validation set (100 images) is used for validation, which follows [12].", "startOffset": 188, "endOffset": 192}, {"referenceID": 20, "context": "The proposed networks are implemented using the cudaconvnet package [22].", "startOffset": 68, "endOffset": 72}, {"referenceID": 10, "context": "We further find the easy-hard transfer suggested by [12] useful.", "startOffset": 52, "endOffset": 56}, {"referenceID": 23, "context": "\u2022 Sparsity-based Dual-Domain Method (S-D) [25] could be viewed as the \u201cshallow\u201d counterpart of D.", "startOffset": 42, "endOffset": 46}, {"referenceID": 23, "context": "It has outperformed most traditional methods [25], such as BM3D [10] and DicTV [8], with which we thus do not compare again.", "startOffset": 45, "endOffset": 49}, {"referenceID": 8, "context": "It has outperformed most traditional methods [25], such as BM3D [10] and DicTV [8], with which we thus do not compare again.", "startOffset": 64, "endOffset": 68}, {"referenceID": 6, "context": "It has outperformed most traditional methods [25], such as BM3D [10] and DicTV [8], with which we thus do not compare again.", "startOffset": 79, "endOffset": 82}, {"referenceID": 10, "context": "In [12], the authors show its advantage over SA-DCT [14], RTF [19], and SR-CNN [13].", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "In [12], the authors show its advantage over SA-DCT [14], RTF [19], and SR-CNN [13].", "startOffset": 52, "endOffset": 56}, {"referenceID": 17, "context": "In [12], the authors show its advantage over SA-DCT [14], RTF [19], and SR-CNN [13].", "startOffset": 62, "endOffset": 66}, {"referenceID": 11, "context": "In [12], the authors show its advantage over SA-DCT [14], RTF [19], and SR-CNN [13].", "startOffset": 79, "endOffset": 83}, {"referenceID": 10, "context": "We adopt the default network configuration in [12]: s1 = 9, s2 = 7, s3 = 1, s4 = 5; n1 = 64, n2 = 32, n3 = 16, n4 = 1.", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "3from the common experiences of choosing dictionary sizes [2] (D-Base), of the same complexity with D-256, named DBase-256.", "startOffset": 58, "endOffset": 61}, {"referenceID": 20, "context": "D-Base-256 utilizes ReLU [22] neurons and the dropout technique.", "startOffset": 25, "endOffset": 29}, {"referenceID": 26, "context": "We use the 29 images in the LIVE1 dataset [28] (converted to the gray scale) to evaluate both the quantitative and qualitative performances.", "startOffset": 42, "endOffset": 46}, {"referenceID": 31, "context": "Three quality assessment criteria: PSNR, structural similarity (SSIM) [33], and PSNR-B [35], are evaluated, the last of which is designed specifically to assess blocky images.", "startOffset": 70, "endOffset": 74}, {"referenceID": 33, "context": "Three quality assessment criteria: PSNR, structural similarity (SSIM) [33], and PSNR-B [35], are evaluated, the last of which is designed specifically to assess blocky images.", "startOffset": 87, "endOffset": 91}], "year": 2017, "abstractText": "In this paper, we design a Deep Dual-Domain (D) based fast restoration model to remove artifacts of JPEG compressed images. It leverages the large learning capacity of deep networks, as well as the problem-specific expertise that was hardly incorporated in the past design of deep architectures. For the latter, we take into consideration both the prior knowledge of the JPEG compression scheme, and the successful practice of the sparsity-based dual-domain approach. We further design the One-Step Sparse Inference (1-SI) module, as an efficient and lightweighted feed-forward approximation of sparse coding. Extensive experiments verify the superiority of the proposed D model over several state-of-the-art methods. Specifically, our best model is capable of outperforming the latest deep model for around 1 dB in PSNR, and is 30 times faster.", "creator": "LaTeX with hyperref package"}}}