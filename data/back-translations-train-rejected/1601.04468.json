{"id": "1601.04468", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2016", "title": "Bandit Structured Prediction for Learning from Partial Feedback in Statistical Machine Translation", "abstract": "We present an approach to structured prediction from bandit feedback, called Bandit Structured Prediction, where only the value of a task loss function at a single predicted point, instead of a correct structure, is observed in learning. We present an application to discriminative reranking in Statistical Machine Translation (SMT) where the learning algorithm only has access to a 1-BLEU loss evaluation of a predicted translation instead of obtaining a gold standard reference translation. In our experiment bandit feedback is obtained by evaluating BLEU on reference translations without revealing them to the algorithm. This can be thought of as a simulation of interactive machine translation where an SMT system is personalized by a user who provides single point feedback to predicted translations. Our experiments show that our approach improves translation quality and is comparable to approaches that employ more informative feedback in learning.", "histories": [["v1", "Mon, 18 Jan 2016 11:09:02 GMT  (30kb)", "http://arxiv.org/abs/1601.04468v1", "In Proceedings of MT Summit XV, 2015. Miami, FL"]], "COMMENTS": "In Proceedings of MT Summit XV, 2015. Miami, FL", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["artem sokolov", "stefan riezler", "tanguy urvoy"], "accepted": false, "id": "1601.04468"}, "pdf": {"name": "1601.04468.pdf", "metadata": {"source": "CRF", "title": "Bandit Structured Prediction for Learning from Partial Feedback in Statistical Machine Translation", "authors": ["Artem Sokolov", "Stefan Riezler", "Tanguy Urvoy"], "emails": ["sokolov@cl.uni-heidelberg.de", "riezler@cl.uni-heidelberg.de", "tanguy.urvoy@orange.com"], "sections": [{"heading": null, "text": "ar Xiv: 160 1,04 468v 1 [cs.C L"}, {"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to abide by the rules that they have imposed on themselves. (...) In fact, it is so that they are able to determine themselves. (...) It is not so that they are able to determine themselves. (...) It is not so that they do it. (...) It is so that they do it. (...) It is so. (...) It is so. (...) It is so. (...) \"(...). (...)\" (...) \"(...).\" (...) \"(...).\" (...) \"(...).\" (...) \"(...).\" () \"(...\"). \"(...\"). \"(...\") (... \"() (...) (...).\" () (...) (() () ()."}, {"heading": "2 Related Work", "text": "In fact, it is the case that we are in a position to abide by the rules that applied in the past."}, {"heading": "3 Expected Loss Minimization under Full Information", "text": "The expected loss learning criterion for structured predictions is defined as a minimization of the expectation of a task loss function in relation to the conditional distribution over structured outputs (Gimpel and Smith, 2010; Yuille and He, 2012). Formally, X is a structured input room, let Y (x) quantify the amount of possible output structures for input x, and let us (y) quantify the loss y (y) because we make errors in predicting y (as a rule) y (y) (y) (y) = 0 iff y (y) = y. \"Then, for a data distribution p (x, y) the learning criteria are defined as minimizing the expected loss distribution (x, y)."}, {"heading": "4 Bandit Structured Prediction", "text": "Bandit feedback in structured predictions means that the gold standard output structure y, in relation to which the objective function is evaluated, is not disclosed to the learner. Therefore, we cannot calculate the gradient of the objective function (4) nor evaluate the task loss (as in the complete case of information). A solution to this problem is to pass the assessment of the loss function to the user, i.e., we directly access the user's feedback without assuming the existence of a fixed reference. We indicate this by dropping the subscript y in structures (y). Assuming a fixed, algorithm 1 Bandit Structured Prediction1: Input: sequence of learning rates \u03b3t 2: Initialize w0 3: for t = 0,.., T do 4: Observe xt 5: Calculate Epwt (y \u2032 | xt) [xt] [xt, y \u2032] [xt, y \u2032 x]."}, {"heading": "4.1 Algorithm", "text": "Algorithm 1 implements these ideas as follows: For each random i.i.d. input structure xt, we calculate the expected number of characteristics (line 1) and a deterministic initialization w0 of the weight vector (line 2). This can be done exactly, provided the underlying graphical model allows a tractable calculation or for intractable models with MCMC sampling. We then try an output structure y limited to simple potentials from the Gibbs model (line 6). If the number of output options is low, this is done by scanning from a multinomic distribution. Otherwise, we use a Perturb and MAP approach (Papandreou and Yuille, 2011) to obtain an approximate Gibbs sample without waiting for the MC chain to mix."}, {"heading": "4.2 Stochastic Approximation Analysis", "text": "The construction of algorithm 1 as a stochastic realization of the true gradient allows us to analyze the algorithm as a stochastic approximation algorithm. We show how our case fits into the pseudo-gradient fit frame of Polyak and Tsypkin (1973), which provides asymptotic guarantees for non-convex and convex targets. They show how aniterative processwt + 1 = wt - and differentiable function J (w) with Lipschitz as learning rate, wt and st are vectors in Rd with fixed w0, and the distribution of st is dependent on w0,., wt - and differentiable function J (w) with Lipschitz continuous gradient J (w), that is, it exists for all, w. \""}, {"heading": "5 Structured Dueling Bandits", "text": "The original algorithm is not specifically designed for structured prediction problems, but it is generic enough to be applicable to such problems when the quality of a parameter vector can be proximized by evaluating losses of an inferred structure. The Structured Dueling Bandits algorithm compares a current weight vector wt with an adjacent point w \u00b2 t along a given direction, conducts exploration (controlled, line 5) by examining random directions, and exploitation (controlled, line 8) by a step in the winning direction. The comparison step in line 6 is adapted to structured predictions from the original algorithm of Yue and Joachims (2009) by comparing the quality of wt and w \u00b2 t by evaluating losses wt (y \u00b2 wt (xt) and y \u00b2 w \u00b2 t (duxt) of real access to two (MAP) -3 situations where the structural access to the world is not complete."}, {"heading": "6 Experiments", "text": "We follow the standard of simulating bandit feedback by evaluating task loss functions against gold standard structures without making them available to the learner. We compare the proposed structured bandit prediction algorithms to structured dueling bandits, and the results of tests on the respective loss functions under MAP inference. Furthermore, we evaluate models of different iterations after their loss to visualize the empirical convergence of algorithms. All experiments with bandit algorithms perform online learning for parameter estimation, and apply early stops to select the last model in a learning sequence for online-to-batch conversion. The end result for bandit algorithms is averaged over 5 independent runes. In this experiment, we present bandit learning for the structured 1 \u2212 BLEU losses used in SMT."}, {"heading": "7 Discussion", "text": "Our experimental evaluation showed promising results, both in comparison to structured dueling bandits, which use two-point feedback, and in comparison to complete information scenarios, in which the correct structure is revealed. Our approach shows its strength where correct structures are not available and two-point feedback is not feasible. In future work, we would like to apply bandit learning to scenarios with limited human feedback, such as the interactive SMT applications discussed above. In such scenarios, BLEU per sentence may not be the best metric for quantifying feedback. Instead, we will examine feedback based on HTER (Snover et al., 2006) or judgments based on Likert scales (Likert, 1932)."}, {"heading": "Acknowledgements", "text": "This research was supported in part by DFG funding RI-2221 / 2-1 \"Grounding Statistical Machine Translation in Perception and Action.\""}], "references": [{"title": "An efficient bandit algorithm", "author": ["J. Abernethy", "A. Rakhlin"], "venue": null, "citeRegEx": "Abernethy and Rakhlin,? \\Q2009\\E", "shortCiteRegEx": "Abernethy and Rakhlin", "year": 2009}, {"title": "Optimal algorithms for online convex optimization with multi-point bandit feedback", "author": ["A. Agarwal", "O. Dekel", "L. Xiao"], "venue": "Conference on Learning Theory (COLT), Haifa, Israel.", "citeRegEx": "Agarwal et al\\.,? 2010", "shortCiteRegEx": "Agarwal et al\\.", "year": 2010}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM Journal on Computing, 32(1):48\u201377.", "citeRegEx": "Auer et al\\.,? 2002", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Large-scale expected BLEU training of phrase-based reordering models", "author": ["M. Auli", "M. Galley", "J. Gao"], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Auli et al\\.,? 2014", "shortCiteRegEx": "Auli et al\\.", "year": 2014}, {"title": "Non-asymptotic analysis of stochastic approximation algorithms for machine learning", "author": ["F. Bach", "E. Moulines"], "venue": "Advances in Neural Information Processing Systems (NIPS), Granada, Spain.", "citeRegEx": "Bach and Moulines,? 2011", "shortCiteRegEx": "Bach and Moulines", "year": 2011}, {"title": "Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n)", "author": ["F. Bach", "E. Moulines"], "venue": "Advances in Neural Information Processing Systems (NIPS), Lake Tahoe, CA, USA.", "citeRegEx": "Bach and Moulines,? 2013", "shortCiteRegEx": "Bach and Moulines", "year": 2013}, {"title": "Online adaptation to post-edits for phrase-based statistical machine translation", "author": ["N. Bertoldi", "P. Simianer", "M. Cettolo", "K. W\u00e4schle", "M. Federico", "S. Riezler"], "venue": "Machine Translation, 29:309\u2013339.", "citeRegEx": "Bertoldi et al\\.,? 2014", "shortCiteRegEx": "Bertoldi et al\\.", "year": 2014}, {"title": "Neuro-Dynamic Programming", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific.", "citeRegEx": "Bertsekas and Tsitsiklis,? 1996", "shortCiteRegEx": "Bertsekas and Tsitsiklis", "year": 1996}, {"title": "Stochastic learning", "author": ["L. Bottou"], "venue": "Bousquet, O. and von Luxburg, U., editors, Advanced Lectures on Machine Learning, pages 146\u2013168.", "citeRegEx": "Bottou,? 2004", "shortCiteRegEx": "Bottou", "year": 2004}, {"title": "Reinforcement learning for mapping instructions to actions", "author": ["S. Branavan", "H. Chen", "L.S. Zettlemoyer", "R. Barzilay"], "venue": "Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, Suntec, Singapore.", "citeRegEx": "Branavan et al\\.,? 2009", "shortCiteRegEx": "Branavan et al\\.", "year": 2009}, {"title": "Learning to search better than your teacher", "author": ["Chang", "K.-W.", "A. Krishnamurthy", "A. Agarwal", "H. Daume", "J. Langford"], "venue": "International Conference on Machine Learning (ICML), Lille, France.", "citeRegEx": "Chang et al\\.,? 2015", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "Simple and scalable response prediction for display advertising", "author": ["O. Chapelle", "E. Manavaglu", "R. Rosales"], "venue": "ACM Transactions on Intelligent Systems and Technology, 5(4).", "citeRegEx": "Chapelle et al\\.,? 2014", "shortCiteRegEx": "Chapelle et al\\.", "year": 2014}, {"title": "A real-world system for simultaneous translation of German lectures", "author": ["E. Cho", "C. F\u00fcgen", "T. Hermann", "K. Kilgour", "M. Mediani", "C. Mohr", "J. Niehues", "K. Rottman", "C. Saam", "S. St\u00fcker", "A. Waibel"], "venue": "Interspeech, Lyon, France.", "citeRegEx": "Cho et al\\.,? 2013", "shortCiteRegEx": "Cho et al\\.", "year": 2013}, {"title": "Contextual bandits with linear payoff functions", "author": ["W. Chu", "L. Li", "L. Reyzin", "R.E. Schapire"], "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS), Fort Lauderdale, FL, USA.", "citeRegEx": "Chu et al\\.,? 2011", "shortCiteRegEx": "Chu et al\\.", "year": 2011}, {"title": "Better hypothesis testing for statistical machine translation: Controlling for optimizer instability", "author": ["J. Clark", "C. Dyer", "A. Lavie", "N. Smith"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL\u201911), Portland, OR.", "citeRegEx": "Clark et al\\.,? 2011", "shortCiteRegEx": "Clark et al\\.", "year": 2011}, {"title": "Domain adaptation for machine translation by mining unseen words", "author": ["H. Daum\u00e9", "J. Jagarlamudi"], "venue": "Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT), Portland, OR, USA.", "citeRegEx": "Daum\u00e9 and Jagarlamudi,? 2011", "shortCiteRegEx": "Daum\u00e9 and Jagarlamudi", "year": 2011}, {"title": "Learning from post-editing: Online model adaptation for statistical machine translation", "author": ["M. Denkowski", "C. Dyer", "A. Lavie"], "venue": "Conference of the European Chapter of the Association for Computational Linguistics (EACL), Gothenburg, Sweden.", "citeRegEx": "Denkowski et al\\.,? 2014", "shortCiteRegEx": "Denkowski et al\\.", "year": 2014}, {"title": "A simple, fast, and effective reparameterization of IBM Model 2", "author": ["C. Dyer", "V. Chahuneau", "N.A. Smith"], "venue": "Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA, USA.", "citeRegEx": "Dyer et al\\.,? 2013", "shortCiteRegEx": "Dyer et al\\.", "year": 2013}, {"title": "Online convex optimization in the bandit setting: gradient descent without a gradient", "author": ["A.D. Flaxman", "A.T. Kalai", "H.B. McMahan"], "venue": "ACM-SIAM Symposium on Discrete Algorithms (SODA), Philadelphia, PA.", "citeRegEx": "Flaxman et al\\.,? 2005", "shortCiteRegEx": "Flaxman et al\\.", "year": 2005}, {"title": "Softmax-margin training for structured log-linear models", "author": ["K. Gimpel", "N.A. Smith"], "venue": "Technical Report CMU-LTI-10-008, Carnegie Mellon University, Pittsburgh, PA, USA.", "citeRegEx": "Gimpel and Smith,? 2010", "shortCiteRegEx": "Gimpel and Smith", "year": 2010}, {"title": "Learning from natural instructions", "author": ["D. Goldwasser", "D. Roth"], "venue": "Machine Learning, 94(2):205\u2013232.", "citeRegEx": "Goldwasser and Roth,? 2013", "shortCiteRegEx": "Goldwasser and Roth", "year": 2013}, {"title": "Human effort and machine learnability in computer aided translation", "author": ["S. Green", "S.I. Wang", "J. Chuang", "J. Heer", "S. Schuster", "C.D. Manning"], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar.", "citeRegEx": "Green et al\\.,? 2014", "shortCiteRegEx": "Green et al\\.", "year": 2014}, {"title": "Maximum expected BLEU training of phrase and lexicon translation models", "author": ["X. He", "L. Deng"], "venue": "Meeting of the Association for Computational Linguistics (ACL), Jeju Island, Korea.", "citeRegEx": "He and Deng,? 2012", "shortCiteRegEx": "He and Deng", "year": 2012}, {"title": "Scalable modified KneserNey language model estimation", "author": ["K. Heafield", "I. Pouzyrevsky", "J.H. Clark", "P. Koehn"], "venue": "Meeting of the Association for Computational Linguistics (ACL), Sofia, Bulgaria.", "citeRegEx": "Heafield et al\\.,? 2013", "shortCiteRegEx": "Heafield et al\\.", "year": 2013}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Birch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens", "C. Dyer", "O. Bojar", "A. Constantin", "E. Herbst"], "venue": "ACL Demo and Poster Sessions, Prague, Czech Republic.", "citeRegEx": "Koehn et al\\.,? 2007", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Experiments in domain adaptation for statistical machine translation", "author": ["P. Koehn", "J. Schroeder"], "venue": "Workshop on Statistical Machine Translation, Prague, Czech Republic.", "citeRegEx": "Koehn and Schroeder,? 2007", "shortCiteRegEx": "Koehn and Schroeder", "year": 2007}, {"title": "The epoch-greedy algorithm for multi-armed bandits with side information", "author": ["J. Langford", "T. Zhang"], "venue": "Advances in Neural Information Processing Systems (NIPS). Vancouver, Canada.", "citeRegEx": "Langford and Zhang,? 2007", "shortCiteRegEx": "Langford and Zhang", "year": 2007}, {"title": "A technique for the measurement of attitudes", "author": ["R. Likert"], "venue": "Archives of Psychology, 140:5\u201355.", "citeRegEx": "Likert,? 1932", "shortCiteRegEx": "Likert", "year": 1932}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization, 19(4):1574\u20131609.", "citeRegEx": "Nemirovski et al\\.,? 2009", "shortCiteRegEx": "Nemirovski et al\\.", "year": 2009}, {"title": "Minimum error rate training in statistical machine translation", "author": ["F.J. Och"], "venue": "Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL), Edmonton, Canada.", "citeRegEx": "Och,? 2003", "shortCiteRegEx": "Och", "year": 2003}, {"title": "Perturb-and-map random fields: Using discrete optimization to learn and sample from energy models", "author": ["G. Papandreou", "A. Yuille"], "venue": "IEEE International Conference on Computer Vision (ICCV), Barcelona, Spain.", "citeRegEx": "Papandreou and Yuille,? 2011", "shortCiteRegEx": "Papandreou and Yuille", "year": 2011}, {"title": "Introduction to Optimization", "author": ["B.T. Polyak"], "venue": "Optimization Software, Inc., New York.", "citeRegEx": "Polyak,? 1987", "shortCiteRegEx": "Polyak", "year": 1987}, {"title": "Acceleration of stochastic approximation by averaging", "author": ["B.T. Polyak", "A.B. Juditsky"], "venue": "SIAM Journal on Control and Optimization, 30(4):838\u2013855.", "citeRegEx": "Polyak and Juditsky,? 1992", "shortCiteRegEx": "Polyak and Juditsky", "year": 1992}, {"title": "Pseudogradient adaptation and training algorithms", "author": ["B.T. Polyak", "Y.Z. Tsypkin"], "venue": "Automation and remote control: a translation of Avtomatika i Telemekhanika, 34(3):377\u2013397.", "citeRegEx": "Polyak and Tsypkin,? 1973", "shortCiteRegEx": "Polyak and Tsypkin", "year": 1973}, {"title": "On some pitfalls in automatic evaluation and significance testing for MT", "author": ["S. Riezler", "J. Maxwell"], "venue": "Proceedings of the ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization, Ann Arbor, MI.", "citeRegEx": "Riezler and Maxwell,? 2005", "shortCiteRegEx": "Riezler and Maxwell", "year": 2005}, {"title": "Response-based learning for grounded machine translation", "author": ["S. Riezler", "P. Simianer", "C. Haas"], "venue": "Meeting of the Association for Computational Linguistics (ACL), Baltimore, MD, USA.", "citeRegEx": "Riezler et al\\.,? 2014", "shortCiteRegEx": "Riezler et al\\.", "year": 2014}, {"title": "Some aspects of the sequential design of experiments", "author": ["H. Robbins"], "venue": "Bulletin of the American Statistical Society, 55:527\u2013535.", "citeRegEx": "Robbins,? 1952", "shortCiteRegEx": "Robbins", "year": 1952}, {"title": "Online discriminative learning for machine translation with binary-valued feedback", "author": ["A. Saluja", "Y. Zhang"], "venue": "Machine Translation, 28:69\u201390.", "citeRegEx": "Saluja and Zhang,? 2014", "shortCiteRegEx": "Saluja and Zhang", "year": 2014}, {"title": "Online learning and online convex optimization", "author": ["S. Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning, 4(2):107\u2013194.", "citeRegEx": "Shalev.Shwartz,? 2012", "shortCiteRegEx": "Shalev.Shwartz", "year": 2012}, {"title": "Minimum risk annealing for training log-linear models", "author": ["D.A. Smith", "J. Eisner"], "venue": "International Committee on Computational Linguistics and the Association for Computational Linguistics (COLING-ACL), Sydney, Australia.", "citeRegEx": "Smith and Eisner,? 2006", "shortCiteRegEx": "Smith and Eisner", "year": 2006}, {"title": "A study of translation edit rate with targeted human annotation", "author": ["M. Snover", "B. Dorr", "R. Schwartz", "L. Micciulla", "J. Makhoul"], "venue": "Conference of the Association for Machine Translation in the Americas (AMTA), Cambridge, MA, USA.", "citeRegEx": "Snover et al\\.,? 2006", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "A coactive learning view of online structured prediction in statistical machine translation", "author": ["A. Sokolov", "S. Riezler", "S.B. Cohen"], "venue": "Proceedings of the Conference on Computational Natural Language Learning (CoNLL), Beijing, China.", "citeRegEx": "Sokolov et al\\.,? 2015", "shortCiteRegEx": "Sokolov et al\\.", "year": 2015}, {"title": "Introduction to Stochastic Search and Optimization: Estimation, Simulation, and Control", "author": ["J.C. Spall"], "venue": "Wiley.", "citeRegEx": "Spall,? 2003", "shortCiteRegEx": "Spall", "year": 2003}, {"title": "Policy gradient methods for reinforcement learning with function approximation", "author": ["R.S. Sutton", "D. McAllester", "S. Singh", "Y. Mansour"], "venue": "Advances in Neural Information Processings Systems (NIPS), Vancouver, Canada.", "citeRegEx": "Sutton et al\\.,? 2000", "shortCiteRegEx": "Sutton et al\\.", "year": 2000}, {"title": "Max-margin parsing", "author": ["B. Taskar", "D. Klein", "M. Collins", "D. Koller", "C. Manning"], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP), Barcelona, Spain.", "citeRegEx": "Taskar et al\\.,? 2004", "shortCiteRegEx": "Taskar et al\\.", "year": 2004}, {"title": "Large margin methods for structured and interdependent output variables", "author": ["I. Tsochantaridis", "T. Joachims", "T. Hofmann", "Y. Altun"], "venue": "Journal of Machine Learning Research, 5:1453\u20131484.", "citeRegEx": "Tsochantaridis et al\\.,? 2005", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2005}, {"title": "A comparison of update strategies for large-scale maximum expected bleu training", "author": ["J. Wuebker", "S. Muehr", "P. Lehnen", "S. Peitz", "H. Ney"], "venue": "Conference of the North American Chapter of the Association for Computational Linguistics Human Language Technologies (NAACL-HLT), Denver, CO, USA.", "citeRegEx": "Wuebker et al\\.,? 2015", "shortCiteRegEx": "Wuebker et al\\.", "year": 2015}, {"title": "Interactively optimizing information retrieval systems as a dueling bandits problem", "author": ["Y. Yue", "T. Joachims"], "venue": "International Conference on Machine Learning (ICML), Montreal, Canada.", "citeRegEx": "Yue and Joachims,? 2009", "shortCiteRegEx": "Yue and Joachims", "year": 2009}, {"title": "Probabilistic models of vision and max-margin methods", "author": ["A. Yuille", "X. He"], "venue": "Frontiers of Electrical and Electronic Engineering, 7(1).", "citeRegEx": "Yuille and He,? 2012", "shortCiteRegEx": "Yuille and He", "year": 2012}], "referenceMentions": [{"referenceID": 11, "context": "This scenario has (financially) important real world applications such as online advertising (Chapelle et al., 2014) that showcases a tradeoff between exploration (a new ad needs to be displayed in order to learn its click-through rate) and exploitation (displaying the ad with the current best estimate is better in the short term).", "startOffset": 93, "endOffset": 116}, {"referenceID": 6, "context": "For example, online learning has been applied successfully in interactive statistical machine translation (SMT) (Bertoldi et al., 2014; Denkowski et al., 2014; Green et al., 2014).", "startOffset": 112, "endOffset": 179}, {"referenceID": 16, "context": "For example, online learning has been applied successfully in interactive statistical machine translation (SMT) (Bertoldi et al., 2014; Denkowski et al., 2014; Green et al., 2014).", "startOffset": 112, "endOffset": 179}, {"referenceID": 21, "context": "For example, online learning has been applied successfully in interactive statistical machine translation (SMT) (Bertoldi et al., 2014; Denkowski et al., 2014; Green et al., 2014).", "startOffset": 112, "endOffset": 179}, {"referenceID": 12, "context": "An example where user feedback is limited by a time constraint is simultaneous translation of a speech input stream (Cho et al., 2013).", "startOffset": 116, "endOffset": 134}, {"referenceID": 29, "context": "We investigate possibilities to \u201cbanditize\u201d objectives such as expected loss (Och, 2003; Smith and Eisner, 2006; Gimpel and Smith, 2010) that have been proposed for structured prediction in NLP.", "startOffset": 77, "endOffset": 136}, {"referenceID": 39, "context": "We investigate possibilities to \u201cbanditize\u201d objectives such as expected loss (Och, 2003; Smith and Eisner, 2006; Gimpel and Smith, 2010) that have been proposed for structured prediction in NLP.", "startOffset": 77, "endOffset": 136}, {"referenceID": 19, "context": "We investigate possibilities to \u201cbanditize\u201d objectives such as expected loss (Och, 2003; Smith and Eisner, 2006; Gimpel and Smith, 2010) that have been proposed for structured prediction in NLP.", "startOffset": 77, "endOffset": 136}, {"referenceID": 44, "context": "Since most current approaches to bandit optimization rely on a multiclass classification scenario, the first challenge of our work is to adapt bandit learning to structured prediction over exponentially large structured output spaces (Taskar et al., 2004; Tsochantaridis et al., 2005).", "startOffset": 234, "endOffset": 284}, {"referenceID": 45, "context": "Since most current approaches to bandit optimization rely on a multiclass classification scenario, the first challenge of our work is to adapt bandit learning to structured prediction over exponentially large structured output spaces (Taskar et al., 2004; Tsochantaridis et al., 2005).", "startOffset": 234, "endOffset": 284}, {"referenceID": 18, "context": "Furthermore, most theoretical work on online learning with bandit feedback relies on convexity assumptions about objective functions, both in the nonstochastic adversarial setting (Flaxman et al., 2005; Shalev-Shwartz, 2012) as well as in the stochastic optimization framework (Spall, 2003; Nemirovski et al.", "startOffset": 180, "endOffset": 224}, {"referenceID": 38, "context": "Furthermore, most theoretical work on online learning with bandit feedback relies on convexity assumptions about objective functions, both in the nonstochastic adversarial setting (Flaxman et al., 2005; Shalev-Shwartz, 2012) as well as in the stochastic optimization framework (Spall, 2003; Nemirovski et al.", "startOffset": 180, "endOffset": 224}, {"referenceID": 42, "context": ", 2005; Shalev-Shwartz, 2012) as well as in the stochastic optimization framework (Spall, 2003; Nemirovski et al., 2009; Bach and Moulines, 2011).", "startOffset": 82, "endOffset": 145}, {"referenceID": 28, "context": ", 2005; Shalev-Shwartz, 2012) as well as in the stochastic optimization framework (Spall, 2003; Nemirovski et al., 2009; Bach and Moulines, 2011).", "startOffset": 82, "endOffset": 145}, {"referenceID": 4, "context": ", 2005; Shalev-Shwartz, 2012) as well as in the stochastic optimization framework (Spall, 2003; Nemirovski et al., 2009; Bach and Moulines, 2011).", "startOffset": 82, "endOffset": 145}, {"referenceID": 33, "context": "Our case is a non-convex optimization problem, which we analyze in the simple and elegant framework of pseudogradient adaptation that allows us to show convergence of the presented algorithm (Polyak and Tsypkin, 1973; Polyak, 1987).", "startOffset": 191, "endOffset": 231}, {"referenceID": 31, "context": "Our case is a non-convex optimization problem, which we analyze in the simple and elegant framework of pseudogradient adaptation that allows us to show convergence of the presented algorithm (Polyak and Tsypkin, 1973; Polyak, 1987).", "startOffset": 191, "endOffset": 231}, {"referenceID": 47, "context": "Similarly, a comparison between our approach and dueling bandits (Yue and Joachims, 2009) is skewed towards the latter approach that has access to two-point feedback instead of one-point feedback as in our case.", "startOffset": 65, "endOffset": 89}, {"referenceID": 1, "context": "While it has been shown that querying the loss function at two points leads to convergence results that closely resemble bounds for the full information case (Agarwal et al., 2010), such feedback is clearly twice as expensive and, depending on the application, might not be elicitable from users.", "startOffset": 158, "endOffset": 180}, {"referenceID": 29, "context": "Stochastic Approximation. Online learning from bandit feedback dates back to Robbins (1952) who formulated the task as a problem of sequential decision making.", "startOffset": 2, "endOffset": 92}, {"referenceID": 32, "context": "While the stochastic approximation framework is quite general, most theoretical analyses of convergence and convergence rate are based on (strong) convexity assumptions (Polyak and Juditsky, 1992; Spall, 2003; Nemirovski et al., 2009; Bach and Moulines, 2011, 2013) and thus not applicable to our case.", "startOffset": 169, "endOffset": 265}, {"referenceID": 42, "context": "While the stochastic approximation framework is quite general, most theoretical analyses of convergence and convergence rate are based on (strong) convexity assumptions (Polyak and Juditsky, 1992; Spall, 2003; Nemirovski et al., 2009; Bach and Moulines, 2011, 2013) and thus not applicable to our case.", "startOffset": 169, "endOffset": 265}, {"referenceID": 28, "context": "While the stochastic approximation framework is quite general, most theoretical analyses of convergence and convergence rate are based on (strong) convexity assumptions (Polyak and Juditsky, 1992; Spall, 2003; Nemirovski et al., 2009; Bach and Moulines, 2011, 2013) and thus not applicable to our case.", "startOffset": 169, "endOffset": 265}, {"referenceID": 2, "context": "The adversarial bandit setting has been extended to take context or side information into account, using models based on general linear classifiers (Auer et al., 2002; Langford and Zhang, 2007; Chu et al., 2011).", "startOffset": 148, "endOffset": 211}, {"referenceID": 26, "context": "The adversarial bandit setting has been extended to take context or side information into account, using models based on general linear classifiers (Auer et al., 2002; Langford and Zhang, 2007; Chu et al., 2011).", "startOffset": 148, "endOffset": 211}, {"referenceID": 13, "context": "The adversarial bandit setting has been extended to take context or side information into account, using models based on general linear classifiers (Auer et al., 2002; Langford and Zhang, 2007; Chu et al., 2011).", "startOffset": 148, "endOffset": 211}, {"referenceID": 18, "context": "Furthermore, most theoretical analyses rely on online (strongly) convex optimization (Flaxman et al., 2005; Shalev-Shwartz, 2012) thus limiting the applicability to our case.", "startOffset": 85, "endOffset": 129}, {"referenceID": 38, "context": "Furthermore, most theoretical analyses rely on online (strongly) convex optimization (Flaxman et al., 2005; Shalev-Shwartz, 2012) thus limiting the applicability to our case.", "startOffset": 85, "endOffset": 129}, {"referenceID": 2, "context": "Auer et al. (2002) initiated an active area of research on nonstochastic bandit learning, i.", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "Bertsekas and Tsitsiklis (1996) cover optimization for neural networks and reinforcement learning under the name of \u201cneurodynamic programming\u201d.", "startOffset": 0, "endOffset": 32}, {"referenceID": 7, "context": "Bertsekas and Tsitsiklis (1996) cover optimization for neural networks and reinforcement learning under the name of \u201cneurodynamic programming\u201d. Both areas are dealing with non-convex objectives that lead to stochastic iterative algorithms. Interestingly, the available analyses of non-convex optimization for neural networks and reinforcement learning in Bertsekas and Tsitsiklis (1996), Sutton et al.", "startOffset": 0, "endOffset": 387}, {"referenceID": 7, "context": "Bertsekas and Tsitsiklis (1996) cover optimization for neural networks and reinforcement learning under the name of \u201cneurodynamic programming\u201d. Both areas are dealing with non-convex objectives that lead to stochastic iterative algorithms. Interestingly, the available analyses of non-convex optimization for neural networks and reinforcement learning in Bertsekas and Tsitsiklis (1996), Sutton et al. (2000), or Bottou (2004) rely heavily on Polyak and Tsypkin (1973)\u2019s pseudogradient framework.", "startOffset": 0, "endOffset": 409}, {"referenceID": 7, "context": "Bertsekas and Tsitsiklis (1996) cover optimization for neural networks and reinforcement learning under the name of \u201cneurodynamic programming\u201d. Both areas are dealing with non-convex objectives that lead to stochastic iterative algorithms. Interestingly, the available analyses of non-convex optimization for neural networks and reinforcement learning in Bertsekas and Tsitsiklis (1996), Sutton et al. (2000), or Bottou (2004) rely heavily on Polyak and Tsypkin (1973)\u2019s pseudogradient framework.", "startOffset": 0, "endOffset": 427}, {"referenceID": 7, "context": "Bertsekas and Tsitsiklis (1996) cover optimization for neural networks and reinforcement learning under the name of \u201cneurodynamic programming\u201d. Both areas are dealing with non-convex objectives that lead to stochastic iterative algorithms. Interestingly, the available analyses of non-convex optimization for neural networks and reinforcement learning in Bertsekas and Tsitsiklis (1996), Sutton et al. (2000), or Bottou (2004) rely heavily on Polyak and Tsypkin (1973)\u2019s pseudogradient framework.", "startOffset": 0, "endOffset": 469}, {"referenceID": 18, "context": "For example, Goldwasser and Roth (2013) presented an online structured learning algorithm that uses positive executability of a semantic parse against a database to convert a predicted parse into a gold standard structure for learning.", "startOffset": 13, "endOffset": 40}, {"referenceID": 18, "context": "For example, Goldwasser and Roth (2013) presented an online structured learning algorithm that uses positive executability of a semantic parse against a database to convert a predicted parse into a gold standard structure for learning. Riezler et al. (2014) apply a similar idea to SMT by using the executability of a semantic parse of a translated database query as signal to convert a predicted translation into gold standard reference in structured learning.", "startOffset": 13, "endOffset": 258}, {"referenceID": 18, "context": "For example, Goldwasser and Roth (2013) presented an online structured learning algorithm that uses positive executability of a semantic parse against a database to convert a predicted parse into a gold standard structure for learning. Riezler et al. (2014) apply a similar idea to SMT by using the executability of a semantic parse of a translated database query as signal to convert a predicted translation into gold standard reference in structured learning. Sokolov et al. (2015) present a coactive learning approach to structured learning in SMT where instead of a gold standard reference a slight improvement over the prediction is shown to be sufficient for learning.", "startOffset": 13, "endOffset": 484}, {"referenceID": 18, "context": "For example, Goldwasser and Roth (2013) presented an online structured learning algorithm that uses positive executability of a semantic parse against a database to convert a predicted parse into a gold standard structure for learning. Riezler et al. (2014) apply a similar idea to SMT by using the executability of a semantic parse of a translated database query as signal to convert a predicted translation into gold standard reference in structured learning. Sokolov et al. (2015) present a coactive learning approach to structured learning in SMT where instead of a gold standard reference a slight improvement over the prediction is shown to be sufficient for learning. Saluja and Zhang (2014) present an incorporation of binary feedback into an latent structured SVM for discriminative SMT training.", "startOffset": 13, "endOffset": 699}, {"referenceID": 9, "context": "NLP applications based on reinforcement learning have been presented by Branavan et al. (2009) or Chang et al.", "startOffset": 72, "endOffset": 95}, {"referenceID": 9, "context": "NLP applications based on reinforcement learning have been presented by Branavan et al. (2009) or Chang et al. (2015). Their model differs from ours in that it is structured as a sequence of states at which actions and rewards are computed, however, the theoretical foundation of both types of models can be traced back to Polyak and Tsypkin (1973)\u2019s pseudogradient framework .", "startOffset": 72, "endOffset": 118}, {"referenceID": 9, "context": "NLP applications based on reinforcement learning have been presented by Branavan et al. (2009) or Chang et al. (2015). Their model differs from ours in that it is structured as a sequence of states at which actions and rewards are computed, however, the theoretical foundation of both types of models can be traced back to Polyak and Tsypkin (1973)\u2019s pseudogradient framework .", "startOffset": 72, "endOffset": 349}, {"referenceID": 19, "context": "The expected loss learning criterion for structured prediction is defined as a minimization of the expectation of a task loss function with respect to the conditional distribution over structured outputs (Gimpel and Smith, 2010; Yuille and He, 2012).", "startOffset": 204, "endOffset": 249}, {"referenceID": 48, "context": "The expected loss learning criterion for structured prediction is defined as a minimization of the expectation of a task loss function with respect to the conditional distribution over structured outputs (Gimpel and Smith, 2010; Yuille and He, 2012).", "startOffset": 204, "endOffset": 249}, {"referenceID": 27, "context": "Despite of this, most approaches rely on gradientdescent techniques for optimization (see Och (2003), Smith and Eisner (2006), He and Deng (2012), Auli et al.", "startOffset": 90, "endOffset": 101}, {"referenceID": 27, "context": "Despite of this, most approaches rely on gradientdescent techniques for optimization (see Och (2003), Smith and Eisner (2006), He and Deng (2012), Auli et al.", "startOffset": 90, "endOffset": 126}, {"referenceID": 21, "context": "Despite of this, most approaches rely on gradientdescent techniques for optimization (see Och (2003), Smith and Eisner (2006), He and Deng (2012), Auli et al.", "startOffset": 127, "endOffset": 146}, {"referenceID": 3, "context": "Despite of this, most approaches rely on gradientdescent techniques for optimization (see Och (2003), Smith and Eisner (2006), He and Deng (2012), Auli et al. (2014), Wuebker et al.", "startOffset": 147, "endOffset": 166}, {"referenceID": 3, "context": "Despite of this, most approaches rely on gradientdescent techniques for optimization (see Och (2003), Smith and Eisner (2006), He and Deng (2012), Auli et al. (2014), Wuebker et al. (2015), inter alia) by following the opposite direction of the gradient of (4):", "startOffset": 147, "endOffset": 189}, {"referenceID": 0, "context": "We use a Gibbs distribution estimate as a sampling distribution to perform simultaneous exploration / exploitation on output structures (Abernethy and Rakhlin, 2009).", "startOffset": 136, "endOffset": 165}, {"referenceID": 30, "context": "Otherwise, we use a Perturb-and-MAP approach (Papandreou and Yuille, 2011), restricted to unary potentials, to obtain an approximate Gibbs sample without waiting for the MC chain to mix.", "startOffset": 45, "endOffset": 74}, {"referenceID": 29, "context": "2 Stochastic Approximation Analysis The construction of the update in Algorithm 1 as a stochastic realization of the true gradient allows us to analyze the algorithm as a stochastic approximation algorithm. We show how our case can be fit in the pseudogradient adaptation framework of Polyak and Tsypkin (1973) which gives asymptotic guarantees for non-convex and convex objectives.", "startOffset": 4, "endOffset": 311}, {"referenceID": 31, "context": "Under the exclusion of trivial solutions such as st = 0, the following convergence assertion can be made: Theorem 1 (Polyak and Tsypkin (1973), Thm.", "startOffset": 117, "endOffset": 143}, {"referenceID": 46, "context": "5 Structured Dueling Bandits For purposes of comparison, we present an extension of Yue and Joachims (2009)\u2019s dueling bandits algorithm to structured prediction problems.", "startOffset": 84, "endOffset": 108}, {"referenceID": 46, "context": "5 Structured Dueling Bandits For purposes of comparison, we present an extension of Yue and Joachims (2009)\u2019s dueling bandits algorithm to structured prediction problems. The original algorithm is not specifically designed for structured prediction problems, but it is generic enough to be applicable to such problems when the quality of a parameter vector can be proxied through loss evaluation of an inferred structure. The Structured Dueling Bandits algorithm compares a current weight vector wt with a neighboring point w t along a direction ut, performing exploration (controlled by \u03b4, line 5) by probing random directions, and exploitation (controlled by \u03b3, line 8) by taking a step into the winning direction. The comparison step in line 6 is adapted to structured prediction from the original algorithm of Yue and Joachims (2009) by comparing the quality of wt and w t via an evaluation of the losses \u2206(\u0177wt(xt)) and \u2206(\u0177w\u2032 t(xt)) of the structured arms corresponding to MAP prediction (3) under wt and w t, respectively.", "startOffset": 84, "endOffset": 838}, {"referenceID": 1, "context": "It has been shown that two-point feedback leads to convergence results that are close to those for learning from full information Agarwal et al. (2010). However, two-point feedback is twice as expensive as one-point feedback, and most importantly, such feedback might not be elicitable from users in real-world situations where feedback is limited by time- and resourceconstraints.", "startOffset": 130, "endOffset": 152}, {"referenceID": 25, "context": "We use the data from the WMT 2007 shared task for domain adaptation experiments in a popular benchmark setup from Europarl to NewsCommentary for French-to-English (Koehn and Schroeder, 2007; Daum\u00e9 and Jagarlamudi, 2011).", "startOffset": 163, "endOffset": 219}, {"referenceID": 15, "context": "We use the data from the WMT 2007 shared task for domain adaptation experiments in a popular benchmark setup from Europarl to NewsCommentary for French-to-English (Koehn and Schroeder, 2007; Daum\u00e9 and Jagarlamudi, 2011).", "startOffset": 163, "endOffset": 219}, {"referenceID": 17, "context": "We tokenized and lowercased our data using the moses toolkit, and prepared word alignments by fast align (Dyer et al., 2013).", "startOffset": 105, "endOffset": 124}, {"referenceID": 24, "context": "The SMT setup is phrase-based translation using non-unique 5,000-best lists from moses (Koehn et al., 2007) and a 4-gram language model (Heafield et al.", "startOffset": 87, "endOffset": 107}, {"referenceID": 23, "context": ", 2007) and a 4-gram language model (Heafield et al., 2013).", "startOffset": 36, "endOffset": 59}, {"referenceID": 29, "context": "The model uses 15 dense features (6 lexicalized reordering features, 1 distortion, 1 outof-domain and 1 in-domain language model, 1 word penalty, 5 translation model features) that are tuned with MERT (Och, 2003) on a dev set of Europarl data (dev2006, 2,000 sentences).", "startOffset": 201, "endOffset": 212}, {"referenceID": 34, "context": "0001, using an Approximate Randomization test (Riezler and Maxwell, 2005; Clark et al., 2011).", "startOffset": 46, "endOffset": 93}, {"referenceID": 14, "context": "0001, using an Approximate Randomization test (Riezler and Maxwell, 2005; Clark et al., 2011).", "startOffset": 46, "endOffset": 93}, {"referenceID": 40, "context": "We will instead investigate feedback based on HTER (Snover et al., 2006), or based on judgements according to Likert scales (Likert, 1932).", "startOffset": 51, "endOffset": 72}, {"referenceID": 27, "context": ", 2006), or based on judgements according to Likert scales (Likert, 1932).", "startOffset": 59, "endOffset": 73}], "year": 2016, "abstractText": "We present an approach to structured prediction from bandit feedback, called Bandit Structured Prediction, where only the value of a task loss function at a single predicted point, instead of a correct structure, is observed in learning. We present an application to discriminative reranking in Statistical Machine Translation (SMT) where the learning algorithm only has access to a 1 \u2212 BLEU loss evaluation of a predicted translation instead of obtaining a gold standard reference translation. In our experiment bandit feedback is obtained by evaluating BLEU on reference translations without revealing them to the algorithm. This can be thought of as a simulation of interactive machine translation where an SMT system is personalized by a user who provides single point feedback to predicted translations. Our experiments show that our approach improves translation quality and is comparable to approaches that employ more informative feedback in learning.", "creator": "LaTeX with hyperref package"}}}