{"id": "1601.05647", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2016", "title": "On Structured Sparsity of Phonological Posteriors for Linguistic Parsing", "abstract": "The speech signal conveys information on different time scales from short (20-40 ms) time scale or segmental, associated to phonological and phonetic information to long (150-250 ms) time scale or supra segmental, associated to syllabic and prosodic information. Linguistic and neurocognitive studies recognize the phonological classes at segmental level as the essential and invariant representations used in speech temporal organization. In the context of speech processing, a deep neural network (DNN) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal. A vector of all phonological class probabilities is referred to as phonological posterior. There are only very few classes comprising a short term speech signal; hence, the phonological posterior is a sparse vector. Although the phonological posteriors are estimated at segmental level, we claim that they convey supra-segmental information. Namely, we demonstrate that phonological posteriors are indicative of syllabic and prosodic events. Building on findings from converging linguistic evidence on the gestural model of Articulatory Phonology as well as neural basis of speech perception, we hypothesize that phonological posteriors convey properties of linguistic classes at multiple time scales, and this information is embedded in their support (index) of active coefficients. To verify this hypothesis, we obtain a binary representation of phonological posteriors at segmental level which is referred to as first-order sparsity structure; the high-order structures are obtained by concatenation of first-order binary vectors. It is then confirmed that classification of supra-segmental linguistic events, the problem known as linguistic parsing, can be achieved with high accuracy using a simple binary pattern matching of first-order or high-order structures.", "histories": [["v1", "Thu, 21 Jan 2016 14:15:41 GMT  (803kb,D)", "https://arxiv.org/abs/1601.05647v1", null], ["v2", "Wed, 18 May 2016 14:08:02 GMT  (818kb,D)", "http://arxiv.org/abs/1601.05647v2", null], ["v3", "Tue, 30 Aug 2016 09:23:58 GMT  (836kb,D)", "http://arxiv.org/abs/1601.05647v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["milos cernak", "afsaneh asaei", "herv\\'e bourlard"], "accepted": false, "id": "1601.05647"}, "pdf": {"name": "1601.05647.pdf", "metadata": {"source": "CRF", "title": "On Structured Sparsity of Phonological Posteriors for Linguistic Parsing", "authors": ["Milos Cernaka", "Afsaneh Asaeia", "Herv\u00e9 Bourlard"], "emails": ["milos.cernak@idiap.ch", "afsaneh.asaei@idiap.ch", "herve.bourlard@idiap.ch"], "sections": [{"heading": null, "text": "The speech signal conveys information on different timescales of short (20-40 ms) time scale or segmental level, coupled with phonological and phonetic information on long (150-250 ms) time scale or supra segmental level, coupled with syllabic and prosodic information. Linguistic and neurocognitive studies recognize the phonological classes at the segmental level as essential and invariant representations used in the temporal organization of speech. In the context of speech processing, a deep neural network (DNN) is an effective computational method to derive the probability of individual phonological classes from a short segment of the speech signal. A vector of all phonological class probabilities is called a phonological latecomer. There are very few classes that include a short-term speech signal; therefore, the phonological latecomer is a sparse vector."}, {"heading": "1. Introduction", "text": "This year, the time has come for us to be able to set out to find a solution that will enable us, that will enable us to put ourselves in a position where we are able to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position, that will enable us to put ourselves in a position where we are."}, {"heading": "2. Phonological Class-conditional Posteriors", "text": "Figure 1 illustrates the process of phonological analysis (Yu et al., 2012; Cernak et al., 2015b). The phonological posterior features are extracted, starting with the transformation of a segment of speech samples into a sequence of acoustic features X = {~ x1,.., ~ xn,., where N denotes the number of segments in the expression. Conventional cepstral coefficients can be used as acoustic characteristics. Then, a bank of phonological class analyzers is realized, which, using neural network classifiers, transforms the acoustic characteristic observation X into a sequence of phonological posterior probabilities Z = {~ z1,. zn,., ~ zN}; a posterioral perception of phonological probabilities ~ zn = [p (c1 | xn), p (ck | xn)."}, {"heading": "2.1. Linguistic Evidence", "text": "Linguistics defines two traditional components of speech structures: 1. Cognitive structure consisting of system primitives, that is, the units of representation for cognitively relevant objects such as phonemes or syllables. System primitives are represented by canonical phonological characteristics (classes) that arise during the phonological coding process (Levelt, 1993).2 Physical structure, which is generated by a series of permissible operations via cognitive system primitives, results in the observed (surface) patterns. The physical structure is represented by phonological characteristics that can be estimated partially from the speech signal by inverse filtering. Phonological posteriors can also be classified as phonological characteristics. Canonical (discrete) phonological characteristics have been used over the last 60 years to describe cognitive structures of speech noise. Miller and Nicely (1955) have experimentally demonstrated that similar confusions were perceived."}, {"heading": "2.2. Cognitive Neuroscience Evidence", "text": "Modern cognitive neuroscience studies use phonological classes as essential and invariant acoustic-phonetic primitives for the temporal organization of language (Poeppel, 2014).Neurological data from brain activity during the planning, production, or perception of language are increasingly used to inform such cognitive models of language and language.Auditory pre-processing occurs in the cochlea and is then divided into two parallel paths leading from the auditory system (Wernicke, 1874 / 1969).For example, the dual-stream model of functional anatomy of language (Hickok and Poeppel, 2007) shows a ventral stream of synthetic signals signals: sound to meaning function using phonological classes, phonological processing at the level on superior temporal sulcus bilaterally, and a dorsal current: sound to action, a direct link between sensory and motor representations of language, which in turn supports speech perception based on the latter phonological classes and a dorsal current."}, {"heading": "3. Sparse Phonological Structures for Linguistic Parsing", "text": "Based on linguistic and cognitive insights, the phonological representation of language is at the center of human language processing. Language analysis takes place at different times, whereby the granularities are generally categorized as segmental and supra-segmental levels. Phonological classes define the subphonetic and phonetic attributes recognized at the segmental level, while syllables, lexical stress and prosodic accent are the basic supra-segmental events - cf. Figure 3. Phonological representations are often examined at the segmental level and their supra-segmental properties are not investigated. This supra-segmental characterization of phonological posteriors is investigated in this paper."}, {"heading": "3.1. Structured Sparsity of Phonological Posteriors", "text": "Phonological background structures are indicators of the physiological posture of the human articulation machinery. Due to physical constraints, only a few combinations can be realized in our vocalization; this physical constraint results in a small number of unique patterns that extend across the entire language corpora (Asaei et al., 2015). We call this structure the first-order structure that is displayed at the segment level. Furthermore, the dynamics of structured sphere patterns are slower than the short segments, and it is indicative of supra-segmental information, leading to a higher order underlying a sequence (trajectory) of phonological background structures. This structure is represented at the supra-segmental level by the analysis of a long duration of phonological background structures, and it is associated with syllabic information or more abstract linguistic attributes. We call this structure a highly ordered structure."}, {"heading": "3.2. Codebook of Linguistic Structures", "text": "The goal of codebook construction is to collect all the structures associated with a particular linguistic event. To this end, we consider binary phonological background events, where probabilities are normalized above 0.5 to 1 and probabilities are reduced below 0.5 to zero. This rounding process allows us to identify the active phonological components as indicators of linguistic events. It also mitigates the speaker and environmental variability encoded in the continuous probabilities. An immediate extension of this approach is the multi-value quantification of phonological background information as opposed to 1-bit quantification. We consider this extension for our future studies and focus on binary phonological indicators to maintain linguistic structures."}, {"heading": "3.3. Pattern Matching for Linguistic Parsing", "text": "Figure 3 illustrates the different time granularity identified for the processing of language. If one follows the suprasegmental characteristics such as syllable type or accented / accented pronunciation, one speaks of linguistic parsing (Poeppel, 2003).The similarity metric can be carried out in a top-down procedure, driven by a priori known segment boundaries. Therefore, we examine several metrics that are effective in different binary classification settings.The definition of binary similarity measures is expressed by operative taxonomic units (Dunn and Everitt, 1982).Consider two binary vectors i, j: a denotes the number of elements at which the values of both i, j, c, 1 are, which means \"positive concordance.\""}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Experimental setup", "text": "We use an open phonological vocoding platform (Cernak and Garner, 2016) to obtain phonological background information. In short, the platform is based on cascaded speech analysis and syntheses that work internally with phonological speech representation. \u2022 In phonological analysis, phonological background information is captured directly from the speech signal by DNNs. Binary (Yu et al., 2012) or polyvalent classifications (Stouten and Martens, 2006; Rasipuram and Magimai.-Doss, 2011) could be used. In the latter case, the phonological classes are grouped by place or type of articulation. We followed binary classification in our work, and thus each DNN determines the probability of a particular phonological class. To confirm the independence of the proposed methodology on a phonological system, two different phonological speech modes are considered: the SPE function (Chomsky and Halle, 1968) and the extended function of SPak."}, {"heading": "4.1.1. Speech Databases", "text": "In recent years, it has been shown that people are able to survive themselves if they do not put themselves in a position to survive and survive on their own. In the last ten years, the number of people who are able to survive has dramatically decreased because they are able to survive. In the last ten years, the number of people who are able to survive and survive has multiplied. In the last ten years, the number of people who are able to survive and survive has multiplied. In the last ten years, the number of people who are able to survive has multiplied. In the last ten years, the number of people who are able to survive has multiplied."}, {"heading": "4.1.2. DNN Training for Phonological Posterior Estimation", "text": "First, we trained a phoneme-based automatic speech recognition system using different frequency cepstral coefficients (MFCC) as acoustic characteristics; the phoneme set of 40 phonemes (including \"sil\" representing silence) was defined by the CMU pronunciation dictionary; the three-dimensional, multilingual triphon model was trained to the 90% subset of the WSJ si tr s 284 set using the HMM-based speech synthesis system (HTS) variant (Zen et al., 2007) of the Hidden Markov Model Toolkit (HTK); the remaining 10% subset was used for cross-validation; we linked triphon models with decision-making structures based on the minimum description length (MDL) criterion (Shinoda and Watanabe, 1997); the MDL criterion allows for unsupervised determination of the number of states."}, {"heading": "4.2. Linguistic Parsing", "text": "In this section we present the evaluation results of our proposed method of top-down linguistic parsing. We provide empirical results on the rarity of phonological hindquarters and confirm the validity of class-specific codebooks for classifying supra-segmental linguistic events based on binary pattern conformity."}, {"heading": "4.2.1. Binary Sparsity of Phonological Posteriors", "text": "Figure 4 illustrates a histogram of the phonological background distribution. We can see that the distribution has the binary nature of phonological background syllables, which is valued in the range of [0 \u2212 1] and is usually very close to 1 or 0. This binary pattern is visible for both stressed and unstressed syllables, as shown in the right and left diagrams. 1-bit discretization, which is achieved by rounding background images, results in a very small number of unique phonological binary structures, 0.1% of all possible structures. This implies that the binary patterns can encode certain forms of the vocal tract. As a limited number of these forms can be produced for human speech, the number of unique patterns is very small. This property also encouraged us to use this binary approximation in the low bit rate language (Cernak et al., 2015b; Asaei et al., 2015)."}, {"heading": "4.2.2. Class-specific Linguistic Structures", "text": "In fact, it is the case that most people who have established themselves in politics and business in recent years, in politics and business, have come up with the idea of surpassing themselves, and that in politics and business they have sided with the people, \"he told the Deutsche Presse-Agentur.\" I don't think we have sided with the people. \"He added,\" I don't think we have sided with the people, I don't think we have sided with the people, but we have sided with the people. \"He added,\" I don't think we have sided with the people who have sided with the people we have sided with. \""}, {"heading": "4.2.3. Dependency of Linguistic Events", "text": "Finally, we test the interdependence between different supra-segmental attributes recorded in code book structures; both stressed and accented syllables convey similar information about the linguistic emphasis, the former denoting it at the lexical level, while the latter denoting it at the prosodic level. Therefore, we assume that the codebook constructed from stressed structures can be used for accent recognition and vice versa. Table 5 lists the accuracies used by these linguistically relevant codebooks. We can see that a codebook constructed from one of the two stress / accent structures can be used with high accuracy to recognize the other. This study confirms the hypothesis that codebooks contain linguistically relevant structures and shows that accentuated structures do indeed correlate to a large extent with the stressed structures."}, {"heading": "5. Concluding Remarks", "text": "The theories of linguistics and cognitive neuroscience indicate that the phonological representation of language is at the center of the linguistic organization of time. We have developed a methodology to quantify the phonological basis of supra-segmental primitives. Experiments confirmed that phonological posteriors mediate supra-segmental information encoded in their support of active components, and these structures can be used as indicators of their higher linguistic attributes. Experiments confirmed that the phonological posteriors contain supra-segmental information encoded in their support of active components."}, {"heading": "6. Acknowledgment", "text": "Afsaneh Asaei is supported by funding from the SNSF project \"Parsimonious Hierarchical Automatic Speech Recognition (PHASER)\" Funding Agreement No. 200021-153507. The authors thank the anonymous reviewers for their time and comments in order to improve the clarity and quality of the manuscript."}, {"heading": "7. References", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "On Compressibility of Neural Network Phonological Features for Low Bit Rate", "author": ["A. References Asaei", "M. Cernak", "H. Bourlard", "Sep"], "venue": null, "citeRegEx": "Asaei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Asaei et al\\.", "year": 2015}, {"title": "The Festival Speech Synthesis System", "author": ["A. Pearson. Black", "P. Taylor", "R. Caley"], "venue": "Communication Sciences and Disorders),", "citeRegEx": "Black et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Black et al\\.", "year": 1997}, {"title": "Functional organization of human sensorimotor cortex", "author": ["K.E. Edinburgh. Bouchard", "N. Mesgarani", "K. Johnson", "E.F. Chang", "Mar"], "venue": null, "citeRegEx": "Bouchard et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bouchard et al\\.", "year": 2013}, {"title": "Towards an articulatory phonology", "author": ["C. P", "L.M. Goldstein"], "venue": "for speech articulation. Nature", "citeRegEx": "P. and Goldstein,? \\Q1986\\E", "shortCiteRegEx": "P. and Goldstein", "year": 1986}, {"title": "2016a. Sound Pattern Matching for Automatic Prosodic", "author": ["M. Cernak", "A. Asaei", "Honnet", "P.-E", "P.N. Garner", "H. Bourlard"], "venue": null, "citeRegEx": "Cernak et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Cernak et al\\.", "year": 2016}, {"title": "Speech vocoding for laboratory phonology", "author": ["M. Cernak", "S. Benus", "A. Lazaridis"], "venue": "Event Detection. In: Proc. of Interspeech. San Francisco,", "citeRegEx": "Cernak et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Cernak et al\\.", "year": 2016}, {"title": "PhonVoc: A Phonetic and Phonological Vocoding Toolkit", "author": ["M. Cernak", "P.N. Garner"], "venue": "Proc. of Interspeech", "citeRegEx": "Cernak and Garner,? \\Q2016\\E", "shortCiteRegEx": "Cernak and Garner", "year": 2016}, {"title": "Incremental Syllable-Context Phonetic Vocoding", "author": ["CA Francisco", "M. USA. Cernak", "P.N. Garner", "A. Lazaridis", "P. Motlicek", "X. Na", "Jun"], "venue": null, "citeRegEx": "Francisco et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Francisco et al\\.", "year": 2015}, {"title": "Phonological vocoding using artificial neural networks", "author": ["M. Cernak", "B. Potard", "P.N. Garner", "Apr"], "venue": "IEEE/ACM Trans. on Audio, Speech, and Language Processing", "citeRegEx": "Cernak et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cernak et al\\.", "year": 2015}, {"title": "The Sound Pattern of English", "author": ["N. Chomsky", "M. Halle"], "venue": null, "citeRegEx": "Chomsky and Halle,? \\Q1968\\E", "shortCiteRegEx": "Chomsky and Halle", "year": 1968}, {"title": "Corpus description of the ester evaluation", "author": ["S. Galliano", "E. Geoffrois", "G. Gravier", "J. f. Bonastre", "D. Mostefa", "K. Choukri"], "venue": null, "citeRegEx": "Galliano et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Galliano et al\\.", "year": 2006}, {"title": "Articulatory phonology: a phonology for public language use", "author": ["L. Goldstein", "C. Fowler"], "venue": null, "citeRegEx": "Goldstein and Fowler,? \\Q2003\\E", "shortCiteRegEx": "Goldstein and Fowler", "year": 2003}, {"title": "The elements of phonological representation", "author": ["J. Harris", "G. Lindsey"], "venue": "Nature Reviews Neuroscience", "citeRegEx": "Harris and Lindsey,? \\Q1995\\E", "shortCiteRegEx": "Harris and Lindsey", "year": 1995}, {"title": "Fundamentals of Language", "author": ["R. 1527\u20131554. Jakobson", "M. Halle"], "venue": "The Hague: Mouton. Jun, S.-A.,", "citeRegEx": "Jakobson and Halle,? \\Q1956\\E", "shortCiteRegEx": "Jakobson and Halle", "year": 1956}, {"title": "A Course in Phonetics, 7th Edition", "author": ["P. Ladefoged", "K. Johnson", "Jan"], "venue": "Oxford University Press,", "citeRegEx": "Ladefoged et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ladefoged et al\\.", "year": 2014}, {"title": "neuronal excitability and stimulus processing in the auditory cortex", "author": ["S. Lee", "S. Yildirim", "A. Kazemzadeh", "S. Narayanan"], "venue": "Journal of neurophysiology", "citeRegEx": "Lee et al\\.,? \\Q1904\\E", "shortCiteRegEx": "Lee et al\\.", "year": 1904}, {"title": "Dynamic encoding of speech sequence probability in human", "author": ["M.K. Leonard", "K.E. Bouchard", "C. Tang", "E.F. Chang"], "venue": null, "citeRegEx": "Leonard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Leonard et al\\.", "year": 2015}, {"title": "A role for amplitude modulation phase relationships in speech", "author": ["V. Leong", "M.A. Stone", "R.E. Turner", "U. Goswami", "Jul"], "venue": "temporal cortex. The Journal of Neuroscience", "citeRegEx": "Leong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Leong et al\\.", "year": 2014}, {"title": "On the relation of speech to language", "author": ["A.M. Bradford Book. Liberman", "D.H. Whalen", "May"], "venue": "Trends in cognitive sciences 4 (5), 187\u2013196. Matt, G., 2014. Disentangling stress and pitch accent: Toward a typology of prominence at different prosodic levels. in Harry", "citeRegEx": "Liberman et al\\.,? 2000", "shortCiteRegEx": "Liberman et al\\.", "year": 2000}, {"title": "An Analysis of Perceptual Confusions Among Some English Consonants", "author": ["G.A. Miller", "P.E. Nicely", "Mar"], "venue": "Gyrus. Science", "citeRegEx": "Miller et al\\.,? \\Q1955\\E", "shortCiteRegEx": "Miller et al\\.", "year": 1955}, {"title": "Exploring how deep neural networks form phonemic categories", "author": ["Soc. Am"], "venue": null, "citeRegEx": "Am.,? \\Q2015\\E", "shortCiteRegEx": "Am.", "year": 2015}, {"title": "Self-organization of syllable structure: A coupled oscillator model", "author": ["H. Nam", "L. Goldstein", "E. Saltzman"], "venue": null, "citeRegEx": "Nam et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nam et al\\.", "year": 2009}, {"title": "The design for the wall street journal-based", "author": ["D.B. 299\u2013328. Paul", "J.M. Baker"], "venue": "CSR corpus. In: Proceedings of the workshop on", "citeRegEx": "Paul and Baker,? \\Q1992\\E", "shortCiteRegEx": "Paul and Baker", "year": 1992}, {"title": "Auditory Cortex Accesses Phonological Categories: An MEG Mismatch Study", "author": ["C. Phillips", "T. Pellathy", "A. Marantz", "E. Yellin", "K. Wexler", "D. Poeppel", "M. McGinnis", "T. Roberts", "Nov."], "venue": "Journal of Cognitive Neuroscience 12 (6), 1038\u20131055.", "citeRegEx": "Phillips et al\\.,? 2000", "shortCiteRegEx": "Phillips et al\\.", "year": 2000}, {"title": "The Analysis of Speech in Different Temporal Integration Windows: Cerebral Lateralization As \u2019Asymmetric Sampling in Time", "author": ["D. Poeppel", "Aug."], "venue": "Speech Communication 41 (1), 245\u2013255.", "citeRegEx": "Poeppel and Aug.,? 2003", "shortCiteRegEx": "Poeppel and Aug.", "year": 2003}, {"title": "The neuroanatomic and neurophysiological infrastructure for speech and language", "author": ["D. Poeppel", "Oct."], "venue": "Current Opinion in Neurobiology 28, 142\u2013149.", "citeRegEx": "Poeppel and Oct.,? 2014", "shortCiteRegEx": "Poeppel and Oct.", "year": 2014}, {"title": "The kaldi speech recognition toolkit", "author": ["D. Povey", "A. Ghoshal", "G. Boulianne", "L. Burget", "O. Glembek", "N. Goel", "M. Hannemann", "P. Motlicek", "Y. Qian", "P. Schwarz", "J. Silovsky", "G. Stemmer", "K. Vesely", "Dec."], "venue": "In: Proc. of ASRU. IEEE SPS, iEEE Catalog No.: CFP11SRW-USB.", "citeRegEx": "Povey et al\\.,? 2011", "shortCiteRegEx": "Povey et al\\.", "year": 2011}, {"title": "Integrating articulatory features using Kullback-Leibler divergence based acoustic model for phoneme recognition", "author": ["R. Rasipuram", "M. Magimai.-Doss", "May"], "venue": "In: Proc. of ICASSP. IEEE, pp. 5192\u20135195.", "citeRegEx": "Rasipuram et al\\.,? 2011", "shortCiteRegEx": "Rasipuram et al\\.", "year": 2011}, {"title": "eLite-HTS: A NLP tool for French HMM-based speech synthesis", "author": ["S. Roekhaut", "S. Brognaux", "R. Beaufort", "T. Dutoit"], "venue": "Proc. of Interspeech", "citeRegEx": "Roekhaut et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roekhaut et al\\.", "year": 2014}, {"title": "A dynamical approach to gestural patterning in speech production", "author": ["E.L. Saltzman", "K.G. Munhall"], "venue": "Ecological Psychology", "citeRegEx": "Saltzman and Munhall,? \\Q1989\\E", "shortCiteRegEx": "Saltzman and Munhall", "year": 1989}, {"title": "Acoustic modeling based on the MDL principle for speech recognition", "author": ["K. Shinoda", "T. Watanabe"], "venue": "Proc. of Eurospeech", "citeRegEx": "Shinoda and Watanabe,? \\Q1997\\E", "shortCiteRegEx": "Shinoda and Watanabe", "year": 1997}, {"title": "Experiments on Cross-Language Attribute Detection and Phone Recognition With Minimal Target-Specific Training Data", "author": ["S.M. Siniscalchi", "Lyu", "D.-C.", "T. Svendsen", "Lee", "C.-H.", "Mar."], "venue": "IEEE Trans. on Audio, Speech, and Language Processing 20 (3), 875\u2013887.", "citeRegEx": "Siniscalchi et al\\.,? 2012", "shortCiteRegEx": "Siniscalchi et al\\.", "year": 2012}, {"title": "Features in Speech Perception and Lexical Access", "author": ["K.N. Stevens"], "venue": "The Handbook of Speech Perception. Blackwell Publishing,", "citeRegEx": "Stevens,? \\Q2005\\E", "shortCiteRegEx": "Stevens", "year": 2005}, {"title": "On The Use of Phonological Features for Pronunciation Scoring", "author": ["F. Stouten", "Martens", "J.-P.", "May"], "venue": "In: Proc. of ICASSP. Vol. 1. IEEE, p. I.", "citeRegEx": "Stouten et al\\.,? 2006", "shortCiteRegEx": "Stouten et al\\.", "year": 2006}, {"title": "Bonston studies in the phylosophy of science", "author": ["C. Wernicke"], "venue": null, "citeRegEx": "Wernicke,? \\Q1874\\E", "shortCiteRegEx": "Wernicke", "year": 1874}, {"title": "Boosting attribute and phone estimation accuracies with deep neural networks for detection-based speech recognition", "author": ["D. Yu", "S. Siniscalchi", "L. Deng", "Lee", "C.-H.", "March"], "venue": "In: Proc. of ICASSP. IEEE SPS.", "citeRegEx": "Yu et al\\.,? 2012", "shortCiteRegEx": "Yu et al\\.", "year": 2012}, {"title": "The HMM-based Speech Synthesis System Version 2.0", "author": ["H. Zen", "T. Nose", "J. Yamagishi", "S. Sako", "T. Masuko", "A. Black", "K. Tokuda"], "venue": "Proc. of ISCA SSW6", "citeRegEx": "Zen et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zen et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 11, "context": "Recent work on Articulatory Phonology (Goldstein and Fowler, 2003) further suggests an existence of coupling/synchronisation of gestures that influence the syllable structure of an utterance.", "startOffset": 38, "endOffset": 66}, {"referenceID": 13, "context": ", (Jakobson and Halle, 1956; Chomsky and Halle, 1968)) emerge during the phonological encoding process \u2013 the processes of speech planning for articulation, namely the preparation of an abstract phonological code and its transformation into speech motor plans that guide articulation (Levelt, 1993).", "startOffset": 2, "endOffset": 53}, {"referenceID": 9, "context": ", (Jakobson and Halle, 1956; Chomsky and Halle, 1968)) emerge during the phonological encoding process \u2013 the processes of speech planning for articulation, namely the preparation of an abstract phonological code and its transformation into speech motor plans that guide articulation (Levelt, 1993).", "startOffset": 2, "endOffset": 53}, {"referenceID": 0, "context": "Previously in (Asaei et al., 2015), we have shown that phonological posteriors admit sparsity structures underlying short-term segmental representations where the structures are quantified as sparse binary vectors.", "startOffset": 14, "endOffset": 34}, {"referenceID": 5, "context": ", (Jakobson and Halle, 1956; Chomsky and Halle, 1968)) emerge during the phonological encoding process \u2013 the processes of speech planning for articulation, namely the preparation of an abstract phonological code and its transformation into speech motor plans that guide articulation (Levelt, 1993). Stevens (2005) reviews evidence about a universal set of phonological classes that consists of articulator-bound classes and articulator-free classes ([continuant], [sonorant], [strident]).", "startOffset": 29, "endOffset": 314}, {"referenceID": 3, "context": "Cernak et al. (2015b) introduce the phonological posterior features for phonological analysis and synthesis, and we hypothesise their relation to the linguistic gestural model.", "startOffset": 0, "endOffset": 22}, {"referenceID": 3, "context": "Cernak et al. (2015b) introduce the phonological posterior features for phonological analysis and synthesis, and we hypothesise their relation to the linguistic gestural model. Saltzman and Munhall (1989) describe the constriction dynamics model as a computational system that incorporates the theory of articulatory phonology.", "startOffset": 0, "endOffset": 205}, {"referenceID": 35, "context": "Figure 1 illustrates the process of the phonological analysis (Yu et al., 2012; Cernak et al., 2015b).", "startOffset": 62, "endOffset": 101}, {"referenceID": 29, "context": "The hypothesis of correspondence of the phonological posterior features to the gestural trajectories is also motivated by the analogy to the constriction dynamics model (Saltzman and Munhall, 1989) that takes gestural scores as input and generates articulator trajectories and acoustic output.", "startOffset": 169, "endOffset": 197}, {"referenceID": 4, "context": "Alternatively to this constriction dynamics model, we generate acoustic output using a phonological synthesis DNN described in Cernak et al. (2015b). In the following sections, we outline converging evidence from linguistics as well as the neural basis of speech perception, that support the hypothesis about phonological posteriors conveying properties of linguistic classes at multiple time scales.", "startOffset": 127, "endOffset": 149}, {"referenceID": 32, "context": "For example, glides are always syllable-initial, and consonants that follow a non-tense vowel are always in the coda of the syllable (Stevens, 2005).", "startOffset": 133, "endOffset": 148}, {"referenceID": 21, "context": "(2015) say that gestures are phonetic in nature), recent developments suggest that the timing of articulatory gestures encodes syllabic (and thus linguistic) information as well (Browman and Goldstein, 1988; Nam et al., 2009).", "startOffset": 178, "endOffset": 225}, {"referenceID": 11, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE).", "startOffset": 20, "endOffset": 46}, {"referenceID": 9, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE).", "startOffset": 50, "endOffset": 75}, {"referenceID": 9, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE). Later advanced phonological systems were proposed, such as multi-valued phonological features of Ladefoged and Johnson (2014), and monovalent Government Phonology features of Harris and Lindsey (1995) that describe sounds by fusing and splitting of primes.", "startOffset": 50, "endOffset": 291}, {"referenceID": 9, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE). Later advanced phonological systems were proposed, such as multi-valued phonological features of Ladefoged and Johnson (2014), and monovalent Government Phonology features of Harris and Lindsey (1995) that describe sounds by fusing and splitting of primes.", "startOffset": 50, "endOffset": 366}, {"referenceID": 9, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE). Later advanced phonological systems were proposed, such as multi-valued phonological features of Ladefoged and Johnson (2014), and monovalent Government Phonology features of Harris and Lindsey (1995) that describe sounds by fusing and splitting of primes. The surface code includes co-articulated canonical code, with further intrinsic (speaker-based) and extrinsic (channel-based) speech variabilities that contribute to the opacity of the function operating between the two codes. The surface features may contain additional gestures dependent on the prosodic context, such as position within a syllable, word, and sentence. Other changes in surface phonological features at different time granularities are due to phonotactic constraints. For example, glides are always syllable-initial, and consonants that follow a non-tense vowel are always in the coda of the syllable (Stevens, 2005). Relation of the canonical and surface code can be investigated by a linguistic theory of Articulatory Phonology (Browman and Goldstein, 1986, 1989, 1992) that introduced articulatory gestures as a basis for human speech production. Although it is generally claimed that gestures convey segmental-level information (for example, Fowler et al. (2015) say that gestures are phonetic in nature), recent developments suggest that the timing of articulatory gestures encodes syllabic (and thus linguistic) information as well (Browman and Goldstein, 1988; Nam et al.", "startOffset": 50, "endOffset": 1407}, {"referenceID": 9, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE). Later advanced phonological systems were proposed, such as multi-valued phonological features of Ladefoged and Johnson (2014), and monovalent Government Phonology features of Harris and Lindsey (1995) that describe sounds by fusing and splitting of primes. The surface code includes co-articulated canonical code, with further intrinsic (speaker-based) and extrinsic (channel-based) speech variabilities that contribute to the opacity of the function operating between the two codes. The surface features may contain additional gestures dependent on the prosodic context, such as position within a syllable, word, and sentence. Other changes in surface phonological features at different time granularities are due to phonotactic constraints. For example, glides are always syllable-initial, and consonants that follow a non-tense vowel are always in the coda of the syllable (Stevens, 2005). Relation of the canonical and surface code can be investigated by a linguistic theory of Articulatory Phonology (Browman and Goldstein, 1986, 1989, 1992) that introduced articulatory gestures as a basis for human speech production. Although it is generally claimed that gestures convey segmental-level information (for example, Fowler et al. (2015) say that gestures are phonetic in nature), recent developments suggest that the timing of articulatory gestures encodes syllabic (and thus linguistic) information as well (Browman and Goldstein, 1988; Nam et al., 2009). Liberman and Whalen (2000) provides theoretic claims about linguisticlly relevant articulatory gestures, and Saltzman and Munhall (1989) implement a syllable structure-based gesture coupling model.", "startOffset": 50, "endOffset": 1654}, {"referenceID": 9, "context": "In the tradition of Jakobson and Halle (1956) and Chomsky and Halle (1968), phonemes are assumed to consist of feature bundles \u2013 the Sound Pattern of English (SPE). Later advanced phonological systems were proposed, such as multi-valued phonological features of Ladefoged and Johnson (2014), and monovalent Government Phonology features of Harris and Lindsey (1995) that describe sounds by fusing and splitting of primes. The surface code includes co-articulated canonical code, with further intrinsic (speaker-based) and extrinsic (channel-based) speech variabilities that contribute to the opacity of the function operating between the two codes. The surface features may contain additional gestures dependent on the prosodic context, such as position within a syllable, word, and sentence. Other changes in surface phonological features at different time granularities are due to phonotactic constraints. For example, glides are always syllable-initial, and consonants that follow a non-tense vowel are always in the coda of the syllable (Stevens, 2005). Relation of the canonical and surface code can be investigated by a linguistic theory of Articulatory Phonology (Browman and Goldstein, 1986, 1989, 1992) that introduced articulatory gestures as a basis for human speech production. Although it is generally claimed that gestures convey segmental-level information (for example, Fowler et al. (2015) say that gestures are phonetic in nature), recent developments suggest that the timing of articulatory gestures encodes syllabic (and thus linguistic) information as well (Browman and Goldstein, 1988; Nam et al., 2009). Liberman and Whalen (2000) provides theoretic claims about linguisticlly relevant articulatory gestures, and Saltzman and Munhall (1989) implement a syllable structure-based gesture coupling model.", "startOffset": 50, "endOffset": 1764}, {"referenceID": 17, "context": "Phillips et al. (2000); Mesgarani et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 17, "context": "Phillips et al. (2000); Mesgarani et al. (2014) present evidence of discrete phonological classes available in the human auditory cortex.", "startOffset": 0, "endOffset": 48}, {"referenceID": 12, "context": "Leong et al. (2014) show that phase relations between the phonetic and syllabic amplitude modulations, known as hierarchical phase locking and nesting or synchronization across different temporal granularity (Lakatos et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 2, "context": "Bouchard et al. (2013) claim that functional organisation of ventral sensorimotor cortex supports the gestural model developed in Articulatory Phonology.", "startOffset": 0, "endOffset": 23}, {"referenceID": 2, "context": "Bouchard et al. (2013) claim that functional organisation of ventral sensorimotor cortex supports the gestural model developed in Articulatory Phonology. Analysis of spatial patterns of activity showed a hierarchy of network states that organizes phonemes by articulatory-bound phonological features. Leonard et al. (2015) further show how listeners use phonotactic knowledge (phoneme sequence statistics) to process spoken input and to link low-level acoustic representations (the coarticulatory dynamics of the sounds through the encoding of combination of phonological features) with linguistic information about word identity and meaning.", "startOffset": 0, "endOffset": 323}, {"referenceID": 0, "context": "This physical limitation leads to a small number of unique patterns exhibited over the entire speech corpora (Asaei et al., 2015).", "startOffset": 109, "endOffset": 129}, {"referenceID": 6, "context": "We use an open-source phonological vocoding platform (Cernak and Garner, 2016) to obtain phonological posteriors.", "startOffset": 53, "endOffset": 78}, {"referenceID": 35, "context": "Binary (Yu et al., 2012) or multi-valued classification (Stouten and Martens, 2006; Rasipuram and Magimai.", "startOffset": 7, "endOffset": 24}, {"referenceID": 9, "context": "To confirm independence of the proposed methodology on a phonological system, two different phonological speech representations are considered: the SPE feature set (Chomsky and Halle, 1968), and the extended SPE (eSPE) feature set (Cernak et al.", "startOffset": 164, "endOffset": 189}, {"referenceID": 4, "context": "To confirm independence of the proposed methodology on a phonological system, two different phonological speech representations are considered: the SPE feature set (Chomsky and Halle, 1968), and the extended SPE (eSPE) feature set (Cernak et al., 2015b) are used in training of the DNNs for phonological posterior estimation on English and French data respectively. The mapping used to map from phonemes to SPE phonological class is taken from Cernak et al. (2016b). The distribution of the phonological labels is non-uniform, driven by mapping different numbers of phonemes to the phonological classes.", "startOffset": 232, "endOffset": 466}, {"referenceID": 35, "context": "For French eSPE feature set, we started from pseudo-phonological feature classification designed for American English (Yu et al., 2012).", "startOffset": 118, "endOffset": 135}, {"referenceID": 31, "context": "To confirm cross-lingual property of phonological posteriors (Siniscalchi et al., 2012), we conducted our evaluations on English and French speech corpora.", "startOffset": 61, "endOffset": 87}, {"referenceID": 22, "context": "To train the DNNs for phonological posterior estimation on English data, we use the Wall Street Journal (WSJ0 and WSJ1) continuous speech recognition corpora (Paul and Baker, 1992).", "startOffset": 158, "endOffset": 180}, {"referenceID": 10, "context": "To train the DNNs for phonological posterior estimation on French data, we use the Ester database (Galliano et al., 2006) containing standard French radio broadcast news in various recording conditions.", "startOffset": 98, "endOffset": 121}, {"referenceID": 1, "context": "The text was processed by a conventional and freely available text to speech synthesis (TTS) front-end (Black et al., 1997), resulting in segmental (quinphone phonetic context) and supra-segmental (full-context) labels.", "startOffset": 103, "endOffset": 123}, {"referenceID": 28, "context": "We generated full-context labels using the French text analyzer eLite (Roekhaut et al., 2014).", "startOffset": 70, "endOffset": 93}, {"referenceID": 36, "context": "The three-state, cross-word triphone models were trained with the HMM-based speech synthesis system (HTS) variant (Zen et al., 2007) of the Hidden Markov Model Toolkit (HTK) on the 90% subset of the WSJ si tr s 284 set.", "startOffset": 114, "endOffset": 132}, {"referenceID": 30, "context": "We tied triphone models with decision tree state clustering based on the minimum description length (MDL) criterion (Shinoda and Watanabe, 1997).", "startOffset": 116, "endOffset": 144}, {"referenceID": 26, "context": "The DNNs with the softmax output function were then trained using a mini-batch based stochastic gradient descent algorithm with the cross-entropy cost function of the KALDI toolkit (Povey et al., 2011).", "startOffset": 181, "endOffset": 201}, {"referenceID": 26, "context": "The DNNs with the softmax output function were then trained using a mini-batch based stochastic gradient descent algorithm with the cross-entropy cost function of the KALDI toolkit (Povey et al., 2011). Table 2 lists the detection accuracy for different phonological classes. The DNN outputs provide the phonological posterior probabilities for each phonological class. Detection accuracy on cross-database (Nancy) test data is lower, however following the accuracy on training and CV data. The consonantal and voice DNN performed worse, and we speculate that this might be caused by difficulty to train good classifiers for such broad (hierarchical) phonological classes. Recent work of Nagamine et al. (2015) suggests that a DNN learns selective phonological classes in different nodes and hidden layers.", "startOffset": 182, "endOffset": 711}, {"referenceID": 0, "context": "This property encouraged us also to use this binary approximation in low bit-rate speech coding (Cernak et al., 2015b; Asaei et al., 2015); these studies confirmed that binary approximation has only a negligible impact on perceptual speech quality.", "startOffset": 96, "endOffset": 138}, {"referenceID": 4, "context": "This idea is further investigated in Cernak et al. (2016a) where a highly competitive emphasis detection system is achieved.", "startOffset": 37, "endOffset": 59}, {"referenceID": 29, "context": "In our future work, we plan to investigate more closely the relationship of the trajectories of the articulatory-bound phonological posterior features to the task dynamic model of inter-articulator coordination in speech (Saltzman and Munhall, 1989).", "startOffset": 221, "endOffset": 249}], "year": 2016, "abstractText": "The speech signal conveys information on different time scales from short (20\u201340 ms) time scale or segmental, associated to phonological and phonetic information to long (150\u2013250 ms) time scale or supra segmental, associated to syllabic and prosodic information. Linguistic and neurocognitive studies recognize the phonological classes at segmental level as the essential and invariant representations used in speech temporal organization. In the context of speech processing, a deep neural network (DNN) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal. A vector of all phonological class probabilities is referred to as phonological posterior. There are only very few classes comprising a short term speech signal; hence, the phonological posterior is a sparse vector. Although the phonological posteriors are estimated at segmental level, we claim that they convey supra-segmental information. Specifically, we demonstrate that phonological posteriors are indicative of syllabic and prosodic events. Building on findings from converging linguistic evidence on the gestural model of Articulatory Phonology as well as the neural basis of speech perception, we hypothesize that phonological posteriors convey properties of linguistic classes at multiple time scales, and this information is embedded in their support (index) of active coefficients. To verify this hypothesis, we obtain a binary representation of phonological posteriors at the segmental level which is referred to as first-order sparsity structure; the high-order structures are obtained by the concatenation of first-order binary vectors. It is then confirmed that the classification of supra-segmental linguistic events, the problem known as linguistic parsing, can be achieved with high accuracy using a simple binary pattern matching of first-order or high-order structures.", "creator": "LaTeX with hyperref package"}}}