{"id": "1601.05764", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2016", "title": "A Confidence-Based Approach for Balancing Fairness and Accuracy", "abstract": "We study three classical machine learning algorithms in the context of algorithmic fairness: adaptive boosting, support vector machines, and logistic regression. Our goal is to maintain the high accuracy of these learning algorithms while reducing the degree to which they discriminate against individuals because of their membership in a protected group.", "histories": [["v1", "Thu, 21 Jan 2016 19:48:07 GMT  (122kb,D)", "http://arxiv.org/abs/1601.05764v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CY", "authors": ["benjamin fish", "jeremy kun", "\\'ad\\'am d lelkes"], "accepted": false, "id": "1601.05764"}, "pdf": {"name": "1601.05764.pdf", "metadata": {"source": "CRF", "title": "A Confidence-Based Approach for Balancing Fairness and Accuracy", "authors": ["Benjamin Fish", "Jeremy Kun", "\u00c1d\u00e1m D. Lelkes"], "emails": ["alelke2}@uic.edu"], "sections": [{"heading": null, "text": "We examine three classic machine learning algorithms in the context of algorithmic fairness: adaptive boosting, support for vector machines, and logistical regression. Our goal is to maintain the high accuracy of these learning algorithms while reducing the degree to which they discriminate against individuals on the basis of their membership in a protected group. Our first contribution is a method of achieving fairness by shifting the decision boundary for the protected group. The method is based on the theory of margins for enhancement. Our method performs or even surpasses previous algorithms in fairness literature in terms of accuracy and low discrimination. We show that even hopelessly naive modifications of a distorted algorithm that cannot reasonably be called fair can still achieve low bias and high accuracy."}, {"heading": "1 Background and Motivation", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2 Methods and Technical Solutions", "text": "In fact, it is so that it is a matter of a way in which it is about a way in which it is about the conceptuality, in which it is about the conceptuality, which is what it is about, about the conceptuality, which is what it is about, about the conceptuality, which is what it is about, about the conceptuality, which is what it is about, about the conceptuality, about the conceptuality, which is what it is about, about the conceptuality, about the conceptuality, which is what it is about, about the conceptuality, about the conceptuality, which is what it is about, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, the conceptuality, about the conceptuality, about the conceptuality, about the conceptuality, the conceptuality, about the conceptuality, the conceptuality, about the conceptuality, the conceptuality, the conceptuality, about the conceptuality, the conceptuality, the conceptuality, the conceptuality, about the conceptuality, the conceptuality, the conceptuality, the conceptuality, about the conceptuality, the conc"}, {"heading": "3 Empirical Evaluation", "text": "The persons mentioned are able to abide by the rules that they are able to abide by the rules that they have applied in practice."}, {"heading": "4 Significance and Impact", "text": "This method, which we call the Shifted Decision Limit (SDS), is applicable to any learning algorithm that has an efficiently calculable measure of trust. We examined three such algorithms - AdaBoost, support for vector machines, and linear regression - and compared our methods with other methods proposed in the earlier literature and in our own baselines, and empirically evaluated the performance of our methods in terms of their resilience to random bias. Our method not only exceeds much of the previous literature, but also has several other desirable properties. Unlike most other fair learning algorithms, the SDS has theoretical limits on generalization errors. Since the shift in margin can be specified after the original learner has been trained on the basis of the data, a practitioner can easily assess the trade-off between error and bias and choose the most desirable point in relation to the trade-off curve."}], "references": [{"title": "Three naive bayes approaches for discrimination-free classification", "author": ["Toon Calders", "Sicco Verwer"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Fairness through awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel"], "venue": "In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Certifying and removing disparate impact", "author": ["Michael Feldman", "Sorelle A. Friedler", "John Moeller", "Carlos Scheidegger", "Suresh Venkatasubramanian"], "venue": "Proceedings of the 21th ACM SIGKDD Intl. Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Classifying without discriminating", "author": ["Faisal Kamiran", "Toon Calders"], "venue": "In 2nd Intl. Conference on Computer, Control and Communication,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Discrimination aware decision tree learning", "author": ["Faisal Kamiran", "Toon Calders", "Mykola Pechenizkiy"], "venue": "IEEE 10th Intl. Conference on Data Mining (ICDM),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Quantifying explainable discrimination and removing illegal discrimination in automated decision making", "author": ["Faisal Kamiran", "Indr\u0117 \u017dliobait\u0117", "Toon Calders"], "venue": "Knowledge and Information Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Fairness-aware classifier with prejudice remover regularizer", "author": ["Toshihiro Kamishima", "Shotaro Akaho", "Hideki Asoh", "Jun Sakuma"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Fairness-aware learning through regularization approach", "author": ["Toshihiro Kamishima", "Shotaro Akaho", "Jun Sakuma"], "venue": "In Data Mining Workshops (ICDMW),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "A multidisciplinary survey on discrimination analysis", "author": ["Andrea Romei", "Salvatore Ruggieri"], "venue": "The Knowledge Engineering Review, 29:582\u2013638,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Boosting: Foundations and Algorithms", "author": ["Robert E. Schapire", "Yoav Freund"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Boosting the margin: A new explanation for the effectiveness of voting methods", "author": ["Robert E. Schapire", "Yoav Freund", "Peter Bartlett", "Wee Sun Lee"], "venue": "Annals of Statistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1998}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["Shai Shalev-Shwartz", "Shai Ben-David"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "The issue of \u201cexplainable discrimination\u201d in machine learning was studied in [8].", "startOffset": 77, "endOffset": 80}, {"referenceID": 10, "context": "SDB is a generic method based on the theory of margins [2, 15], and it can be combined with any learning algorithm that produces a measure of confidence in its prediction (Section 2.", "startOffset": 55, "endOffset": 62}, {"referenceID": 10, "context": "We also give a theorem based on the analysis in [15] bounding the loss of accuracy for SDB under weighted majority schemes (Section 2.", "startOffset": 48, "endOffset": 52}, {"referenceID": 1, "context": "The shortcomings were discussed in [3], e.", "startOffset": 35, "endOffset": 38}, {"referenceID": 8, "context": "Finding the \u201cright\u201d definition of fairness is a major challenge; see the extensive survey of [13] for a detailed discussion.", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "[4] based on the \u201c80% rule\u201d used in United States hiring law.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[3] point out that statistical parity is only a measure of population-wide fairness.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Some previous approaches assume the existence of a ranking or metric on individuals, or try to learn this ranking from data [6, 3].", "startOffset": 124, "endOffset": 130}, {"referenceID": 1, "context": "Some previous approaches assume the existence of a ranking or metric on individuals, or try to learn this ranking from data [6, 3].", "startOffset": 124, "endOffset": 130}, {"referenceID": 1, "context": "kNN -consistency: The second notion, due to [3], calls a classifier \u201cindividually fair\u201d if it classifies similar individuals similarly.", "startOffset": 44, "endOffset": 47}, {"referenceID": 0, "context": "4 Previous work on fair algorithms Learning algorithms studied previously in the context of fairness include naive Bayes [1], decision trees [7], and logistic regression [9].", "startOffset": 121, "endOffset": 124}, {"referenceID": 4, "context": "4 Previous work on fair algorithms Learning algorithms studied previously in the context of fairness include naive Bayes [1], decision trees [7], and logistic regression [9].", "startOffset": 141, "endOffset": 144}, {"referenceID": 6, "context": "4 Previous work on fair algorithms Learning algorithms studied previously in the context of fairness include naive Bayes [1], decision trees [7], and logistic regression [9].", "startOffset": 170, "endOffset": 173}, {"referenceID": 3, "context": "Massaging is done in the previous literature based on a ranking learned from the biased data [6].", "startOffset": 93, "endOffset": 96}, {"referenceID": 7, "context": "The regularization approach consists of adding a regularizer to an optimization objective which penalizes the classifier for discrimination [10].", "startOffset": 140, "endOffset": 144}, {"referenceID": 1, "context": "The first, introduced in [3], is a framework for maximizing the utility of a classification with the constraint that similar people be treated similarly.", "startOffset": 25, "endOffset": 28}, {"referenceID": 1, "context": "Moreover, the work in [3] suggests that learning a suitably fair similarity metric from the data is as hard as the original problem of finding a fair classifier.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": "Rather, we align with the central thesis of [3], that knowing the protected feature is useful to promote fairness.", "startOffset": 44, "endOffset": 47}, {"referenceID": 10, "context": "5 Margins The theory of margins has provided a deep, foundational explanation for the generalization properties of algorithms such as AdaBoost and softmargin SVMs [2, 15].", "startOffset": 163, "endOffset": 170}, {"referenceID": 10, "context": "[15]) Let D be a distribution over X \u00d7 {\u22121, 1} and S be a sample of m examples chosen i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "One can go on to show AdaBoost [14], a popular algorithm that produces a weighted voting scheme, performs well in this respect.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "For background on SVM, logistic regression, and AdaBoost, see [16].", "startOffset": 62, "endOffset": 66}, {"referenceID": 9, "context": "For more on boosting, we refer the reader to [14].", "startOffset": 45, "endOffset": 49}, {"referenceID": 3, "context": "Massaging strategies, introduced by [6], involve eliminating the bias of the training data by modifying the labels of data points, and then training a classifier on this data in the hope that the statistical parity of the training data will generalize to the test set as well.", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "[3] have pointed out, statistical parity fails to capture all important aspects of fairness.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Following the work of [6], we consider age as the protected attribute with a cut-off at 25.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "For comparison, we also included the numbers for the Learning Fair Representations (LFR) method of [17] for the Census Income dataset, for Classification with No Discrimination (CND) method of [6], and for the Discrimination Aware Decision Tree (DADT) technique of [7] (specifically we use the numbers for the \u201cIGC+IGS Relab\u201d method).", "startOffset": 193, "endOffset": 196}, {"referenceID": 4, "context": "For comparison, we also included the numbers for the Learning Fair Representations (LFR) method of [17] for the Census Income dataset, for Classification with No Discrimination (CND) method of [6], and for the Discrimination Aware Decision Tree (DADT) technique of [7] (specifically we use the numbers for the \u201cIGC+IGS Relab\u201d method).", "startOffset": 265, "endOffset": 268}, {"referenceID": 3, "context": "In [17] the authors implemented three other learning algorithms, these are unregularized logistic regression, Fair Naive-Bayes [6], and Regularized Logistic Regression [10].", "startOffset": 127, "endOffset": 130}, {"referenceID": 7, "context": "In [17] the authors implemented three other learning algorithms, these are unregularized logistic regression, Fair Naive-Bayes [6], and Regularized Logistic Regression [10].", "startOffset": 168, "endOffset": 172}, {"referenceID": 4, "context": "In [7] the authors implemented variations on the decision tree learning scheme, and the one we include has the highest accuracy, though they are all closely comparable.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "While DADT appears to achieve lower label error and comparable bias, we note that the standard deviation of the bias reported in [7] is 0.", "startOffset": 129, "endOffset": 132}], "year": 2016, "abstractText": null, "creator": "LaTeX with hyperref package"}}}