{"id": "1601.05977", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jan-2016", "title": "The Singularity Controversy, Part I: Lessons Learned and Open Questions: Conclusions from the Battle on the Legitimacy of the Debate", "abstract": "This report seeks to inform policy makers on the nature and the merit of the arguments for and against the concerns associated with a potential technological singularity.", "histories": [["v1", "Fri, 22 Jan 2016 12:41:43 GMT  (249kb)", "http://arxiv.org/abs/1601.05977v1", null], ["v2", "Thu, 28 Jan 2016 16:32:19 GMT  (325kb)", "http://arxiv.org/abs/1601.05977v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CY", "authors": ["amnon h eden"], "accepted": false, "id": "1601.05977"}, "pdf": {"name": "1601.05977.pdf", "metadata": {"source": "CRF", "title": "THE SINGULARITY CONTROVERSY", "authors": ["Amnon H. Eden"], "emails": [], "sections": [{"heading": null, "text": "Technical Report STR 2016-1 \u2022 January 2016 \u2022 DOI 10.13140 / RG.2.1.3416.6809THE SINGULARITY CONTROVERSY Part I:"}, {"heading": "Lessons Learned and Open Questions:", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Conclusions from the Battle on the Legitimacy of the Debate", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Amnon H. Eden", "text": "(c) 2016 Sapience ProjectSYNOPSIS This report seeks to inform policymakers about the nature and usefulness of the arguments for and against the concerns surrounding potential technological singularity. Part I describes the lessons we have learned from our study of the issue, separating the arguments of merit from the errors and misconceptions that confuse the debate and undermine its rational solution. ACM Computing Classification System (CCS 2012): \u2022 Computer Methodologies ~ Philosophical / Theoretical Foundations of Artificial Intelligence \u2022 Social and Professional Issues ~ Ethical Codes - 2 -"}, {"heading": "London, UK", "text": "The Sapience Project is a think tank dedicated to the research of disruptive and intelligent computing, whose charter is to identify, extrapolate, and anticipate disruptive, long-lasting, and possibly unintended consequences of progressive intelligent computing on the economy and society, as well as syndicate focus reports and mitigation strategies. BOARDVic Callaghan, University of Essex B. Jack Copeland, University of Canterbury Amnon H. Eden, Sapience Project Jim Moor, Dartmouth College David Pearce, BLTC Research Steve Phelps, Kings College London Anders Sandberg, Future of Humanity Institute, Oxford University Tony Willson, Helmsman Services - 3 - CONTENTS Motivation 4 Study the Singularity 5 Conclusions 6Conclusion (A): Singularity = Acceleration + Discontinuity + Superintelligence 6 Conclusion (B): What singularity do you mean? 7 Conclusion (C): \"Some singularities are not\" risks, \"or\" singularities. \""}, {"heading": "MOTIVATION", "text": "Recently, artificial intelligence (AI) has received unusual attention, with news outlets screaming \"Celebrated scientists: the end is near!\" and talking about the prospect of a \"robotic uprising\" that artificial intelligence could bring about. Others dismiss these concerns as speculative, cultivating apocalyptic \"rapture of the nerds\" nonsense. An American think tank has gone so far as to invoke Elon Musk and Stephen Hawking (and implicitly, some of the leading geniuses of computer science are historical!), \"innovation killers\" and a threat to America's technological progress and security. It's not uncommon for scientific controversies to grab headlines. What's unusual about the criticism of AI is that it delegitimizes the debate."}, {"heading": "STUDYING THE SINGULARITY", "text": "Although the thoughts about singularity may seem very new, such ideas do indeed have a long philosophical history. In order to foster awareness of the deep roots of singularity thinking within traditional philosophy, it might be useful to look at some of its historical precursors. Many philosophers have presented cosmic processes as an ascending curve of positivity. Over time, the quantities of intelligence, power, or value are growing stronger and stronger. Technological versions have sometimes referred to broad technological advances and have sometimes focused on more specific outcomes, such as the possible recursive self-improvement of artificial intelligence. Historical analyses of a wide range of paradigm shifts in science, history, and technology - especially in the field of computer technology - suggest that the predictive power of biological evolution, cultural evolution, and technological evolution has been attempted to be standardized under the titles \"Big History\" (Christian 2012) and the \"Law of Acceleration of Returns.\""}, {"heading": "CONCLUSIONS DRAWN", "text": "Almost a decade of research on these issues has led us to the following conclusions:"}, {"heading": "Conclusion (A) :", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Singularity = Acceleration + Discontinuity + Superintelligence", "text": "In fact, it is so that people are able to determine for themselves what they want and what they do not want. (...) It is not so that people are able to decide whether they want it or not. (...) It is not so that they want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...). \"(...).\" (...). \"(.\" (.). \"(. (.).\" (.). \"(.). (.\" (.). \"(.).\" (. \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (.). \"(.).\" (.). \"(.\" (.). (.). \"(.).\" (.). \"(.\" (.). \"(.). (.).\" (. \"(.).). (.).\" (. (.). \"(.).\" (. (.).). \"(.).\" (. (.). (. (.).). (.). (.). (...). (...). (.).... (.)... (.)... (. (.). (. (.).). (.).). (. (.).). (.). (.). (.). (. (.).). (.). (.). (.). (.)..). (.). (.).).. (."}, {"heading": "Conclusion (B) :", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Which singularity do you mean? AI or IA?", "text": "We conclude that all singularity accounts have three common (and seemingly unique) denominators. However, it has also become abundantly clear that singularity hypotheses point to either one of two distinct and very different scenarios: One scenario, the singularity of artificial (super-) intelligence (AI), refers (often dystopian) to the emergence of \"human AI\" and smarter, superintelligent agents or software-based synthetic heads within about four decades. Without precautions, this scenario becomes one of the biggest potential threats to human existence (Sandberg 2014) or \"the worst thing that can happen to humanity in history\" (Hawking et al. 2014). On the other hand, the singularity of posthuman superintelligence will point to radically different (mostly utopian) scenarios that affect the emergence of superintelligence and the emergence of superintelligence within a similar period of time."}, {"heading": "Conclusion (C) :", "text": "Some \"singularities\" are implausible, incoherent, or no singular part IV of the Singularity Hypotheses volume has been dedicated to critics of technological singularity, considered by many to be a religious idea (Proudfoot 2013; Bringsjord, Bringsjord, and Bello 2013): an (again) apocalyptic fantasy, a technology-infused variant of doomsday scenarios emerging around 2045 from mysticism, fiction, cults, and commercial interests. A strong counter-argument to the singularity hypotheses is offered in the theory of energy densities, which physicist Eric Chaisson (Chaisson 2013) describes as discontinuity (Chaisson accepts acceleration and superintelligence - two of the three premises underlying the singularity hypotheses (see Conclusion (A): Singarity Rate Theory of energy density, which goes beyond physical acceleration, but beyond uniformity)."}, {"heading": "Conclusion (D) :", "text": "The term singularity in general use has been heavily influenced by the recent wave of Hollywood blockbusters and popular television series. To illustrate their use of the term, philosophers (Schneider 2009) and scientists (Hawking et al. 2014) have used films to illustrate their understanding of singularity. Indeed, some science fiction stories have greatly contributed to our understanding of AI behavior and its risks, but blockbusters and TV series also have artistic freedom by creatively depicting irrational scenarios in Sapience Project (9)."}, {"heading": "Conclusion (E) :", "text": "In fact, most of them are able to play by the rules that they have set themselves in order to play by the rules."}, {"heading": "Conclusion (F) :", "text": "In fact, it is a very complex matter, in which it is only a matter of time before the solution is found, until it is found."}, {"heading": "Conclusion (G) :", "text": "It is not clear what \"artificial intelligence\" means when textbooks typically portray artificial intelligence as a sub-discipline of computer science and a corpus of knowledge for solving \"difficult\" challenges. This practice defines AI (indirectly) by those challenges that were considered \"difficult but solvable\" at the time the textbook was written."}, {"heading": "7 The study also found one main difference, in that the risks addressed in the 1975 Asilomar conference appeared to", "text": "(...). (...). (...). (...). (...). (...). (...). It is as if it were a pure mind game. (...). It is as if it were a mind game. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (. ("}, {"heading": "8 CAPTCHA stands for Completely Automated Public Turing test to tell Computers and Humans Apart, a test to determine whether an attempt for remote access is made by a human or by a bot.", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9 That is, whatever it the Search for Extra Terrestrial Intelligence is searching for a sign of.", "text": "10 or rather a family of metrics Sapience Project - 13 - The difficulty of determining what AI means undermines our ability to assess its risks: we do not know what capabilities could (and could) be developed in the near future, how long it will take to make applications of any new ability available, how likely it is to lose control of technologies that will result from these applications, or under what circumstances the unintended consequences of future AI technology could pose an existential risk. We explained the sense in which AI technologies have certainly become more powerful and that the trend could continue. But, how far? Research in superintelligence (Bostrom 2014) has given us reasons to believe that the gap between apes and humans is being eclipsed by the gap between human intelligence and superintelligence. Nevertheless, it is completely unclear how much intelligent artificial agents will become in the near future. Without further research, it is up to us to guess whether no significant advances are likely or whether we should continue to prepare ourselves for artificial intelligence before they are clearly advanced. \""}, {"heading": "Conclusion (H) :", "text": "In 2012, after compiling the papers and refutations for the volume Singularity Hypothesis, we came to the conclusion that \"the rapid growth of singularity research will continue and perhaps accelerate\" (Eden, Steinhart et al. 2013). Since then, prominent scientists have been pushing to invest in this direction (Hawking et al. 2014; Future of Life Institute 2015), followed by sensational headlines and the controversy described above, which has not encouraged but merely caricatured and confused the debate. As the following questions remain open, it is clear that the debate has only just begun."}, {"heading": "OPEN QUESTIONS", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution."}, {"heading": "SUMMARY", "text": "Our central conclusion is that the controversy over the future of artificial intelligence should be replaced by a reasonable and well-informed debate about the issues raised by this technology, because the issues are far too important to be left to academics & experts - to remain confused and misinformed, and to be derailed by fantasies like Hollywood's Skynet - or merely speculated by experts, amateurs, and wayward cronies."}], "references": [{"title": "A Law of Acceleration", "author": ["Adams", "Henry."], "venue": "The Education of Henry Adams. New York: Houghton Mifflin. Allen, Paul. 2011. \u2018The Singularity Isn\u2019t Near\u2019. MIT Technology Review, October 12. http://www.technolo-", "citeRegEx": "Adams and Henry.,? 1904", "shortCiteRegEx": "Adams and Henry.", "year": 1904}, {"title": "Evolution and Memes: The Human Brain as a Selective Imitation Device", "author": ["Susan"], "venue": null, "citeRegEx": "Blackmore and Susan.,? \\Q2001\\E", "shortCiteRegEx": "Blackmore and Susan.", "year": 2001}, {"title": "International Institute for Advanced Studies. \u2014\u2014", "author": ["Goreti Marreiros"], "venue": null, "citeRegEx": "Marreiros and 2.12.17.,? \\Q2014\\E", "shortCiteRegEx": "Marreiros and 2.12.17.", "year": 2014}, {"title": "Humans With Amplified Intelligence Could Be More Powerful Than AI", "author": ["George Dvorsky"], "venue": null, "citeRegEx": "Dvorsky,? \\Q2013\\E", "shortCiteRegEx": "Dvorsky", "year": 2013}, {"title": "Belief in The Singularity Is Fideistic", "author": ["Bringsjord", "Selmer", "Alexander Bringsjord", "Paul Bello."], "venue": "Sin-", "citeRegEx": "Bringsjord et al\\.,? 2013", "shortCiteRegEx": "Bringsjord et al\\.", "year": 2013}, {"title": "Limitations and Risks of Machine Ethics", "author": ["Miles"], "venue": "Journal of Experimental & Theoretical Arti-", "citeRegEx": "Brundage and Miles.,? \\Q2014\\E", "shortCiteRegEx": "Brundage and Miles.", "year": 2014}, {"title": "The Singularity: A Philosophical Analysis", "author": ["David J"], "venue": "Journal of Consciousness Studies", "citeRegEx": "Chalmers and J.,? \\Q2010\\E", "shortCiteRegEx": "Chalmers and J.", "year": 2010}, {"title": "Humanoid Histories", "author": ["Dawkins", "Richard"], "venue": "2010.00557.x. \u2014\u2014\u2014", "citeRegEx": "2303", "shortCiteRegEx": "2303", "year": 2012}, {"title": "Call for Papers: Technological Singularity and Acceleration Studies, Track", "author": [], "venue": null, "citeRegEx": "....,? \\Q2010\\E", "shortCiteRegEx": "....", "year": 2010}, {"title": "Call for Papers, Singularity", "author": ["-acceleration-studies. Eden", "Amnon H", "James H. Moor", "Johnny Hartz S\u00f8raker", "Eric Steinhart"], "venue": null, "citeRegEx": "boat.com.blog.2010.04.technological.singularity. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "boat.com.blog.2010.04.technological.singularity. et al\\.", "year": 2010}, {"title": "Singularity Hypotheses: An Over", "author": ["642-32559-5. Eden", "Amnon H", "Eric Steinhart", "David Pearce", "James H. Moor"], "venue": null, "citeRegEx": "Eden et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Eden et al\\.", "year": 2013}, {"title": "Speculations Concerning the First Ultraintelligent Machine", "author": ["Irving John"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1965}, {"title": "The Asilomar Conference: A Case Study in Risk Mitigation", "author": ["Katja"], "venue": null, "citeRegEx": "Grace and Katja.,? \\Q2015\\E", "shortCiteRegEx": "Grace and Katja.", "year": 2015}, {"title": "Are the Robots about to Rise", "author": ["Conference.pdf. Guardian", "Carole Cadwalladr"], "venue": null, "citeRegEx": "Guardian and Cadwalladr.,? \\Q2014\\E", "shortCiteRegEx": "Guardian and Cadwalladr.", "year": 2014}, {"title": "Economics of the Singularity", "author": ["Robin"], "venue": "IEEE Spectrum", "citeRegEx": "Hanson and Robin.,? \\Q2008\\E", "shortCiteRegEx": "Hanson and Robin.", "year": 2008}, {"title": "A Global Arms Race to Create a Superintelligent AI Is Looming", "author": ["Istvan", "Zoltan."], "venue": "Motherboard, March", "citeRegEx": "Istvan and Zoltan.,? 2015", "shortCiteRegEx": "Istvan and Zoltan.", "year": 2015}, {"title": "Why the Future Doesn\u2019t Need Us", "author": ["ing. Joy", "Bill"], "venue": null, "citeRegEx": "Joy and Bill.,? \\Q2000\\E", "shortCiteRegEx": "Joy and Bill.", "year": 2000}, {"title": "The Law of Accelerating Returns", "author": ["chive/8.04/joy.html. Kurzweil", "Ray"], "venue": "In Alan Turing: Life and Legacy of a Great Thinker", "citeRegEx": "Kurzweil and Ray.,? \\Q2004\\E", "shortCiteRegEx": "Kurzweil and Ray.", "year": 2004}, {"title": "The Singularity Is Near: When Humans Transcend Biology", "author": [], "venue": "Minds", "citeRegEx": "http...www.kurzweilai.net.the.law.of.accelerating.returns.,? \\Q2006\\E", "shortCiteRegEx": "http...www.kurzweilai.net.the.law.of.accelerating.returns.", "year": 2006}, {"title": "The Basic AI Drives", "author": ["Forecasting\u2019. Omohundro", "Stephen M"], "venue": "In Proceeding of the 2008 Conference on Artificial Gen-", "citeRegEx": "Omohundro and M.,? \\Q2008\\E", "shortCiteRegEx": "Omohundro and M.", "year": 2008}, {"title": "The Biointelligence Explosion", "author": ["David"], "venue": "In Singularity Hypotheses: A Scientific and Philosophical", "citeRegEx": "Pearce and David.,? \\Q2013\\E", "shortCiteRegEx": "Pearce and David.", "year": 2013}, {"title": "Software Immortals: Science or Faith?", "author": ["Diane"], "venue": "In Singularity Hypotheses: A Scientific and", "citeRegEx": "Proudfoot and Diane.,? \\Q2013\\E", "shortCiteRegEx": "Proudfoot and Diane.", "year": 2013}, {"title": "The Dragons of Eden: Speculations on the Evolution of Human Intelligence", "author": ["Carl"], "venue": null, "citeRegEx": "Sagan and Carl.,? \\Q1977\\E", "shortCiteRegEx": "Sagan and Carl.", "year": 1977}, {"title": "The Five Biggest Threats to Human Existence", "author": ["Books. Sandberg", "Anders."], "venue": "The Conversation, May 29.", "citeRegEx": "Sandberg and Anders.,? 2014", "shortCiteRegEx": "Sandberg and Anders.", "year": 2014}, {"title": "Science Fiction and Philosophy: From Time Travel to Superintelligence", "author": ["Susan"], "venue": null, "citeRegEx": "Schneider and Susan.,? \\Q2009\\E", "shortCiteRegEx": "Schneider and Susan.", "year": 2009}, {"title": "The Third Wave", "author": ["Sons. Toffler", "Alvin"], "venue": null, "citeRegEx": "Toffler and Alvin.,? \\Q1980\\E", "shortCiteRegEx": "Toffler and Alvin.", "year": 1980}, {"title": "A Specifier\u2019s Introduction to Formal Methods", "author": ["Jeannette M"], "venue": null, "citeRegEx": "Wing and M.,? \\Q1990\\E", "shortCiteRegEx": "Wing and M.", "year": 1990}, {"title": "Creating Friendly AI 1.0: The Analysis and Design of Benevolent Goal Architec", "author": ["Yudkowsky", "Eliezer S"], "venue": "Journal of Consciousness Studies", "citeRegEx": "Yudkowsky and S.,? \\Q2001\\E", "shortCiteRegEx": "Yudkowsky and S.", "year": 2001}, {"title": "Friendly Artificial Intelligence", "author": ["sky.net/singularity/schools"], "venue": null, "citeRegEx": "....,? \\Q2013\\E", "shortCiteRegEx": "....", "year": 2013}], "referenceMentions": [{"referenceID": 8, "context": "In July 2009, researchers from the Singularity Institute (later renamed the Machine Learning Research Institute), Dartmouth College and elsewhere presented their work at the venue of the 7th ECAP at the Autonomous University of Barcelona, and again in October 2010 (Eden 2010) for the 8th ECAP at the Technical University in Munich.", "startOffset": 265, "endOffset": 276}], "year": 2016, "abstractText": null, "creator": "PDF reDirect v2"}}}