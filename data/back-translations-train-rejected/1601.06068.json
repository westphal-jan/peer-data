{"id": "1601.06068", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jan-2016", "title": "Paraphrase Generation from Latent-Variable PCFGs for Semantic Parsing", "abstract": "One of the limitations of semantic parsing approaches to open-domain question answering is the lexicosyntactic gap between natural language questions and knowledge base entries -- there are many ways to ask a question, all with the same answer. In this paper we propose to bridge this gap by generating paraphrases of the input question with the goal that at least one of them will be correctly mapped to a knowledge-base query. We introduce a novel grammar model for paraphrase generation that does not require any sentence-aligned paraphrase corpus. Our key idea is to leverage the flexibility and scalability of latent-variable probabilistic context-free grammars to sample paraphrases. We do an extrinsic evaluation of our paraphrases by plugging them into a semantic parser for Freebase. Our evaluation experiments on the WebQuestions benchmark dataset show that the performance of the semantic parser significantly improves over strong baselines.", "histories": [["v1", "Fri, 22 Jan 2016 16:50:22 GMT  (216kb,D)", "https://arxiv.org/abs/1601.06068v1", "10 pages"], ["v2", "Fri, 5 Aug 2016 12:20:52 GMT  (216kb,D)", "http://arxiv.org/abs/1601.06068v2", "10 pages, INLG 2016"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shashi narayan", "siva reddy", "shay b cohen"], "accepted": false, "id": "1601.06068"}, "pdf": {"name": "1601.06068.pdf", "metadata": {"source": "CRF", "title": "Paraphrase Generation from Latent-Variable PCFGs for Semantic Parsing", "authors": ["Shashi Narayan", "Siva Reddy", "Shay B. Cohen"], "emails": ["shashi.narayan@ed.ac.uk,", "siva.reddy@ed.ac.uk,", "scohen@inf.ed.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "(Berant et al., 2013) We have the problem of the semantic analysis of questions relating to questions within the question. (Berant et al., 2013) We have the problem of the semantic analysis of questions within the question. (Kwiatkowski et al., 2013) We have the problem of the semantic analysis of questions within the question. (Berant et al., 2013) We have the problem of the semantic analysis of questions within the question. (Berant et al., 2013) We have the problem of the semantic analysis of questions within the question. (Kwiatkowski et al., 2013) We have the problem of the semantic analysis of questions within the question of questions within the question of questions within the question. (Berant et al., 2013) We have the problem of the semantic analysis of questions within the question of questions within the question. (Berant et al., 2013) We have the problem of the semantic analysis of questions within the question of questions within the question of questions within the question."}, {"heading": "2 Paraphrase Generation Using Grammars", "text": "Our paraphrase generation algorithm is based on a model in the form of an L-PCFG. L-PCFGs are PCFGs in which the nonterminals are refined by latent states that provide some contextual information about each node in a particular derivative. L-PCFGs have been used in various ways, most commonly for syntactic parsing (Prescher, 2005; Matsuzaki et al., 2005; Petrov et al., 2006; Cohen et al., 2013; Narayan and Cohen, 2015; Narayan and Cohen, 2016). In our estimation of L-PCFGs, we use the spectral method of Narayan and Cohen (2015) rather than using EM, as has been used in the past by Matsuzaki et al. (2005) and Petrov et al. (2006). The spectral method we use allows us to choose a number of feature functions that indicate latent states that prove useful in our case."}, {"heading": "2.1 Paraphrases Generation Algorithm", "text": "We are defining our paraphrase generation as an example of what people in the Czech Republic are doing? We are defining our paraphrase generation task as an example word from an L-PCFG Gsyn derived from a large corpus of parser questions. Once this grammar has a specific word and phrase selection that can be used, a word from Gsyn is extracted for the input question. This grammar is limited to the latticle. We are experimenting with three ways of creating word lattices that represent the words from the input question. Once this lattice is created, a grammar syn is extracted for the input question. This grammar is limited to the latticle. We are experimenting with three ways of creating word lattices that represent the word lattices constructed with the paraphrases. (Ganitkevitch et al, 2013) and word lattices, which are constructed with a two-layered L."}, {"heading": "2.2 Bi-Layered L-PCFGs", "text": "As already mentioned, one of our lateral types is based on two-layer PCFGs that are presented here. - In their traditional use, the latent states in LPCFGs are geared toward gathering syntactic information. We present here the use of an L-PCFG with two layers of latent states: one layer is intended to capture the usual syntactic information, and the other aims to capture semantic and current information by using a series of states with specific paraphrase functions.4To create the two-layer L-PCFG, we again use the spectral algorithm of Narayan and Cohen (2015) to estimate a grammarGpar from the Paralex corpus. We use the word alignment of the paraphrase question to represent within and outside trees of the respective nonterminals in the bag of word features."}, {"heading": "2.3 Paraphrase Classification", "text": "To improve its precision, we build a binary classifier to filter the generated paraphrases. We randomly select 100 different questions from the Paralex corpus and generate paraphrases using our generational algorithm with different grid settings. We randomly select 1,000 pairs of entered sentences and manually comment on them as \"right\" or \"wrong.\" 6 This problem is often severe for nonterminals at the top level of the two-layer tree. 7 We found that our Gpar grammar is not fine-grained enough and often transfers different paraphrase information to the same latent state. This problem is severe for nonterminals at the top level of the two-layer tree. Therefore, we rely only on inconsistent lexical rules (the rules that generate terminal fixes) to extract paraphrase patterns in our experiments."}, {"heading": "3 Semantic Parsing using Paraphrasing", "text": "In this section, we describe how the paraphrase algorithm is used to convert natural language into freebase queries. Following Reddy et al. (2014), we formalize the semantic parsing problem as a graph matching problem, i.e. we find the freebase subgraph (Grounded Graph), which is isomorphic to the input question (Unround Graph). This formulation has a major limitation, which can be eased by using our paraphrase generating algorithm. Consider the question, what language do people in the Czech Republic speak? The non-round graph corresponding to this question is shown in Figure 3 (a). The freebase graph, which leads to a correct answer, is shown in Figure 3 (d)."}, {"heading": "3.1 Ungrounded Graphs from Paraphrases", "text": "We use GRAPHPARSER (Reddy et al., 2014) to convert paraphrases into unrounded graphs. This conversion involves three steps: 1) analyze the paraphrase using a CCG parser to extract syntactical derivatives (Lewis and Steedman, 2014), 2) extract logical forms from CCG derivatives (Bos et al., 2004), and 3) convert logical forms into an unrounded graph. 8 The unrounded graph for the example question and its paraphrases are shown in Figure 3 (a), Figure 3 (b), and Figure 3 (c), respectively."}, {"heading": "3.2 Grounded Graphs from Ungrounded Graphs", "text": "The unrounded graphs are grounded on freebase subgraphs by mapping entity nodes, entity edges, and entity nodes in the unrounded graph to freebase entities, relations, and types, respectively. For example, the graph in Figure 3 (b) can be converted to a freebase graph in Figure 3 (d) by replacing the Czech Republic entity node with the CZECHREPUBLIC entity, the edge (speak.arg2, speak.in) between x and the Czech Republic with the freebase relationship (location.country.official language.2, location.country.official language.1), the type node language with the freebase language. Human language and the TARGET node remain intact. The rest of the nodes, edges, and types are grounded to zero. Similarly, Figure 3 (c) on Figure 3, but not grounded to a target (3)."}, {"heading": "3.3 Learning", "text": "We use a linear model to map unrounded diagrams to grounded diagrams. The parameters of the model q q = q q pairs are learned from the question-answer pairs. For example, what language do people in the Czech Republic speak? paired with their answer {CZECHLANGUAGE}. In line with most of the work on the question answered against Freebase, we do not rely on commented logical forms associated with the question for education and treat the mapping of a question on their grounded graph as latent.8For more details see Reddy et al. (2014) Let q be a question, let p be a paraphrase, let u be an unrounded graph for education and let g be a grounded graph that is formed from u to the knowledge base by grounding the nodes and edges."}, {"heading": "4 Experimental Setup", "text": "Below we give details of the evaluation data set and baselines used for the comparison, describe the characteristics of the model and provide details on implementation."}, {"heading": "4.1 Evaluation Data and Metric", "text": "We evaluate our approach using the WebQuestions dataset (Berant et al., 2013). WebQuestions consists of 5,810 question-answer pairs, with questions representing real Google searches. We use the standard train-test split with 3,778 train-test questions and 2,032 test questions. For our development experiments, we match the models to high-fidelity data, which consists of 30% training questions, while we use the complete training data for final tests. We use average precision (avg P.), average recall (avg R.) and average F1 (avg F1), which Berant et al. (2013) suggest as evaluation measures.9"}, {"heading": "4.2 Baselines", "text": "ORIGINAL We use GRAPHPARSER without paraphrases as a starting point. This gives an idea of the effects of using paraphrases. MT We compare our paraphrasing models with monolingual machine translation-based models for generating paraphrases (Quirk et al., 2004; Wubben et al., 2010). Specifically, we use Moses (Koehn et al., 2007) to train a monolingual phrase-based MT system on the Paralex corpus. Finally, we use Moses decoders to generate 10-best paraphrases for the test questions."}, {"heading": "4.3 Implementation Details", "text": "In fact, it is not that we are able to put ourselves in a position to put ourselves in a situation in which we are able to maneuver ourselves into a situation in which we are in a situation in which we are in a situation in which we are not able to find a solution, in which we are able, in which we are able to bring about a solution, \"he said in an interview with the New York Times."}, {"heading": "5 Results and Discussion", "text": "This year it is more than ever before."}, {"heading": "6 Conclusion", "text": "We described a grammar method for generating question paraphrases and applied it to a question system based on semantic parsing. We showed that using paraphrases for a question system is a useful method to improve its performance. Our method is more general and can be applied to any question system."}, {"heading": "Acknowledgements", "text": "The authors would like to thank Nitin Madnani for his help in implementing the Paraphrase Classifier and our anonymous reviewers for their insightful comments. This research was supported by an EPSRC grant (EP / L02411X / 1), the H2020 SUMMA project (under grant agreement 688139) and a Google PhD Fellowship for the second author."}], "references": [{"title": "Learning to paraphrase: An unsupervised approach using multiple-sequence alignment", "author": ["Barzilay", "Lee2003] Regina Barzilay", "Lillian Lee"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "Barzilay et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Barzilay et al\\.", "year": 2003}, {"title": "More accurate question answering on Freebase", "author": ["Bast", "Haussmann2015] Hannah Bast", "Elmar Haussmann"], "venue": "In Proceedings of CIKM", "citeRegEx": "Bast et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bast et al\\.", "year": 2015}, {"title": "Semantic parsing via paraphrasing", "author": ["Berant", "Liang2014] Jonathan Berant", "Percy Liang"], "venue": "In Proceedings of ACL", "citeRegEx": "Berant et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2014}, {"title": "Imitation learning of agenda-based semantic parsers. Transactions of the Association for Computational Linguistics, 3:545\u2013558", "author": ["Berant", "Liang2015] Jonathan Berant", "Percy Liang"], "venue": null, "citeRegEx": "Berant et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2015}, {"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["Andrew Chou", "Roy Frostig", "Percy Liang"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Berant et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Wide-coverage semantic representations from a CCG parser", "author": ["Bos et al.2004] Johan Bos", "Stephen Clark", "Mark Steedman", "James R. Curran", "Julia Hockenmaier"], "venue": "In Proceedings of COLING", "citeRegEx": "Bos et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bos et al\\.", "year": 2004}, {"title": "Coarse-to-fine n-best parsing and maxent discriminative reranking", "author": ["Charniak", "Johnson2005] Eugene Charniak", "Mark Johnson"], "venue": "In Proceedings of ACL", "citeRegEx": "Charniak et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Charniak et al\\.", "year": 2005}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["Chen", "Mooney2011] David L. Chen", "Raymond J. Mooney"], "venue": "In Proceedings of AAAI", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "Experiments with spectral learning of latent-variable PCFGs", "author": ["Cohen et al.2013] Shay B. Cohen", "Karl Stratos", "Michael Collins", "Dean P. Foster", "Lyle Ungar"], "venue": "Proceedings of NAACL", "citeRegEx": "Cohen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2013}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "Answering the question you wish they had asked: The impact of paraphrasing for question answering", "author": ["Duboue", "Jennifer Chu-Carroll"], "venue": "Proceedings of NAACLHLT", "citeRegEx": "Duboue et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Duboue et al\\.", "year": 2006}, {"title": "Paraphrase-driven learning for open question answering", "author": ["Fader et al.2013] Anthony Fader", "Luke Zettlemoyer", "Oren Etzioni"], "venue": "In Proceedings of ACL", "citeRegEx": "Fader et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2013}, {"title": "PPDB: The Paraphrase Database", "author": ["Benjamin Van Durme", "Chris Callison-Burch"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "Ganitkevitch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "The WEKA data mining software: An update", "author": ["Hall et al.2009] Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten"], "venue": "ACM SIGKDD Explorations Newsletter,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Generation as dependency parsing", "author": ["Koller", "Striegnitz2002] Alexander Koller", "Kristina Striegnitz"], "venue": "In Proceedings of ACL", "citeRegEx": "Koller et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Koller et al\\.", "year": 2002}, {"title": "Weakly supervised training of semantic parsers", "author": ["Krishnamurthy", "Tom Mitchell"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Krishnamurthy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krishnamurthy et al\\.", "year": 2012}, {"title": "Scaling semantic parsers with on-the-fly ontology matching", "author": ["Eunsol Choi", "Yoav Artzi", "Luke Zettlemoyer"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Kwiatkowski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2013}, {"title": "Generation that exploits corpusbased statistical knowledge", "author": ["Langkilde", "Knight1998] Irene Langkilde", "Kevin Knight"], "venue": "In Proceedings of ACLCOLING", "citeRegEx": "Langkilde et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Langkilde et al\\.", "year": 1998}, {"title": "A* CCG parsing with a supertag-factored model", "author": ["Lewis", "Steedman2014] Mike Lewis", "Mark Steedman"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Lewis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 2014}, {"title": "Re-examining machine translation metrics for paraphrase identification", "author": ["Joel Tetreault", "Martin Chodorow"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "Madnani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Madnani et al\\.", "year": 2012}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "Proceedings of ACL", "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Probabilistic CFG with latent annotations", "author": ["Yusuke Miyao", "Jun\u2019ichi Tsujii"], "venue": "In Proceedings of ACL", "citeRegEx": "Matsuzaki et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Matsuzaki et al\\.", "year": 2005}, {"title": "A joint model of language and perception for grounded attribute learning", "author": ["Nicholas FitzGerald", "Luke Zettlemoyer", "Liefeng Bo", "Dieter Fox"], "venue": "Proceedings of ICML", "citeRegEx": "Matuszek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Matuszek et al\\.", "year": 2012}, {"title": "Orthogonality of syntax and semantics within distributional spaces", "author": ["Mitchell", "Steedman2015] Jeff Mitchell", "Mark Steedman"], "venue": "In Proceedings of ACL", "citeRegEx": "Mitchell et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2015}, {"title": "Diversity in spectral learning for natural language parsing", "author": ["Narayan", "Cohen2015] Shashi Narayan", "Shay B. Cohen"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Narayan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Narayan et al\\.", "year": 2015}, {"title": "Optimizing spectral learning for parsing", "author": ["Narayan", "Cohen2016] Shashi Narayan", "Shay B. Cohen"], "venue": "In Proceedings of ACL", "citeRegEx": "Narayan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Narayan et al\\.", "year": 2016}, {"title": "Structure-driven lexicalist generation", "author": ["Narayan", "Gardent2012] Shashi Narayan", "Claire Gardent"], "venue": "In Proceedings of COLING", "citeRegEx": "Narayan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Narayan et al\\.", "year": 2012}, {"title": "Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences", "author": ["Pang et al.2003] Bo Pang", "Kevin Knight", "Daniel Marcu"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "Pang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2003}, {"title": "Learning accurate, compact, and interpretable tree annotation", "author": ["Petrov et al.2006] Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein"], "venue": "In Proceedings of COLING-ACL", "citeRegEx": "Petrov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2006}, {"title": "Head-driven pcfgs with latent-head statistics", "author": ["Detlef Prescher"], "venue": "In Proceedings of IWPT", "citeRegEx": "Prescher.,? \\Q2005\\E", "shortCiteRegEx": "Prescher.", "year": 2005}, {"title": "Monolingual machine translation for paraphrase generation", "author": ["Quirk et al.2004] Chris Quirk", "Chris Brockett", "William B. Dolan"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Quirk et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Quirk et al\\.", "year": 2004}, {"title": "Large-scale semantic parsing without question-answer pairs. Transactions of the Association for Computational Linguistics, 2:377\u2013392", "author": ["Reddy et al.2014] Siva Reddy", "Mirella Lapata", "Mark Steedman"], "venue": null, "citeRegEx": "Reddy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Transforming Dependency Structures to Logical Forms for Semantic Parsing", "author": ["Reddy et al.2016] Siva Reddy", "Oscar T\u00e4ckstr\u00f6m", "Michael Collins", "Tom Kwiatkowski", "Dipanjan Das", "Mark Steedman", "Mirella Lapata"], "venue": null, "citeRegEx": "Reddy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2016}, {"title": "Statistical machine translation for query expansion in answer retrieval", "author": ["Alexander Vasserman", "Ioannis Tsochantaridis", "Vibhu Mittal", "Yi Liu"], "venue": "Proceedings of ACL", "citeRegEx": "Riezler et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Riezler et al\\.", "year": 2007}, {"title": "Semantic head-driven generation", "author": ["Gertjan van Noord", "Fernando C.N. Pereira", "Robert C. Moore"], "venue": null, "citeRegEx": "Shieber et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Shieber et al\\.", "year": 1990}, {"title": "A uniform architecture for parsing and generation", "author": ["Stuart M. Shieber"], "venue": "In Proceedings of COLING", "citeRegEx": "Shieber.,? \\Q1988\\E", "shortCiteRegEx": "Shieber.", "year": 1988}, {"title": "Building a semantic parser overnight", "author": ["Wang et al.2015] Yushi Wang", "Jonathan Berant", "Percy Liang"], "venue": "In Proceedings of ACL", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Reining in ccg chart realization", "author": ["Michael White"], "venue": "Natural Language Generation,", "citeRegEx": "White.,? \\Q2004\\E", "shortCiteRegEx": "White.", "year": 2004}, {"title": "Learning for semantic parsing with statistical machine translation", "author": ["Wong", "Mooney2006] Yuk Wah Wong", "Raymond J. Mooney"], "venue": "In Proceedings of NAACL", "citeRegEx": "Wong et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wong et al\\.", "year": 2006}, {"title": "Paraphrase generation as monolingual translation: Data and evaluation", "author": ["Wubben et al.2010] Sander Wubben", "Antal van den Bosch", "Emiel Krahmer"], "venue": "In Proceedings of INLG", "citeRegEx": "Wubben et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wubben et al\\.", "year": 2010}, {"title": "Question Answering on Freebase via Relation Extraction and Textual Evidence", "author": ["Xu et al.2016] Kun Xu", "Siva Reddy", "Yansong Feng", "Songfang Huang", "Dongyan Zhao"], "venue": "Proceedings of ACL", "citeRegEx": "Xu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "S-MART: Novel tree-based structured learning algorithms applied to tweet entity linking", "author": ["Yang", "Chang2015] Yi Yang", "Ming-Wei Chang"], "venue": "In Proceedings of ACL", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Semantic parsing via staged query graph generation: Question answering with knowledge base", "author": ["Yih et al.2015] Wen-tau Yih", "Ming-Wei Chang", "Xiaodong He", "Jianfeng Gao"], "venue": "Proceedings of ACL", "citeRegEx": "Yih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2015}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["Zettlemoyer", "Collins2005] Luke S. Zettlemoyer", "Michael Collins"], "venue": "In Proceedings of UAI", "citeRegEx": "Zettlemoyer et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zettlemoyer et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 22, "context": "Semantic parsers map sentences onto logical forms that can be used to query databases (Zettlemoyer and Collins, 2005; Wong and Mooney, 2006), instruct robots (Chen and Mooney, 2011), extract information (Krishnamurthy and Mitchell, 2012), or describe visual scenes (Matuszek et al., 2012).", "startOffset": 265, "endOffset": 288}, {"referenceID": 4, "context": "Current systems accomplish this by learning task-specific grammars (Berant et al., 2013), strongly-typed CCG grammars (Kwiatkowski et al.", "startOffset": 67, "endOffset": 88}, {"referenceID": 16, "context": ", 2013), strongly-typed CCG grammars (Kwiatkowski et al., 2013; Reddy et al., 2014), or neural networks without requiring any grammar (Yih et al.", "startOffset": 37, "endOffset": 83}, {"referenceID": 31, "context": ", 2013), strongly-typed CCG grammars (Kwiatkowski et al., 2013; Reddy et al., 2014), or neural networks without requiring any grammar (Yih et al.", "startOffset": 37, "endOffset": 83}, {"referenceID": 42, "context": ", 2014), or neural networks without requiring any grammar (Yih et al., 2015).", "startOffset": 58, "endOffset": 76}, {"referenceID": 11, "context": "Paraphrasing has shown to be promising for semantic parsing (Fader et al., 2013; Berant and Liang, 2014; Wang et al., 2015).", "startOffset": 60, "endOffset": 123}, {"referenceID": 36, "context": "Paraphrasing has shown to be promising for semantic parsing (Fader et al., 2013; Berant and Liang, 2014; Wang et al., 2015).", "startOffset": 60, "endOffset": 123}, {"referenceID": 33, "context": "Earlier approaches to paraphrasing used phrase-based machine translation for textbased QA (Duboue and Chu-Carroll, 2006; Riezler et al., 2007), or hand annotated grammars for KB-based QA (Berant and Liang, 2014).", "startOffset": 90, "endOffset": 142}, {"referenceID": 12, "context": "While CFGs have been explored for paraphrasing using bilingual parallel corpus (Ganitkevitch et al., 2013), ours is the first implementation of CFG that uses only monolingual data.", "startOffset": 79, "endOffset": 106}, {"referenceID": 12, "context": "While CFGs have been explored for paraphrasing using bilingual parallel corpus (Ganitkevitch et al., 2013), ours is the first implementation of CFG that uses only monolingual data. Second, we show that generated paraphrases can be used to improve semantic parsing of questions into Freebase logical forms (\u00a73). We build on a strong baseline of Reddy et al. (2014) and show that our grammar model competes with MT baseline even without using any parallel paraphrase resources.", "startOffset": 80, "endOffset": 364}, {"referenceID": 29, "context": "L-PCFGs have been used in various ways, most commonly for syntactic parsing (Prescher, 2005; Matsuzaki et al., 2005; Petrov et al., 2006; Cohen et al., 2013; Narayan and Cohen, 2015; Narayan and Cohen, 2016).", "startOffset": 76, "endOffset": 207}, {"referenceID": 21, "context": "L-PCFGs have been used in various ways, most commonly for syntactic parsing (Prescher, 2005; Matsuzaki et al., 2005; Petrov et al., 2006; Cohen et al., 2013; Narayan and Cohen, 2015; Narayan and Cohen, 2016).", "startOffset": 76, "endOffset": 207}, {"referenceID": 28, "context": "L-PCFGs have been used in various ways, most commonly for syntactic parsing (Prescher, 2005; Matsuzaki et al., 2005; Petrov et al., 2006; Cohen et al., 2013; Narayan and Cohen, 2015; Narayan and Cohen, 2016).", "startOffset": 76, "endOffset": 207}, {"referenceID": 8, "context": "L-PCFGs have been used in various ways, most commonly for syntactic parsing (Prescher, 2005; Matsuzaki et al., 2005; Petrov et al., 2006; Cohen et al., 2013; Narayan and Cohen, 2015; Narayan and Cohen, 2016).", "startOffset": 76, "endOffset": 207}, {"referenceID": 20, "context": "In our estimation of L-PCFGs, we use the spectral method of Narayan and Cohen (2015), instead of using EM, as has been used in the past by Matsuzaki et al. (2005) and Petrov et al.", "startOffset": 139, "endOffset": 163}, {"referenceID": 20, "context": "In our estimation of L-PCFGs, we use the spectral method of Narayan and Cohen (2015), instead of using EM, as has been used in the past by Matsuzaki et al. (2005) and Petrov et al. (2006). The spectral method we use enables the choice of a set of feature functions that indicate the latent states, which proves to be useful in our case.", "startOffset": 139, "endOffset": 188}, {"referenceID": 8, "context": "For more details about these constructions, we refer the reader to Cohen et al. (2013) and Narayan and Cohen (2015).", "startOffset": 67, "endOffset": 87}, {"referenceID": 8, "context": "For more details about these constructions, we refer the reader to Cohen et al. (2013) and Narayan and Cohen (2015).", "startOffset": 67, "endOffset": 116}, {"referenceID": 12, "context": "We experiment with three ways of constructing word lattices: na\u0131\u0308ve word lattices representing the words from the input question only, word lattices constructed with the Paraphrase Database (Ganitkevitch et al., 2013) and word lattices constructed with a bi-layered L-PCFG, described in \u00a72.", "startOffset": 190, "endOffset": 217}, {"referenceID": 11, "context": "L-PCFG Estimation We train the L-PCFG Gsyn on the Paralex corpus (Fader et al., 2013).", "startOffset": 65, "endOffset": 85}, {"referenceID": 27, "context": "Word lattices, formally weighted finite state automata, have been used in previous works for paraphrase generation (Langkilde and Knight, 1998; Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004).", "startOffset": 115, "endOffset": 206}, {"referenceID": 30, "context": "Word lattices, formally weighted finite state automata, have been used in previous works for paraphrase generation (Langkilde and Knight, 1998; Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004).", "startOffset": 115, "endOffset": 206}, {"referenceID": 12, "context": "For our experiments, we extract rules from the PPDBSmall to maintain the high precision (Ganitkevitch et al., 2013).", "startOffset": 88, "endOffset": 115}, {"referenceID": 37, "context": "First, the sampling from an L-PCFG grammar lessens the lexical ambiguity problem evident in lexicalized grammars such as tree adjoining grammars (Narayan and Gardent, 2012) and combinatory categorial grammars (White, 2004).", "startOffset": 209, "endOffset": 222}, {"referenceID": 34, "context": "Second, the top-down sampling restricts the combinatorics inherent to bottom-up search (Shieber et al., 1990).", "startOffset": 87, "endOffset": 109}, {"referenceID": 35, "context": "And fourth, we impose no constraints on the grammar thereby making it easier to maintain bi-directional (recursive) grammars that can be used both for parsing and for generation (Shieber, 1988).", "startOffset": 178, "endOffset": 193}, {"referenceID": 13, "context": "We use WEKA (Hall et al., 2009) to replicate the classifier of Madnani et al.", "startOffset": 12, "endOffset": 31}, {"referenceID": 18, "context": "follow Madnani et al. (2012), who used MT metrics for paraphrase identification, and experiment with 8 MT metrics as features for our binary classifier.", "startOffset": 7, "endOffset": 29}, {"referenceID": 13, "context": "We use WEKA (Hall et al., 2009) to replicate the classifier of Madnani et al. (2012) with our new feature.", "startOffset": 13, "endOffset": 85}, {"referenceID": 31, "context": "Following Reddy et al. (2014), we formalize the semantic parsing problem as a graph matching problem, i.", "startOffset": 10, "endOffset": 30}, {"referenceID": 31, "context": "We use GRAPHPARSER (Reddy et al., 2014) to convert paraphrases to ungrounded graphs.", "startOffset": 19, "endOffset": 39}, {"referenceID": 5, "context": "This conversion involves three steps: 1) parsing the paraphrase using a CCG parser to extract syntactic derivations (Lewis and Steedman, 2014), 2) extracting logical forms from the CCG derivations (Bos et al., 2004), and 3) converting the logical forms to an ungrounded graph.", "startOffset": 197, "endOffset": 215}, {"referenceID": 31, "context": "Please see Reddy et al. (2014) for more details.", "startOffset": 11, "endOffset": 31}, {"referenceID": 31, "context": "Following Reddy et al. (2014), we use beam search to find the highest scoring tuple of paraphrase, ungrounded and grounded graphs (p\u0302, \u00fb, \u011d) under the model \u03b8 \u2208 Rn:", "startOffset": 10, "endOffset": 30}, {"referenceID": 9, "context": "The model parameters are estimated with the averaged structured perceptron (Collins, 2002).", "startOffset": 75, "endOffset": 90}, {"referenceID": 4, "context": "We evaluate our approach on the WebQuestions dataset (Berant et al., 2013).", "startOffset": 53, "endOffset": 74}, {"referenceID": 2, "context": ") and average F1 (avg F1) proposed by Berant et al. (2013) as evaluation metrics.", "startOffset": 38, "endOffset": 59}, {"referenceID": 30, "context": "MT We compare our paraphrasing models with monolingual machine translation based model for paraphrase generation (Quirk et al., 2004; Wubben et al., 2010).", "startOffset": 113, "endOffset": 154}, {"referenceID": 39, "context": "MT We compare our paraphrasing models with monolingual machine translation based model for paraphrase generation (Quirk et al., 2004; Wubben et al., 2010).", "startOffset": 113, "endOffset": 154}, {"referenceID": 20, "context": "We use the Stanford CoreNLP caseless tagger for part-of-speech tagging (Manning et al., 2014).", "startOffset": 71, "endOffset": 93}, {"referenceID": 31, "context": "We use the features from Reddy et al. (2014). These include edge align-", "startOffset": 25, "endOffset": 45}, {"referenceID": 41, "context": "Yih et al. (2015) and Xu et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 40, "context": "(2015) and Xu et al. (2016) use neural network models for semantic parsing, in addition to using sophisticated entity resolution (Yang and Chang, 2015) and a very large unsupervised corpus as additional training data.", "startOffset": 11, "endOffset": 28}], "year": 2016, "abstractText": "One of the limitations of semantic parsing approaches to open-domain question answering is the lexicosyntactic gap between natural language questions and knowledge base entries \u2013 there are many ways to ask a question, all with the same answer. In this paper we propose to bridge this gap by generating paraphrases of the input question with the goal that at least one of them will be correctly mapped to a knowledge-base query. We introduce a novel grammar model for paraphrase generation that does not require any sentence-aligned paraphrase corpus. Our key idea is to leverage the flexibility and scalability of latent-variable probabilistic context-free grammars to sample paraphrases. We do an extrinsic evaluation of our paraphrases by plugging them into a semantic parser for Freebase. Our evaluation experiments on the WebQuestions benchmark dataset show that the performance of the semantic parser improves over strong baselines.", "creator": "LaTeX with hyperref package"}}}