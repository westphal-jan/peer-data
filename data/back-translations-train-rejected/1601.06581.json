{"id": "1601.06581", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2016", "title": "Character-Level Incremental Speech Recognition with Recurrent Neural Networks", "abstract": "In real-time speech recognition applications, the latency is an important issue. We have developed a character-level incremental speech recognition (ISR) system that responds quickly even during the speech, where the hypotheses are gradually improved while the speaking proceeds. The algorithm employs a speech-to-character unidirectional recurrent neural network (RNN), which is end-to-end trained with connectionist temporal classification (CTC), and an RNN-based character-level language model (LM). The output values of the CTC-trained RNN are character-level probabilities, which are processed by beam search decoding. The RNN LM augments the decoding by providing long-term dependency information. We propose tree-based online beam search with additional depth-pruning, which enables the system to process infinitely long input speech with low latency. This system not only responds quickly on speech but also can dictate out-of-vocabulary (OOV) words according to pronunciation. The proposed model achieves the word error rate (WER) of 8.90% on the Wall Street Journal (WSJ) Nov'92 20K evaluation set when trained on the WSJ SI-284 training set.", "histories": [["v1", "Mon, 25 Jan 2016 12:51:46 GMT  (86kb)", "https://arxiv.org/abs/1601.06581v1", "To appear in ICASSP 2016"], ["v2", "Thu, 28 Jan 2016 11:03:05 GMT  (86kb)", "http://arxiv.org/abs/1601.06581v2", "To appear in ICASSP 2016"]], "COMMENTS": "To appear in ICASSP 2016", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["kyuyeon hwang", "wonyong sung"], "accepted": false, "id": "1601.06581"}, "pdf": {"name": "1601.06581.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["kyuyeon.hwang@gmail.com;", "wysung@snu.ac.kr"], "sections": [{"heading": null, "text": "This year it is more than ever before."}, {"heading": "2.1. Acoustic model", "text": "The network consists of two LSTM layers, each with 768 cells, in which the network has a total of 12.2 M traceable parameters. The model is similar to the one in the previous work on multiple utterances. There is no need to reset the RNN states at the outer boundary. This is necessary for the ISR systems, which run continuously with an infinite audio stream. Also, our model has a random concatenation of multiple utterances. There is no need to reset the RNN states at the outer boundary."}, {"heading": "2.2. Language model", "text": "An RNN language model (LM) [18] is used for the proposed ISR system, since conventional statistical LMs such as n-gram backoff models are not suitable for character-level prediction, since they cannot use very long history windows. In particular, the RNN-LM has a deep LSTM network structure with two LSTM layers, in which each of them has 512 memory cells, resulting in a total of 3.2 M parameters. Input of the RNN-LM is a 30-dimensional vector in which the current label (character) is heat-coded once, and the output is also a 30-dimensional vector representing the probabilities of the next labels. Although the RNN-LM is trained to predict the next characters with only the current character, the past character stories are stored internally within the RNN and used for prediction."}, {"heading": "3.1. Tree-based CTC beam search", "text": "The labeling sequence z is a sequence of labels in L. The length of the labeling sequence z is less than or equal to the number of input frames. The goal of decoding the labeling sequence is to find the label sequence that has the maximum posterior probability, since the input characteristics from time 1 to t are generated by the acoustic RNNNs, i.e., zmax = argmax z P (z | x1: t), (1) where x1: t are the input characteristics from time 1 to t. However, the CTC-trained RNN output has another blank labeling, i.e., L \u2032 be the amount of labeling states (or CTC states) with the additional CTC Blank label, and the path \u03c0 (i) t is a sequence of labeling characteristics in time 1 to t. The length of the path \u03c0 (i) t is the same as t."}, {"heading": "3.2. Pruning", "text": "That is, it is only a part of them that sees themselves in a position to surpass themselves, both in terms of quality and also in terms of the way in which it is about quality, and also in terms of the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about the way in which it is about and the way in which it is about the way in which it is about and the way in which it is about, and the way in which it is about the way in which it is about, and the way in which it is about the way in which it is about, and the way in which it is about the way in which it is about and the way in which it is about the way in which it is about, and the way in which it is about the way in which it is about the way in which it is about the way in which it is about and the way in which it is about and the way in which it is about and the way in which it is about the way in which it is about which it is about, and the way in which it is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is not only about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is which is"}], "references": [{"title": "Stability and accuracy in incremental speech recognition", "author": ["Ethan O Selfridge", "Iker Arizmendi", "Peter A Heeman", "Jason D Williams"], "venue": "Proceedings of the SIGDIAL 2011 Conference. Association for Computational Linguistics, 2011, pp. 110\u2013119.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Estimating wordstability during incremental speech recognition", "author": ["Ian McGraw", "Alexander Gruenstein"], "venue": "Training, vol. 17, no. 27,327, pp. 6\u20134, 2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Incremental generation of word graphs", "author": ["Gerhard Sagerer", "Heike Rautenstrauch", "Gernot A Fink", "Bernd Hildebrandt", "A Jusek", "Franz Kummert"], "venue": "ICSLP. Citeseer, 1996.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Grapheme based speech recognition", "author": ["Mirjam Killer", "Sebastian St\u00fcker", "Tanja Schultz"], "venue": "INTERSPEECH, 2003.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Open vocabulary speech recognition with flat hybrid models", "author": ["Maximilian Bisani", "Hermann Ney"], "venue": "INTER- SPEECH, 2005, pp. 725\u2013728.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "author": ["Alex Graves", "Navdeep Jaitly"], "venue": "Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 1764\u20131772.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "DeepSpeech: Scaling up endto-end speech recognition", "author": ["Awni Hannun", "Carl Case", "Jared Casper", "Bryan Catanzaro", "Greg Diamos", "Erich Elsen", "Ryan Prenger", "Sanjeev Satheesh", "Shubho Sengupta", "Adam Coates"], "venue": "arXiv preprint arXiv:1412.5567, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "First-pass large vocabulary continuous speech recognition using bi-directional recurrent DNNs", "author": ["Awni Y Hannun", "Andrew L Maas", "Daniel Jurafsky", "Andrew Y Ng"], "venue": "arXiv preprint arXiv:1408.2873, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding", "author": ["Yajie Miao", "Mohammad Gowayyed", "Florian Metze"], "venue": "arXiv preprint arXiv:1507.08240, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "End-to-end attentionbased large vocabulary speech recognition", "author": ["Dzmitry Bahdanau", "Jan Chorowski", "Dmitriy Serdyuk", "Philemon Brakel", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1508.04395, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Lexicon-free conversational speech recognition with neural networks", "author": ["Andrew L Maas", "Ziang Xie", "Dan Jurafsky", "Andrew Y Ng"], "venue": "NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Colorado, USA, May 31 - June 5, 2015, 2015, pp. 345\u2013354.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks", "author": ["Alex Graves", "Santiago Fern\u00e1ndez", "Faustino Gomez", "J\u00fcrgen Schmidhuber"], "venue": "Proceedings of the 23rd international conference on Machine learning. ACM, 2006, pp. 369\u2013376.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "The design for the Wall Street Journal-based CSR corpus", "author": ["Douglas B Paul", "Janet M Baker"], "venue": "Proceedings of the workshop on Speech and Natural Language. Association for Computational Linguistics, 1992, pp. 357\u2013362.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1992}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "Hybrid speech recognition with deep bidirectional LSTM", "author": ["Alex Graves", "Navdeep Jaitly", "Abdel-rahman Mohamed"], "venue": "Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on. IEEE, 2013, pp. 273\u2013278.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Online sequence training of recurrent neural networks with connectionist temporal classification", "author": ["Kyuyeon Hwang", "Wonyong Sung"], "venue": "arXiv preprint arXiv:1511.06841, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Single stream parallelization of generalized LSTM-like RNNs on a GPU", "author": ["Kyuyeon Hwang", "Wonyong Sung"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 2015, pp. 1047\u2013 1051.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Extensions of recurrent neural network language model", "author": ["Tom\u00e1\u0161 Mikolov", "Stefan Kombrink", "Luk\u00e1\u0161 Burget", "Jan Honza \u010cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 5528\u20135531.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "ADADELTA: An adaptive learning rate method", "author": ["Matthew D Zeiler"], "venue": "arXiv preprint arXiv:1212.5701, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Generating text with recurrent neural networks", "author": ["Ilya Sutskever", "James Martens", "Geoffrey E Hinton"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, pp. 1017\u20131024.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Large vocabulary continuous speech recognition using HTK", "author": ["Phillip C Woodland", "Julian J Odell", "Valtcho Valtchev", "Steve J Young"], "venue": "Acoustics, Speech, and Signal Processing, 1994. ICASSP-94., 1994 IEEE International Conference on. IEEE, 1994, vol. 2, pp. II\u2013125.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 0, "context": "Since ISR is usually employed for immediate reaction to speech, word stability [1, 2] and incremental lattice generation [3] have been important topics.", "startOffset": 79, "endOffset": 85}, {"referenceID": 1, "context": "Since ISR is usually employed for immediate reaction to speech, word stability [1, 2] and incremental lattice generation [3] have been important topics.", "startOffset": 79, "endOffset": 85}, {"referenceID": 2, "context": "Since ISR is usually employed for immediate reaction to speech, word stability [1, 2] and incremental lattice generation [3] have been important topics.", "startOffset": 121, "endOffset": 124}, {"referenceID": 3, "context": "In [4], graphemes are employed as basic units instead of phonemes.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Also, a sub-lexical language model is proposed in [5] for detecting previously unseen words.", "startOffset": 50, "endOffset": 53}, {"referenceID": 5, "context": "RNN-based character-level end-to-end ASR systems were studied in [6, 7, 8, 9, 10].", "startOffset": 65, "endOffset": 81}, {"referenceID": 6, "context": "RNN-based character-level end-to-end ASR systems were studied in [6, 7, 8, 9, 10].", "startOffset": 65, "endOffset": 81}, {"referenceID": 7, "context": "RNN-based character-level end-to-end ASR systems were studied in [6, 7, 8, 9, 10].", "startOffset": 65, "endOffset": 81}, {"referenceID": 8, "context": "RNN-based character-level end-to-end ASR systems were studied in [6, 7, 8, 9, 10].", "startOffset": 65, "endOffset": 81}, {"referenceID": 9, "context": "RNN-based character-level end-to-end ASR systems were studied in [6, 7, 8, 9, 10].", "startOffset": 65, "endOffset": 81}, {"referenceID": 10, "context": "Recently, a lexicon-free end-to-end ASR system is introduced in [11], where a character-level RNN LM is employed.", "startOffset": 64, "endOffset": 68}, {"referenceID": 11, "context": "The acoustic RNN is end-to-end trained with connectionist temporal classification (CTC) [12] using Wall Street Journal (WSJ) speech corpus [13].", "startOffset": 88, "endOffset": 92}, {"referenceID": 12, "context": "The acoustic RNN is end-to-end trained with connectionist temporal classification (CTC) [12] using Wall Street Journal (WSJ) speech corpus [13].", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "Both acoustic RNN and RNN LM have deep unidirectional long short-term memory (LSTM) network structures [14, 15].", "startOffset": 103, "endOffset": 111}, {"referenceID": 14, "context": "Both acoustic RNN and RNN LM have deep unidirectional long short-term memory (LSTM) network structures [14, 15].", "startOffset": 103, "endOffset": 111}, {"referenceID": 11, "context": "The acoustic model is a deep RNN trained with CTC [12].", "startOffset": 50, "endOffset": 54}, {"referenceID": 5, "context": "The model is similar to the one in the previous work about end-to-end speech recognition with RNNs [6] except a few major differences.", "startOffset": 99, "endOffset": 102}, {"referenceID": 15, "context": "In our case, the RNN is trained by online CTC [16] with very long training sequences that are generated by randomly concatenating several utterances.", "startOffset": 46, "endOffset": 50}, {"referenceID": 16, "context": "The networks are trained with stochastic gradient descent (SGD) with 8 parallel input streams on a GPU [17].", "startOffset": 103, "endOffset": 107}, {"referenceID": 17, "context": "An RNN language model (LM) [18] is employed for the proposed ISR system since conventional statistical LMs such as n-gram backoff models are not suitable for character-level prediction since they cannot make use of very long history windows.", "startOffset": 27, "endOffset": 31}, {"referenceID": 18, "context": "The RNN LM is trained with AdaDelta [19] based SGD method for accelerated training and better annealing.", "startOffset": 36, "endOffset": 40}, {"referenceID": 19, "context": "Random sentences can be generated following the method described in [20].", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "As proposed in [8, 11], external language models can be integrated by modifying the posterior probability term in (1) into:", "startOffset": 15, "endOffset": 22}, {"referenceID": 10, "context": "As proposed in [8, 11], external language models can be integrated by modifying the posterior probability term in (1) into:", "startOffset": 15, "endOffset": 22}, {"referenceID": 5, "context": "90% Graves and Jaitly [6] CTC + Trigram (extended) 8.", "startOffset": 22, "endOffset": 25}, {"referenceID": 8, "context": "[9] CTC + Trigram (extended) 7.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] CTC + Trigram 9.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] CTC + Bigram 14.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Encoder-decoder + Trigram 11.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] GMM-HMM + Trigram 9.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] DNN-HMM + Trigram 7.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] with a CTC-trained deep bidirectional LSTM network and a retrained trigram LM with extended vocabulary.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "In real-time speech recognition applications, the latency is an important issue. We have developed a character-level incremental speech recognition (ISR) system that responds quickly even during the speech, where the hypotheses are gradually improved while the speaking proceeds. The algorithm employs a speech-to-character unidirectional recurrent neural network (RNN), which is end-to-end trained with connectionist temporal classification (CTC), and an RNN-based character-level language model (LM). The output values of the CTC-trained RNN are character-level probabilities, which are processed by beam search decoding. The RNN LM augments the decoding by providing long-term dependency information. We propose tree-based online beam search with additional depth-pruning, which enables the system to process infinitely long input speech with low latency. This system not only responds quickly on speech but also can dictate out-of-vocabulary (OOV) words according to pronunciation. The proposed model achieves the word error rate (WER) of 8.90% on the Wall Street Journal (WSJ) Nov\u201992 20K evaluation set when trained on the WSJ SI-284 training set.", "creator": "LaTeX with hyperref package"}}}