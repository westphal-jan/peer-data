{"id": "1601.06862", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jan-2016", "title": "A Survey on Artificial Intelligence and Data Mining for MOOCs", "abstract": "Massive Open Online Courses (MOOCs) have gained tremendous popularity in the last few years. Thanks to MOOCs, millions of learners from all over the world have taken thousands of high-quality courses for free. Putting together an excellent MOOC ecosystem is a multidisciplinary endeavour that requires contributions from many different fields. Artificial intelligence (AI) and data mining (DM) are two such fields that have played a significant role in making MOOCs what they are today. By exploiting the vast amount of data generated by learners engaging in MOOCs, DM improves our understanding of the MOOC ecosystem and enables MOOC practitioners to deliver better courses. Similarly, AI, supported by DM, can greatly improve student experience and learning outcomes. In this survey paper, we first review the state-of-the-art artificial intelligence and data mining research applied to MOOCs, emphasising the use of AI and DM tools and techniques to improve student engagement, learning outcomes, and our understanding of the MOOC ecosystem. We then offer an overview of key trends and important research to carry out in the fields of AI and DM so that MOOCs can reach their full potential.", "histories": [["v1", "Tue, 26 Jan 2016 01:28:29 GMT  (587kb)", "http://arxiv.org/abs/1601.06862v1", "Working Paper"]], "COMMENTS": "Working Paper", "reviews": [], "SUBJECTS": "cs.AI cs.CY", "authors": ["simon fauvel", "han yu"], "accepted": false, "id": "1601.06862"}, "pdf": {"name": "1601.06862.pdf", "metadata": {"source": "CRF", "title": "A Survey on Artificial Intelligence and Data Mining for MOOCs", "authors": ["Simon Fauvel", "Han Yu"], "emails": [], "sections": [{"heading": null, "text": "Massive Open Online Courses (MOOCs) have become enormously popular in recent years. Thanks to MOOCs, millions of learners from around the world have taken thousands of high-quality courses free of charge. Putting together an excellent MOOCs ecosystem is a multidisciplinary endeavor that requires input from many different areas. Artificial intelligence (AI) and data mining (DM) are two such areas that have played a significant role in making MOOCs what they are today. Similarly, by leveraging the vast amounts of data generated by learners engaged in MOOCs, DM improves our understanding of the MOOCs ecosystem and enables MOOCs practitioners to take better courses. Similarly, AI, supported by DM, can greatly improve student experience and learning outcomes. In this survey paper, we first review the state of artificial intelligence and the data mining research applied to MOOCs, and then we can expand our use of MOOCs and MODM tools to enhance our understanding of the technology and tools."}, {"heading": "1. Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2. A Taxonomy of Artificial Intelligence and Data Mining", "text": "Before we delve into the actual research on AI and DM for MOOCs, it is useful to present a taxonomy of these two areas so that we can better understand which aspects of MOOCs research focuses on. AI is a broad area covering many different areas. We borrow the taxonomy from Russell and Norvig's reference book \"Artificial Intelligence: A Modern Approach.\" They define five main areas: problem solving: 1) search (search algorithms and solutions), 2) game theory and incentive mechanisms, and 3) limitation of satisfaction problems. Knowledge, reasoning and planning: 1) knowledge development (propositional logic, first order logic, inference), and 3) knowledge representation (ontologies, taxonomies, reasoning, reasoning, reasoning, reasoning and reasoning: uncertain knowledge and reasoning: 1) knowledge and reasoning under uncertainty (traditional and Bayesian probability statistics, decision-making)."}, {"heading": "3.1. Modelling Engagement and Learning Behaviours", "text": "If you want to improve MOOC outcomes for students, you first need to better understand how learners use MOOC resources and tools. Because of their openness, MOOCs attract large numbers of learners with diverse backgrounds and motivations to participate in a MOOC, resulting in many different learning patterns. A lot of research has already been done to better understand and categorize these different learning styles. We categorize the work according to the data used for the different learning categories."}, {"heading": "3.1.1. Based on activities on the MOOC platform", "text": "MOOC platforms collect all the activities that learners engage in down to the click level. This provides a wealth of data that can be used to extract learning styles. In [6], the authors use two activities for this purpose: viewing a lecture and submitting a task on credit. They then use a histogram approach to clustering learners. They developed a taxonomy of learning behavior that includes five types of engagement: spectator, solver, allrounder, collector, spectator."}, {"heading": "3.1.2. Based on performance", "text": "One way to categorize MOOC learning styles is to group learners according to their performance in a course (based on course exams). In [7], authors use learners \"performance in the sequence of course activities (videos and exercises) to group learners into three broad categories: lurkers, participants who do not complete the course, and participants who complete the course. The cluster method used is not specified and appears to be based on simple statistics."}, {"heading": "3.1.3. Based on forum behaviour", "text": "As mentioned above, most courses provide a forum where learners can interact with each other, providing a rich source of data that can be searched for patterns. In [8], first, a qualitative content analysis of forum posts is performed based on three dimensions: learning, dialog file and topic. Coding is done manually, followed by Bayesian Nonnegative Matrix Factorisation (BNMF) to extract learning communities based on the codes. Different learning communities are identified for two different sub-forums. In one sub-forum, four communities are identified: dedicated crowd promoters, discussion initiators, strategists and individualists. In the other, 5 communities are identified: instrumental help seekers, careful assessors, community builders, focused service providers and project support seekers. 3.1.4. Based on the stated intentions of the learners, most MOs are asked to fill out the pre-questionnaire, such as asking learners to fill out different categories."}, {"heading": "3.1.5. Summary", "text": "An important element is that each research project develops its own categorization of these learning styles based on their specific purpose (since the end goal is usually not simply to identify learning styles, but rather to derive other elements such as performance).Although this has a value (and it can be noted that these different learning styles are generally quite similar and potentially equivalent), the discrepancy prevents comparisons between the work, which is not ideal.3.2. Modelling, predicting and influencing learning performance After modelling engagement and learning behavior, the next logical step is to better understand what leads to learning performance (or, in other words, completing a MOOC).As mentioned in the introduction, one of the main problems with MOOCs at the moment is their low completion rate. Therefore, it should come as no surprise that a significant part of the research goes into modeling learning goals that are commonly used to influence and influence outcomes."}, {"heading": "3.2.1. Based on forum behaviour", "text": "Students tend to express their feelings about a MOOC through the course forum, which provides a good opportunity to check whether forum discussions correlate with performance. We select five recent studies that examine this aspect. These studies are summarized in Table 1. As can be noted, each study examines different aspects of forum behavior, and most evaluate the impact of such factors on drop-outs. Apart from [10], all studies identify variables in forum behavior that affect student performance."}, {"heading": "3.2.2. Based on activities on the MOOC platform", "text": "As mentioned before, MOOC platforms unobtrusively collect a large amount of data from learners \"interaction with the platform, and a large number of papers attempt to use this data to derive learners\" performance from it. We select 12 papers that are representative of this group, summarized in Table 2. Each paper looks at a different subset of variables extracted from activities on the MOOC platform, and the way in which performance is measured also differs from work to work. Due to the very different data, methods, and experimental arrangements, it is very difficult to compare works."}, {"heading": "3.2.3. Based on activities on the MOOC platform and background info", "text": "Each learner is different, and this is even more true for MOOCs. Therefore, considering the learners \"background can provide some insight into performance. [11] However, looking at the learners\" demographics alone is not enough, as it provides very limited explanatory and predictive information about performance in the MOOC. Instead, the learners \"background should be linked to the activities that the learners engage in on the platform; in a way, the background is used to improve learners\" behavior on the platform. We select two papers that take this approach; they are summarized in Table 3."}, {"heading": "3.2.4. Based on course and platform characteristics", "text": "Finally, some studies examine whether course and platform characteristics affect performance (i.e. elements that are independent of the content of the course).We review four such papers; they are summarized in Table 4. As can be seen, course characteristics such as maturity, difficulty, and workload correlate with performance, as well as platform characteristics correlate with performance. Gamification approaches also have the potential to influence performance in MOOCs."}, {"heading": "3.2.5. Summary", "text": "In this section, we have examined various methods for modelling, predicting and influencing learning outcomes, which is a critical challenge in improving MOOCs. The exact data sources used for this purpose are unlimited, as the various state-of-the-art methods described show, each using different data. However, it is important to note that most studies have correlational links (as opposed to causal ones), which means that the process leading to learning outcomes (and underlying explanations) in MOOCs is still poorly underestimated. Another point is that most studies rely on a very limited number of input variables to generate their models, especially compared to the amount of data available in MOOCs. Apart from a few exceptions, they test their models on very few MOOCs courses. Richer models that benefit from more data may have the potential to better predict and influence performance, although such models would usually have to be tested more on MOOCs to avoid overlapping courses."}, {"heading": "3.3.1. Based on assessed activities alone", "text": "One obvious strategy for measuring and modelling learners \"knowledge is to look at their assessed activities (homework, quizzes, exams, etc.) Most courses require learners to complete these activities in order to complete the course, so it is a natural strategy. We review three essays that apply this strategy, all three evaluate their model by creating a predictive model based on homework and testing it on exam problems. [12] Knowledge is measured using discrete knowledge components (KCs) defined by a specialist, each assessed problem is a KC, and a Bayesian knowledge-based method is used to model learners\" knowledge, showing that they can predict with good accuracy whether a learner will successfully solve an exam problem (i.e., whether they have acquired this knowledge during the course). This method requires expert input, which may not always be possible [13] which is studied in specific knowledge modelling."}, {"heading": "3.3.2. Based on activities on the MOOC platform as well as survey data", "text": "Another approach is not just to look at assessed activities, but to consider all the activities that learners engage in on the MOOC platform. Data from surveys before and after the course can also be used. We review five studies that apply this approach. In [15], knowledge is linked to the results of assessed skills based on the way these assessments are made. Authors then look at the number of activities that learners participate in, as well as the feedback from learners in a post-course survey. Regression analysis and classification are then used to find variables that relate to knowledge. A higher number of online activities is associated with more knowledge gain. Learners \"perceived usefulness (i.e. whether the course appears valuable to the learner) is also linked to better learning outcomes."}, {"heading": "3.3.3. Summary", "text": "Compared to measuring behavior and performance, less attention has been paid to measuring knowledge, probably because of the difficulty of the task. Most of the work can be considered preliminary and needs to be expanded further. This requires collaboration with education experts, as pure AI and DM are unlikely to produce good results in this task. For example, while DM can look at assessment results to derive insights, nothing says that these assessments are designed to measure knowledge gain."}, {"heading": "3.4. Summary", "text": "In this section, we have looked at the current work to better understand MOOC learners from three perspectives: 1) modelling engagement and learning behaviour, 2) modelling, predicting and influencing learning performance, and 3) modelling learning knowledge. At the end of this section, we provide a visual overview of the AI and DM tools used for each aspect, based on the taxonomy presented in Section 2. This is summarised in Table 5."}, {"heading": "4. Course Contents", "text": "Course content is the primary learning resource for learners. Because MOOC content is hosted online, they can benefit from AI and DM. In this section, we describe the most advanced AI and DM tools applied to course content and look at the different types of content available in MOOCs."}, {"heading": "4.1. Videos", "text": "Videos are undoubtedly the most prominent learning content available to MOOC learners. Most courses rely on videos to deliver content on a larger scale. We identify two main areas where AI and DM have been used to enhance MOOC videos: video pattern analysis and improved video navigation and viewing."}, {"heading": "4.1.1. DM for video pattern analysis", "text": "Given that millions of learners watch thousands of videos, there is a wealth of raw data about watching video activities. Certainly, interesting patterns can be discovered from these data. In [20], authors examine the characteristics of video production and correlate them with measures of engagement (how long learners watch a particular video and whether they try a post-video exercise).By using simple statistical tools, they can make a series of useful observations that can help instructors create more effective MOOC videos. [21] In addition, there is a strong correlation between video length and engagement: the longer the video, the higher the drop-out rate in the video (i.e. a learner stops watching the video).You can also find video breaking differences between watching it the first time and re-watching it."}, {"heading": "4.1.2. AI to facilitate video navigation and watching", "text": "One way to achieve this is to add AI tools to facilitate video navigation and observation. [23] aims to facilitate nonlinear video navigation by adding several tools to the video interface: a custom dynamic, time-conscious word cloud and a 2D timeline (to provide an overview of the concepts discussed in the video and allow quick navigation to those concepts), video pages (to enable visual search for information through the use of automatically extracted visual slides), and a video summary (to provide a summary of the video). [24] It automatically identifies and links related topics in MOOC videos and then creates an interface that allows learners to navigate to topics of interest. Its approach is based on blurred formal concept analysis and semantic technologies."}, {"heading": "4.2. Supporting Materials", "text": "MOOC videos are often complemented by supporting materials such as notes and reading materials, and AI can help organize and even generate such materials.For more flexible navigation and easier query, AI can be used to label and index materials, which is the approach presented in [25] where collaborative semantic filtering technologies are used to enrich MOOC materials with semantics, enabling collaborative labeling and indexing. Auxiliary materials can also be generated automatically, saving lecturers time. In [26], the authors present a method for automatically generating an interactive presentation using course video slides. The method is based on a model of topic structure analysis and enables topic summaries to be generated based on semantics."}, {"heading": "4.3. Formal and Informal Assessment", "text": "After consuming the informational materials, MOOC students are typically invited to apply the new knowledge through practical exercises, which can be assessed or not, and can be formal or informal depending on whether or not a particular exercise makes up part of the course grade. We focus our discussion on materials that are evaluated (i.e. there is a mechanism to check the accuracy of the solution and / or feedback offered to the student along the way or at the end), as this is an obvious area where AI and DM can contribute - and indeed, much research has already been done. Current methods of evaluating in most MOOC platforms include 1) automatically graded content with predefined answers (e.g. multiple choice questions, numerical questions, short answers with limited answers, etc.); 2) automatically graded content with open answers (e.g. essays, derivatives, programming); and 3) equivalent content with open or non-trivial answers."}, {"heading": "4.3.1. Auto-graded content with non-trivial answers", "text": "For this type of evaluation, research is always focused on domain-specific issues, since each domain has specific requirements."}, {"heading": "4.3.2. Peer grading and feedback", "text": "If automated prediction is not feasible, peer-prediction is usually the chosen alternative. In peer-prediction, the assessment of a learner is checked and evaluated by other learners. Usually, in addition to the grading, detailed feedback is also offered. However, a common challenge in peer-prediction is how to perform grade aggregation so that the result is as accurate and fair as possible. A number of papers have taken on this task. [35] Authors use a confidence graph to automatically combine scores from peer-benders and tutors. The confidence model is used to calculate how much weight each degree is given in making the final-prediction-prediction-predictions-predictions-. [36] Develop methods to improve both cardinal predictions-predictions-predictions-predictions-( absolute judgement) and ordinary (relative judgement )-predictions-peer-bending. On the one hand, they extend existing probable graphical models to improve the cardinal-prediction-prediction-prediction-predictions-use-predictions-idal-predictions-predictions-predictions-predictions-."}, {"heading": "4.3.3. Instructor support", "text": "Due to the very high ratios between learners and instructors in MOOCs, it is not realistic to expect instructors to manually evaluate assessments. However, there are reasons why instructors should look at assessments, for example, to enable them to better understand the gaps in learners \"knowledge or to provide targeted feedback on the scale. There are times when instructors need to provide some input. For example, some algorithms for automatically assessing open problems may require instructors to provide a series of tiered solutions. Without tools, these tasks become very difficult and inefficient due to the large number of entries. AI and DM can be used to assist instructors in this task. Clustering can be a powerful tool to quickly see what learners have understood, to identify patterns in solutions and provide feedback on the scale. In [40] and [41], the authors develop a cluster-based visualization tool that allows you to automatically see algorithms working without solving it."}, {"heading": "4.4. Adaptive Materials and Sequences", "text": "In this context, it is worth mentioning that this is an attempt to use the knowledge and skills acquired in the past to expand and expand, to expand, to expand, to expand, to expand and to expand."}, {"heading": "4.5. Content Authoring and Creation", "text": "As mentioned in the introduction, creating content for a MOOC can be a daunting and time-consuming task. AI and DM can help make this process more efficient, in different ways. First, AI can be used to automatically create content. We have described an example in Section 4.3.1: [32] can automatically create new exercises based on templates. Second, AI can be used to find and reuse existing content. There are already a large number of open learning resources on the Internet that provide a great opportunity to tap into when creating MOOCs. However, it is often difficult to find such resources, and integration can also prove challenging. Using taxonomies, ontologies, and semantic technologies can help. [52] presents the most important aspects needed to support the discovery, accessibility, visibility, and reuse of open resources in MOOCs."}, {"heading": "4.6. Summary", "text": "In this section, we analyzed the current AI and DM work for MOOC content. We looked at course videos, supporting materials, formal and informal assessments, adaptive materials and sequences, as well as the creation and creation of content. At the end of this section, we provide a visual overview of the AI and DM tools used for each aspect, based on the taxonomy presented in Section 2. This is summarized in Table 5."}, {"heading": "5. Community Building", "text": "The large community distinguishes MOOCs from other online learning systems. This is a valuable resource to use as it can improve the experience and learning outcomes of MOOC learners. In this section, we review AI and DM tools for the different types of community building components found in MOOCs."}, {"heading": "5.1. Asynchronous Tools", "text": "Forums are the most important asynchronous tool for interaction in the learning community and are used by most MOOC platforms (in fact, it is the only such tool we have identified in current MOOC platforms).Research on AI and DM for MOOC forums has focused on three main tasks: analyzing forum participation over time, understanding forum users, and improving forum well-being."}, {"heading": "5.1.1. Analysing forum involvement over time", "text": "It is also interesting to understand the trends in how learners participate in the course forum throughout the duration of a MOOC. It is also a first step to take measures to promote fruitful participation. Unsurprisingly, research finds that participation decreases over the course, similar to dropping out of a course. In [54], authors divide forum contributions into the common subcategories of the MOOC forum (e.g. study groups, lectures, tasks, etc.) and then perform a statistical analysis of the number of contributions in each subcategory as a function of the normalized course duration. They show an exponential decline in contributions in all subcategories. In [55], authors take a similar approach, albeit with slightly different subcategories. They also find a steep decline in all subcategories over the course. They also use linear regression to identify factors that help explain this decline. Interestingly, they find that active participation of lecturers does not correlate with an increase in discussion, but does not include an increase in the number of participants."}, {"heading": "5.1.2. Understanding forum users", "text": "Understanding trends is a good first step, but it is not enough to act on an individual level. To do so, we need to understand the forum users themselves. In [56], authors examine the contributions of MOOC \"superposters,\" i.e. the most active users of a course forum. Through statistical analysis, they show that high superposter activity correlates with high participation in the forum as a whole and health, and that superposter entries tend to be of high quality. Therefore, it would be valuable to encourage such postings. In [57], authors analyze on the basis of natural sociological studies to understand whether interactions in the forum are mainly about the content of courses or not. Their results showed that most threads are actually related to course content and as such have a value for the learning experience."}, {"heading": "5.1.3. Improving forum welfare", "text": "Most of the AI and DM work on this problem from different perspectives. The most popular strategies for improving the well-being in the forums are to identify and suggest relevant form contents for the learners. They often do this to demonstrate the effectiveness of their approach. In this context, the authors propose a classification of the forum positions, which are independent of the language. They can ensure that the individual theses are able to demonstrate the effectiveness of their approach."}, {"heading": "5.2. Synchronous Tools", "text": "While synchronous tools are less popular than asynchronous tools, they can also be found on some MOOC platforms. We distinguish between two types of synchronous tools: chatrooms and discussions in small groups."}, {"heading": "5.2.1. Chat rooms", "text": "Chat rooms can be considered an \"uncontrolled\" type of synchronous tool, in the sense that they allow all learners to interact with each other as long as they are online at the same time. As a rule, there are no restrictions on chat rooms. In [63], authors provide a chat room for different course offerings, allowing learners from different classes to interact with each other. [64] They used a chat room to complement the forum, but their conclusion was different. Their statistical analysis showed that there was no significant link between chat usage and variables such as grades, bonding, participation in the forum, or students \"sense of community."}, {"heading": "5.2.2. Small group discussions", "text": "Small group discussions, on the other hand, can be considered a \"controlled\" type of synchronous tool, as there are usually parameters that determine how such groups can come together. In [65] and [66], authors develop a system for small group video discussions. The groups are formed on the basis of teachers \"specific preferences, such as gender distribution and geographical distribution. Statistical analysis showed that learners spent more time with the tool than with the course requirement, which shows how much value they attach to it. In addition, learners in groups consisting of geographically distributed learners receive higher evaluation scores. Other similar systems have been proposed (e.g. [67]) but do not report results."}, {"heading": "5.3. Group Work", "text": "Group work is based on the concept of project-based learning and has proven to be an effective pedagogical approach [need ref]. In MOOCs, AI and DM can contribute to automatically grouping students in an effective way.In [68], authors develop constraint-based team building principles and algorithms so that productive, creative or learning teams can automatically form. They rely on project data and learning knowledge, personality and preferences. Experts have validated their approach for productive and learning teams, but not for creative teams. [69] also introduces a methodology for dynamic team building in MOOCs, using organizational team theory, social network analysis and machine learning. The overarching team building principles aim to connect people with each other who have different skills and do not have historically strong relationships."}, {"heading": "5.4. Peer Support", "text": "Finally, peer support (in the form of mentoring and tutoring) can play a role in building a sense of community in MOOCs. This type of support can be provided through both synchronous and asynchronous tools, and can be provided through tools that are fully designed for this purpose or not. Peer support, for example, can take place in forums, although such tools also have other goals. Instead, research focuses on supporting instructors for learners. Instructors have limited time, so tools are needed to simplify the process. [70] Authors developed a code-sharing tool that allows learners to easily share code with instructors and the problems they face. Instructors can then quickly visualize the problems and provide personalized feedback to the learner. Through this simplified approach, a limited number of instructors can effectively interact with other instructors who actually have a significant impact on any issues that affect them."}, {"heading": "5.5. Summary", "text": "In this section, we have reviewed the current state of play in building thriving communities in MOOCs, looking at the types of community-building components available in different MOOCs. We have examined asynchronous and synchronous tools, group work tools, and peer support tools. To conclude this section, we provide a visual overview of the AI and DM techniques used for each aspect, based on the taxonomy presented in Section 2. This is summarized in Table 5."}, {"heading": "6. Platform", "text": "Finally, we turn our attention to KI and DM research, which is applied to the broad MOOC platform framework. We identify two elements to discuss: 1) course recommendation and search and 2) student authentication and fraud detection."}, {"heading": "6.1. Course Recommendation and Search", "text": "Given the large and growing number of MOOC courses and platforms, learners have plenty to choose from when it comes to learning opportunities, but this can also be seen as a challenge - sometimes it can be overwhelming to search for courses and choose a platform. Often, learners know what they want to learn about and are looking for courses to meet their needs. Sometimes, learners may want to receive course recommendations for courses they find interesting and that would complement their current knowledge.6.1.1. Finding MOOCsAll major MOOC platforms provide an essential search engine that allows learners to search for courses. In addition, there are currently many MOOC aggregator websites that allow them to search for courses across multiple platforms. In general, MOOC aggregator websites offer advanced search capabilities."}, {"heading": "6.1.2. MOOC recommendation", "text": "Again, major MOOC platforms offer recommendations for new courses. Although they do not disclose their algorithms, it appears from personal experience to be based on a learner's past and profile. In [75], the authors examine how MOOC courses can be automatically recommended, using probabilistic topic models to derive curriculum content from college and MOOC curricula, and then using the marks of college learners to match them with MOOC courses to offer them curricula, and their preliminary results show that the recommended MOOCs correspond well with their equivalent college courses in content. In [76], the authors examine the concept of social referral, i.e. the learners recommend courses to others via their social network. Using correlation and regression analyses, they identify which MOOC attributes are most valuable for sharing on social media. They identify six such attributes and show that they can vary depending on the social media tool they use."}, {"heading": "6.2. Student Authentication and Cheating Detection", "text": "Major platforms already have authentication tools in place. Coursera and edX both use image recognition (i.e. comparing a webcam photo with a previously submitted state ID) to authenticate students. Coursera also uses typing patterns as a second layer of authentication. Some researchers have suggested alternative approaches to authentication. In [77], the authors propose a global user authentication model that can include a wide range of authentication modalities (e.g. turning test, biometrics, double verification, continuous user authentication based on MOOC activities, etc.) Your model can select any number of modalities and integrate them into a seamless framework. No outcomes are reported. It is unclear whether large MOOC platforms also use cheating tools at this point."}, {"heading": "6.3. Summary", "text": "In this section, we discussed the current state of work on improving MOOC platforms. We examined course recommendations and searches, as well as student authentication and cheating detection. At the end of this section, we provide a visual overview of the AI and DM techniques used for each aspect, based on the taxonomy presented in Section 2. This is summarized in Table 5."}, {"heading": "7. Key Trends and Future Research Directions", "text": "A lot of work remains to be done before MOOCs can reach their true potential, and both AI and data mining still play an important role. We now list a list of key trends and areas where new research and development could significantly improve MOOCs. 7.1. Redefining what \"open\" means in MOOCs can be viewed from the perspective outlined in the introduction - they are freely available to all learners. However, we would like to highlight other dimensions of openness that would also be very valuable. We have made the point earlier that creating MOOCs is a resource-intensive process for instructors. In this sense, MOOCs are not fully open to all instructors, as they must have the resources before they can embark on the MOOC journey."}, {"heading": "7.2. A more multidisciplinary approach to MOOC research", "text": "There is already a wide range of research on education for online paradigms and an even wider range of research on education in general. MOOC-AI and DM research has not used this well to date. Few tools that have proven effective in online learning systems (such as smart agents) have been tested or integrated into MOOCs. Learning analysis research has not been used, MOOCs researchers are mostly trying to develop their own analyses rather than starting from established research. We could cite more examples. Operation in silos will not allow MOOCs to reach their full potential. We believe that AI and DM should be used for MOOCs in conjunction with existing research in other related fields, for example AI and DM could be used to test education theories on a large scale and look for causal relationships rather than correlative ones. MOOCs could also be used to re-test research results from smaller online education systems to see if results are good."}, {"heading": "7.3. Complementing AI and DM with humans when necessary", "text": "An important problem in MOOC research is that most of the data is unlabeled, making it much more difficult to establish causal relationships in the data (as opposed to simple correlations); at the same time, monitored algorithms must rely on the small amount of labeled data (provided either by student surveys or researchers themselves - both approaches are expensive); examples of crowdsourcing include the ability to evaluate different parts of a video to help redesign the curriculum; gain insights into navigation behavior through short pop-up questions; collaborative material comments to label content; and much more. Crowdsourcing could also be used to reduce the workload on faculty; for example, we described in Section 4.5, where learners were used to develop clues about extending this approach to aspects of game theory by allowing other mechanisms for generating game outcomes (such as creating incentives)."}, {"heading": "7.4. From engagement to knowledge", "text": "As outlined in Section 3, the majority of MOOC research, which focuses on better understanding of learners, is about engagement, performance, and the way students navigate through MOOC platforms. Although this information can be valuable for a number of reasons, it is not enough to ensure that MOOCs are actually capable of imparting knowledge to students. A student can take a course without actually learning much (for example, if the material is too simple); an automatic assessment of the instrumental quality of MOOCs and identifying the criteria that lead to high-quality courses can be valuable. Currently, such assessments are done manually, which is not appropriate on MOOC scales. More targeted questions could also be explored. For example, when it comes to the usefulness of clues and tips for communicating knowledge, current results are contradictory, so new research is needed to shed some light on the issue."}, {"heading": "7.5. More personalisation", "text": "It is important that every learner has a fruitful experience in MOOCs. Previously, we have been committed to providing adaptive content to learners. Different learners do not learn in the same way, so it makes sense to offer everyone a different learning experience. This is probably the most obvious form of personalization in MOOCs, and more research should be done to improve it. As outlined in Section 4.4, current research is somewhat limited and usually requires significant human input to achieve adaptability. More automated approaches that are generalizable would provide high value for MOOCs. Other forms of personalization could be valuable. For example, the use of intelligent agents has the potential to help in all aspects of MOOCs. Such agents can alleviate the shortage of teachers by taking on some of their responsibilities."}, {"heading": "8. Conclusion", "text": "We showed how AI and DM are seamlessly embedded in virtually every aspect of the MOOC ecosystem as we know it today, and then gave an overview of the key trends and important future research findings in AI and DM for MOOCs so that they can reach their full potential. MOOCs are not a panacea; they are unlikely to replace formal education as we know it. Nevertheless, they are certainly part of the puzzle to make universal, lifelong education a reality. By giving learners from all over the world access to free, high-quality courses, we are giving people more opportunities, whether it is the chance to receive an education that they would otherwise not have access to, to acquire new skills to advance their careers, or simply to satisfy their thirst for new knowledge by learning from the environment that we do not all share, but from the environment that we all share."}, {"heading": "577-626, 2013.", "text": "[102] YZ Zhao, M Ma, CY Miao and TN Nguyen, \"An energy-efficient and low-latency MACprotocol with Adaptive Scheduling for multi-hop wireless sensor networks,\" ComputerCommunications 33 (12), 1452-1461, 2010. [103] J Weng, C Miao, A Goh, Z Shen, and R Gay, \"Trust-based agent community for collaborativerecommendation,\" In Proceedings of the 5th International Joint Conference on Autonomousagents and multi-agent systems (AAMAS '06), 1260-1262, 2016 [104] HJ Song, CY Miao, ZQ Shen, W Roel, DH Maja, C Francky, \"Design of fuzzy cognitive mapsusing neural networks for predicting chaotic time series,\" Neural Networks 23 (10), 1264 -"}, {"heading": "1275, 2010.", "text": "In fact, it is in such a way that we are able to go into another world, in which we go into another world, in which we go into another world, in which we go into another world, in which we go into another world, in which we go into another world, in which we go into another world, in which we go into another world, in which we do not go into another world, in which we go into another world, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we are not, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, we, in which we, we, in which we, we, we, in which we, we, we, in which we, we, in which we, we, in which we, we, in which we, we, in which we, we, in which we, we, in which we, we, in which we, we, in which we, we, in which we, in which we, we, in which we, we, we, in which we, we, in which, we, we, in which, we, we, in which, we, in which, we, we, in which, we, we, in which, we, we, in which, we, in which, we, we, in which, in which, we, we, we, in which, we, in which, we, in which, we, in which, we, in which, we, in which, we, in which, we, we, in which, we, in which, we, in which, we, we, in which, we, we, in which, we, we, in which, in which, we, in which, we, we, in which, we, we, in which, in which, we, we, in which, we, in which, we, in which, we, we, we, in which, in which, in which, we, we, we, we, we, in which, in which, in which, we,"}, {"heading": "1329-1330, 2009.", "text": "This year, it is at an all-time high in the history of the European Union."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Massive Open Online Courses (MOOCs) have gained tremendous popularity in the last few years. Thanks to<lb>MOOCs, millions of learners from all over the world have taken thousands of high-quality courses for free.<lb>Putting together an excellent MOOC ecosystem is a multidisciplinary endeavour that requires contributions<lb>from many different fields. Artificial intelligence (AI) and data mining (DM) are two such fields that have played<lb>a significant role in making MOOCs what they are today. By exploiting the vast amount of data generated by<lb>learners engaging in MOOCs, DM improves our understanding of the MOOC ecosystem and enables MOOC<lb>practitioners to deliver better courses. Similarly, AI, supported by DM, can greatly improve student experience<lb>and learning outcomes. In this survey paper, we first review the state-of-the-art artificial intelligence and data<lb>mining research applied to MOOCs, emphasising the use of AI and DM tools and techniques to improve<lb>student engagement, learning outcomes, and our understanding of the MOOC ecosystem. We then offer an<lb>overview of key trends and important research to carry out in the fields of AI and DM so that MOOCs can reach<lb>their full potential.<lb>", "creator": "Microsoft\u00ae Word 2010"}}}