{"id": "1601.06971", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jan-2016", "title": "Sentiment Analysis of Twitter Data: A Survey of Techniques", "abstract": "With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics,have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide a research on twitter data streams. We have also discussed general challenges and applications of Sentiment Analysis on Twitter", "histories": [["v1", "Tue, 26 Jan 2016 10:44:30 GMT  (363kb)", "http://arxiv.org/abs/1601.06971v1", "7 figures, 10 tables"], ["v2", "Tue, 16 Feb 2016 04:53:56 GMT  (0kb,I)", "http://arxiv.org/abs/1601.06971v2", "This paper has been withdrawn by the author due to a crucial changes in results section. It had some inconsistency in results. It requires major changes and revisions in methods discussed. There are some major errors in effects of methods discussed"], ["v3", "Fri, 22 Apr 2016 09:43:11 GMT  (701kb)", "http://arxiv.org/abs/1601.06971v3", "7 figures, 10 tables"]], "COMMENTS": "7 figures, 10 tables", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["vishal a kharde", "prof sheetal sonawane"], "accepted": false, "id": "1601.06971"}, "pdf": {"name": "1601.06971.pdf", "metadata": {"source": "CRF", "title": "Sentiment Analysis of Twitter Data :A Survey of Techniques", "authors": [], "emails": ["vishal.kharde@india.com;", "sssonawane@pict.edu"], "sections": [{"heading": null, "text": "In fact, it is as if most people who are able to express their opinion, that they are able to understand the things they do, do not understand what they do, but what they have to do in order to understand them. (...) It is as if people are able to understand the things. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. It is as if they do it. It is as if they do it. (...) It is as if they do it. It is as if they do it. It is as if they do it. It is if they do it. It is if they do it. It is if they do it. It is if they do it. It is if they do it. It is if they do it. It is if they do it. It is if they do it."}, {"heading": "II. SENTIMENT ANALYSIS", "text": "It is a process that defines the removal of attitudes, opinions, views and emotions from text, language, tweets and data sources by Natural Language Processing (NLP). Sentiment Analysis involves classifying opinions in tweets into categories such as \"positive\" or \"neutral\" tweets, also known as subjectivity analysis. [Sentiment Analysis] Sentiment Analytics is an example of how to translate opinions into texts into categories such as \"positive\" or \"neutral\" tweets. [Sentiment Analytics] is also referred to as subjectivity analysis, opinion environment and value extraction. [Sentiment] Sentiment, opinion, view and belief are used alternately, but there are differences between them. \u2022 Opinion: A conclusion that is open to dispute (because different experts have different opinions) \u2022 View: subjective opinion, conscious acceptance and intellectual overestimation \u2022 Sensation: Opinion that represents feelings that one feels oneself."}, {"heading": "B. Feature Extraction", "text": "In the method of feature extraction, we extract the aspects from the processed data set. Later, this aspect is used to calculate the positive and negative polarity in a sentence that is useful to determine the opinion of individuals using models such as Unikram, Bigram [18]. Machine learning techniques require the presentation of the key features of text or documents for processing, and these key features are considered to be feature vectors used for the classification task. Some examples reported in the literature are: 1. Words and their frequency: unigrams, bigrams and n-gram models with their frequency are considered to be features. There is more research on the use of word presence instead of frequencies to better describe this feature. Pang et al. [23] showed better results by using presence instead of frequencies. 2. Parts of language keywords parts such as adjectives, adjectives, and some groups of syncrates to better describe this feature."}, {"heading": "C. Training:", "text": "Supervised learning is an important technique for solving classification problems. The training of the classifier facilitates future predictions for unknown data."}, {"heading": "D. Classification:", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1. Naive Bayes:", "text": "It compares the content with the list of words to classify the documents into their proper category or class. Let the tweet and c * be a class assigned to d, where \"f\" is a \"feature,\" denotes the number of attributes (fi) with ni (d) and is present in d representing a tweet. Here, m does not represent any attributes. Parameters P (c) and P (f | c) are compressed by highest probability estimates, and smoothing is used for invisible attributes. To train and classify the use of Na\u00efve Baye's machine learning technique, we can use the attributes. Parameters P (c) and P (f | c) are compressed by highest probability estimates, and smoothing is used for invisible attributes."}, {"heading": "III. APPROACHES FOR SENTIMENT ANALYSIS", "text": "There are two main techniques for analyzing the mood of Twitter data:"}, {"heading": "A. Machine Learning Approaches", "text": "The machine learning-based approach uses classification techniques to classify text into classes. There are two main types of machine learning."}, {"heading": "1. Unsupervised learning:", "text": "It does not consist of one category, and they do not deliver the right goals at all, and therefore depend on clustering."}, {"heading": "2. Supervised learning:", "text": "The success of these two learning methods mainly depends on the selection and extraction of the specific characteristics used to detect sentiments. The machine learning approach applicable to sentiment analysis is mainly part of the supervised classification. In a machine learning method, two sets of data are required: 1. Training Set 2. Testset.A number of machine learning techniques were formulated to classify tweets into classes. Machine learning techniques such as Naive Bayes (NB), Maximum Entropy (ME) and Support Vector Machines (SVM) have achieved great successes in sentiment analysis. Machine learning begins with collecting training data sets. Sober we train a classifier on the training data. Once a supervised classification technique has been selected, an important decision is made to select the function. You can tell us how documents are represented \u2022 \u2022 \u2022 Selections \u2022 \u2022 Selections \u2022 \u2022 Selectives \u2022 \u2022 Selections \u2022 \u2022 Selections \u2022 \u2022 Selections \u2022 \u2022 Selections \u2022 \u2022 Selectives \u2022 \u2022 Selections \u2022 Selections \u2022 \u2022 Selectives \u2022 \u2022 Selections \u2022 Selections \u2022 \u2022 Selections \u2022 Selections \u2022 \u2022 Selections \u2022 Selections \u2022 \u2022 Selections \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 \u2022 Selectives \u2022 \u2022 Selectives \u2022 \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 \u2022 \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 \u2022 \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 Selectives \u2022 \u2022 Selectives \u2022"}, {"heading": "B. Lexicon-Based Approaches", "text": "Lexicon-based method [20] uses sentiment dictionaries with opinion words and compares them with the data used to determine polarity. It assigns sentiment scores to the opinion words that describe how positive, negative and objective the words contained in the dictionary are. Dictionary-based approaches are mainly based on a sentiment lexicon, i.e. a collection of well-known and precompiled sentiment terms, phrases and even idioms developed for traditional communication genres such as the Opinion Finder lexicon. There are two sub-classifications for this approach: 1. Dictionary-based: It is based on the use of terms (seeds) that are normally collected and commented manually. This sentence grows by searching for synonyms and antagonyms of a dictionary. An example of this dictionary is WordNet, which is used to develop a thesaurus called Word-Net, and cannot handle disadvantages."}, {"heading": "2. Corpus-Based:", "text": "The corpus-based approach aims to provide dictionaries that relate to a specific area. These dictionaries are generated from a set of seed terms generated by searching for related words using statistical or semantic techniques. \u2022 Statistical-based methods: Latent Semantic Analysis (LSA). \u2022 Methods based on semantic terms such as the use of synonyms and antagonyms, or relationships from thesaurus such as WordNet can also be an interesting solution.In line with performance measures such as precision and recall, we offer a comparative study of existing opinion-forming techniques, including machine learning, lexicon-based approaches, cross-domain and language approaches, as shown in Table 2."}, {"heading": "IV. SENTIMENT ANALYSIS TASKS", "text": "Emotional analysis is a challenging interdisciplinary task involving natural language processing, web mining and machine learning. It is a complex task and can be broken down into: \u2022 Subjectivity Classification \u2022 Sentiment Classification \u2022 Complimentary Taskso Object Holder Extraction o Object / Feature ExtractionFig.4 Sentiment Analysis Tasks"}, {"heading": "A . Subjectivity classification", "text": "Subjectivity classification is the task of classifying propositions as wilful or not wilful. Let S = {s1,.., sn} set a series of propositions in document D. The problem with subjectivity classification is to identify propositions that are used to represent opinions and other forms of subjectivity (subjective propositions set Ss), from propositions that are used to represent objective information (objective propositions set Sun), where Ss U Sun = S."}, {"heading": "B. Sentiment Classification", "text": "Once the task of determining whether a sentence is expressive is complete, we must determine the polarity of the sentence, i.e. whether it expresses a positive or negative opinion. Mood classification can be a binary classification (positive or negative), a multi-class classification (extremely negative, negative, neutral, positive or extremely positive), regression or ranking. Depending on the application of Mood Analysis, subtasks of opinion extraction and object feature extraction are treated as optional."}, {"heading": "C. Complimentary Tasks", "text": "\u2022 Opinion Holder Extraction It is the discovery of opinion holders or sources. The detection of opinion holders is to detect direct or indirect sources of opinion. \u2022 Object / Feature Extraction It is the discovery of the target unit."}, {"heading": "V. LEVELS OF SENTIMENT ANALYSIS", "text": "The tasks described in the previous section can be performed on several levels of granularity. Fig.5 Levels Of Sentiment AnalysisA. Document Level: It is a matter of marking individual documents with their sentiments. At the document level, the entire document is classified into either positive or negative classes. General Approach: Find the sentiment polarities of individual sentences or words and combine them to find the polarity of the document.Other Approaches: Complex linguistic phenomena such as co-reference resolution, pragmatics, etc. Different tasks involved are: \u2022 Task: Sentiment Classification of whole document \u2022 Classes: Positive, negative and \u2022 Assumption: Each document focuses on a single object (not true in discussion posts, blogs, etc.) and contains opinions from a single opinion holderB. Sentiment or Phrase Sentification Level: Sentiment Sentiment Sentiment Sentiment Sentiment Sentence deals with each sentence's analysis of its particular characteristics."}, {"heading": "D. Word Level:", "text": "Most recent work has used the previous polarity of words and phrases for mood classification at the sentence and document level. Word mood classification mainly uses adjectives as traits, but adverbs. The two methods of automatically annotating feelings at the word level are: (1) dictionary-based approaches (2) corpus-based approaches."}, {"heading": "VI. EVALUATION OF SENTIMENT CLASSIFICATION", "text": "The evolution of the mood classification can be evaluated on the basis of four indices, which are calculated as follows: Accuracy = (TP + TN) / (TP + TN + FP + FN) Precision = TP / (TP + FP) Recall = TP / (TP + FN) F1 = (2 \u00b7 Precision \u00b7 Recall) / (Precision + Recall), whereby TP, FN, FP and TN refer respectively to the number of true positive instances, the number of false negative instances, the number of false positive instances and the number of true negative instances as defined in Table 1."}, {"heading": "VII. RESULTS AND DISCUSSION", "text": "We used the Twitter dataset publicly provided by Stanford University. These marked datasets were analyzed using various methods of feature extraction. We used the framework in which the preprocessor is applied to the raw sentences for a better understanding. Furthermore, the various machine learning techniques train the dataset with feature vectors and then semantic analysis provides a large number of synonyms and similarities that allow the polarity of the content.Dataset description: Tensile data 45000 Negative 23514 Positive 21486 Test data 44832 Negative 22606 Positive 22226"}, {"heading": "A. Baseline Algorithm:", "text": "The basic algorithm used is Na\u00efve Bayes without pre-processed data and universal model. The following table shows the accuracy achieved for the basic algorithm at different quantities."}, {"heading": "10 0.46475731620", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50 0.533324411135", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100 0.54744379015", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "500 0.612375089222", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1000 0.652301927195", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5000 0.697403640257", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10000 0.712928265525", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "15000 0.717389364739", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "20000 0.722764989293", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "25000 0.729478943612", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "30000 0.729122055675", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "35000 0.73244557459", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "40000 0.733226266952", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "45000 0.736549785867", "text": "Below are the details of most informative features after the classifier was run on train data. Sad = True neg: pos = 37.6: 1.0 worst. = True neg: pos = 32.4: 1.0 crying = True neg: pos = 24.7: 1.0 fml = True neg: pos = 24.1: 1.0 injured = True neg: pos = 21.2: 1.0 terrible = True neg: pos = 21.1: 1.0ugh. = True neg: pos = 20.4: 1.0 terrible = True neg: pos = 20.4: 1.0 boo. = True neg: pos = 19.2: 1.0 cancelled = True neg: pos = 19.2: 1.0"}, {"heading": "B. Na\u00efve Bayes Algorithm:", "text": "Effect of Stopwords:. When Naive Bayes (Baseline) was executed, an accuracy of 73.65 percent was obtained, which is considered a baseline result. Next, the stopword was removed. When Stopwords were removed and Naive Bayes was executed, an accuracy of 74.56 percent was obtained. The following table shows the accuracy achieved for the Naive Bayes at various sizes, removing stopwords and using pre-processed data based on a universal model."}, {"heading": "10 0.522305496074", "text": "The results differ slightly, even with the linear SVC. This shows that stop words really affect predictions. An intuition in this respect stems from the fact that, given the short length of tweets, stop words such as and, while, before, after and so on are used. Therefore, the removal of stop words makes a big difference in terms of accuracy. Effect of Bigram: Bigram uses a combination of two words as a feature. Bigram effectively captures some features in the data that Unigram does not capture. Words such as \"not sad,\" \"not good\" for example, clearly indicate that the mood is negative. This effect can be clearly seen in the increase in accuracy from 74.56 (Unigram) to 76.44 percent, which is almost an increase of 2%."}, {"heading": "10 0.544990185582", "text": "The most informative features for Naive Bayes with Bigrams as features. (\"so,\" \"sad\") = True neg: pos = 55,2: 1,0 sad. = True neg: pos = 44,2: 1,0 bummed = True neg: pos = 33,8: 1,0 terrible = True neg: pos = 32,0: 1,0 (\"USERNAME,\" \"welcome\") = True neg: pos = 24,7: 1.0 died = True neg: pos = 24,3: 1,0 (\"miss,\" him \") = True neg: pos = 28,1: 1,0 sad = True neg: pos = 27,5: 1,0 (\" i, \"\" lost \") = True neg: pos = 24,7: 1.0 (\" miss, \"him\") = True neg: pos = 24,1: 1,0 effect of using Trigram:."}, {"heading": "10 0.486995895789", "text": "Fig.6 Graph Representing Different results received forNa\u00efve Bayes Algorithm.Table 8. Accuracy of Na\u00efve Bayes AlgorithmAlgorithm Accuracy Na\u00efve Bayes (unigram) 74.56 Na\u00efve Bayes (bigram) 76.44 Na\u00efve Bayes (trigram) 75.41"}, {"heading": "C. Support Vector Machine (SVM):", "text": "Unique effect: The following table shows the accuracy achieved for the SVM algorithm with a unique model for different quantities."}, {"heading": "10 0.525450571021", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10 0.500223054961", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D. Maximum Entropy:", "text": "In the Maximum Entropy Classifier, no assumptions are made regarding the relationship between the features. We achieved an accuracy of 74.93 percent with the universal model. All the features considered show that SVM exceeds Naive Bayes and Maximum Entropy in all cases. In particular, the feature combination of slang stop word removal and bigram yields the maximum accuracy of 77.73 with SVM. Maximum entropy model yields a consistent accuracy between Naive Bayes and SVM. Furthermore, it runs iteratively and takes a lot of time to run. Therefore, MaxEnt was not used for all feature combinations.Fig.7 Graph Representing Different results obtained for Na\u00efve Bayes Algorithm And Linear SVC (SVM)."}, {"heading": "VIII. CHALLENGES IN SENTIMENT ANALYSIS", "text": "Sentiment Analysis is a very challenging task. Below are some of the challenges [13] that Twitter's Sentiment Analysis faces."}, {"heading": "1. Identifying subjective portions of text:", "text": "The same word can be treated as subjective in one context, while it could be objective in another, making it difficult to identify the subjective parts of the text. For example: 1. The author's language was very coarse. 2. Crude oil is extracted from the seabed. The same word \"coarse\" is used as an opinion in the first sentence, while it is completely objective in the second sentence. 2. Associate sentiment with keywords: it is difficult to identify the source of these feelings in sentences with strong opinions. Therefore, associating it with a keyword or sentence is difficult. Every time I read \"Pride and Prejudice,\" I want to dig it up and hit it over the skull with her own shin. In this example, \"her\" refers to the character in the book \"Pride and Prejudice,\" which is not explicitly mentioned."}, {"heading": "9. Building a classifier for subjective vs. objective tweets.", "text": "We have focused mainly on the correct classification of positive and negative. We have not looked very closely at the classification of tweets with feelings and without feelings."}, {"heading": "10. Handling comparisons.", "text": "Example: \"IITs are better than most private colleges,\" the tweet would be considered positive for both IITs and private colleges that use the sack-of-words model, because it does not take into account the relationship to \"better.\" 11. Applying sentiment analysis to Facebook messages. Less work has been done on sentiment analysis of Facebook data, mainly due to various limitations imposed by Facebook graphics and security policies when accessing data. 12. Internationalization [16,17]. Current research focuses mainly on English content, but Twitter has many different users from all over the world."}, {"heading": "IX. APPLICATIONS OF SENTIMENT ANALYSIS", "text": "1. Applications to Review Websites: Nowadays, there is a variety of reviews and feedback on almost everything on the Internet, including product reviews, political feedback, comments on services, etc. Therefore, there is a need for a sentiment analysis system that can extract feelings about a particular product or service. It helps to provide feedback or ratings for the particular product, product, etc. This would serve the needs of both users and providers."}, {"heading": "2. Applications as a Sub-component Technology", "text": "A sentiment predictor system can also be useful for recommendation systems. The recommender system does not recommend elements that receive a lot of negative feedback or less ratings. In online communication, we come across offensive language and other negative elements, which can be easily identified by identifying a highly negative mood and acting accordingly."}, {"heading": "3. Applications in Business Intelligence", "text": "It has been observed that people nowadays tend to look at reviews of products online before buying them. And, for many companies, online opinion can make or break their product. Therefore, sentiment analysis plays an important role in companies. Companies also want to extract sentiment from online reviews to improve their products and hence their reputation."}, {"heading": "4. Applications across different Domains:", "text": "Studies in sociology and other fields have benefited from sentiment analysis, which identifies trends in human emotions, especially in social media."}, {"heading": "5. Applications In Smart Homes", "text": "Smart home is supposed to be the technology of the future. In the future, entire houses would be connected and people could control every part of the house with a tablet device. Lately, a lot of research has been done on the Internet of Things (IoT). Sentiment Analysis would also find its way into the IoT. For example, based on the current mood or emotion of the user, the house could change its environment to create a calming and peaceful environment. Sentiment Analysis can also be used in predicting trends. By tracking public views, important data on sales trends and customer satisfaction can be extracted."}, {"heading": "X. CONCLUSION", "text": "In this paper, we offer an overview and comparative study of existing opinion-forming techniques, including machine learning and lexicon-based approaches, as well as cross-domain and linguistic methods and some evaluation metrics. Research shows that machine learning methods, such as SVM and naive bayes, have the highest accuracy and can be considered basic learning methods, while lexicon-based methods are very effective in some cases, requiring little effort in human-labeled documents. We have also looked at the effects of various features on classification. We can conclude that the cleaner the data, the more accurate the outcomes can be obtained. The use of the Bigram model improves mood accuracy compared to other models. In the future, we can focus on the study that combines machine learning methods with the method of opinion lexicon to improve the accuracy of mood classification and adaptability to the diversity of domains and languages."}], "references": [{"title": "Twitter as a Corpus for Sentiment Analysis and Opinion Mining", "author": ["A.Pak", "P. Paroubek"], "venue": "In Proceedings of the Seventh Conference on International Language Resources and Evaluation,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Movassate, \u201cSentiment Analysis of User- Generated Twitter Updates using Various Classi_cation Techniques\",CS224N", "author": ["M.R. Parikh"], "venue": "Final Report,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Twitter Sentiment Classification Using Distant Supervision", "author": ["Go", "R. Bhayani", "L.Huang"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Robust Sentiment Detection on Twitter from Biased and Noisy Data", "author": ["L. Barbosa", "J. Feng"], "venue": "COLING 2010: Poster Volume,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Sentiment Knowledge Discovery in Twitter Streaming Data", "author": ["Bifet", "E. Frank"], "venue": "In Proceedings of the 13th International Conference on Discovery Science, Berlin,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Sentiment Analysis of Twitter Data", "author": ["Agarwal", "B. Xie", "I. Vovsha", "O. Rambow", "R. Passonneau"], "venue": "In Proceedings of the ACL 2011 Workshop on Languages", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Enhanced Sentiment Learning Using Twitter Hashtags and Smileys", "author": ["Dmitry Davidov", "Ari Rappoport"], "venue": "Coling 2010: Poster Volume pages 241{249,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Opinion Mining on Social Media Data\", IEEE 14th International Conference on Mobile Data Management, Milan, Italy, June 3 ", "author": ["Po-Wei Liang", "Bi-Ru Dai"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Citius: A Naive-Bayes Strategy for Sentiment Analysis on English Tweets", "author": ["Pablo Gamallo", "Marcos Garcia"], "venue": "8th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Sentiment Analysis in Twitter using Machine Learning Techniques", "author": ["M S Neethu", "R Rajashree"], "venue": "4th ICCCNT 2013,at Tiruchengode, India", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews,", "author": ["P.D. Turney"], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Ensemble of feature sets and classification algorithms for sentiment classification,", "author": ["R. Xia", "C. Zong", "S. Li"], "venue": "Information Sciences: an International Journal,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "TingWang, An effective approach to tweets opinion retrieval", "author": ["Zhunchen Luo", "Miles Osborne"], "venue": "Springer Journal onWorld WideWeb,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Adaptive cotraining SVM for sentiment classification on tweets", "author": ["S. Liu", "F. Li", "X. Cheng", "Shen"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management (pp. 2079-2088)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Cross-domain sentiment classification via spectral feature alignment", "author": ["J Pan S", "X Ni", "T Sun J"], "venue": "Proceedings of the 19th international conference on World wide web. ACM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Recursive deep models for semantic compositionality over a sentiment Treebank.", "author": ["Socher", "Richard"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Cross-lingual mixture model for sentiment classification.\" Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1.Association", "author": ["Meng", "Xinfan"], "venue": "Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Lexicon based methods for sentiment analysis", "author": ["M. Taboada", "J. Brooke", "M. Tofiloski", "K. Voll", "Stede"], "venue": "Computational linguistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Active learning for cross-domain sentiment classification", "author": ["S. Li", "Y. Xue", "Z. Wang", "Zhou"], "venue": "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence (pp", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Cross-Domain Sentiment Classification using a Sentiment Sensitive Thesaurus", "author": ["D. Bollegala", "D. Weir", "Carroll"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "42nd Meeting of the Association for Computational Linguistics[C]", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Pak and Paroubek(2010) [1] proposed a model to classify the tweets as objective, positive and negative.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "Parikh and Movassate(2009) [2] implemented two models, a Naive Bayes bigram model and a Maximum Entropy model to classify tweets.", "startOffset": 27, "endOffset": 30}, {"referenceID": 2, "context": "Huang (2009) [3] proposed a solution for sentiment analysis for twitter data by using distant supervision, in which their training data consisted of tweets with emoticons which served as noisy labels.", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "(2010) [4] designed a two phase automatic sentiment analysis method for classifying tweets.", "startOffset": 7, "endOffset": 10}, {"referenceID": 4, "context": "Bifet and Frank(2010) [5] used Twitter streaming data provided by Firehouse API , which gave all messages from every user which are publicly available in real-time.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "(2011)[6] developed a 3-way model for classifying sentiment into positive, negative and neutral classes.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": ",(2010) [7] proposed a approach to utilize Twitter user-defined hastags in tweets as a classification of sentiment type using punctuation, single words, n-grams and patterns as different feature types, which are then combined into a single feature vector for sentiment classification.", "startOffset": 8, "endOffset": 11}, {"referenceID": 7, "context": "(2014) [8] used Twitter API to collect twitter data.", "startOffset": 7, "endOffset": 10}, {"referenceID": 8, "context": "[9] presented variations of Naive Bayes classifiers for detecting polarity of English tweets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Turney et al [11] used bag-of-words method for sentiment analysis in which the relationships between words was not at all considered and a document is represented as just a collection of words.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "[13] used an ensemble framework for Sentiment Classification which is obtained by combining various feature sets and classification techniques.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] highlighted the challenges and an efficient techniques to mine opinions from Twitter tweets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Later this aspect are used to compute the positive and negative polarity in a sentence which is useful for determining the opinion of the individuals using models like unigram,bigram [18].", "startOffset": 183, "endOffset": 187}, {"referenceID": 20, "context": "[23] showed better results by using presence instead of frequencies.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "It is a probabilistic classifier and can learn the pattern of examining a set of documents that has been categorized [9].", "startOffset": 117, "endOffset": 120}, {"referenceID": 13, "context": "Support vector machine analyzes the data, define the decision boundaries and uses the kernels for computation which are performed in input space[15].", "startOffset": 144, "endOffset": 148}, {"referenceID": 17, "context": "Lexicon based method [20] uses sentiment dictionary with opinion words and match them with the data to determine polarity.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "40% Pang, Lee[23]", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "52% Liu[14]", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "70% Richard[18]", "startOffset": 11, "endOffset": 15}, {"referenceID": 17, "context": "Dictionary Amazon\u2019 s Mechani cal Turk --- Taboada[20]", "startOffset": 49, "endOffset": 53}, {"referenceID": 14, "context": "00% Wan,X[16]", "startOffset": 9, "endOffset": 13}, {"referenceID": 14, "context": "[16]", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Thesaurus Bollegala[22 ] SFA Pan S J[15]", "startOffset": 19, "endOffset": 24}, {"referenceID": 13, "context": "Thesaurus Bollegala[22 ] SFA Pan S J[15]", "startOffset": 36, "endOffset": 40}, {"referenceID": 11, "context": "Following are some of the challenges[13] faced in Sentiment Analysis of Twitter.", "startOffset": 36, "endOffset": 40}, {"referenceID": 14, "context": "Internationalization [16,17].", "startOffset": 21, "endOffset": 28}], "year": 2016, "abstractText": "With the advancement of web technology and its growth, there is a huge volume of data present in the web for internet users and a lot of data is generated too. Internet has become a platform for online learning, exchanging ideas and sharing opinions. Social networking sites like Twitter, Facebook, Google+ are rapidly gaining popularity as they allow people to share and express their views about topics,have discussion with different communities, or post messages across the world. There has been lot of work in the field of sentiment analysis of twitter data. This survey focuses mainly on sentiment analysis of twitter data which is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous and are either positive or negative, or neutral in some cases. In this paper, we provide a survey and a comparative analyses of existing techniques for opinion mining like machine learning and lexicon-based approaches, together with evaluation metrics. Using various machine learning algorithms like Naive Bayes, Max Entropy, and Support Vector Machine, we provide a research on twitter data streams. We have also discussed general challenges and applications of Sentiment Analysis on Twitter.", "creator": "Acrobat PDFMaker 11 for Word"}}}