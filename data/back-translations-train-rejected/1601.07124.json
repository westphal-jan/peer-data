{"id": "1601.07124", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jan-2016", "title": "LIA-RAG: a system based on graphs and divergence of probabilities applied to Speech-To-Text Summarization", "abstract": "This paper aims to introduces a new algorithm for automatic speech-to-text summarization based on statistical divergences of probabilities and graphs. The input is a text from speech conversations with noise, and the output a compact text summary. Our results, on the pilot task CCCS Multiling 2015 French corpus are very encouraging", "histories": [["v1", "Tue, 26 Jan 2016 18:19:00 GMT  (47kb,D)", "http://arxiv.org/abs/1601.07124v1", "7 pages, 2 figures, CCCS Multiling 2015 Workshop"]], "COMMENTS": "7 pages, 2 figures, CCCS Multiling 2015 Workshop", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["elvys linhares pontes", "juan-manuel torres-moreno", "r\\'ea carneiro linhares"], "accepted": false, "id": "1601.07124"}, "pdf": {"name": "1601.07124.pdf", "metadata": {"source": "CRF", "title": "LIA-RAG: a system based on graphs and divergence of probabilities applied to Speech-To-Text Summarization", "authors": ["Elvys Linhares Pontes", "Juan-Manuel Torres-Moreno", "Andr\u00e9a Carneiro Linhares"], "emails": ["@gmail.com", "@univ-avignon.fr", "andrea.linhares@ufc.br"], "sections": [{"heading": null, "text": "Keywords: Automatic Text Abstract, Jensen-Shannon Divergence of Probabilities, Speech-to-Text Abstract, Graph Model."}, {"heading": "1 Introduction", "text": "The manual analysis is impossible because it is necessary to analyze a huge number of people using this information in an available time. The summary is a short text with main ideas of the original text (Torres-Moreno, 2014) and reduces the reading time to analyze this data. Audio is widely used in daily life on the radio and on the Internet, in news, interviews and conversations. A call center conversation creates a lot of conversations every day. These centers has problems and tasks. It is important to have control over the topics discussed and the results that are achieved by the customers in these calls."}, {"heading": "2 Related Works", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "3 Modeling the problem", "text": "The proposed methods are based on a specific pre-processing of words, a weighting function of sentences and a bag-of-words model to represent the text content.This model uses K matrices represented by SK [m \u00b7 n] and constructs from K documents, where ma is the number of sentences and na is the number of different words in document a. The cell saij of the matrix represents the frequency of the word j in the sentence i (FPij) of document a. This phase was constructed using the libraries and algorithms of the Cortex summation system (Torres-Moreno et al., 2002; Torres-Moreno et al., 2001)."}, {"heading": "3.1 Jensen-Shannon divergence", "text": "We use Jensen-Shannon (JS) divergence to measure the similarity between propositions, and the divergence is then calculated between these two objects. JS divergence is symmetrical and provides a stable way to measure the difference between two distributions (Equation 2). DJS (P | | Q) = 12 x W [Pw log (2 x Pw Pw + Qw) + Qw log (2 x Qw Pw + Qw)]] (2) The JS divergence value ranges from [0 x +). It is closer to zero if the distributions are similar and they differ from each other in another case. In the case where there is a word missing in one sentence, a smooth (different weighting) is used to avoid values and to have a smoother distribution (Hiemstra, 2009).If a word Qw is in another case, then the number Q c is in a sentence, where the similarity is present in a proposition."}, {"heading": "3.2 Term Frequency-Inverse Sentence Frequency (TF-ISF)", "text": "One way to verify the original relevance of a word and sentence to the text is with the TF-ISF. This indicator is based on the frequency of the term in the text and is calculated by equating 4.tf isf (w) = tf (w) \u00b7 log (nnw) (4), where tf (w) is the frequency of the term w, n is the total number of documents, and nw is the number of documents containing the term w."}, {"heading": "4 The LIA-RAG system", "text": "In general, a text consists of several sentences with different themes. The text can be divided into several groups and each of them describes a step / idea in the text. If a group is large, then it is relevant to the text. It is possible to select the sentences of the largest group and to obtain the most relevant content.The main ideas of a text are usually analyzed and discussed several times. The vertices with a higher degree have more similar sentences and are then important for the text. However, it is not necessary to have many similar sentences in order to be a more relevant one. Re \u0301 sumeur Audio-texte a \u0432base de Graphes (RAG) is a synthesis system after sentence extraction that selects the main sentences of a text and uses post-processing to eliminate some errors and make the text more concise and compact."}, {"heading": "4.1 The RAG algorithm", "text": "RAG uses graph theory and divergence metrics to calculate similarity and group sentences. First, the system performs a filtering process to remove the parentheses, then it performs a process of segmentation, filtering and parentage to remove stopwords and reduce the words to their roots. RAG performs this pre-processing and matrix transformation based on (Torres-Moreno et al., 2001). It calculates the relevance of each sentence based on the TF-ISF metric (Eq.4) and removes the less relevant sentences. The system creates a graph that represents each vertex of a previously selected sentence, analyzes the text and models it as a sentence diagram (Vertices), and based on Eq.4, it calculates the similarity between sentences. If the similarity between two sentences is less than 0.16 (threshold reached by empirical testing), then the system generates an edge between them."}, {"heading": "4.2 LIA-RAG: RAG with a specific speech post-processing", "text": "The speech recognition process generates text that contains multiple grammatical problems (slang, slang, expressions, and speech recognition errors).A summary algorithm selects the relevant sentences, but the sentences may have some grammatical problems.Therefore, it is necessary to perform a treatment of this summary.The most important aspects analyzed in this process are: \u2022 slang, \u2022 language expressions, and \u2022 dates.The LIA-RAG system receives the summary as input. In this input, some speech expressions are used to connect ideas or concepts in oral conversations.The LIA-RAG removes these expressions because they are often mistranscribed (a source of interference).In addition, the system eliminates multiple etiquette and duplicate words. The system replaces some erroneous words with their correct form. Figure 2 shows the architecture of the LIA-RAG system."}, {"heading": "5 Results", "text": "The tests were carried out on a computer with an i5 @ 2.6 GHz processor and 4 GB of RAM running on a 64-bit GNU / Linux Debian operating system. RAG's algorithms were implemented using the Perl language. We used the French DECODA corpus (Bechet et et al., 2012), but the systems must generate textual summaries with the main idea of each conversation that belongs to the corpus. \"The topics of the conversation range from travel and appointment requests to lost and found calls to complaints (the calls were recorded during the strikes).\" (Favre et al., 2015) Each summary has 7% of the number of words in each conversation transcription. We compared LIA-RAG and RAG systems with two baseline systems (random and first lead basis). To evaluate the quality of the summaries, the CCCUS-oriented study used for Gisting Evaluation (ROUGE 2)."}, {"heading": "6 Conclusion and perspectives", "text": "The divergence of probabilities in a graph model for extracting key sentences in the French speech-text summary was very interesting. LIA-RAG uses very few language resources (stopwords and stem building) and has achieved good results. Nevertheless, the system is easily adaptable to other languages, with only a few changes in the pre-processing phase. An interesting perspective of this work is the use of TAGs to calculate the sentence score. Furthermore, it is necessary to improve post-processing to improve the quality of the final summary. Finally, checking the grammaticality and legibility of the extracted key sentences can help produce more realistic abstracts."}, {"heading": "Acknowledgments", "text": "This project was partly financed by a grant from FUNCAP-CE (Brazil)."}], "references": [{"title": "and Jason S", "author": ["Ming-Hong Bai", "Yu-Ming Hsieh", "Keh-Jiann Chen"], "venue": "Chang.", "citeRegEx": "Bai et al.2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Sentence fusion for multidocument news summarization", "author": ["Barzilay", "McKeown2005] Regina Barzilay", "Kathleen R. McKeown"], "venue": "Comput. Linguist.,", "citeRegEx": "Barzilay et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Barzilay et al\\.", "year": 2005}, {"title": "McKeown", "author": ["Regina Barzilay", "Kathleen R"], "venue": "and Michael Elhadad.", "citeRegEx": "Barzilay et al.1999", "shortCiteRegEx": null, "year": 1999}, {"title": "Renato De Mori", "author": ["Frederic Bechet", "Benjamin Maza", "Nicolas Bigouroux", "Thierry Bazillon", "Marc El-Beze"], "venue": "and Eric Arbillot.", "citeRegEx": "Bechet et al.2012", "shortCiteRegEx": null, "year": 2012}, {"title": "2015", "author": ["Benoit Favre", "Evgeny Stepanov", "J\u00e9r\u00e9my Trione", "Fr\u00e9d\u00e9ric B\u00e9chet", "Giuseppe Riccardi"], "venue": "Call centre conversation summarization: A pilot task at multiling", "citeRegEx": "Favre et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-sentence compression: Finding shortest paths in word graphs", "author": ["Katja Filippova"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "Filippova.,? \\Q2010\\E", "shortCiteRegEx": "Filippova.", "year": 2010}, {"title": "Jinguang Chen", "author": ["Tingting He", "Fang Li", "Wei Shao"], "venue": "and Liang Ma.", "citeRegEx": "He et al.2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Personalized multi-document summarization using n-gram topic model fusion", "author": ["Hennig", "Albayrak2010] L. Hennig", "S. Albayrak"], "venue": "In Proceedings of LREC\u201910,", "citeRegEx": "Hennig et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hennig et al\\.", "year": 2010}, {"title": "Probability smoothing", "author": ["D. Hiemstra"], "venue": "In Encyclopedia of Database Systems,", "citeRegEx": "Hiemstra.,? \\Q2009\\E", "shortCiteRegEx": "Hiemstra.", "year": 2009}, {"title": "Maria Luc\u0131\u0301a del Rosario", "author": ["Castro Jorge"], "venue": "and Thiago Alexandre Salgueiro Pardo.", "citeRegEx": "Jorge et al.2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin"], "venue": "In Proc. ACL workshop on Text Summarization Branches Out,", "citeRegEx": "Lin.,? \\Q2004\\E", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Juan-Manuel Torres-Moreno", "author": ["Andr\u00e9a Carneiro Linhares"], "venue": "and Javier Ramirez.", "citeRegEx": "Linhares et al.2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatically assessing machine summary content without a gold standard", "author": ["Louis", "Nenkova2013] Annie Louis", "Ani Nenkova"], "venue": "Computational Linguistics,", "citeRegEx": "Louis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Louis et al\\.", "year": 2013}, {"title": "The automatic creation of literature abstracts", "author": ["H.P. Luhn"], "venue": "IBM J. Res. Dev.,", "citeRegEx": "Luhn.,? \\Q1958\\E", "shortCiteRegEx": "Luhn.", "year": 1958}, {"title": "2005", "author": ["Kathleen Mckeown", "Julia Hirschberg", "Michel Galley", "Sameer Maskey"], "venue": "From text to speech summarization. In ICASSP.", "citeRegEx": "Mckeown et al.2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Steve Renals", "author": ["Gabriel Murray"], "venue": "and Jean Carletta.", "citeRegEx": "Murray et al.2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Methods for sentence compression", "author": ["E. Pitler"], "venue": "Technical report,", "citeRegEx": "Pitler.,? \\Q2010\\E", "shortCiteRegEx": "Pitler.", "year": 2010}, {"title": "Andr\u00e9a Carneiro Linhares", "author": ["Elvys Linhares Pontes"], "venue": "and Juan-Manuel Torres-Moreno.", "citeRegEx": "Pontes et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Juan-Manuel Torres-Moreno", "author": ["Elvys Linhares Pontes"], "venue": "and Andr\u00e9a Carneiro Linhares.", "citeRegEx": "Pontes et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Some experiments on clustering similar sentences", "author": ["Seno", "Mariadas Gra\u00e7as Volpe Nunes"], "venue": null, "citeRegEx": "Seno et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Seno et al\\.", "year": 2008}, {"title": "Um m\u00e9todo para a fus\u00e3o autom\u00e1tica de senten\u00e7as similares em portugu\u00eas", "author": ["Eloize Rossi Marques Seno"], "venue": "Ph.D. thesis, Instituto de Cie\u0302ncias Matema\u0301ticas e de Computac\u0327a\u0303o,", "citeRegEx": "Seno.,? \\Q2010\\E", "shortCiteRegEx": "Seno.", "year": 2010}, {"title": "Patricia Vel\u00e1zquez-Morales", "author": ["Juan-Manuel Torres-Moreno"], "venue": "and Jean-Guy Meunier.", "citeRegEx": "Torres.Moreno et al.2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Patricia Vel\u00e1zquez-Morales", "author": ["Juan-Manuel Torres-Moreno"], "venue": "and Jean-Guy Meunier.", "citeRegEx": "Torres.Moreno et al.2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Automatic Text Summarization", "author": ["Juan-Manuel Torres-Moreno"], "venue": null, "citeRegEx": "Torres.Moreno.,? \\Q2014\\E", "shortCiteRegEx": "Torres.Moreno.", "year": 2014}], "referenceMentions": [], "year": 2016, "abstractText": "This paper aims to introduces a new algorithm for automatic speech-to-text summarization based on statistical divergences of probabilities and graphs. The input is a text from speech conversations with noise, and the output a compact text summary. Our results, on the pilot task CCCS Multiling 2015 French corpus are very encouraging.", "creator": "LaTeX with hyperref package"}}}