{"id": "1601.07969", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jan-2016", "title": "Zipf's law is a consequence of coherent language production", "abstract": "The task of text segmentation, or 'chunking,' may occur at many levels in text analysis, depending on whether it is most beneficial to break it down by paragraphs of a book, sentences of a paragraph, etc. Here, we focus on a fine-grained segmentation task, which we refer to as text partitioning, where we apply methodologies to segment sentences or clauses into phrases, or lexical constructions of one or more words. In the past, we have explored (uniform) stochastic text partitioning---a process on the gaps between words whereby each space assumes one from a binary state of fixed (word binding) or broken (word separating) by some probability. In that work, we narrowly explored perhaps the most naive version of this process: random, or, uniform stochastic partitioning, where all word-word gaps are prescribed a uniformly-set breakage probability, q. Under this framework, the breakage probability is a tunable parameter, and was set to be pure-uniform: q = 1/2. In this work, we explore phrase frequency distributions under variation of the parameter q, and define non-uniform, or informed stochastic partitions, where q is a function of surrounding information. Using a crude but effective function for q, we go on to apply informed partitions to over 20,000 English texts from the Project Gutenberg eBooks database. In these analyses, we connect selection models to generate a notion of fit goodness for the 'bag-of-terms' (words or phrases) representations of texts, and find informed (phrase) partitions to be an improvement over the q = 1 (word) and q = 1/2 (phrase) partitions in most cases. This, together with the scalability of the methods proposed, suggests that the bag-of-phrases model should more often than not be implemented in place of the bag-of-words model, setting the stage for a paradigm shift in feature selection, which lies at the foundation of text analysis methodology.", "histories": [["v1", "Fri, 29 Jan 2016 02:39:56 GMT  (1437kb,D)", "http://arxiv.org/abs/1601.07969v1", "4 pages, 3 figures"], ["v2", "Fri, 5 Aug 2016 22:13:18 GMT  (988kb,D)", "http://arxiv.org/abs/1601.07969v2", "5 pages, 4 figures"]], "COMMENTS": "4 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jake ryland williams", "james p bagrow", "rew j reagan", "sharon e alajajian", "christopher m danforth", "peter sheridan dodds"], "accepted": false, "id": "1601.07969"}, "pdf": {"name": "1601.07969.pdf", "metadata": {"source": "CRF", "title": "Selection models of language production support informed text partitioning: an intuitive and practical, bag-of-phrases framework for text analysis", "authors": ["Jake Ryland Williams", "James P. Bagrow", "Andrew J. Reagan", "Sharon E. Alajajian", "Christopher M. Danforth", "Peter Sheridan Dodds"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of them will be able to play by the rules they have set themselves, and they will be able to play by the rules they have set themselves."}], "references": [{"title": "and P", "author": ["J.R. Williams", "P.R. Lessard", "S. Desu", "E.M. Clark", "J.P. Bagrow", "C.M. Danforth"], "venue": "S. Dodds, CoRR abs/1406.5181 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "and P", "author": ["J.R. Williams", "J.P. Bagrow", "C.M. Danforth"], "venue": "S. Dodds, CoRR ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Biometrika 42", "author": ["H.A. Simon"], "venue": "425 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1955}, {"title": "Human Behaviour and the Principle of Least", "author": ["G.K. Zipf"], "venue": "Effort (Addison-Wesley,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1949}, {"title": "Soviet Physics Doklady 10", "author": ["V.I. Levenshtein"], "venue": "707 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1966}], "referenceMentions": [{"referenceID": 0, "context": "In our previous work on text partitioning [1], and again in our study on the effects of text mixing [2], we have observed the relevance of the selection model proposed long ago by Simon [3].", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "In our previous work on text partitioning [1], and again in our study on the effects of text mixing [2], we have observed the relevance of the selection model proposed long ago by Simon [3].", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "In our previous work on text partitioning [1], and again in our study on the effects of text mixing [2], we have observed the relevance of the selection model proposed long ago by Simon [3].", "startOffset": 186, "endOffset": 189}, {"referenceID": 3, "context": "together with Zipf\u2019s law [4, 5], as the basis for a model of frequency data of text.", "startOffset": 25, "endOffset": 31}, {"referenceID": 1, "context": "As we have seen in [2], dependence can also be caused by mixing, where the rate of a word\u2019s occurrence varies in a (global) mixed text as one transitions from document to document.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "In our work on stochastic text partitioning [1] we proposed a simple mechanism for the fine-grained chunking of text into phrases.", "startOffset": 44, "endOffset": 47}, {"referenceID": 4, "context": ", by edit distances [8], and make repetitions like \u201cha ha\u201d or \u201cla la\u201d, etc.", "startOffset": 20, "endOffset": 23}, {"referenceID": 2, "context": "age: \u03b1 = N/M , from which it can be shown [3] that the scaling parameter emerges to be \u03b8mod = 1\u2212\u03b1.", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "edu [1] J.", "startOffset": 4, "endOffset": 7}, {"referenceID": 1, "context": "[2] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[8] V.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "Jake Ryland Williams, \u2217 James P. Bagrow, \u2020 Andrew J. Reagan, \u2021 Sharon E. Alajajian, \u00a7 Christopher M. Danforth, \u00b6 and Peter Sheridan Dodds \u2217\u2217 School of Information, University of California, Berkeley 102 South Hall #4600 Berkeley, CA 94720-4600. Department of Mathematics & Statistics, Vermont Complex Systems Center, Computational Story Lab, & the Vermont Advanced Computing Core, The University of Vermont, Burlington, VT 05401. (Dated: September 29, 2017)", "creator": "LaTeX with hyperref package"}}}