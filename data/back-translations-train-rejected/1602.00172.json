{"id": "1602.00172", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2016", "title": "Deep Learning For Smile Recognition", "abstract": "Inspired by recent successes of deep learning in computer vision, we propose a novel application of deep convolutional neural networks to facial expression recognition, in particular smile recognition. A smile recognition test accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, significantly outperforming existing approaches based on hand-crafted features with accuracies ranging from 65.55% to 79.67%. The novelty of this approach includes a comprehensive model selection of the architecture parameters, allowing to find an appropriate architecture for each expression such as smile. This is feasible because all experiments were run on a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations on a CPU.", "histories": [["v1", "Sat, 30 Jan 2016 23:59:04 GMT  (68kb,D)", "http://arxiv.org/abs/1602.00172v1", null], ["v2", "Tue, 25 Jul 2017 04:46:01 GMT  (68kb,D)", "http://arxiv.org/abs/1602.00172v2", "Proceedings of the 12th Conference on Uncertainty Modelling in Knowledge Engineering and Decision Making (FLINS 2016)"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["patrick o glauner"], "accepted": false, "id": "1602.00172"}, "pdf": {"name": "1602.00172.pdf", "metadata": {"source": "CRF", "title": "Deep Learning For Smile Recognition", "authors": ["Patrick O. Glauner"], "emails": ["patrick.glauner@uni.lu"], "sections": [{"heading": null, "text": "Deep Learning For Smile RecognitionPatrick O. GlaunerInterdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg2721 Luxembourg, Luxembourg E-Mail: patrick.glauner @ uni.lusnt.uni.luInspired by the recent successes of deep learning in computer vision, we propose a novel application of deep, revolutionary neural networks for facial expression recognition, in particular Smile Recognition. An accuracy of 99.45% of the Smile Recognition tests is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, which significantly exceeds existing approaches based on handmade features with accuracies ranging from 65.55% to 79.67%. The novelty of this approach includes a comprehensive model selection of architectural parameters that enables a suitable architecture to be found for any expression such as smile. This is feasible because all experiments were performed on a Tesla K40GPU Facial Facility, resulting in a factor of 10 over a Pgnition Facilitation;"}, {"heading": "1. Introduction", "text": "Neural networks have been making a comeback over the past decade under the term \"deep learning,\" training many hidden layers that allow complex hierarchies to be learned on their own, making them of particular interest to computer vision, where the description of characteristics has been a long-standing theme. During this period, many advances have been recorded, including new training methods and a paradigm shift from CPUs to GPUs. As a result, these advances enable training of more reliable models much faster, resulting in breakthroughs in signal processing, for example. Nevertheless, deep neural networks are not a miracle weapon and successful training is still heavily based on experimentation.The Facial Action Coding System (FACS) 1 is a system for taxonomizing any facial expression of a person by his or her appearance on the face. Activity units describe muscles or muscle groups in the face, are set or un-Xiv: 160 2.00 172v 1 [cs.V] January 30, 2016 and activation can be performed at different intensity levels."}, {"heading": "2. Deep neural networks", "text": "The formation of neural networks is difficult because their cost functions have many local minima. The more hidden layers, the more difficult the formation of neural networks is. Therefore, the training tends to converge to a local minimum, which leads to a poor generalization of the network. To overcome these problems, a variety of new concepts has been proposed in the literature, of which only a few can be mentioned in this chapter. Unsupervised pre-training methods, such as autoencoders8, also allow to initialize the weights well, in order to optimize them quickly through back propagation. Reflected linear units (ReLU) 7 and Dropout10 are new regulatory methods. The new training methods and other new concepts can also lead to significant improvements of flat neural networks with only a few hidden layers. Convolutionary neural networks (CNNs) were originally proposed by LeCun5 for the detection of hand-written numbers. A CNN consists of two layers: a network layer followed by an inner layer in a convolution layer."}, {"heading": "3. DISFA database", "text": "The Denver Intensity of Spontaneous Facial Action (DISFA) 6 database consists of 27 videos, each with 4844 images and a total of 130,788 images. The annotations of the action unit are at different intensity levels, which are ignored in the following experiments, and the action units are either set or not set. DISFA was set due to the high number of smiles, i.e. Action Unit 12. In detail, 30,792 action units were set, 82,176 images set one action unit (s), and 48,612 images did not set any action unit (s) at all. Fig. 1 contains an example image of DISFA. In the original work on DISFA6, multi-class SVMs were trained for the various levels 0-5 of the action unit. Test accuracies for the individual levels and for the problem of detecting the binary action unit are reported for three different handcrafted description techniques. In these three cases, accuracies of 65.55%, 72.94% for smiles are reported."}, {"heading": "4. Smile recognition", "text": "In the second stage, a regular neural network follows the convolutions in order to discriminate against the characteristics learned from the convolutions, starting from two units for a smile. In this aligned version, the detailed number of faces is cropped and provided with face-marking dots. Both models allow a limited field to be calculated to fit the mouth in all images. In the experiments, two inputs are used: the mouth and the face, which are scaled down to 85 x 69 and 128 x 104 pixels. Both inputs are used to assess whether the mouth alone is as expressive as or even more expressive than the entire face for smile recognition. The architecture of the network is as follows: the entered images are fed into a convolution comprising a revolutionary and a subsampling layer. The convolution can be followed by further convolutions to gradually become more invariant distortions in the input. In the second stage, a neural discriminate follows the convolutions to the convolutions."}, {"heading": "5. Conclusions and future work", "text": "Deep learning is a generic term for training neural networks with potentially many hidden layers using new training methods that allow complex functional hierarchies to be learned from data. Applied in particular to action unit detection and smile detection, a deep convolutionary neural network model with an overall accuracy of 99.45% clearly outperforms existing approaches, and the extensive model selection underpins the ability to find a suitable architecture for each action unit to maximize test accuracy. In the future, we will expand the model to include images from multiple databases and make predictions in sequences of images."}], "references": [{"title": "Facial Action Coding System: A Technique for the Measurement of Facial Movement", "author": ["P. Ekman", "W. Friesen"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1978}, {"title": "Deep Learning based FACS Action Unit Occurrence and Intensity Estimation", "author": ["A. Gudi"], "venue": "Vicarious Perception Technologies", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition", "author": ["G. Hinton"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "LeNet-5, convolutional neural networks. http://yann", "author": ["Y. LeCun"], "venue": "lecun.com/exdb/lenet/. Retrieved: April", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Disfa: A spontaneous facial action intensity database", "author": ["S.M. Mavadati", "M.H. Mahoor", "K. Bartlett", "P. Trinh", "J.F. Cohn"], "venue": "IEEE Transactions on Affective Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Rectified Linear Units Improve Restricted Boltzmann", "author": ["V. Nair", "G.E. Hinton"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Deep Learning Tutorial. http://deeplearning.stanford.edu/ tutorial", "author": ["A. Ng"], "venue": "Retrieved: February", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["N. Srivastava"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}], "referenceMentions": [], "year": 2016, "abstractText": "Inspired by recent successes of deep learning in computer vision, we propose a novel application of deep convolutional neural networks to facial expression recognition, in particular smile recognition. A smile recognition test accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, significantly outperforming existing approaches based on hand-crafted features with accuracies ranging from 65.55% to 79.67%. The novelty of this approach includes a comprehensive model selection of the architecture parameters, allowing to find an appropriate architecture for each expression such as smile. This is feasible because all experiments were run on a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations on a CPU.", "creator": "TeX"}}}