{"id": "1602.00269", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jan-2016", "title": "Numerical Atrribute Extraction from Clinical Texts", "abstract": "This paper describes about information extraction system, which is an extension of the system developed by team Hitachi for \"Disease/Disorder Template filling\" task organized by ShARe/CLEF eHealth Evolution Lab 2014. In this extension module we focus on extraction of numerical attributes and values from discharge summary records and associating correct relation between attributes and values. We solve the problem in two steps. First step is extraction of numerical attributes and values, which is developed as a Named Entity Recognition (NER) model using Stanford NLP libraries. Second step is correctly associating the attributes to values, which is developed as a relation extraction module in Apache cTAKES framework. We integrated Stanford NER model as cTAKES pipeline component and used in relation extraction module. Conditional Random Field (CRF) algorithm is used for NER and Support Vector Machines (SVM) for relation extraction. For attribute value relation extraction, we observe 95% accuracy using NER alone and combined accuracy of 87% with NER and SVM.", "histories": [["v1", "Sun, 31 Jan 2016 15:58:51 GMT  (123kb)", "http://arxiv.org/abs/1602.00269v1", "6 Pages"]], "COMMENTS": "6 Pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["sarath p r", "sunil mandhan", "yoshiki niwa"], "accepted": false, "id": "1602.00269"}, "pdf": {"name": "1602.00269.pdf", "metadata": {"source": "CRF", "title": "Numerical Atrribute Extraction from Clinical Texts", "authors": ["Sunil Mandhan"], "emails": ["sarath@hitachi.co.in", "sunilm@hitachi.co.in", "yoshiki.niwa.tx@hitachi.com"], "sections": [{"heading": null, "text": "Keywords: NLP, NER, relation extraction, information extraction, crf, svm"}, {"heading": "1 Introduction", "text": "Healthcare providers are increasingly using electronic health records (EHR) to improve the quality of care. Nowadays, EHR data and systems are accessible to patients (patient portals) and non-skilled clinical professionals. Clinical information within EHR systems is diverse and consists mainly of unstructured text (e.g. deletion summary). Non-skilled end-users find it difficult to interpret the documents, which contain many medical abbreviations and jargon [8]. Extracting and structuring commonly used information from unstructured clinical text allows end-users to quickly and promptly access patient health-related data. For example, information on vital signs, blood components, drugs, etc. is used in daily operations to understand the progress and treatment of the patient. Most of this information is in numerical form. In this paper, we describe the experiment, the developed system and the results of numerical attributes and associated values extracted from outlooks."}, {"heading": "1.1 Problem Description", "text": "The attributes derive from physical examinations and medical tests required for disease diagnosis and treatment procedures. Blood pressure and heart rate are, for example, the common and important numerical measures required for the diagnosis of almost all diseases. Table 1 shows some important numerical attributes that appear in the clinical diagnosis and are found in discharge summaries [8]. Example sentence: \"Your vital signs the following day had a heart rate of 66, blood pressure 120 / 63, breathing rate of 14, 100% at 5-liter nasal anulas oxygen saturation.\" Manual note: \"Your vital signs the following day had < Attribute-1 > heart rate < Attribute-1 > < < Value-1 > 66 < Value-1 >, < Attribute-2 > < / Attribute-3 > < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &lt"}, {"heading": "2 Related Work", "text": "There are many references for extracting different types of information from clinical documents. Drug identification, testing, procedures [2], symptoms, protein names [3], enzyme interactions, and protein structures [4] are some examples. Other types of information extraction include summarizing medical documents in a tabular format by identifying events, time, and negativity [9].I2B2 [5] and CLEF [6] are the notable workshops dealing with the organization of NLP research problems in the medical field. CLEF paper [1] uses SVM to extract relationships between disease and various characteristics of the disease such as body position, severity, etc. SVM was used when more than one body location was available to establish the relationship between which body location is associated with the disease."}, {"heading": "3 System Architecture", "text": "We solve the problem in two steps: The first step is the extraction of numerical attributes and values, which is developed as a named entity recognition model using Stanford NLP libraries; the second step is the correct mapping of these attributes to values, which is developed as a relation extraction module in the Apache cTAKES framework; we integrated the Stanford NER model as a cTAKES pipeline component and used it in the relation extractor; Figure 1 describes the architecture of the developed system; Section 3.1 describes algorithms and approaches to extracting attributes and values; and Section 3.2 describes the relation extraction module."}, {"heading": "3.1 Attributes and Values Extraction", "text": "We trained a model for extracting attributes and values from summaries of discharges using the Stanford library. Stanford NER provides a general implementation of linear sequence models for any task. [10] It can be trained for any task. 3.1.1 Tokenization: We observed Stanford's standard tokenization tokenizer (Penn Treebank tokenizer) splitting certain attribute words in the summary of discharges in an undesirable manner, as illustrated in an example below. Word Required Tokenization Output from Stanford TokenizationWBC-12.8 * # WBC, -, 12.08, *, # WBC-12,.8, *, # To avoid this problem, we applied regular pre-processing before tokenization input data. We replaced the hyphens in certain types of attributes with white space because they are harmless."}, {"heading": "3.2 Relation Extraction", "text": "SVM algorithm is used to establish the relationship between attribute and value. SVM is a distance-based method and has proven effective for relation extraction [1]. The basic idea of using SVM on relationships is to map a relationship into a attribute space and find the maximum margin hyperplane to separate two classes (related and unrelated). 3.2.1 Model Training: We trained SVM model for relation association using manually commented discharge summaries. The following features are used: 1. Part of speech 2. Punctuation 3. Phrase chunking (noun phrase, verb phrase, etc.) 4. Attribute presence trait: This function is used to check whether there is another attribute between an attribute and a value pair for which one relationship is predicted. Example: 1 + right DP impulse, 2 + left PT impulse is present in this example \"Pulse\" (pulse)."}, {"heading": "4 Results", "text": "This work is an extension of the previously developed system for the CLEF eHealth 2014 task and we are using the same data that served as the training corpus for CLEF eHealth 2014 task 2. In this work, we have only experimented with aggregated discharge data from the available data. We have divided the total of 136 data sets available for training and testing purposes into 100 and 36 data sets respectively."}, {"heading": "4.1 Evaluation Criteria", "text": "The comparison between values determined and true values in the actual data is strict. These values determined and true values are actually sequences of characters (i.e. strings) in a text. Thus, the rigorous evaluation literally compares values determined and true. For example, the true representation of attribute in the actual data is \"blood pressure\"; an attribute identified by the system should be identical to that attribute, i.e. \"blood pressure,\" in order to be marked as true. Other outputs, including matches in substrings such as \"blood\" or \"pressure,\" are marked as false."}, {"heading": "4.2 Evaluation results", "text": "In run 1 we used all the features described in section 3.1.2 and the first three features described in section 3.2.1. In run 2 we used all the features described in sections 3.1.2 and 3.2.1."}, {"heading": "4.3 Discussion", "text": "Another important finding was the distribution of positive and negative training samples. Training data must be explicitly verified for distribution. During the relation extraction tests, accuracy was very low and did not improve. Debugging the SVM tool, it was found that training data tended to be extremely negative, and this distortion led the SVM classifier to place each sample of test data in a negative category. After the distribution was corrected and the distortions corrected, results were dramatically improved."}, {"heading": "5 Conclusion", "text": "This report describes the approach, algorithms and tools used to build the numerical attribute and extract values. CRF algorithm was evaluated and proposed for the extraction of the attribute and values; it gave 0.95 in the F score. SVM algorithm was evaluated and proposed for the relation extraction between attribute and value, and it returned an F score of 0.87. Although the F score means good accuracy numbers, there is scope for further improvement through the development of new features, cross validation and method combinations (e.g. bagging and AdaBoost). This work can be extended to the problem of non-numerical extraction of attributes and values (e.g. dosage specifications such as \"small dose,\" \"sliding scale,\" etc., and frequency information such as \"two weeks,\" etc.)."}, {"heading": "6 References", "text": "1. Optimization of Apache cTAKES for Disease / Disorder Template Filling. Nishikant Johri, Yoshiki Niwa, Veera Raghavendra Chikka, http: / / ceur-ws.org / Vol-1180 / CLEF2014wneHealth-JohriEt2014.pdf 2. Son Doan and Hua Xu, Recognizing Medication related Entities in Hospital Discharge Summaries using Support Vector Machine, http: / / dl.acm.org / citation.cfm? id = 1944596 3. A System for Identifying Named Entities in Biomedical Text: How Results From Two Evaluations Reflect on Both the System and the Evaluations Shipra Dingare, Malvina Nissim, Jenny Finkel, Christopher Manning, Claire Grover, http: / nlp.stanford.u / papers."}], "references": [{"title": "Discovering body site and severity modifiers in clinical texts", "author": ["Dmitriy Dligach", "Steven Bethard", "Lee Becker", "Timothy Miller", "Guergana K Savova"], "venue": "J Am Med Inform Assoc", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Regular expression: ([a-z A-Z]|O3|O2|B12)(-)([0-9])", "startOffset": 45, "endOffset": 50}], "year": 2016, "abstractText": "This paper describes about information extraction system, which is an extension of the system developed by team Hitachi for \"Disease/Disorder Template filling\u201d task organized by ShARe/CLEF eHealth Evolution Lab 2014. In this extension module we focus on extraction of numerical attributes and values from discharge summary records and associating correct relation between attributes and values. We solve the problem in two steps. First step is extraction of numerical attributes and values, which is developed as a Named Entity Recognition (NER) model using Stanford NLP libraries. Second step is correctly associating the attributes to values, which is developed as a relation extraction module in Apache cTAKES framework. We integrated Stanford NER model as cTAKES pipeline component and used in relation extraction module. Conditional Random Field (CRF) algorithm is used for NER and Support Vector Machines (SVM) for relation extraction. For attribute value relation extraction, we observe 95 % accuracy using NER alone and combined accuracy of 87 % with NER and SVM.", "creator": "\u00fe\u00ff"}}}