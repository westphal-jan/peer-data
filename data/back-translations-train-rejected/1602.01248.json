{"id": "1602.01248", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2016", "title": "Using Hadoop for Large Scale Analysis on Twitter: A Technical Report", "abstract": "Sentiment analysis (or opinion mining) on Twitter data has attracted much attention recently. One of the system's key features, is the immediacy in communication with other users in an easy, user-friendly and fast way. Consequently, people tend to express their feelings freely, which makes Twitter an ideal source for accumulating a vast amount of opinions towards a wide diversity of topics. This amount of information offers huge potential and can be harnessed to receive the sentiment tendency towards these topics. However, since none can invest an infinite amount of time to read through these tweets, an automated decision making approach is necessary. Nevertheless, most existing solutions are limited in centralized environments only. Thus, they can only process at most a few thousand tweets. Such a sample, is not representative to define the sentiment polarity towards a topic due to the massive number of tweets published daily. In this paper, we go one step further and develop a novel method for sentiment learning in the MapReduce framework. Our algorithm exploits the hashtags and emoticons inside a tweet, as sentiment labels, and proceeds to a classification procedure of diverse sentiment types in a parallel and distributed manner. Moreover, we utilize Bloom filters to compact the storage size of intermediate data and boost the performance of our algorithm. Through an extensive experimental evaluation, we prove that our solution is efficient, robust and scalable and confirm the quality of our sentiment identification.", "histories": [["v1", "Wed, 3 Feb 2016 10:19:19 GMT  (260kb)", "http://arxiv.org/abs/1602.01248v1", "8 pages, 3 tables, 3 figures"]], "COMMENTS": "8 pages, 3 tables, 3 figures", "reviews": [], "SUBJECTS": "cs.DB cs.CL cs.IR", "authors": ["nikolaos nodarakis", "spyros sioutas", "athanasios tsakalidis", "giannis tzimas"], "accepted": false, "id": "1602.01248"}, "pdf": {"name": "1602.01248.pdf", "metadata": {"source": "CRF", "title": "Using Hadoop for Large Scale Analysis on Twitter: A Technical Report", "authors": ["Nikolaos Nodarakis", "Spyros Sioutas", "Athanasios Tsakalidis", "Giannis Tzimas"], "emails": ["nodarakis@ceid.upatras.gr", "sioutas@ionio.gr", "tsak@ceid.upatras.gr", "tzimas@cti.gr"], "sections": [{"heading": null, "text": "ar Xiv: 160 2.01 248v 1 [cs.D B"}, {"heading": "CCS Concepts", "text": "\u2022 Computing Methodologies \u2192 MapReduce algorithms; feature selection;"}, {"heading": "Keywords", "text": "Big Data; Bloom Filter; Classification; MapReduce; Hadoop; Mood Analysis; Text Mining; Twitter"}, {"heading": "1. INTRODUCTION", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "2. RELATED WORK", "text": "The domain of sentiment analysis or opinion mining, has5http: / / dictionary.reference.com / browse / emoticonbeen extensive in literature during decent years. Early studies focus on document level sentiments analysis about movie or product reviews [9, 25] and posts published on webpages or blogs [24]. Accordingly, much effort has been made to perform sentiment analysis at sentence level [20, 21, 23] examining the phrases and assigning each of them a sentiment polarity (positive, negative, neutral). A less studied area is topic-based sentiment analysis [12, 13] due to the difficulty of providing an adequate definition of the topic and integrating the sentiment factor into the opinion-mining task. Many researchers confront the problem of sentiment analysis through the use of machine learning approaches and / or natural language processing techniques. [16] In the three authors employ negative film machine ratings, or fictitious film learning techniques."}, {"heading": "3. MR-SAT APPROACH", "text": "We begin this section with a formal definition of the problem we are trying to solve, and then present the characteristics we use to classify feelings. Finally, we describe our algorithm using pseudo-codes and proceed with a step-by-step explanation of each pseudo-code. Let's assume a set of hashtags H = {h1, h2,.., hn} and a set of emoticons E = {em1, em2,..., emm} that are associated with a set of tweets T = {t1, t2,.., tl} (training set). Each tweet carries only one sentiment label of L = H. This means that tweets containing more than one label from L are not candidates for T, as their sentimental tendency can be vague. Given a set of unlabeled tweets TT = {tt1, tt2,.. (training set)."}, {"heading": "3.1 Feature Description", "text": "In this subsection, we detail the characteristics used to form classifier C. For each tweet, we combine its characteristics in a feature vector. We apply the characteristics proposed in [6] with some necessary modifications to avoid producing an excess number of calculations, thereby increasing the ongoing performance of our algorithms. 3.1.1 Word and N-Gram characteristics We treat each word in a tweet as a binary characteristic. Respectfully, we consider 2-5 consecutive words in a sentence as binary n-Gram characteristics. If f is a word or n-Gram characteristic, then wf = Nfcount (f) is the weight of f in the Surevector function, Nf is the number of times f appears in f, explaining the number of f in the Twitter corpus. Consequently, rare words and n-Grams have a higher weight than ordinary words, and we have a greater effect on the classification task."}, {"heading": "3.2 Bloom Filter Integration", "text": "Bloom filters are data structures proposed by Bloom [3] to verify element belonging in a given set. A bloom filter is a bit vector of length z, initially setting all bits to 0. We can map an element into the range between 0 and z \u2212 1 of the bloom filter by using q independent hash functions hf1, hf2,..., hfq. To store each element e in the bloom filter, e is encoded with the q hash functions, and all bits with index positions hfj (e) for 1 \u2264 j \u2264 q are set to 1.Bloom filters, which are very useful, and they compress the memory space required for the elements, since we can insert multiple objects within a bloom filter. As part of this work, we use bloom filters to transform our features into numbers, thereby reducing the space needed for storing our feature vectors to the genome space needed for storing the elements, since we can insert multiple objects within a bloom filter."}, {"heading": "3.3 kNN Classification Algorithm", "text": "To assign a sentiment label to each tweet in the TT, we apply a kNN strategy. First, we create the feature vectors for all tweets within the training and test data set (FT or FTT). Then, for each feature vector u in the FTT, we find all feature vectors in V FT that have at least one word / n gram / pattern feature in common with u (matching vectors). Then, we calculate the Euclidean distance d (u, v), HVV and retain the k-lowest values, creating Vk V and each vi Vk has an assigned sentiment label Li, 1 \u2264 k. Finally, we assign u the marking of the majority of vectors in Vk. If u does not have a matching vector, we assign a \"neutral\" label. We build C by adapting an already implemented AkNN classifier in MapReduce to meet the needs of the opinion research."}, {"heading": "3.4 Algorithmic Description", "text": "In this subsection, we describe in detail the sentiment classification process as implemented in the Hadoop framework.We adapt an already implemented MapReduce AkNN classifier to meet the needs of the opinion mining problem.Our approach consists of a series of four MapReduce jobs, each job providing input to the next tweet in the chain.These MapReduce jobs can be summarized as follows: 1) Feature Extraction Extraction: Extract the features from all tweets in T and TT, 2) Feature Vector Construction: Build the feature vectors FT or FTT, 3) Distance Computation: For each vector u-FTT you will find the appropriate vectors (if any) in FT, calculate the Euclidean distance d (u, v), 4) Feature Vector Construction: Build and Form Vk V, 4) Sentiment Classification Mr. Tsification Classification: SsiT: Assification Ta SentiT."}, {"heading": "MapReduce Job 1", "text": "1: Function Map (k1, v1) 2: t id = getId (v1); class = getClass (v1); 3: features = getFeatures (v1); 4: for all f features do / / BF is BloomFilter 5: output (BF (f.text), < t id, f.count, class >); 6: end for 7: end function8: function Reduce (k2, v2) 9: feature freq = 0; 10: for all v-v2 do 11: feature freq = feature freq + v.count; 12: end for 13: l = List {}; 14: for all v-v2 do 15: weight = v.count / feature freq; 16: add (newRecord id, weight, v.class); 17: end for 18: output (k2, l).end functionci is its class."}, {"heading": "MapReduce Job 2", "text": "1: Function Map (k1, v1) 2: f = getFeature (v1); t list = getTweetList (v1); 3: test = training = List {}; 4: for all t-list do 5: output (t.t id, < f, t.weight >); 6: if t.class 6 = NULL then 7: training.add (newRecord (t.t id, t.class)); 8: else 9: test.add (newRecord (t.t id, t.class)); 10: end if 11: end for 12: for all t-test do 13: output (t.t id, training); 14: end for 15: end function16: function reduction (k2, v2) 17: features = training = List {}; 18: for all v-v2 do 19: if v instanceOf List then 20: training.addAll (v); 21: end for 22: reduction of ecressi.add (v); 23: inend for this function (2: vid); 4: vend (v1)."}, {"heading": "4. EXPERIMENTAL EVALUATION", "text": "In this section, we conduct a series of experiments to evaluate the performance of our method from many different perspectives. Specifically, we take into account the effect of k and bloom filters, the spatial compression ratio, and the size of the dataset in the performance of our solution.Our cluster consists of 4 computing nodes (VMs), each of which has a specific size."}, {"heading": "MapReduce Job 3", "text": "1: function map (k1, v1) 2: t ids = getTrainingIds (v1) > 23: end 4GB for the 4GB system; v = getVector (v1); 3: t id = getId (v1); 4: if t ids.size () > 0 then 5: for all u t ids do 6: output (u.t id, < u.class, t id, v >); 7: end for 8: 9: output (t id, v); 10: end if 11: end function12: function Reduce (k2, v2) 13: ttv = List {}; tv = NULL 14: for all v v2 do 15: if v.class 6 = NULL then 16: ttv.add (v); 17: end if 11: end function12: function Reduce (k2, v2) 13: ttv = List {}; tv = list {}."}, {"heading": "MapReduce Job 4", "text": "1: function map (k1, v1) 2: t id = getTweetId (v1); val = getValue (v1); 3: output (t id, val); 4: end function5: function reduce (k2, v2) 6: l k = getKNN (v2); 7: H = HashMap < Class, Occurences > {}; 8: H = findClassOccur (l k); 9: max = 0; maxClass = null; 10: for all entries."}, {"heading": "4.1 Classification Performance", "text": "In this subsection, we measure the classification performance of our solution using the harmonic f-score. We use two experimental settings, the multi-class classification and the binary classification settings. As part of the multi-class classification, we try to assign a single label to each vector in the test set. In the binary classification experiments, we classify a set either as suitable for a particular label or as unsuitable for a certain feeling. As said and in [6], binary classification is a useful application and can be used as a filter that extracts mood sets from a corpus for further processing. We also test how performance is affected with and without the use of bloom filters. The value k for the NN classifier is equal to 50. The results of the experiments are shown in Table 1. In the case of binary classification, the results represent the average score for all classes. For multi-class classification, the results are not very good, but they are well above the random base class."}, {"heading": "4.2 Effect of k", "text": "In this subsection, we try to mitigate the problem of the low performance of our approach to binary classification without bloom filters. To achieve this, we measure the effect of k in the classification performance of the algorithm. We test four different configurations in which k filters are used. The same does not apply if we do not use bloom filters. Specifically, there is a big improvement in the binary classification performance for hashtags and emoticons and a smaller improvement in the case of multi-class classification. The conclusion of this experiment is that greater values of k can provide a big boost in the performance of the algorithm if it does not work with bloom filters."}, {"heading": "4.4 Running Time and Scalability", "text": "In this final experiment, we compare the runtime for the multi-class and binary classification and measure the scalability of our approach. First, we calculate the execution time in all cases to determine whether the bloom filters speed up or slow down the execution time of our algorithm. Results, when k = 50 is shown in Fig. 2, are worth noting that in most cases, the bloom filters slightly increase the execution time. Although we need more pre-processing time to produce the features with bloom filters, they ultimately pay off because the feature vector is smaller, resulting in lower I / O costs between the map and reduce tasks and, as a result, less processing time. Multi-class classification for emoticons is the only exception in our example. Finally, we examine the scalability of our approach. We test the scalability only for the multi-class classification case, which is much larger than the one that produced."}, {"heading": "5. CONCLUSIONS AND FUTURE WORK", "text": "As part of this work, we introduced a novel method of sentiment learning in the framework of MapReduce. Our algorithm uses the hashtags and emoticons within a tweet as a sentimental label and conducts a parallel and dispersed classification process of different types of sentiment. In addition, we use bloom filters to compact the storage size of intermediate data and increase the performance of our algorithm. We conduct a variety of experiments to test the efficiency of our method. Through this extensive experimental evaluation, we demonstrate that our system is efficient, robust and scalable. In the near future, we plan to expand and improve our system by exploring additional features that can be added to the feature vector and enhance the classification performance. In addition, we plan to explore further strategies for FH and FC boundaries to achieve a better separation between the HFWs and CWs. Finally, we plan to implement our solution in other platforms (e.g. to compare the savings performance and the current vaccination)."}, {"heading": "6. REFERENCES", "text": "[1] A. Agarwal, B. Xie, I. Vovsha, O. Rambow, andR. Passonneau. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media, pp. 30-38, 2011. [2] L. Barbosa and J. Feng. Robust sentiment detection on twitter from biased and noisy data. In Proceedings of the 23rd International Conference onComputational Linguistics, pp. 36-44, 2010. [3] B. H. Bloom. Space / Time trade-offs in coding with allowed errors. Commun. ACM, 13 (7): 422-426, 1970. Z. Cheng, J. Caverlee, and K. Lee. You are where you tweet: A content-based approach to geo-locating twitter users. In Proceedings of the 19th ACM International Conference on Information and Knowledge Management, pp. 759-768, 2010."}], "references": [{"title": "Sentiment analysis of twitter data", "author": ["A. Agarwal", "B. Xie", "I. Vovsha", "O. Rambow", "R. Passonneau"], "venue": "In Proceedings of the Workshop on Languages in Social Media,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Robust sentiment detection on twitter from biased and noisy data", "author": ["L. Barbosa", "J. Feng"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Space/time trade-offs in hash coding with allowable errors", "author": ["B.H. Bloom"], "venue": "Commun. ACM,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1970}, {"title": "You are where you tweet: A content-based approach to geo-locating twitter users", "author": ["Z. Cheng", "J. Caverlee", "K. Lee"], "venue": "In Proceedings of the 19th ACM International Conference on Information and Knowledge Management,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words", "author": ["D. Davidov", "A. Rappoport"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Enhanced sentiment learning using twitter hashtags and smileys", "author": ["D. Davidov", "O. Tsur", "A. Rappoport"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Mapreduce: Simplified data processing on large clusters", "author": ["J. Dean", "S. Ghemawat"], "venue": "In Proceedings of the 6th Symposium on Operating Systems Design and Implementation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "The utility of linguistic rules in opinion mining", "author": ["X. Ding", "B. Liu"], "venue": "In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Target-dependent twitter sentiment classification", "author": ["L. Jiang", "M. Yu", "M. Zhou", "X. Liu", "T. Zhao"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Towards building large-scale distributed systems for twitter sentiment analysis", "author": ["V.N. Khuc", "C. Shivade", "R. Ramnath", "J. Ramanathan"], "venue": "In Proceedings of the 27th Annual ACM Symposium on Applied Computing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Joint sentiment/topic model for sentiment analysis", "author": ["C. Lin", "Y. He"], "venue": "In Proceedings of the 18th ACM Conference on Information and Knowledge Management,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Topic sentiment mixture: Modeling facets and opinions in weblogs", "author": ["Q. Mei", "X. Ling", "M. Wondra", "H. Su", "C. Zhai"], "venue": "In Proceedings of the 16th International Conference on World Wide Web,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Sentiment analysis: Capturing favorability using natural language processing", "author": ["T. Nasukawa", "J. Yi"], "venue": "In Proceedings of the 2Nd International Conference on Knowledge Capture,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Efficient multidimensional aknn query processing in the cloud", "author": ["N. Nodarakis", "E. Pitoura", "S. Sioutas", "A.K. Tsakalidis", "D. Tsoumakos", "G. Tzimas"], "venue": "In Database and Expert Systems Applications - 25th International Conference,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Thumbs up?: Sentiment classification using machine learning techniques", "author": ["B. Pang", "L. Lee", "S. Vaithyanathan"], "venue": "In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Topic sentiment analysis in twitter: A graph-based hashtag sentiment classification approach", "author": ["X. Wang", "F. Wei", "X. Liu", "M. Zhou", "M. Zhang"], "venue": "In Proceedings of the 20th ACM International Conference on Information and Knowledge Management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Hadoop: The Definitive Guide, 3rd Edition", "author": ["T. White"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann"], "venue": "In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis", "author": ["T. Wilson", "J. Wiebe", "P. Hoffmann"], "venue": "Comput. Linguist.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Role of emoticons for multidimensional sentiment analysis of twitter", "author": ["Y. Yamamoto", "T. Kumamoto", "A. Nadamoto"], "venue": "In Proceedings of the 16th International Conference on Information Integration and Web-based Applications ", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences", "author": ["H. Yu", "V. Hatzivassiloglou"], "venue": "In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Opinion retrieval from blogs", "author": ["W. Zhang", "C. Yu", "W. Meng"], "venue": "In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Movie review mining and summarization", "author": ["L. Zhuang", "F. Jing", "X.-Y. Zhu"], "venue": "In Proceedings of the 15th ACM International Conference on Information and Knowledge Management,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}], "referenceMentions": [{"referenceID": 16, "context": "a topic and are extensively utilized in tweets [18].", "startOffset": 47, "endOffset": 51}, {"referenceID": 6, "context": "The most popular and notably efficient tool is the MapReduce [7] programming model, developed by Google, for processing large-scale data.", "startOffset": 61, "endOffset": 64}, {"referenceID": 17, "context": "In this paper, we propose MR-SAT: a novel MapReduce Algorithm for Big Data Sentiment Analysis on Twitter implemented in Hadoop [17, 19], the open source MapReduce implementation.", "startOffset": 127, "endOffset": 135}, {"referenceID": 8, "context": "Early studies focus on document level sentiment analysis concerning movie or product reviews [9, 25] and posts published on webpages or blogs [24].", "startOffset": 93, "endOffset": 100}, {"referenceID": 23, "context": "Early studies focus on document level sentiment analysis concerning movie or product reviews [9, 25] and posts published on webpages or blogs [24].", "startOffset": 93, "endOffset": 100}, {"referenceID": 22, "context": "Early studies focus on document level sentiment analysis concerning movie or product reviews [9, 25] and posts published on webpages or blogs [24].", "startOffset": 142, "endOffset": 146}, {"referenceID": 18, "context": "Respectively, many efforts have been made towards the sentence level sentiment analysis [20, 21, 23] which examines phrases and assigns to each one of them a sentiment polarity (positive, negative, neutral).", "startOffset": 88, "endOffset": 100}, {"referenceID": 19, "context": "Respectively, many efforts have been made towards the sentence level sentiment analysis [20, 21, 23] which examines phrases and assigns to each one of them a sentiment polarity (positive, negative, neutral).", "startOffset": 88, "endOffset": 100}, {"referenceID": 21, "context": "Respectively, many efforts have been made towards the sentence level sentiment analysis [20, 21, 23] which examines phrases and assigns to each one of them a sentiment polarity (positive, negative, neutral).", "startOffset": 88, "endOffset": 100}, {"referenceID": 11, "context": "A less investigated area is the topic-based sentiment analysis [12, 13] due to the difficulty to provide an adequate definition of topic and how to incorporate the sentiment factor into the opinion mining task.", "startOffset": 63, "endOffset": 71}, {"referenceID": 12, "context": "A less investigated area is the topic-based sentiment analysis [12, 13] due to the difficulty to provide an adequate definition of topic and how to incorporate the sentiment factor into the opinion mining task.", "startOffset": 63, "endOffset": 71}, {"referenceID": 15, "context": "In [16], the authors employ three machine learning techniques to classify movie reviews as positive or negative.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "On the other hand, Nasukawa and Yi [14] investigate the proper identification of semantic relationships between the sentiment expressions and the subject, in order to enhance the accuracy of sentiment analysis within webpages and online articles.", "startOffset": 35, "endOffset": 39}, {"referenceID": 7, "context": "Moreover, Ding and Liu [8] propose a set of linguistic rules together with a new opinion aggregation function to detect sentiment orientations in online product reviews.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "In [2], the authors propose a 2-step classifier that separates messages as subjective and objective, and further distinguishes the subjective tweets as positive or negative.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "[6] exploit the hashtags and smileys in tweets and evaluate the contribution of different features (e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1] explore the use of a tree kernel model for detecting sentiment orientation in tweets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "A three-step classifier is proposed in [10] that follows a targetdependent sentiment classification strategy by incorporating target-dependent features and taking related tweets into consideration.", "startOffset": 39, "endOffset": 43}, {"referenceID": 16, "context": "Moreover, the authors in [18] perform a topic sentiment analysis in Twitter data through a graph-based model.", "startOffset": 25, "endOffset": 29}, {"referenceID": 20, "context": "A more recent approach [22], investigates the role of emoticons for multidimensional sentiment analysis of Twitter by constructing a sentiment and emoticon lexicon.", "startOffset": 23, "endOffset": 27}, {"referenceID": 10, "context": "A large scale solution is presented in [11] where the authors build a sentiment lexicon and classify tweets using a MapReduce algorithm and a distributed database model.", "startOffset": 39, "endOffset": 43}, {"referenceID": 14, "context": "We implement C by adapting an existing MapReduce classification algorithm based on AkNN queries [15], as described in Subsection 3.", "startOffset": 96, "endOffset": 100}, {"referenceID": 5, "context": "We apply the features proposed in [6] with some necessary modifications to avoid the production of an exceeding amount of calculations, thus boosting the running performance of our algorithm.", "startOffset": 34, "endOffset": 37}, {"referenceID": 5, "context": "Unlike what authors propose in [6], we do not include the substituted meta-words for URLs, references and hashtags (URL, REF and TAG respectively) as word features (see and Section 4).", "startOffset": 31, "endOffset": 34}, {"referenceID": 4, "context": "This is the main feature type and we apply the pattern definitions given in [5] for automated pattern extractions.", "startOffset": 76, "endOffset": 79}, {"referenceID": 2, "context": "Bloom filters are data structures proposed by Bloom [3] for checking element membership in any given set.", "startOffset": 52, "endOffset": 55}, {"referenceID": 5, "context": "Moreover, during preprocessing we have replaced URL links, hashtags and references by URL/REF/TAG meta-words as stated in [6].", "startOffset": 122, "endOffset": 125}, {"referenceID": 3, "context": "Finally, we produced two nosentiment datasets by randomly sampling 72476 and 334377 tweets with no hashtags/emoticons from the dataset used in [4] and is publicly available.", "startOffset": 143, "endOffset": 146}, {"referenceID": 5, "context": "As stated and in [6], the binary classification is a useful application and can be used as a filter that extracts sentiment sentences from a corpus for further processing.", "startOffset": 17, "endOffset": 20}], "year": 2016, "abstractText": "Sentiment analysis (or opinion mining) on Twitter data has attracted much attention recently. One of the system\u2019s key features, is the immediacy in communication with other users in an easy, user-friendly and fast way. Consequently, people tend to express their feelings freely, which makes Twitter an ideal source for accumulating a vast amount of opinions towards a wide diversity of topics. This amount of information offers huge potential and can be harnessed to receive the sentiment tendency towards these topics. However, since none can invest an infinite amount of time to read through these tweets, an automated decision making approach is necessary. Nevertheless, most existing solutions are limited in centralized environments only. Thus, they can only process at most a few thousand tweets. Such a sample, is not representative to define the sentiment polarity towards a topic due to the massive number of tweets published daily. In this paper, we go one step further and develop a novel method for sentiment learning in theMapReduce framework. Our algorithm exploits the hashtags and emoticons inside a tweet, as sentiment labels, and proceeds to a classification procedure of diverse sentiment types in a parallel and distributed manner. Moreover, we utilize Bloom filters to compact the storage size of intermediate data and boost the performance of our algorithm. Through an extensive experimental evaluation, we prove that our solution is efficient, robust and scalable and confirm the quality of our sentiment identification.", "creator": "LaTeX with hyperref package"}}}