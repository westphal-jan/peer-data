{"id": "1602.01718", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2016", "title": "Formal Verification of Autonomous Vehicle Platooning", "abstract": "The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the new autonomous behaviors of the vehicles in these platoons must be certified. An appropriate representation for vehicle platooning is as a multi-agent system in which each agent captures the \"autonomous decisions\" carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the agent code does not scale to the full system and as the global verification technique does not capture the essential verification of autonomous behavior, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles.", "histories": [["v1", "Thu, 4 Feb 2016 15:50:22 GMT  (923kb,D)", "http://arxiv.org/abs/1602.01718v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.SE", "authors": ["maryam kamali", "louise a dennis", "owen mcaree", "michael fisher", "sandor m veres"], "accepted": false, "id": "1602.01718"}, "pdf": {"name": "1602.01718.pdf", "metadata": {"source": "CRF", "title": "Formal Verification of Autonomous Vehicle Platooning", "authors": ["Maryam Kamali", "Louise A. Dennis", "Owen McAree", "Michael Fisher", "Sandor M. Veres"], "emails": [], "sections": [{"heading": null, "text": "However, before such trains can be used, the new autonomous behaviours of the vehicles on these trains must be certified. To ensure that these autonomous decision-makers in the vehicles never breach safety requirements, we use formal verification. However, since the formal verification technology used to verify the agent code is not applied to the entire system and global verification technology does not capture the indispensable verification of autonomous behaviour, we use a combination of the two approaches. This mixed strategy allows us to verify security requirements not of just one model of the system, but of the actual agent code used to program the autonomous vehicles."}, {"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to survive on their own, without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in"}, {"heading": "2 Automotive Platoons", "text": "An automobile train, which enables road vehicles to travel as a group, is led by a vehicle driven by a professional driver [21, 22, 25]. The following vehicles, i.e. train members, are autonomously driven. These vehicles, equipped with low longitudinal (speed control) and transverse (steering control) systems, move in a train with predefined distances between them. Furthermore, V2V communication also connects the vehicles at agent level. The driving vehicle, through its agent, effectively performs coordination over the train: setting parameters, issuing certificates of accession and exit, etc. Each individual vehicle observes its environment and follows incoming commands from the management agent. In the following, we outline a series of high-level automobile train concepts and procedures, including joining and leaving a train [2]. In addition, the initial requirements for these procedures for the development of a safe and reliable reliability are explained."}, {"heading": "2.1 Joining the Platoon", "text": "A vehicle can join a train either at the end or in the middle, using different control strategies: \u2022 a vehicle that is not a member sends an application to the train driver expressing the intended position on the train; \u2022 if the vehicle has asked to join from behind, the guide sends an agreement back to vehicle X if the maximum train length has not been reached and the train is currently in normal operation; \u2022 if the vehicle requests to join before (for example) vehicle X and the maximum train length has not been reached, the guide sends a command for \"more space\" to vehicle X, and if the train driver is informed that sufficient distance has been created (about 17 metres), he sends an agreement back to the joining vehicle; \u2022 after receiving an agreement, the joining vehicle changes lanes (lane change is a manual procedure carried out by the driver); \u2022 once the vehicle is in the correct lane, its automatic speed control is activated and it approaches the vehicle that is approaching the preceding it sufficiently; \u2022 the vehicle approaching the vehicle is close to the preceding it."}, {"heading": "2.2 Leaving the Platoon", "text": "The exit procedure is: \u2022 a member of the train sends a withdrawal request to the train driver and waits for approval; \u2022 after receiving the \"exit permit,\" the vehicle increases its position in relation to the previous vehicle; \u2022 when the maximum distance is reached, the vehicle switches both its speed and steering to \"manual\" and changes lanes; and finally \u2022 the vehicle sends a confirmation to the driver. In order to comply with the agent-related decision elements of the car train, the following two requirements are required: 1. Except in emergencies, a vehicle may not leave the train without the permission of the driver. 2. If it is authorised to leave, the autonomous control must not be deactivated until the maximum permitted level of drunkenness has been reached."}, {"heading": "3 Agent-based Development of Automotive Platoon", "text": "The question is whether and to what extent it is actually a reactionary and reactionary act that takes place in the USA and Europe, and whether and to what extent it is actually a reactionary act that takes place in the USA, and whether and to what extent it is actually a reactionary act (and whether and to what extent it is a reactionary act). The question is only whether and to what extent it is a reactionary act (and whether it is actually a reactionary act) that is a reactionary act (and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is a reactionary act and whether or not it is a reactionary act and whether or not it is actually a reactionary act and whether or not it is a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is actually a reactionary act and whether or not it is a reactionary act and whether or not it is a reactionary act or not) that is a reactionary act and whether or not it is actually a reactionary act and whether or not it is a reactionary act or not."}, {"heading": "4 Verification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Verification Methodology", "text": "We can call the overall system: Comms AgentComms AgentComms AgentAgentThe agent is a GWENDOLEN program, the Comms component is a simple transmission protocol, and the vehicle represents the respective vehicle system with which we interact. This is typically an automotive control system along with environmental interactions, and we have validated this both in simulation (using the TORCS automotive simulation) and in physical vehicles (with Jaguar outdoor rover vehicles). We will not formally verify the vehicular control systems, relying instead on mathematical (usually analytical) techniques from the field of control systems. These control components, for example, with which we follow a prescribed path, are the avoidance of local obstacles that keep distance from the object, etc. We will review the autonomous decisions of the vehicles captured within the vehicle. \"Each agent represents the autonomous decision-maker within each autonomous vehicle decision-maker within each autonomous vehicle."}, {"heading": "V \u20321\u2016A1\u2016Comms12\u2032 |= \u03d5a implies V1\u2016A1\u2016Comms12 |= \u03d5a.", "text": "V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-V2-VV2-V2-VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV"}, {"heading": "4.2 Individual Agent Verification using AJPF", "text": "To check the properties of agents, we use the AJPF Model Checker on our agent, which is written in the GWENDOLEN language as above. For example, we check that:"}, {"heading": "If a vehicle never believes it has received confirmation from the leader,", "text": "This security property corresponds to the first requirement for joining a move, as specified in section 2, and can be defined as follows: 2 (G f3 platoon _ m (f3, f1) \u2192 Df3 perf (changing _ lane (1)) W Bf3 join _ agr (f3, f1))) (1) Here, Gx y stands for a target that agent x is trying to achieve, Bx z stands for a belief in agent x, and Dx k stands for an action k that agent x performs / does. Standard LTL operators, such as 2 for \"always in the future\" and W for \"unless.\" One instance above, in which the agent never receives an accession agreement, is: 2 (G f3 platoon _ m (f1, f1) & \u00ac B f3 join _ agr (f3, f1)) \u2192 2 \u00ac D f3 perf (changing _ lane (1)."}, {"heading": "If a vehicle ever sends a \u2018join\u2019 request to the leader and eventually receives the join agreement and it is not already in the correct lane, it initiates \u2018joining\u2019 the platoon by performing \u201cchanging lane\u201d.", "text": "(G f3 platoon _ m (f3, f1) & \u00ac B f3 changed _ lane & 2 ItD f3send (leader, tell, message (f3, 1, f1)) \u2192 \u2666 B f3 join _ agr (f3, f1)) \u2192 \u2666 D f3 perf (changing _ lane (1)) (3) Property 3 is a liveliness property that ensures that eventually (with the help of the LTL operator) the connection process initiates the alternating track control system as soon as its condition is met."}, {"heading": "If a vehicle never believes it has changed its lane, then it never switches to the automatic speed controller.", "text": "2 (G f3 platoon _ m (f3, f1) & \u00ac B f3 changed _ lane) \u2192 2 \u00ac D f3 perf (speed _ controller (1)) (4)"}, {"heading": "If a vehicle never believes it has received a confirmation from the leader, then it never switches to the automatic speed controller.", "text": "2 (G f3 platoon _ m (f3, f1) & \u00ac B f3 join _ agr (f3, f1)) \u2192 2 \u00ac D f3 perf (speed _ controller (1)) (5)"}, {"heading": "If a vehicle never believes it is sufficiently close to the preceding vehicle, it never switches to the automatic steering controller.", "text": "2 (G f3 platoon _ m (f3, f1) & B f3 join _ distance) \u2192 2 D f3 perf (steering _ controller (1)) (6)"}, {"heading": "If a vehicle never believes it has received a confirmation from the leader to leave the platoon, i.e., increasing spacing has been achieved, then it never disables its autonomous control.", "text": "Note that the leader will return the \"leave agreement\" to follows3 if and only if he has received a confirmation of follows3 indicating that the gap has been widened. 2 (G f3 leave _ platoon & \u00ac B f3 leave _ agr (f3)) \u2192 2 \u00ac D f3 perf (speed _ controller (0)) (7) It is important to remember that perceptions and communications brought to the agent are presented as internal beliefs. Therefore, the proliferation of faith operators is very important. The AJPF Program Model Checker examines all possible combinations of common beliefs and messages. To verify the global properties of multi-agent placement, we use a complementary approach. We manually generate a model of the entire system as time-automated and use the UJPF model to verify the relevant properties of multi-agent placement."}, {"heading": "4.3 Timed Automata Model of Automotive Platoons", "text": "In this context, it should be noted that this is a very complex matter."}, {"heading": "4.4 Multi-agent Platooning Verification using Uppaal", "text": "For the sake of simplicity, we analyze the global and temporal characteristics of a multi-agent train, which is ultimately composed of a leader and three vehicles (with three corresponding) agents. We assume that vehicles can always specify the distance and connection distance in time, i.e., 10 \u00b1 5, but are unable to change lanes in time, i.e., less than 20 + 5. Below, we first give examples of global real estate that include coordination between the leader and the trailers. Second, we evaluate the temporal requirements: the safe lower and upper limits for connecting and leaving activities. We observed that verifying these properties takes less than 3 seconds with Uppaal.If an agent ever obtains a connection agreement with the leader, then the previous agent has increased his space to his front agent. This property is formulated for Agent a3 as follows (A represents \"on all paths\"): A2 (3.rdy _ ch)."}, {"heading": "5 Concluding Remarks", "text": "There are several reasons why we need to do it. \u2022 There is no reason why we should not do it. \u2022 There is no reason why we should not do it. \u2022 There is no reason why we should not do it. \u2022 There is no reason why we should not do it. \u2022 There is no reason why we should not do it."}], "references": [{"title": "Model-Checking in Dense Real-time", "author": ["R. Alur", "C. Courcoubetis", "D. Dill"], "venue": "Information and Computation, 104:2\u201334", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Challenges of Platooning on Public Motorways", "author": ["C. Bergenhem", "Q. Huang", "A. Benmimoun", "T. Robinson"], "venue": "Proc. 17th World Congress on Intelligent Transport Systems, pages 1\u201312", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Using CSP\u2016b Components: Application to a Platoon of Vehicles", "author": ["S. Colin", "A. Lanoix", "O. Kouchnarenko", "J. Souqui\u00e8res"], "venue": "Formal Methods for Industrial Critical Systems, pages 103\u2013118. Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Gwendolen: A BDI Language for Verifiable Agents", "author": ["L.A. Dennis", "B. Farwer"], "venue": "AISB\u201908 Workshop on Logic and the Simulation of Interaction and Reasoning. AISB", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Declarative Abstractions for Agent Based Hybrid Control Systems", "author": ["L.A. Dennis", "M. Fisher", "N.K. Lincoln", "A. Lisitsa", "S.M. Veres"], "venue": "Declarative Agent Languages and Technologies VIII, volume 6619 of LNCS, pages 96\u2013111. Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Two-Stage Agent Program Verification", "author": ["L.A. Dennis", "M. Fisher", "M. Webster"], "venue": "Journal of Logic and Computation", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Model Checking Agent Programming Languages", "author": ["L.A. Dennis", "M. Fisher", "M.P. Webster", "R.H. Bordini"], "venue": "Automated Software Engineering, 19(1):5\u201363", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Compositional Verification for Reactive Multi-Agent Systems Applied to Platoon non Collision Verification", "author": ["M. El-Zaher", "J.-M. Contet", "P. Gruer", "F. Gechter", "A. Koukam"], "venue": "Stud. Inform. Univ., 10(3):119\u2013141", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Combining Temporal Logic Systems", "author": ["M. Finger", "D.M. Gabbay"], "venue": "Notre Dame Journal of Formal Logic, 37(2):204\u2013232", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "Verifying Autonomous Systems", "author": ["M. Fisher", "L.A. Dennis", "M. Webster"], "venue": "ACM Communications, 56(9):84\u201393", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Many-Dimensional Modal Logics: Theory and Applications", "author": ["D. Gabbay", "A. Kurucz", "F. Wolter", "M. Zakharyaschev"], "venue": "Number 148 in Studies in Logic and the Foundations of Mathematics. Elsevier Science", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "The Theory of Hybrid Automata", "author": ["T.A. Henzinger"], "venue": "Proc. 11th IEEE Symposium on Logic in Computer Science, pages 278\u2013. IEEE Computer Society", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1996}, {"title": "Proving Safety of Traffic Manoeuvres on Country Roads", "author": ["M. Hilscher", "S. Linker", "E.-R. Olderog"], "venue": "Z. Liu, J. Woodcock, and H. Zhu, editors, Theories of Programming and Formal Methods, volume 8051 of LNCS, pages 196\u2013212. Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Combined Model Checking for Temporal", "author": ["S. Konur", "M. Fisher", "S. Schewe"], "venue": "Probabilistic, and Real-time Logics. Theoretical Computer Science, 503:61\u201388", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining Modal Logics", "author": ["A. Kurucz"], "venue": "J. van Benthem, P. Blackburn, and F. Wolter, editors, Handbook of Modal Logic, volume 3 of Studies in Logic and Practical Reasoning, pages 869\u2013924. Elsevier", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Verified Hybrid Controllers for Automated Vehicles", "author": ["J. Lygeros", "D. Godbole", "S. Sastry"], "venue": "IEEE Trans. Automatic Control,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1998}, {"title": "Decision Procedures for Propositional Linear-Time Belief-Desire- Intention Logics", "author": ["A.S. Rao"], "venue": "Journal of Logic and Computation, 8(3):293\u2013342", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "An Abstract Architecture for Rational Agents", "author": ["A.S. Rao", "M.P. Georgeff"], "venue": "Proc. 3rd International Conference on Principles of Knowledge Representation and Reasoning (KR), pages 439\u2013449", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "PATH at 20 - History and Major Milestones", "author": ["S.E. Shladover"], "venue": "IEEE Transactions on Intelligent Transportation Systems, 8(4):584\u2013592", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Model Checking Programs", "author": ["W. Visser", "K. Havelund", "G. Brat", "S. Park", "F. Lerda"], "venue": "Automated Software Eng.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "KONVOI: Electronically coupled truck convoys", "author": ["M. Wille", "M. R\u00f6wenstrunk", "G. Debus"], "venue": "Human Factors for Assistance and Automation, pages 243\u2013 256", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "An Introduction to Multiagent Systems", "author": ["M. Wooldridge"], "venue": "John Wiley & Sons", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Foundations of Rational Agency", "author": ["M. Wooldridge", "A. Rao", "editors"], "venue": "Applied Logic Series. Kluwer Academic Publishers,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1999}], "referenceMentions": [{"referenceID": 11, "context": "Traditional approaches involve hybrid automata [12] in which the continuous aspects are encapsulated within discrete states, while discrete behaviours are expressed as transitions between these states.", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "In particular, the agent paradigm is used [26].", "startOffset": 42, "endOffset": 46}, {"referenceID": 22, "context": "In order to be able to reason about, and formally verify, the choices the system makes, we need a rational agent [27].", "startOffset": 113, "endOffset": 117}, {"referenceID": 9, "context": "This not only makes decisions, but has explicit representations of the reasons for making them, allowing us to describe not only what the autonomous system chooses to do, but why it makes particular choices [10].", "startOffset": 207, "endOffset": 211}, {"referenceID": 17, "context": "The Belief-Desire-Intention (BDI) model is one of the most widely used conceptual models not only for describing rational agents but for actually implementing them [20].", "startOffset": 164, "endOffset": 168}, {"referenceID": 3, "context": "In this paper, we use the GWENDOLEN programming language [4], developed for verifiable BDI-style programming,", "startOffset": 57, "endOffset": 60}, {"referenceID": 6, "context": "We verify properties of the rational agent code using the AJPF model-checker [7], one of the very few model-checkers able to cope with complex properties of BDI agents.", "startOffset": 77, "endOffset": 80}, {"referenceID": 18, "context": "An automotive platoon, enabling road vehicles to travel as a group, is led by a vehicle which is driven by a professional driver [21, 22, 25].", "startOffset": 129, "endOffset": 141}, {"referenceID": 20, "context": "An automotive platoon, enabling road vehicles to travel as a group, is led by a vehicle which is driven by a professional driver [21, 22, 25].", "startOffset": 129, "endOffset": 141}, {"referenceID": 1, "context": "In what follows, we outline the set of high-level automotive platoon concepts and procedures including how to join and leave a platoon [2].", "startOffset": 135, "endOffset": 138}, {"referenceID": 4, "context": "We employ a hybrid agent architecture based on [5] for each vehicle:", "startOffset": 47, "endOffset": 50}, {"referenceID": 3, "context": "Figure 1: GWENDOLEN [4] Syntax", "startOffset": 20, "endOffset": 23}, {"referenceID": 9, "context": "Instead, we will verify the autonomous decisions the vehicles make, captured within each vehicle\u2019s \u2018agent\u2019 [10].", "startOffset": 107, "endOffset": 111}, {"referenceID": 0, "context": "In both these cases we will use Timed Automata [1].", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "Thus, the formal structures that allow us to fully represent all the system above are quite complex, combining timed relations as well as relations for each of the belief and intention dimensions [1, 19].", "startOffset": 196, "endOffset": 203}, {"referenceID": 16, "context": "Thus, the formal structures that allow us to fully represent all the system above are quite complex, combining timed relations as well as relations for each of the belief and intention dimensions [1, 19].", "startOffset": 196, "endOffset": 203}, {"referenceID": 8, "context": "We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2 \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2 is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).", "startOffset": 83, "endOffset": 94}, {"referenceID": 10, "context": "We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2 \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2 is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).", "startOffset": 83, "endOffset": 94}, {"referenceID": 14, "context": "We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2 \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2 is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).", "startOffset": 83, "endOffset": 94}, {"referenceID": 10, "context": "The logic then interpreted over such structures combines [11] the syntax of timed temporal logic, for example\u2666\u22645finish , and the syntax of modal logics of belief, desire and intention, for example Bxstarted (i.", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "In principle, though very complex, we could provide all our convoy requirements in such a logic, build structures of the above form for our convoy implementation, and then develop a model-checking approach for this combination [15].", "startOffset": 227, "endOffset": 231}, {"referenceID": 19, "context": "Consequently, we utilise a program model checking [24] approach to assess the correctness of each agent program.", "startOffset": 50, "endOffset": 54}, {"referenceID": 6, "context": "For this formal verification of the agent\u2019s autonomous decisions, we use AJPF [7], an extension of the Java PathFinder (JPF) program model checker [14] for GWENDOLEN that allows verification of belief/intention properties.", "startOffset": 78, "endOffset": 81}, {"referenceID": 12, "context": "Safety verification of platooning in the contorl level was investigated extensively [13, 17].", "startOffset": 84, "endOffset": 92}, {"referenceID": 15, "context": "Safety verification of platooning in the contorl level was investigated extensively [13, 17].", "startOffset": 84, "endOffset": 92}, {"referenceID": 2, "context": "A combined verification approach for vehicle platooning is proposed in [3] where the system behaviour is specified in CSP and B formal methods.", "startOffset": 71, "endOffset": 74}, {"referenceID": 7, "context": "A compositional verification approach for vehicle platooning is introduced in [8] where feedback controllers and agent decision-making are mixed.", "startOffset": 78, "endOffset": 81}, {"referenceID": 5, "context": "In particular, we plan to use the AJPF framework to explore the agent code executions and so automatically build up the automaton that Uppaal can use [6].", "startOffset": 150, "endOffset": 153}], "year": 2016, "abstractText": "The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the new autonomous behaviours of the vehicles in these platoons must be certified. An appropriate representation for vehicle platooning is as a multiagent system in which each agent captures the \u201cautonomous decisions\u201d carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the agent code does not scale to the full system and as the global verification technique does not capture the essential verification of autonomous behaviour, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles.", "creator": "LaTeX with hyperref package"}}}