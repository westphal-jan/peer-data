{"id": "1602.02383", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2016", "title": "Disentangled Representations in Neural Models", "abstract": "Representation learning is the foundation for the recent success of neural network models. However, the distributed representations generated by neural networks are far from ideal. Due to their highly entangled nature, they are di cult to reuse and interpret, and they do a poor job of capturing the sparsity which is present in real- world transformations. In this paper, I describe methods for learning disentangled representations in the two domains of graphics and computation. These methods allow neural methods to learn representations which are easy to interpret and reuse, yet they incur little or no penalty to performance. In the Graphics section, I demonstrate the ability of these methods to infer the generating parameters of images and rerender those images under novel conditions. In the Computation section, I describe a model which is able to factorize a multitask learning problem into subtasks and which experiences no catastrophic forgetting. Together these techniques provide the tools to design a wide range of models that learn disentangled representations and better model the factors of variation in the real world.", "histories": [["v1", "Sun, 7 Feb 2016 15:32:30 GMT  (6312kb,D)", "http://arxiv.org/abs/1602.02383v1", "MIT Master's of Engineering thesis"]], "COMMENTS": "MIT Master's of Engineering thesis", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["william whitney"], "accepted": false, "id": "1602.02383"}, "pdf": {"name": "1602.02383.pdf", "metadata": {"source": "META", "title": "Disentangled Representations in Neural Models", "authors": ["William Whitney"], "emails": [], "sections": [{"heading": null, "text": ". Untangled. Representations in Neural Models. William Whitney. S. B., Massachusetts Institute of Technology (2013). Submitted to the Department of Electrical Engineering and Computer Sciences for partial fulfillment of the requirements for the degree of Master of Engineering in Computer Science and Engineeringat the MASSACHUSETTS INSTITUTE OF TECHNOLOGYFebruary 2016. \u00a9 William Whitney, MMXVI. All rights reserved. The author hereby grants MIT permission to reproduce and distribute this doctoral thesis in whole or in part in any medium."}, {"heading": "Acknowledgments", "text": "I thank my friend Benjamin, who is my joy. She lets me see my work with new eyes. I thank Tejas Kulkarni for his mentorship and friendship. He was my gateway into this world and a strong guiding influence, and without him I would not be here. I thank Josh Tenenbaum for his guidance. He made me think about the most basic problems. I thank my parents for their constant love and support. They made me like this, so please address any complaints to them. I thank Thomas Vetter for accessing the Basel Face Model. I am grateful for the support of the MIT Center for Brains, Minds, and Machines (BMM)."}, {"heading": "1 Introduction 12", "text": "1.1 Overview of documents................................... 13"}, {"heading": "2 Desiderata for representations 14", "text": "2.1 Untangled..........................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "3 Disentanglement in Vision 18", "text": "3.1. Introduction......................................................................... 203.3 Model..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "4 Disentanglement in Computation 36", "text": "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "5 Discussion 52", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 DC-IGN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52", "text": "In fact, most of them will be able to move to another world in which they will be able to move."}, {"heading": "1. Introduction", "text": "Representation is one of the most fundamental problems in machine learning. It is based on areas as diverse as vision, speech recognition, natural language processing, amplification learning, and graphics, but the question of what constitutes good representation is deceptively complex. On the one hand, we want representations that are well suited to tasks in the real world. On the other hand, we want to be able to interpret these representations, and they should be useful for tasks that go beyond the explicit ones in their original drafts. Currently, representations come in two varieties: those that are designed and those that are learned from data. Designed representations can perfectly match our desire for structured reuse and interpretation, while learned representations do not require expert knowledge that outperforms designed features on virtually any task that has sufficient data. This tension has been the source of great debate in the community. Clearly, a representation that shows some factorizable structures that can be easily reused for a new task, or one that can be reused for a new one."}, {"heading": "1.1 Document overview", "text": "The next chapter deals with various criteria for assessing the quality of a presentation. In the following two chapters, I deal with graphics and computer program representations based on these criteria. Each chapter begins with an overview of the problems in the field and related work, then moves on to a description of the specific problem I am addressing, my methods and the results. In the last chapter, I discuss the importance of this work for the field and promising directions for further research."}, {"heading": "2. Desiderata for representations", "text": "When assessing representation, it is valuable to have clear objectives; several of the objectives mentioned here overlap considerably, and to a certain extent, a representation perfectly aligned with one can automatically fulfil the other, but each of them has a clear benefit, and its importance must be taken into account in relation to these advantages."}, {"heading": "2.1 Disentangled", "text": "A representation that is untangled for a particular dataset is one that is more sparse than the transformations contained in those data (Bengio, Courville, and Vincent 2013). For example, a representation that explicitly shows whether the light is on or not is more untangling than a representation that consists of raw pixels, because for the usual transformation of the tilt of the light switch, the first representation changes only in that one dimension (light on or off), while the second changes in each individual dimension (pixel). Untangling a representation implies that it factorises some latent cause or cause of the variation. If there are two causes for the transformations in the data that do not always occur together and that can be distinguished, a maximally untangled representation will have a structure that separates those causes."}, {"heading": "2.2 Interpretable", "text": "A person should be able to predict how changes in the source domain would affect the representation domain, and vice versa. In a graphics engine, on the other hand, it is easy for a person to predict things like \"What would the image (source domain) look like if I changed the angle of that chair (representation domain) by 90 degrees?\" By contrast, in the representation of a classically trained autoencoder, it is virtually impossible for a person to visualize the image that is being generated."}, {"heading": "2.3 Performant", "text": "A powerful representation of a task contains the information required to perform this task well. If the task is to determine whether or not a dog is in a room, a representation consisting of a photo of the room would be less powerful than a 3D voxel model of the room, which would be less powerful than a single binary bit representing whether or not there is a dog."}, {"heading": "2.4 Reusable", "text": "A reusable representation is one that is suitable for many tasks in the same area. To continue the example above, a 3D voxel representation of a room is more reusable than one that indicates whether the room contains a dog or not. Somewhere in between would be a representation consisting of the facts: \u2022 Is there an animal? \u2022 Is it furry? \u2022 How big is it? \u2022 What color is it? This representation could solve the problem of whether the room is likely to contain a dog or not, and also answer the question of whether the room contains a gorilla or a whale or not. However, the tasks it can solve are a strict subset of voxel representation that could also solve problems such as \"Where is the couch?\""}, {"heading": "2.5 Compact", "text": "Compactness may not seem inherently important; it is typically irrelevant when the representation of an image takes up one or two megabytes. However, compactness provides a very valuable obsessive function; one could build a weather prediction model that represents the state of the world down to the last butterfly; the actions of this butterfly could be indeterminate in light of the other latent components of the model, so that it is untangled; it could be perfectly easy to understand the meaning of the representation of the butterfly so that it is interpretable; it could be valuable in another system or context so that it is reusable; and it could even meticulously improve the performance of the weather forecast so that it is powerful; but somehow none of it justifies its presence in a weather model. Compactness says that we only care about the most important factors of variation."}, {"heading": "3. Disentanglement in Vision", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Introduction", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far, until it is so far."}, {"heading": "3.2 Related Work", "text": "This year it has come to the point where it will be able to put itself at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said."}, {"heading": "3.3 Model", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3.3.1 Training with Specific Transformations", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "3.3.2 Invariance Targeting", "text": "By training with only one transformation at a time, we encourage certain neurons to contain certain information; this is equivariance, but we also explicitly want to prevent them from having other information; that is, we want them to be invariant to other transformations. Since our mini-stacks of training data consist of only one transformation per stack, this goal is for all but one of the encoder's initial neurons to deliver the same output for each image in the stack. To promote this characteristic of DC-IGN, we train all neurons corresponding to the inactive transformations with an error gradient corresponding to their difference from the mean. It is easiest to think about this gradient as if they are acting on the group of subvectors."}, {"heading": "3.4 Experiments", "text": "We trained our model on approximately 12,000 stacks of faces generated from a 3D face model by Paysan et al. (2009), in which each stack of 20 faces with random variations in terms of facial identity variables (shape / texture), pose or lighting. To ensure that these techniques work on other types of data, we also trained networks to perform reconstructions on images of very different 3D chairs from many perspectives derived from the Pascal Visual Object Classes dataset as extracted by Aubry et al. (2014, Aubry et al. (2014). This task tests the DC-IGN's ability to learn a rendering function for a dataset with high variations between the elements of the set; the chairs vary from office chairs to basket models and modern designs, training two angles and 360 \u00b0 parameters."}, {"heading": "3.4.1 3D Face Dataset", "text": "The decoder network learns an approximate rendering engine as shown in Fig. 3-4. In a static test image, the encoder network generates the latents that represent scene variables such as light, pose, shape, etc. Similar to a commercial rendering engine, we can control these independently to generate new images with the decoder. As shown in Fig. 3-4, for example, we can vary the illumination of an image by keeping all other latents constant and variable. Perhaps surprisingly, the fully trained decoder network can function as a 3D rendering engine, and this ability is proof that the representation learned through DC-IGN is untangled. We also quantitatively demonstrate the network's ability to represent pose and light in a smooth linear variety, as shown in Fig. 3-7, which directly demonstrates the ability of our training algorithm to unravel complex transformations."}, {"heading": "3.4.2 Comparison with Entangled Representations", "text": "To find out how much difference the DC-IGN training method makes, we compare the reconstruction performance of networks from a novel perspective with entangled representations (baseline) versus unbundled representations (DC-IGN).The baseline mesh is identical in all respects to the DC-IGN, but was trained with SGVB without using our proposed training method.As in Figure 3-6, we feed each network a single input image and then try to render this image using the decoder of the baseline using different azimuth angles.To do this, we first need to find out which latent of the entangled representation is most likely to correspond with the azimuth. We do this quite simply. First, we encode all the images in an azimuth-varied stack using the encoder of the baseline, then we calculate the variance of each of the entangled representation over that stack. The latent with the largest variance is then the closest to the azimuth face we associate, once we consider the face as a new face."}, {"heading": "3.4.3 Chair Dataset", "text": "We conducted a similar series of experiments with the 3D chair dataset described above. This dataset contains stills from 3D CAD models of 1357 different chairs, each of which was skinned with the photographic texture of the real chair. Each of these models is rendered in 60 different poses; in each of two surveys there are 30 images taken from 360 degrees around the model. We used approximately 1200 of these chairs in the training set and the remaining 150 in the test set; as such, the networks had never seen the chairs in the test set from any angle, so the tests examine the ability of the networks to generalize any chairs. We reduced the images to 150 x 150 pixels and turned them grey to match our face dataset. We trained these networks with the azimuth (flat rotation) of the chair as an unintertwined variable represented by a single node."}, {"heading": "4. Disentanglement in Computation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Introduction", "text": "In fact, most of us are able to outdo ourselves, \"he said in an interview with The New York Times.\" I don't think we're able to change the world, \"he said.\" But I don't think we're going to be able to change the world. \"He added,\" I don't think we're going to be able to change the world. \"He added,\" I don't think we're going to be able to change the world. \""}, {"heading": "4.1.1 Catastrophic forgetting", "text": "However, one of the clearest examples of the weakness of highly entangled neural networks is catastrophic forgetfulness. With the recent success of deep learning methods in many areas, efforts have been made to apply deep learning techniques to multifunctional learning problems. Deep learning is a way to extract good representations from complex data at the deepest level, with the higher levels of a network increasingly capturing abstract representations of the data. As such, deep learning appears to be a promising direction for multifunctional learning; abstract representations of the data should be useful for many related tasks, and the network should simply be able to use none that are not helpful for simple, highly coupled tasks such as product evaluations (Glorot, Bordes, and Bengio 2011)."}, {"heading": "4.2 Related Work", "text": "Until recently, work in this area has largely focused on a) learning programs in a fixed language of representation, or b) learning a program together and its representation in e.g. a neural network, without focusing on representation itself. Specifically, Liang et al. (Liang, Jordan, and Klein 2010) suggest learning programs by Bayesian inference with a grammar based on a hierarchical structure. Zaremba et al. (2014) use an LSTM (Hochreiter and Schmidhuber 1997) to predict the results of simple programs written in Python; their effectiveness is remarkable, but the induced representation is so poor that the authors comment: \"We do not know how much our model relies on memorization and how far the learned algorithm deviates from the actual, correct algorithm.\" A classic model that attempts to unravel the arithmetic steps is the mix of experts (Jacobs, Jordan, and Barto 1991)."}, {"heading": "4.3 Controller-function networks", "text": "The proposed model, the Controller Functional Network (CFN), generates an output for a specific timestep through the following steps (shown in Fig. 4-1): 1. The input tensor is fed into the controller. 2. The controller decides which layers are best suited for processing this input3. 3. The controller issues a weight vector that reflects how much output it wants from each of the layers. 4. The input tensor is fed into each layer. 5. The outputs from each layer are multiplied by their respective weights. 4. The weighted outputs from all layers are added and output. 5. The output tensor is stored in each layer. 5. The idea is that at each timestep the input is examined by multiplying the input layer by its respective weights."}, {"heading": "4.3.1 Relationship to mixture of experts", "text": "This architecture is closely related to the expert model proposed by Jacobs et al. (1991), in which several different task-specific \"expert networks\" contribute in a linear combination to the output of the overall network. However, this model differs from the expert mix in two ways: 1. The gating network is an LSTM. This means that the gating network (or controller in my terminology) can easily learn fixed sequential procedures for certain types of input. This allows iterating the model in several steps and dividing its operations into more complex ones. See paragraph 5.2.1 for a description of this application. 2. The training leads to decoupled functions."}, {"heading": "4.3.2 Hard and soft decisions", "text": "In recent years, it has been shown that the number of people who are able to remain in the EU has increased significantly in recent years. (...) In the last ten years, the number of people living in the EU has doubled. (...) In the last ten years, the number of people living in the EU has doubled. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased. (...) The number of people living in the EU has increased."}, {"heading": "4.3.3 Continuation methods", "text": "Continuation methods are a widely used technique for approaching difficult optimization problems. In Continuing Optimization, a transformation of the nonconvex function into an easy-to-minimize function is considered, and the method then gradually converts the simple problem back to the original function, following the path of the minimizer. (Mobahi and Fisher III 2015) As described in Mobahi and Fisher III 2015, continuation methods include ideas as ubiquitous as curriculum learning or deterministic glow, and this paper provides an extensive list of examples. In the search for good solutions to hard-decision problems, continuation methods are a natural tool."}, {"heading": "4.3.4 Training with noisy decisions", "text": "In order to construct a continuation between soft and hard decisions, the CFN combines two tools: weight sharpening and noise. Weight sharpening is a technique used by (Graves, Wayne and Danihelka 2014), which works by adopting a distribution vector of weights [0, 1] and a sharpening parameter \u2265 1 and transforming as follows: \",,\" \",\", \",\", \",\", \",\", \",\", \",\", \"\", \"\", \",\", \",\", \",\", \",\", \",\", \"\""}, {"heading": "4.4 Experiments", "text": "In order to carefully test the ability of different techniques to correctly factorize several presented problems, I constructed a simple dataset of vector functions, inputs, and outputs. These functions are described in detail in Tbl. 4.1. In the following experiments, these functions are applied to random input vectors in [0, 1]. Since the inputs to all these functions are indistinguishable, it would be impossible for each system to achieve better results than averaging the output of all these functions. Therefore, all systems, together with the input vector, receive a uniform vector containing the index of the primitive to be calculated. Each system must learn to interpret this information in its own way. In CFN, these metadata are passed only to the controller, forcing it to use different functions for different inputs. While this is a supervised learning task on the surface (given some inputs of exactly this output), the much more interesting interpretation of the task results when these functions are applied to the respective task."}, {"heading": "4.4.1 Disentanglement of functions", "text": "To test directly how untangled the representation of the CFN is, I analyzed the weights assigned to each function in the network during the entire training process. Ideally, the distribution would be entirely focused on one function at a time; this would indicate that the network has perfectly decoupled its functions. Since no two functions are the same and each has the same input range, no function layer can correctly calculate two of them. In Fig. 4-2, the results of this analysis are shown. By applying the continuation method described in Fig. 4.3.3, the CFN is able to quickly learn to unravel the representation of the functions in the data without affecting performance. In comparison, a network of the same architecture, which was designed without noise and sharpening techniques, can also produce the same output, but its representation of the calculation is very confused."}, {"heading": "4.4.2 Catastrophic forgetting", "text": "To test the resilience of the CFN to the problems of oblivion that have plagued deep methods, I trained a controller functional network and a feedback network for the convergence of the entire dataset, including all eight vector functions. The feedback network was tightly interconnected, with three linear layers of dimensions 18, 100, and 10, with PReLu unsaturated activations occurring in between. After training each of these networks on the full dataset, I put them on a training on a dataset consisting solely of data from one of the primitive functions. Both networks were retrained at the same learning rate and other hyperparameters. Periodically, I evaluated the performance of both networks against a validation set consisting of data from all the other functions. As shown in Figures 4-3, the forward neural network experienced increasing loss during training. These results are typical of neural methods."}, {"heading": "5. Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 DC-IGN", "text": "We have shown that it is possible to train a deep inverse graphic network with a relatively untangled, interpretable graphic code layering representation from static images. By using a deep folding and unfolding architecture within a varying autoencoder formulation, our model can be trained end-to-end by reverse propagation on the stochastic varying objective function (Kingma and Welling 2013). We proposed a training method to force the network to learn untangled and interpretable representations. Using 3D face and stool analysis as a working example, we demonstrated the invariant and equivariant properties of the learned representations. Such representation is powerful because it separates the true generating factors for images from each other. In contrast to a traditional deep representation, the representation generated by the DC-IGN separates the inherent properties of an object from the results of its particular lighting and position. This brings us ever closer to our understanding of the true power of the pre-3D structure, enabling it to use the intangible power of the pre-visualization of the scenes in order to the true power of the 3D."}, {"heading": "5.1.1 Future work", "text": "In order to scale our approach to handling more complex scenes, it will probably be important to experiment with deeper architectures to handle a large number of object categories within a single network architecture. It is also very appealing to design a spatio-temporal convolutional architecture to use motion to handle complicated object transformations. In addition, the current formulation of SGVB is limited to continuous latent variables. However, real-world visual scenes may contain an unknown number of objects moving within and outside the frame. Therefore, it may be necessary to expand this formulation to handle more complex probable structures in scenes. In addition, the current formulation of SGVB is limited to continuous latent variables. However, real-world visual scenes may contain an unknown number of objects moving within and outside the frame. Therefore, it may be necessary to expand this formulation to handle more discrete distributions in scenes (Kulkarni, Saeedi and Gershman 2014) or to extend the model to a recurring latent environment, which can be replaced by a decoding network of more subtle structures (our suscode specific in 2008)."}, {"heading": "5.2 Controller-function networks", "text": "With the design of controller functional networks, I have created a modern version of the expert model and demonstrated that it is possible to learn highly untangled representations of the calculation. Furthermore, I have shown that this does not impose a performance penalty on the system, at least in some cases. These experiments have also shown that untangled representations of the calculation are much more resistant to the ongoing problem of catastrophic forgetfulness that has plagued neural methods since their inception."}, {"heading": "5.2.1 Future work", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "5.3 Unification", "text": "Perhaps the most exciting direction for future work is to combine these two different techniques to build a completely uncontrolled system to deduce the variation factors in the world and to use this structure to represent and predict videos. Instead of using our knowledge of the active transformations via a short video, we could train a controller network to weigh many different transformations for each image. Then, using the same continuation methods described in this essay, we could gradually sharpen these weights over the course of the training, resulting in a representation of real videos that is extremely sparse. Such representation might be able to capture the true generative structure of simple scenes without any supervision and learn dimensions of variation that occur most frequently in the real world. I look forward to continuing my work on building systems that can understand the variation factors in the world, and I hope that this thesis will provide some small help and inspiration in this area."}], "references": [{"title": "Commutative Lie Groups.", "author": ["Desjardins", "Guillaume", "Aaron Courville", "Yoshua Bengio"], "venue": "\u201cDisentangling", "citeRegEx": "Desjardins et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Desjardins et al\\.", "year": 2012}, {"title": "Chairs with Convolutional Neural Networks.", "author": ["Erhan", "Dumitru", "Yoshua Bengio", "Aaron Courville", "Pascal Vincent"], "venue": null, "citeRegEx": "Erhan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2009}, {"title": "Domain Adaptation for Large-Scale Sentiment Classification: A Deep Learning Approach.", "author": ["Glorot", "Xavier", "Antoine Bordes", "Yoshua Bengio"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks.", "author": ["Goodfellow", "Ian J", "Mehdi Mirza", "Da Xiao", "Aaron Courville", "Yoshua Bengio"], "venue": "ArXiv Preprint ArXiv:1312.6211", "citeRegEx": "Goodfellow et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2013}, {"title": "Neural Turing Machines.", "author": ["Graves", "Alex", "Greg Wayne", "Ivo Danihelka"], "venue": "ArXiv Preprint ArXiv:1410.5401", "citeRegEx": "Graves et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Almost Optimal Lower Bounds for Small Depth Circuits.", "author": ["Hastad", "Johan"], "venue": "In Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Hastad and Johan.,? \\Q1986\\E", "shortCiteRegEx": "Hastad and Johan.", "year": 1986}, {"title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on Imagenet Classification.", "author": ["He", "Kaiming", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "ArXiv Preprint ArXiv:1502.01852", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Transforming Auto-Encoders.", "author": ["Hinton", "Geoffrey E", "Alex Krizhevsky", "Sida D Wang"], "venue": "In Artificial Neural Networks and Machine Learning\u2013ICANN", "citeRegEx": "Hinton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2011}, {"title": "A Fast Learning Algorithm for Deep Belief Nets.", "author": ["Hinton", "Geoffrey", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural Computation", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Long Short-Term Memory.", "author": ["Hochreiter", "Sepp", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Task Decomposition Through Competition in a Modular Connectionist Architecture: The What and Where Vision Tasks.", "author": ["Jacobs", "Robert A", "Michael I Jordan", "Andrew G Barto"], "venue": "Cognitive Science", "citeRegEx": "Jacobs et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Jacobs et al\\.", "year": 1991}, {"title": "Adaptive Mixtures of Local Experts.", "author": ["Jacobs", "Robert A", "Michael I Jordan", "Steven J Nowlan", "Geoffrey E Hinton"], "venue": "Neural Computation", "citeRegEx": "Jacobs et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Jacobs et al\\.", "year": 1991}, {"title": "Auto-Encoding Variational Bayes.", "author": ["Kingma", "Diederik P", "Max Welling"], "venue": "ArXiv Preprint ArXiv:1312.6114", "citeRegEx": "Kingma et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2013}, {"title": "Imagenet Classification with Deep Convolutional Neural Networks.", "author": ["Krizhevsky", "Alex", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Picture: A Probabilistic Programming Language for Scene Perception.", "author": ["Kulkarni", "Tejas D", "Pushmeet Kohli", "Joshua B Tenenbaum", "Vikash Mansinghka"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "Inverse Graphics with Probabilistic CAD Models.", "author": ["Kulkarni", "Tejas D", "Vikash K Mansinghka", "Pushmeet Kohli", "Joshua B Tenenbaum"], "venue": "ArXiv Preprint ArXiv:1407.1339", "citeRegEx": "Kulkarni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2014}, {"title": "Variational Particle Approximations.", "author": ["Kulkarni", "Tejas D", "Ardavan Saeedi", "Samuel Gershman"], "venue": "ArXiv Preprint ArXiv:1402.5715", "citeRegEx": "Kulkarni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2014}, {"title": "Deep Convolutional Inverse Graphics Network.", "author": ["Kulkarni", "Tejas D", "Will Whitney", "Pushmeet Kohli", "Joshua B Tenenbaum"], "venue": "ArXiv Preprint ArXiv:1503.03167", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "Convolutional Networks for Images, Speech, and Time Series.", "author": ["LeCun", "Yann", "Yoshua Bengio"], "venue": "The Handbook of Brain Theory and Neural Networks", "citeRegEx": "LeCun et al\\.,? \\Q1995\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1995}, {"title": "Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations.", "author": ["Lee", "Honglak", "Roger Grosse", "Rajesh Ranganath", "Andrew Y Ng"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Lee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "Learning Programs: A Hierarchical Bayesian Approach.", "author": ["Liang", "Percy", "Michael I Jordan", "Dan Klein"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "Liang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2010}, {"title": "Understanding Deep Image", "author": ["Mahendran", "Aravindh", "Andrea Vedaldi"], "venue": null, "citeRegEx": "Mahendran et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mahendran et al\\.", "year": 2014}, {"title": "Generating Images from Captions with Attention.", "author": ["Mansimov", "Elman", "Emilio Parisotto", "Jimmy Lei Ba", "Ruslan Salakhutdinov"], "venue": "ArXiv Preprint ArXiv:1511.02793", "citeRegEx": "Mansimov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mansimov et al\\.", "year": 2015}, {"title": "Approximate Bayesian Image Interpretation Using Generative Probabilistic Graphics Programs.", "author": ["Mansinghka", "Vikash", "Tejas D Kulkarni", "Yura N Perov", "Josh Tenenbaum"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mansinghka et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mansinghka et al\\.", "year": 2013}, {"title": "Human-Level Control Through Deep Reinforcement Learning.", "author": ["Mnih", "Volodymyr", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves"], "venue": "Nature", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "A Theoretical Analysis of Optimization by Gaussian Continuation.", "author": ["Mobahi", "Hossein", "John W Fisher III"], "venue": "In Twenty-Ninth AAAI Conference on Artificial Intelligence", "citeRegEx": "Mobahi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mobahi et al\\.", "year": 2015}, {"title": "The Role of Context for Object Detection and Semantic Segmentation in the Wild.", "author": ["Mottaghi", "Roozbeh", "Xianjie Chen", "Xiaobai Liu", "Nam-Gyu Cho", "Seong-Whan Lee", "Sanja Fidler", "Raquel Urtasun", "Alan Yuille"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "Mottaghi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mottaghi et al\\.", "year": 2014}, {"title": "Analysis-by-Synthesis by Learning to Invert Generative Black Boxes.", "author": ["Nair", "Vinod", "Josh Susskind", "Geoffrey E Hinton"], "venue": "In Artificial Neural Networks-ICANN", "citeRegEx": "Nair et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2008}, {"title": "Neural Programmer: Inducing Latent Programs with Gradient Descent.", "author": ["Neelakantan", "Arvind", "Quoc V Le", "Ilya Sutskever"], "venue": "ArXiv Preprint ArXiv:1511.04834", "citeRegEx": "Neelakantan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "A 3D Face Model for Pose and Illumination Invariant Face Recognition.", "author": ["P. Paysan", "R. Knothe", "B. Amberg", "S. Romdhani", "T. Vetter"], "venue": "Proceedings of the 6th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS) for Security,", "citeRegEx": "Paysan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Paysan et al\\.", "year": 2009}, {"title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.", "author": ["Radford", "Alec", "Luke Metz", "Soumith Chintala"], "venue": null, "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Neural Programmer-Interpreters.", "author": ["Reed", "Scott", "Nando de Freitas"], "venue": null, "citeRegEx": "Reed et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Reed et al\\.", "year": 2015}, {"title": "Stacked Denoising Autoencoders: Learning Useful Rep", "author": ["Antoine Manzagol"], "venue": null, "citeRegEx": "Manzagol.,? \\Q2010\\E", "shortCiteRegEx": "Manzagol.", "year": 2010}, {"title": "How Transferable Are Features in Deep Neural Networks?", "author": ["Yosinski", "Jason", "Jeff Clune", "Yoshua Bengio", "Hod Lipson"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Yosinski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yosinski et al\\.", "year": 2014}, {"title": "Learning to Execute.", "author": ["Zaremba", "Wojciech", "Ilya Sutskever"], "venue": "ArXiv Preprint ArXiv:1410.4615", "citeRegEx": "Zaremba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}, {"title": "Learning Simple Algorithms from Examples.", "author": ["Zaremba", "Wojciech", "Tomas Mikolov", "Armand Joulin", "Rob Fergus"], "venue": "ArXiv Preprint ArXiv:1511.07275", "citeRegEx": "Zaremba et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2015}, {"title": "Visualizing and Understanding Convolutional Networks.", "author": ["Zeiler", "Matthew D", "Rob Fergus"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 24, "context": "Reusable: A representation which was learned to solve a very specific task, like perhaps that of the DQN (Mnih et al. 2015), will not be helpful in other settings, like the real world.", "startOffset": 105, "endOffset": 123}, {"referenceID": 14, "context": "2013, Kulkarni et al. (2014), Kulkarni, Kohli, et al.", "startOffset": 6, "endOffset": 29}, {"referenceID": 14, "context": "2013, Kulkarni et al. (2014), Kulkarni, Kohli, et al. (2015)) follows a general strategy of defining a probabilistic with latent parameters, then using an inference algorithm to find the", "startOffset": 6, "endOffset": 61}, {"referenceID": 19, "context": "els (Hinton, Osindero, and Teh 2006, Salakhutdinov and Hinton (2009), Lee et al. (2009)), our approach is trained using back-propagation with objective function consisting of data reconstruction and the variational bound.", "startOffset": 70, "endOffset": 88}, {"referenceID": 0, "context": "Another piece of related work is Desjardins et al. (2012), who used a spike and slab prior to factorize representations in a generative deep network.", "startOffset": 33, "endOffset": 58}, {"referenceID": 22, "context": "(Mansimov et al. 2015) use", "startOffset": 0, "endOffset": 22}, {"referenceID": 23, "context": "A number of inverse-graphics inspired methods have recently been proposed in the literature (Mansinghka et al. 2013).", "startOffset": 92, "endOffset": 116}, {"referenceID": 7, "context": "The exception to this is work by Hinton et al. (2011) and Tieleman (2014) on transforming autoencoders which use a domain-specific decoder to reconstruct input images.", "startOffset": 33, "endOffset": 54}, {"referenceID": 7, "context": "The exception to this is work by Hinton et al. (2011) and Tieleman (2014) on transforming autoencoders which use a domain-specific decoder to reconstruct input images.", "startOffset": 33, "endOffset": 74}, {"referenceID": 29, "context": "Various statistical shape models trained on 3D scanner data such as faces have the same multivariate normal latent distribution (Paysan et al. 2009).", "startOffset": 128, "endOffset": 148}, {"referenceID": 29, "context": "We trained our model on about 12,000 batches of faces generated from a 3D face model obtained from Paysan et al. (2009), where each batch consists of 20 faces with random variations on face identity variables (shape/texture), pose, or lighting.", "startOffset": 99, "endOffset": 120}, {"referenceID": 26, "context": "(Mottaghi et al. 2014, Aubry et al. (2014)).", "startOffset": 1, "endOffset": 43}, {"referenceID": 13, "context": "The famous ImageNet network by Krizhevsky et al. (2012), for example, contains 60 million parameters which, along with their connectivity, define a function from an input domain of 256x256x3 image to a 1x1000 distribution over labels.", "startOffset": 31, "endOffset": 56}, {"referenceID": 1, "context": "Researchers have developed whole classes of techniques for analyzing them, which use gradient ascent to visualize specific units of the network (Erhan et al. 2009), occlusions of the input to analyze significance (Zeiler and Fergus 2014), or inverting their functions to visualize their information preservation (Mahendran and Vedaldi 2014).", "startOffset": 144, "endOffset": 163}, {"referenceID": 33, "context": "However, even small changes in the task result in substantial changes to the optimal features, especially at high levels of the network (Yosinski et al. 2014).", "startOffset": 136, "endOffset": 158}, {"referenceID": 3, "context": "A recent set of experiments (Goodfellow et al. 2013) detail the tradeoff curve for performance on one task versus performance on the other task for both similar and dissimilar tasks.", "startOffset": 28, "endOffset": 52}, {"referenceID": 20, "context": "In particular, Liang et al. (Liang, Jordan, and Klein 2010) propose to learn programs via Bayesian inference with a grammar over a hierarchical structure. Zaremba et al. (2014) use an LSTM (Hochreiter and Schmidhuber 1997) to predict the output of simple programs written in Python; their effectiveness is remarkable, but the induced representation is so poor that the authors comment, \u201cWe do not know how heavily our model relies on memorization and how far the learned algorithm is from the actual, correct algorithm.", "startOffset": 15, "endOffset": 177}, {"referenceID": 10, "context": "However, as originally described this model was not especially successful at learning distinct functions for each expert; this led to a modification of the design which used sampling instead of weighting using the gating values (Jacobs et al. 1991).", "startOffset": 228, "endOffset": 248}, {"referenceID": 35, "context": "(Zaremba et al. 2015) use an external memory with pointers to learn routines for interacting with external data.", "startOffset": 0, "endOffset": 21}, {"referenceID": 6, "context": "Each of the \u201cfunction\u201d layers is a single-layer network with a PReLU activation function (He et al. 2015).", "startOffset": 89, "endOffset": 105}, {"referenceID": 10, "context": "This architecture is closely related to the mixture of experts model proposed by Jacobs et al. (1991), in which several different task-specific \u201cexpert\u201d networks each contribute in linear combination to the output of the overall network.", "startOffset": 81, "endOffset": 102}], "year": 2016, "abstractText": "Representation learning is the foundation for the recent success of neural network models. However, the distributed representations generated by neural networks are far from ideal. Due to their highly entangled nature, they are difficult to reuse and interpret, and they do a poor job of capturing the sparsity which is present in realworld transformations. In this paper, I describe methods for learning disentangled representations in the two domains of graphics and computation. These methods allow neural methods to learn representations which are easy to interpret and reuse, yet they incur little or no penalty to performance. In the Graphics section, I demonstrate the ability of these methods to infer the generating parameters of images and rerender those images under novel conditions. In the Computation section, I describe a model which is able to factorize a multitask learning problem into subtasks and which experiences no catastrophic forgetting. Together these techniques provide the tools to design a wide range of models that learn disentangled representations and better model the factors of variation in the real world. Thesis Supervisor: Joshua B. Tenenbaum Title: Professor", "creator": "LaTeX with hyperref package"}}}