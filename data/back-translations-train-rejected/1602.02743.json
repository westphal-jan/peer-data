{"id": "1602.02743", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2016", "title": "The IMP game: Learnability, approximability and adversarial learning beyond $\\Sigma^0_1$", "abstract": "We introduce a problem set-up we call the Iterated Matching Pennies (IMP) game and show that it is a powerful framework for the study of three problems: adversarial learnability, conventional (i.e., non-adversarial) learnability and approximability. Using it, we are able to derive the following theorems. (1) It is possible to learn by example all of $\\Sigma^0_1 \\cup \\Pi^0_1$ as well as some supersets; (2) in adversarial learning (which we describe as a pursuit-evasion game), the pursuer has a winning strategy (in other words, $\\Sigma^0_1$ can be learned adversarially, but $\\Pi^0_1$ not); (3) some languages in $\\Pi^0_1$ cannot be approximated by any language in $\\Sigma^0_1$.", "histories": [["v1", "Sun, 7 Feb 2016 04:17:17 GMT  (22kb)", "http://arxiv.org/abs/1602.02743v1", "23 pages"]], "COMMENTS": "23 pages", "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.CC cs.FL", "authors": ["michael brand", "david l dowe"], "accepted": false, "id": "1602.02743"}, "pdf": {"name": "1602.02743.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Michael Brand", "David L. Dowe"], "emails": ["michael.brand@monash.edu", "david.dowe@monash.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 2.02 743v 1 [cs.L O] 7F ebWe are introducing a problem that we call the Iterated Matching Pennies (IMP) game and show that it is a powerful framework for the study of three problems: hostile learning ability, conventional (i.e., non-hostile) learning ability and approach ability. From this we can derive the following theorems. (1) It is possible to learn by example all that we describe as adverse learning (which we describe as persecution avoidance game); (2) in adverse learning the pursuer has a winning strategy (in other words, Econ01 can be learned adversally but Econ01 cannot); (3) some languages in Economy 0 1 cannot be approached by any language in \u04210."}, {"heading": "1. Introduction", "text": "It is about the question to what extent people are able to understand themselves and their environment. (...) It is about the question to what extent people are able to understand themselves and their environment. (...) It is about the question to what extent people are able to understand themselves. (...) It is about the question to what extent people are able to understand themselves. (...) It is about the question to what extent people are able to understand themselves. (...) It is about the question to what extent people are able to understand themselves. (...) It is about the question to what extent they are able to understand themselves. (...) It is about the question to what extent they are able to determine themselves. (...) It is about the question to what extent they are able to determine themselves."}, {"heading": "2. Matching Pennies", "text": "The matching pennies are a zero sum game in which each player must output a bit (= 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = \"2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2\" = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 \"= 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2\" + 2 = 2 = 2 = 2 = 2 = 2 = 2 \"= 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2\" = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 \"= 2 = 2 = 2 = 2 = 2 = 2 =\" = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 1 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 1 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 1 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = = 2 = 2 = 2 = = 2 = 2 = 2 = = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = = = 2 = 2 = 2 = 2 = 2 = 2 = 2 = = 2 = 2 = 2 = 2 = 2 = 2 = = 2 = 2 = 2 = = = = 2 = 2 = = = = 2 = 2 = = 2 ="}, {"heading": "3. Halting Turing machines", "text": "The IMP game serves as a natural platform for the study of adversarial learning: each player has the opportunity to learn from all previous rounds = mixed, extrapolates from this to the question of which algorithm his opponent uses and then chooses his own course of action to best counteract the methods of the opponent. Furthermore, IMP is a natural arena to distinguish between learning a language (e.g. a strategy chosen by R.E.) and complementing it (e.g. a language chosen by Co-R.E.) because the player \"=, the copying player, essentially tries to learn a language from other languages, namely that of players\" 6 =, \"while the player\" 6 = \"tries to learn a language from fellow players, namely the complement to that chosen by players\" =. \"Any benefit for players\" can be attributed exclusively to the difficulty of learning from an algorithm, as opposed to the skills we learn."}, {"heading": "4. Adversarial learning", "text": "We claim that R.E. languages can be learned contradictorily and that it is therefore not possible to learn the complement of R.E. languages in general in the adverse learning scenario.Theorem 3. The game IMP (IMP 01) has a strategy, L =, for the player \"=,\" the S 6 = (L =, L6 =) = 0 for all L6 = (and consequently for all distributions among potential L6 = candidates).In particular, the miracle is inversely learnable.Proof. We describe L = explicitly by means of an algorithm that accepts it. This is stated in Algorithm 2.Note that Algorithm 2 has no \"acceptance\" or \"rejection\" of statements. It returns a bit only if Td returns a bit and does not quit if Td fails: Td ends. To calculate actuallyAlgorithm 2 algorithm for learning a R.E. language: function Bit (I.2): LT. \""}, {"heading": "5. Conventional learnability", "text": "In order to adapt the IMP game to the study of conventional (i.e. non-adversarial) problems, the general sections 1 = 2. \"We introduce the concept of non-adaptive strategies (). Definition 3.\" A non-adaptive strategy is a language that is either an arbitrarily chosen (calculable) strategy, or an arbitrarily chosen (reproducible) enumeration w1, w2, w2. \"Using the complete language, we define the function NA (), which for each language is L, NA (L) is the language like thatx (L), w.\" Beyond that, we define NA (NA). \"(L) is the non-adaptive application of this definition.\" To elucidate this definition, we look again at one (computable). \"We define NA (NA) = {NA (L).\""}, {"heading": "6. Approximability", "text": "If both strategies are not adaptable, they have no means of learning the other way. (D = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = \"0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0,\" \"we = 0 = 0 = 0,\" 0 = 0 = 0 = 0, \"we = 0 = 0,\" 0 = 0 = 0, \"we = 0 = 0,\" we = 0 = 0, \"0 = 0 = 0,\" we = 0 = 0, \"0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0,\" we = 0 = 0 = 0, \"we = 0 = 0 = 0,\" we = 0 = 0 = 0 = 0, \"we = 0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0, 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0, 0 = 0 = 0 = 0 = 0, 0 = 0, 0 =, 0 = 0 = 0 =, 0 =, 0 = 0 = 0 = 0 = 0, 0 =, 0 = 0 =, 0 = 0 = 0 =, 0 = 0 = 0, 0 = 0, 0 = 0 = 0, 0 = 0 =, 0 =, 0 = 0 =, 0 = 0 = 0 =, 0 =, 0 =, 0, 0 = 0 = 0 = 0 ="}, {"heading": "7. Conclusions and further research", "text": "We have introduced the IMP game as an arena in which the ability of algorithms to learn and be learned is tested, and we have specifically investigated three scenarios: Adversarial learning, in which both algorithms simultaneously attempt to imitate each other through observations. Non-adversarial (conventional) learning, in which an algorithm attempts to learn a language using examples. Approximation, in which languages (or language distributions) attempt to imitate each other without having visibility to the actions of their adversaries.In the case of adversarial learning, we have shown that we can learn 0 i, but not 0 i. In conventional learning, however, we have shown that we can learn 0 i, 0 i and beyond (i + 1)."}], "references": [{"title": "Foreword re C", "author": ["D.L. Dowe"], "venue": "S. Wallace. Computer Journal, 51(5):523\u2013560, September", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Minimum Message Length and statistically consistent invariant (objective?) Bayesian probabilistic inference \u2013 from (medical) \u201cevidence", "author": ["D.L. Dowe"], "venue": "Social Epistemology, 22(4):433\u2013460, Oct\u2013Dec", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness", "author": ["D.L. Dowe"], "venue": "Bandyopadhyay, P.S. and Forster, M.R., editor, Handbook of the Philosophy of Science \u2013 Volume 7: Philosophy of Statistics, pages 901\u2013982. Elsevier,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Introduction to Ray Solomonoff 85th Memorial Conference", "author": ["D.L. Dowe"], "venue": "Proceedings of Solomonoff 85th memorial conference \u2013 Lecture Notes in Artificial Intelligence (LNAI), volume 7070, pages 1\u201336. Springer,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Compression and intelligence: Social environments and communication", "author": ["D.L. Dowe", "J. Hern\u00e1ndez-Orallo", "P.K. Das"], "venue": "AGI: 4th Conference on Artificial General Intelligence \u2013 Lecture Notes in Artificial Intelligence (LNAI), pages 204\u2013211,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "The Computational Beauty of Nature: Computer Explorations of Fractals, Chaos, Complex Systems, and Adaptation", "author": ["G.W. Flake"], "venue": "A Bradford book. Cambridge, Massachusetts,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "Language identification in the limit", "author": ["E.M. Gold"], "venue": "Information and Control, 10(5):447\u2013 474,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1967}, {"title": "On more realistic environment distributions for defining, evaluating and developing intelligence", "author": ["J. Hern\u00e1ndez-Orallo", "D.L. Dowe", "S. Espa\u00f1a-Cubillo", "M.V. Hern\u00e1ndez-Lloreda", "J. Insa-Cabrera"], "venue": "AGI: 4th Conference on Artificial General Intelligence \u2013 Lecture Notes in Artificial Intelligence (LNAI), volume 6830, pages 82\u201391. Springer,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Adversarial machine learning", "author": ["Ling Huang", "Anthony D. Joseph", "Blaine Nelson", "Benjamin I.P. Rubinstein", "J.D. Tygar"], "venue": "In Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Scriven on human unpredictability", "author": ["D.K. Lewis", "J.S. Richardson"], "venue": "Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition, 17(5):69\u2013 74, October", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1966}, {"title": "A Game Theoretical Model for Adversarial Learning", "author": ["Wei Liu", "Sanjay Chawla"], "venue": "PS and Wu, XD, editor,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Adversarial learning", "author": ["Daniel Lowd", "Christopher Meek"], "venue": "Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Non-cooperative Games", "author": ["J. Nash"], "venue": "The Annals of Mathematics, 54(2):286\u2013295,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1951}, {"title": "Theory of Games and Economic Behavior", "author": ["J.v. Neumann", "O. Morgenstern"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1944}, {"title": "Theory of Recursive Functions and Effective Computability", "author": ["Hartley Rogers", "Jr."], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1987}, {"title": "An essential unpredictability in human behavior", "author": ["M. Scriven"], "venue": "B.B. Wolman and E. Nagel, editors, Scientific Psychology: Principles and Approaches, pages 411\u2013425. Basic Books (Perseus Books),", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1965}, {"title": "Complexity-based induction systems: Comparisons and convergence theorems", "author": ["R.J. Solomonoff"], "venue": "IEEE Transaction on Information Theory, IT-24(4):422\u2013432,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1978}, {"title": "Algorithmic probability: Theory and applications", "author": ["R.J. Solomonoff"], "venue": "F. Emmert- Streib and M. Dehmer, editors, Information Theory and Statistical Learning, Springer Science and Business Media, pages 1\u201323. Springer, N.Y., U.S.A.,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithmic probability, heuristic programming and AGI", "author": ["R.J. Solomonoff"], "venue": "Proceedings of the Third Conference on Artificial General Intelligence, AGI 2010, pages 251\u2013257, Lugano, Switzerland, March", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Algorithmic probability \u2013 its discovery \u2013 its properties and application to strong AI", "author": ["R.J. Solomonoff"], "venue": "H. Zenil, editor, Randomness Through Computation: Some Answers, More Questions, pages 1\u201323. World Scientific Publishing Co., Inc., River Edge, NJ, USA,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "On computable numbers, with an application to the Entscheidungsproblem", "author": ["A.M. Turing"], "venue": "Proc. London Math. Soc., 42:230\u2013265,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1936}, {"title": "A theory of the learnable", "author": ["Leslie G Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1984}], "referenceMentions": [{"referenceID": 20, "context": "Turing\u2019s seminal 1936 result [21] demonstrated that some languages that can be accepted by Turing machines (TMs) are not decidable.", "startOffset": 29, "endOffset": 33}, {"referenceID": 6, "context": "Valiant in terms of language identification in the limit [7, 22], and also in statistics via the notion of statistical consistency, also known as \u201ccompleteness\u201d (converging arbitrarily closely in the limit to an underlying true model).", "startOffset": 57, "endOffset": 64}, {"referenceID": 21, "context": "Valiant in terms of language identification in the limit [7, 22], and also in statistics via the notion of statistical consistency, also known as \u201ccompleteness\u201d (converging arbitrarily closely in the limit to an underlying true model).", "startOffset": 57, "endOffset": 64}, {"referenceID": 16, "context": "Following upon his convergence results in [17], Solomonoff writes [20, sec.", "startOffset": 42, "endOffset": 46}, {"referenceID": 11, "context": "Lastly, consider adversarial learning [12, 11, 9].", "startOffset": 38, "endOffset": 49}, {"referenceID": 10, "context": "Lastly, consider adversarial learning [12, 11, 9].", "startOffset": 38, "endOffset": 49}, {"referenceID": 8, "context": "Lastly, consider adversarial learning [12, 11, 9].", "startOffset": 38, "endOffset": 49}, {"referenceID": 14, "context": "Here and elsewhere we use the standard notations for language families in the arithmetical hierarchy [15]: \u03a3 1 is the set of recursively enumerable languages, \u03a0 1 is the set of co-R.", "startOffset": 101, "endOffset": 105}, {"referenceID": 15, "context": "The set-up used is an adaptation of one initially introduced by Scriven [16] of a predictor and a contrapredictive (or avoider) effectively playing what we might nowadays describe as a game of iterated matching pennies.", "startOffset": 72, "endOffset": 76}, {"referenceID": 13, "context": "283\u2013284]: its only Nash equilibrium [14, 13] is a mixed strategy wherein each player chooses each of the two options with probability 1/2.", "startOffset": 36, "endOffset": 44}, {"referenceID": 12, "context": "283\u2013284]: its only Nash equilibrium [14, 13] is a mixed strategy wherein each player chooses each of the two options with probability 1/2.", "startOffset": 36, "endOffset": 44}, {"referenceID": 15, "context": "The set-up described here, where Iterated Matching Pennies is essentially described as a pursuit-evasion game, was initially introduced informally by Scriven [16] in order to prove that unpredictability is innate to humans.", "startOffset": 158, "endOffset": 162}, {"referenceID": 9, "context": "Lewis and Richardson [10], without explicitly mentioning Turing machines or any (equivalent) models of computation, reinvestigated the model and used it to refute Scriven\u2019s claim, with a proof that hinges on the halting problem, but references it only implicitly.", "startOffset": 21, "endOffset": 25}, {"referenceID": 15, "context": "2 and footnote 211], and then, as in [16], in the context of predicting bits in a sequence [2, p.", "startOffset": 37, "endOffset": 41}, {"referenceID": 20, "context": "Thus, it would provide an alternative to the method of [21] to prove this undecidability.", "startOffset": 55, "endOffset": 59}], "year": 2016, "abstractText": "We introduce a problem set-up we call the Iterated Matching Pennies (IMP) game and show that it is a powerful framework for the study of three problems: adversarial learnability, conventional (i.e., non-adversarial) learnability and approximability. Using it, we are able to derive the following theorems. (1) It is possible to learn by example all of \u03a31 \u222a \u03a01 as well as some supersets; (2) in adversarial learning (which we describe as a pursuit-evasion game), the pursuer has a winning strategy (in other words, \u03a31 can be learned adversarially, but \u03a01 not); (3) some languages in \u03a0 0 1 cannot be approximated by any language in \u03a3 0 1. We show corresponding results also for \u03a3i and \u03a0 0 i for arbitrary i.", "creator": "LaTeX with hyperref package"}}}