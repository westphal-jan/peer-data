{"id": "1602.02950", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2016", "title": "Spoofing detection under noisy conditions: a preliminary investigation and an initial database", "abstract": "Spoofing detection for automatic speaker verification (ASV), which is to discriminate between live speech and attacks, has received increasing attentions recently. However, all the previous studies have been done on the clean data without significant additive noise. To simulate the real-life scenarios, we perform a preliminary investigation of spoofing detection under additive noisy conditions, and also describe an initial database for this task. The noisy database is based on the ASVspoof challenge 2015 database and generated by artificially adding background noises at different signal-to-noise ratios (SNRs). Five different additive noises are included. Our preliminary results show that using the model trained from clean data, the system performance degrades significantly in noisy conditions. Phase-based feature is more noise robust than magnitude-based features. And the systems perform significantly differ under different noise scenarios.", "histories": [["v1", "Tue, 9 Feb 2016 12:00:56 GMT  (2229kb,D)", "http://arxiv.org/abs/1602.02950v1", "Submitted to Odyssey: The Speaker and Language Recognition Workshop 2016"]], "COMMENTS": "Submitted to Odyssey: The Speaker and Language Recognition Workshop 2016", "reviews": [], "SUBJECTS": "cs.LG cs.SD", "authors": ["xiaohai tian", "zhizheng wu", "xiong xiao", "eng siong chng", "haizhou li"], "accepted": false, "id": "1602.02950"}, "pdf": {"name": "1602.02950.pdf", "metadata": {"source": "CRF", "title": "Spoofing detection under noisy conditions: a preliminary investigation and an initial database", "authors": ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "emails": ["aseschng}@ntu.edu.sg,", "zhizheng.wu@ed.ac.uk,", "hli@i2r.a-star.edu.sg"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2. Noisy Database", "text": "To illustrate the practical application scenarios for spoofing detection, we are trying to design a database in an environment with additional noise based on the challenge database ASVspoof 2015 [19].ASVspoof is a spoofing and anti-spoofing database that includes both real (human language) and ten types of fake language (referred to as S1-S10 in the ASVspoof 2015 challenge) implemented by three speech synthesis and seven spoofing algorithms. ASVspoof database contains three subsets, including training, development and assessment sets. Training and development sets contain only known attacks (S1-S5); while the assessment set includes both known and unknown (S6-S10) attacks. Further details and protocols about the ASVspoof database can be found in [19].This noisy version aims to quantify the effects of current spoofing detection algorithms on this assessment task and we will briefly work on quantifying noise conditions in this section."}, {"heading": "2.1. Noise signals", "text": "Five types of noises representing the likely application scenarios are used to build the noisy ASVspoof database. A subset of three types of noises is selected from the QUTNOISE database [21]: white noise, voice chatter and vehicle interior noises. These are standard types of additive noises used for speech recognition [21-23], speech verification [24, 25] and speech enhancement [26]. We briefly describe these noises as follows: \u2022 White noise: the random signal with constant spectral density. \u2022 Babble noise: voice chatter and recording takes place in a canteen with 100 people speaking. \u2022 Volvo noise: vehicle interior noises and recording takes place in Volvo 340 on a paved road, rain noise: standing noises."}, {"heading": "2.2. Adding noise", "text": "The data from the ASVspoof database is considered clean data, and the noise is then artificially added to the clean data. Filtering and Noise Adding Tool (FaNT) 4 is used to add noise. Noise signals are generated by adding the clean speech and sound files together to different SNRs. Since the silence periods appear in many voice files in the ASVspoof database, it4http: / / dnt.kr.hs-niederrhein.de / is important to calculate the SNR only on the basis of the sections of the speech signal. Bandpass filter or frequency weighting are often used for SNR calculation to ensure that the SNR is appropriate and comparable. In this work, to add noise based on human hearing perception, we define the SNR as the ratio of signal to noise energy after filtering both signals with the weighting filter, where the frequency of the HF is very low, and the frequency of the HF is very high, while the human filter emphasizes the frequency of the HF is very high, and the frequency of the HF is very high."}, {"heading": "3. Benchmarking system", "text": "To demonstrate the usefulness of the ASVspoof sound database, we are conducting a series of experiments to examine the performance of the spoofing voice recognition system on a number of SNRs in all five noise scenarios. The detection system, as shown in Figure 2, consists of (a) the feature extraction module to extract six types of features used for classification; (b) the classification module to calculate the score for each feature; (c) the score fusion module to merge the values obtained from six classifiers; and the details of these three modules are presented as follows."}, {"heading": "3.1. Feature extraction", "text": "As shown in Figure 2 (a), the hamming window and DC offset distance are applied to each analyzer frame, then the short-term Fourier spectrum (STFT) is applied to the speech signal using an analysis window of 25ms with 15ms overlap, the FFT length is chosen to be 512 and the dimension of all original features is 256, for the nth frame the magnitude and phase spectrum, | X (n, \u03c9) are applied to the speech signal."}, {"heading": "3.2. Classifier", "text": "Figure 2 (b) shows the classification part of the recognition system. Our previous multi-layer perceptron (MLP) -based spoofing speech recognition system [29] is used in this thesis. Each of the above features, with its delta and acceleration coefficients, is used as an input vector to train its own classifier. MLP, which contains a hidden layer of 2048 sigmoid nodes, is used to predict the posterior probability of the input vector as a synthetic language. Score is calculated by averaging the posterior probabilities of all frames over the expression. Note that in this work all MLP classifiers are trained from clean data."}, {"heading": "3.3. Evaluation metrics and fusion", "text": "The same error rate (EER), which equals incorrect acceptance and lack of rejection rate, is used to evaluate system performance. As described in Section 3.1, various features are developed to detect different types of artifacts. In order to take advantage of each feature and improve system stability, a merge of the detection system is applied at the score level. Figure 2 (c) shows a merge of the score features of the detection system. The merge is applied based on the feature-based results in various noise scenarios. Based on our preliminary experiments, the IF: Clean conditionFrame number 0 100 200F Requ ency (kH z) 86420IF: white-SNR-20 dBFrame number 0 100 200F Requ Frequency (kH z) 86420F Requ System Number (kH z) 8200200F-weighted."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Experimental setups", "text": "The database used in the experiments consists of three subsets, including the training set, development set and assessment set. The training set consists of clean language data from the ASVspoof database. As the training set consists only of clean data, it models the language without distortion and displays all the language information. The best performance of the clean classifier is achieved in tests with clean data found in our previous paper [29]. The development and assessment sets are selected from the 5https: / / sites.google.com / site / bosaristoolkit / noisy ASVspoof database, including five noise scenarios at three different NRs as described in Section 2. Since the classifier used in these experiments is identical to the one used in our previous paper [29], these results are comparable to the results in clean condition."}, {"heading": "4.2. Evaluation results", "text": "The results are shown independently of the known attacks (S1-S5), the unknown attacks (S6-S9) and the unknown attacks by waveform concatenation (S10).The EERs are listed in Table 1 for both the noisy data sets and the clean data sets using the clean classification. We first analyze the effect of the noisy data for the detection system using different characteristics. Generally, the systems perform worse than the clean state in all five noise scenarios. As expected, the detection performance deteriorates in most cases when the SNR decreases. We note that in most noisy scenarios the order-of-magnitude-based characteristics, LMSand RLMS, are worse than the phase-based characteristics, IF, GD and MGD."}, {"heading": "4.3. Fusion results", "text": "In all noise scenarios with SNR of 20 dB, the deterioration in system performance differs significantly for different noise scenarios. In the development set, the EER of the various backup systems is between 2.52% (caf\u00e9 noise) and 8.32% (Volvo noise); in the assessment set, the EER varies between 5.25% (white noise) and 14.31% (Volvo noise). In the SNR of 0 dB, however, all system performance deteriorates significantly both in development and evaluation. Figure 3 and Figure 4 show that most characteristic patterns occur at such low SNRs. We then analyze the associated results in various noise scenarios. Of all noise scenarios, the system performs best under white noise scenarios, achieving consistently lowest error rates, especially at low SNRs, 10 dB and significantly enhanced noise of the system among other noise scenarios."}, {"heading": "5. Conclusions", "text": "This database is generated from the ASVspoof database and adds five types of additive noise at three SNR levels. To provide benchmark results, we use the state-of-the-art spoofing detection system to detect spoofing attacks under noisy conditions. \u2022 Preliminary results using the classifier trained from clean data show that \u2022 the performance of detection systems deteriorates in all noise scenarios. \u2022 System performance deteriorates when the SNR decreases; \u2022 in noisy environments, even the best EER is about 4% lower (white noise at 20 dB) than the clean state; \u2022 in general, non-stationary noise affects the detection system more seriously; \u2022 system performance varies significantly between different noise scenarios and the phase-based characteristics are more robust than noise based on magnitude-based characteristics. In this paper, we have presented only benchmark plans to demonstrate the accuracy of spoofing."}, {"heading": "6. Acknowledgment", "text": "This research is supported by the National Research Foundation Singapore as part of its Interactive Digital Media (IDM) Strategic Research Programme and also by the DSO-funded MAISON DSOCL14045 project, Singapore."}, {"heading": "7. References", "text": "[1] Kong Aik Lee, Bin Ma, and Haizhou Li, \"Speaker veri-fication makes its debut in smartphone,\" in IEEE Signal Processing Society Speech and language Technical Committee Newsletter, February 2013. [2] Mikhail Khitrov, \"Talking passwords and what's next,\" Biometric Technology Today, vol. 2013, no. 7, pp. 9-11, 2013, no. [4] Brett Beranek, \"Voice biometrics: success factors and what's next,\" Biometric Technology Today, vol. 7, pp."}], "references": [{"title": "Speaker verification makes its debut in smartphone", "author": ["Kong Aik Lee", "Bin Ma", "Haizhou Li"], "venue": "IEEE Signal Processing Society Speech and language Technical Committee Newsletter, February 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Talking passwords: voice biometrics for data access and security", "author": ["Mikhail Khitrov"], "venue": "Biometric Technology Today, vol. 2013, no. 2, pp. 9\u201311, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Voice biometrics: success stories, success factors and what\u2019s next", "author": ["Brett Beranek"], "venue": "Biometric Technology Today, vol. 2013, no. 7, pp. 9\u201311, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Surveying the development of biometric user authentication on mobile phones", "author": ["Wenchao Meng", "Duncan Wong", "Steven Furnell", "Jianying Zhou"], "venue": "IEEE Communications Surveys and Tutorials, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing and countermeasures for speaker verification: a survey", "author": ["Zhizheng Wu", "Nicholas Evans", "Tomi Kinnunen", "Junichi Yamagishi", "Federico Alegre", "Haizhou Li"], "venue": "Speech Communication, vol. 66, pp. 130\u2013153, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Evaluation of speaker verification security and detection of HMM-based synthetic speech", "author": ["P.L. De Leon", "M. Pucher", "J. Yamagishi", "I. Hernaez", "I. Saratxaga"], "venue": "IEEE Trans. Audio, Speech and Language Processing, vol. 20, no. 8, pp. 2280\u20132290, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Synthetic speech detection using temporal modulation feature", "author": ["Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "A study on replay attack and anti-spoofing for textdependent speaker verification", "author": ["Zhizheng Wu", "Sheng Gao", "Eng Siong Chng", "Haizhou Li"], "venue": "Proc. Asia-Pacific Signal Information Processing Association Annual Summit and Conference (APSIPA ASC), 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Synthetic speech discrimination using pitch pat-  tern statistics derived from image analysis", "author": ["Phillip L De Leon", "Bryan Stewart", "Junichi Yamagishi"], "venue": "INTER- SPEECH, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Toward a universal synthetic speech spoofing detection using phase information", "author": ["Jon Sanchez", "Ibon Saratxaga", "Inma Hernaez", "Eva Navas", "Daniel Erro", "Tuomo Raitio"], "venue": "IEEE Trans. on Information Forensics and Security, vol. 10, no. 4, pp. 810\u2013820, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Measuring a decade of progress in text-tospeech", "author": ["Simon King"], "venue": "Loquens, vol. 1, no. 1, pp. e006, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Anti-spoofing for text-independent speaker verification: An initial database, comparison of countermeasures, and human performance", "author": ["Zhizheng Wu", "Phillip L. De Leon", "Cenk Demiroglu", "Ali Khodabakhsh", "Simon King", "Zhen-Hua Ling", "Daisuke Saito", "Bryan Stewart", "Tomoki Toda", "Mirjam Wester", "Junichi Yamagishi"], "venue": "IEEE/ACM Transactions on Audio, Speech and Language Processing, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Detecting converted speech and natural speech for anti-spoofing attack in speaker recognition", "author": ["Zhizheng Wu", "Eng Siong Chng", "Haizhou Li"], "venue": "Proc. Interspeech, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "A study on spoofing attack in state-of-the-art speaker verification: the telephone speech case", "author": ["Zhizheng Wu", "Tomi Kinnunen", "Eng Siong Chng", "Haizhou Li", "Eliathamby Ambikairajah"], "venue": "Proc. Asia-Pacific Signal Information Processing Association Annual Summit and Conference (APSIPA ASC), 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Spoofing countermeasures to protect automatic speaker verification from voice conversion", "author": ["Federico Alegre", "Asmaa Amehraye", "Nicholas Evans"], "venue": "Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Introducing i-vectors for joint anti-spoofing and speaker verification", "author": ["Elie Khoury", "Tomi Kinnunen", "Aleksandr Sizov", "Zhizheng Wu", "S\u00e9bastien Marcel"], "venue": "Proc. Interspeech, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Joint speaker verification and antispoofing in the i-vector space", "author": ["Aleksandr Sizov", "Elie Khoury", "Tomi Kinnunen", "Zhizheng Wu", "Sebastien Marcel"], "venue": "IEEE Trans. on Information Forensics and Security, vol. 10, no. 4, pp. 821\u2013 832, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "On the vulnerability of speaker  verification to realistic voice spoofing", "author": ["Serife Kucur Ergunay", "Elie Khoury", "Alexandros Lazaridis", "Sebastien Marcel"], "venue": "IEEE International Conference on Biometrics Theory, Applications and Systems (BTAS), 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "ASVspoof 2015: the first automatic speaker verification spoofing and countermeasures challenge", "author": ["Zhizheng Wu", "Tomi Kinnunen", "Nicholas Evans", "Junichi Yamagishi", "Cemal Hanil\u00e7i", "Md Sahidullah", "Aleksandr Sizov"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "The NOISEX-92 study on the effect of additive noise on automatic speech recognition", "author": ["A.P. Varga", "H.J.M. Steeneken", "M. Tomlinson", "D. Jones"], "venue": "Tech. Rep., DRA Speech Research Unit, 1992.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "The QUT-NOISE-SRE protocol for the evaluation of noisy speaker recognition", "author": ["David Dean", "Ahilan Kanagasundaram", "Houman Ghaemmaghami", "Md Hafizur Rahman", "Sridha Sridharan"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Assessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems", "author": ["Andrew Varga", "Herman JM Steeneken"], "venue": "Speech communication, vol. 12, no. 3, pp. 247\u2013251, 1993.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1993}, {"title": "The aurora experimental framework for the performance evaluation of speech recognition systems under noisy conditions", "author": ["Hans-G\u00fcnter Hirsch", "David Pearce"], "venue": "ASR2000-Automatic Speech Recognition: Challenges for the new Millenium ISCA Tutorial and Research Workshop (ITRW), 2000.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Speaker verification in noisy environments with combined spectral subtraction and missing feature theory", "author": ["Andrzej Drygajlo", "Mounir El-Maliki"], "venue": "Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). IEEE, 1998.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "Temporally weighted linear prediction features for tackling additive noise in speaker verification", "author": ["Rahim Saeidi", "Jouni Pohjalainen", "Tomi Kinnunen", "Paavo Alku"], "venue": "IEEE Signal Processing Letters, vol. 17, no. 6, pp. 599\u2013 602, 2010.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Single channel speech enhancement based on masking properties of the human auditory system", "author": ["Nathalie Virag"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 7, no. 2, pp. 126\u2013137, 1999.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1999}, {"title": "Loudness, its definition, measurement and calculation", "author": ["Harvey Fletcher", "Wilden A Munson"], "venue": "Bell System Technical Journal, vol. 12, no. 4, pp. 377\u2013430, 1933.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1933}, {"title": "Spoofing speech detection using high dimensional magnitude and phase features: The ntu approach for ASVspoof 2015 challenge", "author": ["Xiong Xiao", "Xiaohai Tian", "Steven Du", "Haihua Xu", "Eng Siong Chng", "Haizhou Li"], "venue": "Proc. Interspeech, 2015.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Spoofing detection from a feature representation perspective", "author": ["Xiaohai Tian", "Zhizheng Wu", "Xiong Xiao", "Eng Siong Chng", "Haizhou Li"], "venue": "Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2016.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Short-time phase spectrum in speech processing: A review and some experimental results", "author": ["Leigh D Alsteris", "Kuldip K Paliwal"], "venue": "Digital Signal Processing, vol. 17, no. 3, pp. 578\u2013616, 2007.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "STFT phase reconstruction in voiced speech for an improved singlechannel speech enhancement", "author": ["Michal Krawczyk", "Timo Gerkmann"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 22, no. 12, pp. 1931\u20131940, 2014.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1931}, {"title": "Significance of group delay functions in spectrum estimation", "author": ["Bayya Yegnanarayana", "Hema A Murthy"], "venue": "IEEE Transactions on Signal Processing, vol. 40, no. 9, pp. 2281\u20132289, 1992.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1992}, {"title": "The effects of noise on the autoregressive spectral estimator", "author": ["Steven M Kay"], "venue": "IEEE Transactions on Acoustics, Speech and Signal Processing, vol. 27, no. 5, pp. 478\u2013485, 1979.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1979}], "referenceMentions": [{"referenceID": 0, "context": "Introduction Recently, automatic speaker verification (ASV) has been significantly advanced to the point of mass-market adoption [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 1, "context": "Introduction Recently, automatic speaker verification (ASV) has been significantly advanced to the point of mass-market adoption [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 2, "context": "Introduction Recently, automatic speaker verification (ASV) has been significantly advanced to the point of mass-market adoption [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 3, "context": "Introduction Recently, automatic speaker verification (ASV) has been significantly advanced to the point of mass-market adoption [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 4, "context": "A significant amount of evidences have confirmed the vulnerability of current state-of-the-art ASV systems under spoofing attacks as reviewed in [5].", "startOffset": 145, "endOffset": 148}, {"referenceID": 5, "context": "In [6, 7], the Wall Street Journal (WSJ) corpus was used to assess countermeasures for speech synthesis attacks.", "startOffset": 3, "endOffset": 9}, {"referenceID": 6, "context": "In [6, 7], the Wall Street Journal (WSJ) corpus was used to assess countermeasures for speech synthesis attacks.", "startOffset": 3, "endOffset": 9}, {"referenceID": 7, "context": "In [8], the publicly available RSR2015 corpus was used to evaluate spoofing detection for replay attacks.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "In [9, 10], synthetic speech from the Blizzard challenge [11] was used for speech synthesis spoofing detection.", "startOffset": 3, "endOffset": 10}, {"referenceID": 9, "context": "In [9, 10], synthetic speech from the Blizzard challenge [11] was used for speech synthesis spoofing detection.", "startOffset": 3, "endOffset": 10}, {"referenceID": 10, "context": "In [9, 10], synthetic speech from the Blizzard challenge [11] was used for speech synthesis spoofing detection.", "startOffset": 57, "endOffset": 61}, {"referenceID": 11, "context": "In [12], a recently released spoofing and anti-spoofing (SAS) corpus as a standard spoofing database was used to assess speech synthesis and voice conversion spoofing countermeasures.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "The National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation (SRE) 2006 database which has significant telephone channel noise was used to assess voice conversion spoofing countermeasures in [13\u201317].", "startOffset": 219, "endOffset": 226}, {"referenceID": 13, "context": "The National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation (SRE) 2006 database which has significant telephone channel noise was used to assess voice conversion spoofing countermeasures in [13\u201317].", "startOffset": 219, "endOffset": 226}, {"referenceID": 14, "context": "The National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation (SRE) 2006 database which has significant telephone channel noise was used to assess voice conversion spoofing countermeasures in [13\u201317].", "startOffset": 219, "endOffset": 226}, {"referenceID": 15, "context": "The National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation (SRE) 2006 database which has significant telephone channel noise was used to assess voice conversion spoofing countermeasures in [13\u201317].", "startOffset": 219, "endOffset": 226}, {"referenceID": 16, "context": "The National Institute of Standards and Technology (NIST) Speaker Recognition Evaluation (SRE) 2006 database which has significant telephone channel noise was used to assess voice conversion spoofing countermeasures in [13\u201317].", "startOffset": 219, "endOffset": 226}, {"referenceID": 17, "context": "In [18], a so-called AVspoof database includes replay, speech synthesis and voice conversion spoofing attacks to simulate realistic scenarios, which re-recorded synthetic or voiceconverted speech using multiple mobile devices.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "Noisy Database In order to represent the practical application scenarios for spoofing detection, we attempt to design a database in additive noisy environments based on the ASVspoof 2015 challenge database [19].", "startOffset": 206, "endOffset": 210}, {"referenceID": 18, "context": "More details and protocols about the ASVspoof database can be found in [19].", "startOffset": 71, "endOffset": 75}, {"referenceID": 19, "context": "A subset of three types of noise, white noise, speech babble and vehicle interior noise, are selected from NOISEX-92 database [20].", "startOffset": 126, "endOffset": 130}, {"referenceID": 20, "context": "Another two types mixed noise, street noise and cafe noise, are selected from QUTNOISE database [21].", "startOffset": 96, "endOffset": 100}, {"referenceID": 20, "context": "These are standard types of additive noise used for speech recognition [21\u201323], speaker verification [24, 25] and speech enhancement [26].", "startOffset": 71, "endOffset": 78}, {"referenceID": 21, "context": "These are standard types of additive noise used for speech recognition [21\u201323], speaker verification [24, 25] and speech enhancement [26].", "startOffset": 71, "endOffset": 78}, {"referenceID": 22, "context": "These are standard types of additive noise used for speech recognition [21\u201323], speaker verification [24, 25] and speech enhancement [26].", "startOffset": 71, "endOffset": 78}, {"referenceID": 23, "context": "These are standard types of additive noise used for speech recognition [21\u201323], speaker verification [24, 25] and speech enhancement [26].", "startOffset": 101, "endOffset": 109}, {"referenceID": 24, "context": "These are standard types of additive noise used for speech recognition [21\u201323], speaker verification [24, 25] and speech enhancement [26].", "startOffset": 101, "endOffset": 109}, {"referenceID": 25, "context": "These are standard types of additive noise used for speech recognition [21\u201323], speaker verification [24, 25] and speech enhancement [26].", "startOffset": 133, "endOffset": 137}, {"referenceID": 26, "context": "This filter emphasizes the frequencies around 3 kHz to 6 kHz where the human ear is most sensitive and give a lower response for the very high and very low frequencies to which the ear is less sensitive [27].", "startOffset": 203, "endOffset": 207}, {"referenceID": 27, "context": "Feature extraction Similar to our previous system described in [28, 29], six types of feature are extracted.", "startOffset": 63, "endOffset": 71}, {"referenceID": 28, "context": "Feature extraction Similar to our previous system described in [28, 29], six types of feature are extracted.", "startOffset": 63, "endOffset": 71}, {"referenceID": 29, "context": "\u2022 IF: Instantaneous frequency [30] is the derivative of the phase along time axis and captures the temporal information of phase.", "startOffset": 30, "endOffset": 34}, {"referenceID": 30, "context": "\u2022 BPD: Baseband phase difference [31] is another phase feature derived from IF and baseband STFT.", "startOffset": 33, "endOffset": 37}, {"referenceID": 31, "context": "\u2022 GD: Group delay [32] is a representation of filter phase response, which is defined as the negative derivative of the Fourier transform phase.", "startOffset": 18, "endOffset": 22}, {"referenceID": 31, "context": "The MGD [32] feature of frame n is calculated as:", "startOffset": 8, "endOffset": 12}, {"referenceID": 28, "context": "Our previous multilayer perceptron (MLP) based spoofing speech detection system [29] is used in this work.", "startOffset": 80, "endOffset": 84}, {"referenceID": 28, "context": "The best performance of the clean classifier is obtained in the case of testing on clean data, which can be found in our previous work [29].", "startOffset": 135, "endOffset": 139}, {"referenceID": 28, "context": "Because the classifier used in these experiments is the same as that of our previous work [29], these results are comparable with the results in clean condition.", "startOffset": 90, "endOffset": 94}, {"referenceID": 28, "context": "Clean indicates the results of our previous work [29].", "startOffset": 49, "endOffset": 53}, {"referenceID": 32, "context": "This may be due to that the LPC filter is not robust in noisy environments [33], which affects the quality of RLMS.", "startOffset": 75, "endOffset": 79}, {"referenceID": 28, "context": "This is consistent with the results in clean condition [29].", "startOffset": 55, "endOffset": 59}, {"referenceID": 28, "context": "Clean indicates the results of our previous work [29].", "startOffset": 49, "endOffset": 53}], "year": 2016, "abstractText": "Spoofing detection for automatic speaker verification (ASV), which is to discriminate between live speech and attacks, has received increasing attentions recently. However, all the previous studies have been done on the clean data without significant additive noise. To simulate the real-life scenarios, we perform a preliminary investigation of spoofing detection under additive noisy conditions, and also describe an initial database for this task. The noisy database is based on the ASVspoof challenge 2015 database and generated by artificially adding background noises at different signal-to-noise ratios (SNRs). Five different additive noises are included. Our preliminary results show that using the model trained from clean data, the system performance degrades significantly in noisy conditions. Phasebased feature is more noise robust than magnitude-based features. And the systems perform significantly differ under different noise scenarios.", "creator": "LaTeX with hyperref package"}}}