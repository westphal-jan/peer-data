{"id": "1602.03609", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2016", "title": "Attentive Pooling Networks", "abstract": "In this work, we propose Attentive Pooling (AP), a two-way attention mechanism for discriminative model training. In the context of pair-wise ranking or classification with neural networks, AP enables the pooling layer to be aware of the current input pair, in a way that information from the two input items can directly influence the computation of each other's representations. Along with such representations of the paired inputs, AP jointly learns a similarity measure over projected segments (e.g. trigrams) of the pair, and subsequently, derives the corresponding attention vector for each input to guide the pooling. Our two-way attention mechanism is a general framework independent of the underlying representation learning, and it has been applied to both convolutional neural networks (CNNs) and recurrent neural networks (RNNs) in our studies. The empirical results, from three very different benchmark tasks of question answering/answer selection, demonstrate that our proposed models outperform a variety of strong baselines and achieve state-of-the-art performance in all the benchmarks.", "histories": [["v1", "Thu, 11 Feb 2016 03:06:33 GMT  (917kb,D)", "http://arxiv.org/abs/1602.03609v1", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["cicero dos santos", "ming tan", "bing xiang", "bowen zhou"], "accepted": false, "id": "1602.03609"}, "pdf": {"name": "1602.03609.pdf", "metadata": {"source": "META", "title": "Attentive Pooling Networks", "authors": ["Cicero dos Santos", "Ming Tan", "Bing Xiang", "Bowen Zhou"], "emails": ["CICERONS@US.IBM.COM", "MINGTAN@US.IBM.COM", "BINGXIA@US.IBM.COM", "ZHOU@US.IBM.COM"], "sections": [{"heading": "1. Introduction", "text": "Recent years have shown that this type of learning is based not only on recurrent neural networks, but also on recurrent neural networks. Another important family of machine learning tasks revolves around pairwise ranking or classification, which have a wide range of applications, including, but not limited to, answering questions, paraphrasing and other pairwise matching models. Current state-of-the-art models typically include NN-based representation for the input pair, followed by a discriminatory ranking or classification model. For example, a constellation (or RNN pooling) is used to use independently distributed representations of representations of representations of representations."}, {"heading": "2. Neural Networks for Answer Selection", "text": "Various neural network architectures have recently been proposed to match semantically related text segments (Yu et al., 2014; Hu et al., 2014; dos Santos et al., 2015; Wang & Nyberg, 2015; Severyn & Moschitti, 2015; Tan et al., 2015).In this section, we briefly consider two NNarchitectures previously applied to the solution selection task: QA-CNN (Feng et al., 2015) and QAbiLSTM (Tan et al., 2015).In the face of a pair (q, a) consisting of a question q and a candidate, both networks evaluate the pair by first computing independent continuous vector representations rq and ra, and then the cosine similarity between these two vectors.In Figure 1, we present a common representation of these two neural networks, with the first layer in QA-CNN and QAbiLSTM converting the word sequences QA-Word-huin word-W-W-W-W-d-W-d."}, {"heading": "2.1. Convolution", "text": "Considering the sequence qemb = {rw1,..., rwM}, we define the matrix Zq = [z1,..., zM] as a matrix in which each column contains a vector zm-Rdk, which is the concatenation of a sequence of k word embeddings centralized in the mth word of the question. Output of the folding with c filters over the question q is calculated as follows: Q = W 1Zq + b1 (1), where each column m in Q-Rc-M contains features extracted in a context window around the mth word of q. Matrix W 1 and vector b1 are parameters to be learned. The number of constitutive filters c and the size of the word context window k are hyperparameters to be selected by the user. Similarly, and using the same NN parameters W 1 and b1, we calculate the word A-L (the answer A-L)."}, {"heading": "2.2. Bidirectional LSTM (biLSTM)", "text": "Our LSTM implementation is similar to that in (Graves et al., 2013) with minor changes. Given the sequence qemb = {rw1,..., rwM}, the hidden vector h (t) (with size H) at step t is updated as follows: it = \u03c3 (We wt + Uih (t \u2212 1) + bi) (3) ft = \u03c3 (Wfr wt + Ufh (t \u2212 1) + bf) (4) ot = \u03c3 (Wor wt + Uoh (t \u2212 1) + bo) (5) C amount = tanh (Wmr wt + Umh (t \u2212 1) + bm) (6) Ct = it."}, {"heading": "2.3. Scoring and Training Procedure", "text": "Considering the matrices Q and A, we calculate the vector representations rq-Rq and ra-Rq by applying column-by-column maximum pooling over Q and A, followed by nonlinearity. Formally, the j-th elements of the vectors rq and ra are calculated as follows: [rq] j = tanh (max1 < m < M [Qj, m]) (9) [ra] j = tanh (max 1 < l < l < L [Aj, l]) (10) The last layer in QA-CNN and QA-biLSTM evaluates the input pair (q, a) by calculating the cosmic similarity between the two representations: s (q, a) = rq.ra-ra-rq-ra-ra-ra-ra-ra-ra (11) < both networks are trained by minimizing a pairwise rank loss function over the learning group D by calculating the input of each pair: s (q, a) = rqra-ra-ra-ra (two pairs)."}, {"heading": "3. Attentive Pooling Networks for Answer Selection", "text": "It is a system that allows the pooling layer to be aware of the current input pairings of Q = q q, in a way that can directly influence the calculation of the answer to the question q, in a way that allows the pooling process to be carried out in the same way as the pooling process. < < < > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > >"}, {"heading": "4. Related Work", "text": "Recently, deep learning (DL) approaches to this task have paid off, achieving significant outperformance compared to traditional non-DL methods, for example in (Yu et al., 2014; Feng et al., 2015; Severyn & Moschitti, 2015) the authors generate the representations of questions and answers one by one and achieve a QA pair by placing a metric of similarity at the top of these representations. Wang & Nyberg (2015) first learns common feature vectors from a common short-term memory (LSTM) that combines questions and answers, and then turns the task into a learning-to-rank metric."}, {"heading": "5. Experimental Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Datasets", "text": "We apply AP-CNN, AP-biLSTM, QA-CNN, and QAbiLSTM to three different sets of answers: Insur-anceQA, TREC-QA, and WikiQA. These records contain text from different domains and have different characteristics. Table 1 presents some statistics about the records, including the number of questions in each set, the average length of questions (M) and answers (L), the average number of answers from candidates in the dev / test sets, and the average ratio between the length of questions and their truth-based answers. InsuranceQA2 is a recently released large-scale, factual QA data set from the insurance domain. This data set provides a training set, a validation set, and two sets of tests. We see no obvious categorical differentiation between the two sets of questions."}, {"heading": "5.2. Word Embeddings", "text": "To be able to compare our results with those of previous work fairly, we use two different sets of pre-trained word embeddings: For the InsuranceQA dataset, we use the 100-dimensional vectors trained by Feng et al. (2015) with word2vec (Mikolov et al., 2013); and after Wang & Nyberg (2015), Tan et al. (2015) and Yin et al. (2015), we use the 300-dimensional vectors trained with word2vec for the TREC-QA and WikiQA datasets, which are publicly available on the website of this Tool5."}, {"heading": "5.3. Neural Networks Setup", "text": "In Table 2 we show the selected hyperparameter values, which were adjusted using the validation sets. We try to use the same hyperparameters for all three datasets as much as possible. We use a size 3 context window for InsuranceQA, while we set this parameter to 4 for TREC-QA and WikiQA. Normally, the best results are achieved using the selected hyperparameters in 15 to 25 training periods. For AP-CNN, APbiLSTM and QA-LSTM, we also use a learning rate plan, which reduces the learning rate according to the training period. Following dos Santos & Zadrozny (2014), the best results are usually achieved using 15 to 25 training periods."}, {"heading": "6. Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. InsuranceQA", "text": "In Table 3, we present the experimental results of the four NNs of the QAP insurance QAP architecture, even though QAP QAP QAP data is evaluated faster; the results are in terms of accuracy, which equals precision at the top. In the lower part of this table, we can see that AP-CNN outperforms QA-CNN by a wide margin in both sets of tests, as well as in the development environment. AP-biLSTM also outperforms QA-biLSTM data in all three sets. AP-CNN and APbiLSTM have similar performance capabilities.In the upper part of Table 3, we present the results of two state-of-the-art systems for this dataset. In (Feng et al., 2015), the authors present a CNN architecture that resembles QA-CNN but uses a different similarity metric instead of cosmic similarity. In (Tan et al., 2015), the authors use a biLTSM architecture that requires consistent attention."}, {"heading": "6.2. TREC-QA", "text": "In Table 4, we present the experimental results of the four NNs for the TREC-QA dataset, which relate to mean mean mean precision (MAP) and mean reciprocal rank (MRR), which are normally used in previous work with the same dataset. We use the official Trec evaluation index to calculate MAP and MRR. In Table 4, we see that AP-CNN outperforms QA-CNN by a wide margin in both metrics. AP-biLSTM outperforms the QA-biLSTM, but its performance is not as good as AP-CNN.At the top of Table 4, we present the results of three recent work using TREC-QA as a benchmark. In (Wang & Nyberg, 2015), the authors present an LTSM architecture for selecting the answers. Their best result consists of a combination of LSTM and the BM25 algorithm. In (Seurn & Moschitti, 2015), the authors present the word based on the QR architecture of the QR-MN."}, {"heading": "6.3. WikiQA", "text": "Table 5 shows the experimental results of the four NNs for the WikiQA dataset. As in the other two datasets, AP-CNN performs better than QA-CNN, and AP-biLSTM performs better than QA-biLSTM. The performance difference between AP-CNN and QA-CNN is smaller than that for the insurance QA dataset. We believe this is due to the fact that the average size of responses in WikiQA (25) is much smaller than in insurance QA (95). Attentive pooling is expected to have a greater impact on datasets with longer response / question lengths. In Table 5, we also present the results of two recent papers using WikiQA as a benchmark. Yang et al. (2015) present a Bigram-CNN model with average pooling. In (Yin et al., 2015) the authors propose an attention-based CNN. To make a fair comparison, we refer AP to the results of both of the Yin the table."}, {"heading": "6.4. Attentive Pooling Visualization", "text": "Figures 5 and 6 show two thermal images of two Insurance QA test questions, which were correctly answered by APCNN and whose answers are more than 100 words long. The stronger the color of a word in the question (answer), the greater the attention weight in \u03c3q (\u03c3a) of the trigram centered on that word. Indeed, as we can see from the images, the mechanism of attentive merging focuses more on the segments of the answer that interact to some extent with the question, and vice versa."}, {"heading": "7. Conclusions", "text": "The main contributions of the paper are: (1) AP is more general than 6Yin et al. (Yin et al., 2015) Report 0.6921 (MAP) and 0.7108 (MRR) when handmade features are used in addition to Word Embeddings. (2) We show that AP can be effectively used with CNNs and biLSTM in the context of the response selection task by using three different benchmark datasets; (3) our experimental results show that AP helps CNN deal with large input texts; (4) we present new state-of-the-art results for InsuranceQA and TREC QA datasets. (5) For the WikiQA datasets, we show that our results so far are not the best used for handmade methods."}, {"heading": "Acknowledgements", "text": "The authors thank Piero Molino for creating the script used to create the text heatmaps presented in this work."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "In ICLR,", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Learning character-level representations for part-of-speech tagging", "author": ["dos Santos", "Cicero Nogueira", "Zadrozny", "Bianca"], "venue": "In Proceedings of the 31st International Conference on Machine Learning, JMLR: W&CP volume", "citeRegEx": "Santos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2014}, {"title": "Applying deep learning to answer selection: A study and an open task", "author": ["Feng", "Minwei", "Xiang", "Bing", "Glass", "Michael R", "Wang", "Lidan", "Zhou", "Bowen"], "venue": "arXiv preprint:1508.01585,", "citeRegEx": "Feng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2015}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Graves", "Alex", "Mohamed", "Abdel-rahman", "Hinton", "Geoffrey"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Graves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Teaching machines to read and comprehend", "author": ["Hermann", "Karl Moritz", "Kocisky", "Tomas", "Grefenstette", "Edward", "Espeholt", "Lasse", "Kay", "Will", "Suleyman", "Mustafa", "Blunsom", "Phil"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "Jurgen"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Reasoning about entailment with neural attention", "author": ["Rockt\u00e4schel", "Tim", "Grefenstette", "Edward", "Hermann", "Karl Moritz", "Kocisk\u00fd", "Tom\u00e1s", "Blunsom", "Phil"], "venue": "CoRR, abs/1509.06664,", "citeRegEx": "Rockt\u00e4schel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Learning to rank short text pairs with convolutional deep neural networks", "author": ["Severyn", "Aliaksei", "Moschitti", "Alessandro"], "venue": "Proceedings of SIGIR,", "citeRegEx": "Severyn et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Severyn et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc V"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Lstm-based deep learning models for nonfactoid answer selection", "author": ["Tan", "Ming", "dos Santos", "Cicero", "Xiang", "Bing", "Zhou", "Bowen"], "venue": "CoRR, abs/1511.04108,", "citeRegEx": "Tan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tan et al\\.", "year": 2015}, {"title": "Probabilistic tree-edit models with structured latent variables for textual entailment and question answering", "author": ["Wang", "Mengqiu", "Manning", "Christopher"], "venue": "The Proceedings of the 23rd International Conference on Computational Linguistics (COLING),", "citeRegEx": "Wang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2010}, {"title": "What is the jeopardy model? a quasi-synchronous grammar for qa", "author": ["Wang", "Mengqiu", "Smith", "Noah", "Teruko", "Mitamura"], "venue": "The Proceedings of EMNLP-CoNLL,", "citeRegEx": "Wang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2007}, {"title": "Faq-based question answering via word alignment", "author": ["Wang", "Zhiguo", "Ittycheriah", "Abraham"], "venue": "arXiv preprint arXiv:1507.02628,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "tagspace: Semantic embeddings from hashtags", "author": ["Weston", "Jason", "Chopra", "Sumit", "Adams", "Keith"], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Weston et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "Wikiqa: A challenge dataset for open-domain question answering", "author": ["Yang", "Yi", "Yih", "Wen-tau", "Meek", "Christopher"], "venue": "In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Answer extraction as sequence tagging with tree edit distance", "author": ["Yao", "Xuchen", "Durme", "Benjamin", "Clark", "Peter"], "venue": "Proceedings of NAACL-HLT,", "citeRegEx": "Yao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2013}, {"title": "Question answering using enhanced lexical semantic models", "author": ["Yih", "Wen-tau", "Chang", "Ming-Wei", "Meek", "Christopher", "Pastusiak", "Andrzej"], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguist (ACL),", "citeRegEx": "Yih et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2013}, {"title": "ABCNN: attention-based convolutional neural network for modeling sentence", "author": ["Yin", "Wenpeng", "Sch\u00fctze", "Hinrich", "Xiang", "Bing", "Zhou", "Bowen"], "venue": "pairs. CoRR,", "citeRegEx": "Yin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2015}, {"title": "Deep learning for answer sentence selection", "author": ["Yu", "Lei", "Hermann", "Karl M", "Blunsom", "Phil", "Pulman", "Stephen"], "venue": "NIPS Deep Learning Workshop,", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": ", 2015), machine translation (Bahdanau et al., 2015) and factoid question answering (Hermann et al.", "startOffset": 29, "endOffset": 52}, {"referenceID": 4, "context": ", 2015) and factoid question answering (Hermann et al., 2015).", "startOffset": 39, "endOffset": 61}, {"referenceID": 14, "context": "For example, a convolution (or a RNN) and a max-pooling is used to independently construct distributed vector representations of the input pair, followed by a large-margin training (Hu et al., 2014; Weston et al., 2014; Shen et al., 2014; dos Santos et al., 2015).", "startOffset": 181, "endOffset": 263}, {"referenceID": 19, "context": "Different neural network architectures have been recently proposed to perform matching of semantically related text segments (Yu et al., 2014; Hu et al., 2014; dos Santos et al., 2015; Wang & Nyberg, 2015; Severyn & Moschitti, 2015; Tan et al., 2015).", "startOffset": 125, "endOffset": 250}, {"referenceID": 10, "context": "Different neural network architectures have been recently proposed to perform matching of semantically related text segments (Yu et al., 2014; Hu et al., 2014; dos Santos et al., 2015; Wang & Nyberg, 2015; Severyn & Moschitti, 2015; Tan et al., 2015).", "startOffset": 125, "endOffset": 250}, {"referenceID": 2, "context": "In this section we briefly review two NN architectures that have previously been applied to the answer selection task: QA-CNN (Feng et al., 2015) and QAbiLSTM (Tan et al.", "startOffset": 126, "endOffset": 145}, {"referenceID": 10, "context": ", 2015) and QAbiLSTM (Tan et al., 2015).", "startOffset": 21, "endOffset": 39}, {"referenceID": 3, "context": "Our LSTM implementation is similar to the one in (Graves et al., 2013) with minor modification.", "startOffset": 49, "endOffset": 70}, {"referenceID": 14, "context": "As in (Weston et al., 2014; Hu et al., 2014), we define the training objective as a hinge loss:", "startOffset": 6, "endOffset": 44}, {"referenceID": 17, "context": "Traditional work on answer selection have normally used feature engineering, linguistic tools, or external resources (Yih et al., 2013; Wang & Manning, 2010; Wang et al., 2007).", "startOffset": 117, "endOffset": 176}, {"referenceID": 12, "context": "Traditional work on answer selection have normally used feature engineering, linguistic tools, or external resources (Yih et al., 2013; Wang & Manning, 2010; Wang et al., 2007).", "startOffset": 117, "endOffset": 176}, {"referenceID": 19, "context": "For example, in (Yu et al., 2014; Feng et al., 2015; Severyn & Moschitti, 2015), the authors generate the representations of questions and answers separately, and score a QA pair using a similarity metric on top of these representations.", "startOffset": 16, "endOffset": 79}, {"referenceID": 2, "context": "For example, in (Yu et al., 2014; Feng et al., 2015; Severyn & Moschitti, 2015), the authors generate the representations of questions and answers separately, and score a QA pair using a similarity metric on top of these representations.", "startOffset": 16, "endOffset": 79}, {"referenceID": 2, "context": ", 2014; Feng et al., 2015; Severyn & Moschitti, 2015), the authors generate the representations of questions and answers separately, and score a QA pair using a similarity metric on top of these representations. In Wang & Nyberg (2015), first a joint feature vectors is learned from a joint long short-term memory (LSTM) model connecting questions and answers, and then the task is converted into a learning-to-rank problem.", "startOffset": 8, "endOffset": 236}, {"referenceID": 0, "context": "At the same time, attention-based systems have shown very promising results on a variety of NLP tasks, such as machine translation (Bahdanau et al., 2015; Sutskever et al., 2014), caption generation (Xu et al.", "startOffset": 131, "endOffset": 178}, {"referenceID": 9, "context": "At the same time, attention-based systems have shown very promising results on a variety of NLP tasks, such as machine translation (Bahdanau et al., 2015; Sutskever et al., 2014), caption generation (Xu et al.", "startOffset": 131, "endOffset": 178}, {"referenceID": 4, "context": ", 2015) and factoid question answering (Hermann et al., 2015).", "startOffset": 39, "endOffset": 61}, {"referenceID": 10, "context": "Unlike (Tan et al., 2015), in which attention is imposed only on answer embedding generation, AP-CNN and AP-biLSTM consider the interdependence between questions and answers.", "startOffset": 7, "endOffset": 25}, {"referenceID": 10, "context": "Tan et al. (2015) developed an attentive reader based on bidirectional long short-term memory, which emphasizes certain part of the answer according to the question embedding.", "startOffset": 0, "endOffset": 18}, {"referenceID": 7, "context": "Rockt\u00e4schel et al. (2015), propose a two-way attention method that is inspired by bidirectional LSTMs that read a sequence and its reverse for improved encoding.", "startOffset": 0, "endOffset": 26}, {"referenceID": 7, "context": "Rockt\u00e4schel et al. (2015), propose a two-way attention method that is inspired by bidirectional LSTMs that read a sequence and its reverse for improved encoding. Their approach, which is designed for RNNs only, differs in many aspects from the approach described in this work, which can be easily applied for CNNs and RNNs. Yin et al. (2015) present a two-way attention mechanism that is tailored to CNNs.", "startOffset": 0, "endOffset": 342}, {"referenceID": 18, "context": "ences between their approach and this work are: (1) they use a simple Euclidean distance to compute the interdependence between the two input texts, while in this work we apply similarity metric learning, which has the potential to learn better ways to measure the interaction between segments of the input items; (2) the models in (Yin et al., 2015) compute the attention vector using sum-pooling over the alignment matrix and use the convolutional outputs updated by the attention as the input for another level of convolutional layer.", "startOffset": 332, "endOffset": 350}, {"referenceID": 2, "context": "More details can be found in (Feng et al., 2015).", "startOffset": 29, "endOffset": 48}, {"referenceID": 11, "context": "TREC-QA3 was created by Wang et al. (2007) based on", "startOffset": 24, "endOffset": 43}, {"referenceID": 16, "context": "git The data is obtained from (Yao et al., 2013)", "startOffset": 30, "endOffset": 48}, {"referenceID": 6, "context": "(2015) using word2vec (Mikolov et al., 2013).", "startOffset": 22, "endOffset": 44}, {"referenceID": 2, "context": "For the InsuranceQA dataset, we use the 100dimensional vectors that were trained by Feng et al. (2015) using word2vec (Mikolov et al.", "startOffset": 84, "endOffset": 103}, {"referenceID": 2, "context": "For the InsuranceQA dataset, we use the 100dimensional vectors that were trained by Feng et al. (2015) using word2vec (Mikolov et al., 2013). Following Wang & Nyberg (2015), Tan et al.", "startOffset": 84, "endOffset": 173}, {"referenceID": 2, "context": "For the InsuranceQA dataset, we use the 100dimensional vectors that were trained by Feng et al. (2015) using word2vec (Mikolov et al., 2013). Following Wang & Nyberg (2015), Tan et al. (2015) and Yin et al.", "startOffset": 84, "endOffset": 192}, {"referenceID": 2, "context": "For the InsuranceQA dataset, we use the 100dimensional vectors that were trained by Feng et al. (2015) using word2vec (Mikolov et al., 2013). Following Wang & Nyberg (2015), Tan et al. (2015) and Yin et al.(2015), for the TREC-QA and the WikiQA datasets we use the 300dimensional vectors that were trained using word2vec and are publicly available on the website of this tool5.", "startOffset": 84, "endOffset": 213}, {"referenceID": 15, "context": "bz2 The data is obtained from (Yang et al., 2015) https://code.", "startOffset": 30, "endOffset": 49}, {"referenceID": 2, "context": "In (Feng et al., 2015), the authors present a CNN architecture that is similar to QA-CNN, but that uses a different similarity metric instead of cosine similarity.", "startOffset": 3, "endOffset": 22}, {"referenceID": 10, "context": "In (Tan et al., 2015), the authors use a biLTSM architecture that employs unidirectional attention.", "startOffset": 3, "endOffset": 21}, {"referenceID": 2, "context": "On the other hand, as also found in (Feng et al., 2015), QA-CNN requires at least 2000 filters to achieve more than 60% accuracy on Insur-", "startOffset": 36, "endOffset": 55}, {"referenceID": 18, "context": "In (Yin et al., 2015), the authors propose an attention-based CNN.", "startOffset": 3, "endOffset": 21}, {"referenceID": 15, "context": "Yang et al. (2015), present a bigram CNN model with average pooling.", "startOffset": 0, "endOffset": 19}, {"referenceID": 18, "context": "(Yin et al., 2015) report 0.", "startOffset": 0, "endOffset": 18}], "year": 2016, "abstractText": "In this work, we propose Attentive Pooling (AP), a two-way attention mechanism for discriminative model training. In the context of pair-wise ranking or classification with neural networks, AP enables the pooling layer to be aware of the current input pair, in a way that information from the two input items can directly influence the computation of each other\u2019s representations. Along with such representations of the paired inputs, AP jointly learns a similarity measure over projected segments (e.g. trigrams) of the pair, and subsequently, derives the corresponding attention vector for each input to guide the pooling. Our two-way attention mechanism is a general framework independent of the underlying representation learning, and it has been applied to both convolutional neural networks (CNNs) and recurrent neural networks (RNNs) in our studies. The empirical results, from three very different benchmark tasks of question answering/answer selection, demonstrate that our proposed models outperform a variety of strong baselines and achieve state-of-the-art performance in all the benchmarks.", "creator": "LaTeX with hyperref package"}}}