{"id": "1602.03779", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2016", "title": "Network of Bandits insure Privacy of end-users", "abstract": "The distribution of the best arm identification task on the user's devices offers several advantages for application purposes: scalability, reduction of deployment costs and privacy. We propose a distributed version of the algorithm Successive Elimination using a simple architecture based on a single server which synchronizes each task executed on the user's devices. We show that this algorithm is optimal in terms of transmitted number of bits and is optimal up to logarithmic factors in terms to number of pulls per player. Finally, we propose an extension of this approach to distribute the contextual bandit algorithm Bandit Forest, which is able to finely exploit the user's data while guaranteeing the privacy.", "histories": [["v1", "Thu, 11 Feb 2016 15:55:59 GMT  (182kb,D)", "http://arxiv.org/abs/1602.03779v1", null], ["v2", "Sun, 14 Feb 2016 16:28:45 GMT  (182kb,D)", "http://arxiv.org/abs/1602.03779v2", null], ["v3", "Mon, 22 Feb 2016 12:26:15 GMT  (182kb,D)", "http://arxiv.org/abs/1602.03779v3", null], ["v4", "Tue, 1 Mar 2016 17:03:16 GMT  (182kb,D)", "http://arxiv.org/abs/1602.03779v4", null], ["v5", "Wed, 30 Mar 2016 15:32:59 GMT  (182kb,D)", "http://arxiv.org/abs/1602.03779v5", null], ["v6", "Tue, 26 Apr 2016 07:37:45 GMT  (0kb,I)", "http://arxiv.org/abs/1602.03779v6", "Theorem 1 does not hold. The proof is wrong. The speed-up factor is not N/2. So, please withdraw the manuscript. Regards, Rapha\\\"el F\\'eraud"], ["v7", "Mon, 6 Jun 2016 12:56:21 GMT  (234kb,D)", "http://arxiv.org/abs/1602.03779v7", "Theorem 1 does not hold. The proof is wrong. The speed-up factor is not N/2. So, please withdraw the manuscript. Regards, Rapha\\\"el F\\'eraud"], ["v8", "Mon, 19 Sep 2016 14:10:21 GMT  (258kb,D)", "http://arxiv.org/abs/1602.03779v8", null], ["v9", "Tue, 11 Oct 2016 07:28:28 GMT  (244kb,D)", "http://arxiv.org/abs/1602.03779v9", null], ["v10", "Mon, 5 Dec 2016 15:10:40 GMT  (326kb,D)", "http://arxiv.org/abs/1602.03779v10", null], ["v11", "Sat, 17 Dec 2016 17:24:05 GMT  (365kb,D)", "http://arxiv.org/abs/1602.03779v11", null], ["v12", "Mon, 6 Feb 2017 13:09:27 GMT  (369kb,D)", "http://arxiv.org/abs/1602.03779v12", null], ["v13", "Mon, 20 Mar 2017 14:04:42 GMT  (367kb,D)", "http://arxiv.org/abs/1602.03779v13", null], ["v14", "Wed, 29 Mar 2017 09:42:40 GMT  (369kb,D)", "http://arxiv.org/abs/1602.03779v14", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DC cs.LG", "authors": ["rapha\\\"el f\\'eraud"], "accepted": false, "id": "1602.03779"}, "pdf": {"name": "1602.03779.pdf", "metadata": {"source": "CRF", "title": "Network of Bandits", "authors": ["Rapha\u00ebl F\u00e9raud"], "emails": ["raphael.feraud@orange.com"], "sections": [{"heading": "1 Introduction", "text": "Since the beginning of this century, an enormous amount of connected devices has been in use. Together, these devices can incur enormous costs through wired and wireless networks, generating infinite streams of events. By interacting with event streams, machine learning algorithms are used, for example, to optimize the selection of ads on a website, select the best human machine interface, recommend products in a webshop to ensure the self-sufficiency of the user's top boxes, assign the best wireless network to mobile phones. As the Internet of Things grows, the number of decisions (or actions) taken by more and more autonomous devices will continue to increase. In this context, the distribution of machine learning algorithms to the user's devices offers crucial advantages: scalability, thanks to the reduction in usage costs, thanks to the elimination of centralized processing archi-tecture, \u2022 privacy, by processing the data of its own devices. However, the massive distribution of machine learning algorithms on file reams raises two major concerns."}, {"heading": "2 Distributed Action Selection", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Principle", "text": "The massive distribution of the best arm identification task among the user's devices is a collaborative game. For example, when a mobile application performs an action such as personalizing its user interface, the user receives feedback. This feedback is used to update the estimated mean reward of the chosen action given the mobile phone. If the mobile application wants to eliminate the action, it sends it to the synchronization system. If enough mobile phones want to eliminate the action, the synchronization system sends the suppressed action to each mobile phone. In theory, any device can be used as a synchronization system. In practice, however, the synchronization system must be accessible at all times, and therefore a server must be used to exchange information between devices (see Figure 1)."}, {"heading": "2.2 Algorithm", "text": "Without losing generality to model the distribution of the best arm identification task on the user's devices, we assume that at each step, a player n is drawn according to a probability P (z), with a probability N (z = n) = 1. To simplify the notations, we will use Pn instead of P (z = n) below. Let A be a series of K actions. Let's [0, 1] K be a vector of the limited rewards at a time t, yk (t) be the reward of the action k at a time t, and ynk (t) be the reward of the action k selected by the player n at a time. Let \u00b5nk = E [y n k] = E [yk \u00b7 1z = n] be the expected reward of the action k for the player n."}, {"heading": "3 Analysis", "text": "Theorem 1 says that in comparison to SUCCESSIVE ELIMINATIONEN = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0"}, {"heading": "4 Distribution of contextual bandit algorithms", "text": "The distribution of tasks is a basic task that can be used in most of us. (The most important points are the distribution of the contextual bandit algorithms based on the proposed architecture (see Figure 1), the information of the user remains based on the user deviation. (To extend our results to the contextual bandit problems, we propose to distribute the BANDIT algorithms. (2016) The key concept of the decision tree and random forest approaches is the decision, which can be extended to the decision structures. (In this section we focus on the decision structures, and then we discuss the extension to BANDIT algorithms.) Any results we have extended to the decision structures can be extended to models that combine them."}, {"heading": "5 Conclusion", "text": "On the basis of this massively distributed architecture, we have proposed a distributed version of SUCCESSIVE ELIMINATION, where the best arm identification task is distributed among the user's devices. DISTRIBUTED ACTION SELECTION receives an acceleration factor linearly in the number of players. We have shown that the communication costs are optimal in terms of the number of bits transferred, while the number of moves per player is optimal up to logarithmic factors. This algorithm is a key to address the distribution of BANDIT FOREST. Finally, we have proposed a context-dependent bandit algorithm that is able to accurately exploit the user's data while ensuring privacy."}], "references": [{"title": "Finite-time Analysis of the Multiarmed Bandit Problem", "author": ["P. Auer et al (2002)a] Auer", "N. Cesa Bianchi", "P. Fischer"], "venue": "Machine Learning,47,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer et al (2002)b] Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM J. COMPUT.,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Stoltz: Pure exploration in multi-armed bandits", "author": ["S. Bubeck et al (2009)] Bubeck", "T. Wang"], "venue": null, "citeRegEx": "Bubeck and Wang,? \\Q2009\\E", "shortCiteRegEx": "Bubeck and Wang", "year": 2009}, {"title": "T.:Efficient Optimal Learning for Contextual Bandits, UAI", "author": ["M. Dudik et al (2011)] Dud\u0131\u0301k", "D. Hsu", "S. Kale", "N. Karampatziakis", "J. Langford", "L. Reyzin", "Zhang"], "venue": null, "citeRegEx": "Dud\u0131\u0301k et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dud\u0131\u0301k et al\\.", "year": 2011}, {"title": "PAC Bounds for Multi-armed Bandit and Markov Decision", "author": ["S. Mannor", "Mansour Y"], "venue": "Processes, COLT,", "citeRegEx": "Even.Dar et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Even.Dar et al\\.", "year": 2002}, {"title": "Random Forest for the Contextual Bandit Problem, AISTATS, 2016", "author": ["R. F\u00e9raud et al (2016)] F\u00e9raud", "R. Allesiardo", "T. Urvoy", "F. Cl\u00e9rot"], "venue": null, "citeRegEx": "F\u00e9raud et al\\.,? \\Q2016\\E", "shortCiteRegEx": "F\u00e9raud et al\\.", "year": 2016}, {"title": "Distributed Exploration in Multi-Armed Bandits", "author": ["E. Hillel et al (2013)] Hillel", "Z. Karnin", "Koren", "R.T. Lempel", "O. Somekh"], "venue": null, "citeRegEx": "Hillel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hillel et al\\.", "year": 2013}, {"title": "Thomson sampling: An asymptotically optimal finite time", "author": ["E. Kaufman et al (2012)] Kaufman", "N. Korda", "R. Munos"], "venue": null, "citeRegEx": "Kaufman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kaufman et al\\.", "year": 2012}, {"title": "The epoch-greedy algorithm for contextual multi-armed bandits", "author": ["Langford", "J. Zhang (2007)] Langford", "T. Zhang"], "venue": null, "citeRegEx": "Langford et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2007}, {"title": "The Sample Complexity of Exploration in the Multi-Armed", "author": ["Mannor", "S. Tsitsiklis (2004)] Mannor", "J.N. Tsitsiklis"], "venue": "Bandit Problem,", "citeRegEx": "Mannor et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mannor et al\\.", "year": 2004}, {"title": "Best-Arm Identification in Linear Bandits", "author": ["M. Soare et al (2014)] Soare", "L. Lazaric", "R. Munos"], "venue": null, "citeRegEx": "Soare et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Soare et al\\.", "year": 2014}, {"title": "Generic Exploration and K-armed Voting Bandits", "author": ["T. Urvoy et al (2013)] Urvoy", "F. Cl\u00e9rot", "R. F\u00e9raud", "S. Naamane"], "venue": null, "citeRegEx": "Urvoy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Urvoy et al\\.", "year": 2013}], "referenceMentions": [], "year": 2017, "abstractText": "The distribution of the best arm identification task on the user\u2019s devices offers several advantages for application purposes: scalability, reduction of deployment costs and privacy. We propose a distributed version of the algorithm SUCCESSIVE ELIMINATION using a simple architecture based on a single server which synchronizes each task executed on the user\u2019s devices. We show that this algorithm is optimal in terms of transmitted number of bits and is optimal up to logarithmic factors in terms to number of pulls per player. Finally, we propose an extension of this approach to distribute the contextual bandit algorithm BANDIT FOREST, which is able to finely exploit the user\u2019s data while guaranteeing the privacy.", "creator": "LaTeX with hyperref package"}}}