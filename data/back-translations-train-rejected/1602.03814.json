{"id": "1602.03814", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Feb-2016", "title": "Enabling Basic Normative HRI in a Cognitive Robotic Architecture", "abstract": "Collaborative human activities are grounded in social and moral norms, which humans consciously and subconsciously use to guide and constrain their decision-making and behavior, thereby strengthening their interactions and preventing emotional and physical harm. This type of norm-based processing is also critical for robots in many human-robot interaction scenarios (e.g., when helping elderly and disabled persons in assisted living facilities, or assisting humans in assembly tasks in factories or even the space station). In this position paper, we will briefly describe how several components in an integrated cognitive architecture can be used to implement processes that are required for normative human-robot interactions, especially in collaborative tasks where actions and situations could potentially be perceived as threatening and thus need a change in course of action to mitigate the perceived threats.", "histories": [["v1", "Thu, 11 Feb 2016 18:18:14 GMT  (146kb,D)", "http://arxiv.org/abs/1602.03814v1", "Presented at \"2nd Workshop on Cognitive Architectures for Social Human-Robot Interaction 2016 (arXiv:1602.01868)\""]], "COMMENTS": "Presented at \"2nd Workshop on Cognitive Architectures for Social Human-Robot Interaction 2016 (arXiv:1602.01868)\"", "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.HC", "authors": ["vasanth sarathy", "jason r wilson", "thomas arnold", "matthias scheutz"], "accepted": false, "id": "1602.03814"}, "pdf": {"name": "1602.03814.pdf", "metadata": {"source": "CRF", "title": "Enabling Basic Normative HRI in a Cognitive Robotic Architecture", "authors": ["Vasanth Sarathy", "Jason R. Wilson", "Matthias Scheutz"], "emails": ["vsarathy@cs.tufts.edu,", "wilson@cs.tufts.edu,", "thomas.arnold@tufts.edu", "matthias.scheutz@tufts.edu"], "sections": [{"heading": null, "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to"}, {"heading": "II. BACKGROUND AND RELATED WORK", "text": "Many in the field of HRI have recognized that ethics must influence competent robotic behavior in the social sphere. Various ethical theories and their combinations have been proposed, most often weighing utilitarian approaches against deontic frameworks (e.g. obligatory or prohibited actions). While autonomous social robots do not need to recapitulate models or features of embodied human cognition to ensure the sheer similarity (e.g. the reproduction of \"aggression\" that clouds the moral principle), it is clear that they must, but should not, interact competently in social space."}, {"heading": "III. COMPONENTS FOR NORMATIVE HRI", "text": "Different architectural skills are required in cognitive robot architectures for robots to become morally competent. [2] Here, we focus on three key functionalities: (1) affordability conclusions, (2) analog thinking, and (3) action selection. For example, robots must guide the knife when passing a knife in a socially acceptable manner (affordability perception), while assessing whether the situation as a whole is socially appropriate compared to similar situations (analog thinking), and mitigate perceived threats through the choice of alternative measures (action selection). In previous work, we have developed a computory representation and framework to think about affordability in general (i.e. physical, functional, aesthetic, social, and ethical affordances). [12] We have also implemented a structural mapping machine for analog thinking (action selection), and have the ability to compare and evaluate situations in terms of similarity in structure."}, {"heading": "A. Goal Manager (GM)", "text": "The Goal Manager (GM) is responsible for the adoption of a goal and the compilation of an action script to fulfill that goal and manages the execution of the script. The GM performs these functions in conjunction with the Affordance InferenceComponent and the Analogical Reasoning Component, which we will discuss in more detail below."}, {"heading": "B. Cognitive Affordance Inference", "text": "We have developed a formal rules-based logical representation format and a cognitive achievement sequence algorithm in which the affordability of an object (A) and its perceived characteristics (F) depend on the context (C). Perceived characteristics (F) include color, shape, texture, relationship information, and general information derived from the pipeline of vision (or other sensory systems) that an agent can interpret. Context is representative of the agent's beliefs, goals, desires, and intentions, along with certain other abstract constructs in the agent's narrative situation. Affordability of the object (A) represents the types of action options that could be available to the robot at any given time. We use the Dempster Shafer (DS) theory to infer affordance (F) from object characteristics (F) in contexts (C) [13]. DS theory is an insecurity framework commonly interpreted as a framework of generalization."}, {"heading": "C. Analogical Reasoning", "text": "We use analogous thinking to identify applicable actions that are consistent with the surrounding context, and the process proceeds as follows: Due to a coding of the situation, we perform a series of analogous comparisons with other situations. To perform each comparison, we use the Structure Mapping Engine (SME) [14]. The other situations are stored in memory and come from previous experiences, instructions, observations and demonstrations. Each successful analogous comparison yields a similarity value and a set of candidate conclusions. A comparison of the similarity values of each comparison shows which situations are most similar to the current situation. Candidate conclusions represent information that is known in the other situation and structurally adapts to the new situation. As there is no semantic verification of this information, a further step is necessary to verify each candidate's inference and determine whether it is true in the current situation."}, {"heading": "IV. PROOF-OF-CONCEPT EXAMPLE", "text": "It concerns the question of how it was possible for a person who is able to survive to survive to survive to survive to survive, and how it was possible for a person who is able to survive to survive to survive to survive to survive to survive \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "V. DISCUSSION", "text": "The ability to detect morally and socially charged situations is an important skill of robots in human-robot collaborations. As research into the cognitive abilities of robots advances and robots are equipped with more advanced behavioral skills, it is becoming increasingly important to ensure that robotic actions are monitored, their moral and social implications recognized, and verified that these actions are within societal norms, especially when robotic systems find their way into everyday life. Take, for example, self-driving cars. As these systems develop the ability to monitor and safely navigate roads, it will also be important that they behave within the social and moral expectations of other drivers on the road, which means that we look at their own driving from the perspective of others and consider whether actions lead to morally positive compromises. Our long-term goal is to give robots moral competence. Here, we have taken a step in this direction by proposing promising mechanisms in integrated situations of moral architecture and social competence."}], "references": [{"title": "Moral competence in social robots", "author": ["B.F. Malle", "M. Scheutz"], "venue": "Ethics in Science, Technol. and Eng., 2014 IEEE Int. Symp. on. IEEE, 2014, pp. 1\u20136.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Robotics, ethical theory, and metaethics: A guide for the perplexed", "author": ["K. Abney"], "venue": "Robot ethics: The ethical and social implications of robotics, pp. 35\u201352, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Morality goes beyond mind perception", "author": ["A.E. Monroe", "S. Guglielmo", "B.F. Malle"], "venue": "Psychological Inquiry, vol. 23, no. 2, pp. 179\u2013184, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Towards morally sensitive action selection for autonomous social robots", "author": ["M. Scheutz", "B. Malle", "G. Briggs"], "venue": "Robot and Human Interactive Communication (RO-MAN), 24th IEEE Int. Symp. on. IEEE, 2015, pp. 492\u2013497.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "On how to build a moral machine", "author": ["P. Bello", "S. Bringsjord"], "venue": "Topoi, vol. 32, no. 2, pp. 251\u2013266, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Moral judgment, human motivation, and neural networks", "author": ["R. Sun"], "venue": "Cognitive Computation, vol. 5, no. 4, pp. 566\u2013579, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "An integrated reasoning approach to moral decision-making.", "author": ["M. Dehghani", "E. Tomai", "K.D. Forbus", "M. Klenk"], "venue": "in Proc. of the 23rd AAAI Conf. on Artificial Intelligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Moral decision-making by analogy: Generalizations versus exemplars", "author": ["J.A. Blass", "K.D. Forbus"], "venue": "Proc. of the 29th AAAI Conf. on Artificial Intelligence, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "First steps toward natural human-like HRI", "author": ["M. Scheutz", "P. Schermerhorn", "J. Kramer", "D. Anderson"], "venue": "Autonomous Robots, vol. 22, no. 4, pp. 411\u2013423, May 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Semantic Representation of Objects and Function", "author": ["V. Sarathy", "M. Scheutz"], "venue": "Proc. of the 2015 IROS Workshop on Learning Object Affordances, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1976}, {"title": "The structure-mapping engine: Algorithm and examples", "author": ["B. Falkenhainer", "K.D. Forbus", "D. Gentner"], "venue": "Artificial intelligence, vol. 41, no. 1, pp. 1\u201363, 1989.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1989}], "referenceMentions": [{"referenceID": 0, "context": "Failing to follow the rule will likely result in blame and reprimand from the chef, which then has to be addressed either by apologizing or by offering an explanation as to why the rule violation was justified [2].", "startOffset": 210, "endOffset": 213}, {"referenceID": 1, "context": "obligated or forbidden actions), [3].", "startOffset": 33, "endOffset": 36}, {"referenceID": 2, "context": "Recent work in cognitive science on human moral reasoning, however, has recently yielded insights into intricate relationships between moral norms, emotions, theory of mind, and blame [4], [5].", "startOffset": 184, "endOffset": 187}, {"referenceID": 3, "context": "reproducing \u201caggression\u201d that clouds moral principle), it is clear that to interact competently in social space such systems will incorporate adept perspective taking and reason giving for their actions [6].", "startOffset": 203, "endOffset": 206}, {"referenceID": 4, "context": "reasoning have been building in scope and force as roles for AI and robotics, from self-driving cars and autonomous weapons systems to domestic and healthcare roles, have accelerated entry into the social sphere [7].", "startOffset": 212, "endOffset": 215}, {"referenceID": 5, "context": "meet that challenge [8].", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "MoralDM, for example, as part of the Companions architecture, base moral decision-making on analogies with cultural narratives [9] or generalizations of ar X iv :1 60 2.", "startOffset": 127, "endOffset": 130}, {"referenceID": 7, "context": "stories [10] to determine the appropriate action.", "startOffset": 8, "endOffset": 12}, {"referenceID": 8, "context": "Recognizing how thoroughly moral norms will shape expectations and evaluations of social robots, we situate moral reasoning as an integral feature of the DIARC architecture [11].", "startOffset": 173, "endOffset": 177}, {"referenceID": 0, "context": "Various architectural capabilities are required in cognitive robotic architectures for robots to become morally competent [2].", "startOffset": 122, "endOffset": 125}, {"referenceID": 9, "context": ", physical, functional, aesthetic, social and ethical affordances) [12].", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "DIARC has been used extensively for human-robot interaction in natural language [11].", "startOffset": 80, "endOffset": 84}, {"referenceID": 10, "context": "We use Dempster-Shafer (DS) theory for inferring affordance (A) from object features (F ) in contexts (C) [13].", "startOffset": 106, "endOffset": 110}, {"referenceID": 11, "context": "We use the Structure Mapping Engine (SME) [14] to perform each comparison.", "startOffset": 42, "endOffset": 46}], "year": 2016, "abstractText": "Collaborative human activities are grounded in social and moral norms, which humans consciously and subconsciously use to guide and constrain their behavior: they undergird human societies by prescribing what is obligatory, permitted, prohibited, and optional [1]. In doing so, they enable effective collaboration and prevent emotional and physical harm. Consider a restaurant kitchen where cooks and assistants perform tasks such as passing knives and cutting vegetables. When handing over a knife to the chef, assistants do so in a way that does not look like they are about to stab the chef. Not only will they orient the knife in the right way, but they should take care not to approach the chef menacingly and without prior warning, while the chef has their back to them. The underlying normative principle could be roughly stated as a rule: \u201cIf you need to hand over a potentially dangerous object with a sharp blade, do not point it with the blade at the other person, but rather grasp it carefully by the blade and hand it over with the bland side or handle facing the other person\u201d. The tacit understanding among the kitchen staff is that everyone will abide by this principle, thus enabling safe exchanges of knives and other potentially dangerous objects. Failing to follow the rule will likely result in blame and reprimand from the chef, which then has to be addressed either by apologizing or by offering an explanation as to why the rule violation was justified [2]. Clearly, social and moral norms play an important functional role in the human cognitive architecture: they are at work in perception to detect morally charged contexts and norm violations, they are employed during decision-making and behavior execution, and they are referred to in communications about normative behavior and norm violations. In other words, normative processing is deeply integrated into the human cognitive system and affects virtually every aspect of the architecture (from perception, to reasoning, to action, to communication). Hence, this type of norm-based processing is also critical for robots in many human-robot interaction scenarios (e.g., when helping elderly and disabled persons in assisted living facilities, or assisting humans in assembly tasks in factories or even the space station). Human beings expect their interactants, including intelligent robots, to follow social and moral norms, and disappointing those expectations will lead to impoverished interactions at best, but can lead to emotional and physical harm in the worst cases. In this position paper, we will briefly describe how several components in an integrated cognitive architecture can be used to implement processes that are required for normative human-robot interactions, especially in collaborative tasks where actions and situations could potentially be perceived as threatening and thus need a change in course of action to mitigate the perceived threats. We will focus on affordancebased reasoning to infer complex affordance relationships between an agent and objects in the environment, and analogical reasoning to decide the appropriateness of the action plan by comparing against other past situations.", "creator": "LaTeX with hyperref package"}}}