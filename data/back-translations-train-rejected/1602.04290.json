{"id": "1602.04290", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2016", "title": "Designing Intelligent Instruments", "abstract": "Remote science operations require automated systems that can both act and react with minimal human intervention. One such vision is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, decides which new measurements to take. This innovation implements experimental design and unites it with data analysis in such a way that it completes the cycle of learning. This cycle is the basis of the Scientific Method.", "histories": [["v1", "Sat, 13 Feb 2016 06:28:22 GMT  (2684kb)", "http://arxiv.org/abs/1602.04290v1", "9 pages, 2 figures. Published in the MaxEnt 2007 Proceedings"]], "COMMENTS": "9 pages, 2 figures. Published in the MaxEnt 2007 Proceedings", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["kevin h knuth", "philip m erner", "scott frasso"], "accepted": false, "id": "1602.04290"}, "pdf": {"name": "1602.04290.pdf", "metadata": {"source": "CRF", "title": "Designing Intelligent Instruments", "authors": ["Kevin H. Knuth", "Philip M. Erner", "Scott Frasso"], "emails": [], "sections": [{"heading": null, "text": "The three basic steps of this cycle are hypothesis generation, query and conclusion. Hypothesis generation is done by artificially providing a parameterized set of possible hypotheses to describe the physical system. The query process is performed by a query engine based on Bayesia adaptive exploration, selecting the optimal experiment as the one that maximizes the expected information gain. The query engine is implemented using the nested scanning algorithm, which provides the query engine with a set of posterior samples from which the expected information gain can be estimated. With these computational structures, the instrument will refine its hypotheses and repeat the learning cycle by measuring until the system under investigation is described within a given tolerance. We will demonstrate our first attempts to achieve this goal with an intelligent instrument that has been experimented with using the GO LEMINSTORNBOT keywords, robotics platform 07.05."}, {"heading": "INTRODUCTION", "text": "These operations, which use semi-automated systems that can perform basic tasks such as locomotion and controlled data collection, require human intervention when it comes to deciding where to go, which experiment to perform, and where exactly to place the sensors. However, as we expand to explore more remote worlds, we will demand that our instruments become increasingly autonomous; the vision we present in this paper is that of an intelligent instrument that collects data in an automated manner, and based on what it learns, the instrument decides which new measurements to take. Relevant to our approach are the concepts of cybernetics (Vienna, 1948) and experimental design (1972, various Fordley, 1956)."}, {"heading": "THE EXPERIMENTAL SETUP", "text": "Choosing a problem that is interesting, challenging and revealing at the same time is extremely difficult. Indeed, the problem we have chosen is a toy problem, but one that can easily be extended to problems that occur in the real world. We are looking at an instrument that is designed to locate and characterize a white circle on a black field."}, {"heading": "The Experimental Problem", "text": "We have developed a robotic instrument designed to locate and characterize a white circle on a black background; the instrument is equipped with a light sensor capable of spot measurements; we have deliberately designed the system so that the sensor cannot simply scan the visual scene; such scans result in numerous inconclusive measurements that waste time, energy, and bandwidth; this limited sensor capability is intended and will serve to highlight the performance of the computer techniques we have developed; in addition, the light sensor has a fairly large point distribution function, which we will not consider in this first presentation; instead, we assume that the light sensor returns a measurement that is normally distributed over the mean light intensity, and ignores \"edge effects.\" This is clearly a search problem with an instrument with limited sensor capability; therefore, the results here will easily expand to include a circle similar to the white circle, such as the one that characterizes the small circle."}, {"heading": "The Robot and its Brains", "text": "The instrument is a robotic arm built with the LEGO MINDSTORMS NXT system (Figure 1).The arm has three degrees of freedom, with the possibility to rotate around the vertical axis (z-axis) and at two points around the y-axis (elbow and wrist).This gives the arm access to a large area of the horizontal plane.The light sensor mounted at the end of the arm is required to point vertically down.The LEGO MINDSTORMS NXT Brick is the computer that directly controls the motors and sensors of the robot.The brick is programmed in the NXT-G programming language, which is a variant of LabVIEW. The brick was programmed with a simple program that moves the arm from the home position to a position on the plane and records the light intensity of the robot.After writing the measurement result into a file, the computer reads the LAGO and the home position of the robot communicates with the DATB."}, {"heading": "INFERENCE AND INQUIRY", "text": "(), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (, (), (), (, (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (, (), (), (), (, (), (), (), (), (, (), (, (), (), (, (), (), (, (), (, (), (), (), (, (), (, (, (), (), (, (), (, (), (, (), (), (), (, (), (, (), (, (), (), (, (, (), (), (), (, (), (), (), (, (, (, (), (), (), (), (), (, (), (), (, (), (), (,"}, {"heading": "RESULTS", "text": "While we tested the system by manually transferring the information between the laptop and NXT Brick via a USB connection, we have fully simulated the process in this presentation in MATLAB. The result we present here is typical and dramatically shows that the number of measurements required by an intelligent instrument is much smaller than a similar scanning system. Figure 2A shows the initial stages of the inference query procedure, in which the white area of the circle has not yet been located. Therefore, there are large areas of the measuring space that are potentially equally informative, as indicated by the large regions of essentially identical entropy in Figure 2B. After several iterations, the robot finds a white area that belongs to the circle."}, {"heading": "CONCLUSION", "text": "This paper is an initial investigation into the development of an intelligent instrument that not only draws conclusions from the data, but also decides which measurements are to be made on the basis of what the instrument has learned.The approach used here is based on Bayesian's adaptive exploration, which selects a measurement based on maximizing the entropy of the possible measurements obtained by querying a series of models from the back.The results of this initial investigation are nicely reduced to looking at the examination process as a selection of efficient binary questions that are known to be optimal from an information theory perspective. It should be noted that these binary questions are not firmly connected to the system. Instead, they result in a natural application of maximizing the entropy of potential readings in light of the model, previous data and our previous information. This maximum entropy approach works as long as the noise described by the probability function in 2003 is independent of calibration."}], "references": [{"title": "Of inference and inquiry", "author": ["R.T. Cox"], "venue": "In: R. D. Levine & M. Tribus (eds.) The Maximum Entropy Formalism, Cambridge:MIT Press, pp. 119\u2013167.", "citeRegEx": "Cox,? 1979", "shortCiteRegEx": "Cox", "year": 1979}, {"title": "Theory of Optimal Experiments", "author": ["V.V. Fedorov"], "venue": "New York:Academic.", "citeRegEx": "Fedorov,? 1972", "shortCiteRegEx": "Fedorov", "year": 1972}, {"title": "The engineering of cybernetic systems", "author": ["L. Fry R."], "venue": "In: R.L. Fry (ed.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Baltimore MD, USA, AIP Conf. Proc. 617, Melville NY:AIP, pp. 497\u2013528.", "citeRegEx": "R.,? 2002", "shortCiteRegEx": "R.", "year": 2002}, {"title": "What is a question? In: C", "author": ["K.H. Knuth"], "venue": "Williams (ed.), Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Moscow ID 2002, AIP Conf. Proc. 659, Melville NY:AIP, pp. 227\u2013242.", "citeRegEx": "Knuth,? 2002", "shortCiteRegEx": "Knuth", "year": 2002}, {"title": "Intelligent machines in the 21st century: Automating the processes of inference and inquiry", "author": ["K.H. Knuth"], "venue": "Phil. Trans. Roy. Soc. Lond. A, Triennial Issue. 361(1813):2859\u201373.", "citeRegEx": "Knuth,? 2003", "shortCiteRegEx": "Knuth", "year": 2003}, {"title": "Lattice duality: The origin of probability and entropy", "author": ["K.H. Knuth"], "venue": "Neurocomputing. 67C: 245\u2013 274.", "citeRegEx": "Knuth,? 2005", "shortCiteRegEx": "Knuth", "year": 2005}, {"title": "Valuations on lattices and their application to information theory", "author": ["K.H. Knuth"], "venue": "(Invited paper), Proceedings of the 2006 IEEE World Congress on Computational Intelligence (IEEE WCCI 2006), Vancouver, BC, Canada, July 2006.", "citeRegEx": "Knuth,? 2006", "shortCiteRegEx": "Knuth", "year": 2006}, {"title": "Lattice Theory, Measures and Probability", "author": ["K.H. Knuth"], "venue": "In: K.H. Knuth, A. Caticha, J. Center, A. Giffin, C.C. Rodr\u00edguez (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Saratoga Springs NY USA, AIP Conf. Proc., Melville NY:AIP, In Press.", "citeRegEx": "Knuth,? 2007", "shortCiteRegEx": "Knuth", "year": 2007}, {"title": "On the measure of information provided by an experiment", "author": ["D.V. Lindley"], "venue": "Ann. Math. Statist. 27, 986\u20131005.", "citeRegEx": "Lindley,? 1956", "shortCiteRegEx": "Lindley", "year": 1956}, {"title": "Bayesian adaptive exploration", "author": ["T.J. Loredo"], "venue": "In: G. J. Erickson, Y. Zhai (eds.) Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Jackson Hole WY, USA, AIP Conf. Proc. 707, Melville NY:AIP, pp. 330\u2013346.", "citeRegEx": "Loredo,? 2003", "shortCiteRegEx": "Loredo", "year": 2003}, {"title": "Information-based objective functions for active data selection", "author": ["D.J.C. MacKay"], "venue": "Neural Computation, 4(4), 589\u2013603.", "citeRegEx": "MacKay,? 1992", "shortCiteRegEx": "MacKay", "year": 1992}, {"title": "Maximum entropy sampling and optimal Bayesian experimental design", "author": ["P. Sebastiani", "H.P. Wynn"], "venue": "J. Roy. Stat. Soc. B, 62, 145\u2013157.", "citeRegEx": "Sebastiani and Wynn,? 2000", "shortCiteRegEx": "Sebastiani and Wynn", "year": 2000}, {"title": "Data Analysis A Bayesian Tutorial, (2nd Edition)", "author": ["D.S. Sivia", "J. Skilling"], "venue": "Oxford Univ. Press:Oxford.", "citeRegEx": "Sivia and Skilling,? 2006", "shortCiteRegEx": "Sivia and Skilling", "year": 2006}, {"title": "Bayesian inference and Maximum Entropy Methods in Science and Engineering, San Jose, California, USA", "author": ["J. Skilling"], "venue": "Turning ON and OFF,", "citeRegEx": "Skilling,? \\Q2005\\E", "shortCiteRegEx": "Skilling", "year": 2005}, {"title": "Probabilistic Robotics, MIT Press:Cambridge", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": null, "citeRegEx": "Thrun et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 2005}, {"title": "Cybernetics or Control and Communication in the Animal and the Machine", "author": ["N. Wiener"], "venue": null, "citeRegEx": "Wiener,? \\Q1948\\E", "shortCiteRegEx": "Wiener", "year": 1948}], "referenceMentions": [{"referenceID": 15, "context": "Relevant to our approach are the concepts of cybernetics (Wiener, 1948) and experimental design (Lindley, 1956; Fedorov, 1972), which have been pursued and", "startOffset": 57, "endOffset": 71}, {"referenceID": 8, "context": "Relevant to our approach are the concepts of cybernetics (Wiener, 1948) and experimental design (Lindley, 1956; Fedorov, 1972), which have been pursued and", "startOffset": 96, "endOffset": 126}, {"referenceID": 1, "context": "Relevant to our approach are the concepts of cybernetics (Wiener, 1948) and experimental design (Lindley, 1956; Fedorov, 1972), which have been pursued and", "startOffset": 96, "endOffset": 126}, {"referenceID": 7, "context": "The first author of this paper, having been inspired by the work of Cox (1979) and Fry (2002), has been actively developing a calculus for questions (Knuth, 2002, 2003, 2005, 2006) based on bi-valuations on lattices (Knuth, 2007) with an explicit focus on experimental design.", "startOffset": 216, "endOffset": 229}, {"referenceID": 9, "context": "Experimental design, which is an act of inquiry, is implemented using Bayesian adaptive exploration (Loredo, 2003), where the optimal experiment maximizes the expected information gain.", "startOffset": 100, "endOffset": 114}, {"referenceID": 1, "context": "unified in various forms by several researchers. Of particular note is the work on cybernetics by Fry (2002), the active data selection approach of MacKay (1992), and maximum entropy sampling and Bayesian experimental design by Sebastiani and Wynn (2000).", "startOffset": 13, "endOffset": 109}, {"referenceID": 1, "context": "unified in various forms by several researchers. Of particular note is the work on cybernetics by Fry (2002), the active data selection approach of MacKay (1992), and maximum entropy sampling and Bayesian experimental design by Sebastiani and Wynn (2000).", "startOffset": 13, "endOffset": 162}, {"referenceID": 1, "context": "unified in various forms by several researchers. Of particular note is the work on cybernetics by Fry (2002), the active data selection approach of MacKay (1992), and maximum entropy sampling and Bayesian experimental design by Sebastiani and Wynn (2000). The maximum entropy sampling approach to experimental design was expounded upon by Loredo (2003) in his work on Bayesian adaptive exploration, which forms the basis of the approach we present here.", "startOffset": 13, "endOffset": 255}, {"referenceID": 1, "context": "unified in various forms by several researchers. Of particular note is the work on cybernetics by Fry (2002), the active data selection approach of MacKay (1992), and maximum entropy sampling and Bayesian experimental design by Sebastiani and Wynn (2000). The maximum entropy sampling approach to experimental design was expounded upon by Loredo (2003) in his work on Bayesian adaptive exploration, which forms the basis of the approach we present here.", "startOffset": 13, "endOffset": 353}, {"referenceID": 0, "context": "The first author of this paper, having been inspired by the work of Cox (1979) and Fry (2002), has been actively developing a calculus for questions (Knuth, 2002, 2003, 2005, 2006) based on bi-valuations on lattices (Knuth, 2007) with an explicit focus on experimental design.", "startOffset": 68, "endOffset": 79}, {"referenceID": 0, "context": "The first author of this paper, having been inspired by the work of Cox (1979) and Fry (2002), has been actively developing a calculus for questions (Knuth, 2002, 2003, 2005, 2006) based on bi-valuations on lattices (Knuth, 2007) with an explicit focus on experimental design.", "startOffset": 68, "endOffset": 94}, {"referenceID": 13, "context": "(Skilling, 2005; Sivia & Skilling, 2006), which allows us to test various hypotheses given the newly collected data.", "startOffset": 0, "endOffset": 40}, {"referenceID": 13, "context": "We accomplish this using the nested sampling algorithm, which samples from the prior probability and explores within an ever-contracting hard likelihood constraint (Skilling, 2005; Sivia & Skilling, 2006).", "startOffset": 164, "endOffset": 204}, {"referenceID": 9, "context": "However, first we revisit the theory behind Bayesian adaptive estimation (Loredo, 2003).", "startOffset": 73, "endOffset": 87}, {"referenceID": 9, "context": "show (Loredo, 2003) that the optimal experiment can be found by maximizing the entropy of the possible measurements", "startOffset": 5, "endOffset": 19}, {"referenceID": 9, "context": "This maximum entropy approximation works as long as the noise level, described by the likelihood function, is independent of the sampling location (Loredo, 2003).", "startOffset": 147, "endOffset": 161}, {"referenceID": 14, "context": "Related maximum entropy techniques are finding their way into robotics (Thrun et al., 2005) and promise to enable these automated systems to interact with their environments in an intelligent manner.", "startOffset": 71, "endOffset": 91}], "year": 2007, "abstractText": "Remote science operations require automated systems that can both act and react with minimal human intervention. One such vision is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, decides which new measurements to take. This innovation implements experimental design and unites it with data analysis in such a way that it completes the cycle of learning. This cycle is the basis of the Scientific Method. The three basic steps of this cycle are hypothesis generation, inquiry, and inference. Hypothesis generation is implemented by artificially supplying the instrument with a parameterized set of possible hypotheses that might be used to describe the physical system. The act of inquiry is handled by an inquiry engine that relies on Bayesian adaptive exploration where the optimal experiment is chosen as the one which maximizes the expected information gain. The inference engine is implemented using the nested sampling algorithm, which provides the inquiry engine with a set of posterior samples from which the expected information gain can be estimated. With these computational structures in place, the instrument will refine its hypotheses, and repeat the learning cycle by taking measurements until the system under study is described within a pre-specified tolerance. We will demonstrate our first attempts toward achieving this goal with an intelligent instrument constructed using the LEGO MINDSTORMS NXT robotics platform.", "creator": "PScript5.dll Version 5.2"}}}