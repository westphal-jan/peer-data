{"id": "1602.04450", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2016", "title": "Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuning in Robotics", "abstract": "Robotics algorithms typically depend on various parameters, the choice of which significantly affects the robot's performance. While an initial guess for the parameters may be obtained from dynamic models of the robot, parameters are usually tuned manually on the real system to achieve the best performance. Optimization algorithms, such as Bayesian optimization, have been used to automate this process. However, these methods may evaluate parameters during the optimization process that lead to safety-critical system failures. Recently, a safe Bayesian optimization algorithm, called SafeOpt, has been developed and applied in robotics, which guarantees that the performance of the system never falls below a critical value; that is, safety is defined based on the performance function. However, coupling performance and safety is not desirable in most cases. In this paper, we define separate functions for performance and safety. We present a generalized SafeOpt algorithm that, given an initial safe guess for the parameters, maximizes performance but only evaluates parameters that satisfy all safety constraints with high probability. It achieves this by modeling the underlying and unknown performance and constraint functions as Gaussian processes. We provide a theoretical analysis and demonstrate in experiments on a quadrotor vehicle that the proposed algorithm enables fast, automatic, and safe optimization of tuning parameters. Moreover, we show an extension to context- or environment-dependent, safe optimization in the experiments.", "histories": [["v1", "Sun, 14 Feb 2016 13:30:43 GMT  (864kb,D)", "http://arxiv.org/abs/1602.04450v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.LG cs.SY", "authors": ["felix berkenkamp", "reas krause", "angela p schoellig"], "accepted": false, "id": "1602.04450"}, "pdf": {"name": "1602.04450.pdf", "metadata": {"source": "CRF", "title": "Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuning in Robotics", "authors": ["Felix Berkenkamp", "Andreas Krause", "Angela P. Schoellig"], "emails": ["krausea}@ethz.ch,", "schoellig@utias.utoronto.ca"], "sections": [{"heading": null, "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "II. PROBLEM STATEMENT", "text": "We consider a given algorithm that is used to accomplish a specific task with a robot. Generally, this algorithm is arbitrary and may contain several components, including vision, state estimation, planning and control laws. The algorithm depends on tuning parameters that have a certain discrete domain A. The goal is to find the parameters within A that maximize a particular, scalar performance measurement, f. While the performance measurement can be set in experiments for all parameters, the negative tracking error rate of a robot [2], the average walking speed of a two-legged robot [13], or any other quantity that can be calculated over a limited time horizon. While the performance measurement can be set in experiments, the function dependence on an unknown a is primarily unknown a. In the following, we write f (a): We write f (a), although the calculation of the performance measurement of the external states depends on the signals and signals."}, {"heading": "III. BACKGROUND", "text": "In this section we discuss Gaussian processes (GPs) and Bayesian optimization, which form the basis of our secure Bayesian optimization algorithm. Introduction to general practitioners is standard and comes from [2] and [11]."}, {"heading": "A. Gaussian Process (GP)", "text": "Both the function f (a) and the security constraints gi (a) in Sec. II are unknown a). We use GPs as a non-parametric model to approximate these unknown functions over their common domain. Below, we will focus on a single function, the goal being to find an approximation of a nonlinear map, f (a): A 7 \u2192 R, from an input vector to an input vector vector vector vector to a function value f (a). This is achieved by assuming that function values f (a) associated with different values of a random variable, and that each finite number of these random variables have a common Gaussian distribution depending on the values of a [11]. For non-parametric regression, we must define a previous mean function and a function."}, {"heading": "B. Bayesian Optimization", "text": "The assumption is that the evaluation of the function is expensive, while the computational resources are cheap. This fits our problem in Sec. II, where each evaluation of the performance function corresponds to an experiment on the real system, see Sec. III-A. GP-based methods use the mean and variance of predictions in (2) and (3) to calculate the next sample location. For example, a popular approach is to model the underlying function as a GP. GP-based methods use the mean and variance of predictions in (2) and (3) to calculate the next sample location."}, {"heading": "IV. SAFEOPT-MC (MULTIPLE CONSTRAINTS)", "text": "In this section, we present the SAFEOPT-MC algorithm for multiple constraints and discuss its theoretical properties. Since the goal of the algorithm is to solve (1) by random sampling, we consider two important properties: the ability (i) to expand the region of the optimization problem that is known to be possible or safe without violating the constraints, and (ii) to find the optimal parameters within this safe set. [26] The theoretical guarantees of the algorithm are based on the Lipschitz continuity of the underlying function. Many commonly used cores, such as the square exponential (Gaussian) kernel, are highly likely to fulfill this condition. [26] In the following, we assume that f (a) and gi (a) are Lipschitz continuity of the underlying function."}, {"heading": "A. The Algorithm", "text": "In this section, we will introduce the algorithm that enables us to achieve the previously defined baseline, but the most critical aspect of the algorithm is security. Once security is assured, the second challenge is to find an assessment criterion that will trade between trying to extend the current estimate further and trying to improve the estimate of the best parameters within the current set. To ensure security, we use the confidence intervals of our posterior GP estimate based on the data observed to date. Confidence intervals for the surrogate function in (4) are defined asQn (a, i): [\u00b5n \u2212 n \u2212 1 / 2n] n-Intervals Confidence intervals (a, i), where \u03b2n a scalar containing the desired confidence intervals of all possible function values between the lower and upper confidence intervals is also used. The probability of true function values lying within this interval depends on the assumptions."}, {"heading": "B. Theoretical Results", "text": "In this section, we show that the same theoretical question is worked out by the SAFEOPT algorithm, in which a variety of limitations and evaluation criteria (14) are available, and the mathematical details are provided separately in [27]. In the following, we assume that all function evaluations are corrupted by noise with the same variance, so that we achieve a specific probability of the actual function contained in the trust intervals for all iterations and functions. The following Lemma allows us to select a scaling factor for (9), so that we achieve a specific probability of the actual function contained in the iterations, assuming that the environment function (a, i) is amped."}, {"heading": "C. Practical Implementation", "text": "In this section, we discuss possible changes to algorithm 1 that make the algorithm more practical, at the expense of losing some of the theoretical guarantees. The main motivation behind this is that the definition of a Lipschitz constant is impractical in many situations and specifying the false constant can lead to conservatism or unsafe actions. In addition, for many commonly used cores, the high probability of the Lipschitz constant is already encoded in the GP model. In this case, we can use the GP directly to ensure safety [2]; that is, we define lin (a) = minQn (a, i) and uin (a, i) = maxQn (a, i) in terms of the confidence intervals constants as safe. In this case, we can define the safe theorem without a Lipschitz constant asSn = S0 (a) = S0 = Intervals constants as safe (a, i)."}, {"heading": "V. QUADROTOR EXPERIMENTS", "text": "In this section, we show algorithm 1 (with the changes discussed in Sec. IV-C) in experiments on a quadrotor vehicle, a Parrot AR.Drone 2.0. During the experiments, measurements of all vehicle states were obtained from an overhead motion capture camera system. The dynamics of the quadrotor can be described by six states: positions, x = (x, y, z), speeds, x = (x, y, z), ZYX-Euler angles, (?,?,?) and body angle speeds (?,?,?,??, z). The control inputs, u, are the desired rolling and pitch angles, the desired Zvelocity, z-Euler angles, (?,?) and the desired yaw angular speeds (?,??,????). The control inputs, u, are the desired rolling and pitch angles, the desired Zvelocity, the desired angle speeds (?), and the angles (?)."}, {"heading": "A. Step Response", "text": "In a first experiment, the goal is to minimize root meansquare disturbance (RMSE) over a time horizon of 5 s (N = 350 sam-ples) during a 1 meter reference position. We define the performance function, f (an) = C (an) \u2212 0.75C (a0), (24) C (an) = 1 \u00b0 N (N \u00b2), which indicates the kth position sample we select \u2212 1 / 2n = 2 to define the confidence interval in (9). What remains is the definition of the GP model associated with this performance requirement. The most important aspect is the selection of the kernel that defines the properties of the mean functions."}, {"heading": "B. Circle Trajectory", "text": "In a second experiment, we define the optimization criterion as RMSE in relation to a radius of 1 m at a velocity of 1 m / s, using the same hyperparameters as in paragraph V-A. The feasibility of such movements was analyzed in [30]. We define safety as a restriction of RMSE (0.2 m) and as a restriction of the maximum angular velocity around the x and y axis (0.5 rad / s). The yaw angle always points to the center of the circle, which should ideally lead to a zero angular velocity. Deviations from this are an indication of unsafe behavior. The paths resulting from the operation of the optimization algorithm are evaluated in Fig. 4. Only safe parameters that keep the vehicle within the limitations of RMSE and angular velocity are evaluated."}, {"heading": "C. Context-Dependent Optimization", "text": "An additional aspect of using GPS to model performance is that we can transfer knowledge to different environmental situations, so-called contexts [31]. Contexts are determined outside the algorithm and can correspond with environmental conditions such as weather or external signals that cannot be influenced by the algorithm. We model how the performance and constraint functions change in relation to these contexts by multiplying the core function kp with another kernel, kz, over the contexts. (28) This core structure implies that function values correlate when both parameters and the context are similar. In our circuit experiment, we model how power and constraints of the OPC vary at the desired speed by defining a kernel kz (x-des, x-s speeds) with parameters."}, {"heading": "VI. CONCLUSION", "text": "In [3] we introduced a generalization of the Safe Bayesian Optimization algorithm, which allows several separate safety restrictions, and applied it to nonlinear control problems of a quadrotor vehicle. Overall, the algorithm enabled efficient and automatic optimization of parameters without violating safety restrictions, which would lead to system failures."}, {"heading": "ACKNOWLEDGMENTS", "text": "This research was partially supported by the SNSF scholarship 200020 159557, the NSERC scholarship RGPIN-2014-04634 and the Connaught New Researchers Award."}], "references": [{"title": "Learning control in robotics", "author": ["S. Schaal", "C.G. Atkeson"], "venue": "IEEE Robotics & Automation Magazine, vol. 17, no. 2, pp. 20\u201329, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Safe controller optimization for quadrotors with Gaussian processes", "author": ["F. Berkenkamp", "A.P. Schoellig", "A. Krause"], "venue": "Proc. of the IEEE International Conference on Robotics and Automation (ICRA), 2016, (to appear).", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Safe exploration for optimization with Gaussian processes", "author": ["Y. Sui", "A. Gotovos", "J.W. Burdick", "A. Krause"], "venue": "Proc. of the International Conference on Machine Learning (ICML), 2015, pp. 997\u20131005.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "PID tuning using extremum seeking: online, model-free performance optimization", "author": ["N.J. Killingsworth", "M. Krsti\u0107"], "venue": "IEEE Control Systems, vol. 26, no. 1, pp. 70\u201379, 2006.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Automatic tuning and adaptation for PID controllers - a survey", "author": ["K.J. \u00c5str\u00f6m", "T. H\u00e4gglund", "C.C. Hang", "W.K. Ho"], "venue": "Control Engineering Practice, vol. 1, no. 4, pp. 699\u2013714, 1993.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1993}, {"title": "Genetic algorithms and robotics: a heuristic strategy for optimization", "author": ["Y. Davidor"], "venue": "World Scientific,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1991}, {"title": "Policy Gradient Methods for Robotics", "author": ["J. Peters", "S. Schaal"], "venue": "Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 2006, pp. 2219\u20132225.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Bayesian approach to global optimization: theory and applications", "author": ["J. Mockus"], "venue": "Springer Science & Business Media,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Convergence rates of efficient global optimization algorithms", "author": ["A.D. Bull"], "venue": "Journal of Machine Learning Research, vol. 12, pp. 2879\u20132904, 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Gaussian process optimization in the bandit setting: no regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S.M. Kakade", "M. Seeger"], "venue": "Proc. of the International Conference on Machine Learning (ICML), 2010.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Gaussian processes for machine learning", "author": ["C.E. Rasmussen", "C.K. Williams"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "A taxonomy of global optimization methods based on response surfaces", "author": ["D.R. Jones"], "venue": "Journal of Global Optimization, vol. 21, no. 4, pp. 345\u2013383, 2001.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Bayesian gait optimization for bipedal locomotion", "author": ["R. Calandra", "N. Gopalan", "A. Seyfarth", "J. Peters", "M.P. Deisenroth"], "venue": "Learning and Intelligent Optimization. Springer, 2014, pp. 274\u2013290.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic gait optimization with Gaussian process regression.", "author": ["D.J. Lizotte", "T. Wang", "M.H. Bowling", "D. Schuurmans"], "venue": "in Proc. of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Using response surfaces and expected improvement to optimize snake robot gait parameters", "author": ["M. Tesch", "J. Schneider", "H. Choset"], "venue": "Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2011, pp. 1069\u20131074.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic LQR tuning based on Gaussian process optimization", "author": ["A. Marco", "P. Hennig", "J. Bohg", "S. Schaal", "S. Trimpe"], "venue": "Proc. of the IEEE International Conference on Robotics and Automation (ICRA), 2016, (to appear).", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "An experimental comparison of Bayesian optimization for bipedal locomotion", "author": ["R. Calandra", "A. Seyfarth", "J. Peters", "M.P. Deisenroth"], "venue": "Proc. of the IEEE International Conference on Robotics and Automation (ICRA), 2014, pp. 1951\u20131958.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Bayesian optimization with unknown constraints", "author": ["M.A. Gelbart", "J. Snoek", "R.P. Adams"], "venue": "Proc. of the Conference on Uncertainty in Artificial Intelligence (UAI), 2014, pp. 250\u2013259.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Safe exploration for active learning with Gaussian processes", "author": ["J. Schreiter", "D. Nguyen-Tuong", "M. Eberts", "B. Bischoff", "H. Markert", "M. Toussaint"], "venue": "Proc. of the European Conference on Machine Learning (ECML), vol. 9284, 2015, pp. 133\u2013149.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Essentials of robust control", "author": ["K. Zhou", "J.C. Doyle"], "venue": "Prentice Hall Upper Saddle River, NJ,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Safe and robust learning control with Gaussian processes", "author": ["F. Berkenkamp", "A.P. Schoellig"], "venue": "Proc. of the European Control Conference (ECC), 2015, pp. 2501\u20132506.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Provably safe and robust learning-based model predictive control", "author": ["A. Aswani", "H. Gonzalez", "S.S. Sastry", "C. Tomlin"], "venue": "Automatica, vol. 49, no. 5, pp. 1216\u20131226, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Reachability-based safe learning with Gaussian processes", "author": ["A.K. Akametalu", "S. Kaynama", "J.F. Fisac", "M.N. Zeilinger", "J.H. Gillula", "C.J. Tomlin"], "venue": "Proc. of the IEEE Conference on Decision and Control (CDC), 2014, pp. 1424\u20131431.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Safe exploration in Markov decision processes", "author": ["T.M. Moldovan", "P. Abbeel"], "venue": "Proc. of the International Conference on Machine Learning (ICML), 2012, pp. 1711\u20131718.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Kernels for Vector- Valued Functions: A Review", "author": ["M.A. \u00c1lvarez", "L. Rosasco", "N.D. Lawrence"], "venue": "Foundations and Trends in Machine Learning, vol. 4, no. 3, pp. 195\u2013266, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Posterior consistency of Gaussian process prior for nonparametric binary regression", "author": ["S. Ghosal", "A. Roy"], "venue": "The Annals of Statistics, vol. 34, no. 5, pp. 2413\u20132429, 2006.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2006}, {"title": "Feed-forward parameter identification for precise periodic quadrocopter motions", "author": ["A. Schoellig", "C. Wiltsche", "R. D\u2019Andrea"], "venue": "Proc. of the American Control Conference (ACC), 2012, pp. 4313\u20134318.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "A platform for aerial robotics research and demonstration: The Flying Machine Arena", "author": ["S. Lupashin", "M. Hehn", "M.W. Mueller", "A.P. Schoellig", "M. Sherback", "R. D\u2019Andrea"], "venue": "Mechatronics, vol. 24, no. 1, pp. 41\u201354, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Feasiblity of motion primitives for choreographed quadrocopter flight", "author": ["A. Schollig", "M. Hehn", "S. Lupashin", "R. D\u2019Andrea"], "venue": "Proc. of the American Control Conference (ACC), 2011, pp. 3843\u20133849.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Contextual Gaussian process bandit optimization", "author": ["A. Krause", "C.S. Ong"], "venue": "Proc. of Neural Information Processing Systems (NIPS), 2011, pp. 2447\u20132455.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "This holds true especially in robotics, where systems often face large prior uncertainties [1].", "startOffset": 91, "endOffset": 94}, {"referenceID": 1, "context": "Recently, this manual tuning approach in robotics was automated by using safe Bayesian optimization [2].", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "framework of SAFEOPT (Safe Optimization) from [3] to our Fig.", "startOffset": 46, "endOffset": 49}, {"referenceID": 3, "context": "However, typical algorithms in the literature do not consider safety of the optimization process, and make other restrictive assumptions such as requiring gradients [4], [5], which are difficult to obtain from noisy data, or an impractical number of experiments [6].", "startOffset": 165, "endOffset": 168}, {"referenceID": 4, "context": "However, typical algorithms in the literature do not consider safety of the optimization process, and make other restrictive assumptions such as requiring gradients [4], [5], which are difficult to obtain from noisy data, or an impractical number of experiments [6].", "startOffset": 170, "endOffset": 173}, {"referenceID": 5, "context": "However, typical algorithms in the literature do not consider safety of the optimization process, and make other restrictive assumptions such as requiring gradients [4], [5], which are difficult to obtain from noisy data, or an impractical number of experiments [6].", "startOffset": 262, "endOffset": 265}, {"referenceID": 6, "context": "In the reinforcement learning literature on policy gradients, safety has mostly been considered in terms of heuristics that disallow large steps along the gradient into areas of the state space that have not been explored before [7].", "startOffset": 229, "endOffset": 232}, {"referenceID": 7, "context": "One recent category of optimization algorithms that has been successfully applied to robotics is Bayesian optimization [8].", "startOffset": 119, "endOffset": 122}, {"referenceID": 8, "context": "global optimum of the objective function while evaluating the function at only few parameters [9], [10].", "startOffset": 94, "endOffset": 97}, {"referenceID": 9, "context": "global optimum of the objective function while evaluating the function at only few parameters [9], [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "Bayesian optimization methods often model the unknown function as a Gaussian process (GP) [11], which in turn is used to guide function evaluations to locations that are informative about the optimum of the unknown function [8], [12].", "startOffset": 90, "endOffset": 94}, {"referenceID": 7, "context": "Bayesian optimization methods often model the unknown function as a Gaussian process (GP) [11], which in turn is used to guide function evaluations to locations that are informative about the optimum of the unknown function [8], [12].", "startOffset": 224, "endOffset": 227}, {"referenceID": 11, "context": "Bayesian optimization methods often model the unknown function as a Gaussian process (GP) [11], which in turn is used to guide function evaluations to locations that are informative about the optimum of the unknown function [8], [12].", "startOffset": 229, "endOffset": 233}, {"referenceID": 12, "context": "include gait optimization of legged robots [13], [14] and ar X iv :1 60 2.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "include gait optimization of legged robots [13], [14] and ar X iv :1 60 2.", "startOffset": 49, "endOffset": 53}, {"referenceID": 14, "context": "the optimization of the controller parameters of a snake-like robot [15].", "startOffset": 68, "endOffset": 72}, {"referenceID": 15, "context": "In [16] the weighting matrices of an LQR controller", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "Several different Bayesian optimization methods were compared in [17] for bipedal locomotion.", "startOffset": 65, "endOffset": 69}, {"referenceID": 17, "context": "In [18] an algorithm to optimize an unknown function subject to an unknown constraint was introduced.", "startOffset": 3, "endOffset": 7}, {"referenceID": 2, "context": "The case of safety-critical constraints was considered in [3] and [19].", "startOffset": 58, "endOffset": 61}, {"referenceID": 18, "context": "The case of safety-critical constraints was considered in [3] and [19].", "startOffset": 66, "endOffset": 70}, {"referenceID": 2, "context": "The algorithm in [3], called SAFEOPT, has been successfully applied to robotics in [2].", "startOffset": 17, "endOffset": 20}, {"referenceID": 1, "context": "The algorithm in [3], called SAFEOPT, has been successfully applied to robotics in [2].", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "We extend the theory of SAFEOPT in [3] to account for these additional constraints and show that similar theoretical guarantees can be obtained for the new setting.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "We then relax the assumptions used in the proofs to obtain a more practical version of the algorithm similar to [2], but additionally show that the safety guarantees carry over to this case.", "startOffset": 112, "endOffset": 115}, {"referenceID": 19, "context": "In control theory, safety in the presence of unmodeled dynamics is often interpreted as stability of the underlying control law with respect to an uncertain model [20].", "startOffset": 163, "endOffset": 167}, {"referenceID": 20, "context": "Safety can be guaranteed by ensuring that either the controller is robustly stable for all possible models within the uncertainty specification [21] or the system never leaves a safe subset of the state space [22], [23], [24].", "startOffset": 144, "endOffset": 148}, {"referenceID": 21, "context": "Safety can be guaranteed by ensuring that either the controller is robustly stable for all possible models within the uncertainty specification [21] or the system never leaves a safe subset of the state space [22], [23], [24].", "startOffset": 209, "endOffset": 213}, {"referenceID": 22, "context": "Safety can be guaranteed by ensuring that either the controller is robustly stable for all possible models within the uncertainty specification [21] or the system never leaves a safe subset of the state space [22], [23], [24].", "startOffset": 215, "endOffset": 219}, {"referenceID": 23, "context": "Safety can be guaranteed by ensuring that either the controller is robustly stable for all possible models within the uncertainty specification [21] or the system never leaves a safe subset of the state space [22], [23], [24].", "startOffset": 221, "endOffset": 225}, {"referenceID": 1, "context": "For example, this performance measure may represent the negative tracking error of a robot [2], the average walking speed of a bipedal robot [13], or any other quantity that can be computed over a finite time horizon.", "startOffset": 91, "endOffset": 94}, {"referenceID": 12, "context": "For example, this performance measure may represent the negative tracking error of a robot [2], the average walking speed of a bipedal robot [13], or any other quantity that can be computed over a finite time horizon.", "startOffset": 141, "endOffset": 145}, {"referenceID": 1, "context": "The introduction to GPs is standard and taken from [2] and [11].", "startOffset": 51, "endOffset": 54}, {"referenceID": 10, "context": "The introduction to GPs is standard and taken from [2] and [11].", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "This is accomplished by assuming that function values f(a), associated with different values of a, are random variables and that any finite number of these random variables have a joint Gaussian distribution depending on the values of a [11].", "startOffset": 237, "endOffset": 241}, {"referenceID": 10, "context": "A review of potential kernels can be found in [11].", "startOffset": 46, "endOffset": 50}, {"referenceID": 24, "context": "treated by considering a matrix of kernel functions, which models the correlation between different functions [25].", "startOffset": 110, "endOffset": 114}, {"referenceID": 24, "context": "Importantly, using this surrogate function rather than the framework in [25] allows us to bound the information gain and provide theoretical guarantees in Sec.", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "Bayesian optimization aims to find the global maximum of an unknown function [8].", "startOffset": 77, "endOffset": 80}, {"referenceID": 9, "context": "in [10], the next sample location is", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "In this paper, we extend the safe optimization algorithm SAFEOPT [3] to multiple constraints.", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "SAFEOPT [3] trades off between these two sets by choosing for the next experiment the parameters inside the safe set about whose performance we are most uncertain.", "startOffset": 8, "endOffset": 11}, {"referenceID": 25, "context": "Many commonly used kernels, such as the squared exponential (Gaussian) kernel, satisfy this condition with high probability [26].", "startOffset": 124, "endOffset": 128}, {"referenceID": 2, "context": "Instead, we follow [3] and consider learning the safety constraint to some accuracy, .", "startOffset": 19, "endOffset": 22}, {"referenceID": 18, "context": "One could, similar to [19], simply select the most uncertain element over the entire set.", "startOffset": 22, "endOffset": 26}, {"referenceID": 2, "context": "To avoid this, we first define subsets of Sn that correspond to parameters that could either improve the estimate of the maximum or could expand the safe set, similar to [3].", "startOffset": 170, "endOffset": 173}, {"referenceID": 2, "context": "In this section, we show that the same theoretical frame work from the SAFEOPT algorithm [3] can be extended to multiple constraints and the evaluation criterion (14).", "startOffset": 89, "endOffset": 92}, {"referenceID": 9, "context": "1 in [10].", "startOffset": 5, "endOffset": 9}, {"referenceID": 9, "context": "bounded noise see [10].", "startOffset": 18, "endOffset": 22}, {"referenceID": 9, "context": "It has been shown in [10] that the mutual information has a sublinear dependence on the number of samples for commonly used kernels.", "startOffset": 21, "endOffset": 25}, {"referenceID": 1, "context": "In practice, we use the GP directly to ensure safety [2]; that is, we define l n(a) = minQn(a, i) and un(a, i) = maxQn(a, i) in terms of the confidence intervals.", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "the number of new states that are classified as safe, see [2].", "startOffset": 58, "endOffset": 61}, {"referenceID": 26, "context": "For details regarding the controllers see [28], [29].", "startOffset": 42, "endOffset": 46}, {"referenceID": 27, "context": "For details regarding the controllers see [28], [29].", "startOffset": 48, "endOffset": 52}, {"referenceID": 10, "context": "Here, we choose the Mat\u00e8rn kernel with parameter \u03bd = 3/2 [11],", "startOffset": 57, "endOffset": 61}, {"referenceID": 1, "context": "If, as was done in [2], one were to set the safety constraint as g1(a) = f(a), the algorithm would classify the blue shaded region in Fig.", "startOffset": 19, "endOffset": 22}, {"referenceID": 28, "context": "Feasibility of such motions has been analyzed in [30].", "startOffset": 49, "endOffset": 53}, {"referenceID": 29, "context": "An additional aspect of using GPs to model the performance is that we can transfer knowledge to different environmental situations, called contexts [31].", "startOffset": 148, "endOffset": 152}, {"referenceID": 2, "context": "We presented a generalization of the Safe Bayesian Optimization algorithm in [3] that allows for multiple, separate safety constraints and applied it to nonlinear control problems on a quadrotor vehicle.", "startOffset": 77, "endOffset": 80}], "year": 2016, "abstractText": "Robotics algorithms typically depend on various parameters, the choice of which significantly affects the robot\u2019s performance. While an initial guess for the parameters may be obtained from dynamic models of the robot, parameters are usually tuned manually on the real system to achieve the best performance. Optimization algorithms, such as Bayesian optimization, have been used to automate this process. However, these methods may evaluate parameters during the optimization process that lead to safety-critical system failures. Recently, a safe Bayesian optimization algorithm, called SAFEOPT, has been developed and applied in robotics, which guarantees that the performance of the system never falls below a critical value; that is, safety is defined based on the performance function. However, coupling performance and safety is not desirable in most cases. In this paper, we define separate functions for performance and safety. We present a generalized SAFEOPT algorithm that, given an initial safe guess for the parameters, maximizes performance but only evaluates parameters that satisfy all safety constraints with high probability. It achieves this by modeling the underlying and unknown performance and constraint functions as Gaussian processes. We provide a theoretical analysis and demonstrate in experiments on a quadrotor vehicle that the proposed algorithm enables fast, automatic, and safe optimization of tuning parameters. Moreover, we show an extension to contextor environmentdependent, safe optimization in the experiments.", "creator": "LaTeX with hyperref package"}}}