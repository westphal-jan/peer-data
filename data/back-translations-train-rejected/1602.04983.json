{"id": "1602.04983", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2016", "title": "Contextual Media Retrieval Using Natural Language Queries", "abstract": "The widespread integration of cameras in hand-held and head-worn devices as well as the ability to share content online enables a large and diverse visual capture of the world that millions of users build up collectively every day. We envision these images as well as associated meta information, such as GPS coordinates and timestamps, to form a collective visual memory that can be queried while automatically taking the ever-changing context of mobile users into account. As a first step towards this vision, in this work we present Xplore-M-Ego: a novel media retrieval system that allows users to query a dynamic database of images and videos using spatio-temporal natural language queries. We evaluate our system using a new dataset of real user queries as well as through a usability study. One key finding is that there is a considerable amount of inter-user variability, for example in the resolution of spatial relations in natural language utterances. We show that our retrieval system can cope with this variability using personalisation through an online learning-based retrieval formulation.", "histories": [["v1", "Tue, 16 Feb 2016 11:04:29 GMT  (7220kb,D)", "http://arxiv.org/abs/1602.04983v1", "8 pages, 9 figures, 1 table"]], "COMMENTS": "8 pages, 9 figures, 1 table", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.CL cs.CV cs.HC", "authors": ["sreyasi nag chowdhury", "mateusz malinowski", "reas bulling", "mario fritz"], "accepted": false, "id": "1602.04983"}, "pdf": {"name": "1602.04983.pdf", "metadata": {"source": "CRF", "title": "Contextual Media Retrieval Using Natural Language Queries", "authors": ["Sreyasi Nag Chowdhury", "Mateusz Malinowski", "Andreas Bulling", "Mario Fritz"], "emails": ["sreyasi@mpi-inf.mpg.de", "mmalinow@mpi-inf.mpg.de", "bulling@mpi-inf.mpg.de", "mfritz@mpi-inf.mpg.de"], "sections": [{"heading": "1. INTRODUCTION", "text": "Due to the widespread use of visual sensors in consumer goods and Internet sharing platforms, we have collectively achieved a fairly detailed visual capture of the world in space and time in recent years. Specifically, mobile devices have changed the way we take pictures, and new technologies such as life-logging devices will continue to do so in the future. With efficient search engines in our favor, images and videos from unknown and distant places are just a few clicks away. These search engines do not allow complex, natural voice queries that include spatio-temporal references and also largely ignore the local context of users. Similar to how mobile devices have changed the way we take pictures, we ask how media search should be changed to take advantage of the rich context available at query time. What if we want to quickly know what is behind the building? What if we want to know what a particular cafe looks like (what a particular cafe looks like to quickly locate it in a busy market area? What winter, what do we want to see in our new neighborhood?"}, {"heading": "2. RELATED WORK", "text": "In fact, most of us are able to behave in a way in which they are able to survive themselves, \"he told the German Press Agency.\" But it's not that they are able to survive themselves, \"he said.\" But it's not that they are able to survive themselves. \"He added,\" It's not that they are able to survive themselves, but that they are able to survive themselves. \""}, {"heading": "3. CONTEXTUAL MEDIA RETRIEVAL", "text": "Our contextual media retrieval architecture allows users to explore a collective media collection in a spatio-temporal context through questions of natural language such as \"What is standing in front of the university bus station?,\" \"What happened to the left of the campus center?,\" \"What happened here five days ago?,\" \"What did this place look like in December?,\" etc. Below, we will show how we formulate our architecture, paying particular attention to how we deal with the dynamic context and spatial references of the user in questions of natural language. Furthermore, we will describe how we collect a data set that relates to our initial motivation to build a collective visual memory."}, {"heading": "3.1 Learning-based, Contextual Media Retrieval by Semantic Parsing", "text": "In this section, we describe how we approach learning-based, contextual media retrieval from natural language questions to semantic questions. First, we describe the applied semantic parser architecture (inspired by Liang et al. [10]) and show how it can be expanded into a contextual media retrieval task. Figure 2 presents the probabilistic model of our architecture. A question x (pronounced by a user) is mapped to a latent logical form z, which is then evaluated in relation to a world w (database of facts), which produces an answer y. The world consists of a static database of geographical information) and a dynamic database that stores user metadata and information about collective visual memory. Logical forms z are presented as labeled trees and automatically generated from the question answer (x, y) pairs.3.1.1 Question Answer"}, {"heading": "3.2 Data Collection", "text": "This year, it has come to the point that there is only one time that there is such a process, in which there is such a process."}, {"heading": "4. EXPERIMENTS", "text": "For our experiments, we use the geographical facts described in the previous section and a collective visual memory. We use a data set consisting of query-retrieval pairs formulated by real users. It consists of user queries that do not follow a specific template and contain spatial relations in addition to those predefined as predicates, such as \"near,\" \"next,\" \"before,\" \"as opposed to,\" etc. In this section, we describe the experiments performed, report their results, and discuss our observations. We also propose the concept of personalizing a media retrieval system to adapt to specific user perceptions. Finally, we provide a qualitative assessment of the usefulness of our contextual media retrieval system."}, {"heading": "4.1 Evaluation of Learning Procedure", "text": "To explore the effects of learning on predictive accuracy, we first developed a model with synthetically generated feedback (SynthModel), which generates the questions through templates - \"What is there < spatial relationship > of X?,\" \"What happened here days / weeks / months / years ago?,\" \"What was this place like in Z?,\" \"Where are the spatial relations?,\" \"Behind it,\" \"On the left,\" \"On the left,\" \"Names of buildings, cafes, restaurants, etc.?,\" \"Y,\" \"Natural numbers\" and \"Names of months.\" Contextual feedback \"is fixed to a specific position. Feedback follows predetermined rules to solve spatial relationships.\""}, {"heading": "4.2 Model Evaluation", "text": "Since a contextual application requires the involvement of potential users and their satisfaction with their use, we opt for a qualitative assessment of the system. Humans are inherently contradictory in their perception of directions and the notion of reference frames [9, 15]. Also, the nature of understanding / speaking English questions varies based on a person's socio-cultural background. Therefore, a system based on fixed question templates and a particular set of rules for solving spatial references does not guarantee high accuracy. A satisfactory result for one person may prove irrelevant for another. In order to better understand these perceptual distortions and yet efficiently analyze the system, a number of user studies have been conducted."}, {"heading": "4.2.1 Evaluation of the Retrieved Results and Human Disagreements", "text": "The aim of this user study is to observe how accurate regular users find our system. Five users were asked to rate the retrieved results as \"relevant\" or \"irrelevant\" for 500 test questions, and the study was carried out in a laboratory setup, with users looking at the retrieved results for each question on a computer screen and indicating whether they found the retrievals relevant or irrelevant to the question. A canonical frame of reference was used in this experiment to solve spatial relationships in queries. In accordance with this convention, \"north,\" \"south,\" \"right\" meant \"east\" and \"left\" meant \"west.\" We observed that opinions were different for each question. On the basis of this observation, we divided the test questions into six groups - (5.0), for which all five users agreed that the retrievals were relevant."}, {"heading": "4.2.2 Canonical and User-centric Reference Frame", "text": "In order to study the effects of this development, we need to look at the extent to which we are able to solve the problems we have had in recent years."}, {"heading": "5. DISCUSSION", "text": "Due to the complex nature of our problem, which consists of natural language queries, media and map data, it is possible that human concepts, especially spatial and temporal language, as well as complex contextual linkages, present a wide range of challenges. We highlight three of them in this section and discuss the parameters: the correct spatial resolution is required in a successful user study. Unfortunately, there is no clear frame of reference and thus no simple explanation for why we behaved this way."}, {"heading": "6. CONCLUSION", "text": "In this article, we proposed Xplore-M-Ego - a novel system for media queries using spatio-temporal natural language queries in a dynamic environment. Our work takes this paradigm in a new direction by exploiting the current context of a user. Our approach is based on a semantic parser that derives interpretations of queries for natural language. We contribute several enhancements that allow the user to dynamically refer to his context through spatial and temporal concepts. We further analyzed the system in the various user studies that underscore the importance of our adaptive and personalized training approaches."}], "references": [{"title": "Semantic parsing via paraphrasing", "author": ["J. Berant", "P. Liang"], "venue": "In Proceedings of ACL,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Driving semantic parsing from the world\u2019s response", "author": ["J. Clarke", "D. Goldwasser", "M.-W. Chang", "D. Roth"], "venue": "In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Grounding spatial relations for human-robot interaction", "author": ["S. Guadarrama", "L. Riano", "D. Golland", "D. Gouhring", "Y. Jia", "D. Klein", "P. Abbeel", "T. Darrell"], "venue": "In Intelligent Robots and Systems (IROS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Semantic video search using natural language queries", "author": ["A. Hakeem", "M.W. Lee", "O. Javed", "N. Haering"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Openstreetmap: Usergenerated street maps", "author": ["M. Haklay", "P. Weber"], "venue": "Pervasive Computing, IEEE,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "A method for processing the natural language query in ontologybased image retrieval system. In Adaptive Multimedia Retrieval: User, Context, and Feedback, pages", "author": ["M. Hwang", "H. Kong", "S. Baek", "P. Kim"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "A natural language-based interface for querying a video database", "author": ["O. Kucuktunc", "U. G\u00fcd\u00fckbay", "\u00d6. Ulusoy"], "venue": "IEEE MultiMedia,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Image retrieval with structured object queries using latent ranking svm", "author": ["T. Lan", "W. Yang", "Y. Wang", "G. Mori"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Space in language and cognition: Explorations in cognitive diversity, volume 5", "author": ["S.C. Levinson"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Learning dependency-based compositional semantics", "author": ["P. Liang", "M.I. Jordan", "D. Klein"], "venue": "Computational Linguistics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Intelligent natural language processing for media data query", "author": ["V. Lum", "K.-c. K. Kim"], "venue": "In Proc. 2nd Int. Golden West Conf. on Intelligent Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1992}, {"title": "Measuring usability with the use questionnaire", "author": ["A.M. Lund"], "venue": "Usability interface,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "A pooling approach to modelling spatial relations for image retrieval and annotation", "author": ["M. Malinowski", "M. Fritz"], "venue": "[cs.CV],", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "A multi-world approach to question answering about real-world scenes based on uncertain input", "author": ["M. Malinowski", "M. Fritz"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Towards a visual turing challenge", "author": ["M. Malinowski", "M. Fritz"], "venue": "In NIPS Workshop on Learning Semantics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Grounding spatial language in perception: an empirical and computational investigation", "author": ["T. Regier", "L.A. Carlson"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Photo tourism: exploring photo collections in 3d", "author": ["N. Snavely", "S.M. Seitz", "R. Szeliski"], "venue": "ACM transactions on graphics (TOG),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Towards surveillance video search by natural language query", "author": ["S. Tellex", "D. Roy"], "venue": "In Proceedings of the ACM International Conference on Image and Video Retrieval,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Videoscapes: exploring sparse, unstructured video collections", "author": ["J. Tompkin", "K.I. Kim", "J. Kautz", "C. Theobalt"], "venue": "ACM Transactions on Graphics (TOG),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Video collections in panoramic contexts", "author": ["J. Tompkin", "F. Pece", "R. Shah", "S. Izadi", "J. Kautz", "C. Theobalt"], "venue": "In Proceedings of the 26th annual ACM symposium on User interface software and technology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Learning synchronous grammars for semantic parsing with lambda calculus", "author": ["Y.W. Wong", "R.J. Mooney"], "venue": "In Annual Meeting-Association for computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Photoscope: visualizing spatiotemporal coverage of photos for construction management", "author": ["F. Wu", "M. Tory"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["L.S. Zettlemoyer", "M. Collins"], "venue": "arXiv preprint arXiv:1207.1420,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}], "referenceMentions": [{"referenceID": 16, "context": "[17] proposed Photo tourism that constructs a sparse 3D geometric representation of the underlying scene from images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "To address challenges in the construction management industry, Wu and Tory [22] designed PhotoScope.", "startOffset": 75, "endOffset": 79}, {"referenceID": 19, "context": "[20] developed Vidicontexts that embeds videos in a panoramic frame of reference (context) and enables simultaneous visualization of videos in different foci.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "A similar system, VideoScapes [19] was implemented as a graph with videos as edges and portals (automatically identified transition opportunities) as vertices.", "startOffset": 30, "endOffset": 34}, {"referenceID": 22, "context": "Traditional approaches to semantic parsing used supervised learning by training on questions with costly manually annotated logical forms [23, 21].", "startOffset": 138, "endOffset": 146}, {"referenceID": 20, "context": "Traditional approaches to semantic parsing used supervised learning by training on questions with costly manually annotated logical forms [23, 21].", "startOffset": 138, "endOffset": 146}, {"referenceID": 1, "context": "Modern approaches use more scalable techniques to train a semantic parser with more accessible textual question-answer pairs [2, 10, 1].", "startOffset": 125, "endOffset": 135}, {"referenceID": 9, "context": "Modern approaches use more scalable techniques to train a semantic parser with more accessible textual question-answer pairs [2, 10, 1].", "startOffset": 125, "endOffset": 135}, {"referenceID": 0, "context": "Modern approaches use more scalable techniques to train a semantic parser with more accessible textual question-answer pairs [2, 10, 1].", "startOffset": 125, "endOffset": 135}, {"referenceID": 13, "context": "Malinowski and Fritz [14] proposed an architecture for question-answering based on real-world indoor images.", "startOffset": 21, "endOffset": 25}, {"referenceID": 9, "context": "[10] to include subjective interpretations of scenes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "They also identified challenges that holistic architectures have to face, such as different frame of reference in spatial relations or ambiguities in the answers [14, 15].", "startOffset": 162, "endOffset": 170}, {"referenceID": 14, "context": "They also identified challenges that holistic architectures have to face, such as different frame of reference in spatial relations or ambiguities in the answers [14, 15].", "startOffset": 162, "endOffset": 170}, {"referenceID": 10, "context": "Lum and Kim [11] presented a method that matches semantic network representations of queries with those of natural language descriptions of media data (manually annotated).", "startOffset": 12, "endOffset": 16}, {"referenceID": 6, "context": "[7] proposed a pattern matching approach based on Part-of-Speech (POS) tags.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "Other approaches are based on RDF-triples [6] and SPARQL queries [4].", "startOffset": 42, "endOffset": 45}, {"referenceID": 3, "context": "Other approaches are based on RDF-triples [6] and SPARQL queries [4].", "startOffset": 65, "endOffset": 68}, {"referenceID": 17, "context": "Tellex and Roy [18] explored spatial relations in surveillance videos by a classification task which handles two prepositions,\u201cacross\u201d and \u201calong\u201d.", "startOffset": 15, "endOffset": 19}, {"referenceID": 7, "context": "[8] used structured queries that consists of two objects linked by a spatial relations chosen from a restricted set of spatial prepositions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10]) and show how to extend it towards a contextual media retrieval task.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "We build our approach on a recently proposed framework for semantic parsing [10] that has been shown to be able to answer questions about facts like geographical data and is trained solely on textual question-answer pairs.", "startOffset": 76, "endOffset": 80}, {"referenceID": 9, "context": "The logical forms follow a dependency-based compositional semantics (DCS) formalism [10] that consists of trees with nodes labeled with predicates and edges labeled with relations between the predicates.", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "The existing works that use such a semantic parser are based on a static environment [10, 1, 14].", "startOffset": 85, "endOffset": 96}, {"referenceID": 0, "context": "The existing works that use such a semantic parser are based on a static environment [10, 1, 14].", "startOffset": 85, "endOffset": 96}, {"referenceID": 13, "context": "The existing works that use such a semantic parser are based on a static environment [10, 1, 14].", "startOffset": 85, "endOffset": 96}, {"referenceID": 15, "context": "Understanding egocentric spatial relations in natural language questions has for long intrigued the research community and forms a separate research area by itself [16, 8, 3, 13].", "startOffset": 164, "endOffset": 178}, {"referenceID": 7, "context": "Understanding egocentric spatial relations in natural language questions has for long intrigued the research community and forms a separate research area by itself [16, 8, 3, 13].", "startOffset": 164, "endOffset": 178}, {"referenceID": 2, "context": "Understanding egocentric spatial relations in natural language questions has for long intrigued the research community and forms a separate research area by itself [16, 8, 3, 13].", "startOffset": 164, "endOffset": 178}, {"referenceID": 12, "context": "Understanding egocentric spatial relations in natural language questions has for long intrigued the research community and forms a separate research area by itself [16, 8, 3, 13].", "startOffset": 164, "endOffset": 178}, {"referenceID": 14, "context": "In our work, we approach ambiguity in the frame of reference [15] by defining predicates that resolve the spatial relations \u201cfront of\u201d, \u201cbehind\u201d, \u201cleft of\u201dand\u201cright of\u201dbased on the geomagnetic reference frame as well as the user-centric reference frame.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "In contrast to previous work on question answering [10, 14], we desire to retrieve media as answers to natural language questions instead of textual information.", "startOffset": 51, "endOffset": 59}, {"referenceID": 13, "context": "In contrast to previous work on question answering [10, 14], we desire to retrieve media as answers to natural language questions instead of textual information.", "startOffset": 51, "endOffset": 59}, {"referenceID": 4, "context": "OpenStreetMap [5] is a freely-available and well-documented collection of geographical data.", "startOffset": 14, "endOffset": 17}, {"referenceID": 8, "context": "Humans are inherently inconsistent in their perception of directions and idea of reference frames [9, 15].", "startOffset": 98, "endOffset": 105}, {"referenceID": 14, "context": "Humans are inherently inconsistent in their perception of directions and idea of reference frames [9, 15].", "startOffset": 98, "endOffset": 105}, {"referenceID": 11, "context": "Afterward they were asked to fill in the USE Questionnaire [12].", "startOffset": 59, "endOffset": 63}], "year": 2016, "abstractText": "The widespread integration of cameras in hand-held and head-worn devices as well as the ability to share content online enables a large and diverse visual capture of the world that millions of users build up collectively every day. We envision these images as well as associated meta information, such as GPS coordinates and timestamps, to form a collective visual memory that can be queried while automatically taking the ever-changing context of mobile users into account. As a first step towards this vision, in this work we present Xplore-M-Ego: a novel media retrieval system that allows users to query a dynamic database of images and videos using spatio-temporal natural language queries. We evaluate our system using a new dataset of real user queries as well as through a usability study. One key finding is that there is a considerable amount of inter-user variability, for example in the resolution of spatial relations in natural language utterances. We show that our retrieval system can cope with this variability using personalisation through an online learning-based retrieval formulation.", "creator": "LaTeX with hyperref package"}}}