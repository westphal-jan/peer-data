{"id": "1602.05388", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2016", "title": "Cross-Language Domain Adaptation for Classifying Crisis-Related Short Messages", "abstract": "Rapid crisis response requires real-time analysis of messages. After a disaster happens, volunteers attempt to classify tweets to determine needs, e.g., supplies, infrastructure damage, etc. Given labeled data, supervised machine learning can help classify these messages. Scarcity of labeled data causes poor performance in machine training. Can we reuse old tweets to train classifiers? How can we choose labeled tweets for training? Specifically, we study the usefulness of labeled data of past events. Do labeled tweets in different language help? We observe the performance of our classifiers trained using different combinations of training sets obtained from past disasters. We perform extensive experimentation on real crisis datasets and show that the past labels are useful when both source and target events are of the same type (e.g. both earthquakes). For similar languages (e.g., Italian and Spanish), cross-language domain adaptation was useful, however, when for different languages (e.g., Italian and English), the performance decreased.", "histories": [["v1", "Wed, 17 Feb 2016 12:29:56 GMT  (264kb)", "http://arxiv.org/abs/1602.05388v1", "10 pages"], ["v2", "Tue, 29 Mar 2016 07:18:43 GMT  (264kb)", "http://arxiv.org/abs/1602.05388v2", "ISCRAM 2016, 10 pages, 4 tables"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["muhammad imran", "prasenjit mitra", "jaideep srivastava"], "accepted": false, "id": "1602.05388"}, "pdf": {"name": "1602.05388.pdf", "metadata": {"source": "CRF", "title": "Cross-Language Domain Adaptation for Classifying Crisis-Related Short Messages", "authors": ["Muhammad Imran", "Prasenjit Mitra", "Jaideep Srivastava"], "emails": ["mimran@qf.org.qa", "pmitra@qf.org.qa", "jsrivastava@qf.org.qa"], "sections": [{"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, Eds."}, {"heading": "Keywords", "text": "Social Media, Tweets Classification, Domain Customization"}, {"heading": "INTRODUCTION", "text": "Microblogging platforms such as Twitter provide active channels of communication during the occurrence of mass events such as natural disasters (Palen et al., 2009; Hughes et al., 2009; Starbird et al., 2010; Vieweg et al., 2010). In recent years, Twitter has been used to disseminate news of victims and damage, offers and requests for donations, and warnings, including multimedia information such as videos and photos (Cameron et al., 2012; Imran et al., 2013a; Qu et al., 2011) Many studies show the importance of this online information (Vieweg et al., 2014; Sakaki et al., 2010; Neubig et al., 2011). Furthermore, it has been observed that these messages are generally communicated faster than disaster information shared via traditional channels such as news websites, etc. The first tweet to report the 2013 attack on Westgate Mall was posted within a minute of the original attack."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "This year, it has come to the point where it can only take one year to move on to the next round."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, eds.from the same data distribution. If the training and testing sets differ significantly, this causes problems for the learning scheme to generalize. However, in order to deal with the inherited problem of label scarcity, we try to investigate how useful the labels of past crisis events can be for classifying a target crisis.The rest of the paper is organized as follows: In the next section, we describe the approach of real-time classification, which is a scope of our current work. Details of the data sets and then sections of the experimental setup provide details of which data sets we are using and our experimental plan. We discuss the results in the discussion section and detailed related studies in the corresponding worksection. Finally, the paper is completed in the Conclusions section."}, {"heading": "REAL-TIME CLASSIFICATION APPROACH", "text": "In order to be useful and feasible for emergency managers during a crisis situation, information must be made available to them in good time. In the case of social media data, this actuality is achieved through a paradigm of real-time rationalization (e.g. Imran et al., 2013b), where data elements are processed as soon as they arrive. Stream processing differs from batch processing, where an archive of the information to be analyzed already exists and processing is done retrospectively. Various data processing techniques can be used for real-time analysis of data streams (Imran et al., 2013b). In this paper, we use monitored classification techniques, and our stream processing settings include components of human and machine data processing. Specifically, people train machines by providing marked examples. However, human identification cannot be applied to volumes of data that are typical of large-scale crises, and is typically carried out on a sample of input data."}, {"heading": "DATASETS", "text": "We use a combination of data collected from the AIDR platform and the CrisisLexT26 dataset (Olteanu et al. 2015), both of which correspond to Twitter's social media messages posted during various crises in 2012, 2013 and 2015. We selected 11 crises of two types: earthquakes (5 crises) and floods (6 crises). Table 1 lists the crises along with other prominent details. AIDR uses volunteers when a crisis occurs to flag crisis-related messages. However, CrisisLex uses paid crowdsourcing platforms to identify people. In the datasets, each crisis corresponds to more than 800 tweets commented on using the \"information type\" comment scheme, which classifies tweets into the following categories: Affected: Deaths, Injuries, Missing, Found or Displaced People and / or Personal Updates. Infrastructure and utilities: Buildings, roads, utilities / Services, Damaged, Recovered, Recovered or Assisted or Missing Information, or Missing Information: or Missing or Missing Information: or Missing Information."}, {"heading": "EXPERIMENTAL SETUP", "text": "In order to determine whether marked data from past crises can contribute to the classification of crisis messages, we conduct extensive experiments."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, eds.Terminologies and Methods: The following are core terminologies that we use in our work. Source event (s): Crisis data set (s) used for training purposes Target event: Crisis data set used for testing / evaluation purposes (we always use a target event for evaluation) In-domain: represents when both source and target events have different types of crisis (e.g. earthquake training and flood testing) Training is always performed on the basis of data from one or more source events, and the generated models are always evaluated on a target event. The test / evaluation set remains the same for all types of experiments (for more details see below) for a particular crisis event. Evaluation of models, especially in domain adjustment, should be performed on a fixed test set, which is a more challenging evaluation task than other cross-validations such as using."}, {"heading": "Preprocessing", "text": "Each crisis data set is divided into two groups: the first set consists of 70% of the messages (i.e. training set) and the second of 30% of the messages (i.e. test set).For both training and test sets, we remove stopwords, URLs and usernames from the messages. As a classification algorithm, we use two types of characteristics: unigrams (one word) and bigrams (two consecutive words).Characteristics are selected using the method for selecting information gains, and the 1,000 best characteristics are selected for training purposes. As a classification algorithm, we use Random Forest, a well-known learning scheme (Liaw et al., 2002).The results of all experiments are presented in four known metrics, i.e. precision, recall, F-"}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, eds.lexical similarity between their spoken languages is high. According to Wikipedia5, the lexical similarity between Spanish and Italian is almost 82%."}, {"heading": "SS CREQ (100%) GUEQ (30%) 0.62 0.55 0.51 0.85", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SS GUEQ (100%) BOEQ (30%) 0.73 0.42 0.48 0.73", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SS BOEQ (100%) NEEQ (30%) 0.48 0.25 0.15 0.64", "text": "Lines with the type of experiment \"SC\" (i.e. special case) in Table 2 and Table 3 show the results of this analysis. For example, in the case of the Bohol earthquake (BOEQ) we performed three additional tests. In the first test (SC1) we dropped ITEQ, as was the case in the BOEQ MS case, where we observed a decrease in accuracy (e.g. AUC). However, after dropping the ITEQ, the classification accuracy increases (see SC1 line of the BOEQ in Table 2). Since the ITEQ sentence contains messages from both the English and Italian languages, this probably causes the decrease in AUC in the 5 https: / / en.wikipedia.org / wiki / Lexical _ similarity"}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, eds.first test and the increase in AUC in the second test. To confirm this observation, we manually analyzed all 912 ITEQ tweets to assign language tags (English or Italian) to them. Results of language tagging revealed that 90% of ITEQ tweets are in Italian. Next, we used only ITEQ-EN (10% English) together with CREQ and GUEQ to train a new model. Results will be shown in the series of SC2 on BOEQ (30%) tests."}, {"heading": "SS PHFL (100%) QUFL (30%) 0.60 0.50 0.51 0.82", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SS QUFL (100%) ABFL (30%) 0.74 0.61 0.61 0.83", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "MS PHFL (100%) + QUFL (100%) ABFL (30%) 0.42 0.43 0.40 0.81", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SS ABFL (100%) MNFL (30%) 0.61 0.52 0.53 0.77", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SS MNFL (100%) CLFL (30%) 0.65 0.54 0.48 0.85", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SC QUFL (100%) + ABFL (100%) CLFL (30%) 0.75 0.67 0.70 0.94", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "SS CLFL (100%) SDFL (30%) 0.55 0.41 0.29 0.78", "text": "In the third test, we include 70% of the BOEQ labels, together with ITEQ-EN, CREQ and GUEQ. The results for this are in the SC3 series of Table 2. If we use ITEQ-EN, i.e. only the English-language tweets related to the earthquake in Italy, we notice an increase in the performance of new classifiers. In the case of flood data sets, rows with the type \"SC\" experiment show the results of the special case analysis. For example, in the case of the MNFL, we can observe an increase in accuracy when we use PHFL as a driving force compared to others."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, eds.PHFL, QUFL and ABFL in total for training (see lines \"MS\" and \"SC1\" of the MNFL)."}, {"heading": "DISCUSSION", "text": "The general lesson we have learned from Table 2 is that the inclusion of more training data, even from a mixed-language source, could significantly improve the accuracy of Q. However, the following are interesting observations.1. Data from the earthquake in Italy had in some settings (earthquakes in Bohol and Nepal earthquakes), but it was useful in others (earthquakes in Costa Rica and Guatemala).We believe that this exception is due to the fact that 90% of the Italian earthquake data was in Italian, while our test case contained tweets referring to earthquakes in Bohol and Nepal, primarily in English. This result seems to indicate that Italian is closer to Spanish as a language than English, an observation confirmed by several speakers of these languages and by the language tree6. In cases where the language is significantly different, e.g. ITEQ versus BOEQ or NEEQ, it is better to leave the training than English. In these cases, it is best to use the ITEQ and the training examples in order to train it."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "Tapia, Antunes, Ba\u00f1uls, Moore and Porto, ed.Initial results promise to show that the use of flood-related tweets to complement earthquake tweets may have a signaling effect, but also has the chance to reduce the accuracy of the classifier. Table 4 (last row) shows, for example, that the addition of MND to BOEQ has improved performance in the NEEQ test kit. However, the previous two lines show a slight decrease in accuracy by adding the flood-related training set. The general consensus seems to be that, given our collection of tagged tweets from the past, we should stick to using all tweets from the same domain, provided the language mix is similar."}, {"heading": "RELATED WORK", "text": "Mass convergence events, especially those without prior warning, require a rapid analysis of the available information to make timely decisions. Information posted on microblogging platforms during the crisis can support crisis response efforts if it is processed in a timely and correct manner (Yin et al. 2012; Starbird et al., 2010; Palen et al., 2009). Many approaches based on human annotation, supervised learning and unsupervised learning techniques have been proposed to process social media data - for a full survey see e.g. (Imran et al., 2015). In this paper, we use supervised machine learning techniques to classify crisis-related messages (many such efforts and systems based on these techniques have been developed in the past, e.g. Mendoza et al., 2010; MacEachren et al., 2011; Imran et al., 2014; Roy et al., 2013)."}, {"heading": "CONCLUSIONS", "text": "The availability of training data to train classifiers for machine learning in the early hours of a crisis situation can help to gain early insights for rapid crisis response. We show that the use of tagged data from past events of the same type can generally be useful whenever the training and testing data is from the same language. If there are not enough tweets in one language (e.g. Spanish), tagged tweets in another language (e.g. Italian and Spanish) can be useful if the two languages in question are very similar (e.g. Italian and Spanish) but not if they are not (e.g. Italian and English / Tagalog). If there are a reasonable number of tagged tweets from the same domain (e.g. earthquakes), then we could not see the benefit of using tagged tweets from another domain (e.g. floods), in which case performance improved slightly while decreasing in another domain."}, {"heading": "Long Paper \u2013 Social Media Studies Proceedings of the ISCRAM 2016 Conference \u2013 Rio de Janeiro, Brazil, May 2016", "text": "In the United States, this is the case. (2009) Twitter Adoption and use in mass convergence and emergency events. International Journal of Emergency Management, 6 (3-4), 248-260.6. Imran, M., Elbassuoni, S. M., Castillo, C., Diaz, F., & Meier, P. (2013a). Extracting information nuggets from disaster-related messages in social media. Proc. of ISCRAM, Baden-Baden, Germany.7. Imran, M., Lykourentzou, I., Naudet, Y., & Castillo, C. (2013b). Engineering crowdsourced stream processing systems. arXiv preprint arXiv: 1310.5463.8. Imran, M., Castillo, C., J., Meier, P., P."}], "references": [{"title": "Tweedr: Mining twitter to inform disaster response", "author": ["Z. Ashktorab", "C. Brown", "M. Nandi", "A. Culotta"], "venue": "Proc. of ISCRAM", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Emergency Situation Awareness from Twitter for Crisis Management", "author": ["M.A. Cameron", "Power. A", "B. Robinson", "J. Yin"], "venue": "In Proc. Conference on World Wide Web (WWW)", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Domain adaptation for statistical classifiers", "author": ["H. Daume III", "D. Marcu"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Twitter adoption and use in mass convergence and emergency", "author": ["A.L. Hughes", "L. Palen"], "venue": "events. International Journal of Emergency Management,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Extracting information nuggets from disaster-related messages in social media", "author": ["M. Imran", "S.M. Elbassuoni", "C. Castillo", "F. Diaz", "P. Meier"], "venue": "Proc. of ISCRAM,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Engineering crowdsourced stream processing systems", "author": ["M. Imran", "I. Lykourentzou", "Y. Naudet", "C. Castillo"], "venue": "arXiv preprint arXiv:1310.5463", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "AIDR: Artificial intelligence for disaster response", "author": ["M. Imran", "C. Castillo", "J. Lucas", "P. Meier", "S. Vieweg"], "venue": "In Proceedings of the companion publication of the 23rd international conference on World Wide Web companion (pp. 159-162)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Processing social media messages in mass emergency: A survey", "author": ["M. Imran", "C. Castillo", "F. Diaz", "S. Vieweg"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Classification and regression by Random Forest", "author": ["A. Liaw", "M. Wiener"], "venue": "R news,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Twitter Mining for Disaster Response: A Domain Adaptation Approach", "author": ["Li", "Hongmin", "Nicolais Guevara", "Nic Herndon", "Doina Caragea", "Kishore Neppalli", "Cornelia Caragea", "Anna Squicciarini", "Andrea H. Tapia"], "venue": "ISCRAM", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "July). Twitter Under Crisis: Can we trust what we RT", "author": ["M. Mendoza", "B. Poblete", "C. Castillo"], "venue": "In Proceedings of the first workshop on social media analytics (pp. 71-79)", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "October). Senseplace2: Geotwitter analytics support for situational awareness", "author": ["A.M. MacEachren", "A. Jaiswal", "A.C. Robinson", "S. Pezanowski", "A. Savelyev", "P. Mitra", "X. Zhang", "J. Blanford"], "venue": "In Visual Analytics Science and Technology (VAST),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Safety information mining \u2013 what can NLP do in a disaster", "author": ["G. Neubig", "Y. Matsubayashi", "M. Hagiwara", "K. Murakami"], "venue": "In Proc. International Joint Conference on Natural Language Processing (IJCNLP)", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Social media communications across crises", "author": ["A. Olteanu", "S. Vieweg", "Castillo", "C. (2015", "February). What to expect when the unexpected happens"], "venue": "In Proceedings of CSCW,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1009}, {"title": "Crisis in a networked world features of computermediated communication", "author": ["L. Palen", "S. Vieweg", "S.B. Liu", "A.L. Hughes"], "venue": "in the April", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Emergency situation awareness: Twitter case studies", "author": ["R. Power", "B. Robinson", "J. Colton", "M. Cameron"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Tweet4act: Using incident-specific profiles for classifying crisis-related messages", "author": ["S. Roy Chowdhury", "M. Imran", "M.R. Asghar", "S. Amer-Yahia", "C. Castillo"], "venue": "In 10th International ISCRAM Conference,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Earthquake shakes Twitter users: real-time event detection by social sensors", "author": ["T. Sakaki", "M. Okazaki", "Y. Matsuo"], "venue": "In Proc. World Wide Web Conference (WWW)", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "February). Chatter on the red: what hazards threat reveals about the social life of microblogged information", "author": ["K. Starbird", "L. Palen", "A.L. Hughes", "S. Vieweg"], "venue": "In Proceedings of the 2010 ACM conference on Computer supported cooperative work (pp. 241-250)", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "what twitter may contribute to situational awareness", "author": ["S. Vieweg", "A.L. Hughes", "K. Starbird", "Palen", "L. (2010", "April). Microblogging during two natural hazards events"], "venue": "In Proceedings of the SIGCHI conference on human factors in computing systems", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1088}, {"title": "Integrating social media communications into the rapid assessment of sudden onset disasters", "author": ["S. Vieweg", "C. Castillo", "M. Imran"], "venue": "In Social Informatics (pp", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Microblogging After a Major Disaster in China: A Case Study of the 2010 Yushu Earthquake", "author": ["Y. Qu", "C. Huang", "P. Zhang", "J. Zhang"], "venue": "In Proc. ACM Computer-Supported Cooperative Work and Social Computing (CSCW)", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Using social media to enhance emergency situation awareness", "author": ["J. Yin", "A. Lampert", "M. Cameron", "B. Robinson", "R. Power"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}], "referenceMentions": [], "year": 2016, "abstractText": "Rapid crisis response requires real-time analysis of messages. After a disaster happens, volunteers attempt to classify tweets to determine needs, e.g., supplies, infrastructure damage, etc. Given labeled data, supervised machine learning can help classify these messages. Scarcity of labeled data causes poor performance in machine training. Can we reuse old tweets to train classifiers? How can we choose labeled tweets for training? Specifically, we study the usefulness of labeled data of past events. Do labeled tweets in different language help? We observe the performance of our classifiers trained using different combinations of training sets obtained from past disasters. We perform extensive experimentation on real crisis datasets and show that the past labels are useful when both source and target events are of the same type (e.g. both earthquakes). For similar languages (e.g., Italian and Spanish), cross-language domain adaptation was useful, however, when for different languages (e.g., Italian and English), the performance decreased.", "creator": "Word"}}}