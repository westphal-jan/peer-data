{"id": "1602.05682", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2016", "title": "Audio Recording Device Identification Based on Deep Learning", "abstract": "In this paper we present a study on identification of audio recording devices from background noise, thus providing a method for forensics and copyright disputes related. The audio signal is the sum of speech signal and noise signal. Since usually, it's the speech which is regarded as the information to be passed that people care about, a great amount of researches have been dedicated to getting higher SNR. So there are many speech enhancement algorithms to improve the quality of the speech signals, which is generally can be seen much like reducing the noise. However, we make the underlying hypothesis that the noise can be regarded as the intrinsic fingerprint traces of an audio recording device in a way. These digital traces can be characterized and identified by new machine learning techniques. Therefore, the noise can serve as the intrinsic features for the identification. As for the classifier, a Softmax classifier and an MLP classifier are used and compared. The identification accuracy is up to 93\\% among nine different devices, and shows the method of getting feature vector from the noise of each device and identifying with deeplearning techniques is viable, and well-preformed.", "histories": [["v1", "Thu, 18 Feb 2016 05:49:37 GMT  (191kb,D)", "https://arxiv.org/abs/1602.05682v1", null], ["v2", "Wed, 27 Apr 2016 02:32:38 GMT  (692kb)", "http://arxiv.org/abs/1602.05682v2", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["simeng qi", "zheng huang", "yan li", "shaopei shi"], "accepted": false, "id": "1602.05682"}, "pdf": {"name": "1602.05682.pdf", "metadata": {"source": "CRF", "title": "Audio Recording Device Identification Based on Deep Learning", "authors": ["Simeng Qi", "Zheng Huang", "Yan Li", "Shaopei Shi"], "emails": ["huang-zheng}@sjtu.edu.cn", "shisp}@ssfjd.cn"], "sections": [{"heading": null, "text": "The idea is that people who stand up for people's rights are also able to protect themselves."}, {"heading": "A. Background Noise Extraction", "text": "The input signal is a passively received audio signal, which is the sum of speech signal and noise signal. This can be expressed as follows: sn = fn + en, in which the time n is the same great. sn is the audio signal we get from previous processing. fn is the speech signal that people are usually interesting. en is the noise signal we need here to identify the device. much research has been devoted to increasing the SNR. Therefore, there are many speech enhancement algorithms to improve the quality of speech signals, which can be seen as reducing noise. In our experiment, we get the noisy version of the input signal, which is expressed in the equation as fn.We use an automatic noise reduction process of a 1-D signal wave signal. The noise objective is to suppress the part of the noise."}, {"heading": "B. Feature Exaction", "text": "After receiving the signal en, we must turn it into feature vectors for classification. Our feature extraction is based only on the characteristics of the frequency range of a recording, which are mathematical representations of the characteristics of the audio signal. To do this, we extract a Fourier coefficient histogram of the signal as feature vector, which has strong descriptive capabilities for audio signals. The corresponding Fourier coefficients for all these segments are summed up to obtain a Fourier coefficient histogram, which is then used as a global feature vector. This process can be expressed as follows: F (en) = FFT (en) After the Fast Fourier transformation, we normalize it as: N (F (en)) = log (F (en) + 1). In this way, the segments of the speech recording are represented by a dot in a high-dimensional vector map."}, {"heading": "C. Classifiers", "text": "It can model high-level abstractions into data by using model architectures that consist of several non-linear transformations. An observation, in our case, can be presented as a vector, and can therefore be processed by several standard algorithms. We will give a brief introduction to the methods we use in our experiments, which are not necessarily independent of other methods we use in our experiments. To get a better solution, some mixed-ups can achieve surprising results. 1) Softmax: Softmax regression model is one of the deep learning models that generalizes and expands generalized regression to perform classifications among more than two classes."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was supported by the \"12th Five-Year Plan\" National Science and Technology Support Program under the 2012 BAK16B05 Scholarship. The authors would like to thank our collaborator Jingyao Luo, who has been very helpful in the collection of audio recording material."}], "references": [{"title": "Mobile phone identification using recorded speech signals", "author": ["C. Kotropoulos", "S. Samaras"], "venue": "in: Digital Signal Processing (DSP), 2014 19th International Conference on, IEEE", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic cell phone recognition fromspeech recordings", "author": ["L. Zou", "J. Yang", "T. Huang"], "venue": "in: Signal and Information Processing (ChinaSIP), 2014 IEEE China Summit & International Conference on, IEEE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Gammatone cepstral coefficients: biologically inspired features for non-speech audio classification", "author": ["X. Valero", "F. Alias"], "venue": "Multimedia, IEEE Transactions on 14 (6) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Automatic acquisition device identification from speech recordings", "author": ["D. Garcia-Romero", "C.Y. Espy-Wilson"], "venue": "in: Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on, IEEE", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Microphone classification using fourier coefficients", "author": ["R. Buchholz", "C. Kraetzer", "J. Dittmann"], "venue": "in: Information Hiding, Springer", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Automatic telephone handset identification by sparse representation of random spectral features", "author": ["Y. Panagakis", "C. Kotropoulos"], "venue": "in: Proceedings of the on Multimedia and security, ACM", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Telephone handset identification using sparse representations of spectral feature sketches", "author": ["C. Kotropoulos"], "venue": "in: Biometrics and Forensics (IWBF), 2013 International Workshop on, IEEE", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Digital audio forensics using background noise", "author": ["S. Ikram", "H. Malik"], "venue": "in: Multimedia and Expo (ICME), 2010 IEEE International Conference on, IEEE", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Identifying microphone from noisy recordings by using representative instance one classclassification approach", "author": ["H.Q. Vu", "S. Liu", "X. Yang", "Z. Li", "Y. Ren"], "venue": "Journal of networks 7 (6) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Audio recorder identification using reduced noise features", "author": ["C.-B. Moon", "H. Kim", "B.M. Kim"], "venue": "in: Ubiquitous Information Technologies and Applications, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Cellphone identification using noise estimates from recorded audio", "author": ["R. Aggarwal", "S. Singh", "A.K. Roul", "N. Khanna"], "venue": "in: Communications and Signal Processing (ICCSP), 2014 International Conference on, IEEE", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "[2] performed research on mobile phone identification using recorded speech signals, and they used Mel frequency cepstral coefficients extracted from recorded speech signals to train a Gaussian Mixture Model with diagonal covariance matrices, thus providing templates for each device.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[3] had similar ideas and utilized Gaussian mixture model-universal background model as the classifier, and showed that Mel frequency cepstral coefficients are more effective than Power-normalized cepstral coefficients.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] compared Gammatone cepstral coefficients to Mel frequency cepstral coefficients in non-speech audio classification and found the GTCC more effective than MFCC, especially at low frequencies.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] proposed a method of automatic identification of acquisition devices when only get access to the output speech recordings, which used a support vector machine classifier to perform closed-set identification experiments and focused on two classes of acquisition devices.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6] extracted a Fourier coefficient histogram of near-silence segments of the recording as the feature vector and used machine learning techniques for the classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] chose random spectral features extracted from each speech signal as an intrinsic fingerprint for device identification, and Constantine Kotropoulos [8] chose the sketches of spectral features.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] chose random spectral features extracted from each speech signal as an intrinsic fingerprint for device identification, and Constantine Kotropoulos [8] chose the sketches of spectral features.", "startOffset": 152, "endOffset": 155}, {"referenceID": 7, "context": "[9] had a great idea about leakage signal, which is actually in the removed noise from speech enhancement, and we find the idea really inspiring.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] identified microphone from noisy recordings by using representative instance One ClassClassification approach, and proposed a representative instance classification framework to improve performance of OCC algorithms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] proposed an audio recorder identification method as one of digital forensic technologies, as well as a new feature reduction method, where Wiener filter was used to extract noise sounds of recorders and their features were extracted by MIRtoolbox.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] used features based on estimates of noise associated with recordings and classified them using sequential minimal optimization based Support Vector Machine.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "In this paper we present a research on identification of audio recording devices from background noise, thus providing a method for forensics. The audio signal is the sum of speech signal and noise signal. Usually, people pay more attention to speech signal, because it carries the information to deliver. So a great amount of researches have been dedicated to getting higher Signal-Noise-Ratio (SNR). There are many speech enhancement algorithms to improve the quality of the speech, which can be seen as reducing the noise. However, noises can be regarded as the intrinsic fingerprint traces of an audio recording device. These digital traces can be characterized and identified by new machine learning techniques. Therefore, in our research, we use the noise as the intrinsic features. As for the identification, multiple classifiers of deep learning methods are used and compared. The identification result shows that the method of getting feature vector from the noise of each device and identifying them with deep learning techniques is viable, and well-preformed. Keywords-audio forensic; device detection; deep learning", "creator": "Microsoft\u00ae Office Word 2007"}}}