{"id": "1602.05703", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2016", "title": "Adaptive Least Mean Squares Estimation of Graph Signals", "abstract": "In many applications spanning from sensor to social networks, transportation systems, gene regulatory networks or big data, the signals of interest are defined over the vertices of a graph. The aim of this paper is to propose a least mean square (LMS) strategy for adaptive estimation of signals defined over graphs. Assuming the graph signal to be band-limited, over a known bandwidth, the method enables reconstruction, with guaranteed performance in terms of mean-square error, and tracking from a limited number of observations over a subset of vertices. A detailed mean square analysis provides the performance of the proposed method, and leads to several insights for designing useful sampling strategies for graph signals. Numerical results validate our theoretical findings, and illustrate the performance of the proposed method. Furthermore, to cope with the case where the bandwidth is not known beforehand, we propose a method that performs a sparse online estimation of the signal support in the (graph) frequency domain, which enables online adaptation of the graph sampling strategy. Finally, we apply the proposed method to build the power spatial density cartography of a given operational region in a cognitive network environment.", "histories": [["v1", "Thu, 18 Feb 2016 07:34:04 GMT  (290kb)", "http://arxiv.org/abs/1602.05703v1", "Submitted to IEEE Transactions on Signal and Information Processing over Networks. arXiv admin note: text overlap witharXiv:1211.6950by other authors without attribution"], ["v2", "Fri, 19 Feb 2016 10:15:47 GMT  (171kb)", "http://arxiv.org/abs/1602.05703v2", "Submitted to IEEE Transactions on Signal and Information Processing over Networks"], ["v3", "Mon, 11 Jul 2016 15:40:59 GMT  (120kb)", "http://arxiv.org/abs/1602.05703v3", "Submitted to IEEE Transactions on Signal and Information Processing over Networks"]], "COMMENTS": "Submitted to IEEE Transactions on Signal and Information Processing over Networks. arXiv admin note: text overlap witharXiv:1211.6950by other authors without attribution", "reviews": [], "SUBJECTS": "cs.LG cs.SY", "authors": ["paolo di lorenzo", "sergio barbarossa", "paolo banelli", "stefania sardellitti"], "accepted": false, "id": "1602.05703"}, "pdf": {"name": "1602.05703.pdf", "metadata": {"source": "CRF", "title": "Least Mean Squares Estimation of Graph Signals", "authors": ["Paolo Di Lorenzo"], "emails": ["paolo.dilorenzo@unipg.it,", "sergio.barbarossa@uniroma1.it,", "paolo.banelli@unipg.it,", "stefania.sardellitti@uniroma1.it"], "sections": [{"heading": null, "text": "In fact, most of them are able to play by the rules that they have adopted in recent years."}, {"heading": "II. GRAPH SIGNAL PROCESSING TOOLS", "text": "In fact, it is such that it is a matter of a way in which people live in a country in which they are able to live and live in a world, in which they are in a world, in which they are in a world, in which they are in a world, in which they are in a world, in which they are in a world, in which they are in a world, in which they are in a world, in which they are in a world, in which they are one world, in which they are one world, in which they are one world, in which they are in a world, in which they are in a world, in which they are in which they are in a world, in which they live, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are living, in which they are living, in which they are living, in which they are living, in which they are one world, in which they are one world, in which they are living, in which they are living, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are one world, in which they are living, in which they are living, in which they are one world, in which they are one world, in which they are one world, in which they are living, in which they are living, in which they are living, in which they are one world, in which they are living, in which they are living, in which they are living, in which they are one world, in which they are living, in which they are living, in which they are one world, in which they are living, in which they are living, in which they are living, in which they are living, in which they are living, in which they are one world, in which they are"}, {"heading": "III. LMS ESTIMATION OF GRAPH SIGNALS", "text": "The least significant square algorithm, introduced by Widrow and Hoff [40], is one of the most popular methods of adaptive filtering. Its applications include echo compensation, channel compensation, interference suppression, and so on. Although there are algorithms with faster convergence rates such as the recursive least square (RLS) methods [38], LMS methods are popular due to their ease of implementation, low computing costs, and robustness. For these reasons, an enormous amount of research has been produced in recent decades focusing on improving the performance of LMS methods, in many cases using some prior information available on the observed signals. For example, if the observed signal is sparse, such prior information can help improve estimation performance, as is shown in many current efforts in the field of compressed sensors [41], [42]. Some of the early work, adapting with most economical reconstruction, rely on today's selection methods that include partial combinations."}, {"heading": "A. Reconstruction Properties", "text": "It is known from adaptive filter theory [38] that the LMS algorithm in (12) is a stochastic approximation method for solving the problem (10), which allows convergence in the middle sense to the true vector x0 (if the step size \u00b5 is sufficiently small), while guaranteeing a limited meansquare error (as we will see below). However, since the existence of a unique band-limited solution to the problem (12) depends on the selected sampling strategy, the first natural question to the address is: What conditions must the sampling operator D fulfill to ensure the reconstruction of signal x0 from the selected samples? The answer is given in the following theorem, which provides a necessary and sufficient condition for the reconstruction of graph signals from partial observations using algorithm 1.Theorem 2: Problem (10) allows a unique solution, i.e. any band-limited signal x0 from the selected samples."}, {"heading": "B. Mean-Square Analysis", "text": "In this section, we will examine the behavior of the proposed LMS strategy and analyze the performance of the LMS algorithm in terms of its behavior. From now on, let us be guided by the error vectors x [n] as realizations of a random process and analyze the performance of the LMS algorithm in terms of its behavior. Let us leave x [n] = x [n] \u2212 x0 are the error vectors n [n]. Subtracting x0 from the left and right side of the (12), obtaining (9) and the relationship Bx [n] = x [n]."}, {"heading": "C. Steady-State Performance", "text": "If you take the boundary of (20) as n \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2) (12), for example, let's say that you want to evaluate the stationary mean square deviation (MSD) of the LMS strategy (12). So if we have in (25) the correct selection of the free weight parameter \u00b2 (I \u2212 Q) s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s (I \u2212 Q) \u2212 1vec (I) s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s) (G \u2212 Q) (G \u2212 Q) \u2212 1vec (I \u2212 Q)"}, {"heading": "D. Sampling Strategies", "text": "Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-Sampler-"}, {"heading": "E. Numerical Results", "text": "In this section we will first illustrate some numerical results aimed at confirming the theoretical results in (26) and (27), then we will illustrate how the sampling strategy affects the performance of the proposed LMS algorithm in (12), and finally we will evaluate the effects of a diagram mismatching in the performance of the proposed algorithm. Performance: Consider the diagram signal shown in Figure 1, which consists of N = 50 nodes in which the color of each vertex denotes the value of the associated signal, the signal has a spectral content limited to the first ten eigenvectors of the Laplacian matrix, and we will look at the graph in Figure 1, i.e. F | 10 the observation noise in (9) is null-meaning, Gaussian, with a diagonal covariance matrix where each element is uniformly selected between 0 and 0.01."}, {"heading": "IV. LMS ESTIMATION WITH ADAPTIVE GRAPH SAMPLING", "text": "The LMS strategy in (12) presupposes complete knowledge of the support where the signal is defined in the graph frequency domain = 29), i.e. F. In fact, this prior knowledge allows to uniquely define the projector operator B in (5) and implement the sampling strategies introduced in Sec. II.D. However, in many practical situations this prior knowledge is unrealistic, due to the possible variability of the graph signal over time at different levels: the signal may vary in time depending on the given model; the signal model may vary over time for a given graphic topology; the graphic topology may also vary over time. In all these situations, we cannot always assume to have prior information about the frequency support F, which must be derived directly from the streaming data [n] in (9). Here we consider the important case in which the graph is considered fixed and the content is speculated over time."}, {"heading": "V. APPLICATION TO POWER SPATIAL DENSITY", "text": "The advent of smart networking of heterogeneous devices, such as those used to monitor 5G networks, power grids, transport networks and the Internet, will therefore have a strong impact on underlying systems. However, ensuring compliance with service agreements requires ground-breaking management and monitoring tools that provide operators with a comprehensive view of the networking landscape, with minimal human intervention required for ubiquitous smart networking devices to enable a data-driven statistical learning algorithm for distributed, robust and online network operations that adapt to the dynamically evolving networking landscape. In this context, the continuous demand for situational awareness in cognitive radio networks (CR) is complemented by innovative signal processing algorithms."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we have proposed LMS strategies for online estimation of signals defined via graphs, which are capable of exploiting the underlying structure of the graph signal, which can be reconstructed from a limited number of observations duly sampled from a subset of vertexes, under a bandwidth-limited assumption. A detailed mean-square analysis illustrates the deep link between the sampling strategy and the properties of the proposed LMS algorithm in terms of reconstruction capability, stability and mean-square error performance. This analysis also derives some sampling strategies for the adaptive estimation of graph signals. In addition, to address time-varying scenarios, we propose an LMS method with adaptive graph sampling, which estimates and tracks signal support in the (graph) frequency domain, while simultaneously adapting the graph numerical strategy for these simulation simulations and confirming the potential benefits of the simulation strategy."}], "references": [{"title": "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains", "author": ["D.I. Shuman", "S.K. Narang", "P. Frossard", "A. Ortega", "P. Vandergheynst"], "venue": "IEEE Signal Proc. Mag., vol. 30, no. 3, pp. 83\u201398, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Discrete signal processing on graphs", "author": ["A. Sandryhaila", "J.M.F. Moura"], "venue": "IEEE Trans. on Signal Processing, vol. 61, pp. 1644\u20131656, 2013.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Big data analysis with signal processing on graphs: Representation and processing of massive data sets with irregular structure", "author": ["\u2014\u2014"], "venue": "IEEE Signal Proc. Mag., vol. 31, no. 5, pp. 80\u201390, 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Discrete signal processing on graphs: Frequency analysis", "author": ["A. Sandryhaila", "J.M. Moura"], "venue": "IEEE Transactions on Signal Processing, vol. 62, no. 12, pp. 3042\u20133054, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Perfect reconstruction two-channel wavelet filter banks for graph structured data", "author": ["S.K. Narang", "A. Ortega"], "venue": "IEEE Transactions on Signal Processing, vol. 60, no. 6, pp. 2786\u20132799, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Compact support biorthogonal wavelet filterbanks for arbitrary undirected graphs", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Signal Processing, vol. 61, no. 19, pp. 4673\u20134685, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Sampling in Paley-Wiener spaces on combinatorial graphs", "author": ["I.Z. Pesenson"], "venue": "Trans. of the American Mathematical Society, vol. 360, no. 10, pp. 5603\u20135627, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Sampling, filtering and sparse approximations on combinatorial graphs", "author": ["I.Z. Pesenson", "M.Z. Pesenson"], "venue": "Journal of Fourier Analysis and Applications, vol. 16, no. 6, pp. 921\u2013942, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Approximating signals supported on graphs", "author": ["X. Zhu", "M. Rabbat"], "venue": "IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), March 2012, pp. 3921\u20133924.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Discrete signal processing on graphs: Sampling theory", "author": ["S. Chen", "R. Varma", "A. Sandryhaila", "J. Kova\u010devi\u0107"], "venue": "IEEE Trans. on Signal Proc., vol. 63, pp. 6510\u20136523, Dec. 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Algebraic signal processing theory: Foundation and 1-D time", "author": ["M. P\u00fcschel", "J.M.F. Moura"], "venue": "IEEE Trans. Signal Process., vol. 56, pp. 3572\u20133585, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Algebraic signal processing theory: 1-D space", "author": ["\u2014\u2014"], "venue": "IEEE Trans. on Signal Processing, pp. 3586\u20133599, 2008.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "On the graph fourier transform for directed graphs", "author": ["S. Sardellitti", "S. Barbarossa"], "venue": "available at: http://arxiv.org/abs/1601.05972, 2016.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "A spectral graph uncertainty principle", "author": ["A. Agaskar", "Y.M. Lu"], "venue": "IEEE Trans. on Inform. Theory, vol. 59, no. 7, pp. 4338\u20134356, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Toward an uncertainty principle for weighted graphs", "author": ["B. Pasdeloup", "R. Alami", "V. Gripon", "M. Rabbat"], "venue": "online: arXiv:1503.03291, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Graph theoretic uncertainty principles", "author": ["J.J. Benedetto", "P.J. Koprowski"], "venue": "http://www.math.umd.edu/ jjb/graph theoretic UP April 14.pdf, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Finite frames and graph theoretic uncertainty principles", "author": ["P.J. Koprowski"], "venue": "Ph.D. dissertation, 2015. [Online]. Available: http://hdl.handle.net/1903/16666", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Signals on graphs: Uncertainty principle and sampling", "author": ["M. Tsitsvero", "S. Barbarossa", "P. Di Lorenzo"], "venue": "submitted to IEEE Trans. on Signal Processing; available at http://arxiv.org/abs/1507.08822, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Signal processing techniques for interpolation in graph structured data", "author": ["S. Narang", "A. Gadde", "A. Ortega"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2013, pp. 5445\u20135449.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Local-set-based graph signal reconstruction", "author": ["X. Wang", "P. Liu", "Y. Gu"], "venue": "IEEE Trans. on Signal Processing, vol. 63, no. 9, pp. 2432\u20132444, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Sampling of graph signals with successive local aggregations", "author": ["A.G. Marquez", "S. Segarra", "G. Leus", "A. Ribeiro"], "venue": "To appear on IEEE Trans. Signal Process., 2016.  13", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "On the degrees of freedom of signals on graphs", "author": ["M. Tsitsvero", "S. Barbarossa"], "venue": "2015 European Signal Proc. Conf. (Eusipco 2015), Sep. 2015, pp. 1521\u20131525.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Localized iterative methods for interpolation in graph structured data", "author": ["S.K. Narang", "A. Gadde", "E. Sanou", "A. Ortega"], "venue": "IEEE Global Conference on Signal and Information Processing, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "A distributed tracking algorithm for reconstruction of graph signals", "author": ["X. Wang", "M. Wang", "Y. Gu"], "venue": "IEEE Journal of Selected Topics in Signal Processing, vol. 9, no. 4, pp. 728\u2013740, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Semi-supervised multiresolution classification using adaptive graph filtering with application to indirect bridge structural health monitoring", "author": ["S. Chen", "F. Cerda", "P. Rizzo", "J. Bielak", "J.H. Garrett", "J. Kovacevic"], "venue": "IEEE Trans. on Signal Processing, vol. 62, no. 11, pp. 2879\u20132893, 2014.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Classification via regularization on graphs.", "author": ["A. Sandryhaila", "J.M. Moura"], "venue": "Proc. of IEEE Global conference on Signal and Information Processing,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Waveletregularized graph semi-supervised learning", "author": ["V.N. Ekambaram", "G. Fanti", "B. Ayazifar", "K. Ramchandran"], "venue": "IEEE Global Conference on Signal and Information Processing, 2013, pp. 423\u2013426.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning of structured graph dictionaries", "author": ["X. Zhang", "X. Dong", "P. Frossard"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing, 2012, pp. 3373\u20133376.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Parametric dictionary learning for graph signals", "author": ["D. Thanou", "D.I. Shuman", "P. Frossard"], "venue": "IEEE Global Conference on Signal and Information Processing, 2013, pp. 487\u2013490.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning graphs from signal observations under smoothness prior", "author": ["X. Dong", "D. Thanou", "P. Frossard", "P. Vandergheynst"], "venue": "submitted to: IEEE Transacctions on Signal Processing, 2014.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "A regularization framework for learning from graph data", "author": ["D. Zhou", "B. Sch\u00f6lkopf"], "venue": "ICML workshop on statistical relational learning and Its connections to other fields, vol. 15, 2004, pp. 67\u201368.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "The J. of Machine Learning Research, vol. 7, pp. 2399\u20132434, 2006.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "Signal inpainting on graphs via total variation minimization", "author": ["S. Chen", "A. Sandryhaila", "G. Lederman", "Z. Wang", "J.M. Moura", "P. Rizzo", "J. Bielak", "J.H. Garrett", "J. Kovacevic"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing, 2014, pp. 8267\u20138271.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Signal denoising on graphs via graph filtering", "author": ["S. Chen", "A. Sandryhaila", "J.M. Moura", "J. Kovacevic"], "venue": "IEEE Global Conference on Signal and Information Processing, 2014, pp. 872\u2013876.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Local fiedler vector centrality for detection of deep and overlapping communities in networks", "author": ["P.-Y. Chen", "A.O. Hero"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing, 2014, pp. 1120\u20131124.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Signal recovery on graphs: Variation minimization", "author": ["S. Chen", "A. Sandryhaila", "J.M. Moura", "J. Kovacevic"], "venue": "IEEE Transactions on Signal Processing, vol. 63, no. 17, pp. 4609\u20134624, 2015.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Signal recovery on graphs: Fundamental limits of sampling strategies", "author": ["S. Chen", "R. Varma", "A. Singh", "J. Kova\u010devi\u0107"], "venue": "arXiv preprint arXiv:1512.05405, 2015.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2015}, {"title": "Adaptive filters", "author": ["A.H. Sayed"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Adaptive signal processing", "author": ["B. Widrow", "S.D. Stearns"], "venue": "Englewood Cliffs, NJ, Prentice-Hall, Inc.,, vol. 1, 1985.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1985}, {"title": "Compressed sensing", "author": ["D.L. Donoho"], "venue": "IEEE Transactions on Information Theory, vol. 52, no. 4, pp. 1289\u20131306, 2006.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2006}, {"title": "Compressive sensing", "author": ["R.G. Baraniuk"], "venue": "IEEE signal processing magazine, vol. 24, no. 4, 2007.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2007}, {"title": "LMS estimation via structural detection", "author": ["J. Homer", "I. Mareels", "R.R. Bitmead", "B. Wahlberg", "F. Gustafsson"], "venue": "IEEE Transactions on Signal Processing, vol. 46, no. 10, pp. 2651\u20132663, 1998.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1998}, {"title": "Partial update LMS algorithms", "author": ["M. Godavarti", "A.O. Hero III"], "venue": "IEEE Trans. on Signal Processing, vol. 53, no. 7, pp. 2382\u20132399, 2005.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2005}, {"title": "Proportionate normalized least-mean-squares adaptation in echo cancelers", "author": ["D.L. Duttweiler"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 8, no. 5, pp. 508\u2013518, 2000.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2000}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp. 267\u2013288, 1996.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1996}, {"title": "Enhancing sparsity by reweighted l 1 minimization", "author": ["E.J. Candes", "M.B. Wakin", "S.P. Boyd"], "venue": "Journal of Fourier analysis and applications, vol. 14, no. 5-6, pp. 877\u2013905, 2008.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2008}, {"title": "Sparse LMS for system identification", "author": ["Y. Chen", "Y. Gu", "A.O. Hero III"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing, 2009, pp. 3125\u20133128.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "Online adaptive estimation of sparse signals: Where RLS meets the-norm", "author": ["D. Angelosante", "J.A. Bazerque", "G.B. Giannakis"], "venue": "IEEE Transactions on Signal Processing, vol. 58, no. 7, pp. 3436\u20133447, 2010.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2010}, {"title": "Online sparse system identification and signal reconstruction using projections onto weighted balls", "author": ["Y. Kopsinis", "K. Slavakis", "S. Theodoridis"], "venue": "IEEE Transactions on Signal Processing, vol. 59, no. 3, pp. 936\u2013 952, 2011.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "A sparsity promoting adaptive algorithm for distributed learning", "author": ["S. Chouvardas", "K. Slavakis", "Y. Kopsinis", "S. Theodoridis"], "venue": "IEEE Transactions on Signal Processing, vol. 60, no. 10, pp. 5412\u20135425, 2012.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2012}, {"title": "Sparse distributed learning based on diffusion adaptation", "author": ["P. Di Lorenzo", "A.H. Sayed"], "venue": "IEEE Transactions on Signal Processing, vol. 61, no. 6, pp. 1419\u20131433, 2013.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed spectrum estimation for small cell networks based on sparse diffusion adaptation", "author": ["P. Di Lorenzo", "S. Barbarossa", "A.H. Sayed"], "venue": "IEEE Signal Processing Letters, vol. 20, no. 12, pp. 1261\u20131265, 2013.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2013}, {"title": "Diffusion adaptation strategies for distributed estimation over gaussian markov random fields", "author": ["P. Di Lorenzo"], "venue": "IEEE Transactions on Signal Processing, vol. 62, no. 21, pp. 5748\u20135760, 2014.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed Detection and Estimation in Wireless Sensor Networks", "author": ["S. Barbarossa", "S. Sardellitti", "P. Di Lorenzo"], "venue": "Academic Press Library in Signal Processing,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2014}, {"title": "Energy conservation and the learning ability of LMS adaptive filters", "author": ["A.H. Sayed", "V.H. Nascimento"], "venue": null, "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2003}, {"title": "An iterative thresholding algorithm for linear inverse problems with a sparsity constraint", "author": ["I. Daubechies", "M. Defrise", "C. De Mol"], "venue": "Communications on pure and applied mathematics, vol. 57, no. 11, pp. 1413\u2013 1457, 2004.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2004}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM journal on imaging sciences, vol. 2, no. 1, pp. 183\u2013202, 2009.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2009}, {"title": "On the non-negative garrotte estimator", "author": ["M. Yuan", "Y. Lin"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 69, no. 2, pp. 143\u2013161, 2007.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "In many applications, from sensor to social networks, vehicular networks, big data or biological networks, the signals of interest are defined over the vertices of a graph [1].", "startOffset": 172, "endOffset": 175}, {"referenceID": 0, "context": "Over the last few years, a series of papers produced a significant advancement in the development of processing tools for the analysis of signals defined over a graph, or graph signals for short [1]\u2013[3].", "startOffset": 195, "endOffset": 198}, {"referenceID": 2, "context": "Over the last few years, a series of papers produced a significant advancement in the development of processing tools for the analysis of signals defined over a graph, or graph signals for short [1]\u2013[3].", "startOffset": 199, "endOffset": 202}, {"referenceID": 1, "context": "Processing signals defined over a graph has been considered in [2], [4]\u2013[6].", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "Processing signals defined over a graph has been considered in [2], [4]\u2013[6].", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": "Processing signals defined over a graph has been considered in [2], [4]\u2013[6].", "startOffset": 72, "endOffset": 75}, {"referenceID": 6, "context": "Alternative definitions of GFT have been proposed, depending on the different perspectives used to extend classical tools [7], [8], [1], [9], [2].", "startOffset": 122, "endOffset": 125}, {"referenceID": 7, "context": "Alternative definitions of GFT have been proposed, depending on the different perspectives used to extend classical tools [7], [8], [1], [9], [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 0, "context": "Alternative definitions of GFT have been proposed, depending on the different perspectives used to extend classical tools [7], [8], [1], [9], [2].", "startOffset": 132, "endOffset": 135}, {"referenceID": 8, "context": "Alternative definitions of GFT have been proposed, depending on the different perspectives used to extend classical tools [7], [8], [1], [9], [2].", "startOffset": 137, "endOffset": 140}, {"referenceID": 1, "context": "Alternative definitions of GFT have been proposed, depending on the different perspectives used to extend classical tools [7], [8], [1], [9], [2].", "startOffset": 142, "endOffset": 145}, {"referenceID": 6, "context": ", [7], [1], [9] or of the adjacency matrix, see, e.", "startOffset": 2, "endOffset": 5}, {"referenceID": 0, "context": ", [7], [1], [9] or of the adjacency matrix, see, e.", "startOffset": 7, "endOffset": 10}, {"referenceID": 8, "context": ", [7], [1], [9] or of the adjacency matrix, see, e.", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "[2], [10].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[2], [10].", "startOffset": 5, "endOffset": 9}, {"referenceID": 10, "context": "The first approach applies to undirected graphs and builds on the spectral clustering properties of the Laplacian eigenvectors and the minimization of the l2 norm graph total variation; the second approach was proposed to handle also directed graphs and it is based on the interpretation of the adjacency operator as the graph shift operator, which lies at the heart of all linear shift-invariant filtering methods for graph signals [11], [12].", "startOffset": 433, "endOffset": 437}, {"referenceID": 11, "context": "The first approach applies to undirected graphs and builds on the spectral clustering properties of the Laplacian eigenvectors and the minimization of the l2 norm graph total variation; the second approach was proposed to handle also directed graphs and it is based on the interpretation of the adjacency operator as the graph shift operator, which lies at the heart of all linear shift-invariant filtering methods for graph signals [11], [12].", "startOffset": 439, "endOffset": 443}, {"referenceID": 12, "context": "A further very recent contribution proposes to build the graph Fourier basis as the set of orthonormal signals that minimize the (directed) graph cut size [13].", "startOffset": 155, "endOffset": 159}, {"referenceID": 13, "context": "After the introduction of the GFT, an uncertainty principle for graph signals was derived in [14] and, more recently [15], [16], [17], [18].", "startOffset": 93, "endOffset": 97}, {"referenceID": 14, "context": "After the introduction of the GFT, an uncertainty principle for graph signals was derived in [14] and, more recently [15], [16], [17], [18].", "startOffset": 117, "endOffset": 121}, {"referenceID": 15, "context": "After the introduction of the GFT, an uncertainty principle for graph signals was derived in [14] and, more recently [15], [16], [17], [18].", "startOffset": 123, "endOffset": 127}, {"referenceID": 16, "context": "After the introduction of the GFT, an uncertainty principle for graph signals was derived in [14] and, more recently [15], [16], [17], [18].", "startOffset": 129, "endOffset": 133}, {"referenceID": 17, "context": "After the introduction of the GFT, an uncertainty principle for graph signals was derived in [14] and, more recently [15], [16], [17], [18].", "startOffset": 135, "endOffset": 139}, {"referenceID": 17, "context": "In particular, in [18], the authors give simple closed form expressions for the fundamental tradeoff between the concentrations of a signal in the graph and the transformed domains.", "startOffset": 18, "endOffset": 22}, {"referenceID": 6, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 36, "endOffset": 39}, {"referenceID": 18, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 87, "endOffset": 91}, {"referenceID": 17, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 93, "endOffset": 97}, {"referenceID": 19, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 99, "endOffset": 103}, {"referenceID": 20, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "A seminal contribution was given in [7], later extended in [19] and, very recently, in [10], [18], [20], [21], [22].", "startOffset": 111, "endOffset": 115}, {"referenceID": 22, "context": "Alternative signal reconstuction methods have been proposed, either iterative as in [23], [20], [24], or single shot, as in [10], [18].", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "Alternative signal reconstuction methods have been proposed, either iterative as in [23], [20], [24], or single shot, as in [10], [18].", "startOffset": 90, "endOffset": 94}, {"referenceID": 23, "context": "Alternative signal reconstuction methods have been proposed, either iterative as in [23], [20], [24], or single shot, as in [10], [18].", "startOffset": 96, "endOffset": 100}, {"referenceID": 9, "context": "Alternative signal reconstuction methods have been proposed, either iterative as in [23], [20], [24], or single shot, as in [10], [18].", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "Alternative signal reconstuction methods have been proposed, either iterative as in [23], [20], [24], or single shot, as in [10], [18].", "startOffset": 130, "endOffset": 134}, {"referenceID": 6, "context": "Frame-based approaches to reconstruct signals from subsets of samples have been proposed in [7], [20], [18].", "startOffset": 92, "endOffset": 95}, {"referenceID": 19, "context": "Frame-based approaches to reconstruct signals from subsets of samples have been proposed in [7], [20], [18].", "startOffset": 97, "endOffset": 101}, {"referenceID": 17, "context": "Frame-based approaches to reconstruct signals from subsets of samples have been proposed in [7], [20], [18].", "startOffset": 103, "endOffset": 107}, {"referenceID": 24, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 147, "endOffset": 151}, {"referenceID": 26, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 152, "endOffset": 156}, {"referenceID": 27, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 184, "endOffset": 188}, {"referenceID": 28, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 190, "endOffset": 194}, {"referenceID": 29, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 223, "endOffset": 227}, {"referenceID": 30, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 278, "endOffset": 282}, {"referenceID": 31, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 284, "endOffset": 288}, {"referenceID": 32, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 301, "endOffset": 305}, {"referenceID": 33, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 317, "endOffset": 321}, {"referenceID": 34, "context": "The theory developed in the last years for GSP was then applied to solve specific learning tasks, such as semi-supervised classification on graphs [25]\u2013[27], graph dictionary learning [28], [29], learning graphs structures [30], smooth graph signal recovery from random samples [31], [32], inpainting [33], denoising [34], and community detection on graphs [35].", "startOffset": 357, "endOffset": 361}, {"referenceID": 35, "context": "Finally, in [36], [37], the authors proposed signal recovery methods aimed to recover graph signals that are assumed to be smooth with respect to the underlying graph, from sampled, noisy, missing, or corrupted measurements.", "startOffset": 12, "endOffset": 16}, {"referenceID": 36, "context": "Finally, in [36], [37], the authors proposed signal recovery methods aimed to recover graph signals that are assumed to be smooth with respect to the underlying graph, from sampled, noisy, missing, or corrupted measurements.", "startOffset": 18, "endOffset": 22}, {"referenceID": 37, "context": "To the best of our knowledge, this is the first attempt to merge the well established theory of adaptive filtering [38] with the emerging field of signal processing on graphs.", "startOffset": 115, "endOffset": 119}, {"referenceID": 21, "context": "As a consequence, recovering the overall signal from a subset of samples is inevitably affected by aliasing [22].", "startOffset": 108, "endOffset": 112}, {"referenceID": 0, "context": ",N [1], i.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": ", [1], [9], [2], [10].", "startOffset": 2, "endOffset": 5}, {"referenceID": 8, "context": ", [1], [9], [2], [10].", "startOffset": 7, "endOffset": 10}, {"referenceID": 1, "context": ", [1], [9], [2], [10].", "startOffset": 12, "endOffset": 15}, {"referenceID": 9, "context": ", [1], [9], [2], [10].", "startOffset": 17, "endOffset": 21}, {"referenceID": 6, "context": "The space of all signals whose GFT is exactly supported on the set F is known as the Paley-Wiener space for the set F [7].", "startOffset": 118, "endOffset": 121}, {"referenceID": 21, "context": "The localization properties of graph signals were studied in [22] and later extended in [18] to derive the fundamental tradeoff between the localization of a signal in the graph and on its dual domain.", "startOffset": 61, "endOffset": 65}, {"referenceID": 17, "context": "The localization properties of graph signals were studied in [22] and later extended in [18] to derive the fundamental tradeoff between the localization of a signal in the graph and on its dual domain.", "startOffset": 88, "endOffset": 92}, {"referenceID": 21, "context": "The conditions for having perfect localization are stated in the following theorem, which we report here for completeness of exposition; its proof can be found in [22].", "startOffset": 163, "endOffset": 167}, {"referenceID": 17, "context": "Indeed, since the operators BD and DB have the same singular values [18], perfect localization onto the sets S and F can be achieved if and only if", "startOffset": 68, "endOffset": 72}, {"referenceID": 38, "context": "The least mean square algorithm, introduced by Widrow and Hoff [40], is one of the most popular methods for adaptive filtering.", "startOffset": 63, "endOffset": 67}, {"referenceID": 37, "context": "Although there exist algorithms with faster convergence rates such as the Recursive Least Square (RLS) methods [38], LMS-type methods are popular because of its ease of implementation, low computational costs and robustness.", "startOffset": 111, "endOffset": 115}, {"referenceID": 39, "context": "For instance, if the observed signal is known to be sparse in some domain, such prior information can help improve the estimation performance, as demonstrated in many recent efforts in the area of compressed sensing [41], [42].", "startOffset": 216, "endOffset": 220}, {"referenceID": 40, "context": "For instance, if the observed signal is known to be sparse in some domain, such prior information can help improve the estimation performance, as demonstrated in many recent efforts in the area of compressed sensing [41], [42].", "startOffset": 222, "endOffset": 226}, {"referenceID": 41, "context": "Some of the early works that mix adaptation with sparsity-aware reconstruction include methods that rely on the heuristic selection of active taps [43], and on sequential partial updating techniques [44]; some other methods assign proportional step-sizes to different taps according to their magnitudes, such as the proportionate normalized LMS (PNLMS) algorithm and its variations [45].", "startOffset": 147, "endOffset": 151}, {"referenceID": 42, "context": "Some of the early works that mix adaptation with sparsity-aware reconstruction include methods that rely on the heuristic selection of active taps [43], and on sequential partial updating techniques [44]; some other methods assign proportional step-sizes to different taps according to their magnitudes, such as the proportionate normalized LMS (PNLMS) algorithm and its variations [45].", "startOffset": 199, "endOffset": 203}, {"referenceID": 43, "context": "Some of the early works that mix adaptation with sparsity-aware reconstruction include methods that rely on the heuristic selection of active taps [43], and on sequential partial updating techniques [44]; some other methods assign proportional step-sizes to different taps according to their magnitudes, such as the proportionate normalized LMS (PNLMS) algorithm and its variations [45].", "startOffset": 382, "endOffset": 386}, {"referenceID": 44, "context": "In subsequent studies, motivated by the LASSO technique [46] and by connections with compressive sensing [42], [47], several algorithms for sparse adaptive filtering have been proposed based on LMS [48], RLS [49], and projection-based methods [50].", "startOffset": 56, "endOffset": 60}, {"referenceID": 40, "context": "In subsequent studies, motivated by the LASSO technique [46] and by connections with compressive sensing [42], [47], several algorithms for sparse adaptive filtering have been proposed based on LMS [48], RLS [49], and projection-based methods [50].", "startOffset": 105, "endOffset": 109}, {"referenceID": 45, "context": "In subsequent studies, motivated by the LASSO technique [46] and by connections with compressive sensing [42], [47], several algorithms for sparse adaptive filtering have been proposed based on LMS [48], RLS [49], and projection-based methods [50].", "startOffset": 111, "endOffset": 115}, {"referenceID": 46, "context": "In subsequent studies, motivated by the LASSO technique [46] and by connections with compressive sensing [42], [47], several algorithms for sparse adaptive filtering have been proposed based on LMS [48], RLS [49], and projection-based methods [50].", "startOffset": 198, "endOffset": 202}, {"referenceID": 47, "context": "In subsequent studies, motivated by the LASSO technique [46] and by connections with compressive sensing [42], [47], several algorithms for sparse adaptive filtering have been proposed based on LMS [48], RLS [49], and projection-based methods [50].", "startOffset": 208, "endOffset": 212}, {"referenceID": 48, "context": "In subsequent studies, motivated by the LASSO technique [46] and by connections with compressive sensing [42], [47], several algorithms for sparse adaptive filtering have been proposed based on LMS [48], RLS [49], and projection-based methods [50].", "startOffset": 243, "endOffset": 247}, {"referenceID": 49, "context": "Finally, sparsity aware distributed methods were proposed in [51]\u2013[55].", "startOffset": 61, "endOffset": 65}, {"referenceID": 53, "context": "Finally, sparsity aware distributed methods were proposed in [51]\u2013[55].", "startOffset": 66, "endOffset": 70}, {"referenceID": 37, "context": "It is well known from adaptive filters theory [38] that the LMS algorithm in (12) is a stochastic approximation method for the solution of problem (10), which enables convergence in the mean-sense to the true vector x0 (if the step-size \u03bc is chosen sufficiently small), while guaranteing a bounded meansquare error (as we will see in the sequel).", "startOffset": 46, "endOffset": 50}, {"referenceID": 54, "context": "Thus, using energy conservation arguments [56], we consider a general weighted squared error sequence \u015d[n]\u03a6\u015d[n], where \u03a6 \u2208 C is any Hermitian nonnegative-definite matrix that we are free to choose.", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "This greedy strategy was already introduced in [10] in the case of batch signal reconstruction.", "startOffset": 47, "endOffset": 51}, {"referenceID": 55, "context": "sampling operator D[n] at time n, we update the estimate of the GFT vector s using an online version of the celebrated ISTA algorithm [58], [59], which proceeds as:", "startOffset": 134, "endOffset": 138}, {"referenceID": 56, "context": "sampling operator D[n] at time n, we update the estimate of the GFT vector s using an online version of the celebrated ISTA algorithm [58], [59], which proceeds as:", "startOffset": 140, "endOffset": 144}, {"referenceID": 44, "context": "A commonly used thresholding function comes directly by imposing an l1 norm constraint in (30), which is commonly known as the Lasso [46].", "startOffset": 133, "endOffset": 137}, {"referenceID": 57, "context": "A potential improvement can be made by considering the non-negative Garotte estimator as in [60], whose thresholding function is defined as a vector whose entries are derived applying the threshold", "startOffset": 92, "endOffset": 96}], "year": 2017, "abstractText": "In many applications spanning from sensor to social networks, transportation systems, gene regulatory networks or big data, the signals of interest are defined over the vertices of a graph. The aim of this paper is to propose a least mean square (LMS) strategy for adaptive estimation of signals defined over graphs. Assuming the graph signal to be band-limited, over a known bandwidth, the method enables reconstruction, with guaranteed performance in terms of mean-square error, and tracking from a limited number of observations over a subset of vertices. A detailed mean square analysis provides the performance of the proposed method, and leads to several insights for designing useful sampling strategies for graph signals. Numerical results validate our theoretical findings, and illustrate the performance of the proposed method. Furthermore, to cope with the case where the bandwidth is not known beforehand, we propose a method that performs a sparse online estimation of the signal support in the (graph) frequency domain, which enables online adaptation of the graph sampling strategy. Finally, we apply the proposed method to build the power spatial density cartography of a given operational region in a cognitive network environment.", "creator": "LaTeX with hyperref package"}}}