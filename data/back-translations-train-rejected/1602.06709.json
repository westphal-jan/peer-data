{"id": "1602.06709", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2016", "title": "Distributed Deep Learning Using Synchronous Stochastic Gradient Descent", "abstract": "We design and implement a distributed multinode synchronous SGD algorithm, without altering hyper parameters, or compressing data, or altering algorithmic behavior. We perform a detailed analysis of scaling, and identify optimal design points for different networks. We demonstrate scaling of CNNs on 100s of nodes, and present what we believe to be record training throughputs. A 512 minibatch VGG-A CNN training run is scaled 90X on 128 nodes. Also 256 minibatch VGG-A and OverFeat-FAST networks are scaled 53X and 42X respectively on a 64 node cluster. We also demonstrate the generality of our approach via best-in-class 6.5X scaling for a 7-layer DNN on 16 nodes. Thereafter we attempt to democratize deep-learning by training on an Ethernet based AWS cluster and show ~14X scaling on 16 nodes.", "histories": [["v1", "Mon, 22 Feb 2016 10:31:24 GMT  (313kb,D)", "http://arxiv.org/abs/1602.06709v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.LG", "authors": ["dipankar das", "sasikanth avancha", "dheevatsa mudigere", "karthikeyan vaidynathan", "srinivas sridharan", "dhiraj kalamkar", "bharat kaul", "pradeep dubey"], "accepted": false, "id": "1602.06709"}, "pdf": {"name": "1602.06709.pdf", "metadata": {"source": "META", "title": "Distributed Deep Learning Using Synchronous Stochastic Gradient Descent", "authors": ["Dipankar Das", "Sasikanth Avancha", "Dheevatsa Mudigere", "Srinivas Sridharan", "Dhiraj Kalamkar", "Bharat Kaul", "Pradeep Dubey"], "emails": ["DIPANKAR.DAS@INTEL.COM", "SASIKANTH.AVANCHA@INTEL.COM", "DHEEVATSA.MUDIGERE@INTEL.COM", "KARTHIKEYAN.VAIDYANATHAN@INTEL.COM", "SRINIVAS.SRIDHARAN@INTEL.COM", "DHIRAJ.D.KALAMKAR@INTEL.COM", "BHARAT.KAUL@INTEL.COM", "PRADEEP.DUBEY@INTEL.COM"], "sections": [{"heading": null, "text": "We design and implement a distributed, multinode synchronous SGD algorithm without changing hyperparameters, compressing data or changing algorithmic behavior. We perform a detailed scaling analysis and identify optimal design points for different networks. We demonstrate scaling of CNNs to 100s of nodes and present what we consider to be a record throughput of training throughputs. A 512 minibatch VGG-A CNN training run is scaled 90X to 128 nodes. Also, 256 minibatch VGG-A and OverFeat-FAST networks are scaled 53x and 42X respectively on a 64-node cluster. We also demonstrate the universality of our approach using best-in-class 6.5X scaling for a 7-layer DNN to 16 nodes. Afterwards, we try to democratize deep learning by training on an Ethernet-based AWS cluster 16 and scaling to 14X."}, {"heading": "1. Introduction", "text": "In fact, most of them are able to outdo themselves. Most of them are not able to outdo themselves, but most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves. Most of them are able to outdo themselves."}, {"heading": "2. Optimizing Computation in Neural Network Training", "text": "We can see neural network computation as a task diagram where each node represents a computing block (typically a layer) and edges represent the data flow (usually a multi-dimensional tensor) that defines data dependencies between nodes. Understanding the computing and memory bandwidth requirements of nodes and identifying optimal threading, cache blocking, vectorization, and register blocking strategies is critical."}, {"heading": "2.1. Compute Patterns", "text": "The calculation of heavy folding and fully connected layers takes two k + 2-dimensional tensors as input and generates a k + 2-dimensional output tensor. Here k is the number of dimensions of a feature card or kernel. Therefore, the additional two dimensions depend on the type of data: for tensors that contain inputs and outputs or gradients of inputs and outputs, they represent the minibatch and feature identifier; for tensors that contain weights and gradients of weights, they represent a pair of input output characteristics. The calculation operations for forward propagation, backward propagation, and determination of the weight gradient ikh are identical 2k + 3-dimensional loops. As an example, consider a 2D folding forward propagation operation where the input is a 4-D tensor via minibatch, input feature ikh output output (ip) and output value (im)."}, {"heading": "2.2. Cache Blocking", "text": "Unless there is a system in which the BPU Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-Register-"}, {"heading": "2.3. Data Layout and Vectorization", "text": "In addition to cache blocking, we need to vectorize the operations and also perform register blocking. A fully optimized vectorized forward propagation process is presented in Algorithm 2. It includes a 10-nested loop with cache blocking along the ifm and ofm, and register blocking along the external and output dimensions. For this blocked loop structure, we design the data so that access to the innermost loops is as narrow as possible, resulting in better utilization of the cache lines (and the associated bandwidth) and an improvement in prefcher performance. In this work, we lay out all the data, including activations and weights with the innermost dimension, via groups of SIMD latitude (SW) output cards \u00d7 FM \u00d7 FM \u00d7 \u00d7 FM. That is, we lay out the various data structures as: and gradient of activation: N \u00d7 C \u00d7 H \u00d7 H \u00d7 H \u00d7 H (C / SW) x FM FM cards, multiplied by SIMD latitude (SW) output cards \u00d7 FM weights: KHF and gradient."}, {"heading": "2.4. Register Blocking", "text": "The goal of register blocking is twofold: firstly, it improves the ratio of vector merged multiplied and added (VFMA) operations to those of load / memory operation; secondly, a sequence of reg consecutive VFMA statements is required to hide the latency of these statements; the latency for a VFMA operation on the Xeon CPU core is 5 cycles, and an Xeon CPU core can execute 2 VFMA statements per cycle. Therefore, we should have a register block size of at least 10. Therefore, 15 \u2265 RBh; RBw; 10, how we need a register to store the weight \u2212 k. In Algorithm 2, we illustrate a 2-D register block for forward propagation; since a xeon core can execute 2 loads per cycle, 2 VFMAs per cycle and 1 memory per cycle that are output cycles."}, {"heading": "2.5. Threading and Work Partitioning", "text": "For the forward and backward propagation operations, we divide the work into several mini-batches in jobs, each for a number of the output / input features on SW output / input features. These jobs are then evenly distributed among the different threads (iterations in lines 1-4. For the weight update, we treat weight cores for SW input and output feature pairs as a basic work unit, and these jobs are then distributed across several threads. If the number of jobs created in this way is low (as with C1 levels), we additionally divide the problem along the minibatch dimension and extract and then reduce the calculation of the weight gradient."}, {"heading": "3. Optimizing Communication", "text": "In this thesis we perform a strong scaling of the synchronous stochastic descendancy algorithm for minibatch gradients. We scale the calculation for an iteration across several nodes so that the parallel implementation with multiple threads and multiple nodes corresponds to a serial implementation with only one thread. We present a detailed theoretical analysis of the calculation and communication balance equations and define strategies for the division of labor between nodes."}, {"heading": "3.1. Data Parallelism", "text": "We analyze the algorithmic gradients to other nodes and receive updated weights to other nodes. (We analyze the algorithmic gradients to other nodes.) We analyze the algorithmic gradients to other nodes. (...) We analyze the algorithmic gradients to other nodes. (...) We analyze the algorithmic gradients to other nodes. (...) We analyze the algorithmic gradients to other nodes. (...) We analyze the algorithmic gradients to other nodes. (...) We analyze the entire communication to other nodes. (...) We analyze the algorithmic gradients to other nodes. (...) We analyze the algorithmic data to other nodes. (...) We analyze the entire communication to other nodes. (...) We analyze the entire communication per iteration. (...) We analyze the algorithmic gradients to other nodes."}, {"heading": "3.2. Analyzing Model Parallelism", "text": "We first consider a simple parallel model approach where each node operates on a part of the model of size: ifmb \u0445 ofmb input and output feature maps. In this case, the calculation for the forward pass, back pass, or weight-gradient update is given as follows: Computation = 2 \u0445 ifmb. (ifm / ifmb \u2212 1) The amount of data sent by the previous layer is: commsrecv = sizedata. (ifmb) inputw. (ifm / ifmb \u2212 1) The amount of data sent by the previous layer is: commssend = sizedata. (ifmb) ifmb \"inputw\" minibatchHence is the total volume of communication data: sifm \"ifm\" elputw \"elputh.\" (ifm) elputh \"elbatchHence.\""}, {"heading": "3.3. Analyzing Hybrid Parallelism", "text": "It is possible to consider data parallelism as partitioning along the \"minibatch\" dimension, and model parallelism as partitioning along the \"feature map\" dimension. (For this reason, we can divide the nodes into node groups, so that nodes within a group can follow a model parallelism, while corresponding nodes follow a node parallelism regime.) In this scheme, minibatch communication is divided into groups, each containing N / G nodes and responsible for mbgroup / G data points. (Model parallelism on this subgroup, for both forward and backward propagation, leads to an exchange of command model data: Commsmodel = 2, sizedata model, ifm, ifm, ifm, ifm, ifm, ifm, ifm, ifm, ifm."}, {"heading": "3.4. Deep Learning Communication Primitives", "text": "The parallel hybrid approach can be implemented with two simple multi-node data transmission operations, which we call \"part-reduce\" or \"part-broadcast\": With a group of nodes Ng and a tensor \u03c4, the part-reduce operation performs a reduction over partial \u03c4, which is calculated locally on each node of Ng, and then scatters the reduced \u03c4 to all nodes in Ng. The two steps of reduction and scatter can be merged and best represented by MPI Reduce scatter (), as shown in."}, {"heading": "4. PCL-DNN Software Framework", "text": "The PCL-DNN software framework consists of three primary modules: data processing, an optimized computation library of core CNN / DNN functions optimized for x86, and an optimized MPI-based communication library to run PCLDNN on a large distributed system. The data processing module acts as a data layer within our framework, ensuring a continuous stream of input data (e.g. images, language), which drives the training or scoring process for a specific application as needed. It performs the various calculations - forward, backward, and weighted updates - on the underlying hardware. The main role of the data processing module is to input data that the library uses for its functions. An important requirement we place on this module is that it does not become a bottleneck."}, {"heading": "5. Experimental Results", "text": "We use the Cori Phase I system for both single- and multi-node experiments. It is a Cray XC device with 1630 Intel Xeon E5-2698v3 HSW dual-socket CPUs with 16 cores (supporting up to 32 threads) per socket and 128 GB of memory per node. This features a Cray Aries high-speed \"Dragonfly\" topology connection."}, {"heading": "5.1. Single-node Performance", "text": "We show results for both scoring (FP in the figure) and training (FP + BP in the figure) in five minibatch sizes, 16, 32, 64, 128 and 256. Figure 3 shows that our framework delivers approximately 315 and 95 frames / s for Overfeat-FAST and VGG-A for scoring, respectively; for training, the throughput is about 90 and 30, respectively. We also observe that the throughput of PCL DNN across minibatch sizes remains nearly the same for the largest topology VGG-A for both scoring and training. With OverFeat, which is about 3x smaller than VGG-A, we observe that the throughput for the smaller minibatch sizes (i.e. 16 and 32) is lower than the throughput of the largest minibatch (256) for training, whereas there are no significant differences in throughput efficiency for the minibatch sizes."}, {"heading": "5.2. Scaling Results", "text": "PCL-DNN delivers the best scaling performance to date for deep learning applications without the use of specialized HW (accelerators, NW elements, textiles). We present the scaling performance for the VGG-A on the NERSC Cori Phase I cluster, which runs up to 128 nodes. Figure 4 shows the performance of the VGG-A as we scale from 1 to 128 CPU nodes on the NERSC Cori machine. At minibatch sizes of 256 and 512, PCL-DNN scales almost linearly with the number of nodes. At 512 minibatches, PCLDNN scales by 90X, at a throughput of 2510 frames per second, this corresponds to a scaling efficiency of 70% at 128 nodes, which significantly reduces training time to less than 10 minutes per epoch, at 128 nodes, PCLDNN scales by 90X, at a throughput of 10 frames per second, this corresponds to a scaling efficiency of 258% at 128 nodes."}, {"heading": "5.3. Scaling on Cloud", "text": "This section presents the performance and scaling of PCLDNN to AWS EC2. The purpose of these experiments is to demonstrate the applicability of our performance optimizations in multi-tenant cloud environments that are not as powerful as dedicated HPC clusters. Our experiments were conducted on a cluster with 16 nodes c4.x8large RHEL 7.1 instances. Each instance consists of 2-socket 9-core 2.9 GHz Xeon E5-2666 v3 with 60 GB of memory. Connections between instances are made via 10 Gigabit Ethernet. Unlike Cori, a dedicated bare metal HPC cluster, CPU and network resources are virtualized in EC2, resulting in higher overheads. We enabled support for SR-IOV network virtualization (also known as \"enhanced networking\" from AWS). In addition, we dedicated a core for processing interrupt requests for the network by means of transmission and receive performance enhancements of 40% to 27% DNS, respectively, which shows the transmission performance and receive performance of 25%."}, {"heading": "5.4. Automatic Speech Recognition", "text": "We examine DNNs in the context of automatic speech recognition (ASR) using context-dependent Deep Neural Networks (CD-DNN) HMMs (Seide et al., 2011).CDDNN HMMs combine classic artificial-neural network HMMs with traditional bound state triphons and deliver a relative WER reduction of 33% compared to a discriminatory trained GMM-HMM on Hub500 switchboard dataset. This network consists of 7 fully connected hidden layers of 2048 neurons each. For this network, a detailed performance study (Seide et al., 2014b) provides the performance for both single nodes and for scaling. For the CD-DNN network, a Xeon E5-2697v3 HSW-CPU (with 14x2 cores with 1.7 TFLOPS / s SP peak) PCLDNNs key numbers / s. This is better than the 4X-reported performance of the CP4CD-201x and 4CD-4CD."}, {"heading": "6. Conclusions", "text": "We demonstrate that deep learning trainings can be conducted on a large scale with synchronous SGD at high throughput on CPUs. We extend the state of the art in terms of scaling and time-to-solution and present detailed insights and analyses of multi-ode training."}, {"heading": "7. Acknowledgements", "text": "The authors thank Prabhat Kumar, Wahid Bhimji and Lisa Gerhardt of the National Energy Research Scientific Computing Center for their support in accessing the Cori supercomputer."}], "references": [{"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Sermanet", "Pierre", "Eigen", "David", "Zhang", "Xiang", "Mathieu", "Micha\u00ebl", "Fergus", "Rob", "LeCun", "Yann"], "venue": "CoRR, abs/1312.6229,", "citeRegEx": "Sermanet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sermanet et al\\.", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "CoRR, abs/1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Deep image: Scaling up image recognition", "author": ["Wu", "Ren", "Yan", "Shengen", "Shan", "Yi", "Dang", "Qingqing", "Sun", "Gang"], "venue": "CoRR, abs/1501.02876,", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}, {"title": "Deep learning with elastic averaging SGD", "author": ["Zhang", "Sixin", "Choromanska", "Anna", "LeCun", "Yann"], "venue": "CoRR, abs/1412.6651,", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 2, "context": ", 2015), and DeepImage (Wu et al., 2015).", "startOffset": 23, "endOffset": 40}, {"referenceID": 3, "context": ", 2014a), elastic-SGD (Zhang et al., 2014), as well as asynchronous SGD (Chilimbi et al.", "startOffset": 22, "endOffset": 42}, {"referenceID": 0, "context": "We present detailed single-node and multi-node performance results for two well-known deep learning topologies \u2013 OverFeat (Sermanet et al., 2013) and VGG-A (Simonyan Algorithm 1 Forward Propagation 1: for i0 \u2208 0, .", "startOffset": 122, "endOffset": 145}], "year": 2016, "abstractText": "We design and implement a distributed multinode synchronous SGD algorithm, without altering hyperparameters, or compressing data, or altering algorithmic behavior. We perform a detailed analysis of scaling, and identify optimal design points for different networks. We demonstrate scaling of CNNs on 100s of nodes, and present what we believe to be record training throughputs. A 512 minibatch VGG-A CNN training run is scaled 90X on 128 nodes. Also 256 minibatch VGG-A and OverFeat-FAST networks are scaled 53X and 42X respectively on a 64 node cluster. We also demonstrate the generality of our approach via best-in-class 6.5X scaling for a 7-layer DNN on 16 nodes. Thereafter we attempt to democratize deep-learning by training on an Ethernet based AWS cluster and show 14X scaling on 16 nodes.", "creator": "LaTeX with hyperref package"}}}