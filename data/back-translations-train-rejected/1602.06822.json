{"id": "1602.06822", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2016", "title": "Understanding Visual Concepts with Continuation Learning", "abstract": "We introduce a neural network architecture and a learning algorithm to produce factorized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from the previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.", "histories": [["v1", "Mon, 22 Feb 2016 15:38:59 GMT  (4348kb,D)", "http://arxiv.org/abs/1602.06822v1", "Under review as a workshop paper for ICLR 2016"]], "COMMENTS": "Under review as a workshop paper for ICLR 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["william f whitney", "michael chang", "tejas kulkarni", "joshua b tenenbaum"], "accepted": false, "id": "1602.06822"}, "pdf": {"name": "1602.06822.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["William F. Whitney", "Michael Chang", "Tejas Kulkarni", "Joshua B. Tenenbaum"], "emails": ["wwhitney@mit.edu", "mbchang@mit.edu", "tejask@mit.edu", "jbt@mit.edu"], "sections": [{"heading": "INTRODUCTION", "text": "Deep learning has led to remarkable breakthroughs in solving perceptual tasks such as object recognition, localization, and segmentation using large amounts of labeled data. However, the problem of abstract images without manual supervision is an open problem in machine perception. Existing unsupervised learning techniques have attempted to address this problem (Hinton and Salakhutdinov 2006; Ranzato et al. 2007; Lee et al. 2009), but lack the ability to generate latent factors of variation or symbolic visual concepts from raw data. Computer vision has historically been formulated as the problem of symbolic description of scenes from input images (Horn 1986). Without untangled and symbolic visual concepts, it is difficult to interpret or reuse representations across tasks as no single component of the representation vector has a semantic meaning. Traditionally, it has been difficult to adapt neural network architectures to learn such representations from raw data, since no single component of the representation vector has a semantic meaning."}, {"heading": "RELATED WORK", "text": "In fact, most of them will be able to play by the rules they have set themselves in order to play by the rules."}, {"heading": "CONTINUATION LEARNING", "text": "To learn the gating function, we use a technique first described in (W. Whitney 2016) to gently convert a soft weight function into a binary decision. Normally, a model that makes a hard decision to go through a single component (for example, 200) would be difficult to train; in this case, many forward passes through the decoder would be required to calculate the loss expectation for each of the possible decisions. However, a model that uses a soft weight across all components can be trained with weight loss in a single forward and backward pass. To create a continuation between these two possibilities, we use a planning for sharpening the weight (Graves, Wayne and Danihelka 2014) combined with noise on the output of the gate head. Given a weight distribution generated by the gating head, and a sharpening parameter proportional to the training epoch, we produce a sharpened and weighted distribution that focuses on a particular component (this + weighted = N)."}, {"heading": "RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "ATARI FRAMES", "text": "Our first dataset consists of frames from the Atari 2600 game Breakout. The model inputs two frames that occurred one after the other, and then reconstructs the second frame. This dataset was created using a trained DQN network (Mnih et al. 2015). Since the model can only use some components of its representation from the second frame, these components must contain all the information needed to predict the second frame. For this dataset, we use three gating heads that make it possible to include three components of ht in the first frame."}, {"heading": "SYNTHETIC FACES", "text": "We trained the model using the Basel Face Model (Paysan et al. 2009) and prepared it as in Kulkarni et al. 2015. Input consists of two images of the same face, between which only one of {lighting, height, azimuth} changes. We use a single gating head for this data set, so that the model must represent all the differences between these two images in a single unit."}, {"heading": "DISCUSSION", "text": "We have shown that it is possible to train a model that learns a factorized, symbolic representation of the variation factors in image sequences from raw data. Such a model uses time continuity to understand visual concepts at a high level by representing objects and motion instead of raw pixels. Future work may extend this model to more complex settings with any number of variation factors."}], "references": [{"title": "Learning Deep Architectures for AI.", "author": ["Bengio", "Yoshua"], "venue": "Foundations and Trends in Machine Learning", "citeRegEx": "Bengio and Yoshua.,? \\Q2009\\E", "shortCiteRegEx": "Bengio and Yoshua.", "year": 2009}, {"title": "Generative Adversarial Nets.", "author": ["Goodfellow", "Ian", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Neural Turing Machines.", "author": ["Graves", "Alex", "Greg Wayne", "Ivo Danihelka"], "venue": "ArXiv Preprint ArXiv:1410.5401", "citeRegEx": "Graves et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Reducing the Dimensionality of Data with Neural Networks.", "author": ["Hinton", "Geoffrey E", "Ruslan R Salakhutdinov"], "venue": "Science", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Transforming Auto-Encoders.", "author": ["Hinton", "Geoffrey E", "Alex Krizhevsky", "Sida D Wang"], "venue": "In Artificial Neural Networks and Machine Learning\u2013ICANN", "citeRegEx": "Hinton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2011}, {"title": "Robot Vision", "author": ["Horn", "Berthold."], "venue": "MIT press.", "citeRegEx": "Horn and Berthold.,? 1986", "shortCiteRegEx": "Horn and Berthold.", "year": 1986}, {"title": "Auto-Encoding Variational Bayes.", "author": ["Kingma", "Diederik P", "Max Welling"], "venue": "ArXiv Preprint ArXiv:1312.6114", "citeRegEx": "Kingma et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2013}, {"title": "Deep Convolutional Inverse Graphics Network.", "author": ["Kulkarni", "Tejas D", "William F Whitney", "Pushmeet Kohli", "Josh Tenenbaum"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "Human-Level Concept Learning Through Probabilistic Program Induction.", "author": ["Lake", "Brenden M", "Ruslan Salakhutdinov", "Joshua B Tenenbaum"], "venue": "Science", "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations.", "author": ["Lee", "Honglak", "Roger Grosse", "Rajesh Ranganath", "Andrew Y Ng"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Lee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction.", "author": ["Masci", "Jonathan", "Ueli Meier", "Dan Cire\u015fan", "J\u00fcrgen Schmidhuber"], "venue": "In Artificial Neural Networks and Machine Learning\u2013ICANN", "citeRegEx": "Masci et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Masci et al\\.", "year": 2011}, {"title": "Human-Level Control Through Deep Reinforcement Learning.", "author": ["Mnih", "Volodymyr", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves"], "venue": "Nature", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "A 3D Face Model for Pose and Illumination Invariant Face Recognition.", "author": ["P. Paysan", "R. Knothe", "B. Amberg", "S. Romdhani", "T. Vetter"], "venue": "Proceedings of the 6th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS) for Security,", "citeRegEx": "Paysan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Paysan et al\\.", "year": 2009}, {"title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.", "author": ["Radford", "Alec", "Luke Metz", "Soumith Chintala"], "venue": "ArXiv Preprint ArXiv:1511.06434", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition.", "author": ["M Ranzato", "Fu Jie Huang", "Y-L Boureau", "Yann LeCun"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Ranzato et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2007}, {"title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models.", "author": ["Rezende", "Danilo Jimenez", "Shakir Mohamed", "Daan Wierstra"], "venue": "ArXiv Preprint ArXiv:1401.4082", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Disentangled Representations in Neural Models.", "author": ["Whitney", "William"], "venue": "ArXiv Preprint ArXiv:1602.02383", "citeRegEx": "Whitney and William.,? \\Q2016\\E", "shortCiteRegEx": "Whitney and William.", "year": 2016}], "referenceMentions": [{"referenceID": 14, "context": "Existing unsupervised learning techniques have tried to address this problem (Hinton and Salakhutdinov 2006; Ranzato et al. 2007; Lee et al. 2009) but lack the ability to produce latent factors of variations or symbolic visual concepts from raw data.", "startOffset": 77, "endOffset": 146}, {"referenceID": 9, "context": "Existing unsupervised learning techniques have tried to address this problem (Hinton and Salakhutdinov 2006; Ranzato et al. 2007; Lee et al. 2009) but lack the ability to produce latent factors of variations or symbolic visual concepts from raw data.", "startOffset": 77, "endOffset": 146}, {"referenceID": 7, "context": "(2009)), variational auto-encoders (Kingma and Welling 2013; Rezende, Mohamed, and Wierstra 2014; Kulkarni et al. 2015), convolution based encoder-decoders (Ranzato et al.", "startOffset": 35, "endOffset": 119}, {"referenceID": 14, "context": "2015), convolution based encoder-decoders (Ranzato et al. 2007; Lee et al. 2009), and generative adversarial networks (Goodfellow et al.", "startOffset": 42, "endOffset": 80}, {"referenceID": 9, "context": "2015), convolution based encoder-decoders (Ranzato et al. 2007; Lee et al. 2009), and generative adversarial networks (Goodfellow et al.", "startOffset": 42, "endOffset": 80}, {"referenceID": 1, "context": "2009), and generative adversarial networks (Goodfellow et al. 2014; Radford, Metz, and Chintala 2015).", "startOffset": 43, "endOffset": 101}, {"referenceID": 7, "context": "Inverse graphics networks (Kulkarni et al. 2015) have also been shown to disentangle interpretable factors of variations, albeit in a semi-supervised learning setting.", "startOffset": 26, "endOffset": 48}, {"referenceID": 5, "context": "A number of generative models have been proposed in the literature to learn abstract visual representations including RBM-based models (Hinton and Salakhutdinov 2006, Lee et al. (2009)), variational auto-encoders (Kingma and Welling 2013; Rezende, Mohamed, and Wierstra 2014; Kulkarni et al.", "startOffset": 167, "endOffset": 185}, {"referenceID": 10, "context": "This model is a deep convolutional autoencoder (Hinton and Salakhutdinov 2006; Bengio 2009; Masci et al. 2011) with modifications to accommodate multiple frames and encourage a particular factorization in the latent space.", "startOffset": 47, "endOffset": 110}, {"referenceID": 11, "context": "This dataset was generated with a trained DQN network (Mnih et al. 2015).", "startOffset": 54, "endOffset": 72}, {"referenceID": 12, "context": "We trained the model on faces generated from the Basel face model (Paysan et al. 2009) and prepared as in (Kulkarni et al.", "startOffset": 66, "endOffset": 86}, {"referenceID": 7, "context": "2009) and prepared as in (Kulkarni et al. 2015).", "startOffset": 25, "endOffset": 47}], "year": 2016, "abstractText": "We introduce a neural network architecture and a learning algorithm to produce factorized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from the previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.", "creator": "LaTeX with hyperref package"}}}