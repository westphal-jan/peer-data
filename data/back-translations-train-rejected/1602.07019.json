{"id": "1602.07019", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2016", "title": "Sentence Similarity Learning by Lexical Decomposition and Composition", "abstract": "Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a two-channel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.", "histories": [["v1", "Tue, 23 Feb 2016 03:08:50 GMT  (587kb,D)", "http://arxiv.org/abs/1602.07019v1", null], ["v2", "Fri, 14 Jul 2017 19:51:10 GMT  (719kb,D)", "http://arxiv.org/abs/1602.07019v2", "In Proceedings of Coling 2016"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhiguo wang", "haitao mi", "abraham ittycheriah"], "accepted": false, "id": "1602.07019"}, "pdf": {"name": "1602.07019.pdf", "metadata": {"source": "CRF", "title": "Sentence Similarity Learning by Lexical Decomposition and Composition", "authors": ["Zhiguo Wang"], "emails": ["abei}@us.ibm.com"], "sections": [{"heading": null, "text": "Most conventional sentence similarity methods focus only on similar parts of two input sentences and simply ignore the disparate parts that normally give us some clues and semantic meanings about the sentences. In this work, we propose a model that takes into account both the similarities and the dissimilarities by splitting and assembling lexical semantics across sentences. The model presents each word as a vector and calculates a semantic match vector for each word based on all the words of the other sentence. Then, each word vector is split into a similar component and an unequal component based on the semantic match vector. Next, a two-channel CNN model is used to capture features by assembling the similar and dissimilar components. Finally, a similarity value is estimated via the composite feature vectors. Experimental results show that our model maintains the state-of-the-of-the-art performance in selecting the answer sentences and achieves a comparable result in identifying the paraphrase."}, {"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want and what they want to do."}, {"heading": "2 Model Overview", "text": "This year we have reached the stage where there has never been such a process in which there has been such a process."}, {"heading": "3 An End-to-End Implementation", "text": "Section 2 gives us an insight into our model. In this section we describe details of the individual phases."}, {"heading": "3.1 Semantic Matching Functions", "text": "This subsection describes our specifications for the semantic matching function fmatch in equals. (1) The goal of fmatch is to generate a semantic matching vector s \u00b2 i for si by computing the vectors from T. For a set pair S and T, we first calculate a similarity matrix Am \u00b7 n in which each element ai, j \u00b2 Am \u00b7 n calculates the cosinal similarity between the words si and tj asai, j = sTi tj \u00b2 s, j \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s = s \u00b2 s (5) Then we define three different semantic matching functions via Am \u00b7 n: fmatch (si, T) = 1 = 0 ai, j \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s = s \u00b2 s \u00b2 s \u00b2 s = s \u00b2 s \u00b2 s \u00b2 s \u00b2 s = s \u00b2 s \u00b2 s \u00b2 s = s \u00b2 s \u00b2 s \u00b2 s = s \u00b2 s \u00b2 s = s \u00b2 s = s \u00b2 s \u00b2 s = s \u00b2 s = s \u00b2 s = s \u00b2 s = s \u00b2 s = s \u00b2 s = s \u00b2 s = s = s \u00b2 s = s = s \u00b2 s = s = s \u00b2 s = s = s \u00b2 s = s = s = s \u00b2 s = s = s = s = s \u00b2 s = s = s = s = s \u00b2 s = s = s = s = s = s \u00b2 s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s = s \u00b2 s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s = s = s = s = s = s \u00b2 s = s = s = s = s = s = s = s = T)."}, {"heading": "3.2 Decomposition Functions", "text": "This subsection describes the implementations for the decomposition function fdecomp in Eq. (2) The intention of fdecomp is to decompose a word vector sj based on its semantic matching vector s \u2212 j into a similar component s + i and an unequal component s \u2212 i, where s + i specifies the semantics of si, which is covered by s \u2212 i and s \u2212 i. We implement three types of decomposition functions: rigid, linear, and orthogonal. Rigid decomposition adapts only to the maximum version of fmatch. Firstly, it detects whether there is an exactly matching word in the other sentence, or si. If so, the vector si is assigned to the similar component s + i, and the unequal component is assigned a zero vector 0. Otherwise, the vector si is assigned to the unequal component s."}, {"heading": "3.3 Composition Functions", "text": "The objective of the composition function fcomp in Eq. (3) is to extract features from both the similar component matrix and the unequal component matrix. We also want to obtain similarities and differences of different granularity during the composition phase. Inspired by Kim (2014), we use a two-channel Convolutionary Neural Network (CNN) and design filters based on different order of n-grams, e.g. unicam, bigram and trigram. The CNN model includes two sequential operations: folding and maximum pooling. For the folding operation, we define a list of filters {where}. The shape of each filter is d \u00b7 h, where d is the dimension of word vectors and h is the window size. Each filter is applied to two patches (a window size h of vectors), to similar and unequal channels, and generates a feature."}, {"heading": "3.4 Similarity Assessment Function", "text": "The similarity evaluation function fsim in Equation (4) predicts a similarity value by using two feature vectors as input. We use a linear function to summarize all the features and apply a sigmoid function to limit the similarity within the range [0, 1]."}, {"heading": "3.5 Training", "text": "We train our sentence similarity model by maximizing the probability on a training set. Each training instance in the training set is represented as a triple (Si, Ti, Li), where Si and Ti are a sentence pair, and Li, {0, 1} indicates the similarity between them. We assign Li = 1 if Ti is a paraphrase of Si for the paraphrase identification task or Ti is a correct answer for Si for the task of selecting the answer set. Otherwise, we assign Li = 0. We implement the mathematical expressions with Theano (Bastien et al., 2012) and use Adam (Kingma and Ba, 2014) for optimization."}, {"heading": "4 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Setting", "text": "We evaluate our model based on two tasks: the selection of answer sets and paraphrase identification. The task of selecting answer sets is to evaluate a list of candidate answers based on their similarities to a question set, and performance is measured based on mean average precision (MAP) and mean reciprocal rank (MRR). We experiment with two sets of data: QASent and WikiQA. Table 2 summarizes the statistics of the two sets of data in which QASent (Wang et al., 2007) was created from the TREC QA Track, and WikiQA (Yang et al., 2015) is based on real-world queries from Bing and Wikipedia. The task of paraphrase identification is to determine whether two sets are based on the similarity between them. Metrics include accuracy and positive class F1 score. We experiment with the Microsoft Research Paraphrase Corpus (MSRP) (1353), which contains the wrong number of words in the correct train, 1353 and 275 in 2004, and 1753."}, {"heading": "4.2 Model Properties", "text": "This year, the number of infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected infected."}, {"heading": "4.3 Comparing with State-of-the-art Models", "text": "This year, it is in our hands that people all over the world can unfold in a different way from the world in which they live."}, {"heading": "5 Related Work", "text": "The semantic adaptation functions in Section 3.1 are inspired by attention-based neural machine translation (Bahdanau et al., 2014; Luong et al., 2015). Most previous work that used the attention mechanism only in LSTM models introduced the attention mechanism into the CNN model. A similar work is the attention-based CNN model proposed by Yin et al. (2015). You first build an attention matrix for a sentence pair and then directly incorporate the attention matrix as the new channel of the CNN model. Otherwise, our model uses the attention matrix (or similarity matrix) to break down the original sentence matrix into a similar component matrix and an unequal component matrix, and then feeds these two matrices into a dual-channel CNN model. The model can then focus heavily on the interactions between similar sentence matrix and an unequal component matrix."}, {"heading": "6 Conclusion", "text": "To bridge the lexical gap problem, our model represents each word with its context vector. To extract features from both the similarity and the dissimilarity of a sentence pair, we developed several methods to split the word vector into a similar component and an unequal component. To extract features at multiple levels of granularity, we used a two-channel CNN model and equipped it with several types of gram filters. Experimental results show that our model is very effective in both the task of selecting response sets and the task of paraphrase identification."}, {"heading": "Acknowledgments", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.0473", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Theano: new features and speed improvements", "author": ["Pascal Lamblin", "Razvan Pascanu", "James Bergstra", "Ian J. Goodfellow", "Arnaud Bergeron", "Nicolas Bouchard", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bastien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["Dolan et al.2004] Bill Dolan", "Chris Quirk", "Chris Brockett"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Dolan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "Ppdb: The paraphrase database", "author": ["Benjamin Van Durme", "Chris Callison-Burch"], "venue": "In HLT-NAACL,", "citeRegEx": "Ganitkevitch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "Multi-perspective sentence similarity modeling with convolutional neural networks", "author": ["He et al.2015] Hua He", "Kevin Gimpel", "Jimmy Lin"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Tree edit models for recognizing textual entailments, paraphrases, and answers to questions", "author": ["Heilman", "Smith2010] Michael Heilman", "Noah A Smith"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the As-", "citeRegEx": "Heilman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Heilman et al\\.", "year": 2010}, {"title": "Discriminative improvements to distributional sentence similarity", "author": ["Ji", "Eisenstein2013] Yangfeng Ji", "Jacob Eisenstein"], "venue": "In EMNLP,", "citeRegEx": "Ji et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2013}, {"title": "Semantic similarity based on corpus statistics and lexical taxonomy. arXiv preprint cmplg/9709008", "author": ["Jiang", "Conrath1997] Jay J Jiang", "David W Conrath"], "venue": null, "citeRegEx": "Jiang et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Jiang et al\\.", "year": 1997}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba"], "venue": "In International Conference on Learning Representation (ICLR)", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Effective approaches to attention-based neural machine translation", "author": ["Hieu Pham", "Christopher D Manning"], "venue": "arXiv preprint arXiv:1508.04025", "citeRegEx": "Luong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Neural variational inference for text processing", "author": ["Miao et al.2015] Yishu Miao", "Lei Yu", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1511.06038", "citeRegEx": "Miao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Miao et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Paraphrase recognition via dissimilarity significance classification", "author": ["Qiu et al.2006] Long Qiu", "Min-Yen Kan", "Tat-Seng Chua"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Qiu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2006}, {"title": "Using information content to evaluate semantic similarity in a taxonomy. arXiv preprint cmp-lg/9511007", "author": ["Philip Resnik"], "venue": null, "citeRegEx": "Resnik.,? \\Q1995\\E", "shortCiteRegEx": "Resnik.", "year": 1995}, {"title": "Learning to rank short text pairs with convolutional deep neural networks", "author": ["Severyn", "Moschitti2015] Aliaksei Severyn", "Alessandro Moschitti"], "venue": "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development", "citeRegEx": "Severyn et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Severyn et al\\.", "year": 2015}, {"title": "Faq-based question answering via word alignment", "author": ["Wang", "Ittycheriah2015] Zhiguo Wang", "Abraham Ittycheriah"], "venue": "arXiv preprint arXiv:1507.02628", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "What is the jeopardy model? a quasi-synchronous grammar for qa", "author": ["Wang et al.2007] Mengqiu Wang", "Noah A Smith", "Teruko Mitamura"], "venue": "In EMNLPCoNLL,", "citeRegEx": "Wang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2007}, {"title": "Wikiqa: A challenge dataset for opendomain question answering", "author": ["Yang et al.2015] Yi Yang", "Wen-tau Yih", "Christopher Meek"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Convolutional neural network for paraphrase identification", "author": ["Yin", "Sch\u00fctze2015] Wenpeng Yin", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association", "citeRegEx": "Yin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2015}, {"title": "Abcnn: Attention-based convolutional neural network for modeling sentence pairs", "author": ["Yin et al.2015] Wenpeng Yin", "Hinrich Sch\u00fctze", "Bing Xiang", "Bowen Zhou"], "venue": null, "citeRegEx": "Yin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "For example, in paraphrase identification task, sentence similarity is used to determine whether two sentences are paraphrase or not (Yin and Sch\u00fctze, 2015; He et al., 2015).", "startOffset": 133, "endOffset": 173}, {"referenceID": 13, "context": "the dissimilarity (shown in angle brackets) between two sentences is also a significant clue (Qiu et al., 2006).", "startOffset": 93, "endOffset": 111}, {"referenceID": 14, "context": "Examples include knowledge-based metrics (Resnik, 1995) and corpus-based metrics (Jiang and Conrath, 1997; Yin and Sch\u00fctze, 2015; He et al.", "startOffset": 41, "endOffset": 55}, {"referenceID": 4, "context": "Examples include knowledge-based metrics (Resnik, 1995) and corpus-based metrics (Jiang and Conrath, 1997; Yin and Sch\u00fctze, 2015; He et al., 2015).", "startOffset": 81, "endOffset": 146}, {"referenceID": 4, "context": "To measure sentence similarity from various granularities (issue 2), researchers have explored features extracted from n-grams, continuous phrases, discontinuous phrases, and parse trees (Yin and Sch\u00fctze, 2015; He et al., 2015; Heilman and Smith, 2010).", "startOffset": 187, "endOffset": 252}, {"referenceID": 4, "context": "Examples include knowledge-based metrics (Resnik, 1995) and corpus-based metrics (Jiang and Conrath, 1997; Yin and Sch\u00fctze, 2015; He et al., 2015). To measure sentence similarity from various granularities (issue 2), researchers have explored features extracted from n-grams, continuous phrases, discontinuous phrases, and parse trees (Yin and Sch\u00fctze, 2015; He et al., 2015; Heilman and Smith, 2010). The third issue did not get much attention in the past, the only related work of Qiu et al. (2006) explored the dissimilarity between sentences in a pair for paraphrase identification task, but they require human annotations in order to train a classifer, and their performance is still below the state of the art.", "startOffset": 130, "endOffset": 501}, {"referenceID": 12, "context": "(2013) is an effective way to handle the lexical gap issue in the sentence similarity task, as it represents each word with a distributed vector, and words appearing in similar contexts tend to have similar meanings (Mikolov et al., 2013).", "startOffset": 216, "endOffset": 238}, {"referenceID": 12, "context": "Word embedding of Mikolov et al. (2013) is an effective way to handle the lexical gap issue in the sentence similarity task, as it represents each word with a distributed vector, and words appearing in similar contexts tend to have similar meanings (Mikolov et al.", "startOffset": 18, "endOffset": 40}, {"referenceID": 13, "context": "Besides the suggestion from Qiu et al. (2006) that the significance of the dissimilar parts alone between two sentences has a great effect of their similarity, we also think that the dissimilar and similar components have strong connections.", "startOffset": 28, "endOffset": 46}, {"referenceID": 8, "context": "Inspired from Kim (2014), we utilize a twochannel convolutional neural networks (CNN) and design filters based on various order of n-grams, e.", "startOffset": 14, "endOffset": 25}, {"referenceID": 1, "context": "We implement the mathematical expressions with Theano (Bastien et al., 2012) and use Adam (Kingma and Ba, 2014) for optimization.", "startOffset": 54, "endOffset": 76}, {"referenceID": 17, "context": "Table 2 summarises the statistics of the two datasets, where QASent (Wang et al., 2007) was created from the TREC QA track, and WikiQA (Yang et al.", "startOffset": 68, "endOffset": 87}, {"referenceID": 18, "context": ", 2007) was created from the TREC QA track, and WikiQA (Yang et al., 2015) is constructed from real queries of Bing and Wikipedia.", "startOffset": 55, "endOffset": 74}, {"referenceID": 2, "context": "We experiment on the Microsoft Research Paraphrase corpus (MSRP) (Dolan et al., 2004), which includes 2753 true and 1323 false instances in the training set, and 1147 true and 578 false instances in the test set.", "startOffset": 65, "endOffset": 85}, {"referenceID": 12, "context": "word2vec toolkit (Mikolov et al., 2013) on the English Gigaword (LDC2011T07).", "startOffset": 17, "endOffset": 39}, {"referenceID": 17, "context": "Yang et al. (2015) constructed the dataset and reimplemented several baseline models.", "startOffset": 0, "endOffset": 19}, {"referenceID": 11, "context": "Miao et al. (2015) models the sentence similarity by enriching LSTMs with a latent stochastic attention mechanism.", "startOffset": 0, "endOffset": 19}, {"referenceID": 11, "context": "Miao et al. (2015) models the sentence similarity by enriching LSTMs with a latent stochastic attention mechanism. The corresponding performance is given at the third row of Table 4. Yin et al. (2015) introduced the attention mechanism into the CNN model, and captured the best performance (the fourth row of Table 4).", "startOffset": 0, "endOffset": 201}, {"referenceID": 3, "context": ", embeddings from part-ofspeech (POS) tags and PARAGRAM vectors trained from the Paraphrase Database (Ganitkevitch et al., 2013).", "startOffset": 101, "endOffset": 128}, {"referenceID": 3, "context": "He et al. (2015) proposed a similar model to Yin and Sch\u00fctze (2015).", "startOffset": 0, "endOffset": 17}, {"referenceID": 3, "context": "He et al. (2015) proposed a similar model to Yin and Sch\u00fctze (2015). Similarly, they also used a CNN model to extract features at multiple levels of granularity.", "startOffset": 0, "endOffset": 68}, {"referenceID": 3, "context": ", embeddings from part-ofspeech (POS) tags and PARAGRAM vectors trained from the Paraphrase Database (Ganitkevitch et al., 2013). Their model outperformed Yin and Sch\u00fctze (2015) without the need of pretraining (the sixth row of Table 5).", "startOffset": 102, "endOffset": 178}, {"referenceID": 3, "context": ", embeddings from part-ofspeech (POS) tags and PARAGRAM vectors trained from the Paraphrase Database (Ganitkevitch et al., 2013). Their model outperformed Yin and Sch\u00fctze (2015) without the need of pretraining (the sixth row of Table 5). However, the performance was reduced after removing the extra resources (the fourth and fifth rows of Table 5). Yin et al. (2015) applied their attention-based CNN model on this dataset.", "startOffset": 102, "endOffset": 368}, {"referenceID": 3, "context": ", embeddings from part-ofspeech (POS) tags and PARAGRAM vectors trained from the Paraphrase Database (Ganitkevitch et al., 2013). Their model outperformed Yin and Sch\u00fctze (2015) without the need of pretraining (the sixth row of Table 5). However, the performance was reduced after removing the extra resources (the fourth and fifth rows of Table 5). Yin et al. (2015) applied their attention-based CNN model on this dataset. By adding a couple of sparse features and using a layerwise training strategy, they got a pretty good performance. Comparing to these neural network based models, our model obtained a comparable performance (the last row of Table 5) without using any sparse features, extra annotated resources and specific training strategies. However, the best performance so far on this dataset is obtained by Ji and Eisenstein (2013). In their model, they just utilized several hand-crafted features in a Support Vector Machine (SVM) model.", "startOffset": 102, "endOffset": 846}, {"referenceID": 0, "context": "1 are inspired from the attention-based neural machine translation (Bahdanau et al., 2014; Luong et al., 2015).", "startOffset": 67, "endOffset": 110}, {"referenceID": 10, "context": "1 are inspired from the attention-based neural machine translation (Bahdanau et al., 2014; Luong et al., 2015).", "startOffset": 67, "endOffset": 110}, {"referenceID": 0, "context": "1 are inspired from the attention-based neural machine translation (Bahdanau et al., 2014; Luong et al., 2015). However, most of the previous work using the attention mechanism in only LSTM models. Whereas our model introduces the attention mechanism into the CNN model. A similar work is the attention-based CNN model proposed by Yin et al. (2015). They first build an attention matrix for a sentence pair, and then directly take the attention matrix as a new channel of the CNN model.", "startOffset": 68, "endOffset": 349}], "year": 2016, "abstractText": "Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a twochannel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.", "creator": "LaTeX with hyperref package"}}}