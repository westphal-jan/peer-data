{"id": "1602.07029", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2016", "title": "Latent Skill Embedding for Personalized Lesson Sequence Recommendation", "abstract": "Students in online courses generate large amounts of data that can be used to personalize the learning process and improve quality of education. In this paper, we present the Latent Skill Embedding (LSE), a probabilistic model of students and educational content that can be used to recommend personalized sequences of lessons with the goal of helping students prepare for specific assessments. Akin to collaborative filtering for recommender systems, the algorithm does not require students or content to be described by features, but it learns a representation using access traces. We formulate this problem as a regularized maximum-likelihood embedding of students, lessons, and assessments from historical student-content interactions. An empirical evaluation on large-scale data from Knewton, an adaptive learning technology company, shows that this approach predicts assessment results competitively with benchmark models and is able to discriminate between lesson sequences that lead to mastery and failure.", "histories": [["v1", "Tue, 23 Feb 2016 04:20:40 GMT  (608kb,D)", "http://arxiv.org/abs/1602.07029v1", "Under review by the ACM SIGKDD Conference on Knowledge Discovery and Data Mining"]], "COMMENTS": "Under review by the ACM SIGKDD Conference on Knowledge Discovery and Data Mining", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CY", "authors": ["siddharth reddy", "igor labutov", "thorsten joachims"], "accepted": false, "id": "1602.07029"}, "pdf": {"name": "1602.07029.pdf", "metadata": {"source": "META", "title": "Latent Skill Embedding for Personalized Lesson Sequence Recommendation", "authors": ["Siddharth Reddy", "Igor Labutov", "Thorsten Joachims"], "emails": ["sgr45@cornell.edu", "iil4@cornell.edu", "tj@cs.cornell.edu"], "sections": [{"heading": "CCS Concepts", "text": "\u2022 Mathematics of computing \u2192 Probabilistic representations; \u2022 Computer methods \u2192 Learning in probabilistic graphical models; \u2022 Applied informatics \u2192 Computer-aided teaching;"}, {"heading": "Keywords", "text": "Probabilistic Embedding; Sequence Recommendation; Adaptive Learning"}, {"heading": "1. INTRODUCTION", "text": "The party's popularity has multiplied in recent years."}, {"heading": "2. RELATED WORK", "text": "Our work builds on existing literature in psychometric user modeling, which estimates the likelihood that a student will complete an assessment with latent conceptual competence and assessment difficulties. [23] The two-parameter Logistic Item Response Theory (2PL IRT) model adds an evaluation to the likelihood of outcomes. Both models assume that a map of assessments is a priori known to a small number of underlying concepts. We propose a data-driven method of content presentation that does not require priority knowledge of content to concepts. Although this approach sacrifices the interpretative capability of expert assessments, it has two advantages: it does not require labor-intensive expert annotation of content, and 2) it can modify representation over time as existing content or introduce new content."}, {"heading": "3. EMBEDDING MODEL", "text": "We now describe latent skill embedding, a probabilistic model that places students, lessons, and assessments in a common semantic space that we call the latent skill space. Students have trajectories through the latent skill space, while assessments and lessons are placed in fixed places. Formally, a student is presented as a set of latent skill levels. A teaching module is presented as a vector of skill gains."}, {"heading": "3.1 Modeling Assessment Results", "text": "For students the rating is ~ a and the result R, R \u00b2 Bernoulli (??????????????????????????????????????????????????????????????????????????????????????? and???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "3.2 Modeling Student Learning from Lessons", "text": "For students who have worked on a lesson with qualification gains and do not have qualifications at t + 1, the updated student state is ~ st + 1 \u0445 N (~ st + ~, \u03a3) (2), where the covariance matrix \u03a3 = Id\u03c3 2 is diagonal. For students with qualifications ~ q, ~ st + 1 \u0445 N (~ st + ~ \u03c6 (\u0445 (~ st, ~ q)), \u03a3) (3), where \u03c6 is the logistical function and \u0445 (~ st, ~ q) = ~ st \u00b7 q | | | ~ q | | |. The intuition behind this equation is that the qualification gain from a lesson should be weighted accordingly to how well a student fulfils the learning requirements. A student can compensate for missing qualifications in one skill by excessive strength in another skill, but the extent to which this trade-off is possible depends on the relative weights of qualification requirements. The same principle applies to students who acquire qualifications in another skill."}, {"heading": "4. PARAMETER ESTIMATION", "text": "We calculate MAP estimates of model parameters by maximizing the following objective function: L (\u0432) = \u2211 A log (P [R | ~ st, ~ a, \u03b3a]) + \u2211 L log (P [~ st + 1 | ~ st, ~ \u0442, ~ q]) \u2212 \u03b2 \u00b7 \u03bb (\u044b) (4), where A is the set of evaluation interactions, L is the set of lesson interactions, \u03bb (\u0443) is a regulation term that penalizes the L2 norms of embedding parameters (not the preset parameters) and \u03b2 is a regulation parameter. Non-negative constraints of embedding parameters (not the preset parameters) are enforced. L2 regulation is used to punish the size of embedding parameters in order to prevent overadjustment, and the preset parameters are not limited or regulated. This allows \u2212 | | ~ | + a positive evaluation of modules \u00b7 are particularly \u00b7 effective, and the preset parameters are an easy one to solve."}, {"heading": "5. EXPERIMENTS ON SYNTHETIC DATA", "text": "In order to demonstrate the correctness of our model, we must try to find a solution."}, {"heading": "6. EXPERIMENTS ON ONLINE COURSE DATA", "text": "We use data processed by Knewton, an adaptive learning technology company. Knewton's infrastructure uses student content access lanes to generate personalized recommendations and activity analyses for partner organizations using online learning products. Knewton's data describes interactions between college students and two science textbooks. The Book A data set was collected from 869 classrooms between January 1, 2014 and June 1, 2014, and includes 834,811 interactions, 3,471 students, 3,374 lessons, 3,480 assessments, and an average assessment rate of 0.712. The paths students take are skewed by instructional instructions, a referral system, and the sequence of chapters in the textbook. The Book B data set was collected from 1,070 classrooms between January 1, 2014 and June 1, 2014, and includes 1,349,541 interactions, 3,563 students, 3,843 lessons, 3,807 assessments, and an average assessment rate of fewer than the first-to-to-five sets of data."}, {"heading": "6.1 Assessment Result Prediction", "text": "We evaluate the embedding model on the basis of the task of predicting the results of pre-determined evaluation interactions and compare it with three benchmark models: the models of the one- and two-parameter logistics response theory and a two-dimensional model of the item-response theory. The 1PL-IRT model, also known as the rapid model, has the following evaluation probability: P [R = 1] = \u03c6 (\u03b8i \u2212 \u03b2j) for pupils i and item j, which is the item-discriminability and \u03b2 the item-difficulty, and \u03c6 is the logistic link function [23]. The 2PL model expands the probability as follows: P [R = 1] = \u03c6 (\u03b8i \u2212 \u03b2j)), where \u03b1 is the item-discriminability and \u03b2 the item-difficulty, and \u03c6 is the logistic link function [23]. The 2D-MIRT model, which is a multidimensional generalization of the 2PL-probability generalization, has the following Item-probability of success = Ij), where Ij is the probability of success = Ij."}, {"heading": "Lesion Analysis.", "text": "In order to gain an insight into which components of the embedding model contribute most to its predictive power, we perform a lesion analysis. For simplicity, we limit ourselves to using a two-dimensional embedding model (later we describe the effects of a variation in the embedding dimension d). We start with an embedding model that ignores lesson interactions and does not use bias terms. We then add components to the embedding model step by step to investigate their impact on the AUC prediction. Specifically, we evaluate embedding with and without lesson parameters, pre-preparation parameters ~ q for lessons and bias terms. Each variant of the model corresponds to a series in Table 1. From these results, the embedding of bias terms in the assessment probability (Eq. 1) yields a large and statistically significant increase in performance (p < 0.0003 for the standard test, the book vs. the validation validation of the CAUA in Level 6)."}, {"heading": "Effect of Data Heterogeneity.", "text": "One issue that may have influenced the results is the bias of the learning pathways discussed by [8]. In the data, we find that students \"learning paths are strongly guided by modules along common routes. We suspect that this bias diminishes the effect of modelling classroom requirements in embedding, and the inclusion of biases leads to a large performance boost. Most students attack a module with the same background knowledge, so an embedding that captures the variation in students working on the same module is not as valuable. In a regime where students working on a module come from a variety of skill backgrounds, our model, which includes classroom requirements, can further improve the results. Preliminary evidence for this is presented in Figure 9, where we put together our analysis of the two Knewton datasets on several public datasets of student interactions and a private dimension of the learning path, which were compiled into a language learning game."}, {"heading": "Effect of Embedding Dimension.", "text": "In other experiments, we examined the parameter space of the embedding model by varying the regularization constant \u03b2 and the embedding dimension d. The results for the change are not explicitly presented. In summary, we find that the increasing embedding dimension d considerably improves the performance in embedding models without bias, but that it has little influence on the performance in embedding with bias. The former is expected, since the embedding itself must be used to model general completion skills and general assessment difficulties."}, {"heading": "Sensitivity Analysis.", "text": "We perform several sensitivity analyses on Book A and observe that: the AUC prediction is most strongly influenced by a student's recent history (see Figure 10); the number of complete student histories in the training set has a strong impact on the AUC prediction through the quality of the module embedding (see Figure 11); the AUC prediction disintegrates when assessment results are loud in the training set (see Figure 13); the length of the AUC prediction is only slightly dependent on the AUC prediction (see Figure 12). These results lead to two important qualitative insights regarding the performance of the model: (1) for a regularly offered course (e.g. over several semesters) the model is steadily improving as log data is collected from students completing the course, and (2) the model performs best when assessments are made to test specific skills and minimize noise in outcomes."}, {"heading": "6.2 Lesson Sequence Discrimination", "text": "While the ability to predict students \"future performance from assessments is a useful metric for evaluating the embedding they learn, it does not solve the more important task of adaptive tutoring by providing tailored recommendations for the teaching sequence. We are introducing a surrogate task to evaluate the model's sequence recommendation performance based solely on observational data of student interactions by evaluating the model's ability to recommend\" productive \"paths among several alternatives."}, {"heading": "Bubbles as Experimental Evidence.", "text": "The size of the data set creates a unique opportunity to use the variability of learning paths to simulate the setting of a recommended experiment. We use a larger version of Book A data set with 14,707 students and 14,327 content modules for this evaluation. We note that the data includes many examples of learning paths that share the same teaching module at the beginning and end, but contain different lessons along the way. We refer to these cases as bubbles, measured by the relative performance of students who choose the recommended vs. the unrecommended path to the assessment module at the end of the bladder. We can use these bubbles to evaluate the ability of embedding to recommend a learning sequence that leads to success, measured by the relative performance of students taking the recommended vs. unrecommended path to the assessment module at the end of the bladder."}, {"heading": "Propensity Score Matching.", "text": "This observational study is potentially counteracted by many hidden variables. For example, it may be that one group of students systematically takes recommended paths, while another group of students does not, resulting in results at the end of a bubble that are largely dictated by teachers who prefer the groups or other student hidden factors, rather than assessing the quality of the path. To best weigh the settings of a randomized controlled study in our observational study, we use the standard inclination value matching approach for unbiased observation data [25, 2]. The key idea behind inclination value matching is to subdivide the observed data into variables self-contained variables that describe the distribution of traits (\"hidden variables\"), which subjects describe in the two conditions as expected in a randomized experiment. The validity of any conclusion drawn from the matrix matrix variables is unmodulated, and the matrix is pre-taken in this way, as the matrix is pre-assumed to determine the matrix of the matrix, the matrix is pre-taken in this manner."}, {"heading": "Results.", "text": "Figure 15 shows the results of the experiment and shows how much the students will benefit if they follow the path recommended by our embedding. We use the same embedding configuration as in line 6 of Table 1, where conditions and terms of the distortion factor are used in a two-dimensional embedding model with lesson. Of course, our assessment of the gain in the inventory rate from following a recommended path is strongly dependent on the relative advantages of the recommended and alternative path. We therefore record the gain that the recommended path achieves in relation to the difference in path quality, measured by the absolute difference in inventory rates between the two paths. Figure 15 shows that the model is generally able to recommend more successful paths, and this finding is robust compared to the choice of the closest neighbors used in adjusting the slope. As expected, the effect of the system recommendation is greater if there is a significant difference in quality between the two paths."}, {"heading": "7. CONCLUSIONS", "text": "The key idea is to use multi-dimensional embedding to capture the dynamics of learning and testing. Using an extensive data set gathered in real classrooms, we demonstrate (1) the model's ability to successfully predict learning outcomes and (2) implement an offline methodology as a proxy to evaluate the model's ability to recommend personalized learning paths. We demonstrate that our model is capable of successfully distinguishing between personalized learning paths that lead to mastery and failure. An implementation of latent skill embedding and the IPython notebooks used to conduct experiments is available online at http: / / siddharth.io / lentil."}, {"heading": "8. ACKNOWLEDGEMENTS", "text": "We would like to thank the members of Knewton for their valuable feedback on this work, which was partially funded by the National Science Foundation under the awards IIS1247637, IIS-1217686 and IIS-1513692, a John Templeton Foundation grant provided through the Metaknowledge Network at the University of Chicago and the Cornell Presidential Research Scholars Program."}, {"heading": "9. REFERENCES", "text": "[1] E. Andersen. Automatic Scaffolding for ProceduralLearning. Doctoral Thesis, 2014. [2] M. Caliendo and S. Kopeinig. Some Practical Guidelines for the Implementation of Propensity Score Matching. Journal of Economic Surveys, 22 (1): 31-72, 2008. [3] J. R. Carbonell. Ai in cai: An artificial intelligence approach to computer-assisted instruction. Man-Machine Systems, IEEE Transactions on, 11 (4): 190-202, 1970. [4] S. Chen, J. L. Moore, D. Turnbull, and T. Jamiims. Playlist prediction via metric embedding. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 714-722. ACM, 2012. [5] A. T. Corbett and J. R. Anderson. Knowledge tracing: Modeling the acquisition of procedural knowledge knowledge knowledge knowledge."}], "references": [{"title": "Automatic Scaffolding for Procedural Learning", "author": ["E. Andersen"], "venue": "PhD thesis", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Some practical guidance for the implementation of propensity score matching", "author": ["M. Caliendo", "S. Kopeinig"], "venue": "Journal of economic surveys, 22(1):31\u201372", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Ai in cai: An artificial-intelligence approach to computer-assisted instruction", "author": ["J.R. Carbonell"], "venue": "Man-Machine Systems, IEEE Transactions on, 11(4):190\u2013202", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1970}, {"title": "Playlist prediction via metric embedding", "author": ["S. Chen", "J.L. Moore", "D. Turnbull", "T. Joachims"], "venue": "Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 714\u2013722. ACM", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Knowledge tracing: Modeling the acquisition of procedural knowledge", "author": ["A.T. Corbett", "J.R. Anderson"], "venue": "User Modeling and User-Adapted Interaction, 4(4):253\u2013278", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1994}, {"title": "T-skirt: Online estimation of student proficiency in an adaptive learning system", "author": ["C. Ekanadham", "Y. Karklin"], "venue": "Machine Learning for Education Workshop at ICML", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Addressing the assessment challenge with an online system that tutors as it assesses", "author": ["M. Feng", "N. Heffernan", "K. Koedinger"], "venue": "User Modeling and User-Adapted Interaction, 19(3):243\u2013266", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "General features in knowledge tracing: Applications to multiple subskills", "author": ["J. Gonz\u00e1lez-Brenes", "Y. Huang", "P. Brusilovsky"], "venue": "temporal item response theory, and expert knowledge. In Proceedings of the 7th International Conference on Educational Data Mining ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Time-varying learning and content analytics via sparse factor analysis", "author": ["A.S. Lan", "C. Studer", "R.G. Baraniuk"], "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 452\u2013461. ACM", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Sparse factor analysis for learning and content analytics", "author": ["A.S. Lan", "A.E. Waters", "C. Studer", "R.G. Baraniuk"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Sherlock: A coached practice environment for an electronics troubleshooting", "author": ["A. Lesgold"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Handbook of modern item response theory", "author": ["W. Linden", "R.K. Hambleton"], "venue": "New York", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "Taste over time: The temporal dynamics of user preferences", "author": ["J. Moore", "S. Chen", "D. Turnbull", "T. Joachims"], "venue": "Conference of the International Society for Music Information Retrieval Conference (ISMIR), pages 401\u2013406", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "A framework for automatically generating interactive instructional scaffolding", "author": ["E. O\u2019Rourke", "E. Andersen", "S. Gulwani", "Z. Popovic"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Adapting bayesian knowledge tracing to a massive open online course in edx", "author": ["Z. Pardos", "Y. Bergner", "D. Seaton", "D. Pritchard"], "venue": "Educational Data Mining 2013", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Tutor modeling vs", "author": ["Z.A. Pardos", "N.T. Heffernan"], "venue": "student modeling. In Proceedings of the Twenty-Fifth International Florida Artificial Intelligence Research Society Conference, pages 420\u2013425", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning program embeddings to propagate feedback on student code", "author": ["C. Piech", "J. Huang", "A. Nguyen", "M. Phulsuksombati", "M. Sahami", "L. Guibas"], "venue": "arXiv preprint arXiv:1505.05969", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Autonomously generating hints by inferring problem solving policies", "author": ["C. Piech", "M. Sahami", "J. Huang", "L. Guibas"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Deep knowledge tracing", "author": ["C. Piech", "J. Spencer", "J. Huang", "S. Ganguli", "M. Sahami", "L.J. Guibas", "J. Sohl-Dickstein"], "venue": "CoRR, abs/1506.05908", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "A mixed filter algorithm for cognitive state estimation from simultaneously recorded continuous and binary measures of performance", "author": ["M.J. Prerau", "A.C. Smith", "U.T. Eden", "M. Yanike", "W.A. Suzuki", "E.N. Brown"], "venue": "Biological cybernetics, 99(1):1\u201314", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Probabilistic models for some intelligence and attainment tests", "author": ["G. Rasch"], "venue": "ERIC", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1993}, {"title": "Multidimensional Item Response Theory", "author": ["M.D. Reckase"], "venue": "Springer Publishing Company, Incorporated, first edition", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "The central role of the propensity score in observational studies for causal effects", "author": ["P.R. Rosenbaum", "D.B. Rubin"], "venue": "Biometrika, 70(1):41\u201355", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1983}, {"title": "Dynamic analysis of learning in behavioral experiments", "author": ["A.C. Smith", "L.M. Frank", "S. Wirth", "M. Yanike", "D. Hu", "Y. Kubota", "A.M. Graybiel", "W.A. Suzuki", "E.N. Brown"], "venue": "The journal of neuroscience, 24(2):447\u2013461", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "Temporal multi-dimensional item response", "author": ["J. Sohl-Dickenstein"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Algebra i 2005-2006", "author": ["J. Stamper", "A. Niculescu-Mizil", "S. Ritter", "G. Gordon", "K. Koedinger"], "venue": "algebra i 2006-2007, bridge to algebra 2006-2007. Challenge data set from KDD Cup 2010 Educational Data Mining Challenge", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization", "author": ["C. Zhu", "R.H. Byrd", "P. Lu", "J. Nocedal"], "venue": "ACM Transactions on Mathematical Software (TOMS), 23(4):550\u2013560", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1997}], "referenceMentions": [{"referenceID": 2, "context": "Early efforts focused on approximating the behavior of a human tutor through rule-based systems that taught students South American geography [3], electronics troubleshooting [13], and programming in Lisp [5].", "startOffset": 142, "endOffset": 145}, {"referenceID": 10, "context": "Early efforts focused on approximating the behavior of a human tutor through rule-based systems that taught students South American geography [3], electronics troubleshooting [13], and programming in Lisp [5].", "startOffset": 175, "endOffset": 179}, {"referenceID": 4, "context": "Early efforts focused on approximating the behavior of a human tutor through rule-based systems that taught students South American geography [3], electronics troubleshooting [13], and programming in Lisp [5].", "startOffset": 205, "endOffset": 208}, {"referenceID": 9, "context": "Learning and content analytics [12], instructional scaffolding in educational games [16], hint generation [20], and feedback propagation [19] are a few topics currently being explored in the personalized learning space.", "startOffset": 31, "endOffset": 35}, {"referenceID": 13, "context": "Learning and content analytics [12], instructional scaffolding in educational games [16], hint generation [20], and feedback propagation [19] are a few topics currently being explored in the personalized learning space.", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "Learning and content analytics [12], instructional scaffolding in educational games [16], hint generation [20], and feedback propagation [19] are a few topics currently being explored in the personalized learning space.", "startOffset": 106, "endOffset": 110}, {"referenceID": 16, "context": "Learning and content analytics [12], instructional scaffolding in educational games [16], hint generation [20], and feedback propagation [19] are a few topics currently being explored in the personalized learning space.", "startOffset": 137, "endOffset": 141}, {"referenceID": 20, "context": "The Rasch model estimates the probability of a student passing an assessment using latent concept proficiency and assessment difficulty parameters [23].", "startOffset": 147, "endOffset": 151}, {"referenceID": 11, "context": "The twoparameter logistic item response theory (2PL IRT) model adds an assessment discriminability parameter to the result likelihood [14].", "startOffset": 134, "endOffset": 138}, {"referenceID": 9, "context": "propose a sparse factor analysis (SPARFA) approach to modeling graded learner responses that uses assessment-concept associations, concept proficiencies, and assessment difficulty [12].", "startOffset": 180, "endOffset": 184}, {"referenceID": 21, "context": "Multi-dimensional item response theory [24] also learns these assocations from the data.", "startOffset": 39, "endOffset": 43}, {"referenceID": 4, "context": "Bayesian Knowledge Tracing (BKT) uses a Hidden Markov Model to model the evolution of student knowledge (which is discretized into a finite number of states) over time [5].", "startOffset": 168, "endOffset": 171}, {"referenceID": 7, "context": "Further work has modified the BKT framework to include the effects of lessons through an input-output Hidden Markov Model [8, 18, 17].", "startOffset": 122, "endOffset": 133}, {"referenceID": 15, "context": "Further work has modified the BKT framework to include the effects of lessons through an input-output Hidden Markov Model [8, 18, 17].", "startOffset": 122, "endOffset": 133}, {"referenceID": 14, "context": "Further work has modified the BKT framework to include the effects of lessons through an input-output Hidden Markov Model [8, 18, 17].", "startOffset": 122, "endOffset": 133}, {"referenceID": 8, "context": "Similarly, SPARFA has been extended to model time-varying student knowledge and the effects of lesson modules [11].", "startOffset": 110, "endOffset": 114}, {"referenceID": 5, "context": "Item response theory has also been extended to capture temporal changes in student knowledge [6, 27].", "startOffset": 93, "endOffset": 100}, {"referenceID": 24, "context": "Item response theory has also been extended to capture temporal changes in student knowledge [6, 27].", "startOffset": 93, "endOffset": 100}, {"referenceID": 18, "context": "Recurrent neural networks have been used to trace student knowledge over time and model lesson effects [21].", "startOffset": 103, "endOffset": 107}, {"referenceID": 19, "context": "Similar ideas for estimating temporal student knowledge from binary-valued responses have appeared in the cognitive modeling literature [22, 26].", "startOffset": 136, "endOffset": 144}, {"referenceID": 23, "context": "Similar ideas for estimating temporal student knowledge from binary-valued responses have appeared in the cognitive modeling literature [22, 26].", "startOffset": 136, "endOffset": 144}, {"referenceID": 12, "context": "Our model also builds on previous work that uses temporal embeddings to predict music playlists [15].", "startOffset": 96, "endOffset": 100}, {"referenceID": 3, "context": "These bias terms are analogous to the bias terms used for modeling song popularity in [4].", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "Our model differs from [11] in that we explicitly model the effects of prerequisite knowledge on gains from lessons.", "startOffset": 23, "endOffset": 27}, {"referenceID": 26, "context": "We solve the optimization problem with box constraints using the L-BFGS-B [29] algorithm.", "startOffset": 74, "endOffset": 78}, {"referenceID": 20, "context": "The 1PL IRT model, also known as the Rasch model, has the following assessment pass likelihood: P[R = 1] = \u03c6(\u03b8i\u2212\u03b2j) for student i and item j, where \u03b8 is student proficiency and \u03b2 is item difficulty, and \u03c6 is the logistic link function [23].", "startOffset": 235, "endOffset": 239}, {"referenceID": 11, "context": "The 2PL model extends the likelihood as follows: P[R = 1] = \u03c6(\u03b1j(\u03b8i \u2212 \u03b2j)), where \u03b1 is the item discriminability [14].", "startOffset": 113, "endOffset": 117}, {"referenceID": 21, "context": "are the student factors, ~v are the item factors, and \u03bc is the item offset [24].", "startOffset": 75, "endOffset": 79}, {"referenceID": 7, "context": "One issue that may have affected the findings is the biased nature of student paths, which has been discussed by [8].", "startOffset": 113, "endOffset": 116}, {"referenceID": 25, "context": "data set from an online language learning game [28, 7, 1, 9].", "startOffset": 47, "endOffset": 60}, {"referenceID": 6, "context": "data set from an online language learning game [28, 7, 1, 9].", "startOffset": 47, "endOffset": 60}, {"referenceID": 0, "context": "data set from an online language learning game [28, 7, 1, 9].", "startOffset": 47, "endOffset": 60}, {"referenceID": 22, "context": "To best approximate the settings of a randomized controlled trial in our observational study, we use the standard propensity score matching approach for de-biasing observational data [25, 2].", "startOffset": 183, "endOffset": 190}, {"referenceID": 1, "context": "To best approximate the settings of a randomized controlled trial in our observational study, we use the standard propensity score matching approach for de-biasing observational data [25, 2].", "startOffset": 183, "endOffset": 190}], "year": 2016, "abstractText": "Students in online courses generate large amounts of data that can be used to personalize the learning process and improve quality of education. In this paper, we present the Latent Skill Embedding (LSE), a probabilistic model of students and educational content that can be used to recommend personalized sequences of lessons with the goal of helping students prepare for specific assessments. Akin to collaborative filtering for recommender systems, the algorithm does not require students or content to be described by features, but it learns a representation using access traces. We formulate this problem as a regularized maximum-likelihood embedding of students, lessons, and assessments from historical student-content interactions. An empirical evaluation on large-scale data from Knewton, an adaptive learning technology company, shows that this approach predicts assessment results competitively with benchmark models and is able to discriminate between lesson sequences that lead to mastery and failure.", "creator": "LaTeX with hyperref package"}}}