{"id": "1602.07236", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2016", "title": "Petrarch 2 : Petrarcher", "abstract": "PETRARCH 2 is the fourth generation of a series of Event-Data coders stemming from research by Phillip Schrodt. Each iteration has brought new functionality and usability, and this is no exception.Petrarch 2 takes much of the power of the original Petrarch's dictionaries and redirects it into a faster and smarter core logic. Earlier iterations handled sentences largely as a list of words, incorporating some syntactic information here and there. Petrarch 2 now views the sentence entirely on the syntactic level. It receives the syntactic parse of a sentence from the Stanford CoreNLP software, and stores this data as a tree structure of linked nodes, where each node is a Phrase object. Prepositional, noun, and verb phrases each have their own version of this Phrase class, which deals with the logic particular to those kinds of phrases. Since this is an event coder, the core of the logic focuses around the verbs: who is acting, who is being acted on, and what is happening. The theory behind this new structure and its logic is founded in Generative Grammar, Information Theory, and Lambda-Calculus Semantics.", "histories": [["v1", "Tue, 23 Feb 2016 17:05:06 GMT  (10kb,D)", "http://arxiv.org/abs/1602.07236v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["clayton norris"], "accepted": false, "id": "1602.07236"}, "pdf": {"name": "1602.07236.pdf", "metadata": {"source": "CRF", "title": "PETRARCH 2 : PETRARCHer", "authors": ["Clayton Norris", "Phillip Schrodt"], "emails": [], "sections": [{"heading": null, "text": "PETRARCH 2: PETRARCHerClayton Norris PETRARCH 2 is the fourth generation of a series of event data encoders resulting from Phillip Schrodt's research1. Each iteration has brought new functionality and ease of use 2, and this is no exception. Petrarca 2 takes much of the power of the original Petrarca dictionaries and redirects it into a faster and smarter core logic. Previous iterations largely treated sentences as a word list and stored this data as a tree of linked nodes in which each node is a phrase object. Prepositional, noun, and verb phrases each have their own version of this phrase class, which deals with the specific logic of that logic, with each node being a phrase object."}, {"heading": "1 Tree structure", "text": "In an attempt to exploit all the syntactical information provided to us by the Stanford parser, Petrarch implements the sentence encoding in such a way that the syntax tree becomes apparent in the data structure and logic. It is a simple tree structure, each sentence or word being its own node, with references to the parent node and the sentence of child nodes 3. Syntactic phrases are stored as nested objects of the \"phrase\" class, which has three subclasses \"NounPhrase,\" \"VerbPhrase\" and \"PrepPhrase.\" If a phrase does not fall within one of these categories, it is simply retained as a \"phrase,\" although when finally there is sufficient reason to add another type (adjective phrases, for example), it can be carried out so easily. Each of these phrase types has several unique methods to obtain it and its own version of an earthed meaning (), which determines the coding of a child's meaning from its node."}, {"heading": "1.1 Syntax trees", "text": "Let's start with a short linguistic lesson. Each sentence in English (and in most languages) is composed of several \"components.\" A component of a sentence can be a single word or phrase (which is a component of the components), but the crucial feature is that each component serves a certain syntactic (i.e. grammatical) role. Components of a sentence are associated hierarchically (hence the phrasal component of the components), and so the most convenient way to visualize or store syntactic structures is in a syntax tree. There is an example of a syntax tree and how it is used in the parse at the end of this document. The CoreNLP software that Petrarch relies on for syntactical parsing uses Penn Treebank II 4 syntax notation, which is slightly different from the canonical generative grammar markup, but equally useful for our purposes."}, {"heading": "2 Flow", "text": "The core logic of the semantic generic terms is based on the idea that every node in the tree has a meaning, and the meaning of a node is a combination of the meanings of its children. This means that words and meanings are combined as one climbs the tree and passes from word to sentence level until one has a meaning of a noun and a meaning of a verbal expression. The meaning of the verbal expression covers most of the meaning of the sentence and explains all relevant nouns and verbs below it. 4https: / / www.cis.upenn.edu / ~ Treebank / 5Many syntax theories dictate that each node can have a maximum of two children, which would never lead to a situation where one has multiple choices, but CoreNLP does not follow this binary branch. Due to the recursive nature of the definition of meaning, one can derive the meaning of the verbal expression from the uppermost verbal phrase."}, {"heading": "3 Classes and class-specific flow", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Noun Phrases", "text": "The NounPhrase class has only one unique method, check date (), which decides which actor code to choose when the code changes for a particular person or country over time, and this method comes almost directly from the older version of Petrarch. The get meaning () method in the noun phrase matches both the patterns for actors and agents of children at word level and combines the meanings of the constituent PP, PS and VP children. Priority is given as WordPatterns > NP > PP > V P, and only if actors and agents are not coded, the node that finds meaning will revert to a lower priority formulation, meaning that the noun phrase \"American troops in Iraq\" would be coded only as USAMIL, but \"troops in Iraq\" as IRQMIL."}, {"heading": "3.1.1 Pronouns", "text": "When Petrarch encounters a pronoun, it searches up the tree for a precursor within the same sentence. If the pronoun is relfexiv (ending with -self or -selves), Petrarch searches until it finds a noun, or until it finds a verb phrase with a defined subject, 6http: / / eventdata.parusanalytics.com / cameo.dir / CAMEO.09b6.pdf 7Schrodt et al. 2008and assigns this as meaning. However, if the pronoun is not reflexive, Petrarch moves upward until it finds an S-level phrase, then its search begins. This is based on the binding rules that pronouns follow in generative grammar. Due to the distinction between the two types of pronouns, Petrarch can correctly see that \"itself\" in A said B refers to Hillary, while \"it\" in A said B refers to her. Petrarch currently has no concept of the pronoun or the number of which should be put in both sentences."}, {"heading": "3.2 Prepositional Phrases", "text": "The get meaning () method of PrepPhrase objects returns the meaning of their non-preposition constituents, making it easier for the seeker to traverse prepositional phrases. PrepPhrase objects store the preposition as an attribute of the object and in some cases use it to determine whether a particular prephrase should be considered or not."}, {"heading": "3.3 Verb Phrases", "text": "In fact, most of them will be able to play by the rules they have adopted in recent years."}, {"heading": "3.4 Event extraction", "text": "A call to the get meaning () method of the uppermost VP causes the rest of the tree to be analyzed, and returns the event encoding of that VP, the event encoding of the entire tree. Since not all events of the sentence may be complete at this point, the sentence object that contains the phrase tree calls Meaning () in its get events () method and checks whether the event is satisfactory. If the event returned by get meaning () is a complete encoding (comprising all three parts), it is assigned to the sentence and the process is complete."}, {"heading": "4 Dictionaries", "text": "Petrarca uses the same dictionaries as always for actor, agent, discard and output, but the latest version has brought changes in the format and structure of the verb Dictionary. Sentences of synonymous nouns (synsets) remain the same, as well as the organization and storage of basic verbs. The two biggest differences are the transformations that fit to transform (), and the patterns for matching phrases."}, {"heading": "4.1 Patterns", "text": "Patterns in the dictionaries should now follow a few simple rules: 1. The intended pattern should contain exactly one verb: the verb that is associated with it. 2. Pattern entries should be minimal, i.e. the smallest amount of information necessary to capture the intended phrases.3. The pattern consists of up to four parts: pre-verb nouns, pre-verb prepositions, post-verb prepositions. The patterns themselves contain additional annotating symbols to provide the parser with more syntactical information: \u2022 Unmarked words are nouns or particles. These nouns are phrase heads. \u2022 {Brackets} are phrase heads. The first word is the preposition that can be summarized with the rest."}, {"heading": "4.2 Verb+Verb interaction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 Combinations", "text": "This occurs when the meaning of the two verbs together is literally the meaning of the two verbs individually, which usually occur to indicate the subcode of something vague or high-level CAMEO categories, such as the intention to refuse or the demand. This is handled by an internal translation of CAMEO codes into a system that extends the hierarchy of CAMEO beyond the basic top-level classification system, allowing for controllable processing of verb combinations inherent in CAMEO. Thus, rather than a system in which \"Intend [070] we tend to do something.\""}, {"heading": "4.2.2 Transformations", "text": "Sometimes this is insufficient, for example when the meaning of verbal interaction also depends on the relationships between the nouns acting and acting. The difference between \"A says B attacks C\" and \"A says A attacks B\" is one such case. The first is equivalent to \"A accuses B of an attack\" and the second \"Acclaims praise for an attack on B.\" Since this depends on the nouns involved, we have to look at them in the transformation category and not in the combination category. The specification of how they are formatted is included in the documentation."}, {"heading": "5 Example", "text": "(Consider the sentence \u2022 \"Israel said a mortar bomb was fired at it from the Gaza Strip on Tuesday.\" Petrarch would code this sentence as ISR PSEGZA 112 with the following tree: 11 S. VPISR PSEGZA 112SBARSVPSEGZA ISR 190VPSEGZA ISR 190PPNP + PSEGZAPPNNPTUESDAYINONNP + PSEGZANNPSTRIPNPGAZADTTHEINFROMPPNP + ISRPRPITINATVBLAUNCHEDVBDWASNPNNBOMBJMORTARDTAVBDSAIDNP + ISRNPISRAELThe color coding shows where the actor codes come from. The significant steps taken in this analysis include the verbs \"said\" and \"flaunch,\" and the pronoun \"4. The formulation for the finder finder process."}, {"heading": "6 Works Cited", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Automated Coding of International Event Data Using Sparse Pars- ing Techniques.", "author": ["Schrodt", "Philip A"], "venue": "Paper presented at the International Studies Association,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Precedents, Progress and Prospects in Political Event Data.\u201d Inter- national Interactions 38(5):546569", "author": ["Schrodt", "Philip A"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Coding Sub-State Actors using the CAMEO (Conflict and Mediation Event Observations) Actor Coding Framework.", "author": ["Schrodt", "Philip A", "Omur Yilmaz", "Deborah J. Gerner", "Dennis Hermrick"], "venue": "International Studies Association,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}], "referenceMentions": [], "year": 2016, "abstractText": "PETRARCH 2 is the fourth generation of a series of Event-Data coders stemming from research by Phillip Schrodt1. Each iteration has brought new functionality and usability 2, and this is no exception. Petrarch 2 takes much of the power of the original Petrarch\u2019s dictionaries and redirects it into a faster and smarter core logic. Earlier iterations handled sentences largely as a list of words, incorporating some syntactic information here and there. Petrarch 2 (henceforth referred to as Petrarch) now views the sentence entirely on the syntactic level. It receives the syntactic parse of a sentence from the Stanford CoreNLP software, and stores this data as a tree structure of linked nodes, where each node is a Phrase object. Prepositional, noun, and verb phrases each have their own version of this Phrase class, which deals with the logic particular to those kinds of phrases. Since this is an event coder, the core of the logic focuses around the verbs: who is acting, who is being acted on, and what is happening. The theory behind this new structure and its logic is founded in Generative Grammar, Information Theory, and Lambda-Calculus Semantics.", "creator": "LaTeX with hyperref package"}}}