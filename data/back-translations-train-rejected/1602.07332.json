{"id": "1602.07332", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2016", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations", "abstract": "Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked \"What vehicle is the person riding?\", computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) in order to answer correctly that \"the person is riding a horse-drawn carriage\".", "histories": [["v1", "Tue, 23 Feb 2016 22:00:40 GMT  (7812kb,D)", "http://arxiv.org/abs/1602.07332v1", "44 pages, 37 figures"]], "COMMENTS": "44 pages, 37 figures", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["ranjay krishna", "yuke zhu", "oliver groth", "justin johnson", "kenji hata", "joshua kravitz", "stephanie chen", "yannis kalantidis", "li-jia li", "david a shamma", "michael s bernstein", "fei-fei li"], "accepted": false, "id": "1602.07332"}, "pdf": {"name": "1602.07332.pdf", "metadata": {"source": "CRF", "title": "Connecting Language and Vision Using Crowdsourced Dense Image Annotations", "authors": ["Ranjay Krishna", "Yuke Zhu", "Oliver Groth", "Justin Johnson", "Kenji Hata", "Joshua Kravitz", "Stephanie Chen", "Yannis Kalantidis", "David A. Shamma", "Michael S. Bernstein", "Li Fei-Fei"], "emails": ["ranjaykrishna@cs.stanford.edu"], "sections": [{"heading": null, "text": "Image classification, computers still perform poorly in cognitive tasks such as image description and answering questions. Cognition is the core of tasks that involve not only recognizing our visual world, but also thinking about it. To achieve success in cognitive tasks, models must understand the interactions and relationships between objects at Ranjay Krishna Stanford University, Stanford, CA, USA, e-mail: ranjaykrishna @ cs.stanford.eduYuke Zhu Stanford University, Stanford, CA, USAOliver Groth Dresden University of Technology, GermanyJustin Johnson Stanford University, Stanford, CA, USAKenji Hata Stanford University, Stanford, CA, USAnowitz Kravitz Stanford University, Stanford, Stanford, Stanford, Stanford, Stanford, Stanford, Stanford, Stanford, Stanford, USA."}, {"heading": "1 Introduction", "text": "In fact, it is the case that most of them will be able to move into another world, in which they are able to put themselves into another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they are able to put themselves into another world, in which they are able to put themselves into another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they"}, {"heading": "2 Visual Genome Data Representation", "text": "In fact, most of them will be able to move to another world, in which they can move to another world."}, {"heading": "3 Related Work", "text": "We discuss existing datasets used by the Vision Community for classification and object recognition, we also mention work that has improved object and attribute recognition models, then we explore existing work that has used representations similar to our relationships between objects, and we delve into the literature that relates to cognitive tasks such as image descriptions, questions, and knowledge representations. It is one of the first datasets to be hand-curated for image classification, with 101 object categories and 15-30 examples per category. One of the biggest criticisms of Caltech 101 was the lack of variability in its examples. Caltech 256 (Griffin et al, 2007) increased the number of categories to 256, while also addressing some of the shortcomings of Caltech 101."}, {"heading": "4 Crowdsourcing Strategies", "text": "In fact, it is the case that most of them are able to survive themselves without being able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "5 Dataset Statistics and Analysis", "text": "In fact, most of them are able to determine for themselves what they want and what they want to do."}, {"heading": "6 Experiments", "text": "In fact, it is a matter of a way in which one blames oneself and others. (...) In fact, it is a matter of a form in which one blames oneself. (...) In fact, it is a matter of a form in which one puts oneself into the centre. (...) In fact, it is a matter of a form in which one puts oneself into the centre. (...) It is a matter of a form in which one puts oneself into the centre. (...) In fact, it is a matter of a form in which one puts oneself into the centre. (...) It is as if it is a form in which it is a form, in which it is a form in which one acts oneself. (...) It is a matter in which one acts oneself. (...) It is as if it is a form. (...) It is a matter of a form. (...) It is as if it is a matter."}, {"heading": "7 Future Applications", "text": "We have analyzed the individual components of this dataset and presented experiments with basic results for tasks such as attribute classification, relationship classification, description generation, and question answering. However, there are more applications and experiments for which our dataset can be used. In this section, we point to a few potential applications that our dataset can enable. Dense captions. We have seen numerous captions (Kiros et al., 2014, Mao et al., 2014, Vinyals et al., 2014) that attempt to describe a complete picture with a single caption. However, these captions do not describe all parts of the scene. A natural extension of this application that allows the visual genome dataset is the ability to create working models that describe parts of the sceneal asal asale.Answering visual questions. While visual questions were answered as a separate task."}, {"heading": "8 Conclusion", "text": "The Visual Genome offers a multi-layered understanding of images. It enables a multi-perspective study of an image, from pixel-based information such as objects to relationships that require further inferences, to even deeper cognitive tasks such as answering questions. It is a comprehensive dataset for training and benchmarking the next generation of computer vision models. With the Visual Genome, we expect these models to develop a broader understanding of our visual world and complement computers \"ability to describe objects with skills, describe these objects, and explain their interactions and relationships. The Visual Genome is a large formalized representation of knowledge for visual understanding and a broader set of descriptions and questions that underlie visual concepts of language. Acknowledgements We would like to start by thanking our sponsors: Stanford Computer Science Department, Yahoo Labs!, The Brown Institute for Media Innovation, Toyota and Adobe. Next, we would like to thank in particular Michael Stark, Dresden, Yutian RLi of the University of Dresden, and others for their support."}], "references": [{"title": "The berkeley framenet project", "author": ["B.J."], "venue": "Proceedings", "citeRegEx": "J.,? 1998", "shortCiteRegEx": "J.", "year": 1998}, {"title": "Toward never ending language", "author": ["S.H. Wang"], "venue": null, "citeRegEx": "Wang,? \\Q2009\\E", "shortCiteRegEx": "Wang", "year": 2009}, {"title": "A shortest path dependency kernel for", "author": ["J. R"], "venue": null, "citeRegEx": "R.,? \\Q2005\\E", "shortCiteRegEx": "R.", "year": 2005}, {"title": "Semantic parsing for text to 3d scene", "author": ["D. C"], "venue": null, "citeRegEx": "C.,? \\Q2014\\E", "shortCiteRegEx": "C.", "year": 2014}, {"title": "arXiv preprint arXiv:1504.00325", "author": ["Z. Liu", "M. Sun"], "venue": null, "citeRegEx": "X. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "X. et al\\.", "year": 2014}, {"title": "biguation. In EMNLP, pages 1025\u20131035", "author": ["A. Shrivastava", "A. Gupta"], "venue": null, "citeRegEx": "X. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "X. et al\\.", "year": 2013}, {"title": "Understanding indoor scenes using 3d", "author": ["S. Savarese"], "venue": null, "citeRegEx": "Savarese,? \\Q2013\\E", "shortCiteRegEx": "Savarese", "year": 2013}, {"title": "Rmsprop and equilibrated adap", "author": ["Y. Bengio"], "venue": null, "citeRegEx": "J. and Bengio,? \\Q2015\\E", "shortCiteRegEx": "J. and Bengio", "year": 2015}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng et al", "J. 2009. Deng", "W. Dong", "R. Socher", "Li", "L.-J", "K. Li", "L. Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2009\\E", "shortCiteRegEx": "al. et al\\.", "year": 2009}, {"title": "Pedestrian detection: An evaluation of the state of the art", "author": ["Dollar et al", "P. 2012. Dollar", "C. Wojek", "B. Schiele", "P. Perona"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "The pascal visual object classes (voc) challenge", "author": ["Everingham et al", "M. 2010. Everingham", "L. Van Gool", "C.K. Williams", "J. Winn", "A. Zisserman"], "venue": "International journal of computer vision,", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Describing objects by their attributes", "author": ["Farhadi et al", "A. 2009. Farhadi", "I. Endres", "D. Hoiem", "D. Forsyth"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2009\\E", "shortCiteRegEx": "al. et al\\.", "year": 2009}, {"title": "Every picture tells a story: Generating sentences from images", "author": ["Farhadi et al", "A. 2010. Farhadi", "M. Hejrati", "M.A. Sadeghi", "P. Young", "C. Rashtchian", "J. Hockenmaier", "D. Forsyth"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories", "author": ["Fei-Fei et al", "L. 2007. Fei-Fei", "R. Fergus", "P. Perona"], "venue": "Computer Vision and Image Understanding,", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Learning visual attributes", "author": ["Ferrari", "Zisserman", "V. 2007. Ferrari", "A. Zisserman"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ferrari et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ferrari et al\\.", "year": 2007}, {"title": "Building watson: An overview of the deepqa project", "author": ["Ferrucci et al", "D. 2010. Ferrucci", "E. Brown", "J. Chu-Carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J Prager"], "venue": "AI magazine,", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Cognition does not affect perception: Evaluating the evidence for top-down effects", "author": ["Firestone", "Scholl", "C. 2015. Firestone", "B.J. Scholl"], "venue": "Behavioral and brain sciences,", "citeRegEx": "Firestone et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Firestone et al\\.", "year": 2015}, {"title": "Are you talking to a machine? dataset and methods for multilingual image question answering", "author": ["Gao et al", "H. 2015. Gao", "J. Mao", "J. Zhou", "Z. Huang", "L. Wang", "W. Xu"], "venue": "arXiv preprint arXiv:1505.05612", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Visual turing test for computer vision systems", "author": ["Geman et al", "D. 2015. Geman", "S. Geman", "N. Hallonquist", "L. Younes"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Girshick et al", "R. 2014. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Nonparametric part transfer for fine-grained recognition", "author": ["Goering et al", "C. 2014. Goering", "E. Rodner", "A. Freytag", "J. Denzler"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Exploring various knowledge in relation extraction", "author": ["GuoDong et al", "Z. 2005. GuoDong", "S. Jian", "Z. Jie", "Z. Min"], "venue": "In Proceedings of the 43rd annual meeting on", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "Association for Computational Linguistics", "author": ["L.S. Davis"], "venue": null, "citeRegEx": "A. and Davis,? \\Q2008\\E", "shortCiteRegEx": "A. and Davis", "year": 2008}, {"title": "Observing human-object interactions: Using", "author": ["S. L"], "venue": null, "citeRegEx": "L.,? \\Q2009\\E", "shortCiteRegEx": "L.", "year": 2009}, {"title": "Long short-term memory", "author": ["J. Schmidhuber"], "venue": "Neural", "citeRegEx": "Schmidhuber,? 1997", "shortCiteRegEx": "Schmidhuber", "year": 1997}, {"title": "Framing image description as a ranking", "author": ["J. maier"], "venue": null, "citeRegEx": "maier,? \\Q2013\\E", "shortCiteRegEx": "maier", "year": 2013}, {"title": "Labeled faces in the wild: A", "author": ["E. Learned-Miller"], "venue": null, "citeRegEx": "Learned.Miller,? \\Q2008\\E", "shortCiteRegEx": "Learned.Miller", "year": 2008}, {"title": "Multimodal neural language models", "author": ["R."], "venue": "Pro-", "citeRegEx": "R.,? 2014", "shortCiteRegEx": "R.", "year": 2014}, {"title": "Learning (ICML-14), pages 595\u2013603", "author": ["K. Hata", "S. Chen"], "venue": null, "citeRegEx": "R. et al\\.,? \\Q2016\\E", "shortCiteRegEx": "R. et al\\.", "year": 2016}, {"title": "Embracing error to enable rapid crowdsourc", "author": ["S. M"], "venue": null, "citeRegEx": "M.,? \\Q2016\\E", "shortCiteRegEx": "M.", "year": 2016}, {"title": "Imagenet classification with deep", "author": ["G.E. Hinton"], "venue": null, "citeRegEx": "Hinton,? \\Q2012\\E", "shortCiteRegEx": "Hinton", "year": 2012}, {"title": "Learning to detect unseen object classes by between-class attribute transfer", "author": ["Lampert et al", "C.H. 2009. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2009\\E", "shortCiteRegEx": "al. et al\\.", "year": 2009}, {"title": "Using corpus statistics and wordnet relations for sense identification", "author": ["Leacock et al", "C. 1998. Leacock", "G.A. Miller", "M. Chodorow"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1998\\E", "shortCiteRegEx": "al. et al\\.", "year": 1998}, {"title": "Phrase-based image captioning", "author": ["Lebret et al", "R. 2015. Lebret", "P.O. Pinheiro", "R. Collobert"], "venue": "arXiv preprint arXiv:1502.03671", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Microsoft coco: Common objects in context", "author": ["Lin et al", "2014. Lin", "T.-Y", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r", "C.L. Zitnick"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Visual relationship detection using language priors", "author": ["Lu et al", "C. 2016. Lu", "R. Krishna", "M.S. Bernstein", "L. Fei-Fei"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2016\\E", "shortCiteRegEx": "al. et al\\.", "year": 2016}, {"title": "Learning to answer questions from image using convolutional neural network. arXiv preprint arXiv:1506.00333", "author": ["Ma et al", "L. 2015. Ma", "Z. Lu", "H. Li"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "A multi-world approach to question answering about real-world scenes based on uncertain input", "author": ["Malinowski", "Fritz", "M. 2014. Malinowski", "M. Fritz"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Malinowski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Malinowski et al\\.", "year": 2014}, {"title": "Ask your neurons: A neural-based approach to answering questions about images. arXiv preprint arXiv:1505.01121", "author": ["Malinowski et al", "M. 2015. Malinowski", "M. Rohrbach", "M. Fritz"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Recognition by association via learning perexemplar distances", "author": ["Malisiewicz et al", "T. 2008. Malisiewicz", "A Efros"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Manning et al", "C.D. 2014. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "In Proceedings of 52nd Annual Meeting of the Association", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Explain images with multimodal recurrent neural networks. arXiv preprint arXiv:1410.1090", "author": ["Mao et al", "J. 2014. Mao", "W. Xu", "Y. Yang", "J. Wang", "A.L. Yuille"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "The senseval-3 english lexical sample task. Association for Computational Linguistics", "author": ["Mihalcea et al", "R. 2004. Mihalcea", "T.A. Chklovski", "A. Kilgarriff"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2004\\E", "shortCiteRegEx": "al. et al\\.", "year": 2004}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Mikolov et al", "T. 2013. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Wordnet: a lexical database for english", "author": ["Miller", "G.A. 1995. Miller"], "venue": "Communications of the ACM,", "citeRegEx": "Miller and Miller,? \\Q1995\\E", "shortCiteRegEx": "Miller and Miller", "year": 1995}, {"title": "Indoor segmentation and support inference from rgbd images", "author": ["Nathan Silberman", "Fergus", "2012. Nathan Silberman", "P.K. Derek Hoiem", "R. Fergus"], "venue": null, "citeRegEx": "Silberman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Silberman et al\\.", "year": 2012}, {"title": "Elementary: Large-scale knowledge-base construction via machine learning and statistical inference", "author": ["Niu et al", "F. 2012. Niu", "C. Zhang", "C. R\u00e9", "J. Shavlik"], "venue": "International Journal on Semantic Web and Information Systems (IJSWIS),", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Im2text: Describing images using 1 million captioned photographs", "author": ["Ordonez et al", "V. 2011. Ordonez", "G. Kulkarni", "T.L. Berg"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Word sense disambiguation: a survey", "author": ["Pal", "Saha", "A.R. 2015. Pal", "D. Saha"], "venue": "arXiv preprint arXiv:1508.01346", "citeRegEx": "Pal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pal et al\\.", "year": 2015}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Papineni et al", "K. 2002. Papineni", "S. Roukos", "T. Ward", "Zhu", "W.-J"], "venue": "In Proceedings of the 40th annual meeting on association for computational linguistics,", "citeRegEx": "al. et al\\.,? \\Q2002\\E", "shortCiteRegEx": "al. et al\\.", "year": 2002}, {"title": "The sun attribute database: Beyond categories for deeper scene understanding", "author": ["Patterson et al", "G. 2014. Patterson", "C. Xu", "H. Su", "J. Hays"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Improving the fisher kernel for largescale image classification", "author": ["Perronnin et al", "F. 2010. Perronnin", "J. S\u00e1nchez", "T. Mensink"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Weakly supervised learning of interactions between humans and objects", "author": ["Prest et al", "A. 2012. Prest", "C. Schmid", "V. Ferrari"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Learning semantic relationships for better action retrieval in images", "author": ["Ramanathan et al", "V. 2015. Ramanathan", "C. Li", "J. Deng", "W. Han", "Z. Li", "K. Gu", "Y. Song", "S. Bengio", "C. Rossenberg", "L. Fei-Fei"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recog-", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Image question answering: A visual semantic embedding model and a new dataset. arXiv preprint arXiv:1505.02074", "author": ["Ren et al", "M. 2015a. Ren", "R. Kiros", "R. Zemel"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Faster r-cnn: Towards real-time object detection with region proposal", "author": ["Ren et al", "S. 2015b. Ren", "K. He", "R. Girshick", "J. Sun"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Autoextend: Extending word embeddings to embeddings for synsets and lexemes", "author": ["Rothe", "Sch\u00fctze", "S. 2015. Rothe", "H. Sch\u00fctze"], "venue": "arXiv preprint arXiv:1507.01127", "citeRegEx": "Rothe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rothe et al\\.", "year": 2015}, {"title": "Describing Common Human Visual Actions in Images. ArXiv e-prints", "author": ["Ruggero Ronchi", "Perona", "M. 2015. Ruggero Ronchi", "P. Perona"], "venue": null, "citeRegEx": "Ronchi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ronchi et al\\.", "year": 2015}, {"title": "Labelme: a database and web-based tool for image annotation", "author": ["Russell et al", "B.C. 2008. Russell", "A. Torralba", "K.P. Murphy", "W.T. Freeman"], "venue": "International journal of computer vision,", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Viske: Visual knowledge extraction and question answering by visual verification of relation phrases", "author": ["Sadeghi et al", "F. 2015. Sadeghi", "S.K. Divvala", "A. Farhadi"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Recognition using visual phrases", "author": ["Sadeghi", "Farhadi", "M.A. 2011. Sadeghi", "A. Farhadi"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Sadeghi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sadeghi et al\\.", "year": 2011}, {"title": "We are dynamo: Overcoming stalling and friction in collective action for crowd workers", "author": ["Salehi et al", "N. 2015. Salehi", "L.C. Irani", "M.S. Bernstein"], "venue": "In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems,", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Scripts, plans, goals, and understanding: An inquiry into human knowledge", "author": ["Schank", "Abelson", "R.C. 2013. Schank", "R.P. Abelson"], "venue": null, "citeRegEx": "Schank et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schank et al\\.", "year": 2013}, {"title": "Verbnet: A Broadcoverage, Comprehensive Verb Lexicon", "author": ["Schuler", "K.K. 2005. Schuler"], "venue": "PhD thesis,", "citeRegEx": "Schuler and Schuler,? \\Q2005\\E", "shortCiteRegEx": "Schuler and Schuler", "year": 2005}, {"title": "Generating semantically precise scene graphs from textual descriptions for improved image retrieval", "author": ["Schuster et al", "S. 2015. Schuster", "R. Krishna", "A. Chang", "L. Fei-Fei", "C.D. Manning"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks. arXiv preprint arXiv:1312.6229", "author": ["Sermanet et al", "P. 2013. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Very deep convolutional networks for largescale image recognition", "author": ["Simonyan", "Zisserman", "K. 2014. Simonyan", "A. Zisserman"], "venue": "arXiv preprint arXiv:1409.1556", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Cheap and fast\u2014but is it good?: evaluating non-expert annotations for natural language tasks", "author": ["Snow et al", "R. 2008. Snow", "B. O\u2019Connor", "D. Jurafsky", "A.Y. Ng"], "venue": "In Proceedings of the conference on empirical methods in natural language processing,", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Socher et al", "R. 2012. Socher", "B. Huval", "C.D. Manning", "A.Y. Ng"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Yfcc100m: The new data in multimedia research", "author": ["Thomee et al", "B. 2016. Thomee", "D.A. Shamma", "G. Friedland", "B. Elizalde", "K. Ni", "D. Poland", "D. Borth", "Li", "L.-J"], "venue": "Commun. ACM,", "citeRegEx": "al. et al\\.,? \\Q2016\\E", "shortCiteRegEx": "al. et al\\.", "year": 2016}, {"title": "A statistical approach to texture classification from single images", "author": ["Varma", "Zisserman", "M. 2005. Varma", "A. Zisserman"], "venue": null, "citeRegEx": "Varma et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Varma et al\\.", "year": 2005}, {"title": "Show and tell: A neural image caption generator", "author": ["Vinyals et al", "O. 2014. Vinyals", "A. Toshev", "S. Bengio", "D. Erhan"], "venue": "arXiv preprint arXiv:1411.4555", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "The caltech-ucsd birds200-2011", "author": ["Wah et al", "C. 2011. Wah", "S. Branson", "P. Welinder", "P. Perona", "S. Belongie"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Sun database: Large-scale scene recognition from abbey to zoo. In Computer vision and pattern recognition", "author": ["Xiao et al", "J. 2010. Xiao", "J. Hays", "K. Ehinger", "A. Oliva", "A Torralba"], "venue": "IEEE conference on,", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Show, attend and tell: Neural image caption generation with visual attention. CoRR, abs/1502.03044", "author": ["Xu et al", "K. 2015. Xu", "J. Ba", "R. Kiros", "K. Cho", "A.C. Courville", "R. Salakhutdinov", "R.S. Zemel", "Y. Bengio"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Modeling mutual context of object and human pose in humanobject interaction activities", "author": ["Yao", "Fei-Fei", "B. 2010. Yao", "L. Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Yao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2010}, {"title": "Introduction to a large-scale general purpose ground truth database: methodology, annotation tool and benchmarks", "author": ["Yao et al", "B. 2007. Yao", "X. Yang", "Zhu", "S.-C"], "venue": "In Energy Minimization Methods in Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics, 2:67\u201378", "author": ["Young et al", "P. 2014. Young", "A. Lai", "M. Hodosh", "J. Hockenmaier"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Visual Madlibs: Fill in the blank Image Generation and Question Answering", "author": ["Yu et al", "L. 2015. Yu", "E. Park", "A.C. Berg", "T.L. Berg"], "venue": "arXiv preprint arXiv:1506.00278", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Relation classification via convolutional deep neural network", "author": ["Zeng et al", "D. 2014. Zeng", "K. Liu", "S. Lai", "G. Zhou", "J. Zhao"], "venue": "In Proceedings of COLING,", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Tree kernel-based relation extraction with context-sensitive structured parse tree information", "author": ["Zhou et al", "G. 2007. Zhou", "M. Zhang", "D.H. Ji", "Q. Zhu"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Statsnowball: a statistical approach to extracting entity relationships", "author": ["Zhu et al", "J. 2009. Zhu", "Z. Nie", "X. Liu", "B. Zhang", "Wen", "J.-R"], "venue": "In Proceedings of the 18th international conference on World wide web,", "citeRegEx": "al. et al\\.,? \\Q2009\\E", "shortCiteRegEx": "al. et al\\.", "year": 2009}, {"title": "Reasoning about Object Affordances in a Knowledge Base Representation", "author": ["Zhu et al", "Y. 2014. Zhu", "A. Fathi", "L. Fei-Fei"], "venue": "In European Conference on Computer Vision", "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries", "author": ["Zhu et al", "Y. 2015. Zhu", "C. Zhang", "C. R\u00e9", "L. Fei-Fei"], "venue": "In arXiv preprint arXiv:1507.05670", "citeRegEx": "al. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "al. et al\\.", "year": 2015}, {"title": "Bringing semantics into focus using visual abstraction", "author": ["Zitnick", "Parikh", "C.L. 2013. Zitnick", "D. Parikh"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Zitnick et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zitnick et al\\.", "year": 2013}], "referenceMentions": [], "year": 2016, "abstractText": "Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in Ranjay Krishna Stanford University, Stanford, CA, USA E-mail: ranjaykrishna@cs.stanford.edu Yuke Zhu Stanford University, Stanford, CA, USA Oliver Groth Dresden University of Technology, Dresden, Germany Justin Johnson Stanford University, Stanford, CA, USA Kenji Hata Stanford University, Stanford, CA, USA Joshua Kravitz Stanford University, Stanford, CA, USA Stephanie Chen Stanford University, Stanford, CA, USA Yannis Kalantidis Yahoo Inc., San Francisco, CA, USA Li-Jia Li Snapchat Inc., Los Angeles, CA, USA David A. Shamma Yahoo Inc., San Francisco, CA, USA Michael S. Bernstein Stanford University, Stanford, CA, USA Li Fei-Fei Stanford University, Stanford, CA, USA an image. When asked \u201cWhat vehicle is the person riding?\u201d, computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) in order to answer correctly that \u201cthe person is riding a horse-drawn carriage.\u201d In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 100K images where each image has an average of 21 objects, 18 attributes, and 18 pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answers.", "creator": "LaTeX with hyperref package"}}}