{"id": "1602.07360", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2016", "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 1MB (461x smaller than AlexNet).", "histories": [["v1", "Wed, 24 Feb 2016 00:09:45 GMT  (402kb,D)", "http://arxiv.org/abs/1602.07360v1", null], ["v2", "Sat, 27 Feb 2016 20:24:20 GMT  (513kb,D)", "http://arxiv.org/abs/1602.07360v2", null], ["v3", "Wed, 6 Apr 2016 07:21:49 GMT  (1006kb,D)", "http://arxiv.org/abs/1602.07360v3", "Added macro- and microarchitectural design space exploration. Dense-&gt;sparse-&gt;dense training. Further compression. Expanded from 5 pages to 9 pages"], ["v4", "Fri, 4 Nov 2016 21:26:08 GMT  (533kb,D)", "http://arxiv.org/abs/1602.07360v4", "In ICLR Format"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["forrest n iandola", "song han", "matthew w moskewicz", "khalid ashraf", "william j dally", "kurt keutzer"], "accepted": false, "id": "1602.07360"}, "pdf": {"name": "1602.07360.pdf", "metadata": {"source": "CRF", "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size", "authors": ["Forrest N. Iandola", "Matthew W. Moskewicz", "Khalid Ashraf", "Song Han", "William J. Dally", "Kurt Keutzer"], "emails": ["keutzer}@eecs.berkeley.edu", "dally}@stanford.edu"], "sections": [{"heading": null, "text": "The SqueezeNet architecture can be downloaded here: https: / / github.com / DeepScale / SqueezeNet"}, {"heading": "1. Introduction and Motivation", "text": "Much of the recent research on deep neural networks has focused on increasing the accuracy of FPGA datasets. For a certain level of accuracy, there are typically multiple DNN architectures that reach that level of accuracy. At the same level of accuracy, a DNN architecture with fewer parameters has several advantages: \u2022 More efficient distributed training. Communication between servers is the limiting factor for the scalability of distributed DNN training. For distributed data-parallel training, the communication effort is directly proportional to the number of parameters in the model [11]. In short, small models train faster because less communication is needed. \u2022 Less effort when exporting new models to customers. For autonomous driving, companies like Tesla regularly copy new models from their servers to customers \"cars. With AlexNet, this would require 240 MB. Section: http: / / deepscale.aiof communication from the server to the car."}, {"heading": "2. SqueezeNet: preserving accuracy with", "text": "In this section, we first outline our design strategies for DNN architectures with a few parameters, then introduce the Fire module, the building block from which we build DNN architectures. Finally, we use our design strategies to construct SqueezeNet, which consists largely of Fire modules."}, {"heading": "2.1. Architectural Design Strategies", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "2.2. The Fire Module", "text": "We define the Fire module as follows: A Fire module consists of: a squeeze convolution module consisting of 1x1 filters fed into an extension module consisting of a mixture of 1x1 and 3x3 convolution filters; we illustrate this in Figure 1. The generous use of 1x1 filters in Fire modules allows us to use Strategy 1 from Section 2.1. We set three tunable dimensions (hyperparameters) in a Fire module: s1x1, e1x1, and e3x3. In a Fire module, s1x1 is the number of filters in the Squeeze module (all 1x1), e1x1 is the number of 1x1 filters in the Expanded module, and e3x3 is the number of 3x3 filters in the Expanded module. If we use Fire modules, we set s1x1 to less than the number of ex1 filters in the Squeeze (+ 1x3), so that the number of 3x3 filters is limited."}, {"heading": "2.3. The SqueezeNet architecture", "text": "We now describe the SqueezeNet DNN architecture. We illustrate in Figure 2 that SqueezeNet begins with a standalone folding layer (Conv1), followed by 8 Fire modules (Fire2-9) and ends with a final Conv layer (Conv10). We gradually increase the number of filters per Fire module from the beginning to the end of the network. SqueezeNet performs max pooling with a step from 2 to Conv1, Fire4, Fire8 and Conv10; these relatively late placements of the pooling allow us to achieve strategy 3 from Section 2.1. We present the complete SqueezeNet architecture in Table 1."}, {"heading": "2.3.1 Other SqueezeNet details", "text": "\u2022 To ensure that the output activations of 1x1 and 3x3 filters have the same height and width, we add a 1-pixel margin with zero padding in the input data to 3x3 filters of expansion modules. \u2022 ReLU [18] is applied to activations of squeeze and expansion modules. \u2022 Dropout [20] with a ratio of 50% is applied after the FireCaffe layer. \u2022 Note the absence of fully bonded layers in SqueezeNet; this design selection was inspired by the NiN [17] architecture. \u2022 In the training of SqueezeNet, we use a polynomic learning rate similar to that described in the FireCaffe paper [11]. For details on the training protocol (e.g. batch size, learning rate, parameter initialization), please refer to our Caffe [15] configuration files located here: https / gizeCaffe / DetailCeex.com / 1x1 box / 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-"}, {"heading": "3. Related Work", "text": "The overarching goal of our work is to identify a model that has very few parameters, but is precise nonetheless. To address this problem, a reasonable approach is to lossy compress an existing DNN model. Indeed, a research community has emerged around the issue of model compression, and several approaches have been reported. A fairly straightforward approach by Denton et al. is to apply singular value decomposition (SVD) to a pre-trained DNN model [4]. Han et al. developed Network Pruning, which begins with a pre-trained model, then replaces parameters below a certain threshold with zeros to form a sparse matrix, and finally performs some iterations of training on the sparse DNN [9]. Recently, Han et al. expanded their work by combining network pruning with quantization (on 8 bit or less) and huffman-coding [8]."}, {"heading": "4. Evaluation", "text": "We are now turning our attention to evaluating SqueezeNet. In each of the DNN model compression papers reviewed in the previous section, the goal was to compress an AlexNet4 [16] model that was trained to classify images using the ImageNet [3] (ILSVRC 2012). Therefore, we are using AlexNet4 and the associated model compression results as the basis for comparison when evaluating SqueezeNet.In Table 2, we review SqueezeNet in the context of recent model compression results. The SVD-based approach is able to compress a pre-formed AlexNet4 model by a factor of 5x, while reducing the accuracy to 56.0% of the top-1 accuracy [4]. Network pruning achieves a 9x reduction in model size while maintaining the baseline of 57.2% top-1 and 80.3% top-5 accuracy on image [9]."}, {"heading": "5. Conclusions and Future Work", "text": "We introduced SqueezeNet, a DNN architecture that has 50x fewer parameters than AlexNet and maintains AlexNet-level accuracy in ImageNet. In this post, we focused on ImageNet as the target dataset. However, it has become common practice to apply ImageNet-trained DNN representations to a variety of applications, such as fine-grained object recognition [21, 5], logo identification in images [13] and the generation of sentences over images [6]. ImageNet-trained DNNs have also been used for a number of applications related to autonomous driving, including pedestrian and vehicle recognition in images [12, 7] and videos [2], as well as segmentation of the road shape [1]. We think that SqueezeNet will be a good DNN architecture for a variety of applications, especially those where small model sizes matter. SqueezeNet is one of several new DNNs that we have discovered while we are dragging the DNN space to the DNN architectures."}, {"heading": "Acknowledgments", "text": "The authors thank Bill Dally for the helpful discussions. Partly funded by DARPA award number HR0011-12-2-0016, as well as ASPIRE industry patrons and subsidiaries Intel, Google, Huawei, Nokia, NVIDIA, Oracle and Samsung. Resources from the Oak Ridge Leadership Facility at the Oak Ridge National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under contract number DEAC05-00OR22725, were used for this research."}], "references": [{"title": "SegNet: A deep convolutional encoder-decoder architecture for image segmentation", "author": ["V. Badrinarayanan", "A. Kendall", "R. Cipolla"], "venue": "arxiv:1511.00561", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "3d object proposals for accurate object class detection", "author": ["X. Chen", "K. Kundu", "Y. Zhu", "A.G. Berneshawi", "H. Ma", "S. Fidler", "R. Urtasun"], "venue": "NIPS", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "ImageNet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei- Fei"], "venue": "CVPR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Exploiting linear structure within convolutional networks for efficient evaluation", "author": ["E. Denton", "W. Zaremba", "J. Bruna", "Y. LeCun", "R. Fergus"], "venue": "NIPS", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "arXiv:1310.1531", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "From captions to visual concepts and back", "author": ["H. Fang", "S. Gupta", "F. Iandola", "R. Srivastava", "L. Deng", "P. Dollar", "J. Gao", "X. He", "M. Mitchell", "J.C. Platt", "C.L. Zitnick", "G. Zweig"], "venue": "CVPR", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Deformable part models are convolutional neural networks", "author": ["R.B. Girshick", "F.N. Iandola", "T. Darrell", "J. Malik"], "venue": "CVPR", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep compression: Compressing DNNs with pruning", "author": ["S. Han", "H. Mao", "W. Dally"], "venue": "trained quantization and huffman coding. arxiv:1510.00149v3", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning both weights and connections for efficient neural networks", "author": ["S. Han", "J. Pool", "J. Tran", "W. Dally"], "venue": "NIPS", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Convolutional neural networks at constrained time cost", "author": ["K. He", "J. Sun"], "venue": "CVPR", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "FireCaffe: near-linear acceleration of deep neural network training on compute clusters", "author": ["F.N. Iandola", "K. Ashraf", "M.W. Moskewicz", "K. Keutzer"], "venue": "arxiv:1511.00175", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "DenseNet: Implementing efficient convnet descriptor pyramids", "author": ["F.N. Iandola", "M.W. Moskewicz", "S. Karayev", "R.B. Girshick", "T. Darrell", "K. Keutzer"], "venue": "arXiv:1404.1869", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "DeepLogo: Hitting logo recognition with the deep neural network hammer", "author": ["F.N. Iandola", "A. Shen", "P. Gao", "K. Keutzer"], "venue": "arXiv:1510.02131", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "JMLR", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "ACM Multimedia", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "arXiv:1312.4400", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "ICML", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "arXiv:1409.1556", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "JMLR", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Deformable part descriptors for fine-grained recognition and attribute prediction", "author": ["N. Zhang", "R. Farrell", "F. Iandola", "T. Darrell"], "venue": "ICCV", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 10, "context": "For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the model [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 9, "context": "Sun applied delayed downsampling to four different DNN architectures, and in each case delayed downsampling led to higher classification accuracy [10].", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "\u2022 ReLU [18] is applied to activations from squeeze and expand modules.", "startOffset": 7, "endOffset": 11}, {"referenceID": 19, "context": "\u2022 Dropout [20] with a ratio of 50% is applied after the fire9 layer.", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "\u2022 Note the lack of fully-connected layers in SqueezeNet; this design choice was inspired by the NiN [17] architecture.", "startOffset": 100, "endOffset": 104}, {"referenceID": 10, "context": "\u2022 When training SqueezeNet, we use a polynomial learning rate much like the one that we described in the FireCaffe paper [11].", "startOffset": 121, "endOffset": 125}, {"referenceID": 14, "context": "batch size, learning rate, parameter initialization), please refer to our Caffe [15] configuration files located here: https://github.", "startOffset": 80, "endOffset": 84}, {"referenceID": 13, "context": "(The formatting of this table was inspired by the Inception2 paper [14].", "startOffset": 67, "endOffset": 71}, {"referenceID": 3, "context": "is to apply singular value decomposition (SVD) to a pretrained DNN model [4].", "startOffset": 73, "endOffset": 76}, {"referenceID": 8, "context": "developed Network Pruning, which begins with a pretrained model, then replaces parameters that are below a certain threshold with zeros to form a sparse matrix, and finally performs a few iterations of training on the sparse DNN [9].", "startOffset": 229, "endOffset": 232}, {"referenceID": 7, "context": "extended their work by combining Network Pruning with quantization (to 8 bits or less) and huffman encoding to create an approach called Deep Compression [8].", "startOffset": 154, "endOffset": 157}, {"referenceID": 15, "context": "In each of the DNN model compression papers reviewed in the previous section, the goal was to compress an AlexNet [16] model that was trained to classify images using the ImageNet [3] (ILSVRC 2012) dataset.", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "In each of the DNN model compression papers reviewed in the previous section, the goal was to compress an AlexNet [16] model that was trained to classify images using the ImageNet [3] (ILSVRC 2012) dataset.", "startOffset": 180, "endOffset": 183}, {"referenceID": 3, "context": "0% top-1 accuracy [4].", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "3% top-5 accuracy on ImageNet [9].", "startOffset": 30, "endOffset": 33}, {"referenceID": 7, "context": "Deep Compression achieves a 35x reduction in model size, while still maintaining the baseline accuracy level [8].", "startOffset": 109, "endOffset": 112}, {"referenceID": 7, "context": "Until now, an open question has been: are small models amenable to compression, or do small models \u201cneed\u201d all of the representational power afforded by dense floating-point values? To find out, we applied Deep Compression [8] to SqueezeNet, using 50% sparsity5 and 8-bit quantization.", "startOffset": 222, "endOffset": 225}, {"referenceID": 14, "context": "4Our baseline is bvlc alexnet from the Caffe codebase [15].", "startOffset": 54, "endOffset": 58}, {"referenceID": 3, "context": "3% AlexNet SVD [4] 32 bit 240MB \u2192 48MB 5x 56.", "startOffset": 15, "endOffset": 18}, {"referenceID": 8, "context": "4% AlexNet Network Pruning [9] 32 bit 240MB \u2192 27MB 9x 57.", "startOffset": 27, "endOffset": 30}, {"referenceID": 7, "context": "AlexNet Deep Compression[8] 5-8 bit 240MB \u2192 6.", "startOffset": 24, "endOffset": 27}, {"referenceID": 7, "context": "In addition, these results demonstrate that Deep Compression [8] not only works well on DNN architectures with many parameters (e.", "startOffset": 61, "endOffset": 64}, {"referenceID": 18, "context": "AlexNet and VGG [19]), but it is also able to compress the already compact, fully convolutional SqueezeNet architecture.", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "However, it has become common practice to apply ImageNet-trained DNN representations to a variety of applications such as fine-grained object recognition [21, 5], logo identification in images [13], and generating sentences about images [6].", "startOffset": 154, "endOffset": 161}, {"referenceID": 4, "context": "However, it has become common practice to apply ImageNet-trained DNN representations to a variety of applications such as fine-grained object recognition [21, 5], logo identification in images [13], and generating sentences about images [6].", "startOffset": 154, "endOffset": 161}, {"referenceID": 12, "context": "However, it has become common practice to apply ImageNet-trained DNN representations to a variety of applications such as fine-grained object recognition [21, 5], logo identification in images [13], and generating sentences about images [6].", "startOffset": 193, "endOffset": 197}, {"referenceID": 5, "context": "However, it has become common practice to apply ImageNet-trained DNN representations to a variety of applications such as fine-grained object recognition [21, 5], logo identification in images [13], and generating sentences about images [6].", "startOffset": 237, "endOffset": 240}, {"referenceID": 11, "context": "ImageNettrained DNNs have also been applied to a number of applications pertaining to autonomous driving, including pedestrian and vehicle detection in images [12, 7] and videos [2], as well as segmenting the shape of the road [1].", "startOffset": 159, "endOffset": 166}, {"referenceID": 6, "context": "ImageNettrained DNNs have also been applied to a number of applications pertaining to autonomous driving, including pedestrian and vehicle detection in images [12, 7] and videos [2], as well as segmenting the shape of the road [1].", "startOffset": 159, "endOffset": 166}, {"referenceID": 1, "context": "ImageNettrained DNNs have also been applied to a number of applications pertaining to autonomous driving, including pedestrian and vehicle detection in images [12, 7] and videos [2], as well as segmenting the shape of the road [1].", "startOffset": 178, "endOffset": 181}, {"referenceID": 0, "context": "ImageNettrained DNNs have also been applied to a number of applications pertaining to autonomous driving, including pedestrian and vehicle detection in images [12, 7] and videos [2], as well as segmenting the shape of the road [1].", "startOffset": 227, "endOffset": 230}], "year": 2016, "abstractText": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNetlevel accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 1MB (461x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet", "creator": "LaTeX with hyperref package"}}}