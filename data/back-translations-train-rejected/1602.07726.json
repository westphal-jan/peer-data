{"id": "1602.07726", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2016", "title": "Adaptive Learning with Robust Generalization Guarantees", "abstract": "The traditional notion of generalization --- i.e., learning a hypothesis whose empirical error is close to its true error --- is surprisingly brittle. As has recently been noted [DFH+15b], even if several algorithms have this guarantee in isolation, the guarantee need not hold if the algorithms are composed adaptively. In this paper, we study three notions of generalization ---increasing in strength--- that are robust to post-processing and amenable to adaptive composition, and examine the relationships between them.", "histories": [["v1", "Wed, 24 Feb 2016 21:59:30 GMT  (136kb)", "http://arxiv.org/abs/1602.07726v1", null], ["v2", "Thu, 2 Jun 2016 00:07:01 GMT  (158kb)", "http://arxiv.org/abs/1602.07726v2", null]], "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["rachel cummings", "katrina ligett", "kobbi nissim", "aaron roth", "zhiwei steven wu"], "accepted": false, "id": "1602.07726"}, "pdf": {"name": "1602.07726.pdf", "metadata": {"source": "CRF", "title": "Adaptive Learning with Robust Generalization Guarantees", "authors": ["Rachel Cummings", "Katrina Ligett", "Kobbi Nissim", "Aaron Roth", "Zhiwei Steven Wu"], "emails": ["rachelc@caltech.edu", "katrina@caltech.edu", "kobbi@cs.bgu.ac.il", "aaroth@cis.upenn.edu", "wuzhiwei@cis.upenn.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 2.07 726v 1 [cs.D S] 2 4Fe bWe refer to the weakest such notion as Robust Generalization. A second, middle, notion is the Stability Guarantee, which is known as Differential Privacy. The strongest guarantee, which we consider to be Perfect Generalization. We prove that any hypotheses class that PAC is learnable is also PAC learnable, albeit with an exponential increase in sample complexity. We suspect that a stronger version of this theorem also applies, which avoids any bubble in sample complexity (and would actually do so, subject to a long-standing assumption [LW86, War03]). It was previously known that differentiated private algorithms satisfy a robust generalization. In this essay we show that robust generalization is a strictly weaker concept and that there is a learning task that can be performed under robust guarantees, but may not be a more general question than DFH, which is a more general question."}, {"heading": "1 Introduction", "text": "The generalization, informal, is the ability of a learner to reflect not only his training data, but also the characteristics of the underlying data processing from which the data is extracted. In conjunction with empirical risk minimization, it is the fundamental goal of learning. Typically, we say that a learning algorithm generalizes when it has access to a series of training courses that i.i.d have arisen from an underlying data distribution, the general way in which the distributions of computer science and mathematical sciences are executed is not only a general learning method, but also a general learning one. The Hebrew University of Jerusalem. katrina @ caltech.edu Dept. of Computer Science, Ben-Gurion University and Center for Research in Computation and Society, Harvard University of Computing and Society, kobbi @ cs.bgu.ac.il \u00a7 Dept. of Computer and Information Sciences, University of Pennsylvania @ arup.arup.coth @."}, {"heading": "1.1 Our Results", "text": "We say that a learning algorithm guarantees a robust generalization when it is not only possible to issue a hypothesis whose empirical error is close to the true error (and almost optimal), but when no opponent takes the initial hypothesis as input, another hypothesis can be found whose empirical error is substantially different from his actual error. (In particular, generalized generalization of algorithms is inherently robust in post-processing and can therefore be used to generate other test statistics in an arbitrary manner without overadjustment. We say that a learning algorithm has the stronger guarantee of perfect generalization when its output reveals almost nothing about the training data that could not only be learned through direct data restriction. It was previously known [DFH + 15b, DFH + 15a, BNS + 16] that both the differential privacy and the limited description of the outputs are sufficient to guarantee that a learning algorithm is a robust one."}, {"heading": "1.2 Related work", "text": "There are three main approaches to prove standard generalizations of this kind. The first is the delimitation of the sensitivity of a classic in length, and the second is the deviation from the deviation. The third is the deviation from the deviation from the original deviation. The third is the deviation from the original deviation from the original deviation. The third is the deviation from the original deviation from the original deviation."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Learning Theory Background", "text": "LetX denotes a domain that contains all possible examples. A hypothesis h: X \u2192 \u03b2 = 0.1} is a Boolean figure that denotes examples by {0.1}, where h (x) = 1 indicates that x is a positive instance and h (x) = 0 indicates that x is a negative instance. A hypothesis class is a series of hypotheses. Throughout the paper, we will hide dependencies on the dimension of the domain. We will sometimes write an example of X \u00d7 {0.1}, i.e., labeled examples. LetDL is a distribution of labeled examples; we will refer to it as the underlying distribution. We will write SL \u0445 i.d. DnL to name a sample of n-labeled examples, the i.i.d. from the DL, a learning algorithm takes such a sample SL (also known as the educational theorem) as input and issues a hypothesis."}, {"heading": "2.2 Notions of Generalization", "text": "In this section, we present the three concepts of generalization that are examined in this work."}, {"heading": "2.3 Basic Properties of the Generalization Notions", "text": "The following problem is a useful tool for limiting the coherence parameters between two distributions via an intermediate distribution, such as that of the simulator. It allows us to say that for each perfectly generalizing mechanism two \"typical\" patterns induce similar output distributions. Lemma 2.9. LetD1, D2, D3 may also be distributions over an abstract domain X. That is, D1, D2, D3, D3, X. If D1, D2 and D2."}, {"heading": "3 Robust Generalization via Compression Schemes", "text": "In this section, we present a new technique based on the idea of compression limits to design learning algorithms with the robust generalization guarantee. Recent work [DFH + 15b, DFH + 15a, BNS + 16] provides two additional techniques for obtaining robust generalization mechanisms. As we will see, our new technique allows learning hypotheses classes under robust generalization, for which the two previous techniques are not applicable. These results lead us to a fascinating open question: Is any PAC hypothesis also learnable under the duress of robust generalization? This question is closely related to a long-standing problem [LW86, War03]. First, we give a definition of what it means to learn a hypothesis under robust generalization.Definition 3.1 (RG PAC / Agnostic Learning). A hypothesis about class H is ClassdomainAC Learning X (Pagnostic Learning)."}, {"heading": "3.1 Compression Learners", "text": "It is a hypothesis that is an empirical risk minimizer. (SL) It is a hypothesis that we have a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL) It is a hypothesis. (SL). (SL). (SL). (SL). (SL). (SL). (SL). (SL)."}, {"heading": "3.2 Robust Generalization via Differential Privacy and Description Length", "text": "We briefly consider two existing techniques for generalizing algorithms with a robust generalization guarantee, starting with [DFH + 15b] and followed by [DFH + 15a, BH15, BNS + 16]. At this point, we will rephrase their results in terms of robust generalization (this terminology is new in the present work). First, it is known that differential privacy implies a robust generalization.Theorem 3.8 ([BNS + 16]) Let M: X n \u2192 R be a (\u03b5, \u03b4) -differentiated private mechanism for n \u2265 O (ln (1 / \u03b4) / \u03b52).ThenM also satisfies (O (\u03b5), O (\u03b5 / \u03b5) -robust generalization. Algorithms with a small output range (i.e., each output can be described with a small number of bits) also enjoy robust generalization."}, {"heading": "3.3 Case Study: Proper Threshold Learning", "text": "Next, we look at the problem of properly learned thresholds in the PAC setting. We will first note that if the domain size is infinite, there is no correct PAC learner who is differentiated private or has a limited output range. In contrast to these impossibility results, we show that the threshold function class allows a simple compression scheme, and therefore there is a PAC learning algorithm that fulfills a robust generalization, which results in particular in a separation between the power of learning under robust generalization and that of learning under differential privacy. Consider the hypotheses category of threshold functions {hx} x over a fully ordered domain X, in which hx (y) = 1, if y x and hx (y) = 0, if y > x. We will first remember an impossibility result for privately learnable limits. Theorem 3.10 (BNS15) = 1, if y x and hx (y) = 0, if y > x."}, {"heading": "3.4 A Conjecture on Robust Generalizing Learning", "text": "The result of Theorem 3.6 gives us a novel tool for robust generalization of learners for multiple hypotheses. This leads us to the following conjecture: Conjecture 3.13. Any PAC-learnable hypotheses category is also PAC-learnable under robust generalization. However, we will first show that any PAC-learnable hypotheses category (i.e., any hypotheses category with polynomic VC dimension) is learnable with a guarantee of robust generalization, but not necessarily with a polynomic sample generalization class. We will first show that any hypotheses category (i.e. any hypotheses category with polynomic VC dimension) is learnable."}, {"heading": "4 Learning under Perfect Generalization", "text": "In this section, we will focus on the problem of agnostic learning under the compulsion of perfect generalization. Our main result gives a perfectly generalizing generic learner in environments where domain X or the hypothesis class H has a limited size. Sample complexity arithmically depends on these two quantities. In addition, we will give a reduction from each perfectly generalizing learner to a differentiated private learner who maintains the boundaries of sample complexity (up to constant factors), allowing us to transfer lower boundaries for differentiated private learning to learning under perfect generalization. In particular, we will show that correct threshold learning with unlimited domain size under perfect generalization is impossible. We will first define what it means to learn a hypothesis under perfect generalization. Definition 4.1 (PG PAC / Agnostic Learning Class H over domain size) -agnostic learnable under perfect generalization (PG / perfect generalization)."}, {"heading": "4.1 Generic PG Agnostic Learner", "text": "We show that this algorithm is completely generalized. Algorithm 1 Generic Learner A (\u03b2, H), and samples a random hypothesis with a probability that tends exponentially toward hypotheses with small empirical errors. We show that this algorithm is completely generalizing. Algorithm 1 Generic Learner A (\u03b2, H), output h H with probability proportional to exp (\u2212 SL, h). We show that this algorithm is completely generalizable."}, {"heading": "4.2 PG Learning with VC Dimension Sample Bounds", "text": "We can also extend the sample complexity bound in Theorem 4.3 by one that depends on the VC dimension of the hypothesis class H, but the resulting limit will have a logarithmic dependence on the size of the domain. Any hypothesis class H with a finite VC dimension can be learned agnostically with a sample size of n = O ((((VCDIM (H) \u00b7 ln | X | + ln 1\u03b2) 3 \u00b7 1\u03b52\u03b12). Proof. From Sauer's Lemma (see e.g. [KV94]) we know that mostO (| X | VCDIM (H))) has different names of domain X through the hypotheses in H. We can execute the exponential mechanism through such a hypothesis class H \u2032 with cardinality | H \u2032 | = O (| X | VCDIM (H))."}, {"heading": "4.3 Limitations of PG learning", "text": "We have so far given a generic agnostic learner with perfect generalization in cases where either \u03b2 (X) or H (H) is finite. We now show that such a finite condition is necessary by re-examining the learning problem in Section 3.3. Specifically, we will show that if the domain size is infinite, proper learning thresholds under perfect generalization are impossible. Our result is crucially based on a reduction from a perfectly generalizing learner to a differential private learner, which allows us to apply lower bound results of differential private learning (such as Theorem 3.10) to PG agnostic learning thresholds. First, consider the reduction in Algorithm 2, which is a black box mechanism that takes as input a completely generalizing mechanism M: X nL \u2192 R and a labeled sample SL \u00b2 nL, and outputs an element of R. We show that this new mechanism is perfect (Algorithm 2M)."}, {"heading": "5 Relationship between Perfect Generalization and Other Generaliza-", "text": "In this section we examine the relationship between perfect generalization and both robust generalization and differential privacy. Section 5.1 shows that any perfectly generalizing mechanism is also robust generalizing, but there are robust generalizing mechanisms that are neither differentiated private nor completely generalizing for reasonable parameters. Section 5.2 shows that all differentiated private mechanisms are perfectly generalizing, with some necessary loss of generalizing parameters, but there are perfectly generalizing mechanisms that are not differentiated private for reasonable parameters. Thus, perfect generalization is stronger than robust generalization in the qualitative sense: perfect generalization implies robust generalization, but the opposite is not true. Perfect generalization is stronger than differentiated privacy only in a quantitative sense: differential privacy implies perfect generalization, but more necessarily worse generalization."}, {"heading": "5.1 Separation between Perfect and Robust Generalization", "text": "In this section, we show that a perfect generalization is a stronger requirement than a robust generalization. Lemma 5.1 shows a direction of this development by showing that any perfectly generalizing mechanism also satisfies a robust generalization with only a constant degradation in the generalization parameters. Then, M is also (\u03b1 +) -robust generalization (0.1), provided that a mechanism (X n + 1) with an arbitrary range (2). Proof. let A: R \u2192 (X \u2192 0.1) be the function that takes over the production of M (S) and produces a hypothesis h: X \u2192 {0.1}. Our goal is to show that h will not go beyond the original sample. From Lemma 2.11, the composition of A: X \u2192 X \u2192 X (S), that we are making a hypothesis."}, {"heading": "5.2 Perfect Generalization and Differential Privacy", "text": "We will now focus on the relationship between differential privacy and perfect generalization to show that perfect generalization is a strictly stronger definition in the sense that problems that can be solved with perfect generalization can also be solved in a differential private mechanism with only a constant factor loss in the parameters (Theorem 4.5). However, we point out here that this compilation is necessary - that fully generalizing algorithms are not necessarily themselves private. In the opposite direction, we will show that any private algorithm is highly generalizing, with some necessary degradation in the generalization parameters. We will first give an example of a perfectly generalizing mechanism that does not necessarily fulfill differential privacy for all reasonable parameters."}, {"heading": "6 Conjectures and Open Problems", "text": "We have demonstrated in Theorem 3.14 that any PAC-learnable hypotheses class (i.e. any hypotheses class with polynomial VC dimension) can be learned with a guarantee of robust generalization, albeit with a possible exponential blow-up in sample complexity. This connection is based on the recent work of [MY15], which shows that each VC class of dimension d has a compression scheme of size exponentially in d. We note that a corresponding result is not known for differentiated private learners - in fact, there is a hypotheses class of VC dimension 1 (one-dimensional threshold functions) for which there is no known private learner. We suspect something much stronger - that any PAC-learnable problem is learnable with the guarantee of a robust generalization, with at most a constant blow-up in sample complexity. Our guess is implied by Warth's Class 03 [warmth pattern] that each dimension has a constant blow-up in sample complexity."}, {"heading": "A Missing Proofs in Section 2", "text": "For all O R, Pr y \u0445 D1 [y \u00b2 O] \u2264 (exp \u00b2) Pr y \u00b2 D2 [y \u00b2 O] + \u03b4 (p \u00b2) Pr y \u00b2 D2 [y \u00b2 O]) A similar argument is given by Pry \u00b2 D3 [y \u00b2 O] + \u03b4 \u00b2 (exp ()) Pr y \u00b2 D3 [y \u00b2 O] + \u03b4M \u00b2 (2 \u00b2 O). A similar argument is given by Pry \u00b2 D3 [y \u00b2 O] + \u03b4 \u00b2 (exp ()) Pr y y \u00b2 D3 [y \u00b2 O] + \u03b4M \u00b2 (2 \u00b2 O)."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "The traditional notion of generalization\u2014i.e., learning a hypothesis whose empirical error<lb>is close to its true error\u2014is surprisingly brittle. As has recently been noted [DFH+15b], even<lb>if several algorithms have this guarantee in isolation, the guarantee need not hold if the al-<lb>gorithms are composed adaptively. In this paper, we study three notions of generalization\u2014<lb>increasing in strength\u2014that are robust to postprocessing and amenable to adaptive composi-<lb>tion, and examine the relationships between them.<lb>We call the weakest such notion Robust Generalization. A second, intermediate, notion is<lb>the stability guarantee known as differential privacy. The strongest guarantee we consider we<lb>call Perfect Generalization. We prove that every hypothesis class that is PAC learnable is also<lb>PAC learnable in a robustly generalizing fashion, albeit with an exponential blowup in sam-<lb>ple complexity. We conjecture that a stronger version of this theorem also holds that avoids<lb>any blowup in sample complexity (and, in fact, it would, subject to a longstanding conjec-<lb>ture [LW86, War03]). It was previously known that differentially private algorithms satisfy<lb>robust generalization. In this paper, we show that robust generalization is a strictly weaker<lb>concept, and that there is a learning task that can be carried out subject to robust generaliza-<lb>tion guarantees, yet cannot be carried out subject to differential privacy, answering an open<lb>question of [DFH+15a]. We also show that perfect generalization is a strictly stronger guar-<lb>antee than differential privacy, but that, nevertheless, many learning tasks can be carried out<lb>subject to the guarantees of perfect generalization.", "creator": "LaTeX with hyperref package"}}}