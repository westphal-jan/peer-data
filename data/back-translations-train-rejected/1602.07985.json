{"id": "1602.07985", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2016", "title": "How effective can simple ordinal peer grading be?", "abstract": "Ordinal peer grading has been proposed as a simple and scalable solution for computing reliable information about student performance in massive open online courses. The idea is to outsource the grading task to the students themselves as follows. After the end of an exam, each student is asked to rank ---in terms of quality--- a bundle of exam papers by fellow students. An aggregation rule will then combine the individual rankings into a global one that contains all students. We define a broad class of simple aggregation rules and present a theoretical framework for assessing their effectiveness. When statistical information about the grading behaviour of students is available, the framework can be used to compute the optimal rule from this class with respect to a series of performance objectives. For example, a natural rule known as Borda is proved to be optimal when students grade correctly. In addition, we present extensive simulations and a field experiment that validate our theory and prove it to be extremely accurate in predicting the performance of aggregation rules even when only rough information about grading behaviour is available.", "histories": [["v1", "Thu, 25 Feb 2016 16:37:57 GMT  (434kb,D)", "http://arxiv.org/abs/1602.07985v1", "23 pages, 5 figures, 4 tables"]], "COMMENTS": "23 pages, 5 figures, 4 tables", "reviews": [], "SUBJECTS": "cs.AI cs.DS cs.LG", "authors": ["ioannis caragiannis", "george a krimpas", "alexandros a voudouris"], "accepted": false, "id": "1602.07985"}, "pdf": {"name": "1602.07985.pdf", "metadata": {"source": "CRF", "title": "How effective can simple ordinal peer grading be?\u2217", "authors": ["Ioannis Caragiannis", "George A. Krimpas", "Alexandros A. Voudouris"], "emails": ["caragian@ceid.upatras.gr.", "krimpas@ceid.upatras.gr.", "voudouris@ceid.upatras.gr."], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them will be able to play by the rules that they have shown in recent years, and they will be able to play by the rules that they have set themselves."}, {"heading": "2 Preliminaries", "text": "We assume that n students have taken an exam and submitted their papers. Our approach to ordinary peer grading has three different tasks: distributing the tasks to the students, the grading task of each student, and summarizing the grades to a final result. We describe these tasks in detail here and give definitions that will be useful later."}, {"heading": "2.1 Distributing the exam papers", "text": "The goal of the first task is to balance the student's grading burden by distributing (copies) of each paper to the students so that each paper is given to exactly k students and each student receives exactly k (delimited) papers. The k-regular papers that a student receives form their bundle. These are the examination papers that the student has to grade. Crucially, the bundle of a student should not contain its own examination papers. A k-regular two-part graph G = (U, V, E) with n nodes on each side of the division (called a (n, k) bundle graph in [4]) can be used to represent the distribution of the examination papers to the students. Each node of the sentences U and V represents a student. An edge of graph G between a node u-node and a node v-V indicates that the student's examination paper is becoming a node."}, {"heading": "2.2 Modelling the grading task", "text": "It is only a matter of time before that happens, that it happens."}, {"heading": "2.3 Aggregation rules", "text": "A simple but very convincing aggregation rule is inspired by the Borda voting rule. In our context, Borda calculates a score for each paper by examining the positions it has in the ranking of papers that have this Borda paper in their bundles. Borda's result is a ranking of papers in no increasing order of their Borda results. If we use Borda, we assume that balances are broken uniformly at random, but other unbalanced rules could also be taken into account. More generally, a positional score aggregation rule considers a different point vector (a1, a2,..., ak) that adapts to the final score of the examination papers, as if it is an even score or not."}, {"heading": "3 Type-ordering aggregation rules", "text": "We use the term type to refer to the gradation result of an exam paper. Here, the gradation result consists of the ranks it receives from the k-graders that have it in their bundles. Thus, the type is a vector k integer of [k] = {1, 2,..., k}. We follow the convention that the k entries appear in types in monotonous, not decreasing order."}, {"heading": "Tk = {\u03c3 = (\u03c31, \u03c32, ..., \u03c3k)|1 \u2264 \u03c31 \u2264 \u03c32 \u2264 ... \u2264 \u03c3k \u2264 k}", "text": "It is not difficult to see that TC actually contains (2k \u2212 1k) different types. As an example with k = 6, an exam paper of type (1, 2, 2, 2, 2, 5) is placed first by one of his students, second by a fourth-grader, and fifth by a fifth-grader. Let us now consider another exam paper of type (2, 2, 2, 3, 3) and note that Borda gives both papers the same Borda score of 28. Is there a specific reason why these two papers should be very close in the final order? Let us now look at the two types of exams (1, 1, 2, 5, 6) and (2, 2, 3, 3) of Borda points 26 and 27) of Borda points. Borda suggests that a paper of the second type is better. But if we look carefully at the ranking, we could come to the following interpretation."}, {"heading": "3.1 A framework for theoretical analysis", "text": "This is close to the vision of MOOCs with huge numbers of enrolled students and is the important assumption that constitutes the theoretical analysis. Thus, we can assume that the positions of students in the ranking of basic truths are considered as the continuum of the interval [0, 1]. We will usually select an exam paper as a real number x [0, 1], i.e., according to their rank in the ranking of basic truths, we will assume that in each of the k bundles to which the exam paper x belongs, the remaining k-1 exam papers will be selected as a unified result from the student population. Our assumption of infinite numbers of students allows us to ignore subtleties such as the requirement that all students should be distinguishable and also different from the students who behave the degrees of degrees of that requirement (the probability that this requirement will not be met in any bundle)."}, {"heading": "3.2 Computing optimal type-ordering aggregation rules", "text": "The approach in Section 3.1 suggests a general way of evaluating the performance of papers with small values. To calculate the expected number of correctly restored pair-wise relations, it is sufficient to use equations (2), (3) and (5). Equation (5) can be used to obtain the expected number of correctly restored pair-wise relations, which is then used in Equation (3) to calculate the weights (for any pair of types). Finally, Equation (2) returns the expected number of correctly restored pair-wise relations. Of course, the expected number of correctly restored pair-wise relations is not the only performance objective one would like to measure. We could simply ignore tests that are very close in the ranking of basic truths. The ranking of fundamentals is largely a modeling of assumption and should be very restrictive in the rating of an aggregated rule."}, {"heading": "3.3 Borda is optimal for perfect graders", "text": "Theorem 3. For any scenario in which perfectionists are involved, Borda (with any tie-break) is the optimal type-order aggregation rule. Proof. Let us suppose that we have a scenario with a bundle size of k, perfect grading (i.e., a k \u00b7 k identity noise matrix), and a bivariate function f representing the object of performance. We first calculate the probability that the test paper will get x type with (4) and the fact that p\u03c3i, '= 1, if \u03c3i = \"and p\u03c3i,' = 0 is otherwise. Consequently, Pr [xB] k = 1 (k \u2212 1) x\u03c3i \u2212 1 \u2212 x\u03c3i \u2212 1 (1 \u2212 x) k \u2212 i \u2212 1 (1 \u2212 x) is the difference \u2212 and the fact that the difference (n) k \u2212 x (k \u2212 x) is equality, and the equality [n] is equality."}, {"heading": "4 Validation of our framework", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Building a realistic noise model using a field experiment", "text": "This year it is so far that it will be able to reete.n the aforementioned lcihsrcnlrVo"}, {"heading": "4.2 On the accuracy of theoretical performance predictions", "text": "In this context, it should be noted that this is a very complex situation, in which the two parties cannot only agree on a common denominator, but must also agree on a common denominator."}, {"heading": "4.3 The effect of inaccuracies in the noise model", "text": "It is only a matter of time before that happens, that it happens."}, {"heading": "A Computing the weights", "text": "We are now working on how to express analytically the weight W (\u03c3, \u03c3) (\u03b2 = 1); the following calculations are implemented in algorithm 1 (dt = 1) (dt = 1). Remember that W (\u03c3, \u03c3) = 1 (dt = 1) Pr [xB \u00b2] dy dx (6), and that the objective bivariate function f (x, y) indicates whether a correctly restored pair relationship between two students x and y (with x < y) should be accounted for or not. All the perfection goals we are looking at in this paper can generally be described by such a function f (x, y) = 1 if x and y [x +] if they are to be accounted for appropriately by both students x < y)."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "<lb>Ordinal peer grading has been proposed as a simple and scalable solution for com-<lb>puting reliable information about student performance in massive open online courses.<lb>The idea is to outsource the grading task to the students themselves as follows. After<lb>the end of an exam, each student is asked to rank \u2014in terms of quality\u2014 a bundle of<lb>exam papers by fellow students. An aggregation rule will then combine the individ-<lb>ual rankings into a global one that contains all students. We define a broad class of<lb>simple aggregation rules and present a theoretical framework for assessing their ef-<lb>fectiveness. When statistical information about the grading behaviour of students is<lb>available, the framework can be used to compute the optimal rule from this class with<lb>respect to a series of performance objectives. For example, a natural rule known as<lb>Borda is proved to be optimal when students grade correctly. In addition, we present<lb>extensive simulations and a field experiment that validate our theory and prove it to<lb>be extremely accurate in predicting the performance of aggregation rules even when<lb>only rough information about grading behaviour is available.", "creator": "LaTeX with hyperref package"}}}