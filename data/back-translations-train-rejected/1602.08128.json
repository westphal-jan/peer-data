{"id": "1602.08128", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2016", "title": "PCA Method for Automated Detection of Mispronounced Words", "abstract": "This paper presents a method for detecting mispronunciations with the aim of improving Computer Assisted Language Learning (CALL) tools used by foreign language learners. The algorithm is based on Principle Component Analysis (PCA). It is hierarchical with each successive step refining the estimate to classify the test word as being either mispronounced or correct. Preprocessing before detection, like normalization and time-scale modification, is implemented to guarantee uniformity of the feature vectors input to the detection system. The performance using various features including spectrograms and Mel-Frequency Cepstral Coefficients (MFCCs) are compared and evaluated. Best results were obtained using MFCCs, achieving up to 99% accuracy in word verification and 93% in native/non-native classification. Compared with Hidden Markov Models (HMMs) which are used pervasively in recognition application, this particular approach is computational efficient and effective when training data is limited.", "histories": [["v1", "Thu, 25 Feb 2016 21:48:56 GMT  (1095kb)", "http://arxiv.org/abs/1602.08128v1", "SPIE Defense, Security, and Sensing"]], "COMMENTS": "SPIE Defense, Security, and Sensing", "reviews": [], "SUBJECTS": "cs.SD cs.CL cs.LG", "authors": ["zhenhao ge", "sudhendu r sharma", "mark j t smith"], "accepted": false, "id": "1602.08128"}, "pdf": {"name": "1602.08128.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 2.08 128v 1 [cs.S D] 25 Feb 2016Keywords: mispronunciation, PCA"}, {"heading": "1. INTRODUCTION", "text": "With the advent of technology, many Computer Assisted Language Learning (CALL) and Computer Assisted Pronunciation Training (CAPT) tools are available on the market to help people learn a new language. Learning a new language can be very difficult. Without proper feedback, it can be very frustrating. Most CALL tools focus on teaching new words or sentences using a list-and-repetition method. These tools use advanced automatic speech recognition (ASR) algorithms and provide visual tools such as spectrograms and waveforms as feedback. However, these tools are not designed to identify specific aberrations and are therefore a poor substitute for a human instructor. The work discussed in this paper focuses on aberrations in speech recognition. In the past two decades, a significant amount of research has been conducted in the field of aberrations."}, {"heading": "2. PCA METHOD FOR PATTEN RECOGNITION", "text": "One of the most popular applications of PCA is facial recognition, which has been extensively studied over the last 20 years.9-13 The basic idea behind PCA is to encode the most relevant information that distinguishes a pattern from others, and eliminate dimensions with less information to reduce computational costs.14 The mispronunciation work in this essay has much in common with facial recognition. Misspronunciation can be considered a pattern recognition problem, just like facial recognition. In addition, the Mel Frequency Cepstral Coefficient (MFCCs) and spectrograms, the features we study, are also of high dimension. The similarities between mispronunciation and facial recognition motivated us to include PCA-based facial recognition techniques in our work. In the next section, we first review the use of PCA in facial recognition and then discuss the techniques of mispronunciation."}, {"heading": "2.1 Review of Face Recognition using PCA", "text": "The PCA approach to face recognition requires all data (facial images), training data Dtrain = and test data Dtest from multiple classes to have the same size (say N1 \u00b7 N2). The method works best when the faces in all images are in the same position within the image. These data matrices are then vectorized to N1N2-dimensional column vectors. When implementing a PCA-based recognition / classification system, such as face recognition, the M-vectorized training faces (1, 2,...) are vectorized to N1N2-dimensional slit vectors. < M-based recognition / classification systems, such as face recognition, the M-vectorized training faces are used. <"}, {"heading": "2.2 Procedure for Mispronunciation Detection Using PCA", "text": "The first class consists of samples of native speakers who all have correct pronunciations; the second class includes samples of native speakers with possible mispronunciations; the first class consists of samples of native speakers who all have correct pronunciations; the second class includes samples of native speakers with possible mispronunciations; the second class includes samples of native speakers with possible mispronunciations; the third group includes samples of native speakers with possible mispronunciations; and the third group includes samples of native speakers who all include native DNN.train samples. If edfes < Td, where Td is the threshold for word verification, then the test sample is deemed \"verified\" and we proceed to Step 2. The test sample is \"rejected\" and the detection class stops. Native / NN) Classification: \"The first class is only\" classified. \""}, {"heading": "3. SYSTEM DESIGN AND IMPLEMENTATION", "text": "After reviewing the application of PCA in face detection and how it can be applied to error detection, the following section discusses in detail the implementation of PCA-based error detection, including database design, data preprocessing, feature selection, self-space training, and detection threshold optimization."}, {"heading": "3.1 Database Construction", "text": "The database used in this paper is relatively small and contains only 10 Spanish words listed in Table 1. These words were selected by language experts to cover a variety of common mispronunciations observed by American speakers learning Spanish. There were 13 male speakers, 7 of whom were native speakers and 6 non-native speakers. Each speaker repeated each of the 10 words 5 times. Due to the limited size of the database, the leave-one-out method was used for training and testing and will be discussed further in Section 3.4."}, {"heading": "3.2 Data Pre-processing and Feature Extraction", "text": "The PCA method requires centralized and unified input functions for training and testing. To centralize, phases of silence before and after the actual speech segment were removed using speech / voiceless recognition. To unify all samples in size, samples were timed to match the average duration of training data. In addition, background noise was suppressed and the amplitude of each sample was normalized to a unit to improve detection performance. Spectrograms and MFCCs were selected as input functions for the detection system. These characteristics were calculated for frames with window size 25 ms (using a haming window) and 15 ms of overlap between frames. Spectrogram space is 50-dimensional with each dimension from 320 Hz to 16 KHz. The MFCC feature space was 13-dimensional and represented the first 13 central coefficients."}, {"heading": "3.3 Eigenspace Training and Detection Threshold Optimization", "text": "As discussed in Section 2.2, these three steps are: (a) word verification; (b) N / NN classification; and (c) syllablelevel misstatements. (c) The recognition system runs on a word-to-word basis. (c) For each word, two sets of distances are e1 dfes and e2 dfes, where e1 dfes equals the distances from \"class 1\" to the proper spaces U and e2dfes equals the distance from \"class 2\" samples to U. \u2022 Phase 3: Find an optimal detection threshold T that separates these two sets of distances. Even if the 3 training phases are the same steps (a), (b) and (c), each step has a different space and a different class."}, {"heading": "4. SYSTEM TESTING AND RESULTS", "text": "After the self-space training and the optimization of the detection threshold, the error detection system is built up. In the following section, the results of the system tests are presented in each step."}, {"heading": "4.1 Leave-One-Out Training and Testing", "text": "Due to the relatively small size of the database, the Leave-One-Out (LOO) method is used for training and testing. Traditionally, in LOO all but one sample is used in training and the omitted sample is used for testing. In our case, samples belonging to one speaker (i.e. all 5 repetitions) are omitted for testing, and all samples belonging to all other speakers are used in system training, including the 3 phases discussed in Section 3.3: eigenspace construction (U), 2-class distance measurement (e1dfes, e2 dfes) and detection threshold optimization (Td, Tc and Tk)."}, {"heading": "4.2 Results of Word Verification and N/NN Classification", "text": "Compared to the theoretical error rate in Equation (3), the performance of the mispronunciation recognition system is slightly increased by the numerical error rate PePe = Ne1 + Ne2 N1 + N2, (5) where N1, N2 are the number of test samples from classes 1 and 2, and Ne1, Ne2 is the number of misclassified samples from each class.In word verification, the error rate Pe is always below 3% and 7% for MFCCs and spectrograms, respectively. In the N / NN classification, performance based on HMMs using MFCCs is also compared with the PCA methodology. Figure 7 and 8 show the results of the Leave-One-Distribution-Out method applied to the word aire using PCA and HMMs. The 13 columns in the figure represent the 13 speakers of the word aire in the database. For each column (speaker), there are 5 samples that are compared against the HMS threshold."}, {"heading": "4.3 Results of Syllable-Level Mispronunciation Detection", "text": "In practice, however, only samples that are classified as non-native in the N / NN classification are used. This is because the assumption that two classes of data are separated in eigenspace training and in the Edfes calculation is no longer valid, namely some syllables that may be sufficiently pronounced to be distinguished between native and non-native steps. This is the case because the assumption that two classes of data are separated in eigenspace training and in the Edfes calculation is no longer valid. (Thus, some syllables that are unable to distinguish natively from non-natively can be pronounced well.) The threshold reached with Bayes rules is biased and moves toward the native class, drastically increasing the classification error rate."}, {"heading": "5. CONCLUSION AND FUTURE WORK", "text": "The test results in Section 4 show that PCA can be a computationally efficient approach to detecting misstatements, even when the training and test database is limited. MFCCs are more powerful than spectrograms. Compared to HMMs, the PCA method is much faster and achieves comparable results for the database used in this paper. For future work, the threshold should be optimized at each step on a larger database to improve robustness, which is especially important for optimizing the threshold for syllable-level detection, as subtle differences that occur in syllables require more data to differentiate. Due to the limitations of the PCA method in data separation (discriminatory information may remain in the less significant components), further investigation of the distribution of multiple types of misstatements is also warranted. In addition, hybrid methods based on PCA, LDA (Linear Discriminant Analysis) and IConent (Independent Analysis) should be considered."}], "references": [{"title": "Recognition and pronunciation scoring for language learning,\u201d in [Proc", "author": ["H. Franco", "V. Abrash", "K. Precoda", "H. Bratt", "R. Rao", "J. Butzberger", "R. Rossier", "F. Cesari", "\u201cThe sri eduspeak system"], "venue": "of InSTIL ], 123\u2013128", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Automatic detection of mispronunciation for language instruction,", "author": ["O. Ronen", "L. Neumeyer", "H. Franco"], "venue": "in [Proc. of Eurospeech ],", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Mispronunciation detection based on cross-language phonological comparisons,", "author": ["L. Wang", "X. Feng", "H.M. Meng"], "venue": "[IEEE IET International Conference on Audio, Language and Image Processing ],", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Improving mispronunciation detection and diagnosis of learners\u2019 speech with context-sensitive phonological rules based on language transfer,", "author": ["A. Harrison", "W. Lau", "H. Meng", "L. Wang"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Implementation of an extended recognition network for mispronunciation detection and diagnosis in computer-assisted pronunciation training,", "author": ["A. Harrison", "W. Lo", "X. Qian", "H. Ming"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "A new method for mispronunciation detection using support vector machine based on pronunciation space models,", "author": ["S. Wei", "G. Hu", "Y. Hu", "Wang", "R.-H"], "venue": "Speech Communication 51(10),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Capturing l2 segmental mispronunciations with joint-sequence models in computer-aided pronunciation training (CAPT),", "author": ["X. Qian", "H. Meng", "F. Soong"], "venue": "in [International Symposium on Chinese Spoken Language Processing (ISCSLP) ],", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Data balancing for efficient training of hybrid ANN/HMM automatic speech recognition systems,", "author": ["A.I. Gar\u0107\u0131a-Moral", "R. Solera-Ure\u00f1a", "C. Pel\u00e1ez-Moreno", "F.D. de Ma\u0155\u0131a"], "venue": "IEEE Transactions on Audio, Speech & Language Processing", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "A low-dimensional procedure for the characterization of human faces,", "author": ["L. Sirovich", "M. Kirby"], "venue": "The Journal of the Optical Society of America", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1987}, {"title": "Application of the karhunen-loeve procedure for the characterization of human faces,", "author": ["M. Kirby", "L. Sirovich"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Recognition using class specific linear projection,\u201d IEEE Trans", "author": ["P. Belhumeur", "J. Hespanha", "D. Kriegman", "\u201cEigenfaces vs. fisherfaces"], "venue": "on Pattern Analysis and Machine Intelligence 19(7), 771\u2013720", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "Face recognition using curvelet based pca,", "author": ["T. Mandal", "Q.M.J.Wu"], "venue": "in [Pattern Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Eigenfaces for recognition,", "author": ["M. Turk", "A. Pentland"], "venue": "Journal of Cognitive Neuroscience", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "A tutorial on principal component analysis,", "author": ["J. Shlens"], "venue": "tech. rep., Institute for Nonlinear Science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Principal variance component analysis,", "author": ["S.A. Batch"], "venue": "http://www.niehs.nih.gov/research/resources/software/pvca", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "The Sounds of Spanish: Analysis and Application with special reference to American English", "author": ["R.M. Hammond"], "venue": "Cascadilla", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}], "referenceMentions": [], "year": 2016, "abstractText": "This paper presents a method for detecting mispronunciations with the aim of improving Computer Assisted Language Learning (CALL) tools used by foreign language learners. The algorithm is based on Principle Component Analysis (PCA). It is hierarchical with each successive step refining the estimate to classify the test word as being either mispronounced or correct. Preprocessing before detection, like normalization and time-scale modification, is implemented to guarantee uniformity of the feature vectors input to the detection system. The performance using various features including spectrograms and Mel-Frequency Cepstral Coefficients (MFCCs) are compared and evaluated. Best results were obtained using MFCCs, achieving up to 99% accuracy in word verification and 93% in native/non-native classification. Compared with Hidden Markov Models (HMMs) which are used pervasively in recognition application, this particular approach is computational efficient and effective when training data is limited.", "creator": "LaTeX with hyperref package"}}}