{"id": "1602.08332", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2016", "title": "Bounded Rational Decision-Making in Feedforward Neural Networks", "abstract": "Bounded rational decision-makers transform sensory input into motor output under limited computational resources. Mathematically, such decision-makers can be modeled as information-theoretic channels with limited transmission rate. Here, we apply this formalism for the first time to multilayer feedforward neural networks. We derive synaptic weight update rules for two scenarios, where either each neuron is considered as a bounded rational decision-maker or the network as a whole. In the update rules, bounded rationality translates into information-theoretically motivated types of regularization in weight space. In experiments on the MNIST benchmark classification task for handwritten digits, we show that such information-theoretic regularization successfully prevents overfitting across different architectures and attains state-of-the-art results for both ordinary and convolutional neural networks.", "histories": [["v1", "Fri, 26 Feb 2016 14:15:03 GMT  (39kb,D)", "https://arxiv.org/abs/1602.08332v1", null], ["v2", "Mon, 23 May 2016 15:51:07 GMT  (41kb,D)", "http://arxiv.org/abs/1602.08332v2", "Proceedings of the 32nd Conference on Uncertainty in Artificial Intelligence (UAI), New York City, NY, USA, 2016"]], "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.NE", "authors": ["felix leibfried", "daniel alexander braun"], "accepted": false, "id": "1602.08332"}, "pdf": {"name": "1602.08332.pdf", "metadata": {"source": "CRF", "title": "Bounded Rational Decision-Making in Feedforward Neural Networks", "authors": ["Felix Leibfried", "Daniel A. Braun"], "emails": [], "sections": [{"heading": null, "text": "In mathematical terms, such decision-makers can be modeled as information-theoretical channels with limited transmission rates. In this context, we apply this formalism for the first time to multi-layered, feedback-forward neural networks. From this, we derive synaptic weight-actualization rules for two scenarios, in which either each neuron is considered a bound rational decision-maker or the network as a whole. In the update rules, bound rationality translates into information-theoretically motivated types of regulation in the weight space. In experiments with the MNIST benchmark classification task for handwritten digits, we show that such information-theoretical regulation successfully prevents an overmatch between different architectures and achieves results that compete with other newer techniques such as Dropout, Dropconnect and Bayes by backprop."}, {"heading": "1 INTRODUCTION", "text": "In fact, most people who are able to move are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 BACKGROUND ON BOUNDED RATIONAL DECISION-MAKING", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 A FREE ENERGY PRINCIPLE FOR BOUNDED RATIONALITY", "text": "A decision-maker is faced with the task of selecting an optimal action from a series of actions. Each action y is associated with a specific task-specific utility value (\u03b2 \u03b2) (\u03b2 \u03b2). A fully rational decision-maker selects the action y * that maximizes the benefit function globally, where y * = arg maxy U (y) assumes that the global maximum is unique. However, with limited computational resources, the decision-maker may not be able to identify the globally optimal action y *, leading to the question of how limited computational resources should be quantified. Generally, the decision-maker's behavior can be expressed as a probability distribution across actions p (y). The basic idea of information theory of limited rationality is that changes in such probability distributions are costly and require computational resources. More precisely, computational resources are expressed as optimal costs that are caused by the change from a previous probability strategy (0) to a postabilistic plasy (p)."}, {"heading": "2.2 A RATE DISTORTION PRINCIPLE FOR CONTEXT-DEPENDENT DECISION-MAKING", "text": "In the face of multiple contexts, fully rational decision-making requires finding an optimal plot y for any environment (\u03b2 = \u03b2 = q) in which optimality is defined by a utility function (x, y). Limited rational decision-making in multiple contexts means calculating multiple strategies, expressed as conditional probability distributions p (y | x), among limited computing resources. Limited computing resources are modeled by an upper limit p (y) defined by the expected kullback-Leibler divergence < DKL (p (y) | p0 (y) > p (x) \u2264 B between strategies p (y) and a common previous p0 (y) averaged over all possible environments p (x, 15]. The resulting optimization problem can be formalized as a utility distribution problem (y) = arg max (y)."}, {"heading": "3 THEORETICAL RESULTS: SYNAPTIC WEIGHT UPDATE RULES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 PARAMETERIZED STRATEGIES AND ONLINE RULES", "text": "Calculation of the optimal solution of the interest rate distortion problem in Equation (6) using \u03b2 > U function (7) and (8) by the Blahut-Arimoto algorithm has two serious disadvantages. Firstly, it requires the calculation and storage of conditional strategies p (y | x) and the marginal strategy p (y) explicitly, which is unaffordable for large environmental and action spaces. Secondly, it requires that the decision maker is able to calculate and store the usefulness function for arbitrary environmental action pairs (x, y), which is a plausible assumption in the planning, but not in enhancing learning, where samples from the supply function equation can only be obtained from interactions with the environment. Therefore, we assume a parameterized form of strategy pw (y | x) from which the decision maker can derive samples for a given sample of the environment x, and the objective of the interest rate equation (6) is distored."}, {"heading": "3.2 A STOCHASTIC NEURON AS A BOUNDED RATIONAL DECISION-MAKER", "text": "A stochastic neuron can be considered a limited rational decision-maker [21]: the pre-synaptic input of the neuron is interpreted as an environmental context and the output of the neuron as an action variable. (21) The parameterized strategy of the neuron corresponds to its firing behavior and is initially interpreted as bypw (y | x) = y \u00b7 \u03c1 (w > x) + (1 \u2212 y) \u00b7 (1 \u2212 y) \u00b7 (w > x), (12) where y (0, 1} is a binary variable reflecting the current firing state of the neuron, x is a binary column vector representing the current pre-synaptic input of the neuron, and w is a real column vector representing the strength of pre-synaptic firing. (0; 1) is a monotonically increasing function that represents the current firing probability of the neuron. In a more similar way, the fire behavior of the neuron can be expressed as pw = (y)."}, {"heading": "3.3 A DETERMINISTIC NEURON AS A BOUNDED RATIONAL DECISION-MAKER", "text": "In a deterministic setup, the parameterized firing behavior of neurons in a small time window (> \u03b2-rate) (> \u03b2-rate) (> \u03b2-rate) (> \u03b2-rate) (> \u03b2-rate) (> \u03b2-rate) (> \u03b2-rate) (> \u03b2-rate) can be expressed as: pw (y-rate) = y-rate (w-rate) = y-rate (w-rate) and p-rate (w-rate) = y-rate (w-rate). (Similarly, the mean firing behavior of neurons is given as bypw-rate (y-rate) (rate) (w-rate). (w-rate) (w-rate). (w-rate)."}, {"heading": "3.4 A NEURAL NETWORK OF BOUNDED RATIONAL DETERMINISTIC NEURONS", "text": "Assuming that all neurons aim to maximize a global utility function while minimizing their local mutual information rate, each neuron n can be interpreted as a solution to a deterministic distortion goal in which the utility function is shared between all neurons but the mutual information costs are neuron-specific: wn \u043d = arg max wn (1 \u2212 \u03b2) U (in, f (W, in)) p (in) \u03b2 lim \u00b2 t \u00b2 t \u00b2 (in, yn), (24) where wn, n and yn refer to the presynaptic weight vector, presynaptic firing rates, and the current firing state of neurons n, while W denotes the totality of all weights in the entire neural network."}, {"heading": "3.5 A DETERMINISTIC NEURAL NETWORK AS", "text": "A BOUNDED RATIONAL DECISION MAKERWhile we focus on individual neurons as limited rational decision makers in the previous section, it is also possible to interpret a complete multi-layered perception as a limited rational decision maker. To allow this interpretation, we consider categorical distribution as a limited rational strateypW (W) as a limited rational strategiypW (Y) = a generative distribution probability (26) that generates a binary unit vector y given the input rates and amount of all weights across the network. The average rational strategy is then generated bypW (y) = a binary unit vector y."}, {"heading": "4 EXPERIMENTAL RESULTS: MNIST CLASSIFICATION", "text": "In our simulations, we applied both types of rate distortion regularization (the local type of Section 3.4 and the global type of Section 3.5) to the MNIST benchmark task. [1] Specifically, we investigated to what extent this information-theoretically motivated regularization is subject to generalizations. [2] For this purpose, we chose a network with two hidden levels of rectified linear units [29] and a top layer of 10 softmax units implemented in Lua with Torch. [3] We chose a network with two hidden levels of rectified linear units [4] and an upper layer of 10 softmax units, which selected as the optimization criterion the negative cross-entropy between the class labels and network outputs. [4] U (f,) = [5] j (W,) ln fj (W) (32), where the class outputs themselves as the optimization criterion and the network outputs."}, {"heading": "5 CONCLUSION", "text": "Previously, a synaptic weight updating rule was developed for a single reward-maximizing spiking neuron, in which the neuron was interpreted as a limited rational decision-maker using limited computing resources using distortion theory. [21] It has been shown that such a limited rational weight updating rule leads to efficient regulation by preventing synaptic weights from growing indefinitely. In our current work, we extend these results to deterministic neurons and neural networks. At the MNIST benchmark classification task, we demonstrated the regulatory effect of our approach by successfully preventing networks from becoming overloaded. These results are robust because we have conducted experiments with different network architectures that achieve performance that can be applied with other newer techniques such as Dropout [33], Dropconnect [32] and Bayes by Backprop [10] that it is both an artificially distorted network and a previously competitive network strength, for example, because it is a terrestrial one."}, {"heading": "A APPENDIX", "text": "A.1 MUTUAL INFORMATION RATE OF A DETERMINISTIC NEURONlim (01) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (p) p (0) p (0) p (0) p (0) p (p) p () p () p () p () p) p () p (0) p) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p) p (0) p (0) p) p (p) p (p) p) p () p) p () p) p () p) p () p) p () p () p) p () p) p () p) p (0) p) p (0) p) p (0) p (0) p) p (0) p) p (0) p (0) p) p (0) p) p (0) p) p (0) p) p (0) p) p (0) p (0) p (0) p) p (0) p) p (0) p (0) p (0) p) p (0) p (0) p (0) p (0) p) p (0) p (p) p (0) p (0) p (0) p (0) p) p) p (p (0) p (0) p (0) p (p (0) p (0) p) p (p (0) p (p (0) p (0) p (0) p (0) p) p (p (0) p (p (0) p (p) p) p (p (p (p (0) p) p (p (p (0) p) p) p (0) p"}, {"heading": "Acknowledgements", "text": "This study was supported by the DFG, Emmy Noether Fellowship BR4164 / 1-1."}], "references": [{"title": "Theory of Games and Economic Behavior", "author": ["J von Neumann", "O Morgenstern"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1944}, {"title": "Computational rationality: a converging paradigm for intelligence in brains", "author": ["S J Gershman", "E J Horvitz", "J B Tenenbaum"], "venue": "minds, and machines. Science, 349(6245):273\u2013278", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Theories of bounded rationality", "author": ["H A Simon"], "venue": "Decision and Organization, 1:161\u2013176", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1972}, {"title": "Bounded rationality", "author": ["T Genewein", "F Leibfried", "J Grau-Moya", "D A Braun"], "venue": "abstraction and hierarchical decision-making: an information-theoretic optimality principle. Frontiers in Robotics and AI, 2(27)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Information-theoretic bounded rationality", "author": ["P A Ortega", "D A Braun", "J Dyer", "K-E Kim", "N Tishby"], "venue": "arXiv preprint arXiv:1512.06789", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Thermodynamics as a theory of decision-making with informationprocessing costs", "author": ["P A Ortega", "D A Braun"], "venue": "Proceedings of the Royal Society A, 469", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2153}, {"title": "Rational inattention and monetary economics", "author": ["C A Sims"], "venue": "Handbook of Monetary Economics, volume 3, chapter 4. Elsevier", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Information theory - the bridge connecting bounded rational game theory and statistical physics", "author": ["D H Wolpert"], "venue": "Complex Engineered Systems, chapter 12. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Probabilistic choice and procedurally bounded rationality", "author": ["L G Mattsson", "J W Weibull"], "venue": "Games and Economic Behavior, 41(1):61\u201378", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Weight uncertainty in neural networks", "author": ["C Blundell", "J Cornebise", "K Kavukcuoglu", "D Wierstra"], "venue": "Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Lossy is lazy", "author": ["S Still"], "venue": "Workshop on Information Theoretic Methods in Science and Engineering, pages 17\u201321", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Ratedistortion auto-encoders", "author": ["L G Sanchez Giraldo", "J C Principe"], "venue": " arXiv preprint arXiv:1312.7381", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimal control as a graphical model inference problem", "author": ["H J Kappen", "V G\u00f3mez", "M Opper"], "venue": "Machine Learning, 87(2):159\u2013182", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "On stochastic optimal control and reinforcement learning by approximate inference", "author": ["K Rawlik", "M Toussaint", "S Vijayakumar"], "venue": "Proceedings Robotics: Science and Systems", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Trading value and information in MDPs", "author": ["J Rubin", "O Shamir", "N Tishby"], "venue": "Decision Making with Imperfect Decision Makers, chapter 3. Springer", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Information theory of decisions and actions", "author": ["N Tishby", "D Polani"], "venue": "Perception-Action Cycle, chapter 19. Springer", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "The free-energy principle: a unified brain theory? Nature Reviews Neuroscience", "author": ["K Friston"], "venue": "11(2):127\u2013 138", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Relative entropy policy search", "author": ["J Peters", "K Muelling", "Y Altun"], "venue": "Proceedings of the National Conference on Artificial Intelligence", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Information-theoretic approach to interactive learning", "author": ["S Still"], "venue": "Europhysics Letters, 85(2):28005", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Efficient computation of optimal actions", "author": ["E Todorov"], "venue": "Proceedings of the National Academy of Sciences of the United States of America, 106(28):11478\u201311483", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "A reward-maximizing spiking neuron as a bounded rational decision maker", "author": ["F Leibfried", "D A Braun"], "venue": "Neural Computation, 27(8):1686\u2013720", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning in neural networks by reinforcement of irregular spiking", "author": ["X Xie", "H S Seung"], "venue": "Physical Review E, 69(4 Pt 1):041909", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "The information bottleneck method", "author": ["N Tishby", "F C Pereira", "W Bialek"], "venue": "Proceedings of the 37th Annual Allerton Conference on Communication, Control and Computing, pages 368\u2013377", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Coding theorems for a discrete source with a fidelity criterion", "author": ["C E Shannon"], "venue": "Institute of Radio Engineers, International Convention Record, 7:142\u2013163", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1959}, {"title": "An algorithm for computing the capacity of arbitrary discrete memoryless channels", "author": ["S Arimoto"], "venue": "IEEE Transactions on Information Theory, 18(1):14\u201320", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1972}, {"title": "Computation of channel capacity and ratedistortion functions", "author": ["R Blahut"], "venue": "IEEE Transactions on Information Theory, 18(4):460\u2013473", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1972}, {"title": "On the computation of rate-distortion functions", "author": ["I. Csiszar"], "venue": "IEEE Transactions on Information Theory, 20(1):122\u2013124", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1974}, {"title": "Efficient backprop", "author": ["Y LeCun", "L Bottou", "G B Orr", "K R M\u00fcller"], "venue": "Neural Networks: Tricks of the Trade, volume 1524, chapter 2, pages 9\u201350. Springer Berlin Heidelberg", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1998}, {"title": "Deep sparse rectifier neural networks", "author": ["X Glorot", "A Bordes", "Y Bengio"], "venue": "Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pages 315\u2013323", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Torch7: a matlab-like environment for machine learning", "author": ["R Collobert", "K Kavukcuoglu", "C Farabet"], "venue": "BigLearn, NIPS Workshop. No. EPFL-CONF- 192376", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Best practices for convolutional neural networks applied to visual document analysis", "author": ["P Y Simard", "D Steinkraus", "J C Platt"], "venue": "Proceedings of the Seventh International Conference on Document Analysis and Recognition", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2003}, {"title": "Regularization of neural networks using dropconnect", "author": ["L Wan", "M Zeiler", "S Zhang", "Y LeCun", "R Fergus"], "venue": "Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Dropout : a simple way to prevent neural networks from overfitting", "author": ["N Srivastava", "G E Hinton", "A Krizhevsky", "I Sutskever", "R Salakhutdinov"], "venue": "Journal of Machine Learning Research, 15:1929\u20131958", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "An important idea, originating from the foundations of decision theory, is the principle of maximum expected utility [1].", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": "One way of taking computational resources into account is to study optimal decisionmaking under information-processing constraints [2, 3].", "startOffset": 131, "endOffset": 137}, {"referenceID": 2, "context": "One way of taking computational resources into account is to study optimal decisionmaking under information-processing constraints [2, 3].", "startOffset": 131, "endOffset": 137}, {"referenceID": 3, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 89, "endOffset": 98}, {"referenceID": 4, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 89, "endOffset": 98}, {"referenceID": 5, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 89, "endOffset": 98}, {"referenceID": 6, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 146, "endOffset": 155}, {"referenceID": 7, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 146, "endOffset": 155}, {"referenceID": 8, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 146, "endOffset": 155}, {"referenceID": 9, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 10, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 11, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 12, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 13, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 14, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 15, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 16, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 17, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 18, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 19, "context": "In this study, we use an information-theoretic model of bounded rational decision-making [4, 5, 6] that has precursors in the economic literature [7, 8, 9] and that is closely related to recent advances harnessing information theory for machine learning and perception-action systems [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].", "startOffset": 284, "endOffset": 328}, {"referenceID": 20, "context": "Previously, this information-theoretic bounded rationality model was applied to derive a synaptic weight update rule for a single reward-maximizing spiking neuron [21].", "startOffset": 163, "endOffset": 167}, {"referenceID": 21, "context": "The bounded rational weight update rule furthermore generalizes the synaptic weight update rule for an ordinary reward-maximizing spiking neuron as presented for example in [22].", "startOffset": 173, "endOffset": 177}, {"referenceID": 9, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 4, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 5, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 12, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 13, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 14, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 16, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 17, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 18, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 19, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 7, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 8, "context": "Mathematically, this informational cost is given by the Kullback-Leibler divergence DKL(p(y)||p0(y)) \u2264 B between prior and posterior strategy, where computational resources are modeled as an upper bound B \u2265 0 [10, 5, 6, 13, 14, 15, 17, 18, 19, 20, 8, 9].", "startOffset": 209, "endOffset": 253}, {"referenceID": 3, "context": "Limited computational resources are modeled through an upper bound B \u2265 0 on the expected Kullback-Leibler divergence \u3008DKL(p(y|x)||p0(y))\u3009p(x) \u2264 B between the strategies p(y|x) and a common prior p0(y), averaged over all possible environments described by the distribution p(x) [4, 15].", "startOffset": 277, "endOffset": 284}, {"referenceID": 14, "context": "Limited computational resources are modeled through an upper bound B \u2265 0 on the expected Kullback-Leibler divergence \u3008DKL(p(y|x)||p0(y))\u3009p(x) \u2264 B between the strategies p(y|x) and a common prior p0(y), averaged over all possible environments described by the distribution p(x) [4, 15].", "startOffset": 277, "endOffset": 284}, {"referenceID": 22, "context": "It can be shown that the most economic prior p0(y) is given by the marginal distribution p0(y) = p(y) = \u2211 x p(y|x)p(x), because the marginal distribution minimizes the expected KullbackLeibler divergence for a given set of conditional distributions p(y|x)\u2014see [23].", "startOffset": 260, "endOffset": 264}, {"referenceID": 3, "context": "In this case, the expected KullbackLeibler divergence becomes identical to the mutual information I(x, y) between the environment x and the action y [4, 21, 11, 12, 7, 16].", "startOffset": 149, "endOffset": 171}, {"referenceID": 20, "context": "In this case, the expected KullbackLeibler divergence becomes identical to the mutual information I(x, y) between the environment x and the action y [4, 21, 11, 12, 7, 16].", "startOffset": 149, "endOffset": 171}, {"referenceID": 10, "context": "In this case, the expected KullbackLeibler divergence becomes identical to the mutual information I(x, y) between the environment x and the action y [4, 21, 11, 12, 7, 16].", "startOffset": 149, "endOffset": 171}, {"referenceID": 11, "context": "In this case, the expected KullbackLeibler divergence becomes identical to the mutual information I(x, y) between the environment x and the action y [4, 21, 11, 12, 7, 16].", "startOffset": 149, "endOffset": 171}, {"referenceID": 6, "context": "In this case, the expected KullbackLeibler divergence becomes identical to the mutual information I(x, y) between the environment x and the action y [4, 21, 11, 12, 7, 16].", "startOffset": 149, "endOffset": 171}, {"referenceID": 15, "context": "In this case, the expected KullbackLeibler divergence becomes identical to the mutual information I(x, y) between the environment x and the action y [4, 21, 11, 12, 7, 16].", "startOffset": 149, "endOffset": 171}, {"referenceID": 23, "context": "which is mathematically equivalent to the rate distortion problem from information theory [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 24, "context": "This procedure is known as Blahut-Arimoto algorithm [25, 26] and is guaranteed to converge to a global optimum [27] presupposed that q(y) does not assign zero probability mass to any y.", "startOffset": 52, "endOffset": 60}, {"referenceID": 25, "context": "This procedure is known as Blahut-Arimoto algorithm [25, 26] and is guaranteed to converge to a global optimum [27] presupposed that q(y) does not assign zero probability mass to any y.", "startOffset": 52, "endOffset": 60}, {"referenceID": 26, "context": "This procedure is known as Blahut-Arimoto algorithm [25, 26] and is guaranteed to converge to a global optimum [27] presupposed that q(y) does not assign zero probability mass to any y.", "startOffset": 111, "endOffset": 115}, {"referenceID": 20, "context": "We therefore assume a parameterized form of the strategy pw(y|x), from which the decision-maker can draw samples y for a given sample of the environment x, and optimize the rate distortion objective from Equation (6) with help of gradient ascent [21]\u2014also referred to as policy gradient in the reinforcement learning literature [22].", "startOffset": 246, "endOffset": 250}, {"referenceID": 21, "context": "We therefore assume a parameterized form of the strategy pw(y|x), from which the decision-maker can draw samples y for a given sample of the environment x, and optimize the rate distortion objective from Equation (6) with help of gradient ascent [21]\u2014also referred to as policy gradient in the reinforcement learning literature [22].", "startOffset": 328, "endOffset": 332}, {"referenceID": 20, "context": "Previously, Equation (11) was applied to a single spiking neuron that was stochastic [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "A stochastic neuron may be considered as a bounded rational decision-maker [21]: the neuron\u2019s presynaptic input is", "startOffset": 75, "endOffset": 79}, {"referenceID": 20, "context": "where \u03c4 is a constant defining the time horizon [21].", "startOffset": 48, "endOffset": 52}, {"referenceID": 20, "context": "1 [21].", "startOffset": 2, "endOffset": 6}, {"referenceID": 20, "context": "By averaging over the binary quantity y, a more concise weight update rule is derived [21]:", "startOffset": 86, "endOffset": 90}, {"referenceID": 27, "context": "The derivative of the utility function with respect to the weight \u2202 \u2202wn i U(\u03be , f(W, \u03be)) can be straightforwardly derived via ordinary backpropagation [28].", "startOffset": 151, "endOffset": 155}, {"referenceID": 27, "context": "Note that the derivative of the rate distortion objective \u2202 \u2202wn i L(W) takes a convenient form which can be easily computed by extending ordinary backpropagation [28].", "startOffset": 162, "endOffset": 166}, {"referenceID": 28, "context": "For all our simulations, we used a network with two hidden layers of rectified linear units [29] and a top layer of 10 softmax units implemented in Lua with Torch [30].", "startOffset": 92, "endOffset": 96}, {"referenceID": 29, "context": "For all our simulations, we used a network with two hidden layers of rectified linear units [29] and a top layer of 10 softmax units implemented in Lua with Torch [30].", "startOffset": 163, "endOffset": 167}, {"referenceID": 30, "context": "We chose as optimization criterion the negative cross entropy between the class labels and the network output [31]", "startOffset": 110, "endOffset": 114}, {"referenceID": 9, "context": "Table 1: Classification Errors on the MNIST Test Set in the Permutation Invariant Setup Method #neu Error [%] Bayes by backprop [10] 1200 1.", "startOffset": 128, "endOffset": 132}, {"referenceID": 31, "context": "32 Dropout [32] 800 1.", "startOffset": 11, "endOffset": 15}, {"referenceID": 31, "context": "28 Dropconnect [32] 800 1.", "startOffset": 15, "endOffset": 19}, {"referenceID": 32, "context": "20 Dropout [33] 4096 1.", "startOffset": 11, "endOffset": 15}, {"referenceID": 32, "context": "01% [33] and 1.", "startOffset": 4, "endOffset": 8}, {"referenceID": 31, "context": "28% [32]), dropconnect (1.", "startOffset": 4, "endOffset": 8}, {"referenceID": 31, "context": "20% [32]) and Bayes by backprop (1.", "startOffset": 4, "endOffset": 8}, {"referenceID": 9, "context": "32% [10]).", "startOffset": 4, "endOffset": 8}, {"referenceID": 31, "context": "2) to a convolutional neural network with an architecture according to [32]\u2014see Section B.", "startOffset": 71, "endOffset": 75}, {"referenceID": 31, "context": "2 in [32]\u2014attaining an error of 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 31, "context": "59% [32]) and dropconnect (0.", "startOffset": 4, "endOffset": 8}, {"referenceID": 31, "context": "63% [32]).", "startOffset": 4, "endOffset": 8}, {"referenceID": 32, "context": "In line with [33], we preprocessed the input with ZCA whitening and added a max-norm regularizer to limit the size of presynaptic weight vectors to at most 3.", "startOffset": 13, "endOffset": 17}, {"referenceID": 31, "context": "Table 2: Classification Errors on the MNIST Test Set in the Permutation Non-Invariant Setup Method Error [%] Conv net + Dropconnect [32] 0.", "startOffset": 132, "endOffset": 136}, {"referenceID": 31, "context": "61 Conv net + Dropout [32] 0.", "startOffset": 22, "endOffset": 26}, {"referenceID": 20, "context": "Previously, a synaptic weight update rule for a single reward-maximizing spiking neuron was devised, where the neuron was interpreted as a bounded rational decisionmaker under limited computational resources with help of rate distortion theory [21].", "startOffset": 244, "endOffset": 248}, {"referenceID": 32, "context": "These results are robust as we conducted experiments with different network architectures achieving performance competitive with other recent techniques like dropout [33], dropconnect [32] and Bayes by backprop [10] for both ordinary and convolutional networks.", "startOffset": 166, "endOffset": 170}, {"referenceID": 31, "context": "These results are robust as we conducted experiments with different network architectures achieving performance competitive with other recent techniques like dropout [33], dropconnect [32] and Bayes by backprop [10] for both ordinary and convolutional networks.", "startOffset": 184, "endOffset": 188}, {"referenceID": 9, "context": "These results are robust as we conducted experiments with different network architectures achieving performance competitive with other recent techniques like dropout [33], dropconnect [32] and Bayes by backprop [10] for both ordinary and convolutional networks.", "startOffset": 211, "endOffset": 215}, {"referenceID": 11, "context": "Parameterized policies that optimize the rate distortion objective have been previously applied to unsupervised density estimation tasks with autoencoder networks [12].", "startOffset": 163, "endOffset": 167}], "year": 2016, "abstractText": "Bounded rational decision-makers transform sensory input into motor output under limited computational resources. Mathematically, such decision-makers can be modeled as informationtheoretic channels with limited transmission rate. Here, we apply this formalism for the first time to multilayer feedforward neural networks. We derive synaptic weight update rules for two scenarios, where either each neuron is considered as a bounded rational decision-maker or the network as a whole. In the update rules, bounded rationality translates into information-theoretically motivated types of regularization in weight space. In experiments on the MNIST benchmark classification task for handwritten digits, we show that such information-theoretic regularization successfully prevents overfitting across different architectures and attains results that are competitive with other recent techniques like dropout, dropconnect and Bayes by backprop, for both ordinary and convolutional neural networks.", "creator": "LaTeX with hyperref package"}}}