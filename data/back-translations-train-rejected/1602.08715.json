{"id": "1602.08715", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2016", "title": "Identification of Parallel Passages Across a Large Hebrew/Aramaic Corpus", "abstract": "We propose a method for efficiently finding all parallel passages in a large corpus, even if the passages are not quite identical due to rephrasing and orthographic variation. The key ideas are the representation of each word in the corpus by its two most infrequent letters, finding matched pairs of strings of four or five words that differ by at most one word and then identifying clusters of such matched pairs. Using this method, over 4600 parallel pairs of passages were identified in the Babylonian Talmud, a Hebrew-Aramaic corpus of over 1.8 million words, in just over 30 seconds. Empirical comparisons on sample data indicate that the coverage obtained by our method is essentially the same as that obtained using slow exhaustive methods.", "histories": [["v1", "Sun, 28 Feb 2016 13:43:33 GMT  (131kb)", "http://arxiv.org/abs/1602.08715v1", "Submission to the Journal of Data Mining and Digital Humanities (Special Issue on Computer-Aided Processing of Intertextuality in Ancient Languages)"]], "COMMENTS": "Submission to the Journal of Data Mining and Digital Humanities (Special Issue on Computer-Aided Processing of Intertextuality in Ancient Languages)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["avi shmidman", "moshe koppel", "ely porat"], "accepted": false, "id": "1602.08715"}, "pdf": {"name": "1602.08715.pdf", "metadata": {"source": "CRF", "title": "Identification of Parallel Passages Across a Large Hebrew/Aramaic Corpus", "authors": ["Avi Shmidman", "Moshe Koppel", "Ely Porat"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of them are able to set out in search of a new home."}, {"heading": "I Description of the Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1 Per-word Preprocessing", "text": "In fact, it is so that we will be able to move the two letters in the same direction, in the same direction in which they are located. In fact, the letters are able to move the letters in the same direction. In fact, the letters are able to go in the same direction, and the letters are able to move in the same direction. In fact, the letters have gone in the same direction, and the letters have gone in the same direction, and the letters have gone in the same direction."}, {"heading": "1.2 N-grams and Skip-grams", "text": "The basic unit of comparison within our algorithm is an n-gram of length 4; that is, we must allow the word exchanges and interpolations in which the parallel word sequences contain a word in the middle that is completely different, or that exists in one sequence but not in the other."}, {"heading": "1.3 Indexing the Skip-grams", "text": "As a general rule, n-gram-based algorithms would, at this point, go to calculate a RabinKarp numerical hash of each n-gram [Karp and Rabin, 1987] to index for quick recovery, but using such hashes can slow performance due to potential collisions. Fortunately, we can use our two-letter reduction method (detailed in section 1.1) to efficiently index our jumps without hash collisions. As mentioned in the previous section, each skip gram consists of four words, each represented by two letters. There are a total of 22 letters in Hebrew and Aramaic languages (we count final letters as regular shapes), and since each skip gram is effectively a permutation of 8 such letters, there are a total of 228 possibilities - just under 55 billion. We can therefore clearly represent each skip gram with a single 64-bit integer."}, {"heading": "1.4 Identifying clusters of skip-grams", "text": "As we have seen above, our skip grams are only 4 words long, and in addition, they are based on double reductions of words. What we really need to find to confirm a given match is a cluster of matching skip grams [Grozea et al, 2009]. For our purposes, we define a cluster as follows: a set of i or more matching skip grams with gaps of no more than j words between the skip grams, which extend over a total number of at least k words from the beginning of the first skip program to the end of the last. For this paper, we use the values i = 3, j = 8, k = 20. An important advantage of this method is that we are able to skip passages in which phrases are interpolated up to 8 words in length in one or the other of the skip places."}, {"heading": "II Results", "text": "Our algorithm, which runs in a single thread, takes just over 30 seconds to complete its analysis of the entire Babylonian Talmud, including pre-processing, indexing and matching programs and identifying clusters. This is a dramatic improvement over the many thousands of hours it would have taken to arrive at the same results through editdistance callations.7 Journal of Data Mining and Digital Humanities http: / / jdmdh.episciences.org ISSN 2416-5999. Our algorithm has identified a total of 4602 pairs of parallel passages in the Talmud of 20 words or more in length, totaling 130,242 words (counting each pair of parallel passages once), working at an average of 3.3 parallel passages on the Talmud side."}, {"heading": "III Auto-generating a Thesaurus", "text": "In fact, most of them are able to decide for themselves how they want to."}, {"heading": "IV Conclusions", "text": "In this paper, we have presented an effective method for identifying texts in large corporations of Hebrew and Aramaic texts - a task previously considered a formidable challenge with many millions of words. Because our algorithm builds its list of potential matches from a single procedural step, it can process texts of any size in O (N) time, allowing it to respond well to text containing many millions of words."}], "references": [{"title": "A Closer Look at Skip-gram Modelling", "author": ["D. Guthrie", "B. Allison", "W. Liu", "L. Guthrie", "Y. Wilks"], "venue": "Proceedings of the 5th International Conference on Language Resources and Evaluation", "citeRegEx": "Guthrie et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Guthrie et al\\.", "year": 2006}, {"title": "ENCOPLOT: Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection. 3rd PAN Workshop. Uncovering Plagiarism, Authorship and Social Software Misuse", "author": ["C. Grozea", "C. Gehl", "M. Popescu"], "venue": "Harris Z., Distributional structure", "citeRegEx": "Grozea et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Grozea et al\\.", "year": 2009}, {"title": "Efficient randomized pattern-matching algorithms", "author": ["R. Karp", "M.O. Rabin"], "venue": "IBM Journal of Research and Development", "citeRegEx": "Karp and Rabin,? \\Q1987\\E", "shortCiteRegEx": "Karp and Rabin", "year": 1987}, {"title": "Finding Inexact Quotations Within a Tibetan Buddhist Corpus", "author": ["E. Klein", "N. Dershowitz", "L. Wolf", "O. Almogi", "D. Wangchuk"], "venue": "Digital Humanities", "citeRegEx": "Klein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2014}, {"title": "Measures of distributional similarity. 37th Annual Meeting of the Association for Computational Linguistics", "author": ["L. Lee"], "venue": null, "citeRegEx": "Lee,? \\Q1999\\E", "shortCiteRegEx": "Lee", "year": 1999}, {"title": "Towards a theory of semantic space", "author": ["W. Lowe"], "venue": "Proceedings of the 23rd Annual Meeting of the Cognitive Science Society", "citeRegEx": "Lowe,? \\Q2001\\E", "shortCiteRegEx": "Lowe", "year": 2001}, {"title": "Exact and Approximate Pattern Matching in the Streaming Model", "author": ["B Porat", "E. Porat"], "venue": null, "citeRegEx": "Porat and Porat,? \\Q2009\\E", "shortCiteRegEx": "Porat and Porat", "year": 2009}], "referenceMentions": [{"referenceID": 6, "context": "Identifying skip-grams in a text is special case of the k-mismatch problem in approximate pattern matching for which surprisingly efficient algorithms have been found [Porat and Porat, 2009].", "startOffset": 167, "endOffset": 190}, {"referenceID": 2, "context": "As a general rule, n-gram-based algorithms would, at this point, proceed to compute a RabinKarp numerical hash of each n-gram [Karp and Rabin, 1987], in order to index them for quick retrieval.", "startOffset": 126, "endOffset": 148}, {"referenceID": 4, "context": "Of course, the identification of synonyms based on similarity of usage in corpora is a venerable idea [Harris, 1954]; for our purposes, we propose using substitutability in parallel texts rather than more general distributional similarity, as has been typical in previous work [Lee, 1999; Lowe, 2001].", "startOffset": 277, "endOffset": 300}, {"referenceID": 5, "context": "Of course, the identification of synonyms based on similarity of usage in corpora is a venerable idea [Harris, 1954]; for our purposes, we propose using substitutability in parallel texts rather than more general distributional similarity, as has been typical in previous work [Lee, 1999; Lowe, 2001].", "startOffset": 277, "endOffset": 300}], "year": 2016, "abstractText": "We propose a method for efficiently finding all parallel passages in a large corpus, even if the passages are not quite identical due to rephrasing and orthographic variation. The key ideas are the representation of each word in the corpus by its two most infrequent letters, finding matched pairs of strings of four or five words that differ by at most one word and then identifying clusters of such matched pairs. Using this method, over 4600 parallel pairs of passages were identified in the Babylonian Talmud, a Hebrew-Aramaic corpus of over 1.8 million words, in just over 30 seconds. Empirical comparisons on sample data indicate that the coverage obtained by our method is essentially the same as that obtained using slow exhaustive methods.", "creator": "PScript5.dll Version 5.2.2"}}}