{"id": "1603.00522", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2016", "title": "Solving Combinatorial Games using Products, Projections and Lexicographically Optimal Bases", "abstract": "In order to find Nash-equilibria for two-player zero-sum games where each player plays combinatorial objects like spanning trees, matchings etc, we consider two online learning algorithms: the online mirror descent (OMD) algorithm and the multiplicative weights update (MWU) algorithm. The OMD algorithm requires the computation of a certain Bregman projection, that has closed form solutions for simple convex sets like the Euclidean ball or the simplex. However, for general polyhedra one often needs to exploit the general machinery of convex optimization. We give a novel primal-style algorithm for computing Bregman projections on the base polytopes of polymatroids. Next, in the case of the MWU algorithm, although it scales logarithmically in the number of pure strategies or experts $N$ in terms of regret, the algorithm takes time polynomial in $N$; this especially becomes a problem when learning combinatorial objects. We give a general recipe to simulate the multiplicative weights update algorithm in time polynomial in their natural dimension. This is useful whenever there exists a polynomial time generalized counting oracle (even if approximate) over these objects. Finally, using the combinatorial structure of symmetric Nash-equilibria (SNE) when both players play bases of matroids, we show that these can be found with a single projection or convex minimization (without using online learning).", "histories": [["v1", "Tue, 1 Mar 2016 23:02:38 GMT  (56kb,D)", "http://arxiv.org/abs/1603.00522v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["swati gupta", "michel goemans", "patrick jaillet"], "accepted": false, "id": "1603.00522"}, "pdf": {"name": "1603.00522.pdf", "metadata": {"source": "CRF", "title": "Solving Combinatorial Games using Products, Projections and Lexicographically Optimal Bases", "authors": ["Swati Gupta", "Michel Goemans", "Patrick Jaillet"], "emails": ["SWATIG@MIT.EDU", "GOEMANS@MATH.MIT.EDU", "JAILLET@MIT.EDU"], "sections": [{"heading": "1. Introduction", "text": "This year it is so far that it is only a matter of time before it is so far, until it is so far."}, {"heading": "1.1. Online Mirror Descent", "text": "Although the online mirror parentage algorithm is nearly optimal for most online learning problems (Srebro et al. (2011), it is not computationally efficient. One of the crucial steps in the field of the mirror parentage algorithm is that it focuses on the strategic polytopy, which has a separable form for simple cases such as the Euclid ball, and that is why such polytopias are the focus of attention."}, {"heading": "1.2. Multiplicative Weights Update", "text": "The Multiplicative Weights Update (MWU) algorithms by maintaining a probability distribution over all the pure strategies of each player and multiplying the probability distribution in response to the opposing strategy. O (N) is the number of iterations that the MWU algorithm needs to converge to an approximate strategy due to the necessary updating of the probabilities of each pure strategy. A natural question is whether the MWU algorithm can be adapted to the number of strategies."}, {"heading": "1.3. Structure of symmetric Nash equilibria", "text": "It is important for them to be able to solve the problem in the general case."}, {"heading": "2. Related work", "text": "The general problem of finding Nash equilibria in 2-player games is PPAD-complete (Chen et al. (2009), Daskalakis et al. (2009). Restriction to 2-player zero-sum games without any assumptions about the structure of loss functions, asymptotic upper and lower limits (order O (logN / 2)) to support the - approximate Nash equilibria with N-pure strategies are known (Altho-fer (1994), Lipton et al. (2003), Feder et al. (2007). These results conduct a search for the support of Nash equilibria and it is not known how to find Nash equilibria for large two-player zero-sum games in time logarithmically in the number of pure strategies of players."}, {"heading": "3. Preliminaries", "text": "In a two-player zero-sum game with loss (or payout) is the matrix R-RM-N, a mixed strategy x (or y) for the series of players (or column players) who try to minimize their strategies (or maximize their strategies). A pair of mixed strategies (x-R) is designated as an assignment x-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-R-"}, {"heading": "4. Online mirror descent", "text": "In this section, we will show how to perform mirror reflexes faster by using algorithms for minimizing strongly convex functions over base polytopes of polymatroids. Let's consider a compact convex set X-Rn, and let D-Rn be a convex open set, so that X is included in its closure. A mirror map (or distance-generating function) is a k-strongly convex-functioning and differentiable function that fulfills additional properties of the divergence of gradient at the boundary of D, i.e., limx \u2192 D-rape (x) is a k-strongly convex (for details, refer to Nemirovski and Yudin (1983), Beck and Teboulle (2003), Bubeck (2014). In particular, we will consider two important mirror cards in this work, the Euclidean mirror card and the unstandardized mirror card."}, {"heading": "4.1. Convex Minimization on Base Polytopes of Polymatroids", "text": "In this context, it is also necessary that the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU, the EU Commission, the EU Commission, the EU Commission, the EU, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the EU Commission, the Commission, the EU Commission, the EU Commission, the Commission, the Commission, the EU, the Commission, the Commission, the Commission, the EU, the EU, the Commission, the Commission, the Commission, the EU, the Commission, the EU, the Commission, the EU, the Commission, the Commission, the Commission, the EU, the Commission, the EU, the Commission, the Commission, the EU, the Commission, the EU, the Commission, the Commission, the EU, the Commission, the Commission, the Commission, the EU, the Commission, the EU, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the EU, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the EU, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission, the Commission,"}, {"heading": "4.2. Bregman Projections under the Entropy and Euclidean Mirror Maps", "text": "Next, we will discuss the application of the INC-FIX algorithm to two important mirror cards. A feature that both have in common is that the orbit of x in INC-FIX is altogether linear, and the main step is to find the maximum possible increase of x in a certain direction. (Unnormalized entropy map This map is given by x (e). (e) \u2212 E x (e) lnx (e) - E (e) - E (e) and its divergence is the maximum possible increase of x in a certain direction. (e) ln (e) ln (e) / y (e) - E x (e) - E (e) - E y y (e). Note that the divergence (e) for a given y > 0. Finally, D \u2212 1) = ye \u2212 x. To minimize the divergence (x) in relation to a given point, we use the INC-FIX-FIX algorithms."}, {"heading": "5. The Multiplicative Weights Update Algorithm", "text": "We now limit our attention to MSP games above 0 / 1 strategy polytopes P and Q, so that U = vert (P) (0, 1) m and V = vert (Q) (0, 1) n. The vertices of these polytopes form the pure strategies of these games (i.e., combinatorial concepts such as spanning trees, deletions, k-sets). We check the Multiplicative Weight Update (MWU) algorithm for MSP games via strategy polytopes P and Q. The MWU algorithm starts with the uniform distribution across all vertices and simulates an iterative procedure in which the learner (say player 1) plays a mixed strategy game x (t) in each round. In response, the ORACLE selects the most opposing loss vector for the learner, i.e. l (t) = Lv (t) = lv (t) = arg maxy Q (t) Ly."}, {"heading": "5.1. MWU in Polynomial Time", "text": "We show how we can simulate the MWU algorithms in the time in which we use the MWU algorithms in the time of distribution losses, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU product algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms, which we use in the time of the MWU algorithms in the time of the MWU algorithms, which we use in the time of the production algorithms of the MWU algorithms, which we use in the time of the time of the MWU algorithms in the time of the MWU algorithms, which we use in the time of the MWU algorithms we use in the time of the time of the MWU algorithms, which we use in the time of the MWU in the time of the MWU algorithms we use in the time of the MWU algorithms, which we use in the time of the MWU in the time of the time of the MWU algorithms of the MWU algorithms in the time of the MWU algorithms we use in the time of the MWU algorithms, which we use in the time of the MWU in the time of the MWU in the time of the MWU algorithms we use in the time of the MWU algorithms, which we use in the time of the MWU in the production algorithms we use the time of the MWU in the time of the MWU in the time of the MWU algorithms, which we use"}, {"heading": "6. Symmetric Nash-equilibria", "text": "In this section we have a series of optimal strategies so that both players play the exact same mixed strategy in equilibrium games. We assume here that the strategies of the two players are the same. In this section we set necessary and sufficient conditions for a symmetrical equilibrium function: E \u2192 R +. Let L be the loss matrix for the player so that it is symmetrical, i.e. LT = L. Let us leave x = L. Let us leave x (M) = x x x x (S)."}, {"heading": "Appendix A. Mirror Descent", "text": "Lemma 15 The unnormalized entropy map, \u03c9 (x) = \u2211 n i = 1 xi lnxi \u2212 \u2211 ni = 1 xi, is 1-strongly convex with respect to the L1 standard over each matroid base polytopic B (f) = {x-RE: x (E) = r (E), x (E (S) \u2264 r (S) \u2022 S E, x \u2265 0}. Proof We have \u03c9 (x) \u2212 \u03c9 (y) \u2212 E (y) T (x \u2212 y) = E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E (5) = E-E-E-E-E-E-E-E-E (5) = E-E-E-E-E-E-E-E (xe / ye) \u2265 (1) 2 (E-E-E-E-E-E) 2 = 1 2 | x \u2212 y | 21, (6) where (1) follows from Pinskers inequality."}, {"heading": "Appendix B. Multiplicative Weights Update Algorithm", "text": "(1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T) T (1) T (1) T (1) T) T (1) T (1) T (1) T) T (1) T (1) T (1) T (1) T) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1) T (1 (1) T (1) T (1) T (1 (1) T (1) T (1 (1) T (1) T (1) T (1) T (1 (1) T (1 (1) T (1) T (1 (1) T (1) T (1 (1) T (1) T (1) T (1 (1 (1) T (1 (1) T (1) T (1) T (1) T (1 (1) T (1 (1) T (1 (1"}], "references": [{"title": "Improved Bounds for Online Learning Over the Permutahedron and Other Ranking Polytopes", "author": ["N. Ailon"], "venue": "Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Ailon.,? \\Q2014\\E", "shortCiteRegEx": "Ailon.", "year": 2014}, {"title": "On sparse approximations to randomized strategies and convex combinations", "author": ["I. Alth\u00f6fer"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "Alth\u00f6fer.,? \\Q1994\\E", "shortCiteRegEx": "Alth\u00f6fer.", "year": 1994}, {"title": "The Multiplicative Weights Update Method: a Meta-Algorithm and Applications", "author": ["S. Arora", "E. Hazan", "S. Kale"], "venue": "Theory of Computing,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "An O (log n/log log n)approximation Algorithm for the Asymmetric Traveling Salesman Problem", "author": ["A. Asadpour", "M.X. Goemans", "A. Madry", "S. Oveis Gharan", "A. Saberi"], "venue": null, "citeRegEx": "Asadpour et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Asadpour et al\\.", "year": 2010}, {"title": "Regret in online combinatorial optimization", "author": ["J. Audibert", "S. Bubeck", "G. Lugosi"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Audibert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2013}, {"title": "On the problem of approximating the number of bases of a matriod", "author": ["Y. Azar", "A.Z. Broder", "A.M. Frieze"], "venue": "Information processing letters,", "citeRegEx": "Azar et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Azar et al\\.", "year": 1994}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["A. Beck", "M. Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "Beck and Teboulle.,? \\Q2003\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2003}, {"title": "Lectures on modern convex optimization: analysis, algorithms, and engineering applications, volume", "author": ["A. Ben-Tal", "A. Nemirovski"], "venue": null, "citeRegEx": "Ben.Tal and Nemirovski.,? \\Q2001\\E", "shortCiteRegEx": "Ben.Tal and Nemirovski.", "year": 2001}, {"title": "Regret minimization and the price of total anarchy", "author": ["A. Blum", "M.T. Hajiaghayi", "K. Ligett", "A. Roth"], "venue": "Proceedings of the fortieth annual ACM symposium on Theory of computing,", "citeRegEx": "Blum et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2008}, {"title": "Introduction to online optimization", "author": ["S. Bubeck"], "venue": "Lecture Notes,", "citeRegEx": "Bubeck.,? \\Q2011\\E", "shortCiteRegEx": "Bubeck.", "year": 2011}, {"title": "Theory of Convex Optimization for Machine Learning", "author": ["S. Bubeck"], "venue": "arXiv preprint arXiv:1405.4980,", "citeRegEx": "Bubeck.,? \\Q2014\\E", "shortCiteRegEx": "Bubeck.", "year": 2014}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Cambridge university press,", "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Design is as easy as optimization", "author": ["D. Chakrabarty", "A. Mehta", "V.V. Vazirani"], "venue": "In Automata, Languages and Programming,", "citeRegEx": "Chakrabarty et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chakrabarty et al\\.", "year": 2006}, {"title": "Settling the complexity of computing two-player Nash equilibria", "author": ["Xi Chen", "Xiaotie Deng", "Shang-Hua Teng"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Following the perturbed leader for online structured learning", "author": ["A. Cohen", "T. Hazan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Cohen and Hazan.,? \\Q2015\\E", "shortCiteRegEx": "Cohen and Hazan.", "year": 2015}, {"title": "Minimum cuts, modular functions, and matroid", "author": ["W.H. Cunningham"], "venue": "polyhedra. Networks,", "citeRegEx": "Cunningham.,? \\Q1985\\E", "shortCiteRegEx": "Cunningham.", "year": 1985}, {"title": "The complexity of computing a Nash equilibrium", "author": ["C. Daskalakis", "P.W. Goldberg", "C.H. Papadimitriou"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Daskalakis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2009}, {"title": "Submodular functions, matroids, and certain polyhedra", "author": ["J. Edmonds"], "venue": "Combinatorial structures and their applications,", "citeRegEx": "Edmonds.,? \\Q1970\\E", "shortCiteRegEx": "Edmonds.", "year": 1970}, {"title": "Matroids and the greedy algorithm", "author": ["J. Edmonds"], "venue": "Mathematical programming,", "citeRegEx": "Edmonds.,? \\Q1971\\E", "shortCiteRegEx": "Edmonds.", "year": 1971}, {"title": "Approximating Nash equilibria using small-support strategies", "author": ["T. Feder", "H. Nazerzadeh", "A. Saberi"], "venue": "Electronic Commerce,", "citeRegEx": "Feder et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Feder et al\\.", "year": 2007}, {"title": "Adaptive game playing using multiplicative weights", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Games and Economic Behavior,", "citeRegEx": "Freund and Schapire.,? \\Q1999\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1999}, {"title": "Lexicographically optimal base of a polymatroid with respect to a weight vector", "author": ["S. Fujishige"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Fujishige.,? \\Q1980\\E", "shortCiteRegEx": "Fujishige.", "year": 1980}, {"title": "Submodular functions and optimization, volume 58", "author": ["S. Fujishige"], "venue": null, "citeRegEx": "Fujishige.,? \\Q2005\\E", "shortCiteRegEx": "Fujishige.", "year": 2005}, {"title": "Two algorithms for maximizing a separable concave function over a polymatroid feasible region", "author": ["H. Groenevelt"], "venue": "European journal of operational research,", "citeRegEx": "Groenevelt.,? \\Q1991\\E", "shortCiteRegEx": "Groenevelt.", "year": 1991}, {"title": "The ellipsoid method and its consequences in combinatorial optimization", "author": ["M. Gr\u00f6tschel", "L. Lov\u00e1sz", "A. Schrijver"], "venue": null, "citeRegEx": "Gr\u00f6tschel et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Gr\u00f6tschel et al\\.", "year": 1981}, {"title": "The computational power of optimization in online learning", "author": ["E. Hazan", "T. Koren"], "venue": "arXiv preprint arXiv:1504.02089,", "citeRegEx": "Hazan and Koren.,? \\Q2015\\E", "shortCiteRegEx": "Hazan and Koren.", "year": 2015}, {"title": "Predicting nearly as well as the best pruning of a decision tree", "author": ["D.P. Helmbold", "R.E. Schapire"], "venue": "Machine Learning,", "citeRegEx": "Helmbold and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Helmbold and Schapire.", "year": 1997}, {"title": "Learning permutations with exponential weights", "author": ["D.P. Helmbold", "M.K. Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Helmbold and Warmuth.,? \\Q2009\\E", "shortCiteRegEx": "Helmbold and Warmuth.", "year": 2009}, {"title": "A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries", "author": ["M. Jerrum", "A. Sinclair", "E. Vigoda"], "venue": "ACM Symposium of Theory of Computing,", "citeRegEx": "Jerrum et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Jerrum et al\\.", "year": 2004}, {"title": "Random generation of combinatorial structures from a uniform distribution", "author": ["M.R. Jerrum", "L.G. Valiant", "V.V. Vazirani"], "venue": "Theoretical Computer Science,", "citeRegEx": "Jerrum et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Jerrum et al\\.", "year": 1986}, {"title": "Efficient algorithms for online decision problems", "author": ["A. Kalai", "S. Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kalai and Vempala.,? \\Q2005\\E", "shortCiteRegEx": "Kalai and Vempala.", "year": 2005}, {"title": "Structured prediction models via the matrix-tree theorem", "author": ["T. Koo", "A. Globerson", "X.C. P\u00e9rez", "M. Collins"], "venue": "In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),", "citeRegEx": "Koo et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2007}, {"title": "Second-order quantile methods for experts and combinatorial games", "author": ["W.M. Koolen", "T. Van Erven"], "venue": "In Proceedings of The 28th Conference on Learning Theory,", "citeRegEx": "Koolen and Erven.,? \\Q2015\\E", "shortCiteRegEx": "Koolen and Erven.", "year": 2015}, {"title": "Approaching optimality for solving SDD linear systems", "author": ["I. Koutis", "G.L. Miller", "R. Peng"], "venue": "Proceedings - Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Koutis et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Koutis et al\\.", "year": 2010}, {"title": "Generating random combinatorial objects", "author": ["V.G. Kulkarni"], "venue": "Journal of Algorithms,", "citeRegEx": "Kulkarni.,? \\Q1990\\E", "shortCiteRegEx": "Kulkarni.", "year": 1990}, {"title": "Simple strategies for large zero-sum games with applications to complexity theory", "author": ["R.J. Lipton", "N.E. Young"], "venue": "Proceedings of the twenty-sixth annual ACM symposium on Theory of computing.,", "citeRegEx": "Lipton and Young.,? \\Q1994\\E", "shortCiteRegEx": "Lipton and Young.", "year": 1994}, {"title": "Playing large games using simple strategies", "author": ["R.J. Lipton", "E. Markakis", "A. Mehta"], "venue": "Proceedings of the 4th ACM conference on Electronic commerce,", "citeRegEx": "Lipton et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2003}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Information and computation,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "Geometric algorithms and combinatorial optimization", "author": ["L. Lov\u00e1sz", "M. Gr\u00f6tschel", "A. Schrijver"], "venue": "Berlin: Springer-Verlag,", "citeRegEx": "Lov\u00e1sz et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Lov\u00e1sz et al\\.", "year": 1988}, {"title": "Using separation algorithms to generate mixed integer model reformulations", "author": ["R.K. Martin"], "venue": "Operations Research Letters,", "citeRegEx": "Martin.,? \\Q1991\\E", "shortCiteRegEx": "Martin.", "year": 1991}, {"title": "On convex minimization over base polytopes", "author": ["K. Nagano"], "venue": "Integer Programming and Combinatorial Optimization,", "citeRegEx": "Nagano.,? \\Q2007\\E", "shortCiteRegEx": "Nagano.", "year": 2007}, {"title": "A strongly polynomial algorithm for line search in submodular polyhedra", "author": ["K. Nagano"], "venue": "Discrete Optimization,", "citeRegEx": "Nagano.,? \\Q2007\\E", "shortCiteRegEx": "Nagano.", "year": 2007}, {"title": "A faster parametric submodular function minimization algorithm and applications", "author": ["K. Nagano"], "venue": null, "citeRegEx": "Nagano.,? \\Q2007\\E", "shortCiteRegEx": "Nagano.", "year": 2007}, {"title": "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems", "author": ["A. Nemirovski"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski.,? \\Q2004\\E", "shortCiteRegEx": "Nemirovski.", "year": 2004}, {"title": "Problem complexity and method efficiency in optimization", "author": ["A.S. Nemirovski", "D.B. Yudin"], "venue": null, "citeRegEx": "Nemirovski and Yudin.,? \\Q1983\\E", "shortCiteRegEx": "Nemirovski and Yudin.", "year": 1983}, {"title": "Importance weighting without importance weights: An efficient algorithm for combinatorial semi-bandits", "author": ["G. Neu", "G. Bart\u00f3k"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Neu and Bart\u00f3k.,? \\Q2015\\E", "shortCiteRegEx": "Neu and Bart\u00f3k.", "year": 2015}, {"title": "Max flows in o(nm) time, or better", "author": ["J.B. Orlin"], "venue": "In Proceedings of the forty-fifth annual ACM Symposium on Theory of Computing,", "citeRegEx": "Orlin.,? \\Q2013\\E", "shortCiteRegEx": "Orlin.", "year": 2013}, {"title": "Computing correlated equilibria in multi-player games", "author": ["C.H. Papadimitriou", "T. Roughgarden"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Papadimitriou and Roughgarden.,? \\Q2008\\E", "shortCiteRegEx": "Papadimitriou and Roughgarden.", "year": 2008}, {"title": "Optimization, learning, and games with predictable sequences", "author": ["A. Rakhlin", "K. Sridharan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Rakhlin and Sridharan.,? \\Q2013\\E", "shortCiteRegEx": "Rakhlin and Sridharan.", "year": 2013}, {"title": "The matching polytope has exponential extension complexity", "author": ["T. Rothvo\u00df"], "venue": "ACM Symposium of Theory of Computing,", "citeRegEx": "Rothvo\u00df.,? \\Q2014\\E", "shortCiteRegEx": "Rothvo\u00df.", "year": 2014}, {"title": "Optimal algorithms for self-reducible problems", "author": ["C. Schnorr"], "venue": "In ICALP,", "citeRegEx": "Schnorr.,? \\Q1976\\E", "shortCiteRegEx": "Schnorr.", "year": 1976}, {"title": "Combinatorial optimization: polyhedra and efficiency, volume 24", "author": ["A. Schrijver"], "venue": "Springer Science & Business Media,", "citeRegEx": "Schrijver.,? \\Q2003\\E", "shortCiteRegEx": "Schrijver.", "year": 2003}, {"title": "Approximate counting, uniform generation and rapidly mixing markov chains", "author": ["A. Sinclair", "M. Jerrum"], "venue": "Information and Computation,", "citeRegEx": "Sinclair and Jerrum.,? \\Q1989\\E", "shortCiteRegEx": "Sinclair and Jerrum.", "year": 1989}, {"title": "Entropy, optimization and counting", "author": ["M. Singh", "N.K. Vishnoi"], "venue": "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Singh and Vishnoi.,? \\Q2014\\E", "shortCiteRegEx": "Singh and Vishnoi.", "year": 2014}, {"title": "On the universality of online mirror descent", "author": ["N. Srebro", "K. Sridharan", "A. Tewari"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Srebro et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2011}, {"title": "Online prediction under submodular constraints", "author": ["D. Suehiro", "K. Hatano", "S. Kijima"], "venue": "Algorithmic Learning Theory, pages 260\u2013274,", "citeRegEx": "Suehiro et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Suehiro et al\\.", "year": 2012}, {"title": "Path kernels and multiplicative updates", "author": ["E. Takimoto", "M.K. Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Takimoto and Warmuth.,? \\Q2003\\E", "shortCiteRegEx": "Takimoto and Warmuth.", "year": 2003}, {"title": "The complexity of computing the permanent", "author": ["L.G. Valiant"], "venue": "Theoretical computer science,", "citeRegEx": "Valiant.,? \\Q1979\\E", "shortCiteRegEx": "Valiant.", "year": 1979}, {"title": "Zur theorie der gesellschaftsspiele", "author": ["J. von Neumann"], "venue": "Mathematische Annalen,", "citeRegEx": "Neumann.,? \\Q1928\\E", "shortCiteRegEx": "Neumann.", "year": 1928}, {"title": "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension", "author": ["M.K. Warmuth", "D. Kuzmin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Warmuth and Kuzmin.,? \\Q2008\\E", "shortCiteRegEx": "Warmuth and Kuzmin.", "year": 2008}, {"title": "Two person zero-sum games for network interdiction", "author": ["A. Washburn", "K. Wood"], "venue": "Operations Research,", "citeRegEx": "Washburn and Wood.,? \\Q1995\\E", "shortCiteRegEx": "Washburn and Wood.", "year": 1995}, {"title": "Some problems on approximate counting in graphs and matroids", "author": ["D. Welsh"], "venue": "In Research Trends in Combinatorial Optimization,", "citeRegEx": "Welsh.,? \\Q2009\\E", "shortCiteRegEx": "Welsh.", "year": 2009}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": null, "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [{"referenceID": 46, "context": "These are succinct games, as discussed in the paper of Papadimitriou and Roughgarden (2008) on correlated equilibria.", "startOffset": 55, "endOffset": 92}, {"referenceID": 46, "context": "These are succinct games, as discussed in the paper of Papadimitriou and Roughgarden (2008) on correlated equilibria. For example, in a spanning tree game in which all the results of this paper apply, pure strategies correspond to spanning trees T1 and T2 selected by the two players in a graph G (or two distinct graphs G1 and G2) and the payoff \u2211 e\u2208T1,f\u2208T2 Lef is a bilinear function; this allows for example to model classic network interdiction games (see for e.g., Washburn and Wood (1995)), design problems (Chakrabarty et al.", "startOffset": 55, "endOffset": 495}, {"referenceID": 12, "context": ", Washburn and Wood (1995)), design problems (Chakrabarty et al. (2006)), and the interaction between algorithms for many problems such as ranking and compression as bilinear duels (Immorlica et al.", "startOffset": 46, "endOffset": 72}, {"referenceID": 12, "context": ", Washburn and Wood (1995)), design problems (Chakrabarty et al. (2006)), and the interaction between algorithms for many problems such as ranking and compression as bilinear duels (Immorlica et al. (2011)).", "startOffset": 46, "endOffset": 206}, {"referenceID": 52, "context": "Nash equilibria for two-player zero-sum games can be characterized and found by solving a linear program (von Neumann (1928)).", "startOffset": 110, "endOffset": 125}, {"referenceID": 42, "context": "However, for succinct games in which the strategies of both players are exponential in a natural description of the game, the corresponding linear program has exponentially many variables and constraints, and as Papadimitriou and Roughgarden (2008) point out in their open questions section, \u201cthere are no standard techniques for linear programs that have both dimensions exponential.", "startOffset": 212, "endOffset": 249}, {"referenceID": 20, "context": "\u201d Under bilinear losses/payoffs however, the von Neumann linear program can be reformulated in terms of the strategy polytopes P and Q, and this reformulation can be solved using the equivalence between optimization and separation and the ellipsoid algorithm (Gr\u00f6tschel et al. (1981)) (discussed in more detail in Section 3).", "startOffset": 260, "endOffset": 284}, {"referenceID": 15, "context": "In the case of the spanning tree game mentioned above, the strategy polytope of each player is simply the spanning tree polytope characterized by Edmonds (1971). Note that Immorlica et al.", "startOffset": 146, "endOffset": 161}, {"referenceID": 15, "context": "In the case of the spanning tree game mentioned above, the strategy polytope of each player is simply the spanning tree polytope characterized by Edmonds (1971). Note that Immorlica et al. (2011) give such a reformulation for bilinear games involving strategy polytopes with compact formulations only (i.", "startOffset": 146, "endOffset": 196}, {"referenceID": 10, "context": "As is well-known, if one of the players uses a no-regret learning algorithm and adapts his/her strategies according to the losses incurred so far (with respect to the most adversarial opponent strategy) then the average of the strategies played by the players in the process constitutes an approximate equilibrium (Cesa-Bianchi and Lugosi (2006)).", "startOffset": 315, "endOffset": 346}, {"referenceID": 4, "context": ", Audibert et al. (2013)), where the learner is required to play a pure strategy ut \u2208 U (where U is the vertex set of P ) possibly randomized according to a mixed strategy xt \u2208 P , and aims to minimize the loss in expectation, i.", "startOffset": 2, "endOffset": 25}, {"referenceID": 54, "context": "Online Mirror Descent Even though the online mirror descent algorithm is near-optimal in terms of regret for most of online learning problems (Srebro et al. (2011)), it is not computationally efficient.", "startOffset": 143, "endOffset": 164}, {"referenceID": 43, "context": "As a remark, in order to compute -approximate Nash-equilibria, if both the strategy polytopes are polymatroids then the same projection algorithms apply to the saddle-point mirror prox algorithm (Nemirovski (2004)) and reduce the dependence of the rate of convergence on to O(1/ ).", "startOffset": 196, "endOffset": 214}, {"referenceID": 48, "context": "For selfreducible structures U (Schnorr (1976)) (such as spanning trees, matchings or Hamiltonian cycles), the latter condition for every element f is superfluous, and the generalized approximate counting oracle can be replaced by a fully polynomial approximate generator as shown by Jerrum et al.", "startOffset": 32, "endOffset": 47}, {"referenceID": 28, "context": "For selfreducible structures U (Schnorr (1976)) (such as spanning trees, matchings or Hamiltonian cycles), the latter condition for every element f is superfluous, and the generalized approximate counting oracle can be replaced by a fully polynomial approximate generator as shown by Jerrum et al. (1986). Whenever we have access to a generalized approximate counting oracle, the MWU algorithm converges to -approximate in O(ln |U|/ 2) time.", "startOffset": 284, "endOffset": 305}, {"referenceID": 58, "context": ", Welsh (2009)) and randomized approximate ones for bipartite matchings (Jerrum et al.", "startOffset": 2, "endOffset": 15}, {"referenceID": 28, "context": ", Welsh (2009)) and randomized approximate ones for bipartite matchings (Jerrum et al. (2004)) and extensions such as 0\u2212 1 circulations in directed graphs or subgraphs with prespecified degree sequences (Jerrum et al.", "startOffset": 73, "endOffset": 94}, {"referenceID": 28, "context": ", Welsh (2009)) and randomized approximate ones for bipartite matchings (Jerrum et al. (2004)) and extensions such as 0\u2212 1 circulations in directed graphs or subgraphs with prespecified degree sequences (Jerrum et al. (2004)).", "startOffset": 73, "endOffset": 225}, {"referenceID": 28, "context": ", Welsh (2009)) and randomized approximate ones for bipartite matchings (Jerrum et al. (2004)) and extensions such as 0\u2212 1 circulations in directed graphs or subgraphs with prespecified degree sequences (Jerrum et al. (2004)). As a remark, if a generalized approximate counting oracle exists for both strategy polytopes (as is the case for the spanning tree game mentioned early in the introduction), the same ideas apply to the optimistic mirror descent algorithm (Rakhlin and Sridharan (2013)) and reduce the dependence of the rate of convergence on to O(1/ ) while maintaining polynomial running time.", "startOffset": 73, "endOffset": 495}, {"referenceID": 5, "context": "On the other hand, there exist matroids (Azar et al. (1994)) for which any generalized approximate counting algorithm requires an exponential number of calls to an independence oracle, while an independence oracle is all what we need to make the Bregman projection efficient in the online mirror descent approach.", "startOffset": 41, "endOffset": 60}, {"referenceID": 13, "context": "Related work The general problem of finding Nash-equilibria in 2-player games is PPAD-complete (Chen et al. (2009), Daskalakis et al.", "startOffset": 96, "endOffset": 115}, {"referenceID": 13, "context": "Related work The general problem of finding Nash-equilibria in 2-player games is PPAD-complete (Chen et al. (2009), Daskalakis et al. (2009)).", "startOffset": 96, "endOffset": 141}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al.", "startOffset": 163, "endOffset": 179}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al.", "startOffset": 163, "endOffset": 204}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al.", "startOffset": 163, "endOffset": 226}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al. (2007)).", "startOffset": 163, "endOffset": 247}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al. (2007)). These results perform a search on the support of the Nash equilibria and it is not known how to find Nash equilibria for large two-player zero sum games in time logarithmic in the number of pure strategies of the players. In recent work, Hazan and Koren (2015) show that any online algorithm requires \u03a9\u0303( \u221a N) time to approximate the value of a two-player zero-sum game, even when given access to constant time best-response oracles.", "startOffset": 163, "endOffset": 510}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al. (2007)). These results perform a search on the support of the Nash equilibria and it is not known how to find Nash equilibria for large two-player zero sum games in time logarithmic in the number of pure strategies of the players. In recent work, Hazan and Koren (2015) show that any online algorithm requires \u03a9\u0303( \u221a N) time to approximate the value of a two-player zero-sum game, even when given access to constant time best-response oracles. In this work, we restrict our attention to two-player zero-sum games with bilinear loss functions and give polynomial time algorithms for finding Nash-equilibria (polynomial in the representation of the game). One way to find Nash-equilibria is by using regret-minimization algorithms. We look at the problem of learning combinatorial concepts that has recently gained a lot of popularity in the community (Koolen and Van Erven (2015), Audibert et al.", "startOffset": 163, "endOffset": 1118}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al. (2007)). These results perform a search on the support of the Nash equilibria and it is not known how to find Nash equilibria for large two-player zero sum games in time logarithmic in the number of pure strategies of the players. In recent work, Hazan and Koren (2015) show that any online algorithm requires \u03a9\u0303( \u221a N) time to approximate the value of a two-player zero-sum game, even when given access to constant time best-response oracles. In this work, we restrict our attention to two-player zero-sum games with bilinear loss functions and give polynomial time algorithms for finding Nash-equilibria (polynomial in the representation of the game). One way to find Nash-equilibria is by using regret-minimization algorithms. We look at the problem of learning combinatorial concepts that has recently gained a lot of popularity in the community (Koolen and Van Erven (2015), Audibert et al. (2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al.", "startOffset": 163, "endOffset": 1142}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al. (2007)). These results perform a search on the support of the Nash equilibria and it is not known how to find Nash equilibria for large two-player zero sum games in time logarithmic in the number of pure strategies of the players. In recent work, Hazan and Koren (2015) show that any online algorithm requires \u03a9\u0303( \u221a N) time to approximate the value of a two-player zero-sum game, even when given access to constant time best-response oracles. In this work, we restrict our attention to two-player zero-sum games with bilinear loss functions and give polynomial time algorithms for finding Nash-equilibria (polynomial in the representation of the game). One way to find Nash-equilibria is by using regret-minimization algorithms. We look at the problem of learning combinatorial concepts that has recently gained a lot of popularity in the community (Koolen and Van Erven (2015), Audibert et al. (2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al.", "startOffset": 163, "endOffset": 1165}, {"referenceID": 0, "context": "of the loss functions, asymptotic upper and lower bounds (of the order O(logN/ 2)) on the support of approximate Nash equilibria with N pure strategies are known (Alth\u00f6fer (1994), Lipton and Young (1994), Lipton et al. (2003), Feder et al. (2007)). These results perform a search on the support of the Nash equilibria and it is not known how to find Nash equilibria for large two-player zero sum games in time logarithmic in the number of pure strategies of the players. In recent work, Hazan and Koren (2015) show that any online algorithm requires \u03a9\u0303( \u221a N) time to approximate the value of a two-player zero-sum game, even when given access to constant time best-response oracles. In this work, we restrict our attention to two-player zero-sum games with bilinear loss functions and give polynomial time algorithms for finding Nash-equilibria (polynomial in the representation of the game). One way to find Nash-equilibria is by using regret-minimization algorithms. We look at the problem of learning combinatorial concepts that has recently gained a lot of popularity in the community (Koolen and Van Erven (2015), Audibert et al. (2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al.", "startOffset": 163, "endOffset": 1189}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al.", "startOffset": 55, "endOffset": 68}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc.", "startOffset": 55, "endOffset": 90}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)).", "startOffset": 55, "endOffset": 406}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)).", "startOffset": 55, "endOffset": 506}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)).", "startOffset": 55, "endOffset": 530}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al.", "startOffset": 55, "endOffset": 693}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al.", "startOffset": 55, "endOffset": 743}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al.", "startOffset": 55, "endOffset": 840}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)).", "startOffset": 55, "endOffset": 864}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component.", "startOffset": 55, "endOffset": 1005}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm.", "startOffset": 55, "endOffset": 1479}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm.", "startOffset": 55, "endOffset": 1542}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)).", "startOffset": 55, "endOffset": 2008}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)).", "startOffset": 55, "endOffset": 2042}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)). Our algorithm is fundamentally different from the decomposition algorithm; the latter generates a sequence of violated inequalities (a dual approach) while our algorithm maintains a feasible point in the polymatroid (a primal approach). The violated inequalities in the decomposition algorithm come from a series of submodular function minimizations, and their computations can be amortized into a parametric submodular function minimization as is shown in Nagano (2007a,b); Suehiro et al. (2012). In the special cases of the Euclidean or the entropy mirror maps, our iterative algorithm leads to problems involving the maintenance of feasibility along lines, which reduces to parametric submodular function minimization problems.", "startOffset": 55, "endOffset": 2541}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)). Our algorithm is fundamentally different from the decomposition algorithm; the latter generates a sequence of violated inequalities (a dual approach) while our algorithm maintains a feasible point in the polymatroid (a primal approach). The violated inequalities in the decomposition algorithm come from a series of submodular function minimizations, and their computations can be amortized into a parametric submodular function minimization as is shown in Nagano (2007a,b); Suehiro et al. (2012). In the special cases of the Euclidean or the entropy mirror maps, our iterative algorithm leads to problems involving the maintenance of feasibility along lines, which reduces to parametric submodular function minimization problems. In the special case of cardinality-based submodular functions (f(S) = g(|S|) for some concave g), our algorithm can be implemented overall in O(n2) time, matching the running time of a specialized algorithm due to Suehiro et al. (2012). We also consider the multiplicative weights update (MWU) algorithm (Littlestone and Warmuth (1994), Freund and Schapire (1999), Arora et al.", "startOffset": 55, "endOffset": 3011}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)). Our algorithm is fundamentally different from the decomposition algorithm; the latter generates a sequence of violated inequalities (a dual approach) while our algorithm maintains a feasible point in the polymatroid (a primal approach). The violated inequalities in the decomposition algorithm come from a series of submodular function minimizations, and their computations can be amortized into a parametric submodular function minimization as is shown in Nagano (2007a,b); Suehiro et al. (2012). In the special cases of the Euclidean or the entropy mirror maps, our iterative algorithm leads to problems involving the maintenance of feasibility along lines, which reduces to parametric submodular function minimization problems. In the special case of cardinality-based submodular functions (f(S) = g(|S|) for some concave g), our algorithm can be implemented overall in O(n2) time, matching the running time of a specialized algorithm due to Suehiro et al. (2012). We also consider the multiplicative weights update (MWU) algorithm (Littlestone and Warmuth (1994), Freund and Schapire (1999), Arora et al.", "startOffset": 55, "endOffset": 3111}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)). Our algorithm is fundamentally different from the decomposition algorithm; the latter generates a sequence of violated inequalities (a dual approach) while our algorithm maintains a feasible point in the polymatroid (a primal approach). The violated inequalities in the decomposition algorithm come from a series of submodular function minimizations, and their computations can be amortized into a parametric submodular function minimization as is shown in Nagano (2007a,b); Suehiro et al. (2012). In the special cases of the Euclidean or the entropy mirror maps, our iterative algorithm leads to problems involving the maintenance of feasibility along lines, which reduces to parametric submodular function minimization problems. In the special case of cardinality-based submodular functions (f(S) = g(|S|) for some concave g), our algorithm can be implemented overall in O(n2) time, matching the running time of a specialized algorithm due to Suehiro et al. (2012). We also consider the multiplicative weights update (MWU) algorithm (Littlestone and Warmuth (1994), Freund and Schapire (1999), Arora et al.", "startOffset": 55, "endOffset": 3139}, {"referenceID": 0, "context": "(2013), Neu and Bart\u00f3k (2015), Cohen and Hazan (2015), Ailon (2014), Koolen et al. (2010)), and has found many real world applications in communication, principal component analysis, scheduling, routing, personalized content recommendation, online ad display etc. There are two popular approaches to learn over combinatorial concepts. The first is the Follow-the-Perturbed-Leader (Kalai and Vempala (2005)), though efficient in runtime complexity it is suboptimal in terms of regret (Neu and Bart\u00f3k (2015), Cohen and Hazan (2015)). The other method for learning over combinatorial structures is the online mirror descent algorithm (online convex optimization is attributed to Zinkevich (2003) and mirror descent to Nemirovski and Yudin (1983)), which fares better in terms of regret but is computationally inefficient (Srebro et al. (2011), Audibert et al. (2013)). In the first part of the work, we give a novel algorithm that speeds up the mirror descent algorithm in some setting. Koolen et al. (2010) introduce the Component Hedge (CH) algorithm for linear loss functions that sum over the losses for each component. They perform multiplicative updates for each component and subsequently perform Bregman projections over certain extended formulations with a polynomial number of constraints, using off-the-shelf convex optimization subroutines. Our work, on the other hand, allows for polytopes with exponentially many inequalities. The works of Helmbold and Warmuth (2009) (for learning over permutations) and Warmuth and Kuzmin (2008) (for learning k-sets) have been shown to be special cases of the CH algorithm. Our work applies to these settings. One of our contributions is to give a new efficient algorithm INC-FIX for performing Bregman projections on base polytopes of polymatroids, a step in the online mirror descent algorithm. Another way of solving the associated separable convex optimization problem over base polytopes of polymatroids is the decomposition algorithm of Groenevelt (1991) (also studied in Fujishige (2005)). Our algorithm is fundamentally different from the decomposition algorithm; the latter generates a sequence of violated inequalities (a dual approach) while our algorithm maintains a feasible point in the polymatroid (a primal approach). The violated inequalities in the decomposition algorithm come from a series of submodular function minimizations, and their computations can be amortized into a parametric submodular function minimization as is shown in Nagano (2007a,b); Suehiro et al. (2012). In the special cases of the Euclidean or the entropy mirror maps, our iterative algorithm leads to problems involving the maintenance of feasibility along lines, which reduces to parametric submodular function minimization problems. In the special case of cardinality-based submodular functions (f(S) = g(|S|) for some concave g), our algorithm can be implemented overall in O(n2) time, matching the running time of a specialized algorithm due to Suehiro et al. (2012). We also consider the multiplicative weights update (MWU) algorithm (Littlestone and Warmuth (1994), Freund and Schapire (1999), Arora et al. (2012)) rediscovered for different settings in game theory, machine learning, and online decision making with a large number of applications.", "startOffset": 55, "endOffset": 3160}, {"referenceID": 8, "context": "also made in Blum et al. (2008). In order to perform this algorithm efficiently for exponential experts (with combinatorial structure), it does not take much to see that multiplicative updates for linear losses can be made using product terms.", "startOffset": 13, "endOffset": 32}, {"referenceID": 8, "context": "also made in Blum et al. (2008). In order to perform this algorithm efficiently for exponential experts (with combinatorial structure), it does not take much to see that multiplicative updates for linear losses can be made using product terms. However, the analysis of prior works was very specific to the structure of the problem. For example, Takimoto and Warmuth (2003) give efficient implementations of the MWU for learning over general s\u2212 t paths that allow for cycles or over simple paths in acyclic directed graphs.", "startOffset": 13, "endOffset": 373}, {"referenceID": 8, "context": "also made in Blum et al. (2008). In order to perform this algorithm efficiently for exponential experts (with combinatorial structure), it does not take much to see that multiplicative updates for linear losses can be made using product terms. However, the analysis of prior works was very specific to the structure of the problem. For example, Takimoto and Warmuth (2003) give efficient implementations of the MWU for learning over general s\u2212 t paths that allow for cycles or over simple paths in acyclic directed graphs. This approach relies on the recursive structure of these paths, and does not generalize to simple paths in an undirected graph (or a directed graph). Similarly, Helmbold and Schapire (1997) rely on the recursive structure of bounded depth binary decision trees.", "startOffset": 13, "endOffset": 713}, {"referenceID": 8, "context": "also made in Blum et al. (2008). In order to perform this algorithm efficiently for exponential experts (with combinatorial structure), it does not take much to see that multiplicative updates for linear losses can be made using product terms. However, the analysis of prior works was very specific to the structure of the problem. For example, Takimoto and Warmuth (2003) give efficient implementations of the MWU for learning over general s\u2212 t paths that allow for cycles or over simple paths in acyclic directed graphs. This approach relies on the recursive structure of these paths, and does not generalize to simple paths in an undirected graph (or a directed graph). Similarly, Helmbold and Schapire (1997) rely on the recursive structure of bounded depth binary decision trees. Koo et al. (2007) use the matrix tree theorem to learn over spanning trees by doing largemargin optimization.", "startOffset": 13, "endOffset": 803}, {"referenceID": 37, "context": "4) in Lov\u00e1sz et al. (1988)).", "startOffset": 6, "endOffset": 27}, {"referenceID": 24, "context": ") This means that our polytope defining (LP1\u2032) is well-described (\u00e0 la Gr\u00f6tschel et al.). We can thus use the machinery of the ellipsoid algorithm (Gr\u00f6tschel et al. (1981)) to find a Nash Equilibrium in polynomial", "startOffset": 71, "endOffset": 172}, {"referenceID": 39, "context": "This allows to give a compact extended formulation for (LP1\u2032) for the spanning tree game as a compact formulation is known for the spanning tree polytope (Martin (1991)) (and any other game where the two strategy polytopes can be described using polynomial number of inequalities).", "startOffset": 155, "endOffset": 169}, {"referenceID": 39, "context": "This allows to give a compact extended formulation for (LP1\u2032) for the spanning tree game as a compact formulation is known for the spanning tree polytope (Martin (1991)) (and any other game where the two strategy polytopes can be described using polynomial number of inequalities). However, this would not work for a corresponding matching game since the extension complexity for the matching polytope is exponential (Rothvo\u00df (2014)).", "startOffset": 155, "endOffset": 433}, {"referenceID": 40, "context": ", limx\u2192\u2202D ||\u2207\u03c9(x)|| = \u221e (for details, refer to Nemirovski and Yudin (1983), Beck and Teboulle (2003), Bubeck (2014)).", "startOffset": 47, "endOffset": 75}, {"referenceID": 6, "context": ", limx\u2192\u2202D ||\u2207\u03c9(x)|| = \u221e (for details, refer to Nemirovski and Yudin (1983), Beck and Teboulle (2003), Bubeck (2014)).", "startOffset": 76, "endOffset": 101}, {"referenceID": 6, "context": ", limx\u2192\u2202D ||\u2207\u03c9(x)|| = \u221e (for details, refer to Nemirovski and Yudin (1983), Beck and Teboulle (2003), Bubeck (2014)).", "startOffset": 76, "endOffset": 116}, {"referenceID": 8, "context": "We restate the theorem about the regret of the online mirror-descent algorithm (adapted from Bubeck (2011), Ben-Tal and Nemirovski (2001), Rakhlin and Sridharan (2014)).", "startOffset": 93, "endOffset": 107}, {"referenceID": 7, "context": "We restate the theorem about the regret of the online mirror-descent algorithm (adapted from Bubeck (2011), Ben-Tal and Nemirovski (2001), Rakhlin and Sridharan (2014)).", "startOffset": 108, "endOffset": 138}, {"referenceID": 7, "context": "We restate the theorem about the regret of the online mirror-descent algorithm (adapted from Bubeck (2011), Ben-Tal and Nemirovski (2001), Rakhlin and Sridharan (2014)).", "startOffset": 108, "endOffset": 168}, {"referenceID": 17, "context": "Given such a function f , the independent set polytope is defined as P (f) = {x \u2208 R+ : x(U) \u2264 f(U) \u2200 U \u2286 E} and the base polytope as B(f) = {x \u2208 R+ : x(E) = f(E), x(U) \u2264 f(U) \u2200 U \u2286 E} (Edmonds (1970)).", "startOffset": 185, "endOffset": 200}, {"referenceID": 17, "context": "Using Edmonds\u2019 greedy algorithm Edmonds (1971), we know that any z\u2217 \u2208 B(f) is a minimizer of \u2207h(x\u2217)T z if and only if it is tight (i.", "startOffset": 6, "endOffset": 47}, {"referenceID": 15, "context": "For the graphic matroid, feasibility in the forest polytope can be solved by O(|V |) maximum flow problems (Cunningham (1985), Corollary 51.", "startOffset": 108, "endOffset": 126}, {"referenceID": 15, "context": "For the graphic matroid, feasibility in the forest polytope can be solved by O(|V |) maximum flow problems (Cunningham (1985), Corollary 51.3a in Schrijver (2003)), and as result, LINE can be solved as O(|V |2) maximum flow problems (by Dinkelbach\u2019s discrete Newton method) orO(|V |) parametric maximum flow problems.", "startOffset": 108, "endOffset": 163}, {"referenceID": 15, "context": "For the graphic matroid, feasibility in the forest polytope can be solved by O(|V |) maximum flow problems (Cunningham (1985), Corollary 51.3a in Schrijver (2003)), and as result, LINE can be solved as O(|V |2) maximum flow problems (by Dinkelbach\u2019s discrete Newton method) orO(|V |) parametric maximum flow problems. For general polymatroids over the ground set E, the problem LINE can be solved using Nagano\u2019s parametric submodular function minimization (Nagano (2007c)) that requires O(|E|6 + \u03b3|E|5) running time, where \u03b3 is the time required by the value oracle of the submodular function.", "startOffset": 108, "endOffset": 472}, {"referenceID": 15, "context": "For the graphic matroid, feasibility in the forest polytope can be solved by O(|V |) maximum flow problems (Cunningham (1985), Corollary 51.3a in Schrijver (2003)), and as result, LINE can be solved as O(|V |2) maximum flow problems (by Dinkelbach\u2019s discrete Newton method) orO(|V |) parametric maximum flow problems. For general polymatroids over the ground set E, the problem LINE can be solved using Nagano\u2019s parametric submodular function minimization (Nagano (2007c)) that requires O(|E|6 + \u03b3|E|5) running time, where \u03b3 is the time required by the value oracle of the submodular function. Each of the entropy and the Euclidean mirror maps requires O(|E|) (O(|V |) for the graphic matroid) such computations to compute a projection, since each iteration of the INC-FIX algorithm at least one non-tight edge becomes tight. Thus, for the graphic matroid we can compute Bregman projections in O(|V |4|E|) time (using Orlin\u2019s O(|V ||E|) algorithm (Orlin (2013)) for computing the maximum flow) and for general polymatroids the running time is O(|E|7 + \u03b3|E|6) where |E| is the size of the ground set.", "startOffset": 108, "endOffset": 961}, {"referenceID": 2, "context": "Arora et al. (2012)).", "startOffset": 0, "endOffset": 20}, {"referenceID": 3, "context": "This follows from the analysis, and also from the fact that any point in the relative interior of a 0/1 polytope can be viewed as a (max-entropy) product distribution over the vertices of the polytope (Asadpour et al. (2010), Singh and Vishnoi (2014)).", "startOffset": 202, "endOffset": 225}, {"referenceID": 3, "context": "This follows from the analysis, and also from the fact that any point in the relative interior of a 0/1 polytope can be viewed as a (max-entropy) product distribution over the vertices of the polytope (Asadpour et al. (2010), Singh and Vishnoi (2014)).", "startOffset": 202, "endOffset": 251}, {"referenceID": 30, "context": ", Koutis et al. (2010)) for obtaining a fast approximate marginal oracle.", "startOffset": 2, "endOffset": 23}, {"referenceID": 27, "context": ", rankings), one can use the randomized generalized approximate counting oracle from (Jerrum et al. (2004)) for computing permanents to obtain a feasible marginal oracle.", "startOffset": 86, "endOffset": 107}, {"referenceID": 27, "context": ", rankings), one can use the randomized generalized approximate counting oracle from (Jerrum et al. (2004)) for computing permanents to obtain a feasible marginal oracle. Note that the problem of counting the number of perfect matchings in a bipartite graph is #P-complete as it is equivalent to computing the permanent of a 0/1 matrix (Valiant (1979)).", "startOffset": 86, "endOffset": 352}, {"referenceID": 27, "context": ", rankings), one can use the randomized generalized approximate counting oracle from (Jerrum et al. (2004)) for computing permanents to obtain a feasible marginal oracle. Note that the problem of counting the number of perfect matchings in a bipartite graph is #P-complete as it is equivalent to computing the permanent of a 0/1 matrix (Valiant (1979)). The problem of approximately counting the number of perfect matchings in a general graph is however a long standing open problem, if solved, it would result in another way of solving MSP games on the matching polytope. Another example of a polytope that admits a polynomial approximate counting oracle is the cycle cover polytope (or 0 \u2212 1 circulations) over directed graphs (Singh and Vishnoi (2014)).", "startOffset": 86, "endOffset": 755}, {"referenceID": 27, "context": ", rankings), one can use the randomized generalized approximate counting oracle from (Jerrum et al. (2004)) for computing permanents to obtain a feasible marginal oracle. Note that the problem of counting the number of perfect matchings in a bipartite graph is #P-complete as it is equivalent to computing the permanent of a 0/1 matrix (Valiant (1979)). The problem of approximately counting the number of perfect matchings in a general graph is however a long standing open problem, if solved, it would result in another way of solving MSP games on the matching polytope. Another example of a polytope that admits a polynomial approximate counting oracle is the cycle cover polytope (or 0 \u2212 1 circulations) over directed graphs (Singh and Vishnoi (2014)). Also, we would like to note that to compute Nash-equilibria for MSP games that admit marginal oracles for both the polytopes, the optimistic mirror descent algorithm is simply the exponential weights with a modified loss vector (Rakhlin and Sridharan (2013)), and hence the same framework applies.", "startOffset": 86, "endOffset": 1015}, {"referenceID": 27, "context": ", rankings), one can use the randomized generalized approximate counting oracle from (Jerrum et al. (2004)) for computing permanents to obtain a feasible marginal oracle. Note that the problem of counting the number of perfect matchings in a bipartite graph is #P-complete as it is equivalent to computing the permanent of a 0/1 matrix (Valiant (1979)). The problem of approximately counting the number of perfect matchings in a general graph is however a long standing open problem, if solved, it would result in another way of solving MSP games on the matching polytope. Another example of a polytope that admits a polynomial approximate counting oracle is the cycle cover polytope (or 0 \u2212 1 circulations) over directed graphs (Singh and Vishnoi (2014)). Also, we would like to note that to compute Nash-equilibria for MSP games that admit marginal oracles for both the polytopes, the optimistic mirror descent algorithm is simply the exponential weights with a modified loss vector (Rakhlin and Sridharan (2013)), and hence the same framework applies. Sampling pure strategies: In online learning scenarios that require the learner to play a combinatorial concept (i.e., a pure strategy in each round), we note first that given any mixed strategy (that lies in a strategy polytope \u2208 Rn), the learner can obtain a convex decomposition of the mixed strategy into at most n + 1 vertices by using the well-known Caratheodory\u2019s Theorem. The learner can then play a pure strategy sampled proportional to the convex coefficients in the decomposition. In the case of learning over the spanning tree and bipartite perfect matching polytopes using product distributions however, there exists a more efficient way of sampling due to the self-reducibility6 of the these polytopes (Kulkarni (1990), Asadpour et al.", "startOffset": 86, "endOffset": 1788}, {"referenceID": 3, "context": "In the case of learning over the spanning tree and bipartite perfect matching polytopes using product distributions however, there exists a more efficient way of sampling due to the self-reducibility6 of the these polytopes (Kulkarni (1990), Asadpour et al. (2010)): Order the edges of the graph randomly and decide for each probabilistically whether to use it in the final object or not.", "startOffset": 242, "endOffset": 265}, {"referenceID": 3, "context": "In the case of learning over the spanning tree and bipartite perfect matching polytopes using product distributions however, there exists a more efficient way of sampling due to the self-reducibility6 of the these polytopes (Kulkarni (1990), Asadpour et al. (2010)): Order the edges of the graph randomly and decide for each probabilistically whether to use it in the final object or not. The probabilities of each edge are updated after every iteration conditioned on the decisions (i.e., to include or not) made on the earlier edges. This sampling procedure works as long as there exists a polynomial time marginal oracle (i.e., a generalized counting oracle) to update the probabilities of the elements of the ground set after each iteration and if the polytope is self-reducible (Sinclair and Jerrum (1989)).", "startOffset": 242, "endOffset": 811}, {"referenceID": 21, "context": "Lexicographic optimality: We further note that symmetric Nash-equilibria are closely related to the concept of being lexicographically optimal as studied in Fujishige (1980). For a matroid M = (E, I), x \u2208 B(M) is called lexicographically optimal with respect to a positive weight vector w if the |E|-tuple of numbers x(e)/w(e) (e \u2208 E) arranged in the order of increasing magnitude is lexicographically maximum among all", "startOffset": 157, "endOffset": 174}, {"referenceID": 21, "context": "We evoke the following theorem from Fujishige (1980).", "startOffset": 36, "endOffset": 53}], "year": 2016, "abstractText": "In order to find Nash-equilibria for two-player zero-sum games where each player plays combinatorial objects like spanning trees, matchings etc, we consider two online learning algorithms: the online mirror descent (OMD) algorithm and the multiplicative weights update (MWU) algorithm. The OMD algorithm requires the computation of a certain Bregman projection, that has closed form solutions for simple convex sets like the Euclidean ball or the simplex. However, for general polyhedra one often needs to exploit the general machinery of convex optimization. We give a novel primal-style algorithm for computing Bregman projections on the base polytopes of polymatroids. Next, in the case of the MWU algorithm, although it scales logarithmically in the number of pure strategies or experts N in terms of regret, the algorithm takes time polynomial in N ; this especially becomes a problem when learning combinatorial objects. We give a general recipe to simulate the multiplicative weights update algorithm in time polynomial in their natural dimension. This is useful whenever there exists a polynomial time generalized counting oracle (even if approximate) over these objects. Finally, using the combinatorial structure of symmetric Nash-equilibria (SNE) when both players play bases of matroids, we show that these can be found with a single projection or convex minimization (without using online learning).", "creator": "LaTeX with hyperref package"}}}