{"id": "1603.00964", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2016", "title": "Learning Tabletop Object Manipulation by Imitation", "abstract": "We aim to enable robot to learn tabletop object manipulation by imitation. Given external observations of demonstrations on object manipulations, we believe that two underlying problems to address in learning by imitation is 1) segment a given demonstration into skills that can be individually learned and reused, and 2) formulate the correct RL (Reinforcement Learning) problem that only considers the relevant aspects of each skill so that the policy for each skill can be effectively learned. Previous works made certain progress in this direction, but none has taken private information into account. The public information is the information that is available in the external observations of demonstration, and the private information is the information that are only available to the agent that executes the actions, such as tactile sensations. Our contribution is that we provide a method for the robot to automatically segment the demonstration into multiple skills, and formulate the correct RL problem for each skill, and automatically decide whether the private information is an important aspect of each skill based on interaction with the world. Our motivating example is for a real robot to play the shape sorter game by imitating other's behavior, and we will show the results in a simulated 2D environment that captures the important properties of the shape sorter game. The evaluation is based on whether the demonstration is reasonably segmented, and whether the correct RL problems are formulated. In the end, we will show that robot can imitate the demonstrated behavior based on learned policies.", "histories": [["v1", "Thu, 3 Mar 2016 03:49:02 GMT  (259kb,D)", "https://arxiv.org/abs/1603.00964v1", null], ["v2", "Fri, 26 Aug 2016 19:20:03 GMT  (259kb,D)", "http://arxiv.org/abs/1603.00964v2", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["zhen zeng", "benjamin kuipers"], "accepted": false, "id": "1603.00964"}, "pdf": {"name": "1603.00964.pdf", "metadata": {"source": "CRF", "title": "Learning Tabletop Object Manipulation by Imitation", "authors": ["Zhen Zeng", "Benjamin Kuipers"], "emails": ["zengzhen@umich.edu,", "kuipers@umich.edu"], "sections": [{"heading": null, "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "II. RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Understanding Manipulation Behavior", "text": "A potentially useful representation of manipulation behavior for artificial agents should fulfill several criteria; as set out in [2], representation must be based on sensory signals and can be learned through observation; from the point of view of learning through imitation, representation should also fulfill that (1) it is not redundant in the sense that it should not encode information that only exists within certain observed behaviors, such as specific movements of human wrists and objects; (2) it should be so simple that it can easily be interpreted as a roadmap that guides an agent to action. Previous work on human manipulation actions has attempted to depict manipulation behavior in a probable manner. Human poses, the human-object context, and the object context were considered to be a common solution to the problem, as in [3]. Similarly, in works by Kjellstrom et al al al al. [4] predefined object characteristics and manipulation characteristics are presented as mutually identical and manipulative characteristics in CRM."}, {"heading": "B. Learning by Imitation", "text": "It is indeed the case that we are able to go in search of a solution that is capable of finding the solution that we need in order to find a solution."}, {"heading": "III. NOTATIONS", "text": "First, the general state space, and it is subdivided into the general public space and the general private state space, is private. In private, each dimension is a public state variable whose value can be observed externally, such as the x-coordinate of an object center and a Boolean state variable indicating whether the hand is open or not. In private, each dimension is a private state variable whose value cannot be observed externally, like tactile sensations at the fingertips. The robot observes a sequence of states measured at the frame rate, O = {s0, s1, sfinal}, where si \u00b2, a vector consists of the pose vectors of objects in the work space, and the pose vector of the hand, si o1 i, P o2 i, \u00b7 \u00b7 \u00b7 \u00b7, P h i, TI, is the vector of the visible object in the work space."}, {"heading": "IV. LINEAR VALUE FUNCTION APPROXIMATION", "text": "The value function V maps a given state vector to the expected return, and it can be estimated as a linear combination of a given set of basic functions \u03a6 = {\u03c61, \u00b7 \u00b7, \u03c6k}, V \u0445 (s) = k \u2211 i = 1 wi\u03c6i (s), the basic function being the Fourier base, a generic base that generally performs well [16]. The state variables of the d function are defined in the second order by systematic variation of the coefficients cj. From the synthesized rewards, we can obtain a Monte Carlo sample of the expected return from each state s, R (s) = n \u0445 i = 0 \u0445iriwhere the discount factor is and ri the synthetic reward cj. And from the synthesized reward, we can obtain a Monte Carlo sample of the expected return from each state s, R (s) = 0 \u0445iriwhere the discount factor is."}, {"heading": "V. METHOD", "text": "We would like to divide the demonstration into several skills if it consists of underlying policies that use different abstractions, or policies that are too complex to approximate with an approximator for a single function. In this case, an algorithm for detecting change points can be used to find the limits of each skill and select the best abstraction for each skill."}, {"heading": "A. Changepoint Detection", "text": "With q q q q of observed data and a set of candidate models Q, we assume that the data is generated sequentially by an instance of a single model, occasionally switching to a different model or switching to a different instance of the same model at a given time, known as change points, with the aim of deriving the number and positions of the change points and selecting a suitable model instance for each segment. An efficient change point detection algorithm was introduced by Fearnhead and Liu [17], which obtains the MAP change points and models via an online Viterbi algorithm: given file tuples (xt, yt) that are observed for times t."}, {"heading": "B. Demonstration Segmentation and Abstraction Selection", "text": "Our framework for simultaneous demonstration segmentation and abstraction selection is as shown in Figure 2. We apply the intersection detection algorithm to segment the demonstration at points in time when the abstraction changes and selects the appropriate abstraction for each segment, so that, 1) the observed behavior can be effectively captured by the basic functions associated with the selected abstraction; 2) the observed orbit in the state space is simple. By default, only public state and action variables are taken into account, if the RL problem formulated with the abstracted public state and action space cannot reproduce the observed behavior, we will reformulate the RL problem by reading in private state and action variations.The set of candidate models Q is composed by the sets of basic functions associated with each abstract M, and R (st) at the moment t is the target variable yt. For the interchange point detection algorithm, a good adaptation algorithm is needed for the model to work."}, {"heading": "VI. EXPERIMENT", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Shape Sorter Game", "text": "Our motivating example is the shape sorting game, as shown in Figure 3 (a), the goal is to pick up a block and align it with the corresponding shape hole and push it into the box. Now, let's assume that only the box and the green block are within the visible field, as shown in Figure 3 (b), and the demonstrator demonstrates the insertion of the green block into the box. General public space will contain the pose of block P, the box P-Box and the hand Phand in a world frame. All private state space will include the private tactile sensation on the left and right fingers, and the action space will be introduced as before. In this case, three coordinate frames are available, i.e. the world frame, the block frame and the box frame."}, {"heading": "B. The Abstraction Library", "text": "We aim to design an abstraction library that is sufficient for manipulating tabletop objects such as assembly tasks, so that the correct abstraction is available for all tabletop object manipulation capabilities that the robot may learn. We define the mapping functions < \u03c3M, \u03c4M > of an abstraction M using two sets of parameters < P\u03c3, P\u043d >: [IL, IO, Io1, Io2, \u00b7 \u00b7, Ij, C] P\u03c4 = [IT, IR, IF], each parameter being a binary digit. In P\u0430, if IT = 1, then the hand translation action is included in the abstract action space AM; if IT = 0, then it is not included in AM. Similarly, IR indicates whether hand rotation actions are included in AM, and I\u0432, indicates whether the open / close with command is included in AM space, IIL, Iledge, IIL, IIL, IIL are included."}, {"heading": "C. Simplified 2D Manipulation Domain", "text": "Our toy example, which captures the important characteristics in our motivational example, is a 2D manipulation domain involving a robot, a block and a basket. The observed behavior is that the hand (or robot) reaches the block first and then translates it into the basket, as shown in Figure 4."}, {"heading": "D. Evaluation", "text": "Given the external observations of a demonstration, as shown in Figure 5,6, and assuming reasonable perceptual errors, the evaluation is mainly about 1) whether the demonstration is adequately segmented into multiple skills, and 2) whether the correct RL problem is formulated for each segmented skill, including whether private information is taken into account in the RL formulation when it is actually important. Videos of robot learning to reproduce the observed behavior are available at https: / / www.dropbox.com / s / eltjxl0solevnw0 / QUAL2 _ ZHEN _ slides.pptx? dl = 0.The segmentation results were successful in two different sample trajectories, and the abstraction chosen is also correct. In both experiments, abstraction is selected as robot distance and angle for the 1st segment."}, {"heading": "VII. CONCLUSION", "text": "We show that, based on our framework, we can divide the behavior into multiple skills based on the observed behavior, if necessary, and select the appropriate abstraction so that 1) the observed behavior is captured and 2) the right reference frame and relevant objects are selected. And, if there is no private information available in the observed behavior, the robot is able to decide whether the private information is important and, if necessary, reformulate the RL issues."}], "references": [{"title": "Robot learning from demonstration by constructing skill trees", "author": ["G. Konidaris", "S. Kuindersma", "R. Grupen", "A. Barto"], "venue": "The International Journal of Robotics Research, p. 0278364911428653, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning the semantics of object\u2013action relations by observation", "author": ["E.E. Aksoy", "A. Abramov", "J. D\u00f6rr", "K. Ning", "B. Dellen", "F. W\u00f6rg\u00f6tter"], "venue": "The International Journal of Robotics Research, p. 0278364911410459, 2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning human activities and object affordances from rgb-d videos", "author": ["H.S. Koppula", "R. Gupta", "A. Saxena"], "venue": "The International Journal of Robotics Research, vol. 32, no. 8, pp. 951\u2013970, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Simultaneous visual recognition of manipulation actions and manipulated objects", "author": ["H. Kjellstr\u00f6m", "J. Romero", "D. Mart\u00ednez", "D. Kragi\u0107"], "venue": "Computer Vision\u2013ECCV 2008, pp. 336\u2013349, Springer, 2008.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning rhythmic movements by demonstration using nonlinear oscillators", "author": ["A.J. Ijspeert", "J. Nakanishi", "S. Schaal"], "venue": "Proceedings of the ieee/rsj int. conference on intelligent robots and systems (iros2002), no. BIOROB-CONF-2002-003, pp. 958\u2013963, 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning from demonstration and adaptation of biped locomotion", "author": ["J. Nakanishi", "J. Morimoto", "G. Endo", "G. Cheng", "S. Schaal", "M. Kawato"], "venue": "Robotics and Autonomous Systems, vol. 47, no. 2, pp. 79\u2013 91, 2004.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Movement imitation with nonlinear dynamical systems in humanoid robots", "author": ["A.J. Ijspeert", "J. Nakanishi", "S. Schaal"], "venue": "Robotics and Automation, 2002. Proceedings. ICRA\u201902. IEEE International Conference on, vol. 2, pp. 1398\u20131403, IEEE, 2002.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Confidence-based policy learning from demonstration using gaussian mixture models", "author": ["S. Chernova", "M. Veloso"], "venue": "Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems, p. 233, ACM, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Interactive policy learning through confidence-based autonomy", "author": ["S. Chernova", "M. Veloso"], "venue": "Journal of Artificial Intelligence Research, vol. 34, no. 1, p. 1, 2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Interactive task training of a mobile robot through human gesture recognition", "author": ["P.E. Rybski", "R.M. Voyles"], "venue": "Robotics and Automation, 1999. Proceedings. 1999 IEEE International Conference on, vol. 1, pp. 664\u2013669, IEEE, 1999.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Teaching multi-robot coordination using demonstration of communication and state sharing", "author": ["S. Chernova", "M. Veloso"], "venue": "Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 3, pp. 1183\u20131186, International Foundation for Autonomous Agents and Multiagent Systems, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning robot soccer skills from demonstration", "author": ["D.H. Grollman", "O.C. Jenkins"], "venue": "Development and Learning, 2007. ICDL 2007. IEEE 6th International Conference on, pp. 276\u2013281, IEEE, 2007.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "A survey of robot learning from demonstration", "author": ["B.D. Argall", "S. Chernova", "M. Veloso", "B. Browning"], "venue": "Robotics and autonomous systems, vol. 57, no. 5, pp. 469\u2013483, 2009.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Between mdps and semi-mdps: Learning, planning, and representing knowledge at multiple temporal scales", "author": ["R.S. Sutton"], "venue": "1998.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1998}, {"title": "Apprenticeship learning via inverse reinforcement learning", "author": ["P. Abbeel", "A.Y. Ng"], "venue": "Proceedings of the twenty-first international conference on Machine learning, p. 1, ACM, 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Value function approximation in reinforcement learning using the fourier basis", "author": ["G. Konidaris"], "venue": "2008.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "On-line inference for multiple changepoint problems", "author": ["P. Fearnhead", "Z. Liu"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 69, no. 4, pp. 589\u2013605, 2007.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "[1], they provided an elegant approach for behavior segmentation, and abstraction selection for formulating the RL problems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "out in [2], the representation needs to be based on sensory signals and learnable by observation.", "startOffset": 7, "endOffset": 10}, {"referenceID": 2, "context": "Human poses, human-object context, and object-object context have been considered to solve the problem jointly as in [3].", "startOffset": 117, "endOffset": 120}, {"referenceID": 3, "context": "[4], pre-defined handobject features and manipulation features are extracted, and the semantic manipulation action-object dependencies are learned based on CRFs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Works by Aksoy\u2019s group [2] revealed an effective way to represent manipulation behavior.", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": "Some previous works learn movements by imitating joint trajectories [5][6][7].", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": "Some previous works learn movements by imitating joint trajectories [5][6][7].", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "Some previous works learn movements by imitating joint trajectories [5][6][7].", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "[8][9] learns to navigate through corridors by observing the behavior generated by expert teleoperation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[8][9] learns to navigate through corridors by observing the behavior generated by expert teleoperation.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "Similar works have been focused on high-level primitive actions such as hand gestures, for learning box and ball sorting tasks [10][11].", "startOffset": 127, "endOffset": 131}, {"referenceID": 10, "context": "Similar works have been focused on high-level primitive actions such as hand gestures, for learning box and ball sorting tasks [10][11].", "startOffset": 131, "endOffset": 135}, {"referenceID": 11, "context": "[12] has applied locally weighted projection regression to soccer skill learning task on an AIBO robot.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "For more details on works that solves the correspondence issue, please refer to this survey[13].", "startOffset": 91, "endOffset": 95}, {"referenceID": 13, "context": "Each skill is formally defined as an option o, as introduced in [14].", "startOffset": 64, "endOffset": 68}, {"referenceID": 14, "context": "If the real reward function is more complex than that, other inverse reinforcement learning methods [15] can be applied to infer the reward function from the demonstration.", "startOffset": 100, "endOffset": 104}, {"referenceID": 15, "context": "where the basis function are Fourier basis, a generic basis that generally exhibits good performance [16].", "startOffset": 101, "endOffset": 105}, {"referenceID": 0, "context": "HMM for changepoint detection [1].", "startOffset": 30, "endOffset": 33}, {"referenceID": 16, "context": "An efficient changepoint detection algorithm was introduced by Fearnhead and Liu [17] that obtains the MAP changepoints and models via an online Viterbi algorithm: given data tuples (xt, yt) observed for times t \u2208 [1, 2, \u00b7 \u00b7 \u00b7 , T ], and a set of candidate models Q with prior p(q) for each q \u2208 Q.", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "[1], it is suggested to assume a geometric distribution for skill lengths with parameter p, so that", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": ", P\u03c4 = [1, 0, 0], the state variables that the action can affect are the location variables, thus it is reasonable to constrain SM to include only location variables in this case, i.", "startOffset": 7, "endOffset": 16}, {"referenceID": 0, "context": ", IL, IO, I\u039b = [1, 0, 0].", "startOffset": 15, "endOffset": 24}, {"referenceID": 0, "context": "And the same principle applies to P\u03c4 = [0, 1, 0], P\u03c4 = [0, 0, 1], P\u03c4 = [1, 1, 0] and so on.", "startOffset": 39, "endOffset": 48}, {"referenceID": 0, "context": "And the same principle applies to P\u03c4 = [0, 1, 0], P\u03c4 = [0, 0, 1], P\u03c4 = [1, 1, 0] and so on.", "startOffset": 55, "endOffset": 64}, {"referenceID": 0, "context": "And the same principle applies to P\u03c4 = [0, 1, 0], P\u03c4 = [0, 0, 1], P\u03c4 = [1, 1, 0] and so on.", "startOffset": 71, "endOffset": 80}, {"referenceID": 0, "context": "And the same principle applies to P\u03c4 = [0, 1, 0], P\u03c4 = [0, 0, 1], P\u03c4 = [1, 1, 0] and so on.", "startOffset": 71, "endOffset": 80}], "year": 2016, "abstractText": "We aim to enable robot to learn tabletop object manipulation by imitation. Given external observations of demonstrations on object manipulations, we believe that two underlying problems to address in learning by imitation is 1) segment a given demonstration into skills that can be individually learned and reused, and 2) formulate the correct RL (Reinforcement Learning) problem that only considers the relevant aspects of each skill so that the policy for each skill can be effectively learned. Previous works made certain progress in this direction, but none has taken private information into account. The public information is the information that is available in the external observations of demonstration, and the private information is the information that are only available to the agent that executes the actions, such as tactile sensations. Our contribution is that we provide a method for the robot to automatically segment the demonstration into multiple skills, and formulate the correct RL problem for each skill, and automatically decide whether the private information is an important aspect of each skill based on interaction with the world. Our motivating example is for a real robot to play the shape sorter game by imitating other\u2019s behavior, and we will show the results in a simulated 2D environment that captures the important properties of the shape sorter game. The evaluation is based on whether the demonstration is reasonably segmented, and whether the correct RL problems are formulated. In the end, we will show that robot can imitate the demonstrated behavior based on learned policies.", "creator": "LaTeX with hyperref package"}}}