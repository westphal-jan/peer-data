{"id": "1603.01514", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2016", "title": "A Bayesian Model of Multilingual Unsupervised Semantic Role Induction", "abstract": "We propose a Bayesian model of unsupervised semantic role induction in multiple languages, and use it to explore the usefulness of parallel corpora for this task. Our joint Bayesian model consists of individual models for each language plus additional latent variables that capture alignments between roles across languages. Because it is a generative Bayesian model, we can do evaluations in a variety of scenarios just by varying the inference procedure, without changing the model, thereby comparing the scenarios directly. We compare using only monolingual data, using a parallel corpus, using a parallel corpus with annotations in the other language, and using small amounts of annotation in the target language. We find that the biggest impact of adding a parallel corpus to training is actually the increase in mono-lingual data, with the alignments to another language resulting in small improvements, even with labeled data for the other language.", "histories": [["v1", "Fri, 4 Mar 2016 16:03:53 GMT  (413kb,D)", "http://arxiv.org/abs/1603.01514v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["nikhil garg", "james henderson"], "accepted": false, "id": "1603.01514"}, "pdf": {"name": "1603.01514.pdf", "metadata": {"source": "CRF", "title": "A Bayesian Model of Multilingual Unsupervised Semantic Role Induction", "authors": ["Nikhil Garg", "James Henderson"], "emails": ["nikgarg@gmail.com", "james.henderson@unige.ch"], "sections": [{"heading": "1 Introduction", "text": "Semantic Role Labeling (SRL) has proven to be an important task in Natural Language Processing (NLP), which is applicable due to its applicability in information extraction, answering questions, and other NLP tasks. SRL is the problem of finding predicate argument structures in a sentence, as illustrated below: [A0 Mike] has [A1 a book] (S1) Here, the predicate WRITE has two arguments: \"Mike\" as author or \"a book\" as A1 or what was written. A0 and A1 are consistent with the notes of PropBank (Palmer et al., 2005). As the need for SRL arises in different domains and languages, the existing manual annotedcorpora becomes insufficient to build supervised systems, which has motivated us to work on superordinate SRL languages (Lang and Lapata, 2011b; Titov and Klementiev, 2012and Klementieg systems)."}, {"heading": "2 Unsupervised SRL Pipeline", "text": "As noted in previous work (Gildea and Jurafsky, 2002; Pradhan et al., 2005), we use a standard that consists of the following steps: 1. Off-the-shelf syntactic parsing can be used to syntactically analyze a given sentence. We use a dependency parse because of its simplicity and ease of comparison with previous work in unattended SRL.2. Predicate identification We select all non-auxiliary verbs in a sentence as predications.3. Argument identification For a given predicate, this step classifies each component of the parse tree as a semantic argument or a non-argument. Heuristics based on syntactic characteristics such as the dependency relationship of a constituent to its head, the path from constituent to the predicate, etc."}, {"heading": "3 Monolingual Model", "text": "It is a question of whether it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, in which it is a model, a model,"}, {"heading": "4 Multilingual Model", "text": "The multilingual models use word alignments between sentences in a parallel corpus to exploit the role correspondences between two different languages. We make copies of the monolingual model for each language and add additional bilingual latent variables (CLVs) to pair the monolingual models, but the multilingual role patterns, when based on parallel sentences, always remain the same as the monolingual model for most languages, with the exception of alignedroles generated by both monolingual roles, as the parent of the two corresponding role variables. The generative process, as explained below, remains the same as the monolingual model for most languages, except for alignedroles generated by both monolingual roles. Monolingual Data Given a parallel frame with the predicate p1, p2, generate two separate monolingual frames as in Section 3.2."}, {"heading": "5 Inference and Training", "text": "The conclusion problem is to predict the role names and CLVs (the hidden variables) given the predicate, its voice, and the syntactic properties of all identified arguments (the visible variables). We use a collapsed Gibbs \u2212 sampling-based approach to generate samples for the hidden variables (model parameters are integrated), the sample counts and the priors are then used to calculate the MAP estimate of the model parameters. For the monolingual model, the role at a given position is called: P (ri | r \u2212 i, f, p, vc, D \u2212 olters, p, vc, D \u2212 olters) = P (ri, r \u2212 i, f \u2212 olters, f, p, f, f \u2212 i, p, p, p, p, p, p, p, p, p, vc) P (r \u2212 i, vc) P (r \u2212 variable, D \u2212) d \u2212 dp, where the subscript \u2212 ampers, the \u2212 ampers, the \u2212 ampers, the \u2212 ri, the \u2212 rz, the \u2212 rz, the \u2212 \u2212 vi, the \u2212 rz, the \u2212 vi, the \u2212 vz"}, {"heading": "6 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Evaluation", "text": "After determining Titov and Klementiev (2012b), we evaluate only those arguments that have been correctly identified, since the incorrectly identified arguments do not have semantic gold markings, using the metric proposed by Lang and Lapata (2011a), which has three components: (i) purity (PU) measures how well an induced cluster corresponds to a single gold roll, (ii) collocation (CO) measures how well a gold roll corresponds to a single induced cluster, and (iii) F1 is the harmonious mean of PU and CO. For each predicate, N should indicate the total number of argument instances, Ci the induced cluster instances i and Gj the instances labeled j in gold annotations. PU = 1N = i = i maxj | Ci \u00b2 Gj |, CO = 1 N = j \u00b2 Gj | and F1 = 2 \u00b7 PU \u00b7 COPU + The total value for each argument is weighted by the COPU."}, {"heading": "6.2 Baseline", "text": "We use the same baseline as Lang and Lapata (2011a), which has proved difficult to beat. This baseline assigns a semantic role to a component based on its syntactic function, i.e. the dependency relationship to its head. If there are N clusters altogether, (N \u2212 1) the most common syntactic functions each receive a cluster, and the rest is assigned to the N-th cluster."}, {"heading": "6.3 Closest Previous Work", "text": "This model has separate monolingual models for each language and an additional penalty term that attempts to maximize P (rl2 | rl1) and P (rl1 | rl2) so that the given ratio is maximized and vice versa. However, there is no efficient way to optimize the target with this penalty term, and the authors used an inference method similar to annotation projection. Furthermore, the method does not naturally scale to more than two languages. Its algorithm first performs monolingual conclusions in one language, ignoring the penalty, and then the conclusion in the second language taking into account the penalty term. In contrast, our model adds the latent variables as part of the model itself."}, {"heading": "6.4 Data", "text": "According to Titov and Klementiev (2012b), we conduct our experiments on the English (EN) and German (DE) sections of the CoNLL 2009 corpus (Hajic and al., 2009) and on the EN-DE section of the Europarl corpus (Koehn, 2005). We obtain about 40k EN and 36k DE sentences from the CoNLL 2009 training set and about 1.5M parallel EN-DE sentences from Europarl. For an appropriate comparison, we consider the same setting as in (Titov and Klementiev, 2012b) for automatic parsing and ar-gumente identification, which we briefly describe here. EN sentences are synchronized with MaltParser (Nivre et al., 2007) and DE with LTH parsers (Johansson and Nugues, 2008). All non-auxiliary verbs are selected as predicates."}, {"heading": "6.5 Main Results", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "6.6 Multilingual Training with Labeled Data for One Language", "text": "Another motivation for the joint modeling of SRL in multiple languages is the transfer of information from a resource-rich language to a resource-poor language. We evaluated our model in a very general annotation transfer scenario in which we have a small, labeled dataset for one language (source) and a large, parallel unlabeled dataset for the source and another (target) language. We investigate whether this setting improves the parameter estimates for the target language. To this end, we brace the role annotations of the source language in the CoNLL dataset by means of a predefined mapping and do not take them during the training. These data provide us with good parameters for the source language that we use to scan scan the roles of the source language in the unlabeled Europarl data. CLVs aim to capture this improvement and thus improve the sample and parameter estimates for the target language. Table 2 shows the results of this experiment."}, {"heading": "6.7 Labeled Data in Monolingual Model", "text": "We investigated the improvement of the monolingual model in a semi-monitored environment. To this end, we randomly selected S% of the records in the CoNLL dataset as \"monitored records\" and the rest (100 \u2212 S)% was left unattended. Next, we clamped the role names of the monitored records 1A0 was assigned to the primary roles P1, A1 to P2, and the rest was assigned to the secondary roles (S1,..., S19) in order of their decreasing frequency. Using the predefined mapping of Section 6.6, the sampling was performed on the unmonitored records as usual. We then measured cluster performance using the trained parameters. 2To better achieve the contribution of the partial supervision, we constructed a \"monitored baseline\" as follows. For predicates seen in the monitored records, a MAP estimate of the parameters was calculated from the predefined values."}, {"heading": "7 Related Work", "text": "As discussed in Section 6.3, our work is closely related to the cross-border, unattended SRL work of Titov and Klementiev (2012b).The idea of using superlingual latent variables to collect cross-border information was proposed by Naseem et al. (2009) for the POS marker we use here for SRL. In a semi-monitored environment, Pado and Lapata (2009) used a graph-based approach to transferring semantic role commentary from English to German. Fu rstenau and Lapata (2009) used a graphical alignment method to measure the semantic and syntactic similarity between dependency tree arguments of known and unknown verbs. For monolingual unattended SRL, Swier and Stevenson (2004) presented the first work on a cross-domain general corpus, the British National Corpus visus, with 54 verbs from verbs of known and unknown verbs suggesting Lang and Henderson (2012) suggesting a Rye2b-related model for all of each other."}, {"heading": "8 Conclusions", "text": "The crossslingual latent variables capture correlations between roles in different languages and regulate the parameter estimates of the monolingual models. As it is a common Bayesian model of multilingual SRI, we can apply the same model to a variety of training scenarios by changing the inference method accordingly. We evaluate monolingual SRI with a large, unlabeled data set, bilingual SRI with a parallel corpus, bilingual SRI with annotations available for the source language, and monolingual SRI with a small, labeled data set. The increase in the amount of monolingual, unlabeled data significantly improves SRI in German, but not in English. Adding word matches in parallel sentences results in small, non-significant improvements, even if there are some small data packets that present a major difficulty in using roles."}, {"heading": "Acknowledgments", "text": "This work was financed by the Swiss NSF-contribution 200021 125137 and the EU-FP7-contribution PARLANCE."}], "references": [{"title": "Graph alignment for semi-supervised semantic role labeling", "author": ["F\u00fcrstenau", "Lapata2009] H. F\u00fcrstenau", "M. Lapata"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume", "citeRegEx": "F\u00fcrstenau et al\\.,? \\Q2009\\E", "shortCiteRegEx": "F\u00fcrstenau et al\\.", "year": 2009}, {"title": "Unsupervised semantic role induction with global role ordering", "author": ["Garg", "Henderson2012] N. Garg", "J. Henderson"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Garg et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Garg et al\\.", "year": 2012}, {"title": "Automatic labeling of semantic roles", "author": ["Gildea", "Jurafsky2002] D. Gildea", "D. Jurafsky"], "venue": "Computational Linguistics,", "citeRegEx": "Gildea et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2002}, {"title": "Unsupervised discovery of a statistical verb lexicon", "author": ["Grenager", "Manning2006] T. Grenager", "C.D. Manning"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Grenager et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Grenager et al\\.", "year": 2006}, {"title": "The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages", "author": ["Haji\u010d et al.2009] J. Haji\u010d", "M. Ciaramita", "R. Johansson", "D. Kawahara", "M.A. Mart\u0131", "L. M\u00e0rquez", "A. Meyers", "J. Nivre", "S. Pad\u00f3", "J. \u0160t\u011bp\u00e1nek"], "venue": null, "citeRegEx": "Haji\u010d et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Haji\u010d et al\\.", "year": 2009}, {"title": "Dependency-based semantic role labeling of propbank", "author": ["Johansson", "Nugues2008] R. Johansson", "P. Nugues"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Johansson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Johansson et al\\.", "year": 2008}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["P. Koehn"], "venue": "In MT summit,", "citeRegEx": "Koehn.,? \\Q2005\\E", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Unsupervised semantic role induction via splitmerge clustering", "author": ["Lang", "Lapata2011a] J. Lang", "M. Lapata"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Lang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lang et al\\.", "year": 2011}, {"title": "Unsupervised semantic role induction with graph partitioning", "author": ["Lang", "Lapata2011b] J. Lang", "M. Lapata"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Lang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lang et al\\.", "year": 2011}, {"title": "Semantic role labeling: an introduction to the special issue", "author": ["M\u00e0rquez et al.2008] L. M\u00e0rquez", "X. Carreras", "K.C. Litkowski", "S. Stevenson"], "venue": null, "citeRegEx": "M\u00e0rquez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "M\u00e0rquez et al\\.", "year": 2008}, {"title": "Multilingual part-of-speech tagging: Two unsupervised approaches", "author": ["T. Naseem", "B. Snyder", "J. Eisenstein", "R. Barzilay"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Naseem et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Naseem et al\\.", "year": 2009}, {"title": "Maltparser: A languageindependent system for data-driven dependency parsing", "author": ["J. Nivre", "J. Hall", "J. Nilsson", "A. Chanev", "G. Eryigit", "S. Kubler", "S. Marinov", "E. Marsi"], "venue": "Natural Language Engineering,", "citeRegEx": "Nivre et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2007}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Och", "Ney2003] F.J. Och", "H. Ney"], "venue": "Computational linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "Cross-lingual annotation projection for semantic roles", "author": ["Pad\u00f3", "Lapata2009] S. Pad\u00f3", "M. Lapata"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Pad\u00f3 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pad\u00f3 et al\\.", "year": 2009}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["M. Palmer", "D. Gildea", "P. Kingsbury"], "venue": null, "citeRegEx": "Palmer et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2005}, {"title": "Combinatorial stochastic processes", "author": ["J. Pitman"], "venue": "Technical report, Technical Report 621, Dept. Statistics, UC Berkeley,", "citeRegEx": "Pitman.,? \\Q2002\\E", "shortCiteRegEx": "Pitman.", "year": 2002}, {"title": "Support vector learning for semantic argument classification", "author": ["Pradhan et al.2005] S. Pradhan", "K. Hacioglu", "V. Krugler", "W. Ward", "J.H. Martin", "D. Jurafsky"], "venue": "Machine Learning,", "citeRegEx": "Pradhan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2005}, {"title": "Semantic role labeling via integer linear programming inference", "author": ["D. Roth", "W. Yih", "D. Zimak"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Punyakanok et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Punyakanok et al\\.", "year": 2004}, {"title": "Unsupervised multilingual grammar induction", "author": ["Snyder et al.2009] B. Snyder", "T. Naseem", "R. Barzilay"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-", "citeRegEx": "Snyder et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Snyder et al\\.", "year": 2009}, {"title": "Unsupervised semantic role labelling", "author": ["Swier", "Stevenson2004] R. Swier", "S. Stevenson"], "venue": "In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Swier et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Swier et al\\.", "year": 2004}, {"title": "A bayesian approach to unsupervised semantic role induction", "author": ["Titov", "Klementiev2012a] I. Titov", "A. Klementiev"], "venue": "In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Titov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Titov et al\\.", "year": 2012}, {"title": "Crosslingual induction of semantic roles", "author": ["Titov", "Klementiev2012b] I. Titov", "A. Klementiev"], "venue": "In Proceedings of the 50th Annual Meeting of the Association", "citeRegEx": "Titov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Titov et al\\.", "year": 2012}, {"title": "A global joint model for semantic role labeling", "author": ["A. Haghighi", "C.D. Manning"], "venue": null, "citeRegEx": "Toutanova et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 14, "context": "The labels A0 and A1 correspond to the PropBank annotations (Palmer et al., 2005).", "startOffset": 60, "endOffset": 81}, {"referenceID": 10, "context": "Previous work has indicated that unsupervised systems could benefit from the word alignment information in parallel text in two or more languages (Naseem et al., 2009; Snyder et al., 2009; Titov and Klementiev, 2012b).", "startOffset": 146, "endOffset": 217}, {"referenceID": 18, "context": "Previous work has indicated that unsupervised systems could benefit from the word alignment information in parallel text in two or more languages (Naseem et al., 2009; Snyder et al., 2009; Titov and Klementiev, 2012b).", "startOffset": 146, "endOffset": 217}, {"referenceID": 10, "context": "This latent variable approach has been demonstrated to increase the performance in a multilingual unsupervised part-of-speech tagging model based on HMMs (Naseem et al., 2009).", "startOffset": 154, "endOffset": 175}, {"referenceID": 16, "context": "As established in previous work (Gildea and Jurafsky, 2002; Pradhan et al., 2005), we use a standard unsupervised SRL setup, consisting of the following steps:", "startOffset": 32, "endOffset": 81}, {"referenceID": 17, "context": "Ordering and repetition information was found to be helpful in supervised SRL as well (Punyakanok et al., 2004; Pradhan et al., 2005; Toutanova et al., 2008).", "startOffset": 86, "endOffset": 157}, {"referenceID": 16, "context": "Ordering and repetition information was found to be helpful in supervised SRL as well (Punyakanok et al., 2004; Pradhan et al., 2005; Toutanova et al., 2008).", "startOffset": 86, "endOffset": 157}, {"referenceID": 22, "context": "Ordering and repetition information was found to be helpful in supervised SRL as well (Punyakanok et al., 2004; Pradhan et al., 2005; Toutanova et al., 2008).", "startOffset": 86, "endOffset": 157}, {"referenceID": 15, "context": "We generate the CLVs via a Chinese Restaurant Process (Pitman, 2002), a non-parametric Bayesian model, which allows us to induce the number of CLVs for every predicate-tuple from the data.", "startOffset": 54, "endOffset": 68}, {"referenceID": 4, "context": "Following Titov and Klementiev (2012b), we run our experiments on the English (EN) and German (DE) sections of the CoNLL 2009 corpus (Haji\u010d et al., 2009), and EN-DE section of the Europarl corpus (Koehn, 2005).", "startOffset": 133, "endOffset": 153}, {"referenceID": 6, "context": ", 2009), and EN-DE section of the Europarl corpus (Koehn, 2005).", "startOffset": 50, "endOffset": 63}, {"referenceID": 11, "context": "The EN sentences are parsed syntactically using MaltParser (Nivre et al., 2007) and DE using LTH parser (Johansson and Nugues, 2008).", "startOffset": 59, "endOffset": 79}, {"referenceID": 11, "context": "The EN sentences are parsed syntactically using MaltParser (Nivre et al., 2007) and DE using LTH parser (Johansson and Nugues, 2008). All the non-auxiliary verbs are selected as predicates. In CoNLL data, this gives us about 3k EN and 500 DE predicates. The total number of predicate instances are 3.4M in EN (89k CoNLL + 3.3M Europarl) and 2.62M in DE (17k CoNLL + 2.6M Europarl). The arguments for EN are identified using the heuristics proposed by Lang and Lapata (2011a). However, we get an F1 score of 85.", "startOffset": 60, "endOffset": 475}, {"referenceID": 11, "context": "The EN sentences are parsed syntactically using MaltParser (Nivre et al., 2007) and DE using LTH parser (Johansson and Nugues, 2008). All the non-auxiliary verbs are selected as predicates. In CoNLL data, this gives us about 3k EN and 500 DE predicates. The total number of predicate instances are 3.4M in EN (89k CoNLL + 3.3M Europarl) and 2.62M in DE (17k CoNLL + 2.6M Europarl). The arguments for EN are identified using the heuristics proposed by Lang and Lapata (2011a). However, we get an F1 score of 85.1% for argument identification on CoNLL 2009 EN data as opposed to 80.7% reported by Titov and Klementiev (2012b). This could be due to implementation differences, which unfortunately makes our EN results incomparable.", "startOffset": 60, "endOffset": 624}, {"referenceID": 10, "context": "The idea of using superlingual latent variables to capture crosslingual information was proposed for POS tagging by Naseem et al. (2009), which we use here for SRL.", "startOffset": 116, "endOffset": 137}, {"referenceID": 10, "context": "The idea of using superlingual latent variables to capture crosslingual information was proposed for POS tagging by Naseem et al. (2009), which we use here for SRL. In a semi-supervised setting, Pad\u00f3 and Lapata (2009) used a graph based approach to transfer semantic role annotations from English to German.", "startOffset": 116, "endOffset": 218}, {"referenceID": 10, "context": "The idea of using superlingual latent variables to capture crosslingual information was proposed for POS tagging by Naseem et al. (2009), which we use here for SRL. In a semi-supervised setting, Pad\u00f3 and Lapata (2009) used a graph based approach to transfer semantic role annotations from English to German. F\u00fcrstenau and Lapata (2009) used a graph alignment method to measure the semantic and syntactic similarity between dependency tree arguments of known and unknown verbs.", "startOffset": 116, "endOffset": 336}, {"referenceID": 9, "context": "M\u00e0rquez et al. (2008) provide a good overview of the supervised SRL systems.", "startOffset": 0, "endOffset": 22}], "year": 2016, "abstractText": "We propose a Bayesian model of unsupervised semantic role induction in multiple languages, and use it to explore the usefulness of parallel corpora for this task. Our joint Bayesian model consists of individual models for each language plus additional latent variables that capture alignments between roles across languages. Because it is a generative Bayesian model, we can do evaluations in a variety of scenarios just by varying the inference procedure, without changing the model, thereby comparing the scenarios directly. We compare using only monolingual data, using a parallel corpus, using a parallel corpus with annotations in the other language, and using small amounts of annotation in the target language. We find that the biggest impact of adding a parallel corpus to training is actually the increase in mono-lingual data, with the alignments to another language resulting in small improvements, even with labeled data for the other language.", "creator": "LaTeX with hyperref package"}}}