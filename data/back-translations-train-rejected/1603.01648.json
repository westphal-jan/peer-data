{"id": "1603.01648", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2016", "title": "Getting More Out Of Syntax with PropS", "abstract": "Semantic NLP applications often rely on dependency trees to recognize major elements of the proposition structure of sentences. Yet, while much semantic structure is indeed expressed by syntax, many phenomena are not easily read out of dependency trees, often leading to further ad-hoc heuristic post-processing or to information loss. To directly address the needs of semantic applications, we present PropS -- an output representation designed to explicitly and uniformly express much of the proposition structure which is implied from syntax, and an associated tool for extracting it from dependency trees.", "histories": [["v1", "Fri, 4 Mar 2016 22:47:46 GMT  (246kb,D)", "http://arxiv.org/abs/1603.01648v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["gabriel stanovsky", "jessica ficler", "ido dagan", "yoav goldberg"], "accepted": false, "id": "1603.01648"}, "pdf": {"name": "1603.01648.pdf", "metadata": {"source": "CRF", "title": "Getting More Out Of Syntax with PROPS", "authors": ["Gabriel Stanovsky", "Jessica Ficler", "Ido Dagan", "Yoav Goldberg"], "emails": ["gabriel.satanovsky@gmail.com", "jessica.ficler@gmail.com", "yoav.goldberg@gmail.com", "dagan@cs.biu.ac.il"], "sections": [{"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Design Principles", "text": "We focus our output representation on the sentence structure required for semantic applications, rather than on the syntactic focus of dependency trees. To this end, we propose five desired structural principles that we miss or miss in dependency trees. Section 3 describes these principles, as well as the consistent formulation of the PROPS output format. The next two sections describe the corresponding dependency tree conversions that have been implemented in PROPS. Section 3 describes the greater part of the conversions, which can be accomplished with high precision from dependency trees that are attainable by current dependency savers. Few cases where we have applied heuristics to address some tougher decisions will be covered in Section 4.Masking non-core syntactic details (Section 3.1) We want to focus the application on the semantic components of the sentence, which are often overspecified, and contain a node for each one."}, {"heading": "2.1 Output Format", "text": "To achieve our desired principles, we choose a representation format that resembles dependency structures, with the following changes: Typed nodes To clearly identify the suggestions in our structures, we distinguish between two types of nodes (compared to syntactic dependencies, where there is only one type of node): (1) predicates that provoke a proposal and (2) non-predicates that can be either arguments or modifiers. In addition, we model function words such as modality and tendency on characteristics of nodes. Figure 1 represents the sentence \"Barack Obama, the young candidate, was elected president\" in dependency representation (top) verus PROPS output (bottom). PROPS clearly marks the predicates elect, young, and SameAs (representing the apposition) as shaded nodes in the chart, along with their characteristics (for example, past tense in the subscript for the chosen predicate)."}, {"heading": "3 The PROPS Converter", "text": "In this section, we describe the transformations that have been carried out in PROPS, a rules-based converter of Stanford dependency trees.1 These transformations fulfill the guiding principles described in the previous paragraph. Specifically, we aim at phenomena that we consider feasible from both dependency trees and common denominations2. 2As we have identified for semantic applications through frequency analysis via PTB, the code is made available upon acceptance."}, {"heading": "3.1 Masking Non-Core Syntactic Detail", "text": "In addition to individual word nodes, we produce structures that contain multi-word nodes for cases of multi-word predicates (e.g., take a picture) or noun connections (e.g., New York). In certain syntactic formalisms, these constructs are represented as multiple nodes connected by a particular label. In particular, PROPS is based on the nn and mwe relationships in Stanford dependencies for noun phrases or multiple word expressions. Linking such units in a single node reduces the size of the tree, reduces the label set, and simplifies its processing overall. In addition, we write words in their basic form and encode characteristics for modality, negation, definitivity, tension, and passive or active voice for each node in a flat key = value structure (e.g., \"was chosen\" appears as a single selected node with a tense form in Figure 1)."}, {"heading": "3.2 Representing Propositions in a Uniform Manner", "text": "Beyond verbal predicates, we deal with three common types of predications that do not follow the simple verbal-oriented representation in dependency trees. We rearrange the tree structure so that each predicate produces its arguments and modifiers. 3Adjectives Prediction While syntactic analyses treat adjectives as modifiers, we explicitly also represent their propositional meaning (for example, phrases like \"the boy is big\" and \"the big boy\" evoke the proposition big (boy)). Adjective propositions are associated with the \"project of\" relationship, whereby we refer to the 1-year prediction. We also retain the modification status of an adjective using the \"mod\" rela-3The rather complex case of nominal prediction will be incorporated into future work. We will elaborate the results in Section 3.3. This leads to the following structures: (1) She said that the boy is tall."}, {"heading": "3.3 Canonicalizing and Differentiating Syntactic Constructions", "text": "In fact, it is a very complex, yet very complex story, which is about putting people at the centre, in order to enable them to put themselves in a position to integrate, in order to put them in the position in which they find themselves."}, {"heading": "3.4 Marking Proposition Boundaries", "text": "While syntactical dependency representations contain much of the sentence structure, they do not clearly mark the boundaries of different proposals and their arguments, making it difficult to focus on individual proposals. We use restrictive versus non-restrictive modifications to properly narrow the scope of arguments (Kamp and Reyle, 1993). Consider, for example, the following sentences: - \"The director who edited\" Rear Window \"has released Psycho.\" - \"Hitchcock who edited\" Rear Window \"has released Psycho.\" While syntactical analyses assign a similar structure to both instances, each other induces sentence boundaries. In the first sentence, the director who edited \"Rear Window\" sets the minimum scope of a single argument, resulting in a release of the proposal (the director who edited Rear Window, Psycho). But in the second sentence, we can separate the relative clause from the entity that edits it by producing two different predictions: Hitchcock Window (Hitchcock Window) and HitchWindow (HitchWindow)."}, {"heading": "4 Heuristically Dealing with Harder Cases", "text": "One of the guiding principles for selecting the phenomena described in Section 3 is the ability to provide basic rules for handling them based on automatic parsing output. However, certain phenomena are difficult to identify directly from the output of current parsers and do not fall within this range. However, we note that we target them with relatively high precision by applying a few heuristics and can provide a more practical representation to downstream semantic applications. Although most of these distinctions are not currently handled by syntactic parsers, they are commented on in existing linguistic datasets. In Section 6, we use these annotations and are therefore able to provide a gold standard corpus that reliably covers these phenomena."}, {"heading": "4.1 Differentiating Raising-to-Subject from Control", "text": "Following the analysis by Huddleston et al (2002), we would like to canonize syntactically different sentences, such as: (11) They seem impatient and mark the verb as its modifier, as we have previously analyzed it for adjective complements (Example 8). However, using the results of syntactical parsers, it is difficult to distinguish Example 12 from cases such as Example 13 in which we would like to maintain the nested dependency representation. (13) They want to be impatient, subjectively aux xcomp acompLinguistic theories identify Example 12 as raising to the subject and distinguish it from cases such as Example 13 in which we would like to maintain the linkage of dependency representation. (13) They want to be impatient aux xcomp acompLinguistic theories identify Example 12 as raising to the subject and distinguish it from controlled constructions (Example 13) by addressing tactical constructions, but where we are not synchronized between syntactical and dupLinguistic theories (Example 12)."}, {"heading": "4.2 Propagating Relations", "text": "In some cases, especially in coordination constructions, predicate-argument relationships can be propagated according to the syntactic structure, which leads to new proposals. For example, in \"Dell makes and distributes products\" the propagation results in the three proposals we make (Dell, products), distribute (Dell, products) and manufacture and distribute (Dell, products). Likewise in \"Dell sells laptops and servers\" that we sell (Dell, laptops), sell (Dell, servers) and sell (Dell, laptops and servers). Our representation of coordination follows the Prager Treebank style (Popel et al., 2013; Bo \u00b8 hmova and al., 2003) and positions the coordination word as the main node of the coordination and connection structure, while the various conjunctions are bound to it (conj \"edges)."}, {"heading": "4.3 Syntactic assertedness", "text": "This property has been studied in corpora PDTB (Prasad et al., 2006) and PARC (Pareti, 2012) and has proved useful for semantic applications (e.g. (Aramaki et al., 2009). Using a specific node feature, we mark cases where it is syntactically possible to determine whether a sentence is asserted. While hierarchical structure generally implies the dependence of the nested sentence, in certain constructions the nested sentence is actually independent of its subordinate clause. This is the case for a non-restrictive relative clause (\"Alfred Hitchcock, the psycho-directed\" in which the directed sentence is syntactically asserted), certain conditionalities (\"glaciers melt because temperature rises\" in which both rising and melting predictions are asserted) and several others in the second case are distinguished by the constellation."}, {"heading": "5 Concrete Example", "text": "Figure 2 compares PROPS with the Stanford Dependency Analysis for a typical WSJ theorem. Dependence representation contains 27 knots (and thus 27 edges), while our representation contains 17 knots and 19 edges. A simple crossing of all predicate knots in our chart results in the following statements: (1) lower wine prices have occurred [claims] (2) the dramatic price increase has hit the wine (3) see producers (2) (4) see producers not like (3) [claims] (5) Mr. Pratt is marketing manager [claims] (6) (1) because (4) (7) Mr. Pratt believes that (6) [claims] the marketing manager means (6) [claims] to extract these sentences and their claim status from the dependency tree."}, {"heading": "6 Annotated Corpus", "text": "In addition to the PROPS converter described in earlier sections, we have also created a large PROPS corpus that extracts with high precision both the core structures described in Section 3 and the more difficult cases described in Section 4.7. To obtain this corpus, we have adapted the conversions described in Section 3 and executed them on full gold choice trees available from Penn Tree Bank (PTB) (Bies et al., 1995). Using the PTB together with the Propbank (which also commented on the WSJ) allows us to make the corpus available on publication to explicitly restore some of the phenomena dealt with only heuristically in the PROPS converter (Section 4). To restore argument propagation and the handling of compounds, we use the rich syntactical information present in the gold trees (including traces, empty elements and functional notes)."}, {"heading": "7 Evaluation", "text": "We evaluate the PROPS converter intrinsically (by adjusting its output to a gold standard) and extrinsically (by demonstrating the usefulness of the corresponding structure in a text comprehension task)."}, {"heading": "7.1 Intrinsic Evaluation", "text": "In order to achieve this, we have to deal with the question of how the future is organized, and how the future is organized. (...) We have to deal with the question of how the future is organized. (...) We have to deal with the question of how the future is organized. (...) We have to deal with the question of how the future is organized. (...) We have to deal with the question of how the future is organized. (...) We have to deal with the question of how the future is organized. (...) We have to deal with the question of how the future of the world is organized. (...) We have to deal with the question of how the future of the world is organized. (...) We have to deal with the question of how the future of the world is organized. (...) We have to deal with the question of how the future of the world is organized. (...) We have to deal with the question of how the future of the world is organized. (...) We have to deal with the question of how the world is organized. (...) We have to deal with the world of the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world, the world of the world of the world of the world of the world, the world of the world of the world of the world of the world of the world, the world of the world of the world of the world of the world of the world (...) We have to deal with the question of the question of the world of the world of the world of the world of the world of the world of the future of the future of the future of the future, the question of the future of the future of the future of the future of the future. (...) We have to deal with the question of the question of the question of the question of the question of the future of the question of the future of the future of the question of the future of the future of the future of the future of"}, {"heading": "7.2 Extrinsic Evaluation", "text": "To evaluate our automatic converter extrinsically, we use the MCTest machine understanding corpus (Richardson et al., 2013), consisting of 500 short stories, followed by 4 multiple choice questions each. The MCTest comprehension task does not require extensive world knowledge, making it ideal for testing underlying representations, since performance largely depends on the accuracy and informativeness of the representation. We focus our tests on questions that can be answered in the corpus as a single sentence in history (905 questions followed by 3,620 candidate answers).Our goal in this evaluation is to demonstrate the usability of PROPS in an out-of-the-box application. We therefore focus on a simple format-independent algorithm that allows us to control our evaluation around the underlying representation. The intention of this evaluation is to emphasize the attractive properties of PROPS for secular applications, rather than to emphasize textual comprehension algorithms (a highly adaptable algorithm followed by a complex algorithm in each case)."}, {"heading": "8 Related Work", "text": "Abstract away from syntax and provide a more semantically oriented sentence representation has been the focus of several research efforts. In terms of the results produced that are most similar to ours, UCCA (Evening and Rappoport, 2013) proposed a new representation scheme that focuses on semantic applications and a small accompanying gold standard corpus. However, UCCA differs in its main motivations, namely that they aim to be a cognitive interlingua representation. UCCA's design decisions seem to focus on descriptivity and universality, rather than on direct use, resulting in a cognitively motivated label set that \"for11Both PROPS and Stanford dependency trees were achieved through the use of Berkeley Parser (Petrov and Klein, 2007) as the base parser. In both cases, the representative units (source word (s), label, target word (s), target word (s), target word (s), (s), subtriplets), and both (s) are the subtriplets."}, {"heading": "9 Conclusion", "text": "We introduced PROPS - a large number of linguistically motivated conversions. PROPS enables semantic applications to easily explore a wide range of sentence structure without knowing how it was expressed in the syntactic form of the interface. In addition, we produced an automatic conversion of the WSJ with high accuracy and demonstrated the ready-to-use applicability of the PROPS converter."}], "references": [{"title": "Universal conceptual cognitive annotation (ucca)", "author": ["Omri Abend", "Ari Rappoport."], "venue": "ACL (1), pages 228\u2013238.", "citeRegEx": "Abend and Rappoport.,? 2013", "shortCiteRegEx": "Abend and Rappoport.", "year": 2013}, {"title": "Leveraging linguistic structure for open domain information extraction", "author": ["Gabor Angeli", "Melvin Johnson Premkumar", "Christopher D. Manning."], "venue": "ACL.", "citeRegEx": "Angeli et al\\.,? 2015", "shortCiteRegEx": "Angeli et al\\.", "year": 2015}, {"title": "Text2table: medical text summarization system based on named entity recognition and modality identification", "author": ["Eiji Aramaki", "Yasuhide Miura", "Masatsugu Tonoike", "Tomoko Ohkuma", "Hiroshi Mashuichi", "Kazuhiko Ohe."], "venue": "Proceedings of the Workshop", "citeRegEx": "Aramaki et al\\.,? 2009", "shortCiteRegEx": "Aramaki et al\\.", "year": 2009}, {"title": "Broad-coverage ccg semantic parsing with amr", "author": ["Yoav Artzi", "Kenton Lee", "Luke Zettlemoyer."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1699\u20131710, Lisbon, Portugal, September. Association", "citeRegEx": "Artzi et al\\.,? 2015", "shortCiteRegEx": "Artzi et al\\.", "year": 2015}, {"title": "Deepsyntactic parsing", "author": ["Miguel Ballesteros", "Bernd Bohnet", "Simon Mille", "Leo Wanner."], "venue": "Proceedings of the 25th International Conference on Computational Linguistics (COLING), Dublin, Ireland.", "citeRegEx": "Ballesteros et al\\.,? 2014", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2014}, {"title": "Abstract meaning representation for sembanking", "author": ["Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider"], "venue": null, "citeRegEx": "Banarescu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Banarescu et al\\.", "year": 2013}, {"title": "Developing a large semantically annotated corpus", "author": ["Valerio Basile", "Johan Bos", "Kilian Evang", "Noortje Venhuizen."], "venue": "LREC, volume 12, pages 3196\u2013 3200.", "citeRegEx": "Basile et al\\.,? 2012", "shortCiteRegEx": "Basile et al\\.", "year": 2012}, {"title": "A philosophical guide to conditionals", "author": ["Jonathan Bennett"], "venue": null, "citeRegEx": "Bennett.,? \\Q2003\\E", "shortCiteRegEx": "Bennett.", "year": 2003}, {"title": "Modeling biological processes for reading comprehension", "author": ["Jonathan Berant", "Vivek Srikumar", "Pei-Chun Chen", "Abby Vander Linden", "Brittany Harding", "Brad Huang", "Peter Clark", "Christopher D. Manning."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Berant et al\\.,? 2014", "shortCiteRegEx": "Berant et al\\.", "year": 2014}, {"title": "Bracketing guidelines for treebank ii style penn treebank project", "author": ["Ann Bies", "Mark Ferguson", "Karen Katz", "Robert MacIntyre", "Victoria Tredinnick", "Grace Kim", "Mary Ann Marcinkiewicz", "Britta Schasberger."], "venue": "University of Pennsylvania, 97:100.", "citeRegEx": "Bies et al\\.,? 1995", "shortCiteRegEx": "Bies et al\\.", "year": 1995}, {"title": "The prague dependency treebank", "author": ["Alena B\u00f6hmov\u00e1", "Jan Haji\u010d", "Eva Haji\u010dov\u00e1", "Barbora Hladk\u00e1."], "venue": "Treebanks, pages 103\u2013127. Springer.", "citeRegEx": "B\u00f6hmov\u00e1 et al\\.,? 2003", "shortCiteRegEx": "B\u00f6hmov\u00e1 et al\\.", "year": 2003}, {"title": "Introduction to the conll-2005 shared task: Semantic role labeling", "author": ["Xavier Carreras", "Llu\u0131\u0301s M\u00e0rquez"], "venue": "In Proceedings of CONLL,", "citeRegEx": "Carreras and M\u00e0rquez.,? \\Q2005\\E", "shortCiteRegEx": "Carreras and M\u00e0rquez.", "year": 2005}, {"title": "Introduction to the conll-2005 shared task: Semantic role labeling", "author": ["Xavier Carreras", "Llu\u0131\u0301s M\u00e0rquez"], "venue": "In Proceedings of the Ninth Conference on Computational Natural Language Learning,", "citeRegEx": "Carreras and M\u00e0rquez.,? \\Q2005\\E", "shortCiteRegEx": "Carreras and M\u00e0rquez.", "year": 2005}, {"title": "Using very large corpora to detect raising and control verbs", "author": ["Grzegorz Chrupa\u0142a", "Josef van Genabith."], "venue": "Proceedings of the LFG07 Conference.", "citeRegEx": "Chrupa\u0142a and Genabith.,? 2007", "shortCiteRegEx": "Chrupa\u0142a and Genabith.", "year": 2007}, {"title": "Dependency tree kernels for relation extraction", "author": ["Aron Culotta", "Jeffrey Sorensen."], "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 423. Association for Computational Linguistics.", "citeRegEx": "Culotta and Sorensen.,? 2004", "shortCiteRegEx": "Culotta and Sorensen.", "year": 2004}, {"title": "The grammar of raising and control: A course in syntactic argumentation", "author": ["William D Davies", "Stanley Dubinsky."], "venue": "John Wiley & Sons.", "citeRegEx": "Davies and Dubinsky.,? 2008", "shortCiteRegEx": "Davies and Dubinsky.", "year": 2008}, {"title": "Stanford typed dependencies manual", "author": ["Marie-Catherine de Marneffe", "Christopher D Manning."], "venue": "Technical report, Stanford University.", "citeRegEx": "Marneffe and Manning.,? 2008a", "shortCiteRegEx": "Marneffe and Manning.", "year": 2008}, {"title": "The stanford typed dependencies representation", "author": ["Marie-Catherine de Marneffe", "Christopher D Manning."], "venue": "Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 1\u20138.", "citeRegEx": "Marneffe and Manning.,? 2008b", "shortCiteRegEx": "Marneffe and Manning.", "year": 2008}, {"title": "A discriminative graph-based parser for the abstract meaning representation", "author": ["J. Flanigan", "S. Thomson", "J. Carbonell", "C. Dyer", "N.A. Smith."], "venue": "Proc. of ACL, Baltimore, Maryland, June. Association for Computational Linguistics.", "citeRegEx": "Flanigan et al\\.,? 2014", "shortCiteRegEx": "Flanigan et al\\.", "year": 2014}, {"title": "The cambridge grammar of english", "author": ["Rodney Huddleston", "Geoffrey K Pullum"], "venue": null, "citeRegEx": "Huddleston and Pullum,? \\Q2002\\E", "shortCiteRegEx": "Huddleston and Pullum", "year": 2002}, {"title": "From discourse to logic: Introduction to model theoretic semantics of natural language, formal logic and discourse representation theory", "author": ["Hans Kamp", "Uwe Reyle."], "venue": "Number 42. Springer Science & Business Media.", "citeRegEx": "Kamp and Reyle.,? 1993", "shortCiteRegEx": "Kamp and Reyle.", "year": 1993}, {"title": "Propbank: the next level of treebank", "author": ["Paul Kingsbury", "Martha Palmer."], "venue": "Proceedings of Treebanks and lexical Theories, volume 3.", "citeRegEx": "Kingsbury and Palmer.,? 2003", "shortCiteRegEx": "Kingsbury and Palmer.", "year": 2003}, {"title": "A database of attribution relations", "author": ["Silvia Pareti."], "venue": "LREC, pages 3213\u20133217. Citeseer.", "citeRegEx": "Pareti.,? 2012", "shortCiteRegEx": "Pareti.", "year": 2012}, {"title": "Improved inference for unlexicalized parsing", "author": ["Slav Petrov", "Dan Klein."], "venue": "HLT-NAACL, volume 7, pages 404\u2013411.", "citeRegEx": "Petrov and Klein.,? 2007", "shortCiteRegEx": "Petrov and Klein.", "year": 2007}, {"title": "Coordination structures in dependency treebanks", "author": ["Martin Popel", "David Marecek", "Jan Step\u00e1nek", "Daniel Zeman", "Zdenek Zabokrtsk\u1ef3."], "venue": "Proc. of ACL, pages 517\u2013527.", "citeRegEx": "Popel et al\\.,? 2013", "shortCiteRegEx": "Popel et al\\.", "year": 2013}, {"title": "Annotating attribution in the penn discourse treebank", "author": ["Rashmi Prasad", "Nikhil Dinesh", "Alan Lee", "Aravind Joshi", "Bonnie Webber."], "venue": "Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 31\u201338. Association for Computational Linguistics.", "citeRegEx": "Prasad et al\\.,? 2006", "shortCiteRegEx": "Prasad et al\\.", "year": 2006}, {"title": "Parsing english into abstract meaning representation using syntaxbased machine translation", "author": ["Michael Pust", "Ulf Hermjakob", "Kevin Knight", "Daniel Marcu", "Jonathan May."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Pust et al\\.,? 2015", "shortCiteRegEx": "Pust et al\\.", "year": 2015}, {"title": "Mctest: A challenge dataset for the open-domain machine comprehension of text", "author": ["Matthew Richardson", "Christopher JC Burges", "Erin Renshaw."], "venue": "EMNLP, pages 193\u2013203.", "citeRegEx": "Richardson et al\\.,? 2013", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "A theory of conditionals", "author": ["Robert C Stalnaker."], "venue": "Ifs, pages 41\u201355. Springer.", "citeRegEx": "Stalnaker.,? 1981", "shortCiteRegEx": "Stalnaker.", "year": 1981}, {"title": "The universal networking language beyond machine translation", "author": ["Hiroshi Uchida", "Meiying Zhu."], "venue": "International Symposium on Language in Cyberspace, Seoul, pages 26\u201327.", "citeRegEx": "Uchida and Zhu.,? 2001", "shortCiteRegEx": "Uchida and Zhu.", "year": 2001}, {"title": "Adding noun phrase structure to the penn treebank", "author": ["David Vadas", "James Curran."], "venue": "ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, volume 45, page 240.", "citeRegEx": "Vadas and Curran.,? 2007", "shortCiteRegEx": "Vadas and Curran.", "year": 2007}, {"title": "A transition-based algorithm for amr parsing", "author": ["Chuan Wang", "Nianwen Xue", "Sameer Pradhan."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 366\u2013", "citeRegEx": "Wang et al\\.,? 2015", "shortCiteRegEx": "Wang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "Dependency trees (de Marneffe and Manning, 2008b) are attractive as they directly connect verbal predicates to their arguments, while deep syntax extensions of dependency trees also mark long distance dependencies, further broadening predicate-argument coverage (Ballesteros et al., 2014).", "startOffset": 262, "endOffset": 288}, {"referenceID": 5, "context": "Notable examples are Semantic Role Labeling (SRL) (Carreras and M\u00e0rquez, 2005a), which extracts frames linking predicates with their semantic arguments, or, more recently, Abstract Meaning Representation (AMR) (Banarescu et al., 2013), which aims to extract a graph representation capturing the semantic structure of the sentence.", "startOffset": 210, "endOffset": 234}, {"referenceID": 14, "context": ", (Culotta and Sorensen, 2004)), the possibility of creating such heuristics rests on rather strong linguistic grounds \u2013 the syntactic structure reliably expresses a wide range of predications.", "startOffset": 2, "endOffset": 30}, {"referenceID": 9, "context": "In addition to providing an automatic tool to convert dependency trees we also provide a large semiautomatic annotation of the WSJ portion of the Penn Tree Bank (PTB) (Bies et al., 1995).", "startOffset": 167, "endOffset": 186}, {"referenceID": 21, "context": "We do so by utilizing gold phrase-based annotations and other annotated resources, such as Propbank (Kingsbury and Palmer, 2003) or Vadas and Curran\u2019s (2007) NP structure annotation.", "startOffset": 100, "endOffset": 128}, {"referenceID": 9, "context": "In addition to providing an automatic tool to convert dependency trees we also provide a large semiautomatic annotation of the WSJ portion of the Penn Tree Bank (PTB) (Bies et al., 1995). This recovers our structures with higher accuracy, and includes an accurate handling for the previously mentioned semantically hard decisions. We do so by utilizing gold phrase-based annotations and other annotated resources, such as Propbank (Kingsbury and Palmer, 2003) or Vadas and Curran\u2019s (2007) NP structure annotation.", "startOffset": 168, "endOffset": 489}, {"referenceID": 1, "context": "(Angeli et al., 2015)), and not trivially available in depdendency trees.", "startOffset": 0, "endOffset": 21}, {"referenceID": 28, "context": "While there has been extensive linguistic study of the subject (Stalnaker, 1981; Bennett, 2003), NLP applications tend to overlook these constructions (a recent exception is (Berant et al.", "startOffset": 63, "endOffset": 95}, {"referenceID": 7, "context": "While there has been extensive linguistic study of the subject (Stalnaker, 1981; Bennett, 2003), NLP applications tend to overlook these constructions (a recent exception is (Berant et al.", "startOffset": 63, "endOffset": 95}, {"referenceID": 8, "context": "While there has been extensive linguistic study of the subject (Stalnaker, 1981; Bennett, 2003), NLP applications tend to overlook these constructions (a recent exception is (Berant et al., 2014)).", "startOffset": 174, "endOffset": 195}, {"referenceID": 20, "context": "We use restrictive versus nonrestrictive modification to properly bound the scope of arguments (Kamp and Reyle, 1993).", "startOffset": 95, "endOffset": 117}, {"referenceID": 15, "context": ", example 13), by the correspondence between syntactic and semantic arguments (Davies and Dubinsky, 2008) (i.", "startOffset": 78, "endOffset": 105}, {"referenceID": 24, "context": "Our representation of coordination follows the Prague-Treebank style (Popel et al., 2013; B\u00f6hmov\u00e1 et al., 2003) and posits the coordinating word as the main node of the coordinating-conjunction structure, while the different conjuncts are attached to it using \u201cconj\u201d edges.", "startOffset": 69, "endOffset": 111}, {"referenceID": 10, "context": "Our representation of coordination follows the Prague-Treebank style (Popel et al., 2013; B\u00f6hmov\u00e1 et al., 2003) and posits the coordinating word as the main node of the coordinating-conjunction structure, while the different conjuncts are attached to it using \u201cconj\u201d edges.", "startOffset": 69, "endOffset": 111}, {"referenceID": 25, "context": "This property was extensibility studied in the PDTB (Prasad et al., 2006) and PARC (Pareti, 2012) corpora, and was shown to be useful in semantic applications (e.", "startOffset": 52, "endOffset": 73}, {"referenceID": 22, "context": ", 2006) and PARC (Pareti, 2012) corpora, and was shown to be useful in semantic applications (e.", "startOffset": 17, "endOffset": 31}, {"referenceID": 2, "context": ", (Aramaki et al., 2009)).", "startOffset": 2, "endOffset": 24}, {"referenceID": 9, "context": "To obtain this corpus we adapted the conversions described in Section 3 and ran them on full gold constituency trees, available from the Penn Tree Bank (PTB) (Bies et al., 1995).", "startOffset": 158, "endOffset": 177}, {"referenceID": 23, "context": "Additionally, we test the accuracy of converting PROPS over automatic dependency trees derived by running the Stanford converter on top of the Berkeley parser (Petrov and Klein, 2007).", "startOffset": 159, "endOffset": 183}, {"referenceID": 27, "context": "2 Extrinsic Evaluation To extrinsically evaluate our automatic converter we use the MCTest corpus for machine comprehension (Richardson et al., 2013), composed of 500 short stories, each followed by 4 multiple choice questions.", "startOffset": 124, "endOffset": 149}, {"referenceID": 0, "context": "In terms of the produced outputs, perhaps the most similar to ours is UCCA (Abend and Rappoport, 2013).", "startOffset": 75, "endOffset": 102}, {"referenceID": 23, "context": "Both PROPS and Stanford-dependency trees were obtained by using Berkeley Parser (Petrov and Klein, 2007) as the base parser.", "startOffset": 80, "endOffset": 104}, {"referenceID": 6, "context": "Other notable semantic representations include GMB (Basile et al., 2012), UNL (Uchida and Zhu, 2001) and recently AMR (Banarescu et al.", "startOffset": 51, "endOffset": 72}, {"referenceID": 29, "context": ", 2012), UNL (Uchida and Zhu, 2001) and recently AMR (Banarescu et al.", "startOffset": 13, "endOffset": 35}, {"referenceID": 5, "context": ", 2012), UNL (Uchida and Zhu, 2001) and recently AMR (Banarescu et al., 2013).", "startOffset": 53, "endOffset": 77}, {"referenceID": 18, "context": "Producing accurate AMR structures requires in-depth semantic analysis, and it is currently produced with relatively low accuracy (Flanigan et al., 2014; Wang et al., 2015; Pust et al., 2015; Artzi et al., 2015).", "startOffset": 129, "endOffset": 210}, {"referenceID": 31, "context": "Producing accurate AMR structures requires in-depth semantic analysis, and it is currently produced with relatively low accuracy (Flanigan et al., 2014; Wang et al., 2015; Pust et al., 2015; Artzi et al., 2015).", "startOffset": 129, "endOffset": 210}, {"referenceID": 26, "context": "Producing accurate AMR structures requires in-depth semantic analysis, and it is currently produced with relatively low accuracy (Flanigan et al., 2014; Wang et al., 2015; Pust et al., 2015; Artzi et al., 2015).", "startOffset": 129, "endOffset": 210}, {"referenceID": 3, "context": "Producing accurate AMR structures requires in-depth semantic analysis, and it is currently produced with relatively low accuracy (Flanigan et al., 2014; Wang et al., 2015; Pust et al., 2015; Artzi et al., 2015).", "startOffset": 129, "endOffset": 210}], "year": 2016, "abstractText": "Semantic NLP applications often rely on dependency trees to recognize major elements of the proposition structure of sentences. Yet, while much semantic structure is indeed expressed by syntax, many phenomena are not easily read out of dependency trees, often leading to further ad-hoc heuristic postprocessing or to information loss. To directly address the needs of semantic applications, we present PROPS \u2013 an output representation designed to explicitly and uniformly express much of the proposition structure which is implied from syntax, and an associated tool for extracting it from dependency trees.", "creator": "LaTeX with hyperref package"}}}