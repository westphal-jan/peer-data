{"id": "1603.01855", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2016", "title": "Online Learning to Rank with Feedback at the Top", "abstract": "We consider an online learning to rank setting in which, at each round, an oblivious adversary generates a list of $m$ documents, pertaining to a query, and the learner produces scores to rank the documents. The adversary then generates a relevance vector and the learner updates its ranker according to the feedback received. We consider the setting where the feedback is restricted to be the relevance levels of only the top $k$ documents in the ranked list for $k \\ll m$. However, the performance of learner is judged based on the unrevealed full relevance vectors, using an appropriate learning to rank loss function. We develop efficient algorithms for well known losses in the pointwise, pairwise and listwise families. We also prove that no online algorithm can have sublinear regret, with top-1 feedback, for any loss that is calibrated with respect to NDCG. We apply our algorithms on benchmark datasets demonstrating efficient online learning of a ranking function from highly restricted feedback.", "histories": [["v1", "Sun, 6 Mar 2016 18:43:54 GMT  (217kb,D)", "http://arxiv.org/abs/1603.01855v1", "Appearing in AISTATS 2016"]], "COMMENTS": "Appearing in AISTATS 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sougata chaudhuri", "ambuj tewari"], "accepted": false, "id": "1603.01855"}, "pdf": {"name": "1603.01855.pdf", "metadata": {"source": "CRF", "title": "Online Learning to Rank with Feedback at the Top", "authors": ["Sougata Chaudhuri", "Ambuj Tewari"], "emails": [], "sections": [{"heading": null, "text": "We consider online learning to be a ranking setting in which, in each round, an unconscious opponent creates a list of m-documents related to a query, and the learner generates points for the ranking of the documents, the opponent then generates a relevance vector, and the learner updates his ranking according to the feedback received. We consider the setting in which feedback is limited to the relevance levels of only the k-documents in the ranking for k m to be relevant. However, the student's performance is judged on the basis of the undisclosed complete relevance vectors, using an appropriate learning method to rank losses. We develop efficient algorithms for known losses in meaningful, pairing and listic families. We also prove that no online algorithm can have sublinear regrets, with top-1 feedback, for losses calibrated in relation to NDCG. We apply our algorithms to benchmark data sets that demonstrate efficient online learning from a highly restricted ranking."}, {"heading": "1 Introduction", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "2 Preliminaries", "text": "When learning the ranking order, an instance is a matrix X-Rm-d, consisting of a list of m documents, each of which is represented as a feature vector in Rd, with each list referring to a single query. Monitoring takes the form of a relevance vector R = {0, 1,.., n} m, which represents the relevance of each document to the query. If n = 1, the relevance vector is staggered binary. For n > 1, the relevance vector is evaluated multiple times. Xi: denotes the line of X and Ri denotes the ith component of R. The subscript t is used exclusively to denote the time t. Thus, Rt denotes the relevance vector generated at the time t and Rt. We assume that feature vectors representing documents are standardized by RD in \"2. documents are ranked by a ranking function. The prevailing function is to be represented by a ranking function, it is a ranking function."}, {"heading": "3 Problem Setting and Learning to Rank Algorithm", "text": "The learner uses the feedback to choose his action for the next round (updated internal scoring function). The learner has the possibility to choose his action for the next round. (...) The learner uses the feedback to choose his action for the next round. (...) The learner uses the feedback to choose his action for the next round. (...) The learner uses the feedback to choose his action for the next round. (...) The learner suffers a loss in relation to the next round. (...) The learner suffers a loss in relation to the next round. (...) The learner uses the feedback to choose his action for the next round. (...) The learner uses the feedback to choose his action for the next round. (...) The learner uses the feedback to choose the next round. (...)"}, {"heading": "4 Unbiased Estimators of Gradients of Surrogates", "text": "Alg. 1 can be implemented for any ranking surrogate, as long as an unbiased estimator of the gradient can be constructed from random feedback. We will use online convex optimization techniques to obtain formal guarantees of remorse. The fourth method is a popular, non-convex surrogate method. Shorthand notations: We note that by chain rule, unbiased estimators of the method \"swtt\" (Xtw, Rt) = \"swtt\" (s wt, Rt), where s wt = \"Xtwt.\" SinceXt is deterministic in our environment, we focus on unbiased estimators of the method \"swtt\" (s wt, Rt) and take a matrix vector product with Xt. To reduce the difference, SinceXt is deterministic in our environment, we focus on unbiased estimators of the method \"swtt\" (s wt, Rt) and a matrix vector."}, {"heading": "4.1 Convex Surrogates", "text": "(s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s) s (s) s (s) s (s) s (s) s) s (s (s) s) s (s) s (s) s) s (s) s (s) s (s) s) s (s) s (s) s (s) s (s (s) s (s) s (s) s (s) s (s (s) s) s (s) s (s (s) s (s) s (s) s (s (s) s (s (s) s (s) s) s (s (s) s (s) s (s (s) s (s (s) s (s) s (s (s) s (s (s) s) s (s (s (s (s (s) s) s (s (s) s (s (s) s (s (s (s) s) s (s (s (s) s (s) s) s (s"}, {"heading": "4.1.1 Non-convex Surrogate", "text": "We give an example of a non-convective surrogate for which Alg. 1 is applicable (however, there are no guarantees of remorse due to non-convective convectivity). We choose the SmoothDCG surrogate, which is given in [Chapelle and Wu, 2010] and which has proven to be very competitive. SmoothDCG (like ListNet) defines a family of surrogates based on the cut-off point of DCG (see original paper [Chapelle and Wu, 2010] for details. We consider SmoothDCG @ 1, the smooth version of DCG @ 1 (i.e., DCG, which focuses only on the best placed document). The surrogate is defined as: \u03c6SD (s, R) = 1 \u2211 m j = 1 exp (sj /) exp (sj /) exp (Ri = 1G) exp (si /), where a known parameter is exa (exj = 1) and exp (exp = 1) exp (exp = 1)."}, {"heading": "4.2 Computational Complexity of", "text": "Algorithm 1Three of the four key steps that regulate the complexity of Alg. 1, i.e. the construction of s-t, \u03c3-t and the sorting can all be performed in O (m log (m)) time. Constructing the estimator is even simpler; the only bottleneck may have been calculations of p (\u03c3 (1) in the square loss, (modified) ListNet loss and SmoothDCG loss, and p (\u03c3 (1), \u03c3 (2))) in the RankSVM loss, because they contain sums of permutations. However, they have a compact representation, i.e. p (\u03c3 (1) = 1 \u2212 \u03b3m and p (\u03c3 (1), \u03c3 (2) = 1 \u2212 \u03b3 + 2\u03b3m (m \u2212 1). The calculations follow easily due to the nature of Pt (step-6 in the algorithm), which weights all permutations with the exception of T equally."}, {"heading": "4.3 Regret Bounds", "text": "The underlying definition of our algorithms is in each round in which we determine the learning rate and the expectation of all random occurrences in the algorithm.However, from the perspective of loss (s).1, in which we find ourselves, the learning rate and expectation of all random occurrences in the algorithm.2 The underlying definition of our algorithms is not in the algorithm.2 The underlying definition of our algorithms is not in the algorithm.1 The underlying definition of algorithms is not in the algorithm.2 The underlying definition of our algorithms is not in the algorithm.2 The underlying definition of our algorithms is not in the algorithm.1, in which we define the underlying algorithm.1, the underlying definition of algorithms is not in the algorithm.2 The underlying definition of our algorithms is not in the algorithm.2, the underlying algorithm is in the algorithm.2) The underlying algorithm is in the algorithm.2)"}, {"heading": "5 Impossibility of Sublinear Regret for NDCG Calibrated Surrogates", "text": "D (D). D (D). D (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D)."}, {"heading": "6 Empirical Results", "text": "We tested the quality of the ranking lists and thus the performance of the developing ranking functions, and thus the performance of the developing ranking functions, against the complete relevance vectors via NDCG10. Ranking functions: We compared Alg. 1, with top-1 feedback, on Squared, KL and SmoothDCG environment, and with top-2 feedback, on the RankSVM surrogate. Since our work is based on a novel feedback model, the performance of Alg. 1 could not be directly compared with any published baseline. So, based on the goal of our work, we selected two different ranking methods for comparison."}, {"heading": "7 Supplementary", "text": "The proof of Lemma 1: We repeat the Lemma before we provide the proof, for the ease of reading: Lemma 1: Let F: Rm 7 \u2192 Ra be a vector rated function, where m \u2265 1, a \u2265 1. For a fixed x-Rm, let k entries of x be observed randomly. That is, for a fixed probability distribution P and a random distribution P (Sm), observed tuple is that it should be possible to compose F (x) via k (or less) coordinations of the existence of an unbiased estimator of F (x), which consists of {L, x\u03c3 P (1),., x\u03c3 (k)}, is that it should be possible to compose F (or less) coordinations of x at a time. That is, F (x) should have the following structure: F (x) = sp."}], "references": [{"title": "Partial monitoring with side information", "author": ["G\u00e1bor Bart\u00f3k", "Csaba Szepesv\u00e1ri"], "venue": "In Algorithmic Learning Theory,", "citeRegEx": "Bart\u00f3k and Szepesv\u00e1ri.,? \\Q2012\\E", "shortCiteRegEx": "Bart\u00f3k and Szepesv\u00e1ri.", "year": 2012}, {"title": "Partial monitoring\u2013classification, regret bounds, and algorithms", "author": ["Gabor Bartok"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Bartok,? \\Q2014\\E", "shortCiteRegEx": "Bartok", "year": 2014}, {"title": "Approximating matrix p-norms", "author": ["Aditya Bhaskara", "Aravindan Vijayaraghavan"], "venue": "In Proceedings of the twenty-second annual ACM-SIAM symposium on Discrete Algorithms,", "citeRegEx": "Bhaskara and Vijayaraghavan.,? \\Q2011\\E", "shortCiteRegEx": "Bhaskara and Vijayaraghavan.", "year": 2011}, {"title": "Multi-scale exploration of convex functions and bandit convex optimization", "author": ["S\u00e9bastien Bubeck", "Ronen Eldan"], "venue": "arXiv preprint arXiv:1507.06580,", "citeRegEx": "Bubeck and Eldan.,? \\Q2015\\E", "shortCiteRegEx": "Bubeck and Eldan.", "year": 2015}, {"title": "On the (non-) existence of convex, calibrated surrogate losses for ranking", "author": ["Cl\u00e9ment Calauzenes", "Nicolas Usunier", "Patrick Gallinari"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Calauzenes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Calauzenes et al\\.", "year": 2012}, {"title": "Learning to rank: from pairwise approach to listwise approach", "author": ["Zhe Cao", "Tao Qin", "Tie-Yan Liu", "Ming-Feng Tsai", "Hang Li"], "venue": "In Proceedings of the 24th International conference on Machine learning,", "citeRegEx": "Cao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2007}, {"title": "Regret minimization under partial monitoring", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi", "Gilles Stoltz"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2006}, {"title": "Yahoo! learning to rank challenge overview", "author": ["Olivier Chapelle", "Yi Chang"], "venue": "Journal of Machine Learning Research-Proceedings Track,", "citeRegEx": "Chapelle and Chang.,? \\Q2011\\E", "shortCiteRegEx": "Chapelle and Chang.", "year": 2011}, {"title": "Gradient descent optimization of smoothed information retrieval metrics", "author": ["Olivier Chapelle", "Mingrui Wu"], "venue": "Information retrieval,", "citeRegEx": "Chapelle and Wu.,? \\Q2010\\E", "shortCiteRegEx": "Chapelle and Wu.", "year": 2010}, {"title": "Large margin optimization of ranking measures", "author": ["Olivier Chapelle", "Quoc Le", "Alex Smola"], "venue": "In NIPS Workshop: Machine Learning for Web Search,", "citeRegEx": "Chapelle et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2007}, {"title": "Online ranking with top-1 feedback", "author": ["Sougata Chaudhuri", "Ambuj Tewari"], "venue": "In Proceedings of the 18th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Chaudhuri and Tewari.,? \\Q2015\\E", "shortCiteRegEx": "Chaudhuri and Tewari.", "year": 2015}, {"title": "Subset ranking using regression", "author": ["David Cossock", "Tong Zhang"], "venue": "In Conference on Learning theory,", "citeRegEx": "Cossock and Zhang.,? \\Q2006\\E", "shortCiteRegEx": "Cossock and Zhang.", "year": 2006}, {"title": "Statistical analysis of bayes optimal subset ranking", "author": ["David Cossock", "Tong Zhang"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Cossock and Zhang.,? \\Q2008\\E", "shortCiteRegEx": "Cossock and Zhang.", "year": 2008}, {"title": "Online convex optimization in the bandit setting", "author": ["Abraham D Flaxman", "Adam Tauman Kalai", "H Brendan McMahan"], "venue": "In Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms,", "citeRegEx": "Flaxman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Flaxman et al\\.", "year": 2005}, {"title": "On multilabel classification and ranking with bandit feedback", "author": ["Claudio Gentile", "Francesco Orabona"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Gentile and Orabona.,? \\Q2014\\E", "shortCiteRegEx": "Gentile and Orabona.", "year": 2014}, {"title": "Balancing exploration and exploitation in listwise and pairwise online learning to rank", "author": ["Katja Hofmann", "Shimon Whiteson", "Maarten de Rijke"], "venue": "Information Retrieval,", "citeRegEx": "Hofmann et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hofmann et al\\.", "year": 2013}, {"title": "Optimizing search engines using clickthrough data", "author": ["Thorsten Joachims"], "venue": "In Proceedings of the 8th ACM SIGKDD,", "citeRegEx": "Joachims.,? \\Q2002\\E", "shortCiteRegEx": "Joachims.", "year": 2002}, {"title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions", "author": ["Robert Kleinberg", "Tom Leighton"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Kleinberg and Leighton.,? \\Q2003\\E", "shortCiteRegEx": "Kleinberg and Leighton.", "year": 2003}, {"title": "Learning to rank for information retrieval", "author": ["Tie-Yan Liu"], "venue": "Springer Science & Business Media,", "citeRegEx": "Liu.,? \\Q2011\\E", "shortCiteRegEx": "Liu.", "year": 2011}, {"title": "Discrete prediction games with arbitrary feedback and loss", "author": ["Antonio Piccolboni", "Christian Schindelhauer"], "venue": "In COLT,", "citeRegEx": "Piccolboni and Schindelhauer.,? \\Q2001\\E", "shortCiteRegEx": "Piccolboni and Schindelhauer.", "year": 2001}, {"title": "Learning diverse rankings with multiarmed bandits", "author": ["Filip Radlinski", "Robert Kleinberg", "Thorsten Joachims"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Radlinski et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Radlinski et al\\.", "year": 2008}, {"title": "On NDCG consistency of listwise ranking methods", "author": ["Pradeep Ravikumar", "Ambuj Tewari", "Eunho Yang"], "venue": "In Proceedings of the 14th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Ravikumar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ravikumar et al\\.", "year": 2011}, {"title": "Test collection based evaluation of information retrieval systems, volume 13", "author": ["Mark Sanderson"], "venue": "Now Publishers Inc,", "citeRegEx": "Sanderson.,? \\Q2010\\E", "shortCiteRegEx": "Sanderson.", "year": 2010}, {"title": "A cross-benchmark comparison of 87 learning to rank methods", "author": ["Niek Tax", "Sander Bockting", "Djoerd Hiemstra"], "venue": "Information Processing and Management,", "citeRegEx": "Tax et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tax et al\\.", "year": 2015}, {"title": "Interactively optimizing information retrieval systems as a dueling bandits problem", "author": ["Yisong Yue", "Thorsten Joachims"], "venue": "In Proceedings of the 26th ICML.,", "citeRegEx": "Yue and Joachims.,? \\Q2009\\E", "shortCiteRegEx": "Yue and Joachims.", "year": 2009}, {"title": "A support vector method for optimizing average precision", "author": ["Yisong Yue", "Thomas Finley", "Filip Radlinski", "Thorsten Joachims"], "venue": "In Proceedings of ACM SIGIR,", "citeRegEx": "Yue et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yue et al\\.", "year": 2007}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Martin Zinkevich"], "venue": "In Proceedings of the 20th International Conference on Machine Learning", "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [{"referenceID": 18, "context": ", rankers are trained on batch data consisting of instances and labels [Liu, 2011].", "startOffset": 71, "endOffset": 82}, {"referenceID": 22, "context": "In certain applications, such as deploying a new web app or developing a custom search engine, collecting large amount of training data might not be possible at all [Sanderson, 2010].", "startOffset": 165, "endOffset": 182}, {"referenceID": 16, "context": "Moreover, a clicked item might not actually be relevant to the user and there is also the problem of bias towards top ranked items in inferring feedback from user clicks [Joachims, 2002].", "startOffset": 170, "endOffset": 186}, {"referenceID": 10, "context": "Our work extends the work of Chaudhuri and Tewari [2015], by combining query-level ranking, in an online manner, with explicit but restricted feedback.", "startOffset": 29, "endOffset": 57}, {"referenceID": 5, "context": ", the cross entropy surrogate in ListNet [Cao et al., 2007] and hinge surrogate in RankSVM [Joachims, 2002], instead of discontinuous ranking measures like NDCG, AP, or ERR because the latter lead to intractable optimization problems.", "startOffset": 41, "endOffset": 59}, {"referenceID": 16, "context": ", 2007] and hinge surrogate in RankSVM [Joachims, 2002], instead of discontinuous ranking measures like NDCG, AP, or ERR because the latter lead to intractable optimization problems.", "startOffset": 39, "endOffset": 55}, {"referenceID": 12, "context": "The convex surrogates considered are from three major learning to ranking methods: squared loss from a pointwise method [Cossock and Zhang, 2008], hinge loss used in the pairwise RankSVM [Joachims, 2002] method, and (modified) cross-entropy surrogate used in the listwise ListNet [Cao et al.", "startOffset": 120, "endOffset": 145}, {"referenceID": 16, "context": "The convex surrogates considered are from three major learning to ranking methods: squared loss from a pointwise method [Cossock and Zhang, 2008], hinge loss used in the pairwise RankSVM [Joachims, 2002] method, and (modified) cross-entropy surrogate used in the listwise ListNet [Cao et al.", "startOffset": 187, "endOffset": 203}, {"referenceID": 5, "context": "The convex surrogates considered are from three major learning to ranking methods: squared loss from a pointwise method [Cossock and Zhang, 2008], hinge loss used in the pairwise RankSVM [Joachims, 2002] method, and (modified) cross-entropy surrogate used in the listwise ListNet [Cao et al., 2007] method.", "startOffset": 280, "endOffset": 298}, {"referenceID": 8, "context": "The non-convex surrogate considered is the SmoothDCG surrogate [Chapelle and Wu, 2010].", "startOffset": 63, "endOffset": 86}, {"referenceID": 21, "context": "The convex surrogates we mentioned above are widely used but are known to fail to be calibrated with respect to NDCG [Ravikumar et al., 2011].", "startOffset": 117, "endOffset": 141}, {"referenceID": 19, "context": "The proof for this rather surprising result is non-trivial and relies on exploiting a connection between the construction of optimal adversary strategies for hopeless finite action partial monitoring games [Piccolboni and Schindelhauer, 2001] and the structure of NDCG calibrated surrogates.", "startOffset": 206, "endOffset": 242}, {"referenceID": 4, "context": "We only focus on NDCG calibrated surrogates for the impossibility results since no (convex) surrogate can be calibrated for AP and ERR [Calauzenes et al., 2012].", "startOffset": 135, "endOffset": 160}, {"referenceID": 11, "context": "Pointwise Method: We will construct the unbiased estimator of the gradient of squared loss [Cossock and Zhang, 2006]: \u03c6sq(s,R) = \u2016s \u2212 R\u20162.", "startOffset": 91, "endOffset": 116}, {"referenceID": 16, "context": "Pairwise Method: We will construct the unbiased estimator of the gradient of hinge-like surrogate in RankSVM [Joachims, 2002]: \u03c6svm(s,R) = \u2211 i 6=j=1 1(Ri > Rj) max(0, 1 + sj \u2212 si).", "startOffset": 109, "endOffset": 125}, {"referenceID": 5, "context": "We will focus on the cross-entropy surrogate used in the highly cited ListNet [Cao et al., 2007] ranking algorithm and show how a very natural modification to the surrogate makes its gradient estimable in our partial feedback setting.", "startOffset": 78, "endOffset": 96}, {"referenceID": 8, "context": "We choose the SmoothDCG surrogate given in [Chapelle and Wu, 2010], which has been shown to have very competitive empirical performance.", "startOffset": 43, "endOffset": 66}, {"referenceID": 8, "context": "SmoothDCG, like ListNet, defines a family of surrogates, based on the cut-off point of DCG (see original paper [Chapelle and Wu, 2010] for details).", "startOffset": 111, "endOffset": 134}, {"referenceID": 26, "context": "The underlying deterministic part of our algorithm is online gradient descent (OGD) [Zinkevich, 2003].", "startOffset": 84, "endOffset": 101}, {"referenceID": 13, "context": "1 of [Flaxman et al., 2005], in our problem setting is:", "startOffset": 5, "endOffset": 27}, {"referenceID": 2, "context": "To get bound on Et\u2016z\u0303t\u20162, we used the following norm relation that holds for any matrix X [Bhaskara and Vijayaraghavan, 2011]: \u2016X\u2016p\u2192q = sup v 6=0 \u2016Xv\u2016q \u2016v\u2016p , where q", "startOffset": 90, "endOffset": 125}, {"referenceID": 3, "context": "For bandit online convex optimization problems with Lipschitz, convex surrogates, the best regret rate known so far, that can be achieved by an efficient algorithm, is O(T ) (however, see the work of Bubeck and Eldan [2015] for a non-constructive O(log(T ) \u221a T ) bound).", "startOffset": 200, "endOffset": 224}, {"referenceID": 21, "context": "We focus on NDCG calibrated surrogates (both convex and non-convex) that have been characterized by Ravikumar et al. [2011]. We first state the necessary and sufficient condition for a surrogate to be calibrated w.", "startOffset": 100, "endOffset": 124}, {"referenceID": 21, "context": "We focus on NDCG calibrated surrogates (both convex and non-convex) that have been characterized by Ravikumar et al. [2011]. We first state the necessary and sufficient condition for a surrogate to be calibrated w.r.t NDCG. For any score vector s and distribution \u03b7 on relevance space Y, let \u03c6\u0304(s, \u03b7) = ER\u223c\u03b7\u03c6(s,R). Moreover, we define G(R) = (G(R1), . . . , G(Rm)) >. Theorem 5.1. [Ravikumar et al., 2011, Thm. 6] A surrogate \u03c6 is NDCG calibrated iff for any distribution \u03b7 on relevance space Y, there exists an invertible, order preserving map g : R 7\u2192 R s.t. the unique minimizer s\u03c6(\u03b7) can be written as s\u03c6(\u03b7) = g ( ER\u223c\u03b7 [ G(R) Zm(R) ]) . (8) Informally, Eq. 8 states that argsort(s\u03c6(\u03b7)) \u2286 argsort(ER\u223c\u03b7 [ G(R) Zm(R) ] ) Ravikumar et al. [2011] give concrete examples of NDCG calibrated surrogates, including how some of the popular surrogates can be converted into NDCG calibrated ones: e.", "startOffset": 100, "endOffset": 746}, {"referenceID": 19, "context": "(Sketch) The proof builds on the proof of hopeless finite action partial monitoring games given by Piccolboni and Schindelhauer [2001]. An examination of their proof of Thm.", "startOffset": 99, "endOffset": 135}, {"referenceID": 19, "context": "3 of Piccolboni and Schindelhauer [2001] cannot be directly extended to prove the impossibility result because it relies on constructing a connected graph on vertices defined by neighboring actions of learner.", "startOffset": 5, "endOffset": 41}, {"referenceID": 23, "context": "ListNet is not only one of the most cited ranking algorithms (over 700 citations according to Google Scholar), but also one of the most validated algorithms [Tax et al., 2015].", "startOffset": 157, "endOffset": 175}, {"referenceID": 7, "context": "They were Yahoo\u2019s Learning to Rank Challenge dataset [Chapelle and Chang, 2011] and a dataset published by Russian search engine Yandex [IM-2009].", "startOffset": 53, "endOffset": 79}], "year": 2016, "abstractText": "We consider an online learning to rank setting in which, at each round, an oblivious adversary generates a list of m documents, pertaining to a query, and the learner produces scores to rank the documents. The adversary then generates a relevance vector and the learner updates its ranker according to the feedback received. We consider the setting where the feedback is restricted to be the relevance levels of only the top k documents in the ranked list for k m. However, the performance of learner is judged based on the unrevealed full relevance vectors, using an appropriate learning to rank loss function. We develop efficient algorithms for well known losses in the pointwise, pairwise and listwise families. We also prove that no online algorithm can have sublinear regret, with top-1 feedback, for any loss that is calibrated with respect to NDCG. We apply our algorithms on benchmark datasets demonstrating efficient online learning of a ranking function from highly restricted feedback.", "creator": "LaTeX with hyperref package"}}}