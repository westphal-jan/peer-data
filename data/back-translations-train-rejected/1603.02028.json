{"id": "1603.02028", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2016", "title": "Adaptive Visualisation System for Construction Building Information Models Using Saliency", "abstract": "Building Information Modeling (BIM) is a recent construction process based on a 3D model, containing every component related to the building achievement. Architects, structure engineers, method engineers, and others participant to the building process work on this model through the design-to-construction cycle. The high complexity and the large amount of information included in these models raise several issues, delaying its wide adoption in the industrial world. One of the most important is the visualization: professionals have difficulties to find out the relevant information for their job. Actual solutions suffer from two limitations: the BIM models information are processed manually and insignificant information are simply hidden, leading to inconsistencies in the building model. This paper describes a system relying on an ontological representation of the building information to label automatically the building elements. Depending on the user's department, the visualization is modified according to these labels by automatically adjusting the colors and image properties based on a saliency model. The proposed saliency model incorporates several adaptations to fit the specificities of architectural images.", "histories": [["v1", "Mon, 7 Mar 2016 12:25:33 GMT  (1215kb,D)", "http://arxiv.org/abs/1603.02028v1", "10 pages, 5 figures, to be submitted"]], "COMMENTS": "10 pages, 5 figures, to be submitted", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["hugo martin", "sylvain chevallier", "eric monacelli"], "accepted": false, "id": "1603.02028"}, "pdf": {"name": "1603.02028.pdf", "metadata": {"source": "CRF", "title": "Adaptive Visualisation System for Construction Building Information Models Using Saliency", "authors": ["Hugo Martin", "Sylvain Chevallier"], "emails": ["hug.martin@bouygues-construction.com", "sylvain.chevallier@uvsq.fr", "eric.monacelli@uvsq.fr"], "sections": [{"heading": null, "text": "Keywords: Importance, Building Information Modeling, Virtual Reality, Building Architecture, Data Visualization, Immersion, Knowledge Representation."}, {"heading": "1 Introduction", "text": "In fact, one is able to establish oneself in a country where most people are able to move to another world."}, {"heading": "2 State of the Art", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Building Management Ontology", "text": "Two different approaches can be identified in the ontology literature applied to building management: the first approach is task-oriented and aims to evaluate the benefits of IM- over non-BIM technologies, based on a complete description of the tasks that take place in the Li et al. [2014] planning process; the work developed in this paper follows a second approach based on user profile centering: all 3D model objects are classified according to their relationship to user profiles; this classification is based either on the intrinsic properties of the Aksamija and Grobler object [2007] or on a model of interaction between different actors Lee et al. [2014] Costa and Lima [2014]. Therefore, one element of the 3D model, such as a wall, is relevant for the work of a civil engineer, but not for a plumbing engineer who deals with piping and water circulation."}, {"heading": "2.2 Saliency", "text": "Many calculation models have been proposed to predict visual attention using highlighting maps, such as Tsotsos et al. [1995] Itti and Koch [2000] Huang and Ahuja [2012]. A comprehensive review could be found in Zhao and Koch [2013], and an evaluation of existing models is proposed based on the highlighting scale Bylinskii et al. [2012]. A commonly found method in highlighting models is to analyze the contrast of an image in terms of intensity, color, and orientation. highlighting models are a simple and quick method for analyzing images and predicting an accurate map of visual attention. Therefore, highlighting models could analyze an image originating from a BIM scene and determine the visually attractive elements of the scenery. In the context of architectural images, the visual scene often displays strong depth information and vanishing points."}, {"heading": "3 Ontology-based Visualization System", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Description of the Proposed System", "text": "Our system implements a method for recognizing vanishing points and calculating the orientation map based on a projection of these points as described in Section 3.2. In the case of BIM, all images are generated by a 3D viewer software, with engineering colors only selected to create a contrast between the elements. Color codes used do not contain important information; colors are often selected randomly. We used the image synthesis highlighting model, which directs the color selection to maximize the highlighting of important BIM components in the scene. In conjunction with a color selection algorithm, our system selects colors that keep the user's visual attention on important elements without hiding or erasing others. Our algorithm is described in Section 3.3."}, {"heading": "3.2 Vanishing Point-Sensitive Computation", "text": "This paper proposes a method for taking the vanishing point into account in the highlighting model. Orientation recognition has been replaced by a vanishing point projection process. Our system is based on the work of Feng et al. to detect the vanishing points Feng et al. [2010] Tardif [2009]. To illustrate this, we applied our algorithm on an example image and the result is shown in Fig. 2. From an input image, the vanishing point is detected using the Feng algorithm, the projection from this vanishing point is calculated. The projection image (Fig. 2, top right) is then analysed in its vertical contrast (Fig. 2, bottom right). A reverse transformation of the result is added to the global model, as the orientation depth of focus map, as shown in the right part of Fig. 3, the characteristics of the Itti map and the Itti indicators calculated from the original Itti model."}, {"heading": "3.3 Enhancing Visual Attention", "text": "The aforementioned cerebral consecrated cerebral consecrated cerebral consecrated cerebral consecrated cerebral consecrated cerebral consecrated cerebral consecrated rf\u00fc ide cerebral consecrated eaeaeaeaeeenrllcnllllllcnlrcnlcnlcnlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "4 Experimental Validation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Methodology and Experiments", "text": "An experiment in the real state was set up, based on three real BIM models by Bouygues Construction Projects from France, in the cities of Paris, Nantes and Lyon. Two of them, Paris and Nantes, mix structural elements (wall, roof, beams,...) and construction methods elements (crane, scaffolding, formwork). The third, Lyon, includes sanitary elements (pipes). The three models were created on 3D construction software \"Revit\" and then exported in real-time 3D engine Unity3D R \u00a9. Each element was given a name and information about its color or type of materials (concrete, metal, cloth...). In Unity3D R \u00a9, these elements are automatically classified as structure, method or sanitary elements that use structural ontology developed for the system.Four visual scenes were taken for each model, and the associated depth plans were compressed. Our system determines the color change for each user profiles that are available with the 3D model Lyon, and the structural elements are improved with four models."}, {"heading": "4.2 Results", "text": "The results of the experiments are consistent in 59.4% of all cases and are compared with the 19% of the answers of the experts who select the original image. Results confirm that our system has improved the visualization quality while retaining all the information on the screen. Nevertheless, the \"indifferent\" answers indicate that there is room for improvement in the system. Experts have confirmed that they have seen the benefit of the system and are waiting for the industrial BIM version. We applied Wilcoxon's Signed Rank Test. For each image, we count the number of engineers who selected the modified or probably modified system for the first sample and those who probably chose the original or the original for the second sample. For the p value that was decided to limit 0.05, the p-value result is 0.001, which confirms the importance of the experiment.A limitation that occurred during the Paris experiments is the most convenient method to evaluate the model corresponding to another category, using one."}, {"heading": "5 Conclusion and perspectives", "text": "This paper describes a system for improving the visualization of the BIM model, in which alienations are used to distort the visual focus on the most relevant elements based on a specific user profile. Based on the knowledge of the BIM managers, we developed a classifier for sorting the elements of the model according to their category in relation to the individual building departments. We described a customized architectural image highlighting system that implements perspective integration for the orientation map and integrated depth hints. Finally, the system will be used in an application to support BIM engineers. The system adjusts the model colors to retain the visual attention of the important elements for the user profile. An experiment has been conducted and shows positively significant results and perspectives for global improvement. Future work will focus on extending the system to include other types of transformation to improve the visualization. Possible candidates include transparency and spatial position. It is important to note that the building system is not embedded in the transformations that are allowed."}, {"heading": "Acknowledgments", "text": "This work was carried out in collaboration with Bouygues Construction and the resulting application will be integrated into the future BIM dive room. Research was funded in partnership with the ANRT (Association Nationale de Recherche et Technologie)."}], "references": [{"title": "Architectural ontology: development of machine-readable representations for building design drivers", "author": ["A. Aksamija", "F. Grobler"], "venue": null, "citeRegEx": "Aksamija and Grobler.,? \\Q2007\\E", "shortCiteRegEx": "Aksamija and Grobler.", "year": 2007}, {"title": "Knowledge representations with ontology support for collaborative engineering in architecture engineering and construction", "author": ["R. Costa", "C. Lima"], "venue": null, "citeRegEx": "Costa and Lima.,? \\Q2014\\E", "shortCiteRegEx": "Costa and Lima.", "year": 2014}, {"title": "The contractors\u2019 guide to BIM", "author": ["J.W. Ernstrom"], "venue": "Associated General Contractors of America,", "citeRegEx": "Ernstrom.,? \\Q2006\\E", "shortCiteRegEx": "Ernstrom.", "year": 2006}, {"title": "Semi-automatic 3d reconstruction of piece planar building models from single image", "author": ["C. Feng", "F. Deng", "V. Kamat"], "venue": "International Conference on Construction Applications of Virtual Reality,", "citeRegEx": "Feng et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2010}, {"title": "Visual attention to surfaces in three-dimensional space", "author": ["Z.J. He", "K. Nakayama"], "venue": "Proceedings of the National Academy of Sciences (PNAS),", "citeRegEx": "He and Nakayama.,? \\Q1995\\E", "shortCiteRegEx": "He and Nakayama.", "year": 1995}, {"title": "Attention and visual memory in visualization and computer graphics", "author": ["C.G Healey", "J.T. Enns"], "venue": "Visualization and Computer Graphics, IEEE Transactions on,", "citeRegEx": "Healey and Enns.,? \\Q2012\\E", "shortCiteRegEx": "Healey and Enns.", "year": 2012}, {"title": "Saliency detection via divergence analysis: A unified perspective", "author": ["J.-B. Huang", "N. Ahuja"], "venue": "In Int. Conf. on Pattern Recognition (ICPR),", "citeRegEx": "Huang and Ahuja.,? \\Q2012\\E", "shortCiteRegEx": "Huang and Ahuja.", "year": 2012}, {"title": "A saliency-based search mechanism for overt and covert shifts of visual attention", "author": ["L. Itti", "C. Koch"], "venue": "Vision research,", "citeRegEx": "Itti and Koch.,? \\Q2000\\E", "shortCiteRegEx": "Itti and Koch.", "year": 2000}, {"title": "Contribution of depth to visual attention: comparison of a computer model and human", "author": ["T. Jost", "N. Ouerhani", "R.v. Wartburg", "R. Muri", "H. Hugli"], "venue": null, "citeRegEx": "Jost et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Jost et al\\.", "year": 2004}, {"title": "Building information modeling: planning and managing construction projects with 4D CAD and simulations", "author": ["W. Kymmell"], "venue": null, "citeRegEx": "Kymmell.,? \\Q2008\\E", "shortCiteRegEx": "Kymmell.", "year": 2008}, {"title": "Depth matters: Influence of depth cues on visual saliency", "author": ["C. Lang", "T.V. Nguyen", "H. Katti", "K. Yadati", "M. Kankanhalli", "S. Yan"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Lang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lang et al\\.", "year": 2012}, {"title": "A filter-mediated communication model for design collaboration in building construction", "author": ["J. Lee", "Y. Jeong", "M. Oh", "S.W. Hong"], "venue": "The Scientific World Journal,", "citeRegEx": "Lee et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "A projectbased quantification of BIM benefits", "author": ["J. Li", "L. Hou", "X. Wang", "J. Wang", "J. Guo", "S. Zhang", "Y. Jiao"], "venue": "International Journal of Advanced Robotics Systems,", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "A new approach to vanishing point detection in architectural environments", "author": ["C. Rother"], "venue": "Image and Vision Computing,", "citeRegEx": "Rother.,? \\Q2002\\E", "shortCiteRegEx": "Rother.", "year": 2002}, {"title": "Attention-based vanishing point detection", "author": ["F. Stentiford"], "venue": "In Image Processing,", "citeRegEx": "Stentiford.,? \\Q2006\\E", "shortCiteRegEx": "Stentiford.", "year": 2006}, {"title": "Non-iterative approach for fast and accurate vanishing point detection", "author": ["J-P Tardif"], "venue": "In Computer Vision,", "citeRegEx": "Tardif.,? \\Q2009\\E", "shortCiteRegEx": "Tardif.", "year": 2009}, {"title": "Modeling visual attention via selective tuning", "author": ["J.K. Tsotsos", "S.M. Culhane", "W.Y.K. Winky", "Y. Lai", "N. Davis", "F. Nuflo"], "venue": "Artificial Intelligence,", "citeRegEx": "Tsotsos et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Tsotsos et al\\.", "year": 1995}, {"title": "Vanishing point detection for architectural photogrammetry", "author": ["F.A Van Den Heuvel"], "venue": "International archives of photogrammetry and remote sensing,", "citeRegEx": "Heuvel.,? \\Q1998\\E", "shortCiteRegEx": "Heuvel.", "year": 1998}, {"title": "Learning saliency-based visual attention: A review", "author": ["Q. Zhao", "C. Koch"], "venue": "Signal Processing,", "citeRegEx": "Zhao and Koch.,? \\Q2013\\E", "shortCiteRegEx": "Zhao and Koch.", "year": 2013}], "referenceMentions": [{"referenceID": 2, "context": "pictures, but it is mostly used in a technical approach [Ernstrom, 2006] [for Construction Innovation, 2007] Kymmell [2008].", "startOffset": 56, "endOffset": 72}, {"referenceID": 2, "context": "pictures, but it is mostly used in a technical approach [Ernstrom, 2006] [for Construction Innovation, 2007] Kymmell [2008]. Several distinct experts are contributing to BIM models, each one modifying or adding its own objects and notes on the 3D model.", "startOffset": 57, "endOffset": 124}, {"referenceID": 9, "context": "The first approach is task-centric and aims at assessing the benefit of BIM versus non-BIM technologies, relying on a complete description of the tasks taking place in the building design process Li et al. [2014]. The work developed in this paper follows a second approach, user profile-centric : all 3D model objects are classified depending on their relation with the users profile.", "startOffset": 196, "endOffset": 213}, {"referenceID": 0, "context": "This classification is either based on the intrinsic properties of the object Aksamija and Grobler [2007] or from a model of interaction between different actors Lee et al.", "startOffset": 78, "endOffset": 106}, {"referenceID": 0, "context": "This classification is either based on the intrinsic properties of the object Aksamija and Grobler [2007] or from a model of interaction between different actors Lee et al. [2014] Costa and Lima [2014].", "startOffset": 78, "endOffset": 180}, {"referenceID": 0, "context": "This classification is either based on the intrinsic properties of the object Aksamija and Grobler [2007] or from a model of interaction between different actors Lee et al. [2014] Costa and Lima [2014]. As such, an element of the 3D model, for example a wall, is relevant for the work of a structure engineer, but is not for a plumbing engineer who is concerned by pipes and water circulation.", "startOffset": 78, "endOffset": 202}, {"referenceID": 10, "context": "Many computational models have been proposed to predict the visual attention through saliency map, such as Tsotsos et al. [1995] Itti and Koch [2000] Huang and Ahuja [2012].", "startOffset": 107, "endOffset": 129}, {"referenceID": 5, "context": "[1995] Itti and Koch [2000] Huang and Ahuja [2012].", "startOffset": 7, "endOffset": 28}, {"referenceID": 5, "context": "[1995] Itti and Koch [2000] Huang and Ahuja [2012]. A comprehensive review could be found in Zhao and Koch [2013] and an assessment of the existing models is proposed on the MIT saliency benchmark Bylinskii et al.", "startOffset": 28, "endOffset": 51}, {"referenceID": 5, "context": "[1995] Itti and Koch [2000] Huang and Ahuja [2012]. A comprehensive review could be found in Zhao and Koch [2013] and an assessment of the existing models is proposed on the MIT saliency benchmark Bylinskii et al.", "startOffset": 28, "endOffset": 114}, {"referenceID": 5, "context": "[1995] Itti and Koch [2000] Huang and Ahuja [2012]. A comprehensive review could be found in Zhao and Koch [2013] and an assessment of the existing models is proposed on the MIT saliency benchmark Bylinskii et al. [2012]. A commonly found methodology in saliency-based models is to analyze the contrast of an image in term of intensity, color and orientation.", "startOffset": 28, "endOffset": 221}, {"referenceID": 5, "context": "[1995] Itti and Koch [2000] Huang and Ahuja [2012]. A comprehensive review could be found in Zhao and Koch [2013] and an assessment of the existing models is proposed on the MIT saliency benchmark Bylinskii et al. [2012]. A commonly found methodology in saliency-based models is to analyze the contrast of an image in term of intensity, color and orientation. Saliency models are an easy and fast way of analyzing images and predicting an accurate map of visual attention. Hence saliency models could analyze an image coming from a BIM scene and determine the visually attractive elements of the scene. In the context of architectural images, the visual scene often display strong depth information and vanishing point. It has been shown that the depth clues are highly informative and have a strong influence on object saliency Lang et al. [2012], He and Nakayama [1995].", "startOffset": 28, "endOffset": 848}, {"referenceID": 4, "context": "[2012], He and Nakayama [1995]. Several works linking vanishing point and visual attention have been conducted.", "startOffset": 8, "endOffset": 31}, {"referenceID": 4, "context": "[2012], He and Nakayama [1995]. Several works linking vanishing point and visual attention have been conducted. Stentiford Stentiford [2006] has proposed to detect vanishing points based on the visual attention.", "startOffset": 8, "endOffset": 141}, {"referenceID": 4, "context": "[2012], He and Nakayama [1995]. Several works linking vanishing point and visual attention have been conducted. Stentiford Stentiford [2006] has proposed to detect vanishing points based on the visual attention. Itti and Koch model integrated the orientation analysis following constant axes (vertical, horizontal, diagonal). Architecture pictures contain important vanishing points which are easily detectables Van Den Heuvel [1998], Rother [2002] as most of the shapes follow the projection of vanishing points.", "startOffset": 8, "endOffset": 434}, {"referenceID": 4, "context": "[2012], He and Nakayama [1995]. Several works linking vanishing point and visual attention have been conducted. Stentiford Stentiford [2006] has proposed to detect vanishing points based on the visual attention. Itti and Koch model integrated the orientation analysis following constant axes (vertical, horizontal, diagonal). Architecture pictures contain important vanishing points which are easily detectables Van Den Heuvel [1998], Rother [2002] as most of the shapes follow the projection of vanishing points.", "startOffset": 8, "endOffset": 449}, {"referenceID": 3, "context": "Our system relies on the work of Feng et al. for the detection of the vanishing points Feng et al. [2010] Tardif [2009].", "startOffset": 33, "endOffset": 106}, {"referenceID": 3, "context": "Our system relies on the work of Feng et al. for the detection of the vanishing points Feng et al. [2010] Tardif [2009]. As an illustration, we applied our algorithm on a sample image and the result is shown Fig.", "startOffset": 33, "endOffset": 120}, {"referenceID": 3, "context": "Our system relies on the work of Feng et al. for the detection of the vanishing points Feng et al. [2010] Tardif [2009]. As an illustration, we applied our algorithm on a sample image and the result is shown Fig. 2. From an input image, the vanishing point are detected with the Feng algorithm, the projection from this vanishing point is computed. The projection image (Fig. 2, top right) is then analyzed in its vertical contrast (Fig. 2, bottom right). An inverse transform of the result is added to the global model as the orientation conspicuity map, as shown on the right part of Fig. 3. This figure displays the saliencies computed with the original Itti model Itti and Koch [2000] on the left and the saliencies obtained with our model on the right.", "startOffset": 33, "endOffset": 689}, {"referenceID": 3, "context": "Our system relies on the work of Feng et al. for the detection of the vanishing points Feng et al. [2010] Tardif [2009]. As an illustration, we applied our algorithm on a sample image and the result is shown Fig. 2. From an input image, the vanishing point are detected with the Feng algorithm, the projection from this vanishing point is computed. The projection image (Fig. 2, top right) is then analyzed in its vertical contrast (Fig. 2, bottom right). An inverse transform of the result is added to the global model as the orientation conspicuity map, as shown on the right part of Fig. 3. This figure displays the saliencies computed with the original Itti model Itti and Koch [2000] on the left and the saliencies obtained with our model on the right. The saliency model of the proposed system takes also into account the contrast of depth. The 3D software computes a depth map associated with each generated image. We have implemented the work of Jost et al. Jost et al. [2004] to include the information extracted from a depth conspicuity map in the system.", "startOffset": 33, "endOffset": 985}, {"referenceID": 3, "context": "Our system relies on the work of Feng et al. for the detection of the vanishing points Feng et al. [2010] Tardif [2009]. As an illustration, we applied our algorithm on a sample image and the result is shown Fig. 2. From an input image, the vanishing point are detected with the Feng algorithm, the projection from this vanishing point is computed. The projection image (Fig. 2, top right) is then analyzed in its vertical contrast (Fig. 2, bottom right). An inverse transform of the result is added to the global model as the orientation conspicuity map, as shown on the right part of Fig. 3. This figure displays the saliencies computed with the original Itti model Itti and Koch [2000] on the left and the saliencies obtained with our model on the right. The saliency model of the proposed system takes also into account the contrast of depth. The 3D software computes a depth map associated with each generated image. We have implemented the work of Jost et al. Jost et al. [2004] to include the information extracted from a depth conspicuity map in the system. In the proposed saliency model, other features map are computed as in the Itti model Itti and Koch [2000]. Thus four conspicuity maps are built, i.", "startOffset": 33, "endOffset": 1172}, {"referenceID": 7, "context": "Itti and Koch [2000]. Right: orientation conspicuity map computed with our model.", "startOffset": 0, "endOffset": 21}, {"referenceID": 5, "context": "The works of Ware Ware [2004] and Healey Healey and Enns [2012] describe links between visual attention, visualization and colors.", "startOffset": 41, "endOffset": 64}, {"referenceID": 5, "context": "The works of Ware Ware [2004] and Healey Healey and Enns [2012] describe links between visual attention, visualization and colors. The thorough experiments of Wolfe Wolfe [2000] caracterize the links between colors and visual attention.", "startOffset": 41, "endOffset": 178}], "year": 2016, "abstractText": "Building Information Modeling (BIM) is a recent construction process based on a 3D model, containing every component related to the building achievement. Architects, structure engineers, method engineers, and others participant to the building process work on this model through the design-to-construction cycle. The high complexity and the large amount of information included in these models raise several issues, delaying its wide adoption in the industrial world. One of the most important is the visualization: professionals have difficulties to find out the relevant information for their job. Actual solutions suffer from two limitations: the BIM models information are processed manually and insignificant information are simply hidden, leading to inconsistencies in the building model. This paper describes a system relying on an ontological representation of the building information to label automatically the building elements. Depending on the user\u2019s department, the visualization is modified according to these labels by automatically adjusting the colors and image properties based on a saliency model. The proposed saliency model incorporates several adaptations to fit the specificities of architectural images.", "creator": "LaTeX with hyperref package"}}}