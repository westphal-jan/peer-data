{"id": "1603.03158", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Mar-2016", "title": "Scenario Submodular Cover", "abstract": "Many problems in Machine Learning can be modeled as submodular optimization problems. Recent work has focused on stochastic or adaptive versions of these problems. We consider the Scenario Submodular Cover problem, which is a counterpart to the Stochastic Submodular Cover problem studied by Golovin and Krause. In Scenario Submodular Cover, the goal is to produce a cover with minimum expected cost, where the expectation is with respect to an empirical joint distribution, given as input by a weighted sample of realizations. In contrast, in Stochastic Submodular Cover, the variables of the input distribution are assumed to be independent, and the distribution of each variable is given as input. Building on algorithms developed by Cicalese et al. and Golovin and Krause for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions. The first achieves an approximation factor of O(log Qm), where m is the size of the sample and Q is the goal utility. The second, simpler algorithm achieves an approximation bound of O(log QW), where Q is the goal utility and W is the sum of the integer weights. (Both bounds assume an integer-valued utility function.) Our results yield approximation bounds for other problems involving non-independent distributions that are explicitly specified by their support.", "histories": [["v1", "Thu, 10 Mar 2016 06:43:52 GMT  (46kb,D)", "http://arxiv.org/abs/1603.03158v1", "32 pages, 1 figure"]], "COMMENTS": "32 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["nathaniel grammel", "lisa hellerstein", "devorah kletenik", "patrick lin"], "accepted": false, "id": "1603.03158"}, "pdf": {"name": "1603.03158.pdf", "metadata": {"source": "CRF", "title": "Scenario Submodular Cover", "authors": ["Nathaniel Grammel", "Lisa Hellerstein", "Devorah Kletenik", "Patrick Lin"], "emails": ["ngrammel@nyu.edu", "lisa.hellerstein@nyu.edu", "kletenik@sci.brooklyn.cuny.edu", "plin15@illinois.edu"], "sections": [{"heading": null, "text": "* Partially supported by NSF Grant 1217968c \u00a9 2016 N. Grammel, L. Hellerstein, D. Kletenik & P. Lin.ar Xiv: 160 3.03 158v 1"}, {"heading": "1. Introduction", "text": "We have a problem in which we focus on the classical problem of entity identification and that is a fundamental problem in submodular optimization. (We have a fundamental problem that relates to a variety of machine learning problems that require the construction of a decision tree where the goal is to minimize the expected costs. Examples are problems of identification of entities (exact learning with member questions), classification (equivalence class determination) and decision region (cf. Golovin and Krause). (2012); Bellala et al al. (2014) Other applications include the reduction of predictive costs for learned classifications when there are costs for defining problems. (2012)."}, {"heading": "Results", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "Applications", "text": "rE \"s, he says,\" it is as if he will be able to erenie.n \"rE\" the erahcn-eSrcnlhsrteeSrteeaJnlhsrteeaeaJnln, he says."}, {"heading": "Organization", "text": "We start with definitions in Section 2. In Section 3, we present the overview of the Mixed Greedy Algorithm. Finally, we present Scenario Mixed Greedy in Section 4, followed by Scenario Adaptive Greedy in Section 5.2. In the literature on surgical research, stochastic function evaluation is often referred to as sequential testing or sequential diagnosis."}, {"heading": "2. Definitions", "text": "Let us be N = {1,.., n} the set of items and then a finite set of items (B). A sample is a subset of items (B). A realization of items is an element that represents a partial realization of items, where for i | N = ai the state of item i. We also refer to an element of item i. We refer to an element of item i. b) b) such a state as a partial realization that is identical to b = a partial realization. Partial realization b) represents the partial realization of items I = [i | bi 6 = II}, where each item i (I) is assigned. For quantity bi [Z], the partial realization that is identical to b = a partial realization. For partial realizations b)."}, {"heading": "3. Mixed Greedy", "text": "The Mixed Greedy Algorithm is a generalization of the approximation algorithm developed by Cicalese et al. for the problem of equivalence class determination. This algorithm effectively solves the scenario submodular coverage problem for a specific \"pair function\" related to equivalence class determination. In contrast, Mixed Greedy can be used on any monotonous, submodular utility function. Following Cicalese et al. we present Mixed Greedy as an output of a decision tree. If the strategy is to be used only for one insight, it is not necessary to build the entire tree. While Mixed Greedy is very similar to the algorithm of Cicalese et al, we describe it here in full so that our presentation is self-contained."}, {"heading": "3.1. Algorithm", "text": "The Mixed Greedy algorithms build a decision tree for the Scenario SC instance (g, Q, S, w, c). The Mixed Greedy algorithms build a decision tree for the Scenario SC instance (g, Q, S, W, c). The Mixed Greedy algorithms work by calling the recursive function MixedGreedy, the pseudo-code of which we present in Algorithm 1. In the original request to MixedGreedy, b, the child is treated in the same way as the child. The Mixed Greedy algorithms work by calling the recursive function MixedGreedy, the pseudo-code of which we present in Algorithm 1. In the first request to MixedGreedy, b, the value of the recursive calls is specified; the other values remain fixed. Each call to MixedGreedy constructs a subtree for the full tree, rooted in a node of that tree."}, {"heading": "4. Scenario Mixed Greedy", "text": "We now present a variant of Mixed Greedy that eliminates the dependence on \u03c1 in the approximation in favor of a dependence on m, the size of the sample. We call this variant Mixed Greedy. Scenario Mixed Greedy works by first modifying g to create a new usage function gS, and then Mixed Greedy with gS instead of g. Usage function gS is created by combining g with another usage function hS, using the standard OR construction described at the end of section 2. Here hS: (ergo:) n \u2192 Z \u2265 0, where hS (b) = m \u2212 | {a \u0441S: a b} | and m = | S |. Thus, hS (b) is the total number of assignments eliminated from S because they are incompatible with the partial state information in b. Usage information m for hS when all assignments in S have been eliminated."}, {"heading": "Scenario Mixed Greedy:", "text": "The third step of the process is reached when the final partial realization of Qm has to be achieved, because the target utilization of Qm has to be achieved even on realizations that are not in S.Theorem 2. Mixed Greedy is an approximation algorithm for the Scenario Submodular Coverage Problem, which reaches an approximation factor of O (logQm), where m reaches the size of the sample utilization of S. Proof Scenario Mixed Greedy."}, {"heading": "5. Scenario Adaptive Greedy", "text": "Scenario Adaptive Greedy works by first constructing a utility function gW, which is generated by applying the standard OR construction to g and utility function hW. Here, hW: hW: (\u0435\u0442 {\u043a}) n \u2192 Z \u2265 0, where hW (b) = W \u2212 \u2211 a \u0418S: a bw (a). Intuitively, hW (b) is the total weight of the assignments that were eliminated from S, because they are achieved with the partial information in b. Utility value W is achieved for hW when all assignments in S have been eliminated. It is obvious that hW is monotonous and submodular. The function gW reaches its target value QW when all possible realizations of the sample have been eliminated or when the target value for g is achieved. Once gW is constructed, Scenario Adaptive Greedy runs on gW. In an online setting, Scenario Adaptive Greedy uses the following procedure to determine the adaptation of initially unknown objects to a realization."}, {"heading": "Scenario Adaptive Greedy:", "text": "1. Construct modified usage function gW by applying the standard OR construct to g and usage function hW.2. Run Adaptive Greed for usage function gW with target value QW, in relation to the sample distribution DS, w to determine the decisions to be made on a.3. According to target value QW, if the partial realization b, which does not meet the states of the selected positions of a, then select the remaining positions in N in arbitrary order to g (b) = Q.In Appendix C we prove the following lemma.Lemma 3 usage function gW is adaptive submodular in relation to the sample distribution DS, w.The consequence of Lemma 3 is that we can now use any algorithm designed for adaptive submodular usage functions. This gives us theorem 4.Theorem 4 usage function gW is adaptive submodular distribution DS, w.The consequence of Lemma is that we can now use any algorithm designed for usage functions designed for use."}, {"heading": "Acknowledgments", "text": "L. Hellerstein thanks Andreas Krause for the useful discussions at the ETH, and in particular for drawing our attention to the border between Streeter and Golovin for a submodular minimum sum cover."}, {"heading": "Appendix A. Proof of Bound for Mixed Greedy", "text": "We will first discuss Wolsey's algorithm, which is used in FindBudget."}, {"heading": "A.1. Wolsey\u2019s Greedy Algorithm for Budgeted Submodular Cover", "text": "The Budgeted Submodular Coverage Problem takes as input a finite amount N of elements, a positive integer B > 0 as budget, a monotonous submodular sentence function f: 2N \u2192 Z \u2265 0 and a vector c indexed by the elements in N, so ci-R \u2265 0 for all i-N. The problem is to find a subset R'N, so that i-R ci \u2264 B, and f (R) is maximized. Wolsey (1982) developed a greedy approximation algorithm for this problem. Here we present the pseudocode for this algorithm, together with Wolsey's approximation limit. Procedure WolseyGreedy (N, f, c, B) 1: output \u2190 0, R \u2190, k \u2190 0 2: repeated 3: k \u2190 k + 1 4: budics is the i-N, the f (R-i) \u2212 ci among all I problems B: output \u2190, R \u00b2 output commodity (Wolk = 7)."}, {"heading": "A.2. Analysis of Mixed Greedy", "text": "Consider a scenario SC instance (g, Q, S, c, c), and a partial realization B (b). Consider a scenario SC instance (g, S, S, S, c, c, b). It constructs a tree for the scenario SC instance caused by b. In this induced instance, the actual set is designed to be the restriction of the actual set to the actual set in N. (c) Assume that N. \"n\" is \"For some n.\" For d. \"(c) n.\" (c) n. \"(d) Restricting the actual set to the actual set in N.\" (c) n. \"(d\") n. \"(d\") denotes the extension d \"to all elements in N. that di\" i. \"(d\" i) for i. \"The utility g.\" (c) n. \""}, {"heading": "A.3. Proof of Lemma 6", "text": "Our evidence is largely based on the work of Streeter and Golovin (2009) on the Min-Sum Submodular Cover Problem. We use some of their terms and definitions in our evidence."}, {"heading": "A.3.1. Definitions", "text": "Let N = {1,.., n} be a set of items and let c = f (N). Let us define a schedule as a finite integer vector of \"times\" associated with these items. Let f: 2N \u2192 Z \u2265 0 be a monotonous, submodular utility function and let Q = f (N). Let us define a schedule as a finite sequence S = < (i1, \u03c41) > of pairs in N \u00b7 R \u2265 0 and refer to \u03c4j as the time to process items. For a schedule S, we define \"(S) = subject j \u2265 1 \u03c4j as the sum of times to be output for all items in S. Let's define a separate version of the min-sum submodular coverage problem."}, {"heading": "A.3.2. Standard Greedy Algorithm for Discrete Min-Sum Submodular Cover", "text": "The Streeter and Golovin algorithm for the general min-sum submodular coverage problem uses a standard greedy approach. It iteratively adds pairs (i, \u03c4) to the end of an initially empty coverage problem by applying the greedy rule that will result in the largest increase in benefit per unit of time. We call this algorithm standard Greedy. We limit our attention to the discrete min-sum submodular coverage problem. Formally, Standard Greedy uses the greedy rule to select the pair (i, ci) that will lead to the greatest increase in benefit as measured by f c, per unit of time. The algorithm ends when the constructed plan S f c (S) = 1.Formally, Standard Greedy uses the greedy rule below to select a greedy plan G = < (g1, \u03c41), (lt1), (lt2), (ltltltc),."}, {"heading": "A.3.3. Bound on Cost of MixedGreedy", "text": "\"We must be prepared not to give up on costs.\" (i1, ci1) > \"We cannot give up on costs.\" (i1, ci1) > \"We cannot give up on costs.\" (i1, ci1) > \"We cannot give up on costs.\" (i1, ci1) > \"We cannot give up on costs.\" (i1, ci1) > \"We cannot give up on costs.\" (i1) > \"We cannot give up on costs.\" (i1, ci1) > \"We cannot give up on costs.\" (i1) > \"We cannot give up on costs.\" (i1) > \"We cannot give up on costs.\" (i1) > \"We cannot give up on costs.\""}, {"heading": "Appendix C. Adaptive Submodularity of gW", "text": "The detection of Lemma 3 Lass w (b) = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p (b) b (b) b (b) b (b) b (Q \u2212 g (b) (W \u2212 g (b) (W \u2212 hW (b) p = b)) p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p. To show that gW is adaptive submodular in relation to the DS distribution, we must show that E [g gW (b, i, g) p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p"}], "references": [{"title": "Group-based active query selection for rapid diagnosis in time-critical situations", "author": ["G. Bellala", "S. Bhavnani", "C. Scott"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Bellala et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bellala et al\\.", "year": 2012}, {"title": "Optimal testing procedure for special structures of coherent systems", "author": ["Y. Ben-Dov"], "venue": "Management Science,", "citeRegEx": "Ben.Dov.,? \\Q1981\\E", "shortCiteRegEx": "Ben.Dov.", "year": 1981}, {"title": "Optimal diagnosis procedures for k-out-of-n structures", "author": ["M.-F. Chang", "W. Shi", "W.K. Fuchs"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "Chang et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Chang et al\\.", "year": 1990}, {"title": "Submodular surrogates for value of information", "author": ["Yuxin Chen", "Shervin Javdani", "Amin Karbasi", "J. Andrew Bagnell", "Siddhartha S. Srinivasa", "Andreas Krause"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Submodular surrogates for value of information", "author": ["Yuxin Chen", "Shervin Javdani", "Amin Karbasi", "J. Andrew Bagnell", "Siddhartha S. Srinivasa", "Andreas Krause"], "venue": "(long version). 2015b. URL http://las.ethz.ch/files/chen15submsrgtvoi-long.pdf", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Diagnosis determination: decision trees optimizing simultaneously worst and expected testing cost", "author": ["Ferdinando Cicalese", "Eduardo Laber", "Aline Medeiros Saettler"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Cicalese et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cicalese et al\\.", "year": 2014}, {"title": "Approximation algorithms for stochastic boolean function evaluation and stochastic submodular set cover", "author": ["A. Deshpande", "L. Hellerstein", "D. Kletenik"], "venue": "In Symposium on Discrete Algorithms,", "citeRegEx": "Deshpande et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Deshpande et al\\.", "year": 2014}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Golovin and Krause.,? \\Q2011\\E", "shortCiteRegEx": "Golovin and Krause.", "year": 2011}, {"title": "Near-optimal Bayesian active learning with noisy observations", "author": ["D. Golovin", "A. Krause", "D. Ray"], "venue": "In 24th Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Golovin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2010}, {"title": "Simultaneous learning and covering with adversarial noise", "author": ["Andrew Guillory", "Jeff A. Bilmes"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "Guillory and Bilmes.,? \\Q2011\\E", "shortCiteRegEx": "Guillory and Bilmes.", "year": 2011}, {"title": "Near optimal bayesian active learning for decision making", "author": ["Shervin Javdani", "Yuxin Chen", "Amin Karbasi", "Andreas Krause", "Drew Bagnell", "Siddhartha S. Srinivasa"], "venue": "In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Javdani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Javdani et al\\.", "year": 2014}, {"title": "Learning with attribute costs", "author": ["H. Kaplan", "E. Kushilevitz", "Y. Mansour"], "venue": "In Symposium on the Theory of Computing,", "citeRegEx": "Kaplan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kaplan et al\\.", "year": 2005}, {"title": "Optimal testing algorithms for symmetric coherent systems", "author": ["S. Salloum"], "venue": "PhD thesis, University of Southern California,", "citeRegEx": "Salloum.,? \\Q1979\\E", "shortCiteRegEx": "Salloum.", "year": 1979}, {"title": "Above this line, the reasoning follows the same reasoning as in Streeter and Golovin", "author": ["y = yk"], "venue": null, "citeRegEx": "yk.,? \\Q2009\\E", "shortCiteRegEx": "yk.", "year": 2009}, {"title": "Here we consider the Scenario BFE problem for k-of-n functions. Following techniques used in a reduction of Deshpande et al. (2014) for Stochastic BFE", "author": ["Ben-Dov"], "venue": null, "citeRegEx": "Ben.Dov,? \\Q1990\\E", "shortCiteRegEx": "Ben.Dov", "year": 1990}], "referenceMentions": [{"referenceID": 6, "context": "We consider the Scenario Submodular Cover problem, which is a counterpart to the Stochastic Submodular Cover problem studied by Golovin and Krause (2011). In Scenario Submodular Cover, the goal is to produce a cover with minimum expected cost, where the expectation is with respect to an empirical joint distribution, given as input by a weighted sample of realizations.", "startOffset": 128, "endOffset": 154}, {"referenceID": 5, "context": "Building on algorithms developed by Cicalese et al. (2014) and Golovin and Krause (2011) for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions.", "startOffset": 36, "endOffset": 59}, {"referenceID": 5, "context": "Building on algorithms developed by Cicalese et al. (2014) and Golovin and Krause (2011) for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions.", "startOffset": 36, "endOffset": 89}, {"referenceID": 5, "context": "Golovin and Krause (2011); Golovin et al.", "startOffset": 0, "endOffset": 26}, {"referenceID": 5, "context": "Golovin and Krause (2011); Golovin et al. (2010); Bellala et al.", "startOffset": 0, "endOffset": 49}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al. (2014)).", "startOffset": 8, "endOffset": 53}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al. (2014)). Other applications include reducing prediction costs for learned Boolean classifiers, when there are costs for determining attribute values (Deshpande et al. (2014)).", "startOffset": 8, "endOffset": 220}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al. (2014)). Other applications include reducing prediction costs for learned Boolean classifiers, when there are costs for determining attribute values (Deshpande et al. (2014)). Previous work on the Stochastic Submodular Cover problem assumes that the variables of the input probability distribution are independent. Optimization is performed with respect to this distribution. We consider a new version of the problem that we call Scenario Submodular Cover, that removes the independence assumption. In this problem, optimization is performed with respect to an input distribution that is given explicitly by its support (with associated probability weights). We give approximation algorithms solving the Scenario Submodular Cover problem over discrete distributions. Before describing our contributions in more detail, we give some background. In generic terms, an adaptive submodular cover problem is a sequential decision problem where we must choose items one by one from an item set N = {1, . . . , n}. Each item has an initially unknown state, which is a member of a finite state set \u0393. The state of an item is revealed only after we have chosen the item. We represent a subset S of items and their states by a vector x \u2208 (\u0393 \u222a {\u2217})n where xi = \u2217 if i 6\u2208 S, and xi is the state of item i otherwise. We are given a monotone, submodular utility function g : (\u0393 \u222a {\u2217})n \u2192 Z\u22650. It assigns a non-negative integer value to each subset of the items and the value can depend on the states of the items.1 There is a non-negative goal utility value Q, such that g(a) = Q for all a \u2208 \u0393n. There is a cost associated with choosing each item, which we are given. In distributional settings, we are also given the joint distribution of the item states. We must continue choosing items until their utility value is equal to the goal utility, Q. The problem is to determine the adaptive order in which to choose the items so as to minimize expected cost (in distributional settings) or worst-case cost (in adversarial settings). Stochastic Submodular Cover is an adaptive submodular cover problem, in a distributional setting. In this problem, the state of each item is a random variable, and these variables are assumed to be independent. The distributions of the variables are given as input. Golovin and Krause introduced a simple greedy algorithm for this problem, called Adaptive Greedy, that achieves an approximation factor of O(logQ). A dual greedy algorithm for the problem, called Adaptive Dual Greedy, was presented and analyzed by Deshpande et al. (2014). These greedy algorithms have been useful in solving other stochastic optimization", "startOffset": 8, "endOffset": 2600}, {"referenceID": 7, "context": "In the terminology used by Golovin and Krause Golovin and Krause (2011), g is pointwise monotone and pointwise submodular.", "startOffset": 27, "endOffset": 72}, {"referenceID": 6, "context": ", Javdani et al. (2014); Chen et al.", "startOffset": 2, "endOffset": 24}, {"referenceID": 3, "context": "(2014); Chen et al. (2015a); Deshpande et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 3, "context": "(2014); Chen et al. (2015a); Deshpande et al. (2014); Golovin et al.", "startOffset": 8, "endOffset": 53}, {"referenceID": 3, "context": "(2014); Chen et al. (2015a); Deshpande et al. (2014); Golovin et al. (2010)).", "startOffset": 8, "endOffset": 76}, {"referenceID": 5, "context": "It is a generalization of an algorithm by Cicalese et al. (2014) for the Equivalence Class Determination problem (which has also been called the Group Identification problem and the Discrete Function Evaluation problem).", "startOffset": 42, "endOffset": 65}, {"referenceID": 5, "context": "It is a generalization of an algorithm by Cicalese et al. (2014) for the Equivalence Class Determination problem (which has also been called the Group Identification problem and the Discrete Function Evaluation problem). The approximation factor achieved by Mixed Greedy for the Scenario SC problem is O ( 1 \u03c1 logQ ) , where \u03c1 is a quantity that depends on the utility function g. In the case of the utility function constructed for the Equivalence Class Determination Problem, \u03c1 is constant, but this is not true in general. We describe a modified version of Mixed Greedy that we call Scenario Mixed Greedy. It works by first constructing a new monotone, submodular utility function gS from g and the sample, for which \u03c1 is constant. It then runs Mixed Greedy on gS with goal value Qm, where m is the size of the sample. We show that Scenario Mixed Greedy achieves an O(logQm) approximation factor for any Scenario SC problem. Mixed Greedy is very similar to the algorithm of Cicalese et al., and we use the same basic analysis. However, at the heart of their analysis is a technical lemma with a lengthy proof bounding a quantity that they call the \u201csepcost\u201d. The proof applies only to the particular utility function used in the Equivalence Class Determination problem. We replace this proof with an entirely different proof that applies to the general Scenario SC problem. Our proof is based on the work of Streeter and Golovin (2009) for the Min-Sum Submodular Cover problem.", "startOffset": 42, "endOffset": 1439}, {"referenceID": 5, "context": "Golovin et al. (2010); Bellala et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al.", "startOffset": 8, "endOffset": 179}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al.", "startOffset": 8, "endOffset": 884}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al.", "startOffset": 8, "endOffset": 907}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al.", "startOffset": 8, "endOffset": 930}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al. (2015b)).", "startOffset": 8, "endOffset": 951}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al. (2015b)). Our construction of gW , and our proof of adaptive submodularity, make it possible to achieve an approximation bound using Adaptive Greedy after proving only submodularity of a constructed g, rather than adaptive submodularity of g and the distribution. Proofs of submodularity are generally easier because they do not involve distributions and expected values. Also, the standard OR construction described in Section 2 preserves submodularity, while it does not preserve Adaptive Submodularity (Chen et al. (2015a)).", "startOffset": 8, "endOffset": 1469}, {"referenceID": 7, "context": "By the results of Golovin and Krause (2011), running Adaptive Greedy with g yields an O(logQ) approximation for the associated Stochastic SC problem.", "startOffset": 18, "endOffset": 44}, {"referenceID": 10, "context": "For example, we can easily obtain a new bound for the Decision Region Identification problem studied by Javdani et al. (2014), which is an extension of the Equivalence Class Determination problem.", "startOffset": 104, "endOffset": 126}, {"referenceID": 8, "context": "In contrast, the bound achieved by Javdani et al. is O ( k log ( W wmin )) , where wmin is the minimum weight on a assignment in the sample. We can apply our greedy algorithms to Scenario BFE (Boolean Function Evaluation) problems, which we introduce here. These problems are a counterpart to the Stochastic BFE problems2 that have been studied in AI, operations research, and in the context of learning with attribute costs (see e.g., \u00dcnl\u00fcyurt (2004); Deshpande et al.", "startOffset": 35, "endOffset": 452}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al.", "startOffset": 19, "endOffset": 43}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)).", "startOffset": 19, "endOffset": 65}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)). In a Scenario BFE problem, we are given a Boolean function f . For each i \u2208 {1, . . . , n}, we are also given a cost ci > 0 associated with obtaining the value of the ith bit of an initially unknown assignment a \u2208 {0, 1}n. Finally, we are given a weighted sample S \u2286 {0, 1}n. The problem is to compute a (possibly implicit) decision tree computing f , such that the expected cost of evaluating f on a \u2208 {0, 1}n, using the tree, is minimized. The expectation is with respect to the distribution defined by the sample weights. Deshpande et al. (2014) gave approximation algorithms for some Stochastic BFE problems that work by constructing an appropriate monotone, submodular utility function g and running Adaptive Greedy.", "startOffset": 19, "endOffset": 616}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)). In a Scenario BFE problem, we are given a Boolean function f . For each i \u2208 {1, . . . , n}, we are also given a cost ci > 0 associated with obtaining the value of the ith bit of an initially unknown assignment a \u2208 {0, 1}n. Finally, we are given a weighted sample S \u2286 {0, 1}n. The problem is to compute a (possibly implicit) decision tree computing f , such that the expected cost of evaluating f on a \u2208 {0, 1}n, using the tree, is minimized. The expectation is with respect to the distribution defined by the sample weights. Deshpande et al. (2014) gave approximation algorithms for some Stochastic BFE problems that work by constructing an appropriate monotone, submodular utility function g and running Adaptive Greedy. By substituting the sample-based algorithms in this paper in place of Adaptive Greedy, we obtain approximation results for analogous Scenario BFE problems. For example, using Mixed Greedy, we can show that the Scenario BFE problem for k-of-n functions has an approximation algorithm achieving a factor of O(k log n) approximation, independent of the size of the sample. Details are in Appendix B. Bounds for other functions follow easily using Scenario Mixed Greedy and Scenario Adaptive Greedy. For example, Deshpande et al. (2014) presented an algorithm achieving an O(log t) approximation for the Stochastic BFE problem for evaluating decision trees of size t.", "startOffset": 19, "endOffset": 1322}, {"referenceID": 5, "context": "We note that our Scenario BFE problem differs from the function evaluation problem by Cicalese et al. (2014). In their problem, the computed decision tree need only compute f correctly on assignments a \u2208 {0, 1}n that are in the sample, while ours needs to compute f correctly on all a \u2208 {0, 1}n.", "startOffset": 86, "endOffset": 109}, {"referenceID": 8, "context": "Guillory and Bilmes (2011); Deshpande et al.", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "Guillory and Bilmes (2011); Deshpande et al. (2014)).", "startOffset": 28, "endOffset": 52}, {"referenceID": 5, "context": "The algorithm of Cicalese et al. for the Equivalence Class Determination problem is essentially the same as our Mixed Greedy algorithm, for g equal to their \u201cPairs\u201d utility function. (There is one small difference \u2013 in their algorithm, the first stage ends right before the greedy step in which the budget B would be exceeded, whereas we allow the budget to be exceeded in the last step.) Like their algorithm, our Mixed Greedy algorithm relies on a greedy algorithm for the Budgeted Submodular Cover problem due to Wolsey. We describe Wolsey\u2019s algorithm in detail in Appendix A.1. If g(b) = Q, then MixedGreedy returns an (unlabeled) single node, which will be a leaf of the full tree for g. Otherwise, MixedGreedy constructs a tree T . It does so by computing a special realization called \u03c3, and then iteratively using \u03c3 to construct a path descending from the root of this subtree, which is called the backbone. It uses recursive calls to build the subtrees \u201changing\u201d off the backbone. The backbone has a special property: for each node v\u2032 in the path, the successor node in the path is the \u03c3i child of v \u2032, where i is the item labeling node v\u2032. The construction of the backbone is done as follows. Using subroutine FindBudget, MixedGreedy first computes a lower bound B on the minimum additional cost required in order to achieve a portion \u03b1 of the goal value Q, assuming we start with partial realization b (Step 6). This computation is done using the Greedy algorithm of Wolsey (1982) described in Section A.", "startOffset": 17, "endOffset": 1491}, {"referenceID": 5, "context": "Generalizing an argument from Cicalese et al. (2014), we now prove that \u03c1S is lower bounded by a constant fraction.", "startOffset": 30, "endOffset": 53}, {"referenceID": 5, "context": "Lemma 6 is the key technical lemma in our analysis, and it is the proof of this lemma that constitutes the major difference between our analysis and the analysis in Cicalese et al. (2014). We defer the proof of this lemma to Section A.", "startOffset": 165, "endOffset": 188}, {"referenceID": 5, "context": "We deal with this by using an approach analogous to one used by Cicalese et al. (2014) (in the analysis of their Equivalence Class Determination algorithm) that allows us to concentrate only on the cost of the portion of the schedule constructed during the first stage.", "startOffset": 64, "endOffset": 87}, {"referenceID": 13, "context": "We note that the first part of the integral consists of the area above the line y = yk. Above this line, the reasoning follows the same reasoning as in Streeter and Golovin (2009): Due to (11), we see that each bar is contained entirely inside the graph of \u03c8, and since j < k, the bar is entirely inside the area of integration.", "startOffset": 84, "endOffset": 180}, {"referenceID": 9, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al.", "startOffset": 0, "endOffset": 15}, {"referenceID": 9, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al.", "startOffset": 0, "endOffset": 42}, {"referenceID": 1, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al.", "startOffset": 43, "endOffset": 58}, {"referenceID": 1, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al. (1990)).", "startOffset": 43, "endOffset": 79}, {"referenceID": 1, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al. (1990)). Here we consider the Scenario BFE problem for k-of-n functions. Following techniques used in a reduction of Deshpande et al. (2014) for Stochastic BFE, we reduce this problem", "startOffset": 43, "endOffset": 213}], "year": 2016, "abstractText": "Many problems in Machine Learning can be modeled as submodular optimization problems. Recent work has focused on stochastic or adaptive versions of these problems. We consider the Scenario Submodular Cover problem, which is a counterpart to the Stochastic Submodular Cover problem studied by Golovin and Krause (2011). In Scenario Submodular Cover, the goal is to produce a cover with minimum expected cost, where the expectation is with respect to an empirical joint distribution, given as input by a weighted sample of realizations. In contrast, in Stochastic Submodular Cover, the variables of the input distribution are assumed to be independent, and the distribution of each variable is given as input. Building on algorithms developed by Cicalese et al. (2014) and Golovin and Krause (2011) for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions. The first achieves an approximation factor of O(logQm), where m is the size of the sample and Q is the goal utility. The second, simpler algorithm achieves an approximation bound of O(logQW ), where Q is the goal utility and W is the sum of the integer weights. (Both bounds assume an integer-valued utility function.) Our results yield approximation bounds for other problems involving non-independent distributions that are explicitly specified by their support. \u2217 Partially Supported by NSF Grant 1217968 c \u00a9 2016 N. Grammel, L. Hellerstein, D. Kletenik & P. Lin. ar X iv :1 60 3. 03 15 8v 1 [ cs .D S] 1 0 M ar 2 01 6 Grammel Hellerstein Kletenik Lin", "creator": "LaTeX with hyperref package"}}}