{"id": "1603.03627", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Mar-2016", "title": "Learning from Imbalanced Multiclass Sequential Data Streams Using Dynamically Weighted Conditional Random Fields", "abstract": "The present study introduces a method for improving the classification performance of imbalanced multiclass data streams from wireless body worn sensors. Data imbalance is an inherent problem in activity recognition caused by the irregular time distribution of activities, which are sequential and dependent on previous movements. We use conditional random fields (CRF), a graphical model for structured classification, to take advantage of dependencies between activities in a sequence. However, CRFs do not consider the negative effects of class imbalance during training. We propose a class-wise dynamically weighted CRF (dWCRF) where weights are automatically determined during training by maximizing the expected overall F-score. Our results based on three case studies from a healthcare application using a batteryless body worn sensor, demonstrate that our method, in general, improves overall and minority class F-score when compared to other CRF based classifiers and achieves similar or better overall and class-wise performance when compared to SVM based classifiers under conditions of limited training data. We also confirm the performance of our approach using an additional battery powered body worn sensor dataset, achieving similar results in cases of high class imbalance.", "histories": [["v1", "Fri, 11 Mar 2016 13:51:37 GMT  (4073kb,D)", "http://arxiv.org/abs/1603.03627v1", "28 pages, 8 figures, 1 table"]], "COMMENTS": "28 pages, 8 figures, 1 table", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["roberto l shinmoto torres", "damith c ranasinghe", "qinfeng shi", "anton van den hengel"], "accepted": false, "id": "1603.03627"}, "pdf": {"name": "1603.03627.pdf", "metadata": {"source": "CRF", "title": "Learning from Imbalanced Multiclass Sequential Data Streams Using Dynamically Weighted Conditional Random Fields", "authors": ["Roberto L. Shinmoto Torres", "Damith C. Ranasinghe", "Qinfeng Shi", "Anton van den Hengel"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Developments in new wireless sensor technologies enable a wide range of applications, particularly in healthcare practice, for applications such as patient location. Activities detection in older people is of particular interest to prevent injuries from events such as falls, by making early intervention or identifying dysfunctions, such as those in people with Alzheimer's or Parkinson's disease, to take preventive interventions.One of the biggest challenges in detecting human activity is that sensor data is generally unbalanced, as data from all sorts of activities are not necessarily evenly distributed, because people naturally perform some activities over a longer period of time than others."}, {"heading": "1.1 Scope and Background", "text": "Unbalanced data can have a negative impact on the training of machine learning algorithms, as the classifier may prefer the majority class. This can be a serious problem, as minority classes are very important in applications such as monitoring human activity. [3] Therefore, it is important to increase the overall classification performance, and in particular the classification performance, in identifying minority classes such as ambulation in our example. Another challenge arising from the nature of human activity problems is the difficulty of collecting and labelling large sets of data from everyday activities (ADL), which is indeed the case for applications such as monitoring patients in acute hospitals, where data is collected to learn activities in hospital."}, {"heading": "1.2 Related works", "text": "This year it is more than ever before."}, {"heading": "1.3 Paper Contributions", "text": "Our approach expands existing knowledge by solving current limitations: degradation of sequential data by re-sampling; learning models driven by metrics (accuracy and specificity) that tend toward the dominant class; and the inclusion of class-specific parameters that are fixed or require comprehensive validation or optimization. We provide the following contributions: 1. We present a novel cost-sensitive learning method for the unbalanced classification of multi-class data in real time, based on weighted conditional random fields (WCRF), where the optimization process is based on maximizing the expected F score. In this method, the cost parameters are dynamically calculated during training. To our knowledge, this is the first attempt to optimize multi-class classifiers based on F-score metrics, to learn from unbalanced data, where the cost parameters are also learned during the training. In particular, we consider graphical models based on our CRF, as well as the higher-level CRF, to learn from unbalanced data, where the cost parameters are also applied to the cost parameters, especially graphical models based on our CRF, and the higher-level CRF."}, {"heading": "2 Proposed Dynamically Weighted Learning", "text": "Method"}, {"heading": "2.1 Background", "text": "In this section, we will briefly return to CRFs, a probabilistic graphical model for structured classification [6, 30], as the background for defining our method in Section 2.2.Let us assume a sequence of input observations {xt} Tt = 1 and their corresponding designations {yt} Tt = 1, with yt messages {1 \u00b7 \u00b7 K} and K being the number of classes to be inferred. CRF's advantage is that it establishes pairs of relationships between adjacent hidden variables and their corresponding observations, a property of the Markov assumption of first order. The probability distribution in CRF is given by the conditional definition of probability asp value (y-x, \u03bb) = 1 Z-Exp value (T value, yt; x value)."}, {"heading": "2.2 Dynamically Weighted Conditional Random Fields (dWCRF)", "text": "The main motivation for implementing a weighted approach is to take into account the negative impact of unbalanced data on learning. Furthermore, classification outcomes such as accuracy (1 error) are not an appropriate metric because results are skewed towards the majority class. Therefore, we need to minimize false positives (FP) or false alarms; and false negatives (FN) or missed classifications. Intuitively, this means that both true positives (TP) and true negatives (TN) of all participating classes are increased. We use the expected F score (or F score) as an optimization measure for our model as it defines FN and FP. In this context, we are introducing a cost term in our classification function to reduce higher costs for errors in minority classes in order to reduce the impact of the imbalance on classifiers."}, {"heading": "2.3 Weights Estimation", "text": "Now we are interested in the calculation of the weight table w in dWCRF, which maximizes the function F + q. We use the previous result in (12), which shows that the objective functions F + and the weighted log probability have gradients equal to zero at the optimal FPP. We have the gradient of the function F + FPP = FPP number, which results in the calculation. (13) and the gradients of the log likelihood function. (yt | xt, \u03bb) + \u00b7 ddtp: yt = K-number. (p). (yt | xt, \u03bb). (13) and the gradients of the log likelihood function. (p)."}, {"heading": "2.4 Real Time Inference", "text": "In a previous study, we emphasized the importance of predicting activities in real time [29], using the multiplication method to obtain the marginal probabilities of the last observation received; we use the current sensor observation and the information from the last conclusion reached on the previous observation. This is derived from the form: (20) m (yt) = 1Zt exp (\u03c6 (yt, x) = 1Zt \u2212 1 (exp (\u03c6 (yt \u2212 1, yt \u2212 1)) m (yt \u2212 1)), where m (yt) is the marginal probability corresponding to the tallest observation xt and Zt corresponds to the normalizing term, so that the limits correspond to the unit at a given time and prevent the boundary from being assigned to the subordinate activity."}, {"heading": "3 Experimental Studies", "text": "This section presents the experimental framework and results. We evaluate our dWCRF methodology using data sets from two different approaches to detecting human activity: i) with battery-powered body wear sensors (BPBW) and ii) with battery-less body wear sensors (BLBW)."}, {"heading": "3.1 Problem Description", "text": "Both scenarios, BPBW and BLBW, look at sequential sensor data; these are time series X = {xt} Tt = 1, where xt-Rd is associated with a sequence of activity designations Y = {yt} Tt = 1, where yt-Y = {1 \u00b7 \u00b7 \u00b7 K} and K is the number of activity designations to predict. In the case of sequential data problems, we assume sequences are i.i.d. from each other; that is, given the set of M training designations D = {(Xm, Ym)} Mm = 1, variables in (Xi, Yi) are independent of those in (Xj, Yj) for i = j. However, dependency relationships between variables in a sequence cannot be assumed. Therefore, given a test sequence T = {(X, Y)}, we are interested in predicting individual class designations y-t for each individual observation using our trained dCRF model."}, {"heading": "3.2 Statistical Analysis", "text": "In this study, we determine class-specific performance measurements: true positives (TP) are the correctly predicted activity indicators. False positives (FP) are those predicted markers that are incorrectly classified and therefore do not match the truth. False negatives (FN) correspond to those basic truth classes that have been overlooked. True negatives (TN) are those non-target (unintended) classes that have been correctly identified by the system. In addition, we evaluate the performance of each class k using the harmonic mean of precision (Pr) and recall (Re): Precision (Pr) = TPk / (TPk + FPk) (21) Recallk (Re) = TPk + FNk) (22) F-Scorek = 2 \u00d7 Prk Prk + Rek + Rek = (12 x Rek) values that represent a rating of the other group."}, {"heading": "3.3 Batteryless Body Worn Sensor Datasets (BLBW)", "text": "These data sets were collected as part of a larger project by our research group on outpatient monitoring of older patients in hospital to prevent falls [7]. We evaluated three case studies based on motion information from healthy and inpatient participants tested using the battery-less body-worn sensor [35] shown in Figure 2 (a). Study participants were asked to perform a series of broadly scripted ADLs, which included: i) sitting on the bed; iii) sitting on the chair; iii) lying on the bed; and iv) walking to the bed, chair, or door. These are the most likely activities performed by older patients in a hospital setting. A researcher who was present during the studies commented directly on the labels as a reference for floor truthfulness. We believe that posture transitions, such as sitting and standing to sitting, are integrated into hospital form."}, {"heading": "3.3.1 Sensor Platform", "text": "Participants wore a flexible wireless identification and sensor (W2ISP) device developed by our team [35] over a garment on the sternum. W2ISP, see Figure 2 (a) and based on [36], comprises a triaxial accelerometer (ADXL330) and a 16-bit microcontroller (MSP430F2132). W2ISP is part of an emerging class of battery-less sensors. In particular, the W2ISP derives its energy from the electromagnetic field that illuminates the tag of RFID antennas well as the W2ISP sensor data. The main motivation for using this passive (battery-less) device is twofold compared to using other battery-powered sensors: i) The device requires no maintenance as it is battery-free, light, inexpensive and easy to replace; and ii) short-term signals, especially those with SNA, are required for observing, such as those with delirium."}, {"heading": "3.3.2 Case Studies", "text": "Case Study 1 Fourteen healthy older subjects with an average age of 74.6 \u00b1 4.9 years each completed about five studies based on their ability and fatigue level. Participants were divided into two different room configurations: Room 1 and Room 2, each forming a data set of 4 and 3 antenna deployments, as shown in Figure 2 (b) and (c). Case Study 2 Twenty-five inpatient patients with an average age of 84.4 \u00b1 5.3 years performed a short sequence of ADLs due to the fragility of the participants. Patients were tested in their respective rooms and formed the data set Room 3. In this hospital configuration, see Figure 2 (d), the displayed measurements are approximate due to differences between rooms (single or double bed), and the bed and chair were always side by side. Case Study 3 This case study examines the performance of our method under the reduced conditions of using data from Study 1, in which we took data from a simulation investigation 1."}, {"heading": "3.3.3 Class Imbalance in Datasets", "text": "The second source of imbalance is due to the passive nature of the W2ISP sensor; however, this affects the power on the device and the regularity of the sensor measurements. Furthermore, the positioning of the sensor and the proximity to the RFID antennas, the posture of the participant (which leads to occlusion) can also affect the switching on of the sensor; in addition, these conditions may change from person to person and room to room. We can see from the room constellations that Room 1 intends to collect sensor observations from the entire room, whereas Room 2 and Room 3 focus on the observation of certain areas around the bed and the chair, while Room 3 has a minimal effect on the small dimensions of the path between bed and chair."}, {"heading": "3.3.4 Feature Extraction", "text": "From the three sets of data, we extract representative acceleration values. We use a fixed time shift window of 4 s (hereinafter referred to as the segment) with limited information from which we extract instantaneous sensory data corresponding to the last successive observation and context information associated with observations in the segment. In addition, we also use intersegment information to capture further trend changes in sensor signals. We select this window method and length because it is easy to implement and perform, as well as more complex methods of feature extraction [29]. The feature vector is composed of three different types of characteristics: Instantaneous Features These characteristics are strictly based on the last observation received relative to the activity currently performed, shown in Table 1, and the gender of the participant who knows each other. We look at the tilting angle of the body at the middle level of the participant relative to the current participant or the posterior."}, {"heading": "3.3.5 Parameter Selection", "text": "We evaluate the performance of our dWCRF model together with the linear chain CRF [6]; a weighted CRF with fixed weights (fWCRF) given by the inversion of the class distribution [22]; and a cost parameter based on CRF, such as the Softmax margin model (C-CRF) [23] on all three data sets, we use the L2 regulation model for each classifier of the form. In addition, we compare the regularization parameters evaluated in the range [10 \u2212 10 \u2212 1]. Parameters limited by the lowest number of iterations with the linear chain CRF. In addition, we compare the SVM multipliers with SVM."}, {"heading": "3.3.6 Results", "text": "First, we show the overall results that correspond to the datasets of all other algorithms; > values for the classification are > 0.72. However, for the SCR1 and Case Study 2 (Room3) and Case Study 2 (Room3) classification, these results were obtained by averaging the results of all participating classes. However, the maximum performance difference between the methods of \"average F-score\" is about 7%; for the SVCRF deviation from the SVCRF deviation is 8%, where the difference between our dWCRF gradations (81.3%) and the most powerful R-WSVM classes (83.8%) is greater than 4.6% (85.4% and 90%, respectively); for the maximum F-score deviation is 8%, where the difference between our dWCRF gradations (81.3%) and the most powerful R-WSVM classes (83.8%) is 2.5%; and for the total F-10-CRF where the maximum deviation is not significant."}, {"heading": "3.4 Battery Powered Body Worn Sensor Dataset (BPBW)", "text": "In order to further validate the generalisability of our approach, we consider other data sets that present sequential information, in particular the detection of human activity using portable sensors. Unfortunately, few public data sets on human activity show imbalance and have enough data samples to modify their levels of imbalance. We decided to use the data set for the detection of opportunity factors [45] available in the UCI repository. In this data set, four participants with multiple sensors attached to their body and environment remove several consecutive life activities. From the multiple sensor data and characteristics generated (243), we select only those that are related to the participant strain, i.e. sensors located on the hip and back of the participant. This gives us only 19 sensor-related features plus a time-related equipment. These sensors are considered the closest to our real scenario (hospital)."}, {"heading": "3.4.1 Results", "text": "We test the data sets using the same methods of case study 3 in Section 3.3.6. The results are shown in Figure 8 (b) - (d). In general, no method is statistically significantly better than the rest with p \u2265 0.174 for Op1, p \u2265 0.137 for Op2, and p \u2265 0.251 for Op3. Nevertheless, the average F score for our dWCRF is generally higher than any other method, except for LWSVM, which overall has a higher F score in 5 (DS3 and DS4 in Op1, DS3 in Op2, and DS3, and DS5 in Op3) of all unbalanced datasets. Furthermore, for dWCRF the lowest class performance in all datasets was class zero; while for L-WSVM the lowest class performance for most datasets was the class Lie, which is the minority class. These results indicate that despite high aggregate results, dWCRF struggles with identifying undefined classes in these datasets."}, {"heading": "3.5 Empirical Comparison of Parameter Validation", "text": "We use the BPBW datasets to illustrate the different training times (including parameter selection) of our proposed dWCRF method and other methods. From the datasets used in the previous section, we randomly select one dataset from each imbalance case: DS5 from Op1, DS3 from Op2, and DS3 from OP3. The resulting times are shown in Figure 9, where the timeline is on a logarithmic scale, with the time representing the total time needed to evaluate the range of validation parameters. In this case, we evaluate dWCRF with one parameter to be validated (regularization parameters in dWCRF1) and two parameters (implications in dWCRF2) with cardinalities of 10 and 121, respectively. LSVM had added a parameter for validation with a cardinality of 11. RSVM had two parameters to validate with a total combination of 200 points of 12C1-SVS, each increasing the initial time between the CEM-SVM and SVS."}, {"heading": "4 Conclusion", "text": "This study found that using a class-by-class cost parameter in objective function, dWCRF improves the overall F score of our battery-less, worn sensor data sets compared to other CRF-based classifiers and performs similar or better than other SVM-based classifiers in conditions where the availability of training data is reduced or it is difficult to collect large data sets. In addition, the developed approach also improves F-score performance metrics in minority classes. Our method has been validated using a set of battery-powered sensor data sets to detect human activity in conditions of high imbalances and limited training data sets. Unlike previous approaches, our method dynamically calculates class-by-cost parameters, i.e. it does not require prior knowledge of the data to assign cost parameter weights and does not need to be evaluated during the validation phase."}, {"heading": "Acknowledgment", "text": "This study was supported by the Australian Research Council (DP130104614) and approved by the Queen Elizabeth Hospital Ethics Committee (Protocol No. 2011129). We would also like to thank Prof. Renuka Visvanathan, Mr. Stephen Hoskins and Dr. Shailaja Nair for their support in selecting and monitoring the study participants."}], "references": [{"title": "Learning from imbalanced data", "author": ["H. He", "E.A. Garcia"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 21, pp. 1263\u20131284, Sept 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "The class imbalance problem: A systematic study", "author": ["N. Japkowicz", "S. Stephen"], "venue": "Intelligent Data Analysis, vol. 6, no. 5, p. 429, 2002.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Epidemiology of falls in residential aged care: analysis of more than 70,000 falls from residents of bavarian nursing homes", "author": ["K. Rapp", "C. Becker", "I.D. Cameron", "H.H. K\u00f6nig", "G. B\u00fcchele"], "venue": "Journal of the American Medical Directors Association, vol. 13, no. 2, pp. 187.e1\u2013187.e6, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Elderly activities recognition and classification for applications in assisted living", "author": ["S. Chernbumroong", "S. Cang", "A. Atkins", "H. Yu"], "venue": "Expert Systems with Applications, vol. 40, no. 5, pp. 1662\u20131674, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Automated activity recognition and monitoring of elderly using wireless sensors: Research challenges", "author": ["D.C. Ranasinghe", "R.L. Shinmoto Torres", "A. Wickramasinghe"], "venue": "Fifth IEEE International Workshop on Advances in Sensors and Interfaces, pp. 224\u2013227, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J.D. Lafferty", "A. McCallum", "F.C.N. Pereira"], "venue": "Proceedings of the 18th International Conference on Machine Learning, (USA), pp. 282\u2013289, Morgan Kaufmann Publishers Inc., 2001.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Framework for preventing falls in acute hospitals using passive sensor enabled radio frequency identification technology", "author": ["R. Visvanathan", "D.C. Ranasinghe", "R.L. Shinmoto Torres", "K. Hill"], "venue": "2012 Annual Interna- 25  tional Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 5858\u20135862, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Low cost and batteryless sensor-enabled radio frequency identification tag based approaches to identify patient bed entry and exit posture transitions", "author": ["D.C. Ranasinghe", "R.L. Shinmoto Torres", "K. Hill", "R. Visvanathan"], "venue": "Gait & Posture, vol. 39, no. 1, pp. 118 \u2013 123, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Sensor enabled wearable rfid technology for mitigating the risk of falls near beds", "author": ["R.L. Shinmoto Torres", "D.C. Ranasinghe", "Q. Shi", "A.P. Sample"], "venue": "Seventh IEEE International Conference on RFID, pp. 191\u2013198, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "A study of the behavior of several methods for balancing machine learning training data", "author": ["G.E.A.P.A. Batista", "R.C. Prati", "M.C. Monard"], "venue": "SIGKDD Explorations Newsletter, vol. 6, no. 1, pp. 20\u201329, 2004.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Inverse random under sampling for class imbalance problem and its application to multi-label classification", "author": ["M.A. Tahir", "J. Kittler", "F. Yan"], "venue": "Pattern Recognition, vol. 45, no. 10, pp. 3738\u20133750, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Handling imbalanced and overlapping classes in smart environments prompting dataset", "author": ["B. Das", "N.C. Krishnan", "D.J. Cook"], "venue": "Data Mining for Service (K. Yada, ed.), vol. 3 of Studies in Big Data, pp. 199\u2013219, Springer, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Why does rebalancing class-unbalanced data improve auc for linear discriminant analysis", "author": ["J.-H. Xue", "P. Hall"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 37, pp. 1109\u20131112, May 2015.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning when data sets are imbalanced and when costs are unequal and unknown", "author": ["M.A. Maloof"], "venue": "ICML-2003 Workshop on Learning from Imbalanced Data Sets II, vol. 2, pp. 2\u20131, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Metacost: a general method for making classifiers costsensitive", "author": ["P. Domingos"], "venue": "Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (USA), pp. 155\u2013164, ACM, 1999.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1999}, {"title": "The influence of class imbalance on costsensitive learning: an empirical study", "author": ["X.-Y. Liu", "Z.-H. Zhou"], "venue": "Sixth International Conference on Data Mining., pp. 970\u2013974, Dec 2006.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "On multi-class cost-sensitive learning", "author": ["Z.-H. Zhou", "X.-Y. Liu"], "venue": "Computational Intelligence, vol. 26, no. 3, pp. 232\u2013257, 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Dynamic class imbalance learning for incremental LPSVM", "author": ["S. Pang", "L. Zhu", "G. Chen", "A. Sarrafzadeh", "T. Ban", "D. Inoue"], "venue": "Neural Networks, vol. 44, no. 0, pp. 87 \u2013 100, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Iterative bayes", "author": ["J. Gama"], "venue": "Theoretical Computer Science, vol. 292, no. 2, pp. 417 \u2013 430, 2003. Theoretical Aspects of Discovery Science.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Cost-sensitive bayesian network classifiers", "author": ["L. Jiang", "C. Li", "S. Wang"], "venue": "Pattern Recognition Letters, vol. 45, no. 0, pp. 211\u2013216, 2014. 26", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Weighted support vector machine for classification with uneven training class sizes", "author": ["Y.-M. Huang", "S. xin Du"], "venue": "Proceedings of 2005 International Conference on Machine Learning and Cybernetics., vol. 7, pp. 4365\u2013 4369, Aug 2005.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Weighted conditional random fields for supervised interpatient heartbeat classification", "author": ["G. de Lannoy", "D. Francois", "J. Delbeke", "M. Verleysen"], "venue": "IEEE Transactions on Biomedical Engineering, vol. 59, no. 1, pp. 241\u2013247, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Softmax-margin crfs: Training log-linear models with cost functions", "author": ["K. Gimpel", "N.A. Smith"], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, (USA), pp. 733\u2013736, Association for Computational Linguistics, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Data mining for imbalanced datasets: An overview", "author": ["N.V. Chawla"], "venue": "Data Mining and Knowledge Discovery Handbook (O. Maimon and L. Rokach, eds.), pp. 853\u2013867, Springer, 2005.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Entropy and margin maximization for structured output learning", "author": ["P. Pletscher", "C.S. Ong", "J.M. Buhmann"], "venue": "Machine Learning and Knowledge Discovery in Databases (J. L. Balczar, F. Bonchi, A. Gionis, and M. Sebag, eds.), vol. 6323 of Lecture Notes in Computer Science, pp. 83\u2013 98, Springer, 2010.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "A multi-objective optimisation approach for class imbalance learning", "author": ["P. Soda"], "venue": "Pattern Recognition, vol. 44, no. 8, pp. 1801 \u2013 1810, 2011.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1801}, {"title": "Classifying imbalanced data sets using similarity based hierarchical decomposition", "author": ["C. Beyan", "R. Fisher"], "venue": "Pattern Recognition, vol. 48, no. 5, pp. 1653 \u2013 1672, 2015.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient f measure maximization via weighted maximum likelihood", "author": ["G. Dimitroff", "G. Georgiev", "L. Tolo\u015fi", "B. Popov"], "venue": "Machine Learning, vol. 98, no. 3, pp. 435\u2013454, 2015.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Evaluation of wearable sensor tag data segmentation approaches for real time activity classification in elderly", "author": ["R.L. Shinmoto Torres", "D.C. Ranasinghe", "Q. Shi"], "venue": "Mobile and Ubiquitous Systems: Computing, Networking, and Services (I. Stojmenovic, Z. Cheng, and S. Guo, eds.), vol. 131 of Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, pp. 384\u2013395, Springer, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "An introduction to conditional random fields for relational learning", "author": ["C. Sutton", "A. McCallum"], "venue": "Introduction to Statistical Relational Learning (L. Getoor and B. Taskar, eds.), pp. 93\u2013127, The MIT Press, 2006.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}, {"title": "An introduction to conditional random fields", "author": ["C. Sutton", "A. McCallum"], "venue": "Foundations and Trends in Machine Learning, vol. 4, no. 4, pp. 267\u2013 373, 2012. 27", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Ambulatory system for human motion analysis using a kinematic sensor: monitoring of daily physical activity in the elderly", "author": ["B. Najafi", "K. Aminian", "A. Paraschiv-Ionescu", "F. Loew", "C. Bula", "P. Robert"], "venue": "IEEE Transactions on Biomedical Engineering, vol. 50, no. 6, pp. 711\u2013723, 2003.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2003}, {"title": "Activity classification using a single chest mounted tri-axial accelerometer", "author": ["A. Godfrey", "A.K. Bourke", "G.M. \u00d3laighin", "P. van de Ven", "J. Nelson"], "venue": "Medical Engineering & Physics, vol. 33, no. 9, pp. 1127\u20131135, 2011.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2011}, {"title": "Wearable quarter-wave microstrip antenna for passive UHF RFID applications", "author": ["T. Kaufmann", "D.C. Ranasinghe", "M. Zhou", "C. Fumeaux"], "venue": "International Journal of Antennas and Propagation, vol. 2013, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Design of an rfid-based battery-free programmable sensing platform", "author": ["A.P. Sample", "D.J. Yeager", "P.S. Powledge", "A.V. Mamishev", "J.R. Smith"], "venue": "IEEE Transactions on Instrumentation and Measurement, vol. 57, no. 11, pp. 2608\u20132615, 2008.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2008}, {"title": "Technology studies to meet the needs of people with dementia and their caregivers: A literature review", "author": ["P. Topo"], "venue": "Journal of Applied Gerontology, vol. 28, no. 1, pp. 5\u201337, 2009.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2009}, {"title": "Activity recognition on streaming sensor data", "author": ["N.C. Krishnan", "D.J. Cook"], "venue": "Pervasive and Mobile Computing, vol. 10, pp. 138\u2013154, 2014.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning, vol. 20, no. 3, pp. 273\u2013297, 1995.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1995}, {"title": "A training algorithm for optimal margin classifiers", "author": ["B.E. Boser", "I.M. Guyon", "V.N. Vapnik"], "venue": "Proceedings of the Fifth Annual Workshop on Computational Learning Theory, (USA), pp. 144\u2013152, ACM, 1992.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1992}, {"title": "Another approach to polychotomous classification", "author": ["J.H. Friedman"], "venue": "tech. rep., Department of Statistics, Stanford University, 1996.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1996}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, vol. 2, pp. 27:1\u201327:27, 2011. Software available at http://www.csie.ntu.edu. tw/~cjlin/libsvm.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Softmax-margin training for structured loglinear models", "author": ["K. Gimpel", "N.A. Smith"], "venue": "Tech. Rep. CMU-LTI-10-008, Carnegie Mellon University, 2010.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "The CMA evolution strategy: A comparing review", "author": ["N. Hansen"], "venue": "Towards a New Evolutionary Computation (J. A. Lozano, P. Larra\u00f1aga, I. Inza, and E. Bengoetxea, eds.), vol. 192 of Studies in Fuzziness and Soft Computing, pp. 75\u2013102, Springer, 2006.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2006}, {"title": "Collecting complex activity data sets in highly rich networked sensor environments", "author": ["D. Roggen", "A. Calatroni", "M. Rossi", "T. Holleczek", "K. F\u00f6rster", "G. Tr\u00f6ster", "P. Lukowicz", "D. Bannach", "G. Pirkl", "A. Ferscha", "J. Doppler", "C. Holzmann", "M. Kurz", "G. Holl", "R. Chavarriaga", "H. Sagha", "H. Bayati", "M. Creatura", "J. d. R. Mill\u00e1n"], "venue": "Seventh International Conference on Networked Sensing Systems, pp. 233\u2013240, 2010. 28", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Imbalanced data can negatively affect the training of machine learning algorithms as the classifier can be biased to prefer the majority class [1, 2].", "startOffset": 143, "endOffset": 149}, {"referenceID": 1, "context": "Imbalanced data can negatively affect the training of machine learning algorithms as the classifier can be biased to prefer the majority class [1, 2].", "startOffset": 143, "endOffset": 149}, {"referenceID": 2, "context": "For example, older people previously assessed as being at risk of falling performing a short duration ambulation\u2014as opposed to large amounts of time spent in resting postures such as lying in bed\u2014are potentially at a risk of falling and injury [3].", "startOffset": 244, "endOffset": 247}, {"referenceID": 3, "context": "This is indeed the case for applications such as monitoring patients in acute hospitals where collecting data to learn activities of hospitalized older people is very difficult due to physical limitations resulting from their older age and associated ailments[4, 5].", "startOffset": 259, "endOffset": 265}, {"referenceID": 4, "context": "This is indeed the case for applications such as monitoring patients in acute hospitals where collecting data to learn activities of hospitalized older people is very difficult due to physical limitations resulting from their older age and associated ailments[4, 5].", "startOffset": 259, "endOffset": 265}, {"referenceID": 5, "context": "fields (CRFs) [6], a graphical model for structured classification that captures dependency relationships between performed activities as described by sensor observations.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "The study presented in this article is part of our ongoing research aimed at recognizing activities by older people in hospital and nursing home settings for falls prevention, as described in [7, 8, 9].", "startOffset": 192, "endOffset": 201}, {"referenceID": 7, "context": "The study presented in this article is part of our ongoing research aimed at recognizing activities by older people in hospital and nursing home settings for falls prevention, as described in [7, 8, 9].", "startOffset": 192, "endOffset": 201}, {"referenceID": 8, "context": "The study presented in this article is part of our ongoing research aimed at recognizing activities by older people in hospital and nursing home settings for falls prevention, as described in [7, 8, 9].", "startOffset": 192, "endOffset": 201}, {"referenceID": 9, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 126, "endOffset": 142}, {"referenceID": 10, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 126, "endOffset": 142}, {"referenceID": 11, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 126, "endOffset": 142}, {"referenceID": 12, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 126, "endOffset": 142}, {"referenceID": 13, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 174, "endOffset": 178}, {"referenceID": 14, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 15, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 16, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 17, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 18, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 19, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 20, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 21, "context": "This section reviews previous methods developed for improving the classification of imbalanced data, such as data re-sampling [10, 11, 12, 13], adjusting decision thresholds [14] or the inclusion of cost parameters or weights into the classification algorithm [15, 16, 17, 18, 19, 20, 21, 22].", "startOffset": 260, "endOffset": 292}, {"referenceID": 9, "context": "The main issue with re-sampling techniques [10, 11, 12] is that the removal or introduction of data can modify the sequence structure and its meaning.", "startOffset": 43, "endOffset": 55}, {"referenceID": 10, "context": "The main issue with re-sampling techniques [10, 11, 12] is that the removal or introduction of data can modify the sequence structure and its meaning.", "startOffset": 43, "endOffset": 55}, {"referenceID": 11, "context": "The main issue with re-sampling techniques [10, 11, 12] is that the removal or introduction of data can modify the sequence structure and its meaning.", "startOffset": 43, "endOffset": 55}, {"referenceID": 13, "context": "Decision threshold methods such as that of [14] achieved similar results to re-sampling techniques and used receiver operating characteristic (ROC) curves to decide which decision threshold produces the best performance.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "Generally, cost sensitive learning approaches have been reported to perform better than re-sampling techniques in some applications [1].", "startOffset": 132, "endOffset": 135}, {"referenceID": 14, "context": "Some cost parameters have the form of a cost matrix that weighs each possible misclassification case, giving higher costs to misclassifications of a minority class observation in comparison to majority classes [15, 16, 17].", "startOffset": 210, "endOffset": 222}, {"referenceID": 15, "context": "Some cost parameters have the form of a cost matrix that weighs each possible misclassification case, giving higher costs to misclassifications of a minority class observation in comparison to majority classes [15, 16, 17].", "startOffset": 210, "endOffset": 222}, {"referenceID": 16, "context": "Some cost parameters have the form of a cost matrix that weighs each possible misclassification case, giving higher costs to misclassifications of a minority class observation in comparison to majority classes [15, 16, 17].", "startOffset": 210, "endOffset": 222}, {"referenceID": 16, "context": "from a cost matrix; these methods are reported to work well in binary data and only in some multiclass cases [17].", "startOffset": 109, "endOffset": 113}, {"referenceID": 16, "context": "various reasons[17].", "startOffset": 15, "endOffset": 19}, {"referenceID": 20, "context": "[21] introduced a fixed set of weights for each class for a binary SVM algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20], weights calculated from the misclassification cost of each class were introduced into Bayesian network classifiers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23], focused on improving the classification performance by modifying costs according to specific performance tasks (task-wise) such as improving recall, precision or both (as in F -score) [23] as opposed to classification error minimization as in previous studies.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23], focused on improving the classification performance by modifying costs according to specific performance tasks (task-wise) such as improving recall, precision or both (as in F -score) [23] as opposed to classification error minimization as in previous studies.", "startOffset": 190, "endOffset": 194}, {"referenceID": 21, "context": "The introduction of weights in CRF (WCRF) is not new; however, previous approaches only considered using a fixed set of weights during training for optimization [22]; however, finding an optimal set of weights [23, 20] require an extensive validation process.", "startOffset": 161, "endOffset": 165}, {"referenceID": 22, "context": "The introduction of weights in CRF (WCRF) is not new; however, previous approaches only considered using a fixed set of weights during training for optimization [22]; however, finding an optimal set of weights [23, 20] require an extensive validation process.", "startOffset": 210, "endOffset": 218}, {"referenceID": 19, "context": "The introduction of weights in CRF (WCRF) is not new; however, previous approaches only considered using a fixed set of weights during training for optimization [22]; however, finding an optimal set of weights [23, 20] require an extensive validation process.", "startOffset": 210, "endOffset": 218}, {"referenceID": 19, "context": "These previously mentioned methods [20, 22, 23] require empirical calculation of parameters.", "startOffset": 35, "endOffset": 47}, {"referenceID": 21, "context": "These previously mentioned methods [20, 22, 23] require empirical calculation of parameters.", "startOffset": 35, "endOffset": 47}, {"referenceID": 22, "context": "These previously mentioned methods [20, 22, 23] require empirical calculation of parameters.", "startOffset": 35, "endOffset": 47}, {"referenceID": 23, "context": "This is because the resulting measure, accuracy, is largely favoured by the dominant class and does not provide performance information regarding the predicted minority class [24].", "startOffset": 175, "endOffset": 179}, {"referenceID": 18, "context": "[19] dynamically changed the cost of the naive Bayes classifier by verifying and introducing classification errors on each iteration; this method optimized the squared loss function as opposed to the 0\u20131 loss function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18], dynamically learned parameters were introduced into a binary linear proximal SVM (LPSVM) objective function where weights were proportional to the ratio of the other class population.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] presented a method for generalizing structured classifiers such as CRF and Structured SVM (SSVM) and introduced a cost parameter given by the Hamming distance between predicted output and ground truth which was dynamically calculated during training.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Although the methods in [18, 25] presented dynamically calculated cost parameters, the model optimization was based on classification error minimization.", "startOffset": 24, "endOffset": 32}, {"referenceID": 24, "context": "Although the methods in [18, 25] presented dynamically calculated cost parameters, the model optimization was based on classification error minimization.", "startOffset": 24, "endOffset": 32}, {"referenceID": 25, "context": "Other studies offered alternative methods [26, 27].", "startOffset": 42, "endOffset": 50}, {"referenceID": 26, "context": "Other studies offered alternative methods [26, 27].", "startOffset": 42, "endOffset": 50}, {"referenceID": 25, "context": "The method of Soda [26] decided between an unbalanced or a balanced classifier for every observation and measured its performance based on accuracy; while Beyan et al.", "startOffset": 19, "endOffset": 23}, {"referenceID": 26, "context": "[27] proposed a hierarchical method based on clustering and outlier detection that, in general, was not significantly better than other methods.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] considered a learning algorithm for binary classification using a maximum likelihood model (weighted maximum entropy) to optimize the expected F -score during training where weights were calculated autonomously.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Our study extends weighted maximum entropy [28], originally", "startOffset": 43, "endOffset": 47}, {"referenceID": 8, "context": "We use CRF in order to model the dependency between consecutive activities described by sensor observations in the training sequences and applied in previous research [9, 29].", "startOffset": 167, "endOffset": 174}, {"referenceID": 28, "context": "We use CRF in order to model the dependency between consecutive activities described by sensor observations in the training sequences and applied in previous research [9, 29].", "startOffset": 167, "endOffset": 174}, {"referenceID": 5, "context": "In this section we briefly revisit CRFs, a probabilistic graphical model for structured classification [6, 30], as background to defining our method in Section 2.", "startOffset": 103, "endOffset": 110}, {"referenceID": 29, "context": "In this section we briefly revisit CRFs, a probabilistic graphical model for structured classification [6, 30], as background to defining our method in Section 2.", "startOffset": 103, "endOffset": 110}, {"referenceID": 27, "context": "We use the expected F -score (or F-measure) [28], as an optimization metric for our model as it considers FN and FP in its definition.", "startOffset": 44, "endOffset": 48}, {"referenceID": 27, "context": "In [28], Dimitroff et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "More information on Pareto efficiency can be found in [28, 31].", "startOffset": 54, "endOffset": 62}, {"referenceID": 27, "context": "However, the approach followed in [28] was for a binary Maximum Entropy classifier.", "startOffset": 34, "endOffset": 38}, {"referenceID": 27, "context": "Our work above expands the proof in [28] for binary classification to multiclass classification.", "startOffset": 36, "endOffset": 40}, {"referenceID": 30, "context": "Usually, class inference process for CRF is performed for complete sequences of data where methods as the forward-backwards or Viterbi algorithms are applied to the test segment and complete sequence of labels is returned [32].", "startOffset": 222, "endOffset": 226}, {"referenceID": 28, "context": "In a previous study, we have underscored the importance of real time prediction of activities [29] where we applied the belief propagation method to obtain the marginal probabilities of the last received observation; we use the current sensor observation and the information from the last inference made on the previous observation.", "startOffset": 94, "endOffset": 98}, {"referenceID": 31, "context": "Note we do not evaluate metrics depending on true negatives (TN) such as specificity [33, 34, 9] as specificity does not appropriately reflect the performance of the minority class.", "startOffset": 85, "endOffset": 96}, {"referenceID": 32, "context": "Note we do not evaluate metrics depending on true negatives (TN) such as specificity [33, 34, 9] as specificity does not appropriately reflect the performance of the minority class.", "startOffset": 85, "endOffset": 96}, {"referenceID": 8, "context": "Note we do not evaluate metrics depending on true negatives (TN) such as specificity [33, 34, 9] as specificity does not appropriately reflect the performance of the minority class.", "startOffset": 85, "endOffset": 96}, {"referenceID": 6, "context": "These datasets were obtained in the context of a larger project by our research group directed at the ambulatory monitoring of hospitalized older patients to prevent falls [7].", "startOffset": 172, "endOffset": 175}, {"referenceID": 33, "context": "We evaluate three case studies based on motion information from trialled healthy and hospitalized participants using the battery-less body worn sensor [35], shown in Figure 2(a).", "startOffset": 151, "endOffset": 155}, {"referenceID": 8, "context": "We consider that posture transitions such as sit to stand and stand to sit are integrated into the ambulation or sitting movements as data collected during posture transitions is scarce as the movements are of short duration [9].", "startOffset": 225, "endOffset": 228}, {"referenceID": 33, "context": "The participants wore a flexible Wearable Wireless Identification and Sensing Platform (WISP) device, developed by our team [35], over a garment on top of the sternum.", "startOffset": 124, "endOffset": 128}, {"referenceID": 34, "context": "The WISP, see Figure 2(a), and based on [36], encases a triaxial accelerometer (ADXL330) and a 16 bit microcontroller (MSP430F2132).", "startOffset": 40, "endOffset": 44}, {"referenceID": 35, "context": "The main motivation for using this passive (batteryless) device compared to using other battery powered sensors are twofold: i) the device requires no maintenance as it is battery free, lightweight, inexpensive and easy to replace; and ii) frail older people, especially those with conditions such as delirium or dementia, require easy-to-use equipment [37], and our proposed sensors\u2019 development objective is to be inconspicuous to the user i.", "startOffset": 353, "endOffset": 357}, {"referenceID": 28, "context": "We selected this window method and length as it is simple to deploy and performs as well as more complex windowing methods for feature extraction [29].", "startOffset": 146, "endOffset": 150}, {"referenceID": 31, "context": "We consider the body tilting angle \u03b1 on the midsagittal plane towards the front or back of the participant from the vertical reference [33].", "startOffset": 135, "endOffset": 139}, {"referenceID": 0, "context": "prefer sin(\u03b1) as it is proportional to \u03b1 and range limited to [-1,1].", "startOffset": 62, "endOffset": 68}, {"referenceID": 8, "context": "We also consider the time difference (\u2206t) between sensor observations as in previous research [9].", "startOffset": 94, "endOffset": 97}, {"referenceID": 36, "context": "complementary information to the instantaneous features in the temporal vicinity of the last received sensor observation [38].", "startOffset": 121, "endOffset": 125}, {"referenceID": 28, "context": "The mutual Information between bed and chair areas considers the occurrences of consecutive observations from two antennas focused towards the chair and bed occurring in either directions as used in [29].", "startOffset": 199, "endOffset": 203}, {"referenceID": 5, "context": "We evaluate the performance of our dWCRF model together with linear chain CRF [6]; a weighted CRF with fixed weight values (fWCRF), given by the inverse of the class distribution [22]; and a cost parameter based CRF such as the softmax-margin model (C-CRF) [23] on all three datasets, we use the L2 regularized model for each classifier of the form \u03b8\u2016\u03bb\u20162.", "startOffset": 78, "endOffset": 81}, {"referenceID": 21, "context": "We evaluate the performance of our dWCRF model together with linear chain CRF [6]; a weighted CRF with fixed weight values (fWCRF), given by the inverse of the class distribution [22]; and a cost parameter based CRF such as the softmax-margin model (C-CRF) [23] on all three datasets, we use the L2 regularized model for each classifier of the form \u03b8\u2016\u03bb\u20162.", "startOffset": 179, "endOffset": 183}, {"referenceID": 22, "context": "We evaluate the performance of our dWCRF model together with linear chain CRF [6]; a weighted CRF with fixed weight values (fWCRF), given by the inverse of the class distribution [22]; and a cost parameter based CRF such as the softmax-margin model (C-CRF) [23] on all three datasets, we use the L2 regularized model for each classifier of the form \u03b8\u2016\u03bb\u20162.", "startOffset": 257, "endOffset": 261}, {"referenceID": 37, "context": "In addition, we also compare with multiclass SVM for linear and radial basis function (RBF) kernels (L-SVM and R-SVM respectively) and the weighted SVM for both classifiers (L-WSVM and R-WSVM) [39, 40, 41].", "startOffset": 193, "endOffset": 205}, {"referenceID": 38, "context": "In addition, we also compare with multiclass SVM for linear and radial basis function (RBF) kernels (L-SVM and R-SVM respectively) and the weighted SVM for both classifiers (L-WSVM and R-WSVM) [39, 40, 41].", "startOffset": 193, "endOffset": 205}, {"referenceID": 39, "context": "In addition, we also compare with multiclass SVM for linear and radial basis function (RBF) kernels (L-SVM and R-SVM respectively) and the weighted SVM for both classifiers (L-WSVM and R-WSVM) [39, 40, 41].", "startOffset": 193, "endOffset": 205}, {"referenceID": 40, "context": "SVM algorithms were evaluated using libSVM [42] toolbox in Matlab, which performs a one-vs-one approach for multiclass classification.", "startOffset": 43, "endOffset": 47}, {"referenceID": 41, "context": "In the case of C-CRF, the parameters are selected to optimize F -score as in [43]; we applied an extensive grid search to obtain the optimal parameters in the value range [0, 20].", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "In the case of C-CRF, the parameters are selected to optimize F -score as in [43]; we applied an extensive grid search to obtain the optimal parameters in the value range [0, 20].", "startOffset": 171, "endOffset": 178}, {"referenceID": 42, "context": "Instead we use the covariance matrix adaptation evolution strategy (CMA-ES) [44], a widely used evolutionary optimization algorithm, to find the optimal set of per-class parameters for these classifiers.", "startOffset": 76, "endOffset": 80}, {"referenceID": 19, "context": "Given the stochastic nature of the initial parameter selection for the iterative CMA-ES process, we require evaluating multiple starting values; in our case, we evaluated 350 random initial points uniformly distributed in the range [0, 20] for each classifier.", "startOffset": 232, "endOffset": 239}, {"referenceID": 43, "context": "We chose to use the Opportunity activity recognition dataset [45], available in the UCI repository.", "startOffset": 61, "endOffset": 65}, {"referenceID": 22, "context": "In addition, our method obtained performance results comparable to other cost functions that optimize F -score such as Softmax-Margin [23] and other SVM based classifiers, but with an extensive reduction in learning time.", "startOffset": 134, "endOffset": 138}], "year": 2016, "abstractText": "The present study introduces a method for improving the classification performance of imbalanced multiclass data streams from wireless body worn sensors. Data imbalance is an inherent problem in activity recognition caused by the irregular time distribution of activities, which are sequential and dependent on previous movements. We use conditional random fields (CRF), a graphical model for structured classification, to take advantage of dependencies between activities in a sequence. However, CRFs do not consider the negative effects of class imbalance during training. We propose a class-wise dynamically weighted CRF (dWCRF) where weights are automatically determined during training by maximizing the expected overall F-score. Our results based on three case studies from a healthcare application using a batteryless body worn sensor, demonstrate that our method, in general, improves overall and minority class F-score when compared to other CRF based classifiers and achieves similar or better overall and class-wise performance when compared to SVM based classifiers under conditions of limited training data. We also confirm the performance of our approach using an additional battery powered body worn sensor dataset, achieving similar results in cases of high class imbalance.", "creator": "LaTeX with hyperref package"}}}