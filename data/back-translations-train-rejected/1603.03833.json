{"id": "1603.03833", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Mar-2016", "title": "Learning real manipulation tasks from virtual demonstrations using LSTM", "abstract": "Robots assisting disabled or elderly people in the performance of activities of daily living need to perform complex manipulation tasks which are highly dependent on the environment and preferences of the user. In addition, these environments and users are not suitable for the collection of massive amounts of training data, as the manipulated objects can be fragile, and the wheelchair-bound users might have difficulty recovering from a failed manipulation task.", "histories": [["v1", "Sat, 12 Mar 2016 00:47:38 GMT  (1949kb,D)", "http://arxiv.org/abs/1603.03833v1", null], ["v2", "Thu, 15 Sep 2016 23:56:19 GMT  (2964kb,D)", "http://arxiv.org/abs/1603.03833v2", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.LG", "authors": ["rouhollah rahmatizadeh", "pooya abolghasemi", "aman behal", "ladislau b\\\"ol\\\"oni"], "accepted": false, "id": "1603.03833"}, "pdf": {"name": "1603.03833.pdf", "metadata": {"source": "CRF", "title": "Learning Manipulation Trajectories Using Recurrent Neural Networks", "authors": ["Rouhollah Rahmatizadeh", "Pooya Abolghasemi", "Ladislau B\u00f6l\u00f6ni"], "emails": ["lboloni}@eecs.ucf.edu"], "sections": [{"heading": "1 Introduction", "text": "eDi eeisrcnlhsrteeSrlteeeeeteeteeteeterrrrrsrteeaeVrlrrrteeoiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiteteeteeteeteeterrrrrrsrrsrsrrsrsrsrrrrrrteeteeteeteeteeteerrrsrrrsrrrrsrsrsrrrteeetnlrsrsrteeteeteeteeteeteeteeteerrrrrrrrrrsrrrsrrrrrrsrsrrrteeteeteeteeteeteeteeteeteeteeteeteeteerrrrrsrrsrsrsrrrsrrsrrrsrrsrrsrrsrrrrrsrsrsrrsrrsrsrrrrsrsrrsrteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteeteersrsrrsrsrsrrsrsrsrrsrsrrsrsrsrsrsrsrsrsrrsrsrsrsrrsrsrsrsrsrsrsrsrsrsrsrsrsrsrsrrrsrsrsrsrrsrsrrsrsrsrrrsrrsrsrrrrrrrrrrrrrrrrrrr"}, {"heading": "2 Related work", "text": "In fact, most of them are not an individual, but a group of people who are able to survive themselves, and a group of people who are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "3 Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Trajectory representation", "text": "Suppose that N demonstrations D = {d1... di.. dN} are available to perform a task. Each demonstration di = {E, Q, P} consists of Q = {q1... qt... qT}, in which qt the state of the environment in due course t = [1.. T], E = [e1.... et... eT], in which et is the end effector, can be extended for each demonstration by the gripper status (open / close). In this essay, we consider the state of environment Q as the sequence of objects involved in a manipulation task. PT} is the set of user preferences in each time step. The duration of execution of a proposed path T may vary for each demonstration. In this essay, we consider the state of environment Q as the sequence of objects involved in a manipulation task. Therefore, we assume that qt = {o1... oj."}, {"heading": "3.2 The input and output of the neural network", "text": "Similar to the upstream neural networks, the RNNs take a fixed-size vector of the inputs and generate a fixed-size vector of the outputs. However, what makes the RNNs special is the feedback connection from the output of each layer to its input. This structure helps them store a memory of the past and use this information as they generate the output. We use this property of the RNNs to model a trajectory, since the current trajectory waypoint depends on the previous waypoints. It is easy to feed in a waypoint that contains et, the end effect at a time, and to ask the network to predict what et + 1 will be, the next end effect at a time t + 1. However, in this scenario, the network learns to execute an average of the trajectories trajectories without taking into account the state of the environment. As a tampering trajectories also depends on the pose of all objects involved in the task, the network will prefeed the state of each affected object to the trajectories that contains the trajectories."}, {"heading": "3.3 The structure of the neural network", "text": "The goal of the network is to learn a model of the trajectory by estimating the mean of the probability distribution of the next waypoint in the trajectory containing all previous waypoints containing end effector, environmental state and user preferences: P (e1,.., eT) = T \u0442t = 1 P (et | {e, q, p} 1,.., {e, q, p} t \u2212 1) (1) For this purpose, RNs learn a specified size representation of the input and use it to predict the output. This hidden representation can be stored in one or more layers. Let's show the state of the layer l = 1.. L at time step t t = 1. T at hlt, the input of the layer is the current output of the previous layer \u2212 1t and the output of the last layer h \u2212 0.004 at the previous layer. The first layer h \u2212 1 t is the input xt = qt, Gr \u00b2, the last layer \u2212 ylt."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Simulation environment", "text": "In order to collect the data necessary to train the network and to test the execution of the task, we designed a virtual environment in the Unity3D game engine. Unity3D simulates the basic physics of the real world, including gravity, collision between objects and friction. For experiments in a typical environment where ADLs take place, we created a model of a desk that holds a variety of objects. Since the scenario we assume includes a wheelchair-mounted robotic arm (such as an InMotion MANUS or Kinova Jaco), the virtual environment contains a simple two-finger gripper that can be opened and closed to grasp and carry an object. The user can move the end effect of the robot in the 3D cartesian space using the mouse or joystick. It is also possible to rotate the end effector using the keyboard or joystick. In addition, opening and closing the gripper is made available to the user at any time so that the gripper is able to perform the task in the degree of 7."}, {"heading": "4.2 Manipulation tasks for ADLs", "text": "The performance of ADLs such as self-feeding, dressing, grooming and personal hygiene typically involves manipulation tasks interrupted by pauses and cognitive decisions. Unless users have severe cognitive disabilities, they would normally maintain cognitive decisions (such as deciding which food to reach next). Therefore, for this paper we have focused on two manipulation tasks that are components of many ADLs: Push. The first task is to place a large box that is not tangible somewhere near the shelf to organize the desk. The robot starts from a random gripper position, moves the gripper near the box and gradually pushes the box toward the shelf to be processed. If the box reaches the desired area near the shelf tolerance error, the box will reappear in a random position on the desk with a random orientation. The gripper must circle the box without colliding with it to repeat the task."}, {"heading": "4.3 User preferences", "text": "There are different ways to accomplish a task. For example, if the goal is to put the box on the shelf, any trajectory that allows the box to be placed on the shelf is acceptable. However, these trajectories may be different in their path, speed, smoothness, etc. To show how well our model can generate the trajectory based on user preferences, we consider two preferences when selecting and placing the task. To this end, the end point of each task execution (i.e. if the box is located within the shelf) is taken into account and the position of the box at that moment is extracted. It is possible to extract this preference from the recorded data and use it to control this behavior. To this end point of each task execution (i.e. if the box is located within the shelf) is considered and the position of the box at that moment is extracted."}, {"heading": "4.4 Data", "text": "We have collected a dataset in which the sliding task was demonstrated 473 times, while the pick-and-place task is transmitted 290 times. During the demonstration, the demonstrating user made occasional errors, so the data is noisy. As the difference between the consecutive waypoints when the task is recorded at 33 Hz is very small, the network cannot capture long-distance dependencies. Therefore, we only hold 1 waypoint from each 4 consecutive points to make the resulting path rate of 8 Hz. Thus, we ended up with 12908 waypoints for training the network on the first task. In the second task, to properly capture the user's preferences, we need more data, while the data is generated and overhauled, we have added synthetic trajectories to the dataset, which are gained by transferring the entire web in space and time."}, {"heading": "4.5 Network architectures", "text": "For our experimental study, we trained four different neural networks of the following architectures and parameterization: \u2022 LSTM-2: 2 layers of LSTM with 512 memory states in each layer \u2022 LSTM-4: 4 layers of LSTM with total parameters close to the LSTM-2 network \u2022 GRU-2: 2 layers of GRU with sufficient memory states to make the total number of parameters close to the previous networks \u2022 FeedForward-4: a fully connected feedback network with 4 layers and a number of parameters close to the LSTM and GRU networks. The input is the pose of the current gripper and the status supplemented by the current pose of the objects involved in the manipulation and the output is the next predicted pose of the gripper and its state. All networks have approximately 4.2 million parameters."}, {"heading": "5 Results", "text": "The aforementioned lcihsrcnlAe nvo edn rf\u00fc ide eerwdnei rf\u00fc ide eerwdnei eerwdnei eerwdnei eerwdnei rf\u00fc ide eerwdnei eerwdnei eerwdne.nlrVo nI \"s tsi hacu,\" he asgt."}, {"heading": "6 Discussion", "text": "The proposed model is deterministic, which means that only one action can be taken in each state. However, in some tasks there are different solutions from one state. As a simplified example, we consider the task of moving a box to the northeast, which is not the right solution. However, in this type of task, the proposed model does not learn properly to perform the task. Such errors indicate the need to integrate decision-making at a higher level into the process as the tasks become more complex. Extending to the real world is not the right solution. The proposed model can be trained with the data collected from the simulation to perform the task properly. Such errors indicate the need to integrate decision-making at a higher level into the process."}, {"heading": "7 Conclusions", "text": "The approach is based on mediating a neural network to generate the trajectory by means of demonstration sequences. As the networks require a relatively large number of demonstrations, we developed a virtual reality environment in which the demonstrations can be performed more quickly and safely. We found that recurring neural networks were able to learn the two tasks (push object and pick-and-place) using a 2-layer LTSM network that works best. On the other hand, we found that an upstream neural network with its implicit Markov assumption cannot learn any of these tasks."}], "references": [{"title": "Autonomous helicopter aerobatics through apprenticeship learning", "author": ["Pieter Abbeel", "Adam Coates", "Andrew Y Ng"], "venue": "International Journal of Robotics Research (IJRR),", "citeRegEx": "Abbeel et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Robotics and autonomous systems", "author": ["Brenna D Argall", "Sonia Chernova", "Manuela Veloso", "Brett Browning. A survey of robot learning from demonstration"], "venue": "57(5):469\u2013483,", "citeRegEx": "Argall et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Bakebot: Baking cookies with the PR2", "author": ["Mario Bollini", "Jennifer Barry", "Daniela Rus"], "venue": "IROS PR2 workshop: results, challenges and lessons learned in advancing robots with a common platform,", "citeRegEx": "Bollini et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Florent D\u2019halluin", "author": ["Sylvain Calinon"], "venue": "Eric L Sauser, Darwin G Caldwell, and Aude G Billard. Learning and reproduction of gestures by imitation. IEEE Robotics & Automation Magazine, 17(2):44\u201354,", "citeRegEx": "Calinon et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.1259,", "citeRegEx": "Cho et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "pages 339\u2013346", "author": ["Christopher Crick", "Sarah Osentoski", "Graylin Jay", "Odest Chadwicke Jenkins. Human", "robot perception in large-scale learning from demonstration. In International conference on Human-robot interaction"], "venue": "ACM,", "citeRegEx": "Crick et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["Donahue et al", "2014] Jeff Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Kate Saenko", "Trevor Darrell"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2014\\E", "shortCiteRegEx": "al. et al\\.", "year": 2014}, {"title": "In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "author": ["Felix Endres", "Jeff Trinkle", "Wolfram Burgard. Learning the dynamics of doors for robotic manipulation"], "venue": "pages 3543\u20133549,", "citeRegEx": "Endres et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Robot programming by demonstration with crowdsourced action fixes", "author": ["Maxwell Forbes", "Michael Jae-Yoon Chung", "Maya Cakmak", "Rajesh PN Rao"], "venue": "Second AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "Forbes et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "A novel connectionist system for unconstrained handwriting recognition", "author": ["Graves et al", "2009] Alex Graves", "Marcus Liwicki", "Santiago Fern\u00e1ndez", "Roman Bertolami", "Horst Bunke", "J\u00fcrgen Schmidhuber"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI),", "citeRegEx": "al. et al\\.,? \\Q2009\\E", "shortCiteRegEx": "al. et al\\.", "year": 2009}, {"title": "Speech and Signal Processing (ICASSP)", "author": ["Alan Graves", "Abdel-rahman Mohamed", "Geoffrey Hinton. Speech recognition with deep recurrent neural networks. In IEEE International Conference on Acoustics"], "venue": "pages 6645\u20136649,", "citeRegEx": "Graves et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Neural computation", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber. Long short-term memory"], "venue": "9(8):1735\u20131780,", "citeRegEx": "Hochreiter and Schmidhuber. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "Visualizing and understanding recurrent networks", "author": ["Andrej Karpathy", "Justin Johnson", "Fei-Fei Li"], "venue": "arXiv preprint arXiv:1506.02078,", "citeRegEx": "Karpathy et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In IEEE International Conference on Robotics and Automation (ICRA)", "author": ["Ben Kehoe", "Akihiro Matsukawa", "Sal Candido", "James Kuffner", "Ken Goldberg. Cloud-based robot grasping with the Google object recognition engine"], "venue": "pages 4263\u20134270,", "citeRegEx": "Kehoe et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "In International Joint Conference on Artificial Intelligence (IJCAI)", "author": ["Jens Kober", "Erhan Oztop", "Jan Peters. Reinforcement learning to adjust robot movements to new situations"], "venue": "volume 22, page 2650,", "citeRegEx": "Kober et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "End-to-end training of deep visuomotor policies", "author": ["Sergey Levine", "Chelsea Finn", "Trevor Darrell", "Pieter Abbeel"], "venue": "arXiv preprint arXiv:1504.00702,", "citeRegEx": "Levine et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "The International Journal of Robotics Research", "author": ["Stephen Miller", "Jur Van Den Berg", "Mario Fritz", "Trevor Darrell", "Ken Goldberg", "Pieter Abbeel. A geometric approach to robotic laundry folding"], "venue": "31(2):249\u2013267,", "citeRegEx": "Miller et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "In IEEE International Conference on Robotics and Automation (ICRA)", "author": ["Peter Pastor", "Heiko Hoffmann", "Tamim Asfour", "Stefan Schaal. Learning", "generalization of motor skills by learning from demonstration"], "venue": "pages 763\u2013768,", "citeRegEx": "Pastor et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Robobarista: Object part-based transfer of manipulation trajectories from crowd-sourcing in 3d pointclouds", "author": ["Jaeyong Sung", "Seok Hyun Jin", "Ashutosh Saxena"], "venue": "International Symposium on Robotics Research (ISRR),", "citeRegEx": "Sung et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "In Advances in neural information processing systems (NIPS)", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc VV Le. Sequence to sequence learning with neural networks"], "venue": "pages 3104\u20133112,", "citeRegEx": "Sutskever et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["Tieleman", "Hinton", "2012] Tijmen Tieleman", "Geoffrey Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Tieleman et al\\.", "year": 2012}, {"title": "Show and tell: A neural image caption generator", "author": ["Oriol Vinyals", "Alexander Toshev", "Samy Bengio", "Dumitru Erhan"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Vinyals et al.. 2015", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 7, "context": "as solving problems of object identification combined with problems in planning and control theory [Endres et al., 2013; Miller et al., 2012; Bollini et al., 2011].", "startOffset": 99, "endOffset": 163}, {"referenceID": 16, "context": "as solving problems of object identification combined with problems in planning and control theory [Endres et al., 2013; Miller et al., 2012; Bollini et al., 2011].", "startOffset": 99, "endOffset": 163}, {"referenceID": 2, "context": "as solving problems of object identification combined with problems in planning and control theory [Endres et al., 2013; Miller et al., 2012; Bollini et al., 2011].", "startOffset": 99, "endOffset": 163}, {"referenceID": 11, "context": "Recurrent neural networks, and especially Long Short Term Memory (LSTM) [Hochreiter and Schmidhuber, 1997] with gating mechanism, had been proved to be effective in many sequence learning tasks.", "startOffset": 72, "endOffset": 106}, {"referenceID": 12, "context": "For instance, in character-level text generation [Karpathy et al., 2015], they can learn to close a parenthesis that had been opened earlier.", "startOffset": 49, "endOffset": 72}, {"referenceID": 12, "context": ", 2009], language modeling [Karpathy et al., 2015], machine translation [Sutskever et al.", "startOffset": 27, "endOffset": 50}, {"referenceID": 19, "context": ", 2015], machine translation [Sutskever et al., 2014], speech recognition [Graves et al.", "startOffset": 29, "endOffset": 53}, {"referenceID": 10, "context": ", 2014], speech recognition [Graves et al., 2013], visual recognition [Donahue et al.", "startOffset": 28, "endOffset": 49}, {"referenceID": 21, "context": ", 2014], and image captioning [Vinyals et al., 2015].", "startOffset": 30, "endOffset": 52}, {"referenceID": 11, "context": "Newer RNN models feature explicit gating mechanism [Hochreiter and Schmidhuber, 1997] that helped in storing and retrieving information over long time periods.", "startOffset": 51, "endOffset": 85}, {"referenceID": 4, "context": "In recent years, similar mechanisms were proposed such as Gated Recurrent Units (GRU) [Cho et al., 2014].", "startOffset": 86, "endOffset": 104}, {"referenceID": 1, "context": "One of the most effective approaches for teaching robots to execute a desired task is Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings [Argall et al., 2009].", "startOffset": 194, "endOffset": 215}, {"referenceID": 0, "context": "of successful application include autonomous helicopter maneuvers [Abbeel et al., 2010], playing table tennis [Kober et al.", "startOffset": 66, "endOffset": 87}, {"referenceID": 14, "context": ", 2010], playing table tennis [Kober et al., 2011][Calinon et al.", "startOffset": 30, "endOffset": 50}, {"referenceID": 3, "context": ", 2011][Calinon et al., 2010], object manipulation [Pastor et al.", "startOffset": 7, "endOffset": 29}, {"referenceID": 17, "context": ", 2010], object manipulation [Pastor et al., 2009], and making coffee [Sung et al.", "startOffset": 29, "endOffset": 50}, {"referenceID": 18, "context": ", 2009], and making coffee [Sung et al., 2015].", "startOffset": 27, "endOffset": 46}, {"referenceID": 13, "context": "enough data for the task learning, some researchers proposed to use cloud-based and crowdsourced data collection techniques [Kehoe et al., 2013], [Forbes et al.", "startOffset": 124, "endOffset": 144}, {"referenceID": 8, "context": ", 2013], [Forbes et al., 2014], [Crick et al.", "startOffset": 9, "endOffset": 30}, {"referenceID": 5, "context": ", 2014], [Crick et al., 2011].", "startOffset": 9, "endOffset": 29}, {"referenceID": 15, "context": "For instance, [Levine et al., 2015] utilized feed-forward neural networks to map robot\u2019s visual input to control commands.", "startOffset": 14, "endOffset": 35}, {"referenceID": 11, "context": "The recurrent networks we use in this paper are LSTM [Hochreiter and Schmidhuber, 1997] and GRU [Cho et al.", "startOffset": 53, "endOffset": 87}, {"referenceID": 4, "context": "The recurrent networks we use in this paper are LSTM [Hochreiter and Schmidhuber, 1997] and GRU [Cho et al., 2014] that follow the general formulation explained above.", "startOffset": 96, "endOffset": 114}, {"referenceID": 19, "context": "08 following the recommendation by [Sutskever et al., 2014].", "startOffset": 35, "endOffset": 59}, {"referenceID": 17, "context": "[Pastor et al., 2009])", "startOffset": 0, "endOffset": 21}], "year": 2016, "abstractText": "Robots assisting disabled or elderly people in the performance of activities of daily living need to perform complex manipulation tasks which are highly dependent on the environment and preferences of the user. In addition, these environments and users are not suitable for the collection of massive amounts of training data, as the manipulated objects can be fragile, and the wheelchair-bound users might have difficulty recovering from a failed manipulation task. In this paper, we propose an end-to-end learning mechanism for the type of complex robot arm trajectories used in manipulation tasks for assistive robots. The trajectory is learned using a recurrent neural network that can generate the trajectory in real-time based on the current situation of the end-effector, the objects in the environment and the preferences of the user. The learning data is acquired from a simulation environment where the human can demonstrate the task in a simulation closely modeling his or her own environment. Experiments using two different manipulation tasks show that the robot can learn the manipulation planning as well the ability to recover from failure.", "creator": "LaTeX with hyperref package"}}}