{"id": "1603.04000", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Mar-2016", "title": "Learning Typographic Style", "abstract": "Typography is a ubiquitous art form that affects our understanding, perception, and trust in what we read. Thousands of different font-faces have been created with enormous variations in the characters. In this paper, we learn the style of a font by analyzing a small subset of only four letters. From these four letters, we learn two tasks. The first is a discrimination task: given the four letters and a new candidate letter, does the new letter belong to the same font? Second, given the four basis letters, can we generate all of the other letters with the same characteristics as those in the basis set? We use deep neural networks to address both tasks, quantitatively and qualitatively measure the results in a variety of novel manners, and present a thorough investigation of the weaknesses and strengths of the approach.", "histories": [["v1", "Sun, 13 Mar 2016 05:44:57 GMT  (1706kb,D)", "http://arxiv.org/abs/1603.04000v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["shumeet baluja"], "accepted": false, "id": "1603.04000"}, "pdf": {"name": "1603.04000.pdf", "metadata": {"source": "CRF", "title": "Learning Typographic Style", "authors": ["Shumeet Baluja"], "emails": ["shumeet@google.com"], "sections": [{"heading": null, "text": "Keywords: style analysis, typography, image generation, learning"}, {"heading": "1 Introduction", "text": "The history of the country is huge, and its origins date back to the 19th century."}, {"heading": "2 A Discriminative Task: Same Font or Not?", "text": "By addressing the question of whether a set of base letters contains enough information to extract the \"style,\" we immediately work to identify sources of potential difficulties for the overarching goal of character generation - i.e., will the generative process have enough information to extract the base letters to successfully complete the task? In addition, the networks created here will be a critical component in validating the final results generated (Section 3.3). The discriminatory task is as follows: With a set of four base letters 1, e.g. B, A, S, Q, in font-A and another letter, can we train a classifier to correctly detect whether \u03a6 is generated in the style of font-A? See Figure 2. Next, we describe how the data is preprocessed and the neural networks used to accomplish the task."}, {"heading": "2.1 Data Specifics", "text": "Because of the large variation in the font surfaces studied, normalization of the font images was vital, albeit minimal; each letter was entered into the network as a 36 x 36 grayscale pixel image; a total of 5 letters were used as inputs: the first 4 were the base letters (all of the same font), and the fifth letter should be categorized; the output of the network was a single binary value indicating whether the fifth letter belongs to the same font as the others; all fonts used in this study were true-type font examples (TTF) that allow scaling; due to the stylistic variations present in the data, the ratio of width to height of the different font surfaces varies dramatically; the size of the characters within the 36 x 36 x 36 image is determined as follows: For each font, all 26 uppercase letters are generated with the same number of dots until the drill box is reached."}, {"heading": "2.2 Network Architectures", "text": "Building on the success of deep meshes for image recognition (see [20] for a recent summary with ImageNet), we are exploring a variety of neural network architectures for this task. Numerous experiments have been conducted to find effective network architectures, and of the more than 60 architectures mentioned, the best seven have been selected."}, {"heading": "2.3 Individual and Ensembles Network Results", "text": "As mentioned in the previous section, over 60 architectures were experimented with this task. Gradient Desktop with Dynamics (SGD + Momentum) was used to train the networks and not domain-specific pre-normalization of weights. Of the 60 architectures, seven were selected (see Table 1), all based on the tower architecture (Figure 3). The performance of the discrimination task was measured on an independent test set - the 4-base letters and were drawn from fonts not used for training. Results were consistent across a variety of free parameters, the number of parameters varied by a factor of 18 \u00d7, the performance was illuminated to visualize the types of errors."}, {"heading": "3 A Generative Task: Creating Style-Specific Characters", "text": "In the previous section, we found that the 4-base letters contain enough information to correctly determine whether a fifth letter is a member of the same font. In this section, we are trying to construct networks that generate characters. Broadly, the experiments are divided into two approaches: single-letter and multi-letter generation. In the first approach, a network is trained to generate only a single letter. In multi-letter generation networks, all letters are generated by the same network at the same time. Although the single-letter networks are easier conceptually, forming a network to generate multiple letters at the same time can allow the hidden units to share useful representations and features - i.e., serif style, line width, angle, etc. This is a form of transfer learning with a strong foundation for multi-tasking learning [28,29,30,31]."}, {"heading": "3.1 Single Letter Generation", "text": "As in the previous section, experiments were conducted with numerous network architectures, varying in the number of layers (2-10), units (100s-1000s), and connectivity patterns, and the final architecture is shown in Figure 6 (left). In the discrimination task described in the previous section, there was a single source node, which allowed the use of large hidden layers because the number of connections to the final output remained low. In contrast, the number of output nodes is the number of desired pixels; in this case, it is the size of a full input character (36 x 36), dramatically increasing the number of connections in the network. To mitigate this growth in the number of connections, reverse retinal connections were used, in which each hidden unit in the penultimate layer forms a link to a small layer."}, {"heading": "3.2 Simultaneous Letter Generation - Multi-Task Learning", "text": "In this section, we examine the task of generating all uppercase letters at the same time, as many letters share common components (e.g. \"P\" & \"R,\" \"O\" & \"Q,\" \"T\" & \"I.\") See Figure 6 (Right) Once again, numerous architectures were examined (a total of over 30). Comparing the best networks of the letter generation with the best networks of the multi-letter generation, the SSE error was repeatedly reduced by using the multi-letter generation (by 5% -6%), but qualitatively, the letters generated by both networks appeared similar. Nevertheless, due to the slight improvement in the SSE error coupled with the ease of use, the multi-letter generation networks will be used in the future (by 5% -6%)."}, {"heading": "3.3 Validating Results", "text": "In the previous section, the results of the font generation network were measured on the basis of the SSE error of the network and then by an external human evaluator. Here, we present alternative methods based on the use of the discriminatory networks used in Section 2. The discriminatory networks were used to determine whether an input character was the same as the initial characters. Remember that by using a matching ensemble of 7 networks, 92.1% accuracy was used. To test the generative network G for font f, the results of G (f) are passed into the discriminatory network ensemble (D) along with the original BASQ base letters, D (Bf, Af, Sf, Qf, G (f)). Consequently, the output of D is used to determine whether the generated character is the same font as the base letter. Novel variants of this method, using pairs of generator / discrimination networks were proposed independently."}, {"heading": "4 Future Work", "text": "Beyond the simple exploration of the number and selection of base letters and also the generation of lowercase letters, there are many conceptually interesting paths for future work. First, an alternative approach to using generator networks is to use discrimination networks and derivatives back to the inputs to maximize the similarity of the hidden states. This has recently been proposed to create natural images as well as dreamlike images. \"Deep Dreams\" [38,17]. Second, we have made a concerted effort to use the simplest networks that are possible. An extensive empirical search through the space of networks and learning algorithms has been conducted to find the simplest solutions to this task."}, {"heading": "5 Conclusions", "text": "The results are promising, but the complete capture of the artistic visual intention is just the beginning. Many of the shapes, weights, angles and serifs have been successfully modeled. As the learning process progresses, some of the more individual nuances and repeated intricate design patterns unique to individual fonts will be captured."}, {"heading": "6 Acknowledgments", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Treasury of Alphabets and Lettering: A Source Book of the Best Letter Forms of Past and Present for Sign Painters, Graphic Artists, Commercial Artists, Typographers, Printers, Sculptors, Architects, and Schools of Art and Design", "author": ["J. Tschichold"], "venue": "A Norton professional book. Norton", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Typeface timeline shows us the history of fonts", "author": ["E. Hutchings"], "venue": "http://www.psfk.com/2012/04/history-of-fonts.html", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "An eye tracking study of how font size and type influence online reading", "author": ["D. Beymer", "D. Russell", "P. Orton"], "venue": "Proceedings of the 22nd British HCI Group Annual Conference on People and Computers: Culture, Creativity, Interaction-Volume 2, British Computer Society", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "The influence of design factors on trust in a bank\u2019s website", "author": ["S. Ha"], "venue": "Digital Repository@ Iowa State University", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Increasing trust in mobile commerce through design aesthetics", "author": ["Y.M. Li", "Y.S. Yeh"], "venue": "Computers in Human Behavior 26(4)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Download", "author": ["10000Fonts.com"], "venue": "http://www.10000fonts.com/catalog/", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Separating style and content with bilinear models", "author": ["J.B. Tenenbaum", "W.T. Freeman"], "venue": "Neural computation 12(6)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2000}, {"title": "A fontastic voyage: Generative fonts with adversarial networks", "author": ["M. Bowey"], "venue": "http://multithreaded.stitchfix.com/blog/2016/02/02/a-fontastic-voyage", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "From A to Z: Supervised Transfer of Style and Content Using Deep Neural Network Generators", "author": ["P. Upchurch", "N. Snavely", "K. Bala"], "venue": "ArXiv e-prints", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Analyzing 50k fonts using deep neural networks (2016", "author": ["E. Bernhardsson"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Elements of style: learning perceptual shape style similarity", "author": ["Z. Lun", "E. Kalogerakis", "A. Sheffer"], "venue": "ACM Transactions on Graphics (TOG) 34(4)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Defining pictorial style: Lessons from linguistics and computer graphics", "author": ["J. Willats", "F. Durand"], "venue": "Axiomathes 15(3)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "CoRR abs/1308.0850", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Recognizing image style", "author": ["S. Karayev", "A. Hertzmann", "H. Winnemoeller", "A. Agarwala", "T. Darrell"], "venue": "CoRR abs/1311.3715", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "The interestingness of images", "author": ["M. Gygli", "H. Grabner", "H. Riemenschneider", "F. Nater", "L. Gool"], "venue": "Proceedings of the IEEE International Conference on Computer Vision.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "What makes an image popular", "author": ["A. Khosla", "A. Das Sarma", "R. Hamid"], "venue": "Proceedings of the 23rd international conference on World wide web,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "A neural algorithm of artistic style", "author": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"], "venue": "CoRR abs/1508.06576", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Representing musical genre: A state of the art", "author": ["J.J. Aucouturier", "F. Pachet"], "venue": "Journal of New Music Research 32(1)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "A 20 minute intro to typography basics", "author": ["M. Bowey"], "venue": "http://design.tutsplus.com/articles/a-20-minute-intro-to-typography-basics\u2013 psd-3326", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M.S. Bernstein", "A.C. Berg", "F. Li"], "venue": "CoRR abs/1409.0575", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Largescale video classification with convolutional neural networks", "author": ["A. Karpathy", "G. Toderici", "S. Shetty", "T. Leung", "R. Sukthankar", "L. Fei-Fei"], "venue": "Proceedings of the IEEE conference on Computer Vision and Pattern Recognition.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-path convolutional neural networks for complex image classification", "author": ["M. Wang"], "venue": "CoRR abs/1506.04701", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature 521(7553)", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "On rectified linear units for speech processing", "author": ["M.D. Zeiler", "M. Ranzato", "R. Monga", "M. Mao", "K. Yang", "Q.V. Le", "P. Nguyen", "A. Senior", "V. Vanhoucke", "J Dean"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, IEEE", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Boosting the margin: A new explanation for the effectiveness of voting methods", "author": ["R.E. Schapire", "Y. Freund", "P. Bartlett", "W.S. Lee"], "venue": "Annals of statistics", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1998}, {"title": "Deep learning of representations for unsupervised and transfer learning", "author": ["Y. Bengio"], "venue": "Unsupervised and Transfer Learning Challenges in Machine Learning 7", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers", "author": ["J.T. Huang", "J. Li", "D. Yu", "L. Deng", "Y. Gong"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, IEEE", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Machine learning 28(1)", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1997}, {"title": "Deep convolutional neural network for image deconvolution", "author": ["L. Xu", "J.S. Ren", "C. Liu", "J. Jia"], "venue": "Advances in Neural Information Processing Systems.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning a deep convolutional network for image super-resolution", "author": ["C. Dong", "C.C. Loy", "K. He", "X. Tang"], "venue": "Computer Vision\u2013ECCV 2014. Springer", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Generating images with recurrent adversarial networks", "author": ["D. Jiwoong Im", "C. Dongjoo Kim", "H. Jiang", "R. Memisevic"], "venue": "ArXiv e-prints", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "Generating Images with Perceptual Similarity Metrics based on Deep Networks", "author": ["A. Dosovitskiy", "T. Brox"], "venue": "ArXiv e-prints", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2016}, {"title": "Inceptionism: Going deeper into neural networks", "author": ["A. Mordvintsev", "C. Olah", "M. Tyka"], "venue": "http://googleresearch.blogspot.com/2015/06/inceptionism-going-deeperinto-neural.html", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "szlam", "a.", "R. Fergus"], "venue": "In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., Garnett, R., eds.: Advances in Neural Information Processing Systems 28. Curran Associates, Inc.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to execute", "author": ["W. Zaremba", "I. Sutskever"], "venue": "arXiv preprint arXiv:1410.4615", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2014}, {"title": "A first look at music composition using lstm recurrent neural networks", "author": ["D. Eck", "J. Schmidhuber"], "venue": "Istituto Dalle Molle Di Studi Sull Intelligenza Artificiale 103", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2002}, {"title": "Neural turing machines", "author": ["A. Graves", "G. Wayne", "I. Danihelka"], "venue": "arXiv preprint arXiv:1410.5401", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "\u201d This was based on the handwriting style of the time, and was used to print the first books [1,2].", "startOffset": 93, "endOffset": 98}, {"referenceID": 1, "context": "\u201d This was based on the handwriting style of the time, and was used to print the first books [1,2].", "startOffset": 93, "endOffset": 98}, {"referenceID": 2, "context": "Centuries later, numerous studies have consistently shown the large impact that fonts have on not only the readability of text, but also the comprehensibility and trustability of what is written [3,4,5].", "startOffset": 195, "endOffset": 202}, {"referenceID": 3, "context": "Centuries later, numerous studies have consistently shown the large impact that fonts have on not only the readability of text, but also the comprehensibility and trustability of what is written [3,4,5].", "startOffset": 195, "endOffset": 202}, {"referenceID": 4, "context": "Centuries later, numerous studies have consistently shown the large impact that fonts have on not only the readability of text, but also the comprehensibility and trustability of what is written [3,4,5].", "startOffset": 195, "endOffset": 202}, {"referenceID": 5, "context": "A small sample of a few of the over 10,000 fonts [6] used in this study are shown in Figure 1.", "startOffset": 49, "endOffset": 52}, {"referenceID": 6, "context": "The seminal work of Tenenbaum and Freeman [7] towards separating style from content was applied to letter generation.", "startOffset": 42, "endOffset": 45}, {"referenceID": 6, "context": "In contrast to [7], we do not attempt to explicitly model style and content separately; rather, through training a learning model (a deep neural network) to reproduce style, content and style are implicitly distinguished.", "startOffset": 15, "endOffset": 18}, {"referenceID": 7, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 82, "endOffset": 90}, {"referenceID": 8, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 82, "endOffset": 90}, {"referenceID": 9, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 82, "endOffset": 90}, {"referenceID": 10, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 162, "endOffset": 166}, {"referenceID": 11, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 186, "endOffset": 190}, {"referenceID": 12, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 205, "endOffset": 209}, {"referenceID": 13, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 223, "endOffset": 233}, {"referenceID": 14, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 223, "endOffset": 233}, {"referenceID": 15, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 223, "endOffset": 233}, {"referenceID": 16, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 243, "endOffset": 247}, {"referenceID": 17, "context": "Recently, growing attention has been devoted to style, not only in terms of fonts [8,9,10], but in perceptual shape similarity for architecture and rigid objects [11], computer graphics [12], cursive text [13], photographs [14,15,16], artwork [17], and music [18].", "startOffset": 259, "endOffset": 263}, {"referenceID": 18, "context": "For example, the character \u2019Q\u2019 sometimes has a descender [19] that extends below the font\u2019s baseline; this will appear raised up in the training examples (see Figure 2).", "startOffset": 57, "endOffset": 61}, {"referenceID": 19, "context": "Building on the successes of deep neural networks for image recognition tasks (see [20] for a recent summary with ImageNet), we explore a variety of neural network architectures for this task.", "startOffset": 83, "endOffset": 87}, {"referenceID": 20, "context": "creating individual \u2019towers\u2019 for each of the 5 characters (see [21,22,23,24] for a review of column/tower architectures).", "startOffset": 63, "endOffset": 76}, {"referenceID": 21, "context": "creating individual \u2019towers\u2019 for each of the 5 characters (see [21,22,23,24] for a review of column/tower architectures).", "startOffset": 63, "endOffset": 76}, {"referenceID": 22, "context": "creating individual \u2019towers\u2019 for each of the 5 characters (see [21,22,23,24] for a review of column/tower architectures).", "startOffset": 63, "endOffset": 76}, {"referenceID": 23, "context": "creating individual \u2019towers\u2019 for each of the 5 characters (see [21,22,23,24] for a review of column/tower architectures).", "startOffset": 63, "endOffset": 76}, {"referenceID": 24, "context": "Unlike in general object detection tasks in which deep neural networks are able to exploit the property that images can be thoughts of as compositional hierarchies [25], such deep hierarchies may not be present for this task.", "startOffset": 164, "endOffset": 168}, {"referenceID": 25, "context": "RELU or Logistic? A variety of activation functions were attempted, including exclusively logistic activations throughout the network (recall that the networks were not as deep as is often used in image-recognition tasks, a condition often cited for using Rectified Linear (RELU) activations [26]).", "startOffset": 292, "endOffset": 296}, {"referenceID": 26, "context": "Despite the similar performance of the 7 networks, enough variation in the outputs exists to use them as an ensemble [27].", "startOffset": 117, "endOffset": 121}, {"referenceID": 27, "context": "This is a form of transfer learning with a strong basis in multi-task learning [28,29,30,31].", "startOffset": 79, "endOffset": 92}, {"referenceID": 28, "context": "This is a form of transfer learning with a strong basis in multi-task learning [28,29,30,31].", "startOffset": 79, "endOffset": 92}, {"referenceID": 29, "context": "This is a form of transfer learning with a strong basis in multi-task learning [28,29,30,31].", "startOffset": 79, "endOffset": 92}, {"referenceID": 30, "context": "This is a form of transfer learning with a strong basis in multi-task learning [28,29,30,31].", "startOffset": 79, "endOffset": 92}, {"referenceID": 31, "context": "Similar architectures have been used for superresolution and image deconvolution, often with weight sharing [32,33].", "startOffset": 108, "endOffset": 115}, {"referenceID": 32, "context": "Similar architectures have been used for superresolution and image deconvolution, often with weight sharing [32,33].", "startOffset": 108, "endOffset": 115}, {"referenceID": 33, "context": "Numerous experiments, both with and without batch normalization [34], were conducted \u2013 no consistent difference in final error was observed.", "startOffset": 64, "endOffset": 68}, {"referenceID": 34, "context": "Novel variants of this method, using pairs of generator/discriminator networks have been independently proposed in [35], which is based on the architectures of generative-adversarial models [36,37].", "startOffset": 115, "endOffset": 119}, {"referenceID": 35, "context": "Novel variants of this method, using pairs of generator/discriminator networks have been independently proposed in [35], which is based on the architectures of generative-adversarial models [36,37].", "startOffset": 190, "endOffset": 197}, {"referenceID": 36, "context": "Novel variants of this method, using pairs of generator/discriminator networks have been independently proposed in [35], which is based on the architectures of generative-adversarial models [36,37].", "startOffset": 190, "endOffset": 197}, {"referenceID": 37, "context": "This has recently been proposed to create natural images as well as dream like images \u201cDeep Dreams\u201d [38,17].", "startOffset": 100, "endOffset": 107}, {"referenceID": 16, "context": "This has recently been proposed to create natural images as well as dream like images \u201cDeep Dreams\u201d [38,17].", "startOffset": 100, "endOffset": 107}, {"referenceID": 8, "context": "Recent preprints [9,35] describe concurrent explorations of similar and related problems with much more complex architectures that yield comparably promising results.", "startOffset": 17, "endOffset": 23}, {"referenceID": 34, "context": "Recent preprints [9,35] describe concurrent explorations of similar and related problems with much more complex architectures that yield comparably promising results.", "startOffset": 17, "endOffset": 23}, {"referenceID": 35, "context": "example, the evaluation mechanisms used in this study are akin to Generative Adversarial Nets (GAN) [36,39,37] in which a synthetic-vs.", "startOffset": 100, "endOffset": 110}, {"referenceID": 38, "context": "example, the evaluation mechanisms used in this study are akin to Generative Adversarial Nets (GAN) [36,39,37] in which a synthetic-vs.", "startOffset": 100, "endOffset": 110}, {"referenceID": 36, "context": "example, the evaluation mechanisms used in this study are akin to Generative Adversarial Nets (GAN) [36,39,37] in which a synthetic-vs.", "startOffset": 100, "endOffset": 110}, {"referenceID": 39, "context": "Similar programmatic learning in which LSTMs compose simple programs and sequences of music have been recently attempted [40,41,42].", "startOffset": 121, "endOffset": 131}, {"referenceID": 40, "context": "Similar programmatic learning in which LSTMs compose simple programs and sequences of music have been recently attempted [40,41,42].", "startOffset": 121, "endOffset": 131}, {"referenceID": 41, "context": "Similar programmatic learning in which LSTMs compose simple programs and sequences of music have been recently attempted [40,41,42].", "startOffset": 121, "endOffset": 131}], "year": 2016, "abstractText": "Typography is a ubiquitous art form that affects our understanding, perception, and trust in what we read. Thousands of different font-faces have been created with enormous variations in the characters. In this paper, we learn the style of a font by analyzing a small subset of only four letters. From these four letters, we learn two tasks. The first is a discrimination task: given the four letters and a new candidate letter, does the new letter belong to the same font? Second, given the four basis letters, can we generate all of the other letters with the same characteristics as those in the basis set? We use deep neural networks to address both tasks, quantitatively and qualitatively measure the results in a variety of novel manners, and present a thorough investigation of the weaknesses and strengths of the approach.", "creator": "LaTeX with hyperref package"}}}