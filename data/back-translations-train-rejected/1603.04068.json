{"id": "1603.04068", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Mar-2016", "title": "A Signaling Game Approach to Databases Querying and Interaction", "abstract": "As most database users cannot precisely express their information needs, it is challenging for database querying and exploration interfaces to understand them. We propose a novel formal framework for representing and understanding information needs in database querying and exploration. Our framework considers querying as a collaboration between the user and the database system to establish a mutual language for representing information needs. We formalize this collaboration as a signaling game, where each mutual language is an equilibrium for the game. A query interface is more effective if it establishes a less ambiguous mutual language faster. We discuss some equilibria, strategies, and the convergence in this game. In particular, we propose a reinforcement learning mechanism and analyze it within our framework. We prove that this adaptation mechanism for the query interface improves the effectiveness of answering queries stochastically speaking, and converges almost surely. Most importantly, we show that the proposed learning rule is robust to the choice of the metric/reward by the database.", "histories": [["v1", "Sun, 13 Mar 2016 19:28:22 GMT  (53kb)", "https://arxiv.org/abs/1603.04068v1", "10 page"], ["v2", "Wed, 22 Jun 2016 14:18:52 GMT  (891kb)", "http://arxiv.org/abs/1603.04068v2", "14 pages"], ["v3", "Sat, 27 May 2017 22:04:56 GMT  (69kb)", "http://arxiv.org/abs/1603.04068v3", "17 pages"], ["v4", "Thu, 22 Jun 2017 17:04:16 GMT  (69kb)", "http://arxiv.org/abs/1603.04068v4", "17 pages"]], "COMMENTS": "10 page", "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["ben mccamish", "arash termehchy", "behrouz touri"], "accepted": false, "id": "1603.04068"}, "pdf": {"name": "1603.04068.pdf", "metadata": {"source": "CRF", "title": "A Signaling Game Approach to Databases Querying and Interaction", "authors": ["Ben McCamish", "Arash Termehchy", "Behrouz Touri"], "emails": ["mccamis@oregonstate.edu", "termehca@oregonstate.edu", "touri@colorado.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.04 068v 4 [cs.D B] 22 June 2017Since most users cannot precisely express their information needs in the form of queries, it is difficult for database management systems to understand the true information needs behind users \"queries. Query interfaces use users\" feedback on the answers returned to a query to improve their understanding of the true information needs behind the query. Nevertheless, users generally assume that a user follows a fixed strategy to express their information needs, i.e., the probability that a user submits a query to express a specific information need remains unchanged for a potentially long period of time. Nevertheless, users can learn from their interactions with the database system and gradually choose more precise queries to express their intentions. In this essay, we introduce a novel formal framework that represents database queries as cooperation between two active and potential rational agents of the user interface to improve the equality of information."}, {"heading": "1. INTRODUCTION", "text": "This year, it is only a matter of time before there is an agreement, until there is an agreement."}, {"heading": "2. FORMAL FRAMEWORK", "text": "After submitting each query, the user can revise his strategy and select another query to express his intention, hoping that the new query will give him more relevant answers. The user can also inform the database system to what extent the returned answers fulfill the intention behind the query, using explicit or implicit feedback, such as click information [29]. The database system can update its interpretation of the query according to the user's feedback. Intuitively, this interaction can be modelled as a game between two agents with identical interests, in which the agents communicate about the transmission of queries, results and feedback about the results. In each interpretation, both agents receive a reward according to the degree to which the result behind the query receives a reward amount."}, {"heading": "2.1 The Data Interaction Game", "text": "Next, we describe the components and structure of the data interaction game for relational databases. A schema S is a series of relation symbols. Each relation symbol R has a corresponding similarity. Let dom be an infinite number of constants. A database instance that I use over S with each n-ary relation symbol R-S is a finite subset of IR of n.2.1.1 IntentAn intention represents an information need sought by the user. Current user-friendly query interfaces over databases usually assume that each intention is a query in a sufficiently expressive query language in the domain of interest, e.g. SQL, about the underlying database instance [14, 35, 21]. Our framework and results are orthogonal to the language that accurately describes the intentions of the users. In our examples, we consider the intention to be language conjunctive queries [1]. Table 1 illustrates a database instance that contains ranking, name, university schematic information."}, {"heading": "2.2 Open Problems", "text": "Traditionally, usable query interfaces, such as keyword interfaces, aim to improve user satisfaction by optimizing some effectiveness metrics, such as p @ k, for their input queries. [14] However, in our game theory formalization, the goal of the DBMS should be to guide the interaction to a desired and stable state, that is, a balance in which, broadly speaking, both players have no motivation to change their strategies, and both receive the highest possible reward. There are three important questions related to this game. \u2022 What are the desired and undesirable balances of the game? It is important to identify the game's non-optimal balances, since the interaction in these balances can stabilize. \u2022 What reasonable assumptions about the behavior and degree of rationality of the user? \u2022 Given the answers to the two previous questions, which strategy adjustment mechanisms (the DS) should lead to both using the BMS and BMS to achieve an equal balance."}, {"heading": "3. EQUILIBRIUM ANALYSIS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Fixed User Strategy", "text": "In some cases, it is reasonable to assume that the user's strategy is set. Therefore, the game will reach a desirable state in which the DBMS adjusts a strategy that clearly maximizes the expected response. Let a strategy profile be a pair of users and DBMS strategies. Let a strategy profile be the best response result. Let a strategy profile be the best user and DBMS strategies.DEFINITION 3.1 Given a strategy profile (U, D), D is a best response to U w.r.t. Effectiveness as an answer r if we ur (U, D) \u2265 ur ur ur ur ur (U, D) for all database strategiesD \u2032.A DBMS strategy D is a strict response to U if the inequality in the 3.1 definition becomes strict for all D."}, {"heading": "3.2 Nash Equilibrium", "text": "In this section and Section 3.3, we analyze the balance of the game, in which both users and DBMS can change their strategies."}, {"heading": "3.3 Strict Nash Equilibrium", "text": "A strict Nash balance is a strategy profile in which the DBMS and the user achieve worse results by unilaterally changing their equilibrium strategies.DEFINITION 3.9. A strategy profile (U, D) is a strict Nash balance.r.t. Measuring effectiveness r when we apply strict (U, D) > ur (U, D) for all DBMS strategies (U, D) > ur (U, D) > ur (U, D) > ur for all user strategies U \u2032 6 = U.EXAMPLE 3.3. Let's consider the intentions, queries, strategy profile and database instance in Tables 4 (a), 4 (b), 5 and 1. The strategy profile is a strict Nash balance w.r.t precision, which we do not exactly intend in Example 3.2."}, {"heading": "3.4 Number of Equilibria", "text": "A natural question is how many (strict) Nash balances exist in a game. Theorem 3.10 guarantees that both user and DBMS strategies are pure in a strict Nash balance. However, given that the objectives and queries in a game are finite, there are endless strict Nash balances in the game. LEMMA 3.11. If a game has a non-strict Nash balance, we will show that when the objectives and queries in a game are finite, the game has endless Nash balances. LEMMA 3.11. If a game has a non-strict Nash balance, then there are infinite Nash balances. \u2212 PROOF. The result is derived from the fact that the ash (1) is a two-dimensional form of U and D, i.e. it is alinear from D when U-U."}, {"heading": "3.5 Efficiency", "text": "In this section we discuss the efficiency of different balances. We refer to the value of the benefit (payout) in formula (1) to a strategy profile for the efficiency of the strategy. Therefore, of course, the most efficient strategy profile is what maximizes the strategies (1). We point to a balance with maximum efficiency as an efficient balance. So far, we have discussed two types of balances, but that balances cannot be an efficient balance is unlikely that each player will deviate from his current strategy. In some cases, it may be possible to enter a state of balances in which neither player has an incentive to deviate, but that balances cannot be an efficient balance. The strategy profile in Table 3 (b) provides the highest payout for the user and DBMS given the ingredients and queries in Tables 2 (a) and 2 (b) via the database in Table 1."}, {"heading": "4. USER ADAPTATIONMECHANISM", "text": "Many laboratory studies with human subjects conclude that human learning can be modelled using reinforcement learning models [56, 47]. However, the method of reinforcement learning used by a person may vary depending on their abilities and the task at hand. We have conducted an empirical study using a real-world query protocol to find out which reinforcement learning models best explain the learning mechanism by which users adapt their strategies during interaction with a data management system."}, {"heading": "4.1 Query Workload", "text": "For our empirical study, we used a partial sample of a Yahoo! query log [63]. The Yahoo! query log consists of queries sent to a Yahoo! search engine over a period of July 2010. Each record in the query log consists of a timestamp, a user cookie, a query submitted, the 10 results displayed to the user, and the positions of user clicks. All record logs are anonymized so that every time stamp, query, and result returned are stored as a unique identifier. Table 8 illustrates an example of what the log record looks like. Note: For the result column, there are 10 results returned. Accompanying the query log is a series of relevance assessments for each query and each result pair. The relevance assessment values determine the satisfaction of the user with this query, with the most relevant score showing a 2.4 out of a possible score of 0.4 indicating that the result is not relevant at all."}, {"heading": "4.2 Reinforcement Learning Methods", "text": "These models are mainly based on 1) the degree to which the user takes previous interactions into account when updating his current strategy; other models allow the user to forget older interactions; these methods also differ in how they use the value of the reward to update the user's strategy; some models reinforce a behavior, for example, by using a specific statement of intent to convey an intention after a successful attempt, regardless of the amount of the reward received; others use the value of the reward received to control the rate at which a behavior is amplified; in this study, we used the value of the NDCG as a reward in each interaction."}, {"heading": "4.3 Training and Testing", "text": "Some models, such as the cross-model, have some parameters that need to be trained. We used 5,000 sets of data in the query's workload and found the optimal values for these parameters based on a grid search and the sum of square errors. Each strategy was initialized with a uniform distribution of probabilities, so that all queries are likely to be used for a specific purpose in the original strategy. After we had the parameters estimated for each model, we ran each model over 300,000 sets of data that follow the initial 5,000 rows in the query log to calculate a user strategy. All models used the same queries and results. During the training phase, a total of 3,456 queries, 3,088 queries and 253,952 users were covered, meaning that queries and intentions were frequently reused and there were many recurring users over time. We compared the NDCG value for each interaction using the available relevance assessment values, we did not observe the CYOY Interest Strategies or any of Interest!"}, {"heading": "4.4 Empirical Results", "text": "The results of the tests we conducted are as interesting as the estimated parameters. A lower mean square distance implies that the model more accurately represents the learning method of the users. Roth and Erev's and Erev's modified models both bring out the best of all the models tested. Because Roth and Erev's use modified models, this model does not forget the results of the previous interactions with the system. Therefore, it is more similar to the original Roth and Erev's model. Because Roth and Erev's models update the user's strategies by using the information of the previous strategies and interactions, users use their previous strategies and the results of their previous interactions with the system when selecting a query to express their current intention. This result also shows that the value of the reward received should be taken into account when using the strategies of the previous strategies and interactions that users use."}, {"heading": "5. ADAPTATIONMECHANISMSFORDBMS", "text": "In many relevant applications, user learning takes place in a much slower timeframe than DBMS learning, so one can assume that the user's strategy is set in relation to the DBMS adaptation timeframe. Therefore, in this section, we first consider the case where the user does not adapt to the DBMS strategy, and then consider the case where the user's strategy adapts to the DBMS strategy, but perhaps on a slower timeframe. In dealing with the game presented in the previous sections, many questions arise: i. How can a DBMS learn or adapt to a user's strategy? ii. In mathematical terms, a given learning rule is effective? iii. What would be the limiting behavior of a given learning rule? Here, we address the first and second questions. Dealing with the third question extends far beyond the limits of this paper."}, {"heading": "5.1 Reinforcement Learning for an Arbitrary Similarity Measure", "text": "In fact, most of them are able to play by the rules that they need for their work, and they are not able to play by the rules that they need for their work."}, {"heading": "5.2 Analysis of the Learning Rule", "text": "In this section we provide an analysis of the amplification mechanisms and will show that the adjustment rule leads to an improvement in the effectiveness of the interaction (1). (1) Note: Since the user can only use one tuple in the result, it can be assumed without the loss of the general public that the cardinality of list k (15) is defined for an effectiveness measurement r as in Section 5. (1) We remember that a random process {X) is a submartingale [19] if it is absolutely integral (i.e. E (t). (t) <) < (X + 1)."}, {"heading": "5.3 User Adaptation", "text": "In this case, we assume that the user also adapts to the strategy of the DBMS. If the user submits a query q = \u00b7 \u00b7 reward q and the DBMS delivers a result that fully fulfils the intention behind the query e, it is relatively more likely that the user uses the query q to express e again during his interaction with the DBMS. In fact, researchers have observed that users exhibit stronger learning behavior when interacting with a DBMS over a period of time [11]. In particular, the authors in [11] have shown that some user groups have learned to formulate queries with a model similar to Roth-Erev. We define the similarity measurement as follows: For simplicity, we assume that m = o and the following similarity measurement: ri =, 0 otherwise. In this case, we assume that the user adapts the strategy; BMK;"}, {"heading": "5.4 Analysis of User and DBMS Adaptation", "text": "In this section, we provide an analysis of the reinforcement mechanism and will show that, statistically speaking, our proposed rule of adjustment for DBMS, even if the user adapts, leads to an improvement in the effectiveness of the interaction. (1) Let t = tk for some k (n) N (U, D (t) N (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O (n) O, O (n) O (O, O n (O, O n, O n (O, O n, O, O n (O n, O n, O n (O, O n, O n, O n (O n, O n, O, O n (n, O n, O n, O n (n, O n, O n, O n, O n, O n (n, O n, O n, O n, O n (n, O n, O n, O n, O n, O n (n), O n (n, O n, O n, O n, O n (n), O n (n, O n, O n), O n (n, O n, O n (n), O n (n), O n (n, O n, O n, O n, O n (n), O n (n, O n, O n (n), O n (n, O n), O n (n, O n, O n (n), O n (n, O n, O n (n), O n (n, O n, O n (n, O n, O n), O n, O n, O n (n, O n), O n, O n (n (n), O n, O n (n, O n,"}, {"heading": "5.5 Limiting Equilibria", "text": "One of the most important immediate directions that need to be studied is to examine the limiting behavior of the adaptation mechanism and to identify its characteristics. Such questions are partially answered in [32] in the case that both actors in a single game synchronously and identically adjust their strategy. In this case, only certain equilibriums can arise in the limitation. Ultimately, either an object that intends to match many signals in our model can be associated with queries in our model (synonyms) or with many intentions of a query (polysemy), but two intentions are not associated with two queries (see Theorem 2.3 in [32] for more details). The authors in [32] follow a traditional language game approach as in Section 6. Our immediate future research guidelines for investigating the adaptation mechanism are to examine the convergence properties of the proposed amplification algorithm in sections 5.1 and 5.3."}, {"heading": "6. RELATED WORK", "text": "It is indeed the case that we are able to go in search of a solution that is capable of finding a solution that meets the needs of the people and that meets the needs of the people."}, {"heading": "7. CONCLUSION & FUTUREWORK", "text": "We modeled the interaction between the user and the DBMS as a signal game in which players begin with different mappings between queries and desired results and want to achieve mutual understanding; we formally analyzed the different balances of this game; we also showed that some balances may not have optimal benefits; we proposed an adaptation mechanism for the DBMS to learn the user's query strategy; and we demonstrated that this mechanism increases the expected benefits for both the user and the DBMS on average and almost certainly converges; this case was expanded when the user changes his strategy; and we provided an adaptation mechanism for the DBMS that almost certainly converges. Interactive query of databases has recently received a lot of attention [34]. We believe that our proposed framework will provide a basis for in-depth exploration of some interesting and important issues; in particular, we plan to consider the characteristics of Nash and efficient Nash balances, as we explore the balances in different ways."}, {"heading": "8. REFERENCES", "text": "[1] S. Abiteboul, R. Hull, and V. Vianu. Foundations of Databases GMao 1973: The Logical Level. Addison-Wesley, 1994. [2] A. Abouzied, D. Angluin, C. H. Papadimitriou, J. M. Hellerstein, and A. Silberschatz. Learning and verifying quantified boolean queries by example. [3] I. Abraham, D. Dolev, R. Gonen, and J. Halpern. Distributed computing meets game theory: robust mechanisms for rational secret sharing, and multi-party computation. In PODC, 2006. [4] S. Agrawal, S. Chaudhuri."}], "references": [{"title": "Foundations of Databases: The Logical Level", "author": ["S. Abiteboul", "R. Hull", "V. Vianu"], "venue": "Addison-Wesley,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Learning and verifying quantified boolean queries by example", "author": ["A. Abouzied", "D. Angluin", "C.H. Papadimitriou", "J.M. Hellerstein", "A. Silberschatz"], "venue": "PODS,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed computing meets game theory: robust mechanisms for rational secret sharing and multiparty computation", "author": ["I. Abraham", "D. Dolev", "R. Gonen", "J. Halpern"], "venue": "PODC,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Automated ranking of database query results", "author": ["S. Agrawal", "S. Chaudhuri", "G. Das", "A. Gionis"], "venue": "CIDR,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Finite-time analysis of the multiarmed bandit problem.Machine learning", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Shared lexicon for distributed annotations on the Web", "author": ["P. Avesani", "M. Cova"], "venue": "InWWW,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "The role of forgetting in the evolution and learning of language", "author": ["J.A. Barrett", "K. Zollman"], "venue": "Journal of Experimental and Theoretical Artificial Intelligence, 21(4):293\u2013309,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning join queries from user examples", "author": ["A. Bonifati", "R. Ciucanu", "S. Staworko"], "venue": "TODS, 40(4),", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "A stochastic model with  applications to learning", "author": ["R.R. Bush", "F. Mosteller"], "venue": "The Annals of Mathematical Statistics, pages 559\u2013585,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1953}, {"title": "Reinforcement learning in information searching", "author": ["Y. Cen", "L. Gan", "C. Bai"], "venue": "Information Research: An International Electronic Journal, 18(1):n1,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic information retrieval approach for ranking of database query results", "author": ["S. Chaudhuri", "G. Das", "V. Hristidis", "G. Weikum"], "venue": "TODS, 31(3),", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Keyword search on structured and semi-structured data", "author": ["Y. Chen", "W. Wang", "Z. Liu", "X. Lin"], "venue": "SIGMOD,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Keyword search on structured and semi-structured data", "author": ["Y. Chen", "W. Wang", "Z. Liu", "X. Lin"], "venue": "SIGMOD,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Signaling games and stable equilibria", "author": ["I. Cho", "D. Kreps"], "venue": "Quarterly Journal of Economics, 102,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1987}, {"title": "A stochastic learning model of economic behavior", "author": ["J.G. Cross"], "venue": "The Quarterly Journal of Economics, 87(2):239\u2013266,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1973}, {"title": "Explore-by-example: An automatic query steering framework for interactive data exploration", "author": ["K. Dimitriadou", "O. Papaemmanouil", "Y. Diao"], "venue": "SIGMOD,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "The evolution of functionally referential meaning in a structured world", "author": ["M.C. Donaldson", "M. Lachmannb", "C.T. Bergstroma"], "venue": "Journal of Mathematical Biology, 246,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Probability: theory and examples", "author": ["R. Durrett"], "venue": "Cambridge university press,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "On the Need for Low Rationality, Gognitive Game Theory: Reinforcement Learning in Experimental Games with Unique", "author": ["I. Erev", "A.E. Roth"], "venue": "Mixed Strategy Equilibria", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Understanding Queries in a Search Database System", "author": ["R. Fagin", "B. Kimelfeld", "Y. Li", "S. Raghavan", "S. Vaithyanathan"], "venue": "PODS,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Towards a theory of search queries", "author": ["G.H.L. Fletcher", "J.V.D. Bussche", "D.V. Gucht", "S. Vansummeren"], "venue": "ICDT,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Dynamics in atomic signaling games", "author": ["M.J. Fox", "B. Touri", "J.S. Shamma"], "venue": "Journal of theoretical biology, 376,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "The Theory of Learning in Games", "author": ["D. Fudenberg", "D. Levine"], "venue": "MIT Press,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "A probabilistic relational algebra for the integration of information retrieval and database systems", "author": ["N. Fuhr", "T. Rolleke"], "venue": "TOIS, 15,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning toms: Towards non-myopic equilibria", "author": ["A. Ghosh", "S. Sen"], "venue": "AAAI,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "Imperfect information games and generalized planning", "author": ["G.D. Giacomo", "A.D. Stasio", "A. Murano", "S. Rubin"], "venue": "In IJCAI,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Robbers, marshals, and guards: Game theoretic and logical characterizations of hypertree width", "author": ["G. Gottlob", "N. Leone", "F. Scarcello"], "venue": "PODS,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "Eye-tracking analysis of user behavior in www search", "author": ["L.A. Granka", "T. Joachims", "G. Gay"], "venue": "SIGIR, ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2004}, {"title": "Balancing exploration and exploitation in listwise and pairwise online learning to rank for information retrieval", "author": ["K. Hofmann", "S. Whiteson", "M. de Rijke"], "venue": "Information Retrieval,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Efficient IR-Style Keyword Search over Relational Databases", "author": ["V. Hristidis", "L. Gravano", "Y. Papakonstantinou"], "venue": "VLDB", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2003}, {"title": "Reinforcement learning in signaling game", "author": ["Y. Hu", "B. Skyrms", "P. Tarr\u00e8s"], "venue": "arXiv preprint arXiv:1103.5818,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "User see, user point: Gaze and cursor alignment in web search", "author": ["J. Huang", "R. White", "G. Buscher"], "venue": "CHI,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2012}, {"title": "Overview of data exploration techniques", "author": ["S. Idreos", "O. Papaemmanouil", "S. Chaudhuri"], "venue": "SIGMOD,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Making database systems usable", "author": ["H.V. Jagadish", "A. Chapman", "A. Elkiss", "M. Jayapandian", "Y. Li", "A. Nandi", "C. Yu"], "venue": "SIGMOD,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2007}, {"title": "Snipsuggest: Context-aware autocompletion for sql", "author": ["N. Khoussainova", "Y. Kwon", "M. Balazinska", "D. Suciu"], "venue": "PVLDB, 4(1),", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2010}, {"title": "Finding and Approximating Top-k Answers in Keyword Proximity Search", "author": ["B. Kimelfeld", "Y. Sagiv"], "venue": "PODS,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Generating and solving imperfect information games", "author": ["D. Koller", "A. Pfeffer"], "venue": "IJCAI,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1995}, {"title": "Convention", "author": ["D. Lewis"], "venue": "Cambridge: Harvard University Press,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1969}, {"title": "Query from examples: An iterative, data-driven approach to query construction", "author": ["H. Li", "C.-Y. Chan", "D. Maier"], "venue": "PVLDB, 8(13),", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2015}, {"title": "Win-win search: Dual-agent stochastic game in session search", "author": ["J. Luo", "S. Zhang", "H. Yang"], "venue": "SIGIR,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}, {"title": "SPARK: Top-k Keyword Query in Relational Databases", "author": ["Y. Luo", "X. Lin", "W. Wang", "X. Zhou"], "venue": "SIGMOD", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2007}, {"title": "Modeling collaboration in academia: A game theoretic approach", "author": ["Q. Ma", "S. Muthukrishnan", "B. Thompson", "G. Cormode"], "venue": "BigScholar,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Toward logical data independence: A relational query language without relations", "author": ["D. Maier", "D. Rozenshtein", "S. Salveter", "J. Stein", "D.S. Warren"], "venue": "SIGMOD,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1982}, {"title": "An Introduction to Information Retrieval", "author": ["C. Manning", "P. Raghavan", "H. Schutze"], "venue": "Cambridge University Press,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2008}, {"title": "Guided interaction: Rethinking the query-result paradigm", "author": ["A. Nandi", "H.V. Jagadish"], "venue": "PVLDB, 102,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "The neuroscience of reinforcement learning", "author": ["Y. Niv"], "venue": "ICML,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2009}, {"title": "Reinforcement learning in the brain", "author": ["Y. Niv"], "venue": "The Journal of Mathematical Psychology, 53(3):139\u2013154,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "The evolution of  language", "author": ["M.A. Nowak", "D.C. Krakauer"], "venue": "PNAS, 96(14),", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1999}, {"title": "A convergence theorem for non negative almost supermartingales and some applications", "author": ["H. Robbins", "D. Siegmund"], "venue": "Herbert Robbins Selected Papers. Springer,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1985}, {"title": "Learning in extensive-form games: Experimental data and simple dynamic models in the intermediate term", "author": ["A.E. Roth", "I. Erev"], "venue": "Games and economic behavior, 8(1):164\u2013212,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1995}, {"title": "Synthesizing view definitions from data", "author": ["A.D. Sarmaa", "A. Parameswaran", "H. Garcia-Molina", "J. Widom"], "venue": "ICDT,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2010}, {"title": "Games for active XML revisited", "author": ["M. Schuster", "T. Schwentick"], "venue": "ICDT,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2015}, {"title": "Some topics in two-person games", "author": ["L.S. Shapley"], "venue": "Advances in game theory,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1964}, {"title": "Computer science and game theory", "author": ["Y. Shoham"], "venue": "Commun. ACM, 51(8),", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2008}, {"title": "Reinforcement learning and human behavior", "author": ["H. Shteingart", "Y. Loewenstein"], "venue": "Current Opinion in Neurobiology, 25:93\u201398, 04/2014", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2014}, {"title": "Game Theory: An Introduction", "author": ["S. Tadelis"], "venue": "Princeton University Press,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2013}, {"title": "A signaling game approach to database querying and interaction", "author": ["A. Termehchy", "B. Touri"], "venue": "ICTIR,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2015}, {"title": "Language evolution in a noisy environment", "author": ["B. Touri", "C. Langbort"], "venue": "(ACC). IEEE,", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2013}, {"title": "Query by output", "author": ["Q. Tran", "C. Chan", "S. Parthasarathy"], "venue": "SIGMOD,", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2009}, {"title": "Nash equilibria for an evolutionary language game", "author": ["P. Trapa", "M. Nowak"], "venue": "Journal of Mathematical Biology, 41,", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2000}, {"title": "Gathering additional feedback on search results by multi-armed bandits with respect to production ranking", "author": ["A. Vorobev", "D. Lefortier", "G. Gusev", "P. Serdyukov"], "venue": "InWWW,", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2015}, {"title": "Strategic learning and its limits", "author": ["H.P. Young"], "venue": "OUP Oxford,", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2004}, {"title": "The k-armed dueling bandits problem", "author": ["Y. Yue", "J. Broder", "R. Kleinberg", "T. Joachims"], "venue": "J. Comput. Syst. Sci., 78(5),", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2012}, {"title": "Towards a game-theoretic framework for information retrieval", "author": ["C. Zhai"], "venue": "SIGIR,", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2015}, {"title": "Query relaxation using malleable schemas", "author": ["X. Zhou", "J. Gaugaz", "W.-T. Balke", "W. Nejdl"], "venue": "SIGMOD,", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 33, "context": "Most users do not know the structure and/or content of databases and cannot precisely express their queries [35, 13, 21, 34].", "startOffset": 108, "endOffset": 124}, {"referenceID": 11, "context": "Most users do not know the structure and/or content of databases and cannot precisely express their queries [35, 13, 21, 34].", "startOffset": 108, "endOffset": 124}, {"referenceID": 19, "context": "Most users do not know the structure and/or content of databases and cannot precisely express their queries [35, 13, 21, 34].", "startOffset": 108, "endOffset": 124}, {"referenceID": 32, "context": "Most users do not know the structure and/or content of databases and cannot precisely express their queries [35, 13, 21, 34].", "startOffset": 108, "endOffset": 124}, {"referenceID": 42, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 32, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 11, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 44, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 33, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 23, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 20, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 35, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 19, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 1, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 7, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 50, "context": "Database researchers have proposed models, methods and systems to help users specify their queries more precisely and DBMS understand users\u2019 intents more accurately [44, 34, 13, 46, 35, 25, 8, 22, 37, 21, 2, 9, 52].", "startOffset": 165, "endOffset": 214}, {"referenceID": 38, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 151, "endOffset": 170}, {"referenceID": 15, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 151, "endOffset": 170}, {"referenceID": 7, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 151, "endOffset": 170}, {"referenceID": 50, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 151, "endOffset": 170}, {"referenceID": 58, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 151, "endOffset": 170}, {"referenceID": 1, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 198, "endOffset": 201}, {"referenceID": 34, "context": "Given a user\u2019s information need e, the DBMS estimates e by various methods including showing potential results to the user and collecting her feedback [40, 17, 9, 52, 60], asking questions from her [2], or suggesting potential queries to her [36].", "startOffset": 242, "endOffset": 246}, {"referenceID": 28, "context": "Types of the user\u2019s feedbackmay include clicking on the relevant answers [30, 65], the amount of time the user spends on reading the results [29], or user\u2019s eye movements [33].", "startOffset": 73, "endOffset": 81}, {"referenceID": 62, "context": "Types of the user\u2019s feedbackmay include clicking on the relevant answers [30, 65], the amount of time the user spends on reading the results [29], or user\u2019s eye movements [33].", "startOffset": 73, "endOffset": 81}, {"referenceID": 27, "context": "Types of the user\u2019s feedbackmay include clicking on the relevant answers [30, 65], the amount of time the user spends on reading the results [29], or user\u2019s eye movements [33].", "startOffset": 141, "endOffset": 145}, {"referenceID": 31, "context": "Types of the user\u2019s feedbackmay include clicking on the relevant answers [30, 65], the amount of time the user spends on reading the results [29], or user\u2019s eye movements [33].", "startOffset": 171, "endOffset": 175}, {"referenceID": 22, "context": "Furthermore, it has been shown that certain learning strategies that may be useful in a static setting do not converge to a desired outcome in a setting where both agents modify their strategies [24].", "startOffset": 195, "endOffset": 199}, {"referenceID": 13, "context": "\u2022 We model the long term interaction between the user and DBMS as a particular type of game called a signaling game in Section 2 [15, 49].", "startOffset": 129, "endOffset": 137}, {"referenceID": 47, "context": "\u2022 We model the long term interaction between the user and DBMS as a particular type of game called a signaling game in Section 2 [15, 49].", "startOffset": 129, "endOffset": 137}, {"referenceID": 49, "context": "\u2022 Using extensive empirical studies over a real-world query workload, we show that users\u2019 learning can be accurately modeled by Roth and Erv\u2019s reinforcement learning algorithm [51] in Section 4.", "startOffset": 176, "endOffset": 180}, {"referenceID": 27, "context": ", click-through information [29].", "startOffset": 28, "endOffset": 32}, {"referenceID": 12, "context": ", SQL, over the underlying database instance [14, 35, 21].", "startOffset": 45, "endOffset": 57}, {"referenceID": 33, "context": ", SQL, over the underlying database instance [14, 35, 21].", "startOffset": 45, "endOffset": 57}, {"referenceID": 19, "context": ", SQL, over the underlying database instance [14, 35, 21].", "startOffset": 45, "endOffset": 57}, {"referenceID": 0, "context": "In our examples, we consider the intent language to be conjunctive queries [1].", "startOffset": 75, "endOffset": 78}, {"referenceID": 33, "context": "Thus, they prefer to articulate their intents in languages that are easy-touse and relatively less complex, such as keyword query language [35, 14, 21].", "startOffset": 139, "endOffset": 151}, {"referenceID": 12, "context": "Thus, they prefer to articulate their intents in languages that are easy-touse and relatively less complex, such as keyword query language [35, 14, 21].", "startOffset": 139, "endOffset": 151}, {"referenceID": 19, "context": "Thus, they prefer to articulate their intents in languages that are easy-touse and relatively less complex, such as keyword query language [35, 14, 21].", "startOffset": 139, "endOffset": 151}, {"referenceID": 10, "context": "Nevertheless, because they may not know precisely the content and structure of the data, their submitted queries may not always be the same as their intents [12, 36].", "startOffset": 157, "endOffset": 165}, {"referenceID": 34, "context": "Nevertheless, because they may not know precisely the content and structure of the data, their submitted queries may not always be the same as their intents [12, 36].", "startOffset": 157, "endOffset": 165}, {"referenceID": 19, "context": "The DBMS usually selects a query language for the interpreted intents according to the information in the domain of interest [21, 31, 14].", "startOffset": 125, "endOffset": 137}, {"referenceID": 29, "context": "The DBMS usually selects a query language for the interpreted intents according to the information in the domain of interest [21, 31, 14].", "startOffset": 125, "endOffset": 137}, {"referenceID": 12, "context": "The DBMS usually selects a query language for the interpreted intents according to the information in the domain of interest [21, 31, 14].", "startOffset": 125, "endOffset": 137}, {"referenceID": 29, "context": "For example, some keyword query interfaces over relational databases interpret keyword queries as Select-Project-Join SQL queries with only conjunctions in the where clause [31, 42].", "startOffset": 173, "endOffset": 181}, {"referenceID": 40, "context": "For example, some keyword query interfaces over relational databases interpret keyword queries as Select-Project-Join SQL queries with only conjunctions in the where clause [31, 42].", "startOffset": 173, "endOffset": 181}, {"referenceID": 19, "context": "Furthermore, given a query, the DBMS explores finitely many alternative intents to interpret the query efficiently [21, 31, 14].", "startOffset": 115, "endOffset": 127}, {"referenceID": 29, "context": "Furthermore, given a query, the DBMS explores finitely many alternative intents to interpret the query efficiently [21, 31, 14].", "startOffset": 115, "endOffset": 127}, {"referenceID": 12, "context": "Furthermore, given a query, the DBMS explores finitely many alternative intents to interpret the query efficiently [21, 31, 14].", "startOffset": 115, "endOffset": 127}, {"referenceID": 43, "context": "DBMSs often implement their strategies using a real-valued function called scoring function over pairs of queries and intents [45, 14, 21].", "startOffset": 126, "endOffset": 138}, {"referenceID": 12, "context": "DBMSs often implement their strategies using a real-valued function called scoring function over pairs of queries and intents [45, 14, 21].", "startOffset": 126, "endOffset": 138}, {"referenceID": 19, "context": "DBMSs often implement their strategies using a real-valued function called scoring function over pairs of queries and intents [45, 14, 21].", "startOffset": 126, "endOffset": 138}, {"referenceID": 28, "context": "It is shown, however, that such a deterministic mapping may limit the effectiveness of interpreting queries in long-term interactions [30, 65, 62, 5].", "startOffset": 134, "endOffset": 149}, {"referenceID": 62, "context": "It is shown, however, that such a deterministic mapping may limit the effectiveness of interpreting queries in long-term interactions [30, 65, 62, 5].", "startOffset": 134, "endOffset": 149}, {"referenceID": 60, "context": "It is shown, however, that such a deterministic mapping may limit the effectiveness of interpreting queries in long-term interactions [30, 65, 62, 5].", "startOffset": 134, "endOffset": 149}, {"referenceID": 4, "context": "It is shown, however, that such a deterministic mapping may limit the effectiveness of interpreting queries in long-term interactions [30, 65, 62, 5].", "startOffset": 134, "endOffset": 149}, {"referenceID": 28, "context": "Hence, the DBMS may adopt a stochastic strategy:it may randomly select and show the results of intents such that the ones with higher scores are more often chosen [30, 65, 62, 5].", "startOffset": 163, "endOffset": 178}, {"referenceID": 62, "context": "Hence, the DBMS may adopt a stochastic strategy:it may randomly select and show the results of intents such that the ones with higher scores are more often chosen [30, 65, 62, 5].", "startOffset": 163, "endOffset": 178}, {"referenceID": 60, "context": "Hence, the DBMS may adopt a stochastic strategy:it may randomly select and show the results of intents such that the ones with higher scores are more often chosen [30, 65, 62, 5].", "startOffset": 163, "endOffset": 178}, {"referenceID": 4, "context": "Hence, the DBMS may adopt a stochastic strategy:it may randomly select and show the results of intents such that the ones with higher scores are more often chosen [30, 65, 62, 5].", "startOffset": 163, "endOffset": 178}, {"referenceID": 60, "context": "Researchers have shown that it is possible to find the stochastic strategy that results in returning sufficiently many answers to keep users engaged and sufficiently diverse results to collect useful feedback and improve significantly the effectiveness of query answering [62, 30].", "startOffset": 272, "endOffset": 280}, {"referenceID": 28, "context": "Researchers have shown that it is possible to find the stochastic strategy that results in returning sufficiently many answers to keep users engaged and sufficiently diverse results to collect useful feedback and improve significantly the effectiveness of query answering [62, 30].", "startOffset": 272, "endOffset": 280}, {"referenceID": 43, "context": "This reward is measured based on the user feedback and using standard effectiveness metrics [45].", "startOffset": 92, "endOffset": 96}, {"referenceID": 3, "context": "Due to their lack of information, users may sometimes submit queries that may not return any tuple over the underlying database [4].", "startOffset": 128, "endOffset": 131}, {"referenceID": 3, "context": "The DBMS typically map these queries to relatively broad and relaxed intents with non-empty result over the database [4, 67].", "startOffset": 117, "endOffset": 124}, {"referenceID": 64, "context": "The DBMS typically map these queries to relatively broad and relaxed intents with non-empty result over the database [4, 67].", "startOffset": 117, "endOffset": 124}, {"referenceID": 12, "context": ", p@k, for their input queries [14].", "startOffset": 31, "endOffset": 35}, {"referenceID": 52, "context": "Nevertheless, in some collaborative two-player games in which both players adapt their strategies to improve their payoff, the learning may not converge to any (desired) equilibrium and cycle among several unstable states [54, 64].", "startOffset": 222, "endOffset": 230}, {"referenceID": 61, "context": "Nevertheless, in some collaborative two-player games in which both players adapt their strategies to improve their payoff, the learning may not converge to any (desired) equilibrium and cycle among several unstable states [54, 64].", "startOffset": 222, "endOffset": 230}, {"referenceID": 28, "context": "More importantly, the DBMS should use an adaptation strategy that keeps users engaged [30].", "startOffset": 86, "endOffset": 90}, {"referenceID": 13, "context": "Our definition of pool of intent resembles the notion of pool of state in signaling games [15, 18].", "startOffset": 90, "endOffset": 98}, {"referenceID": 16, "context": "Our definition of pool of intent resembles the notion of pool of state in signaling games [15, 18].", "startOffset": 90, "endOffset": 98}, {"referenceID": 24, "context": "Some users may be willing to lose some payoff in the short-term to gain more payoff in the long run, therefore, an interesting direction is to define and analyze less myopic equilibria for the game [26].", "startOffset": 198, "endOffset": 202}, {"referenceID": 16, "context": "10 extends the Theorem 1 in [18] for our model.", "startOffset": 28, "endOffset": 32}, {"referenceID": 0, "context": "In particular, for \u03b1 \u2208 [0, 1], if D,D are stochastic matrices, \u03b1D + (1 \u2212 \u03b1)D will be a stochastic matrix and hence, (U, \u03b1D + (1 \u2212 \u03b1)D) is a Nash equilibrium as well.", "startOffset": 23, "endOffset": 29}, {"referenceID": 0, "context": "Similarly, if (U , D) and (U,D) are Nash equilibria for U 6= U , then ur(\u03b1U + (1\u2212 \u03b1)U , D) = ur(U,D) and (\u03b1U + (1\u2212 \u03b1)U , D) is a Nash-equilibrium for any \u03b1 \u2208 [0, 1].", "startOffset": 158, "endOffset": 164}, {"referenceID": 55, "context": "Every finite game has always a mixed Nash equilibrium [57].", "startOffset": 54, "endOffset": 58}, {"referenceID": 54, "context": "It is well established that humans show reinforcement behavior in learning [56, 47, 48].", "startOffset": 75, "endOffset": 87}, {"referenceID": 45, "context": "It is well established that humans show reinforcement behavior in learning [56, 47, 48].", "startOffset": 75, "endOffset": 87}, {"referenceID": 46, "context": "It is well established that humans show reinforcement behavior in learning [56, 47, 48].", "startOffset": 75, "endOffset": 87}, {"referenceID": 54, "context": "Many lab studies with human subjects conclude that one can model human learning using reinforcement learningmodels [56, 47].", "startOffset": 115, "endOffset": 123}, {"referenceID": 45, "context": "Many lab studies with human subjects conclude that one can model human learning using reinforcement learningmodels [56, 47].", "startOffset": 115, "endOffset": 123}, {"referenceID": 8, "context": "Bush and Mosteller\u2019s model increases the probability that a user will choose a given query when searching for a specific intent by an amount proportional based on the reward of using that query and the current probability of using this query for the intent in the strategy [10].", "startOffset": 273, "endOffset": 277}, {"referenceID": 0, "context": "Uij(t)\u2212 \u03b1 BM \u00b7 Uij(t) qj 6= q(t) \u2227 r \u2265 0 Uij(t) + \u03b2 BM \u00b7 (1\u2212 Uij(t) qj 6= q(t) \u2227 r < 0 (4) In the aforementioned formulas,\u03b1 \u2208 [0, 1] and \u03b2 \u2208 [0, 1] are parameters of the model, q(t) denotes the query picked by the user at time t, and r is the reward of the interaction.", "startOffset": 126, "endOffset": 132}, {"referenceID": 0, "context": "Uij(t)\u2212 \u03b1 BM \u00b7 Uij(t) qj 6= q(t) \u2227 r \u2265 0 Uij(t) + \u03b2 BM \u00b7 (1\u2212 Uij(t) qj 6= q(t) \u2227 r < 0 (4) In the aforementioned formulas,\u03b1 \u2208 [0, 1] and \u03b2 \u2208 [0, 1] are parameters of the model, q(t) denotes the query picked by the user at time t, and r is the reward of the interaction.", "startOffset": 141, "endOffset": 147}, {"referenceID": 14, "context": "Cross\u2019s model modifies the user\u2019s strategy similar to Bush and Mosteller\u2019s model [16].", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "In the above formulas, \u03b1 \u2208 [0, 1] and \u03b2 \u2208 [0, 1] are the parameters used compute the adjusted reward R(r) based", "startOffset": 27, "endOffset": 33}, {"referenceID": 0, "context": "In the above formulas, \u03b1 \u2208 [0, 1] and \u03b2 \u2208 [0, 1] are the parameters used compute the adjusted reward R(r) based", "startOffset": 42, "endOffset": 48}, {"referenceID": 49, "context": "Roth and Erev\u2019s model reinforces the probabilities directly from the reward value r that is received when the user enters query q(t) [51].", "startOffset": 133, "endOffset": 137}, {"referenceID": 18, "context": "Roth and Erev\u2019s modified model is similar to the original Roth and Erev\u2019s model, but it has an additional parameter that determines to what extent the user takes in to account the outcomes of her past interactions with the system [20].", "startOffset": 230, "endOffset": 234}, {"referenceID": 0, "context": "This is accounted for by the forget parameter \u03c3 \u2208 [0, 1].", "startOffset": 50, "endOffset": 56}, {"referenceID": 0, "context": "In the aforementioned formulas, \u01eb \u2208 [0, 1] is a parameter that weights the reward that the user receives, n is the maximum number of possible queries for a given intent ei, and rmin is the minimum expected reward that the user wants to receive.", "startOffset": 36, "endOffset": 42}, {"referenceID": 6, "context": "TheWin-Stay/Lose-Randomizemethod uses only the most recent interaction for an intent to determine the queries used to express the intent in the future [7].", "startOffset": 151, "endOffset": 154}, {"referenceID": 0, "context": "Let a user receive reward r \u2208 [0, 1] by entering query qj to express intent ei.", "startOffset": 30, "endOffset": 36}, {"referenceID": 9, "context": "Those studies show that non-proficient users tend to use models that do not leverage the information about the past interactions, such as Cross\u2019s model [11].", "startOffset": 152, "endOffset": 156}, {"referenceID": 30, "context": "As in [32], we consider Roth-Erev reinforcement learning mechanism for adaptation of the DBMS adaption.", "startOffset": 6, "endOffset": 10}, {"referenceID": 30, "context": "For the case that both the DBMS and the user adapt their strategies, one can use the results in [32].", "startOffset": 96, "endOffset": 100}, {"referenceID": 10, "context": "[12], for the initial reward condition R(0) which possibly leads to an intuitive initial point for the learning rule.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "As queries and intents generally follow a power law distribution [45], one may use sampling techniques to use this algorithm in other settings.", "startOffset": 65, "endOffset": 69}, {"referenceID": 17, "context": "We recall that a random process {X(t)} is a submartingale [19] if it is absolutely integrable (i.", "startOffset": 58, "endOffset": 62}, {"referenceID": 17, "context": "We refer the interested readers to [19] for further information on this result (martingale convergence theorem).", "startOffset": 35, "endOffset": 39}, {"referenceID": 48, "context": "[50] A random process {Xt} converges almost surely if Xt is bounded, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "Note that this result is a weaker form of the Robins-Siegmund martingale convergence theorem in [50] but it will serve for the purpose of our discussion.", "startOffset": 96, "endOffset": 100}, {"referenceID": 17, "context": "the Jensen\u2019s inequality [19], we have:", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "Therefore, using the Borel-Cantelli Lemma for adapted processes [19] we have { 1 R j (t) } is summable", "startOffset": 64, "endOffset": 68}, {"referenceID": 9, "context": "In fact, researchers have observed that users show reinforcement learning behavior when interacting with a DBMS over a period of time [11].", "startOffset": 134, "endOffset": 138}, {"referenceID": 9, "context": "In particular, the authors in [11] have shown that some groups of users learned to formulate queries with a model similar to Roth-Erev reinforcement learning.", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "Therefore, by the Jensen\u2019s inequality [19], we have:", "startOffset": 38, "endOffset": 42}, {"referenceID": 30, "context": "Such questions are partially addressed in [32] for the case that both the players in a singling game adapt their strategy synchronously and identically.", "startOffset": 42, "endOffset": 46}, {"referenceID": 30, "context": "3 in [32] for more details).", "startOffset": 5, "endOffset": 9}, {"referenceID": 30, "context": "The authors in [32] follow a traditional language game approach as explained in Section 6.", "startOffset": 15, "endOffset": 19}, {"referenceID": 37, "context": "Signaling games model communication between two or more agents and have been widely used in economics, sociology, biology, and linguistics [39, 15, 49, 18].", "startOffset": 139, "endOffset": 155}, {"referenceID": 13, "context": "Signaling games model communication between two or more agents and have been widely used in economics, sociology, biology, and linguistics [39, 15, 49, 18].", "startOffset": 139, "endOffset": 155}, {"referenceID": 47, "context": "Signaling games model communication between two or more agents and have been widely used in economics, sociology, biology, and linguistics [39, 15, 49, 18].", "startOffset": 139, "endOffset": 155}, {"referenceID": 16, "context": "Signaling games model communication between two or more agents and have been widely used in economics, sociology, biology, and linguistics [39, 15, 49, 18].", "startOffset": 139, "endOffset": 155}, {"referenceID": 13, "context": "A signaling game may not be cooperative in which the interests of players do not coincide [15].", "startOffset": 90, "endOffset": 94}, {"referenceID": 59, "context": "Our framework extends a particular category of signaling games called language games [61, 49, 18] and is closely related to learning in signaling games [32, 59, 23].", "startOffset": 85, "endOffset": 97}, {"referenceID": 47, "context": "Our framework extends a particular category of signaling games called language games [61, 49, 18] and is closely related to learning in signaling games [32, 59, 23].", "startOffset": 85, "endOffset": 97}, {"referenceID": 16, "context": "Our framework extends a particular category of signaling games called language games [61, 49, 18] and is closely related to learning in signaling games [32, 59, 23].", "startOffset": 85, "endOffset": 97}, {"referenceID": 30, "context": "Our framework extends a particular category of signaling games called language games [61, 49, 18] and is closely related to learning in signaling games [32, 59, 23].", "startOffset": 152, "endOffset": 164}, {"referenceID": 57, "context": "Our framework extends a particular category of signaling games called language games [61, 49, 18] and is closely related to learning in signaling games [32, 59, 23].", "startOffset": 152, "endOffset": 164}, {"referenceID": 21, "context": "Our framework extends a particular category of signaling games called language games [61, 49, 18] and is closely related to learning in signaling games [32, 59, 23].", "startOffset": 152, "endOffset": 164}, {"referenceID": 2, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 36, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 25, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 53, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 51, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 26, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 41, "context": "Game theoretic approaches have been used in various areas of computer science, such as distributed systems, planning, security, and data mining [3, 38, 27, 55, 53, 28, 43].", "startOffset": 144, "endOffset": 171}, {"referenceID": 63, "context": "Researchers have also leveraged economical models to build query interfaces that return desired results to the users using the fewest possible interactions [66].", "startOffset": 156, "endOffset": 160}, {"referenceID": 39, "context": "In particular, researchers have recently applied game theoretic approaches to model the actions taken by users and document retrieval systems in a single session [41].", "startOffset": 162, "endOffset": 166}, {"referenceID": 5, "context": "have used signaling games to create a shared lexicon between multiple autonomous systems [6].", "startOffset": 89, "endOffset": 92}, {"referenceID": 56, "context": "We have proposed the possibility of using signaling games to model the interaction between users and DBMS and provided an initial result in a short paper in [58].", "startOffset": 157, "endOffset": 161}, {"referenceID": 56, "context": "However, authors in [58] assume that a result either fully satisfies the user\u2019s information need or does not contain information relevant to the submitted intent.", "startOffset": 20, "endOffset": 24}, {"referenceID": 32, "context": "Interactive querying of databases has recently received a lot of attention [34].", "startOffset": 75, "endOffset": 79}], "year": 2017, "abstractText": "As most users cannot precisely express their information needs in form of queries, it is challenging for database management systems to understand the true information needs behind users\u2019 queries. Query interfaces leverage user\u2019s feedback on the returned answers for a query to improve their understanding of the true information need behind the query. Current query interfaces generally assume that a user follows a fixed strategy of expressing her information needs, that is, the likelihood by which a user submits a query to express a certain information need remains unchanged over a potentially long period of time. Nevertheless, users may learn from their interactions with the database system and gradually choose more precise queries to express their intents. In this paper, we introduce a novel formal framework that models database querying as a collaboration between two active and potentially rational agents: the user and the database management system. These agents follow the identical interest of establishing amutual language for representing information needs. We formalize this collaboration as a signaling game, where each mutual language is an equilibrium for the game. A query interface is more effective if it establishes a less ambiguous mutual language faster. We explore some important characteristics of the equilibria of the game. Using an extensive empirical analysis over a real-world query workload, we show that users follow a reinforcement learning method to improve the articulation of their information needs. We also propose and analyze a reinforcement learning mechanism for the database query interface. We prove that this adaptation mechanism for the query interface improves the effectiveness of answering queries stochastically speaking, and converges almost surely, for both the cases where users follows a fixed and reinforcement learning strategy for expressing their information needs.", "creator": "LaTeX with hyperref package"}}}