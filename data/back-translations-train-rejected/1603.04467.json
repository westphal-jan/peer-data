{"id": "1603.04467", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Mar-2016", "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems", "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.", "histories": [["v1", "Mon, 14 Mar 2016 20:50:20 GMT  (1364kb,D)", "http://arxiv.org/abs/1603.04467v1", null], ["v2", "Wed, 16 Mar 2016 16:57:12 GMT  (1364kb,D)", "http://arxiv.org/abs/1603.04467v2", "Version 2 updates only the metadata, to correct the formatting of Mart\\'in Abadi's name"]], "reviews": [], "SUBJECTS": "cs.DC cs.LG", "authors": ["mart\\'in abadi", "ashish agarwal", "paul barham", "eugene brevdo", "zhifeng chen", "craig citro", "greg s corrado", "y davis", "jeffrey dean", "matthieu devin", "sanjay ghemawat", "ian goodfellow", "rew harp", "geoffrey irving", "michael isard", "yangqing jia", "rafal jozefowicz", "lukasz kaiser", "manjunath kudlur", "josh levenberg", "dan mane", "rajat monga", "sherry moore", "derek murray", "chris olah", "mike schuster", "jonathon shlens", "benoit steiner", "ilya sutskever", "kunal talwar", "paul tucker", "vincent vanhoucke", "vijay vasudevan", "fernanda viegas", "oriol vinyals", "pete warden", "martin wattenberg", "martin wicke", "yuan yu", "xiaoqiang zheng"], "accepted": false, "id": "1603.04467"}, "pdf": {"name": "1603.04467.pdf", "metadata": {"source": "CRF", "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems", "authors": ["Mart\u0131\u0301n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S. Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Ian Goodfellow", "Andrew Harp", "Geoffrey Irving", "Michael Isard", "Yangqing Jia", "Rafal Jozefowicz", "Lukasz Kaiser", "Manjunath Kudlur", "Josh Levenberg", "Dan Man\u00e9", "Rajat Monga", "Sherry Moore", "Derek Murray", "Chris Olah", "Mike Schuster", "Jonathon Shlens", "Benoit Steiner", "Ilya Sutskever", "Kunal Talwar", "Paul Tucker", "Vincent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi\u00e9gas", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "emails": ["jeff@google.com", "rajatmonga@google.com"], "sections": [{"heading": null, "text": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (Preliminary White Paper, November 9, 2015) Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Sororawat, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vie-gas, Oriol Vinyals, Pete Warden, Martin Warden, Wattenberg Yuqu Yuqu."}, {"heading": "1 Introduction", "text": "This year, the time has come for such a process to take place only once, in which the question is to what extent it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a country, in a country, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city, in a city,"}, {"heading": "2 Programming Model and Basic Concepts", "text": "The graph represents a dataflow calculation with extensions to obtain and update some types of nodes. An example fragment to construct and then execute a TensorFlow graph using the Python frontend is usually a computational graph using one of the supported frontend languages (C + + or Python). An example fragment to construct and execute a TensorFlow graph is shown in Figure 1."}, {"heading": "W = tf.Variable(tf.random_uniform([784,100],-1,1)) # 784x100 matrix w/rnd vals x = tf.placeholder(name=\"x\") # Placeholder for input relu = tf.nn.relu(tf.matmul(W, x) + b) # Relu(Wx+b)", "text": "The TensorFlow implementation can use the arguments to Run to calculate the transitive closure of all the nodes that need to be executed to compute the requested results, and can then arrange to execute the corresponding nodes in an order that respects their dependencies (as described in 3.1 in more detail). Most of our applications for TensorFlow set up a session with a graph once, and then execute the complete graph or some unique subgraph thousands or millions of times over run calls. VariableMost calculations run a graph multiple times. Most tensors do not survive a single execution of the graph. However, a variable is a special type of operation that returns a handle to a continuous modifiable subgraph, or survives the execution of a portion that is passed on to a handful of such operations."}, {"heading": "3 Implementation", "text": "The main components in a TensorFlow system are the client that uses the session interface to communicate with the master, and one or more worker processes, each worker being responsible for arbitrating access to one or more computing devices (such as CPU cores or GPU cards) and executing graphs on these devices as instructed by the master. We have both local and distributed implementations of the TensorFlow interface. Local implementation is used when the client, the master, and the worker are all running on a single machine in the context of a single operating system process (possibly with multiple devices if the machine has many GPU cards installed). Distributed implementation shares most of the code with the local implementation, but extends with support for an environment where the master, and the workers all work in different processes, and the workers can be in different processes."}, {"heading": "3.1 Single-Device Execution", "text": "First, consider the simplest execution scenario: a single worker process with a single device. The nodes of the graph are executed in an order that respects the dependencies between the nodes. Specifically, we track per node a count of the number of dependencies of this node that have not yet been executed. If this count drops to zero, the node is authorized to execute and is added to a finished queue. The finished queue is processed in an unspecified order and delegates the execution of the node for a node to the device object. When a node has finished execution, the number of all nodes that depend on the finished node is reduced."}, {"heading": "3.2 Multi-Device Execution", "text": "Once a system has multiple devices, there are two major complications: deciding which device will place the calculation for each node in the diagram, and managing the required data transmission across device boundaries implied by these placement decisions. In this section, these two issues are discussed."}, {"heading": "3.2.1 Node Placement", "text": "In view of a calculation curve, one of the main tasks of the TensorFlow implementation will be to map the calculation to the set of available devices. A simplified version of this algorithm is presented here. See Section 4.3 for extensions supported by this algorithm. Input to the placement algorithm is a cost model that includes estimates of the size (in bytes) of the input and output sensor for each graph node, along with estimates of the calculation time required for each node when presented with its input types. This cost model is either estimated based on the heuristics associated with different types of operations, or is measured based on an actual series of placement decisions for earlier versions of the graph. The placement algorithm first performs a simulated execution of the graph. The simulation is described below and ends with the selection of a device for each node in the graph that is operated with hayristic."}, {"heading": "3.2.2 Cross-Device Communication", "text": "Each cross-device edge from x to y is removed and replaced by an edge from x to a new send node in the subgraph of x, and an edge from a corresponding receive node to y in the subgraph of y. See Figure 4 for an example of this graph transformation. At runtime, the implementations of the send-and-receive node coordinate the transmission of data between devices. This allows us to isolate all communication within send-and-receive implementations, which simplifies the rest of the runtime. When we insert send-and-receive nodes, we canonize all users of a specific tensor on a particular device to use a single receive node instead of having one receive node per device, ensuring that the data for the required tensor is transmitted only once between a source device and a destination device."}, {"heading": "3.3 Distributed Execution", "text": "Distributed execution of a graph is very similar to execution by multiple devices. Once the device is placed, one subgraph is created per device.Fault tolerance failures in distributed execution can be detected in a variety of places.The most important ones we rely on are (a) an error in communication between a send-receiver node pair and (b) periodic health checks from the master process to each work process.When an error is detected, the entire graph execution is aborted and restarted. However, keep in mind that variable nodes refer to tensors that persist beyond execution of the graph. We support consistent testing and restoration of this state at restart. Partly, each variable node is associated with a save node. These save nodes are executed at regular intervals, say all N iterations, or all N data is only stored once in a file, with each node first connected to a specific node."}, {"heading": "4 Extensions", "text": "In this section, we describe some advanced features of the basic programming model introduced in Section 2."}, {"heading": "4.1 Gradient Computation", "text": "In fact, most of them will be able to play by the rules they have established over the last five years."}, {"heading": "4.2 Partial Execution", "text": "To support this, once the client has set up a calculation graph in a session, it must execute an arbitrary subgraph of the entire graph and inject arbitrary data along any edge in the graph. Finally, each node in the graph can have a name, and each output of a node is identified by the source node name and the output port of the node, numbered from 0 (e.g. \"bar: 0\" refers to the first output of the \"bar\" node, while \"bar: 1\" refers to the second output. Two arguments for the run call help define the exact subgraph of the calculation graph to execute."}, {"heading": "4.3 Device Constraints", "text": "TensorFlow clients can control the placement of nodes on devices by setting partial constraints on a node on which devices it can run. For example, \"place this node only on a GPU-type device,\" or \"this node can be located on any device in / job: worker / task: 17,\" or \"locate this node with a node called Variable13.\" Within the constraints of these constraints, the placement algorithm is responsible for selecting an allocation of nodes to devices that allows the calculation to be performed quickly and also fulfills various constraints imposed by the devices themselves, such as limiting the total amount of memory a device needs to execute its subset of graph nodes. To support such constraints, changes to the placement algorithm described in Section 3.2.1 are required. First, we calculate the feasible amount of devices for each node, and then use Union-find on the graph to calculate the constraints that need to be put together to perform the constraints."}, {"heading": "4.4 Control Flow", "text": "Although the basic idea is very meaningful without any explicit control, we have observed a number of cases where it can lead to precise and efficient representations of machine learning processes."}, {"heading": "4.5 Input Operations", "text": "Although input data can be provided to a calculation via feed nodes, another common mechanism for training large machine learning models is to have specialized input operation nodes in the graph that are typically configured with a set of filenames and produce a tensor at each execution that contains one or more examples of the data stored in that dataset. This allows data to be read directly from the underlying storage system into the machine's memory that will perform the subsequent processing of the data. In configurations where the client process is separated from the worker process, if the data were fed in, it would typically require an additional network hop (from storage system to client and then from client to worker directly from storage system to worker using an input node)."}, {"heading": "4.6 Queues", "text": "Queues are a useful feature that we have added to TensorFlow. They allow different parts of the graph to run asynchronously, possibly with different candles, and to deliver data through enqueue and dequeue operations. Queue operations can block until space in the queue becomes available, and dequeue operations can block until a desired minimum number of elements is available in the queue. One use of queues is to fetch input data from disk files while a previous batch of data is still being processed by the computational portion of a machine learning model. They can also be used for other types of groupings, including clustering many gradients to calculate a more complex combination of gradients over a larger stack, or grouping different sets of recurring language models into containers of sentences that are roughly the same length and can then be processed more efficiently."}, {"heading": "4.7 Containers", "text": "A container is the mechanism within TensorFlow for managing a long-lasting variable state. The backup memory for a variable lives in a container. The standard container is one that persists until the end of the process, but we also allow other named containers. A container can be reset by being completely stripped of its contents. With the help of containers, it is possible to divide the state even using completely uncommon calculation diagrams associated with different sessions."}, {"heading": "5 Optimizations", "text": "In this section, we describe some of the optimizations in the TensorFlow implementation that improve the performance or resource usage of the system."}, {"heading": "5.1 Common Subexpression Elimination", "text": "Since the construction of calculation graphs often takes place through many different levels of abstractions in the client code, calculation graphs can easily end up with redundant copies of the same calculation. To accomplish this, we have implemented a common partial expression pass, similar to the algorithm described by Click [12], which runs over the calculation graph and canonizes multiple copies of operations with identical inputs and operation types on only one of these nodes, and redirects graph margins accordingly to reflect this canonization."}, {"heading": "5.2 Controlling Data Communication and Memory Usage", "text": "Careful planning of TensorFlow operations can lead to better performance of the system, especially in terms of data transfer and memory usage. In particular, planning can reduce the window of time in which interim results between operations must be stored in memory, and thus peak memory usage. This reduction is particularly important for GPU devices where memory is scarce. In addition, orchestrating data communication between devices can reduce the dispute over network resources. Although there are many options for planning optimizations, here we are focusing on one that we thought was particularly necessary and effective: planning reception nodes for reading remote values. If no precautions are taken, these nodes can start much earlier than necessary, possibly all at once when execution begins. By performing a calculation as soon as possible / as late as possible (ASAP / ALAP), of the kind commonly used in operational research, we can analyze the critical paths of receiving diagrams to estimate when to start."}, {"heading": "5.3 Asynchronous Kernels", "text": "In addition to normal synchronous kernels that complete their execution at the end of the compute method, our framework also supports non-blocking kernels. Such non-blocking kernels use a slightly different interface, passing a continuation to the compute method that should be called when the execution of the kernel is complete. This is optimization for environments where the presence of many active threads is relatively expensive in terms of memory usage or other resources, and allows us not to tie an execution thread indefinitely while waiting for I / O or other events. Examples of asynchronous kernels are the receive kernel and the enqueue and dequeue kernels (which may need to be blocked if there is no space in the queue or if there is no data available to read)."}, {"heading": "5.4 Optimized Libraries for Kernel Implementations", "text": "We often use pre-existing highly optimized numeric libraries to implement kernels for some operations. For example, there are a number of optimized libraries for performing matrix multiplications on different devices, including BLAS [15] and cuBLAS [39], or GPU libraries for revolutionary cores for deep neural networks, such as cuda-convennet [28] and cuDNN [9]. Many of our kernel implementations are relatively thin shells around such optimized libraries. We use the open source linear algebra library Eigen [25] for many of the kernel implementations in the system. As part of the development of TensorFlow, our team (primarily Benoit Steiner) has added support for arbitrary dimensional sensor operations to the Oigen open source library."}, {"heading": "5.5 Lossy Compression", "text": "Some machine learning algorithms, including those typically used to train neural networks, are noise-tolerant and reduce precise arithmetic. Similar to the DistBelief system [14], we often use lossy compression of higher internal representations when sending data between devices (sometimes within the same machine, but especially across machine boundaries); for example, we often insert special conversion nodes that convert 32-bit floating-point representations into a 16-bit floating-point representation (not the proposed IEEE 16-bit floating-point standard, but just a 32-bit IEEE 794 floating-point format, but with 16-bit less precision in the mantissa), and then convert back to a 32-bit representation on the other side of the communication channel (simply giving zeros for the lost portion of the floating-point format, which is less likely to be recalculated with this circular 32)."}, {"heading": "6 Status and Experience", "text": "This year, it has come to the point that there is only one time that there is such a process, in which there is such a process."}, {"heading": "7 Common Programming Idioms", "text": "In fact, it is so that the majority of them are able to set off to the USA in order to stay where they are: in the USA, to Europe, to the USA, to the USA, to Europe, to the USA, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, to Turkey, Turkey, to Turkey, to Turkey, to Turkey, to Turkey, Turkey, to Turkey, to Turkey, Turkey, to Turkey, to Turkey, Turkey, to Turkey, Turkey, to"}, {"heading": "8 Performance", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A future version of this white paper will have a comprehensive performance evaluation section of both the single machine and distributed implementations.", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9 Tools", "text": "This section describes some of the tools we have developed that stand next to the central TensorFlow Graph Execution Engine."}, {"heading": "9.1 TensorBoard: Visualization of graph structures and summary statistics", "text": "To help users understand the structure of their computer graphics and also the overall behavior of machine learning models, we have built TensorBoard, a visualization tool for TensorFlow included in the open source release. For example, the calculation method for forming a model similar to Google's Inception model [48], a deep-rooted neural network that has the best classification performance in ImageNet 2014, has 36,000 nodes in its TensorFlow calculation chart, and some deep-rooted LSTM models."}, {"heading": "9.2 Performance Tracing", "text": "We have an internal tool called EEG (not in the original open source release in November 2015) that we use to collect and visualize very fine-grained information about the exact layout and performance of TensorFlow graphics. This tool works both in our individual machines and in the distributed implementations, and is very useful for understanding the bottlenecks in the calculation and communication patterns of a TensorFlow program. Tracks are collected simultaneously on every machine in the system, including the Linux kernel trace, our own lightweight thread tracing tools, and the CUDA profiling tools interface (CUPTI)."}, {"heading": "10 Future Work", "text": "We will continue to use TensorFlow to develop new and interest-driven machine learning models for artificial intelligence, and in the process we may need to find ways to expand the basic TensorFlow system. The open source community may also find new and interesting instructions for TensorFlow implementation. An extension of the basic programming model we are considering is a functional mechanism where a user can specify an entire subgraph of a TensorFlow calculation as a reusable component. In the implementation we have designed, these functions can become reusable components, even in different front-end languages for TensorFlow, so that a user can define a function with the Python frontend, but then use this function as a basic building block within the C + + boundary."}, {"heading": "11 Related Work", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "12 Conclusions", "text": "We have described TensorFlow, a flexible data flow-based programming model, as well as individual machines and distributed implementations of this programming model. The system is based on real-world experience in conducting research and deploying more than a hundred machine learning projects across a wide range of Google products and services. We have developed an open source version of TensorFlow and hope that a vibrant community will develop around the use of TensorFlow. We are excited to see how others outside of Google use TensorFlow in their own work."}, {"heading": "Acknowledgements", "text": "The development of TensorFlow has benefited enormously from the large and broad machine learning community at Google, in particular from the suggestions and contributions of the rest of the Google Brain team, as well as from the hundreds of users of DistBelief and TensorFlow within Google. Undoubtedly, the ease of use and functionality of TensorFlow has been enhanced by listening to their feedback. Many individuals have contributed to TensorFlow and its open source release, including John Giannandrea (for creating a supportive research environment), Irina Kofman and Phing Turner (project management), Bill Gruber and David Westbrook (technical writing), Dave Andersen, Anelia Angelova, Yaroslav Bulatov, Jianmin Chen, Jerjou Cheng, George Dahl, Andrew Dai, Lucy Gao, mig Gerard, Stephan Gouws, Naveen Kumar, Geoffrey Hinton, Mrinal Kalishnan, Anjuli Kannan Team, Xiannan Yutsam Xiu-Leon Sobi, Jaeml Jaeml of Wasorlow, Yuti Li."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "author": ["Mart\u0131\u0301n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S. Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Ian Goodfellow", "Andrew Harp", "Geoffrey Irving", "Michael Isard", "Yangqing Jia", "Rafal Jozefowicz", "Lukasz Kaiser", "Manjunath Kudlur", "Josh Levenberg", "Dan Man\u00e9", "Rajat Monga", "Sherry Moore", "Derek Murray", "Chris Olah", "Mike Schuster", "Jonathon Shlens", "Benoit Steiner", "Ilya Sutskever", "Kunal Talwar", "Paul Tucker", "Vincent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi\u00e9gas", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Pedestrian detection with a large-field-of-view deep network", "author": ["Anelia Angelova", "Alex Krizhevsky", "Vincent Vanhoucke"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Annual review of computer science vol. 1, 1986. chapter  Dataflow Architectures, pages 225\u2013253", "author": ["Arvind", "David E. Culler"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1986}, {"title": "Executing a program on the MIT tagged-token dataflow architecture", "author": ["Arvind", "Rishiyur S. Nikhil"], "venue": "IEEE Trans. Comput.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1990}, {"title": "Multiple object recognition with visual attention", "author": ["Jimmy Ba", "Volodymyr Mnih", "Koray Kavukcuoglu"], "venue": "arXiv preprint arXiv:1412.7755,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "The neural networks behind", "author": ["Fran\u00e7oise Beaufays"], "venue": "Google Voice transcription,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Theano: A CPU and GPU math expression compiler", "author": ["James Bergstra", "Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio"], "venue": "In Proceedings of the Python for scientific computing conference (SciPy),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "FlumeJava: easy, efficient data-parallel pipelines", "author": ["Craig Chambers", "Ashish Raniwala", "Frances Perry", "Stephen Adams", "Robert R Henry", "Robert Bradshaw", "Nathan Weizenbaum"], "venue": "In ACM Sigplan Notices,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "cuDNN: Efficient primitives for deep learning", "author": ["Sharan Chetlur", "Cliff Woolley", "Philippe Vandermersch", "Jonathan Cohen", "John Tran", "Bryan Catanzaro", "Evan Shelhamer"], "venue": "arXiv preprint arXiv:1410.0759,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Project Adam: Building an efficient and scalable deep learning training system", "author": ["Trishul Chilimbi", "Yutaka Suzue", "Johnson Apacible", "Karthik Kalyanaraman"], "venue": "In 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Google turning its lucrative web search over to AI machines", "author": ["Jack Clark"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Global code motion/global value numbering", "author": ["Cliff Click"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Torch: A modular machine learning software library", "author": ["Ronan Collobert", "Samy Bengio", "Johnny Mari\u00e9thoz"], "venue": "Technical report, IDIAP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Large scale distributed deep networks", "author": ["Jeffrey Dean", "Gregory S. Corrado", "Rajat Monga", "Kai Chen", "Matthieu Devin", "Quoc V. Le", "Mark Z. Mao", "Marc\u2019Aurelio Ranzato", "Andrew Senior", "Paul Tucker", "17  Ke Yang", "Andrew Y. Ng"], "venue": "In NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "A set of level 3 basic linear algebra subprograms", "author": ["Jack J Dongarra", "Jeremy Du Croz", "Sven Hammarling", "Iain S Duff"], "venue": "ACM Transactions on Mathematical Software (TOMS),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1990}, {"title": "DeVISE: A deep visual-semantic embedding model", "author": ["Andrea Frome", "Greg S Corrado", "Jonathon Shlens", "Samy Bengio", "Jeff Dean", "Tomas Mikolov"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Frameby-frame language identification in short utterances using deep neural networks", "author": ["Javier Gonzalez-Dominguez", "Ignacio Lopez-Moreno", "Pedro J Moreno", "Joaquin Gonzalez-Rodriguez"], "venue": "Neural Networks,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "How Google Translate squeezes deep learning onto a phone", "author": ["Otavio Good"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Multi-digit number recognition from Street View imagery using deep convolutional neural networks", "author": ["Ian J. Goodfellow", "Yaroslav Bulatov", "Julian Ibarz", "Sacha Arnoud", "Vinay Shet"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Multilingual acoustic models using distributed deep neural networks", "author": ["Georg Heigold", "Vincent Vanhoucke", "Alan Senior", "Patrick Nguyen", "Marc\u2019Aurelio Ranzato", "Matthieu Devin", "Jeffrey Dean"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["Geoffrey E. Hinton", "Li Deng", "Dong Yu", "George E. Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N. Sainath", "Brian Kingsbury"], "venue": "IEEE Signal Process. Mag.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Long shortterm memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1997}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "shift. CoRR,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Dryad: distributed data-parallel programs from sequential building blocks", "author": ["Michael Isard", "Mihai Budiu", "Yuan Yu", "Andrew Birrell", "Dennis Fetterly"], "venue": "In ACM SIGOPS Operating Systems Review,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell"], "venue": "In Proceedings of the ACM International Conference on Multimedia,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Large-scale video classification with convolutional neural networks", "author": ["Andrej Karpathy", "George Toderici", "Sachin Shetty", "Tommy Leung", "Rahul Sukthankar", "Li Fei- Fei"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "One weird trick for parallelizing convolutional neural networks", "author": ["Alex Krizhevsky"], "venue": "arXiv preprint arXiv:1404.5997,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Quoc Le", "Marc\u2019Aurelio Ranzato", "Rajat Monga", "Matthieu Devin", "Greg Corrado", "Kai Chen", "Jeff Dean", "Andrew Ng"], "venue": "In ICML\u20192012,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Move evaluation in Go using deep convolutional neural networks", "author": ["Chris J Maddison", "Aja Huang", "Ilya Sutskever", "David Silver"], "venue": "arXiv preprint arXiv:1412.6564,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In International Conference on Learning Representations: Workshops Track,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "Naiad: a timely dataflow system", "author": ["Derek G Murray", "Frank McSherry", "Rebecca Isaacs", "Michael Isard", "Paul Barham", "Mart\u0131\u0301n Abadi"], "venue": "In Proceedings of the Twenty- Fourth ACM Symposium on Operating Systems Principles,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Ciel: a universal execution engine for distributed data-flow computing", "author": ["Derek G. Murray", "Malte Schwarzkopf", "Christopher Smowton", "Steven Smit", "Anil Madhavapeddy", "Steven Hand"], "venue": "In Proceedings of the Ninth USENIX Symposium on Networked Systems Design and Implementation,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Massively parallel methods for deep reinforcement learning", "author": ["Arun Nair", "Praveen Srinivasan", "Sam Blackwell", "Cagdas Alcicek", "Rory Fearon", "Alessandro De Maria", "Vedavyas Panneershelvam", "Mustafa Suleyman", "Charles Beattie", "Stig Petersen"], "venue": "arXiv preprint arXiv:1507.04296,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Cublas library", "author": ["CUDA Nvidia"], "venue": "NVIDIA Corporation, Santa Clara, California, 15", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "Halide: A language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines", "author": ["Jonathan Ragan-Kelley", "Connelly Barnes", "Andrew Adams", "Sylvain Paris", "Fr\u00e9do Durand", "Saman Amarasinghe"], "venue": "ACM SIGPLAN Notices,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2013}, {"title": "Massively multitask networks for drug discovery", "author": ["Bharath Ramsundar", "Steven Kearnes", "Patrick Riley", "Dale Webster", "David Konerding", "Vijay Pande"], "venue": "arXiv preprint arXiv:1502.02072,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Benjamin Recht", "Christopher Re", "Stephen Wright", "Feng Niu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2011}, {"title": "Improving Photo Search: A step across the semantic gap", "author": ["Chuck Rosenberg"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2013}, {"title": "Dandelion: a compiler and runtime for heterogeneous systems", "author": ["Christopher J Rossbach", "Yuan Yu", "Jon Currey", "Jean- Philippe Martin", "Dennis Fetterly"], "venue": "In Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2013}, {"title": "Learning representations by backpropagating errors", "author": ["David E Rumelhart", "Geoffrey E Hinton", "Ronald J Williams"], "venue": "Cognitive modeling,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1988}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le"], "venue": "In NIPS,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"], "venue": "In CVPR\u20192015,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2015}, {"title": "Speech recognition and deep learning", "author": ["Vincent Vanhoucke"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2015}, {"title": "Large-scale cluster management at Google with Borg", "author": ["Abhishek Verma", "Luis Pedrosa", "Madhukar Korupolu", "David Oppenheimer", "Eric Tune", "John Wilkes"], "venue": "In Proceedings of the Tenth European Conference on Computer Systems,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2015}, {"title": "Grammar as a foreign language", "author": ["O. Vinyals", "L. Kaiser", "T. Koo", "S. Petrov", "I. Sutskever", "G. Hinton"], "venue": "Technical report, arXiv:1412.7449", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2014}, {"title": "An introduction to computational networks and the computational network toolkit", "author": ["Dong Yu", "Adam Eversole", "Mike Seltzer", "Kaisheng Yao", "Zhiheng Huang", "Brian Guenter", "Oleksii Kuchaiev", "Yu Zhang", "Frank Seide", "Huaming Wang"], "venue": "Technical report, Tech. Rep. MSR, Microsoft Research,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2014}, {"title": "Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing", "author": ["Matei Zaharia", "Mosharaf Chowdhury", "Tathagata Das", "Ankur Dave", "Justin Ma", "Murphy McCauley", "Michael J Franklin", "Scott Shenker", "Ion Stoica"], "venue": "In Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2012}, {"title": "On rectified linear units for speech processing", "author": ["Matthew D. Zeiler", "Marc\u2019Aurelio Ranzato", "Rajat Monga", "Mark Mao", "Ke Yang", "Quoc Le", "Patrick Nguyen", "Andrew Senior", "Vincent Vanhoucke", "Jeff Dean", "Geoffrey E. Hinton"], "venue": "In ICASSP,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "TensorFlow [1] is an interface for expressing machine learn-", "startOffset": 11, "endOffset": 14}, {"referenceID": 13, "context": "As part of the early work in this project, we built DistBelief, our first-generation scalable distributed training and inference system [14], and this system has served us well.", "startOffset": 136, "endOffset": 140}, {"referenceID": 27, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 123, "endOffset": 127}, {"referenceID": 29, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 153, "endOffset": 161}, {"referenceID": 44, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 153, "endOffset": 161}, {"referenceID": 15, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 216, "endOffset": 224}, {"referenceID": 41, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 216, "endOffset": 224}, {"referenceID": 25, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 247, "endOffset": 251}, {"referenceID": 47, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 272, "endOffset": 284}, {"referenceID": 20, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 272, "endOffset": 284}, {"referenceID": 19, "context": "We and others at Google have performed a wide variety of research using DistBelief including work on unsupervised learning [31], language representation [35, 52], models for image classification and object detection [16, 48], video classification [27], speech recognition [56, 21, 20],", "startOffset": 272, "endOffset": 284}, {"referenceID": 40, "context": "com sequence prediction [47], move selection for Go [34], pedestrian detection [2], reinforcement learning [38], and other areas [17, 5].", "startOffset": 24, "endOffset": 28}, {"referenceID": 28, "context": "com sequence prediction [47], move selection for Go [34], pedestrian detection [2], reinforcement learning [38], and other areas [17, 5].", "startOffset": 52, "endOffset": 56}, {"referenceID": 1, "context": "com sequence prediction [47], move selection for Go [34], pedestrian detection [2], reinforcement learning [38], and other areas [17, 5].", "startOffset": 79, "endOffset": 82}, {"referenceID": 32, "context": "com sequence prediction [47], move selection for Go [34], pedestrian detection [2], reinforcement learning [38], and other areas [17, 5].", "startOffset": 107, "endOffset": 111}, {"referenceID": 16, "context": "com sequence prediction [47], move selection for Go [34], pedestrian detection [2], reinforcement learning [38], and other areas [17, 5].", "startOffset": 129, "endOffset": 136}, {"referenceID": 4, "context": "com sequence prediction [47], move selection for Go [34], pedestrian detection [2], reinforcement learning [38], and other areas [17, 5].", "startOffset": 129, "endOffset": 136}, {"referenceID": 10, "context": "In addition, often in close collaboration with the Google Brain team, more than 50 teams at Google and other Alphabet companies have deployed deep neural networks using DistBelief in a wide variety of products, including Google Search [11], our advertising products, our speech recognition systems [50, 6, 46], Google Photos [43], Google Maps and StreetView [19], Google Translate [18], YouTube, and many others.", "startOffset": 235, "endOffset": 239}, {"referenceID": 42, "context": "In addition, often in close collaboration with the Google Brain team, more than 50 teams at Google and other Alphabet companies have deployed deep neural networks using DistBelief in a wide variety of products, including Google Search [11], our advertising products, our speech recognition systems [50, 6, 46], Google Photos [43], Google Maps and StreetView [19], Google Translate [18], YouTube, and many others.", "startOffset": 298, "endOffset": 309}, {"referenceID": 5, "context": "In addition, often in close collaboration with the Google Brain team, more than 50 teams at Google and other Alphabet companies have deployed deep neural networks using DistBelief in a wide variety of products, including Google Search [11], our advertising products, our speech recognition systems [50, 6, 46], Google Photos [43], Google Maps and StreetView [19], Google Translate [18], YouTube, and many others.", "startOffset": 298, "endOffset": 309}, {"referenceID": 37, "context": "In addition, often in close collaboration with the Google Brain team, more than 50 teams at Google and other Alphabet companies have deployed deep neural networks using DistBelief in a wide variety of products, including Google Search [11], our advertising products, our speech recognition systems [50, 6, 46], Google Photos [43], Google Maps and StreetView [19], Google Translate [18], YouTube, and many others.", "startOffset": 325, "endOffset": 329}, {"referenceID": 18, "context": "In addition, often in close collaboration with the Google Brain team, more than 50 teams at Google and other Alphabet companies have deployed deep neural networks using DistBelief in a wide variety of products, including Google Search [11], our advertising products, our speech recognition systems [50, 6, 46], Google Photos [43], Google Maps and StreetView [19], Google Translate [18], YouTube, and many others.", "startOffset": 358, "endOffset": 362}, {"referenceID": 17, "context": "In addition, often in close collaboration with the Google Brain team, more than 50 teams at Google and other Alphabet companies have deployed deep neural networks using DistBelief in a wide variety of products, including Google Search [11], our advertising products, our speech recognition systems [50, 6, 46], Google Photos [43], Google Maps and StreetView [19], Google Translate [18], YouTube, and many others.", "startOffset": 381, "endOffset": 385}, {"referenceID": 13, "context": "Modest changes in the description of the computation allow a wide variety of different approaches to parallelism to be achieved and tried with low effort [14, 29, 42].", "startOffset": 154, "endOffset": 166}, {"referenceID": 26, "context": "Modest changes in the description of the computation allow a wide variety of different approaches to parallelism to be achieved and tried with low effort [14, 29, 42].", "startOffset": 154, "endOffset": 166}, {"referenceID": 36, "context": "Modest changes in the description of the computation allow a wide variety of different approaches to parallelism to be achieved and tried with low effort [14, 29, 42].", "startOffset": 154, "endOffset": 166}, {"referenceID": 10, "context": "These clients rely on TensorFlow for research and production, with tasks as diverse as running inference for computer vision models on mobile phones to large-scale training of deep neural networks with hundreds of billions of parameters on hundreds of billions of example records using many hundreds of machines [11, 47, 48, 18, 53, 41].", "startOffset": 312, "endOffset": 336}, {"referenceID": 40, "context": "These clients rely on TensorFlow for research and production, with tasks as diverse as running inference for computer vision models on mobile phones to large-scale training of deep neural networks with hundreds of billions of parameters on hundreds of billions of example records using many hundreds of machines [11, 47, 48, 18, 53, 41].", "startOffset": 312, "endOffset": 336}, {"referenceID": 41, "context": "These clients rely on TensorFlow for research and production, with tasks as diverse as running inference for computer vision models on mobile phones to large-scale training of deep neural networks with hundreds of billions of parameters on hundreds of billions of example records using many hundreds of machines [11, 47, 48, 18, 53, 41].", "startOffset": 312, "endOffset": 336}, {"referenceID": 17, "context": "These clients rely on TensorFlow for research and production, with tasks as diverse as running inference for computer vision models on mobile phones to large-scale training of deep neural networks with hundreds of billions of parameters on hundreds of billions of example records using many hundreds of machines [11, 47, 48, 18, 53, 41].", "startOffset": 312, "endOffset": 336}, {"referenceID": 35, "context": "These clients rely on TensorFlow for research and production, with tasks as diverse as running inference for computer vision models on mobile phones to large-scale training of deep neural networks with hundreds of billions of parameters on hundreds of billions of example records using many hundreds of machines [11, 47, 48, 18, 53, 41].", "startOffset": 312, "endOffset": 336}, {"referenceID": 30, "context": "The graph represents a dataflow computation, with extensions for allowing some kinds of nodes to maintain and update persistent state and for branching and looping control structures within the graph in a manner similar to Naiad [36].", "startOffset": 229, "endOffset": 233}, {"referenceID": 43, "context": "In our distributed environment, these different tasks are containers in jobs managed by a cluster scheduling system [51].", "startOffset": 116, "endOffset": 120}, {"referenceID": 39, "context": "Many optimization algorithms, including common machine learning training algorithms like stochastic gradient descent [45], compute the gradient of a cost function with respect to a set of inputs.", "startOffset": 117, "endOffset": 121}, {"referenceID": 2, "context": "Much as in the dataflow-machine approach described by Arvind [3], we introduce a small set of primitive control flow operators into TensorFlow and generalize TensorFlow to handle cyclic dataflow graphs.", "startOffset": 61, "endOffset": 64}, {"referenceID": 3, "context": "The TensorFlow runtime implements a notion of tags and frames conceptually similar to the MIT TaggedToken machine [4].", "startOffset": 114, "endOffset": 117}, {"referenceID": 11, "context": "To handle this, we have implemented a common subexpression pass similar to the algorithm described by Click [12] that runs over the computation graph and canonicalizes multiple copies of operations with identical inputs and operation types to just a single one of these nodes, and redirects graph edges appropriately to reflect this canonicalization.", "startOffset": 108, "endOffset": 112}, {"referenceID": 14, "context": "For example, there are a number of optimized libraries for performing matrix multiplies on different devices, including BLAS [15] and cuBLAS [39], or GPU libraries for convolutional kernels for deep neural nets such as cuda-convnet [28] and cuDNN [9].", "startOffset": 125, "endOffset": 129}, {"referenceID": 33, "context": "For example, there are a number of optimized libraries for performing matrix multiplies on different devices, including BLAS [15] and cuBLAS [39], or GPU libraries for convolutional kernels for deep neural nets such as cuda-convnet [28] and cuDNN [9].", "startOffset": 141, "endOffset": 145}, {"referenceID": 8, "context": "For example, there are a number of optimized libraries for performing matrix multiplies on different devices, including BLAS [15] and cuBLAS [39], or GPU libraries for convolutional kernels for deep neural nets such as cuda-convnet [28] and cuDNN [9].", "startOffset": 247, "endOffset": 250}, {"referenceID": 13, "context": "In a manner similar to the DistBelief system [14], we often use lossy compression of higher precision internal representations when sending data between devices (sometimes within the same machine but especially across machine boundaries).", "startOffset": 45, "endOffset": 49}, {"referenceID": 21, "context": "The examples include models for classifying hand-written digits from the MNIST dataset (the \u201chello world\u201d of machine learning algorithms) [32], classifying images from the CIFAR10 dataset [30], doing language modeling using a recurrent LSTM [22] network, training word embedding vectors [35] and more.", "startOffset": 241, "endOffset": 245}, {"referenceID": 29, "context": "The examples include models for classifying hand-written digits from the MNIST dataset (the \u201chello world\u201d of machine learning algorithms) [32], classifying images from the CIFAR10 dataset [30], doing language modeling using a recurrent LSTM [22] network, training word embedding vectors [35] and more.", "startOffset": 287, "endOffset": 291}, {"referenceID": 13, "context": "We have quite a few machine learning models in our previous DistBelief system [14] that we have migrated over to TensorFlow.", "startOffset": 78, "endOffset": 82}, {"referenceID": 22, "context": "In particular, we focus on our lessons from porting a state-of-the-art convolutional neural network for image recognition termed Inception [23].", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "This asynchronous approach was also described in [14].", "startOffset": 49, "endOffset": 53}, {"referenceID": 40, "context": "Figure 8 shows an example of a recurrent, deep LSTM model used for sequence to sequence learning (see [47]), parallelized across three different devices.", "startOffset": 102, "endOffset": 106}, {"referenceID": 41, "context": "For example, the computation graph for training a model similar to Google\u2019s Inception model [48], a deep convolutional neural net that had the best classification performance in the ImageNet 2014 contest, has over 36,000 nodes in its TensorFlow computation graph, and some deep recurrent LSTM models for language modeling have more than 15,000 nodes.", "startOffset": 92, "endOffset": 96}, {"referenceID": 6, "context": "Theano [7], Torch [13], Caffe [26], Chainer [49] and the Computational Network Toolkit [54] are a few systems designed primarily for the training of neural networks.", "startOffset": 7, "endOffset": 10}, {"referenceID": 12, "context": "Theano [7], Torch [13], Caffe [26], Chainer [49] and the Computational Network Toolkit [54] are a few systems designed primarily for the training of neural networks.", "startOffset": 18, "endOffset": 22}, {"referenceID": 24, "context": "Theano [7], Torch [13], Caffe [26], Chainer [49] and the Computational Network Toolkit [54] are a few systems designed primarily for the training of neural networks.", "startOffset": 30, "endOffset": 34}, {"referenceID": 45, "context": "Theano [7], Torch [13], Caffe [26], Chainer [49] and the Computational Network Toolkit [54] are a few systems designed primarily for the training of neural networks.", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "The TensorFlow system shares some design characteristics with its predecessor system, DistBelief [14], and with later systems with similar designs like Project Adam [10] and the Parameter Server project [33].", "startOffset": 97, "endOffset": 101}, {"referenceID": 9, "context": "The TensorFlow system shares some design characteristics with its predecessor system, DistBelief [14], and with later systems with similar designs like Project Adam [10] and the Parameter Server project [33].", "startOffset": 165, "endOffset": 169}, {"referenceID": 34, "context": "The Halide system [40] for expressing image processing pipelines uses a similar intermediate representation to the TensorFlow dataflow graph.", "startOffset": 18, "endOffset": 22}, {"referenceID": 23, "context": "Dryad [24] and Flume [8] demonstrate how a complex workflow can be represented as a dataflow graph.", "startOffset": 6, "endOffset": 10}, {"referenceID": 7, "context": "Dryad [24] and Flume [8] demonstrate how a complex workflow can be represented as a dataflow graph.", "startOffset": 21, "endOffset": 24}, {"referenceID": 31, "context": "CIEL [37] and Naiad [36] introduce generic support for data-dependent control flow: CIEL represents iteration as a DAG that dynamically unfolds, whereas Naiad uses a static graph with cycles to support lower-latency iteration.", "startOffset": 5, "endOffset": 9}, {"referenceID": 30, "context": "CIEL [37] and Naiad [36] introduce generic support for data-dependent control flow: CIEL represents iteration as a DAG that dynamically unfolds, whereas Naiad uses a static graph with cycles to support lower-latency iteration.", "startOffset": 20, "endOffset": 24}, {"referenceID": 46, "context": "Spark [55] is optimized for computations that access the same data repeatedly, using \u201cresilient distributed datasets\u201d (RDDs), which are soft-state cached outputs of earlier computations.", "startOffset": 6, "endOffset": 10}, {"referenceID": 38, "context": "Dandelion [44] executes dataflow graphs across a cluster of heterogeneous devices, including GPUs.", "startOffset": 10, "endOffset": 14}], "year": 2016, "abstractText": "Mart\u0131\u0301n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Man\u00e9, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\u00e9gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng Google Research\u2217 Abstract", "creator": "LaTeX with hyperref package"}}}