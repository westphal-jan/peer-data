{"id": "1603.04779", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2016", "title": "Revisiting Batch Normalization For Practical Domain Adaptation", "abstract": "Deep neural networks (DNN) have shown unprecedented success in various computer vision applications such as image classification and object detection. However, it is still a common (yet inconvenient) practice to prepare at least tens of thousands of labeled image to fine-tune a network on every task before the model is ready to use. Recent study shows that a DNN has strong dependency towards the training dataset, and the learned features cannot be easily transferred to a different but relevant task without fine-tuning.", "histories": [["v1", "Tue, 15 Mar 2016 17:44:32 GMT  (1263kb,D)", "http://arxiv.org/abs/1603.04779v1", null], ["v2", "Wed, 16 Mar 2016 03:57:19 GMT  (1263kb,D)", "http://arxiv.org/abs/1603.04779v2", null], ["v3", "Wed, 21 Sep 2016 08:41:43 GMT  (1223kb,D)", "http://arxiv.org/abs/1603.04779v3", null], ["v4", "Tue, 8 Nov 2016 06:11:30 GMT  (6116kb,D)", "http://arxiv.org/abs/1603.04779v4", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["yanghao li", "naiyan wang", "jianping shi", "jiaying liu", "xiaodi hou"], "accepted": false, "id": "1603.04779"}, "pdf": {"name": "1603.04779.pdf", "metadata": {"source": "CRF", "title": "Revisiting Batch Normalization For Practical Domain Adaptation", "authors": ["Yanghao Li", "Naiyan Wang", "Jianping Shi", "Jiaying Liu", "Xiaodi Hou"], "emails": ["lyttonhao@pku.edu.cn", "winsty@gmail.com", "shijianping5000@gmail.com", "liujiaying@pku.edu.cn", "xiaodi.hou@gmail.com"], "sections": [{"heading": null, "text": "Keywords: domain customization; batch normalization"}, {"heading": "1 Introduction", "text": "In fact, it is as if you can borrow the training data from an existing data set, or query images from the Internet, which often differ from the target domain. (...) In fact, the approaches differ from the target domain. (...) In fact, the approaches differ from the target domain. (...) In fact, it is as if the approaches differ from the target domain. (...) It is as if they differ from the target domain. (...) It is as if the approaches differ from the target domain. (...) It is as if the views differ from the target domain. (...) It is as if they differ from the target domain. (...) It is as if they are derived from the target domain. (...) It is as if they are derived from the target domain. (...)"}, {"heading": "2 Related Work", "text": "In more recent literature, domain transfer has gained increasing attention [8,9]. Often referred to as covariance shift [10] or dataset bias [3], this problem poses a major challenge to the generalizability of a learned model. A key component of domain transfer is modelling the difference between source and target distributions. In [11], authors assign an explicit bias vector to each dataset and train a discriminatory model to handle multiple classification problems with different bias terms. However, a more explicit method for calculating the target difference is based on Maximum Mean Discrepancy [12]. It uses a non-linear mapping to project each data sample into a project that Hilbert Space will reproduce and then calculate the difference between the sample media. To reduce dataset discrepancies, many methods are proposed, including sample selection of project directions, Axial-Expect-Axial-Axial-Principle-Principle-Principle-Principle-Principle-Principle-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Principle-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print-Print"}, {"heading": "2.1 Batch Normalization Revisited", "text": "In this section, we briefly consider the batch normalization (BN) [2], which is closely related to our AdaBN. Originally, the BN layer was designed to alleviate the problem of internal covariance shift - a common problem while training a very deep neural network. It first standardizes each feature in a mini-batch and then learns a common inclination and distortion for each mini-batch. Formally, the BN layer transforms a feature j [1] into a BN layer X-Rn \u00d7 p, where n denotes the batch size, and p is the feature dimension, the BN layer transforms a feature j {1.... p} in: x-j = xj \u2212 E [X \u00b7 j] \u221a Var [X \u00b7 j] yj + \u03b2j, (1) where xj and yj represent the input / output scalars of a neuron reaction in a data sample, X \u00b7 j-j, leading to a variant."}, {"heading": "3 The Model", "text": "In this section, we first analyze the domain shift in the deep neural network and present two central observations in paragraph 3.1. Then, in paragraph 3.2, we present our method of Adaptive Batch Normalization (AdaBN) based on these observations. Finally, we analyze our method in paragraph 3.3. Revisiting Batch Normalization For Practical Domain Adaptation 5."}, {"heading": "3.1 A Pilot Experiment", "text": "Although batch normalization (BN) was originally proposed to support SGD optimization, its core idea is to align training data from different distributions. From this perspective, it is interesting to examine the BN parameters (batch-by-batch mean and variance) across different datasets at different levels of the network.In this pilot, we are using the MXNet implementation [27] of the InceptionBN model [2], which was previously trained as our DNN base model on an ImageNet classification task [28].Our image data comes from [29], which contains the same image classes of Caltech 256 dataset [30] and Bing image search results. For each mini batch sampled from a dataset, we first select a layer and then combine the mean and variance of each neuron to form a feature vector."}, {"heading": "3.2 Adaptive Batch Normalization", "text": "Given the pre-trained DNN model and a target domain, our Adaptive Batch Normalization (AdaBN) algorithm is as follows: Algorithm 1 Adaptive Batch Normalization (AdaBN) for Neuron j in DNN, Image m in Target Domain do concatenate neuron responses on all images of the target domain: xj = [xj (m),..] Calculate the mean and variance of the target domain: \u00b5tj = E (xtj), \u03c3tj = \u221a Var (xtj). End for Neuron j in DNN, test image m in target domain doCompute BN output yj (m): = \u03b3j (xj (m) \u2212 \u00b5tj) \u03c3tj + \u03b2jend forThe intuition behind our method is very simple: Standardizing each layer by domain ensures that each layer receives data from a similar distribution, whether source domain or target domain."}, {"heading": "3.3 Further thoughts about AdaBN", "text": "As we all know, neural networks are highly nonlinear composite functions. Consider a simple neural network with input size x-Rp1 \u00d7 1. It has a BN layer with mean and variance of each characteristic as \u00b5i and \u03c3 2 i, a fully connected layer with weight matrix W-Rp1 \u00d7 p2 and bias b-Rp2 \u00d7 1, and a nonlinear transformation layer f (\u00b7). The output of this network is f (WTa x + b \u2032 a), with Wa = W-T\u0440 \u2212 1, ba = \u2212 WT\u0440 \u2212 1\u00b5 + b, \u03a3 = diag (\u03c321,..., \u03c3 2 p1), \u00b5 = (\u00b51, \u00b5p1). (2) 1 In practice, we adopt an online algorithm to efficiently estimate the averages and variances."}, {"heading": "4 Experiments", "text": "In this section we show the effectiveness of AdaBN on standard domain adaptation data sets and analyze the adapted features empirically."}, {"heading": "4.1 Experimental Settings", "text": "We first set our experimental settings on two standard datasets: Office [33] and Caltech-Bing [29], some baselines and the configurations of our experiments. Office [33] is a standard benchmark for domain adaptation, which is a collection of 4652 images in 31 classes from three different domains: Amazon (A), DSRL (D) and Webcam (W). We evaluate all six adjustment tasks in our experiments, which are often taken over by other domain adaptation methods [4,24,5]. For multi-source domain adaptation, we evaluate our method on the three transfer tasks (A, W)."}, {"heading": "4.2 Results", "text": "Office Dataset We report our results on Office in the individual and multiple source settings in Table 1 and Table 2. Note that the models in the first part of Table 1 are preschooled on AlexNet [34] instead of the Inception-BN [2] model, since there is no public pre-trained Inception-BN model in Caffe [35]. Therefore, the absolute number cannot be directly compared, the relative improvements over Baseline are a more reasonable metric. From Table 1, we first note that the Inception-BN [2] model actually improves over the AlexNet model [34], which means that the CNN preschooled on ImageNet actually learns general features that improvements over ImageNet technology can apply to new tasks. Among the methods based on Inception-BN functions, our method improves most over the baseline, which validates the need for deep customization. Furthermore, since our method is complementary to other features, we simply apply to the CORAL features."}, {"heading": "4.3 Empirical Analysis", "text": "In this section, we conduct two experiments to empirically analyze the characteristics that have been adapted by our method and another experiment to illustrate how the number of samples in the target domain affects performance. Visualization of the characteristics. We first visualize the characteristics of the last layer before and after the fit using t-SNE [31] in Fig. 3. We select two adjustment settings for visualization: Amazon to Webcam and Amazon to DSLR. Each red circle represents a training sample, while each blue circle represents a test sample. We can see that after the fit, the characteristics of the test data are blended more evenly with the training data compared to those without the fit. In other words, the distribution of the test samples is more consistent with the training sample. This intuitive illustration confirms once again that our method is effective against domain shift.Revisited Batch Normalization For Practical Domain Adaptation 11Analysis of Fevergence."}, {"heading": "5 Conclusion and Future Works", "text": "In this article, we have described a stunningly simple but effective approach to domain customization for batch normalized neural networks. We have taken advantage of another functionality of the BN layer: domain customization. The basic idea is to replace the statistics of each BN layer in the source domain Revisiting Batch Normalization For Practical Domain Adaptation 13 with that of the target domain. Therefore, the proposed method is easy to implement and parameter-free, and it requires almost no effort to extend it to multiple source domains and semi-monitored settings. Furthermore, our method is not sensitive to the size of the target domain, making it more advantageous for practitioners compared to other methods of deep learning-based domain customization. Finally, we have tested our method on standard benchmarks. Our method established new state-of-the-art results on both single source domains as well as on multiple domains, and we believe that our main method opens up a new pathway for loss of our main domains."}], "references": [{"title": "A deeper look at dataset bias", "author": ["T. Tommasi", "N. Patricia", "B. Caputo", "T. Tuytelaars"], "venue": "arXiv preprint arXiv:1505.01257", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "ICML.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Unbiased look at dataset bias", "author": ["A. Torralba", "A.A. Efros"], "venue": "CVPR.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep domain confusion: Maximizing for domain invariance", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "arXiv preprint arXiv:1412.3474", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning transferable features with deep adaptation networks", "author": ["M. Long", "Y. Cao", "J. Wang", "M. Jordan"], "venue": "ICML.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Simultaneous deep transfer across domains and tasks", "author": ["E. Tzeng", "J. Hoffman", "T. Darrell", "K. Saenko"], "venue": "ICCV.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "ICML.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain adaptations for computer vision applications", "author": ["O. Beijbom"], "venue": "arXiv preprint arXiv:1211.4860", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Visual domain adaptation: A survey of recent advances", "author": ["V.M. Patel", "R. Gopalan", "R. Li", "R. Chellappa"], "venue": "IEEE Signal Processing Magazine 32(3)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "author": ["H. Shimodaira"], "venue": "Journal of statistical planning and inference 90(2)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "Undoing the damage of dataset bias", "author": ["A. Khosla", "T. Zhou", "T. Malisiewicz", "A.A. Efros", "A. Torralba"], "venue": "ECCV. Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Sch\u00f6lkopf", "A. Smola"], "venue": "The Journal of Machine Learning Research 13(1)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A. Gretton", "K.M. Borgwardt", "B. Sch\u00f6lkopf", "A.J. Smola"], "venue": "NIPS.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation", "author": ["B. Gong", "K. Grauman", "F. Sha"], "venue": "ICML.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "IEEE Transactions on Neural Networks 22(2)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "ICCV.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Unsupervised domain adaptation by domain invariant projection", "author": ["M. Baktashmotlagh", "M. Harandi", "B. Lovell", "M. Salzmann"], "venue": "ICCV.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised visual domain adaptation using subspace alignment", "author": ["B. Fernando", "A. Habrard", "M. Sebban", "T. Tuytelaars"], "venue": "ICCV.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "CVPR.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "How transferable are features in deep neural networks? In: NIPS", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "DeCAF: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "ICML.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "DLID: Deep learning for domain adaptation by interpolating between domains", "author": ["S. Chopra", "S. Balakrishnan", "R. Gopalan"], "venue": "ICML Workshop on Challenges in Representation Learning. Volume 2.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Domain adaptive neural networks for object recognition", "author": ["M. Ghifary", "W.B. Kleijn", "M. Zhang"], "venue": "PRICAI 2014: Trends in Artificial Intelligence.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Return of frustratingly easy domain adaptation", "author": ["B. Sun", "J. Feng", "K. Saenko"], "venue": "arXiv preprint arXiv:1511.05547", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Rethinking the inception architecture for computer vision", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": "arXiv preprint arXiv:1512.00567", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "MXNet: A flexible and efficient machine learning library for heterogeneous distributed systems", "author": ["T. Chen", "M. Li", "Y. Li", "M. Lin", "N. Wang", "M. Wang", "T. Xiao", "B. Xu", "C. Zhang", "Z. Zhang"], "venue": "arXiv preprint arXiv:1512.01274", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "ImageNet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M Bernstein"], "venue": "International Journal of Computer Vision 115(3)", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach", "author": ["A. Bergamo", "L. Torresani"], "venue": "NIPS.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Caltech-256 object category dataset", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Visualizing data using t-sne", "author": ["L. Van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research 9(2579-2605)", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "The art of computer programming", "author": ["E.K. Donald"], "venue": "Sorting and searching 3", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1999}, {"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "ECCV.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "ACM MM.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Recent study [1] shows that a DNN has strong dependency towards the training dataset, and the learned features cannot be easily transferred to a different but relevant task without fine-tuning.", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "Our approach is based on the well-known Batch Normalization technique [2] which has become a standard component in modern deep learning.", "startOffset": 70, "endOffset": 73}, {"referenceID": 2, "context": "These approaches usually suffer from inferior performance due to dataset discrepancies, or \u201cdataset bias\u201d, because 1) the distributions of the source domains (third party datasets or Internet images) are often different from the target domain (testing images); and 2) DNN is particularly good at capturing dataset bias in its internal representation [3], which eventually leads to overfitting.", "startOffset": 350, "endOffset": 353}, {"referenceID": 3, "context": "Known as domain adaptation, the effort to bridge the gap between training and testing data distribution has been discussed several times under the context of deep learning [4,5,6,7].", "startOffset": 172, "endOffset": 181}, {"referenceID": 4, "context": "Known as domain adaptation, the effort to bridge the gap between training and testing data distribution has been discussed several times under the context of deep learning [4,5,6,7].", "startOffset": 172, "endOffset": 181}, {"referenceID": 5, "context": "Known as domain adaptation, the effort to bridge the gap between training and testing data distribution has been discussed several times under the context of deep learning [4,5,6,7].", "startOffset": 172, "endOffset": 181}, {"referenceID": 6, "context": "Known as domain adaptation, the effort to bridge the gap between training and testing data distribution has been discussed several times under the context of deep learning [4,5,6,7].", "startOffset": 172, "endOffset": 181}, {"referenceID": 7, "context": "Domain transfer in visual recognition tasks has gained increasing attention in recent literature [8,9].", "startOffset": 97, "endOffset": 102}, {"referenceID": 8, "context": "Domain transfer in visual recognition tasks has gained increasing attention in recent literature [8,9].", "startOffset": 97, "endOffset": 102}, {"referenceID": 9, "context": "Often referred as covariance shift [10] or dataset bias [3], this problem poses great challenge to the generalization ability of a learned model.", "startOffset": 35, "endOffset": 39}, {"referenceID": 2, "context": "Often referred as covariance shift [10] or dataset bias [3], this problem poses great challenge to the generalization ability of a learned model.", "startOffset": 56, "endOffset": 59}, {"referenceID": 10, "context": "In [11], the authors assign each dataset with an explicit bias vector, and train one discriminative model to handle multiple classification problems with different bias terms.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "A more explicit way to compute dataset difference is based on Maximum Mean Discrepancy [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 88, "endOffset": 95}, {"referenceID": 13, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 88, "endOffset": 95}, {"referenceID": 14, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 126, "endOffset": 136}, {"referenceID": 15, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 126, "endOffset": 136}, {"referenceID": 16, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 126, "endOffset": 136}, {"referenceID": 17, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 166, "endOffset": 173}, {"referenceID": 18, "context": "To reduce dataset discrepancies, many methods are proposed, including sample selections [13,14], explicit projection learning [15,16,17] and principal axes alignment [18,19].", "startOffset": 166, "endOffset": 173}, {"referenceID": 19, "context": "In the field of deep learning, feature transferability across different domains is a tantalizing yet generally unsolved topic [20,1].", "startOffset": 126, "endOffset": 132}, {"referenceID": 0, "context": "In the field of deep learning, feature transferability across different domains is a tantalizing yet generally unsolved topic [20,1].", "startOffset": 126, "endOffset": 132}, {"referenceID": 20, "context": "To transfer the learned representations to a new dataset, pre-training and fine-tuning [21] have become de facto procedures.", "startOffset": 87, "endOffset": 91}, {"referenceID": 21, "context": "Early works of domain adaptation either focus on reordering fine-tuning samples [22], or regularizing MMD [12] in a shallow network [23].", "startOffset": 80, "endOffset": 84}, {"referenceID": 11, "context": "Early works of domain adaptation either focus on reordering fine-tuning samples [22], or regularizing MMD [12] in a shallow network [23].", "startOffset": 106, "endOffset": 110}, {"referenceID": 22, "context": "Early works of domain adaptation either focus on reordering fine-tuning samples [22], or regularizing MMD [12] in a shallow network [23].", "startOffset": 132, "endOffset": 136}, {"referenceID": 3, "context": "[4] used the classical MMD loss to regularize the representation in the last layer of CNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] further extend the method to multiple kernel MMD and multiple layer adaptation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] devised a gradient reverse layer to reverse the gradient that helps to distinguish the domains of each data sample.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] proposed to simultaneously transfer task correlations and maximize domain confusion for (semi)-supervised domain adaptation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "Another related work is CORAL [24].", "startOffset": 30, "endOffset": 34}, {"referenceID": 1, "context": "In this section, we briefly review Batch Normalization(BN) [2] which is closely related to our AdaBN.", "startOffset": 59, "endOffset": 62}, {"referenceID": 24, "context": "BN layer has become a standard component in recent top-performing CNN architectures, such as deep residual network [25], and Inception V3 [26].", "startOffset": 115, "endOffset": 119}, {"referenceID": 25, "context": "BN layer has become a standard component in recent top-performing CNN architectures, such as deep residual network [25], and Inception V3 [26].", "startOffset": 138, "endOffset": 142}, {"referenceID": 26, "context": "In this pilot experiment, we use MXNet implementation [27] of the InceptionBN model [2] pre-trained on ImageNet classification task [28] as our baseline DNN model.", "startOffset": 54, "endOffset": 58}, {"referenceID": 1, "context": "In this pilot experiment, we use MXNet implementation [27] of the InceptionBN model [2] pre-trained on ImageNet classification task [28] as our baseline DNN model.", "startOffset": 84, "endOffset": 87}, {"referenceID": 27, "context": "In this pilot experiment, we use MXNet implementation [27] of the InceptionBN model [2] pre-trained on ImageNet classification task [28] as our baseline DNN model.", "startOffset": 132, "endOffset": 136}, {"referenceID": 28, "context": "Our image data are drawn from [29], which contains the same classes of images from both Caltech-256 dataset [30] and Bing image search results.", "startOffset": 30, "endOffset": 34}, {"referenceID": 29, "context": "Our image data are drawn from [29], which contains the same classes of images from both Caltech-256 dataset [30] and Bing image search results.", "startOffset": 108, "endOffset": 112}, {"referenceID": 30, "context": "t-SNE [31] visualization of the mini-batch BN feature vector distributions in both shallow and deep layers, across different datasets.", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "1 In practice we adopt an online algorithm [32] to efficiently estimate the mean and variance.", "startOffset": 43, "endOffset": 47}, {"referenceID": 23, "context": "Another question is why we transform the neuron responses independently, not decorrelate and then re-correlate the responses as suggested in [24].", "startOffset": 141, "endOffset": 145}, {"referenceID": 32, "context": "We first introduce our experimental settings on two standard datasets: Office [33] and Caltech-Bing [29], some baselines and the configurations of our experiments.", "startOffset": 78, "endOffset": 82}, {"referenceID": 28, "context": "We first introduce our experimental settings on two standard datasets: Office [33] and Caltech-Bing [29], some baselines and the configurations of our experiments.", "startOffset": 100, "endOffset": 104}, {"referenceID": 32, "context": "Office [33] is a standard benchmark for domain adaptation, which is a collection of 4652 images in 31 classes from three different domains: Amazon(A), DSRL(D) and Webcam(W).", "startOffset": 7, "endOffset": 11}, {"referenceID": 3, "context": "We evaluate all the six adaptation tasks in our experiments, which are commonly adopted by other domain adaptation methods [4,24,5].", "startOffset": 123, "endOffset": 131}, {"referenceID": 23, "context": "We evaluate all the six adaptation tasks in our experiments, which are commonly adopted by other domain adaptation methods [4,24,5].", "startOffset": 123, "endOffset": 131}, {"referenceID": 4, "context": "We evaluate all the six adaptation tasks in our experiments, which are commonly adopted by other domain adaptation methods [4,24,5].", "startOffset": 123, "endOffset": 131}, {"referenceID": 28, "context": "Caltech-Bing [29] is a much larger domain adaptation dataset, which contains 30,607 and 121,730 images in 256 categories from two domains Caltech256(C) and Bing(B), respectively.", "startOffset": 13, "endOffset": 17}, {"referenceID": 17, "context": "We compare our method with a variety of methods, including three shallow methods: SA [18], GFK [19], CORAL [24], and three deep methods: DDC [4], DAN [5], RevGrad [7].", "startOffset": 85, "endOffset": 89}, {"referenceID": 18, "context": "We compare our method with a variety of methods, including three shallow methods: SA [18], GFK [19], CORAL [24], and three deep methods: DDC [4], DAN [5], RevGrad [7].", "startOffset": 95, "endOffset": 99}, {"referenceID": 23, "context": "We compare our method with a variety of methods, including three shallow methods: SA [18], GFK [19], CORAL [24], and three deep methods: DDC [4], DAN [5], RevGrad [7].", "startOffset": 107, "endOffset": 111}, {"referenceID": 3, "context": "We compare our method with a variety of methods, including three shallow methods: SA [18], GFK [19], CORAL [24], and three deep methods: DDC [4], DAN [5], RevGrad [7].", "startOffset": 141, "endOffset": 144}, {"referenceID": 4, "context": "We compare our method with a variety of methods, including three shallow methods: SA [18], GFK [19], CORAL [24], and three deep methods: DDC [4], DAN [5], RevGrad [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 6, "context": "We compare our method with a variety of methods, including three shallow methods: SA [18], GFK [19], CORAL [24], and three deep methods: DDC [4], DAN [5], RevGrad [7].", "startOffset": 163, "endOffset": 166}, {"referenceID": 20, "context": "We follow the full protocol [21] for the single source setting; while for multiple sources setting, we use all the samples in the source domains as training data, and use all the samples in the target domain as testing data.", "startOffset": 28, "endOffset": 32}, {"referenceID": 1, "context": "We fine-tune the Inception-BN [2] model on source domain in each task for 100 epochs.", "startOffset": 30, "endOffset": 33}, {"referenceID": 4, "context": "Since the office dataset is quite small, following the best practice in [5], we freeze the first three groups of Inception modules, and set the learning rate of fourth and fifth group one tenth of the base learning rate to avoid overfitting.", "startOffset": 72, "endOffset": 75}, {"referenceID": 33, "context": "Note that the models in the first part of the Table 1 are pre-trained on AlexNet [34] instead of the Inception-BN [2] model, because there is no public pre-trained Inception BN model in Caffe [35].", "startOffset": 81, "endOffset": 85}, {"referenceID": 1, "context": "Note that the models in the first part of the Table 1 are pre-trained on AlexNet [34] instead of the Inception-BN [2] model, because there is no public pre-trained Inception BN model in Caffe [35].", "startOffset": 114, "endOffset": 117}, {"referenceID": 34, "context": "Note that the models in the first part of the Table 1 are pre-trained on AlexNet [34] instead of the Inception-BN [2] model, because there is no public pre-trained Inception BN model in Caffe [35].", "startOffset": 192, "endOffset": 196}, {"referenceID": 1, "context": "From Table 1, we first notice that the Inception BN [2] model indeed improves over the AlexNet [34] model on average, which means that the CNN pre-trained on ImageNet indeed learns general features, the improvements on ImageNet can be transferred on new tasks.", "startOffset": 52, "endOffset": 55}, {"referenceID": 33, "context": "From Table 1, we first notice that the Inception BN [2] model indeed improves over the AlexNet [34] model on average, which means that the CNN pre-trained on ImageNet indeed learns general features, the improvements on ImageNet can be transferred on new tasks.", "startOffset": 95, "endOffset": 99}, {"referenceID": 33, "context": "AlexNet [34] 61.", "startOffset": 8, "endOffset": 12}, {"referenceID": 3, "context": "1 DDC [4] 61.", "startOffset": 6, "endOffset": 9}, {"referenceID": 4, "context": "DAN [5] 68.", "startOffset": 4, "endOffset": 7}, {"referenceID": 6, "context": "9 RevGrad [7] 67.", "startOffset": 10, "endOffset": 13}, {"referenceID": 1, "context": "Inception BN [2] 70.", "startOffset": 13, "endOffset": 16}, {"referenceID": 17, "context": "5 SA [18] 69.", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "GFK [19] 66.", "startOffset": 4, "endOffset": 8}, {"referenceID": 23, "context": "7 CORAL [24] 70.", "startOffset": 8, "endOffset": 12}, {"referenceID": 32, "context": "Single source domain adaptation results on Office-31 [33] dataset with standard unsupervised adaptation protocol.", "startOffset": 53, "endOffset": 57}, {"referenceID": 1, "context": "Inception BN [2] 90.", "startOffset": 13, "endOffset": 16}, {"referenceID": 23, "context": "CORAL [24] 92.", "startOffset": 6, "endOffset": 10}, {"referenceID": 32, "context": "Multi-source domain adaptation results on Office-31 [33] dataset with stan-", "startOffset": 52, "endOffset": 56}, {"referenceID": 1, "context": "Inception BN [2] 35.", "startOffset": 13, "endOffset": 16}, {"referenceID": 23, "context": "CORAL [24] 35.", "startOffset": 6, "endOffset": 10}, {"referenceID": 28, "context": "Single source domain adaptation results on Caltech-Bing [29] dataset.", "startOffset": 56, "endOffset": 60}, {"referenceID": 30, "context": "We first visualize the features of the last layer before and after adaptation using t-SNE [31] in Fig.", "startOffset": 90, "endOffset": 94}], "year": 2016, "abstractText": "Deep neural networks (DNN) have shown unprecedented success in various computer vision applications such as image classification and object detection. However, it is still a common (yet inconvenient) practice to prepare at least tens of thousands of labeled image to finetune a network on every task before the model is ready to use. Recent study [1] shows that a DNN has strong dependency towards the training dataset, and the learned features cannot be easily transferred to a different but relevant task without fine-tuning. In this paper, we propose a simple yet powerful remedy, called Adaptive Batch Normalization(AdaBN), to increase the generalization ability of a DNN. Our approach is based on the well-known Batch Normalization technique [2] which has become a standard component in modern deep learning. In contrary to other deep learning domain adaptation methods, our method does not require additional components, and is parameterfree. It archives state-of-the-art performance despite its surprising simplicity. Furthermore, we demonstrate that our method is complementary with other existing methods. Combining AdaBN with existing domain adaptation treatments may further improve model performance.", "creator": "LaTeX with hyperref package"}}}