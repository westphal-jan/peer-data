{"id": "1603.06265", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2016", "title": "Collaborative prediction with expert advice", "abstract": "We consider a collaborative variant of prediction with expert advice. In each round, one user wishes to make a prediction, and must choose which expert to follow. The users would like to share their experiences in order to learn faster--ideally they could amortize the same total regret cross the whole community of users. However, some of the users may behave maliciously, distorting their reported payoffs in order to manipulate the honest users of the system. And even if all users behave honestly, different experts may perform better for different users, such that sharing data can be counterproductive.", "histories": [["v1", "Sun, 20 Mar 2016 20:34:32 GMT  (14kb)", "http://arxiv.org/abs/1603.06265v1", null], ["v2", "Wed, 6 Apr 2016 20:41:12 GMT  (22kb)", "http://arxiv.org/abs/1603.06265v2", null], ["v3", "Fri, 8 Apr 2016 00:36:06 GMT  (22kb)", "http://arxiv.org/abs/1603.06265v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["paul christiano"], "accepted": false, "id": "1603.06265"}, "pdf": {"name": "1603.06265.pdf", "metadata": {"source": "CRF", "title": "Robust Collaborative Online Learning", "authors": ["Paul Christiano"], "emails": ["paulfchristiano@eecs.berkeley.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.06 265v 1 [cs.L GWe presents a robust collaborative prediction algorithm with expert advice that guarantees that each subset of users performs H almost as well as if they had shared all their data, ignoring all data from users outside H. This algorithm limits the damage that dishonest users suffer from O (\u221a T) compared to the O (T) that we would achieve through naive aggregation of data. We also extend our results to general online convective optimization. The resulting algorithm achieves little remorse but is mathematically insolvable, showing that there is no statistical obstacle to generating robust collaborative online learning, but leaves the design of more efficient algorithms as an open problem."}, {"heading": "1 Introduction", "text": "Modern machine learning systems often aggregate data from many users. This facilitates rapid learning, but automatically leaves these systems vulnerable to manipulation by malicious users. Traditional results in learning theory give very weak guarantees about robustness to manipulation. This is not an abstract concern. Machine learning systems are used to make a number of economically significant decisions, from aggregated assessments that shape what we buy to search rankings that shape what we read, and the incentives to manipulate those systems can be very strong. We consider a collaborative version of prediction with expert advice, a fundamental problem in online learning. In our collaborative formulation, each round involves a specific user who can make a decision based on all the information reported by users in previous rounds. We want to guarantee that each group of users performs relatively well. That is, if we choose an arbitrary subset H of users, and limit our attention to the overall number of users that comprise one."}, {"heading": "1.1 Our model", "text": "In this section, we present our model for online optimization. (...) We assume that the losses in [\u2212 1, 1]. Online optimization includes a forecast with expert advice as a special case. (...) We consider only the decision-theoretical framework for predicting with expert advice ([7]). This is the special case of online optimization, where S is the number of probability distributions over a finite group of \"experts\" X, and the loss functions have no form that matches the form of the prediction (p) x x x x x x px. We imagine ourselves in the position of a central recommendation service that must give advice to some specified users U. (...) We make our decisions in a sequence of rounds, t = 2., T."}, {"heading": "1.2 Our contributions", "text": "Prediction with expert advice: For predictions with expert advice, we have a transformation that introduces additional regrets about the conversion of O (msv) (msv).The most important technical idea is to reverse the relationship between experts and users: instead of the experts always advising RT, we need to teach each expert which user to advise ([8]).The goal of the expert is to offer advice when and only if their advice is helpful. The resulting experts are \"specialists\" who sometimes forgo advice, and we can use a standard method to compete with the best specialist (8]. By improving the learning algorithm used by the experts, we can significantly improve this limit when there are either few or many malicious users. \u2212 For example, when only a fraction of users are malicious (or honest), and only a fraction of users are malicious."}, {"heading": "1.3 Related work", "text": "Common Filtering: In the collaborative filtering problem, a set of users interact with a set of resources and exploit their common taste to more efficiently predict which resources each of them will highly value. This problem has been extensively studied; see ([12]) for an overview. A wide range of theoretical models for this problem have been studied ([1], [9], [2], [6]). Our work differs from this literature in two ways. First, we focus on achieving very strong robustness and non-manipulability without sacrificing statistical efficiency. Second, we look at the general problem of predicting with expert advice, rather than predicting which resources a user will highly value. As a result, we need completely different techniques. Robust collaborative filtering is the most closely related work. ([5]) Their results fit into our model of robust collaborative learning, but they investigate another problem (a particular model of collaborative filtering, we have different technical problems)."}, {"heading": "2 Preliminaries: learning algorithms as sub-", "text": "RoutinesOur results are transformations, from single-user learning algorithms to collaborative versions.We are the output of the converted algorithm inviting multiple learning algorithms as subroutines, (one of which is the algorithm PEA or OCO that we are transforming to a collaborative version).We will typically use the Roman letters A, B, C,.. to represent these subroutines, each of them will solve an independent learning problem. The \"outer\" learning problem we are trying to solve the results in a series of rounds t = 1, 2,., T,... In general, the \"inner\" learning problems will progress more slowly; some, but not all subroutines will makea prediction and receive a loss function in each round of the outer learning problem. We say that a subroutines is \"active\" in a given round of the output and receives a loss."}, {"heading": "3 Collaborative prediction with expert ad-", "text": "viceRecall the model discussed in section 1.1. N = | U | is the number of users. We will be given an algorithm PEA for the single user case, with regret RT (PEA), and show a protocol PEA with the following guarantee: Theorem 1. Let H be any set of users. Then PEA meets the stronger limits: H \u2264 T \u2264 OPTH \u2264 OPTH \u2264 T + RT (PEA) + O (TTHN | H | log (TTHN | H |) and TS = | {t \u2264 T: ut S} |, then PEA satisfies the stronger limits: H \u2264 T \u2264 OPTH \u2264 OPTH \u2264 T + RT (PEA) + O (TH | H | log (TTHN | H | H |) and H \u2264 T \u2264 T + RT (PEA) + O (PEA) and isest (TTDN | D | D | D | hihihiv)."}, {"heading": "It also satisfies the stronger bound:", "text": "In our result for online convex optimization, we get a similar limit of remorse, which depends on mRT / m (PEA) and not on mRT (PEA). However, the algorithm that reaches this limit is not efficient. We leave closing this gap as an open problem. The most likely approach is to replace the term RT (PEA) in Theorem 1 with RTH (PEA)."}, {"heading": "3.1 Basic algorithm", "text": "The full algorithm for which we will prove theorem 1 is discussed in the next section and analyzed in annex B. (For each x-X round and each round t we calculate an quantity that reflects the probability of reflexes that experts x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-"}, {"heading": "3.2 Improving the algorithm", "text": "In the previous algorithm, the experts treat each user as a separate learning problem. We can improve the algorithm by letting the experts learn what percentage of users are honest, rather than implicitly assuming that half of all users are honest. We are introducing a new learning algorithm to solve a simultaneous prediction with an expert advice problem for each user. We are imagining a separate learning problem for each user by specifying which learning problem will occur in Round T. Instead of simply using an independent prediction of strabismus for each user, we are learning a parameter that reflects a previous distribution over {0, 1}. In Appendix B, we are defining a separate learning problem for each user, specifying which learning problem will occur in Round T. Instead of simply using an independent prediction of strabismus for each user, we are learning a parameter that reflects a previous distribution over {0, 1}."}, {"heading": "4 Online convex optimization", "text": "In this section we present a general method for converting an online optimization algorithm into a collaborative version (SO). Both algorithms optimize using a standard algorithm for the sleep experts to aggregate these different OCO instances; the experts are exactly the ones that correspond to sets, the ut.A (2U), where 2U is the power quantity of U, with a standard algorithm for the sleep experts to aggregate these different OCO instances; for the experts, exactly the sets that correspond to ut.A (2U), where 2U is the power quantity of U, are with A0 (S) = p (S), for S U do BS () OCO (); end for t = 1, 2,. do Observe ut ut ut ut ut ut ut ut ut ut ut ut ut ut.U; Wt: ut S: ut S (S); Play pt = S U: ut S U: ut S U (S)."}, {"heading": "5 Open questions", "text": "The robust collaborative learning framework provides a general transformation from a single-user learning problem to robust collaborative learning problems. We have answered a few basic questions, but we leave much more open. \u2022 Efficient online convex optimization. Our online convex optimization algorithm is insoluble. Although such a general transformation is impossible, we can aim for efficient algorithms for a broader range of online convex optimization problems, such as online learning about combinatorial structures. \u2022 Exploitation of user information. Our additional regret depends on a quantity such as | H, which reflects the previous probability of the H set under an appropriate distribution. If we can find a better probability distribution over subsets that potentially exploits other available information about users, then the statistically optimal additional regret of p (H) as an example."}, {"heading": "A Defining A\u03b8", "text": "(...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...)) (...) (...) (...) (...)) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (... (...) (...) (...) (...) (... (...) (...) (...) (...) (...) (... (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) ("}, {"heading": "B Proof of Theorem 1", "text": "The PEA algorithm is defined in Figure 4. The algorithm is exactly analogous to the algorithms in Section 3.1, and its analysis is exactly parallel to the analyses in this section."}], "references": [{"title": "Tell me who I am: An interactive recommendation system", "author": ["Alon", "Awerbuch", "Azar", "Patt-Shamir"], "venue": "In SPAA: Annual ACM Symposium on Parallel Algorithms and Architectures", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Collaborate with strangers to find own preferences", "author": ["Awerbuch", "Azar", "Lotker", "Patt-Shamir", "Tuttle"], "venue": "MST: Mathematical Systems Theory", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Competitive collaborative learning", "author": ["Awerbuch", "Kleinberg"], "venue": "In COLT: Proceedings of the Workshop on Computational Learning Theory, Morgan Kaufmann Publishers", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Can machine learning be secure", "author": ["M. Barreno", "B. Nelson", "R. Sears", "A.D. Joseph", "J.D. Tygar"], "venue": "In Proceedings of the 2006 ACM Symposium on Information, Computer and Communications Security (New York, NY, USA,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Provably manipulation-resistant reputation systems", "author": ["P. Christiano"], "venue": "CoRR abs/1411.1127", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Competitive recommendation systems", "author": ["Drineas", "Kerenidis", "Raghavan"], "venue": "In STOC: ACM Symposium on Theory of Computing (STOC)", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Freund", "Schapire"], "venue": "JCSS: Journal of Computer and System Sciences", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "Using and combining predictors that specialize", "author": ["Freund", "Schapire", "Singer", "Warmuth"], "venue": "In STOC: ACM Symposium on Theory of Computing (STOC)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Near-optimal algorithms for online matrix prediction", "author": ["E. Hazan", "S. Kale", "S. Shalev-Shwartz"], "venue": "CoRR abs/1204.0136", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Second-order quantile methods for experts and combinatorial games", "author": ["W.M. Koolen", "T. van Erven"], "venue": "CoRR abs/1502.08009", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Online learning and online convex optimization", "author": ["S. Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning 4,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}], "referenceMentions": [{"referenceID": 10, "context": "Online convex optimization is an extremely general learning problem that captures many traditional learning problems as special cases ([11]).", "startOffset": 135, "endOffset": 139}, {"referenceID": 6, "context": "We only consider the decision-theoretic setting for prediction with expert advice ([7]).", "startOffset": 83, "endOffset": 86}, {"referenceID": 7, "context": "The resulting experts are \u201cspecialists,\u201d who sometimes abstain from offering advice, and we can apply a standard technique to compete with the best specialist ([8]).", "startOffset": 160, "endOffset": 163}, {"referenceID": 7, "context": "We then aggregate these recommendations using an algorithm for learning from specialists ([8]).", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "A wide range of theoretical models for this problem have been studied ([1], [9], [2], [6]).", "startOffset": 71, "endOffset": 74}, {"referenceID": 8, "context": "A wide range of theoretical models for this problem have been studied ([1], [9], [2], [6]).", "startOffset": 76, "endOffset": 79}, {"referenceID": 1, "context": "A wide range of theoretical models for this problem have been studied ([1], [9], [2], [6]).", "startOffset": 81, "endOffset": 84}, {"referenceID": 5, "context": "A wide range of theoretical models for this problem have been studied ([1], [9], [2], [6]).", "startOffset": 86, "endOffset": 89}, {"referenceID": 4, "context": "The most closely related work is ([5]).", "startOffset": 34, "endOffset": 37}, {"referenceID": 2, "context": "Along similar lines, ([3]) provides a robust collaborative algorithm for the multi-armed bandit problem, under an additional stochastic assumption.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "Another literature deals with learning problems in which an adversary has some influence over the training or testing data ([4]).", "startOffset": 124, "endOffset": 127}, {"referenceID": 9, "context": "We will use the algorithm Squint from ([10]).", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "Once the experts have decided whether to participate in a round, we use a standard algorithm for combining \u201cspecialists,\u201d experts who are only active in some rounds ([8]).", "startOffset": 166, "endOffset": 169}, {"referenceID": 4, "context": "([5]) develops robust collaborative algorithms for this problem when the number of experts in each problem is \u00d5 (1).", "startOffset": 1, "endOffset": 4}], "year": 2017, "abstractText": "We consider a collaborative variant of prediction with expert advice. In each round, one user wishes to make a prediction, and must choose which expert to follow. The users would like to share their experiences in order to learn faster\u2014ideally they could amortize the same total regret cross the whole community of users. However, some of the users may behave maliciously, distorting their reported payoffs in order to manipulate the honest users of the system. And even if all users behave honestly, different experts may perform better for different users, such that sharing data can be counterproductive. We present a robust collaborative algorithm for prediction with expert advice, which guarantees that every subset of users H perform nearly as well as if they had shared all of their data, and ignored all data from users outside of H. This algorithm limits the damage done by the dishonest users to O (\u221a T ) , compared to the O (T ) we would obtain by naively aggregating data. We also extend our results to general online convex optimization. The resulting algorithm achieves low regret, but is computationally intractable. This demonstrates that there is no statistical obstruction to generalizing robust collaborative online learning, but leaves the design of efficient algorithms as an open problem.", "creator": "LaTeX with hyperref package"}}}