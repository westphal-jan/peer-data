{"id": "1603.06352", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2016", "title": "Online Learning with Low Rank Experts", "abstract": "We consider the problem of prediction with expert advice when the losses of the experts have low-dimensional structure: they are restricted to an unknown $d$-dimensional subspace. We devise algorithms with regret bounds that are independent of the number of experts and depends only on the rank $d$. For the stochastic model we show a tight bound of $\\Theta(\\sqrt{dT})$, and extend it to a setting of an approximate $d$ subspace. For the adversarial model we show an upper bound of $O(d\\sqrt{T})$ and a lower bound of $\\Omega(\\sqrt{dT})$.", "histories": [["v1", "Mon, 21 Mar 2016 08:29:05 GMT  (20kb)", "https://arxiv.org/abs/1603.06352v1", null], ["v2", "Mon, 23 May 2016 06:47:33 GMT  (20kb)", "http://arxiv.org/abs/1603.06352v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["elad hazan", "tomer koren", "roi livni", "yishay mansour"], "accepted": false, "id": "1603.06352"}, "pdf": {"name": "1603.06352.pdf", "metadata": {"source": "CRF", "title": "Online Learning with Low Rank Experts \u030a", "authors": ["Elad Hazan", "Tomer Koren", "Roi Livni", "Yishay Mansour"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 3.06 352v 2 [cs.L G] 23 May 201 6? dT q, and extend it to a setting of an approximate d-subspace. For the opposing model we show an upper limit of Opd? T q and a lower limit of P? dT q."}, {"heading": "1 Introduction", "text": "In its simplest form, a learner wishes to make an educated decision, and in each round he decides to take the advice of one of N experts. In fact, the learner then suffers a loss of between 0 and 1. However, it is a standard outcome in online learning that without further assumptions has the best strategy for the learner based on a few degrees of freedom - for example, when experts are experts, their political bias or school of thought dominates their decision-making. Experts can also be assets on which learners want to distribute their wealth. In this setting, weather, market conditions and interests are dominant factors. It is also reasonable to assume that this structure can be exploited to achieve a better result, potentially an independent strategy of actually maintaining the actual number of actual experts."}, {"heading": "1.1 Related Work", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Problem Setup and Main Results", "text": "In each round t \"1,.., T the learner chooses a probability vector xt P\" N, where \"N\" denotes the N-simplex, namely the set of all possible distributions via N experts, \"N\"! x P RN: @ i, xpiq \"0 and\" N \"xpiq\" 1). An opponent responds by choosing a loss vector, \"P r\" 1, 1sN, 1 and the learner suffers a loss xtptq \"xt.\" The goal of the learner is to minimize their regret, which is defined as follows, RegretT \"T\" 1, 1sN, 1 and the learner suffers a loss xtptptq \"xt\" xt. \"In the stochastic online expert model, the distribution D over the loss vectors in r\" 1, 1sN. \""}, {"heading": "2.1 Main Results", "text": "Next, we cite the main results of this work: Theorem 1. The T-round regret of algorithm 2 (described in section 4 below) is at most Opd? T q, where d \"rankpLq.We note that a regret upper limit of Op? T mintd,? logNuq is attainable by combining the standard algorithm for multiplicative updates with our algorithm.2 Our upper limit is accompanied by the following lower limited.Theorem 2. For every online learning algorithm, there is a sequence of loss vectors, T? and d? log2N, 1,.... T P r '1, 1sN like RegretT\" T \"t\" 1 xt. \"t\" min iPrNsT \"1\" tpiq \u011bcdT8, and rankpLq \"d. 1As will later turn out, in our setup it is more obvious, symmetrical Metricians\" 1, 1s values as a problem to consider between the two losses, rather than a series of 2."}, {"heading": "3 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Notation", "text": "The columns of a matrix U are denoted by u1, u2,... The i'te coordinate of a vector x is denoted by xpiq. For a matrix M we denote by M: the Moore-Penrose pseudo-inverse of M. For a positive definitive matrix H \u0105 0 we denote its corresponding norm} x} H \"? xTHx, and its dual norm} x} \u02da H\"? xTH \"1x. For a positive semi-definitive matrix M iele 0, its corresponding ellipsoid is defined as: EpMq\" tx: xTM: x-1u."}, {"heading": "3.2 Ellipsoidal Approximation of Convex Bodies", "text": "A major tool in our algorithm is an ellipsoid approximation of convex solids. Let's remember John's theorem for symmetrical, zero-centered convex solids. Theorem 3 (Johns Theorem; e.g. Ball, 1997) Let K be a convex body in Rd that is symmetrically around zero (i.e. K \"'K). Let E be an ellipsoid with minimal volume enclosing K. Then: 1? d E-K-E. While calculating the minimum volume of an ellipsoid is mathematically difficult, it can be approximated for symmetrical convex solids within a factor in polynomial time. Concretely, consider as input a matrix A P RN\u00c9 d the polytopic PA\" tx \":} Ax} 8 \u0445 1u. We have the following theorem 4 (Gro'tschel et al., 2012, theorem 4.6.5)."}, {"heading": "3.3 Online Mirror Descent", "text": "Another main tool in our analysis is the well-known Online Mirror Descent algorithm for online convex optimisation. Online Mirror Descent is a subgradient descent method for optimisation via a convex set in Rd, which implies an a priori selected regulation factor. In algorithm 1 we describe the algorithm for the special case where the convex set is N and the regulation function is 2: for t \"1 to T 3: Play xt \u00b2 t: Suffer cost xt \u00b2 t and note: t 5: Updatext '1\" arg min xP \u00b2 N \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 x \"xt \u00b2 t \u00b2 t.\" 6: end forbound The regret of the algorithm depends on the choice of regulation and note: t 5: Updatext' 1 \"arg min xP \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t,\" T \u00b2 t \u00b2 t \u00b2 t \u00b2 t \"2: end of The choice of regularization is e.t."}, {"heading": "3.4 Rademacher Complexity", "text": "Our tool for analyzing the stochastic case will be the Rademacher complexity, specifically we will use it to bind the regret of a \"Follow The Leader\" algorithm (FTL). Let's remember that the FTL algorithm selection rule is defined as xt \"arg min xP\" 1 \"1\" 1 \"1.\" One way to bind the regret of the FTL algorithm in the stochastic case is to limit the Rademacher complexity of the realizable samples. Let's mention that the Rademacher complexity of a class of target functions F over a sample St \"t1.,\" \"It is defined as followsRpF, Stq\" E\u03c3 \"sup fPF1tt\" i \"1.\" iqff \"iqff,\" where the Rademaker complexity of a class of target functions F over a sample St. \""}, {"heading": "4 Upper Bound", "text": "In this section, we discuss our online algorithms to which we strive. \"We must abide by the rules.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" We. \"\" \"We.\" \"\" \"\" We. \"\" \"\" \"We.\" \"\" \"\". \"\" \"We.\" \"\" \"\" \"\" We. \"\" \"\" \"\" \"We.\" \".\" \"\" \"\" We. \"\" \".\" \"\" \"\" We. \".\". \"\" \"\" We. \".\" \"\" \"\" We. \".\" \"\" \"\" We. \".\". \"\" \"\" \"\" We. \"..\" \"\" \"\".. \"\" \"\" \"We.....\" \"\" \"\" \".\". \"\". \"\" \".\". \"\". \".\" \".\" \".\" \".\" \"\". \"\". \"\". \"\" \".\" \".\" \".\" \"\". \"\". \".\" \".\". \".\". \"\". \"\" \".\". \".\". \".\". \"\". \"\". \".\" \"\". \".\". \".\". \".\". \".\". \".\" \"\". \".\". \".\". \".\". \".\". \".\" \".\". \".\". \".\" \"\". \".\". \".\". \".\". \".\". \"\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\" \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \"..\". \".\". \".\"."}, {"heading": "4.1 Stochastic Online Experts", "text": "In this case, we can achieve a right regret by using a simple \"Follow The Leader\" (FTL) algorithm. Indeed, we will show an even stronger result in the stochastic case that an approximate rank is sufficient to limit complexity. Remember that the following statement is the main result for this section: Theorem 9. Assume that an opponent decides to take their losses. (See Alon et al., 2013): rankpLq \"mintrankpL1q:\" mintrankpL1q: \"The rankpP is the main result for this section."}, {"heading": "5 Lower Bound", "text": "We now prove theorem 2. For our proof, we rely on lower limits for online learning of hypotheses classes relative to the Littlestone dimension (see Shalev-Shwartz, 2011). For a class H of target functions h: X-t0, 1u, the Littlestone dimension LdimpHq measures the complexity or online learning ability of the class.To define LdimpHq, consider trees whose internal nodes are marked by instances. Any branch in such a tree can be described as a sequence of examples px1, y1q, pxd, ydq, where the instance is associated with the ith node in the path, and yi is the real child of the i-th node, and yi \"0 otherwise. LdimpHq is then defined as the depth of the largest binary tree, which is H. An example labeled tree is smashed by a class when we hack it as root."}, {"heading": "6 Discussion and Open Problems", "text": "We look at the problem of the experts with a hidden low structure. Our results are that in the non-stochastic case, similar to the stochastic case, the limits of regret are independent of the number of experts. Then, the most natural question is to bridge the gap between the upper and lower limits: Open problem 1. Is there an algorithm that can achieve the regret op? dT \u00b2 for each sequence? Our goal is to construct new online algorithms that can exploit the structure without explicit information about the structure. Other settings can also be considered within our framework? T q? As discussed, our agenda is more general than the low-level setting. Our goal is to construct new online algorithms that can exploit the structure of the data. Other settings can be considered within our framework. Another interesting setting that avoids dependence in the dimension is to assume that experts are embedded in a Hilbert room."}, {"heading": "A Technical Proofs", "text": "Lemma 11. Let M P Rdd, U P Rdn such that M q 0 and U.ThenUpUTMUq: UT \"M '1.Proof. Let N\" M1 {2U. \"Then we have NpNTNq: NT\" Id. \"To see this, we write the SVD decomposition N\" OVT \"with diagonal, non-singular\" P Rdd \"and OOT\" OTO \"VTV\" Id. \"Then we get M1 {2UpUTMUq: Ndt\" VTpV \"2VTq: V\" OT. \"VTpV\" 2VTqV. \"P\" Id. \""}, {"heading": "B Lower Bounds for the AdaGrad Algorithm", "text": "\"We assume that there is an episode.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\" \"We assume that we have an episode of it.\""}], "references": [{"title": "The approximate rank of a matrix and its algorithmic applications: approximate rank", "author": ["N. Alon", "T. Lee", "A. Shraibman", "S. Vempala"], "venue": "In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,", "citeRegEx": "Alon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2013}, {"title": "An elementary introduction to modern convex geometry", "author": ["K. Ball"], "venue": "Flavors of geometry,", "citeRegEx": "Ball.,? \\Q1997\\E", "shortCiteRegEx": "Ball.", "year": 1997}, {"title": "Agnostic online learning", "author": ["S. Ben-David", "D. P\u00e1l", "S. Shalev-Shwartz"], "venue": "In COLT. Citeseer,", "citeRegEx": "Ben.David et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2009}, {"title": "Exact matrix completion via convex optimization", "author": ["E.J. Cand\u00e8s", "B. Recht"], "venue": "Foundations of Computational mathematics,", "citeRegEx": "Cand\u00e8s and Recht.,? \\Q2009\\E", "shortCiteRegEx": "Cand\u00e8s and Recht.", "year": 2009}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Improved second-order bounds for prediction with expert advice", "author": ["N. Cesa-Bianchi", "Y. Mansour", "G. Stoltz"], "venue": "Machine Learning,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2007}, {"title": "Online optimization with gradual variations", "author": ["C.-K. Chiang", "T. Yang", "C.-J. Lee", "M. Mahdavi", "C.-J. Lu", "R. Jin", "S. Zhu"], "venue": "In COLT,", "citeRegEx": "Chiang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chiang et al\\.", "year": 2012}, {"title": "Follow the leader if you can, hedge if you must", "author": ["S. De Rooij", "T. Van Erven", "P.D. Gr\u00fcnwald", "W.M. Koolen"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Rooij et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rooij et al\\.", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Concentration-based guarantees for low-rank matrix reconstruction", "author": ["R. Foygel", "N. Srebro"], "venue": "arXiv preprint arXiv:1102.3923,", "citeRegEx": "Foygel and Srebro.,? \\Q2011\\E", "shortCiteRegEx": "Foygel and Srebro.", "year": 2011}, {"title": "Regret minimization for branching experts", "author": ["E. Gofer", "N. Cesa-Bianchi", "C. Gentile", "Y. Mansour"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Gofer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gofer et al\\.", "year": 2013}, {"title": "Transduction with matrix completion: Three birds with one stone", "author": ["A. Goldberg", "B. Recht", "J. Xu", "R. Nowak", "X. Zhu"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Goldberg et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2010}, {"title": "Geometric algorithms and combinatorial optimization, volume 2", "author": ["M. Gr\u00f6tschel", "L. Lov\u00e1sz", "A. Schrijver"], "venue": "Springer Science & Business Media,", "citeRegEx": "Gr\u00f6tschel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gr\u00f6tschel et al\\.", "year": 2012}, {"title": "Introduction to Onlne Convex Optimization, Draft", "author": ["E. Hazan"], "venue": "Publishers Inc.,", "citeRegEx": "Hazan.,? \\Q2015\\E", "shortCiteRegEx": "Hazan.", "year": 2015}, {"title": "On stochastic and worst-case models for investing", "author": ["E. Hazan", "S. Kale"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Hazan and Kale.,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2009}, {"title": "Extracting certainty from uncertainty: Regret bounded by variation in costs", "author": ["E. Hazan", "S. Kale"], "venue": "Machine learning,", "citeRegEx": "Hazan and Kale.,? \\Q2010\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2010}, {"title": "Better algorithms for benign bandits", "author": ["E. Hazan", "S. Kale"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Hazan and Kale.,? \\Q2011\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2011}, {"title": "Classification with low rank and missing data", "author": ["E. Hazan", "R. Livni", "Y. Mansour"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2015}, {"title": "Maximum-margin matrix factorization", "author": ["N. Srebro", "J. Rennie", "T.S. Jaakkola"], "venue": null, "citeRegEx": "Srebro et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 4, "context": "It is a standard result in online learning that, without further assumptions, the best strategy for the learner will incur \u0398p ? T logNq regret (Cesa-Bianchi and Lugosi, 2006).", "startOffset": 143, "endOffset": 174}, {"referenceID": 3, "context": "They have been successfully applied to various problems, most notably to matrix completion (Cand\u00e8s and Recht, 2009; Foygel and Srebro, 2011; Srebro et al., 2004) but also in the context of classification with missing data (Goldberg et al.", "startOffset": 91, "endOffset": 161}, {"referenceID": 9, "context": "They have been successfully applied to various problems, most notably to matrix completion (Cand\u00e8s and Recht, 2009; Foygel and Srebro, 2011; Srebro et al., 2004) but also in the context of classification with missing data (Goldberg et al.", "startOffset": 91, "endOffset": 161}, {"referenceID": 11, "context": ", 2004) but also in the context of classification with missing data (Goldberg et al., 2010; Hazan et al., 2015) and large scale optimization (Shalev-Shwartz et al.", "startOffset": 68, "endOffset": 111}, {"referenceID": 17, "context": ", 2004) but also in the context of classification with missing data (Goldberg et al., 2010; Hazan et al., 2015) and large scale optimization (Shalev-Shwartz et al.", "startOffset": 68, "endOffset": 111}, {"referenceID": 10, "context": "A similar problem that was studied in the literature is the Branching Experts Problem (Gofer et al., 2013).", "startOffset": 86, "endOffset": 106}, {"referenceID": 3, "context": "They have been successfully applied to various problems, most notably to matrix completion (Cand\u00e8s and Recht, 2009; Foygel and Srebro, 2011; Srebro et al., 2004) but also in the context of classification with missing data (Goldberg et al., 2010; Hazan et al., 2015) and large scale optimization (Shalev-Shwartz et al., 2011). A similar problem that was studied in the literature is the Branching Experts Problem (Gofer et al., 2013). In the branching expert problem N potential experts are effectively only k distinct experts, but the clustering of the experts to the k clusters is unknown a-priori. This case can be considered as a special instance of our setting as indeed we can embed each expert as a kdimensional vector. Gofer et al. (2013) proved a sharp \u0398p ? kT q regret (the bound is tight only when k \u0103 c logN for some constant c \u0105 0).", "startOffset": 92, "endOffset": 746}, {"referenceID": 6, "context": ", 2014), as well as the exploration of various structural assumptions that can be leveraged for obtaining improved regret guarantees (e.g., Cesa-Bianchi et al., 2007; Hazan and Kale, 2010, 2011; Chiang et al., 2012; Rakhlin and Sridharan, 2013).", "startOffset": 133, "endOffset": 244}, {"referenceID": 8, "context": "One of the earliest and most widely used methods in this family is the AdaGrad algorithm (Duchi et al., 2011), a subgradient descent method that dynamically incorporate knowledge of the geometry of the data from earlier iterations.", "startOffset": 89, "endOffset": 109}, {"referenceID": 2, "context": "The SOA algorithm suggested by Ben-David et al. (2009) is a general framework for regret minimization that depends solely on the Littlestone dimension.", "startOffset": 31, "endOffset": 55}, {"referenceID": 2, "context": "Lemma 10 (Ben-David et al., 2009).", "startOffset": 9, "endOffset": 33}], "year": 2016, "abstractText": "We consider the problem of prediction with expert advice when the losses of the experts have low-dimensional structure: they are restricted to an unknown d-dimensional subspace. We devise algorithms with regret bounds that are independent of the number of experts and depend only on the rank d. For the stochastic model we show a tight bound of \u0398p ? dT q, and extend it to a setting of an approximate d subspace. For the adversarial model we show an upper bound of Opd ? T q and a lower bound of \u03a9p ? dT q.", "creator": "LaTeX with hyperref package"}}}