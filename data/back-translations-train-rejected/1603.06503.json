{"id": "1603.06503", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2016", "title": "Static and Dynamic Feature Selection in Morphosyntactic Analyzers", "abstract": "We study the use of greedy feature selection methods for morphosyntactic tagging under a number of different conditions. We compare a static ordering of features to a dynamic ordering based on mutual information statistics, and we apply the techniques to standalone taggers as well as joint systems for tagging and parsing. Experiments on five languages show that feature selection can result in more compact models as well as higher accuracy under all conditions, but also that a dynamic ordering works better than a static ordering and that joint systems benefit more than standalone taggers. We also show that the same techniques can be used to select which morphosyntactic categories to predict in order to maximize syntactic accuracy in a joint system. Our final results represent a substantial improvement of the state of the art for several languages, while at the same time reducing both the number of features and the running time by up to 80% in some cases.", "histories": [["v1", "Mon, 21 Mar 2016 17:20:34 GMT  (34kb)", "http://arxiv.org/abs/1603.06503v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["bernd bohnet", "miguel ballesteros", "ryan mcdonald", "joakim nivre"], "accepted": false, "id": "1603.06503"}, "pdf": {"name": "1603.06503.pdf", "metadata": {"source": "CRF", "title": "Static and Dynamic Feature Selection in Morphosyntactic Analyzers", "authors": ["Bernd Bohnet", "Miguel Ballesteros", "Ryan McDonald", "Joakim Nivre"], "emails": ["bohnetbd@google.com,", "ryanmcd@google.com,", "miguel.ballesteros@upf.edu,", "joakim.nivre@lingfil.uu.se"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.06 503v 1 [cs.C L] 21 Mar 201 6"}, {"heading": "1 Introduction", "text": "In fact, it is as if most of us are able to survive ourselves by putting ourselves in the role of the individual. (...) It is not as if they step into the role of the individual. (...) It is as if they step into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...). (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...)"}, {"heading": "2 Related Work", "text": "As morphosyntactic marking interacts with other tasks such as word segmentation and syntactic parsing, there is increasing interest in common models that integrate marking with these other tasks, including common marking and word segmentation (Zhang and Clark, 2008a), common marking and recognition of designated units (Mo'ra and Vincze, 2012), common marking and parsing (Lee et al., 2011; Li et al., 2011; Hatori et al., 2011; Bohnet and Nivre, 2012; Bohnet et al., 2013), and even common word segmentation, tagging and parsing (Hatori et al., 2012). These studies often show improved accuracy from common inferences in one or all of the tasks. Characteristic selection has been a staple of statistical NLP et al, 2013, since its inception."}, {"heading": "3 Feature Selection", "text": "The methods of feature selection that we are examining can all be regarded as greedy forward selection, as shown in Figure 1. This paradigm assumes an empty set and takes into account feature after feature after feature. In each iteration, a model is generated from a training set and tested on the basis of a development set in relation to a certain accuracy metric of interest. The feature to be taken into account is added when it increases this characteristic above a certain threshold and is otherwise discarded. This strategy is similar to that implemented in MaltOptimizer (Ballesteros and Nivre, 2014), which differs from classical forward selection (Della Pietra et al., 1997) in that it does not test all characteristics in parallel, but instead relies on a sequence of characteristics as input. This is primarily for efficiency reasons, as training models are cumbersome parallel to a large number of feature templates. The feature set F can be more easily defined as a fully inferred suffix, or as a fixed suffix, for example."}, {"heading": "3.1 Static Feature Ordering", "text": "Our feature selection algorithm assumes a predetermined sequence of features to be evaluated against the objective function. A simple strategy is that a human provides a static sequence of features that is fixed for the traversal. This means that we test feature patterns in a predefined sequence and maintain those that improve accuracy. Those that are not discarded and are never visited again. In Figure 1, this means that the sequence (F) is fixed throughout the process. In our experiments, this fixed sequence is the same as in Table 1."}, {"heading": "3.2 Dynamic Feature Ordering", "text": "In text categorization, static feature selection based on correlation statistics is a popular technique (Yang and Pedersen, 1997).The typical strategy in such offline selectors is to evaluate each feature based on its correlation to the output space and to select the best K characteristics. This strategy is often referred to as maximum relevance because it aims to optimize the characteristics solely based on their predictive effectiveness. Unfortunately, the n best characteristics selected by these algorithms may not yield the best outcomes (Peng et al., 2005).Redundancy among the characteristics is the primary reason for this, and Peng et al. develop the Minimal Redundancy of Maximum Relevance (MRMR) to address this issue. MRMR methodology attempts to keep redundancy among the characteristics to a minimum. The approach is based on mutual information in order to compress the relevance of the characteristics, minimize the redundancy of a feature already selected and on a number of redundancies in a feature."}, {"heading": "4 Morphosyntactic Tagging", "text": "In this section we describe the two systems of morphosyntactic marking that we use to compare techniques for selecting characteristics."}, {"heading": "4.1 Standalone Tagger", "text": "The first tagger is a standalone SVM tagger, whose training regime is illustrated in Figure 2. The tagger iterates up to k times (typically twice) over a set from left to right (line 2), iterating to allow the final assignment of tag functions on both sides of the target token. For each token of the set, the tagger initializes an n-best list and extracts characteristics for the token in question (line 4-7). In the innermost loop (line 9-11), the algo rithm calculates the score for each morphosyntactic tag and inserts a pair consisting of the morphosyntactic tag and its score into the n-best list. The algorithm returns a two-dimensional array in which the first dimension contains the tokens and the second dimension contains the sorted lists of tag score pairs. The tagger is trained online using MIRA (Crammer al, 2006)."}, {"heading": "4.2 Joint Dependency-Based Tagger", "text": "The common tagger parser follows the design of Bohnet et al. (2013), which extends an arcstandard transition-based dependency parser with the ability to select a part-of-speech tag and / or a morphological tag for each input word from an n-best list of tags, and the tag selection is performed when an input word is moved to the stack, taking into account only the k tokens with the highest score from each n-best list, and only tags whose score is at most \u03b1 below the score of the best tag. In all experiments on this paper, we set k to 2 and \u03b1 to 0.25. The tagger parser uses the bar search to find the combined tagging and dependency tree with the highest score. When trimming the bar, it first extracts the 40 best-rated unique dependency trees, and then up to 8 variants that differ only in terms of tagging, a technique that was found to balance between the al and the 2013 parsing system (good balance)."}, {"heading": "5 Part-of-Speech Tagging Experiments", "text": "To simplify matters, we begin by examining feature selection for part-of-speech taggers, both in the context of stand-alone and shared systems. The main hypotheses we test are whether feature selection techniques are more powerful in common morphosyntactic systems than standalone taggers. That is, the resulting models are both more compact and precise. In addition, we would like to empirically compare the effects of both static and dynamic feature selection techniques."}, {"heading": "5.1 Data Sets", "text": "We experiment with corpora from five different languages: Chinese, English, German, Hungarian and Russian. For Chinese we use the Penn Chinese Treebank 5.1 (CTB5), converted with the head finding rules, conversion tools and with the same split as in Zhang and Clark (2008b).1 For English we use the WSJ section of Penn Treebank, converted with the head finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).2 For German we use the Tiger Treebank (Brants et al., 2002) in the improved dependency conversion of Seeker and Kuhn (2012). For Hungarian we use the Szeged Dependency Treebank (Farkas et al., 2012). For Russian we use the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002)."}, {"heading": "5.2 Feature Templates", "text": "Table 1 shows the characteristic patterns we used in our experiments (second column). The name of the radio gate indicates the purpose of the feature template. For example, the function form defines the word form. The argument defines the position of the token, e.g. form (w + 1) denotes the symbol to the right of the current token. If more than one argument is given, the radio gate is applied to each defined position and the results are concatenated. Thus, form (w, w + 1) expands to form (w) + form (w + 1). The radio gate formlc denotes the form with all letters converted to lowercase letters and lem denotes the problem of a word. The functions suffix1, suffix2,... and prefix1,... denote suffixes and prefixes of length 1, 2,...,...,..., 5. The suffix1 + uc,... radiators concatenate a suffix with a1Training: 001-801, development and prefixes of length 1, 2,...,...,...,..., 5. Suffix1 + uc,..."}, {"heading": "5.3 Main Results", "text": "In our experiments, we have a division of the training concepts into 80% for training and 20% for development. Therefore, in each iteration, a model for more than 80% of the training process is formed and tested to 20%. If the result of the realignment is better than the best result, then the feature is added to the feature model. Otherwise, it is not possible to show an improvement in performance of at least 0.2 on the part of the speech that has accuracy in order to count as a cheater. 4Table 1 shows the characteristics that the algorithms have selected for each language and each system, and Table 2 shows the performance on the part of the speech that has accuracy."}, {"heading": "6 Morphological Tagging Experiments", "text": "Common morphology and syntactical conclusion require the selection of morphological attributes (case, number, etc.) and the selection of characteristics to predict morphological characteristics. In previous work on common morphosyntactic analysis, all morphological attributes are predicted together with syntactic dependencies (Bohnet et al., 2013). However, this could lead to unnecessary complexity, since only a subset of attributes is likely to influence analysis decisions and vice versa. In this section, we examine whether methods for selecting characteristics can also be used to reduce the number of morphological attributes predicted as part of a common system. For example, consider a language that has the following attributes: case, gender, number, animation. And say that language has no gender agreement. Then, only case and number will probably be useful in a common system, and the gender and animation characteristics can be predicted independently."}, {"heading": "6.1 Data Sets", "text": "We use the records listed in paragraph 5.1 for the languages that provide morphological annotations, namely German, Hungarian and Russian."}, {"heading": "6.2 Main Results: Attribute Selection", "text": "For the selection of morphological attributes (e.g. case, number, voltage), we examine a simple method that differs slightly from those in Section 3. Specifically, we do not perform greedy forward selection. Instead, we calculate accuracy improvements for each attribute offline. We then select attributes independently of these values. Our initial design was a greedy forward selection of attributes, but we experimentally determined that this independent attribute selection worked best. We perform 10-fold cross-validation experiments on the training set, using 90% of the training set for training and 10% for testing. Here, we simply test for each attribute regardless of whether its inclusion in a common morphosyntactic parsing system increases parsing accuracy (LAS / UAS) by a statistically significant amount."}, {"heading": "6.3 Main Results: Feature Selection", "text": "Once we have defined the set of attributes that need to be predicted together with the parser, we can turn our attention to optimizing the character sets for morphosyntactic markers. To this end, we look again at the greedy forward selection with static and dynamic strategies. Table 1 shows the selected characteristics for the different languages in which the gray boxes again mean that the feature has been selected. Table 6 shows the performance on the development set. For Germany, the full template set performs best, but only 0.04 better than the static selection, which performs almost as well and reduces the template by 68%. For Hungary, all sentences perform similarly, while the dynamic selection requires 86% fewer characteristics. The most powerful feature for Russia is the dynamic selection in a common system, which requires 81% fewer characteristics. We observe again that the dynamic selection tends to select fewer feature templates than the static selection, but both the complete set of features requires less than the static selection, as well as the static selection requires 86% less than the most powerful characteristics selected by the combined system."}, {"heading": "7 Conclusions", "text": "Several methodological lessons can be learned from this work: First, feature selection is generally useful because it leads to fewer features and faster tagging while remaining state-of-the-art; second, feature selection for common tagging parsing is even more effective where it leads to even better results and smaller feature sets; in some cases, the number of feature templates is reduced by up to 80%, while runtime is shortened accordingly; third, dynamic feature selection strategies (Peng et al., 2005) lead to more compact models than static feature selection without significantly affecting accuracy; and finally, similar methods can be applied to morphological attribute selection, leading to even leaner and faster models."}, {"heading": "Acknowledgement", "text": "Miguel Ballesteros is supported by the European Commission under contract numbers FP7-ICT610411 (Project MULTISENSOR) and H2020RIA-645012 (Project KRISTINA)."}], "references": [{"title": "Automatic feature selection for agenda-based dependency parsing", "author": ["Ballesteros", "Bohnet2014] Miguel Ballesteros", "Bernd Bohnet"], "venue": "In Proceedings of the 25th International Conference on Computational Linguistics (COLING)", "citeRegEx": "Ballesteros et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2014}, {"title": "MaltOptimizer: Fast and Effective Parser Optimization", "author": ["Ballesteros", "Nivre2014] Miguel Ballesteros", "Joakim Nivre"], "venue": "Natural Language Engineering", "citeRegEx": "Ballesteros et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2014}, {"title": "Effective morphological feature selection with maltoptimizer at the spmrl 2013 shared task", "author": ["Miguel Ballesteros"], "venue": "In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,", "citeRegEx": "Ballesteros.,? \\Q2013\\E", "shortCiteRegEx": "Ballesteros.", "year": 2013}, {"title": "Open information extraction for the web", "author": ["Banko et al.2007] Michele Banko", "Michael J Cafarella", "Stephen Soderland", "Matthew Broadhead", "Oren Etzioni"], "venue": "In IJCAI,", "citeRegEx": "Banko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "Dependency treebank for Russian: Concept, tools, types of information", "author": ["Svetlana Grigorieva", "Nikolai Grigoriev", "Leonid Kreidlin", "Nadezhda Frid"], "venue": "In COLING,", "citeRegEx": "Boguslavsky et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Boguslavsky et al\\.", "year": 2000}, {"title": "Development of a dependency treebank for Russian and its possible applications in NLP", "author": ["Ivan Chardin", "Svetlana Grigorieva", "Nikolai Grigoriev", "Leonid Iomdin", "Leonid Kreidlin", "Nadezhda Frid"], "venue": null, "citeRegEx": "Boguslavsky et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Boguslavsky et al\\.", "year": 2002}, {"title": "Rule-based dependency parser refined by empirical and corpus statistics", "author": ["Leonid Iomdin", "Victor Sizov", "Leonid Tsinman", "Vadim Petrochenkov"], "venue": "In Proceedings of the International Conference", "citeRegEx": "Boguslavsky et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boguslavsky et al\\.", "year": 2011}, {"title": "A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing", "author": ["Bohnet", "Nivre2012] Bernd Bohnet", "Joakim Nivre"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Bohnet et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bohnet et al\\.", "year": 2012}, {"title": "Joint morphological and syntactic analysis for richly inflected languages", "author": ["Bohnet et al.2013] Bernd Bohnet", "Joakim Nivre", "Igor Boguslavsky", "Richard Farkas", "Filip Ginter", "Jan Hajia"], "venue": null, "citeRegEx": "Bohnet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bohnet et al\\.", "year": 2013}, {"title": "TnT \u2013 a statistical part-of-speech tagger. In ANLP", "author": ["Thorsten Brants"], "venue": null, "citeRegEx": "Brants.,? \\Q2000\\E", "shortCiteRegEx": "Brants.", "year": 2000}, {"title": "CoNLL-X shared task on multilingual dependency parsing", "author": ["Buchholz", "Marsi2006] Sabine Buchholz", "Erwin Marsi"], "venue": "In CoNLL,", "citeRegEx": "Buchholz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Buchholz et al\\.", "year": 2006}, {"title": "The use of mmr, diversitybased reranking for reordering documents and producing summaries", "author": ["Carbonell", "Goldstein1998] Jaime Carbonell", "Jade Goldstein"], "venue": "In Proceedings of the 21st annual international ACM SIGIR conference on Re-", "citeRegEx": "Carbonell et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Carbonell et al\\.", "year": 1998}, {"title": "Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing", "author": ["Michael Collins", "Terry Koo"], "venue": "In CoNLL,", "citeRegEx": "Carreras et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Carreras et al\\.", "year": 2008}, {"title": "Coarse-to-fine n-best parsing and MaxEnt discriminative reranking", "author": ["Charniak", "Johnson2005] Eugene Charniak", "Mark Johnson"], "venue": "In ACL,", "citeRegEx": "Charniak et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Charniak et al\\.", "year": 2005}, {"title": "Online passive-aggressive algorithms", "author": ["Crammer et al.2006] Koby Crammer", "Ofer Dekel", "Joseph Keshet", "Shai Shalev-Shwartz", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2006}, {"title": "Inducing features of random fields", "author": ["Vincent Della Pietra", "John Lafferty"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Pietra et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Pietra et al\\.", "year": 1997}, {"title": "Dependency parsing of hungarian: Baseline results and challenges", "author": ["Veronika Vincze", "Helmut Schmid"], "venue": "In EACL,", "citeRegEx": "Farkas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Farkas et al\\.", "year": 2012}, {"title": "A comparative study of parameter estimation methods for statistical natural language processing", "author": ["Gao et al.2007] Jianfeng Gao", "Galen Andrew", "Mark Johnson", "Kristina Toutanova"], "venue": "In ACL,", "citeRegEx": "Gao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2007}, {"title": "SVMTool: A general POS tagger generator based on support vector machines", "author": ["Gim\u00e9nez", "M\u00e0rquez2004] Jes\u00fas Gim\u00e9nez", "Llu\u0131\u0301s M\u00e0rquez"], "venue": null, "citeRegEx": "Gim\u00e9nez et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Gim\u00e9nez et al\\.", "year": 2004}, {"title": "A single generative model for joint morphological segmentation and syntactic parsing", "author": ["Goldberg", "Tsarfaty2008] Yoav Goldberg", "Reut Tsarfaty"], "venue": "In ACL,", "citeRegEx": "Goldberg et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2008}, {"title": "Arabic preprocessing schemes for statistical machine translation", "author": ["Habash", "Sadat2006] Nizar Habash", "Fatiha Sadat"], "venue": null, "citeRegEx": "Habash et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2006}, {"title": "Incremental joint pos tagging and dependency parsing in chinese", "author": ["Hatori et al.2011] Jun Hatori", "Takuya Matsuzaki", "Yusuke Miyao", "Jun\u2019ichi Tsujii"], "venue": "In IJCNLP,", "citeRegEx": "Hatori et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hatori et al\\.", "year": 2011}, {"title": "Incremental joint approach to word segmentation, pos tagging, and dependency parsing in chinese", "author": ["Hatori et al.2012] Jun Hatori", "Takuya Matsuzaki", "Yusuke Miyao", "Jun\u2019ichi Tsujii"], "venue": "In ACL,", "citeRegEx": "Hatori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hatori et al\\.", "year": 2012}, {"title": "Dynamic programming for linear-time incremental parsing", "author": ["Huang", "Sagae2010] Liang Huang", "Kenji Sagae"], "venue": "In ACL,", "citeRegEx": "Huang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2010}, {"title": "Efficient third-order dependency parsers", "author": ["Koo", "Collins2010] Terry Koo", "Michael Collins"], "venue": "In ACL,", "citeRegEx": "Koo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2010}, {"title": "Simple semi-supervised dependency parsing", "author": ["Koo et al.2008] Terry Koo", "Xavier Carreras", "Michael Collins"], "venue": "In ACL,", "citeRegEx": "Koo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "A discriminative model for joint morphological disambiguation and dependency parsing", "author": ["Lee et al.2011] John Lee", "Jason Naradowsky", "David A. Smith"], "venue": "In ACL,", "citeRegEx": "Lee et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2011}, {"title": "Joint models for chinese pos tagging and dependency parsing", "author": ["Li et al.2011] Zhenghua Li", "Min Zhang", "Wanxiang Che", "Ting Liu", "Wenliang Chen", "Haizhou Li"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "A general pos tagger generator based on support vector machines. JMLR", "author": ["M\u00e0rquez", "Gim\u00e9nez2004] L M\u00e0rquez", "J Gim\u00e9nez"], "venue": null, "citeRegEx": "M\u00e0rquez et al\\.,? \\Q2004\\E", "shortCiteRegEx": "M\u00e0rquez et al\\.", "year": 2004}, {"title": "Turbo parsers: Dependency parsing by approximate variational inference", "author": ["Noah Smith", "Eric Xing", "Pedro Aguiar", "Mario Figueiredo"], "venue": "In EMNLP,", "citeRegEx": "Martins et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2010}, {"title": "Structured sparsity in structured prediction", "author": ["Noah A Smith", "Pedro MQ Aguiar", "M\u00e1rio AT Figueiredo"], "venue": "In EMNLP,", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons", "author": ["McCallum", "Li2003] Andrew McCallum", "Wei Li"], "venue": "In Proceedings of the seventh conference on Natural language learn-", "citeRegEx": "McCallum et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McCallum et al\\.", "year": 2003}, {"title": "Online learning of approximate dependency parsing algorithms", "author": ["McDonald", "Pereira2006] Ryan McDonald", "Fernando Pereira"], "venue": "In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics", "citeRegEx": "McDonald et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2006}, {"title": "Online largemargin training of dependency parsers", "author": ["Koby Crammer", "Fernando Pereira"], "venue": "In ACL,", "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Joint part-of-speech tagging and named entity recognition using factor graphs", "author": ["M\u00f3ra", "Vincze2012] Gy\u00f6rgy M\u00f3ra", "Veronika Vincze"], "venue": null, "citeRegEx": "M\u00f3ra et al\\.,? \\Q2012\\E", "shortCiteRegEx": "M\u00f3ra et al\\.", "year": 2012}, {"title": "Efficient higher-order crfs for morphological tagging", "author": ["M\u00fcller et al.2013] Thomas M\u00fcller", "Helmut Schmid", "Hinrich Sch\u00fctze"], "venue": "Proceedings of EMNLP", "citeRegEx": "M\u00fcller et al\\.,? \\Q2013\\E", "shortCiteRegEx": "M\u00fcller et al\\.", "year": 2013}, {"title": "Feature Selection Based on Mutual Information: Criteria of Max-Dependency, Max-Relevance, and Min-Redundancy", "author": ["Peng et al.2005] Hanchuan Peng", "Fuhui Long", "Chris Ding"], "venue": "In IEEE Transactions On Pattern Analysis And Machine In-", "citeRegEx": "Peng et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Peng et al\\.", "year": 2005}, {"title": "Learning accurate, compact, and interpretable tree annotation", "author": ["Petrov et al.2006] Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein"], "venue": "In ACL,", "citeRegEx": "Petrov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2006}, {"title": "A maximum entropy part-of-speech tagger", "author": ["Adwait Ratnaparkhi"], "venue": "In EMNLP,", "citeRegEx": "Ratnaparkhi.,? \\Q1996\\E", "shortCiteRegEx": "Ratnaparkhi.", "year": 1996}, {"title": "Making ellipses explicit in dependency conversion for a german treebank", "author": ["Seeker", "Kuhn2012] Wolfgang Seeker", "Jonas Kuhn"], "venue": "In LREC,", "citeRegEx": "Seeker et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Seeker et al\\.", "year": 2012}, {"title": "Morphological and syntactic case in statistical dependency parsing", "author": ["Seeker", "Kuhn2013] Wolfgang Seeker", "Jonas Kuhn"], "venue": "Computational Linguistics,", "citeRegEx": "Seeker et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Seeker et al\\.", "year": 2013}, {"title": "An empirical study of semi-supervised structured conditional models for dependency parsing", "author": ["Suzuki et al.2009] Jun Suzuki", "Hideki Isozaki", "Xavier Carreras", "Michael Collins"], "venue": null, "citeRegEx": "Suzuki et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Suzuki et al\\.", "year": 2009}, {"title": "Enriching the knowledge sources used in a maximum entropy partof-speech tagger", "author": ["Toutanova", "Manning2000] Kristina Toutanova", "Christopher D. Manning"], "venue": "Joint SIGDAT Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Toutanova et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2000}, {"title": "Statistical dependency analysis with support vector machines", "author": ["Yamada", "Matsumoto2003] Hiroyasu Yamada", "Yuji Matsumoto"], "venue": "In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),", "citeRegEx": "Yamada et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Yamada et al\\.", "year": 2003}, {"title": "A comparative study on feature selection in text categorization", "author": ["Yang", "Pedersen1997] Yiming Yang", "Jan O Pedersen"], "venue": "In ICML,", "citeRegEx": "Yang et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Yang et al\\.", "year": 1997}, {"title": "Joint word segmentation and POS tagging using a single perceptron", "author": ["Zhang", "Clark2008a] Yue Zhang", "Stephen Clark"], "venue": "In ACL,", "citeRegEx": "Zhang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2008}, {"title": "A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing", "author": ["Zhang", "Clark2008b] Yue Zhang", "Stephen Clark"], "venue": "In EMNLP,", "citeRegEx": "Zhang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2008}, {"title": "Transition-based parsing with rich non-local features", "author": ["Zhang", "Nivre2011] Yue Zhang", "Joakim Nivre"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2011}, {"title": "Online learning for inexact hypergraph search", "author": ["Zhang et al.2013] Hao Zhang", "Liang Huang", "Kai Zhao", "Ryan McDonald"], "venue": "In EMNLP,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 3, "context": "machine translation (Habash and Sadat, 2006) to information extraction (Banko et al., 2007).", "startOffset": 71, "endOffset": 91}, {"referenceID": 9, "context": "To achieve state-of-the-art results, they employ sophisticated optimization techniques in combination with rich feature representations (Brants, 2000; Toutanova and Manning, 2000; Gim\u00e9nez and M\u00e0rquez, 2004; M\u00fcller et al., 2013).", "startOffset": 136, "endOffset": 227}, {"referenceID": 35, "context": "To achieve state-of-the-art results, they employ sophisticated optimization techniques in combination with rich feature representations (Brants, 2000; Toutanova and Manning, 2000; Gim\u00e9nez and M\u00e0rquez, 2004; M\u00fcller et al., 2013).", "startOffset": 136, "endOffset": 227}, {"referenceID": 37, "context": "The most common case is parsers that predict constituency structures jointly with part-ofspeech tags (Charniak and Johnson, 2005; Petrov et al., 2006) or richer word morphology Goldberg and Tsarfaty (2008).", "startOffset": 101, "endOffset": 150}, {"referenceID": 9, "context": "To achieve state-of-the-art results, they employ sophisticated optimization techniques in combination with rich feature representations (Brants, 2000; Toutanova and Manning, 2000; Gim\u00e9nez and M\u00e0rquez, 2004; M\u00fcller et al., 2013). Joint taggers, on the other hand, combine morphosyntactic tagging with deeper syntactic processing. The most common case is parsers that predict constituency structures jointly with part-ofspeech tags (Charniak and Johnson, 2005; Petrov et al., 2006) or richer word morphology Goldberg and Tsarfaty (2008).", "startOffset": 137, "endOffset": 535}, {"referenceID": 26, "context": "In dependency parsing, pipeline models have traditionally been the norm, but recent studies have shown that joint tagging and dependency parsing can improve accuracy of both (Lee et al., 2011; Hatori et al., 2011; Bohnet and Nivre, 2012; Bohnet et al., 2013).", "startOffset": 174, "endOffset": 258}, {"referenceID": 21, "context": "In dependency parsing, pipeline models have traditionally been the norm, but recent studies have shown that joint tagging and dependency parsing can improve accuracy of both (Lee et al., 2011; Hatori et al., 2011; Bohnet and Nivre, 2012; Bohnet et al., 2013).", "startOffset": 174, "endOffset": 258}, {"referenceID": 8, "context": "In dependency parsing, pipeline models have traditionally been the norm, but recent studies have shown that joint tagging and dependency parsing can improve accuracy of both (Lee et al., 2011; Hatori et al., 2011; Bohnet and Nivre, 2012; Bohnet et al., 2013).", "startOffset": 174, "endOffset": 258}, {"referenceID": 7, "context": ", 2011; Bohnet and Nivre, 2012; Bohnet et al., 2013). Unfortunately, joint models typically increase the search space, making them more cumbersome than their pipeline equivalents. For instance, in the joint morphosyntactic transition-based parser of Bohnet et al. (2013), the number of parser actions", "startOffset": 32, "endOffset": 271}, {"referenceID": 7, "context": "We investigate this question in the context of the joint morphosyntactic parser of Bohnet et al. (2013), focusing on optimizing and compressing feature sets via greedy feature selection techniques, and explicitly contrasting joint systems with standalone taggers.", "startOffset": 83, "endOffset": 104}, {"referenceID": 22, "context": ", 2013), and even joint word segmentation, tagging and parsing (Hatori et al., 2012).", "startOffset": 63, "endOffset": 84}, {"referenceID": 38, "context": "Feature selection has been a staple of statistical NLP since its beginnings, notably selection via frequency cut-offs in part-of-speech tagging (Ratnaparkhi, 1996).", "startOffset": 144, "endOffset": 163}, {"referenceID": 17, "context": "Sparse priors, such as L1 regularization, are a common feature selection technique that trades off feature sparsity with the model\u2019s objective (Gao et al., 2007).", "startOffset": 143, "endOffset": 161}, {"referenceID": 34, "context": "Feature selection has been a staple of statistical NLP since its beginnings, notably selection via frequency cut-offs in part-of-speech tagging (Ratnaparkhi, 1996). Since then efforts have been made to tie feature selection with model optimization. For instance, McCallum and Li (2003) used greedy forward selection with respect to model log-likelihood to select features for named entity recognition.", "startOffset": 145, "endOffset": 286}, {"referenceID": 16, "context": "Sparse priors, such as L1 regularization, are a common feature selection technique that trades off feature sparsity with the model\u2019s objective (Gao et al., 2007). Martins et al. (2011) extended such sparse regularization techniques to allow a model to deselect entire feature templates, potentially saving entire blocks of feature extraction computation.", "startOffset": 144, "endOffset": 185}, {"referenceID": 2, "context": "Selection of morphological attributes has been carried out previously in Ballesteros (2013) and selection of features under similar constraints was carried out by Ballesteros and Bohnet (2014).", "startOffset": 73, "endOffset": 92}, {"referenceID": 2, "context": "Selection of morphological attributes has been carried out previously in Ballesteros (2013) and selection of features under similar constraints was carried out by Ballesteros and Bohnet (2014).", "startOffset": 73, "endOffset": 193}, {"referenceID": 36, "context": "(Peng et al., 2005).", "startOffset": 0, "endOffset": 19}, {"referenceID": 14, "context": "The tagger is trained online using MIRA (Crammer et al., 2006).", "startOffset": 40, "endOffset": 62}, {"referenceID": 7, "context": "The joint tagger-parser follows the design of Bohnet et al. (2013), who augment an arcstandard transition-based dependency parser with the capability to select a part-of-speech tag and/or morphological tag for each input word from an n-best list of tags for that word.", "startOffset": 46, "endOffset": 67}, {"referenceID": 7, "context": "When pruning the beam, it first extracts the 40 highest scoring distinct dependency trees and then up to 8 variants that differ only with respect to the tagging, a technique that was found by Bohnet et al. (2013) to give a good balance between tagging and parsing ambiguity in the beam.", "startOffset": 192, "endOffset": 213}, {"referenceID": 16, "context": "For Hungarian, we use the Szeged Dependency Treebank (Farkas et al., 2012).", "startOffset": 53, "endOffset": 74}, {"referenceID": 4, "context": "For Russian we use the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002).", "startOffset": 42, "endOffset": 94}, {"referenceID": 5, "context": "For Russian we use the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002).", "startOffset": 42, "endOffset": 94}, {"referenceID": 6, "context": "2 For German, we use the Tiger Treebank (Brants et al., 2002) in the improved dependency conversion by Seeker and Kuhn (2012). For Hungarian, we use the Szeged Dependency Treebank (Farkas et al.", "startOffset": 41, "endOffset": 126}, {"referenceID": 8, "context": "ical attributes are predicted jointly with syntactic dependencies (Bohnet et al., 2013).", "startOffset": 66, "endOffset": 87}, {"referenceID": 22, "context": "case, number, tense), we explore a simple method System POS LAS UAS # Chinese Li et al. (2011) 93.", "startOffset": 78, "endOffset": 95}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.", "startOffset": 3, "endOffset": 24}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.", "startOffset": 3, "endOffset": 60}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.", "startOffset": 3, "endOffset": 143}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.", "startOffset": 3, "endOffset": 176}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.", "startOffset": 3, "endOffset": 204}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.", "startOffset": 3, "endOffset": 232}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.", "startOffset": 3, "endOffset": 261}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.", "startOffset": 3, "endOffset": 288}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Bohnet and Nivre (2012) 97.", "startOffset": 3, "endOffset": 318}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Bohnet and Nivre (2012) 97.33 92.44 93.38 Zhang et al. (2013) 93.", "startOffset": 3, "endOffset": 356}, {"referenceID": 20, "context": "55 Hatori et al. (2012) 93.94 81.20 Bohnet and Nivre (2012) 93.24 77.91 81.42 joint-static 94.14 78.77 81.91 20 English McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Bohnet and Nivre (2012) 97.33 92.44 93.38 Zhang et al. (2013) 93.50 Koo et al. (2008) \u2020 93.", "startOffset": 3, "endOffset": 380}, {"referenceID": 12, "context": "16 Carreras et al. (2008) \u2020 93.", "startOffset": 3, "endOffset": 26}, {"referenceID": 12, "context": "16 Carreras et al. (2008) \u2020 93.5 Suzuki et al. (2009) \u2020 93.", "startOffset": 3, "endOffset": 54}, {"referenceID": 11, "context": "81 Hungarian Farkas et al. (2012) 87.", "startOffset": 13, "endOffset": 34}, {"referenceID": 4, "context": "1 Bohnet et al. (2013) 97.", "startOffset": 2, "endOffset": 23}, {"referenceID": 4, "context": "32 Russian Boguslavsky et al. (2011) 86.", "startOffset": 11, "endOffset": 37}, {"referenceID": 4, "context": "32 Russian Boguslavsky et al. (2011) 86.0 90.0 Bohnet et al. (2013) 98.", "startOffset": 11, "endOffset": 68}, {"referenceID": 36, "context": "Third, dynamic feature selection strategies (Peng et al., 2005) lead to more compact models than static feature selection, without significantly impacting accuracy.", "startOffset": 44, "endOffset": 63}], "year": 2016, "abstractText": "We study the use of greedy feature selection methods for morphosyntactic tagging under a number of different conditions. We compare a static ordering of features to a dynamic ordering based on mutual information statistics, and we apply the techniques to standalone taggers as well as joint systems for tagging and parsing. Experiments on five languages show that feature selection can result in more compact models as well as higher accuracy under all conditions, but also that a dynamic ordering works better than a static ordering and that joint systems benefit more than standalone taggers. We also show that the same techniques can be used to select which morphosyntactic categories to predict in order to maximize syntactic accuracy in a joint system. Our final results represent a substantial improvement of the state of the art for several languages, while at the same time reducing both the number of features and the running time by up to 80% in some cases.", "creator": "LaTeX with hyperref package"}}}