{"id": "1603.07012", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2016", "title": "Semi-supervised Word Sense Disambiguation with Neural Models", "abstract": "Determining the intended sense of words in text -- word sense disambiguation (WSD) -- is a long-standing problem in natural language processing. In this paper, we present WSD algorithms which use neural network language models to achieve state-of-the-art precision. Each of these methods learns to disambiguate word senses using only a set of word senses, a few example sentences for each sense taken from a licensed lexicon, and a large unlabeled text corpus. We classify based on cosine similarity of vectors derived from the contexts in unlabeled query and labeled example sentences. We demonstrate state-of-the-art results when using the WordNet sense inventory, and significantly better than baseline performance using the New Oxford American Dictionary inventory. The best performance was achieved by combining an LSTM language model with graph label propagation.", "histories": [["v1", "Tue, 22 Mar 2016 22:15:10 GMT  (207kb,D)", "http://arxiv.org/abs/1603.07012v1", null], ["v2", "Sat, 5 Nov 2016 01:15:21 GMT  (153kb,D)", "http://arxiv.org/abs/1603.07012v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dayu yuan", "julian richardson", "ryan doherty", "colin evans", "eric altendorf"], "accepted": false, "id": "1603.07012"}, "pdf": {"name": "1603.07012.pdf", "metadata": {"source": "CRF", "title": "Word Sense Disambiguation with Neural Language Models", "authors": ["Dayu Yuan", "Ryan Doherty", "Julian Richardson", "Colin Evans", "Eric Altendorf"], "emails": ["dayuyuan@google.com", "portalfire@google.com", "jdcr@google.com", "colinhevans@google.com", "ealtendorf@google.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is in such a way that we are able to assert ourselves in a position to assert that we are able to assert ourselves in the world, that we are able to assert ourselves in the world, that we are in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in, in the world, in, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the, in the world, in the, in the world, in the world, in the, in the, in, in the, in the world, in, in the world, in the, in, in the, in, in the world, in the, in, in, in, in the world, in, in the, in, in the world, in the, in, in the, in, in, in the, in the world, in, in, in, in the, in, in the, in, in, in the, in the, in the, in, in, in the, in, in, in the, in, in the, in the, in, in the, in the, in the, in, in, in the, in, in, in the, in, in the, in the, in, in the, in, in, in the, in the, in the, in the, in the, in, in, in the, in the, in the, in, in the, in, in, in the, in the, in the, in, in the, in, in, in the, in the, in, in, in the, in, in, in the, in, in the, in the, in, in the, in the, in, in, in, in"}, {"heading": "2 Related Work", "text": "Recent development of large lexical resources such as WordNet (Fellbaum, 1998) and BabelNet (Navigli et al., 2013; Moro et al., 2015) has enabled knowledge-based algorithms that show promising results in word-based prediction tasks (Ponzetto and Navigli, 2010; Navigli et al., 2007; Navigli et al., 2007; Navigli, 2009; Zhong and Ng, 2010). Acquiring large training sets is costly. In this paper, we show that a supervised WSD algorithm can work well with a small number (e.g. 20) of training examples per sense."}, {"heading": "3 Classifying Using Example Sentences", "text": "The methods we propose require one or more sample sentences for each sense of the inventory to which we want to assign. Our monitored WSD algorithms (Section 4) classify a word by finding the sample sentences that are most similar to the sentence in which the word occurs (Figure 3a). To overcome the relative scarcity in the space of the sample sentences, we also present a semi-monitored method (Section 5) that supplements the sample sentences with a large number of unlabeled sentences from the net. Sense labels are then transferred from the sample sentences to the unlabeled sentences (Figure 3)."}, {"heading": "4 Supervised WSD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Word Vector Similarity", "text": "The CBOW model is designed to predict a target word with its context as input text (Mikolov et al., 2013). We use the context vector of CBOW for WSD. We used 1000-dimensional labels from a 100 billion-word message corpus to add the vectors of the context word and then predict the target with the context vector (Figure 1). The vocabulary consists of the most common 1, 000 000 000 words, without lemmatization or case normalization."}, {"heading": "6 Experiments", "text": "We investigated the performance with different experiments. We compared the NNLMs of CBOW and LSTM with and without LP. We trained at different corporations using two different inventories. We also compared the performance of our algorithms with a selection of basic WSD algorithms and with the results of SemEval 2013 and 2015."}, {"heading": "6.1 Word Sense Inventory", "text": "In this paper, we use the New Oxford American Dictionary (NOAD) (Stevenson and Lindberg, 2010), which focuses on American English and is based on the Oxford Dictionary of English (ODE) (Stevenson, 2010). It distinguishes in the same way between coarse (core) and fine-grained (sub-) phrases such as ODE. Previous research (Navigli, 2006; Navigli et al., 2007) using the ODE example has shown that coarse-grained words caused by the ODE inventory address problems with the fine-grained inventory of WordNet, and that the inventory is useful for word confusion. In our experiments, we use the core senses of NOAD, and we use lexicographically curated sample phrases from the Semantic English Language Database (NOSELD) 1, which are provided by Oxford University. Table 3 shows the total number of polytzes."}, {"heading": "6.2 NOAD Experiment", "text": "Table 4 lists the number of ambiguous words and the average number of candidates senses per word in NOAD, SemCor and MASC.We compare our algorithms with five basic algorithms: \u2022 First sense: Label word w with w's firstNOAD sense, which is typically the most popular sense. \u2022 Most frequent sense: Compute the sense fre-quency (from a labeled corpus) and label word w with w's most common sense. \u2022 Gloss overlap: Annotation of a word in a toxic context with the sense whose definition overlaps most with the context. \u2022 Fuzzy Gloss overlap: Similar to glosoverlap, but we measure the overlap of two words with the cosmic similarity between the two words \"CBOW word vectors.\" \u2022 Reader: Note a word in a given context."}, {"heading": "6.2.1 Training data", "text": "By default, the WSD classifier uses the sample NOAD sets as training data. We build a larger training record by adding labeled sets of SemCor and MASC, and examine the change in F1 values in Tables 5 and 6. Over most of the language tags and records, both the micro and macro F1 values increase after adding more training data. We further test our algorithm by using SemCor (or MASC) as training data (without NOAD test results). The SemCor (or MASC) trained classifier is equivalent to the NOAD trained classifier in terms of F1 value."}, {"heading": "6.2.2 Change of language model capacity", "text": "In this experiment, we change the capacity of the LSTM model by varying the number of hidden units h and the dimensions of the input embeds p and measuring F1. Figure 4 shows a strong correlation between F1 and the capacity of the language model. However, larger models are slower to train and use more memory. To balance accuracy and resource consumption, we use the second best LSTM model by default (h = 2048 and p = 512)."}, {"heading": "6.3 Semi-supervised WSD", "text": "For each word, we collect three types of sentences: (1) seed sets: labeled sets from the training data sets, (2) 1000 unlabeled sets randomly scanned from the web, and (3) valuation sets with hidden gold labels. We construct the graph as described in Section 5 and execute LP to propagate scythe labels from the seed nodes to the unlabeled nodes. We suspect this is because LP is sensitive to the quality of the graph by comparing the predicted labels and gold markings on the evaluation nodes. We saw significant improvements in LP with the LSTM language model. As shown in Table 5, LP does not provide a clear benefit when using the CBOW language model. We suspect that LP is sensitive to the quality of the graph spacing."}, {"heading": "6.4 SemEval Tasks", "text": "In this section, we examine the performance of our classifiers in SemEval-2013 Task 12 (Navigli et al., 2013) and SemEval-2015 Task 13 (Moro and Navigli, 2015), both of which use WordNet as a sensory inventory for English WSD. We use a mapping to label sample NOAD sentences with WordNet senses (see Section 6.1) for the training. We also use SemCor (commented with WordNet senses) for the training. To make a fair comparison with related works, the classifiers are evaluated for all words (both polysamen and monosemales). Table 7 shows the results of Sem-Eval 2013. Our proposed algorithms surpass UMCCDLSI, the best WSD algorithm reported in SemEval 2013. The LP classifier with an LSTM language model has the highest score. Table 8 shows the results of Sem-Eval 2015."}, {"heading": "7 Discussion and Future Work", "text": "Our approach to WSD is not based on large marked data sets or structured semantic resources, both of which are costly to curate. Instead, it relies on powerful language models learned from large unmarked corpora, and on label propagation over blank sentences using representations learned through the language model, which allows us to use small (e.g. 20 examples per sense) marked data sets that can be licensed from existing lexicographic sources. Several unanswered questions point to lines of future work. We have not yet investigated the relationship between the number of marked training examples and performance. As our general approach is capable of incorporating any given language model, further developments in NNLMs could enable higher performance. We would also like to better understand the limitations of language modeling for this task: we expect there to be situations - e.g. in idiomatic phrases - where word visions contain little information."}, {"heading": "8 Conclusion", "text": "In this paper, we have presented several WSD algorithms that combine (1) neural network speech models trained on a large, unlabeled text corpus, with (2) labeled data in the form of sample sentences, and optionally (3) unlabeled data in the form of additional sentences. Each of our algorithms searches for the most similar sample sentences to the sentence in which the word we want to classify appears. Using an LSTM language model yielded better performance than one based on CBOW word embedding, although both exceed the current state of the art. Best performance was achieved by our semi-monitored WSD algorithm, which builds a graph of labeled sample sentences, supplemented by a large number of unlabeled sentences from the Web, and classified by the dissemination of sensory names through this graph."}], "references": [{"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014] Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski"], "venue": null, "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Computing semantic relatedness using wikipedia-based explicit semantic analysis", "author": ["Gabrilovich", "Shaul Markovitch"], "venue": "In IJCAI,", "citeRegEx": "Gabrilovich et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gabrilovich et al\\.", "year": 2007}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Characteraware neural language models", "author": ["Kim et al.2015] Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M Rush"], "venue": "arXiv preprint arXiv:1508.06615", "citeRegEx": "Kim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2015}, {"title": "Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone", "author": ["Michael Lesk"], "venue": "In Proceedings of the 5th Annual International Conference on Systems Documentation,", "citeRegEx": "Lesk.,? \\Q1986\\E", "shortCiteRegEx": "Lesk.", "year": 1986}, {"title": "Neural word embedding as implicit matrix factorization", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Extensions of recurrent neural network language model", "author": ["Stefan Kombrink", "Luk\u00e1\u0161 Burget", "Jan Honza \u010cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Mikolov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2011}, {"title": "Efficient estimation of word representations in vector space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In arXiv preprint arXiv:1301.3781", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A semantic concordance", "author": ["Claudia Leacock", "Randee Tengi", "Ross T Bunker"], "venue": "In Proceedings of the workshop on Human Language Technology,", "citeRegEx": "Miller et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Miller et al\\.", "year": 1993}, {"title": "Semeval-2015 task 13: multilingual all-words sense disambiguation and entity linking", "author": ["Moro", "Navigli2015] Andrea Moro", "Roberto Navigli"], "venue": "Proc. of SemEval,", "citeRegEx": "Moro et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Moro et al\\.", "year": 2015}, {"title": "Entity linking meets word sense disambiguation: a unified approach. Transactions of the Association for Computational Linguistics, 2:231\u2013244", "author": ["Moro et al.2014] Andrea Moro", "Alessandro Raganato", "Roberto Navigli"], "venue": null, "citeRegEx": "Moro et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Moro et al\\.", "year": 2014}, {"title": "BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network", "author": ["Navigli", "Ponzetto2012] Roberto Navigli", "Simone Paolo Ponzetto"], "venue": "Artificial Intelligence,", "citeRegEx": "Navigli et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Navigli et al\\.", "year": 2012}, {"title": "Semeval2007 task 07: Coarse-grained English all-words task", "author": ["Kenneth C Litkowski", "Orin Hargraves"], "venue": "In Proceedings of the 4th International Workshop on Semantic Evaluations,", "citeRegEx": "Navigli et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Navigli et al\\.", "year": 2007}, {"title": "Semeval-2013 task 12: Multilingual word sense disambiguation", "author": ["David Jurgens", "Daniele Vannella"], "venue": "In Second Joint Conference on Lexical and Computational Semantics (* SEM),", "citeRegEx": "Navigli et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Navigli et al\\.", "year": 2013}, {"title": "Meaningful clustering of senses helps boost word sense disambiguation performance", "author": ["Roberto Navigli"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Associ-", "citeRegEx": "Navigli.,? \\Q2006\\E", "shortCiteRegEx": "Navigli.", "year": 2006}, {"title": "Word sense disambiguation: A survey", "author": ["Roberto Navigli"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "Navigli.,? \\Q2009\\E", "shortCiteRegEx": "Navigli.", "year": 2009}, {"title": "Knowledge-rich word sense disambiguation rivaling supervised systems", "author": ["Ponzetto", "Roberto Navigli"], "venue": "In Proceedings of the 48th Annual Meeting of the Association", "citeRegEx": "Ponzetto et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ponzetto et al\\.", "year": 2010}, {"title": "Semeval-2007 task 17: English lexical sample, SRL and all words", "author": ["Edward Loper", "Dmitriy Dligach", "Martha Palmer"], "venue": "In Proceedings of the 4th International Workshop on Semantic Evaluations,", "citeRegEx": "Pradhan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2007}, {"title": "Large scale distributed semi-supervised learning using streaming approximation", "author": ["Ravi", "Diao2016] Sujith Ravi", "Qiming Diao"], "venue": "In AISTATS", "citeRegEx": "Ravi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ravi et al\\.", "year": 2016}, {"title": "Autoextend: Extending word embeddings to embeddings for synsets and lexemes", "author": ["Rothe", "Sch\u00fctze2015] Sascha Rothe", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Rothe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rothe et al\\.", "year": 2015}, {"title": "Recursive deep models for semantic compositionality over", "author": ["Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "LSTM neural networks for language modeling", "author": ["Ralf Schl\u00fcter", "Hermann Ney"], "venue": "In INTERSPEECH,", "citeRegEx": "Sundermeyer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sundermeyer et al\\.", "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Semi-supervised word sense disambiguation using word embeddings in general and specific domains", "author": ["Taghipour", "Ng2015] Kaveh Taghipour", "Hwee Tou Ng"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter", "citeRegEx": "Taghipour et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Taghipour et al\\.", "year": 2015}, {"title": "New regularized algorithms for transductive learning", "author": ["Talukdar", "Koby Crammer"], "venue": "In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II,", "citeRegEx": "Talukdar et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Talukdar et al\\.", "year": 2009}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Turian et al.2010] Joseph Turian", "Lev Ratinov", "Yoshua Bengio"], "venue": "In Proceedings of the 48th annual meeting of the association for computational linguistics,", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "It makes sense: A wide-coverage word sense disambiguation system for free text", "author": ["Zhong", "Ng2010] Zhi Zhong", "Hwee Tou Ng"], "venue": "ACLDemos", "citeRegEx": "Zhong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 15, "context": "Word sense disambiguation (WSD) is a longstanding problem in natural language processing (NLP) with broad applications (Navigli, 2009).", "startOffset": 119, "endOffset": 134}, {"referenceID": 15, "context": "Supervised, unsupervised, and knowledge-based approaches have been studied for WSD (Navigli, 2009).", "startOffset": 83, "endOffset": 98}, {"referenceID": 17, "context": "However, for all-words WSD, where all words in a corpus need to be annotated with word senses, it has proven extremely challenging to beat the strong baseline, which always assigns the most frequent sense of a word without considering the context (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Navigli et al., 2013; Moro and Navigli, 2015).", "startOffset": 247, "endOffset": 352}, {"referenceID": 12, "context": "However, for all-words WSD, where all words in a corpus need to be annotated with word senses, it has proven extremely challenging to beat the strong baseline, which always assigns the most frequent sense of a word without considering the context (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Navigli et al., 2013; Moro and Navigli, 2015).", "startOffset": 247, "endOffset": 352}, {"referenceID": 15, "context": "However, for all-words WSD, where all words in a corpus need to be annotated with word senses, it has proven extremely challenging to beat the strong baseline, which always assigns the most frequent sense of a word without considering the context (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Navigli et al., 2013; Moro and Navigli, 2015).", "startOffset": 247, "endOffset": 352}, {"referenceID": 13, "context": "However, for all-words WSD, where all words in a corpus need to be annotated with word senses, it has proven extremely challenging to beat the strong baseline, which always assigns the most frequent sense of a word without considering the context (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Navigli et al., 2013; Moro and Navigli, 2015).", "startOffset": 247, "endOffset": 352}, {"referenceID": 15, "context": "Given the good performance of published supervised WSD systems when provided with significant training data on specific words (Navigli, 2009; Zhong and Ng, 2010), it appears lack of sufficient labeled training data for large vocabularies is the central problem.", "startOffset": 126, "endOffset": 161}, {"referenceID": 7, "context": "The first model is the continuous bag of words model (CBOW) (Mikolov et al., 2013).", "startOffset": 60, "endOffset": 82}, {"referenceID": 13, "context": "The recent development of large lexical resources, such as WordNet (Fellbaum, 1998) and BabelNet (Navigli and Ponzetto, 2012), has enabled knowledge-based algorithms which show promising results on all-word prediction tasks (Ponzetto and Navigli, 2010; Navigli et al., 2013; Moro and Navigli, 2015).", "startOffset": 224, "endOffset": 298}, {"referenceID": 17, "context": "WSD algorithms based on supervised learning are generally believed to perform better than knowledge-based WSD algorithms, but they need large training sets to perform well (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Zhong and Ng, 2010).", "startOffset": 172, "endOffset": 251}, {"referenceID": 12, "context": "WSD algorithms based on supervised learning are generally believed to perform better than knowledge-based WSD algorithms, but they need large training sets to perform well (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Zhong and Ng, 2010).", "startOffset": 172, "endOffset": 251}, {"referenceID": 15, "context": "WSD algorithms based on supervised learning are generally believed to perform better than knowledge-based WSD algorithms, but they need large training sets to perform well (Pradhan et al., 2007; Navigli et al., 2007; Navigli, 2009; Zhong and Ng, 2010).", "startOffset": 172, "endOffset": 251}, {"referenceID": 7, "context": "In the past few years, much progress has been made on using neural networks to learn word embeddings (Mikolov et al., 2013; Levy and Goldberg, 2014), to construct language models (Mikolov et al.", "startOffset": 101, "endOffset": 148}, {"referenceID": 6, "context": ", 2013; Levy and Goldberg, 2014), to construct language models (Mikolov et al., 2011), perform sentiment analysis (Socher et al.", "startOffset": 63, "endOffset": 85}, {"referenceID": 20, "context": ", 2011), perform sentiment analysis (Socher et al., 2013), machine translation (Sutskever et al.", "startOffset": 36, "endOffset": 57}, {"referenceID": 22, "context": ", 2013), machine translation (Sutskever et al., 2014) and many other NLP applications.", "startOffset": 29, "endOffset": 53}, {"referenceID": 6, "context": "In the past few years, much progress has been made on using neural networks to learn word embeddings (Mikolov et al., 2013; Levy and Goldberg, 2014), to construct language models (Mikolov et al., 2011), perform sentiment analysis (Socher et al., 2013), machine translation (Sutskever et al., 2014) and many other NLP applications. For the WSD problem, Rothe and Sch\u00fctze (2015) extended word embeddings to word sense or synset embeddings, and trained a SVM classifier (Zhong and Ng, 2010) with word sense and synset embeddings as features.", "startOffset": 102, "endOffset": 377}, {"referenceID": 6, "context": "In the past few years, much progress has been made on using neural networks to learn word embeddings (Mikolov et al., 2013; Levy and Goldberg, 2014), to construct language models (Mikolov et al., 2011), perform sentiment analysis (Socher et al., 2013), machine translation (Sutskever et al., 2014) and many other NLP applications. For the WSD problem, Rothe and Sch\u00fctze (2015) extended word embeddings to word sense or synset embeddings, and trained a SVM classifier (Zhong and Ng, 2010) with word sense and synset embeddings as features. Taghipour et al. (2015) trained a feedforward neural network with automatically labeled training samples to learn word embeddings for WSD.", "startOffset": 102, "endOffset": 563}, {"referenceID": 25, "context": "Distributional methods, in particular using word vectors trained using neural networks, have been shown to be extremely effective in NLP tasks (Turian et al., 2010; Baroni et al., 2014).", "startOffset": 143, "endOffset": 185}, {"referenceID": 0, "context": "Distributional methods, in particular using word vectors trained using neural networks, have been shown to be extremely effective in NLP tasks (Turian et al., 2010; Baroni et al., 2014).", "startOffset": 143, "endOffset": 185}, {"referenceID": 7, "context": "The CBOW model is trained to predict a target word with its context as input (Mikolov et al., 2013).", "startOffset": 77, "endOffset": 99}, {"referenceID": 7, "context": "We used 1000-dimensional embeddings from a 100-billion-word news corpus, trained using word2vec (Mikolov et al., 2013).", "startOffset": 96, "endOffset": 118}, {"referenceID": 21, "context": "Neural networks with long short-term memory (LSTM) units (Hochreiter and Schmidhuber, 1997) make good language models which do consider word order (Sundermeyer et al., 2012).", "startOffset": 147, "endOffset": 173}, {"referenceID": 14, "context": "Previous investigations (Navigli, 2006; Navigli et al., 2007) using the ODE have shown that coarse-grained word senses induced by the ODE inventory address problems with WordNet\u2019s fine-grained inventory, and that the inventory is useful for word sense disambiguation.", "startOffset": 24, "endOffset": 61}, {"referenceID": 12, "context": "Previous investigations (Navigli, 2006; Navigli et al., 2007) using the ODE have shown that coarse-grained word senses induced by the ODE inventory address problems with WordNet\u2019s fine-grained inventory, and that the inventory is useful for word sense disambiguation.", "startOffset": 24, "endOffset": 61}, {"referenceID": 8, "context": "We manually annotated all words of the English language SemCor (Miller et al., 1993) corpus and MASC 2 corpora with NOAD word senses in order to evaluate performance.", "startOffset": 63, "endOffset": 84}, {"referenceID": 4, "context": "\u2022 Lesk: Annotate a word in a given context with the sense whose gloss shares the largest number of common words with the glosses of the other words in the context (Lesk, 1986).", "startOffset": 163, "endOffset": 175}, {"referenceID": 13, "context": "In this section, we study the performance of our classifiers on SemEval-2013 Task 12 (Navigli et al., 2013) and SemEval-2015 task 13 (Moro and Navigli, 2015).", "startOffset": 85, "endOffset": 107}, {"referenceID": 3, "context": "Character-level LSTMs (Kim et al., 2015) may provide robustness to morphology and diacritics and may prove useful even in English for spelling errors and out of vocabulary words.", "startOffset": 22, "endOffset": 40}, {"referenceID": 15, "context": "We would also like to investigate how work on unsupervised sense induction (Navigli, 2009) could be integrated with our models to detect out of vocabulary senses \u2013 particularly a problem in web text where terminology evolves rapidly.", "startOffset": 75, "endOffset": 90}, {"referenceID": 10, "context": "Finally, many applications of WSD systems for nominal resolution require integration with resolution systems for named entities, since surface forms often overlap (Moro et al., 2014; Navigli and Ponzetto, 2012).", "startOffset": 163, "endOffset": 210}], "year": 2017, "abstractText": "Determining the intended sense of words in text \u2013 word sense disambiguation (WSD) \u2013 is a long-standing problem in natural language processing. In this paper, we present WSD algorithms which use neural network language models to achieve state-of-the-art precision. Each of these methods learns to disambiguate word senses using only a set of word senses, a few example sentences for each sense taken from a licensed lexicon, and a large unlabeled text corpus. We classify based on cosine similarity of vectors derived from the contexts in unlabeled query and labeled example sentences. We demonstrate state-of-the-art results when using the WordNet sense inventory, and significantly better than baseline performance using the New Oxford American Dictionary inventory. The best performance was achieved by combining an LSTM language model with graph label propagation.", "creator": "LaTeX with hyperref package"}}}