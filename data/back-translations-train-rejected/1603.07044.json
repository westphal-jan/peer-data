{"id": "1603.07044", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2016", "title": "Recurrent Neural Network Encoder with Attention for Community Question Answering", "abstract": "We apply a general recurrent neural network (RNN) encoder framework to community question answering (cQA) tasks. Our approach does not rely on any linguistic processing, and can be applied to different languages or domains. Further improvements are observed when we extend the RNN encoders with a neural attention mechanism that encourages reasoning over entire sequences. To deal with practical issues such as data sparsity and imbalanced labels, we apply various techniques such as transfer learning and multitask learning. Our experiments on the SemEval-2016 cQA task show 10% improvement on a MAP score compared to an information retrieval-based approach, and achieve comparable performance to a strong handcrafted feature-based method.", "histories": [["v1", "Wed, 23 Mar 2016 01:52:54 GMT  (1272kb,D)", "http://arxiv.org/abs/1603.07044v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["wei-ning hsu", "yu zhang", "james glass"], "accepted": false, "id": "1603.07044"}, "pdf": {"name": "1603.07044.pdf", "metadata": {"source": "CRF", "title": "Recurrent Neural Network Encoder with Attention for Community Question Answering", "authors": ["Wei-Ning Hsu"], "emails": ["wnhsu@csail.mit.edu", "yzhang87@csail.mit.edu", "jrg@csail.mit.edu"], "sections": [{"heading": "1 Introduction", "text": "Over the past decade, these websites have attracted a large number of users, and they have amassed a large collection of questions and comments that users have answered with a new question, or when looking for solutions to an existing question. The automation of cQA forums can be divided into three tasks: question-comment relevance (task B) and question-relevance (task C)."}, {"heading": "2 Related Work", "text": "Previous work to answer community questions relied heavily on feature engineering, linguistic tools, and external resources. (Jeon et al., 2006) and (Shah and Pomerantz, 2010) used rich non-textual features such as the profile of the answer. (Grundstro \u00b6 m and Nugues, 2014) syntactically analyzed the question and extracted characteristics of naming units. (Harabagiu and Hickl, 2006) showed that a textual interweaving system can improve the cQA task by raising questions to logical correlations. Recent work integrated word vectors into their feature extraction system and based on this developed different distance metrics for question and answer (Tran et al., 2015) (Belinkov et al., 2015). While these approaches showed effectiveness, it is difficult to generalize them to common cQA tasks, since linguistic tools and external resources in other languages and features can be restrictive."}, {"heading": "3 Method", "text": "In this section, we will first discuss the units of long-term short-term memory (LSTM) and the attentiveness mechanism associated with it. Next, we will explain how to encode a sentence pair into a dense vector for predicting relationships using an LSTM with attentiveness mechanism. Finally, we will apply these models to predict similarities between question and comment, similarities between question and comment, and similarities between question and comment."}, {"heading": "3.1 LSTM Models", "text": "An LSTM unit contains a self-connecting memory cell and three multiplicative gates for controlling the flow of information. In view of the input vector xt, earlier hidden outputs ht \u2212 1 and the earlier cell state ct \u2212 1, LSTM units function as follows: X = [xtht \u2212 1] (1) it = \u03c3 (WiXX + Wicct \u2212 1 + bi) (2) ft = \u03c3 (WfXX + Wfcct \u2212 1 + bf) (3) ot = \u03c3 (WoXX + Wocct \u2212 1 + bo) (4) ct = ft ct \u2212 1 + it tanh (WcXX + bc) (5) ht = ot tanh (ct) (6), each of which are input, forget and output gates. The sigmoid function \u043c () is a soft gate function for controlling the flow of information. W s and b are model parameters to be learned."}, {"heading": "3.2 Neural Attention", "text": "A traditional RNN encoder decoder approach (Sutskever et al., 2014) initially encodes any length input sequence into a dense fixed-length vector that can be used as input for subsequent classification models or to initialize the hidden state of a secondary decoder. However, the requirement to compress all necessary information into a single fixed-length vector can be problematic. A neural attention model (Bahdanau et al., 2014) (Cho et al., 2014) was recently proposed to mitigate this problem by allowing the network to take into account past outputs when decoding. Thus, the encoder no longer needs to represent a whole sequence with a vector; instead, it encodes information into a sequence of vectors and adaptively selects a subset of vectors when decoding."}, {"heading": "3.3 Predicting Relationships of Object Pairs with an Attention Model", "text": "In our cQA tasks, the object pair is (question, question) or (question, comment), and the relationship is relevant / irrelevant. On the left side of Figure 1, an intuitive way to predict relationships using RNNs is shown. Parallel LSTMs encode two objects independently of each other and then link their results as input to a forward-facing neural network (FNN) with a softmax output layer for classification. The representations of the two objects are generated independently of each other. However, we are more interested in the relationship than the object representation itself. Therefore, we are looking at a serialized LSTM encoder model in the right side of Figure 1 that resembles the representation in (Rockta \ufffd schel et al., 2015), but also allows extended feature input to the FNN classification. Figure 2 illustrates our attention frame in more detail. The first LSTM reads an object and passes information hidden units to the second LM object."}, {"heading": "3.4 Modeling Question-External Comments", "text": "For task C, in addition to an initial question (oriQ) and an external comment (relC), the question on which relC commented (relQ) is also posed. To include this additional information, we consider a multitask learning framework that collectively learns to predict the relationships of the three pairs (oriQ / relQ, oriQ / relC, relQ / relC). Figure 3 shows our framework: The three lower models are separate serial LSTM encoders for the three pairs of objects, while the upper model is a FNN that takes the concatenation of the outputs of three encoders as input and predicts the relationships for all three pairs. Specifically, the output layer consists of three Softmax layers, each of which is designed to predict the relationship of a particular combination of numbers. For the total loss function, we combine three separate loss functions using a heuristic weight vector \u03b2, which assigns a higher weight to the main task (oriQ-C relationship, followed by 1: \u03b23)."}, {"heading": "4 Experiments", "text": "We evaluate our approach on all three cQA tasks. We use the cQA datasets provided by Semeval 2016 Paper 1. The cQA data is organized as follows: There are 267 original questions, each question has 10 related questions, and each related question has 10 comments. Therefore, for Paper A there is a total of 26,700 question comment pairs. For Paper B there are 2,670 question pairs. For Paper C there are 26,700 question comment pairs. The test data set includes 50 questions, 500 related questions, and 5000 comments that are not consistent with 1http: / / alt.qcri.org / semeval2016 / task3the Training Set."}, {"heading": "4.1 Preliminary Results", "text": "Table 2 shows the initial results with the RNN encoder for various tasks. We observe that the attention model without attention always achieves better results than the RNN, especially in task C. However, the RNN model achieves a very low F1 value. In task B, it is even worse than the random baseline. We believe that the reason for this is that in task B there are only 2,670 pairs of training, which is very limited training for a reasonable neural network. In task C, we believe that the problem is highly unbalanced data. As the corresponding comments did not directly comment on the original question, more than 90% of the comments are considered irrelevant to the original question. Low F1 (with high precision and low memory) means that our system identifies most of the comments as irrelevant. In the following section, we will examine methods for solving these problems."}, {"heading": "4.2 Robust Parameter Initialization", "text": "One way to improve models trained on limited data is to use external data to pre-train the neural network. Therefore, we considered two different sets of data for this task. \u2022 Cross-domain: The corpus of Stanford Natural Language Inference (SNLI) (Bowman et al., 2015) contains an enormous amount of purified presumption and hypotheses pairs. Unfortunately, the pairs have a different task. The relationship between premise and hypothesis may be similar to the relationship between questions and comments, but may be different. \u2022 Cross-domain: Since task A performs reasonably and the network is also well-trained, we could use it directly to initialize task B. To use the data, we first trained the model on each helper task (SNLI or task A) and then removed the softmax layer. Then we train the network using the target data with a softmax layer that was randomly initialized."}, {"heading": "4.3 Multitask Learning", "text": "As mentioned in Section 3.4, we have also examined a multitask learning framework that collectively learns to predict the relationships between all three tasks. We have set 0.8 for the main task (task C) and 0.1 for the other auxiliary tasks. MAP score has not improved, but F1 rises to 0.1617. We believe this is due to other tasks having more balanced names, which improves the common parameters for task C."}, {"heading": "4.4 Augmented data", "text": "There are many sources of external question-and-answer pairs that could be used in our tasks. For example: WebQuestion (introduced by the authors of the SEMPRE system (Berant et al., 2013) and The SimpleQuestions dataset 2. All of them are positive examples of our task and we can easily create negative examples from them. Initial experiments suggest that it is very easy to surpass these obvious negative examples. We believe this is because our negative2http: / / fb.ai / babi.examples are not informative for our task and we merely introduce notes. As the external data appears to affect performance, we try to use the in-domain pairs to improve task B and task C. For task B, if relative question 1 (Relativ1) and relative question 2 (Relativ2) are both relevant for the original question, then we add a positive sample (Relativ1, Relativ2)."}, {"heading": "4.5 Augmented features", "text": "To further improve the system, we add a single hot vector of the original IR ranking to the FNN classifier as an additional feature. Table 3 shows the results. When comparing the models with and without advanced features, we see big improvements for task B and C. The F1 value for task A deteriorates slightly, but MAP improves. This may be because task A already had a significant amount of training data."}, {"heading": "4.6 Comparison with Other Systems", "text": "Table 4 provides the final comparison between different models (we only list the MAP value because it is the official value for the challenge).Since the two basic models did not use any additional data, our system in this table was also limited to the provided training data. In task A, we can see that our single system already performs better than a very strong feature-rich system if sufficient training data is provided. In task B, since there is only limited training data, both the feature-rich system and our system are inferior to the IR system. In task C, our system has also achieved comparable results with the feature-rich system. If we perform a simple system combination (average ranking) between our system and the IR system, the combined system will make great profits in task B and task C3. This means that our system renders the IR system complementary."}, {"heading": "5 Analysis of Attention Mechanism", "text": "In addition to quantitative analysis, it is natural to evaluate the performance of the attention mechanism qualitatively by visualizing the weight distribution of each instance. We randomly selected several examples from the test set in task A. These examples are shown in Figure 5 and categorized into short, long, and loud sentences for discussion, with a darker bruise indicating greater weight compared to other words in the same sentence."}, {"heading": "5.1 Short Sentences", "text": "Figure 5a illustrates two cQA examples whose questions are relatively short: the comments that correspond to these questions are... \"snorkeling two days ago off the coast of Dukhan...\" and \"Doha International Airport....\" We can observe that our model successfully learns to focus on the most representative part of the question concerning the classification of the relationship, namely \"place to snorkel\" for the first example and \"place to visit... in Qatar\" for the second example.3The feature-rich based system has already been combined with the IR system.)"}, {"heading": "5.2 Long Sentences", "text": "In Figure 5b, we examine two examples with longer questions, both of which contain 63 words. Interestingly, the weight distribution is not becoming more uniform; the model still focuses attention on a small number of hot words, such as \"puppy dog for... shopping mall\" and \"frantic driving in doha... car insurance... quite expensive.\" Also, some words that occur frequently but contain little classification information are assigned very small weights, such as I / we / my, is / am, like, and to."}, {"heading": "5.3 Noisy Sentence", "text": "Figure 5c is an example of the excessive use of question marks. Here, too, our model proves its robustness by assigning very low weights to noise symbols, thus excluding non-informative content."}, {"heading": "6 Conclusion", "text": "By adding a neural attention mechanism, we demonstrated quantitatively and qualitatively that attention can improve the RNN encoder framework. To handle a more realistic scenario, we expanded the framework to include metadata as extended inputs in an FNN classifier and pre-trained models for larger sets of data, increasing stability and performance. Our model is consistently better or comparable to a strong feature-rich base system and superior to an IR-based system when there is an appropriate level of training data. Our model complements an IR-based system that uses vast amounts of external resources but is trained for general purposes. By combining the two systems, it outperforms the feature-rich and IR- based system in all three tasks. In addition, our approach is also language-independent. We have also conducted preliminary experiments on the Arabic part of the QA task SemEval-2016."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.0473", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Vectorslu: A continuous word vector approach to answer selection in community question answering systems", "author": ["Mitra Mohtarami", "Scott Cyphers", "James Glass"], "venue": "In Proceedings of the 9th International", "citeRegEx": "Belinkov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Belinkov et al\\.", "year": 2015}, {"title": "Semantic parsing on freebase from question-answer pairs", "author": ["Berant et al.2013] J. Berant", "A. Chou", "R. Frostig", "P. Liang"], "venue": null, "citeRegEx": "Berant et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David WardeFarley", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "A large annotated corpus for learning natural language inference", "author": ["Bowman et al.2015] S. Bowman", "G. Angeli", "C. Potts", "C. Manning"], "venue": null, "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Applying deep learning to answer selection: A study and an open task. arXiv preprint arXiv:1508.01585", "author": ["Feng et al.2015] Minwei Feng", "Bing Xiang", "Michael R Glass", "Lidan Wang", "Bowen Zhou"], "venue": null, "citeRegEx": "Feng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2015}, {"title": "LSTM: A search space odyssey", "author": ["Greff et al.2015] Klaus Greff", "Rupesh Kumar Srivastava", "Jan Koutn\u0131\u0301k", "Bas R. Steunebrink", "J\u00fcrgen Schmidhuber"], "venue": null, "citeRegEx": "Greff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Greff et al\\.", "year": 2015}, {"title": "Using syntactic features in answer reranking", "author": ["Grundstr\u00f6m", "Nugues2014] Jakob Grundstr\u00f6m", "Pierre Nugues"], "venue": "In AAAI 2014 Workshop on Cognitive Computing for Augmented Human Intelligence,", "citeRegEx": "Grundstr\u00f6m et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Grundstr\u00f6m et al\\.", "year": 2014}, {"title": "Methods for using textual entailment in open-domain question answering", "author": ["Harabagiu", "Hickl2006] Sanda Harabagiu", "Andrew Hickl"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting", "citeRegEx": "Harabagiu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Harabagiu et al\\.", "year": 2006}, {"title": "A framework to predict the quality of answers with non-textual features", "author": ["Jeon et al.2006] Jiwoon Jeon", "W Bruce Croft", "Joon Ho Lee", "Soyeon Park"], "venue": "In Proceedings of the 29th annual international ACM", "citeRegEx": "Jeon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Jeon et al\\.", "year": 2006}, {"title": "Semeval-2015 task 3: Answer selection in community question answering", "author": ["Nakov et al.2015] R. Nakov", "L. Marquez", "W. Magdy", "A. Moschitti", "J. Glass"], "venue": "In Proc. SamEval,", "citeRegEx": "Nakov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2015}, {"title": "Reasoning about entailment with neural attention", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1509.06664", "citeRegEx": "Rockt\u00e4schel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Evaluating and predicting answer quality in community qa", "author": ["Shah", "Pomerantz2010] Chirag Shah", "Jefferey Pomerantz"], "venue": "In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Shah et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Shah et al\\.", "year": 2010}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112", "author": ["Oriol Vinyals", "Quoc VV Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Jaist: Combining multiple features for answer selection in community question answering", "author": ["Tran et al.2015] Quan Hung Tran", "Vu Tran", "Tu Vu", "Minh Le Nguyen", "Son Bao Pham"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation,", "citeRegEx": "Tran et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tran et al\\.", "year": 2015}, {"title": "A long short-term memory model for answer sentence selection in question answering", "author": ["Wang", "Nyberg2015] Di Wang", "Eric Nyberg"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "A study of smoothing methods for language models applied to information retrieval", "author": ["Zhai", "Lafferty2004] C. Zhai", "J. Lafferty"], "venue": "In ACM Trans. Inf. Syst", "citeRegEx": "Zhai et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Zhai et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 11, "context": "SemEval 2015 (Nakov et al., 2015)) relied heavily on additional features and reasoning capabilities.", "startOffset": 13, "endOffset": 33}, {"referenceID": 12, "context": "In (Rockt\u00e4schel et al., 2015), a neural attention-based model was proposed for automatically recognizing entailment relations between pairs of natural language sentences.", "startOffset": 3, "endOffset": 29}, {"referenceID": 10, "context": "(Jeon et al., 2006) and (Shah and Pomerantz, 2010) utilized rich non-textual features such as answer\u2019s profile.", "startOffset": 0, "endOffset": 19}, {"referenceID": 15, "context": "More recent work incorporated word vector into their feature extraction system and based on it designed different distance metric for question and answer (Tran et al., 2015) (Belinkov et al.", "startOffset": 154, "endOffset": 173}, {"referenceID": 1, "context": ", 2015) (Belinkov et al., 2015).", "startOffset": 8, "endOffset": 31}, {"referenceID": 6, "context": "(Feng et al., 2015) proposed several convolutional neural network (CNN) architectures for cQA.", "startOffset": 0, "endOffset": 19}, {"referenceID": 14, "context": "A traditional RNN encoder-decoder approach (Sutskever et al., 2014) first encodes an arbitrary length input sequence into a fixed-length dense vector that can be used as input to subsequent classification models, or to initialize the hidden state of a secondary decoder.", "startOffset": 43, "endOffset": 67}, {"referenceID": 0, "context": "A neural attention model (Bahdanau et al., 2014) (Cho et al.", "startOffset": 25, "endOffset": 48}, {"referenceID": 5, "context": ", 2014) (Cho et al., 2014) has been recently proposed to alleviate this issue by enabling the network to attend to past outputs when decoding.", "startOffset": 8, "endOffset": 26}, {"referenceID": 12, "context": "Therefore, we consider a serialized LSTM-encoder model in the right side of Figure 1 that is similar to that in (Rockt\u00e4schel et al., 2015), but also allows an augmented feature input to the FNN classifier.", "startOffset": 112, "endOffset": 138}, {"referenceID": 1, "context": "The featurerich system is that proposed by (Belinkov et al., 2015) in SemEval-2015.", "startOffset": 43, "endOffset": 66}, {"referenceID": 3, "context": "RNN encoder: Our system is based on Theano (Bastien et al., 2012; Bergstra et al., 2010).", "startOffset": 43, "endOffset": 88}, {"referenceID": 7, "context": "As suggested by (Greff et al., 2015), the hyper-parameters for LSTMs can be tuned independently.", "startOffset": 16, "endOffset": 36}, {"referenceID": 4, "context": "\u2022 Cross-domain: The Stanford natural language inference (SNLI) corpus (Bowman et al., 2015) has a huge amount of cleaned premise and hypothesis pairs.", "startOffset": 70, "endOffset": 91}, {"referenceID": 2, "context": "For example: WebQuestion (was introduced by the authors of SEMPRE system (Berant et al., 2013)) and The SimpleQuestions dataset 2.", "startOffset": 73, "endOffset": 94}], "year": 2016, "abstractText": "We apply a general recurrent neural network (RNN) encoder framework to community question answering (cQA) tasks. Our approach does not rely on any linguistic processing, and can be applied to different languages or domains. Further improvements are observed when we extend the RNN encoders with a neural attention mechanism that encourages reasoning over entire sequences. To deal with practical issues such as data sparsity and imbalanced labels, we apply various techniques such as transfer learning and multitask learning. Our experiments on the SemEval-2016 cQA task show 10% improvement on a MAP score compared to an information retrieval-based approach, and achieve comparable performance to a strong handcrafted feature-based method.", "creator": "LaTeX with hyperref package"}}}