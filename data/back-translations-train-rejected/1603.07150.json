{"id": "1603.07150", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2016", "title": "The Anatomy of a Search and Mining System for Digital Archives", "abstract": "Samtla (Search And Mining Tools with Linguistic Analysis) is a digital humanities system designed in collaboration with historians and linguists to assist them with their research work in quantifying the content of any textual corpora through approximate phrase search and document comparison. The retrieval engine uses a character-based n-gram language model rather than the conventional word-based one so as to achieve great flexibility in language agnostic query processing.", "histories": [["v1", "Wed, 23 Mar 2016 12:02:12 GMT  (5388kb,D)", "http://arxiv.org/abs/1603.07150v1", "49 pages"]], "COMMENTS": "49 pages", "reviews": [], "SUBJECTS": "cs.DL cs.CL cs.IR", "authors": ["martyn harris", "mark levene", "dell zhang", "dan levene"], "accepted": false, "id": "1603.07150"}, "pdf": {"name": "1603.07150.pdf", "metadata": {"source": "CRF", "title": "The Anatomy of a Search and Mining System for Digital Archives", "authors": ["Martyn Harris", "Mark Levene"], "emails": ["@dcs.bbk.ac.uk", "d.levene@soton.ac.uk"], "sections": [{"heading": null, "text": "Keywords: Digital Humanities, Statistical Language Model, Information Retrieval, Text Analysisar Xiv: 160 3.07 150v 1"}, {"heading": "1 Introduction", "text": "In fact, most people are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 Related Work", "text": "There are a number of existing systems that represent the state of affairs in the humanities. We will discuss some of the systems that have a common functionality, source material or user groups, in terms of the way they move, both the way they move, the way they move, and the way they move, and the way they move, and the way they move."}, {"heading": "3 System Architecture", "text": "In this context, it is worth mentioning that the case concerns a person who was born in another country than in another case: a woman who was born in another country, a woman who was born in another country, a woman who was born in another country, a woman who grew up in another country, a woman who grew up in another country, a woman who grew up in another country, a woman who lives in another country, a woman who grew up in another country."}, {"heading": "4 Data Model", "text": "Statistical language modeling [67] is central to Samtla's data model. It forms the basis for Samtla's search tool, which enables the user to find documents by complete and partial query matches. Samtla's Statistical Language Model (SLM), the details of which are listed in Section 4.1, is supported by a character-based suffix tree [36], which is described in detail in Section 4.2. A suffix tree is a very powerful data structure that supports fast retrieval of strings known as n-grams, where n is the length of a sequence (measured in characters for our purposes). Samtla is unique in that it is language agnostic and can therefore support a variety of languages within a single data model; we will demonstrate this in Section 7."}, {"heading": "4.1 Statistical Language Models", "text": "An example of this is the fact that most of them are people who are able to live in a country where they are able to integrate."}, {"heading": "4.2 Suffix Tree", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "5 Text Mining Tools", "text": "Books, websites, articles and reports are examples of unstructured text data where relevant information is potentially present somewhere within the document. Unstructured text data is often managed and retrieved via a search engine (see [46]). Search engines provide the means to retrieve information, but not to analyze it. Textmining techniques are useful at this point because they provide the researcher with different views of the data that enable him to discover and evaluate text patterns [18]. The Samtla system is designed as a research environment packaged with a range of extensible text mining tools, which provide a means to analyze a corpus by identifying patterns or \"formulas\" that are of interest to researchers. In addition, the tools are designed alongside each user group to identify the problem domain and provide solutions that can be implemented in accordance with the underlying system."}, {"heading": "5.1 Related Queries Tool", "text": "The related query tool extracts 10 text fragments from the corpus (specifically from the suffix tree representing collection model C, as discussed in Section 4.1) that are most similar to the original user query, and these are then displayed as part of the ranked search results. For example, searching for \"beginning\" in the Bible edition of Samtla would return related queries \"bigynnynnyng\" and \"begynnynge\" that represent alternative spellings. Related queries are generated by a process similar to the Levenshtein Edit Distance algorithm [36], in which alternative forms of the original query are created by processes of deleting, replacing, and inserting. This query can be more formally defined as follows. Let Q represent the related query, where n is the length of the original query q, and i component q, 2,."}, {"heading": "5.2 Related Documents Tool", "text": "The related document tool finds up to twenty documents from the corpus that are most similar to the document currently seen by the user (referred to as the target document). Retrieving twenty documents is a decision of the user interface, as we calculate similarity values for all document pairs in the corpus. Each document in the menu of related documents provides a link to the document comparison tool (discussed in Section 5.3). A document can be considered a probability distribution via n-gram sequences [31], and the similarity between a document pair can be calculated by the Jensen-Shannon divergence (JSD) via its corresponding document models Md (as described in Section 4.1) [48]. JSD is the symmetrical version of the known Kullback-Liebler divergence (KLD) based on the identical mutation (KLD)."}, {"heading": "5.3 Document Comparison Tool", "text": "A common task applied to speech corpora is to find representative examples of language usage illustrated by string patterns. Samtla provides a document comparison tool that allows users to compare the document they are currently viewing with a document selected from a list of similar documents (see Section 5.2 above). This function is considered essential by our user groups because this form of comparison is done manually and can be a complex task due to the overlapping of text regions with common sequences. Although there are some document comparison tools such as diff on UNIX, they perform global sequence alignment that attempts to match all documents, while Samtla users are interested in local sequence alignments that identify text regions of similarity within two documents that may be far apart. The underlying algorithm for identifying common text patterns is an ASL-tailored variant of the Local AligTool."}, {"heading": "5.4 Named Entity Tool", "text": "The name Entity Recognition (NER) [22] describes the process of extracting words (or sequences of characters, in our case) representing the names of persons, companies and locations. Samtla uses Gazetteers to extract named entities from the raw documents. Gazetteers have been used for some time to improve the performance of named entity systems, other, more complex methods exist, such as semi-supervised learning techniques such as bootstrapping [18], but Gazetteers are becoming popular again due to the wealth of structured data on named entities provided by platforms such as Wikipedia and DBpedia [41]. Another motivation for adopting the Gazetteer approach is that current versions of Samtla support a number of historical text collections, such as the Bible and Vasari's \"The Lives of the Most Outstanding Artists and Architects\" 7, these collections are closed businesses, meaning new documents are rarely included in the collection."}, {"heading": "5.5 Recommendation Tools", "text": "Personalized recommendation systems are familiar to many users of the Internet. For example, online shoppers often come across the \"what other customers have bought\" page, which presents a series of recommended items that other shoppers have purchased based on items in their \"shopping cart\" or \"shopping cart.\" Other examples of recommendation systems can be found in socially influenced personalization, where a user is part of a select group that shares content and opinions with other users they trust, as well as collaborative searches that allow users to discover new search terms based on other users \"search behavior [65]. Samtla uses user activity to generate recommended queries and documents. By analyzing log data, Samtla can inform users of the top 10 most popular queries and documents in the research community to help users search collectively, so a user of Samtla may not be referred to the\" interesting \"aspects of the Corpus page being investigated previously."}, {"heading": "6 User Interface", "text": "The interaction with the system takes place via a browser-based user interface and the user can perform three main tasks in the current version of the system: (i) Corpus frowning (see Section 6.1), (ii) Search (Section 6.2) and (iii) Document comparison (Section 6.4). The toolset is modular and extendable to allow the development of further tools with our users without affecting already established system components (see Chapters 3, 7 and 9)."}, {"heading": "6.1 Browse Documents", "text": "Samtla uses a cluster (or facet) navigation model in which each cluster describes a category represented by a collection of shared-ownership documents [24] [28]. Clustering documents according to a specific feature [63] can give the user an indication of the type and availability of data in a system [38] and is a useful approach to encouraging the user to explore and discover information within a collection [37]. By adopting a cluster navigation model, future components can be integrated in a modular way without visual confusion through traditional UI elements such as tabs and drop-down menus. The browser architecture is divided into two separate presentation layers. By default, a list view imitating a traditional file directory in which each row entry represents either a folder or an individual document. Columns contain the cluster label or the document name and the theme of a common document (see the metadata), where each row entry can be represented in either a folder or an individual document."}, {"heading": "6.2 Search Documents", "text": "Sets Snipets-Snipets Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Sets-Snipets-Sets-Sets-Snipets-Sets-Sets-Snipets-Sets-Snipets-Sets-Sets-Snipets-Sets-Snipets-Sets-Sets-Sets-Sets-Snipets-Sets-Snipets-Sets-Snipets-Snipets-Sets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Sets-Snipets-Sets-Snipets-Sets-Snipets-Sets-Snipets-Sets-Snipets-Sets-Snipets-Sets-Snipets-Sets-Sets-Snipets-Sets-Snipets-Snipets-Snipets-Sets-Snipets-Snipets-Snipets-Snipets-Snipets-Sets-Snipets-Snipets-Sets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Sets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Sets-Sets-Snipets-Sets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Snipets-Sets-Sets-Sets-Sets-Snipets-Sets-Sets-Sets-Sets-Sets-Snipets-Snipets-Snipets-Sets-Snipets-Sets-Sets-Snipets-Snipets-Sets-Sets-Sets-Sets-Sets-Sets-S"}, {"heading": "6.3 View Documents", "text": "When a user arrives at the document level by browsing or searching, he will be presented with a main window displaying the text of the document or, if available, the image of the scanned document, see Figure 6. If the user has navigated to the document through the browsing tool, all document metadata, including the named entity (see Figure 10), will be highlighted; for documents located via the search tool, we will highlight all instances of the query. In the document view, the user will have access to metadata, document comparisons and named entity tools."}, {"heading": "6.4 Compare Documents", "text": "Related documents (see Section 5.2) provide access to the document comparison tool. The document comparison tool consists of two document windows, one for the target document (the document the user is currently viewing) and another for the document selected from the list of associated documents. Each time a user selects a new document, both documents are updated with new sequence data and the longest sequence between the two documents is highlighted as the starting point for the user. It is equipped with a control to select the length of the text pattern to display, with a minimum of 3 grams and the default setting showing the longest sequence between the two documents. It allows the user to examine large sequences between multiple lines to smaller sequences that represent a word or grammatical attachment (typically 3 grams long). A small horizontal map appears above each document summarizing all sequences in the document, giving the user an overview of the documents as distributed in the two documents."}, {"heading": "7 Case Studies", "text": "In fact, the greater part of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "8 Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.1 Overview", "text": "In this section, we describe the evaluation process for measuring the performance of the statistical language model underlying the Samtla search engine (see Section 4). The evaluation evaluates the ranking quality of the Samtla search engine in terms of whether the system (see Section 4) consistently puts the most relevant documents at the top of the search results list."}, {"heading": "8.2 Crowdsourcing", "text": "Crowdsourcing is a web-based business model [23] that enables companies and individuals to harness the skills of people from a distributed community to perform some tasks in return for a small reward. These tasks are often extensive or complex and therefore time consuming as outcomes. Crowdsourcing in information retrieval typically involves outsourcing manual tasks such as data annotation, labeled data collection for training models, and system evaluation, often completed in-house with a limited number of workers, which could be a slow process that takes several working days depending on the size of the task. Due to the size of the crowd, which is globally distributed, tasks can be completed much faster at any hour of the day. There is also the potential for reducing bais in aggregated results compared to internal evaluations, due to the diversity and representativeness of workers in terms of demographics [44].There are a number of crowdsourcing platforms available for conducting surveys and evaluations."}, {"heading": "8.3 Methodology", "text": "The evaluation consisted of 50 searches, represented by a ranking of the top 10 documents returned by the Samtla system. Users were asked to assign graded relevance values to each document in the ranking based on a specific search query displayed at the top of each search result, according to the four levels of relevance: \"not relevant,\" \"reasonably relevant,\" \"fairly relevant\" or \"highly relevant.\""}, {"heading": "8.3.1 Data Preparation", "text": "To evaluate the ranking performance of the system, we used the King James Bible version of Samtla, as many people are familiar with the contents of the Bible to some extent. We prepared a set of 50 queries of varying lengths, ranging from individual word queries (i.e. \"Moses\" and \"Jesus Christ\") to longer, verbatim queries representing specific phrases (i.e. \"the Lord has spoken\" and \"God be praised\"), and constructed two test queries to have some control over the quality of the users. Each query was submitted to the Samtla search engine and the documents for the top 10 results were selected, and the queries are processed to generate two permutations of the order of the documents. The first permutation is a ranking in which the documents are sorted according to their statistical language model (SLM), with the ranking of the relevant documents sorted according to the ranking."}, {"heading": "8.3.2 User Interface", "text": "The evaluation interface is a stripped-down version of the Samtla system that isolates the search results window. At the top of the page, we display the query submitted to the system from which the list of top 10 search results was created. Each document in the ranking list is displayed with the title and a short snippet showing the top three fragments that contain the highlighted query in the document. Next to each document, there is a drop-down field in which the user selects a corresponding degree of relevance."}, {"heading": "8.3.3 Selecting participants", "text": "Prolific Academic provides a set of filters that allow researchers to exclude certain users based on certain attributes that are stored as part of the user profile. The most important filter criteria applied to our study were to ensure that users are fluent in English. Therefore, when we speak of a participant, it should be clear from the outset that he is a member of the public and not necessarily concerned with the motivation behind the specific study, or that he has a background in the type of data you present to him as a researcher. Therefore, it is important to prepare for this fact and try to filter the crowd for those who are competent in performing the required task. As mentioned above, the evaluation included two test queries at the beginning of the survey. Not all users will have read or understood the instructions [34], and others can simply assign relevance marks at random to complete the survey as quickly as possible and receive payment as quickly as possible."}, {"heading": "8.4 Evaluation Measures", "text": "We use two measures to calculate system performance: the first measures the correlation between the system and the ranking generated by the user for each query in the ranking order of the SLM ranking and the ranking order of the display. If the ranking of the system is strongly correlated with the ranking of the user, we can conclude that the ranking order of the system closely matches that of a human assessor. The second measure measures the ranking quality of the system using the Normalized Discounted Cumulative Gain Measurement (NDCG), which is commonly used for graded-relevance ratings [40]. We perform the measurements using both the SLM and the representation of permutations. In the following sections, we describe each of the measurements in more detail before presenting a summary of the final results."}, {"heading": "8.4.1 Correlation Measures", "text": "We measure the degree of correlation between the system and users using Spearman's foot rule [30] and the M measurement variant [21]. These non-parametric measures describe the degree of correlation between the two rankings and provide similar results to other correlation measures, including the consensus of Spearman and Kendall. \"In our case, the two rankings are represented by the SLM Ranking r1, and the User Consensus Ranking r2. We discuss each of the correlation measures more precisely, where we will abbreviate Spearman's footnote to cover the rest of this section. The foot rule is ranked by summing up the result of the absolute differences between the rankings of the individual user positions of the documents for each rankings. The foot rule, formally defined by Fr, is defined as follows: Fr (r1, r2)"}, {"heading": "8.4.2 Normalised Discounted Cumulative Gain (NDCG)", "text": "While the correlation measures tell us how well the generated ranking correlates with the user judgments, it does not directly describe the quality of the ranking algorithm. The ranking order of an information query system can be measured using the Normalized Discounted Cumulative Gain (NDCG) calculated using the tested relevance values. NDCG for a ranking of the size k is calculated by: NDCGk = DCGk IDCGk (15), where DCG is the discounted cumulative gain, IDCG represents the idealDCG achieved by sorting the documents in descending order by relevance value, and then calculating the DCG to obtain the maximum DCG used at the standardization stage. We selected two discounting functions for the comparison. The first method reduces the contribution of the relevance point according to the relevance, the relevance function we define as the second most frequent of the Location Points in the Location I function."}, {"heading": "8.4.3 Significance testing", "text": "As part of the evaluation, we evaluate the statistical significance of the results. We use the bootstrap method [29, 62, 59], which attempts to approximate the original underlying distribution of the population by selecting a series of random samples of size N with substitutes from the observed population data. An advantage of the bootstrap method is that it is compatible with any statistical metric [62], which means that we can use the correlation and the NDCG values as test statistics if the confidence intervals do not overlap. To obtain the confidence intervals, we assume that the zero hypothesis is that there is no difference between the ranking generated by the system and the ranking generated by the user ratings. The difference is considered significant with respect to the specified level of significance if the confidence intervals do not overlap, and that there is no difference between the ranking generated by the system and the ranking generated by the user ratings. In order to obtain the condensation measurement, we obtain a set of condensation intervals from the original G, and generate a number of condensed samples."}, {"heading": "8.5 Evaluation Results", "text": "The evaluation lasted several days and 65 participants took part in the evaluation. A total of 24 users successfully completed the survey and the majority of entries came from men aged between 20 and 30 years old, residing or born in North America. Of the total submissions, we excluded 10 users due to incomplete results due to connection time overruns, and 31 users who failed the test queries, which is almost half of the total number of submissions. Interestingly, 10 of the users who failed the test did not even pass the first test query, meaning that they could not find that the top 10 results were composed of two completely different queries of varying length (a short query versus a long verbose query), underlining the importance of designing tests as part of an evaluation to filter potentially low-performing users."}, {"heading": "8.5.1 Correlation measures", "text": "In this context, it should be noted that this is a very complex issue."}, {"heading": "8.5.2 Normalised Discounted Cumulative Gain (NDCG)", "text": "Before presenting the results for the NDCG ranking, below (see Table 5 and Table 6) we will make a distinction between the representation of trust for the SLM ranking, using a different method of measuring the correlation, in which we simulate the input of 1000 random users. Each user is represented by randomly assigning the relevance notes to the documents for each query, which we then summarize by calculating the average NDCG results by user and query for each discounting function n and log2. We have found that we get similar results regardless of the discounting function adopted, but we include both models of user persistence, representing a more impatient user. The final averages for the SLM ranking and the scoreboard ranking applied are presented below (see Table 5 and Table 6)."}, {"heading": "8.6 Discussion", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "9 Concluding Remarks", "text": "We have introduced the underlying framework of the Samtla system (Section 3), and the data structures and algorithms have been adopted; we have also described how users interact with the system (Section 6), and the tools we currently share with our user groups (Section 5); the case studies provide insight into the way our users conduct their research (Section 7); and we are now focusing on developing the underlying framework, looking at additional parameters that can be incorporated into the data model (Section 4) to provide insight into the way our users conduct their research (Section 7)."}], "references": [{"title": "vasari, giorgio.\u201d in dictionary of art historians", "author": ["Sorensen", "lee"], "venue": "http:// www.dictionaryofarthistorians.org/wittkowerr.htm, Retrieved", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Mining Text Data", "author": ["C. Aggarwal", "C. Zhai"], "venue": "Springer-Verlag New York Inc,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Design and implementation of relevance assessments using crowdsourcing", "author": ["O. Alonso", "R.A. Baeza-Yates"], "venue": "In Advances in Information Retrieval - 33rd European Conference on IR Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Presentation bias is significant in determining user preference for search resultsa user study", "author": ["J. Bar-Ilan", "K. Keenoy", "M. Levene", "E. Yaari"], "venue": "Journal of the American Society for Information Science and Technology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Methods for comparing rankings of search engine results", "author": ["J. Bar-Ilan", "M. Mat-Hassan", "M. Levene"], "venue": "Comput. Netw.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "An algorithm that learns what\u2019s in a name", "author": ["D.M. Bikel", "R. Schwartz", "R.M. Weischedel"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1999}, {"title": "Crowdsourcing as a model for problem solving: An introduction and cases", "author": ["D.C. Brabham"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Faceted classification as a basis for knowledge organization in a digital environment: The bliss bibliographic classification as a model for vocabulary management and the creation of multidimensional knowledge structures", "author": ["V. Broughton"], "venue": "New Rev. Hypermedia Multimedia,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Squarified treemaps", "author": ["M. Bruls", "K. Huizing", "J. van Wijk"], "venue": "Proceedings of the Joint Eurographics and IEEE TCVG Symposium on Visualization,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1999}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["S. Chen", "J. Goodman"], "venue": "Computer Speech and Language,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}, {"title": "Responsa: A full-text retrieval system with linguistic processing for a 65-million word corpus of jewish heritage in hebrew", "author": ["Y. Choueka"], "venue": "Data Eng.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1989}, {"title": "Dimensionality reduction and topic modeling: From latent semantic indexing to latent dirichlet allocation and beyond", "author": ["S.P. Crain", "K. Zhou", "S.-H. Yang", "H. Zha"], "venue": "Mining Text Data,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Bootstrap Methods and their Application", "author": ["A.C. Davison", "D.V. Hinkley"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1997}, {"title": "Spearman\u2019s footrule as a measure of disarray", "author": ["P. Diaconis", "R.L. Graham"], "venue": "Royal Statistical Society Series B,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1977}, {"title": "A new metric for probability distributions", "author": ["D.M. Endres", "J.E. Schindelin"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2003}, {"title": "Comparing top k lists", "author": ["R. Fagin", "R. Kumar", "D. Sivakumar"], "venue": "Proceedings of the ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2003}, {"title": "Advances in knowledge discovery and data mining. chapter From Data Mining to Knowledge Discovery: An Overview, pages 1\u201334", "author": ["U.M. Fayyad", "G. Piatetsky-Shapiro", "P. Smyth"], "venue": "American Association for Artificial Intelligence,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1996}, {"title": "Challenges in data crowdsourcing", "author": ["H. Garcia-Molina", "M. Joglekar", "A. Marcus", "A. Parameswaran", "V. Verroios"], "venue": "Knowledge and Data Engineering, IEEE Transactions on,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "Building better digital humanities tools: Toward broader audiences and user-centered designs", "author": ["F. Gibbs", "T. Owens"], "venue": "Digital Humanities Quarterly,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2012}, {"title": "Algorithms on Strings, Trees, and Sequences: Computer Science and Computational Biology", "author": ["D. Gusfield"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1997}, {"title": "Uis for faceted navigation: Recent advances and remaining open problems", "author": ["M.A. Hearst"], "venue": "In in the Workshop on Computer Interaction and Information Retrieval,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2008}, {"title": "Search User Interfaces", "author": ["M.A. Hearst"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}, {"title": "Evaluating verbose query processing techniques", "author": ["S. Huston", "W.B. Croft"], "venue": "In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2010}, {"title": "Cumulated gain-based evaluation of ir techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Trans. Inf. Syst.,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2002}, {"title": "Exploiting wikipedia as external knowledge for named entity recognition", "author": ["J. Kazama", "K. Torisawa"], "venue": "In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2007}, {"title": "Crowdsourcing user studies with mechanical turk", "author": ["A. Kittur", "E.H. Chi", "B. Suh"], "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2008}, {"title": "Language models for financial news recommendation", "author": ["V. Lavrenko", "M.D. Schmill", "D. Lawrie", "P. Ogilvie", "D. Jensen", "J. Allan"], "venue": "In CIKM,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2000}, {"title": "Crowdsourcing for information retrieval: introduction to the special issue", "author": ["M. Lease", "E. Yilmaz"], "venue": "Information Retrieval,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2013}, {"title": "Web-application development using the model/view/controller design pattern", "author": ["A. Leff", "J. Rayfield"], "venue": "In Enterprise Distributed Object Computing Conference,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2001}, {"title": "An Introduction to Search Engines and Web Navigation", "author": ["M. Levene"], "venue": null, "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2010}, {"title": "Naive (bayes) at forty: The independence assumption in information retrieval", "author": ["D.D. Lewis"], "venue": "In Proceedings of the 10th European Conference on Machine Learning,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1998}, {"title": "Divergence measures based on the shannon entropy", "author": ["J. Lin"], "venue": "IEEE Transactions on Information theory,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1991}, {"title": "Statistical language modeling for information retrieval", "author": ["X. Liu", "W.B. Croft"], "venue": "Annual Review of Information Science and Technology,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2005}, {"title": "Modern BLAST programs", "author": ["J. Ma", "L. Zhang"], "venue": "In Problem Solving Handbook in Computational Biology and Bioinformatics. Springer US,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2011}, {"title": "Introduction to Information Retrieval", "author": ["C. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2008}, {"title": "Character n-gram tokenization for european language text retrieval", "author": ["P. Mcnamee", "J. Mayfield"], "venue": "Inf. Retr.,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2004}, {"title": "Outperforming lru with an adaptive replacement cache algorithm", "author": ["N. Megiddo", "D.S. Modha"], "venue": "IEEE Computer,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2004}, {"title": "Markov Chains and Stochastic Stability", "author": ["S. Meyn", "R.L. Tweedie"], "venue": null, "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2009}, {"title": "Relevance: The whole history", "author": ["S. Mizzaro"], "venue": "JOURNAL OF THE AMERI- CAN SOCIETY FOR INFORMATION SCIENCE,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1997}, {"title": "A survey of named entity recognition and classification", "author": ["D. Nadeau", "S. Sekine"], "venue": "Lingvisticae Investigationes,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2007}, {"title": "Literary studies. In A Companion to Digital Humanities, pages 88\u201396", "author": ["T. Rommel"], "venue": "Blackwell Publishing Ltd,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2007}, {"title": "Two decades of statistical language modeling: Where do we go from here", "author": ["R. Rosenfeld"], "venue": "In Proceedings of the IEEE,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2000}, {"title": "Evaluating evaluation metrics based on the bootstrap", "author": ["T. Sakai"], "venue": "In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2006}, {"title": "Event detection and tracking in social streams", "author": ["H. Sayyadi", "M. Hurst", "A. Maykov"], "venue": "Proceedings of the International Conference on Weblogs and Social Media (ICWSM", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2009}, {"title": "The generalised k-truncated suffix tree for time-and space-efficient searches in multiple dna or protein", "author": ["M.H. Schulz", "S. Bauer", "P.N. Robinson"], "venue": "sequences. IJBRA,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2008}, {"title": "A comparison of statistical significance tests for information retrieval evaluation", "author": ["M.D. Smucker", "J. Allan", "B. Carterette"], "venue": "In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2007}, {"title": "A comparison of document clustering techniques", "author": ["M. Steinbach", "G. Karypis", "V. Kumar"], "venue": "KDD Workshop on Text Mining,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2000}, {"title": "User needs for enhanced engagement with cultural heritage collections", "author": ["M. Sweetnam", "M. Agosti", "N. Orio", "C. Ponchia", "C. Steiner", "E. Hillemann", "M. \u00d3 Siochr\u00fa", "S. Lawless"], "venue": "In Proceedings of the International Conference on Theory and Practice of Digital Libraries (TPDL),", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2012}, {"title": "Search user interface design", "author": ["M.L. Wilson"], "venue": "Synthesis Lectures on Information Concepts, Retrieval, and Services,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2011}, {"title": "Crowdsourcing translation: Professional quality from non-professionals", "author": ["O.F. Zaidan", "C. Callison-Burch"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2011}, {"title": "Statistical Language Models for Information Retrieval", "author": ["C. Zhai"], "venue": "Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers, San Francisco,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2009}, {"title": "The dual role of smoothing in the language modeling approach", "author": ["C. Zhai", "J. Lafferty"], "venue": "In Proceedings of the Workshop on Language Models for Information Retrieval (LMIR)", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2001}, {"title": "A study of smoothing methods for language models applied to information retrieval", "author": ["C. Zhai", "J. Lafferty"], "venue": "ACM Trans. Inf. Syst.,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2004}], "referenceMentions": [{"referenceID": 40, "context": "Digital textual representations of original historic documents are being made available thanks to the work of digital archiving projects [57].", "startOffset": 137, "endOffset": 141}, {"referenceID": 18, "context": "However, there are still barriers to adoption, including usability and the scope of the provided tools [35, 64].", "startOffset": 103, "endOffset": 111}, {"referenceID": 47, "context": "However, there are still barriers to adoption, including usability and the scope of the provided tools [35, 64].", "startOffset": 103, "endOffset": 111}, {"referenceID": 50, "context": "We have adopted a Statistical Language Model (SLM) for information retrieval [67], and incorporated text mining tools into the system to allow researchers to go beyond a pure search and browse paradigm.", "startOffset": 77, "endOffset": 81}, {"referenceID": 18, "context": "part of their research strategy [35, 64].", "startOffset": 32, "endOffset": 40}, {"referenceID": 47, "context": "part of their research strategy [35, 64].", "startOffset": 32, "endOffset": 40}, {"referenceID": 10, "context": "The corpus spans approximately three thousand years, and includes the Mishnah, Talmud, Torah, and the Bible in Aramaic [27].", "startOffset": 119, "endOffset": 123}, {"referenceID": 28, "context": "Samtla can be viewed as a Model-View-Controller (MVC) design pattern [45], allowing the separation of the system by function.", "startOffset": 69, "endOffset": 73}, {"referenceID": 50, "context": "and uses a Statistical Language Model (SLM), which is a relatively recent framework for information retrieval [67]; see Section 4.", "startOffset": 110, "endOffset": 114}, {"referenceID": 50, "context": "Statistical language modelling [67] is central to Samtla\u2019s data model.", "startOffset": 31, "endOffset": 35}, {"referenceID": 19, "context": "1, is supported by a characterbased suffix tree [36], described in detail in Subsection 4.", "startOffset": 48, "endOffset": 52}, {"referenceID": 41, "context": "A SLM is a mathematical model representing the probabilistic distribution of words or sequences of characters found in the natural language represented by text corpora [58, 49, 67].", "startOffset": 168, "endOffset": 180}, {"referenceID": 32, "context": "A SLM is a mathematical model representing the probabilistic distribution of words or sequences of characters found in the natural language represented by text corpora [58, 49, 67].", "startOffset": 168, "endOffset": 180}, {"referenceID": 50, "context": "A SLM is a mathematical model representing the probabilistic distribution of words or sequences of characters found in the natural language represented by text corpora [58, 49, 67].", "startOffset": 168, "endOffset": 180}, {"referenceID": 35, "context": "Word-based models typically require a language-dependent stemming, part-of-speech tagging, or text segmentation algorithm, however, by adopting a character-based n-gram model these issues can be ignored to some extent and character-based models have been shown to outperform raw word-based models, especially when the language is morphologically complex [52].", "startOffset": 354, "endOffset": 358}, {"referenceID": 50, "context": "The notion of relevance refers to the users expectation of which documents should be present at the top of the ranked list, in other words, which documents the user may be looking for [67].", "startOffset": 184, "endOffset": 188}, {"referenceID": 38, "context": "In Samtla we take the view that the more probable a document in the SLM sense, the more relevant it is, thus avoiding the philosophical debate on the notion of \u201crelevance\u201d [55].", "startOffset": 172, "endOffset": 176}, {"referenceID": 30, "context": "Using Bayes theorem [47]:", "startOffset": 20, "endOffset": 24}, {"referenceID": 34, "context": ", ci\u22121), on the right-hand side of (2), with 1 \u2264 i \u2264 m, may be approximated by the maximum likelihood estimator (MLE ) [51]:", "startOffset": 119, "endOffset": 123}, {"referenceID": 37, "context": "Moreover, for any sequence of characters we only make use of its n character history/context (or less than n for shorter sequences) as an approximation to the conditional probabilities in (2), in accordance with an n-order Markov rule [54].", "startOffset": 235, "endOffset": 239}, {"referenceID": 9, "context": "To overcome this problem, smoothing [26, 69] adjusts the MLE probabilities to make them non-zero.", "startOffset": 36, "endOffset": 44}, {"referenceID": 52, "context": "To overcome this problem, smoothing [26, 69] adjusts the MLE probabilities to make them non-zero.", "startOffset": 36, "endOffset": 44}, {"referenceID": 22, "context": "The historians we are working with tend to submit long and verbose queries representing \u201cformulae\u201d, which can impact on retrieval performance [39], since they contain many uninformative query terms (such as prepositions: of, in, to, by, and determiners: a, the).", "startOffset": 142, "endOffset": 146}, {"referenceID": 51, "context": "[68].", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "As mentioned, long verbose queries require more smoothing than keyword or title queries due to the number of uninformative terms and so may require a higher setting for \u03bb [68].", "startOffset": 171, "endOffset": 175}, {"referenceID": 51, "context": "We further emphasise that the Jelinek-Mercer smoothing method has been adopted, since many of our users will submit long queries representing textual fragments (for example, a Bible verse), and this method of smoothing has been shown to be particularly effective for addressing long and verbose queries [68, 69].", "startOffset": 303, "endOffset": 311}, {"referenceID": 52, "context": "We further emphasise that the Jelinek-Mercer smoothing method has been adopted, since many of our users will submit long queries representing textual fragments (for example, a Bible verse), and this method of smoothing has been shown to be particularly effective for addressing long and verbose queries [68, 69].", "startOffset": 303, "endOffset": 311}, {"referenceID": 19, "context": "Samtla\u2019s search capability, based on SLMs as described in the previous subsection, is supported by a space optimised character-based suffix tree, with the aim of holding the complete data structure in memory for fast retrieval [36].", "startOffset": 227, "endOffset": 231}, {"referenceID": 44, "context": "In order to reduce the suffix tree\u2019s memory consumption, we create a k-truncated suffix tree [61], which compresses the suffix tree by limiting its depth to k nodes at most, and store the data attached to tree nodes in an external key-value database.", "startOffset": 93, "endOffset": 97}, {"referenceID": 19, "context": "These are gathered together during a depth-first-search and stored as a \u2019supernode\u2019, whose label is constructed from the concatenation of the collected node labels [36].", "startOffset": 164, "endOffset": 168}, {"referenceID": 29, "context": "Unstructured text data is often managed and retrieved via a search engine (see [46]).", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "Search engines provide the means to retrieve information but not to analyse it, this is where text mining techniques are useful, as they provide the researcher with different views of the data that can enable them to discover and evaluate textual patterns [18].", "startOffset": 256, "endOffset": 260}, {"referenceID": 26, "context": "This subset of tools fall under the recommendation component of the system, where statistical language models have been shown to perform well [43].", "startOffset": 142, "endOffset": 146}, {"referenceID": 39, "context": "In document view the user can also overlay additional data in the form of named entities [56], which are", "startOffset": 89, "endOffset": 93}, {"referenceID": 19, "context": "The related queries are generated through a process similar to the Levenshtein edit distance algorithm [36] where alternative forms of the original query are created through processes of deletion, substitution, and insertion.", "startOffset": 103, "endOffset": 107}, {"referenceID": 14, "context": "A document can be considered a probability distribution over n-gram sequences [31], and the similarity between a pair of documents may be calculated through the Jensen-Shannon Divergence(JSD) over their corresponding document models Md (as described in section 4.", "startOffset": 78, "endOffset": 82}, {"referenceID": 31, "context": "1) [48].", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "where M is the average of the two distributions 12 (P + Q) [31].", "startOffset": 59, "endOffset": 63}, {"referenceID": 33, "context": "The underlying algorithm for identifying shared text patterns is a tailored variant of the Basic Local Alignment Search Tool (BLAST) algorithm [50], widely used in bioinformatics for comparing DNA sequences.", "startOffset": 143, "endOffset": 147}, {"referenceID": 19, "context": "During the iterative extension process, we score any pair of (approximately) matched strings s1 and s2 by their Levenshtein edit distance [36], which measures the number of changes required to convert one string in to another using deletion, insertion, and substitution.", "startOffset": 138, "endOffset": 142}, {"referenceID": 5, "context": "Named Entity Recognition (NER) [22] describes the process of extracting words (or sequences of characters, in our case), that represent names of people, companies, and locations.", "startOffset": 31, "endOffset": 35}, {"referenceID": 1, "context": "Gazetteers have been used for some time to improve the performance of named entity systems, other more sophisticated methods exist, for instance, semi-supervised learning techniques such as bootstrapping [18], however gazetteers are becoming popular once again due to the wealth of structured data on named entities provided by platforms such as Wikipedia and DBpedia [41].", "startOffset": 204, "endOffset": 208}, {"referenceID": 24, "context": "Gazetteers have been used for some time to improve the performance of named entity systems, other more sophisticated methods exist, for instance, semi-supervised learning techniques such as bootstrapping [18], however gazetteers are becoming popular once again due to the wealth of structured data on named entities provided by platforms such as Wikipedia and DBpedia [41].", "startOffset": 368, "endOffset": 372}, {"referenceID": 16, "context": "The gazatteers could also be used to form the basis of training data for a statistical learning approach [33] to enable Samtla to identify and mark up documents semi-automatically, which is an approach that we will be investigating as part of future work.", "startOffset": 105, "endOffset": 109}, {"referenceID": 48, "context": "they trust, as well as collaborative search, which enables users to discover new search terms based on the search behaviours of other users [65].", "startOffset": 140, "endOffset": 144}, {"referenceID": 36, "context": "The popular queries and documents are ranked and selected using an algorithm similar to the Adaptive Replacement Cache (ARC) [53], where the frequency of each query or document is combined with its recency (measured by the number of days that have passed since the last submission of the query or document view), and used for ranking.", "startOffset": 125, "endOffset": 129}, {"referenceID": 7, "context": "Samtla adopts a clustered (or faceted) navigation model, where each cluster describes a category represented by a collection of documents sharing a common property [24] [28].", "startOffset": 164, "endOffset": 168}, {"referenceID": 11, "context": "Samtla adopts a clustered (or faceted) navigation model, where each cluster describes a category represented by a collection of documents sharing a common property [24] [28].", "startOffset": 169, "endOffset": 173}, {"referenceID": 46, "context": "Clustering documents according to a particular feature [63], can provide users with an indication of the type and availability of data in a system [38], and is a useful approach for encouraging users to explore and discover information within a collection [37].", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "Clustering documents according to a particular feature [63], can provide users with an indication of the type and availability of data in a system [38], and is a useful approach for encouraging users to explore and discover information within a collection [37].", "startOffset": 147, "endOffset": 151}, {"referenceID": 20, "context": "Clustering documents according to a particular feature [63], can provide users with an indication of the type and availability of data in a system [38], and is a useful approach for encouraging users to explore and discover information within a collection [37].", "startOffset": 256, "endOffset": 260}, {"referenceID": 8, "context": "treemap [25], and can be considered as representing a topic model (see Figure 8), where each topic provides the user with a different clustered view of the corpus generated from the metadata or the named entity tool (see Section 5.", "startOffset": 8, "endOffset": 12}, {"referenceID": 21, "context": "Snippet windows were selected as the most appropriate method for summarising the document, as they are familiar to users [38].", "startOffset": 121, "endOffset": 125}, {"referenceID": 0, "context": "Giorgio Vasari is considered to be the founding father of the Art History discipline [17].", "startOffset": 85, "endOffset": 89}, {"referenceID": 6, "context": "Crowdsourcing is a web-based business model [23] that enables companies and individuals to employ the skills of people from a distributed community in order to perform some task in return for a small reward.", "startOffset": 44, "endOffset": 48}, {"referenceID": 27, "context": "There is also the potential for reducing bais in aggregated results, compared to in-house evaluations, due to the diversity and representativeness of the workers in terms of demographic [44].", "startOffset": 186, "endOffset": 190}, {"referenceID": 25, "context": "Amazon Mechanical Turk (MTurk) is one of the better known ones [42, 19, 66], however, it is only available to researchers resident in the United States of America.", "startOffset": 63, "endOffset": 75}, {"referenceID": 2, "context": "Amazon Mechanical Turk (MTurk) is one of the better known ones [42, 19, 66], however, it is only available to researchers resident in the United States of America.", "startOffset": 63, "endOffset": 75}, {"referenceID": 49, "context": "Amazon Mechanical Turk (MTurk) is one of the better known ones [42, 19, 66], however, it is only available to researchers resident in the United States of America.", "startOffset": 63, "endOffset": 75}, {"referenceID": 3, "context": "We test for a presentation bias [20] by comparing this consensus ranking to the display order of the documents using both the full set of 50 queries and the 40 random order queries.", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "Not all users will have read or understood the instructions [34], and others may simply assign relevance grades at random in order to complete the survey and receive payment as quickly as possible, known as \u201dgaming\u201d the system [42].", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "Not all users will have read or understood the instructions [34], and others may simply assign relevance grades at random in order to complete the survey and receive payment as quickly as possible, known as \u201dgaming\u201d the system [42].", "startOffset": 227, "endOffset": 231}, {"referenceID": 49, "context": "It is important to plan and mitigate against these types of user behaviour, especially when it comes to crowdsourcing, since it is generally not feasible to monitor the performance of users in realtime during the evaluation (although see [66]).", "startOffset": 238, "endOffset": 242}, {"referenceID": 23, "context": "The second measure evaluates the ranking quality of the system using the Normalised Discounted Cumulative Gain measure (NDCG), which is commonly adopted for graded-relevance based evaluations [40].", "startOffset": 192, "endOffset": 196}, {"referenceID": 13, "context": "We measure the degree of correlation between the system and the users with Spearman\u2019s footrule [30] and the M-measure variant [21].", "startOffset": 95, "endOffset": 99}, {"referenceID": 4, "context": "We measure the degree of correlation between the system and the users with Spearman\u2019s footrule [30] and the M-measure variant [21].", "startOffset": 126, "endOffset": 130}, {"referenceID": 15, "context": "These non-parametric measures describe the degree of correlation between two ranked lists, and provide similar results to other correlation measures including Spearman\u2019s \u03c1 and Kendall\u2019s \u03c4 [32].", "startOffset": 188, "endOffset": 192}, {"referenceID": 4, "context": "When evaluating search results, however, we may wish to consider the fact that documents in the top ranks are often considered the most relevant to the users information need than documents appearing in lower ranks [21].", "startOffset": 215, "endOffset": 219}, {"referenceID": 4, "context": "Due to the fact that the ranked lists contain the same set of documents, we can drop the terms S and T mentioned in [21], which record the set of documents unique to r1 and r2, respectively, and reformulate the M-measure more precisely as:", "startOffset": 116, "endOffset": 120}, {"referenceID": 23, "context": "The discounting function models user persistence [40] in terms of whether the user will continue to look for more documents further down the search results.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "We adopt the bootstrap method [29, 62, 59], which attempts to approximate the original underlying distribution of the population, by selecting a series of random samples of size N with replacement from the observed population data.", "startOffset": 30, "endOffset": 42}, {"referenceID": 45, "context": "We adopt the bootstrap method [29, 62, 59], which attempts to approximate the original underlying distribution of the population, by selecting a series of random samples of size N with replacement from the observed population data.", "startOffset": 30, "endOffset": 42}, {"referenceID": 42, "context": "We adopt the bootstrap method [29, 62, 59], which attempts to approximate the original underlying distribution of the population, by selecting a series of random samples of size N with replacement from the observed population data.", "startOffset": 30, "endOffset": 42}, {"referenceID": 45, "context": "An advantage of the bootstrap method is that it is compatible with any statistical measure [62], meaning we can use the correlation and NDCG scores as our test statistics.", "startOffset": 91, "endOffset": 95}, {"referenceID": 42, "context": "Lastly, the significance of the results was evaluated with the bootstrap method, which is non-parametric, relatively simple to implement, and as effective as other significance tests [59].", "startOffset": 183, "endOffset": 187}, {"referenceID": 43, "context": "This task is often referred to as event tracking and identification [60].", "startOffset": 68, "endOffset": 72}], "year": 2016, "abstractText": "Samtla (Search And Mining Tools with Linguistic Analysis) is a digital humanities system designed in collaboration with historians and linguists to assist them with their research work in quantifying the content of any textual corpora through approximate phrase search and document comparison. The retrieval engine uses a character-based n-gram language model rather than the conventional word-based one so as to achieve great flexibility in language agnostic query processing. The index is implemented as a space-optimised character-based suffix tree with an accompanying database of document content and metadata. A number of text mining tools are integrated into the system to allow researchers to discover textual patterns, perform comparative analysis, and find out what is currently popular in the research community. Herein we describe the system architecture, user interface, models and algorithms, and data storage of the Samtla system. We also present several case studies of its usage in practice together with an evaluation of the systems\u2019 ranking performance through crowdsourcing.", "creator": "LaTeX with hyperref package"}}}