{"id": "1603.07185", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2016", "title": "Enabling Cognitive Intelligence Queries in Relational Databases using Low-dimensional Word Embeddings", "abstract": "We apply distributed language embedding methods from Natural Language Processing to assign a vector to each database entity associated token (for example, a token may be a word occurring in a table row, or the name of a column). These vectors, of typical dimension 200, capture the meaning of tokens based on the contexts in which the tokens appear together. To form vectors, we apply a learning method to a token sequence derived from the database. We describe various techniques for extracting token sequences from a database. The techniques differ in complexity, in the token sequences they output and in the database information used (e.g., foreign keys). The vectors can be used to algebraically quantify semantic relationships between the tokens such as similarities and analogies. Vectors enable a dual view of the data: relational and (meaningful rather than purely syntactical) text. We introduce and explore a new class of queries called cognitive intelligence (CI) queries that extract information from the database based, in part, on the relationships encoded by vectors. We have implemented a prototype system on top of Spark to exhibit the power of CI queries. Here, CI queries are realized via SQL UDFs. This power goes far beyond text extensions to relational systems due to the information encoded in vectors. We also consider various extensions to the basic scheme, including using a collection of views derived from the database to focus on a domain of interest, utilizing vectors and/or text from external sources, maintaining vectors as the database evolves and exploring a database without utilizing its schema. For the latter, we consider minimal extensions to SQL to vastly improve query expressiveness.", "histories": [["v1", "Wed, 23 Mar 2016 13:57:33 GMT  (242kb,D)", "http://arxiv.org/abs/1603.07185v1", "Submitted to VLDB"]], "COMMENTS": "Submitted to VLDB", "reviews": [], "SUBJECTS": "cs.CL cs.DB", "authors": ["rajesh bordawekar", "oded shmueli"], "accepted": false, "id": "1603.07185"}, "pdf": {"name": "1603.07185.pdf", "metadata": {"source": "CRF", "title": "Enabling Cognitive Intelligence Queries in Relational Databases using Low-dimensional Word Embeddings", "authors": ["Rajesh Bordawekar", "Oded Shmueli"], "emails": ["bordaw@us.ibm.com", "oshmu@cs.technion.ac.il"], "sections": [{"heading": null, "text": "We are introducing a new class of queries called cognitive intelligence (CI), which extracts information from the database, some of which is based on vector-encoded relationships. We have implemented a prototype system on Spark [1] to represent the performance of CI queries, where CI queries are realized via SQL UDFs. This performance goes far beyond text extensions to relational systems because of the vector-encoded information. We are also looking at various extensions of the basic scheme, including the use of a collection of views from the database to focus on an area of interest, using vectors and / or text from external sources, maintaining vectors as the database develops and exploring a database without using its schema. For the latter, we are looking at minimal enhancements to SQL to greatly improve the meaningfulness of the query."}, {"heading": "1. INTRODUCTION", "text": "In fact, it is that we are able to assert ourselves, that we are able to be able to be able to be able to be able to be able to be."}, {"heading": "2. RELATED WORK", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able, that we are able, that we are able, that we are able, that we are able, and that we are able, that we are able, to be able, to be able, to be able, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in the position we are in. \""}, {"heading": "3. TOKENIZATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Basic Tokenization", "text": "In fact, it is such that the majority of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a"}, {"heading": "3.2 Extensions", "text": "This year, it has come to the point where it will only take a few weeks to get a result."}, {"heading": "4. COGNITIVE INTELLIGENCE QUERIES", "text": "FROM EXAMPLES"}, {"heading": "4.1 Similarity Queries", "text": "This year it is more than ever before."}, {"heading": "4.2 Schema-less Navigation", "text": "In fact, it is as if people who stand up for people's rights have to burden themselves and their rights and obligations. (...) It is not as if people are able to exercise their rights and obligations themselves. (...) It is as if people were able to exercise their rights and obligations. (...) It is as if people were able to exercise their rights and obligations. (...) It is as if they were able to exercise their rights and obligations. (...) It is as if they were able to exercise their rights and obligations. (...) It is as if people were able to exercise their rights and obligations. \"(...) It is as if they were able to do it to themselves, as if they were doing it, as if they were doing it, as if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it, if they were doing it."}, {"heading": "4.3 Analogy Queries", "text": "A unique feature of vectors is the fact that we can use them to derive analogies; for example, a king for the man is like a queen for the woman. The following query (Figure 11) identifies product pairs that are related to each other, like Tokens peanut butter and jelly (both are product types). The key is that if product p1 refers to product p2, like peanut butter to jelly, the associated vectors V p1, V p2, V peanut butter and V jelly are likely to satisfy that the vector differences (V peanut butter - V jelly) and (V p1 - V p2) are cosine-like. Potential answers to this query may be (chips, salsa) or (pancakes, maple syrup). Here, we use a vector variant (V peanut butter - V jelly) that is a vector variant (V peanut butter - V jelly) and (V - 1) is cosmic."}, {"heading": "5. CI QUERIES IN PRACTICE", "text": "In this section, we discuss how a cognitive intelligence (CI) database is used in practice, and then demonstrate its capabilities by describing the execution of CI queries in a park-based prototype. Figure 12 presents the three key phases in the execution flow of a CI database. The first, optional training phase takes place when the database is used to train the model. Using the approaches described in Section 3, the data in the database table is first converted into a meaningful text format and then used to generate a series of vectors (Phase 1). Alternatively, this phase can also use an external text repository (e.g. Wikipedia) to train the vectors. After the vector training, the resulting vectors are stored in a relational system table (Phase 2). At runtime, the SQL executor uses various UDFs that can be learned from the trained vectors in the course of the system table (and the 3)."}, {"heading": "5.1 CI Queries over a DBLP-based Database", "text": "In fact, it is the case that most people who are interested in politics decide for politics and politics, that they decide for politics and the economy, for politics and for the economy and for the people who are interested in politics and for the economy, for the economy and for the economy, for the economy and for the people, for the people and for the environment, for the environment and for the environment, for the people and for the environment, for the environment and for the environment, for the people and for the environment, for the environment and for the environment, for the environment and for the environment, for the environment, for the environment and for the environment, for the environment and for the environment, for the people and for the environment, for the people and for the environment, for the people and for the environment, for the people and for the people, for the people and for the people, for the people and for the people, the people and for the people, the people and for the people, the people, the people and for the people, the people and for the people, the people, the people and for the people, the people and for the people, the people and for the people, the people and for the people, the people, the people and for the people, the people and for the people, the people, the people and for the people, the people, the people and for the people, the people and for the people, the people, the people and for the people, the people, the people and for the people, the people, the people and for the people, the people, the people and for the people, the people, the people, the people and for the people, the people, the people, the people and for the people, the people, the people, the people and for the people, the people, the people, the people, the people for the people and for the people, the people, the people for the people, the people, the people for the people and for the people and for the people and for the people, the people, the people and for the people, the people and for the people, the people and for the people, the people and for the people, the people, the people, the people for the people and for the people and for the people, the people, the people and for the people and for the people, the people and for the people, the people and for the people, the people, the people, the"}, {"heading": "5.2 Performance Issues", "text": "In an end-to-end cochlear implant system, there are three points where performance can become a problem. Firstly, this training phase is not necessary because the system can use pre-formed vectors, and if the vectors from the raw data need to be trained, the training (or retraining for new data) can be implemented as a batch process. Secondly, the performance of the training can be further improved by using GPUs. Secondly, the cost of accessing the trained vectors from the system tables must be as low as possible, as any delay would affect the execution of the run-time query (Figure 12). Access to the system tables can be improved by building a traditional B + tree index, using the tokens as the key. Finally, the execution cost of a cochlear implant query depends on the performance of the query function. In many cases, we need to calculate distances between a large number of accelerators, e.g. depending on the number of cochlear accelerators (analogues)."}, {"heading": "6. CONCLUSIONS AND FUTURE WORK", "text": "We describe the extended question arising from the fact that each database is associated with a vector that captures its syntactic and semantic properties. Vectors are reached by a learning device based on the database derivative text. We use these vectors to create a new class of queries (CIs) that extract information from the database in which they are located, as vectors that allow a double view of the data. We introduce a new class of queries called cognitive intelligence."}, {"heading": "7. REFERENCES", "text": "[1] Apache Foundation. Apache Funke: A fast and generalengine for large-scale data processing. http: / / spark.apache.org. [2] S. Arora, Y. Li, Y. Liang, T. Ma, and A. Risteski. Randoms walks on context spaces: Towards a description of the mysteries of semantic word embeddings. CoRR, abs / 1502.03520, 2015. [3] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. Journal of Machine Learning Research, 3: 1137-1155, 2003. [4] S. Chaudhuri, V. Ganti, and R. Kaushik. A primitive operator for similarity adheres to data purification. In Proceedings of the 22nd International Conference on Data Engineering, Washington, DC, USA, 2006."}, {"heading": "8. APPENDIX", "text": "It is a software tool for associating vocabulary with vectors. The tool comes in two flavors, continuous pocket-of-words (CBOW) and continuous skip-gram (SG). Intuitively, in CBOW, each word w is represented by two vectors Vw and V \u2032 w. The algorithm scans a text window of a predetermined size d, and by calculating a gradient, tries to move the Vw vectors of words in the window (except the central word) towards the V \u2032 c vector of the window word c. SG has a similar, but slightly more expensive mechanic. word2vec can use a technique called negative sampling (NS), in which examples with high probability, by choosing text windows, do not connect to the text windows vector."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We apply distributed language embedding methods from<lb>Natural Language Processing to assign a vector to each<lb>database entity associated token (for example, a token may<lb>be a word occurring in a table row, or the name of a col-<lb>umn). These vectors, of typical dimension 200, capture the<lb>meaning of tokens based on the contexts in which the to-<lb>kens appear together. To form vectors, we apply a learning<lb>method to a token sequence derived from the database. We<lb>describe various techniques for extracting token sequences<lb>from a database. The techniques differ in complexity, in<lb>the token sequences they output and in the database infor-<lb>mation used (e.g., foreign keys). The vectors can be used<lb>to algebraically quantify semantic relationships between the<lb>tokens such as similarities and analogies.<lb>Vectors enable a dual view of the data: relational and<lb>(meaningful rather than purely syntactical) text. We in-<lb>troduce and explore a new class of queries called cognitive<lb>intelligence (CI) queries that extract information from the<lb>database based, in part, on the relationships encoded by<lb>vectors. We have implemented a prototype system on top<lb>of Spark [1] to exhibit the power of CI queries. Here, CI<lb>queries are realized via SQL UDFs. This power goes far<lb>beyond text extensions to relational systems due to the in-<lb>formation encoded in vectors.<lb>We also consider various extensions to the basic scheme,<lb>including using a collection of views derived from the database<lb>to focus on a domain of interest, utilizing vectors and/or text<lb>from external sources, maintaining vectors as the database<lb>evolves and exploring a database without utilizing its schema.<lb>For the latter, we consider minimal extensions to SQL to<lb>vastly improve query expressiveness.", "creator": "LaTeX with hyperref package"}}}