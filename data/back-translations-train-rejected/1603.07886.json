{"id": "1603.07886", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2016", "title": "A Novel Biologically Mechanism-Based Visual Cognition Model--Automatic Extraction of Semantics, Formation of Integrated Concepts and Re-selection Features for Ambiguity", "abstract": "Integration between biology and information science benefits both fields. Many related models have been proposed, such as computational visual cognition models, computational motor control models, integrations of both and so on. In general, the robustness and precision of recognition is one of the key problems for object recognition models.", "histories": [["v1", "Fri, 25 Mar 2016 11:47:16 GMT  (4849kb,D)", "http://arxiv.org/abs/1603.07886v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["peijie yin", "hong qiao", "wei wu", "lu qi", "yinlin li", "shanlin zhong", "bo zhang"], "accepted": false, "id": "1603.07886"}, "pdf": {"name": "1603.07886.pdf", "metadata": {"source": "CRF", "title": "A Novel Biologically Mechanism-Based Visual Cognition Model \u2013Automatic Extraction of Semantics, Formation of Integrated Concepts and Re-selection Features for Ambiguity", "authors": ["Peijie Yin", "Hong Qiao", "Wei Wu", "Lu Qi", "YinLin Li", "Shanlin Zhong", "Bo Zhang"], "emails": ["hong.qiao@ia.ac.cn)."], "sections": [{"heading": null, "text": "This year, it will only take one year for an agreement to be reached."}, {"heading": "II. BIOLOGICAL EVIDENCE", "text": "In this paper, several biological mechanisms are introduced into the new framework to mimic semantic extraction, conceptualization, and re-selection of traits in human visual processing, and related biological evidence is reviewed and discussed for its validity for later implementation."}, {"heading": "A. Semantic Feature Extraction", "text": "Two different types of memory are stored in the brain: episodic memory and semantic memory [25], [27]. Episodic memory stores events and detailed context information, while semantic memory extracts regularities from different spatio-temporal events and forms perception categories, complex concepts and relationships [27]. This requires that the extraction of regularities or semantics should take place via episodes [28], [29]. Since the hippocampus contributes to the organization of information by storing episodic memory and the prefrontal cortex, the extraction process could be achieved through hippocampus and mPFC (medial prefrontal cortex) interaction [30] - [32]. The extracted semantic information could be used for later tasks."}, {"heading": "B. Structural Information", "text": "It has been proposed to describe objects with parts and their positioning and linkage relationships [33], [34]. Thus, for example, neurons in V4 are adjusted to the orientation of contour fragments with a certain object relative position [35]. In other words, a neuron in V4 could react to convex curvature in the lower right (like \"b\"), but not to orientation in the upper right (like \"p\"). Thus, neurons in the V4 range react to individual contour fragments and their relationships are encoded in population reactions [36]. In PIT (posterior inferior temporal cortex), neurons integrate information about multiple fragments [35]. Thus, the integrated explicit representations of multi-part configurations could be encoded in IT."}, {"heading": "C. Selective Attention", "text": "Attention is required when people perform different tasks, as relevant environmental stimuli and information should be selected and processed in the brain [22], [37]. In the attention process, several areas of the brain are activated, such as frontal eye fields (FEF), anterior cingula, frontal cortex, etc. [38]. Visual attention usually consists of active exploration of the environment, task-related information selection, and distraction suppression. If visual stimuli are not clear for the task, the visual attention process may suppress distraction from the location of the previous focus of attention and find new positions to search for related information [39]."}, {"heading": "III. THE FRAMEWORK", "text": "In this section we present the structure of the proposed framework. Firstly, the framework is outlined, and secondly, the algorithms of semantic feature extraction, integrated concept building and feature selection are presented in detail."}, {"heading": "A. Outline of the Framework", "text": "Figure 1 shows the training procedure of the model. Figure 2 shows the detection and online update procedure Block1) Block1: Primary episodic feature extraction block, where episodic features are extracted directly from the original image. Block 1 includes a four-layer Convolutionary Deep Belief Network (CDBN), which is trained layer by layer without supervision. Output of the layer is the activation state of the last layer (for Block 2) and the learned compound weights (for Block 3).2) Block2: Semantic feature extraction block, which applies semantic features from the learned episodic features in Block 1.A cluster-based method, which provides a better abstract description of the object than the character.3) Block3) Block3: Semantic spatial information categories Learning block, where spatial positions of semantic features are learned from the output of Block 1 and Block 2."}, {"heading": "B. Episodic Features Learning with Unsupervised Deep Neural Network (Block 1)", "text": "In human episodic memory, memory is the memory that represents experiences and specific events in time from which people can reconstruct the actual events that took place in any place. (In this work, the episodic features are extracted via an unmonitored, deep neural network. (In our previous work [42], CDBN was used to extract episodic information from the image.) As an unattended model, CDBN is able to extract good local features and encoded components by minimizing the reconstruction errors that ensure good performance in recognition. CDBN is composed of stacked Convolutional Machine (CRBM)."}, {"heading": "C. Semantic Representation Learning based on Episodic Features (Block 2)", "text": "Semantics has several definitions in various fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49], and so on. Cognitive science is about facts that capture the internal properties of an object [27], [47]. Human use of semantic memories to store the category and abstract information about the object and to distinguish one category of objects from another. Binder and Desai [47] have proposed that modality-specific semantic memory is encoded in the corresponding cortex. Convergence of these results, semantic information in the vision is presented in a similar form to visual episodic features, but more abstract and discriminatory. Inspired by the above-mentioned properties of semantic memories in neuroscience, a reasonable hypothesis is that semantic features for visual tasks are formed on the basis of such hierarchical episodic features."}, {"heading": "D. Structural Learning with Population Coding (Block 3 &", "text": "This year, the time has come for a reorientation in the first half of the year, in which there will be a reorientation, which will then enter into force in the second half of the year in the second half of the year."}, {"heading": "F. Feature Re-selection (Block 6)", "text": "During recognition, the human brain is not static, but dynamically adapts to new stimuli. This paper focuses in particular on the ambiguity of images. As the results in the visual systems suggest, the brain will form a new concept based on existing semantic characteristics. [52] Inspired by the above-mentioned principles, a feature of re-election is applied to deal with an ambiguous state in which the results of classification have more than one."}, {"heading": "IV. EXPERIMENT", "text": "Several experiments will be conducted to verify the effectiveness of the proposed biologically inspired model, and each module will be tested and analyzed in detail; the experiments will focus on three aspects: 1) Visualization of episodic and semantic characteristics extracted by the proposed model; 2) Investigation of structural information learned by the proposed model; 3) Assessment of classification performance on different datasets. Extraction of episodic characteristics of the CDBN This experiment is to visualize the extracted episodic characteristics and verify whether these characteristics can capture the critical information of the original image. Here, the MNIST dataset is used as an example. Visualizations of the learned characteristics of the CDBN are given in Figure 9, which corresponds to the episodic characteristics in our model. Here, two visualization techniques are used, including the deconversion method and the average of maximum activations used in the figure."}, {"heading": "B. Semantic Features Extraction and Structure Learning", "text": "This experiment is performed to show the abstraction process from episodic characteristics to structural semantic outcomes. Semantic characteristics are bundled from extracted episodic characteristics, as in Fig. 11. The number of clusters is set at 8. In Fig. 11, different semantic characteristics are less similar to each other, increasing the diversity of characteristics and gathering more information with fewer characteristics. After extracting semantic characteristics, we calculate the activation of PNeurons by applying positioning tuning functions to the characteristics. Here, a positioning function is a 2D Gaussian function with different mean, but the same covariance matrix. For compatibility, we use the discredited version of PNeurons, as shown in Fig. 12. For each feature, there are 16 PNeurons forming a matrix comprising 4 x x 4 x 4 x 4 x 4 x 4 positions. An example of positioning matrix of multiple Gsib is shown in the mixture of Gsib 12."}, {"heading": "C. Feature Re-selection Experiment", "text": "The learned semantic features and structures are not static during the test process. Here, we show how the features are re-selected to deal with the ambiguity and unknowingness. If the input is ambiguous, it is easy to output them as multiple candidates, the model could re-select features to achieve an accurate classification. To better illustrate the process, Fig. 14 shows examples of ambiguous images, while the input images are misclassified as \"6\" by a revolutionary neural network. These ambiguous images are generated by the method proposed in [21], so-called \"adversarial images.\" That is, optimizing and modifying the original image, as that is called \"7,\" is misclassified by a revolutionary neural network as \"6.\" By applying the reverse propagation to the input space and limiting the martyrdom of gradients, we are able to generate tiny perturbations."}, {"heading": "D. Classification Performance", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "V. CONCLUSION", "text": "This paper proposes a novel biologically inspired model for robust visual recognition that mimics the visual processing system in the human brain. By introducing semantics and 11 structural conceptual outputs into the traditional CDBN network, the model gains more generalization ability, especially for a small training dataset. The process of re-selecting characteristics gives the model more robustness against ambiguity. During the cognitive process, when ambiguity is detected during the detection process, new characteristics are re-selected online for later cognition according to the difference between ambiguous candidates. In the future, the proposed model will be further improved by extracting spatio-temporal semantics and concepts for sequence analysis that are more similar to the human neural system. Another approach to improving the model is to further introduce the biological mechanisms in higher perception and inference. A more flexible and robust classifier, such as the cortex function, is integrated into the prex."}], "references": [{"title": "Hierarchical models of object recognition in cortex", "author": ["M. Riesenhuber", "T. Poggio"], "venue": "Nat. Neuroscience, vol. 2, no. 11, pp. 1019\u20131025, 1999.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1999}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Primal sketch: Integrating structure and texture", "author": ["C.-e. Guo", "S.-C. Zhu", "Y.N. Wu"], "venue": "Computer Vision and Image Understanding, vol. 106, no. 1, pp. 5\u201319, 2007.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Top-down feedback in an hmax-like cortical model of object perception based on hierarchical bayesian networks and belief propagation", "author": ["S. Dura-Bernal", "T. Wennekers", "S.L. Denham"], "venue": "PloS one, vol. 7, no. 11, p. e48216, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Realistic modeling of simple and complex cell tuning in the hmax model, and implications for invariant object recognition in cortex", "author": ["T. Serre", "M. Riesenhuber"], "venue": "DTIC Document, Tech. Rep., 2004.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Automated mitosis detection using texture, sift features and hmax biologically inspired approach", "author": ["H. Irshad", "S. Jalali", "L. Roux", "D. Racoceanu", "L.J. Hwee", "G. Le Naour", "F. Capron"], "venue": "J. Pathology informatics, vol. 4, no. Suppl, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Extended coding and pooling in the hmax model", "author": ["C. Theriault", "N. Thome", "M. Cord"], "venue": "IEEE Trans. Image Process., vol. 22, no. 2, pp. 764\u2013777, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Sparsity-regularized hmax for visual recognition", "author": ["X. Hu", "J. Zhang", "J. Li", "B. Zhang"], "venue": "PloS one, vol. 9, no. 1, p. e81813, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1813}, {"title": "Enhanced hmax model with feedforward feature learning for multiclass categorization", "author": ["Y. Li", "W. Wu", "B. Zhang", "F. Li"], "venue": "Frontiers in computational neuroscience, vol. 9, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Hmax model: A survey", "author": ["C. Liu", "F. Sun"], "venue": "Neural Networks (IJCNN), 2015 International Joint Conference on. IEEE, 2015, pp. 1\u20137.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Biologically plausible saliency mechanisms improve feedforward object recognition", "author": ["S. Han", "N. Vasconcelos"], "venue": "Vision research, vol. 50, no. 22, pp. 2295\u20132307, 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Hierarchical model for object recognition based on natural-stimuli adapted filters", "author": ["P. Mishra", "B.K. Jenkins"], "venue": "Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on. IEEE, 2010, pp. 950\u2013953.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "A model of saliency-based visual attention for rapid scene analysis", "author": ["L. Itti", "C. Koch", "E. Niebur"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., no. 11, pp. 1254\u20131259, 1998.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "A neural model combining attentional orienting to object recognition: Preliminary explorations on the interplay between where and what", "author": ["F. Miau", "L. Itti"], "venue": "Proc. of the 23rd Annu. International Conference of the IEEE, vol. 1. IEEE, 2001, pp. 789\u2013792.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "Attentional selection for object recognition: gentle way", "author": ["D. Walther", "L. Itti", "M. Riesenhuber", "T. Poggio", "C. Koch"], "venue": "Biologically Motivated Computer Vision. Springer, 2002, pp. 472\u2013479.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "What and where: A bayesian inference theory of attention", "author": ["S. Chikkerur", "T. Serre", "C. Tan", "T. Poggio"], "venue": "Vision research, vol. 50, no. 22, pp. 2233\u20132247, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "What/where to look next? modeling top-down visual attention in complex interactive environments", "author": ["A. Borji", "D.N. Sihite", "L. Itti"], "venue": "IEEE Trans. Syst., Man, Cybern., A, vol. 44, no. 5, pp. 523\u2013538, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Introducing memory and association mechanism into a biologically inspired visual model", "author": ["H. Qiao", "Y. Li", "T. Tang", "P. Wang"], "venue": "IEEE Trans. Cybern., vol. 44, no. 9, pp. 1485\u20131496, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Biologically inspired visual model with preliminary cognition and active attention adjustment", "author": ["H. Qiao", "X. Xi", "Y. Li", "W. Wu", "F. Li"], "venue": "IEEE Trans. Cybern., vol. 45, no. 11, pp. 2612\u20132624, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["A. Nguyen", "J. Yosinski", "J. Clune"], "venue": "arXiv preprint arXiv:1412.1897, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1897}, {"title": "Explaining and harnessing adversarial examples", "author": ["I.J. Goodfellow", "J. Shlens", "C. Szegedy"], "venue": "arXiv preprint arXiv:1412.6572, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural mechanisms of selective visual attention", "author": ["R. Desimone", "J. Duncan"], "venue": "Annu. review of neuroscience, vol. 18, no. 1, pp. 193\u2013222, 1995.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1995}, {"title": "A biologically inspired system for action recognition", "author": ["H. Jhuang", "T. Serre", "L. Wolf", "T. Poggio"], "venue": "Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on. Ieee, 2007, pp. 1\u20138.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "The Representation of Meaning in Memory (PLE: Memory)", "author": ["W. Kintsch"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Where do you know what you know? the representation of semantic knowledge in the human brain", "author": ["K. Patterson", "P.J. Nestor", "T.T. Rogers"], "venue": "Nature Reviews Neuroscience, vol. 8, no. 12, pp. 976\u2013987, 2007.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["B.M. Lake", "R. Salakhutdinov", "J.B. Tenenbaum"], "venue": "Science, vol. 350, no. 6266, pp. 1332\u20131338, 2015.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "How many memory systems are there?", "author": ["E. Tulving"], "venue": "American psychologist,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1985}, {"title": "Functional neuroanatomy of remote episodic, semantic and spatial memory: a unified account based on multiple trace theory", "author": ["M. Moscovitch", "R.S. Rosenbaum", "A. Gilboa", "D.R. Addis", "R. Westmacott", "C. Grady", "M.P. McAndrews", "B. Levine", "S. Black", "G. Winocur"], "venue": "J. Anatomy, vol. 207, no. 1, pp. 35\u201366, 2005.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "Neural mechanisms supporting the extraction of general knowledge across episodic memories", "author": ["C.C. Sweegers", "A. Takashima", "G. Fern\u00e1ndez", "L.M. Talamini"], "venue": "Neuroimage, vol. 87, pp. 138\u2013146, 2014.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Coherent theta oscillations and reorganization of spike timing in the hippocampal-prefrontal network upon learning", "author": ["K. Benchenane", "A. Peyrache", "M. Khamassi", "P.L. Tierney", "Y. Gioanni", "F.P. Battaglia", "S.I. Wiener"], "venue": "Neuron, vol. 66, no. 6, pp. 921\u2013936, 2010.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Tracking the emergence of conceptual knowledge during human decision making", "author": ["D. Kumaran", "J.J. Summerfield", "D. Hassabis", "E.A. Maguire"], "venue": "Neuron, vol. 63, no. 6, pp. 889\u2013901, 2009.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Persistent schema-dependent hippocampal-neocortical connectivity during memory encoding and postencoding rest in humans", "author": ["M.T. van Kesteren", "G. Fern\u00e1ndez", "D.G. Norris", "E.J. Hermans"], "venue": "Proc. Natl. Acad. Sci. U.S.A., vol. 107, no. 16, pp. 7550\u20137555, 2010.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Recognition-by-components: a theory of human image understanding.", "author": ["I. Biederman"], "venue": "Psychological review,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1987}, {"title": "Representation and recognition of the spatial organization of three-dimensional shapes", "author": ["D. Marr", "H.K. Nishihara"], "venue": "Proc. the Royal Society of London B: Biological Sciences, vol. 200, no. 1140, pp. 269\u2013 294, 1978.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1978}, {"title": "Shape representation in area v4: position-specific tuning for boundary conformation", "author": ["A. Pasupathy", "C.E. Connor"], "venue": "J. neurophysiology, vol. 86, no. 5, pp. 2505\u20132519, 2001.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2001}, {"title": "Population coding of shape in area v4", "author": ["\u2014\u2014"], "venue": "Nature neuroscience, vol. 5, no. 12, pp. 1332\u20131338, 2002.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2002}, {"title": "The attention system of the human brain: 20 years after", "author": ["S.E. Petersen", "M.I. Posner"], "venue": "Annu. review of neuroscience, vol. 35, p. 73, 2012.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Using genetic data in cognitive neuroscience: from growing pains to genuine insights", "author": ["A.E. Green", "M.R. Munaf\u00f2", "C.G. DeYoung", "J.A. Fossella", "J. Fan", "J.R. Gray"], "venue": "Nature Reviews Neuroscience, vol. 9, no. 9, pp. 710\u2013720, 2008.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2008}, {"title": "The native coordinate system of spatial attention is retinotopic", "author": ["J.D. Golomb", "M.M. Chun", "J.A. Mazer"], "venue": "J. Neuroscience, vol. 28, no. 42, pp. 10 654\u201310 662, 2008.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "Episodic memory: From mind to brain", "author": ["E. Tulving"], "venue": "Annu. review of psychology, vol. 53, no. 1, pp. 1\u201325, 2002.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2002}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "Proc. the 26th Annu. Int. Conference on Mach. Learning. ACM, 2009, pp. 609\u2013616.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2009}, {"title": "Biologically inspired model for visual cognition achieving unsupervised episodic and semantic feature learning", "author": ["H. Qiao", "Y. Li", "F. Li", "W. Wu"], "venue": "IEEE Trans. Cybern., 2015.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["G.E. Hinton"], "venue": "Neural computation, vol. 14, no. 8, pp. 1771\u20131800, 2002.  12", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2002}, {"title": "Is semantics still possible?", "author": ["J. Berg"], "venue": "J. pragmatics,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2002}, {"title": "How comparative is semantics? a unified parametrictheory of bare nouns and proper names", "author": ["G. Longobardi"], "venue": "Natural language semantics, vol. 9, no. 4, pp. 335\u2013369, 2001.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2001}, {"title": "Composition in distributional models of semantics", "author": ["J. Mitchell", "M. Lapata"], "venue": "Cognitive science, vol. 34, no. 8, pp. 1388\u20131429, 2010.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2010}, {"title": "The neurobiology of semantic memory", "author": ["J.R. Binder", "R.H. Desai"], "venue": "Trends in cognitive sciences, vol. 15, no. 11, pp. 527\u2013536, 2011.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2011}, {"title": "Combining answer set programming with description logics for the semantic web", "author": ["T. Eiter", "G. Ianni", "T. Lukasiewicz", "R. Schindlauer", "H. Tompits"], "venue": "Artificial Intelli., vol. 172, no. 12, pp. 1495\u20131539, 2008.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning the semantics of object\u2013action relations by observation", "author": ["E.E. Aksoy", "A. Abramov", "J. D\u00f6rr", "K. Ning", "B. Dellen", "F. W\u00f6rg\u00f6tter"], "venue": "The International J. of Robotics Research, p. 0278364911410459, 2011.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2011}, {"title": "Top-down activation of shape-specific population codes in visual cortex during mental imagery", "author": ["M. Stokes", "R. Thompson", "R. Cusack", "J. Duncan"], "venue": "The J. of Neuroscience, vol. 29, no. 5, pp. 1565\u20131572, 2009.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2009}, {"title": "How recent experience affects the perception of ambiguous objects", "author": ["V. Daelli", "N.J. van Rijsbergen", "A. Treves"], "venue": "Brain research, vol. 1322, pp. 81\u201391, 2010.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2010}, {"title": "The parallel distributed processing approach to semantic cognition", "author": ["J.L. McClelland", "T.T. Rogers"], "venue": "Nature Reviews Neuroscience, vol. 4, no. 4, pp. 310\u2013322, 2003.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2003}, {"title": "Intriguing properties of neural networks", "author": ["C. Szegedy", "W. Zaremba", "I. Sutskever", "J. Bruna", "D. Erhan", "I. Goodfellow", "R. Fergus"], "venue": "Learning Representation, 2014. ICLR 2014. International Conference on, 2014, pp. 1\u20138.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "HMAX model tries to mimic the functions of primate visual system layer by layer [1].", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "The main difference between HMAX and other hierarchical architectures (such as hand-crafted hierarchical features [2], convolutional neural networks [3], and etc.", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "The main difference between HMAX and other hierarchical architectures (such as hand-crafted hierarchical features [2], convolutional neural networks [3], and etc.", "startOffset": 149, "endOffset": 152}, {"referenceID": 3, "context": ") is that it focused on reproducing anatomical, physiological and psychophysical properties of the ventral pathway of visual system [4], which consists of V 1, V 2, V 4 and inferior temporal (IT) cortical areas.", "startOffset": 132, "endOffset": 135}, {"referenceID": 4, "context": "After its first publication in 1999, this well-known model has been further developed and improved in different aspects [5]\u2013[8].", "startOffset": 120, "endOffset": 123}, {"referenceID": 7, "context": "After its first publication in 1999, this well-known model has been further developed and improved in different aspects [5]\u2013[8].", "startOffset": 124, "endOffset": 127}, {"referenceID": 8, "context": "For example, many researchers modified the original HMAX model by adding feedback process to improve the recognition precision [9], [10].", "startOffset": 127, "endOffset": 130}, {"referenceID": 9, "context": "For example, many researchers modified the original HMAX model by adding feedback process to improve the recognition precision [9], [10].", "startOffset": 132, "endOffset": 136}, {"referenceID": 7, "context": "Other modifications include adding sparsity to the convolutional layer [8], enhancing the architecture by adding specific layers to the model [7], [11], and changing strategies of feature selection and filtering properties [12].", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "Other modifications include adding sparsity to the convolutional layer [8], enhancing the architecture by adding specific layers to the model [7], [11], and changing strategies of feature selection and filtering properties [12].", "startOffset": 142, "endOffset": 145}, {"referenceID": 10, "context": "Other modifications include adding sparsity to the convolutional layer [8], enhancing the architecture by adding specific layers to the model [7], [11], and changing strategies of feature selection and filtering properties [12].", "startOffset": 147, "endOffset": 151}, {"referenceID": 11, "context": "Other modifications include adding sparsity to the convolutional layer [8], enhancing the architecture by adding specific layers to the model [7], [11], and changing strategies of feature selection and filtering properties [12].", "startOffset": 223, "endOffset": 227}, {"referenceID": 12, "context": "Itti proposed a saliency-based model based on the saliency map theory in human visual system [13] and combined attention with object recognition [14], [15].", "startOffset": 93, "endOffset": 97}, {"referenceID": 13, "context": "Itti proposed a saliency-based model based on the saliency map theory in human visual system [13] and combined attention with object recognition [14], [15].", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "Itti proposed a saliency-based model based on the saliency map theory in human visual system [13] and combined attention with object recognition [14], [15].", "startOffset": 151, "endOffset": 155}, {"referenceID": 15, "context": "It has been implement by Bayesian inference [16] and saliency model [17].", "startOffset": 44, "endOffset": 48}, {"referenceID": 16, "context": "It has been implement by Bayesian inference [16] and saliency model [17].", "startOffset": 68, "endOffset": 72}, {"referenceID": 17, "context": "developed a series of models introducing association [18], attention [19] to the model.", "startOffset": 53, "endOffset": 57}, {"referenceID": 18, "context": "developed a series of models introducing association [18], attention [19] to the model.", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "However, recent findings [20], [21] point out that even the state-of-art deep hierarchical networks suffer from tiny disturbance and transformation.", "startOffset": 25, "endOffset": 29}, {"referenceID": 20, "context": "However, recent findings [20], [21] point out that even the state-of-art deep hierarchical networks suffer from tiny disturbance and transformation.", "startOffset": 31, "endOffset": 35}, {"referenceID": 20, "context": "It is shown that tiny perturbation may cause significant difference in the output of hierarchical network models [21].", "startOffset": 113, "endOffset": 117}, {"referenceID": 21, "context": "According to biological findings, objection recognition tasks involve multiple cortices and many sophisticated mechanisms including preliminary cognition, top-down attention [22], semantic and conceptual memory [23]\u2013[25].", "startOffset": 174, "endOffset": 178}, {"referenceID": 22, "context": "According to biological findings, objection recognition tasks involve multiple cortices and many sophisticated mechanisms including preliminary cognition, top-down attention [22], semantic and conceptual memory [23]\u2013[25].", "startOffset": 211, "endOffset": 215}, {"referenceID": 24, "context": "According to biological findings, objection recognition tasks involve multiple cortices and many sophisticated mechanisms including preliminary cognition, top-down attention [22], semantic and conceptual memory [23]\u2013[25].", "startOffset": 216, "endOffset": 220}, {"referenceID": 25, "context": "Lake, Salakhutdinov and Tenenbaum recently [26] employs semantics and concepts explicitly and achieves significant improvement in robustness of one-shot character recognition.", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "Two different types of memory are stored in the brain: episodic memory and semantic memory [25], [27].", "startOffset": 91, "endOffset": 95}, {"referenceID": 26, "context": "Two different types of memory are stored in the brain: episodic memory and semantic memory [25], [27].", "startOffset": 97, "endOffset": 101}, {"referenceID": 26, "context": "Episodic memory stores events and detailed contextual information, while semantic memory extracts regularities from different spatial-temporal events and forms perceptual categories, complex concepts and relations [27].", "startOffset": 214, "endOffset": 218}, {"referenceID": 27, "context": "This requires that extraction of regularities or semantics should be carried out over episodes [28], [29].", "startOffset": 95, "endOffset": 99}, {"referenceID": 28, "context": "This requires that extraction of regularities or semantics should be carried out over episodes [28], [29].", "startOffset": 101, "endOffset": 105}, {"referenceID": 29, "context": "Since hippocampus is involved with storage of episodic memory and prefrontal cortex contributes to organization of information, the extraction process could be achieved via hippocampus and mPFC (medial prefrontal cortex) interaction [30]\u2013[32].", "startOffset": 233, "endOffset": 237}, {"referenceID": 31, "context": "Since hippocampus is involved with storage of episodic memory and prefrontal cortex contributes to organization of information, the extraction process could be achieved via hippocampus and mPFC (medial prefrontal cortex) interaction [30]\u2013[32].", "startOffset": 238, "endOffset": 242}, {"referenceID": 32, "context": "It has been proposed that objects could be described with parts and their positional and connectional relationships [33], [34].", "startOffset": 116, "endOffset": 120}, {"referenceID": 33, "context": "It has been proposed that objects could be described with parts and their positional and connectional relationships [33], [34].", "startOffset": 122, "endOffset": 126}, {"referenceID": 34, "context": "For example, neurons in V4 are tuned for contour fragment orientation with specific object-relative position [35].", "startOffset": 109, "endOffset": 113}, {"referenceID": 35, "context": "Thus, in V4 area, neurons respond to individual contour fragments and their relationships are encoded in population responses [36].", "startOffset": 126, "endOffset": 130}, {"referenceID": 34, "context": "In PIT (posterior inferior temporal cortex), neurons integrate information on multiple fragments [35].", "startOffset": 97, "endOffset": 101}, {"referenceID": 21, "context": "Attention is required when people carry out various tasks, since relevant environmental stimuli and information should be selected and processed in the brain [22], [37].", "startOffset": 158, "endOffset": 162}, {"referenceID": 36, "context": "Attention is required when people carry out various tasks, since relevant environmental stimuli and information should be selected and processed in the brain [22], [37].", "startOffset": 164, "endOffset": 168}, {"referenceID": 37, "context": "[38].", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "When visual stimuli is not clear for the task, visual attention process could suppress distraction from location of previous attention focus and find new positions for the search of related information [39].", "startOffset": 202, "endOffset": 206}, {"referenceID": 26, "context": "In human, episodic memory is the memory that represents experiences and specific events in time, from which people can reconstruct the actual events that took place at any given time [27].", "startOffset": 183, "endOffset": 187}, {"referenceID": 39, "context": "Episodic memory is one of the basic forms of explicit memory and considered as the source of other forms of memory [40].", "startOffset": 115, "endOffset": 119}, {"referenceID": 40, "context": "Unsupervised convolutional deep belief network (CDBN) is first introduced in Ng\u2019s work [41] for feature extraction tasks.", "startOffset": 87, "endOffset": 91}, {"referenceID": 41, "context": "In our previous work [42], CDBN has been used to extract episodic information from the image.", "startOffset": 21, "endOffset": 25}, {"referenceID": 42, "context": "The CRBM can be trained with Contrastive Divergence (CD), which is an approximate Maximum-Likelihood learning algorithm [43].", "startOffset": 120, "endOffset": 124}, {"referenceID": 43, "context": "Semantics has multiple definitions in different fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49] and etc.", "startOffset": 76, "endOffset": 80}, {"referenceID": 44, "context": "Semantics has multiple definitions in different fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49] and etc.", "startOffset": 82, "endOffset": 86}, {"referenceID": 45, "context": "Semantics has multiple definitions in different fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49] and etc.", "startOffset": 106, "endOffset": 110}, {"referenceID": 46, "context": "Semantics has multiple definitions in different fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49] and etc.", "startOffset": 112, "endOffset": 116}, {"referenceID": 47, "context": "Semantics has multiple definitions in different fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49] and etc.", "startOffset": 142, "endOffset": 146}, {"referenceID": 48, "context": "Semantics has multiple definitions in different fields, such as linguistics [44], [45], cognitive science [46], [47], artificial intelligence [48], [49] and etc.", "startOffset": 148, "endOffset": 152}, {"referenceID": 26, "context": "In cognitive science, semantic memory is about facts that capture the internal properties about an object [27], [47].", "startOffset": 106, "endOffset": 110}, {"referenceID": 46, "context": "In cognitive science, semantic memory is about facts that capture the internal properties about an object [27], [47].", "startOffset": 112, "endOffset": 116}, {"referenceID": 46, "context": "Binder and Desai [47] proposed that modality-specific semantic memory is encoded in the corresponding cortex.", "startOffset": 17, "endOffset": 21}, {"referenceID": 49, "context": "Neuroscience researches [50] reveal that human brain processes this kind of information with a population of neurons.", "startOffset": 24, "endOffset": 28}, {"referenceID": 44, "context": "Related model can predict human eye movements well in visual search tasks without any further assumptions or parameter tuning [45].", "startOffset": 126, "endOffset": 130}, {"referenceID": 50, "context": "As the findings in visual systems suggest [51], for an ambiguous image which has multiple competitive candidates, human will pay more attention to the difference between the candidates.", "startOffset": 42, "endOffset": 46}, {"referenceID": 51, "context": "When a new category of images appears, the brain tends to form a new concept, based on existing semantic memory [52]", "startOffset": 112, "endOffset": 116}, {"referenceID": 40, "context": "Here, two visualization techniques are used, including the deconvolution method and the average of max activations used in [41].", "startOffset": 123, "endOffset": 127}, {"referenceID": 40, "context": "9, the proposed deconvolution method could achieve clearer edges and parts than the method in [41].", "startOffset": 94, "endOffset": 98}, {"referenceID": 20, "context": "These ambiguous images are generated by the method proposed in [21], so-called \"adversarial images\".", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": "Images with perturbation are originally designed for a convolutional neural network, but it could also affect the recognition by a CDBN, which is consistent with the results in [21].", "startOffset": 177, "endOffset": 181}, {"referenceID": 40, "context": "ologically inspired models (such as traditional CDBN [41], HMAX [1], and etc.", "startOffset": 53, "endOffset": 57}, {"referenceID": 0, "context": "ologically inspired models (such as traditional CDBN [41], HMAX [1], and etc.", "startOffset": 64, "endOffset": 67}, {"referenceID": 52, "context": "2) Ambiguous Images from MNIST: The ambiguous data set is generated by adding a relative small perturbation to the original MNIST data sets [53].", "startOffset": 140, "endOffset": 144}], "year": 2016, "abstractText": "Integration between biology and information science benefits both fields. Many related models have been proposed, such as computational visual cognition models, computational motor control models, integrations of both and so on. In general, the robustness and precision of recognition is one of the key problems for object recognition models. In this paper, inspired by features of human recognition process and their biological mechanisms, a new integrated and dynamic framework is proposed to mimic the semantic extraction, concept formation and feature re-selection in human visual processing. The main contributions of the proposed model are as follows: (1) Semantic feature extraction: Local semantic features are learnt from episodic features that are extracted from raw images through a deep neural network; (2) Integrated concept formation: Concepts are formed with local semantic information and structural information learnt through network. (3) Feature re-selection: When ambiguity is detected during recognition process, distinctive features according to the difference between ambiguous candidates are re-selected for recognition. Experimental results on hand-written digits and facial shape dataset show that, compared with other methods, the new proposed model exhibits higher robustness and precision for visual recognition, especially in the condition when input samples are smantic ambiguous. Meanwhile, the introduced biological mechanisms further strengthen the interaction between neuroscience and information science.", "creator": "LaTeX with hyperref package"}}}