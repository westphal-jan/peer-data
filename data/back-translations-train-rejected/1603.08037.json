{"id": "1603.08037", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2016", "title": "On the Detection of Mixture Distributions with applications to the Most Biased Coin Problem", "abstract": "This paper studies the trade-off between two different kinds of pure exploration: breadth versus depth. The most biased coin problem asks how many total coin flips are required to identify a \"heavy\" coin from an infinite bag containing both \"heavy\" coins with mean $\\theta_1 \\in (0,1)$, and \"light\" coins with mean $\\theta_0 \\in (0,\\theta_1)$, where heavy coins are drawn from the bag with probability $\\alpha \\in (0,1/2)$. The key difficulty of this problem lies in distinguishing whether the two kinds of coins have very similar means, or whether heavy coins are just extremely rare. This problem has applications in crowdsourcing, anomaly detection, and radio spectrum search. Chandrasekaran et. al. (2014) recently introduced a solution to this problem but it required perfect knowledge of $\\theta_0,\\theta_1,\\alpha$. In contrast, we derive algorithms that are adaptive to partial or absent knowledge of the problem parameters. Moreover, our techniques generalize beyond coins to more general instances of infinitely many armed bandit problems. We also prove lower bounds that show our algorithm's upper bounds are tight up to $\\log$ factors, and on the way characterize the sample complexity of differentiating between a single parametric distribution and a mixture of two such distributions. As a result, these bounds have surprising implications both for solutions to the most biased coin problem and for anomaly detection when only partial information about the parameters is known.", "histories": [["v1", "Fri, 25 Mar 2016 21:22:59 GMT  (40kb)", "http://arxiv.org/abs/1603.08037v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["kevin jamieson", "daniel haas", "ben recht"], "accepted": false, "id": "1603.08037"}, "pdf": {"name": "1603.08037.pdf", "metadata": {"source": "CRF", "title": "On the Detection of Mixture Distributions with applications to the Most Biased Coin Problem", "authors": ["Kevin Jamieson"], "emails": ["kjamieson@eecs.berkeley.edu", "dhaas@eecs.berkeley.edu", "brecht@eecs.berkeley.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.08 037v 1 [cs.L G] 25 M"}, {"heading": "1 Introduction", "text": "In contrast, this work examines the trade-off between two different types of pure exploration: width versus depth. Consider a magic bag containing an infinite number of two types of biased coins: \"heavy\" coins with medium probability (0, 1) and \"light\" coins with medium probability (0, 1) and \"light\" coins with medium probability (0, 1). When a player selects a coin from his pocket, with the probability that the coin is \"heavy\" and probable (1 \u2212 \u03b1), the coin is \"light.\" The player can pick any coin from his pocket as many times as he wants, and the goal is to identify a heavy coin. The main difficulty of this problem is to distinguish whether the two types of coins have very similar means, or whether heavy coins are extremely rare. This is how to flip a single coin several times to maximize the probability to maximize the probability of a problem."}, {"heading": "1.1 Motivation and Related Work", "text": "Labeling data for machine learning applications is often done by humans, and recent work in the crowdsourcing literature speeds up labeling by organizing and paying workers into groups of markers to wait for incoming data (Bernstein et al., 2011; Haas et al., 2015). Because workers hired in marketplaces like Amazon's Mechanical Turk (MTurk) vary widely in skills, identifying high-quality workers is an important challenge. If we model each worker's performance (e.g. accuracy or speed) based on a set of tasks drawn from some distribution to [0, 1] then selecting a good worker is tantamount to identifying a worker with a high mean by taking as few total samples as possible from all workers. If we do not pay attention directly to an employee's innate skill or importance, we must give them tasks from which we evaluate them (such as repeatedly flipping a distorted coin), which means good identification is the most common problem."}, {"heading": "1.2 Preliminaries", "text": "Let P and Q be two probability distributions with a common measurable space. For the sake of simplicity, assume that P and Q have the same support. Definition 1. Definition of the KL divergence between P and Q as KL (P, Q) = Log (dP dQ) dP. Definition 2. Definition of the KL divergence between P and Q as Log (P, Q) = Log (dP dQ) = Log (dP (x) \u2212 dQ (x)) 2 dQ (x) dx.Note that Jensen's inequality KL (P, Q) = EP [Log (dPdQ)] \u2264 Log (EP [dPdQ]) = Log (P, Q) + 1 Log (P, Q) \u2264 Log (P, Q) + 1 Log (P, Q) + 1 Log (P, Q) (2) Example 1 (Gaussian)."}, {"heading": "1.3 The Most Biased Coin Problem Statement", "text": "Consider a sequence of iid Bernoulli random variables. Consider a sequence of iid Bernoulli random variables drawn from i = 1, 2,.. if each P (i = 1) = 1 \u2212 P (i = 0) = \u03b1. Let Xi, j for j = 1, 2,.. be a sequence of random variables drawn from i = 1 and otherwise from i = 1, and let {Xi, j} Mij = 1} Ni = 1 represent the sample history, which is represented by a method for some N-N and (M1,..) a sequence of random variables drawn from i = 1 and otherwise. (MN) represent a sequence of random variables drawn by a method for some N-N and (NN,.) a sequence of random variables."}, {"heading": "2 Lower bounds", "text": "In this section, we deduce lower limits for the sample complexity of valid procedures. Section 2.1 provides a lower limit for each adaptive procedure that can independently decide how often samples are sampled from each distribution, and Section 2.2 deduces limits for procedures of fixed sample size that select one m \u2265 1 and one sample from each distribution exactly m times. Section 2.2.1 applies to procedures with full knowledge of \u03b1, \u03b80, \u03b81, and Section 2.2.2 shows that without knowledge of these parameters, the sample complexity becomes much higher. Initialize an empty history (N = 0, M = {}). Repeat until the heavy distribution: Select one of 1. get an additional sample from the distribution i = N so that Wed \u2190 Wed + 1 2. Draw a sample from the (N + 1) st distribution so that N \u2190 N + 1, MN = 1 3. the distribution i = N is taken as a heavy algorithm 1: Sequential method for identification of a particular time may declare a heavy distribution to be the last one."}, {"heading": "2.1 Fully adaptive strategies", "text": "Theorem 1. (Malloy et al., 2012, Theorem 2) Fix \u03b4 (0, 1). Allow T to be the total number of samples taken from each method that is likely to be correct in identifying a heavy distribution. ThenE [T] \u2265 c1 max {1 \u2212 \u03b4 \u03b1, (1 \u2212 \u03b4) \u03b1KL (g\u03b80 | g\u03b81)} always where c1, c2 (0, 1) are absolute constants. The above theorem is directly applicable to the specific case where it is a Bernoulli distribution, which implicitly implies a lower limit of max {1 \u2212 \u03b4, pending for 2min (0, 1) means that this upper theorem (0 \u2212 1) is applicable."}, {"heading": "2.2 The fixed sample size strategy and the detection of mixtures", "text": "The lower limits of this section are based on two simple observations. The first observation is that determining that a specific distribution i \u2264 N is heavy (i.e. that a specific distribution i \u2264 1) is at least as difficult as determining that one of the distributions up to time N is heavy. Therefore, we have reduced the problem to a sequential hypotheses test, whether all observed samples come from a single distribution or from a mixture of two distributions: Problem 2.H0: i, j Xi, j \u00b2, j \u00b2, g \u00b2, for some distribution problems."}, {"heading": "2.2.1 Sample complexity when parameters are known", "text": "Theorem 2 characterizes the sample complexity of problem 3 for each valid procedure. Note that a lower limitation of the problem also limits any specified sample size method that solves the most distorted coin problem. Theorem 2. Fix \u03b4 (0, 1). Consider the hypotheses test of problem 3 for all established problems. Let N be the random number of distributions that are taken into account before stopping and explaining a hypothesis. If a procedure fulfills P0 (N < \u221e) \u2264 \u03b4 and P1 (HNi = 1 {\u0445i = 1}) \u2265 1 \u2212 \u0421i, then E1 [N] \u2265 max {1 \u2212 \u0421\u0430 \u03b1, log (1\u0421\u0430) KL (P1 | P0)} \u2265 max {1 \u2212 \u0421\u0430, log (1\u043c) \u04212 (P1 | P0)}."}, {"heading": "In addition, if \u0398\u0303 = {\u03b80} then", "text": "The next sequence refers to theorem 2 in the special case where the distribution is Bernoulli coins and the goal is to find a heavy coin; the second result of the sequence is similar to that of Malloy et al. (2012, theorem 4), which considers the limit as \u03b1 \u2192 0 and assumes that m is sufficiently large (specific, large enough to apply the Chernoff Stone Lemma); in contrast, our result applies to all finite coins, \u03b1, m. Correction 1. Fix \u03b4 (0, 1), m \u00b2 N and let us consider the class of algorithms that flips each coin exactly m times and returns a coin i \u2264 N as its estimate for a heavy coin. If an algorithm in this class III is probably correct, then the algorithm in this class III-probably thenE [Nm] is max. \u2212 \u2212 \u2212 \u2212 \u2212 scale 0, log (1) small coin \u2264 1 (1) we can issue a coin as a heavy coin estimate."}, {"heading": "2.2.2 Sample complexity when parameters are unknown", "text": "Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha Alpha"}, {"heading": "3 Upper bounds and algorithms", "text": "In this section, we demonstrate the existence of algorithms that are close to the lower limits, even with only partial ancillary knowledge. Table 1 summarizes the algorithms and their limitations. Our main result in Section 3.3 is Theorem 8, which describes the performance of an algorithm that has no prior knowledge of the parameters \u03b1, \u03b80, \u03b81, but yields an upper limit that corresponds to the lower limit of Theorem 1 down to logarithmic factors. In the following, we assume that samples from heavy or light distributions are based on [0, 1] and that drawn samples are independent and unbiased estimators of the mean value, i.e. E [Xi, j] = \u00b5i for \u00b5i distributions. All results can easily be extended to sub-Gaulish distributions. We start with a fixed sample strategy and then turn our attention to adaptive sampling methods."}, {"heading": "3.1 Fixed sample strategy for known \u03b1, \u03b80, \u03b81", "text": "A lower limit of \u03b1 tells us how many distributions we have to take into account, and the knowledge of the difference (\u03b81 \u2212 \u03b80) tells us how often we should scan each distribution as a sample. The following sentence is within a logfactor of the lower limit, which has generally proved itself in sequence 1 and is narrow if \u03b1 \u2264 \u03b4. Theorem 4 (Fixed sample size, known \u03b1 and \u03b80, \u03b81) There is a fixed sample size strategy with stopping time Nm \u2264 n \u0438, which is most likely correct and satisfactory E [mNm] \u2264 3 log (1 / \u03b1) + Log (12 log (6 / \u04210) \u03b1 (\u04451 \u2212 success0) 2 \u2264 12 log (2 \u041a1 \u2212 \u03b80)."}, {"heading": "3.2 Fully adaptive strategies when \u03b1 and/or \u03b80, \u03b81 are known", "text": "While the previous section is considered as a strategy that takes a constant number of samples from each distribution, this section allows the determination of the number of times to sample a particular distribution, adaptive based on the samples from that distribution. \u2212 This section also shows that there are simple procedures that adapt to the case when only a subset of Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha and Alpha, Alpha, Alpha and Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, Alpha, Alpha and Alpha, Alpha and Alpha, Alpha, Alpha and Alpha, Alpha, Alpha, and Alpha, Alpha, Alpha, Alpha, and Alpha, Alpha, Alpha, Alpha, and Alpha, Alpha, Alpha, and Alpha, Alpha, and Alpha, Alpha, and Alpha, Alpha, and Alpha, and Alpha, and Alpha, Alpha, Alpha, and Alpha, and Alpha"}, {"heading": "3.3 Fully adaptive strategies when \u03b1, \u03b80, \u03b81 are unknown", "text": "The algorithm for this setting, algorithm 5, requires a more sophisticated argument than the simple \"duplication trick\" used above, when incomplete information was available. As far as we know, this is the first result of its kind that does not require prior estimation or knowledge of the unknown mean distribution parameters. We also point out that the placement of \"boundary stones\" (\u03b1k, \u0395k) throughout the search space as performed in algorithm 5 can also be generalized to generic, unlimited, armed bandit problems, which may be a simple alternative to the two-step approach to estimation, then the research of Carpentier and Valko (2015)."}, {"heading": "4 Conclusion", "text": "In this paper, we demonstrate upper and lower limits of the complexity of detecting mixture distributions with partial or lack of knowledge of distribution parameters. We note that there is still a logfactor gap between several of our upper and lower boundaries, and investigating whether one of the two can be tightened remains an interesting problem. Importantly, in this paper we have considered mixtures of only two components, while the literature on infinitely armed bandits considers continuous mixture. Extending the algorithms developed for our upper boundaries to the case of continuous mixture is a promising direction, as it would be the first such algorithm that does not rely on knowledge of distribution parameters or evaluates them initially with a two-step approach."}, {"heading": "Acknowledgments", "text": "Kevin Jamieson is generously supported by the ONR awards N00014-15-1-2620 and N00014-13-1-0129. This research is supported in part by the NSF CISE Expeditions Award CCF-1139158, the DOE Award SN10040 de-sc0012463 and the DARPA XData Award FA8750-12-2-0331, as well as gifts from Amazon Web Services, Google, IBM, SAP, The Thomas and Stacey Siebel Foundation, Apple Inc., Arimo, Blue Goji, Bosch, Cisco, Cray, Cloudera, Ericsson, Facebook, Fujitsu, Guavus, HP, Huawei, Intel, Microsoft, Pivotal, Samsung, Schlumberger, Splunk, State Farm and VMware."}, {"heading": "A Proofs of Lower Bounds", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Proof of Claim 1", "text": "Proof. Suppose there is a \u03b4-probably correct method with P (N (0, \u03b80, \u03b81) < \u221e) > \u03b4. Then there is a finite n-shaped method, so that P (N (0, \u03b80, \u03b81) \u2264 n) > \u03b4. To be defined later, define \u03b1 (0, 1) = log (11) 2n \"and note that for this \u03b1, P (n) i = 1 (0) = (1 \u2212 \u03b1) n (1 \u2212 \u03b1) n (1 \u2212 2) n (1 \u2212 1). Thus, the probability that the method ends with a light distribution below \u03b1 = \u03b1) is at least P (N (\u03b1, \u04450, \u04451) \u2264 n (n)."}, {"heading": "A.2 Proof of Theorem 2", "text": "First of all, let us prove that N is the number of distributions considered at the time of the stop. Note that T \u2265 N (1). Assuming that the method fulfills P1 (N \u2265 n = 1 {\u03b8i = 0}) = P1 (N \u2265 n = 1 {\u043fi = 0}) P1 (N \u00b1 n \u2212 1i = 1 {\u043fi = 0}) \u2265 (1 \u2212 \u0432) (1 \u2212 \u0445) n \u2212 1Thus, E1 [N] = \u2211 n = 1 P1 (N \u2012 n) \u2265 n = 1 (1 \u2212 \u03b1 = 0}) P1 (1 \u2212 \u0421i = 1}) \u2265 (1 \u2212 \u0421i) n \u2212 1Thus, the first argument of the maximally applicable theorem 2,38 of Siegmund (2013) results in < E1 < P1 \u2212 fem) n = 1 (P1 \u2212 \u03b1) n \u2212 1 result (1 \u2212 \u041a1)."}, {"heading": "A.3 Proof of Corollary 1", "text": "The proof: For k = 0, 1 g\u03b8k should be a Bernoulli distribution with the parameter \u03b8k and f\u03b8k = g\u03b8k \u00b7 \u00b7 g\u03b8k a product distribution composed of m g\u03b8k distributions. Then\u03c72 (g\u03b81 | g\u03b80) = (\u03b81 \u2212 \u03b80) 2 \u03b80 (1 \u2212 \u03b80) \u2264 e (\u03b81 \u2212 \u03b80) 2 \u03b80 (1 \u2212 \u03b80) \u2212 1and\u03c72 (f\u03b81 | f\u03b80) = (1 + \u03c72 (g\u03b81 | g\u03b80)) m \u2212 1 \u2264 em (\u03b81 \u2212 \u03b80) 2 success0 (1 \u2212 \u03b80) \u2212 1.Furthermore e m (\u03b81 \u2212 \u03b80) 2 \u03b80 (1 \u2212 success0) \u2212 1 \u2264 m (success1 \u2212 success0) 2\u03b80 (1 \u2212 \u04450) 2 \u04450."}, {"heading": "A.4 Proof of Theorem 3", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "A.5 Proof of Corollary 2", "text": "One binomial x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "B Proofs of Upper Bounds", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Proof of Theorem 4", "text": "The proof: Let us define the minimum of n = 0 and the first i \u2212 n = 1 in such a way that p = 1 = n = n = n = n = n = n = 0. Declare the distribution N as heavy. The total number of revolutions of this method yields mN. Define the event set 1 = n = n = n \u2212 i = 1, namely i = 1 {| p = 1 | < p = 1 \u2212 2}. Note that P (... c1) = P (... 1 = 0) n = (1 \u2212 xi \u2212 n) n = 1, p (\u2212 n) n = 1, p (\u2212 n) n = n \u00b2 / 2. And by a compound boundary and Chernoff's inequality P (... c2), p (... c2)."}, {"heading": "B.2 Proof of Theorem 5", "text": "Firstly, we demonstrate several technical lmmas that are necessary to analyze our algorithm: p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p"}, {"heading": "B.3 Proof of Theorem 6", "text": "Proof. On each level k becomes algorithm 2 as k = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D = D"}, {"heading": "B.4 Proof of Theorem 7", "text": "The proof for this result is almost identical to that of theorem 6 except for the following modifications. Let K be the random stage in which algorithm 4 outputs a distribution, and let k-N be the smallest k-N that fulfills 2 \u2212 k \u2264 \u03b1. If Mk is the number of measurements at stage k, then the expected number of measurements is limited by Wood's identity by E [K-k = 1Mk] = \u00b2 k-k-k. If Mk is the number of measurements at stage k (2k) + c-p-log (2k) + c-log (2k2\u043c) 2 \u2212 k2 max {1, (54) (15) k-k-k \u00b2 \u2264 k-log (2k2-p \u00b2)."}, {"heading": "B.5 Proof of Theorem 8", "text": "The proof is divided into a few steps, which are summarized as follows: For each given procedure, 1 (1 / 2) simply becomes O (1 / 2) + 1 (1 / 2) samples in expectation and the procedure results in an error (i.e. a heavy distribution is returned) with a probability of less than 1 (2). Let us define this result to show that if we are given an upper limit, 0 (2) returns a high distribution with a probability of at least 4 / 5, a heavy distribution is returned after the same expectation of the samples. We will use this result to show that if we have such an upper limit 0 (1), that 2 (2) uses a high distribution with a probability of at least 4 / 5 using only O (log2)."}, {"heading": "C Gaussians", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 On the detection of a mixture of Gaussians", "text": "For known \u03c32, consider the hypotheses test of problem 1. Note that for the two distributions of problem 1: 2 (\u03b81 \u2212 \u03b80) and KL (\u03b81, \u03b80) 2\u03c3 \u2264 1: 1, the following divergences exist: \u03c72 (\u03b81 \u2212 \u03b80) = e (\u03b81 \u2212 \u03b80) 2\u03c32 \u2212 1 \u2264 2 (\u03b81 \u2212 success0) 2\u03c32 = 4KL (\u03b81, \u03b80) According to Theorem 2, for (\u03b81 \u2212 success0) 2\u03c32 \u2264 1, a method with a maximum probability of error smaller than is required, at least max."}, {"heading": "C.2 Lower bounds", "text": "Administrative 11: Phenomenal 11: Administrative 11: Phenomenal 11: 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Phenomenal 11: 11 Administrative 11: 11: 11 Phenomenal 11: 11 Administrative 11: 11 Administrative 11: 11 Phenomenal 11: 11 Administrative 11: 11 Administrative 11: 11: 11 Phenomenal 11: 11 Administrative 11: 11 Administrative 11: 11: 11 Administrative 11: 11: 11 Phenomenal 11: 11: Administrative 11: Administrative 11: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 9: Phenomenal 11: Phenomenal 11: Phenomenal 11: Phenomenal 11: Phenomenal 11: Phenomenal 11: Ph"}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "This paper studies the trade-off between two different kinds of pure exploration: breadth versus depth. The most biased coin problem asks how many total coin flips are required to identify a \u201cheavy\u201d coin from an infinite bag containing both \u201cheavy\u201d coins with mean \u03b81 \u2208 (0, 1), and \u201clight\u201d coins with mean \u03b80 \u2208 (0, \u03b81), where heavy coins are drawn from the bag with probability \u03b1 \u2208 (0, 1/2). The key difficulty of this problem lies in distinguishing whether the two kinds of coins have very similar means, or whether heavy coins are just extremely rare. This problem has applications in crowdsourcing, anomaly detection, and radio spectrum search. Chandrasekaran and Karp (2014) recently introduced a solution to this problem but it required perfect knowledge of \u03b80, \u03b81, \u03b1. In contrast, we derive algorithms that are adaptive to partial or absent knowledge of the problem parameters. Moreover, our techniques generalize beyond coins to more general instances of infinitely many armed bandit problems. We also prove lower bounds that show our algorithm\u2019s upper bounds are tight up to log factors, and on the way characterize the sample complexity of differentiating between a single parametric distribution and a mixture of two such distributions. As a result, these bounds have surprising implications both for solutions to the most biased coin problem and for anomaly detection when only partial information about the parameters is known.", "creator": "LaTeX with hyperref package"}}}