{"id": "1603.08253", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Mar-2016", "title": "Negative Learning Rates and P-Learning", "abstract": "We present a method of training a differentiable function approximator for a regression task using negative examples. We effect this training using negative learning rates. We also show how this method can be used to perform direct policy learning in a reinforcement learning setting.", "histories": [["v1", "Sun, 27 Mar 2016 20:02:13 GMT  (96kb,D)", "https://arxiv.org/abs/1603.08253v1", null], ["v2", "Tue, 29 Mar 2016 11:10:33 GMT  (96kb,D)", "http://arxiv.org/abs/1603.08253v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["devon merrill"], "accepted": false, "id": "1603.08253"}, "pdf": {"name": "1603.08253.pdf", "metadata": {"source": "CRF", "title": "Negative Learning Rates and P-Learning", "authors": ["Devon J. Merrill"], "emails": [], "sections": [{"heading": null, "text": "Using negative examples, we present a method for training a differentiated functional approximation factor for a regression task. We conduct this training on the basis of negative learning rates and show how this method can be used to perform direct policy learning in a learning environment for strengthening."}, {"heading": "1 Regression and Learning Rates", "text": "The goal of regression analysis is to find an approximate regression function, a function that automatically models the relationship between the independent variables (the inputs) and the dependent variables (the outputs). If there is a complex relationship between these variables, no exact regression function is sought. Instead, an approximate regression function is used to model the relationship. Function approximators have proven to be a solid method for finding approximate regression functions. Function approximators are usually trained using sample input-output pairs from the function to be approximated. Given the input from the pair, the output of the function approximator is compared with the actual output from the example. The function approximator is then modified - possibly by gradient decentration - so that its output matches the output from the output-output output function that is to be approximated from the one."}, {"heading": "2 Learning Rates as a Learning Channel", "text": "In regression, the learning rate does not contain information about what the approximate zi = zi should output for any given function. However, there are many situations where we do not have access to good input-output pairs. Therefore, the learning rate is always positive; a positive learning rate means that the approximate should come closer to this example. However, there are many situations where we do not have access to good input-output pairs. The pairs we have access to may not come from the actual function we are trying to model, but from any other function. However, the pairs we have may have access to a measurement in which the output we have corresponds to hypothetical output-output pairs, with some input-output pairs e = (x, z) where x is an input vector and z is an output vector. We would like our function approximator nx to give us the correct output of our target function nx (n)."}, {"heading": "2.1 Intuition", "text": "When we form a model, we usually assume that all examples are taken from the target distribution, so we can use a learning rate of \u00b5 \u00d7 1 per example to make the model fully match those examples. Instead, if we know that the i-training examples (xi, zi) do not deviate from the target function and instead are a certain distance from the desired output dist * (xi, zi), we do not want the model to exactly match those examples. We want each example to be partially correlated by an amount that is dist * (xi, zi). If the distance to the desired output dist * (xi, zi) = 0, then we want it to match completely; the example comes from the target distribution. If the distance to the desired output dist * (xi, zi) > 0, then the amount that we want to correlate with the example decreases. Here, we get the \u2212 dist * (xi, zi) part of the formula. Also, we assume that we have the global learning rate set to an amount that we do not want."}, {"heading": "3 Negative Learning Rates", "text": "The network shown in Figure 2 seems to be trying to adapt the target function, but it is still quite bad. This is because we have set the learning rates of the worst examples to close to 0. Therefore, we do not learn from the worst examples. To maintain our negative learning rates, we must use all the given examples, not just the best ones. We can do this by using negative learning rates. Negative learning rates are a little unusual, so we will try to give them a good treatment method. To maintain our negative learning rates, we cannot limit them to the range [0, 1] but to the range [\u2212 1]. The per example learning rates for the n examples are becomeri = \u2212 dist. (xi, zi) \u2212 zjn maxi."}, {"heading": "4.1 How to Use P-Learning as Reinforcement Learning", "text": "The reinforcement paradigm is that the agent does not affect the state of the environment. It can then take action and receive rewards. The agent's goal is to maximize the total discounted future rewards."}, {"heading": "5 Conclusion", "text": "In this paper we have shown how to use negative examples to train functional approximations in regression tasks. We have also shown how to use negative learning rates to influence this training. We have also introduced a method of reinforcement learning, p-learning, which directly learns a good policy without either learning an environmental model or conducting a policy assessment."}, {"heading": "Acknowledgments", "text": "Thanks for reading:)"}], "references": [{"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "D. . . Hassabis"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Mastering the game of Go with deep neural networks and tree", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre", "G.V. Driessche", "D. . . Hassabis"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "This will give use a per example learning rate that decreases with distance to the target value and normalize to the range [0, 1].", "startOffset": 123, "endOffset": 129}, {"referenceID": 0, "context": "To get our negative learning rates we can constrain not to the range [0, 1] but to the range [\u22121, 1].", "startOffset": 69, "endOffset": 75}, {"referenceID": 1, "context": "[2] Another approach finds the function Q(s, a) where s is the current state and a is an action.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1] Our method has several features that distinguish it from other reinforcement learning methods.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "The agent\u2019s goal at time t0 is to maximize the total discounted future rewards \u2211 t \u03b3 0rt with some discount factor \u03b3 \u2208 [0, 1].", "startOffset": 119, "endOffset": 125}], "year": 2016, "abstractText": "We present a method of training a differentiable function approximator for a regression task using negative examples. We effect this training using negative learning rates. We also show how this method can be used to perform direct policy learning in a reinforcement learning setting. 1 Regression and Learning Rates The goal of regression analyses is to find a regression function, a function that models the relationship between the independent variables (the inputs) and the dependent variables (the outputs). When a complex relationship between these variables, an exact regression function is not sought. Instead an approximate regression function is used to model the relationship. Function approximators have been shown to be a sound method for finding approximate regression functions. Function approximates are generally trained using example input-output pairs from the function that is to be approximated. Given the input from the pair, the output of the function approximator is compared to the actual output from the example. The function approximator is then modified \u2013possibly through gradient descent\u2013 so that its output matches the output in the example. This is one training step. The function approximator is not usually modified so vigorously that the output matches the example output perfectly for each training. Extreme modification of the approximator tends to result in the loss or forgetting of the previous examples, that is, the previous training is overwritten by too strong of an update. Also, updates that are too vigorous tend to negatively affect the approximator\u2019s ability to generalize to unseen examples. Another issue occures when a function approximator is updated, the parameters of the model, it are changed. If these parameters are changed too quickly, they can overrun a computer\u2019s ability to represent these numbers. This is sometimes known as model explosion and it prevents the use of the function approximator. To solve these and other problems, the updates to a function approximator are attenuated by a fractional amount, conceptualized as the learning rate. This allows the approximator to be pushed in the desired direction by a small, tunable amount. All approximators trained by gradient descent use a learning rate. Numerous methods have been developed to automatically compute learning rates. Many use the second derivative of the parameter change (where the first derivative is the raw magnitude and direction of the update. This basic method is used from the familiar Newton\u2019s Method, to esoteric concave optimization methods. Other methods use previous update amounts to tune the learning rate. However, the most common method for setting a learning rate is to start with 0.1 and hope for the best. 1 ar X iv :1 60 3. 08 25 3v 2 [ cs .A I] 2 9 M ar 2 01 6 2 Learning Rates as a Learning Channel In regression, the learning rate does not contain information about what the approximator should output for any given input. This information is contained in the input-output example pairs. This is why the learning rate is always positive; a positive learning rate means that the approximator should match this example more closely. Still, there are many situations where we do not have access to good input-output pairs. The pairs we have access to might not be from the actual function we are trying to model, but from any other function. The pairs we have might be totally random. However, we might have access to a measure of how closely the output we have matches up with hypothetical output, given some input, from the function we are trying to approximate. For example, take input-output pair e = (x, z) where x is some input vector and z is an output vector. We would like our function approximator nn(x) to give us the correct output from our target function nn\u2217(x) = y, but we do not have access to any example nn\u2217(x) = y for any x. However, if we have a distance to desired output function function dist\u2217(x, z) \u2192 R that gives a similarity measure between z and nn\u2217(x) = y, we can still train nn(\u00b7) We would like to use dist\u2217(\u00b7, \u00b7) as a training signal to train n. Learning rate is useful as a channel for this distance to desired output function training signal. To use the learning rate as a learning channel we can take each example in the training set and use it to assign a custom learning rate for each example. We should still have a global learning rate \u03bc. Now, when we train on example i, the learning rate ri for example ei is \u03bc\u00d7 dist(xi, zi). Now we train a simple 2-layer artificial neural network to reproduce the sine function on the interval [\u22125, 5] with 40 example points. The network uses tanh activation function for the 128 hidden units. Each example is of the form ei = (xi, zi, ri) where xi = \u22125 + i \u00d7 0.25 and zi is drawn from a uniform distribution on the interval [\u22121, 1]. The value ri is the learning rate factor for example i calculated by the distance to desired output function dist(xi) = ri = |sin(xi)\u2212 zi|. Let\u2019s see how this works in figure 1. Figure 1: Output of network trained with per example learning rates ri = dist(xi, zi).", "creator": "LaTeX with hyperref package"}}}