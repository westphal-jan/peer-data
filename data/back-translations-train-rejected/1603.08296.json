{"id": "1603.08296", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2016", "title": "The SVM Classifier Based on the Modified Particle Swarm Optimization", "abstract": "The problem of development of the SVM classifier based on the modified particle swarm optimization has been considered. This algorithm carries out the simultaneous search of the kernel function type, values of the kernel function parameters and value of the regularization parameter for the SVM classifier. Such SVM classifier provides the high quality of data classification. The idea of particles' {\\guillemotleft}regeneration{\\guillemotright} is put on the basis of the modified particle swarm optimization algorithm. At the realization of this idea, some particles change their kernel function type to the one which corresponds to the particle with the best value of the classification accuracy. The offered particle swarm optimization algorithm allows reducing the time expenditures for development of the SVM classifier. The results of experimental studies confirm the efficiency of this algorithm.", "histories": [["v1", "Mon, 21 Mar 2016 20:12:44 GMT  (623kb)", "http://arxiv.org/abs/1603.08296v1", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["l demidova", "e nikulchev", "yu sokolova"], "accepted": false, "id": "1603.08296"}, "pdf": {"name": "1603.08296.pdf", "metadata": {"source": "META", "title": "The SVM Classifier Based on the Modified Particle Swarm Optimization", "authors": ["Liliya Demidova", "Evgeny Nikulchev", "Yulia Sokolova"], "emails": [], "sections": [{"heading": null, "text": "This year, it has come to the point where it will be able to put itself at the top, \"he said in an interview with the\" Welt am Sonntag. \""}], "references": [{"title": "Choosing Multiple Parameters for Support Vector Machine", "author": ["O. Chapelle", "V. Vapnik", "O. Bousquet", "S. Mukherjee"], "venue": "Machine Learning, vol. 46, no. 1\u20133, pp. 131\u2013159, 2002.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Bio-Inspired Credit Risk Analysis", "author": ["L. Yu", "S. Wang", "K.K. Lai", "L. Zhou"], "venue": "Computational Intelligence with Support Vector Machines. Springer-Verlag,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Performance Evaluation of SVM and K- Nearest Neighbor Algorithm over Medical Data set", "author": ["J.S. Raikwal", "K. Saxena"], "venue": "International Journal of Computer Applications, vol. 50, no. 14, pp. 35\u201339, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning Algorithms for Classification: A Comparison on Handwritten Digit Recognition", "author": ["Y. LeCun", "L.D. Jackel", "L. Bottou", "C. Cortes at al."], "venue": "Neural Networks: The Statistical Mechanics Perspective, J. H. Oh, C. Kwon and S. Cho, Eds. World Scientific, 1995, pp. 261\u2013276.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features", "author": ["T. Joachims"], "venue": "Lecture Notes in Computer Science, vol. 1398, pp. 137\u2013142, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "SVM Based Learning System For Information Extraction", "author": ["Y. Li", "K. Bontcheva", "H. Cunningham"], "venue": "Lecture Notes in Computer Science, vol. 3635, pp. 319\u2013339, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Pedestrian Detection Using Wavelet Templates", "author": ["M. Oren", "C. Papageorgious", "P. Sinha", "E. Osuna", "T. Poggio"], "venue": "1997 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 1997, pp. 193\u2013199.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "Training Support Vector Machines: An Application to Face Detection", "author": ["E. Osuna", "R. Freund", "F. Girosi"], "venue": "1997 IEEE Computer Society Conf. on Computer Vision and Pattern Recognition, 1997, pp. 130\u2013136.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Fast Training of Support Vector Machines Using Sequential Minimal Optimization", "author": ["J.C. Platt"], "venue": "Advances in Kernel Methods. Support Vector Learning, 1998, pp. 185\u2013208.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "Improvements to the SMO Algorithm for SVM Regression", "author": ["S.K. Shevade", "S.S. Keerthi", "C. Bhattacharyya", "K.R.K. Murthy"], "venue": "IEEE Trans. on Neural Networks, vol. 11, no. 5, pp. 1188\u20131193, 2000.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Improved Training Algorithm for Support Vector Machines", "author": ["E. Osuna", "R. Freund", "F. Girosi"], "venue": "1997 IEEE Workshop Neural Networks for Signal Processing, 1997, pp. 24\u201326. (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 7, No. 2, 2016 24 | P a g e www.ijacsa.thesai.org", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1997}, {"title": "SSVM: a simple SVM algorithm", "author": ["S.V.N. Vishwanathan", "A. Smola", "N. Murty"], "venue": "Proceedings of the 2002 International Joint Conference on Neural Networks, vol. 3, pp. 2393-2398, 2002.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "Pegasos: Primal Estimated sub-Gradient Solver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical Programming, vol. 127, no. 1, pp. 3\u201330, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Messy genetic algorithms: Motivation, analysis, and first results", "author": ["D.E. Goldberg", "B. Korb", "K. Deb"], "venue": "Complex Systems, vol. 3, no. 5, pp. 493\u2013530, 1989.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1989}, {"title": "Genetic algorithms and support vector machines for time series classification", "author": ["D.R. Eads", "D. Hill", "S. Davis", "S.J. Perkins", "J. Ma at al."], "venue": "Proc. SPIE 4787 Applications and Science of Neural Networks, Fuzzy Systems, and Evolutionary Computation, vol. 74, 2002, p. 74.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "Genetic algorithms for support vector machine model selection", "author": ["S. Lessmann", "R. Stahlbock", "S.F. Crone"], "venue": "2006 International Joint Conference on Neural Networks, 2006, pp. 3063\u20133069.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Artificial Bee Colony (ABC) Optimization Algorithm for Solving Constrained Optimization Problems", "author": ["D. Karaboga", "B. Basturk"], "venue": "Proc. of the 12th Intern. Fuzzy Systems Association world congress on Foundations of Fuzzy Logic and Soft Computing, 2007, pp. 789\u2013798.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Particle Swarm Optimisation: Classical and Quantum Perspectives", "author": ["J. Sun", "C.-H. Lai", "X.-J. Wu"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Particle swarm optimization", "author": ["R. Poli", "J. Kennedy", "T. Blackwell"], "venue": "Swarm Intelligence, vol. 1, no. 1, pp. 33\u201357, 2007.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Modification Of Particle Swarm Algorithm For The Problem Of The SVM Classifier Development", "author": ["L. Demidova", "Yu. Sokolova"], "venue": "2015 International Conference \"Stability and Control Processes\" (SCP), 2015, pp. 623\u2013627.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Use of Fuzzy Clustering Algorithms\u2019 Ensemble for SVM classifier Development", "author": ["L. Demidova", "Yu. Sokolova", "E. Nikulchev"], "venue": "International Review on Modelling and Simulations, vol. 8, no. 4, pp. 446\u2013457, 2015.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "SVM-Classifier Development With Use Of Fuzzy Clustering Algorithms' Ensemble On The Base Of Clusters' Tags' Vectors' Similarity Matrixes", "author": ["L. Demidova", "Yu. Sokolova"], "venue": "16th International Symposium on Advanced Intelligent Systems, 2015, pp. 889\u2013906.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Training Set Forming For SVM Algorithm With Use Of The Fuzzy Clustering Algorithms Ensemble On Base Of Cluster Tags Vectors Similarity Matrices", "author": ["L. Demidova", "Yu. Sokolova"], "venue": "2015 International Conference Stability and Control Processes (SCP), pp. 619\u2013622, 2015.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Support vector machines in R", "author": ["A. Karatzoglou", "D. Meyer", "K. Hornik"], "venue": "Research Report, WU Vienna,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "This algorithm includes in the group of boundary classification algorithms [1], [2].", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 84, "endOffset": 87}, {"referenceID": 2, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 109, "endOffset": 112}, {"referenceID": 3, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 148, "endOffset": 151}, {"referenceID": 4, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 173, "endOffset": 176}, {"referenceID": 5, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 201, "endOffset": 204}, {"referenceID": 6, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 227, "endOffset": 230}, {"referenceID": 7, "context": "The SVM classifiers by the SVM algorithm have been applied for credit risk analysis [3], medical diagnostics [4], handwritten character recognition [5], text categorization [6], information extraction [7], pedestrian detection [8], face detection [9], etc.", "startOffset": 247, "endOffset": 250}, {"referenceID": 0, "context": "Training of the SVM classifier assumes solving a quadratic optimization problem [1]\u2013[3].", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "Training of the SVM classifier assumes solving a quadratic optimization problem [1]\u2013[3].", "startOffset": 84, "endOffset": 87}, {"referenceID": 8, "context": "Nowdays methods like SMO [10, 11], chunking [12] and simple SVM [13], Pegasos [14] exist that iteratively compute the required solution and have a linear space complexity [15].", "startOffset": 25, "endOffset": 33}, {"referenceID": 9, "context": "Nowdays methods like SMO [10, 11], chunking [12] and simple SVM [13], Pegasos [14] exist that iteratively compute the required solution and have a linear space complexity [15].", "startOffset": 25, "endOffset": 33}, {"referenceID": 10, "context": "Nowdays methods like SMO [10, 11], chunking [12] and simple SVM [13], Pegasos [14] exist that iteratively compute the required solution and have a linear space complexity [15].", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "Nowdays methods like SMO [10, 11], chunking [12] and simple SVM [13], Pegasos [14] exist that iteratively compute the required solution and have a linear space complexity [15].", "startOffset": 64, "endOffset": 68}, {"referenceID": 12, "context": "Nowdays methods like SMO [10, 11], chunking [12] and simple SVM [13], Pegasos [14] exist that iteratively compute the required solution and have a linear space complexity [15].", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "It is necessary to find the kernel function type, values of the kernel function parameters and value of the regularization parameter, which must be set by a user and shouldn't change [1], [2].", "startOffset": 183, "endOffset": 186}, {"referenceID": 1, "context": "can be used [3].", "startOffset": 12, "endOffset": 15}, {"referenceID": 13, "context": "Gradient methods are not suitable for search of the optimum of such objective function, but search algorithms of stochastic optimization, such as the genetic algorithm [16]\u2013 [18], the artificial bee colony algorithm [19], the particle swarm algorithm [20], [21], etc.", "startOffset": 168, "endOffset": 172}, {"referenceID": 15, "context": "Gradient methods are not suitable for search of the optimum of such objective function, but search algorithms of stochastic optimization, such as the genetic algorithm [16]\u2013 [18], the artificial bee colony algorithm [19], the particle swarm algorithm [20], [21], etc.", "startOffset": 174, "endOffset": 178}, {"referenceID": 16, "context": "Gradient methods are not suitable for search of the optimum of such objective function, but search algorithms of stochastic optimization, such as the genetic algorithm [16]\u2013 [18], the artificial bee colony algorithm [19], the particle swarm algorithm [20], [21], etc.", "startOffset": 216, "endOffset": 220}, {"referenceID": 17, "context": "Gradient methods are not suitable for search of the optimum of such objective function, but search algorithms of stochastic optimization, such as the genetic algorithm [16]\u2013 [18], the artificial bee colony algorithm [19], the particle swarm algorithm [20], [21], etc.", "startOffset": 251, "endOffset": 255}, {"referenceID": 18, "context": "Gradient methods are not suitable for search of the optimum of such objective function, but search algorithms of stochastic optimization, such as the genetic algorithm [16]\u2013 [18], the artificial bee colony algorithm [19], the particle swarm algorithm [20], [21], etc.", "startOffset": 257, "endOffset": 261}, {"referenceID": 17, "context": "The particle swarm algorithm (Particle Swarm Optimization, PSO algorithm), which is based on an idea of possibility to solve the optimization problems using modeling of animals\u2019 groups\u2019 behavior is the simplest algorithm of evolutionary programming because for its implementation it is necessary to be able to determine only value of the optimized function [20], [21].", "startOffset": 357, "endOffset": 361}, {"referenceID": 18, "context": "The particle swarm algorithm (Particle Swarm Optimization, PSO algorithm), which is based on an idea of possibility to solve the optimization problems using modeling of animals\u2019 groups\u2019 behavior is the simplest algorithm of evolutionary programming because for its implementation it is necessary to be able to determine only value of the optimized function [20], [21].", "startOffset": 363, "endOffset": 367}, {"referenceID": 19, "context": "Along with the traditional approach to the application of the PSO algorithm a new approach, that implements the simultaneous search for the best type of the kernel function, values of the kernel function parameters and value of the regularization parameter, is offered [22].", "startOffset": 269, "endOffset": 273}, {"referenceID": 0, "context": "A herewith it is assumed that every object i z is mapped to q dimensional vector of numerical values of characteristics ) , , , ( 2 1 q i i i i z z z z \uf04b \uf03d (typically normalized by values from the interval [0, 1]) where l i z is the numeric value of the l -th", "startOffset": 206, "endOffset": 212}, {"referenceID": 19, "context": "characteristic for the i -th object ( s i , 1 \uf03d , q l , 1 \uf03d ) [22]\u2013[25].", "startOffset": 62, "endOffset": 66}, {"referenceID": 22, "context": "characteristic for the i -th object ( s i , 1 \uf03d , q l , 1 \uf03d ) [22]\u2013[25].", "startOffset": 67, "endOffset": 71}, {"referenceID": 19, "context": "The SVM classifier with satisfactory training and testing results can be used to classify new objects [22].", "startOffset": 102, "endOffset": 106}, {"referenceID": 0, "context": "The separating hyperplane for the objects from the training set can be represented by equation 0 , \uf03d \uf02bb z w , where w is a vector-perpendicular to the separating hyperplane; b is a parameter which corresponds to the shortest distance from the origin of coordinates to the hyperplane; , w z is a scalar product of vectors w and z [1\u20133].", "startOffset": 329, "endOffset": 334}, {"referenceID": 1, "context": "The separating hyperplane for the objects from the training set can be represented by equation 0 , \uf03d \uf02bb z w , where w is a vector-perpendicular to the separating hyperplane; b is a parameter which corresponds to the shortest distance from the origin of coordinates to the hyperplane; , w z is a scalar product of vectors w and z [1\u20133].", "startOffset": 329, "endOffset": 334}, {"referenceID": 0, "context": "In the case of linear separability of classes we can choose a hyperplane so that there is no any object from the training set between them, and then maximize the distance between the hyperplanes (width of the strip) 2 , w w \uf03c \uf03e , solving the problem of quadratic optimization [1], [2]:", "startOffset": 276, "endOffset": 279}, {"referenceID": 0, "context": "The problem of the separating hyperplane building can be reformulated as the dual problem of searching a saddle point of the Lagrange function, which reduces to the problem of quadratic programming, containing only dual variables [1], [2]:", "startOffset": 230, "endOffset": 233}, {"referenceID": 0, "context": "A herewith typically one of the following functions is used as the kernel function ) , ( \uf074 \uf06b z zi [1], [3], [26]:", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "A herewith typically one of the following functions is used as the kernel function ) , ( \uf074 \uf06b z zi [1], [3], [26]:", "startOffset": 103, "endOffset": 106}, {"referenceID": 23, "context": "A herewith typically one of the following functions is used as the kernel function ) , ( \uf074 \uf06b z zi [1], [3], [26]:", "startOffset": 108, "endOffset": 112}, {"referenceID": 17, "context": "The coordinates of the i -th particle ( m i , 1 \uf03d ) in the n dimensional search space uniquely determine the value of the objective function ) , , , ( ) ( 2 1 n i i i i x x x f x f \uf04b \uf03d which is a certain solution of the optimization problem [20] \u2013 [22].", "startOffset": 241, "endOffset": 245}, {"referenceID": 19, "context": "The coordinates of the i -th particle ( m i , 1 \uf03d ) in the n dimensional search space uniquely determine the value of the objective function ) , , , ( ) ( 2 1 n i i i i x x x f x f \uf04b \uf03d which is a certain solution of the optimization problem [20] \u2013 [22].", "startOffset": 248, "endOffset": 252}, {"referenceID": 17, "context": "for the i -th particle ( m i , 1 \uf03d ) [20].", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "velocity vector ( n j , 1 \uf03d ) of the i -th particle ( m i , 1 \uf03d ) is made in accordance with formula [20]:", "startOffset": 101, "endOffset": 105}, {"referenceID": 17, "context": "In one of the most known canonical version of the PSO algorithm it is supposed to undertake the normalization of the acceleration coefficients \uf06a\u0302 and \uf06a~ to make the convergence of the algorithm not so much dependent on the choice of their values [20].", "startOffset": 246, "endOffset": 250}, {"referenceID": 17, "context": "When using formula (4) for correction of velocity vector the convergence of the PSO algorithm is guaranteed and there is no need to control the particle velocity explicitly [20].", "startOffset": 173, "endOffset": 177}, {"referenceID": 1, "context": "Quality evaluation of the SVM classifier can be executed with the use of different classification quality indicators [3].", "startOffset": 117, "endOffset": 120}, {"referenceID": 9, "context": "Moreover two testing data sets were used in experimental researches: Test [11] and \u041c\u041e\u0422\u041f12 (the source is http://machinelearning.", "startOffset": 74, "endOffset": 78}], "year": 2016, "abstractText": "The problem of development of the SVM classifier based on the modified particle swarm optimization has been considered. This algorithm carries out the simultaneous search of the kernel function type, values of the kernel function parameters and value of the regularization parameter for the SVM classifier. Such SVM classifier provides the high quality of data classification. The idea of particles' \u00abregeneration\u00bb is put on the basis of the modified particle swarm optimization algorithm. At the realization of this idea, some particles change their kernel function type to the one which corresponds to the particle with the best value of the classification accuracy. The offered particle swarm optimization algorithm allows reducing the time expenditures for development of the SVM classifier. The results of experimental studies confirm the efficiency of this algorithm. Keywords\u2014particle swarm optimization; SVM-classifier; kernel function type; kernel function parameters; regularization parameter; support vectors", "creator": "Microsoft\u00ae Word 2010"}}}