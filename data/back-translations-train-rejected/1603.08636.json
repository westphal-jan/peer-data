{"id": "1603.08636", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2016", "title": "Towards an Automated Requirements-driven Development of Smart Cyber-Physical Systems", "abstract": "The Invariant Refinement Method for Self Adaptation (IRM-SA) is a design method targeting development of smart Cyber-Physical Systems (sCPS). It allows for a systematic translation of the system requirements into the system architecture expressed as an ensemble-based component system (EBCS). However, since the requirements are captured using natural language, there exists the danger of their misinterpretation due to natural language requirements' ambiguity, which could eventually lead to design errors. Thus, automation and validation of the design process is desirable. In this paper, we (i) analyze the translation process of natural language requirements into the IRM-SA model, (ii) identify individual steps that can be automated and/or validated using natural language processing techniques, and (iii) propose suitable methods.", "histories": [["v1", "Tue, 29 Mar 2016 04:34:39 GMT  (258kb,D)", "http://arxiv.org/abs/1603.08636v1", "In Proceedings FESCA 2016,arXiv:1603.08371"]], "COMMENTS": "In Proceedings FESCA 2016,arXiv:1603.08371", "reviews": [], "SUBJECTS": "cs.SE cs.CL", "authors": ["jiri vinarek", "petr hnetynka"], "accepted": false, "id": "1603.08636"}, "pdf": {"name": "1603.08636.pdf", "metadata": {"source": "CRF", "title": "Towards an Automated Requirements-driven Development of Smart Cyber-Physical Systems", "authors": ["Jiri Vinarek", "Petr Hnetynka"], "emails": ["vinarek@d3s.mff.cuni.cz", "hnetynka@d3s.mff.cuni.cz"], "sections": [{"heading": null, "text": "J. Kofron, J. Tumova, B. Buhnova (Hrsg.): Formal Engineering Approaches to Software Components and Architectures (FESCA '16) EPTCS 205, 2016, pp. 59-68, doi: 10.4204 / EPTCS.205.5c \u00a9 J. Vinarek, P. Hnetynka This work is published under the Creative Commons Attribution License.Towards Automated Requirements-driven Development of Smart Cyber-Physical SystemsPosition paperJiri Vinarek Petr Hnetynka Charles University in Prague, Faculty of Mathematics and Physics, Department of Distributed and Dependable Systems, Malostranske namesti 25, Prague, Czech Republicvinarek @ d3s.mff.cuni.cz hnetynka @ d3s.mff.cuni.czThe Invariant Refinement Method for Self Adaptation (EBprober Language) is a design methodology based on Methyncync.3ff.cuniff.cz (HIR.3ff.3ff.cc)."}, {"heading": "1 Introduction", "text": "Look at how the situation has developed in recent years, and how the situation has developed in recent years, how the situation has developed in the individual countries, how the situation has changed in the individual countries, how the situation has developed in the individual countries and how the situation has developed in the individual countries. Look at how the situation has developed in the individual countries, how the situation has developed, how the situation has developed, how the situation has developed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed, how the situation has changed."}, {"heading": "2 IRM-SA explained by example", "text": "In this section, we briefly describe the IRM-SA method and its application using an example (for a detailed description, see IRM-SA Guide).The experiment described in [6] proved that the use of IRM-SA was a significant help in designing and developing EBCS. Participants in this experiment designed an EBCS architecture with fewer errors than those using a different design method.Although the resulting architectures were not completely error-free, especially due to the different understanding of the input requirements provided as text in natural language, there is still room for improvisation. This is even more important since one of the results of the IRM-SA method - the IRM-SA model - can be used not only at design time, but also during the development and maintenance of the developed system. In particular, the IRM-SA model enables traceability between the purpose of each inventor (request) and its realization and thus it is ideal for documentation."}, {"heading": "2.1 IRM-SA method and model", "text": "The IRM-SA design method is an iterative top-down design approach. A designer must perform the following steps in order to build the IRM-SA model from the requirements specification: 1. Find the top-level objectives of the system and specify the top-level invariants (abstract). 2. Find the components of the system (and their fields) by asking \"what knowledge each invariant contains and where this knowledge can be gained?\" 3. Separate each invariant by asking \"Why do I need to satisfy these invariants?\" 4. Separate the concerns of the abstract invariants into sub-invariants that correspond to the (abstract) activities that can be performed in isolation. 5. Compose invariants together by asking \"Why do I need to satisfy these invariants?\" 6. In the case of situation-specific requirements, try first to accurately capture the state of being in one situation or another situation in order to apply them."}, {"heading": "3 Automation of IRM-SA", "text": "In this section, we analyze the IRM-SA method from the perspective of its automation. We identify individual steps that can be automated using natural language processing techniques and suggest appropriate methods, the individual objectives of such automation being: (i) (semi) automatic generation of invariants in the IRM-SA model from the requirements document (making the synchronization and traceability between requirements and the IRM-SA model more robust and accessible), (ii) (semi) automatic validation of the resulting IRM-SA model."}, {"heading": "3.1 Component identification", "text": "Components in EBCS design represent \"intelligent\" units of the system. In our example, there are two types of components - e-car and parking. Both components and their attributes are mentioned several times both in the requirements and in the summary. Based on our experience with deriving the domain model from textual specifications [17], it seems possible to obtain a list of potential components in an automated manner. A similar approach is also applied in [5] where authors retrieve UML class models from test cases. Both names of components and their attributes are almost always presented in the requirement texts as noun sentences that appear in simple sentences as subjects or objects (either directly or indirectly). To analyze a sentence and identify its elements, the Stanford CoreNLP toolkit [11] is an ideal tool. For example, using the Stanford dependency saver on the sentence \"Every car must monitor its level statistically (battery).\""}, {"heading": "3.2 Component disambiguation", "text": "Another problem with the list of candidates for component / attribute names is that they can be ambiguous. Multiple noun phrases can refer to the same component, e.g. in our system specification for e-cars, the words \"e-car\" and \"car\" refer to the same component. On the other hand, such a situation can occur (especially if the specification is prepared by multiple authors and / or evolves over time) and even more, in some cases, the use of different words for the same entity may be intended, e.g. for abbreviations and noun phrases abbreviations (\"place of interest\" and \"POI\" or \"itinerary\" etc.). A distinction between these cases is not always clear and we expect that this word will be an ambiguous decision with respect to the battery level (another battery level requirement \") that can be used automatically at the battery level (\" POI \"or\" plan \"etc.)."}, {"heading": "3.3 Invariant type identification", "text": "When using the IRM-SA method, sentences in the Requirements section of the specification are more likely to be translated directly into invariants of the IRM-SA model. However, the problem is to determine whether the sentence in question refers to the abstract, process, exchange, or assumption variant. It would be helpful if the IRM-SA editor could automatically suggest the invariant font. Adopted invariants should only be included in the situation-specific section of the requirement specification and are therefore easier to localize (see the yellow highlighting in Figure 2 and the yellow invariants in Figure 1). In addition, the individual sentences express a condition that can be detected and extracted. To extract them, the dependency saver can be reused. To support them, information extraction tools such as Ollie4 or OpenIE5 can be used, as they are able to detect the conditions."}, {"heading": "3.4 Knowledge flow recognition", "text": "In fact, most of them will be able to play by the rules."}, {"heading": "3.5 Invariant refinement and composition", "text": "In EBCS, the communication between components is implicit in their knowledge exchange, which is mediated by ensembles. Thus, an ensemble is defined by a condition that determines when components are part of the respective ensemble, and by knowledge that is interchangeable. Let's take again the requirement 1 (d) with the parameter AbstrationV:: Energy, V:: POI, P:: Availability - > V:: Plan.Since the parameters come from different components (V and P), but the calculation can only be performed in a single component, it is clear that the inventory needs to be refined as a composition of several inventors, at least one of which is an exchange invariant (in the implementation, the exchange invariants lead to the ensemble definition)."}, {"heading": "3.6 Model validation", "text": "With the abstraction of invariants described in 3.4, the IRM-SA model can be automatically validated according to the knowledge flow. In particular, the following checks can be performed: \u2022 Configurations with missing input parameters can be detected (i.e. an invariant that creates the respective attribute is not included in the configuration due to a missing dependency relationship) \u2022 Configurations with multiple invariants that write to the same attribute can be detected. \u2022 Detection of unused output parameters or unused attributes can also be performed. All these checks can indicate errors in the model and / or specification and detect them early."}, {"heading": "4 Related work", "text": "As far as we know, there are no attempts to automate requirements processing for EBCS design. Nevertheless, a similar approach is described in [3], in which authors propose an approach called NPL-KAOS, which can automatically obtain a KAOS model from large volumes of literature (KAOS [9] is a goal-oriented requirement method and it was one of the inspirations for the IRM-SA method). Using tools for natural language processing and text mining techniques, they process abstractions of scientific publications. First, they recognize target-oriented keywords and then use the Stanford parser to identify semantic structures. From preserved semantic trees, they extract targets and eventually organize them into taxonomies. Taxonomies are used to define relationships between goals and thus simulate the process of refinement. Similar to our approach, authors attempt to derive a model from textual data that would serve the engineering requirements."}, {"heading": "5 Conclusion", "text": "In the thesis, we have analyzed the design method IRM-SA with regard to its possible automation using methods and tools for processing natural language. We have identified steps that can be automated and outlined. As automated understanding of natural language in general is still a challenge, full automation is difficult (and in many cases impossible) to achieve. Therefore, we aim for a semi-automatic system that guides the human designer, recommends solutions and validates the actions of the designer. At the moment, we plan to implement all identified solutions, integrate them into the existing IRM-SA editor and validate the resulting system based on a real case study. Although the proposed approaches are tailored to IRM-SA (which is currently linked to the DEECo component model), they can be reused in different contexts. The IRM-SA method itself can be applied without modifications to another semblem-based component model (e.g. HelOS approaches proposed in this paper and [7] for the tools proposed in Kena)."}, {"heading": "6 Acknowledgement", "text": "This work was supported partly by project No. LD15051 from the COST CZ (LD) programme of the Ministry of Education, Youth and Sport of the Czech Republic and partly by institutional funding from the Charles University SIA-2016-260331."}], "references": [{"title": "DEECO: An Ensemble-based Component System", "author": ["Tomas Bures", "Ilias Gerostathopoulos", "Petr Hnetynka", "Jaroslav Keznikl", "Michal Kit", "Frantisek Plasil"], "venue": "Proceedings of CBSE", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "The Invariant Refinement Method", "author": ["Tomas Bures", "Ilias Gerostathopoulos", "Petr Hnetynka", "Jaroslav Keznikl", "Michal Kit", "Frantisek Plasil"], "venue": "In: Software Engineering for Collective Autonomic Systems, LNCS 8998,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "NLP-KAOS for Systems Goal Elicitation: Smart Metering System Case Study", "author": ["E. Casagrande", "S. Woldeamlak", "W.L. Woon", "H.H. Zeineldin", "D. Svetinovic"], "venue": "IEEE Transactions on Software Engineering", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A comparison of string distance metrics for name-matching tasks", "author": ["William W. Cohen", "Pradeep Ravikumar", "Stephen E. Fienberg"], "venue": "Proceedings of IIWeb-03,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Formal Specification Level: Towards verificationdriven design based on natural language processing", "author": ["Rolf Drechsler", "Mathias Soeken", "Robert Wille"], "venue": "Proceedings of FDL", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Foundations for Ensemble Modeling \u2014 The Helena Approach. In: Specification, Algebra, and Software, LNCS 8373", "author": ["Rolf Hennicker", "Annabelle Klarl"], "venue": "Springer, pp. 359\u2013381,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Software Engineering for Ensembles", "author": ["Matthias H\u00f6lzl", "Axel Rauschmayer", "Martin Wirsing"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Requirements Engineering: From Craft to Discipline", "author": ["Axel van Lamsweerde"], "venue": "Proceedings of SIGSOFT\u201908/FSE-16,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Applying UML and patterns: an introduction to object-oriented analysis and design and the unified proces, 3rd edition", "author": ["Craig Larman"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "The Stanford CoreNLP Natural Language Processing Toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "WordNet: A Lexical Database for English", "author": ["George A. Miller"], "venue": "Communications of the ACM 38(11),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Taming Heterogeneity and Distribution in sCPS", "author": ["Brice Morin", "Franck Fleurey", "Olivier Barais"], "venue": "Proceedings of SEsCPS", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Architectural Abstractions for Hybrid Programs", "author": ["Ivan Ruchkin", "Bradley Schmerl", "David Garlan"], "venue": "Proceedings of CBSE", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Formal Verification of Annotated Textual Use-Cases", "author": ["Viliam Simko", "David Hauzar", "Petr Hnetynka", "Tomas Bures", "Frantisek Plasil"], "venue": "The Computer Journal 58(7),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "From Textual Use-Cases to Component-Based Applications", "author": ["Viliam Simko", "Petr Hnetynka", "Tomas Bures"], "venue": "SNPD", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Implemented Domain Model Generation", "author": ["Viliam Simko", "Petr Kroha", "Petr Hnetynka"], "venue": "Technical Report D3S-TR-2013-03, Charles University in Prague, Faculty of Mathematics and Physics, Department of Distributed and Dependable Systems", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Recovering Traceability Links Between Code and Specification Through Domain Model Extraction", "author": ["Jiri Vinarek", "Petr Hnetynka", "Viliam Simko", "Petr Kroha"], "venue": "Proceedings of EOMAS", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}], "referenceMentions": [{"referenceID": 6, "context": "The traditional software design and development techniques have been shown unsuitable for such systems and novel approaches [8, 13, 14] have been proposed to tackle with the challenges.", "startOffset": 124, "endOffset": 135}, {"referenceID": 11, "context": "The traditional software design and development techniques have been shown unsuitable for such systems and novel approaches [8, 13, 14] have been proposed to tackle with the challenges.", "startOffset": 124, "endOffset": 135}, {"referenceID": 12, "context": "The traditional software design and development techniques have been shown unsuitable for such systems and novel approaches [8, 13, 14] have been proposed to tackle with the challenges.", "startOffset": 124, "endOffset": 135}, {"referenceID": 0, "context": "One of these promising approaches is Ensemble-Based Component Systems (EBCS) [1].", "startOffset": 77, "endOffset": 80}, {"referenceID": 1, "context": "The Invariant Refinement Method for Self Adaptation (IRM-SA) [2] is a design method targeting development of sCPS using EBCS.", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "Invariants are then hierarchically decomposed and at the lowest level, they directly correspond to an implementation (in the DEECo component model [1], with which IRM-SA is currently tied).", "startOffset": 147, "endOffset": 150}, {"referenceID": 13, "context": "To achieve the goal, we use our experience gained with automated processing of textual use-cases, their verification and transformation into an implementation ([15, 16, 18]).", "startOffset": 160, "endOffset": 172}, {"referenceID": 14, "context": "To achieve the goal, we use our experience gained with automated processing of textual use-cases, their verification and transformation into an implementation ([15, 16, 18]).", "startOffset": 160, "endOffset": 172}, {"referenceID": 16, "context": "To achieve the goal, we use our experience gained with automated processing of textual use-cases, their verification and transformation into an implementation ([15, 16, 18]).", "startOffset": 160, "endOffset": 172}, {"referenceID": 8, "context": "Plus, as stated in [10], it is a mistake to understand requirements specifications as final and unchangeable and thus keeping up-to-date traceability links to requirements is quite important.", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "[2] In order to do that, every car needs to :", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "(a) Continuously monitor its energy level (battery) ;[9]", "startOffset": 53, "endOffset": 56}, {"referenceID": 5, "context": "(b) Continuously monitor its position) ;[7]", "startOffset": 40, "endOffset": 43}, {"referenceID": 6, "context": "(c) Continuously assess whether its energy level would be enough to complete the trip based on the distance left to cover; [8] (d) Have a plan to follow, which is based on its energy level and on the available parking slots in the parking places near the POI .", "startOffset": 123, "endOffset": 126}, {"referenceID": 9, "context": "[11, 14]", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "[11, 14]", "startOffset": 0, "endOffset": 8}, {"referenceID": 8, "context": "[10]", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12, 15]", "startOffset": 0, "endOffset": 8}, {"referenceID": 13, "context": "[12, 15]", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "When an e-car is more than 5km far from the POI [16], it should update its plan at least once per 60 seconds .", "startOffset": 48, "endOffset": 52}, {"referenceID": 12, "context": "[14]", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "When an e-car is equal to or less than 5km far from the POI [13], it should update its plan at least every 10 seconds [11].", "startOffset": 60, "endOffset": 64}, {"referenceID": 9, "context": "When an e-car is equal to or less than 5km far from the POI [13], it should update its plan at least every 10 seconds [11].", "startOffset": 118, "endOffset": 122}, {"referenceID": 15, "context": "Based on our experience with derivation of the domain model from textual specification [17], it seems possible to obtain a list of potential components in an automated fashion.", "startOffset": 87, "endOffset": 91}, {"referenceID": 4, "context": "Also, a similar approach is employed in [5], where authors retrieve UML class models from test cases.", "startOffset": 40, "endOffset": 43}, {"referenceID": 9, "context": "To parse a sentence and identify its elements, the Stanford CoreNLP toolkit [11] is an ideal tool.", "startOffset": 76, "endOffset": 80}, {"referenceID": 16, "context": "Similarly, we have employed these techniques in [18].", "startOffset": 48, "endOffset": 52}, {"referenceID": 3, "context": "Another option for disambiguation might be employment of string distance metrics [4]3 to identify corresponding entities (e.", "startOffset": 81, "endOffset": 84}, {"referenceID": 10, "context": "Instead, a suitable approach is to classify verbs according to their meaning, which is taken from WordNet[12].", "startOffset": 105, "endOffset": 109}, {"referenceID": 1, "context": "One of the key IRM-SA ideas is that each invariant (with the exception of assumption ones) represents a computation that produces output knowledge given a particular input knowledge such that the invariant is satisfied (as stated in [2]).", "startOffset": 233, "endOffset": 236}, {"referenceID": 2, "context": "Nevertheless, a related approach is described in [3], in which authors propose an approach called NPL-KAOS that can automatically obtain a KAOS model from large volume of literature (KAOS [9] is a goal-oriented requirement engineering method and it was one of inspirations for the IRM-SA method).", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "Nevertheless, a related approach is described in [3], in which authors propose an approach called NPL-KAOS that can automatically obtain a KAOS model from large volume of literature (KAOS [9] is a goal-oriented requirement engineering method and it was one of inspirations for the IRM-SA method).", "startOffset": 188, "endOffset": 191}, {"referenceID": 4, "context": "In [5], the authors (semi-)automatically derive a UML model and OCL constraints from a specification and test cases, which are both written in natural language.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": ", Helena [7]) and the approaches proposed in this paper can be applied in tools for the KAOS method or similar ones.", "startOffset": 9, "endOffset": 12}], "year": 2016, "abstractText": "The Invariant Refinement Method for Self Adaptation (IRM-SA) is a design method targeting development of smart Cyber-Physical Systems (sCPS). It allows for a systematic translation of the system requirements into the system architecture expressed as an ensemble-based component system (EBCS). However, since the requirements are captured using natural language, there exists the danger of their misinterpretation due to natural language requirements\u2019 ambiguity, which could eventually lead to design errors. Thus, automation and validation of the design process is desirable. In this paper, we (i) analyze the translation process of natural language requirements into the IRM-SA model, (ii) identify individual steps that can be automated and/or validated using natural language processing techniques, and (iii) propose suitable methods.", "creator": "LaTeX with hyperref package"}}}