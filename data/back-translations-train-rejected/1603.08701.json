{"id": "1603.08701", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2016", "title": "What a Nerd! Beating Students and Vector Cosine in the ESL and TOEFL Datasets", "abstract": "In this paper, we claim that Vector Cosine, which is generally considered one of the most efficient unsupervised measures for identifying word similarity in Vector Space Models, can be outperformed by a completely unsupervised measure that evaluates the extent of the intersection among the most associated contexts of two target words, weighting such intersection according to the rank of the shared contexts in the dependency ranked lists. This claim comes from the hypothesis that similar words do not simply occur in similar contexts, but they share a larger portion of their most relevant contexts compared to other related words. To prove it, we describe and evaluate APSyn, a variant of Average Precision that, independently of the adopted parameters, outperforms the Vector Cosine and the co-occurrence on the ESL and TOEFL test sets. In the best setting, APSyn reaches 0.73 accuracy on the ESL dataset and 0.70 accuracy in the TOEFL dataset, beating therefore the non-English US college applicants (whose average, as reported in the literature, is 64.50%) and several state-of-the-art approaches.", "histories": [["v1", "Tue, 29 Mar 2016 10:00:27 GMT  (1016kb)", "http://arxiv.org/abs/1603.08701v1", "in LREC 2016"]], "COMMENTS": "in LREC 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["enrico santus", "tin-shing chiu", "qin lu", "alessandro lenci", "chu-ren huang"], "accepted": false, "id": "1603.08701"}, "pdf": {"name": "1603.08701.pdf", "metadata": {"source": "CRF", "title": "What a Nerd! Beating Students and Vector Cosine in the ESL and TOEFL Datasets", "authors": ["Enrico Santus", "Tin-Shing Chiu", "Qin Lu", "Alessandro Lenci", "Chu-Ren Huang"], "emails": ["esantus@gmail.com,", "cstschiu@comp.polyu.edu.hk,", "churen.huang}@polyu.edu.hk", "alessandro.lenci@unipi.it"], "sections": [{"heading": null, "text": "This assertion stems from the hypothesis that similar words do not simply occur in similar contexts, but have a larger proportion of their most relevant contexts in common than other related words. To prove this, we describe and rate APSyn, a variant of average precision that - regardless of the parameters used - exceeds the vector cosine and common occurrence in the ESL and TOEFL test sets. In the best setting, APSyn achieves 0.73 accuracy on the ESL dataset and 0.70 accuracy on the TOEFL dataset, beating the non-English college applicants (whose average, as reported in the literature, is 64.50%) and several state-of-DSL models, vector models, VMs keywords: Similar words:"}, {"heading": "1. Introduction", "text": "Word similarity detection plays an important role in Natural Language Processing (NLP), as it is the backbone of several applications, as Paraphrasing, Query Expansion, Word Sense Disambiguation, Automatic Thesauri Creation, and so on (Terra and Clarke, 2003) Several approaches have been proposed to measure word similarity (Terra and Clarke, 2003; Jarmasz and Szpakowicz, 2003; Mikolov et al., 2015; Santus et al. 2016a), some of which rely on knowledge resources (such as lexicons or semantic networks), while other Corpus-based texts generally exploit the distribution hypothesis that words occur in similar contexts (Harris, 1954). Although these approaches extract statistics from large corporations, they define what should be considered context (i.e.e., association, context, synthetics, etc.)."}, {"heading": "2. Background", "text": "Word similarity measures also have a fundamental role in tasks such as Information Retrieval (IR), Text Classification (TC), Text Summarization (TS), Question Answering (QA), Sentiment Analysis (SA), and so on (Terra and Clarke, 2003; Tungthamthiti et al., 2015), which can be either knowledge-based or corpus-based (Gomaa and Fahmy, 2013), the former relying on lexicographs or semantic networks, such as WordNet (Fellbaum, 1998), which measure the distance between nodes in the network. The latter, instead, calculate the similarity between words based on statistical information, in large companies and Hanks, 1990). Knowledge-based approaches, which generally exploit handmade resources, provide high quality."}, {"heading": "2.1 Distance Measures", "text": "Regardless of the approach used to learn word statistics, corpus-based approaches present word meanings as vectors in vector spaces commonly referred to as semantic spaces. In such semantic spaces, the similarity of words can be measured as the proximity between vectors. Several measures have been taken in this area. In the following lines, we briefly describe some of them, while defining the vector cosine, which is generally considered the most efficient. Manhattan distance (L1) can be defined as the sum of the differences of dimensions. Euclidean distance (L2) is the square root of the sum of the square differences of dimensions. Instead, the dice coefficient is twice the number of common dimensions divided by the total number of dimensions in the two vectors."}, {"heading": "2.2 State-of-the-art in the ESL and TOEFL", "text": "After first being used in Landauer and Dumais (1997), the TOEFL dataset became one of the most common benchmarks for testing vector space models: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al. (2005), Dob\u00f3 and Csirik (2013), and Rapp (2003). Bullinaria and Levy (2012) even achieved an accuracy of 100% on this dataset. In their paper, the authors analyze numerous parameters, including the influence of body size, window size, stop lists, ancestry, and individual values (SVD), until they find a perfectly optimized model. Having achieved perfect precision on the TOEFL, the authors acknowledge that these results are impressive for the benchmark, but can hardly be generalized to new tasks."}, {"heading": "3. Method", "text": "Considering a traditional DSM counting method, in which each word is presented as a vector of weighted associations between such words and contexts, we can rethink the distribution hypothesis (Harris, 1954) by assuming that similar words not only occur in similar contexts, but - more accurately - they share a greater number of their most associated contexts, compared to other contexts. This can be done in several steps by measuring the extent of the intersection between the most used contexts words, by the rank of common contexts in the lists contexts."}, {"heading": "4. Evaluation", "text": "In the following sections we describe our DSMs, the test kits and the task."}, {"heading": "4.1 Distributional Semantic Model", "text": "We use several window-based DSMs that record word coincidences within the K nearest substantive words to the left and right of each target, with K having the following values: 2, 3, 5, and 10. Word incidence is extracted from a combination of ukWaC and WaCkypedia corpora (approximately 2.7 billion words) for substantive words - namely adjectives, nouns, and verbs - occurring over 1,000 times, and weighted with PPMI. The model consists of 28,870 word vectors with 28,870 dimensions each."}, {"heading": "4.2 Test Sets", "text": "To evaluate the proposed measure, we use both the ESL (Turney, 2001) and the TOEFL data sets (Landauer and Dumais, 1997), the former consisting of 50 questions, the latter of 80 questions. ESL records were not used in our experiments. An example of the ESL question is the following: \"An underground [corridor] connected the house to the garage.\" a. hallway b. Ticket b. Entrance to the spaceIn both data sets, we answered each question in four pairs, each of which contained the problem word and the possible answer. Unfortunately, we do not have complete coverage of the data sets, as our model for substantive words was built with a frequency of more than 1000, parts-of-speech keywords or adjectives, nouns or verbs. In the ESL test, 4 out of 50 questions were excluded. In the TOEFL test, 20 out of 80 questions were excluded for the same reason."}, {"heading": "4.3 Task", "text": "We assigned APSyn to all pairs and then - for each problem word - sorted the possible choices in descending order. We considered each problem word that had the right answer in the first place to be positive, all others to be negative."}, {"heading": "5. Results", "text": "In Table 1, we report on the results of APSyn and baselines in the ESL test. As can be seen in Table 1 and Figure 1, APSyn always performs better than baselines. Window size and N have some influence on the performance of APSyn. The first parameter also affects baselines (vector cosine seems to perform slightly better in larger windows, while the frequency of incidence seems to favor smaller contexts).Our measurement seems to perform better especially in smaller windows and near 100, while its performance decreases slightly in N near 1000. One possible reason for such a decline could be that when considering too many contexts, some rumors are added, because APSyn is forced to consider less important contexts of the targets with larger values of N. In Table 2, we report on the values of APSyn and baselines in the TOEFL test set evaluation, as these preferences are smaller than the guylin results are actually larger than the guylin results."}, {"heading": "6. Error Analysis", "text": "In this case, it is as if it were a mere red herring."}, {"heading": "8. Conclusions", "text": "In this paper, we described APSyn, a totally uncontrolled measure based on the evaluation of the magnitude and relevance of the intersection between the top rankings distribution characteristics of target words. APSyn was tested on the random questions of ESL and TOEFL, exceeding the vector cosine and the presence of several lexicon-based and hybrid models. In particular, our results are higher than those given in the literature for non-English US college applicants on the TOEFL test (64.50%). Our experiments show that the intersection between the most related contexts of the target words is indeed a reliable index of similarity. In our reviews, we also considered the role of both window size and N. APSyn better on smaller windows and with N3Not unlike Santus et al. (2016a), the LMI-based APSyms have engaged in 6,225 questions."}, {"heading": "9. Acknowledgements", "text": "This work is partially supported by HK PhD Fellowship Scheme under PF12-1365610. Main ReferencesBaroni, M. and Lenci, A. (2011). How we BLESSeddistributional semantic evaluation. Proceedings of the EMNLP 2011 Geometrical Models for Natural Language Semantics (GEMS 2011) Workshop. Edinburg, UK. 1-10. Benotto, Giulia. (2015). Distributional Models forSemantic Relations on Hyponymy and Antonymy International Language Thesis, University of Pisa. Bullinaria, J.A. and Levy, J.P., Giulia. Extractingsemantic representations from word co-occurrence statistics: A computational study. Behavior Research Methods, 39 (3), 510-526. Bullinaria. Bullinaria, J.A. and Levy, J.P. (2012). Extractingsemantic representations from word co-occurrence statistics: A computational study."}], "references": [{"title": "Mining the Web for synonyms: PMI-IR versus LSA on TOEFL", "author": ["P.D. ESL. In: Turney"], "venue": "Proceedings of ECML-2001,", "citeRegEx": "Turney,? \\Q2001\\E", "shortCiteRegEx": "Turney", "year": 2001}, {"title": "EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models", "author": ["E. EVALution. In: Santus", "F. Yung", "A. Lenci", "Huang C-R"], "venue": "Proceedings of the 4th Workshop on Linked Data in Linguistics,", "citeRegEx": "Santus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2015}, {"title": "SimLex-999: Evaluating Semantic Models with (Genuine) Similarity Estimation", "author": ["SimLex-999. In: Hill", "Felix", "Roi Reichart", "Anna Korhonen"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2014}, {"title": "A solution to Plato's problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge", "author": ["T.K. TOEFL. In: Landauer", "S.T. Dumais"], "venue": "Psychological Review,", "citeRegEx": "Landauer and Dumais,? \\Q1997\\E", "shortCiteRegEx": "Landauer and Dumais", "year": 1997}], "referenceMentions": [{"referenceID": 1, "context": "In fact, vectors have as nearest neighbours not only synonyms, but also hypernyms, co-hyponyms, antonyms, as well as a wide range of other semantically related items (Santus et al., 2015).", "startOffset": 166, "endOffset": 187}, {"referenceID": 3, "context": "(TOEFL; Landauer and Dumais, 1997).", "startOffset": 0, "endOffset": 34}, {"referenceID": 0, "context": "Such limitation has often prompted researchers to pursue hybrid approaches (Turney, 2001).", "startOffset": 75, "endOffset": 89}, {"referenceID": 3, "context": "php?title=ESL_Synonym _Questions_(State_of_the_art) (LSA; Landauer and Dumais, 1997).", "startOffset": 52, "endOffset": 84}, {"referenceID": 3, "context": "standard in distributional semantics (Landauer and Dumais, 1997; Jarmasz and Szpakowicz, 2003; Mikolov et al., 2013; Levy et al., 2015).", "startOffset": 37, "endOffset": 135}, {"referenceID": 3, "context": "2 State-of-the-art in the ESL and TOEFL After its first use in Landauer and Dumais (1997), the", "startOffset": 63, "endOffset": 90}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al.", "startOffset": 142, "endOffset": 156}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al.", "startOffset": 142, "endOffset": 171}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al.", "startOffset": 142, "endOffset": 196}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al.", "startOffset": 142, "endOffset": 224}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al. (2005), Dob\u00f3 and Csirik (2013) and Rapp (2003).", "startOffset": 142, "endOffset": 248}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al. (2005), Dob\u00f3 and Csirik (2013) and Rapp (2003).", "startOffset": 142, "endOffset": 272}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al. (2005), Dob\u00f3 and Csirik (2013) and Rapp (2003). Bullinaria and Levy (2012) even achieved 100% accuracy on this dataset.", "startOffset": 142, "endOffset": 288}, {"referenceID": 0, "context": "TOEFL dataset became one of the most common benchmarks for vector space models testing: Karlgren and Sahlgren (2001), Pado and Lapata (2007), Turney (2001), Turney (2008), Terra and Clarke (2003), Bullinaria and Levy (2007), Matveeva et al. (2005), Dob\u00f3 and Csirik (2013) and Rapp (2003). Bullinaria and Levy (2012) even achieved 100% accuracy on this dataset.", "startOffset": 142, "endOffset": 316}, {"referenceID": 0, "context": "Few years after the introduction of TOEFL as a benchmark, Turney (2001) proposed the ESL.", "startOffset": 58, "endOffset": 72}, {"referenceID": 0, "context": "Few years after the introduction of TOEFL as a benchmark, Turney (2001) proposed the ESL. These 50 multiple-choice synonym questions are provided in a sentence context, to facilitate sense disambiguation. ESL has soon become a very popular benchmark on which several models have been evaluated. The best reported corpus-based approaches in this benchmark were those of Turney (2001), Terra and Clarke (2003) and Jarmasz and Szpakowicz (2003).", "startOffset": 58, "endOffset": 383}, {"referenceID": 0, "context": "Few years after the introduction of TOEFL as a benchmark, Turney (2001) proposed the ESL. These 50 multiple-choice synonym questions are provided in a sentence context, to facilitate sense disambiguation. ESL has soon become a very popular benchmark on which several models have been evaluated. The best reported corpus-based approaches in this benchmark were those of Turney (2001), Terra and Clarke (2003) and Jarmasz and Szpakowicz (2003).", "startOffset": 58, "endOffset": 408}, {"referenceID": 0, "context": "Few years after the introduction of TOEFL as a benchmark, Turney (2001) proposed the ESL. These 50 multiple-choice synonym questions are provided in a sentence context, to facilitate sense disambiguation. ESL has soon become a very popular benchmark on which several models have been evaluated. The best reported corpus-based approaches in this benchmark were those of Turney (2001), Terra and Clarke (2003) and Jarmasz and Szpakowicz (2003). The latter achieving the best result of 82% accuracy.", "startOffset": 58, "endOffset": 442}, {"referenceID": 1, "context": "In previous experiments, published in Santus et al. (2016a), we used Local Mutual Information (LMI; Evert,", "startOffset": 38, "endOffset": 60}, {"referenceID": 0, "context": "2 Test Sets In order to evaluate the proposed measure, we use both the ESL (Turney, 2001) and TOEFL (Landauer and Dumais, 1997) datasets.", "startOffset": 75, "endOffset": 89}, {"referenceID": 3, "context": "2 Test Sets In order to evaluate the proposed measure, we use both the ESL (Turney, 2001) and TOEFL (Landauer and Dumais, 1997) datasets.", "startOffset": 100, "endOffset": 127}, {"referenceID": 1, "context": "APSyn was introduced in Santus et al. (2016a) and tested on the ESL.", "startOffset": 24, "endOffset": 46}, {"referenceID": 1, "context": "3 Not differently from Santus et al. (2016a), the LMI-based APSyn guessed 26.", "startOffset": 23, "endOffset": 45}, {"referenceID": 1, "context": "3 Not differently from Santus et al. (2016a), the LMI-based APSyn guessed 26.25 questions (24 full and 3 partial), but being the recall higher in the current DSM, this number has been divided by 46. 4 Not differently from Santus et al. (2016a), the LMI-based APSyn guessed 24.", "startOffset": 23, "endOffset": 244}, {"referenceID": 2, "context": "Moreover, since ESL and TOEFL are small test sets, APSyn performance should be further explored on larger datasets, such as the Lenci/Benotto (Benotto, 2015), SimLex-999 (Hill et al., 2014) and EVALuation (Santus et al.", "startOffset": 170, "endOffset": 189}], "year": 2016, "abstractText": "In this paper, we claim that Vector Cosine \u2013 which is generally considered one of the most efficient unsupervised measures for identifying word similarity in Vector Space Models \u2013 can be outperformed by a completely unsupervised measure that evaluates the extent of the intersection among the most associated contexts of two target words, weighting such intersection according to the rank of the shared contexts in the dependency ranked lists. This claim comes from the hypothesis that similar words do not simply occur in similar contexts, but they share a larger portion of their most relevant contexts compared to other related words. To prove it, we describe and evaluate APSyn, a variant of Average Precision that \u2013 independently of the adopted parameters \u2013 outperforms the Vector Cosine and the co-occurrence on the ESL and TOEFL test sets. In the best setting, APSyn reaches 0.73 accuracy on the ESL dataset and 0.70 accuracy in the TOEFL dataset, beating therefore the non-English US college applicants (whose average, as reported in the literature, is 64.50%) and several state-of-the-art approaches.", "creator": "Microsoft\u00ae Word 2010"}}}