{"id": "1603.08868", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2016", "title": "A Readable Read: Automatic Assessment of Language Learning Materials based on Linguistic Complexity", "abstract": "Corpora and web texts can become a rich language learning resource if we have a means of assessing whether they are linguistically appropriate for learners at a given proficiency level. In this paper, we aim at addressing this issue by presenting the first approach for predicting linguistic complexity for Swedish second language learning material on a 5-point scale. After showing that the traditional Swedish readability measure, L\\\"asbarhetsindex (LIX), is not suitable for this task, we propose a supervised machine learning model, based on a range of linguistic features, that can reliably classify texts according to their difficulty level. Our model obtained an accuracy of 81.3% and an F-score of 0.8, which is comparable to the state of the art in English and is considerably higher than previously reported results for other languages. We further studied the utility of our features with single sentences instead of full texts since sentences are a common linguistic unit in language learning exercises. We trained a separate model on sentence-level data with five classes, which yielded 63.4% accuracy. Although this is lower than the document level performance, we achieved an adjacent accuracy of 92%. Furthermore, we found that using a combination of different features, compared to using lexical features alone, resulted in 7% improvement in classification accuracy at the sentence level, whereas at the document level, lexical features were more dominant. Our models are intended for use in a freely accessible web-based language learning platform for the automatic generation of exercises.", "histories": [["v1", "Tue, 29 Mar 2016 18:12:28 GMT  (30kb,D)", "http://arxiv.org/abs/1603.08868v1", "Presented at CICLING 2015 and won the best poster award (16th International Conference on Intelligent Text Processing and Computational Linguistics). To appear in International Journal of Computational Linguistics and Applications (IJLCA), 2016"]], "COMMENTS": "Presented at CICLING 2015 and won the best poster award (16th International Conference on Intelligent Text Processing and Computational Linguistics). To appear in International Journal of Computational Linguistics and Applications (IJLCA), 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ildik\\'o pil\\'an", "sowmya vajjala", "elena volodina"], "accepted": false, "id": "1603.08868"}, "pdf": {"name": "1603.08868.pdf", "metadata": {"source": "CRF", "title": "A Readable Read: Automatic Assessment of Language Learning Materials based on Linguistic Complexity", "authors": ["Ildik\u00f3 Pil\u00e1n", "Sowmya Vajjala", "Elena Volodina"], "emails": ["ildiko.pilan@svenska.gu.se", "elena.volodina@svenska.gu.se", "sowmya@sfs.uni-tuebingen.de"], "sections": [{"heading": null, "text": "Keywords: machine learning, readability, language acquisition"}, {"heading": "1 Introduction", "text": "In fact, we are able to go in search of a solution that meets the needs of the individual."}, {"heading": "2 Datasets", "text": "Our data set is a subset of the COCTAILL corpus, a corpus of textbooks covering five CEFR levels (A1-C1) [20]. This corpus consists of twelve books (from four different publishers), the usability and level of which has been confirmed by Swedish L2 teachers. Textbooks have been commented on both in terms of content (e.g. exercises, lists) and linguistically (e.g. with POS and dependency labels) [20]. We have collected a total of 867 texts (reading passages) from this corpus. We have excluded texts based primarily on dialogues from the current experiments, due to their specific linguistic structure, with the aim of scaling down differences associated with text genres rather than linguistic complexity. We plan to study the readability of dialogues and compare them with non-dialogical texts in the future."}, {"heading": "3 Features", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "4 Experiments and Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Setup", "text": "We investigated various classification algorithms for this task using the WEKA machine learning tool [25], including: (1) a multinomial logistic regression model with comb estimator, (2) a multi-layer perceptron, (3) a support vector machine learner, sequential minimal optimization (SMO), and (4) a decision tree (J48). For each of these settings, the default parameter settings were applied as implemented in WEKA. We considered classification accuracy, F-Score, and Root Mean Squared Error (RMSE) as evaluation benchmarks for our approach. We also took into account a confusion matrix, as we are dealing with a data set that is unbalanced across CEFR levels. Results were obtained through a tenfold cross-validation (CV)."}, {"heading": "4.2 Document-Level Experiments", "text": "We had two fundamentals: a majority classic (majority), a majority classic (majority class) and an LSD score (LSD) of 91.6% of the ingredients as a B2 score. Length-based, semantic and syntactical features in isolation showed similar or only slightly better performance than the fundamentals, so we excluded them from the table. LSD-Score-Score-Score-Score-Score-Scale-Scale-Score-Score-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Scale-Sc"}, {"heading": "4.3 Sentence-Level Experiments", "text": "In this context, it should be noted that this is a very complex situation, a very complex, complex and complex issue."}, {"heading": "5 Conclusion and Future Work", "text": "Our document level model, the first for L2 Swedish, achieved an F score of 0.8, which allows us to reliably differentiate between skill levels. Compared to the widely used measure of readability in Swedish, LIX, we achieved a significant gain in both accuracy and F score (46% and 0.6 higher, respectively).The accuracy of the sentence level model remained lower than that of the text model, however, using the full feature set, the system achieved 23% and 22% above the majority basis or LIX, respectively. Misclassifications of more than one level did not occur in more than 8% of the sentences, so our sentence level model improved over previous results for L2 Swedish readability."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Corpora and web texts can become a rich language learning resource if we have a means of assessing whether they are linguistically appropriate for learners at a given proficiency level. In this paper, we aim at addressing this issue by presenting the first approach for predicting linguistic complexity for Swedish second language learning material on a 5-point scale. After showing that the traditional Swedish readability measure, L\u00e4sbarhetsindex (LIX), is not suitable for this task, we propose a supervised machine learning model, based on a range of linguistic features, that can reliably classify texts according to their difficulty level. Our model obtained an accuracy of 81.3% and an F-score of 0.8, which is comparable to the state of the art in English and is considerably higher than previously reported results for other languages. We further studied the utility of our features with single sentences instead of full texts since sentences are a common linguistic unit in language learning exercises. We trained a separate model on sentence-level data with five classes, which yielded 63.4% accuracy. Although this is lower than the document level performance, we achieved an adjacent accuracy of 92%. Furthermore, we found that using a combination of different features, compared to using lexical features alone, resulted in 7% improvement in classification accuracy at the sentence level, whereas at the document level, lexical features were more dominant. Our models are intended for use in a freely accessible web-based language learning platform for the automatic generation of exercises.", "creator": "TeX"}}}