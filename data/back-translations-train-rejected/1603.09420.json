{"id": "1603.09420", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2016", "title": "Minimal Gated Unit for Recurrent Neural Networks", "abstract": "Recently recurrent neural networks (RNN) has been very successful in handling sequence data. However, understanding RNN and finding the best practices for RNN is a difficult task, partly because there are many competing and complex hidden units (such as LSTM and GRU). We propose a gated unit for RNN, named as Minimal Gated Unit (MGU), since it only contains one gate, which is a minimal design among all gated hidden units. The design of MGU benefits from evaluation results on LSTM and GRU in the literature. Experiments on various sequence data show that MGU has comparable accuracy with GRU, but has a simpler structure, fewer parameters, and faster training. Hence, MGU is suitable in RNN's applications. Its simple architecture also means that it is easier to evaluate and tune, and in principle it is easier to study MGU's properties theoretically and empirically.", "histories": [["v1", "Thu, 31 Mar 2016 00:01:10 GMT  (178kb,D)", "http://arxiv.org/abs/1603.09420v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["guo-bing zhou", "jianxin wu", "chen-lin zhang", "zhi-hua zhou"], "accepted": false, "id": "1603.09420"}, "pdf": {"name": "1603.09420.pdf", "metadata": {"source": "META", "title": "Minimal Gated Unit for Recurrent Neural Networks", "authors": ["Guo-Bing Zhou", "Jianxin Wu", "Chen-Lin Zhang", "Zhi-Hua Zhou"], "emails": ["ZHOUGB@LAMDA.NJU.EDU.CN", "WUJX@NJU.EDU.CN", "U-ZHANGCL@LAMDA.NJU.EDU.CN", "ZHOUZH@NJU.EDU.CN"], "sections": [{"heading": "1. Introduction", "text": "In recent years, we have focused primarily on the handling of data that have complex internal structures."}, {"heading": "2. RNN: LSTM, GRU, and More", "text": "It is about the question to what extent people are able to put themselves in the world in which they live. (...) It is about the question to what extent people are able to live and live in the world. (...) It is about the question to what extent people in the world are able to live in the world. (...) It is about the question to what extent people in the world are able to live in the world. (...) It is about the question to what extent people live in the world in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in the world, in which they live in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in"}, {"heading": "3. Minimal Gated Unit", "text": "rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc"}, {"heading": "4. Experimental Results", "text": "In this section, we evaluate the effectiveness of MGU based on four sets of data. The simple addition problem is used in Section 4.1 as a reliability check. Finally, we evaluate MGU based on Penn TreeBank (PTB) voice modeling in Section 4.4. As shown in the evaluations (Chung et al., 2014; Jozefowicz et al., 2015), GRU has comparable accuracy with LSTM and has fewer parameters than LSTM. We will use GRU as the base architecture and compare the proposed MGU with GRU. Unless otherwise stated, we will compare these two algorithms with the same number of hidden units. All RNs will be associated with the lasagne package in the Theano Libry.The hidden MGU is not completely connected to the unit (we are not completely comparing the technique with the GRU)."}, {"heading": "4.1. The Adding Problem", "text": "The addition problem was originally proposed in (Hochreiter & Schmidhuber, 1997), and we use the variant in (Le et al., 2015). Input has two components: one is a random number in the range [0 1] and the other is a mask in {+ 1, 0, \u2212 1}. In the sequence (the length of which ranges from 50 to 55) there are only 2 numbers with mask + 1, and the output should be the sum of these two. Both MGU and GRU use 100 hidden units; batch size is 100, and the learning rate is 10 \u2212 3. For this problem we use a bidirectional network structure (Graves & Schmidhuber, 2005) that scans the sequence from left to right as well as from left; the entire hidden state is the concatenation of the hidden state in both scans."}, {"heading": "4.2. IMDB", "text": "The second problem we are investigating is the sentiment classification in the IMDB film reviews, whose task is to divide the ratings into positive and negative. This data set was published in (Maas et al., 2011).4 There are 25,000 movie reviews in the training set, another 25,000 for testing purposes. We use the provided bag-of-words format as sequence input. The maximum sequence length is 128. Both MGU and GRU have 100 hidden units; batch size is 16, and the learning rate is 10 \u2212 8 with an impulse of 0.99. Similar to the addition problem, we use a fully connected layer on the last hidden state to classify a film review as either positive or negative. We show the accuracy of this binary classification problem in Figure 3, evaluated on the test set. In the x-axis of Figure 3, we show the epochal number divided by 100. Since both curves show that they conform to 15,000 after each epoch, they are strong after each epoch."}, {"heading": "4.3. MNIST", "text": "The MNIST datasets from LeCun et al. (1998) contain images of handwritten digits (\"0\" - \"9\"). All images are 28 x 28.5 in size. There are 60,000 images in the training set and 10,000 in the test set. The images are pre-processed in such a way that the center of the mass of these digits is in two respects. The first is to treat each line (28 pixels) as a single input in the input sequence. Hence, an image is a sequence with the length 28 that corresponds to the 28 image lines (top to bottom). For this task we use 100 hidden units and the batch size is 100. The learning rate is 10 \u2212 8 with a 0.99 dynamic. A fully connected layer transfers the last GRU problem to the GRU output 10 elements."}, {"heading": "4.4. Penn TreeBank", "text": "This year, it has come to the point where it will be able to retaliate, \"he said.\" We've never waited so long to be able to unite, \"he said.\" We've never had to do as much as we want to. \""}, {"heading": "4.5. Discussions", "text": "We have evaluated the proposed MGU using four different sequence data: the comparison mainly refers to the GRU, the results of IRNN and SCRN are also quoted when appropriate; the input sequence length ranges from short (35, 50-55), moderate (128) and long (784); the sequence data ranges from artificial to real, and the task areas also vary; the proposed method corresponds to the GRU in terms of accuracy (or error or perplexity); due to its minimal gate design, the MGU has only two thirds of the parameters of the GRU and therefore trains faster in all data sets; however, in some problems (e.g. Penn TreeBank) the GRU converges faster than the MGU. Overall, we believe that these experimental results have made the MGU an attractive alternative in building RNN."}, {"heading": "5. Conclusions and Future Work", "text": "The proposed Minimal Gated Unit (MGU) has the minimum design of each gated hidden unit for RNN. It has only one gate (the forget gate) and does not include a peephole connection. Therefore, the number of parameters in the MGU is only half as large as in the Long Short-Term Memory (LSTM) or two thirds of those in the Gated Recurrent Unit (GRU). We compared the MGU with the GRU for several tasks dealing with sequence data in different areas. MGU has achieved a comparable accuracy with the GRU and trains (thanks to the minimal design) faster than the GRU. Based on our evaluations, the MGU could easily be used as a hidden unit in one RNN, which could reduce the storage requirements and training time in some applications. More importantly, the minimal design will facilitate our theoretical understanding or empirical observation (e.g. through this visualization of models), improving the understanding of the RNU models and improving the accuracy."}], "references": [{"title": "Nueral Machine Translation by Jointly Learning to Align and Translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "In Int\u2019l Conf Learning Represenations,", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Learning Longterm Dependencies with Gradient Descent is Difficult", "author": ["Y. Bengio", "P. Simard", "P. Frasconi"], "venue": "IEEE Trans.Neural Networks,", "citeRegEx": "Bengio et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1994}, {"title": "Learning to Forget: Continual Prediction with LSTM", "author": ["F.A. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "In Proc. Int\u2019l Conf Artificial Neural Networks,", "citeRegEx": "Gers et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Gers et al\\.", "year": 1999}, {"title": "Learning Precise Timing with LSTM Recurrent Networks", "author": ["F.A. Gers", "N.N. Schraudolph", "J. Schmidhuber"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Gers et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gers et al\\.", "year": 2002}, {"title": "Framewise Phoneme Classification with Bidirectional LSTM Networks", "author": ["A. Graves", "J. Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "Graves and Schmidhuber,? \\Q2005\\E", "shortCiteRegEx": "Graves and Schmidhuber", "year": 2005}, {"title": "Speech Recognition with Deep Recurrent Neural Networks", "author": ["A. Graves", "Mohamed", "A.-R", "G. Hinton"], "venue": "In Proc. Int\u2019l Conf. Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Graves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Long Short-Term Memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter and Schmidhuber,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "An Empirical Exploration of Recurrent Network Architectures", "author": ["R. Jozefowicz", "W. Zaremba", "I. Sutskever"], "venue": "In Proc. Int\u2019l Conf. on Machine Learning,", "citeRegEx": "Jozefowicz et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2015}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "In Proc. IEEE Int\u2019l Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "Karpathy and Fei.Fei,? \\Q2015\\E", "shortCiteRegEx": "Karpathy and Fei.Fei", "year": 2015}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Proc. Advances in Neural Information Processing Systems", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "A Simple Way to Initialize Recurrent Networks of Rectified Linear Units", "author": ["Q.V. Le", "N. Jaitly", "G.E. Hinton"], "venue": "arXiv preprint arXiv:1504.00941,", "citeRegEx": "Le et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Le et al\\.", "year": 2015}, {"title": "Phrasebased Image Captioning", "author": ["R. Lebret", "P.O. Pinheiro", "R. Collobert"], "venue": "In Proc. Int\u2019l Conf. on Machine Learning,", "citeRegEx": "Lebret et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lebret et al\\.", "year": 2015}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Learning Word Vectors for Sentiment Analysis", "author": ["A.L. Maas", "R.E. Daly", "P.T. Pham", "D. Huang", "A.Y. Ng", "C. Potts"], "venue": "In Proc. 49th Annual Meeting of the ACL,", "citeRegEx": "Maas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2011}, {"title": "Building a Large Annotated Corpus of English: The Penn Treebank", "author": ["M.P. Marcus", "B. Santorini", "M.A. Marcinkiewicz"], "venue": "Computational linguistics,", "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Learning Longer Memory in Recurrent Neural Networks", "author": ["T. Mikolov", "A. Joulin", "S. Chopra", "M. Mathieu", "M. Ranzato"], "venue": "In Int\u2019l Conf Learning Represenations,", "citeRegEx": "Mikolov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2015}, {"title": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting", "author": ["X. Shi", "Z. Chen", "H. Wang", "Yeung", "D.-Y", "W.K. Wong", "Woo", "W.-C"], "venue": "In Proc. Advances in Neural Information Processing Systems", "citeRegEx": "Shi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shi et al\\.", "year": 2015}, {"title": "Unsupervised Learning of Video Representations using LSTMs", "author": ["N. Srivastava", "E. Mansimov", "R. Salakhutdinov"], "venue": "In Proc. Int\u2019l Conf. on Machine Learning,", "citeRegEx": "Srivastava et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2015}, {"title": "Sequence to Sequence Learning with Neural Networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "In Proc. Advances in Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhudinov", "R. Zemel", "Y. Bengio"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Recurrent Neural Network Regularization", "author": ["W. Zaremba", "I. Sutskever", "O. Vinyals"], "venue": "arXiv preprint arXiv:1409.2329,", "citeRegEx": "Zaremba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}, {"title": "Visualizing and Understanding Convolutional Networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "In Proc. European Conf. Computer Vision, volume LNCS", "citeRegEx": "Zeiler and Fergus,? \\Q2014\\E", "shortCiteRegEx": "Zeiler and Fergus", "year": 2014}], "referenceMentions": [{"referenceID": 12, "context": "For example, convolutional neural networks (CNN) are very effective in handling image data in which 2D spatial relationships are critical among the set of raw pixel values in an image (LeCun et al., 1998; Krizhevsky et al., 2012).", "startOffset": 184, "endOffset": 229}, {"referenceID": 9, "context": "For example, convolutional neural networks (CNN) are very effective in handling image data in which 2D spatial relationships are critical among the set of raw pixel values in an image (LeCun et al., 1998; Krizhevsky et al., 2012).", "startOffset": 184, "endOffset": 229}, {"referenceID": 18, "context": "In sequence modeling, recurrent neural networks (RNN) have been very successful in language translation (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015), speech recognition (Graves et al.", "startOffset": 104, "endOffset": 169}, {"referenceID": 0, "context": "In sequence modeling, recurrent neural networks (RNN) have been very successful in language translation (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015), speech recognition (Graves et al.", "startOffset": 104, "endOffset": 169}, {"referenceID": 5, "context": ", 2015), speech recognition (Graves et al., 2013), image captioning, i.", "startOffset": 28, "endOffset": 49}, {"referenceID": 19, "context": "summarizing the semantic meaning of an image into a sentence (Xu et al., 2015; Karpathy & Fei-Fei, 2015; Lebret et al., 2015), recognizing actions in videos (Donahue et al.", "startOffset": 61, "endOffset": 125}, {"referenceID": 11, "context": "summarizing the semantic meaning of an image into a sentence (Xu et al., 2015; Karpathy & Fei-Fei, 2015; Lebret et al., 2015), recognizing actions in videos (Donahue et al.", "startOffset": 61, "endOffset": 125}, {"referenceID": 17, "context": ", 2015), recognizing actions in videos (Donahue et al., 2015; Srivastava et al., 2015), or short-term precipitation prediction (Shi et al.", "startOffset": 39, "endOffset": 86}, {"referenceID": 16, "context": ", 2015), or short-term precipitation prediction (Shi et al., 2015).", "startOffset": 48, "endOffset": 66}, {"referenceID": 6, "context": "Proposed by Hochreiter and Schmidhuber (1997), the Long Short-Term Memory (LSTM) model and its variants have been the overall best performing RNN.", "startOffset": 12, "endOffset": 46}, {"referenceID": 3, "context": "(1999) to the original LSTM, and a peephole connection made it even more complex (Gers et al., 2002).", "startOffset": 81, "endOffset": 100}, {"referenceID": 2, "context": "For example, a forget gate was added by Gers et al. (1999) to the original LSTM, and a peephole connection made it even more complex (Gers et al.", "startOffset": 40, "endOffset": 59}, {"referenceID": 7, "context": "Very recently there have been empirical evaluations on LSTM, GRU, and their variants (Chung et al., 2014; Jozefowicz et al., 2015; Greff et al., 2015).", "startOffset": 85, "endOffset": 150}, {"referenceID": 7, "context": ", 2014) and (Jozefowicz et al., 2015) both show that more gates do not lead to better accuracy.", "startOffset": 12, "endOffset": 37}, {"referenceID": 7, "context": "Evaluations in (Chung et al., 2014; Jozefowicz et al., 2015; Greff et al., 2015) agreed that RNN with a gated unit works significantly better than a RNN with a simple tanh unit without any gate.", "startOffset": 15, "endOffset": 80}, {"referenceID": 1, "context": "RNN in the simple form suffers from the vanishing or exploding gradient issue, which makes learning RNN using gradient descent very difficult in long sequences (Bengio et al., 1994; Hochreiter & Schmidhuber, 1997).", "startOffset": 160, "endOffset": 213}, {"referenceID": 2, "context": "The original LSTM (Hochreiter & Schmidhuber, 1997) does not include the forget gate, which was later introduced in (Gers et al., 1999).", "startOffset": 115, "endOffset": 134}, {"referenceID": 2, "context": "The original LSTM (Hochreiter & Schmidhuber, 1997) does not include the forget gate, which was later introduced in (Gers et al., 1999). Gers et al. (2002) makes LSTM even more complicated by allowing the three gates (f t, it, ot) to take ct\u22121 or ct as an additional input, called the peephole connections.", "startOffset": 116, "endOffset": 155}, {"referenceID": 7, "context": "Similar observations were also corroborated in (Jozefowicz et al., 2015).", "startOffset": 47, "endOffset": 72}, {"referenceID": 15, "context": "Instead of using gates to control information flow in RNN, the Structurally Constrained Recurrent Network (SCRN) added a hidden context vector st to simple RNN, which changes slowly over time if the parameter \u03b1 is large (Mikolov et al., 2015), as", "startOffset": 220, "endOffset": 242}, {"referenceID": 15, "context": "SCRN has still fewer parameters than GRU, and has shown similar performance as LSTM in (Mikolov et al., 2015).", "startOffset": 87, "endOffset": 109}, {"referenceID": 12, "context": "Especially in the MNIST dataset (LeCun et al., 1998), IRNN significantly outperforms LSTM.", "startOffset": 32, "endOffset": 52}, {"referenceID": 10, "context": "The same initialization trick was used in (Le et al., 2015) too.", "startOffset": 42, "endOffset": 59}, {"referenceID": 9, "context": "Le et al. (2015) showed that minor changes to the simple RNN architecture can significantly improve its accuracy.", "startOffset": 0, "endOffset": 17}, {"referenceID": 7, "context": "Similarly, Jozefowicz et al. (2015) also showed that proper initialization is also important for LSTM.", "startOffset": 11, "endOffset": 36}, {"referenceID": 7, "context": "Jozefowicz et al. (2015) proposed three variants of GRU.", "startOffset": 0, "endOffset": 25}, {"referenceID": 7, "context": ", on the importance of the output gate Jozefowicz et al. (2015) and Greff et al.", "startOffset": 39, "endOffset": 64}, {"referenceID": 7, "context": ", on the importance of the output gate Jozefowicz et al. (2015) and Greff et al. (2015)", "startOffset": 39, "endOffset": 88}, {"referenceID": 7, "context": "As was shown in the evaluations (Chung et al., 2014; Jozefowicz et al., 2015), GRU has comparable accuracy with LSTM, and has fewer parameters than LSTM.", "startOffset": 32, "endOffset": 77}, {"referenceID": 10, "context": "The adding problem was originally proposed in (Hochreiter & Schmidhuber, 1997), and we use the variant in (Le et al., 2015).", "startOffset": 106, "endOffset": 123}, {"referenceID": 13, "context": "This dataset was generated in (Maas et al., 2011).", "startOffset": 30, "endOffset": 49}, {"referenceID": 12, "context": "The MNIST dataset by LeCun et al. (1998) contains images of handwritten digits (\u20180\u2019\u2013\u20189\u201d).", "startOffset": 21, "endOffset": 41}, {"referenceID": 20, "context": "For this dataset, we work on the word-level prediction task, which is the same as the version in (Zaremba et al., 2014).", "startOffset": 97, "endOffset": 119}, {"referenceID": 20, "context": "As in (Zaremba et al., 2014), we use two layers and the sequence length is 35.", "startOffset": 6, "endOffset": 28}, {"referenceID": 14, "context": "The Penn TreeBank (PTB) dataset provides data for language modeling, which is released by Marcus et al. (1993). For this dataset, we work on the word-level prediction task, which is the same as the version in (Zaremba et al.", "startOffset": 90, "endOffset": 111}, {"referenceID": 7, "context": "We can also compare MGU with the results in (Jozefowicz et al., 2015).", "startOffset": 44, "endOffset": 69}, {"referenceID": 7, "context": "55, lower than the GRU (with 5M parameters) result in (Jozefowicz et al., 2015), which is 108.", "startOffset": 54, "endOffset": 79}, {"referenceID": 7, "context": "02, also lower than the GRU result in (Jozefowicz et al., 2015).", "startOffset": 38, "endOffset": 63}], "year": 2016, "abstractText": "Recently recurrent neural networks (RNN) has been very successful in handling sequence data. However, understanding RNN and finding the best practices for RNN is a difficult task, partly because there are many competing and complex hidden units (such as LSTM and GRU). We propose a gated unit for RNN, named as Minimal Gated Unit (MGU), since it only contains one gate, which is a minimal design among all gated hidden units. The design of MGU benefits from evaluation results on LSTM and GRU in the literature. Experiments on various sequence data show that MGU has comparable accuracy with GRU, but has a simpler structure, fewer parameters, and faster training. Hence, MGU is suitable in RNN\u2019s applications. Its simple architecture also means that it is easier to evaluate and tune, and in principle it is easier to study MGU\u2019s properties theoretically and empirically.", "creator": "LaTeX with hyperref package"}}}