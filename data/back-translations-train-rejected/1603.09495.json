{"id": "1603.09495", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2016", "title": "Reactive Policies with Planning for Action Languages", "abstract": "We describe a representation in a high-level transition system for policies that express a reactive behavior for the agent. We consider a target decision component that figures out what to do next and an (online) planning capability to compute the plans needed to reach these targets. Our representation allows one to analyze the flow of executing the given reactive policy, and to determine whether it works as expected. Additionally, the flexibility of the representation opens a range of possibilities for designing behaviors.", "histories": [["v1", "Thu, 31 Mar 2016 09:05:28 GMT  (56kb,D)", "http://arxiv.org/abs/1603.09495v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["zeynep g saribatur", "thomas eiter"], "accepted": false, "id": "1603.09495"}, "pdf": {"name": "1603.09495.pdf", "metadata": {"source": "META", "title": "Reactive Policies with Planning for Action Languages", "authors": ["Zeynep G. Saribatur", "Thomas Eiter"], "emails": ["zeynep@kr.tuwien.ac.at", "eiter@kr.tuwien.ac.at"], "sections": [{"heading": null, "text": "This year, more than ever before in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a, a, a place, a place, a place, a, a, a place, a place, a, a place, a, a, a place, a, a place, a, a, a place, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a"}, {"heading": "Preliminaries", "text": "Definition 1. A transition system T is defined as T = < S, S0, A, \u03a6 > where \u2022 S is the set of states. \u2022 S0 S is the set of possible initial states. \u2022 A is the set of possible actions. \u2022 \u03a6: S \u00b7 A \u2192 2S is the transition function, returns the set of possible subsequent states after applying a possible action in the current state. \u2022 For all states s, s \u00b2 S we say that there is an orbit between s and s \u00b2 designated for some action sequences \u03c3 = a1,..., where n \u2265 0, if there is s0,......, sn \u0445 S such that s = s0, s \u00b2 = sn and si + 1 \u00b2 (si, ai + 1) for all 0 \u2264 i < n.We will refer to this transition system as the original transition system. Components S and A are assumed to be finite in the rest of the paper."}, {"heading": "Action Languages", "text": "In fact, it is as if most people who are able to see themselves are able to help themselves. (...) It is not as if they were able to save themselves. (...) It is as if they were able to save themselves. (...) It is as if they were able to save themselves. (...) It is not as if they were able to save themselves. (...) It is as if they were able to save themselves. (...) It is as if they were able to save themselves. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (). (...). (). (...). (). (...). (. (...). (). (...). (). (...). ().). (...). (). (). (). ().). (...). (...). (...). (...). (...).). (...). ("}, {"heading": "Modeling Policies in Transition Systems", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, in which it is a country, in which it is a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in"}, {"heading": "Constraining equalization", "text": "However, the aim of defining such a balanced transitional system is not to introduce new features, but to maintain the structure of the original transitional system and discard the unnecessary parts relating to policy. Therefore, further restrictions must be imposed on the original transitions of the balanced transitional system in order to achieve the basic conditions of the original transitional system. (1) This condition ensures that a transition between two states is possible. (s) 2 in the balanced transitional system represents that each state in s 2 has a transition from any state in s 2."}, {"heading": "Relation with Action Languages", "text": "In this section, we will describe how our definition of a superordinate transitional system that models behavior can fit into the action languages. Considering a program defined by an action language and its respective (original) transition system, we will now describe how this program can be modelled according to a reactive policy and how the appropriate balanced transitional system can be built according to policy."}, {"heading": "Classifying the state space", "text": "The approach to the classification of the (original) territory of the state is based on the definition of a function that classifies the states. There are at least two types of such classification; one can classify the states according to whether they give the same values for certain rivers and omit knowledge of the values of the remaining rivers, or one can introduce a new group of rivers and classify the states according to whether they give the same values for the new rivers: \u2022 Type 1: Extend the set of truth values by V \u2032 = V, {u}, where u denotes the value as unknown. Extend the evaluation function by V \u2032: F \u00b7 S \u2192 V. \"Then we consider a new group of states that constitute a new group of states, S = {s \u00b2 1,."}, {"heading": "Defining a target language", "text": "Let F (F) denote the set of formulas in an abstract language that can be constructed using F (F). Let us consider a declarative way to find goals. Let FB (F) F (F) be the set of formulas that describe goal determination. Let FGB (F) F (F) denote the set of possible goals that are determined through the evaluation of formulas FB (F) about the related flows in the balanced states. Note that the separation of goal formulas FB (F) and goals FGB (F) should allow outsourced planners who are able to understand simple goal formulas. These planners do not need to know the target language in order to find plans."}, {"heading": "Transition between states", "text": "s look at a simple example where a policy (of two phases) is defined as: \u2022 when in phase 1 and not all blocks are on the table, and not all blocks on the table, and not all blocks on the table, and not all blocks on the table, and not all blocks on the list. < < < < < <"}, {"heading": "Defining a policy", "text": "It is a question of the extent to which it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question,"}, {"heading": "Conclusion and Future Work", "text": "In this paper, we have described a high-level representation that models reactive behavior and integrates goal-development and online planning skills. Flexibility in these components not only obliges the use of action languages, but also allows the use of other formalizations. For future work, one could imagine that goals depend on additional parameters or incorporate learning from experience into the framework. It is also possible to use other plans, e.g. short-term conditional plans, in the planner component.The long-term goal of this work is to verify and verify the properties of the reactive strategies for action languages. In order to solve these problems in practice, it is necessary to use techniques from model review, such as abstraction, compositional thinking and parameterization. Also, the use of time-logical formulas is necessary to express complex goals such as characteristics of the strategies. Our main goal is to work with action languages and to link their syntax and semantics with such techniques of model testing."}], "references": [{"title": "Verification of Golog programs over description logic actions", "author": ["F. Baader", "B. Zarrie\u00df"], "venue": "Frontiers of Combining Systems 181\u2013196.", "citeRegEx": "Baader and Zarrie\u00df,? 2013", "shortCiteRegEx": "Baader and Zarrie\u00df", "year": 2013}, {"title": "Strong planning under partial observability", "author": ["P. Bertoli", "A. Cimatti", "M. Riveri", "P. Traverso"], "venue": "Artificial Intelligence 170(4):337\u2013384.", "citeRegEx": "Bertoli et al\\.,? 2006", "shortCiteRegEx": "Bertoli et al\\.", "year": 2006}, {"title": "Verifying multi-agent programs by model checking", "author": ["R.H. Bordini", "M. Fisher", "W. Visser", "M. Wooldridge"], "venue": "Autonomous agents and multi-agent systems 12(2):239\u2013256.", "citeRegEx": "Bordini et al\\.,? 2006", "shortCiteRegEx": "Bordini et al\\.", "year": 2006}, {"title": "Verification and synthesis in description logic based dynamic systems", "author": ["D. Calvanese", "G. De Giacomo", "M. Montali", "F. Patrizi"], "venue": "Web Reasoning and Rule Systems. Springer. 50\u201364.", "citeRegEx": "Calvanese et al\\.,? 2013", "shortCiteRegEx": "Calvanese et al\\.", "year": 2013}, {"title": "Automatic OBDD-based generation of universal plans in nondeterministic domains", "author": ["A. Cimatti", "M. Riveri", "P. Traverso"], "venue": "Proc. of AAAI/IAAI, 875\u2013881.", "citeRegEx": "Cimatti et al\\.,? 1998a", "shortCiteRegEx": "Cimatti et al\\.", "year": 1998}, {"title": "Strong planning in non-deterministic domains via model checking", "author": ["A. Cimatti", "M. Riveri", "P. Traverso"], "venue": "AIPS 98:36\u201343.", "citeRegEx": "Cimatti et al\\.,? 1998b", "shortCiteRegEx": "Cimatti et al\\.", "year": 1998}, {"title": "A logic for nonterminating Golog programs", "author": ["J. Cla\u00dfen", "G. Lakemeyer"], "venue": "Proc. of KR, 589\u2013599.", "citeRegEx": "Cla\u00dfen and Lakemeyer,? 2008", "shortCiteRegEx": "Cla\u00dfen and Lakemeyer", "year": 2008}, {"title": "Execution monitoring of high-level robot programs", "author": ["G. De Giacomo", "R. Reiter", "M. Soutchanski"], "venue": "Proc. of KR, 453\u2013465.", "citeRegEx": "Giacomo et al\\.,? 1998", "shortCiteRegEx": "Giacomo et al\\.", "year": 1998}, {"title": "Nonterminating processes in the situation calculus", "author": ["G. De Giacomo", "E. Ternovskaia", "R. Reiter"], "venue": "Working Notes of Robots, Softbots, Immobots: Theories of Action, Planning and Control, AAAI97 Workshop.", "citeRegEx": "Giacomo et al\\.,? 1997", "shortCiteRegEx": "Giacomo et al\\.", "year": 1997}, {"title": "Model checking agent programming languages", "author": ["L.A. Dennis", "M. Fisher", "M.P. Webster", "R.H. Bordini"], "venue": "Automated Software Engineering 19(1):5\u201363.", "citeRegEx": "Dennis et al\\.,? 2012", "shortCiteRegEx": "Dennis et al\\.", "year": 2012}, {"title": "A logic programming approach to knowledge-state planning: Semantics and complexity", "author": ["T. Eiter", "W. Faber", "N. Leone", "G. Pfeifer", "A. Polleres"], "venue": "ACM Trans. Comput. Log. 5(2):206\u2013263.", "citeRegEx": "Eiter et al\\.,? 2004", "shortCiteRegEx": "Eiter et al\\.", "year": 2004}, {"title": "A Uniform Integration of Higher-Order Reasoning and External Evaluations in Answer-Set Programming", "author": ["T. Eiter", "G. Ianni", "R. Schindlauer", "H. Tompits"], "venue": "Proc. of IJCAI, 90\u201396.", "citeRegEx": "Eiter et al\\.,? 2005", "shortCiteRegEx": "Eiter et al\\.", "year": 2005}, {"title": "A logicbased approach to finding explanations for discrepancies in optimistic plan execution", "author": ["T. Eiter", "E. Erdem", "W. Faber", "J. Senko"], "venue": "Fundamenta Informaticae 79(12):25\u201369.", "citeRegEx": "Eiter et al\\.,? 2007", "shortCiteRegEx": "Eiter et al\\.", "year": 2007}, {"title": "Intelligent execution monitoring in dynamic environments", "author": ["M. Fichtner", "A. Gro\u00dfmann", "M. Thielscher"], "venue": "Fundamenta Informaticae 57(2-4):371\u2013392.", "citeRegEx": "Fichtner et al\\.,? 2003", "shortCiteRegEx": "Fichtner et al\\.", "year": 2003}, {"title": "Acthex: Implementing HEX programs with action atoms", "author": ["M. Fink", "S. Germano", "G. Ianni", "C. Redl", "P. Sch\u00fcller"], "venue": "Logic Programming and Nonmonotonic Reasoning 317\u2013322.", "citeRegEx": "Fink et al\\.,? 2013", "shortCiteRegEx": "Fink et al\\.", "year": 2013}, {"title": "Coala: A compiler from action languages to ASP", "author": ["M. Gebser", "T. Grote", "T. Schaub"], "venue": "Proc. of JELIA, 360\u2013364. Springer Heidelberg.", "citeRegEx": "Gebser et al\\.,? 2010", "shortCiteRegEx": "Gebser et al\\.", "year": 2010}, {"title": "Representing action and change by logic programs", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "The Journal of Logic Programming 17(2):301\u2013321.", "citeRegEx": "Gelfond and Lifschitz,? 1993", "shortCiteRegEx": "Gelfond and Lifschitz", "year": 1993}, {"title": "Action languages", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "Electronic Transactions on AI 3(16).", "citeRegEx": "Gelfond and Lifschitz,? 1998", "shortCiteRegEx": "Gelfond and Lifschitz", "year": 1998}, {"title": "An action language based on causal explanation: Preliminary report", "author": ["E. Giunchiglia", "V. Lifschitz"], "venue": "Proc. of AAAI/IAAI, 623\u2013630.", "citeRegEx": "Giunchiglia and Lifschitz,? 1998", "shortCiteRegEx": "Giunchiglia and Lifschitz", "year": 1998}, {"title": "Nonmonotonic causal theories", "author": ["E. Giunchiglia", "J. Lee", "V. Lifschitz", "N. McCain", "H. Turner"], "venue": "Artificial Intelligence 153(1):49\u2013104.", "citeRegEx": "Giunchiglia et al\\.,? 2004", "shortCiteRegEx": "Giunchiglia et al\\.", "year": 2004}, {"title": "From logic programming towards multi-agent systems", "author": ["R.A. Kowalski", "F. Sadri"], "venue": "Ann. Math. Artif. Intell. 25(34):391\u2013419.", "citeRegEx": "Kowalski and Sadri,? 1999", "shortCiteRegEx": "Kowalski and Sadri", "year": 1999}, {"title": "GOLOG: A logic programming language for dynamic domains", "author": ["H.J. Levesque", "R. Reiter", "Y. Lesperance", "F. Lin", "R.B. Scherl"], "venue": "The Journal of Logic Programming 31(1):59\u201383.", "citeRegEx": "Levesque et al\\.,? 1997", "shortCiteRegEx": "Levesque et al\\.", "year": 1997}, {"title": "Action languages, answer sets and planning", "author": ["V. Lifschitz"], "venue": "The Logic Programming Paradigm: a 25-Year Perspective, 357\u2013373. Springer.", "citeRegEx": "Lifschitz,? 1999", "shortCiteRegEx": "Lifschitz", "year": 1999}, {"title": "What is answer set programming? In Proc", "author": ["V. Lifschitz"], "venue": "of. AAAI, 1594\u20131597.", "citeRegEx": "Lifschitz,? 2008", "shortCiteRegEx": "Lifschitz", "year": 2008}, {"title": "Modeling rational agents within a BDI-architecture", "author": ["A.S. Rao", "M.P. Georgeff"], "venue": "Proc. of KR, 473\u2013484.", "citeRegEx": "Rao and Georgeff,? 1991", "shortCiteRegEx": "Rao and Georgeff", "year": 1991}, {"title": "Formalizing sensing actions \u2013 a transition function based approach", "author": ["T.C. Son", "C. Baral"], "venue": "Artificial Intelligence 125(1):19\u201391.", "citeRegEx": "Son and Baral,? 2001", "shortCiteRegEx": "Son and Baral", "year": 2001}, {"title": "High-level robot programming and program execution", "author": ["M. Soutchanski"], "venue": "Proc. of ICAPS Workshop on Plan Execution.", "citeRegEx": "Soutchanski,? 2003", "shortCiteRegEx": "Soutchanski", "year": 2003}, {"title": "Polynomial-length planning spans the polynomial hierarchy", "author": ["H. Turner"], "venue": "Proc. of JELIA, 111\u2013124. Springer.", "citeRegEx": "Turner,? 2002", "shortCiteRegEx": "Turner", "year": 2002}], "referenceMentions": [{"referenceID": 17, "context": "Action languages (Gelfond and Lifschitz 1998) provide a useful framework on defining actions and reasoning about them, by modeling dynamic systems as transition systems.", "startOffset": 17, "endOffset": 45}, {"referenceID": 23, "context": "As these languages are closely related with classical logic and answer set programming (ASP) (Lifschitz 2008; 1999), they can be translated into logic programs and queried for computation.", "startOffset": 93, "endOffset": 115}, {"referenceID": 17, "context": "There have been various works on action languages (Gelfond and Lifschitz 1998; 1993; Giunchiglia and Lifschitz 1998) and their reasoning systems (Giunchiglia et al.", "startOffset": 50, "endOffset": 116}, {"referenceID": 18, "context": "There have been various works on action languages (Gelfond and Lifschitz 1998; 1993; Giunchiglia and Lifschitz 1998) and their reasoning systems (Giunchiglia et al.", "startOffset": 50, "endOffset": 116}, {"referenceID": 19, "context": "There have been various works on action languages (Gelfond and Lifschitz 1998; 1993; Giunchiglia and Lifschitz 1998) and their reasoning systems (Giunchiglia et al. 2004; Gebser, Grote, and Schaub 2010), with underlying mechanisms that rely on SAT and ASP solvers.", "startOffset": 145, "endOffset": 202}, {"referenceID": 11, "context": "For example, one can use HEX (Eiter et al. 2005) to describe a program that determines a target given the current state of an agent, finds the respective plan and the execution schedule.", "startOffset": 29, "endOffset": 48}, {"referenceID": 14, "context": "ACTHEX programs (Fink et al. 2013), in particular, provide the tools to define such reactive behaviors as it allows for iterative evaluation of the logic programs and the ability to observe the outcomes of executing the actions in the environment.", "startOffset": 16, "endOffset": 34}, {"referenceID": 16, "context": "This method matches the observe-think-act cycle of Kowalski and Sadri (1999), but involves a planner that considers targets.", "startOffset": 51, "endOffset": 77}, {"referenceID": 18, "context": "In particular, we consider the action language C (Giunchiglia and Lifschitz 1998) to illustrate an application.", "startOffset": 49, "endOffset": 81}, {"referenceID": 25, "context": "Different from the work by Son and Baral (2001) where they consider a \u201ccombined-state\u201d which consists of the real state of the world and the states that the agent thinks it may be in, we consider a version where we combine the real states into one state if they provide the same classification (or observation, in case of partial observability) for the agent.", "startOffset": 27, "endOffset": 48}, {"referenceID": 18, "context": "In this section, we describe how one can construct an equalized transition system for a reactive system that is represented using the action language C (Giunchiglia and Lifschitz 1998).", "startOffset": 152, "endOffset": 184}, {"referenceID": 27, "context": "Furthermore, by well-known results on the complexity of action language C (Turner 2002; Eiter et al. 2004) all the results in Theorems 1-5 can be turned into completeness results already for this fragment.", "startOffset": 74, "endOffset": 106}, {"referenceID": 10, "context": "Furthermore, by well-known results on the complexity of action language C (Turner 2002; Eiter et al. 2004) all the results in Theorems 1-5 can be turned into completeness results already for this fragment.", "startOffset": 74, "endOffset": 106}, {"referenceID": 21, "context": "There are works being conducted on the verification of GOLOG programs (Levesque et al. 1997), a family of highlevel action programming languages defined on top of action theories expressed in the situation calculus.", "startOffset": 70, "endOffset": 92}, {"referenceID": 6, "context": "The method of verifying properties of non-terminal processes are sound, but do not have the guarantee of termination due to the verification problem being undecidable (De Giacomo, Ternovskaia, and Reiter 1997; Cla\u00dfen and Lakemeyer 2008).", "startOffset": 167, "endOffset": 236}, {"referenceID": 0, "context": "By resorting to action formalisms based on description logic, decidability can be achieved (Baader and Zarrie\u00df 2013).", "startOffset": 91, "endOffset": 116}, {"referenceID": 3, "context": "Verifying temporal properties of dynamic systems in the context of data management is studied by (Calvanese et al. 2013) in the presence of description logic knowledge bases.", "startOffset": 97, "endOffset": 120}, {"referenceID": 2, "context": "Some works carried out on verifying properties of agents represented in these languages, such as (Bordini et al. 2006; Dennis et al. 2012).", "startOffset": 97, "endOffset": 138}, {"referenceID": 9, "context": "Some works carried out on verifying properties of agents represented in these languages, such as (Bordini et al. 2006; Dennis et al. 2012).", "startOffset": 97, "endOffset": 138}, {"referenceID": 22, "context": "The logical framework for agent theory developed by Rao and Georgeff (1991) is based on beliefs, desires and intentions, in which agents are viewed as being rational and acting in accordance with their beliefs and goals.", "startOffset": 52, "endOffset": 76}, {"referenceID": 1, "context": "(1998b; 1998a), Bertoli et al. (2006). These approaches are able to solve difficult planning problems like strong planning and strong cyclic planning.", "startOffset": 16, "endOffset": 38}, {"referenceID": 26, "context": "The approaches that are studied are replanning (De Giacomo, Reiter, and Soutchanski 1998), backtracking to the point of failure and continuing from there (Soutchanski 2003), or diagnosing the failure and recovering from the failure situation (Fichtner, Gro\u00dfmann, and Thielscher 2003; Eiter et al.", "startOffset": 154, "endOffset": 172}, {"referenceID": 12, "context": "The approaches that are studied are replanning (De Giacomo, Reiter, and Soutchanski 1998), backtracking to the point of failure and continuing from there (Soutchanski 2003), or diagnosing the failure and recovering from the failure situation (Fichtner, Gro\u00dfmann, and Thielscher 2003; Eiter et al. 2007).", "startOffset": 242, "endOffset": 302}], "year": 2016, "abstractText": "We describe a representation in a high-level transition system for policies that express a reactive behavior for the agent. We consider a target decision component that figures out what to do next and an (online) planning capability to compute the plans needed to reach these targets. Our representation allows one to analyze the flow of executing the given reactive policy, and to determine whether it works as expected. Additionally, the flexibility of the representation opens a range of possibilities for designing behaviors. Autonomous agents are systems that decide for themselves what to do to satisfy their design objectives. These agents have a knowledge base that describes their capabilities, represents facts about the world and helps them in reasoning about their course of actions. A reactive agent interacts with its environment. It perceives the current state of the world through sensors, consults its memory (if there is any), reasons about actions to take and executes them in the environment. A policy for these agents gives guidelines to follow during their interaction with the environment. As autonomous systems become more common in our lives, the issue of verifying that they behave as intended becomes more important. During the operation of an agent, one would want to be sure that by following the designed policy, the agent will achieve the desired results. It would be highly costly, time consuming and sometimes even fatal to realize at runtime that the designed policy of the agent does not provide the expected properties. For example, in search and rescue scenarios, an agent needs to find a missing person in unknown environments. A naive approach would be to directly try to find a plan that achieves the main goal of finding the person. However, this problem easily becomes troublesome, since not knowing the environment causes the planner to consider all possible cases and find a plan that guarantees reaching the goal in all settings. Alternatively, one can describe a reactive policy for the agent that determines its course of actions according to its current knowledge, and guides the agent in the environment towards the main goal. A possible such policy could be \u201calways \u2217This work has been supported by Austrian Science Fund (FWF) project W1255-N23. Copyright c \u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. move to the farthest unvisited point in visible distance, until a person is found\u201d. Following this reactive policy, the agent would traverse the environment by choosing its actions to reach the farthest possible point from the current state, and by reiterating the decision process after reaching a new state. The agent may also remember the locations it has been in and gain information (e.g. obstacle locations) through its sensors on the way. Verifying beforehand whether or not the designed policy of the agent satisfies the desired goal (e.g. can the agent always find the person?), in all possible instances of the environment is nontrivial. Action languages (Gelfond and Lifschitz 1998) provide a useful framework on defining actions and reasoning about them, by modeling dynamic systems as transition systems. Their declarative property helps in describing the system in an understandable, concise language, and they also address the problems encountered when reasoning about actions. By design, these languages are made to be decidable, which ensures reliable descriptions of dynamic systems. As these languages are closely related with classical logic and answer set programming (ASP) (Lifschitz 2008; 1999), they can be translated into logic programs and queried for computation. The programs produced by such translations can yield sound and complete answers to such queries. There have been various works on action languages (Gelfond and Lifschitz 1998; 1993; Giunchiglia and Lifschitz 1998) and their reasoning systems (Giunchiglia et al. 2004; Gebser, Grote, and Schaub 2010), with underlying mechanisms that rely on SAT and ASP solvers. The shortage of representations that are capable of modeling reactive policies prevents one from verifying such policies using action languages as above before putting them into use. The necessity of such a verification capability motivates us to address this issue. We thus aim for a general model that allows for verifying the reactive behavior of agents in environments with different types in terms of observability and determinism. In that model, we want to use the representation power of the transition systems described by action languages and combine components that are efficient for describing reactivity. Towards this aim, we consider in this paper agents with a reactive behavior that decide their course of actions by determining targets to achieve during their interaction with the environment. Such agents come with an (online) planning ar X iv :1 60 3. 09 49 5v 1 [ cs .A I] 3 1 M ar 2 01 6 capability that computes plans to reach the targets. This method matches the observe-think-act cycle of Kowalski and Sadri (1999), but involves a planner that considers targets. The flexibility in the two components target development and external planning allow for a range of possibilities for designing behaviors. For example, one can use HEX (Eiter et al. 2005) to describe a program that determines a target given the current state of an agent, finds the respective plan and the execution schedule. ACTHEX programs (Fink et al. 2013), in particular, provide the tools to define such reactive behaviors as it allows for iterative evaluation of the logic programs and the ability to observe the outcomes of executing the actions in the environment. Specifically, we make the following contributions: (1) We introduce a novel framework for describing the semantics of a policy that follows a reactive behavior, by integrating components of target establishment and online planning. The purpose of this work is not synthesis, but to lay foundations for verification of behaviors of (human-designed) reactive policies. The outsourced planning might also lend itself for modular, hierarchic planning, where macro actions (expressed as targets) are turned into a plan of micro actions. Furthermore, outsourced planning may also be exploited to abstract from correct sub-behaviors (e.g. going always to the farthest point). (2) We relate this to action languages and discuss possibilities for policy formulation. In particular, we consider the action language C (Giunchiglia and Lifschitz 1998) to illustrate an application. The remainder of this paper is organized as follows. After some preliminaries, we present a running example and then the general framework for modeling policies with planning. After that, we consider the relation to action languages, and as a particular application we consider (a fragment of) the action language C. We briefly discuss some related work and conclude with some issues for ongoing and future work. Preliminaries Definition 1. A transition system T is defined as T = \u3008S, S0,A,\u03a6\u3009 where \u2022 S is the set of states. \u2022 S0 \u2286 S is the set of possible initial states. \u2022 A is the set of possible actions. \u2022 \u03a6 : S \u00d7 A \u2192 2 is the transition function, returns the set of possible successor states after applying a possible action in the current state. For any states s, s\u2032 \u2208 S, we say that there is a trajectory between s and s\u2032, denoted by s\u2192\u03c3 s\u2032 for some action sequence \u03c3 = a1, . . . , an where n \u2265 0, if there exist s0, . . . , sn \u2208 S such that s = s0, s\u2032 = sn and si+1 \u2208 \u03a6(si, ai+1) for all 0 \u2264 i < n. We will refer to this transition system as the original transition system. The constituents S and A are assumed to be finite in the rest of the paper. Note that, this transition system represents fully observable settings. Large environments cause high number of possibilities for states, which cause the transition systems to be large. Especially, if the environment is nondeterministic, the resulting transition system contains high amount of transitions between states, since one needs to consider all possible outcomes of executing an action.", "creator": "TeX"}}}