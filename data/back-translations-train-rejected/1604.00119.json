{"id": "1604.00119", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2016", "title": "Semi-supervised and Unsupervised Methods for Categorizing Posts in Web Discussion Forums", "abstract": "Web discussion forums are used by millions of people worldwide to share information belonging to a variety of domains such as automotive vehicles, pets, sports, etc. They typically contain posts that fall into different categories such as \\textit{problem}, \\textit{solution}, \\textit{feedback}, \\textit{spam}, etc. Automatic identification of these categories can aid information retrieval that is tailored for specific user requirements. Previously, a number of supervised methods have attempted to solve this problem; however, these depend on the availability of abundant training data. A few existing unsupervised and semi-supervised approaches are either focused on identifying a single category or do not report category-specific performance. In contrast, this work proposes unsupervised and semi-supervised methods that require no or minimal training data to achieve this objective without compromising on performance. A fine-grained analysis is also carried out to discuss their limitations. The proposed methods are based on sequence models (specifically, Hidden Markov Models) that can model language for each category using word and part-of-speech probability distributions, and manually specified features. Empirical evaluations across domains demonstrate that the proposed methods are better suited for this task than existing ones.", "histories": [["v1", "Fri, 1 Apr 2016 03:32:03 GMT  (540kb,D)", "https://arxiv.org/abs/1604.00119v1", null], ["v2", "Tue, 5 Apr 2016 16:06:13 GMT  (540kb,D)", "http://arxiv.org/abs/1604.00119v2", null], ["v3", "Sun, 24 Apr 2016 21:27:17 GMT  (540kb,D)", "http://arxiv.org/abs/1604.00119v3", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG cs.SI", "authors": ["krish perumal"], "accepted": false, "id": "1604.00119"}, "pdf": {"name": "1604.00119.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Krish Perumal"], "emails": [], "sections": [{"heading": null, "text": "Partially monitored and unsupervised methods of categorizing posts on web discussion forums Krish PerumalMaster of ScienceGraduate Department of Computer ScienceUniversity of Toronto 2016 Web discussion forums are used by millions of people worldwide to share information that belongs to a variety of areas such as automobiles, pets, sports, etc. They typically include posts that fall into different categories, such as problem, solution, feedback, spam, etc. Automatic identification of these categories can help retrieve information that is tailored to specific user needs. To date, a number of monitored methods have attempted to address this problem, but these depend on the availability of abundant training data. Some existing uncontrolled and partially monitored approaches either focus on identifying a single category or report non-category-specific performance. By contrast, this work proposes uncontrolled and semi-monitored methods that require no or minimal training data, without compromising performance."}, {"heading": "Acknowledgements", "text": "I also thank my second reader, Prof. Gerald Penn, for evaluating my work and providing valuable comments. I am grateful to Dr. Afsaneh Fazly for introducing me to this work for the first time, and advise me on possible research directions that I can explore at every step of the work. I also thank Brandon Seibel and Alex Minnaar for helping me during my visits to Verticalscope Inc. (No. EGP 477227-14). I thank Verticalscope Inc. for giving me access to their data for this research. I also thank Mohamed Abdalla for helping me with some of the implementations mentioned in this work. I thank my parents who worked tirelessly to provide me with a great education. I also thank my friends and good friends who stood by me during my time at the Indian Faculty of Computer Science."}, {"heading": "1 Introduction 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Related Work 5", "text": "2.1 Managed Methods.................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "3 Description of Implemented Methods 12", "text": "3.1. Existing methods with minor improvements.............. 123.1.1. Conversations....... 173.1.3. Fully monitored..................... 123.1.2. Conversations.... Proposed methods... Properties. Mixtures.............. 173.1.3. Fully monitored.......................... 183.2 Proposed methods... Properties.................."}, {"heading": "4 Data Collection and Annotation 27", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 Experiments 32", "text": "5.1. Evaluation yardsticks.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "6 Conclusions and Future Work 44", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "2.1 Supervised Methods", "text": "Related previous work on classifying categories of discussion forums has largely focused on the application of these methods, focusing in particular on the computer-related technical requirement. Catherine et al. (2012) employed Support Vector Machines (SVMs) to extract responses in a thread (provided that the first post in the thread is a question), using a number of structural and syntactical features in addition to forum-specific functions such as authority and rating types. Their methods were evaluated against a corpus of Apple discussion forums. Bhatia et al. (2012) used monitored machine learning algorithms (i.e., SVMs, logit model classifier, naive Bayes, etc.) to classify forum contributions into eight categories."}, {"heading": "2.2 Unsupervised Methods", "text": "These methods use a task-dependent measure of similarity to determine whether or not two input units belong to the same cluster, and in some cases, the interactions between the clusters are also modeled. By contrast, they do not require labeled data, so their applicability is not limited to a specific domain. To get the most out of our knowledge, three unattended techniques have been proposed for categorizing posts in web forums."}, {"heading": "2.3 Semi-supervised Methods", "text": "Semi-monitored methods can overcome the disadvantages of both unattended and monitored methods by using a minimal amount of marked data (which is costly to obtain) and a large amount of unmarked data (which is readily available). To our knowledge, there are only two semi-monitored methods for categorizing posts in web forums; another method used domain adaptation from marked spoken dialogue records using a sub-tree pattern mining algorithm (Jeong et al., 2009); another method extracted response posts in forum threads using a co-training framework (Catherine et al., 2013); however, it focused only on extracting response posts, assuming that the first post in a thread is a question; both methods used features such as the chronological position of a post in the thread as well as post and author ratings."}, {"heading": "2.4 Methods Applied to Other Tasks", "text": "Barzilay and Lee (2004) proposed a content model for summarizing multiple documents based on sentence extraction, which consists of a sentence-level HMM tailored to identify sentence clusters that relate to different topics. Inspired by this model, Ritter et al. (2010) proposed a \"conversation model\" for modeling dialog files in Twitter conversations. Their model replicates Barzilay's model, but replaces sentences in a document with tweets in a Twitter conversation as units of HMM. They used topic modeling (using latent dirichlet allocation) along with the conversation model and reported better performance, but the evaluation was only qualitative. Similarly, Joty et al. (2011) applied conversation models for e-mails and forum threads, in which a single post is considered an HMM unit, enriched this technique in addition to the use of e-mails and technical features related to the work."}, {"heading": "3.1 Existing Methods with Minor Enhancements", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1 Conversation Model", "text": "The idea behind it is that it is a way in which people are able to put themselves in the world, in which they are able to understand the world and understand what they want. (...) The idea behind it is that people are able to understand and understand the world. (...) The idea behind it is to understand the world. \"(...) The idea behind it is that people are able to understand and understand the world.\" (...) The idea behind it is that people are able to understand the world in the world in which they live, to understand and to understand the world. (...)"}, {"heading": "3.1.2 Conversation Model with Gaussian Mixtures", "text": "To counteract this, Joty et al. (2011) proposed a method that models HMM emissions as a mixture of Gaussian emissions, i.e., a Gaussian mixing model (GMM). A plate notation of the resulting model is shown in Figure 3.2. Here, a thread Tk consists of a sequence of category labels, and each category label Ci and Gaussian mixture Mi emits a bag of wordgrams Ni corresponding to the i th chronological item in the thread. Apart from preventing topical clusters, the authors argue that this can define finer and thus richer emission distributions. In contrast to the Topic Model-based approach (Ritter et al., 2010), learning and inference with the EM algorithm can take place without approximate interference."}, {"heading": "3.1.3 Fully Supervised Methods", "text": "The accumulation of all characteristics used by existing monitored methods and their adaptation to specific datasets (where necessary) is GMx = 35, a fully monitored method is implemented using Support Vector Machines (SVM) 1. Table 3.2 lists the most representative characteristics used. 1The weka.classifiers.functions.SMO classifier from the Weka toolkit (Hall et al., 2009) is used for implementing SVM.Chapter 3. Description of implemented methods 19 Algorithm 2 Conversation Model with Gaussian Mixtures Input: A list of threads T, each with a list of posts P (in chronological order) Parameters: initialNumericClusters, mertionStates, stateSizeSizeThreshold, maxNumIterations, lmType, inspect 1, inspect 2, numturex: Output: Components Output Output Output: A list of each post (P in laboratories Corder A: Type maxl) in maxels: 1."}, {"heading": "3.2 Proposed Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 Conversation Model with Part-of-Speech Tags", "text": "To overcome this limitation, the conversation model will be improved by modelling emissions partially derived from Part-of-Speech (POS). The proposed model uses POS-n-gram language models in addition to word-n-gram language models and calculates the HMM emission probability of a post using a linear combination of both. Here, the probability of a Post-Pi is calculated taking into account a state Sk as in Equation 3.3.3.p (Pi | Sk) = HMM emission probability of a post using a linear combination of the two."}, {"heading": "3.2.2 Conversation Model with Features", "text": "This model allows for the inclusion of discriminatory features that could be useful in generating clusters that better represent the desired categories. For example, the chronological position of a post in a thread could be a useful feature, as a post is more of a problem if it is the first post in a thread than any other position. Here, the probability of a post Pi when specifying a state Sk is calculated as in Equation 3.4.p (Pi | Sk) = 0j p (Wi, j | Lk) 0f (Fi, f | FLk) (3.4), with: Fi, f being the f (in no particular order) discretely weighted feature in post Pi, and FLk being the feature model for state Sc.Table 3.3 listing the features used in this model. All feature values are discredited. These features include a small subset of features used in the fully monitored facility, and are relatively easy and easy to maintain."}, {"heading": "3.2.3 Conversation Model with Post Embeddings", "text": "To avoid this, it is proposed to use embedding, which is a low-dimensional semantic representation of contributions. Word2Vec2 with improvements, as proposed by Le and Mikolov (2014), can be used to generate embedding of different text lengths. This technique uses a recursive neural network that predicts a word based on its surrounding context. For the current task, this technique is used to 2http: / / code.google.com / p / word2vec / Chapter 3. Description of implemented methods: 24one embedding per post, which can then be used for clustering, leaving the rest of the model unchanged."}, {"heading": "3.2.4 Semi-supervised Conversation Model", "text": "As previously discussed, semi-supervised techniques can use a minimal amount of labeled data to better guide prediction of labels (as opposed to unlabeled clusters for uncontrolled techniques).To achieve this, a modification can be made to the previous models - the priors can be constructed from a small amount of labeled data, rather than clustering all items using vectors of post-n-grams. Specifically, labeled data can be used to initialize the language models and the HMM parameters (output state and state transition probabilities) for the first iteration of the EM algorithm, leaving the rest of the model unaffected."}, {"heading": "3.2.5 Other Enhancements", "text": "All the models discussed above can be combined with each other, except in the case of semi-monitored models with post-embeddings = 3.5. This is because the semi-monitored models calculate priorities from labeled data, while those with post-embeddings use hierarchical clustering of unlabeled data. Also, the following modifications can be made in an attempt to simplify the models and improve performance. Talk models with POS tags require setting a configuration parameter that determines the proportion of probability that comes from voice and POS models in the linear combination. Again, this parameter value (if fixed) is uniformly used across all word and POS programs. However, one could estimate a parameter value specific to a word and a POS tag pair by using frequency numbers from predicted designations during the previous iteration of the EM algorithm."}, {"heading": "3.3 Mapping of Clusters to Categories", "text": "To compare them with an observed category label, a one-to-one mapping was created using six different categories of data, each contained in a two-part chart. In this process, a series of instructions of the two-part charts is calculated, the number of entries predicted as c and which also have a gold label. (2011) Follow the set of manually obtained gold labels. The weight of a border from a cluster label c to a gold label is calculated because the number of entries that are forecast as c and also have a gold label. (2011) Follow the procedure 4Data Collection and AnnotationPrevious work has used forum datasets belonging to the travel and computer-related technical domains (listed in Table 4.1).In addition to these current attempts to observe the performance of post-categorization."}, {"heading": "5.1 Evaluation Measures", "text": "The predicted labels for all items can be evaluated using the appropriate gold labels using metrics such as precision, recall and F1 measurement. In addition, micro-averaged and macro-averaged values of these metrics can indicate overall performance across categories. All valuation metrics are calculated as shown in equations 5.1 to 5.12. In all cases, c is a single category, and CS is the set of all categories. The values of micro-averaged precision, recall recuracy and F1 measurement are the same if the number of predictions is equal to the number of items (i.e., each item is predicted as part of a category). All methods implemented in the current work make a category prediction for each item; therefore, this condition applies. Accuracy, A (c) = # actual c digits predicted as c digits predicted as c + # actual c digits are predicted as c digits (i.e., each item in the current work makes a category prediction for each item; therefore, this condition applies. Accuracy, c = # actual c digits predicted as c digits predicted as c's actual c digits) are predicted as c digits predicted as c digits (i.e. item 5.c each item is not predicted as Macroc's 5.c digits) (i.e., each item is predicted as Macroc's 5.c digits not Macrop)."}, {"heading": "5.2 Experimental Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.1 Preprocessing and Configuration Parameters", "text": "It is important to note that the forum conversations often consist of informal English language texts, and this is accepted as a limitation of the current way of working. All methods, except those that use postbedding, require the conversion of contributions to vector n-grams. To this end, both unigrams and bigrams were tried, and the former was found to produce better performance. Using TF-IDF terms did not direct performance."}, {"heading": "5.2.2 Baselines", "text": "In all datasets reporting results, the solution is the most common gold category. Two other baselines are heuristic in nature, both based on the assumption that the first post in the thread is most likely a problem. The first of these posts, called problem solution heuristic 1, assigns the problem to the first post in the thread, Anders to the last post and Anders to the rest. It assumes that the last post in the thread is most likely unrelated to the main topic of the thread and that many of the previous posts will probably be the solution. The second heuristic baseline, called problem solution heuristic 2, chapter 5. Experiments 36 assign the problem to the first post in the thread, the solution to the second post and the rest of the solution."}, {"heading": "5.3 Main Results", "text": "Table 5.1 lists the micro and macro averaged accuracy values when performing experiments with all possible combinations of the implemented models. For the reported results of the unattended methods, different values of the parameters, initialNumClusters and stateSizeThreshold, were used in each case, because the same values did not result in the desired number of clusters. For example, for the JeepForum dataset, the parameters of the conversation model were: initialNumClusters = 30 and stateSizeThreshold = 25. This resulted in six clusters, the same number of gold label categories. However, the same parameters resulted in a very large number of clusters (15) when used with the conversation model after embedding. Only the best-performing results are reported. For methods performed with the help of GMM, as parameters were randomly initialized, fluctuations in performance across different runs.Therefore, the accuracy values reported above 10 are achieved."}, {"heading": "5.4 Performance Comparison with State-of-the-Art", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.4.1 Unsupervised HMM+Mix Model", "text": "Joty et al. (2011) reported the results of their best-performing HMM + Mix model for classifying dialog files on e-mail and forum thread records, none of which are available to other researchers; their forum thread record contains 200 threads obtained from TripAdvisor (for which they give a macro accuracy of 78.35%); therefore, a data set of almost 200 threads from TripAdvisor (provided by Bhatia et al. (2012)) was also used for performance comparison; however, it should be noted that this record has eight dialog file categories, while Joty et al. (2011) 12. Also, the current conversation model with GMM (called HMM + Mix + +) was used for performance comparison, as it represents an improved fit of the HMM + Mix model. Table 5.2 shows that the proposed conversation model does not intersect with this chapter's U90 POS + MX and MX characteristics directly as compared to the HMM + MX model."}, {"heading": "5.4.2 Semi-supervised Answer Extraction", "text": "Catherine et al. (2013) reported on the performance of their semi-monitored response extraction approach on 300 tagged threads of the Apple Discussion Forum dataset. They trained with only three training threads, but these three are not available to other researchers. Code is also not available. Therefore, for the sake of simplicity, the methods are indirectly compared as follows: For their method, the values given in their paper are used as they are. For the best suggested method (i.e. the semi-monitored conversation models with POS tags and features), a 100-fold cross-validation setup was used (i.e. out of 300 tagged threads, 3 were used for training and 297 for testing). Table 5.3 shows that the values obtained for the proposed method are better in terms of F1 measurement and precision."}, {"heading": "5.5 Category-wise Performance and Error Analysis", "text": "Table 5.4 shows the categorical performance of one of the runs of 5x cross-validation for the JeepForum and Benzworld datasets using the semi-monitored conversation model with POS tags and features. This method exceeded the heuristic problem solving baseline for each category except problem. Table 5.5 shows the confusion matrix of the same experimental folds using the JeepForum dataset. The confusion matrix for the BenzWorld dataset is similar. Furthermore, the most common error was often predicted as a problem, and clarification was predicted as a solution. This seems to be happening because the method towards predicting chapter 5. Experiments 40 is the majority category. This also happened in the case of others, but to a lesser extent. Furthermore, the clarification requirement was often predicted as a problem, and clarification was predicted as a solution. This seems to happen because clarification requirement and clarification can be understood as a clarification requirement and clarification as a specific type of problem and solution."}, {"heading": "5.6 Effect of the Amount of Training Data", "text": "An important measure of the quality of a learning algorithm is whether its performance increases as the amount of training data increases. To evaluate this, multiple n-fold cross-validation experiments were conducted with decreasing n-value, i.e. increasing the number of training threads. Figure 5.1 shows that the performance of the semi-monitored conversation model with POS tags and features on the JeepForum dataset increased with decreasing number of wrinkles. Micro-accuracy is 0.50 when using 10-chapter 5. Experiments show 42-fold cross-validation, showing that approximately 9 labeled threads 1 are sufficient to reasonably predict categories of invisible threads. Similar effects can be seen in the case of other datasets, but to avoid redundancy, they are not shown here. The same method in a fully monitored setup cross-section is even better. Table 5.7 shows its performance in a 10-fold cross-validation setup compared to an equivalent setup used in SVMs."}, {"heading": "5.7 Summary of Experimental Results", "text": "Experimental results indicate that purely unattended methods are not sufficient to tackle a task as complex as forum post categorization, but they are able to capture some sequential dependencies, as evidenced by the fact that they exceeded two trivial baselines (i.e. the random and majority baselines), and performance did not improve completely by using post embedding (1The JeepForum dataset contains 93 threads, of which only 1 / 10 were used in a single 10-fold cross-validation), but knowledge of POS tags and simple text features provided more context for classification and thus enabled the technique to be classified more accurately. A novel suggestion to include a few marked examples to initialize model priorities resulted in better performance than the heuristic baselines of problem solving, and direct comparison with existing methods is not possible due to limitations in the comparison categories."}, {"heading": "6.1 Conclusions", "text": "This paper described the problem of forum post categorization and discussed the need for automatic methods to solve the problem. The relevant previous work was presented and an argument was made for the need for unattended and semi-supervised methods to solve the problem. Subsequently, methods were proposed for categorizing forum posts that differentiate between categories, using language models based on word and part-of-speech probability distributions in addition to manually defined characteristics. Unsupervised methods include the novel use of conversation models previously proposed for other tasks. Although the experimental results show that they are practically useless, they show that they are better than previously proposed methods. Therefore, it can be safely concluded that the current unsupervised methods are not robust enough to capture the complexity of forum post-categorization. Next, it was proposed to use a novel semi-supervised version of the earlier methods, using a few labeled threads to guide the process."}, {"heading": "6.2 Future Work", "text": "In such cases, the post is commented on with a single representative category. Although this may be straightforward for human commentators, the proposed methods do not have any intuition about it. Therefore, it might also be useful to use the summary to maintain the overall meaning of the post and cut out those parts that are not representative. Such methods only need to classify the relevant text in the post and could work better. This problem could also be solved by classifying individual sentences in the posts, rather than the post as a whole. This could be done in a two-step HMM setup, where the first level includes sentence classification, and the second level includes the relevant text in the post and could work better. However, this proposal depends on the availability of individual sentences in the posts rather than looking at the post as a whole. Instead, majority votes or other heuristics could be used in the categories where categories are classified by categories that are classified by categories."}], "references": [{"title": "Inter-coder agreement for computational linguistics", "author": ["Ron Artstein", "Massimo Poesio"], "venue": "Computational Linguistics,", "citeRegEx": "Artstein and Poesio.,? \\Q2008\\E", "shortCiteRegEx": "Artstein and Poesio.", "year": 2008}, {"title": "Catching the drift: Probabilistic content models, with applications to generation and summarization", "author": ["Regina Barzilay", "Lillian Lee"], "venue": "In Proceedings of the 2nd Human Language Technology Conference and Annual Meeting of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Barzilay and Lee.,? \\Q2004\\E", "shortCiteRegEx": "Barzilay and Lee.", "year": 2004}, {"title": "Classifying user messages for managing web forum data", "author": ["Sumit Bhatia", "Prakhar Biyani", "Prasenjit Mitra"], "venue": "In Proceedings of the 15th International Workshop on the Web and Databases", "citeRegEx": "Bhatia et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bhatia et al\\.", "year": 2012}, {"title": "Does similarity matter? The case of answer extraction from technical discussion forums", "author": ["Rose Catherine", "Amit Singh", "Rashmi Gangadharaiah", "Dinesh Raghu", "Karthik Visweswariah"], "venue": "In Proceedings of the 24th International Conference on Computational Linguistics (COLING),", "citeRegEx": "Catherine et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Catherine et al\\.", "year": 2012}, {"title": "Semi-supervised answer extraction from discussion forums", "author": ["Rose Catherine", "Rashmi Gangadharaiah", "Karthik Visweswariah", "Dinesh Raghu"], "venue": "In Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP),", "citeRegEx": "Catherine et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Catherine et al\\.", "year": 2013}, {"title": "Finding question-answer pairs from online forums", "author": ["Gao Cong", "Long Wang", "Chin-Yew Lin", "Young-In Song", "Yueheng Sun"], "venue": "In Proceedings of the 31st Annual International ACM SIGIR Conference,", "citeRegEx": "Cong et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cong et al\\.", "year": 2008}, {"title": "Unsupervised classification of dialogue acts using a Dirichlet process mixture model", "author": ["Nigel Crook", "Ramon Granell", "Stephen Pulman"], "venue": "In Proceedings of the 10th Annual Meeting of the Special Interest Group on Discourse and Dialogue,", "citeRegEx": "Crook et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Crook et al\\.", "year": 2009}, {"title": "Unsupervised solution post identification from discussion forums", "author": ["P Deepak", "Karthik Visweswariah"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Deepak and Visweswariah.,? \\Q2014\\E", "shortCiteRegEx": "Deepak and Visweswariah.", "year": 2014}, {"title": "Using conditional random fields to extract contexts and answers of questions from online forums", "author": ["Shilin Ding", "Gao Cong", "Chin-yew Lin Xiaoyan"], "venue": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies", "citeRegEx": "Ding et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ding et al\\.", "year": 2008}, {"title": "The WEKA data mining software: an update", "author": ["Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten"], "venue": "ACM SIGKDD Explorations Newsletter,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Semi-supervised speech act recognition in emails and forums", "author": ["Minwoo Jeong", "CY Lin", "GG Lee"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Jeong et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jeong et al\\.", "year": 2009}, {"title": "Unsupervised modeling of dialog acts in asynchronous conversations", "author": ["Shafiq Joty", "Giuseppe Carenini", "Chin Yew Lin"], "venue": "In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Joty et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Joty et al\\.", "year": 2011}, {"title": "Tagging and linking web forum posts", "author": ["Su Nam Kim", "Li Wang", "Timothy Baldwin"], "venue": "In Proceedings of the 14th Conference on Computational Natural Language Learning (CoNLL),", "citeRegEx": "Kim et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2010}, {"title": "The Hungarian method for the assignment problem", "author": ["Harold W Kuhn"], "venue": "Naval Research Logistics Quarterly,", "citeRegEx": "Kuhn.,? \\Q1955\\E", "shortCiteRegEx": "Kuhn.", "year": 1955}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc Le", "Tomas Mikolov"], "venue": "In Proceedings of the 31st International Conference on Machine Learning (ICML),", "citeRegEx": "Le and Mikolov.,? \\Q2014\\E", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,", "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Algorithms for the assignment and transportation problems", "author": ["James Munkres"], "venue": "Journal of the Society for Industrial and Applied Mathematics,", "citeRegEx": "Munkres.,? \\Q1957\\E", "shortCiteRegEx": "Munkres.", "year": 1957}, {"title": "Finding problem solving threads in online forum", "author": ["Zhonghua Qu", "Yang Liu"], "venue": "In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP),", "citeRegEx": "Qu and Liu.,? \\Q2011\\E", "shortCiteRegEx": "Qu and Liu.", "year": 2011}, {"title": "Unsupervised modeling of Twitter conversations", "author": ["Alan Ritter", "Colin Cherry", "Bill Dolan"], "venue": "In Proceedings of the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Ritter et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2010}, {"title": "Not all character ngrams are created equal: a study in authorship attribution", "author": ["Upendra Sapkota", "Steven Bethard", "Manuel Montes-y G\u00f3mez"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Sapkota et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sapkota et al\\.", "year": 2015}, {"title": "Shallow information extraction from medical forum data", "author": ["Parikshit Sondhi", "Manish Gupta", "Chengxiang Zhai", "Julia Hockenmaier"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),", "citeRegEx": "Sondhi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sondhi et al\\.", "year": 2010}, {"title": "Dialogue act modeling for automatic tagging and recognition of conversational speech", "author": ["Andreas Stolcke", "Klaus Ries", "Noah Coccaro", "Elizabeth Shriberg", "Rebecca Bates", "Daniel Jurafsky", "Paul Taylor", "Rachel Martin", "Carol Van Ess-Dykema", "Marie Meteer"], "venue": "Computational Linguistics,", "citeRegEx": "Stolcke et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Stolcke et al\\.", "year": 2000}, {"title": "Thread-level analysis over technical user forum data", "author": ["Li Wang", "Su Nam Kim", "Timothy Baldwin"], "venue": "In Proceedings of the Australasian Language Technology Association Workshop,", "citeRegEx": "Wang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2010}, {"title": "Predicting thread discourse structure over technical web forums", "author": ["Li Wang", "Marco Lui", "Su Nam Kim", "Joakim Nivre", "Timothy Baldwin"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 21, "context": "It is closely related to the problem of dialogue act tagging, which is defined as the identification of the meaning of an utterance at the level of illocutionary force (Stolcke et al., 2000), i.", "startOffset": 168, "endOffset": 190}, {"referenceID": 2, "context": "(2010) Tagset: Question, Question-Add, Question-Confirmation, Question-Correction, Answer, Answer-Add, Answer-Confirmation, Answer-Correction, Answer-Objection, Resolution, Reproduction, Other Classifier: CRF Features: Lexical, structural, post context, semantic Dataset: CNET (computer-related technical domain) Qu and Liu (2011) Tagset: Problem, Solution, Good Feedback, Bad Feedback Classifier: HMM Features: Bag-of-words Dataset: Oracle database (computer-related technical domain) Catherine et al. (2012) Tagset: Answer Classifier: SVM Features: Structural, syntactic, author authority, post ratings Dataset: Apple (computer-related technical domain) Bhatia et al.", "startOffset": 486, "endOffset": 510}, {"referenceID": 2, "context": "(2012) Tagset: Answer Classifier: SVM Features: Structural, syntactic, author authority, post ratings Dataset: Apple (computer-related technical domain) Bhatia et al. (2012) Tagset: Question, Repeat Question, Clarification, Solution, Further Details, Positive Feedback, Negative Feedback, Spam Classifiers: SVM, logit model Features: Structural, content, sentiment, number of posts by user, user authority Datasets: Ubuntu (computer-related technical domain), TripAdvisor-NYC (travel domain)", "startOffset": 153, "endOffset": 174}, {"referenceID": 2, "context": "Catherine et al. (2012) employed Support Vector Machines (SVMs) to extract Answer posts in a thread (assuming that the first post in the thread is a Question).", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Bhatia et al. (2012) used supervised machine learning algorithms (i.", "startOffset": 0, "endOffset": 21}, {"referenceID": 2, "context": "Bhatia et al. (2012) used supervised machine learning algorithms (i.e., SVMs, logit model classifier, naive Bayes, etc.) to classify forum posts into eight categories \u2014 Question, Repeat Question, Clarification, Further Details, Solution, Positive Feedback, Negative Feedback, and Junk. They evaluated their methods on a dataset of the Ubuntu forums. Qu and Liu (2011) used Hidden Markov Models (HMMs) to classify forum posts into four categories \u2014 Problem, Solution, Good Feedback and Bad Feedback.", "startOffset": 0, "endOffset": 368}, {"referenceID": 2, "context": "Bhatia et al. (2012) used supervised machine learning algorithms (i.e., SVMs, logit model classifier, naive Bayes, etc.) to classify forum posts into eight categories \u2014 Question, Repeat Question, Clarification, Further Details, Solution, Positive Feedback, Negative Feedback, and Junk. They evaluated their methods on a dataset of the Ubuntu forums. Qu and Liu (2011) used Hidden Markov Models (HMMs) to classify forum posts into four categories \u2014 Problem, Solution, Good Feedback and Bad Feedback. They evaluated their methods on the Oracle database support forums. Similarly, Wang et al. (2010) attempted to identify Problem and Solution posts in the CNET forums dataset, but with more fine-grained categories based on the types of Problem posts (i.", "startOffset": 0, "endOffset": 597}, {"referenceID": 2, "context": "Bhatia et al. (2012) used supervised machine learning algorithms (i.e., SVMs, logit model classifier, naive Bayes, etc.) to classify forum posts into eight categories \u2014 Question, Repeat Question, Clarification, Further Details, Solution, Positive Feedback, Negative Feedback, and Junk. They evaluated their methods on a dataset of the Ubuntu forums. Qu and Liu (2011) used Hidden Markov Models (HMMs) to classify forum posts into four categories \u2014 Problem, Solution, Good Feedback and Bad Feedback. They evaluated their methods on the Oracle database support forums. Similarly, Wang et al. (2010) attempted to identify Problem and Solution posts in the CNET forums dataset, but with more fine-grained categories based on the types of Problem posts (i.e., Hardware, Software, Media, OS, Network, and Programming) and Solution posts (i.e., Documentation, Install, Search, and Support). Kim et al. (2010) worked on the same dataset, and attempted to classify posts into 12 categories that are similar to the ones used by Bhatia et al.", "startOffset": 0, "endOffset": 902}, {"referenceID": 2, "context": "Bhatia et al. (2012) used supervised machine learning algorithms (i.e., SVMs, logit model classifier, naive Bayes, etc.) to classify forum posts into eight categories \u2014 Question, Repeat Question, Clarification, Further Details, Solution, Positive Feedback, Negative Feedback, and Junk. They evaluated their methods on a dataset of the Ubuntu forums. Qu and Liu (2011) used Hidden Markov Models (HMMs) to classify forum posts into four categories \u2014 Problem, Solution, Good Feedback and Bad Feedback. They evaluated their methods on the Oracle database support forums. Similarly, Wang et al. (2010) attempted to identify Problem and Solution posts in the CNET forums dataset, but with more fine-grained categories based on the types of Problem posts (i.e., Hardware, Software, Media, OS, Network, and Programming) and Solution posts (i.e., Documentation, Install, Search, and Support). Kim et al. (2010) worked on the same dataset, and attempted to classify posts into 12 categories that are similar to the ones used by Bhatia et al. (2012). Additionally, they tagged the links between posts, i.", "startOffset": 0, "endOffset": 1039}, {"referenceID": 3, "context": "According to Catherine et al. (2012), author authority is a numerical or categorical value that is indicative of an author\u2019s level of expertise in the context of the forum.", "startOffset": 13, "endOffset": 37}, {"referenceID": 20, "context": "Wang et al. (2011) went one step further by jointly classifying both posts and the links between them.", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "Ding et al. (2008) used CRFs to identify Answer posts and the context in which they answered the Question post.", "startOffset": 0, "endOffset": 19}, {"referenceID": 8, "context": "Ding et al. (2008) used CRFs to identify Answer posts and the context in which they answered the Question post. However, they did not attempt to identify Question posts, because they were assumed to be known beforehand. Their techniques were evaluated on a corpus of the TripAdvisor forums. Sondhi et al. (2010) used CRFs and SVMs with various semantic and structural features to identify Medical Problem and Treatment in the HealthBoards forums.", "startOffset": 0, "endOffset": 312}, {"referenceID": 5, "context": "Cong et al. (2008) used labeled sequential patterns to identify Question posts, followed by a graph-based propagation method to extract corresponding Answer posts.", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "Other unsupervised techniques have been employed for the related tasks of dialogue act classification in spoken dialogue systems (Crook et al., 2009) and Twitter conversations (Ritter et al.", "startOffset": 129, "endOffset": 149}, {"referenceID": 18, "context": ", 2009) and Twitter conversations (Ritter et al., 2010).", "startOffset": 34, "endOffset": 55}, {"referenceID": 6, "context": "Deepak and Visweswariah (2014) identified Solution posts using a translation-based model that leverages lexical correlations between Problem and Solution posts.", "startOffset": 0, "endOffset": 31}, {"referenceID": 6, "context": "Deepak and Visweswariah (2014) identified Solution posts using a translation-based model that leverages lexical correlations between Problem and Solution posts. Joty et al. (2011) used a combination of HMMs and Gaussian Mixture Models (GMMs) in order to classify forum posts into 12 dialogue act categories.", "startOffset": 0, "endOffset": 180}, {"referenceID": 10, "context": "One employed domain adaptation from labeled spoken dialogue datasets by means of a sub-tree pattern mining algorithm (Jeong et al., 2009).", "startOffset": 117, "endOffset": 137}, {"referenceID": 4, "context": "Another method extracted Answer posts in forum threads using a co-training framework (Catherine et al., 2013).", "startOffset": 85, "endOffset": 109}, {"referenceID": 1, "context": "Barzilay and Lee (2004) proposed a content model for multi-document summarization based on sentence extraction.", "startOffset": 0, "endOffset": 24}, {"referenceID": 1, "context": "Barzilay and Lee (2004) proposed a content model for multi-document summarization based on sentence extraction. This model consists of an HMM at the sentence level that is tailored towards identifying sentence clusters belonging to different topics. Inspired by this model, Ritter et al. (2010) suggested a \u2018conversation model\u2019 for the modeling of dialogue acts in Twitter conversations.", "startOffset": 0, "endOffset": 295}, {"referenceID": 1, "context": "Barzilay and Lee (2004) proposed a content model for multi-document summarization based on sentence extraction. This model consists of an HMM at the sentence level that is tailored towards identifying sentence clusters belonging to different topics. Inspired by this model, Ritter et al. (2010) suggested a \u2018conversation model\u2019 for the modeling of dialogue acts in Twitter conversations. Their model replicates Barzilay\u2019s model but replaces sentences in a document with tweets in a Twitter conversation as units of the HMM. They used Topic Modeling (using Latent Dirichlet Allocation) along with the conversation model and reported better performance; but the evaluation was done only qualitatively. Similarly, Joty et al. (2011) applied conversation models to email and forum threads where a single post is considered an HMM unit.", "startOffset": 0, "endOffset": 730}, {"referenceID": 1, "context": "While there are three different variants of this model (as described in the previous chapter), this work implements the originally proposed model by Barzilay and Lee (2004), while making necessary modifications for applying it to forum post categorization.", "startOffset": 149, "endOffset": 173}, {"referenceID": 17, "context": "1 (derived from Ritter et al. (2010) and Joty et al.", "startOffset": 16, "endOffset": 37}, {"referenceID": 11, "context": "(2010) and Joty et al. (2011)).", "startOffset": 11, "endOffset": 30}, {"referenceID": 18, "context": "Also, in contrast to the Topic Model-based approach (Ritter et al., 2010), learning and inference can be done using the EM algorithm without approximate inference techniques.", "startOffset": 52, "endOffset": 73}, {"referenceID": 11, "context": "To counter this, Joty et al. (2011) proposed a method which models the HMM emissions as a mixture of Gaussians, i.", "startOffset": 17, "endOffset": 36}, {"referenceID": 9, "context": "SMO classifier from the Weka toolkit (Hall et al., 2009) is used for implementing SVM.", "startOffset": 37, "endOffset": 56}, {"referenceID": 14, "context": "Word2Vec, with enhancements as proposed by Le and Mikolov (2014), can be used to generate embeddings of variable lengths of text.", "startOffset": 43, "endOffset": 65}, {"referenceID": 19, "context": "Also, they have been a very useful discriminative feature in the area of authorship attribution, because they seem to account for lexical, syntactic, and stylistic information (Sapkota et al., 2015).", "startOffset": 176, "endOffset": 198}, {"referenceID": 13, "context": "In order to match them with an observed category label, a one-to-one mapping is obtained using Kuhn-Munkres algorithm for maximal weighting in a bipartite graph (Kuhn, 1955; Munkres, 1957).", "startOffset": 161, "endOffset": 188}, {"referenceID": 16, "context": "In order to match them with an observed category label, a one-to-one mapping is obtained using Kuhn-Munkres algorithm for maximal weighting in a bipartite graph (Kuhn, 1955; Munkres, 1957).", "startOffset": 161, "endOffset": 188}, {"referenceID": 11, "context": "Joty et al. (2011) follow the same procedure.", "startOffset": 0, "endOffset": 19}, {"referenceID": 2, "context": "Ubuntu (Bhatia et al., 2012) Domain: Computer technical Tagset: Question, Repeat Question, Clarification, Solution, Further Details, Positive Feedback, Negative Feedback, Spam Number of threads: 100 TripAdvisor-NYC (Bhatia et al.", "startOffset": 7, "endOffset": 28}, {"referenceID": 2, "context": ", 2012) Domain: Computer technical Tagset: Question, Repeat Question, Clarification, Solution, Further Details, Positive Feedback, Negative Feedback, Spam Number of threads: 100 TripAdvisor-NYC (Bhatia et al., 2012) Domain: Travel Tagset: Same as Ubuntu Number of threads: 100 Apple (Catherine et al.", "startOffset": 194, "endOffset": 215}, {"referenceID": 3, "context": ", 2012) Domain: Travel Tagset: Same as Ubuntu Number of threads: 100 Apple (Catherine et al., 2012) Domain: Computer technical Tagset: Answer Number of threads: 300 labeled and 140,000 unlabeled", "startOffset": 75, "endOffset": 99}, {"referenceID": 12, "context": "Kim et al. (2010) use a tagset of 12 categories \u2014 Question, Question-Add, Question-Confirmation, Question-Correction, Answer, Answer-Add, Answer-Confirmation, Answer-Correction, Answer-Objection, Resolution, Reproduction, and Other.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "Hence, instead of using standard annotation quality measures like Scott\u2019s \u03c0 and Fleiss\u2019s \u03ba, Krippendorf\u2019s \u03b1 is reported, which can account for missing values (Artstein and Poesio, 2008).", "startOffset": 158, "endOffset": 185}, {"referenceID": 15, "context": "Initially, all forum posts were tokenized by sentence and word, followed by POS tagging and stemming \u2014 all using Stanford CoreNLP Toolkit (Manning et al., 2014).", "startOffset": 138, "endOffset": 160}, {"referenceID": 2, "context": "Hence, for performance comparison, the current work also used a dataset of nearly 200 threads from TripAdvisor (made available by Bhatia et al. (2012)).", "startOffset": 130, "endOffset": 151}, {"referenceID": 2, "context": "Hence, for performance comparison, the current work also used a dataset of nearly 200 threads from TripAdvisor (made available by Bhatia et al. (2012)). As a caveat, it is important to note that this dataset has eight dialogue act categories, whereas Joty et al. (2011) consider 12.", "startOffset": 130, "endOffset": 270}, {"referenceID": 3, "context": "Precision Recall F1-measure Catherine et al. (2013) 0.", "startOffset": 28, "endOffset": 52}], "year": 2016, "abstractText": "Semi-supervised and unsupervised methods for categorizing posts in Web discussion forums Krish Perumal Master of Science Graduate Department of Computer Science University of Toronto 2016 Web discussion forums are used by millions of people worldwide to share information belonging to a variety of domains such as automotive vehicles, pets, sports, etc. They typically contain posts that fall into different categories such as problem, solution, feedback, spam, etc. Automatic identification of these categories can aid information retrieval that is tailored for specific user requirements. Previously, a number of supervised methods have attempted to solve this problem; however, these depend on the availability of abundant training data. A few existing unsupervised and semi-supervised approaches are either focused on identifying a single category or do not report category-specific performance. In contrast, this work proposes unsupervised and semi-supervised methods that require no or minimal training data to achieve this objective without compromising on performance. A fine-grained analysis is also carried out to discuss their limitations. The proposed methods are based on sequence models (specifically, Hidden Markov Models) that can model language for each category using word and part-of-speech probability distributions, and manually specified features. Empirical evaluations across domains demonstrate that the proposed methods are better suited for this task than existing ones.", "creator": "LaTeX with hyperref package"}}}