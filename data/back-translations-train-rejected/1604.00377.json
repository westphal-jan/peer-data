{"id": "1604.00377", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2016", "title": "Reinforcement learning based local search for grouping problems: A case study on graph coloring", "abstract": "Grouping problems aim to partition a set of items into multiple mutually disjoint subsets according to some specific criterion and constraints. Grouping problems cover a large class of important combinatorial optimization problems that are generally computationally difficult. In this paper, we propose a general solution approach for grouping problems, i.e., reinforcement learning based local search (RLS), which combines reinforcement learning techniques with descent-based local search. The viability of the proposed approach is verified on a well-known representative grouping problem (graph coloring) where a very simple descent-based coloring algorithm is applied. Experimental studies on popular DIMACS and COLOR02 benchmark graphs indicate that RLS achieves competitive performances compared to a number of well-known coloring algorithms.", "histories": [["v1", "Fri, 1 Apr 2016 19:38:35 GMT  (340kb)", "http://arxiv.org/abs/1604.00377v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["yangming zhou", "jin-kao hao", "b\\'eatrice duval"], "accepted": false, "id": "1604.00377"}, "pdf": {"name": "1604.00377.pdf", "metadata": {"source": "CRF", "title": "Reinforcement learning based local search for grouping problems: A case study on graph coloring", "authors": ["Yangming Zhou", "Jin-Kao Hao", "B\u00e9atrice Duval"], "emails": ["zhou.yangming@yahoo.com", "hao@info.univ-angers.fr", "bd@info.univ-angers.fr"], "sections": [{"heading": null, "text": "ar Xiv: 160 4.00 377v 1 [cs.A I] Grouping problems are aimed at dividing a series of items into several mutually resolving subsets according to some specific criteria and constraints. Grouping problems cover a large class of important combinatorial optimization problems, which are generally mathematically difficult. In this paper, we propose a general approach to grouping problems, i.e. a very simple descent-based local search (RLS) that combines attachment techniques with descent-based local search. Experimental studies on popular DIMACS and COLOR02 benchmark diagrams show that RLS achieves competitive performance compared to a number of well-known coloring algorithms: grouping and enhancement;"}, {"heading": "1 Introduction", "text": "In fact, it is so that most people are able to understand themselves and understand what they are doing. (...) In fact, it is so that they are able to survive themselves. \"(...)\" It is not so, as if. \"(...)\" It is so, as if. \"(...)\" It is so, as if. \"(...)\" It is so, as if. \"(...)\" \"It is so, as if.\" (...) \"(...)\" (...) \"(...)\" (...) \"(...)\" (...) \"()\" () \"().\" () \"()\" () \"()\" () \"(). ()\" () \"()\" (). () \"()\" (). () \"() () ((). ()\" () \"(). () () (().\" () ()."}, {"heading": "2 Reinforcement learning and heuristic search", "text": "In this section, we briefly present the principles of reinforcement learning (RL) and give an overview of some representative examples of the use of reinforcement learning to solve combinatorial optimization problems."}, {"heading": "2.1 Reinforcement learning", "text": "Reinforcement learning is a learning pattern that aims to learn optimal actions from a limited number of available actions through continuous interaction with an unknown environment. In contrast to supervised learning techniques, reinforcement learning does not require an experienced agent to indicate the right path, but adapts its future actions based on the feedback signal received from the environment [18]. There are three key elements in an RL agent, i.e. states, actions and rewards. At any time, an RL agent observes the current state and performs an action from the amount of available actions for the current state. As soon as an action is performed, the RL agent switches to a new state based on transitional probabilities. Accordingly, a feedback signal is sent back to the RL agent to inform him of the quality of his actions performed."}, {"heading": "2.2 Reinforcement learning and heuristic search", "text": "There are a number of studies in the literature in which amplification techniques are put at the service of heuristic algorithms to solve combinatorial problems. Amplification techniques in these studies have been explored at three different levels. Heuristic level, where RL is used directly as heuristics to solve optimization problems. In this case, RL techniques are used to match the values to the variables. For example, the authors of [35] are proposed to solve combinatorial optimization problems based on a population of RL agents. Pairs of variables and values are considered as RL states, and the branched strategies as actions. Each RL agent is assigned to a specific area in which he learns and finds good local solutions. Meta-heuristic level, where RL agents are integrated."}, {"heading": "3 Reinforcement learning based local search for grouping problems", "text": "For our RLS approach, we assume that the number of groups k is given in advance. Note that such an assumption is not necessarily restrictive. To solve a grouping problem with the variable k, you can repeatedly run RLS with different k values. We will illustrate this approach with the problem of graph coloring in Section 4."}, {"heading": "3.1 Main scheme", "text": "By combining attachment techniques with a solution improvement method, our proposed RLS approach consists of four key components: a descent-oriented local search method, a group selection strategy, a probability update mechanism (i.e., attachment learning mechanism), and a probability smoothing technique. We define a probability matrix P of the size n \u00d7 k (n is the number of items and k is the number of groups, see Figure 1 for an example).An element pij denotes the probability that the i-th item vi selects the j-th group gj as its group. Therefore, the i-th series of the probability matrix defines the probability vector of the i-th item and is denoted by pi-te. Initially, all probability values in the probability matrix are set as 1 / k."}, {"heading": "3.2 Group selection", "text": "For each iteration of RLS, each element vi must select a group gj from the k available groups according to their probability vector pi. We consider four possible group selection strategies: \u2022 Random selection: the element randomly selects its group (regardless of whether it is a pseudo-code of our RLS for selecting group problems. \u2022 Random selection: the element randomly selects its group. \u2022 3: for all vi, i = 1, 2,..., n do 4: P0 = [pij = 1 / k] Random probability: the probability randomly; k: the end for 6: repeat probability 7: h"}, {"heading": "3.3 Descent-based local search for solution improvement", "text": "Even if any optimization method can be used to improve a given starting group solution. > For the sake of simplicity, we use a simple and fast descend-based local search method (DB-LS) in this work. To explore the search space, DB-LS iteratively makes transitions from the established solution to an adjacent solution according to a given neighborhood relationship, so that each transition leads to a better solution. This iterative improvement process continues until no improved solution exists in the neighborhood. In this case, the existing solution corresponds to a local optimization in relation to the neighborhood. Let's name the search space of the given grouping problem so that each transition leads to a better solution. Let's pursue the neighborhood relationship associated with each solution. N (S) is a subset of solutions (i.e. N (S) is the set of adjacent solutions of S)."}, {"heading": "3.4 Reinforcement learning - probability updating", "text": "Reinforcement learning is defined as the way an agent should take action in an environment to maximize a certain notion of cumulative reward. Reinforcement learning works best by interacting trial and error with an unknown environment. Actions can affect not only the immediate reward, but also the next situation and all subsequent rewards. Through interactions with the unknown environment, RLS develops and progressively finds the optimal or suboptimal solution to the problem. At the moment t we first create a grouping solution St based on the current probability matrix Pt (see Section 3.1). In other words, each item selects a suitable group from among the available groups based on its probability vectors (using the group selection strategy of Sect. 3.2). Then the solution St is improved by the local search process leading to an improved reward solution."}, {"heading": "3.5 Reinforcement learning - probability smoothing", "text": "The intuition behind the probability smoothing technique is that old decisions made a long time ago are no longer helpful and can mislead the current search. Therefore, these aged decisions should be considered less important than recent ones. Furthermore, all elements are required to properly select their appropriate groups to produce a legal grouping technology. It is not enough that only a part of the items can correctly select their groups. Based on these two reasons, we introduce a probability smoothing technology to periodically decrease group probabilities. Our probability smoothing technology is inspired by forgetting mechanisms for smoothing techniques in the clause weighting of local search algorithms for the satisfaction probability (SAT) [23.25]. Based on the way weights are smoothed or forgotten, there are four available shaping or smoothing techniques for MVC and one of the weights is greater than one of the AWS \u2022 weights."}, {"heading": "4 RLS applied to graph coloring: a case study", "text": "This section presents an application of the proposed RLS method to the known graph coloring problem, which is a typical grouping problem. After presenting the descent-based local search method for the problem, we first perform an experimental analysis of the RLS approach by examining the influence of its three important components, i.e. the reinforcement learning mechanism, the probability smoothing technique, and the group selection strategy. We then present the calculation results obtained with the proposed RLS method compared to a number of existing local search algorithms via known DIMACS and COLOR02 benchmark instances."}, {"heading": "4.1 Graph coloring and local search coloring algorithm", "text": "GCP is one of the most studied combination optimization problems [17]. GCP is also a nice representative of grouping problems. In view of an undirected graph G = (V, E), where V should determine the number of indentations and indentations and E the number of different color classes, a legal K-coloring of G is a division of V into different groups or color classes required for a legal coloring. (G) When the number of color classes is fixed, the problem is called k-coloring problem (k-GCP for short). Since there is a grouping problem, the elements correspond to the indentations and groups."}, {"heading": "4.2 Benchmark instances and experimental settings", "text": "The DIMACS diagrams used can be divided into six types: \u2022 Standard random diagrams are referred to as DSJCn.x, where n is the number of wells in the diagram. \u2022 The chromatic number of these diagrams is unknown. \u2022 Random geometric diagrams are made up of R125.x, R250.x, DSJR500.x and R1000.x, diagrams with letters c representing additions to the geometric diagrams. \u2022 Flat diagrams are produced on the basis of an equi partitioning of wells in k-sets. These types of diagrams are referred to as flat n-k 0, where n and k are the number of wells of wells and chromatic numbers respectively. \u2022 Leighton diagrams are structured diagrams created on the basis of an equi partitioning of wells in k-sets."}, {"heading": "4.3 Analysis of key components of the RLS approach", "text": "We will first present an analysis of the main components of the RLS approach: reinforcement learning mechanisms, probability smoothing techniques and group selection strategies. This study will allow us to better understand the behaviour of the proposed RLS approach and shed light on its inner workings."}, {"heading": "4.3.1 Effectiveness of the reinforcement learning mechanism", "text": "In order to verify the effectiveness of the reinforcement learning mechanism used in RLS, we perform a comparison between RLS and its variant RLS0, where we have removed the reinforcement learning mechanism from RLS and restart the search at random if the DB-LS method achieves a local optimum. The investigation was carried out on the 32 DIMACS instances and each algorithm was performed 20 times to solve each instances. The comparison results of RLS and RLS0 are in Table 2. For each graph, we list the known chromatic number or the best K instance reported in the literature, if it is still unknown. For each algorithm, we specify the number of the best (smallest) k value for which the algorithm achieves a legal k coloration, and the number of such successful runs over 20 executions (# hit). The differences between the best k of RL0 and the best of RLS are shown in the last column."}, {"heading": "4.3.2 Effectiveness of the probability smoothing technique", "text": "To investigate the effectiveness of the probability smoothing method used in RLS, we compare RLS with its alternative RLS1 algorithm, which is obtained by RLS by adapting the probability update scheme. Specifically, RLS1 works in the same way as RLS, but does not use the probability smoothing strategy, i.e. line 12 in algorithm 1. For this experiment, we use running profiles to observe the change in the weighting function f across the number of iterations. Running profiles provide interesting information about the convergence of the investigated algorithms. The running profiles of RLS and RLS1 are shown in Figure 3 at two selected instances: Figure 3 (a) for flat 300 28 0 (k = 32) and Figure 3 (b) for Latin squares 10 (k = 101). We note that both algorithms successfully achieve a legal k-coloring, RLS1 converts to the best solution as RLS."}, {"heading": "4.3.3 Comparison of different group selection strategies", "text": "In this section we present an analysis of the group selection strategies to confirm the interest of the chosen hybrid strategy, which combines random and greedy strategies.The study was conducted between RLS and its variant RLS2, which is won by RLS by replacing the strategy of hybrid group selection with the strategy of roulette wheel selection.In the experiment, each instance was independently tested 20 times with different random seeds.The number of successful runs, the average number of runs and the average duration of successful runs are reported.Table 3 shows comparative results of RLS with RLS2 for the selected instances. Results indicate that RLS significantly exceeds RLS2 in terms of the best k-value and the average duration of successful runs."}, {"heading": "4.4 Computational results of RLS and comparisons", "text": "In this context, it should be noted that the solution to problems that have arisen in the past is not a solution, but a solution that was primarily in the past."}, {"heading": "5 Conclusion and discussion", "text": "In this paper, we have proposed an enhancement of learning based on optimization problems. The proposed RLS approach combines enhancement techniques with a descent-oriented local search method. Reinforcement learning is used to obtain and update a set of probability vectors. RLS then applies a descent-oriented local search method to improve the given group solution until a local optimum is reached. At this point, the initial solutions and the ending local solution are compared to update the probability vectors."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the PGMO project (2014-2015, Jacques Hadamard Mathematical Foundation, Paris) and the financial support for Yangming Zhou by the China Scholarship Council (CSC, 2014-2018) is recognized."}], "references": [{"title": "A new grouping genetic algorithm for clustering problems", "author": ["L. Agustn-Blas", "S. Salcedo-Sanz", "S. Jim\u00e9nez-Fern\u00e1ndez", "L. Carro-Calvo", "J.D. Ser", "J. Portilla-Figueras"], "venue": "Expert Systems with Applications,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "A cellular learning automatabased algorithm for solving the vertex coloring problem", "author": ["J.A. Torkestani", "M.R. Meybodi"], "venue": "Expert Systems with Applications,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Statistical machine learning for large-scale optimization", "author": ["S. Baluja", "A. Barto", "K. Boese", "J. Boyan", "W. Buntine", "T. Carson", "R. Caruana", "D. Cook", "S. Davies", "T. Dean"], "venue": "Neural Computing Surveys,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "The LION way. Machine Learning plus Intelligent Optimization, LIONlab", "author": ["R. Battiti", "M. Brunato"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Learning evaluation functions to improve optimization by local search", "author": ["J.A. Boyan", "A.W. Moore"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "An ant-based algorithm for coloring graphs", "author": ["T.N. Bui", "T.H. Nguyen", "C.M. Patel", "K.T. Phan"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "A Tabu-Search Hyper-heuristic for Timetabling and Rostering", "author": ["E. Burke", "G. Kendall", "E. Soubeiga"], "venue": "Journal of Heuristics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "NuMVC: An efficient local search algorithm for minimum vertex cover", "author": ["S. Cai", "K. Su", "C. Luo", "A. Sattar"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "The Plackett-Luce ranking model on permutation-based optimization problems", "author": ["J. Ceberio", "A. Mendiburu", "J.A. Lozano"], "venue": "Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Stochastic local search methods for highly constrained combinatorial optimisation problems, Ph.D", "author": ["M. Chiarandini"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "An application of iterated local search to graph coloring problem", "author": ["M. Chiarandini", "T. St\u00fctzle"], "venue": "Proceedings of the Computational Symposium on Graph Coloring and its Generalizations,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "A grouping hyper-heuristic framework: Application on graph coloring", "author": ["A. Elhag", "E. \u00d6zcan"], "venue": "Expert Systems with Applications,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Genetic Algorithms and Grouping Problems", "author": ["E. Falkenauer"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Genetic and hybrid algorithms for graph coloring", "author": ["C. Fleurent", "J. Ferland"], "venue": "Annals of Operations Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1996}, {"title": "Hybrid evolutionary algorithms for graph coloring", "author": ["P. Galinier", "J.K. Hao"], "venue": "Journal of Combinatorial Optimization,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Recent advances in graph vertex coloring", "author": ["P. Galinier", "J.P. Hamiez", "J.K. Hao", "D. Porumbel"], "venue": "In Handbook of optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Computers and Intractability: A Guide to the Theory of NP-Completness", "author": ["M. Garey", "D. Johnson"], "venue": "W.H. Freeman and Co.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1979}, {"title": "Reinforcement learning: A tutorial survey and recent advances", "author": ["A. Gosavi"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "A multi-agent based selfadaptive genetic algorithm for the long-term car pooling problem", "author": ["Y. Guo", "G. Goncalves", "T. Hsu"], "venue": "Journal of Mathematical Modelling and Algorithms in Operations Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Particle Swarm Algorithm variants for the Quadratic Assignment Problems - A probabilistic learning approach", "author": ["F. Hafiz", "A. Abdennour"], "venue": "Expert Systems with Applications,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "An analysis of solution properties of the graph coloring problem. Metaheuristics: Computer Decision-Making, Chapter 15, pp325-346", "author": ["J.P. Hamiez", "J.K. Hao"], "venue": "Resende M.G.C. and de Sousa J.P. (Eds.), Kluwer", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1993}, {"title": "Using tabu search techniques for graph", "author": ["A. Hertz", "D. de Werra"], "venue": "coloring, Computing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1987}, {"title": "Scaling and probabilistic smoothing: efficient dynamic local search for SAT, Principles and Practice of Constraint Programming", "author": ["F. Hutter", "D.A.D. Tompkins", "H.H. Hoos"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2002}, {"title": "Algorithm runtime prediction: methods & evaluation", "author": ["F. Hutter", "L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Neighbourhood clause weight redistribution in local search for SAT, Principles and Practice of Constraint Programming", "author": ["A. Ishtaiwi", "J. Thornton", "A. Sattar", "D.N. Pham"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Optimization by simulated annealing: an experimental evaluation; part II, graph coloring and number partitioning", "author": ["D.S. Johnson", "C.R. Aragon", "L.A. McGeoch", "C. Schevon"], "venue": "Operations Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1991}, {"title": "Cliques, Coloring, and Satisfiability", "author": ["D.S. Johnson", "Trick M"], "venue": "DIMACS Series in Discrete Math. and Theor. Comput. Sci. ,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1996}, {"title": "A particle swarm optimizer for grouping problems", "author": ["A.H. Kashan", "M.H. Kashan", "S. Karimiyan"], "venue": "Information Sciences,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "A general-purpose hill-climbing method for order independent minimum grouping problems: A case study in graph colouring and bin packing", "author": ["R. Lewis"], "venue": "Computers & Operations Research,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "Finding feasible timetables using group-based operators, Evolutionary Computation", "author": ["R. Lewis", "B. Paechter"], "venue": "IEEE Transactions on,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "A memetic algorithm for graph coloring", "author": ["Z. L\u00fc", "J. Hao"], "venue": "European Journal of Operational Research,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "A metaheuristic approach for the vertex coloring problem", "author": ["E. Malaguti", "M. Monaci", "P. Toth"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2008}, {"title": "A survey on vertex coloring problems", "author": ["E. Malaguti", "P. Toth"], "venue": "International Transactions in Operational Research,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}, {"title": "Modified cuckoo optimization algorithm (MCOA) to solve graph coloring problem", "author": ["S. Mahmoudi", "S. Lotfi"], "venue": "Applied Soft Computing,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Global search in combinatorial optimization using reinforcement learning algorithms, Proceedings of the Congress on Evolutionary Computation (CEC)", "author": ["V.V. Miagkikh", "W.F. Punch III"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1999}, {"title": "A search space \u201ccartography\u201d for guiding graph coloring heuristics", "author": ["D.C. Porumbel", "J.K. Hao", "P. Kuntz"], "venue": "Computers & Operations Research,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "An Evolutionary Approach with Diversity Guarantee and Well-Informed Grouping Recombination for Graph Coloring", "author": ["D.C. Porumbel", "Hao", "J.-K", "P. Kuntz"], "venue": "Computers & Operations Research", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2010}, {"title": "A grouping genetic algorithm with controlled gene transmission for the bin packing problem", "author": ["M. Quiroz-Castellanos", "L. Cruz-Reyes", "J. Torres-Jim\u00e9nez", "C. G\u00f3mez", "H.J. Huacuja", "Alvim", "A.C. F"], "venue": "Computers & Operations Research,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "The exponentiated subgradient algorithm for heuristic boolean programming", "author": ["D. Schuurmans", "F. Southey", "R.C. Holte"], "venue": "In Proceedings of the 7th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2001}, {"title": "A multi-agent based optimization method applied to the quadratic assignment problem", "author": ["I. Sghir", "J.K. Hao", "I.B. Jaafar", "K. Ghdira"], "venue": "Expert Systems with Applications,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "Additive versus multiplicative clause weighting for SAT", "author": ["J. Thornton", "N.P. Duc", "Stuart B", "Valnir F.Jr."], "venue": "In Proceedings of the Conference of the American Association for Artificial Intelligence (AAAI),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2004}, {"title": "Quantum annealing of the graph coloring problem", "author": ["O. Titiloye", "A. Crispin"], "venue": "Discrete Optimization,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2011}, {"title": "Coloring large graphs based on independent set extraction", "author": ["Q. Wu", "J.K. Hao"], "venue": "Computers & Operations Research,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2012}, {"title": "FWLS: A Local Search for Graph Coloring, Frontiers in Algorithmics and Algorithmic Aspects in Information and Management", "author": ["W. Wu", "C. Luo", "K. Su"], "venue": "Third Joint International Conference,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2013}, {"title": "Learning adaptation to solve constraint satisfaction problems, Proceedings of Learning and Intelligent Optimization (LION", "author": ["Y. Xu", "D. Stern", "H. Samulowitz"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2009}], "referenceMentions": [{"referenceID": 11, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 44, "endOffset": 57}, {"referenceID": 14, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 44, "endOffset": 57}, {"referenceID": 16, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 44, "endOffset": 57}, {"referenceID": 28, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 44, "endOffset": 57}, {"referenceID": 11, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 71, "endOffset": 78}, {"referenceID": 29, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 71, "endOffset": 78}, {"referenceID": 12, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 92, "endOffset": 100}, {"referenceID": 37, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 92, "endOffset": 100}, {"referenceID": 27, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 113, "endOffset": 117}, {"referenceID": 0, "context": "include, for instance, graph coloring (GCP) [12,15,17,29], timetabling [12,30], bin packing [13, 38], scheduling [28] and clustering [1].", "startOffset": 133, "endOffset": 136}, {"referenceID": 27, "context": "According to whether the number of groups k is fixed in advance, grouping problems can be divided into constant grouping problems or variable grouping problems [28].", "startOffset": 160, "endOffset": 164}, {"referenceID": 12, "context": "A number of heuristic approaches for grouping problems, in particular based on genetic algorithms, have been proposed in the literature with varying degrees of success [13, 15, 38].", "startOffset": 168, "endOffset": 180}, {"referenceID": 14, "context": "A number of heuristic approaches for grouping problems, in particular based on genetic algorithms, have been proposed in the literature with varying degrees of success [13, 15, 38].", "startOffset": 168, "endOffset": 180}, {"referenceID": 37, "context": "A number of heuristic approaches for grouping problems, in particular based on genetic algorithms, have been proposed in the literature with varying degrees of success [13, 15, 38].", "startOffset": 168, "endOffset": 180}, {"referenceID": 2, "context": "Indeed, previous work has demonstrated that machine learning can contribute to improve optimization methods [3, 4, 20].", "startOffset": 108, "endOffset": 118}, {"referenceID": 3, "context": "Indeed, previous work has demonstrated that machine learning can contribute to improve optimization methods [3, 4, 20].", "startOffset": 108, "endOffset": 118}, {"referenceID": 19, "context": "Indeed, previous work has demonstrated that machine learning can contribute to improve optimization methods [3, 4, 20].", "startOffset": 108, "endOffset": 118}, {"referenceID": 23, "context": "This model can predict algorithm runtime for the propositional satisfiability problem, travelling salesperson problem and mixed integer programming problem [24].", "startOffset": 156, "endOffset": 160}, {"referenceID": 8, "context": "introduced the Plackett-Luce probability model to the framework of estimation of distribution algorithms and applied it to solve the linear order problem and the flow-shop scheduling problem [9].", "startOffset": 191, "endOffset": 194}, {"referenceID": 4, "context": "The learned evaluation function is used to bias future search trajectories towards better solutions [5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 35, "context": "used multidimensional scaling techniques to explore the spatial distribution of the local optimal solutions visited by tabu search, thus improving local search algorithms for the graph coloring problem [36].", "startOffset": 202, "endOffset": 206}, {"referenceID": 20, "context": "For the same problem, the authors of [21] used the results of an analysis of legal k-colorings to help finding solutions with fewer colors.", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "In contrast to supervised learning techniques, reinforcement learning does not need an experienced agent to show the correct way, but adjusts its future actions based on the obtained feedback signal from the environment [18].", "startOffset": 220, "endOffset": 224}, {"referenceID": 34, "context": "For example, the authors of [35] proposed to solve combinatorial optimization problems based on a population of RL agents.", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "For example, RL is employed to learn a new evaluation function over multiple search trajectories of the same problem instance and alternates between using the learned and the original evaluation function [5].", "startOffset": 204, "endOffset": 207}, {"referenceID": 44, "context": "[45] proposed a formulation of constraint satisfaction problems as a RL task.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7] presented a hyperheuristic in which the selection of low-level heuristics makes use of basic reinforcement learning principles combined with a tabu search mechanism.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "Two other examples can be found in [19,40] where RL is used to schedule several search operators (crossovers, local search.", "startOffset": 35, "endOffset": 42}, {"referenceID": 39, "context": "Two other examples can be found in [19,40] where RL is used to schedule several search operators (crossovers, local search.", "startOffset": 35, "endOffset": 42}, {"referenceID": 22, "context": "Our probability smoothing strategy is inspired by forgetting mechanisms in smoothing techniques in clause weighting local search algorithms for satisfiability (SAT) [23,25].", "startOffset": 165, "endOffset": 172}, {"referenceID": 24, "context": "Our probability smoothing strategy is inspired by forgetting mechanisms in smoothing techniques in clause weighting local search algorithms for satisfiability (SAT) [23,25].", "startOffset": 165, "endOffset": 172}, {"referenceID": 40, "context": "\u2022 Decrease one from all clause weights which are greater than one such as PAWS [41].", "startOffset": 79, "endOffset": 83}, {"referenceID": 38, "context": "\u2022 Pull all clause weights to their mean value using the formula wi = \u03c1 \u00b7 wi + (1\u2212 \u03c1) \u00b7 wi like ESG [39] and SAPS [23].", "startOffset": 99, "endOffset": 103}, {"referenceID": 22, "context": "\u2022 Pull all clause weights to their mean value using the formula wi = \u03c1 \u00b7 wi + (1\u2212 \u03c1) \u00b7 wi like ESG [39] and SAPS [23].", "startOffset": 113, "endOffset": 117}, {"referenceID": 24, "context": "\u2022 Transfer weights from neighboring satisfied clauses to unsatisfied ones like DDWF [25].", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "\u2022 Reduce all edge weights using the formula wi = \u230a\u03c1 \u00b7 wi\u230b when the average weight achieves a threshold like NuMVC [8].", "startOffset": 114, "endOffset": 117}, {"referenceID": 16, "context": "GCP is one of the most studied combinatorial optimization problems [17].", "startOffset": 67, "endOffset": 71}, {"referenceID": 15, "context": "Notice that GCP can be approximated by solving a series of k-GCP (with decreasing k) as follows [16].", "startOffset": 96, "endOffset": 100}, {"referenceID": 1, "context": "Given the theoretical and practical interest of GCP, a huge number of coloring algorithms have been proposed in the past decades [2, 16, 27, 33].", "startOffset": 129, "endOffset": 144}, {"referenceID": 15, "context": "Given the theoretical and practical interest of GCP, a huge number of coloring algorithms have been proposed in the past decades [2, 16, 27, 33].", "startOffset": 129, "endOffset": 144}, {"referenceID": 26, "context": "Given the theoretical and practical interest of GCP, a huge number of coloring algorithms have been proposed in the past decades [2, 16, 27, 33].", "startOffset": 129, "endOffset": 144}, {"referenceID": 32, "context": "Given the theoretical and practical interest of GCP, a huge number of coloring algorithms have been proposed in the past decades [2, 16, 27, 33].", "startOffset": 129, "endOffset": 144}, {"referenceID": 25, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 118, "endOffset": 122}, {"referenceID": 14, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 141, "endOffset": 148}, {"referenceID": 21, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 141, "endOffset": 148}, {"referenceID": 9, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 176, "endOffset": 180}, {"referenceID": 10, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 210, "endOffset": 214}, {"referenceID": 41, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 245, "endOffset": 249}, {"referenceID": 43, "context": "Among them, algorithms based on local search are certainly the most popular approaches, like simulated annealing (SA) [26], tabu search (TS) [15,22], guided local search (GLS) [10], iterated local search (ILS) [11], quantum annealing algorithms [42] and focused walk based local search (FWLS) [44].", "startOffset": 293, "endOffset": 297}, {"referenceID": 13, "context": "Populationbased hybrid algorithms represent another class of complex approaches which typically combine local search and dedicated recombination crossover operators [14, 15, 31, 32, 37].", "startOffset": 165, "endOffset": 185}, {"referenceID": 14, "context": "Populationbased hybrid algorithms represent another class of complex approaches which typically combine local search and dedicated recombination crossover operators [14, 15, 31, 32, 37].", "startOffset": 165, "endOffset": 185}, {"referenceID": 30, "context": "Populationbased hybrid algorithms represent another class of complex approaches which typically combine local search and dedicated recombination crossover operators [14, 15, 31, 32, 37].", "startOffset": 165, "endOffset": 185}, {"referenceID": 31, "context": "Populationbased hybrid algorithms represent another class of complex approaches which typically combine local search and dedicated recombination crossover operators [14, 15, 31, 32, 37].", "startOffset": 165, "endOffset": 185}, {"referenceID": 36, "context": "Populationbased hybrid algorithms represent another class of complex approaches which typically combine local search and dedicated recombination crossover operators [14, 15, 31, 32, 37].", "startOffset": 165, "endOffset": 185}, {"referenceID": 15, "context": "Recent surveys of algorithms for GCP can be found in [16, 33].", "startOffset": 53, "endOffset": 61}, {"referenceID": 32, "context": "Recent surveys of algorithms for GCP can be found in [16, 33].", "startOffset": 53, "endOffset": 61}, {"referenceID": 14, "context": "The neighborhood of a given k-coloring is constructed by moving a conflicting vertex v from its original group gi to another group gj(i 6= j) [15].", "startOffset": 142, "endOffset": 146}, {"referenceID": 13, "context": "To evaluate each neighboring solution efficiently, our descentbased local search adopts the fast incremental evaluation technique introduced in [14,15].", "startOffset": 144, "endOffset": 151}, {"referenceID": 14, "context": "To evaluate each neighboring solution efficiently, our descentbased local search adopts the fast incremental evaluation technique introduced in [14,15].", "startOffset": 144, "endOffset": 151}, {"referenceID": 14, "context": "For this experiment, by following [15], we use running profiles to observe the change of evaluation function f over the number of iterations.", "startOffset": 34, "endOffset": 38}, {"referenceID": 25, "context": "This study focuses on five algorithms based on advanced local search methods including the prominent simulating annealing (SA) algorithm [26], the improved tabu search (TS) algorithm [15], the guided local search (GLS) algorithm [10], the iterative local search (ILS) algorithm [11] and the focused walk based local search (FWLS) algorithm [44].", "startOffset": 137, "endOffset": 141}, {"referenceID": 14, "context": "This study focuses on five algorithms based on advanced local search methods including the prominent simulating annealing (SA) algorithm [26], the improved tabu search (TS) algorithm [15], the guided local search (GLS) algorithm [10], the iterative local search (ILS) algorithm [11] and the focused walk based local search (FWLS) algorithm [44].", "startOffset": 183, "endOffset": 187}, {"referenceID": 9, "context": "This study focuses on five algorithms based on advanced local search methods including the prominent simulating annealing (SA) algorithm [26], the improved tabu search (TS) algorithm [15], the guided local search (GLS) algorithm [10], the iterative local search (ILS) algorithm [11] and the focused walk based local search (FWLS) algorithm [44].", "startOffset": 229, "endOffset": 233}, {"referenceID": 10, "context": "This study focuses on five algorithms based on advanced local search methods including the prominent simulating annealing (SA) algorithm [26], the improved tabu search (TS) algorithm [15], the guided local search (GLS) algorithm [10], the iterative local search (ILS) algorithm [11] and the focused walk based local search (FWLS) algorithm [44].", "startOffset": 278, "endOffset": 282}, {"referenceID": 43, "context": "This study focuses on five algorithms based on advanced local search methods including the prominent simulating annealing (SA) algorithm [26], the improved tabu search (TS) algorithm [15], the guided local search (GLS) algorithm [10], the iterative local search (ILS) algorithm [11] and the focused walk based local search (FWLS) algorithm [44].", "startOffset": 340, "endOffset": 344}, {"referenceID": 14, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 32, "endOffset": 36}, {"referenceID": 9, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 41, "endOffset": 45}, {"referenceID": 10, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 50, "endOffset": 54}, {"referenceID": 43, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 60, "endOffset": 64}, {"referenceID": 5, "context": "We also find that our proposed RLS method even achieves competitive performances compared to some complex population algorithms proposed in recent years, such as ant-based algorithm [6] (2008), and modified cuckoo optimiza-", "startOffset": 182, "endOffset": 185}, {"referenceID": 14, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 32, "endOffset": 36}, {"referenceID": 9, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 41, "endOffset": 45}, {"referenceID": 10, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 50, "endOffset": 54}, {"referenceID": 43, "context": "Instance n m \u03c7/k RLS TS [15] SA [26] GLS [10] ILS [11] FWLS [44]", "startOffset": 60, "endOffset": 64}, {"referenceID": 33, "context": "tion algorithm [34] (2015).", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "However, given the very simplicity of its underlying local search procedure, it is no surprise that RLS alone cannot compete with the most powerful coloring algorithms like [15,31,32,37,42,43].", "startOffset": 173, "endOffset": 192}, {"referenceID": 30, "context": "However, given the very simplicity of its underlying local search procedure, it is no surprise that RLS alone cannot compete with the most powerful coloring algorithms like [15,31,32,37,42,43].", "startOffset": 173, "endOffset": 192}, {"referenceID": 31, "context": "However, given the very simplicity of its underlying local search procedure, it is no surprise that RLS alone cannot compete with the most powerful coloring algorithms like [15,31,32,37,42,43].", "startOffset": 173, "endOffset": 192}, {"referenceID": 36, "context": "However, given the very simplicity of its underlying local search procedure, it is no surprise that RLS alone cannot compete with the most powerful coloring algorithms like [15,31,32,37,42,43].", "startOffset": 173, "endOffset": 192}, {"referenceID": 41, "context": "However, given the very simplicity of its underlying local search procedure, it is no surprise that RLS alone cannot compete with the most powerful coloring algorithms like [15,31,32,37,42,43].", "startOffset": 173, "endOffset": 192}, {"referenceID": 42, "context": "However, given the very simplicity of its underlying local search procedure, it is no surprise that RLS alone cannot compete with the most powerful coloring algorithms like [15,31,32,37,42,43].", "startOffset": 173, "endOffset": 192}, {"referenceID": 5, "context": "It performs even better than some recent and complex optimization algorithms like the ant-based algorithm [6] and modified cuckoo optimization algorithm [34].", "startOffset": 106, "endOffset": 109}, {"referenceID": 33, "context": "It performs even better than some recent and complex optimization algorithms like the ant-based algorithm [6] and modified cuckoo optimization algorithm [34].", "startOffset": 153, "endOffset": 157}], "year": 2015, "abstractText": "Grouping problems aim to partition a set of items into multiple mutually disjoint subsets according to some specific criterion and constraints. Grouping problems cover a large class of important combinatorial optimization problems that are generally computationally difficult. In this paper, we propose a general solution approach for grouping problems, i.e., reinforcement learning based local search (RLS), which combines reinforcement learning techniques with descent-based local search. The viability of the proposed approach is verified on a well-known representative grouping problem (graph coloring) where a very simple descent-based coloring algorithm is applied. Experimental studies on popular DIMACS and COLOR02 benchmark graphs indicate that RLS achieves competitive performances compared to a number of well-known coloring algorithms.", "creator": "gnuplot 4.6 patchlevel 4"}}}