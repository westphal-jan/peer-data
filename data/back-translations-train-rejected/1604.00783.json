{"id": "1604.00783", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2016", "title": "Topic Model Based Multi-Label Classification from the Crowd", "abstract": "Multi-label classification is a common supervised machine learning problem where each instance is associated with multiple classes. The key challenge in this problem is learning the correlations between the classes. An additional challenge arises when the labels of the training instances are provided by noisy, heterogeneous crowdworkers with unknown qualities. We first assume labels from a perfect source and propose a novel topic model where the present as well as the absent classes generate the latent topics and hence the words. We non-trivially extend our topic model to the scenario where the labels are provided by noisy crowdworkers. Extensive experimentation on real world datasets reveals the superior performance of the proposed model. The proposed model learns the qualities of the annotators as well, even with minimal training data.", "histories": [["v1", "Mon, 4 Apr 2016 09:24:12 GMT  (524kb,D)", "http://arxiv.org/abs/1604.00783v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["divya padmanabhan", "satyanath bhat", "shirish shevade", "y narahari"], "accepted": false, "id": "1604.00783"}, "pdf": {"name": "1604.00783.pdf", "metadata": {"source": "CRF", "title": "Topic Model Based Multi-Label Classification from the Crowd", "authors": ["Divya Padmanabhan", "Satyanath Bhat", "Shirish Shevade"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Related Work", "text": "rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "3 Our Approach for Multi-label Classification: ML-PA-LDA", "text": "In our experiments, we applied the model to areas other than text. We will explain the transformation of attributes into words when describing our experiments. Let D represent the number of documents in education, C the total number of classes, T the number of topics, and K the number of annotations. In the multi-level classification, a document can belong to any \"subset\" of C classes if we are opposed to the standard classification in which a document belongs to exactly one class. We grade the number of topics and K the number of annotations. In the multi-level classification, a document can belong to any \"subset\" of C classes where a document belongs to exactly one class."}, {"heading": "4 Variational EM for ML-PA-LDA-C", "text": "Since ML-PA-LDA-C is a generalization of ML-PA-LDA to adapt to mass, we provide the details of the steps for ML-PA-LDA-C and provide guidance to highlight the differences with ML-PA-LDA whenever this is true. Given the observed words w and the labels y1,., yk for a document d, the goal of the model described above is to obtain p (...). Here, the challenge lies in the intractable compilation of p (...) resulting from the intractability in the compilation of p (...). We use variational inference with medium field assumptions to overcome this challenge."}, {"heading": "4.1 E-step Updates for ML-PA-LDA-C", "text": "In the e-step, the following steps must be carried out iteratively for each document d.log di-log \u0432i + K \u0445 j = 1 ydij log \u0421j + (1 \u2212 ydij) log 1 \u2212 \u03c1j + Nd n = 1 T \u2211 t = 1 \u03b4dni\u03c6 d ntE [log \u03b8di1t] (17) log (1 \u2212 di) log 1 \u2212 \u0441i + K = 1 (1 \u2212 ydij) log \u0421j + ydij log (1 \u2212 \u03c1j) + Nd \u0441ststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststtistststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststststst"}, {"heading": "4.2 M-step Updates for ML-PA-LDA-C", "text": "11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11"}, {"heading": "5 Smoothing", "text": "In the model described in section 3, we model \u03b2 as a parameter that regulates the multinomial distributions for generating words from each topic. Generally, a new document may contain words that do not appear in any of the training materials, but the unsmoothed model described above does not address this problem. To address this, we need to \"smooth\" the multinomial parameters involved. One way of smoothing it out is to model \u03b2 as a multinomial random variable with parameters. The corresponding graphic model is in Figure 2. Here, too, we model the variable distribution for \u03b2 as a \u03b2-Mult based on the intractable nature of the calculations. We estimate variation parameters in the E-step of the variation parameters EM using Eqn 26, assuming that Eqn 26 is known."}, {"heading": "6 Experiments", "text": "In order to test the effectiveness of the proposed techniques, we evaluate our model using data sets from several areas."}, {"heading": "6.1 Dataset Descriptions", "text": "We have conducted our experiments on several data sets from the text domain as well as non-text domain of 1996 was random size. We now describe the data sets and the pre-processing steps below. Text Datasets: In the text domain, we have evaluated studies on the Reuters21578, Bibtex and Enron datasets. Reuters-21578: The Reuters-21578 dataset [11] is a collection of documents containing news articles. The original corpus had 10,369 documents and a vocabulary of 29,930 words. We have performed tribalisation using the Porter Stemmer algorithm [14] and also removed the stopwords. Of this sentence, the words that have entered the corpus more than 50 times and only documents that contained more than 20 words were retained. Finally, the most common top 10 labels, namely acq, raw, earn, fx, in interest, money, trade, were retained."}, {"heading": "6.2 Results: ML-PA-LDA (Non-Crowd Version)", "text": "In Table 1, we compare the performance of our non-annotated model against other methods such as RAKel, Monte Carlo Classifier Chains (MCC) [16], Binary Relevance Method - Random Subspace (BRQ) [17], Bayesian Chain Classifiers (BCC) [24] and SLDA. BCC [24] is a probabilistic method that requires a chain of classifiers by modelling dependencies between classes using a Bayesian network. MCC instead uses a monte-carlo strategy to learn dependencies. BCC improves on binary Relevant Methods of Combining Classifiers by clarifying dependencies between classes."}, {"heading": "6.3 Results: ML-PA-LDA-C (Crowd Version)", "text": "To verify the performance of the annotator model, in which the labels are provided by multiple annotators, we simulated 50 annotators with different qualities. \u03c1 values of the annotators were sampled from a uniform distribution. For 10 of these annotators, annotator was sampled from U [0.51, 0.65]. For a further 20 of them, annotator from U [0.66, 0.85] was sampled and for the remaining 20, annotator from U [0.86, 0.9999] was sampled. This captures the heterogeneity in the annotator qualities. For each document in the training set, a random 10% (= 5) annotator model was selected for generating the noisy labels. In Table 2, we compare the performance of the annotator model with our non-anotator model version. We find that the performance of ML-PA-LDA-C is close to the performance of ML-PA-LDA-LDA and is better than SDA-LDA."}, {"heading": "7 Conclusion", "text": "We have introduced a new approach to multi-label classification using a novel theme model that uses both information about the presence and absence of classes. In the scenario where the real labels are not available and instead a loud version of the labels is provided by the annotators, we have adapted our theme model to learn the parameters including the qualities of the annotators. Our experiments with real data sets show the superior performance of our approach."}], "references": [{"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "JMLR,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "Occam\u2019s razor", "author": ["A. Blumer", "A. Ehrenfeucht", "D. Haussler", "M.K. Warmuth"], "venue": "Inf. Process. Lett.,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1987}, {"title": "Learning multi-label scene classification", "author": ["M.R. Boutell", "J. Luo", "X. Shen", "C.M. Brown"], "venue": "Pattern recognition,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Mausam, and D", "author": ["J. Bragg"], "venue": "S. Weld. Crowdsourcing multi-label classification for taxonomy creation. In HCOMP,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Scalable multi-label annotation", "author": ["J. Deng", "O. Russakovsky", "J. Krause", "M.S. Bernstein", "A. Berg", "L. Fei-Fei"], "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "A kernel method for multi-labelled classification", "author": ["A. Elisseeff", "J. Weston"], "venue": "In NIPS,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Multilabel text classification for automated tag suggestion", "author": ["I. Katakis", "G. Tsoumakas", "I. Vlahavas"], "venue": "In Proceedings of the ECML/PKDD-08 Workshop on Discovery Challenge,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Supervised topic models", "author": ["J.D. Mcauliffe", "D.M. Blei"], "venue": "In NIPS.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Multi-label text classification with a mixture model trained by em", "author": ["A.K. McCallum"], "venue": "In AAAI 99 Workshop on Text Learning,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning from crowds", "author": ["V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy"], "venue": "JMLR,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient monte carlo optimization for lultilabel classifier chains", "author": ["J. Read", "L. Martino", "D. Luengo"], "venue": "In ICASSP,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Classifier chains for multi-label classification", "author": ["J. Read", "B. Pfahringer", "G. Holmes", "E. Frank"], "venue": "Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning supervised topic models from crowds", "author": ["F. Rodrigues", "B. Ribeiro", "M. Louren\u00e7o", "F. Pereira"], "venue": "In HCOMP,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Statistical topic models for multi-label document classification", "author": ["T.N. Rubin", "A. Chambers", "P. Smyth", "M. Steyvers"], "venue": "Machine Learning,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Random k-labelsets for multilabel classification", "author": ["G. Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": "TKDE,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Mulan: A java library for multi-label learning", "author": ["G. Tsoumakas", "E. Spyromitros-Xioufis", "J. Vilcek", "I. Vlahavas"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Parametric mixture models for multi-labeled text", "author": ["N. Ueda", "K. Saito"], "venue": "In NIPS,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "A generative probabilistic model for multi-label classification", "author": ["H. Wang", "M. Huang", "X. Zhu"], "venue": "In ICDM,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Bayesian chain classifiers for multidimensional classification", "author": ["J.H. Zaragoza", "L.E. Sucar", "E.F. Morales", "C. Bielza", "P. Larra\u00f1aga"], "venue": "In IJCAI,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "In the past, topic models [1] have proved to be successful in modeling the process behind generating text documents.", "startOffset": 26, "endOffset": 29}, {"referenceID": 14, "context": "To overcome this drawback, RAndom k-labELsets method (RAkEL) [20] was introduced, which constructs an ensemble of LP classifiers where each classifier is trained with a random subset of k labels.", "startOffset": 61, "endOffset": 65}, {"referenceID": 5, "context": "Rank-SVM [8] uses PW approach to construct SVM classifiers for every pair of classes and then performs a ranking.", "startOffset": 9, "endOffset": 12}, {"referenceID": 8, "context": "Generative models for multilabel classification model the correlation between the classes using mixing weights for the classes [13].", "startOffset": 127, "endOffset": 131}, {"referenceID": 16, "context": "Other probabilistic mixture models include Parameteric Mixture Models PMM1 and PMM2 [22].", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "After the advent of the topic models like Latent Dirichlet Allocation (LDA) [1], extensions have been proposed for multi-label classification such as Wang et al [23].", "startOffset": 76, "endOffset": 79}, {"referenceID": 17, "context": "After the advent of the topic models like Latent Dirichlet Allocation (LDA) [1], extensions have been proposed for multi-label classification such as Wang et al [23].", "startOffset": 161, "endOffset": 165}, {"referenceID": 17, "context": "However in [23], due to the non-conjugacy of the distributions involved, closed form updates cannot be obtained for several parameters and iterative optimization algorithms such as conjugate gradient and Newton Raphson are required to be used in the variational E step as well as M step, introducing additional implementation issues.", "startOffset": 11, "endOffset": 15}, {"referenceID": 13, "context": "The topic models proposed for multi-label classification in [19] involve far too many parameters which can be learnt effectively only in the presence of large amounts of labeled data.", "startOffset": 60, "endOffset": 64}, {"referenceID": 7, "context": "SLDA [12] is a single label classification technique which works well on multilabel classification when used with the one-vs-all approach.", "startOffset": 5, "endOffset": 9}, {"referenceID": 9, "context": "Raykar et al [15] look at training binary classification models with labels from a crowd with unknown annotator qualities.", "startOffset": 13, "endOffset": 17}, {"referenceID": 3, "context": "Mausam et al [4] look at multi-label classification for taxonomy creation from the crowd.", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "Deng et al [6] look at selecting the instance to be given to a set of crowd-workers.", "startOffset": 11, "endOffset": 14}, {"referenceID": 12, "context": "adapted to learning from the labels provided by crowd annotators [18].", "startOffset": 65, "endOffset": 69}, {"referenceID": 6, "context": "Bibtex: The Bibtex dataset [10] was released as part of the ECML-PKDD 2008 Discovery Challenge.", "startOffset": 27, "endOffset": 31}, {"referenceID": 15, "context": "Enron: The Enron dataset [21] is a collection of emails for which a set of pre-defined categories are to be assigned.", "startOffset": 25, "endOffset": 29}, {"referenceID": 5, "context": "Yeast: The Yeast dataset [8] contains a set of genes which may be associated with several functional classes.", "startOffset": 25, "endOffset": 28}, {"referenceID": 2, "context": "Scene: The Scene dataset [3] is a dataset of images.", "startOffset": 25, "endOffset": 28}, {"referenceID": 10, "context": "In Table 1 we compare the performance of our non-annotator model vs other methods such as RAKel, Monte Carlo Classifier Chains (MCC) [16], Binary Relevance Method - Random Subspace (BRq) [17], Bayesian Chain Classifiers (BCC) [24] and SLDA.", "startOffset": 133, "endOffset": 137}, {"referenceID": 11, "context": "In Table 1 we compare the performance of our non-annotator model vs other methods such as RAKel, Monte Carlo Classifier Chains (MCC) [16], Binary Relevance Method - Random Subspace (BRq) [17], Bayesian Chain Classifiers (BCC) [24] and SLDA.", "startOffset": 187, "endOffset": 191}, {"referenceID": 18, "context": "In Table 1 we compare the performance of our non-annotator model vs other methods such as RAKel, Monte Carlo Classifier Chains (MCC) [16], Binary Relevance Method - Random Subspace (BRq) [17], Bayesian Chain Classifiers (BCC) [24] and SLDA.", "startOffset": 226, "endOffset": 230}, {"referenceID": 18, "context": "BCC [24] is a probabilistic method which constructs a chain of classifiers by modeling the dependencies between the classes using a bayesian network.", "startOffset": 4, "endOffset": 8}, {"referenceID": 1, "context": "This observation is consistent with Occam\u2019s razor [2].", "startOffset": 50, "endOffset": 53}], "year": 2016, "abstractText": "Multi-label classification is a common supervised machine learning problem where each instance is associated with multiple classes. The key challenge in this problem is learning the correlations between the classes. An additional challenge arises when the labels of the training instances are provided by noisy, heterogeneous crowdworkers with unknown qualities. We first assume labels from a perfect source and propose a novel topic model where the present as well as the absent classes generate the latent topics and hence the words. We non-trivially extend our topic model to the scenario where the labels are provided by noisy crowdworkers. Extensive experimentation on real world datasets reveals the superior performance of the proposed model. The proposed model learns the qualities of the annotators as well, even with minimal training data.", "creator": "TeX"}}}