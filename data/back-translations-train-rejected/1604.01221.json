{"id": "1604.01221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2016", "title": "Character-Level Neural Translation for Multilingual Media Monitoring in the SUMMA Project", "abstract": "The paper steps outside the comfort-zone of the traditional NLP tasks like automatic speech recognition (ASR) and machine translation (MT) to addresses two novel problems arising in the automated multilingual news monitoring: segmentation of the TV and radio program ASR transcripts into individual stories, and clustering of the individual stories coming from various sources and languages into storylines. Storyline clustering of stories covering the same events is an essential task for inquisitorial media monitoring. We address these two problems jointly by engaging the low-dimensional semantic representation capabilities of the sequence to sequence neural translation models. To enable joint multi-task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding-window mechanism and operate the sequence to sequence neural translation model on the character-level rather than on the word-level. The story segmentation and storyline clustering problem is tackled by examining the low-dimensional vectors produced as a side-product of the neural translation process. The results of this paper describe a novel approach to the automatic story segmentation and storyline clustering problem.", "histories": [["v1", "Tue, 5 Apr 2016 11:34:11 GMT  (444kb)", "http://arxiv.org/abs/1604.01221v1", "LREC-2016 submission"]], "COMMENTS": "LREC-2016 submission", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["guntis barzdins", "steve renals", "didzis gosko"], "accepted": false, "id": "1604.01221"}, "pdf": {"name": "1604.01221.pdf", "metadata": {"source": "CRF", "title": "Character-Level Neural Translation for Multilingual Media Monitoring in the SUMMA Project", "authors": ["Guntis Barzdins", "Steve Renals", "Didzis Gosko"], "emails": ["guntis.barzdins@lu.lv,", "s.renals@ed.ac.uk,", "didzis.gosko@leta.lv"], "sections": [{"heading": null, "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves if they do not. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}], "references": [{"title": "TensorFlow: Large-scale machine learning on", "author": ["S. Moore", "D. Murray", "C. Olah", "J. Shlens", "B. Steiner", "I. Sutskever", "K. Talwar", "P. Tucker", "V. Vanhoucke", "V. Vasudevan", "F. Vi\u00e9gas", "O. Vinyals", "P. Warden", "M. Wattenberg", "W. Wicke", "Y. Yu", "X. Zheng"], "venue": null, "citeRegEx": "Moore et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2015}, {"title": "Deep speech 2: End-to-end speech recognition in english and mandarin", "author": ["D. Amodei", "R. Anubhai", "E. Battenberg", "C. Case", "J. Casper", "B. Catanzaro", "J. Chen", "M. Chrzanowski", "A. Coates", "G Diamos"], "venue": "arXiv preprint arXiv:1512.02595", "citeRegEx": "Amodei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Amodei et al\\.", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Riga: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy", "author": ["G. Barzdins", "D. Gosko"], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016), (to appear)", "citeRegEx": "Barzdins and Gosko,? 2016", "shortCiteRegEx": "Barzdins and Gosko", "year": 2016}, {"title": "Using C5.0 and Exhaustive Search for Boosting FrameSemantic Parsing Accuracy", "author": ["G. Barzdins", "D. Gosko", "L. Rituma", "P. Paikens"], "venue": "In Proceedings of the 9th Language Resources and Evaluation Conference (LREC),", "citeRegEx": "Barzdins et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barzdins et al\\.", "year": 2014}, {"title": "Riga: from FrameNet to Semantic Frames with C6.0 Rules", "author": ["G. Barzdins", "P. Paikens", "D. Gosko"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Barzdins et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Barzdins et al\\.", "year": 2015}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "The Journal of Machine Learning Research, 12, pp. 2493--2537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Smart Replay", "author": ["G. Corrado"], "venue": "Google Research Blog post, http://googleresearch.blogspot.com/2015/11/computerrespond-to-this-email.html", "citeRegEx": "Corrado,? 2015", "shortCiteRegEx": "Corrado", "year": 2015}, {"title": "Semi-supervised Sequence Learning", "author": ["A.M. Dai", "Q.V. Le"], "venue": "NIPS-2015.", "citeRegEx": "Dai and Le,? 2015", "shortCiteRegEx": "Dai and Le", "year": 2015}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G.S. Corrado", "R. Monga", "K. Chen", "M. Devin", "Q.V. Le", "M.Z. Mao", "M. Ranzato", "A. Senior", "P. Tucker", "K. Yang", "A.Y. Ng"], "venue": "NIPS-2012.", "citeRegEx": "Dean et al\\.,? 2012", "shortCiteRegEx": "Dean et al\\.", "year": 2012}, {"title": "MultiTask Learning for Multiple Language Translation", "author": ["D. Dong", "H. Wu", "W. He", "D. Yu", "H. Wang"], "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on Natural Language Processing, Beijing, China, pp. 1723--1732.", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "author": ["A. Graves", "N. Jaitly"], "venue": "ICML2014.", "citeRegEx": "Graves and Jaitly,? 2014", "shortCiteRegEx": "Graves and Jaitly", "year": 2014}, {"title": "Deep Speech: Scaling up end-to-end speech recognition", "author": ["A. Hannun", "C. Case", "J. Casper", "B. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta", "A. Coates", "A.Y. Ng"], "venue": "arXiv preprint arXiv:1412.5567", "citeRegEx": "Hannun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hannun et al\\.", "year": 2014}, {"title": "Learning Distributed Representations of Sentences from Unlabelled Data", "author": ["F. Hill", "K. Cho", "A. Korhonen"], "venue": "arXiv preprint arXiv:1602.03483", "citeRegEx": "Hill et al\\.,? 2016", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Exploring the Limits of Language Modeling", "author": ["R. Jozefowicz", "O. Vinyals", "M. Schuster", "N. Shazeer", "W. Wu"], "venue": "arXiv preprint arXiv:1602.02410", "citeRegEx": "Jozefowicz et al\\.,? 2016", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2016}, {"title": "The unreasonable effectiveness of recurrent neural networks", "author": ["A. Karpathy"], "venue": "Blog post, http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "citeRegEx": "Karpathy,? 2015", "shortCiteRegEx": "Karpathy", "year": 2015}, {"title": "A Hierarchical Neural Autoencoder for Paragraphs and Documents", "author": ["J. Li", "T. Luong", "D. Jurafsky"], "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on NLP, Beijing, China, pp. 1106--1115.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Multi-task Sequence to Sequence Learning", "author": ["T. Luong", "Q.V. Le", "I. Sutskever", "O. Vinyals", "L. Kaiser"], "venue": "ICLR-2016.", "citeRegEx": "Luong et al\\.,? 2016", "shortCiteRegEx": "Luong et al\\.", "year": 2016}, {"title": "Addressing the rare word problem in neural machine translation", "author": ["T. Luong", "I. Sutskever", "Q.V. Le", "O. Vinyals", "W. Zaremba"], "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on NLP, Beijing, China, pp. 11--19.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Computational Linguistics and Deep Learning", "author": ["C.D. Manning"], "venue": "Computational Linguistics, 41(4), pp. 701--707.", "citeRegEx": "Manning,? 2015", "shortCiteRegEx": "Manning", "year": 2015}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Learning Distributed Representations for Multilingual Text Sequences", "author": ["H. Pham", "M. Luong", "C.D. Manning"], "venue": "NAACL-2015.", "citeRegEx": "Pham et al\\.,? 2015", "shortCiteRegEx": "Pham et al\\.", "year": 2015}, {"title": "Storyline Ontology", "author": ["P. Rissen", "H. Lippell", "M. Chadburn", "T. Leitch", "D. Brickley", "M. Smethurst", "S. Cevey"], "venue": "Blog post, http://www.bbc.co.uk/ontologies/storyline", "citeRegEx": "Rissen et al\\.,? 2013", "shortCiteRegEx": "Rissen et al\\.", "year": 2013}, {"title": "News Across Languages - CrossLingual Document Similarity and Event Tracking", "author": ["J. Rupnik", "A. Muhic", "G. Leban", "P. Skraba", "B. Fortuna", "M. Grobelnik"], "venue": "Journal of Artificial Intelligence Research, 55, pp.283-316.", "citeRegEx": "Rupnik et al\\.,? 2016", "shortCiteRegEx": "Rupnik et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "NIPS-2014, pp. 3104--3112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Translating Videos to Natural Language Using Deep Recurrent Neural Networks", "author": ["S. Venugopalan", "H. Xu", "J. Donahue", "M. Rohrbach", "R. Mooney", "K. Saenko"], "venue": "NAACL-2015, pp. 1494--1504.", "citeRegEx": "Venugopalan et al\\.,? 2015", "shortCiteRegEx": "Venugopalan et al\\.", "year": 2015}, {"title": "A Neural Conversation Model", "author": ["Q. Vinyals", "Q.L. Le"], "venue": "arXiv preprint arXiv:1506.05869", "citeRegEx": "Vinyals and Le,? 2015", "shortCiteRegEx": "Vinyals and Le", "year": 2015}, {"title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhutdinov", "R. Zemel", "Y. Bengio"], "venue": "arXiv preprint arXiv:1502.03044.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 19, "context": "The key difference of the SUMMA project is that it has been incepted after the recent paradigm-shift (Manning, 2015) in the NLP community towards neural network inspired deep learning techniques such as end-to-end automatic speech recognition (Graves & Jaitly, 2014; Hannun et al.", "startOffset": 101, "endOffset": 116}, {"referenceID": 12, "context": "The key difference of the SUMMA project is that it has been incepted after the recent paradigm-shift (Manning, 2015) in the NLP community towards neural network inspired deep learning techniques such as end-to-end automatic speech recognition (Graves & Jaitly, 2014; Hannun et al., 2014; Amodei, 2015), end-to-end machinetranslation (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014; Luong et al.", "startOffset": 243, "endOffset": 301}, {"referenceID": 18, "context": ", 2014; Amodei, 2015), end-to-end machinetranslation (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014; Luong et al., 2015), efficient distributed vectorspace word embeddings (Mikolov et al.", "startOffset": 53, "endOffset": 134}, {"referenceID": 20, "context": ", 2015), efficient distributed vectorspace word embeddings (Mikolov et al., 2013), image and video captioning (Xu et al.", "startOffset": 59, "endOffset": 81}, {"referenceID": 27, "context": ", 2013), image and video captioning (Xu et al., 2015; Venugopalan et al., 2015), unsupervised learning of document representations by autoencoders (Li, Luong & Jurafsky, 2015).", "startOffset": 36, "endOffset": 79}, {"referenceID": 25, "context": ", 2013), image and video captioning (Xu et al., 2015; Venugopalan et al., 2015), unsupervised learning of document representations by autoencoders (Li, Luong & Jurafsky, 2015).", "startOffset": 36, "endOffset": 79}, {"referenceID": 6, "context": "The novelty of the SUMMA project approach is that all languages covered by the project (Table 1) can be embedded in the same vectorspace by means of joint multitask learning (Collobert et al., 2011; Dong et al., 2015; Pham, Luong & Manning, 2015) of eight LSTM-RNN translational autoencoders with hidden layer parameters shared as illustrated in Fig.", "startOffset": 174, "endOffset": 246}, {"referenceID": 10, "context": "The novelty of the SUMMA project approach is that all languages covered by the project (Table 1) can be embedded in the same vectorspace by means of joint multitask learning (Collobert et al., 2011; Dong et al., 2015; Pham, Luong & Manning, 2015) of eight LSTM-RNN translational autoencoders with hidden layer parameters shared as illustrated in Fig.", "startOffset": 174, "endOffset": 246}, {"referenceID": 9, "context": "To avoid complexities of asynchronous parallel training with shared parameter server (Dean et al., 2012), the architecture in Fig.", "startOffset": 85, "endOffset": 104}, {"referenceID": 17, "context": "3 instead can be trained using the alternating training approach proposed in (Luong et al., 2016), where each task is optimized for a fixed number of parameter updates (or mini-batches) before switching to the next task (which is a different language pair).", "startOffset": 77, "endOffset": 97}, {"referenceID": 10, "context": "Neural translation attention mechanism (Bahdanau, Cho & Bengio, 2014) has been shown to be highly beneficial for bi-lingual neural translation of long sentences, but it is not compatible with the multi-task multilingual translation models (Dong et al., 2015; Luong et al, 2016) described in the previous Section and character-level translation models (Barzdins & Gosko, 2016) described in this Section.", "startOffset": 239, "endOffset": 277}, {"referenceID": 15, "context": "A better approach to translating such languages is to use the character-level translation model (Barzdins & Gosko, 2016; Karpathy, 2015; Jozefowicz, 2016).", "startOffset": 96, "endOffset": 154}, {"referenceID": 7, "context": "For stream segmentation into the stories it is possible to utilize the exceptional generalization and memorization capacity of the neural networks, which is already applied in the neural dialogue systems such as Gmail Smart Replies (Corrado, 2015; Vinyals&Le, 2015).", "startOffset": 232, "endOffset": 265}, {"referenceID": 22, "context": "Particularly for storyline (Rissen et al., 2013) clustering the signals for the stories belonging to the same storyline might be not so much the semantic similarity of the articles (they might report various developments of the storyline from differing viewpoints), but rather the matching time and location as well as same organizations and people being involved \u2013 the information typically supplied by Named Entity Linking (NEL) tools.", "startOffset": 27, "endOffset": 48}], "year": 2016, "abstractText": "The paper steps outside the comfort-zone of the traditional NLP tasks like automatic speech recognition (ASR) and machine translation (MT) to addresses two novel problems arising in the automated multilingual news monitoring: segmentation of the TV and radio program ASR transcripts into individual stories, and clustering of the individual stories coming from various sources and languages into storylines. Storyline clustering of stories covering the same events is an essential task for inquisitorial media monitoring. We address these two problems jointly by engaging the low-dimensional semantic representation capabilities of the sequence to sequence neural translation models. To enable joint multi-task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding-window mechanism and operate the sequence to sequence neural translation model on the character-level rather than on the word-level. The story segmentation and storyline clustering problem is tackled by examining the low-dimensional vectors produced as a side-product of the neural translation process. The results of this paper describe a novel approach to the automatic story segmentation and storyline clustering problem.", "creator": "Word"}}}