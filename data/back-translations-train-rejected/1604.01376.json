{"id": "1604.01376", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2016", "title": "Lipschitz Continuity of Mahalanobis Distances and Bilinear Forms", "abstract": "Many theoretical results in the machine learning domain stand only for functions that are Lipschitz continuous. Lipschitz continuity is a strong form of continuity that linearly bounds the variations of a function. In this paper, we derive tight Lipschitz constants for two families of metrics: Mahalanobis distances and bounded-space bilinear forms. To our knowledge, this is the first time the Mahalanobis distance is formally proved to be Lipschitz continuous and that such tight Lipschitz constants are derived.", "histories": [["v1", "Mon, 4 Apr 2016 12:39:26 GMT  (8kb)", "http://arxiv.org/abs/1604.01376v1", null]], "reviews": [], "SUBJECTS": "cs.NA cs.LG", "authors": ["valentina zantedeschi", "r\\'emi emonet", "marc sebban"], "accepted": false, "id": "1604.01376"}, "pdf": {"name": "1604.01376.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["remi.emonet@univ-st-etienne.fr", "valentina.zantedeschi@univ-st-etienne.fr", "marc.sebban@univ-st-etienne.fr"], "sections": [{"heading": null, "text": "ar Xiv: 160 4.01 37"}, {"heading": "1 Multi-variate Lipschitz continuity", "text": "Specifically, the slope of the function is limited by a constant independent of the choice of points. This means that the variation of a function that Lipschitz is continuous within a certain interval is small. Let's take the example of the square function: x2 is continuous to Rm, but it is not Lipschitz continuous (the slope of x2 is not limited). We now consider the Lipschitz continuity as a function f: X 2: Rd Rd R.Definition 1,1. (Multi-layered Lipschitz continuity), but it is not Lipschitz continuous (the slope of x2 is not limited). We consider the Lipschitz continuity as a function f: X 2: kn-lipschitz w.r.t. If the norm is wrong, R.Definition 1.1. (Multi-layered Lipschitz continuity) A function f: X: 2 x-lipschitz continuity can be constant."}, {"heading": "2 Derivation for Particular Functions", "text": "In this section we analyze the Lipschitz continuity of two classic metric functions: the Mahalanobis distance and the bilinear form. These two functions are mainly used in the field of machine learning, especially in metric learning."}, {"heading": "2.1 Derivation for Mahalanobis-like Distances", "text": "We remember that the Mahalanobis distance of a pair (x1, x2) = 1 (max.) = 1 (max.) = 1 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) = 2 (max.) \u2212 2 (max.) \u2212 2 (max.) \u2212 2 (max.) \u2212 2 (max.) \u2212 2 (max.) \u2212 2 (max.) \u2212 2 (max.) \u2212 2 (max.) + 2 (max. + 2) max. + 2 (max. + 2) max."}, {"heading": "2.2 Derivation for Bilinear Forms", "text": "We remember that the bilinear form of a pair (x1, x2) is calculated as dM (x1, x2) = xT1 Mx2, where M is a generic matrix that can be optimized. Then: \u2202 dM (x1, x2) \u2202 x1 = \u2202 x1 (xT1 Mx2)) = Mx2 \u2202 dM (x1, x2) \u0445 x2 (xT1 Mx2)) = MTx1.Lemma 2.2. The bilinear similarity dM (x1, x2) = x T 1 Mx2 is k-lipschitz w.r.t.t.t. The standard is 2, with k = \u221a 2 \u0445 M-2 R, if the double-linear similarity dM (x1, x2) = Proof.max."}, {"heading": "3 Conclusion", "text": "In this paper, we have used a method to prove the Lipschitz continuity and to determine a narrow Lipschitz constant of multivariate differentiable functions. By this approach, we have calculated close Lipschitz constants for two families of metrics, which are widely used in metric learning. We have shown that the Mahalanobis distance is Lipschitz continuous and has a constant of 270 cm \u00b2 L \u00b2 2 (where L is the square root of the correlation matrix).We have also shown that the two-dimensional form xMy Lipschitz is continuous, with a constant of 2 cm \u00b2 R. Many theoretical results in the field of machine learning are based on the Lipschitz continuity and depend on the Lipschitz constants. For example, the generalization boundaries achieved in the context of uniform stability (see [1]) can be derived from the limitation of the functions studied on the Lipschitz continuity originally developed on the boundaries of the Lipschitz."}], "references": [{"title": "Metric learning", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Metric learning as convex combinations of local models with generalization guarantees", "author": ["V. Zantedeschi", "R. Emonet", "M. Sebban"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}], "referenceMentions": [], "year": 2016, "abstractText": "Many theoretical results in the machine learning domain stand only for functions that are Lipschitz continuous. Lipschitz continuity is a strong form of continuity that linearly bounds the variations of a function. In this paper, we derive tight Lipschitz constants for two families of metrics: Mahalanobis distances and bounded-space bilinear forms. To our knowledge, this is the first time the Mahalanobis distance is formally proved to be Lipschitz continuous and that such tight Lipschitz constants are derived.", "creator": "LaTeX with hyperref package"}}}