{"id": "1604.01518", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2016", "title": "Simple and Efficient Learning using Privileged Information", "abstract": "The Support Vector Machine using Privileged Information (SVM+) has been proposed to train a classifier to utilize the additional privileged information that is only available in the training phase but not available in the test phase. In this work, we propose an efficient solution for SVM+ by simply utilizing the squared hinge loss instead of the hinge loss as in the existing SVM+ formulation, which interestingly leads to a dual form with less variables and in the same form with the dual of the standard SVM. The proposed algorithm is utilized to leverage the additional web knowledge that is only available during training for the image categorization tasks. The extensive experimental results on both Caltech101 andWebQueries datasets show that our proposed method can achieve a factor of up to hundred times speedup with the comparable accuracy when compared with the existing SVM+ method.", "histories": [["v1", "Wed, 6 Apr 2016 07:33:55 GMT  (16kb)", "http://arxiv.org/abs/1604.01518v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xinxing xu", "joey tianyi zhou", "ivorw tsang", "zheng qin", "rick siow mong goh", "yong liu"], "accepted": false, "id": "1604.01518"}, "pdf": {"name": "1604.01518.pdf", "metadata": {"source": "CRF", "title": "Simple and Efficient Learning using Privileged Information", "authors": ["Xinxing Xu", "Joey Tianyi Zhou", "Ivor W. Tsang", "Zheng Qin", "Rick Siow Mong Goh", "Yong Liu"], "emails": ["liuyong}@ihpc.a-star.edu.sg,", "ivor.tsang@uts.edu.au"], "sections": [{"heading": null, "text": "ar Xiv: 160 4.01 518v 1 [cs.L G] 6A pr2 01"}, {"heading": "1 Introduction", "text": "In traditional machine learning paradigms, classifiers are trained based on the characteristics of training data, and the test is performed with the same type of information. However, in real-world applications, there is additional information that is only available during training, but not available during the test. For example, for the problem of image categorization, we will usually classify images from different categories. SV1 SV1 data set can be used as an example for each training, simply by using its label information, and hence they are only available during the training phase, but not during the test phase. Another example is learning from poorly labeled web images. Images on the web are usually associated with descriptions uploaded by users. Tag information can be collected during training."}, {"heading": "2 Support Vector Machine using Privileged Information with Hinge Loss", "text": "The objective of each machine learning algorithm is therefore to learn a function f (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = x (x) = 1 (x) = x (x) = 1 (x) = x (x) = 1 (x) = 1 (x) = 1 (1) = 1 (x) = 1 (1) = 1 (x) = 1 (x) = 1 = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x) = 1 (x (x) = 1 (x) = 1 (x) = 1 (x (x) = 1 = 1 = 1 (x) = 1 (x) = 1 (x (x) = 1 (x) = 1 (x (x) = 1) = 1 (x (x (x) = 1 = 1) = 1 (x (x (x) = 1) = 1 (x) = 1 (x (x) = 1 (x (x) = 1 = 1) = 1 (x (x) = 1) = 1 (x (x (x) = 1) = 1 (x (x) = 1 (x (x) = 1) = 1 (x (x (x (x) = 1) = 1 = 1 = 1) = 1"}, {"heading": "3 Support Vector Machine using Privileged Information with Squared Hinge Loss", "text": "i.e. i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i.e., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i. i., i. i. i., i. i. i. i. i. i., i. i. i. i. i. i., i. i. i. i., i. i. i. i., i. i. i., i. i. i., i. i. i., i. i., i. i. i., i. i., i. i. i., i. i., i. i., i. i., i. i., i. i., i., i. i., i., i. i., i. i., i., i., i. i., i., i. i., i., i., i. i., i., i., i., i., i., i., i. i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i., i"}, {"heading": "4 Experiments", "text": "In this section we show the experimental results of our proposed algorithm and the basic algorithms for image categorization tasks on the Caltech101 [Li et al., 2007] and WebQueries [Krapac et al., 2010] datasets. We compare our proposed new SVM2 + algorithm with the basic algorithms, i.e. SVM, SVM2K [Farquhar et al., 2005] and SVM1 +. The SVM is trained only on the basis of the visual feature extracted from images, and the SVM2K is a two-view learning algorithm that trains two classifiers simultaneously on the two views, and we only use the visual feature view for prediction. Therefore, SVM2K, SVM1 + and SVM2 + all used the additional privileged information during the training. However, only the images are used for the test on all algorithms, as the preferred information is not available in our learning setting."}, {"heading": "4.1 Dataset Description and Feature Extraction", "text": "Table 1 summarizes the details of the two data sets used in our experiments, which are described below."}, {"heading": "Caltech101", "text": "The Caltech101 dataset 2 contains images from 101 object categories (e.g. \"helicopter,\" \"elephant\" and \"chair,\" etc.) and a background category that does not include images from the 101 object categories. Per object category there are about 40 to 800 images, while most classes have about 50 images. Image resolution is about 300 x 200 pixels. According to the popular settings [Li et al., 2007] we use 10 images per class for training and up to 50 images per category for the test. Finally, we get 1020 images in the training set and 2995 images in the test set."}, {"heading": "WebQueries", "text": "The WebQueries dataset 3 consists of 71,478 images obtained by retrieving a total of 353 textual web queries (e.g. \"Eiffel Tower,\" \"Violin,\" \"Flag of France,\" etc.). For each image in the WebQueries dataset, corresponding text descriptions are available in either English or French. In addition, the relevant labels were commented manually by humans. In our experiments, the images with English queries and the textual queries with more than 100 images are used as evaluation queries according to the Ground Truth Labels. In this way, we receive a total of 76 queries for the final classification tasks. For each of the 76 queries, we used 10 (or 50) images to create the training set (or test sets)."}, {"heading": "Image Feature Extraction", "text": "For image representation, the deep learning features are extracted from each of the images due to its excellent performance for computer vision tasks [Donahue et al., 2014].2http: / / www.vision.caltech.edu / Image Datasets / Caltech101 3https: / / lear.inrialpes.fr / \u0445 krapac / webqueries / webqueries.htmlThe MatConvNet [Vedaldi et al., 2015] is used to extract the deep learning features. In our work, the vggs model [Chatfield et al., 2014] used on the 1.2 million ImageNet dataset [Deng et al., 2009] and the 4096-dimensional output of the fc6 model in the Deep Convolutional Neural Network (CNN) is used from each image as a visual feature representation. The same type of visual features is extracted for both the Caltech 101 and the web quasets."}, {"heading": "Web Knowledge as Privileged Information", "text": "For Caltech101, it is difficult to obtain descriptions for each image. Therefore, we discover the web knowledge by searching the category name of each category from Wikipedia. Subsequently, we collect the text descriptions of each concept from the Wikipedia website. Finally, to obtain the text descriptions for all categories, we use the term Frequency-inverse document frequency (TF-IDF) to convert each text description into the bag of word frequency characteristics. Finally, we obtain a 29,535-dimensional characteristic vector for each object category. During the training, each training image is associated with a vector that represents its object category as its privileged information. As we do not have the basic applicable labels for test images, the privileged information is not available during the test phases.For the WebQueries dataset, each image is associated with a tag that contains a brief description of the image contained in the website of the image (In addition, we collect the entire text descriptions for each of the training images and then remove the top descriptions for each of the training images)."}, {"heading": "4.2 Experimental Results and Discussion", "text": "We use the linear kernel for both the visual feature and the privileged textual feature to train one-on-one classifiers for each object category or query. Classification accuracy is used as a performance measurement. The experimental results with classification accuracy for the various algorithms are shown as in Table 2. We can find that the additional privileged information helps the classification tasks for both sets by using the SVV framework. Therefore, it is advantageous to use web knowledge for the task of image categorization. In addition, the SVM2K is inferior to SVM and the other algorithms, which shows that the formation of the two-view classifiers for both sets is not effective by using the SVV framework. We observe that the results of SVM2 + are inferior to the two sets of Web.The SVM2K is inferior to the two-view classifiers, which shows the SVM algorithms for the other two and the two is not."}, {"heading": "5 Conclusions", "text": "In this thesis, we propose a simple but effective SVM2 + lens function, using square hinge loss instead of hinge loss as in the traditional SVM1 + method, resulting in up to a hundredfold acceleration in the training of SVM + classifiers on image categorization datasets. In the future, we would like to investigate the convergence rate and theoretical limit for our proposed SVM2 +."}], "references": [{"title": "LIBSVM:a library for support vector machines", "author": ["Chang", "Lin", "2001] Chih-Chung Chang", "ChihJen Lin"], "venue": null, "citeRegEx": "Chang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2001}, {"title": "Return of the devil in the details: Delving deep into convolutional nets", "author": ["K. Chatfield", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "British Machine Vision Conference", "citeRegEx": "Chatfield et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "In Machine Learning", "author": ["Corinna Cortes", "Vladimir Vapnik. Support-vector networks"], "venue": "pages 273\u2013297,", "citeRegEx": "Cortes and Vapnik. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods", "author": ["Nello Cristianini", "John Shawe-Taylor"], "venue": "Cambridge University Press,", "citeRegEx": "Cristianini and Shawe.Taylor. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Jia Deng", "Wei Dong", "Richard Socher", "LiJia Li", "Kai Li", "Fei-Fei Li"], "venue": "CVPR, pages 248\u2013255,", "citeRegEx": "Deng et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "ICML", "citeRegEx": "Donahue et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Two view learning: Svm-2k", "author": ["Jason D.R. Farquhar", "David R. Hardoon", "Hongying Meng", "John Shawe-Taylor", "S\u00e1ndor Szedm\u00e1k"], "venue": "theory and practice. In NIPS, pages 355\u2013362,", "citeRegEx": "Farquhar et al.. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Inf", "author": ["Jan Feyereisl", "Uwe Aickelin. Privileged information for data clustering"], "venue": "Sci., 194:4\u201323,", "citeRegEx": "Feyereisl and Aickelin. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "In ICANN", "author": ["Shereen Fouad", "Peter Ti\u00f1o", "Somak Raychaudhury", "Petra Schneider. Learning using privileged information in prototype based models"], "venue": "pages 322\u2013329,", "citeRegEx": "Fouad et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Neural Netw", "author": ["Shereen Fouad", "Peter Ti\u00f1o", "Somak Raychaudhury", "Petra Schneider. Incorporating privileged information through metric learning. IEEE Trans"], "venue": "Learning Syst., 24(7):1086\u20131098,", "citeRegEx": "Fouad et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Mind the nuisance: Gaussian process classification using privileged noise", "author": ["Daniel Hern\u00e1ndez-Lobato", "Viktoriia Sharmanska", "Kristian Kersting", "Christoph H. Lampert", "Novi Quadrianto"], "venue": "NIPS, pages 837\u2013845,", "citeRegEx": "Hern\u00e1ndez.Lobato et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Making large-scale SVM learning practical", "author": ["T. Joachims"], "venue": "B. Sch\u00f6lkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning, chapter 11, pages 169\u2013184. MIT Press, Cambridge, MA", "citeRegEx": "Joachims. 1999", "shortCiteRegEx": null, "year": 1999}, {"title": "Improving web image search", "author": ["Krapac et al", "2010] Josip Krapac", "Moray Allan", "Jakob J. Verbeek", "Fr\u00e9d\u00e9ric Jurie"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Learning using privileged information: SVM+ and weighted SVM", "author": ["Maksim Lapin", "Matthias Hein", "Bernt Schiele"], "venue": "Neural Networks, 53:95\u2013108,", "citeRegEx": "Lapin et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories", "author": ["Fei-Fei Li", "Robert Fergus", "Pietro Perona"], "venue": "Computer Vision and Image Understanding, 106(1):59\u201370,", "citeRegEx": "Li et al.. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "CoRR", "author": ["David Lopez-Paz", "L\u00e9on Bottou", "Bernhard Sch\u00f6lkopf", "Vladimir Vapnik. Unifying distillation", "privileged information"], "venue": "abs/1511.03643,", "citeRegEx": "Lopez.Paz et al.. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural Netw", "author": ["Li Niu", "Xinxing Xu", "Lin Chen", "Lixin Duan", "Dong Xu. Action", "event recognition in videos by learning from heterogeneous web sources. IEEE Trans"], "venue": "Learning Syst., March", "citeRegEx": "Niu et al.. 2016", "shortCiteRegEx": null, "year": 2016}, {"title": "In NIPS", "author": ["Dmitry Pechyony", "Vladimir Vapnik. On the theory of learnining with privileged information"], "venue": "pages 1894\u20131902,", "citeRegEx": "Pechyony and Vapnik. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "In DMIN", "author": ["Dmitry Pechyony", "Rauf Izmailov", "Akshay Vashist", "Vladimir Vapnik. Smo-style algorithms for learning using privileged information"], "venue": "pages 235\u2013241,", "citeRegEx": "Pechyony et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "In Proceedings of the 14th International Conference on Computer Vision", "author": ["Viktoriia Sharmanska", "Novi Quadrianto", "Christoph H. Lampert. Learning to rank using privileged information"], "venue": "pages 825\u2013832, Sydney, Australia, Dec.", "citeRegEx": "Sharmanska et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning using privileged information: Similarity control and knowledge transfer", "author": ["Vladimir Vapnik", "Rauf Izmailov"], "venue": "Journal of Machine Learning Research, 16:2023\u20132049,", "citeRegEx": "Vapnik and Izmailov. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "A new learning paradigm: Learning using privileged information", "author": ["Vladimir Vapnik", "Akshay Vashist"], "venue": "Neural Networks, 22(5-6):544\u2013557,", "citeRegEx": "Vapnik and Vashist. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Matconvnet: Convolutional neural networks for MATLAB", "author": ["Andrea Vedaldi", "Karel Lenc"], "venue": "Proceedings of the 23rd Annual ACM Conference on Multimedia Conference, MM \u201915, Brisbane, Australia, October 26 - 30, 2015, pages 689\u2013692,", "citeRegEx": "Vedaldi and Lenc. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural Netw", "author": ["Xinxing Xu", "Ivor W. Tsang", "Dong Xu. Soft margin multiple kernel learning. IEEE Trans"], "venue": "Learning Syst., 24(5):749\u2013761,", "citeRegEx": "Xu et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Neural Netw", "author": ["Xinxing Xu", "Wen Li", "Dong Xu. Distance metric learning using privileged information for face verification", "person re-identification. IEEE Trans"], "venue": "Learning Syst., 26(12):3150\u20133162,", "citeRegEx": "Xu et al.. 2015", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 21, "context": "The aforementioned two examples fall into the new learning paradigm of the Learning using Privileged Information (LUPI) [Vapnik and Vashist, 2009], in which the additional information is referred to as the privileged information.", "startOffset": 120, "endOffset": 146}, {"referenceID": 21, "context": "The Support Vector Machine using Privileged Information (SVM+) [Vapnik and Vashist, 2009] has been proposed for utilizing the privileged information.", "startOffset": 63, "endOffset": 89}, {"referenceID": 21, "context": "As the hinge loss is used in [Vapnik and Vashist, 2009], we refer to the formulation in their work as SVM1+ in the following.", "startOffset": 29, "endOffset": 55}, {"referenceID": 17, "context": "It has been proved theoretically that the incorporating of the additional privileged information can improve the convergence rate [Pechyony and Vapnik, 2010].", "startOffset": 130, "endOffset": 157}, {"referenceID": 20, "context": "The SVM+ attracts much attention recently [Vapnik and Izmailov, 2015; Lopez-Paz et al., 2015; Lapin et al., 2014], and has been successfully applied to different applications [Niu et al.", "startOffset": 42, "endOffset": 113}, {"referenceID": 15, "context": "The SVM+ attracts much attention recently [Vapnik and Izmailov, 2015; Lopez-Paz et al., 2015; Lapin et al., 2014], and has been successfully applied to different applications [Niu et al.", "startOffset": 42, "endOffset": 113}, {"referenceID": 13, "context": "The SVM+ attracts much attention recently [Vapnik and Izmailov, 2015; Lopez-Paz et al., 2015; Lapin et al., 2014], and has been successfully applied to different applications [Niu et al.", "startOffset": 42, "endOffset": 113}, {"referenceID": 16, "context": ", 2014], and has been successfully applied to different applications [Niu et al., 2016; Sharmanska et al., 2013; Fouad et al., 2012].", "startOffset": 69, "endOffset": 132}, {"referenceID": 19, "context": ", 2014], and has been successfully applied to different applications [Niu et al., 2016; Sharmanska et al., 2013; Fouad et al., 2012].", "startOffset": 69, "endOffset": 132}, {"referenceID": 8, "context": ", 2014], and has been successfully applied to different applications [Niu et al., 2016; Sharmanska et al., 2013; Fouad et al., 2012].", "startOffset": 69, "endOffset": 132}, {"referenceID": 19, "context": "Following this learning scenario, some recent works proposed to utilize the privileged information for the different learning scenarios such as learning to rank [Sharmanska et al., 2013], Gaussian Process classifier [Hern\u00e1ndez-Lobato et al.", "startOffset": 161, "endOffset": 186}, {"referenceID": 10, "context": ", 2013], Gaussian Process classifier [Hern\u00e1ndez-Lobato et al., 2014], clustering [Feyereisl and Aickelin, 2012] and distance metric learning [Fouad et al.", "startOffset": 37, "endOffset": 68}, {"referenceID": 7, "context": ", 2014], clustering [Feyereisl and Aickelin, 2012] and distance metric learning [Fouad et al.", "startOffset": 20, "endOffset": 50}, {"referenceID": 9, "context": ", 2014], clustering [Feyereisl and Aickelin, 2012] and distance metric learning [Fouad et al., 2013; Xu et al., 2015].", "startOffset": 80, "endOffset": 117}, {"referenceID": 24, "context": ", 2014], clustering [Feyereisl and Aickelin, 2012] and distance metric learning [Fouad et al., 2013; Xu et al., 2015].", "startOffset": 80, "endOffset": 117}, {"referenceID": 21, "context": "However, the proposed optimization method for SVM1+ in [Vapnik and Vashist, 2009] is based on its dual form.", "startOffset": 55, "endOffset": 81}, {"referenceID": 2, "context": "If there are a total number of n training data, the corresponding dual problem is a Quadratic Programming (QP) problem with 2n variables, which is 2 times larger than the dual form of the standard SVM [Cortes and Vapnik, 1995] with only n variables.", "startOffset": 201, "endOffset": 226}, {"referenceID": 11, "context": "Besides, as the constraints in the dual form of SVM+ are different with those in the dual form of the standard SVM, the efficient implementations and the off-the-shelf solvers for SVM such as LibSVM [Chang and Lin, 2001] and SVMLight [Joachims, 1999] can not be readily utilized, and the additional efforts must be spent to design the specific solvers for optimization of SVM1+ [Pechyony et al.", "startOffset": 234, "endOffset": 250}, {"referenceID": 18, "context": "Besides, as the constraints in the dual form of SVM+ are different with those in the dual form of the standard SVM, the efficient implementations and the off-the-shelf solvers for SVM such as LibSVM [Chang and Lin, 2001] and SVMLight [Joachims, 1999] can not be readily utilized, and the additional efforts must be spent to design the specific solvers for optimization of SVM1+ [Pechyony et al., 2010].", "startOffset": 378, "endOffset": 401}, {"referenceID": 21, "context": "WebQueries) when compared with the solution for SVM1+ as in [Vapnik and Vashist, 2009] yet with comparable classification accuracies.", "startOffset": 60, "endOffset": 86}, {"referenceID": 17, "context": "The X is referred to as the decision space as the test is done only in X , while Z is referred to as the correcting space [Pechyony and Vapnik, 2010].", "startOffset": 122, "endOffset": 149}, {"referenceID": 21, "context": "The support vector machine using privileged information (SVM+) has been proposed in [Vapnik and Vashist, 2009] for utilizing the privileged information.", "startOffset": 84, "endOffset": 110}, {"referenceID": 21, "context": "Specifically, f(x) = wx + b is the decision function based on the main feature x and g(z) = zv + \u03c1 is the correcting function based on the privileged information z, and the SVM+ with hinge loss (SVM1+) is proposed to optimize the following objective function [Vapnik and Vashist, 2009]:", "startOffset": 259, "endOffset": 285}, {"referenceID": 21, "context": "The objective function in (1) is solved in its dual form as in [Vapnik and Vashist, 2009; Vapnik and Izmailov, 2015].", "startOffset": 63, "endOffset": 116}, {"referenceID": 20, "context": "The objective function in (1) is solved in its dual form as in [Vapnik and Vashist, 2009; Vapnik and Izmailov, 2015].", "startOffset": 63, "endOffset": 116}, {"referenceID": 23, "context": "Although it is linear kernel here, any type of non-linear kernel [Xu et al., 2013] can be readily utilized in (2).", "startOffset": 65, "endOffset": 82}, {"referenceID": 18, "context": "Therefore, additional efforts are required for the development of the efficient solution and the softwares such as [Pechyony et al., 2010].", "startOffset": 115, "endOffset": 138}, {"referenceID": 3, "context": "In order to solve the SVM+ more efficiently and motivated by the using of squared hinge loss for SVM [Cristianini and Shawe-Taylor, 2000], we propose the Support Vector Machine using Privileged Information with Squared Hinge Loss (SVM2+).", "startOffset": 101, "endOffset": 137}, {"referenceID": 2, "context": "More importantly, the QP problem in (4) also shares the same form with the QP problem of that of the classical SVM [Cortes and Vapnik, 1995].", "startOffset": 115, "endOffset": 140}, {"referenceID": 14, "context": "In this section, we show the experimental results of our proposed algorithm and the baseline algorithms for image categorization tasks on the Caltech101 [Li et al., 2007] and the WebQueries [Krapac et al.", "startOffset": 153, "endOffset": 170}, {"referenceID": 6, "context": ", SVM, SVM2K [Farquhar et al., 2005] and SVM1+.", "startOffset": 13, "endOffset": 36}, {"referenceID": 14, "context": "Following the popular settings [Li et al., 2007], we utilize 10 images per class for training and up to 50 images per category for the test.", "startOffset": 31, "endOffset": 48}, {"referenceID": 5, "context": "For the image representation, the deep learning features are extracted from each of the images due to its excellent performance for computer vision tasks [Donahue et al., 2014].", "startOffset": 154, "endOffset": 176}, {"referenceID": 22, "context": "The MatConvNet [Vedaldi and Lenc, 2015] is used to extract the deep learning features.", "startOffset": 15, "endOffset": 39}, {"referenceID": 1, "context": "The vggs model [Chatfield et al., 2014] is used in our work.", "startOffset": 15, "endOffset": 39}, {"referenceID": 4, "context": "2 million ImageNet dataset [Deng et al., 2009], and the 4096-dimensional output of the fc6 in the deep Convolutional Neural Network (CNN) model from each image is employed as the visual feature representation.", "startOffset": 27, "endOffset": 46}], "year": 2016, "abstractText": "The Support Vector Machine using Privileged Information (SVM+) has been proposed to train a classifier to utilize the additional privileged information that is only available in the training phase but not available in the test phase. In this work, we propose an efficient solution for SVM+ by simply utilizing the squared hinge loss instead of the hinge loss as in the existing SVM+ formulation, which interestingly leads to a dual form with less variables and in the same form with the dual of the standard SVM. The proposed algorithm is utilized to leverage the additional web knowledge that is only available during training for the image categorization tasks. The extensive experimental results on both Caltech101 and WebQueries datasets show that our proposed method can achieve a factor of up to hundred times speedup with the comparable accuracy when compared with the existing SVM+ method.", "creator": "LaTeX with hyperref package"}}}