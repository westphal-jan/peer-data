{"id": "1604.01686", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2016", "title": "Relationship between Variants of One-Class Nearest Neighbours and Creating their Accurate Ensembles", "abstract": "In one-class classification (OCC) problems, only the data for the target class is available, whereas the data for the non-target class may be completely absent. In this paper, we study one-class nearest neighbour (OCNN) classifiers and their different variants for the OCC problem. We present a theoretical analysis to show the equivalence among different variants of OCNN that may use different neighbours or thresholds to identify unseen examples of the non-target class. We also present a method based on inter-quartile range for optimizing parameters used in OCNN in the absence of non-target data during training. Then, we propose to use two ensemble approaches based on random sub-space and random projection approaches to create accurate ensemble that significantly outperforms the baseline OCNN. We tested the proposed methods on various benchmark and real word domain-specific datasets to show their superior performance. The results give strong evidence that the random projection ensemble of the proposed OCNN with optimized parameters variants perform significantly and consistently better than the single OCC on all the tested datasets.", "histories": [["v1", "Wed, 6 Apr 2016 16:36:41 GMT  (371kb,D)", "http://arxiv.org/abs/1604.01686v1", "38 pages, 3 figures"], ["v2", "Fri, 28 Oct 2016 18:00:42 GMT  (385kb,D)", "http://arxiv.org/abs/1604.01686v2", "42 pages, 9 figures, 3 Tables"], ["v3", "Fri, 24 Feb 2017 21:30:42 GMT  (391kb,D)", "http://arxiv.org/abs/1604.01686v3", "14 pages, 9 figures, 3 Tables"], ["v4", "Wed, 22 Mar 2017 20:56:34 GMT  (391kb,D)", "http://arxiv.org/abs/1604.01686v4", "14 pages, 9 figures, 3 Tables"]], "COMMENTS": "38 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["shehroz s khan", "amir ahmad"], "accepted": false, "id": "1604.01686"}, "pdf": {"name": "1604.01686.pdf", "metadata": {"source": "CRF", "title": "Equivalence Among Different Variants of One-Class Nearest Neighbours and Creating Their Accurate Ensembles", "authors": ["Shehroz S. Khan", "Amir Ahmad"], "emails": ["s255khan@uwaterloo.ca", "amirahmad01@gmail.com"], "sections": [{"heading": null, "text": "* Corresponding email addresses of the author: s255khan @ uwaterloo.ca (Shehroz S. Khan), amirahmad01 @ gmail.com (Amir Ahmad) Preprint submitted to Information Sciences September 4, 2017ar Xiv: 160 4.01 686v 1 [cs.L G"}, {"heading": "1. Introduction", "text": "In most cases, however, it is easy to collect the data describing the normal behavior of people. In other cases, it is easy to collect the data describing the normal behavior of people. In other cases, it is easy to collect and analyze the data. In other cases, it is easy to collect the data. In other cases, it is easy to collect the data describing the normal behavior of people. In other cases, it is difficult to collect the data. In other cases, it is easy to collect the data. In other cases, the data is collected in the negative class, even if the data is collected for the negative class."}, {"heading": "2. Related Work", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "3. One-Class Nearest Neighbour Classifiers (OCNN)", "text": "Based on the literature search in Section 2, different OCNN methods can be divided into the following four types, based on the number of closest neighbors they use to calculate the decision threshold: (i) Find the first closest neighbor of the test sample in the target class and the first closest neighbor of the first neighbor (11NN) [5, 12, 13, 15, 16]. (ii) Find the first closest neighbor of the test sample in the target class and the closest neighbor of the first neighbor of the first neighbor (1KNN) [18, 19, 20]. (iii) Find the closest neighbor of the test sample in the target class and the closest neighbor of the first neighbor of the first neighbor J (J1NN) [17]. (iv) Find the closest neighbor of the test sample in the target class and the closest neighbor of the closest neighbor K in the target class show the closest neighbor of the first neighbor J (JKNN). These different OCNN methods may differ in distance metrics, with the distances between the target J in the target class and the final group drawing (1) showing the distance between the decision of the final neighbor (group 1)."}, {"heading": "3.1. One-Class JK Nearest Neighbour", "text": "We now present a general OCNN (JKNN) method for detecting invisible members of the negative class. In this method, we find the J nearest neighbor (NN trj (z)) of the test sample (z) in the target class and find its average, D \u0445J.2. Find the K nearest neighbor of these J neighbors (NN trk (NN trj (z))) and find their average, D \u30fb K. For a certain decision threshold, \u03b8 applies if the test data object is considered a member of the target class or otherwise rejected as a member of the negative class. Algorithm 2 shows the steps to classify a test data object as a member of the target class or not. This algorithm differs from Khan's work [23] in two respects. First, they use the core as a distance metric, while we use Euclidean as a distance metric."}, {"heading": "3.2. Relationship Among Different OCNN approaches", "text": "In this section we will show that the varying decision threshold (\u03b8) with 11NN is similar to other OCNN methods used in Section 3.In the present figure (Figure. 1a), the distance between the new data point and its next adjacent data point is calculated and compared with the distance between the next adjacent data point and its closest neighbor. In this case, even if D1 is slightly more than D2, the test data point is assigned to the negative class. Intuitively, an outlier data point should be at a much greater distance from its closest neighbor (D1) than the distance between that closest neighbor and its closest neighbor (D2). Mathematically, this can be represented as D2."}, {"heading": "3.3. Classifier Ensemble", "text": "However, we suggest that classifier ensembles approach can be used to improve the performance of OCNN methods. Creating accurate and diverse classifiers is the key to accurate ensembles [6]. Creating diverse feature spaces to create diverse NN classifiers is a popular method [10] for NN ensembles. We will use similar approaches for ensembles of OCNN classifiers. In this section, we will discuss two approaches to creating diverse classifier ensembles; Random Subspace and Random Projection. Random Subspace is a popular method for creating ensembles [33]. In any case, a classifier is trained on a randomly selected feature subroom of the original feature space. This creates different classifiers, which in turn create a precise ensemble. Random Subspace technique has also been used to create ensembles for detecting outliers. [34] Projector ensembles of different projector spaces are generated by CNN randomly dimensional ensembles, which are high precision ensembles."}, {"heading": "4. Parameter Optimization for OCNN", "text": "In this section, we will discuss a method by which noisy points of a single class dataset are considered a wrong problem. J can be used to optimize the parameters. We note that the different variants of OCNN discussed in Section 3 (shown in Figure 1) may suffer from one or both of the following problems: 1. Sensitivity to noise - However, the real target data may include noisy observations due to uncalibrated data acquisition devices, human errors in labeling, or accidental artifacts.The one-class approximations discussed above ignore this fact, and the presence of such deviating observations in the target class can make these classifiers sensitive to noise. This case can occur when most of the target data densify toward their center, but some data objects are far from it.This behavior may cause outliers to be accepted as members of the target classes.2. False Negative Negative - If noisy observations are removed from the dataset, but the target class is not neglected, the problem may be a decision class."}, {"heading": "4.1. Removing noise from the target class", "text": "As discussed in the previous section, noise in the target data may arise for various reasons and its presence may adversely affect the decision of the NN-d-based classifier by accepting outliers as members of the target class during the test phase. We present a method to remove the noisy observations based on the Inter-Quarle Range (IQR). Khan et al. [39] show that for the human case detection problem where the data for falls are difficult to obtain, deviating normal human movements can be removed from normal human activities using the IQR technique. These deviating sequences can be used as a proxy for real falls and help in optimizing the parameters of the likely classifier. They use the Hidden Markov Model (HMM) based classification techniques and obtain log similarities of training sequences from the normal activities and apply IQR technology to them to remove the noisy sequences from this apparent technique, although it may be modified specifically for classifier types."}, {"heading": "4.2. Cross Validation", "text": "In a binary or multi-level classification problem, cross-validation is often used to estimate the parameters of a classification algorithm on a validation set, and these parameters are used during the test to classify the test samples. In OCC problems, estimating parameters using cross-validation becomes difficult due to the absence of negative data in the validation phase, because in the OCC the data is only available to the target class during training and the negative class data only appears during the test (along with the target data). We are now introducing a cross-validation method to optimize the nearest neighbors J and K for the JKNN classifier when the decision threshold is set to 1. First, we select the number of cross-validation folds, say F. Then we divide the data set to merge the target data from (F \u2212 1) and become outliers (see Section 4.1)."}, {"heading": "4.2.1. How many noisy observations to reject from the target class?", "text": "As already mentioned, noisy observations can be removed from the training data using the IQR technique (Section 4.1) to establish the validation rate for testing the single-class JKNN classifier. The amount of observations to reject depends on the coverage parameter \u03c9. A higher value of \u03c9 results in fewer repulsions and a lower value means more repulsions. In the internal cross-validation method described in Section 4.2, the validation rate should contain at least one observation as an outlier substitute in each inner fold G. As a rule of thumb, the value of \u03c9 should be chosen in such a way that at least G data objects from the target class are rejected as outliers. Therefore, the value of \u03c9 can be chosen either with domain knowledge or with hit-and-trial method. In our experiments, we mostly chose \u03c9 = 1.5, and if this did not yield the desired number of rejected targets, it will be reduced until the desired number of targets is rejected."}, {"heading": "4.3. Optimizing Decision Threshold", "text": "We discussed the equivalence relationship between JKNN with \u03b8 = 1 and 11NN with variable threshold. To optimize the decision threshold \u03b8 for 11NN, we use the same strategy for optimizing J and K as discussed above, using the rejected outliers from the positive threshold as substitutes for invisible negative class. Then, we use a modified empirical threshold algorithm [46] to optimize the decision threshold. The general idea of the original threshold algorithm is to select an empirical threshold from the training instances according to the misclassification costs. This method can convert any cost-insensitive algorithm into cost-sensitive by looking for the probability that minimizes the mization costs across all training instances as the threshold for predicting the test instances. The advantage of this method is that it is least sensitive when the difference in the misclassification costs is high, it does not require an exact estimate of the probabilities, but rather is sufficient for an internal validation and can be used for possible validation."}, {"heading": "5. Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Performance Metric", "text": "Some of the popular metrics are accuracy, precision, recall, F measurement, AUC, etc. However, a single-class classification represents a unique scenario if target data is sufficiently available during training and negative data is not available. Therefore, when testing the OCC, we would expect to observe a highly distorted distribution of negative data over target data. In this sense, the problem becomes one of highly unbalanced test sets during the test to evaluate the performance of a classifier. Because of this type of test data, conventional performance metrics (e.g. accuracy) cannot be applied directly to the numbers it produces. Other metrics such as F measurement depend on precision and recall, and if all test data is classified as target or negative, then there may be NaN values for precision / recall. Kubat and Matwin [48] use the geometric metric metric (gmean)."}, {"heading": "5.2. Datasets", "text": "There are no standard data sets for testing OCC algorithms, so we test our methods on data sets that have a high imbalance between the number of positive and negative labeled data, in order to highlight the OCC problem where negative class data is rare. However, in our analysis, only positive class data is used during training and parameter optimization, and no negative class data is available during training. Negative and positive class data is available during the test. We show the results using 9 benchmark data sets from the KEEL repository [49] and four domain-specific real data sets described below."}, {"heading": "5.2.1. KEEL Benchmark datasets", "text": "KEEL Dataset Repository provides multiple datasets for testing machine learning algorithms. We select 12 datasets, especially those that have real value characteristics and a high imbalance. Details of these datasets are shown in Table 1."}, {"heading": "5.2.2. German Aerospace Center (DLR) [50]", "text": "This data set is collected using the XSens MTx sensor, an inertial measurement unit (IMU) with built-in 3D magnetometers. It has an embedded processor capable of calculating the orientation of the sensor in real time, and provides calibrated 3D linear acceleration, speed and magnetic field data. Orientation information from the IMU can be determined by the direction of the cosine matrix and the sample frequency is set to 100 Hz. In total, the data set contains data from over 4 hours and 30 minutes of the following 7 activities: standing, sitting, lying, walking (up / down, horizontal), jogging / jumping, each of which consists of a sample and one in each direction."}, {"heading": "5.2.3. MobiFall (MF) [51]", "text": "This data set was collected using a Samsung Galaxy S3 mobile device with inertial module, integrated with a 3D accelerometer and gyroscope, in a trouser pocket randomly chosen by the subjects. In case of falls, the subjects placed the mobile phone in the pocket on the opposite side of the fall direction. All falls were monitored in a specific way. Data stores the time stamp for convenient sampling, but for the accelerometer an average sampling of 87 Hz and for the gyroscope of 200 Hz is reported. The data set is collected from 11 subjects who perform various normal and fall activities and 2 subjects perform only fall activities; therefore, they are excluded from the analysis. In this data set, the following 8 normal activities are recorded: step-in car, step-out, jogging, jumping, sitting, standing, standing up and down and walking."}, {"heading": "5.2.4. Coventry Dataset (COV) [52]", "text": "This data set is collected using two SHIMMERTMor sensor nodes attached to the chest and thighs of subjects, which consist of a 3D accelerometer, a 3D gyroscope and a Bluetooth device. [53] The data was collected at 100 Hz and transmitted and commented on to a remote PC. Two protocols were followed to collect data from subjects. In Protocol 1, data were induced for four types of falls, near-1, by applying a lateral force and a series of ADLs (standing, seated, walking and lying) were collected. Protocol 2 included climbing and descending stairs. 42 healthy young people simulated various ADL and fall scenarios, with 32 participating in Protocols 1 and 10 in Protocol 2. For Protocol 1, the activities were collected in a real life in which subjects read phone calls, books or talked to others while maintaining different positions."}, {"heading": "5.2.5. Aging-related bugs and software complexity metrics", "text": "This dataset contains information about the age-related errors found in the Linux kernel and in MySQL DBMS open source projects. [55] This dataset is designed to examine error prediction for age-related errors using software complexity metrics and machine learning techniques. [55] The data repository contains several datasets, and we select two of them: Linux Driver (LD) and MySQL InnoDB (MI). Both datasets contain 82 attributes (plus a class name) related to program size, age-related errors, and software complexity metrics. The LI dataset contains 2283 positive instances and 9 negative instances (imbalance ratio of 253.66), while the MI dataset contains 370 positive instances and 32 negative instances (imbalance ratio of 11.56). The reason for using this dataset is the motivation for CC applications, which are very low in the negative examples."}, {"heading": "5.2.6. Breast Cancer Data", "text": "The original breast cancer data are available in the UCI repository [14] and have been modified by the German Research Center for Artificial Intelligence [56] to be used for unattended outlier detection. 30 attributes with 357 normal cases and 10 negative samples with an unbalanced ratio of 35.7 are present in the modified data."}, {"heading": "5.3. Experimental Setup", "text": "To perform the experiment, we specify the following values of the parameters: \u2022 5x outer cross-validation \u2022 2x inner cross-validation (for parameter optimization) \u2022 The maximum number of J and K neighbors to be optimized in the OCNN dataset is set to 10. For the DLR, MF, and COV datasets, this number is set to 5 because we could not achieve results in a reasonable amount of time with a large number of closest neighbors. \u2022 Size of the random subspace is set to 50% and 75% of the total size of the randomly selected attributes. \u2022 Size of the ensemble for random subspaces: Random projection is set to 25 [57]. \u2022 Rejection rate is set to 1.5, i.e. for some datasets, it is manually decreased until all classifiers are able to reject at least 5 instances from the positive class. \u2022 The data is normalized using the Minmax method to be within [0, 1], i.e., xi = min \u2212 (x) (.x) x (x) where the values mentioned above are x x (x) and x (.11x)."}, {"heading": "5.4. Experimental Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.4.1. KEEL Benchmark Datasets", "text": "The results of the first experiment of the KEEL benchmark datasets are presented in Table 2 under the heading \"Single\" for each of the specific OCNN techniques (11NN with optimized systems, JKNN and 11NN).The results show that 11NN produces the best (gmean) for 6 of 9 datasets (we observe that 11NN has high TNR values for all datasets, while 11NN the limit for 11NN produces the better TPR values compared to 11NN. This means that the class limits of 11NN are set (\u03b8) and JKNN favorites are accepted as a member of the target class, resulting in fewer false positives, whereas the limit for 11NN beneficiaries results in more samples than negatives, resulting in fewer false negatives. Since gmean combinations of both TPR and TNR with equal weights, there was a higher value of the power metry to 11NN. Alternatively, we can reject these N11N values as fewer false negatives, resulting in fewer false negatives."}, {"heading": "5.4.2. Domain-Specific Real Datasets", "text": "The results of the first experiment at MobiFall, DLR, Coventry, Linux Driver, MySQL-IDB and Breast Cancer datasets are shown in Table 3 under the \"Single\" column for each of the specific OCNN techniques, i.e. 11NN with optimized technology, JKNN and 11NN. Similar to the results on KEEL benchmark datasets, we will find that JKNN and 11NN each tend to the positive class better than the 11NN, resulting in higher TPR costs for lower TNR. However, in these datasets, individual JKNN are always better than individual 11NN in terms of gmean. For three datasets (DLR, Coventry and Breast-Cancer) individual 11NN groups are better than individual 11NN values. These datasets better represent a class classification problem and the negative class are in regions of low density."}, {"heading": "6. Conclusions and Future Work", "text": "In this paper, a theoretical analysis was presented to demonstrate the equivalence and relationship between the different variants of OCNN. We presented a technique for optimizing the parameters for the proposed OCNN, which uses only data from the target class, as the data for the negative data may be missing during the training phase. We tested the proposed methods using 15 benchmark and domain specific data sets, and showed that the RP ensembles of JKNN and 11NN (\u03b8) are highly accurate, especially in identifying the invisible negative samples and the good balance in identifying the members of the target class. 11NN (\u03b8) RP ensembles are fairly accurate; the JKNN RP ensembles are not far behind. Results also provide definitive evidence that individual OCNN classifiers are not a good choice for dealing with classified classification problems when the next adjacent approach is applied, their ensembles tend to perform better."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In one-class classification (OCC) problems, only the data for the target class<lb>is available, whereas the data for the non-target class may be completely ab-<lb>sent. In this paper, we study one-class nearest neighbour (OCNN) classifiers<lb>and their different variants for the OCC problem. We present a theoreti-<lb>cal analysis to show the equivalence among different variants of OCNN that<lb>may use different neighbours or thresholds to identify unseen examples of<lb>the non-target class. We also present a method based on inter-quartile range<lb>for optimizing parameters used in OCNN in the absence of non-target data<lb>during training. Then, we propose to use two ensemble approaches based on<lb>random sub-space and random projection approaches to create accurate en-<lb>semble that significantly outperforms the baseline OCNN. We tested the pro-<lb>posed methods on various benchmark and real word domain-specific datasets<lb>to show their superior performance. The results give strong evidence that the<lb>random projection ensemble of the proposed OCNN with optimized param-<lb>eters variants perform significantly and consistently better than the single<lb>OCC on all the tested datasets.", "creator": "LaTeX with hyperref package"}}}