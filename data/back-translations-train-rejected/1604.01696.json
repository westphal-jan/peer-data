{"id": "1604.01696", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2016", "title": "A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories", "abstract": "Representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding. This issue is particularly challenging for understanding casual and correlational relationships between events. While this topic has received a lot of interest in the NLP community, research has been hindered by the lack of a proper evaluation framework. This paper attempts to address this problem with a new framework for evaluating story understanding and script learning: the 'Story Cloze Test'. This test requires a system to choose the correct ending to a four-sentence story. We created a new corpus of ~50k five-sentence commonsense stories, ROCStories, to enable this evaluation. This corpus is unique in two ways: (1) it captures a rich set of causal and temporal commonsense relations between daily events, and (2) it is a high quality collection of everyday life stories that can also be used for story generation. Experimental evaluation shows that a host of baselines and state-of-the-art models based on shallow language understanding struggle to achieve a high score on the Story Cloze Test. We discuss these implications for script and story learning, and offer suggestions for deeper language understanding.", "histories": [["v1", "Wed, 6 Apr 2016 17:15:10 GMT  (607kb,D)", "http://arxiv.org/abs/1604.01696v1", "In Proceedings of the 2016 North American Chapter of the ACL (NAACL HLT), 2016"]], "COMMENTS": "In Proceedings of the 2016 North American Chapter of the ACL (NAACL HLT), 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["nasrin mostafazadeh", "nathanael chambers", "xiaodong he", "devi parikh", "dhruv batra", "lucy vanderwende", "pushmeet kohli", "james allen"], "accepted": false, "id": "1604.01696"}, "pdf": {"name": "1604.01696.pdf", "metadata": {"source": "CRF", "title": "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories", "authors": ["Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen"], "emails": ["nasrinm@cs.rochester.edu,", "james@cs.rochester.edu,", "nchamber@usna.edu,", "parikh@vt.edu,", "dbatra@vt.edu,", "xiaohe@microsoft.com", "lucyv@microsoft.com", "pkohli@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "It is a very difficult task in the field of scientific understanding, where knowledge of the origin and realization of history plays a major role. It is a very complex and complex story, in which it is important to understand history and narrative. It ranges from generic models of action to complex systems that can be assembled in collaboration with people. It is a great challenge for understanding history (and creating stories), the question is how to communicate everyday knowledge in relation to everyday events and machinations. A large part of the work in the field of understanding history focuses on learning scripts (Schank and Abelson, 1977). Scripts represent structured knowledge of stereotypical sequences of events along with their participants. It is obvious that various NLP applications (summaries, questions, answers, etc.) can greatly benefit from the rich capabilities that represent structured knowledge of events."}, {"heading": "2 Related Work", "text": "Several lines of research have recently focused on the learning of narrative / event representations. Chambers and Jurafsky initially proposed narrative chains (Chambers and Jurafsky, 2008) as a partially ordered series of narrative events that share a common actor, the \"protagonist.\" A narrative event is a tuple of an event (a verb) and its participants are presented as typical dependencies. Several extensions have since been proposed, including narrative schemes (Chambers and Jurafsky, 2009), script sequences (Regneri et al., 2010), and relegrams (Balasubramanian et al, 2013). Formal probability models have also been proposed to learn event schemas and action frameworks (Cheung et al., 2013; Bamman et al., 2013; Nguyen et al., 2015), which are trained on smaller companies and focus less on large-scale learning."}, {"heading": "3 A Corpus of Short Commonsense Stories", "text": "We sought to build a corpus with two goals in mind: 1. The corpus contains a variety of causal and temporal relationships between everyday common-sense events, enabling us to learn a narrative structure across a series of events, as opposed to a single domain or genre. 2. The corpus is a high-quality collection of everyday nonfiction short stories that can be used to train rich coherent narrative models. To narrow our focus, we carefully define a narrative or story as follows: \"A narrative or story is all that is told in the form of a causally (logically) linked series of events involving some common characters.\" The classical definition of a story requires an action (e.g. a character who follows a goal and faces obstacles), but we are not concerned here with how entertaining or dramatic the stories are. Instead, we are concerned with the nature of actually following a meaningful story (Amazon, 1927)."}, {"heading": "3.1 Data Collection Methodology", "text": "This year is the highest in the history of the country."}, {"heading": "3.2 Corpus Release", "text": "The corpus is open to the public and can be accessed through http: / / cs.rochester.edu / nlp / rocstories, which will continue to grow in the years to come. Given the quality control pipeline and the creativity required by workers, data collection is slow. We also provide semantic parses of these stories. Because these stories are not message wire, standard syntactics, and shallow semantic parsers for event extraction, they often fail because of language. To solve this problem, we have adjusted search parameters and added a few lexical entries to TRIPS, the comprehensive semantic parser3, optimizing its performance on our corpus. TRIPS Parser (Allen et al., 2008) produces cutting-edge logical forms of input stories that provide meaningful disambiguated and ontologically typed rich structures that allow event extraction along with semantic rolls and grain sets during five sentences."}, {"heading": "3.3 Temporal Analysis", "text": "This year it is more than ever before."}, {"heading": "4 A New Evaluation Framework", "text": "As described in the introduction, the common evaluation framework for scripting learning is the \"Narrative Cloze Test\" (Chambers and Jurafsky, 2008), in which a system generates a ranking of guesses for a missing event, taking into account some observed events. The original goal of this test was to provide a benchmark for evaluating narrative knowledge. However, gradually, the community began to optimize itself in terms of the test's performance, achieving higher scores without demonstrating learning narrative knowledge. For example, the ranking was created based on the frequency of the event (for example, by always predicting \"X said\") as an extremely strong baseline (Pichotta and Mooney, 2014b). Originally, narrative cloze test chains were extracted by hand and verified as gold chains. However, the cloze test chains used in all recent work are not humanly verified as gold."}, {"heading": "4.1 Story Cloze Test", "text": "The Cloze task (Taylor, 1953) is used to evaluate a person (or a system) for language comprehension by deleting a random word from a sentence and inserting a human space. We introduce the \"Story Cloze Test,\" in which a system is given a four-sentence context and two alternative endings to the story, which are called the \"right end\" and \"wrong end.\" Therefore, in this test the fifth sentence is empty. Then, the task of the system is to choose the correct ending. The \"right ending\" can be considered a hypothesis in a classical framework for recognizing textual entailment (Giampiccolo et al., 2007), and \"wrong\" ending can be considered the \"contradictory\" hypothesis. Table 4 shows three examples of Story Cloze test cases. The Story Cloze test serves as a general framework for understanding stories that is also applicable to evaluating narrative models (for example, calculating the similarity of the two alternatives that are required)."}, {"heading": "4.2 Data Collection Methodology", "text": "We randomly sampled 13,500 stories from ROCStories Corpus and submitted only the first four sentences to the AMT staff. For each story, one worker was asked to write a \"right end\" and a \"wrong end.\" Workers were asked to meet two conditions: (1) the sentence should follow the story by sharing at least one of the characters in the story, and (2) the sentence should be perfectly realistic and reasonable when read in isolation, to ensure that the cases of the Story Cloze test are not trivial. Further details of this setup are described in the supplementary material. Quality Control: The accuracy of the Story Cloze test can play a critical role in steering the research community in the right direction. We introduced the following two-step quality control test: 1. Qualification Test: We designed a qualification test for this task, in which workers had to choose whether a given \"correct completion\" and \"incorrect completion\" met our limitations."}, {"heading": "5 Story Cloze Test Models", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "6 Discussion", "text": "There are three key contributions in this paper: (1) a new corpus of common sense stories called ROCStories, (2) a new evaluation framework for evaluating script / storytellers called Story Cloze Test, and (3) a variety of initial approaches to address this new testing framework. ROCStories Corpus is the first crowdsourced corpus of its kind. We have published about 50k stories as well as validation and testing kits for Story Cloze Test. This record will eventually grow to 100k stories that will be published through our website. To continue to make meaningful progress in this task, although it is possible to further increase training data, we expect the community to develop models that learn to generalize invisible concepts and situations. The Story Cloze Test proved to be a challenge for all of the models we tested. We believe it will serve as an effective evaluation both for understanding stories and for scripting knowledge."}, {"heading": "Acknowledgments", "text": "We thank William de Beaumont and Choh Man Teng for their work on the TRIPS parser. We thank Alyson Grealish for their great help in quality control of our corpus. This work was partially supported by Grant W911NF-15-1-0542 with the US Defense Advanced Research Projects Agency (DARPA), the Army Research Office (ARO) and the Office of Naval Research (ONR)."}], "references": [{"title": "Deep semantic analysis of text", "author": ["James F. Allen", "Mary Swift", "Will de Beaumont."], "venue": "Proceedings", "citeRegEx": "Allen et al\\.,? 2008", "shortCiteRegEx": "Allen et al\\.", "year": 2008}, {"title": "Searching for storiness: Storygeneration from a reader\u2019s perspective", "author": ["Paul Bailey."], "venue": "AAAI Fall Symposium on Narrative Intelligence.", "citeRegEx": "Bailey.,? 1999", "shortCiteRegEx": "Bailey.", "year": 1999}, {"title": "Generating coherent event schemas at scale", "author": ["Niranjan Balasubramanian", "Stephen Soderland", "Oren Etzioni Mausam", "Oren Etzioni."], "venue": "EMNLP, pages 1721\u20131731.", "citeRegEx": "Balasubramanian et al\\.,? 2013", "shortCiteRegEx": "Balasubramanian et al\\.", "year": 2013}, {"title": "Learning latent personas of film characters", "author": ["David Bamman", "Brendan OConnor", "Noah Smith."], "venue": "ACL.", "citeRegEx": "Bamman et al\\.,? 2013", "shortCiteRegEx": "Bamman et al\\.", "year": 2013}, {"title": "Learning natural language inference from a large annotated corpus", "author": ["Samuel R Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D Manning."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632\u2013642,", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "The icwsm 2009 spinn3r dataset", "author": ["K. Burton", "A. Java", "I. Soboroff"], "venue": "Proceedings of the Third Annual Conference on Weblogs and Social Media (ICWSM", "citeRegEx": "Burton et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Burton et al\\.", "year": 2009}, {"title": "Unsupervised learning of narrative event chains", "author": ["Nathanael Chambers", "Daniel Jurafsky."], "venue": "Kathleen McKeown, Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, editors, ACL, pages 789\u2013797. The Association for Computer Linguistics.", "citeRegEx": "Chambers and Jurafsky.,? 2008", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2008}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["Nathanael Chambers", "Dan Jurafsky."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Process-", "citeRegEx": "Chambers and Jurafsky.,? 2009", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2009}, {"title": "Event schema induction with a probabilistic entity-driven model", "author": ["Nathanael Chambers."], "venue": "EMNLP, volume 13, pages 1797\u20131807.", "citeRegEx": "Chambers.,? 2013", "shortCiteRegEx": "Chambers.", "year": 2013}, {"title": "Toward a model of children\u2019s story comprehension", "author": ["Eugene Charniak."], "venue": "December.", "citeRegEx": "Charniak.,? 1972", "shortCiteRegEx": "Charniak.", "year": 1972}, {"title": "Probabilistic frame induction", "author": ["Jackie Cheung", "Hoifung Poon", "Lucy Vanderwende."], "venue": "ACL.", "citeRegEx": "Cheung et al\\.,? 2013", "shortCiteRegEx": "Cheung et al\\.", "year": 2013}, {"title": "Aspects of the Novel", "author": ["E.M. Forster."], "venue": "Edward Arnold, London.", "citeRegEx": "Forster.,? 1927", "shortCiteRegEx": "Forster.", "year": 1927}, {"title": "The third pascal recognizing textual entailment challenge", "author": ["Danilo Giampiccolo", "Bernardo Magnini", "Ido Dagan", "Bill Dolan."], "venue": "Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing, RTE \u201907, pages 1\u20139, Stroudsburg, PA, USA.", "citeRegEx": "Giampiccolo et al\\.,? 2007", "shortCiteRegEx": "Giampiccolo et al\\.", "year": 2007}, {"title": "Identifying Personal Stories in Millions of Weblog Entries", "author": ["Andrew S. Gordon", "Reid Swanson."], "venue": "Third International Conference on Weblogs and Social Media, Data Challenge Workshop, San Jose, CA, May.", "citeRegEx": "Gordon and Swanson.,? 2009", "shortCiteRegEx": "Gordon and Swanson.", "year": 2009}, {"title": "Teaching machines to read and comprehend", "author": ["Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom."], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances", "citeRegEx": "Hermann et al\\.,? 2015", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "Learning deep structured semantic models for web search using clickthrough data", "author": ["Po-Sen Huang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Acero", "Larry Heck."], "venue": "Proceedings of the 22Nd ACM International Conference on Information & Knowl-", "citeRegEx": "Huang et al\\.,? 2013", "shortCiteRegEx": "Huang et al\\.", "year": 2013}, {"title": "Skip n-grams and ranking functions for predicting script events", "author": ["Bram Jans", "Steven Bethard", "Ivan Vuli\u0107", "Marie Francine Moens."], "venue": "Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguis-", "citeRegEx": "Jans et al\\.,? 2012", "shortCiteRegEx": "Jans et al\\.", "year": 2012}, {"title": "Skip-thought vectors", "author": ["Ryan Kiros", "Yukun Zhu", "Ruslan Salakhutdinov", "Richard S Zemel", "Antonio Torralba", "Raquel Urtasun", "Sanja Fidler."], "venue": "NIPS.", "citeRegEx": "Kiros et al\\.,? 2015", "shortCiteRegEx": "Kiros et al\\.", "year": 2015}, {"title": "The winograd schema challenge", "author": ["Hector J. Levesque."], "venue": "AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning. AAAI.", "citeRegEx": "Levesque.,? 2011", "shortCiteRegEx": "Levesque.", "year": 2011}, {"title": "Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics", "author": ["Chin-Yew Lin", "Franz Josef Och."], "venue": "Proceedings of the 42Nd Annual Meeting on Association for Computational Linguistics, ACL \u201904, Strouds-", "citeRegEx": "Lin and Och.,? 2004", "shortCiteRegEx": "Lin and Och.", "year": 2004}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics:", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Learning a Probabilistic Model of Event Sequences From Internet Weblog Stories", "author": ["Mehdi Manshadi", "Reid Swanson", "Andrew S. Gordon."], "venue": "21st Conference of the Florida AI Society, Applied Natural Language Processing Track, Coconut Grove, FL, May.", "citeRegEx": "Manshadi et al\\.,? 2008", "shortCiteRegEx": "Manshadi et al\\.", "year": 2008}, {"title": "Learning to tell tales: A data-driven approach to story generation", "author": ["Neil McIntyre", "Mirella Lapata."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International", "citeRegEx": "McIntyre and Lapata.,? 2009", "shortCiteRegEx": "McIntyre and Lapata.", "year": 2009}, {"title": "A model of character affinity for agent-based story generation", "author": ["Gonzalo M\u00e9ndez", "Pablo Gerv\u00e1s", "Carlos Le\u00f3n."], "venue": "9th International Conference on Knowledge, Information and Creativity Support Systems, Limassol, Cyprus, 11/2014. Springer-Verlag,", "citeRegEx": "M\u00e9ndez et al\\.,? 2014", "shortCiteRegEx": "M\u00e9ndez et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean."], "venue": "Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neu-", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: A lexical database for english", "author": ["G. Miller."], "venue": "In Communications of the ACM.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Semantic annotation of event structures in commonsense stories", "author": ["Nasrin Mostafazadeh", "Alyson Grealish", "Nathanael Chambers", "James F. Allen", "Lucy Vanderwende."], "venue": "Proceedings of the The 4th Workshop on EVENTS: Definition, Detection, Coreference,", "citeRegEx": "Mostafazadeh et al\\.,? 2016", "shortCiteRegEx": "Mostafazadeh et al\\.", "year": 2016}, {"title": "Understanding script-based stories using commonsense reasoning", "author": ["Erik T. Mueller."], "venue": "Cognitive Systems Research, 5:2004.", "citeRegEx": "Mueller.,? 2002", "shortCiteRegEx": "Mueller.", "year": 2002}, {"title": "Modeling space and time in narratives about restaurants", "author": ["Erik T. Mueller."], "venue": "LLC, 22(1):67\u201384.", "citeRegEx": "Mueller.,? 2007", "shortCiteRegEx": "Mueller.", "year": 2007}, {"title": "Generative event schema induction with entity disambiguation", "author": ["Kiem-Hieu Nguyen", "Xavier Tannier", "Olivier Ferret", "Romaric Besan\u00e7on."], "venue": "Proceedings of the 53rd annual meeting of the Association for Computational Linguistics (ACL-15).", "citeRegEx": "Nguyen et al\\.,? 2015", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Statistical script learning with multi-argument events", "author": ["Karl Pichotta", "Raymond J Mooney."], "venue": "EACL 2014, page 220.", "citeRegEx": "Pichotta and Mooney.,? 2014a", "shortCiteRegEx": "Pichotta and Mooney.", "year": 2014}, {"title": "Statistical script learning with multi-argument events", "author": ["Karl Pichotta", "Raymond J. Mooney."], "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014), Gothenburg, Sweden, April.", "citeRegEx": "Pichotta and Mooney.,? 2014b", "shortCiteRegEx": "Pichotta and Mooney.", "year": 2014}, {"title": "Timeml: Robust specification of event and temporal expressions in text", "author": ["James Pustejovsky", "Jos Castao", "Robert Ingria", "Roser Saur", "Robert Gaizauskas", "Andrea Setzer", "Graham Katz."], "venue": "in Fifth International Workshop on Computational Semantics (IWCS-", "citeRegEx": "Pustejovsky et al\\.,? 2003", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2003}, {"title": "Learning script knowledge with web experiments", "author": ["Michaela Regneri", "Alexander Koller", "Manfred Pinkal."], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Regneri et al\\.,? 2010", "shortCiteRegEx": "Regneri et al\\.", "year": 2010}, {"title": "Mctest: A challenge dataset for the open-domain machine comprehension of text", "author": ["Matthew Richardson", "Christopher J.C. Burges", "Erin Renshaw."], "venue": "EMNLP, pages 193\u2013203. ACL.", "citeRegEx": "Richardson et al\\.,? 2013", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "Toward vignette-based story generation for drama management systems", "author": ["M. Riedl", "Carlos Le\u00f3n."], "venue": "Workshop on Integrating Technologies for Interactive Stories - 2nd International Conference on INtelligent TEchnologies for interactive enterTAINment, 8-10/1.", "citeRegEx": "Riedl and Le\u00f3n.,? 2008", "shortCiteRegEx": "Riedl and Le\u00f3n.", "year": 2008}, {"title": "Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning", "author": ["Melissa Roemmele", "Cosmin Adrian Bejan", "Andrew S. Gordon."], "venue": "AAAI Spring Symposium on Logical Formalizations of Commonsense Reasoning, Stanford Univer-", "citeRegEx": "Roemmele et al\\.,? 2011", "shortCiteRegEx": "Roemmele et al\\.", "year": 2011}, {"title": "Script induction as language modeling", "author": ["Rachel Rudinger", "Pushpendre Rastogi", "Francis Ferraro", "Benjamin Van Durme."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP-15).", "citeRegEx": "Rudinger et al\\.,? 2015", "shortCiteRegEx": "Rudinger et al\\.", "year": 2015}, {"title": "Scripts, Plans, Goals and Understanding: an Inquiry into Human Knowledge Structures", "author": ["Roger C. Schank", "Robert P. Abelson."], "venue": "L. Erlbaum, Hillsdale, NJ.", "citeRegEx": "Schank and Abelson.,? 1977", "shortCiteRegEx": "Schank and Abelson.", "year": 1977}, {"title": "Episodic logic meets little red riding hood: A comprehensive, natural representation for language understanding", "author": ["Lenhart K. Schubert", "Chung Hee Hwang."], "venue": "Natural Language Processing and Knowledge Representation: Language for Knowledge", "citeRegEx": "Schubert and Hwang.,? 2000", "shortCiteRegEx": "Schubert and Hwang.", "year": 2000}, {"title": "Say Anything: A Massively collaborative Open Domain Story Writing Companion", "author": ["Reid Swanson", "Andrew S. Gordon."], "venue": "First International Conference on Interactive Digital Storytelling, Erfurt, Germany, November.", "citeRegEx": "Swanson and Gordon.,? 2008", "shortCiteRegEx": "Swanson and Gordon.", "year": 2008}, {"title": "Cloze procedure: a new tool for measuring readability", "author": ["Wilson L Taylor."], "venue": "Journalism quarterly.", "citeRegEx": "Taylor.,? 1953", "shortCiteRegEx": "Taylor.", "year": 1953}, {"title": "The creative process: A computer model of storytelling", "author": ["Scott R. Turner."], "venue": "Hillsdale: Lawrence Erlbaum.", "citeRegEx": "Turner.,? 1994", "shortCiteRegEx": "Turner.", "year": 1994}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["Jason Weston", "Antoine Bordes", "Sumit Chopra", "Tomas Mikolov."], "venue": "CoRR, abs/1502.05698.", "citeRegEx": "Weston et al\\.,? 2015", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Understanding Natural Language", "author": ["Terry Winograd."], "venue": "Academic Press, Inc., Orlando, FL, USA.", "citeRegEx": "Winograd.,? 1972", "shortCiteRegEx": "Winograd.", "year": 1972}, {"title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books", "author": ["Yukun Zhu", "Ryan Kiros", "Richard Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler."], "venue": "arXiv preprint", "citeRegEx": "Zhu et al\\.,? 2015", "shortCiteRegEx": "Zhu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "Story understanding is an extremely challenging task in natural language understanding with a longrunning history in AI (Charniak, 1972; Winograd, 1972; Turner, 1994; Schubert and Hwang, 2000).", "startOffset": 120, "endOffset": 192}, {"referenceID": 44, "context": "Story understanding is an extremely challenging task in natural language understanding with a longrunning history in AI (Charniak, 1972; Winograd, 1972; Turner, 1994; Schubert and Hwang, 2000).", "startOffset": 120, "endOffset": 192}, {"referenceID": 42, "context": "Story understanding is an extremely challenging task in natural language understanding with a longrunning history in AI (Charniak, 1972; Winograd, 1972; Turner, 1994; Schubert and Hwang, 2000).", "startOffset": 120, "endOffset": 192}, {"referenceID": 39, "context": "Story understanding is an extremely challenging task in natural language understanding with a longrunning history in AI (Charniak, 1972; Winograd, 1972; Turner, 1994; Schubert and Hwang, 2000).", "startOffset": 120, "endOffset": 192}, {"referenceID": 40, "context": "This ranges from generic story telling models to building systems which can compose meaningful stories in collaboration with humans (Swanson and Gordon, 2008).", "startOffset": 132, "endOffset": 158}, {"referenceID": 38, "context": "A large body of work in story understanding has focused on learning scripts (Schank and Abelson, 1977).", "startOffset": 76, "endOffset": 102}, {"referenceID": 6, "context": "Most relevant to this issue is work on unsupervised learning of \u2018narrative chains\u2019 (Chambers and Jurafsky, 2008) and event schemas (Chambers and Jurafsky, 2009; Balasubramanian et al.", "startOffset": 83, "endOffset": 112}, {"referenceID": 7, "context": "Most relevant to this issue is work on unsupervised learning of \u2018narrative chains\u2019 (Chambers and Jurafsky, 2008) and event schemas (Chambers and Jurafsky, 2009; Balasubramanian et al., 2013; Cheung et al., 2013; Nguyen et al., 2015).", "startOffset": 131, "endOffset": 232}, {"referenceID": 2, "context": "Most relevant to this issue is work on unsupervised learning of \u2018narrative chains\u2019 (Chambers and Jurafsky, 2008) and event schemas (Chambers and Jurafsky, 2009; Balasubramanian et al., 2013; Cheung et al., 2013; Nguyen et al., 2015).", "startOffset": 131, "endOffset": 232}, {"referenceID": 10, "context": "Most relevant to this issue is work on unsupervised learning of \u2018narrative chains\u2019 (Chambers and Jurafsky, 2008) and event schemas (Chambers and Jurafsky, 2009; Balasubramanian et al., 2013; Cheung et al., 2013; Nguyen et al., 2015).", "startOffset": 131, "endOffset": 232}, {"referenceID": 29, "context": "Most relevant to this issue is work on unsupervised learning of \u2018narrative chains\u2019 (Chambers and Jurafsky, 2008) and event schemas (Chambers and Jurafsky, 2009; Balasubramanian et al., 2013; Cheung et al., 2013; Nguyen et al., 2015).", "startOffset": 131, "endOffset": 232}, {"referenceID": 5, "context": "Consider the following snippet from ICWSM 2011 Spinn3r Dataset of Weblog entries (Burton et al., 2009):", "startOffset": 81, "endOffset": 102}, {"referenceID": 6, "context": "A commonly used evaluation is the \u2018Narrative Cloze Test\u2019 (Chambers and Jurafsky, 2008) in which a system predicts a held-out event (a verb and its arguments) given a set of observed events.", "startOffset": 57, "endOffset": 86}, {"referenceID": 6, "context": "Chambers and Jurafsky first proposed narrative chains (Chambers and Jurafsky, 2008) as a partially ordered set of narrative events that share a common actor called the \u2018protagonist\u2019.", "startOffset": 54, "endOffset": 83}, {"referenceID": 7, "context": "Several expansions have since been proposed, including narrative schemas (Chambers and Jurafsky, 2009), script sequences (Regneri et al.", "startOffset": 73, "endOffset": 102}, {"referenceID": 33, "context": "Several expansions have since been proposed, including narrative schemas (Chambers and Jurafsky, 2009), script sequences (Regneri et al., 2010), and relgrams (Balasubramanian et al.", "startOffset": 121, "endOffset": 143}, {"referenceID": 2, "context": ", 2010), and relgrams (Balasubramanian et al., 2013).", "startOffset": 22, "endOffset": 52}, {"referenceID": 10, "context": "Formal probabilistic models have also been proposed to learn event schemas and frames (Cheung et al., 2013; Bamman et al., 2013; Chambers, 2013; Nguyen et al., 2015).", "startOffset": 86, "endOffset": 165}, {"referenceID": 3, "context": "Formal probabilistic models have also been proposed to learn event schemas and frames (Cheung et al., 2013; Bamman et al., 2013; Chambers, 2013; Nguyen et al., 2015).", "startOffset": 86, "endOffset": 165}, {"referenceID": 8, "context": "Formal probabilistic models have also been proposed to learn event schemas and frames (Cheung et al., 2013; Bamman et al., 2013; Chambers, 2013; Nguyen et al., 2015).", "startOffset": 86, "endOffset": 165}, {"referenceID": 29, "context": "Formal probabilistic models have also been proposed to learn event schemas and frames (Cheung et al., 2013; Bamman et al., 2013; Chambers, 2013; Nguyen et al., 2015).", "startOffset": 86, "endOffset": 165}, {"referenceID": 16, "context": "(Jans et al., 2012) redefined the test to be a text ordered sequence of events, whereas the original did not rely on text order (Chambers and Jurafsky, 2008).", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": ", 2012) redefined the test to be a text ordered sequence of events, whereas the original did not rely on text order (Chambers and Jurafsky, 2008).", "startOffset": 116, "endOffset": 145}, {"referenceID": 30, "context": "Since then, others have shown language-modeling techniques perform well (Pichotta and Mooney, 2014a; Rudinger et al., 2015).", "startOffset": 72, "endOffset": 123}, {"referenceID": 37, "context": "Since then, others have shown language-modeling techniques perform well (Pichotta and Mooney, 2014a; Rudinger et al., 2015).", "startOffset": 72, "endOffset": 123}, {"referenceID": 18, "context": "reasoning (Levesque, 2011; Roemmele et al., 2011; Bowman et al., 2015).", "startOffset": 10, "endOffset": 70}, {"referenceID": 36, "context": "reasoning (Levesque, 2011; Roemmele et al., 2011; Bowman et al., 2015).", "startOffset": 10, "endOffset": 70}, {"referenceID": 4, "context": "reasoning (Levesque, 2011; Roemmele et al., 2011; Bowman et al., 2015).", "startOffset": 10, "endOffset": 70}, {"referenceID": 14, "context": "There are a few recent frameworks for evaluating language comprehension (Hermann et al., 2015; Weston et al., 2015), including the MCTest (Richardson et al.", "startOffset": 72, "endOffset": 115}, {"referenceID": 43, "context": "There are a few recent frameworks for evaluating language comprehension (Hermann et al., 2015; Weston et al., 2015), including the MCTest (Richardson et al.", "startOffset": 72, "endOffset": 115}, {"referenceID": 34, "context": ", 2015), including the MCTest (Richardson et al., 2013) as a notable one.", "startOffset": 30, "endOffset": 55}, {"referenceID": 27, "context": "This includes research on understanding newswire involving terrorism scripts (Mueller, 2002), stories about people in a restaurant where a reasonable number of questions about time and space can be answered (Mueller, 2007), and generating stories from fairy tales (McIntyre and Lapata, 2009).", "startOffset": 77, "endOffset": 92}, {"referenceID": 28, "context": "This includes research on understanding newswire involving terrorism scripts (Mueller, 2002), stories about people in a restaurant where a reasonable number of questions about time and space can be answered (Mueller, 2007), and generating stories from fairy tales (McIntyre and Lapata, 2009).", "startOffset": 207, "endOffset": 222}, {"referenceID": 22, "context": "This includes research on understanding newswire involving terrorism scripts (Mueller, 2002), stories about people in a restaurant where a reasonable number of questions about time and space can be answered (Mueller, 2007), and generating stories from fairy tales (McIntyre and Lapata, 2009).", "startOffset": 264, "endOffset": 291}, {"referenceID": 23, "context": "Finally, there is a rich body of work on story plot generation and creative or artistic story telling (M\u00e9ndez et al., 2014; Riedl and Le\u00f3n, 2008).", "startOffset": 102, "endOffset": 145}, {"referenceID": 35, "context": "Finally, there is a rich body of work on story plot generation and creative or artistic story telling (M\u00e9ndez et al., 2014; Riedl and Le\u00f3n, 2008).", "startOffset": 102, "endOffset": 145}, {"referenceID": 11, "context": "We follow the notion of \u2018storiness\u2019 (Forster, 1927; Bailey, 1999), which is described as \u201cthe expectations and questions that a reader may have as the story develops\u201d, where expectations are \u2018common-sense logical inferences\u2019 made by the imagined reader of the story.", "startOffset": 36, "endOffset": 65}, {"referenceID": 1, "context": "We follow the notion of \u2018storiness\u2019 (Forster, 1927; Bailey, 1999), which is described as \u201cthe expectations and questions that a reader may have as the story develops\u201d, where expectations are \u2018common-sense logical inferences\u2019 made by the imagined reader of the story.", "startOffset": 36, "endOffset": 65}, {"referenceID": 25, "context": "Here we count event as any hyponym of \u2018event\u2019 or \u2018process\u2019 in WordNet (Miller., 1995).", "startOffset": 70, "endOffset": 85}, {"referenceID": 0, "context": "TRIPS parser (Allen et al., 2008) produces state-of-the-art logical forms for input stories, providing sense disambiguated and ontology-typed rich deep structures which enables event extraction together with semantic roles and coreference chains throughout the five sentences.", "startOffset": 13, "endOffset": 33}, {"referenceID": 32, "context": "We performed a simplified TimeML-driven (Pustejovsky et al., 2003) expert annotation of a sample of 20 stories6.", "startOffset": 40, "endOffset": 66}, {"referenceID": 26, "context": "This is captured in a recent work on semantic annotation of ROCStories (Mostafazadeh et al., 2016).", "startOffset": 71, "endOffset": 98}, {"referenceID": 6, "context": "As described earlier in the introduction, the common evaluation framework for script learning is the \u2018Narrative Cloze Test\u2019 (Chambers and Jurafsky, 2008), where a system generates a ranked list of guesses for a missing event, given some observed events.", "startOffset": 124, "endOffset": 153}, {"referenceID": 31, "context": ", always predicting \u2018X said\u2019) was shown to be an extremely strong baseline (Pichotta and Mooney, 2014b).", "startOffset": 75, "endOffset": 103}, {"referenceID": 41, "context": "The cloze task (Taylor, 1953) is used to evaluate a human (or a system) for language understanding by deleting a random word from a sentence and having a human fill in the blank.", "startOffset": 15, "endOffset": 29}, {"referenceID": 12, "context": "The \u2018right ending\u2019 can be viewed as \u2018entailing\u2019 hypothesis in a classic Recognizing Textual Entailment (RTE) framework (Giampiccolo et al., 2007), and \u2018wrong\u2019 ending can be seen as the \u2019contradicting\u2019 hypothesis.", "startOffset": 119, "endOffset": 145}, {"referenceID": 19, "context": "We compute Smoothed-BLEU (Lin and Och, 2004) score for measuring up to four-gram overlap of an alternative and the context.", "startOffset": 25, "endOffset": 44}, {"referenceID": 24, "context": "GenSim: Average Word2Vec: Choose the hypothesis with closer average word2vec (Mikolov et al., 2013) embedding to the average word2vec embedding of the context.", "startOffset": 77, "endOffset": 99}, {"referenceID": 20, "context": "We use the state-of-the-art sentiment analysis model (Manning et al., 2014) which assigns a numerical value from 1 to 5 to a sentence.", "startOffset": 53, "endOffset": 75}, {"referenceID": 17, "context": "Skip-thoughts Model: This model uses Skipthoughts\u2019 Sentence2Vec embedding (Kiros et al., 2015) which models the semantic space of novels.", "startOffset": 74, "endOffset": 94}, {"referenceID": 45, "context": "This model is trained on the \u2018BookCorpus\u2019 (Zhu et al., 2015) (containing 16 different genres) of over 11,000 books.", "startOffset": 42, "endOffset": 60}, {"referenceID": 6, "context": "Narrative Chains-AP: Implements the standard approach to learning chains of narrative events based on Chambers and Jurafsky (2008). An event is represented as a verb and a typed dependency (e.", "startOffset": 102, "endOffset": 131}, {"referenceID": 15, "context": "Deep Structured Semantic Model (DSSM): This model (Huang et al., 2013) is trained to project the four-sentences context and the fifth sentence into the same vector space.", "startOffset": 50, "endOffset": 70}, {"referenceID": 15, "context": "Deep Structured Semantic Model (DSSM): This model (Huang et al., 2013) is trained to project the four-sentences context and the fifth sentence into the same vector space. It consists of two separate deep neural networks for learning jointly the embedding of the four-sentences context and the fifth sentence, respectively. As suggested in Huang et al. (2013), the input of the DSSM is based on contextdependent characters, e.", "startOffset": 51, "endOffset": 359}], "year": 2016, "abstractText": "Representation and learning of commonsense knowledge is one of the foundational problems in the quest to enable deep language understanding. This issue is particularly challenging for understanding casual and correlational relationships between events. While this topic has received a lot of interest in the NLP community, research has been hindered by the lack of a proper evaluation framework. This paper attempts to address this problem with a new framework for evaluating story understanding and script learning: the \u2018Story Cloze Test\u2019. This test requires a system to choose the correct ending to a four-sentence story. We created a new corpus of 50k five-sentence commonsense stories, ROCStories, to enable this evaluation. This corpus is unique in two ways: (1) it captures a rich set of causal and temporal commonsense relations between daily events, and (2) it is a high quality collection of everyday life stories that can also be used for story generation. Experimental evaluation shows that a host of baselines and state-of-the-art models based on shallow language understanding struggle to achieve a high score on the Story Cloze Test. We discuss these implications for script and story learning, and offer suggestions for deeper language understanding.", "creator": "LaTeX with hyperref package"}}}