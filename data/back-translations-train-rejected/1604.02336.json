{"id": "1604.02336", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Apr-2016", "title": "Back to the Basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation", "abstract": "Estimating student proficiency is an important task for computer-based learning systems. We compare a family of IRT-based proficiency estimation methods with a recently proposed approach using recurrent neural networks (RNNs) on two publicly available and one proprietary data set, evaluating each model according to how well a student's future response is predicted given previous responses. IRT-based methods consistently matched or outperformed the RNN-based method across all data sets at the finest level of content granularity that was tractable for them to be trained on. A hierarchical extension of IRT that captured item grouping structure performed best overall. When data sets included non-trivial autocorrelations in student response patterns, a temporal extension of IRT improved performance over standard IRT while the RNN-based method did not. We conclude that IRT-based models provide a simpler, better-performing alternative to the current generation of RNN-based models while also affording more interpretability and guarantees due to their formulation as Bayesian probabilistic models.", "histories": [["v1", "Fri, 8 Apr 2016 12:54:18 GMT  (55kb,D)", "https://arxiv.org/abs/1604.02336v1", "6 pages, 2 figures, Submitted"], ["v2", "Sat, 21 May 2016 18:26:21 GMT  (56kb,D)", "http://arxiv.org/abs/1604.02336v2", "6 pages, 2 figures, Educational Data Mining 2016"]], "COMMENTS": "6 pages, 2 figures, Submitted", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["kevin h wilson", "yan karklin", "bojian han", "chaitanya ekanadham"], "accepted": false, "id": "1604.02336"}, "pdf": {"name": "1604.02336.pdf", "metadata": {"source": "CRF", "title": "Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation", "authors": ["Kevin H. Wilson", "Yan Karklin", "Bojian Han", "Chaitanya Ekanadham"], "emails": ["kevin@knewton.com", "yan@knewton.com", "chaitu@knewton.com", "bojianh@andrew.cmu.edu"], "sections": [{"heading": "Acknowledgements", "text": "Many thanks to Siddharth Reddy, David Kuntz, Kyle Hausmann and Celia Alicata for discussing this work and helping to edit the manuscript. Tags Item Response Theory, Recurrent Neural Nets, Bayesian Models of Student Performance, Deep Knowledge Tracing"}, {"heading": "1. INTRODUCTION", "text": "A key challenge for computer-aided learning systems is to assess a student's performance based on their previous interactions with the system."}, {"heading": "2. MODELS OF STUDENT RESPONSES", "text": "In this section, we specify the notation and describe the models we compare. Throughout the section, we present student D's response data as a series of tuples (s, i, r, t) that indicate the student, item, correctness, and time of each answer. In this essay, time is indexed by the interaction index (not the time of the wall clock)."}, {"heading": "2.1 Item Response Theory (IRT)", "text": "Item Response Theory (IRT) is a standard framework for modeling student responses from the 1950s (8, 13). A single number, referred to as \"level of knowledge or ability,\" represents a student's level of knowledge over the course of several exams. It is assumed that this level of knowledge will not change during this exam. In its simplest form, the one-parameter model, each item is assigned a parameter \u03b2i that represents the difficulty of the item. \u2212 The probability that a student answers item i correctly is given by f (\u03b8s \u2212 \u03b2i), where f is a sigmoid function. If f is the logistic function, this corresponds to (structured) logistic regression, where the factors for responding to an item are indicators for students and items, where f is a normal function."}, {"heading": "2.2 Hierarchical IRT (HIRT)", "text": "2For an in-depth discussion of IRT and a review of related literature see [17], in particular Chapter 5. 3The IRJ provides nearly identical results on the commonly used logistical link function, but allows recalculation in closed form in the IRT temporal model described in paragraph 2.3 4. For example, the predictions of responses are invariable when adding a constant offset to the properties of items that are more similar within groups than between them. In many situations, including all of our datasets, the assessment elements can have a structure that can predict students \"responses. (For example, item groups can judge the same topic, resulting in item properties that are more similar within groups than between them. Alternatively, item elements can be derived from common templates. Templates that are often found in math courses look like this:\" What is x + y? \"and a certain instantiation is generated by selecting values for the same set and ASTy containing multiple data sets of the same data set)."}, {"heading": "2.3 Temporal IRT (TIRT)", "text": "1PO IRT and HIRT assume that each student's level of knowledge remains constant over time. In an environment where a student acquires (or forgets) knowledge over a period of time (e.g. while interacting with a tutor system), we can expand this model by modelling each of these phenomena as a stochastic process (see, for example, [5]). We apply the approach described in [3] by modelling the student's knowledge as a Viennese process: P (phenomena, t + phenomena, t) = e \u2212 (phenomena, t + prognostics, t + forecasting, t, t, t, t, t. (3) In other words, the change in the student's state of knowledge between time t + forecasting (expressed as phenomena, t + forecasting), t \u2212 (phenomena, t + forecasting), t \u2212 (phenomena, t + forecasting, t)."}, {"heading": "2.4 Deep Knowledge Tracing (DKT)", "text": "Recently, a recursive neural network has been used to predict student reactions [16]. Such architectures have seen tremendous success in applications in a wide range of other areas (e.g. image processing [6], speech recognition [7], and natural language processing [20]). In this model, the input vectors are representations of whether the student answered a particular question correctly or incorrectly in the previous time step, and the output vectors are representations of the probability, across all the questions in the questionnaire, that a student gets the question right in the following time step. In [16], the authors suggest using a unified vector that is not xs, t, but R2I to represent a student's answer s (on item i). Here is the total number of item effects and the first I slots represent the answer correctly and the remaining I slots represent the answer incorrectly. Output vectors ~ ys, t-RI are the probabilities where the element is the probability of the answer to the element."}, {"heading": "3. DATA SETS", "text": "To test these models, we used three datasets, two publicly available and one proprietary dataset. Each of these datasets comes from a system in which students interact with a computerized learning system in a variety of educational environments (e.g. between classroom lectures, offline work, etc.)."}, {"heading": "3.1 ASSISTments", "text": "This data set comes from the ASSISTments product, an online platform that integrates students with formative skills = 30.5 percent of multiple skills provided with scaffoldings. Most assessments are templated, and each problem is reconciled with one, several, or none of the skills the product is trying to teach. The data set [4] is split into two parts, the \"skill builder,\" which is associated with formative assessments, and the \"non-skill builder,\" which is associated with summary assessments. All of our results are reported via the \"skill builder\" dataset, as we expect a stronger time signal from formative assessments than from summary assessments. This was also the assessment dataset for [16].In pre-processing of the data, we associated elements that are not aligned with a skill to a proven \"dummy\" skill, as we believe in 16, [we decided to duplicate a single series]."}, {"heading": "3.2 KDD Cup", "text": "In 2010, the PSLC DataShop published several sets of data derived from Carnegie Learning's cognitive tutor in (pre) algebra from 2005-2009 [19]. We used the largest of the \"Development\" sets, called \"Bridge to Algebra 2006-2007.\" One clear difference between Carnegie Learning's product and ASSISTments is that Carnegie Learning provides a much more accurate representation of the concepts evaluated by a single element. Note that this \"Problem \u2192 Step\" structure is based on an equipped formative assessment, in which each step a student takes to answer a problem is counted as a separate interaction, with each step evaluating potentially different capabilities (so-called Knowledge Components (KCs) in the data set."}, {"heading": "3.3 Knewton", "text": "The data was collected from a variety of educational products that are integrated into Knewton's adaptive learning platform and used in different classrooms around the world. These products differ in terms of learning content used (disciplines included math, science and English) and in the way students are guided through the content. For example, students can perform an initial assessment and then be corrected in areas that need improvement. In other products, students start from scratch and work toward a goal set by the teacher. In all of these contexts, Knewton receives data on each interaction (s, i, r, t) multiple of Section 2. We used approximately 1 million answers from 6.3 K randomly selected students to 105.5 K questions over a period of about 4 months. Students who completed less than 5 questions in total were excluded."}, {"heading": "4. EVALUATION METHODOLOGY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Parameter Selection", "text": "For each set of data, 20% of the students were initially set aside for parameter selection, which we performed as follows: Wizard KDDKnewton \u2022 For 1PO IRT, there were no parameters to choose from. \u2022 For HIRT, we swept values of variances \u03c42 and \u03c32 of the group medium or item difficulty, including regimes (\u03c42 small) that made the model mathematically equivalent to 1PO IRT. \u2022 For TIRT, we swept the temporal smoothing parameter \u03b32, including the regime (\u03b32 small) that made the model mathematically equivalent to 1PO IRT. \u2022 For DKT, we swept the compression dimension C (the dimension of space into which the input was projected using a random matrix), the hidden dimension H, the failure probability p, and the step size of our gradient ascent."}, {"heading": "4.2 Online prediction accuracy", "text": "We use an evaluation method, which we call online response prediction, and which matches that of [16]. Students are first divided into training and test populations, each model is first trained on the basis of the training population, and the model parameters that are not student (item parameters for IRT-based models, weights for neural networks) are frozen. Then, for each t > 1 in the history of each student test student, we train the student parameters in the model on the first t-1 interactions of student history, enabling him to calculate the probability that the t-th answer is correct. This process reflects the practical task performed by an IT.We report on two different metrics for comparing the predicted correctness probabilities with the observed correctness values. Accuracy (Acc) is calculated as the percentage of the answers in which correctness coincides with the probability that is greater than 50% of the correctness range of the AUC for each answer."}, {"heading": "5. RESULTS AND DISCUSSION", "text": "It is indeed the case that we will be able to go in search of a solution that meets the needs of the people."}, {"heading": "6. CONCLUSION", "text": "Our results suggest that simple IRT-based models are equal to or better than DKT on a variety of datasets, suggesting that incorporating domain knowledge into structured Bayesian models is a promising area of future research into student interaction modeling. In our experience, structured models were easier to learn and require fewer parameters than DKT. Furthermore, DKT's computer requirements hampered our ability to fully explore the parameter space, and we found that computing time and memory load were prohibitive for tens of thousands of items, which could not be mitigated by reducing dimensionality without significantly impairing performance. Further work on discriminatory models is necessary, but currently, IRT-based models seem superior in both performance and ease of use, making them suitable candidates for real-world applications (e.g. smart tutoring systems, recommendation systems, or analytical studies)."}], "references": [{"title": "Theano: a CPU and GPU math expression compiler", "author": ["J Bergstra"], "venue": "SciPy", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Knowledge tracing: Modeling the acquisition of procedural knowledge", "author": ["A. Corbett", "J. Anderson"], "venue": "User Modeling and User-Adapted Interaction", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "T-SKIRT: Online estimation of student proficiency in an adaptive learning system", "author": ["C. Ekanadham", "Y. Karklin"], "venue": "Machine Learning for Education Workshop at ICML", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Addressing the assessment challenge with an online system that tutors as it assesses", "author": ["M. Feng", "N. Heffernan", "K. Koedinger"], "venue": "In User Modeling, Adaption, and Personalization,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "General features in knowledge tracing: Applications to multiple subskills, temporal item response theory, and expert knowledge", "author": ["J. Gonzalez-Brenes", "Y. Huang", "P. Brusilovsky"], "venue": "EDM", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["K Gregor"], "venue": "ICML", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "How deep is knowledge tracing? In EDM 2016", "author": ["M. Khajah", "R.V. Lindsey", "M.C. Mozer"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Integrating knowledge tracing and item response theory. Personalization Approaches in Learning Environments", "author": ["M.M. Khajah", "Y. Huang", "J.P. Gonz\u00e1lez-Brenes", "M.C. Mozer", "P. Brusilovsky"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Time-varying learning and content analytics via sparse factor analysis", "author": ["A.S. Lan", "C. Studer", "R.G. Baraniuk"], "venue": "KDD", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "A Theory of Test Scores. No. 7 in Psychometric Monograph", "author": ["F.M. Lord"], "venue": "Psychometric Corporation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1952}, {"title": "Modeling individualization in a Bayesian Networks implementation of knowledge tracing", "author": ["Z.A. Pardos", "N.T. Heffernan"], "venue": "In User Modeling, Adaption, and Personalization,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "KT-IDEM: Introducing Item Difficulty to the Knowledge Tracing Model", "author": ["Z.A. Pardos", "N.T. Heffernan"], "venue": "In User Modeling, Adaption, and Personalization,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Deep Knowledge Tracing", "author": ["C. Piech", "J. Bassen", "J. Huang", "S. Ganguli", "M. Sahami", "L. Guibas", "J. Sohl-Dickstein"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Diagnostic Measurement: Theory, Methods, and Applications", "author": ["A.A. Rupp", "J. Templin", "R.A. Henson"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["N Srivastava"], "venue": "Journal of Machine Learning Research", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Challenge data sets from KDD Cup 2010. pslcdatashop.web.cmu.edu/KDDCup/downloads.jsp", "author": ["J. Stamper", "A. Niculescu-Mizil", "S. Ritter", "G.G.J Gordon", "K. Koedinger"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Grammar as a foreign language", "author": ["O Vinyals"], "venue": "NIPS", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "Two classical families of methods for estimating proficiency are Item Response Theory (IRT) [8, 13] and Bayesian Knowledge Tracing (BKT) [2].", "startOffset": 92, "endOffset": 99}, {"referenceID": 1, "context": "Two classical families of methods for estimating proficiency are Item Response Theory (IRT) [8, 13] and Bayesian Knowledge Tracing (BKT) [2].", "startOffset": 137, "endOffset": 140}, {"referenceID": 10, "context": "A growing body of recent work has focused on modeling various structural properties of students and assessments in an attempt to combine the advantages of IRT and BKT, for instance [14, 15, 11, 5, 10, 12, 3]).", "startOffset": 181, "endOffset": 207}, {"referenceID": 11, "context": "A growing body of recent work has focused on modeling various structural properties of students and assessments in an attempt to combine the advantages of IRT and BKT, for instance [14, 15, 11, 5, 10, 12, 3]).", "startOffset": 181, "endOffset": 207}, {"referenceID": 8, "context": "A growing body of recent work has focused on modeling various structural properties of students and assessments in an attempt to combine the advantages of IRT and BKT, for instance [14, 15, 11, 5, 10, 12, 3]).", "startOffset": 181, "endOffset": 207}, {"referenceID": 4, "context": "A growing body of recent work has focused on modeling various structural properties of students and assessments in an attempt to combine the advantages of IRT and BKT, for instance [14, 15, 11, 5, 10, 12, 3]).", "startOffset": 181, "endOffset": 207}, {"referenceID": 7, "context": "A growing body of recent work has focused on modeling various structural properties of students and assessments in an attempt to combine the advantages of IRT and BKT, for instance [14, 15, 11, 5, 10, 12, 3]).", "startOffset": 181, "endOffset": 207}, {"referenceID": 2, "context": "A growing body of recent work has focused on modeling various structural properties of students and assessments in an attempt to combine the advantages of IRT and BKT, for instance [14, 15, 11, 5, 10, 12, 3]).", "startOffset": 181, "endOffset": 207}, {"referenceID": 12, "context": "In a recently proposed method known as Deep Knowledge Tracing (DKT) [16], a recurrent neural network was trained to predict student responses and was shown to outperform the best published results ([15]) on the publicly available ASSISTments data set [4] by about 20 percentage points with respect to the AUC metric described in Section 4.", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "In a recently proposed method known as Deep Knowledge Tracing (DKT) [16], a recurrent neural network was trained to predict student responses and was shown to outperform the best published results ([15]) on the publicly available ASSISTments data set [4] by about 20 percentage points with respect to the AUC metric described in Section 4.", "startOffset": 198, "endOffset": 202}, {"referenceID": 3, "context": "In a recently proposed method known as Deep Knowledge Tracing (DKT) [16], a recurrent neural network was trained to predict student responses and was shown to outperform the best published results ([15]) on the publicly available ASSISTments data set [4] by about 20 percentage points with respect to the AUC metric described in Section 4.", "startOffset": 251, "endOffset": 254}, {"referenceID": 12, "context": "To investigate DKT\u2019s advantage over traditional models, we compared a standard one parameter IRT model, two extensions of that model, and DKT on three data sets (two are publicly available and one is proprietary) on a realistic online prediction task that is typically required by computerbased learning systems (see Section 4), and which was consistent with the evaluation task employed in [16].", "startOffset": 391, "endOffset": 395}, {"referenceID": 12, "context": "We reproduce the results of [16] on the ASSISTments data set, but find that proper accounting for duplicate data negates the claimed performance gains.", "startOffset": 28, "endOffset": 32}, {"referenceID": 9, "context": "Item Response Theory (IRT) is a standard framework for modeling student responses dating back to the 1950s [8, 13].", "startOffset": 107, "endOffset": 114}, {"referenceID": 13, "context": "For an in depth discussion of IRT and a review of related literature see [17], especially Chapter 5.", "startOffset": 73, "endOffset": 77}, {"referenceID": 4, "context": ", while interacting with a tutoring system), we can extend this model by modeling each \u03b8s as a stochastic process varying over time (see for example [5]).", "startOffset": 149, "endOffset": 152}, {"referenceID": 2, "context": "We adopt the approach described in [3], modeling the student\u2019s knowledge as a Wiener process:", "startOffset": 35, "endOffset": 38}, {"referenceID": 2, "context": "We fit the parameters according to the procedure described in [3].", "startOffset": 62, "endOffset": 65}, {"referenceID": 2, "context": "See [3] for details.", "startOffset": 4, "endOffset": 7}, {"referenceID": 12, "context": "Recently, a recurrent neural network was used to predict student responses [16].", "startOffset": 75, "endOffset": 79}, {"referenceID": 5, "context": ", image processing [6], speech recognition [7], and natural language processing [20]).", "startOffset": 19, "endOffset": 22}, {"referenceID": 16, "context": ", image processing [6], speech recognition [7], and natural language processing [20]).", "startOffset": 80, "endOffset": 84}, {"referenceID": 12, "context": "In [16], the authors propose using a one-hot vector ~xs,t \u2208 R to represent the response of a student s (on item i) at time t.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "Note that in [16], an LSTM network was used in addition to the RNN described here, and the performance of the two networks was comparable.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "In order to make learning tractable, we reduced the dimensionality of the input by projecting the ~xs,t \u2208 R to a lower dimensional space R using a random projection matrix c : R \u2192 R , as was done in [16].", "startOffset": 199, "endOffset": 203}, {"referenceID": 14, "context": "We used batch gradient ascent with dropout [18], and chose the input dimensionality C and the hidden dimensionality H by sweeping these parameters on a data set that was held out from the data used for training and cross-validation.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "Stochastic gradient ascent with minibatches of students on the unrolled RNN, coded using Theano [1], was used to optimize this objective function.", "startOffset": 96, "endOffset": 99}, {"referenceID": 3, "context": "The data set [4] is divided in two parts, the \u201cskill builder\u201d set associated with formative assessment and the \u201cnon skill builder\u201d set associated with summative assessment.", "startOffset": 13, "endOffset": 16}, {"referenceID": 12, "context": "This was also the evaluation data set for [16].", "startOffset": 42, "endOffset": 46}, {"referenceID": 12, "context": "In preprocessing the data, we associated items not aligned with a skill to a designated \u201cdummy\u201d skill, as was done in [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 12, "context": "We chose to discard rows duplicating a single interaction (represented by a unique order_id value), a step we do not believe was taken by [16].", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "In 2010, the PSLC DataShop released several data sets derived from Carnegie Learning\u2019s Cognitive Tutor in (Pre)Algebra from the years 2005\u20132009 [19].", "startOffset": 144, "endOffset": 148}, {"referenceID": 12, "context": "We use an evaluation method we call online response prediction which matches that of [16].", "startOffset": 85, "endOffset": 89}, {"referenceID": 12, "context": "Finally, we note that our DKT results in Figure 1 contradict those of [16] on the ASSISTments data set, which reported an AUC of 0.", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "Indeed, we were able to reproduce the performance reported in [16] when applying our RNN implementation on the raw data set (with duplicates left in).", "startOffset": 62, "endOffset": 66}, {"referenceID": 6, "context": "Other recent work [9] points out that the specific method of computing AUC in [16] also significantly affects the reported performance relative to BKT-based models, and further demonstrates that BKT-based models can perform just as well as DKT on a variety of data sets.", "startOffset": 18, "endOffset": 21}, {"referenceID": 12, "context": "Other recent work [9] points out that the specific method of computing AUC in [16] also significantly affects the reported performance relative to BKT-based models, and further demonstrates that BKT-based models can perform just as well as DKT on a variety of data sets.", "startOffset": 78, "endOffset": 82}], "year": 2016, "abstractText": "Estimating student proficiency is an important task for computer based learning systems. We compare a family of IRTbased proficiency estimation methods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural network model with promising initial results. We evaluate how well each model predicts a student\u2019s future response given previous responses using two publicly available and one proprietary data set. We find that IRT-based methods consistently matched or outperformed DKT across all data sets at the finest level of content granularity that was tractable for them to be trained on. A hierarchical extension of IRT that captured item grouping structure performed best overall. When data sets included non-trivial autocorrelations in student response patterns, a temporal extension of IRT improved performance over standard IRT while the RNNbased method did not. We conclude that IRT-based models provide a simpler, better-performing alternative to existing RNN-based models of student interaction data while also affording more interpretability and guarantees due to their formulation as Bayesian probabilistic models.", "creator": "LaTeX with hyperref package"}}}