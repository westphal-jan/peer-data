{"id": "1604.02780", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2016", "title": "Knowledge Extraction and Knowledge Integration governed by {\\L}ukasiewicz Logics", "abstract": "The development of machine learning in particular and artificial intelligent in general has been strongly conditioned by the lack of an appropriate interface layer between deduction, abduction and induction. In this work we extend traditional algebraic specification methods in this direction. Here we assume that such interface for AI emerges from an adequate Neural-Symbolic integration. This integration is made for universe of discourse described on a Topos governed by a many-valued {\\L}ukasiewicz logic. Sentences are integrated in a symbolic knowledge base describing the problem domain, codified using a graphic-based language, wherein every logic connective is defined by a neuron in an artificial network. This allows the integration of first-order formulas into a network architecture as background knowledge, and simplifies symbolic rule extraction from trained networks. For the train of such neural networks we changed the Levenderg-Marquardt algorithm, restricting the knowledge dissemination in the network structure using soft crystallization. This procedure reduces neural network plasticity without drastically damaging the learning performance, allowing the emergence of symbolic patterns. This makes the descriptive power of produced neural networks similar to the descriptive power of {\\L}ukasiewicz logic language, reducing the information lost on translation between symbolic and connectionist structures. We tested this method on the extraction of knowledge from specified structures. For it, we present the notion of fuzzy state automata, and we use automata behaviour to infer its structure. We use this type of automata on the generation of models for relations specified as symbolic background knowledge.", "histories": [["v1", "Mon, 11 Apr 2016 03:23:21 GMT  (35kb)", "http://arxiv.org/abs/1604.02780v1", "38 pages"]], "COMMENTS": "38 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["carlos leandro"], "accepted": false, "id": "1604.02780"}, "pdf": {"name": "1604.02780.pdf", "metadata": {"source": "CRF", "title": "KNOWLEDGE EXTRACTION AND KNOWLEDGE INTEGRATION GOVERNED BY LUKASIEWICZ LOGICS", "authors": ["Carlos Leandro"], "emails": ["miguel.melro.leandro@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 160 4.02 780v 1 [cs.A I] 1 1A pr - - - - - - - - - - - - - - - - - - - - -"}, {"heading": "1 INTRODUCTION", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2 PRELIMINARIES", "text": "In this section, we present some concepts that are used throughout the essay."}, {"heading": "2.1 Lukasiewicz logics", "text": "The algebraic semantics of this logic is defined by Boolean algebra. (...) The generalization of Boolean algebra may be based on the relationship between conjunction and implication given by Boolean algebra. (...) The properties of Boolean algebra are too rigid to define a new binary connectivity, commonly referred to as fusion, and the resistance equivalences imply the properties of logical operators in Boolean algebra. In fuzzy logic applications, the properties of Boolean connection are too rigid, hence it is a new binary connectivity, and resistance equivalence is commonly referred to as truth (...)."}, {"heading": "2.2 Relations", "text": "A vague relationship R defines between a family of sets (Ai) i) i) i) i) i) i) i) i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i \"i.\" i \"i\" i \"i.\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i. \"i\" i \"i\" i. \"i\" i \"i\" i \"i.\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i \"i.\" i \"i\" i. \"i\" i \"i\" i. \"i\" i \"i\" i. \"i\" i \"i\" i \"i.\" i \"i\" i. \"i\" i \"i\" i \"i\" i. \"i\" i \"i\" i \"i\" i. \"i\" i. \"i\" i \"i.\" i \"i\" i \"i\" i \"i.\" i \"i.\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"i.\" i \"i\" i. \"i.\" i. \"i\" i \"i.\" i. \"i.\" i \"i\" i. \"i\" i. \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i. \"i.\" i. \"i\" i \"i.\" i. \"i\" i. \"i\" i \"i\" i \"i\" i"}, {"heading": "2.3 Inference", "text": "In general, inference is a process that is now used to generate facts based on known facts. In the context of polyvalent logic, inference allows to refine the degree of two for a new proposition based on the known degree of truth for propositions [?] This inference can be described with the composition operator defined in the area set [?]."}, {"heading": "R\u2297 S: If a \u2208 \u03b1 then c \u2208 \u03b3", "text": "(b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b) (b (b) (b) (b) (b) (b) (b) (b) (b) (b) (b"}, {"heading": "2.4 Limit sentences and colimit sentences", "text": "In this sense, any set of views in a multi-graph sentence homomorphism D: G \u2192 sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence"}, {"heading": "2.5 Concepts", "text": "A table or concept description using values in the family (A\u03b1), Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-Alpha-"}, {"heading": "3 SPECIFICATION SYSTEM", "text": "All common data specification mechanisms (such as the Entity Relationship Model [22], the Basic Data Model [23], the Generic Semantic Model [24], OOA & D schemes in a million versions, and UML, which itself includes a variety of different notations, have a strong graphical component. They are essentially graphs with special markers in them. Normally, the semantics of these markers are defined in an ad-hoc and sometimes non-formal manner. An important component of the mathematical structure that will be used for formalized knowledge are multi-graphs homomorphisms in the class set of relation views. When specifying an information system, it will be necessary to formulate constraints on such graphs homomorphisms. An identical idea of a specification whose models are homomorphisms in a category theory is known to us in the category community."}, {"heading": "3.1 Knowledge integration via specification systems", "text": "Specification systems are graphical specifications formalisms (their components are multigraphs and markers in these diagrams) and can be taken as a store of knowledge about the UoD. They are described in a strict graphical language with a precise formula, where we have a methodology to query their models. However, their goal is to enrich this structure with knowledge extracted from one of their models. We simplify this process by interpreting first-order logic constraints into a graphic formula. To do this, consider the multigraph used in defining the specification system as a first-order component library that uses many sorted signatures: nodes of the graph are interpreted as data types, and multi-arrows are interpreted as relationships that are evaluated in interpretation. A structure for this signature is exactly a multigraph, homomorphism from G to Set. Each formula for this signature is special because there are only relationships."}, {"heading": "3.2 A specification system description", "text": "A specification system is by nature a graphical specification, but some times as described in this exhibition, it is preferable to a description of the specification system with a string-based representation. To this end, we have used a string-based codification for specification systems called \"Relational Specification,\" which generalizes the concept of specification essentially formalistically: the original idea goes back to Freyd [26] and with the same expressive force as finite boundary sketches [27]. The essential algebraic fragment, are mainly interesting because theories of many types of specification formalisms are in fact original algebras for some essential algebraic specifications. A number of evidence systems for essentially algebraic specifications has been introduced. [28].17Recall this order on a series X is well founded iff any strictly decreasing chain of elements of X must be finite."}, {"heading": "4 EXTRACTING KNOWLEDGE FROM CONCEPT DESCRIPTIONS", "text": "In this sense, the information structure in a neural network can be crystallized and codified in string-based notation. In this section, we present a methodology to extract the formalities of the first order, the available information in a llogic. As mentioned in [30], there is a lack of a deep study of the relationships between logic and NNNs. In [13] it is shown how, by using as an activation function, the identity truncated to zero and one (1, x, x, x, x, x) the identity truncated to zero (1, x, x, x, x, x, x, x, x, x etc.) the identity truncated to zero and one (1, x, x, x, x, x, x, x, x, x, x, x, x, x etc.)."}, {"heading": "4.1 Similarity between a configuration and a formula", "text": "We call Castro neural network (CNN) a type of NN having as activation function. (x) = min (1, max (0, x)), where its weights are -1, 0 or 1 and having by bias an integer. A CNN is called Lukasiewicz neural network (LNN) if it can be codified as a binary NN: i.e. a CNN, where each neuron has one or two inputs. A CNN is representable when can be codified by an equivalent LNN.Each neuron, with n inputs, in a CNN can be described as a binary NN: i.e. b (x1, x2, x2,... xn \u2212 b) and it is representable when can be described by a LNNN = b1 y1, or."}, {"heading": "4.2 Crystallizing trained neural networks", "text": "The basic EBP method adjusts the weights in the direction in which the EBP algorithms were developed. There is a good exchange between the speed of the Newton algorithms and the stability of the EBP algorithms. [33] The basic EBP algorithm method adjusts the weights in the direction of the EBP algorithms. When we train with the EBP method, an iteration of the algorithms is defined."}, {"heading": "5 GENERATING ARTIFICIAL FUZZY STRUCTURES", "text": "In this section, we present our approach based on artificially created data sets. To this end, we developed a simple method for generating complex blurred structures. Our method is based on a non-deterministic state machine. In this machine, all states have assigned a level of uncertainty quantified by a truth value, by a much-vaunted logic. This type of machine has changed its statistics based on reading a word, and this change is described by a relationship that defines the statistical transition from the actual state to the characters that are read. This relationship to static change is a multi-morphism that is evaluated based on the data generated from its execution, and the characters actually read are described by a query. We called this type of state machine an \"N-automaton.\" In this section, we describe automata as a concept that needs to be learned, and show how reverse engineering executes its structure based on the data generated from its execution."}, {"heading": "5.1 Lukasiewicz automatas", "text": "This change is made after reading a character from a word. Each symbol used to define an automatic input string is a character that has the shape of the output character. Input at position i defines the truth of the output character. Automatic representation is defined by a series of states E. At any moment, these states are associated with a level of uncertainty in which the state of the automatic output character is evaluated. In this sense, an automatic actual state is described by a relationship defined in a series of states. The states of an automatic state are classified into three classes: input states, auxiliary states and output states. Input states are directly mapped to the input characters by uncertainty."}, {"heading": "5.2 Reverse engineering Lukasiewicz automatas", "text": "In fact, most of them are able to go to another world, to go to another world, to go to another world."}, {"heading": "6 KNOWLEDGE INTEGRATION VIA SPECIFICATION SYSTEMS", "text": "In fact, they are both very complex, very complex, very complex, very complex."}, {"heading": "7 CONCLUSIONS", "text": "This method of codifying and extracting symbolic knowledge from an NN is very simple and efficient for extracting comprehensible rules from medium-sized datasets. In addition, it is very useful to attribute relevance to it. 36From a theoretical point of view, it is particularly interesting that the limitation of values assumed by neuron weights restricts the propagation of information in the network, thus enabling the formation of patterns in the neural network structure.In the case of linear neural networks, which reduce identity to 0 and 1 by activation function, these structures are distinguished by the appearance of patterns in the neuron configuration, which can be directly represented as formulas in logic. Applying procedures such as the above to information systems generates a lot of information. We organize this information in a specification system using a relational language. And we propose this language as an interface for artificial intelligence."}], "references": [{"title": "Locally Presentable and Accessible Cateories", "author": ["J. Ad\u00e1mek", "J. Rosick\u00fd"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1994}, {"title": "Neural-simbolic Cognitive Reasoning", "author": ["A.S. d\u2019Avila Garcez", "L.C. Lamb", "D.M. Gabbay"], "venue": "Cognitive Technologies,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Topoi: The Categorical Analysis of Logic", "author": ["R. Goldblatt"], "venue": "Dover Publications", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Training feed-forward networks with marquardt algorithm", "author": ["M. Hagan", "M. Menhaj"], "venue": "IEEE Transaction on Neural Networks,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1999}, {"title": "Esquesses et types de structures algbriques", "author": ["C. Ehresmann"], "venue": "Bull. Instit. Polit., XIV,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1968}, {"title": "Sketches of an Elephant: A Topos Theory Compendium", "author": ["P. Johnstone"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Massively parallel reasoning. in: Automated Deduction - A Basis foe", "author": ["S. Bornscheuer", "S. H\u00f6lldobler", "Y. Kalinke", "A. Strohmaier"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Logic programs and connectionist networks", "author": ["P. Hitzler", "S. H\u00f6lldobler", "A. Seda"], "venue": "Journal of Applied Logic,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Challenge problems for the integration of logic and connectionist systems", "author": ["S. H\u00f6lldobler"], "venue": "Proceedings 14. Workshop Logische Programmierung, GMD Report", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Advances in neural-symbolic learning systems: Modal and temporal reasoning", "author": ["A.S. d\u2019Avila Garcez"], "venue": "Perspectives of Neural- Symbolic Integration, Studies in Computational Intelligence, Volume", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Connectionistic representation of multi-valued logic programs", "author": ["E. Komendantskaya", "M. Lane", "A.K. Seda"], "venue": "Studies in Computational Intelligence, Volume", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "The logic of neural networks", "author": ["J. Castro", "E. Trillas"], "venue": "Mathware and Soft Computing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Optimal brain surgeon and general network pruning", "author": ["B. Hassibi", "D. Stork", "G. Wolf"], "venue": "IEEE International Conference on Neural Network,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1993}, {"title": "An overview of generalised basic logic algebra", "author": ["P. Jipsen"], "venue": "Neural Network World,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Functional representation of many-valued logics based on continuous t-norms", "author": ["B. Gerla"], "venue": "PhD thesis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}, {"title": "Fuzzy logic and probability", "author": ["P. H\u00e1jek", "L. Godo", "Esteva"], "venue": "Uncertainty in Artificial Intelligence", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1995}, {"title": "Categories, Allegories", "author": ["P. Freyd", "A. Scedrov"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1990}, {"title": "Handbook of Categorical Algebra 1: Basic Category Theory", "author": ["B. Borceux"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1994}, {"title": "One setting for all: Metric, topology, uniformity, approach structure", "author": ["M. Clementino", "D. Hofmann", "W. Tholen"], "venue": "Theory Appl. Categ., v.11 n.15,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "The entity-relationship model - towards a unified view of data", "author": ["P. Chen"], "venue": "ACM Translations on Database Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1976}, {"title": "The functional data model and the data language daplex", "author": ["D. Shipman"], "venue": "ACM Translations on Database Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1981}, {"title": "What vs. how of visual modeling: The arrow logic of graphic notation", "author": ["Z. Diskin", "B. Kadish", "F. Piessens"], "venue": "Behavioral Specifications in Businesses and Systems, Eds. H. Kilov et al, Kluwer Acad.,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2000}, {"title": "Aspects of topoi", "author": ["P. Freyd"], "venue": "Bulletin of the Australian Mathematical Computer Science,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1972}, {"title": "Category Theory for Computing Science. Prentice-Hall International Series in Computer Science, Prentice-Hall", "author": ["M. Barr", "C. Wells"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}, {"title": "Generalized sketches as a framework for completeness theorems", "author": ["M. Makkai"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1993}, {"title": "Humans, computers, specifications: The arrow logic of information systems engineering", "author": ["Z. Diskin", "B. Kadish", "F. Pissen"], "venue": "Int. J. of Computing Anticipatory Systems,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "Neural networks and rational lukasiewicz logic", "author": ["P. Amato", "A. Nola", "B. Gerla"], "venue": "IEEE Transaction on Neural Networks,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "Semantics of architectural connectors", "author": ["J. Fiadeiro", "A. Lopes"], "venue": "TAPSOFT\u201997 LNCS, v.1214,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1997}, {"title": "A modified regression algorithm for fast one layer neural network training", "author": ["T. Andersen", "B. Wilamowski"], "venue": "World Congress of Neural Networks, Washington DC, USA,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1995}, {"title": "Frist- and second-order methods for learning between steepest descent and newton\u2019s method", "author": ["R. Battiti"], "venue": "Neural Computation,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1992}, {"title": "Neural Network Design", "author": ["M. Hagan", "H. Demuth", "M. Beal"], "venue": "PWS Publishing Company, Boston", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1996}, {"title": "Reverse engineering and simbolic knowledge extraction on lukasiewicz logics using neural networks", "author": ["C. Leandro"], "venue": "International Conference on Fuzzy Computation, IJCCI2009 proceedings,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2009}, {"title": "Rational lukasiewicz logic and divisible mv-algebras", "author": ["B. Gerla"], "venue": "Neural Networks World,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2001}, {"title": "Unifying logical and statistical ai", "author": ["P. Domingos", "S. Kok", "H. Poon", "M. Richardson", "P. Singla"], "venue": "In Proceeding of the Twenty-First National Conference on Artificial Intelegence", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "In this work we extend traditional algebraic specification methods [2] in this direction.", "startOffset": 67, "endOffset": 70}, {"referenceID": 1, "context": "Here we assume that such interface for AI emerges from an adequate Neural-Symbolic integration [3].", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "This integration is made for universe of discourse described on a Topos[4] governed by a many-valued Lukasiewicz logic.", "startOffset": 71, "endOffset": 74}, {"referenceID": 3, "context": "For the train of such neural networks we changed the Levenderg-Marquardt algorithm [5], restricting the knowledge dissemination in the network structure using soft crystallization.", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "The data specification requires finite, effective and comprehensive presentation of complete structures, this type of methodology was explored on Category Theory for algebraic specification by Ehresmann[6].", "startOffset": 202, "endOffset": 205}, {"referenceID": 5, "context": "for definition [7]), defined by relation evaluated in a many-valued logic.", "startOffset": 15, "endOffset": 18}, {"referenceID": 6, "context": "In the context of classic logic see [8] [9] [10], for the extraction of logic programs from trained networks.", "startOffset": 36, "endOffset": 39}, {"referenceID": 7, "context": "In the context of classic logic see [8] [9] [10], for the extraction of logic programs from trained networks.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "In the context of classic logic see [8] [9] [10], for the extraction of logic programs from trained networks.", "startOffset": 44, "endOffset": 48}, {"referenceID": 9, "context": "For the extraction of modal and temporal logic programs see [11] and [3].", "startOffset": 60, "endOffset": 64}, {"referenceID": 1, "context": "For the extraction of modal and temporal logic programs see [11] and [3].", "startOffset": 69, "endOffset": 72}, {"referenceID": 10, "context": "In [12] we can find processes to generate connectionist representation of multi-valued logic programs and for Lukasiewicz logic programs ( LL) [?].", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "Every logic connective can be defined by a neuron in an artificial network having, by activation function, the identity truncated to zero and one [13].", "startOffset": 146, "endOffset": 150}, {"referenceID": 3, "context": "using the Levenderg-Marquardt (LM) algorithm [5], and the generated network can be simplified using the \u201dOptimal Brain Surgeon\u201d algorithm proposed by B.", "startOffset": 45, "endOffset": 48}, {"referenceID": 12, "context": "Stork [14].", "startOffset": 6, "endOffset": 10}, {"referenceID": 13, "context": "Both, the logic and the algebraic semantics have been generalized in many directions [15].", "startOffset": 85, "endOffset": 89}, {"referenceID": 13, "context": "These two operators induce a structure of residuated poset on a partially ordered set of truth values P [15].", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "In [16], it is described as a binary operator defined in [0, 1] commutative and associative, non-decreasing in both arguments, 1\u2297 x = x and 0\u2297 x = 0.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "The Lukasiewicz fusion operator x\u2297y = max(0, x+y\u22121), its residue x\u2297y = min(1, 1\u2212x+y), and the lattice operators x\u2228y = max{x, y} and x\u2227y = minx, y, defined in \u03a9 = [0, 1] a structure of resituated lattice [15] since: 1.", "startOffset": 203, "endOffset": 207}, {"referenceID": 15, "context": "Petr H\u00e1jek presented in [18] extends this principle by embedding probabilistic logic in LL, for this we associated to each boolean formula \u03c6 a fuzzy proposition \u201d\u03c6 is provable\u201d.", "startOffset": 24, "endOffset": 28}, {"referenceID": 16, "context": "In next section we describe this type of relations in the context of allegory theory [19].", "startOffset": 85, "endOffset": 89}, {"referenceID": 17, "context": "The category \u03a9-Set is a symmetric monoidal closed category [20], where the tensor product of \u03a9-sets is given for \u03b1 : A and \u03b2 : B by \u03b1\u2297 \u03b2 : A\u00d7B defined (\u03b1\u2297 \u03b2)(a, b) = \u03b1(a) \u2297 \u03b2(b).", "startOffset": 59, "endOffset": 63}, {"referenceID": 18, "context": "Functor \u03b1\u2297 have by left adjunct a functor \u03b1 \u22b8 : \u03a9-Set \u2192 \u03a9-Set, defined for \u03a9-sets \u03b2 : B by \u03b1 \u22b8 \u03b2 : [A,B], construct as the internalization for \u03a9-set Hom [21] (\u03b1 \u22b8 \u03b2)(t, h) = \u2228", "startOffset": 153, "endOffset": 157}, {"referenceID": 17, "context": "This adjunction \u03b1\u2297 \u22a2 \u03b1 \u22b8 have by unit [20] the natural transformation, \u03bb defined for each \u03a9-set \u03b3 : C, by a multi-morphism \u03bb\u03b3 : (\u03b1 \u22b8 \u03b3)\u2297 \u03b1 \u21c0 \u03b3,", "startOffset": 38, "endOffset": 42}, {"referenceID": 17, "context": "The classically definition of limit for a diagram, in the category of sets, can been as a way to internalize the structure of a diagram in form of a table [20].", "startOffset": 155, "endOffset": 159}, {"referenceID": 0, "context": "Limits, colimits and commutativity can be used on the specification of structures [2].", "startOffset": 82, "endOffset": 85}, {"referenceID": 17, "context": "The construction of a colimit reduces to that of two coproducts and a coequalizer, siting [20], in the category of sets governed by classic logic the explicit description of a coequalizer is generically very technical since it involves the description of the equivalence relation generated by a family of pairs.", "startOffset": 90, "endOffset": 94}, {"referenceID": 19, "context": "All the widely used data specification mechanisms (like Entity Relationship Model [22], the Fundamental Data Model [23], the Generic Semantic Model [24]), OOA&D-schemas in a million of versions and UML which itself comprises a host of various notations, have a strong graphical component.", "startOffset": 82, "endOffset": 86}, {"referenceID": 20, "context": "All the widely used data specification mechanisms (like Entity Relationship Model [22], the Fundamental Data Model [23], the Generic Semantic Model [24]), OOA&D-schemas in a million of versions and UML which itself comprises a host of various notations, have a strong graphical component.", "startOffset": 115, "endOffset": 119}, {"referenceID": 21, "context": "Sketches where invented by Charles Ehresmann and can be perceived as a graphic based logic, which formalizes in a precise and uniform way the semantic of graph with marks [25].", "startOffset": 171, "endOffset": 175}, {"referenceID": 0, "context": "However, it is known from [2] what where are structures specifiable using sketches but not in first-order logic.", "startOffset": 26, "endOffset": 29}, {"referenceID": 21, "context": "This result allows to use a mixture of limits, colimits and formulas in the UoD specification and be sure that the resulting specification can always be translated to a specification system [25].", "startOffset": 190, "endOffset": 194}, {"referenceID": 22, "context": "For this we used a string-based codification for specification systems named relational specification, generalizing the notion of essentially algebraic specification: the original idea goes back to Freyd [26] and having the same expressive power as finite limit sketches [27].", "startOffset": 204, "endOffset": 208}, {"referenceID": 23, "context": "For this we used a string-based codification for specification systems named relational specification, generalizing the notion of essentially algebraic specification: the original idea goes back to Freyd [26] and having the same expressive power as finite limit sketches [27].", "startOffset": 271, "endOffset": 275}, {"referenceID": 24, "context": "A number of proof systems for essentially algebraic specification have been introduced [28].", "startOffset": 87, "endOffset": 91}, {"referenceID": 24, "context": "Makkai [28] and Z.", "startOffset": 7, "endOffset": 11}, {"referenceID": 25, "context": "Diskin [29].", "startOffset": 7, "endOffset": 11}, {"referenceID": 26, "context": "As mentioned in [30] there is a lack of a deep investigation of the relationships between logics and NNs.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "In [13] it is shown how, by taking as activation function, \u03c8, the identity truncated to zero and one,", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "\u03c8(x)=min(1,max(x,0)), it is possible to represent the corresponding NN as a combination of propositions of Lukasiewicz calculus and vice-versa [30].", "startOffset": 143, "endOffset": 147}, {"referenceID": 27, "context": "This task of construct complex structures based on simplest ones can be formalized using generalized programming [31].", "startOffset": 113, "endOffset": 117}, {"referenceID": 3, "context": "The Levenberg-Marquardt (LM) algorithm [5] [32] ensued from the development of EBP algorithm-dependent methods.", "startOffset": 39, "endOffset": 42}, {"referenceID": 28, "context": "The Levenberg-Marquardt (LM) algorithm [5] [32] ensued from the development of EBP algorithm-dependent methods.", "startOffset": 43, "endOffset": 47}, {"referenceID": 29, "context": "It gives a good exchange between the speed of the Newton algorithm and the stability of the steepest descent method [33].", "startOffset": 116, "endOffset": 120}, {"referenceID": 30, "context": "In this way, the performance function is always reduced at each iteration of the algorithm [34].", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "The optimization problem is constrained, following [14], we form the Lagrangian operator L = 1 2 \u2206wHw\u2206w + \u03bb(e T q \u2206wq + wq), where \u03bb is a Lagrange undetermined multiplier.", "startOffset": 51, "endOffset": 55}, {"referenceID": 31, "context": "5 GENERATING ARTIFICIAL FUZZY STRUCTURES We tested our methodology in real data sets [35] and on artificially generated data structures.", "startOffset": 85, "endOffset": 89}, {"referenceID": 32, "context": "This type of fuzzy automata have its behaviour described using formulas of Relational Lukasiewicz logic, introduced in [36], outfitting the scope of this work.", "startOffset": 119, "endOffset": 123}, {"referenceID": 12, "context": "This can be minimized by regularizing the produced NN using \u201dOptimal Brain Surgeon\u201d method [14].", "startOffset": 91, "endOffset": 95}, {"referenceID": 33, "context": "Here, classic graphical models like Bayesian and Markov networks have to some extent played the part of an interface layer, but one with a limited range having insufficiently expressive for general AI [37].", "startOffset": 201, "endOffset": 205}], "year": 2016, "abstractText": "The development of machine learning in particular and artificial intelligent in general has been strongly conditioned by the lack of an appropriate interface layer between deduction, abduction and induction [1]. In this work we extend traditional algebraic specification methods [2] in this direction. Here we assume that such interface for AI emerges from an adequate Neural-Symbolic integration [3]. This integration is made for universe of discourse described on a Topos[4] governed by a many-valued Lukasiewicz logic. Sentences are integrated in a symbolic knowledge base describing the problem domain, codified using a graphicbased language, wherein every logic connective is defined by a neuron in an artificial network. This allows the integration of first-order formulas into a network architecture as background knowledge, and simplifies symbolic rule extraction from trained networks. For the train of such neural networks we changed the Levenderg-Marquardt algorithm [5], restricting the knowledge dissemination in the network structure using soft crystallization. This procedure reduces neural network plasticity without drastically damaging the learning performance, allowing the emergence of symbolic patterns. This makes the descriptive power of produced neural networks similar to the descriptive power of Lukasiewicz logic language, reducing the information lost on translation between symbolic and connectionist structures. We tested this method on the extraction of knowledge from specified structures. For it, we present the notion of fuzzy state automata, and we use automata behaviour to infer its structure. We use this type of automata on the generation of models for relations specified as symbolic background knowledge. Using the involved automata behaviour as data sets, we used our learning methodology, to extract new insights about the models, and inject them into the specification. This allows the improvement about the problem domain knowledge. \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013", "creator": "LaTeX with hyperref package"}}}