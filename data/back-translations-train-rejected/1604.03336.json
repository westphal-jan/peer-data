{"id": "1604.03336", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2016", "title": "Typical Stability", "abstract": "In this paper, we introduce a new notion of algorithmic stability called typical stability. When our goal is to release real-valued queries (statistics) computed over a dataset, this notion does not require the queries to be of bounded sensitivity -- a condition that is generally assumed under a standard notion of algorithmic stability known as differential privacy [DMNS06, Dwo06]. Instead, typical stability requires the output of the query, when computed on a dataset drawn from the underlying distribution, to be \"well-concentrated\" around its expected value with respect to that distribution. Typical stability can also be motivated as an alternative definition for database privacy (in such case, we call it typical privacy). Like differential privacy, this notion enjoys several important properties including robustness to post-processing and adaptive composition.", "histories": [["v1", "Tue, 12 Apr 2016 10:52:06 GMT  (19kb,D)", "http://arxiv.org/abs/1604.03336v1", null], ["v2", "Mon, 19 Sep 2016 00:06:06 GMT  (25kb,D)", "http://arxiv.org/abs/1604.03336v2", "New sections, extended discussions, and complete proofs"]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["raef bassily", "yoav freund"], "accepted": false, "id": "1604.03336"}, "pdf": {"name": "1604.03336.pdf", "metadata": {"source": "CRF", "title": "Typicality-Based Stability and Privacy", "authors": ["Raef Bassily", "Yoav Freund"], "emails": ["rbassily@ucsd.edu", "yfreund@eng.ucsd.edu"], "sections": [{"heading": null, "text": "We also discuss the guarantees of the typical stability of the generalization error (i.e. the difference between the value of the query calculated on the dataset and the expected value of the query in terms of true data distribution).We show that these guarantees apply to a broader class of queries than to queries with limited sensitivity. This class includes all queries whose output distributions have a \"light\" tail, e.g. subgaussian and subexponential queries. In particular, we show that if a typical stable interaction with a dataset results in a query from that class, that query, when evaluated on the same dataset, will most likely have a small generalization error (i.e., it will not match the dataset).We discuss the composition guarantees for typical stability and prove a composition theory that results in a characterization of the degradation of the parameters of typical stability / privacy under Xixfold composition."}, {"heading": "1 Introduction", "text": "In this thesis we present a new conception of algorithmic stability, which requires a typical change in the value of the data set due to a change in each individual data point of the data distribution. In this thesis we present a new conception of algorithmic stability, which requires typical stability of the data distribution."}, {"heading": "2 Typical Stability/Privacy", "text": "Before formally defining typical stability, we first present a standard definition for the definition of indistinguishability between the distributions of random variables. Random variables X, Y with the same bandwidth should have (\u03b7, \u03c4) -indistinguishable distributions, which are called X \u2248 \u03b7, \u03c4 Y, if for all measurable subsets O of their range over"}, {"heading": "P [X \u2208 O] \u2264 e\u03b7P [Y \u2208 O] + \u03c4 and P [Y \u2208 O] \u2264 e\u03b7P [X \u2208 O] + \u03c4.", "text": "(Definition 2.2 (Typical Definition Stability / Privacy). Letter A: X n \u2192 Z is a randomized algorithm (Definition 2.2 (Definition 2.2). (Definition 2.2 (Typical Stability / Privacy). Letter A: X n \u2192 Z is a randomized algorithm (Definition 2.2). (Definition 2.2). (Definition 2.2 (Typical Stability / Privacy). Letter A: X n \u2192 Z is a randomized algorithm. (Definition 2.2). (Definition 2.2). Definition 2.2. Definition 2.2. Definition 2.3. Definition 2.2. Definition 2.2. Definition 2.2. Definition 2.2. Definition 2.2. Definition 2.2."}, {"heading": "2.1 Some properties of typical stability", "text": "Here we list some useful properties of typical stable algorithms. In particular, we show that this notion is closed under post-processing and non-adaptive composition, where the stability parameters decrease linearly with the number of algorithms to be composed. We move the discussion on the adaptive composition of typically stable algorithms to Section 3.Lemma 2.4 (Postprocessing). Let A: X n \u2192 Z enter (\u03b7, \u03c4, \u03bd) -typically stable algorithm in relation to a family of distributions P via X. Let B: Zn \u2192 U be a randomized algorithm. Let C: X n \u2192 U be defined as C (x) = B (x). Then C is a typically stable algorithm in relation to P.Proof. The proof follows from a simple manipulation in which the probability of a measurable subset O of the results of C is expressed."}, {"heading": "2.2 Queries", "text": "We introduce the classes of queries (data set statistics) that are taken into account in this article. \u2022 We define q-q q q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-"}, {"heading": "2.3 Typical stability and the Near-Independence property", "text": "The following dilemma describes an important implication of typical stability. It describes the effects of typical stability on the common distribution of the dataset and the output of a typical stable algorithm. Let P be a family of distributions over X. Let X-P be P-P for any distribution. Let A: X-Z (Search, Search, Find) -typical stable algorithm with respect to P-Lemma 2.6 below state that the common probability measurement of (X, A (X)) is \"close\" to the product measurement of X and A (X) (i.e., the measurement quantity induced by the product of the marginal distributions. A similar statement is known for the quantitative-differentiated private algorithms over a link to the notion of max information [DFH + 15a]. Although the argument here is closely related, we will not go through the limitation of max information to the typical stability that we assume that the dissemination of the X data comes from any given family."}, {"heading": "2.4 Generalization via Typical Stability", "text": "Let P have a distribution over X n. The next theorem states that if a (\u03b7, \u03c4, e \u2212 \u03b3n (\u03b1)) -typically stable interaction with a dataset X \u0445 P leads to a query in Q\u03b3n (P), then the generalization error of this query will most likely be limited to the dataset by \u03b1. Theorem 2,7 (generalization about typical stability). Let P have any distribution in X. Leave A: X > 0. Let A: X n \u2192 Q\u03b3n (P) be a typically stable algorithm in relation to P, which will output an acquin-focused query in Q\u03b3n (P). Let qX specify the output of A (X)."}, {"heading": "3 Adaptive Composition of Typically Stable Algorithms", "text": "In this section we will discuss an important property of typical stability. Before presenting our composition results, we will first describe the adaptive composition model. Let P define a family of distributions over X n. We will consider an arbitrary sequence of adaptively chosen k algorithms Ai: X n \u00b7 Z1 \u00b7.. \u00b7 Zi \u2212 1 \u2192 Zi, i [k] such that for each i-fold [k] and each zi \u2212 1, (z1,..., zi \u2212 1), Z1 \u00b7. \u00b7 Zi \u2212 1) the algorithm Ai (\u00b7, zi \u2212 1) is typically stable in relation to P. We will consider the k-fold adaptive composition mechanism ismMk outlined in Algorithm 1.definition 3.1. We will say that the class of (n, zi \u2212 1) -fold, permanent, permanent, permanent, permanent, permanent) -stable mechanisms (Mwr.P) is typically stable."}, {"heading": "3.1 Composition of pure typically stable algorithms", "text": "In this section we state and prove our composition theorem for pure typical stable algorithms (i.e., \u03c4 = 0). Whenever we refer to any run of Mk in this section, it is assumed that Mk is \u03c4 = 0.For pure typical stable algorithms, for each process. \"> 0, the following parameters are attainable for the k-fold adaptive composition (where k \u2265 2): \u03b7k = 3 \u221a 2k log (1 / \u03c4 \u2032) \u03b7 + 3k\u03b7 (e\u03b7 \u2212 1), (3) \u03c4k = 5 k.P = 5 k.P = 5 k.P is the applicable ability of 1 / 2 (4) This is formally stated in the following Theorem.Theorem 3.2 (Adaptive Composition of Pure Typically Stable Algorithms). Let us leave the K-N. For all processes. > 0, 0 k.P < and 0 & lt. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "3.1.1 Proof of Theorem 3.2", "text": "Fix any P-value. Let us fix X-value for each integer j-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-value i-i-value i-value i-value i-value i-value i-value i-i-value i-value i-i-value i-value i-i-value i-i-value i-i-value i-value i-i-value i-i-i-i-i-value"}, {"heading": "3.2 Composition of approximate typically stable algorithms: \u03c4 > 0", "text": "< < &; < < &; < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &lt"}, {"heading": "4 Achieving typical stability", "text": "We describe here two simple noise-adding mechanisms to achieve a pure and approximate typical stability for the release of noise. As a special case, we obtain typical stable algorithms for the release of queries with low sensitivity. The algorithms are based on the addition of Laplace and Gaussian noise to the output of the query, and therefore such algorithms become very similar to their different private counterparts. However, the added noise is calibrated differently than in the case of differential privacy. Instead of calibrating noise on the basis of the global (or smooth) sensitivity of the query, noise is added here on the basis of the concentration radius of the query output, i.e., based on the query output focuses on its averages in relation to the data. In particular, for the class of Gault-n concentrated queries, in order to achieve typical stability, noise is calibrated on the basis of the query output (s) \u2212 n."}, {"heading": "Acknowledgement", "text": "We would like to thank Adam Smith for the helpful discussion and for pointing out to us the conditioning dilemma of [KS14] that we have used in our evidence for the adaptive composition that guarantees typical stability."}], "references": [{"title": "Algorithmic stability for adaptive data analysis", "author": ["Raef Bassily", "Kobbi Nissim", "Adam Smith", "Uri Stemmer", "Thomas Steinke", "Jonathan Ullman"], "venue": null, "citeRegEx": "Bassily et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bassily et al\\.", "year": 2016}, {"title": "Adaptive learning with robust generalization guarantees. arXiv:1602.07726v1, Feb. 2016", "author": ["Rachel Cummings", "Katrina Ligett", "Kobbi Nissim", "Aaron Roth", "Zhiwei Steven Wu"], "venue": null, "citeRegEx": "Cummings et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Cummings et al\\.", "year": 2016}, {"title": "Generalization in adaptive data analysis and holdout reuse", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "In ACM Symposium on the Theory of Computing (STOC)", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "The reusable holdout: Preserving validity in adaptive data analysis", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": "Science,", "citeRegEx": "Dwork et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2015}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "author": ["Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor"], "venue": "In EUROCRYPT,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "The algorithmic foundations of differential privacy", "author": ["Cynthia Dwork", "Aaron Roth"], "venue": "Foundations and Trends in Theoretical Computer Science,", "citeRegEx": "Dwork and Roth.,? \\Q2014\\E", "shortCiteRegEx": "Dwork and Roth.", "year": 2014}, {"title": "Boosting and differential privacy", "author": ["Cynthia Dwork", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": "In IEEE Symposium on Foundations of Computer Science (FOCS", "citeRegEx": "Dwork et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2010}, {"title": "Differential privacy. In Automata, Languages and Programming, 33rd International Colloquium, ICALP 2006, Venice, Italy", "author": ["Cynthia Dwork"], "venue": "July 10-14,", "citeRegEx": "Dwork.,? \\Q2006\\E", "shortCiteRegEx": "Dwork.", "year": 2006}, {"title": "On the \u2018semantics\u2019 of differential privacy: A bayesian formulation", "author": ["Shiva P. Kasiviswanathan", "Adam Smith"], "venue": "Journal of Privacy and Confidentiality,", "citeRegEx": "Kasiviswanathan and Smith.,? \\Q2014\\E", "shortCiteRegEx": "Kasiviswanathan and Smith.", "year": 2014}, {"title": "Controlling bias in adaptive data analysis using information theory", "author": ["Daniel Russo", "James Zhou"], "venue": "Novemver", "citeRegEx": "Russo and Zhou.,? \\Q2015\\E", "shortCiteRegEx": "Russo and Zhou.", "year": 2015}, {"title": "A minimax theory for adaptive data analysis", "author": ["Yu-Xiang Wang", "Jing Lei", "Stephen E. Fienberg"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}], "referenceMentions": [], "year": 2017, "abstractText": "In this paper, we introduce a new notion of algorithmic stability called typical stability. When our goal is to release real-valued queries (statistics) computed over a dataset, this notion does not require the queries to be of bounded sensitivity \u2013 a condition that is generally assumed under a standard notion of algorithmic stability known as differential privacy [DMNS06, Dwo06]. Instead, typical stability requires the output of the query, when computed on a dataset drawn from the underlying distribution, to be \u201cwell-concentrated\u201d around its expected value with respect to that distribution. Typical stability can also be motivated as an alternative definition for database privacy (in such case, we call it typical privacy). Like differential privacy, this notion enjoys several important properties including robustness to post-processing and adaptive composition. We also discuss the guarantees of typical stability on the generalization error (i.e., the difference between the value of the query computed on the dataset and the expected value of the query with respect to the true data distribution). We show that these guarantees hold for a broader class of queries than that of bounded-sensitivity queries. This class contains all queries whose output distributions have a \u201clight\u201d tail, e.g., subgaussian and subexponential queries. In particular, we show that if a typically stable interaction with a dataset yields a query from that class, then this query when evaluated on the same dataset will have small generalization error with high probability (i.e., it will not overfit to the dataset). We discuss the composition guarantees of typical stability and prove a composition theorem that gives a characterization of the degradation of the parameters of typical stability/privacy under k-fold adaptive composition. We also give simple noise-addition algorithms that achieve this notion. These algorithms are similar to their differentially private counterparts, however, the added noise is calibrated differently. \u2217University of California San Diego, Center for Information Theory and Applications and Department of Computer Science and Engineering. rbassily@ucsd.edu \u2020University of California San Diego, Department of Computer Science and Engineering. yfreund@eng.ucsd.edu ar X iv :1 60 4. 03 33 6v 1 [ cs .L G ] 1 2 A pr 2 01 6", "creator": "LaTeX with hyperref package"}}}