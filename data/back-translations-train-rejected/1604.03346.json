{"id": "1604.03346", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2016", "title": "An incremental linear-time learning algorithm for the Optimum-Path Forest classifier", "abstract": "We present a classification method with linear-time incremental capabilities based on the Optimum-Path Forest (OPF) classifier. The OPF considers instances as nodes of a fully-connected training graph, where the edges' weights are the distances between two nodes' feature vectors. Upon this graph, a minimum spanning tree is built, and every edge connecting instances of different classes is removed, with those nodes becoming prototypes or roots of a tree. A new instance is classified by discovering which tree it would conquer. In this paper we describe a new training algorithm with incremental capabilities while keeping the properties of the OPF. New instances can be inserted in the model into one of the existing trees; substitute the prototype of a tree; or split a tree. This incremental method was tested for accuracy and running time against both full retraining using the original OPF and an adaptation of the Differential Image Foresting Transform. The method updates the training model in linear-time, while keeping similar accuracies when compared with the original model, which runs in quadratic-time.", "histories": [["v1", "Tue, 12 Apr 2016 11:31:23 GMT  (242kb,D)", "https://arxiv.org/abs/1604.03346v1", null], ["v2", "Wed, 22 Jun 2016 15:47:21 GMT  (483kb,D)", "http://arxiv.org/abs/1604.03346v2", null], ["v3", "Fri, 29 Jul 2016 15:54:04 GMT  (243kb,D)", "http://arxiv.org/abs/1604.03346v3", "submitted to Journal"], ["v4", "Fri, 12 Aug 2016 13:14:10 GMT  (243kb,D)", "http://arxiv.org/abs/1604.03346v4", "submitted to Journal"], ["v5", "Wed, 23 Nov 2016 12:08:23 GMT  (253kb,D)", "http://arxiv.org/abs/1604.03346v5", "submitted to IPL Journal for consideration in Nov/2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["moacir ponti", "mateus riva"], "accepted": false, "id": "1604.03346"}, "pdf": {"name": "1604.03346.pdf", "metadata": {"source": "CRF", "title": "An incremental linear-time learning algorithm for the Optimum-Path Forest classifier", "authors": ["Moacir Ponti", "Mateus Riva"], "emails": [], "sections": [{"heading": null, "text": "We present a classification method with incremental capabilities based on the Optimum Path Forest Classifier (OPF). The OPF regards instances as nodes in a fully networked training graph, arc weights represent distances between two attribute vectors. Our algorithm considers new instances in an OPF in linear time while maintaining similar accuracies to the original square time model."}, {"heading": "1. Introduction", "text": "The best solution is for it to be a way in which people are able to decide for themselves what they want to do and what they want to do."}, {"heading": "2. OPF Incremental (OPFI)", "text": "The optimal path forest (OPF) classifier [1] interprets the instances (examples) as the nodes (indentations) of a graph. The edges that connect the indentations are defined by an adjacence relationship between the examples, which is weighted by a distance function. It is expected that training examples from a given class are joined by a path of nearby examples. Therefore, the model learned by the algorithm is composed of several trees, each tree is a minimum stress tree (MST) and the root of each tree becomes a prototype. Our OPF incremental updates on an initial model that is achieved by using the minimum stress construction properties in the existing optimum path forest. Provided this initial model can include a new instance in linear time. Note that it is typical in incremental learning scenarios to start with an incomplete training class, often presenting a lack of accuracy due to a sufficient class."}, {"heading": "3. Complexity Analysis", "text": "The complexity of inserting a new example into a model that altogether contains n nodes is O (n), as we show for each case below. (i) The predecessor belongs to a different class. splitting a tree is O (1), as it requires only a certain edge to be removed. Recapture is O (n), as it passes through each node at most once, as described by [1]. (ii) The predecessor is of the same class and is a prototype. Also, the complexity of recapture is O (n). Otherwise, it is an insertion, with the complexity O (n), as described in the case. (iii) The predecessor is of the same class and is not a prototype. The complexity of the operation is related to the inclusion of a new example on an existing tree. The complexity is O (n), or linear in terms of the number of examples."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Data sets", "text": "The code and all datasets that are not publicly available can be found at http: / / www.icmc.usp.br / ~ moacir / paper / 16opfi.html. A variety of synthetic and real datasets are used in the experiments.Synthetic datasets: Base1 / Base2 / Base3: with the size 10000 and data distributed over 4 regions. Base1 has 2 classes, Base2 has 4 classes and Base3 has 3 classes; Lithuanian, Circle vs Gaussian (C-vs-G), Cone-Torus and Saturn: are 2-d classes with different distributions. Real datasets: CTG cardiotocography dataset, 2126 examples, 21 features, 3 classes; NTL (non-technical losses) Energy Profile dataset, 4952 examples, 8 features, 2 classes; Parkinsons dataset, 193 examples, 22 features, 2 classes; Produce Image dataset, 1400-mail, examples, 64-examples, and E-samples; 14-types."}, {"heading": "4.2. Experimental setup", "text": "The experiments were conducted to test the OPFI algorithm and compare it with the original OPF and DIFT. We strive for a similar accuracy in terms of linear time. Each experiment was performed in 10-fold hold-out sampling: 1. Split Data 50-50: S for supervised training and T for testing, maintaining the class distribution of the original data set; 2. Split S: maintaining class proportions: BaseN, C-vs-G, Lithu, CTG, NTL, Parkinsons, Produce, SpamBase, Skin: in 100 subsets Si, with i = 0.. 99. Cone-Torus, Saturn, MPEG7: in 10 subsets Si, with i = 0.. 9 (fewer subsets because they have few examples / class).3. Initial training on S0 using the original OPF as a basis to be incremented; 4. Update model including each sequence starting with 1."}, {"heading": "5. Results and Discussion", "text": "The balanced accuracy (taking into account the proportions of the examples in each class) of the results is shown in Table 1. A diagram with accuracy and runtime results for 3 datasets is shown in Figure 2. By looking at the average and standard deviations, one can see that OPFI is able to obtain accuracies similar to the original OPF and DIFT. However, it runs faster than the OPF and does not affect the graph structure as with DIFT. Optimal path trees are preserved and can therefore be examined in scenarios where incremental learning is required. Runtime curves show linear versus quadratic behavior in all experiments: In the examples in the previous model, each new recording would take O (n + 1) 2 with the original OPF, while OPFI would do it in O (n + 1)."}, {"heading": "Acknowledgment", "text": "We thank FAPESP (# 11 / 22749-8 and # 11 / 16411-4)."}], "references": [{"title": "Efficient supervised optimum-path forest classification for large datasets", "author": ["J.P. Papa", "A. Falc\u00e3o", "V. De Albuquerque", "J. Tavares"], "venue": "Pattern Recognition 45 (1) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Ensembles of optimum-path forest classifiers using input data manipulation and undersampling", "author": ["M. Ponti-Jr.", "I. Rossi"], "venue": "in: MCS 2013,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Improving accuracy and speed of optimum-path forest classifier using combination of disjoint training subsets", "author": ["M. Ponti-Jr", "J. Papa"], "venue": "in: 10th Int. Work. on Multiple Classifier Systems ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "A path-and label-cost propagation approach to speedup the training of the optimum-path forest classifier", "author": ["A.S. Iwashita", "J.P. Papa", "A. Souza", "A.X. Falc\u00e3o", "R. Lotufo", "V. Oliveira", "V.H.C. De Albuquerque", "J.M.R. Tavares"], "venue": "Pattern Recognition Letters 40 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Estimating the number of connected components in sublinear time", "author": ["P. Berenbrink", "B. Krayenhoff", "F. Mallmann-Trenn"], "venue": "Information Processing Letters 114 (11) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Incremental learning", "author": ["X. Geng", "K. Smith-Miles"], "venue": "Encyclopedia of Biometrics ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Interactive volume segmentation with differential image foresting transforms", "author": ["A.X. Falc\u00e3o", "F.P. Bergo"], "venue": "Medical Imaging, IEEE Transactions on 23 (9) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Algorithms for updating minimal spanning trees", "author": ["F. Chin", "D. Houck"], "venue": "Journal of Computer and System Sciences 16 (3) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1978}, {"title": "Incremental algorithms for minimal length paths", "author": ["G. Ausiello", "G.F. Italiano", "A.M. Spaccamela", "U. Nanni"], "venue": "Journal of Algorithms 12 (4) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "The optimum-path forest (OPF) classifier [1] a classification method that can be used to build simple, multiclass and parameter independent classifiers.", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "Some efforts were made to mitigate such running time by using several OPF classifiers trained with ensembles of reduced training sets [2] and fusion using split sets using multi-threading [3].", "startOffset": 134, "endOffset": 137}, {"referenceID": 2, "context": "Some efforts were made to mitigate such running time by using several OPF classifiers trained with ensembles of reduced training sets [2] and fusion using split sets using multi-threading [3].", "startOffset": 188, "endOffset": 191}, {"referenceID": 0, "context": "Also, recent work developed strategies to speed-up the training algorithm by taking advantage of data structures such as [1, 4].", "startOffset": 121, "endOffset": 127}, {"referenceID": 3, "context": "Also, recent work developed strategies to speed-up the training algorithm by taking advantage of data structures such as [1, 4].", "startOffset": 121, "endOffset": 127}, {"referenceID": 4, "context": "However, an OPF-based method with incremental capabilities is still to be investigated, since sub-quadratic algorithms are important in many scenarios [5].", "startOffset": 151, "endOffset": 154}, {"referenceID": 5, "context": "Incremental learning is a machine learning paradigm in which the classifier changes and adapts itself to include new examples that emerged after the initial construction of the classifier [6].", "startOffset": 188, "endOffset": 191}, {"referenceID": 3, "context": "In [4] the authors propose", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "In this paper we describe an algorithm that can include new examples individually (or in small batches) in an already build model, which is a different objective when compared to [4] and [1].", "startOffset": 179, "endOffset": 182}, {"referenceID": 0, "context": "In this paper we describe an algorithm that can include new examples individually (or in small batches) in an already build model, which is a different objective when compared to [4] and [1].", "startOffset": 187, "endOffset": 190}, {"referenceID": 0, "context": "In fact, we already used the improvements proposed by [1].", "startOffset": 54, "endOffset": 57}, {"referenceID": 6, "context": "Because OPF is based on the Image Foresting Transform for which there is a differential algorithm available (DIFT) [7], it would be a natural algorithm to try.", "startOffset": 115, "endOffset": 118}, {"referenceID": 7, "context": "Our OPF-Incremental (OPFI) is inspired in graph theory methods to update minimum spanning trees [8] and minimal length paths [9] in order to maintain the graph structure and thus the learning model.", "startOffset": 96, "endOffset": 99}, {"referenceID": 8, "context": "Our OPF-Incremental (OPFI) is inspired in graph theory methods to update minimum spanning trees [8] and minimal length paths [9] in order to maintain the graph structure and thus the learning model.", "startOffset": 125, "endOffset": 128}, {"referenceID": 0, "context": "The optimum-path forest (OPF) classifier [1] interprets the instances (examples) as the nodes (vertices) of a graph.", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "1: OPF Classify(Z, T) // as in [1] 2: for i\u2190 1 to b (each new example) do", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "The minimum spanning tree insertion function, described on Algorithm 2 is an adapted version of the minimum spanning tree updating algorithm proposed by [8].", "startOffset": 153, "endOffset": 156}, {"referenceID": 0, "context": "The reconquest function was defined by [1], and described also here on Algorithm 4 for clarity.", "startOffset": 39, "endOffset": 42}, {"referenceID": 0, "context": "in [1].", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "The reconquest is O(n), since it goes through each node at most once as described by [1];", "startOffset": 85, "endOffset": 88}], "year": 2016, "abstractText": "We present a classification method with incremental capabilities based on the Optimum-Path Forest classifier (OPF). The OPF considers instances as nodes of a fully-connected training graph, arc weights represent distances between two feature vectors. Our algorithm includes new instances in an OPF in linear-time, while keeping similar accuracies when compared with the original quadratic-time model.", "creator": "LaTeX with hyperref package"}}}