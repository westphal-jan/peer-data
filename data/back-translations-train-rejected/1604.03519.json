{"id": "1604.03519", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2016", "title": "Going Deeper with Contextual CNN for Hyperspectral Image Classification", "abstract": "In this paper, we describe a novel deep convolutional neural networks (CNN) based approach called contextual deep CNN that can jointly exploit spatial and spectral features for hyperspectral image classification. The contextual deep CNN first concurrently applies multiple 3-dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image. The initial spatial and spectral feature maps obtained from applying the variable size convolutional filters are then combined together to form a joint spatio-spectral feature map. The joint feature map representing rich spectral and spatial properties of the hyperspectral image is then fed through fully convolutional layers that eventually predict the corresponding label of each pixel vector. The proposed approach is tested on the Indian Pines data and performance comparison shows enhanced classification performance of the proposed approach over the current state of the art.", "histories": [["v1", "Tue, 12 Apr 2016 18:44:34 GMT  (255kb)", "http://arxiv.org/abs/1604.03519v1", null], ["v2", "Fri, 21 Oct 2016 19:39:52 GMT  (440kb)", "http://arxiv.org/abs/1604.03519v2", null], ["v3", "Tue, 9 May 2017 14:21:21 GMT  (917kb,D)", "http://arxiv.org/abs/1604.03519v3", "14 pages"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hyungtae lee", "heesung kwon"], "accepted": false, "id": "1604.03519"}, "pdf": {"name": "1604.03519.pdf", "metadata": {"source": "CRF", "title": "CONTEXTUAL DEEP CNN BASED HYPERSPECTRAL CLASSIFICATION", "authors": ["Hyungtae Lee", "Heesung Kwon"], "emails": [], "sections": [{"heading": null, "text": "Networks (CNN) based approach called Contextual Deep CNN, which collectively utilizes spatial and spectral characteristics for hyperspectral image classification. Contextual Deep CNN first applies multiple three-dimensional local coil filters of different sizes simultaneously, using spatial and spectral characteristics of a hyper-spectral image. Initial spatial and spectral characteristic maps derived from the application of the variable size of coil filters are then combined into a common spatial-spectral characteristic map. The common characteristic map, which represents rich spectral and spatial characteristics of the hyper-spectral image, is then fed through fully contextual layers that ultimately predict the corresponding designation of each pixel vector. The proposed approach is tested on the data from Indian Pines and the performance comparison demonstrates an improved classification performance of the proposed approach over the current state of art.Index terms - contextual hyperspectral, shared classification and spatial separation."}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them will be able to move to another world, where they will be able to integrate and flourish."}, {"heading": "2. CONTEXTUAL DEEP CNN", "text": "In fact, it is the case that we will be able to set out to find a solution that is in the position in which we find ourselves."}, {"heading": "3. EXPERIMENTAL RESULTS", "text": "The hyper-spectral classification performance of the proposed network is evaluated using the Indian Pines dataset, which consists of 145x145 and 220 spectral reflection bands in the range of 0.4 to 2.45 \u03bcm of the visible and near infrared spectrum with a spatial resolution of 20m. Indian Pines dataset comprises 16 classes, but we only use 8 classes with a relatively large number of samples. We compare the performance with Hu et al. [4] using a different architecture of deep CNN. For a fair comparison, we randomly select 200 samples for each class and use them as training samples. The rest is used to test the proposed network. Selected classes and the number of training and test samples are listed in Table 1. Since the proposed network is constructed as FCN, any hyper-spectral image of any size can be learned and tested. Table 2 shows the performance comparison between the proposed network and baseline. As baseline, we use an SVM classification with the proposed base architecture and the proposed kernel architecture respectively."}, {"heading": "4. CONCLUSIONS", "text": "A fully convolutionary neural network that can share local spatial-spectral properties of hyperspectral images has been proposed; the proposed CNN architecture uses a total of 9 convolutionary layers that are trained effectively without overlapping from a relatively small number of training samples; and the proposed network provides improved classification performance compared to the current state of the art using various deep CNN architectures."}, {"heading": "5. REFERENCES", "text": "[1] A. Krizhevsky, I. Sutskever and G. E. Hinton, \"ImageNet Classification with deep convolutional neural networks,\" NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada [2] Deep learning related papers published in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2014-15, European Conference on Computer Vision (ECCV) 2014, International Conference on Applied Computer Vision (ICCV) 2015. [3] Y. Chen, Z. Lin, G. Wang, and Y. Gu, \"Deep Learning-Based Classification of Hyperspectral Data,\" IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, Volume 7, No. 6, June 2014. [4] W. Hu, Y. Huang, W. Li, F. Zhang, and H. Li, \"Deep Convolutional Neural Networks for Hyperspectral Image Classifications, of Journal of Sensors, No. 6, June 2014, and W. Hu. [4] Wang, Hu."}], "references": [{"title": "ImageNet Classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep Learning-Based Classification of Hyperspectral Data", "author": ["Y. Chen", "Z. Lin", "G. Wang", "Y. Gu"], "venue": "IEEE Journal of Selected topics in applied earth observations and remote sensing, vol 7, No. 6, June 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep Convolutional Neural Networks for Hyperspectral Image Classifications", "author": ["W. Hu", "Y. Huang", "W. Li", "F. Zhang", "H. Li"], "venue": "Journal of Sensors, Vol. 2015, Article ID 258619.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Going Deeper with Convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Residual Learning for Image Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv:1512.03385v1.  Figure 2. RGB composition maps of groundtruth (left) of Indian Pines dataset and classification results (right) of the proposed network for the dataset. The legend is listed below the figure.  Corn-notill Corn-mintill Grass-pasture Hay-windrowed Soybean-notill Soybean-mintill Soybean-clean Woods", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1512}], "referenceMentions": [{"referenceID": 0, "context": "Recently, deep convolutional neural networks (CNN) [1,2] have been extensively used for a wide range of visual perception tasks, such as object detection, action/activity recognition, etc.", "startOffset": 51, "endOffset": 56}, {"referenceID": 1, "context": "Lately, there have been increasing efforts to use deep learning based approaches for hyperspectral image classification [3,4].", "startOffset": 120, "endOffset": 125}, {"referenceID": 2, "context": "Lately, there have been increasing efforts to use deep learning based approaches for hyperspectral image classification [3,4].", "startOffset": 120, "endOffset": 125}, {"referenceID": 1, "context": "In [3], stacked autoencoders (SAE) are used to learn deep features of hyperspectral signatures in an unsupervised fashion followed by logistic regression used to classify extracted deep features into their appropriate material categories.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "In [4], individual spectral pixel vectors are independently fed through simple CNN in which local convolutional filters are applied to the spectral vectors extracting local spectral features.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "As can be seen in [3,4], the current state of the art approaches for deep learning based hyperspectral classification fall short of fully exploiting spectral and spatial information together.", "startOffset": 18, "endOffset": 23}, {"referenceID": 2, "context": "As can be seen in [3,4], the current state of the art approaches for deep learning based hyperspectral classification fall short of fully exploiting spectral and spatial information together.", "startOffset": 18, "endOffset": 23}, {"referenceID": 1, "context": "The two different types of information, spectral and spatial, are more or less acquired separately from pre-processing and then processed together for feature extraction and classification in [3].", "startOffset": 192, "endOffset": 195}, {"referenceID": 2, "context": "[4] also failed to jointly process the spectral and spatial information together by only using individual spectral pixel vectors as input to the CNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "In this paper, inspired by [5], we propose a novel deep learning based approach called contextual deep CNN that uses fully convolutional layers to better exploit spectral and spatial information from hyperspectral data together.", "startOffset": 27, "endOffset": 30}, {"referenceID": 3, "context": "The first convolutional layer applied to the input hyperspectral image uses an inception module [5] that locally convolves the input image with two convolutional filters with different sizes (1x1xB and 3x3xB where B is the number of spectral bands).", "startOffset": 96, "endOffset": 99}, {"referenceID": 4, "context": "We use two modules from the residual learning approach [6], which demonstrated to ease the training of deep network.", "startOffset": 55, "endOffset": 58}, {"referenceID": 0, "context": "The layer combination in the last three convolutional layers is the same as the fully connected layers of Alexnet [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "[4] using a different architecture of deep CNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "As baselines, we use a SVM classifier with RBF kernel and the different architecture of deep CNN in [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "[4] 90.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "In this paper, we describe a novel deep convolutional neural networks (CNN) based approach called contextual deep CNN that can jointly exploit spatial and spectral features for hyperspectral image classification. The contextual deep CNN first concurrently applies multiple 3-dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image. The initial spatial and spectral feature maps obtained from applying the variable size convolutional filters are then combined together to form a joint spatio-spectral feature map. The joint feature map representing rich spectral and spatial properties of the hyperspectral image is then fed through fully convolutional layers that eventually predict the corresponding label of each pixel vector. The proposed approach is tested on the Indian Pines data and performance comparison shows enhanced classification performance of the proposed approach over the current state of the art.", "creator": "Microsoft\u00ae Word 2010"}}}