{"id": "1604.03526", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2016", "title": "Spatiotemporal Articulated Models for Dynamic SLAM", "abstract": "We propose an online spatiotemporal articulation model estimation framework that estimates both articulated structure as well as a temporal prediction model solely using passive observations. The resulting model can predict future mo- tions of an articulated object with high confidence because of the spatial and temporal structure. We demonstrate the effectiveness of the predictive model by incorporating it within a standard simultaneous localization and mapping (SLAM) pipeline for mapping and robot localization in previously unexplored dynamic environments. Our method is able to localize the robot and map a dynamic scene by explaining the observed motion in the world. We demonstrate the effectiveness of the proposed framework for both simulated and real-world dynamic environments.", "histories": [["v1", "Tue, 12 Apr 2016 19:00:48 GMT  (942kb,D)", "http://arxiv.org/abs/1604.03526v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["suren kumar", "vikas dhiman", "madan ravi ganesh", "jason j corso"], "accepted": false, "id": "1604.03526"}, "pdf": {"name": "1604.03526.pdf", "metadata": {"source": "CRF", "title": "Spatiotemporal Articulated Models for Dynamic SLAM", "authors": ["Suren Kumar", "Vikas Dhiman", "Madan Ravi Ganesh", "Jason J. Corso"], "emails": ["jjcorso}@umich.edu"], "sections": [{"heading": null, "text": "In fact, most of them will be able to move to another world, where they will be able to move to another world, where they will be able to move to another world, where they will be able to move to where they are."}, {"heading": "II. RELATED WORK", "text": "We review previous work on spatio-temporal estimation of articulated structures as well as on SLAM in dynamic environments."}, {"heading": "A. Articulation Structure", "text": "In fact, most people who are able to determine for themselves what they want and what they want to do are not willing to decide whether they want it or not. In fact, they do not want it."}, {"heading": "B. SLAM in Dynamic Environments", "text": "Previous literature on handling dynamic environments can be divided into two dominant approaches: i) recognize moving objects and ignore them [10], and ii) track moving objects as landmarks [2]. In the first approach, moving objects explicitly pursue by adding them to the estimated state [29]. Hahnel et al. [10] suggest tracking people in densely populated environments and removing the areas that correspond to humans to create static maps. Nieuwenhuisen et al. [18] suggest using a parameterized model of a door to locate doors in a moving environment, while estimating a static map. Recent work focuses on updating the map by removing dynamic parts of the scene without taking into account the nature of the movement in the environment."}, {"heading": "III. SPATIOTEMPORAL ARTICULATION MODELS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Articulation Models", "text": "We represent all articulated movements in the environment aszt = fM (C, q (t)), where the observed motion of an object (a trajectory in time t), M (Mj) rj = 1 is one of the r possible motion models, C is the configuration space (e.g. axis vector in the case of a door), q (t) represents the temporally varying motion variables (e.g. the length of the prism) associated with the motion model M. We assume that all observed movements are explained by one of the predefined r-possible motion models. In fact, there are only finite motion variables in the artificial environment, the angle that moves."}, {"heading": "B. Temporal Structure", "text": "The articulation estimation provides us with configuration parameters of articulated motion, but it is nevertheless necessary to estimate the evolution of motion variables over time (e.g. position of the object along an axis for a prismatic joint).The aim of our approach is to impose a structure on the evolution of articulated motion without using prior information specific to the actual articulated body. We draw our inspiration from the neuroscience literature, which states that humans create smooth trajectories to plan movements from one point to another in the environment [8].This uniformity assumption can be exploited by using motion models using a limited number of position derivatives. Suppose that q (t) is the articulated motion variable (e.g. extension of a prismatic joint, door angle along a hinges).The system model for a finite motion in a discrete time range with X (t) [q = 1, q (q) (1) (q)."}, {"heading": "IV. ARTICULATION MODEL ESTIMATION", "text": "We now consider the task of estimating the type of articulated model M-Mj-rj = 1 from different models. This does not automatically follow from the configuration and motion variables estimation. Consider, for example, the case of a point particle moving in 3D space: one can use a line, a circle or assume that it is static. One can potentially use Goodnessof-Fit measurements to estimate the corresponding model along with some heuristics. However, there are various limitations when comparing quality-of-fit measurements based on the number of free parameters in different models, noise in the data, overmatch and the number of data samples required. Instead of choosing a model in the first step, we use a filtering-based multiple model approach to correctly select the model for a given object. We assume that our target object / particle obeys one of the different motion models. In the current formulation, we proceed from a previous consistent preceding."}, {"heading": "V. SLAM FOR DYNAMIC ENVIRONMENT", "text": "To demonstrate the necessity of an articulation estimation with explicit time dependence, we propose an algorithm for performing SLAM in a dynamic scene. Figure 2 shows the graphical model of our general SLAM problem, where xt, ut, zt, mt, vt represents the robot state, input to the robot, observation by the robot, the state of the environment or the action of various actors in the surroundings. Please note that m is used in lowercase letters to refer to the map, while M is used to refer to the type of the motion model.Basic SLAM algorithms assume that the map mt \u2212 1 mt \u2261 m must be static and model the combination of robot state and map ({xt, m}) as the state of the estimation problem [5]. The associated estimation problem requires only a motion model P (xt | xt \u2212 1, ut) and an observation model P (zt | 1, \u2212 1) that the observation model implies that the observation model and the current observation state (P) are dynamic."}, {"heading": "A. Motion Propagation", "text": "The updating of motion propagation models the development of the state according to the motion model. To write the equation precisely, leave A = {Z0: t \u2212 1, U0: t, V0: t, x0, m0}, then P (xt, mt | A) = VP (xt, xt \u2212 1, mt, mt \u2212 1 | A) dxt \u2212 1dmt \u2212 1 = VP (xt | xt \u2212 1, ut) P (mt | mt \u2212 1, vt \u2212 1) P (xt \u2212 1, mt \u2212 1 | A) dxt \u2212 1dmt \u2212 1 (5) The independence relationship in deriving the time current in equivalent. 5 is based on the Bayesian network in Fig. 2, in which each node is independent of its non-descendants, since the parents of that node are named. Given the structure of the time update, we need two motion models, one for the robot, P (xt | xt \u2212 1, ut) and one for the world, P (mt \u2212 1, which can be observed \u2212 qm)."}, {"heading": "B. Measurement Update", "text": "To keep the equations short, let B = {Z0: t, U0: t, V0: t, x0, m0}, then P (xt, mt | B) = P (zt | xt, mt, A) P (xt, mt | A) P (zt | A) (6) Equation 6 together with Equation 5 define the complete recursive form of the SLAM algorithm for a dynamic environment. Focus of the current work is the representation of a non-static environment using articulation motion model to extend the standard SLAM algorithm with its static world assumption to a dynamic world."}, {"heading": "C. Dynamic World Representation", "text": "In this thesis, we demonstrate the SLAM algorithm for a feature-based map. The general framework is expandable to other types of mapping algorithms, such as dense maps. In feature-based mapping, it is assumed that the movement of each feature is independent, since the position of the feature is given in the previous time step. The state of the map, mt, is the collection of motion parameters of all the landmarks observed in the scene. The true motion model for each landmark in the scene is assumed to be one of the motion models M-Mj-rj = 1."}, {"heading": "VI. ARTICULATED EKF SLAM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Robot Motion Model", "text": "We consider a robot with the state xt = (x, y, \u03b8) T at present t, which moves at constant linear velocity vt and angular velocity \u03c9t. The state of the robot in the next time step can be represented asxt + 1 = x \u2212 vt\u03c9t sin \u03b8 + vt\u03c9t sin (\u03b8 + \u03c9t\u00e4t) y + vt\u03c9t cos \u03b8 \u2212 vt\u03c9t cos (\u03b8 + \u03c9k\u00e4t) \u03b8 + \u03c9k\u00e4t + N (0, Nt), (7), where \u03b4t is the width of the time step and Nt is the error covariance of noise (zero average Gaussian). Error covariance can be derived by spreading the noise through the robot motion model and projecting the input noise into the state space [28]. If the angular velocity model is laid out by the input space and the input noise [28]."}, {"heading": "B. Observation Model", "text": "The robot uses an ASUS Xtion camera that provides depth estimates for all characteristics. Leave the jest object at position mj = (mj, x, mj, y, mjz) T within the sensor field of the robot. Any observation can be written aszit = R T t mj, x \u2212 xmj, y \u2212 y mj, z + N (0, Qk) (11), where zit is the ith observation of the jest object at a time that is disturbed by the mean Gaussian noise with the covariance matrix Qk, and Rt is the rotation matrix corresponding to the rotation of the angle \u03b8k around the z-axis. It is assumed that the robot moves in the same plane and therefore its position in the z-axis is not part of the state. However, our model is easily extendable to general robot motion cases."}, {"heading": "C. Jacobian Computation", "text": "Extended Kalman Filtering (EKF) requires a linearization of the motion model of the robot to ensure that the state propagation maintains the Gaussianity of the state distribution. To propagate the state, we estimate the Jacobian of the state propagation model in relation to the state in time step. Jacobian state can be projected as Jxt + 1xt = 1 0 \u2212 vt\u03c9t cos + vt\u03c9t cos (\u03b8 + perspect\u00e4t) 0 1 \u2212 vt\u03c9t sin \u03b8 + vt\u03c9t sin (\u03b8 + perspect\u00e4t) 0 0 1 (12) Furthermore, the error in the control room is projected onto the state space for which we assign the Jacobian of the state propagation model in relation to the input. To support each observation zti, we calculate the Jacobian of the observation model in relation to the entire SLAM state, consisting of the robot state, as well as the motion parameters bian state J, which are associated with each observation step."}, {"heading": "VII. EXPERIMENTS", "text": "We analyze components of the proposed framework for estimating spatio-temporal articulation and also evaluate its predictive power to explore dynamic environments."}, {"heading": "A. Articulated Structure", "text": "In order to illustrate the effectiveness of the separation of motion parameters and structure parameters, we consider the structural estimation of a 2D boundary that is in rotational motion. In the current case, articulation structure refers to the center and radius of the boundary, while the motion parameter is the non-time angle. For the common estimation, we choose a frequently used motion model with constant velocity, zt = Xc + r [cos (\u03b80 + \u03b4T\u03c9), sin (\u03b80 + \u03b4T\u03c9)] T (14), where zt is the observed boundary position, \u03b80 is the starting angle, Xc is the center of the boundary and \u03c9 the constant angular velocity of the point. The estimation problem resulting from Eq.14 is non-linear in Equation 0 and \u03c9. On the other hand, the proposed articulated structural estimation approach solves a well-conditioned problem of estimating a circle of points lying on a circle."}, {"heading": "B. Temporal Order", "text": "After evaluating the structural parameters, different orders of time models can be estimated using the approach outlined in section III-B. To evaluate the performance of different motion continuity orders, we obtain a raw angular curve of a spring-loaded door and adapt time models of first and second order. We use the time model in an EKF filter system with direct acquisition of motion parameters as an observation model. This corresponds to the observation of the landmark mark after estimating the articulated structure using inverse kinematics. Figure 4 shows the motion parameters for different orders. It can be observed that an increase in order creates additional flexibility. For the rest of the experiments, we choose a first order continuity time model."}, {"heading": "C. Articulation Estimation", "text": "To test the articulation estimation system, we simulated an environment with a static, prismatic and pivot point each. We used at least 7 samples to estimate the configuration and initialize motion parameters. Figure 5 shows the results of the articulation estimation. With sufficient observation, all articulation models are correctly estimated, but static articulation takes the longest time to be correctly estimated, due to the difficulty of separating a static landmark from a revolving and prismatic landmark at zero speeds."}, {"heading": "D. Dynamic World SLAM", "text": "To test our dynamic SLAM system, we simulated a map with landmarks that are either static, prismatic or revolving. A robot with a limited field of view (90 degree cone of radius 4 meters) simulated readings from a depth sensor that was then used simultaneously to locate the robot and map the environment. We used a total of 42 landmarks in the area with 1 revolt, 1 prismatic and 40 static landmarks. Both the revolt and prismatic landmarks were correctly identified with a threshold of \u03c4 = 0.6. Figure 6 shows the robot location using the standard EKF slam algorithm, a dynamic variant of the standard EKF slot based on xt \u2212 1 + (xt \u2212 xt \u2212 2) and the articulated EKF (A-SLAM) algorithm that compares the standard EKF-SLAM algorithm and its dynamic variant with the proposed SLAM algorithm."}, {"heading": "VIII. CONCLUSION", "text": "We presented a principal approach to the estimation of articulated structures, which is indispensable for the representation of articulated movements in unexplored environments. Our spatio-temporal articulation models can be estimated by pursuing a single threshold for 1-DOF joints. The proposed framework also presents a passive approach to the modelling of temporal motion propagation. We demonstrated that our approach exceeds traditional SLAM algorithms by integrating articulated structural estimates."}, {"heading": "A. Articulated Motion Models", "text": "We briefly describe the articulated structure and motion parameters of the articulated joints modeled in this paper.1) Rotary joint: For a landmark that moves due to rotational motion, the articulation structure consists of the motion plane P, the location of the center and radius of the circle in that plane. The motion parameter used to characterize motion is simply the angle of the current point in relation to the horizontal. The motion equation can be asmj = (x0 + r cos\u03c6t) v1 + (y0 + r sin\u03c6t) v2 + P0, (15) where mj is the current location of j of the landmark. v1, v2 and P0 are two vertical vectors in the plane and a point on the plane P or a point on P. r is the radius of the circle and the angle in relation to the landmark."}], "references": [{"title": "Mobile robot localisation and mapping in extensive outdoor environments", "author": ["Tim Bailey"], "venue": "PhD thesis, Citeseer,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Simultaneous localization and mapping (slam): Part ii", "author": ["Tim Bailey", "Hugh Durrant-Whyte"], "venue": "IEEE RA Magazine,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Whole-body motion planning for manipulation of articulated objects", "author": ["Felix Burget", "Anja Hornung", "Maren Bennewitz"], "venue": "In ICRA. IEEE,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "A multibody factorization method for independently moving objects", "author": ["Jo\u00e3o Paulo Costeira", "Takeo Kanade"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "Simultaneous localization and mapping: part i", "author": ["Hugh Durrant-Whyte", "Tim Bailey"], "venue": "IEEE RA Magazine,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Dynamic obstacles detection and 3d map updating", "author": ["Federico Ferri", "Mario Gianni", "Matteo Menna", "Fiora Pirri"], "venue": "In IROS. IEEE,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Comparing artag and artoolkit plus fiducial marker systems", "author": ["Mark Fiala"], "venue": "In Haptic Audio Visual Environments and their Applications,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "The coordination of arm movements: an experimentally confirmed mathematical model", "author": ["Tamar Flash", "Neville Hogan"], "venue": "The journal of Neuroscience,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1985}, {"title": "A single planner for a composite task of approaching, opening and navigating through nonspring and spring-loaded doors", "author": ["Steven Gray", "Subhashini Chitta", "Vipin Kumar", "Maxim Likhachev"], "venue": "In ICRA. IEEE,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Mobile robot mapping in populated environments", "author": ["Dirk H\u00e4hnel", "Dirk Schulz", "Wolfram Burgard"], "venue": "Advanced Robotics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Active articulation model estimation through interactive perception", "author": ["Karol Hausman", "Scott Niekum", "Sarah Osentoski", "G Sukhatme"], "venue": "In ICRA,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Extracting planar kinematic models using interactive perception", "author": ["Dov Katz", "Oliver Brock"], "venue": "In Unifying Perspec-  tives in Computational and Robot Vision,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Interactive segmentation, tracking, and kinematic modeling of unknown 3d articulated objects", "author": ["Dov Katz", "Moslem Kazemi", "J. Andrew (Drew) Bagnell", "Anthony (Tony) Stentz"], "venue": "In ICRA,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Towards fully autonomous driving: Systems and algorithms", "author": ["Jesse Levinson", "Jake Askeland", "Jan Becker", "Jennifer Dolson", "David Held", "Soeren Kammel", "J Zico Kolter", "Dirk Langer", "Oliver Pink", "Vaughan Pratt"], "venue": "In Intelligent Vehicles Symposium (IV),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Online interactive perception of articulated objects with multi-level recursive estimation based on task-specific priors", "author": ["Roberto Martin Martin", "Oliver Brock"], "venue": "In IROS. IEEE,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Kinectfusion: Real-time dense surface mapping and tracking", "author": ["Richard A Newcombe", "Shahram Izadi", "Otmar Hilliges", "David Molyneaux", "David Kim", "Andrew J Davison", "Pushmeet Kohi", "Jamie Shotton", "Steve Hodges", "Andrew Fitzgibbon"], "venue": "In Mixed and augmented reality (ISMAR),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Dynamicfusion: Reconstruction and tracking of non-rigid scenes in real-time", "author": ["Richard A Newcombe", "Dieter Fox", "Steven M Seitz"], "venue": "In CVPR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Improving indoor navigation of autonomous robots by an explicit representation of doors", "author": ["Matthias Nieuwenhuisen", "J\u00f6rg St\u00fcckler", "Sven Behnke"], "venue": "In ICRA. IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Probabilistic mobile manipulation in dynamic environments, with application to opening doors", "author": ["Anna Petrovskaya", "Andrew Y Ng"], "venue": "In IJCAI,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Learning articulated motions from visual demonstration", "author": ["Sudeep Pillai", "Matthew Walter", "Seth Teller"], "venue": "In RSS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Dart: Dense articulated real-time tracking", "author": ["Tanner Schmidt", "Richard Newcombe", "Dieter Fox"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Evaluating goodness-of-fit in comparison of models to data. Psychologie der Kognition: Reden and vortr\u00e4ge anl\u00e4sslich der emeritierung von Werner Tack", "author": ["Christian D Schunn", "Dieter Wallach"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "On the representation and estimation of spatial uncertainty", "author": ["Randall C Smith", "Peter Cheeseman"], "venue": "IJRR,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1986}, {"title": "Mobile robot mapping and localization in non-static environments", "author": ["Cyrill Stachniss", "Wolfram Burgard"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1999}, {"title": "Learning kinematic models of articulated objects. In Approaches to Probabilistic Model Learning for Mobile Manipulation Robots, pages 65\u2013111", "author": ["J\u00fcrgen Sturm"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "A  probabilistic framework for learning kinematic models of articulated objects", "author": ["J\u00fcrgen Sturm", "Cyrill Stachniss", "Wolfram Burgard"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "A benchmark for the evaluation of rgb-d slam systems", "author": ["J\u00fcrgen Sturm", "Nikolas Engelhard", "Felix Endres", "Wolfram Burgard", "Daniel Cremers"], "venue": "In IROS. IEEE,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Online simultaneous localization and mapping with detection and tracking of moving objects: Theory and results from a ground vehicle in crowded urban areas", "author": ["Chieh-Chih Wang", "Charles Thorpe", "Sebastian Thrun"], "venue": "In ICRA. IEEE,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2003}, {"title": "Mobile robot simultaneous localization and mapping in dynamic environments", "author": ["Denis F Wolf", "Gaurav S Sukhatme"], "venue": "Autonomous Robots,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2005}, {"title": "Model selection and velocity estimation using novel priors for motion patterns", "author": ["Shuang Wu", "Hongjing Lu", "Alan L Yuille"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "Estimation with applications to tracking and navigation", "author": ["Bar-Shalom Yaakov", "XR Li", "Kirubarajan Thiagalingam"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2001}, {"title": "Automatic kinematic chain building from feature trajectories of articulated objects", "author": ["Jingyu Yan", "M. Pollefeys"], "venue": "In CVPR,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}], "referenceMentions": [{"referenceID": 22, "context": "Simultaneous localization and mapping (SLAM) has significantly improved over the last few decades, moving from sparse, 2D, slow feature-based maps [23] to dense, 3D, fast maps [16].", "startOffset": 147, "endOffset": 151}, {"referenceID": 15, "context": "Simultaneous localization and mapping (SLAM) has significantly improved over the last few decades, moving from sparse, 2D, slow feature-based maps [23] to dense, 3D, fast maps [16].", "startOffset": 176, "endOffset": 180}, {"referenceID": 15, "context": "For example, KinectFusion [16] impressively estimates a full 6 degrees-of-freedom (DOF) camera motion while building a dense, metrically accurate 3D map of an environment in real-time [16].", "startOffset": 26, "endOffset": 30}, {"referenceID": 15, "context": "For example, KinectFusion [16] impressively estimates a full 6 degrees-of-freedom (DOF) camera motion while building a dense, metrically accurate 3D map of an environment in real-time [16].", "startOffset": 184, "endOffset": 188}, {"referenceID": 13, "context": "The ability for robotic systems to deal with such motion is increasingly critical for the advancement of robotic systems used in autonomous driving [14], interaction with articulated objects [3] and tracking [21], among others.", "startOffset": 148, "endOffset": 152}, {"referenceID": 2, "context": "The ability for robotic systems to deal with such motion is increasingly critical for the advancement of robotic systems used in autonomous driving [14], interaction with articulated objects [3] and tracking [21], among others.", "startOffset": 191, "endOffset": 194}, {"referenceID": 20, "context": "The ability for robotic systems to deal with such motion is increasingly critical for the advancement of robotic systems used in autonomous driving [14], interaction with articulated objects [3] and tracking [21], among others.", "startOffset": 208, "endOffset": 212}, {"referenceID": 27, "context": "Early attempts at extending SLAM to dynamic environments either explicitly track the moving objects [29], remove the moving landmarks [10] from observations, or, alternatively, build two different maps for static and dynamic parts of the environment as Wolf et al.", "startOffset": 100, "endOffset": 104}, {"referenceID": 9, "context": "Early attempts at extending SLAM to dynamic environments either explicitly track the moving objects [29], remove the moving landmarks [10] from observations, or, alternatively, build two different maps for static and dynamic parts of the environment as Wolf et al.", "startOffset": 134, "endOffset": 138}, {"referenceID": 28, "context": "[30] do.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "This first part of our method is inspired by psychophysical experiments on human motion understanding that have demonstrated humans first distinguish between competing articulations (translation, rotation, and expansion) and then estimate the motion conditioned on the motion model [31].", "startOffset": 282, "endOffset": 286}, {"referenceID": 3, "context": "The early approaches to address this problem extended multibody structure from motion [4] ideas to understand articulation by clustering feature trajectories into individual rigid bodies [33].", "startOffset": 86, "endOffset": 89}, {"referenceID": 31, "context": "The early approaches to address this problem extended multibody structure from motion [4] ideas to understand articulation by clustering feature trajectories into individual rigid bodies [33].", "startOffset": 187, "endOffset": 191}, {"referenceID": 19, "context": "With the introduction of the commercial depth camera, the feature trajectories could be directly represented in 3D and thus avoiding the need to estimate shape [20, 13].", "startOffset": 160, "endOffset": 168}, {"referenceID": 12, "context": "With the introduction of the commercial depth camera, the feature trajectories could be directly represented in 3D and thus avoiding the need to estimate shape [20, 13].", "startOffset": 160, "endOffset": 168}, {"referenceID": 6, "context": "To avoid the problem of dense feature tracking, some methods achieve direct sensing of articulated motion via placement of markers, such as, ARToolKit [7], checker-board markers etc.", "startOffset": 151, "endOffset": 154}, {"referenceID": 8, "context": "[9, 26, 25, 11].", "startOffset": 0, "endOffset": 15}, {"referenceID": 25, "context": "[9, 26, 25, 11].", "startOffset": 0, "endOffset": 15}, {"referenceID": 24, "context": "[9, 26, 25, 11].", "startOffset": 0, "endOffset": 15}, {"referenceID": 10, "context": "[9, 26, 25, 11].", "startOffset": 0, "endOffset": 15}, {"referenceID": 11, "context": "Another way to get better estimation of articulated motion is via active interaction of a robot manipulating an articulated object [12, 11].", "startOffset": 131, "endOffset": 139}, {"referenceID": 10, "context": "Another way to get better estimation of articulated motion is via active interaction of a robot manipulating an articulated object [12, 11].", "startOffset": 131, "endOffset": 139}, {"referenceID": 25, "context": ", [26, 25].", "startOffset": 2, "endOffset": 10}, {"referenceID": 24, "context": ", [26, 25].", "startOffset": 2, "endOffset": 10}, {"referenceID": 14, "context": "[15] who propose a framework for online estimation; however, their method has no explicit probabilistic measure for model confidence to select an articulation model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Temporal modeling of arbitrary order allows us to: i) track new parts/objects that enter/exit the scene [15]; ii) model the entire scene and as a result explore dependencies between neighboring objects; and, iii) assimilate articulated object motion in SLAM [5].", "startOffset": 104, "endOffset": 108}, {"referenceID": 4, "context": "Temporal modeling of arbitrary order allows us to: i) track new parts/objects that enter/exit the scene [15]; ii) model the entire scene and as a result explore dependencies between neighboring objects; and, iii) assimilate articulated object motion in SLAM [5].", "startOffset": 258, "endOffset": 261}, {"referenceID": 25, "context": "Apart from the applications presented in this paper, temporal models associated with articulated structure will help in robot-environment interaction, specifically obtaining dynamic characteristics of the objects in the environment [26].", "startOffset": 232, "endOffset": 236}, {"referenceID": 9, "context": "Previous literature to handle dynamic environments can be divided into two predominant approaches: i) detect moving objects and ignore them [10], and ii) track moving objects as landmarks [2].", "startOffset": 140, "endOffset": 144}, {"referenceID": 1, "context": "Previous literature to handle dynamic environments can be divided into two predominant approaches: i) detect moving objects and ignore them [10], and ii) track moving objects as landmarks [2].", "startOffset": 188, "endOffset": 191}, {"referenceID": 0, "context": "In the first approach, using the fact that the conventional SLAM map is highly redundant, the moving landmarks can be removed from the map building process [1].", "startOffset": 156, "endOffset": 159}, {"referenceID": 27, "context": "In contrast, moving-object tracking-based approaches explicitly track moving objects by adding them to the estimation state [29].", "startOffset": 124, "endOffset": 128}, {"referenceID": 9, "context": "[10] propose tracking humans in dense populated environments and removing the areas corresponding to humans to build static maps.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] proposed using a parametrized model of a door to localize doors in a moving environment while simultaneously estimating a static map.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Recent work has focused on updating the map by removing dynamic parts of the scene without considering the nature of motion in the environment [6].", "startOffset": 143, "endOffset": 146}, {"referenceID": 23, "context": "Stachniss and Burgard [24] considered a graphic model similar to ours to update the map of a dynamic environment by using local patch maps and modeling transitions between patch maps.", "startOffset": 22, "endOffset": 26}, {"referenceID": 16, "context": "A recent work has extended dense tracking and mapping to dynamic scenes by estimating a dense warp field [17].", "startOffset": 105, "endOffset": 109}, {"referenceID": 18, "context": "[19] used a model of the door and a prior low-resolution static map of environment to track objects for manipulation tasks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "We take our inspiration from neuroscience literature which posits that humans produce smooth trajectories to plan movements from one point to another in environment [8].", "startOffset": 165, "endOffset": 168}, {"referenceID": 21, "context": "However, there are various limitations in comparing goodness-of-fit measures related to the number of free parameters in different models, noise in the data, overfitting and the number of data samples required [22].", "startOffset": 210, "endOffset": 214}, {"referenceID": 30, "context": "Motion model probabilities are updated as more and more observations are received using laws of total probability [32].", "startOffset": 114, "endOffset": 118}, {"referenceID": 30, "context": "This probability for an Extended Kalman Filter (EKF) based filtering algorithm is the probability of observation residual as sampled from a normal distribution distributed with zero mean and innovation covariance [32].", "startOffset": 213, "endOffset": 217}, {"referenceID": 4, "context": "Basic SLAM algorithms assume the map mt\u22121 \u2261 mt \u2261 m to be static and model the combination of robot state and map ({xt,m}) as the state of the estimation problem [5].", "startOffset": 161, "endOffset": 164}, {"referenceID": 30, "context": "The goal of the estimation process is to produce unbiased and consistent estimates (the expectation of mean squared errors should match the filter-calculated covariance) [32].", "startOffset": 170, "endOffset": 174}, {"referenceID": 26, "context": "As a result, we only compare the resulting localization estimates of the robot using community accepted error metrics [27].", "startOffset": 118, "endOffset": 122}, {"referenceID": 19, "context": "[20].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "mj = P0 + [1, 1, 1] T lt, (17)", "startOffset": 10, "endOffset": 19}, {"referenceID": 0, "context": "mj = P0 + [1, 1, 1] T lt, (17)", "startOffset": 10, "endOffset": 19}, {"referenceID": 0, "context": "mj = P0 + [1, 1, 1] T lt, (17)", "startOffset": 10, "endOffset": 19}], "year": 2010, "abstractText": "We propose an online spatiotemporal articulation model estimation framework that estimates both articulated structure as well as a temporal prediction model solely using passive observations. The resulting model can predict future motions of an articulated object with high confidence because of the spatial and temporal structure. We demonstrate the effectiveness of the predictive model by incorporating it within a standard simultaneous localization and mapping (SLAM) pipeline for mapping and robot localization in previously unexplored dynamic environments. Our method is able to localize the robot and map a dynamic scene by explaining the observed motion in the world. We demonstrate the effectiveness of the proposed framework for both simulated and real-world dynamic environments.", "creator": "LaTeX with hyperref package"}}}