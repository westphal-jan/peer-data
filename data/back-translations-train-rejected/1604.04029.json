{"id": "1604.04029", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Apr-2016", "title": "Multi-Source Multi-View Clustering via Discrepancy Penalty", "abstract": "With the advance of technology, entities can be observed in multiple views. Multiple views containing different types of features can be used for clustering. Although multi-view clustering has been successfully applied in many applications, the previous methods usually assume the complete instance mapping between different views. In many real-world applications, information can be gathered from multiple sources, while each source can contain multiple views, which are more cohesive for learning. The views under the same source are usually fully mapped, but they can be very heterogeneous. Moreover, the mappings between different sources are usually incomplete and partially observed, which makes it more difficult to integrate all the views across different sources. In this paper, we propose MMC (Multi-source Multi-view Clustering), which is a framework based on collective spectral clustering with a discrepancy penalty across sources, to tackle these challenges. MMC has several advantages compared with other existing methods. First, MMC can deal with incomplete mapping between sources. Second, it considers the disagreements between sources while treating views in the same source as a cohesive set. Third, MMC also tries to infer the instance similarities across sources to enhance the clustering performance. Extensive experiments conducted on real-world data demonstrate the effectiveness of the proposed approach.", "histories": [["v1", "Thu, 14 Apr 2016 04:02:47 GMT  (1051kb,D)", "https://arxiv.org/abs/1604.04029v1", null], ["v2", "Tue, 19 Apr 2016 03:00:30 GMT  (1052kb,D)", "http://arxiv.org/abs/1604.04029v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["weixiang shao", "jiawei zhang", "lifang he", "philip s yu"], "accepted": false, "id": "1604.04029"}, "pdf": {"name": "1604.04029.pdf", "metadata": {"source": "CRF", "title": "Multi-Source Multi-View Clustering via Discrepancy Penalty", "authors": ["Weixiang Shao", "Jiawei Zhang", "Lifang He", "Philip S. Yu"], "emails": ["wshao4@uic.edu,", "jzhan9@uic.edu,", "psyu@uic.edu", "lifanghescut@gmail.com"], "sections": [{"heading": null, "text": "In fact, it is such that most of us are able to move into another world, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in fact, in which they, in fact, in which they are able to change, in which they are able to change, in which they are able to change the world, in which they are able to change, in which they are able to change, in which they"}, {"heading": "II. PROBLEM FORMULATION", "text": "In this section, we will first define the problem of multi-source multi-view clustering and then proceed from the single-source problem to develop the objective function for multi-source multi-view clustering."}, {"heading": "A. Problem Definition", "text": "Before we define the problem of multi-source multi-view clustering, we summarize the notations in Table I. S = {Sk} Kk = 1 represents the set of available K sources. For each Sk we have Sk = {Xki} vk i = 1, where X k i denotes the i-th view in source k and vk denotes the number of views in source k. We assume that source k (1 \u2264 k \u2264 K) contains nk instances. Let M = {M (i, j)} 1 \u2264 i, j \u2264 K be the known instance mappings between sources, where M (i, j) and Rni \u00b7 nj + denotes the instance mappings between sources i and j and its element is defined by M (i, j) a, b = 1 instance a in source i is mapped to instance b in source j. 0. (1) Our goal is to group the instances for each source cluster M. while we consider the others through cross-mapping in the source."}, {"heading": "B. Single Source Multiple Views Clustering", "text": "In order to take into account the differences between the two sources, we only have to solve the following optimization problem for the diagonal matrix with the diagonal elements of the series of Kki. In order to carry out a spectral clustering between the single views in the source k, we must carry out the spectral clustering in the source k. (Uki) TLki U k i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i"}, {"heading": "C. Multiple Sources Multiple Views Clustering", "text": "In this section, we derive the objective function for the multi-source clustering function. To estimate the cohesiveness of views within a source, we should capture the consensus latent feature matrix for each source and punish only the discrepancy between these consensus latent feature matrices. Similar to the discrepancy function between views within a source, the streamlining function between sources should take into account the discrepancy between the consensus latent feature matrices. As the mappings between sources are incomplete and partially known, we cannot directly apply the same streamlining function as with the multiple view clustering objective function. However, by using the mapping matrices that project the learned latent feature matrix matrix from one source to another source, M (i, j) T U i point as a projection of the instance in the multi-source clustering function matrix."}, {"heading": "III. OPTIMIZATION AND MMC FRAMEWORK", "text": "The proposed MMC framework simultaneously optimizes the latent matrices in multiple sources. [13] Instead, we assume that the principle of cross-border instance similarity contributes to improving clustering performance. To optimize the objective function in Eq (10), we use a alternating scheme, that is, we optimize the objective function in relation to a variable, while optimizing the objective function using two stages. First, maximizing O over Uk. Second, maximizing equity over Uk. We repeat these two steps until we can learn iteratively how to optimize the latent properties for each source. However, if only a small fraction of the instances is mapped, clustering performance is affected by the incompleteness of the instance."}, {"heading": "E. MMC framework", "text": "The algorithm for the MMC framework is called algorithm 1. We first calculate the kernel matrices and the corresponding normalized graph-laplak matrices for each view. In all experiments throughout the paper, we use the Gaussian kernel to calculate the similarities, unless otherwise specified. The default deviation of the kernel corresponds to the median of the paired euclidean distances between the data points. We then initialize the latent feature matrices {Uki}, {Uk} and the instance mappings M (i, j). We then iteratively update the Uki s, Uk and M (i, j) s until they all converge. Algorithm 1 MMC FrameworkInput: Data matrices for each view from each source {Xki}. Instance mappraisals between the sources {M (i, j) and M (i, j) s until they all converge."}, {"heading": "IV. EXPERIMENTS AND RESULTS", "text": "In this section we compare the MMC framework with a number of baselines on three real datasets."}, {"heading": "A. Comparison Methods", "text": "We compare the proposed MMC method with several non-negative matrix methods. Since no previous methods can be applied directly to the multi-source multiview situation to compare with the previous methods, we make some changes. The details of the comparison methods are as follows: \u2022 MMC: MMC is the clustering framework proposed in this paper that applies collective spectral clustering with discrepancy penalty across the sources. The parameter \u03b1 is set to 0.1 and \u03b2 is set to 1 for all views and sources in the entire experiment. \u2022 Concat: Feature concatenation is a way to integrate all views. We link views within each source so that each source is a concatenated view. Since the distances between the sources are not fully aligned, we expand each source by adding pseudo-distances (average features). So we then apply PCA and k means to get the clustering results. Sym \u2022 NetF-Symmric-MF results are not negative."}, {"heading": "B. Dataset", "text": "In this paper, three sets of real data sets are used to evaluate the proposed MMC method. Important statistics of them are summarized in Table II. \u2022 Dutch-USPS This data set comes from two sources, UCIHandwritten Dutch digit numbers and USPS digit data. The first source, Dutch1, consists of 2000 examples of handwritten numbers' 0- '9' (200 examples per class) extracted from a collection of Dutch utility maps. All examples were digitized in binary images. Each example is represented in the following six views: (1) 76 Fourier coefficients of character shapes, (2) 216 profile correlations, (3) 64 Karhunen-Love coefficients, (4) 240 pixel averages in 2 x 3 windows, (5) 47 Zernike moments, and (6) 6 morphological characteristics. The second source, USPS2, consists of digital images of the size 16 x 16 for numbers \"0\" - \"we select the corresponding examples from 2000."}, {"heading": "C. Results", "text": "The results are obtained using 60% known mappings. We report the NMI (Normalized Mutual Information) for each source in Table III.From Table III, we can find that the proposed MMC framework outperforms all other comparative methods for both Dutch-USPS and English-Translation by at least 10%. In the Dutch-USPS data, although CoReg-M and CGC perform better than all other methods for Dutch-USPS (less than 4%) than all other methods for USPS, we can also find that MultiNMF-M and CoReg-M perform better for MultiNMF-S and CoReg-S for Dutch-USPS than other methods for USPS. However, the performance of the multi-source methods is worse than the single-source method for English-Translation. This suggests that combining multiple sources for Reuters-Mappings can even impair performance."}, {"heading": "D. Parameter Study", "text": "In the proposed MMC method there are two sets of parameters: {\u03b1ki}, the relative meaning of the view i in source k, and {\u03b2 (i, j)}, the weight of the discrepancy penalty between source i and j. Here we examine the influence of the visible weight and the discrepancy penalty weights. We first fix {\u03b2 (i, j)} to 1 and execute the proposed MMC method with various {\u03b1ki} values (10 \u2212 3 to 103). Then we fix {\u03b1ki} to 0.1 and execute the proposed MMC method with various {\u03b2 (i, j)} values (10 \u2212 3 to 103). Due to the spatial limitation, we report the results on Dutch USPS data only with 60% known mapping in Fig. 4 and Fig. 5. Fig. 4 shows that the performance is stable when the performance is less than 100, and the best performance is achieved when the performance is about 0.1."}, {"heading": "V. DISCUSSION", "text": "This year, compared to the previous year, the number of job-related dismissals is many times higher than the number of job-related dismissals, so that the number of job-related dismissals is many times higher than the number of job-related dismissals."}, {"heading": "VI. RELATED WORKS", "text": "Multiview learning [3], [4], [18], it is proposed to learn from instances having multiple representations in different attribute space. Example: [1] developed and stud-TABLE VII: NMI for English translation data with different percentages of known mapping method 30% known 40% known 50% known 60% known 80% known 90% known 100% known Concat (E) 0.1144 0.1334 0.1617 0.2037 0.2488 0.2495 0.2498Sym-NMF (E) 0.2783 0.2783 0.2783 0.2783 0.2783 MultiNMF-S (E) 0.3413 0.3413 0.3413 0.3413 0.3413 0.3413 0.3481 0.3481 MultiNMF-M (E) 0.3253 0.32881 0.32574 0.32574 0.374"}, {"heading": "VII. CONCLUSION", "text": "The proposed MMC framework treats views in the same source as a coherent clustering group by learning latent attribute matrices from views within a source. It also includes multiple sources by using cross-source discrepancy penalties to increase cluster performance. MMC also uses the learned latent features to infer cross-source mapping of unknown similarities, which in turn will help improve cluster performance. Extensive experiments conducted on three sets of real datasets demonstrate the effectiveness of MMC comparison with other state-of-the-art methods."}], "references": [{"title": "Multi-view clustering", "author": ["S. Bickel", "T. Scheffer"], "venue": "ICDM, 2004.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Multi-view clustering via canonical correlation analysis", "author": ["K. Chaudhuri", "S.M. Kakade", "K. Livescu", "K. Sridharan"], "venue": "ICML, 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Co-regularized multi-view spectral clustering", "author": ["A. Kumar", "P. Rai", "H.D. III"], "venue": "NIPS, 2011.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "A general model for multiple view unsupervised learning.", "author": ["B. Long", "P.S. Yu", "Z.M. Zhang"], "venue": "in SDM. SIAM,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "A co-training approach for multi-view spectral clustering", "author": ["A. Kumar", "H.D. III"], "venue": "ICML, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Clustering on multiple incomplete datasets via collective kernel learning", "author": ["W. Shao", "X. Shi", "P.S. Yu"], "venue": "ICDM, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Partial multi-view clustering", "author": ["S. Li", "Y. Jiang", "Z. Zhou"], "venue": "AAAI, 2014, pp. 1968\u20131974.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Clustering on multi-source incomplete data via tensor modeling and factorization", "author": ["W. Shao", "L. He", "P.S. Yu"], "venue": "PAKDD, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "A tutorial on spectral clustering", "author": ["U. Luxburg"], "venue": "Statistics and Computing, vol. 17, no. 4, pp. 395\u2013416, Dec. 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "On spectral clustering: Analysis and an algorithm", "author": ["A.Y. Ng", "M.I. Jordan", "Y. Weiss"], "venue": "NIPS, 2002, pp. 849\u2013856.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Inferring anchor links across multiple heterogeneous social networks", "author": ["X. Kong", "J. Zhang", "P.S. Yu"], "venue": "CIKM, 2013, pp. 179\u2013188.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Meta-path based multi-network collective link prediction", "author": ["J. Zhang", "P.S. Yu", "Z.-H. Zhou"], "venue": "KDD, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Symmetric nonnegative matrix factorization for graph clustering.", "author": ["D. Kuang", "H. Park", "C.H.Q. Ding"], "venue": "in SDM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Multi-view clustering via joint nonnegative matrix factorization", "author": ["J. Liu", "C. Wang", "J. Gao", "J. Han"], "venue": "SDM, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning from multiple partially observed views - an application to multilingual text categorization", "author": ["M.R. Amini", "N. Usunier", "C. Goutte"], "venue": "NIPS, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["A. Blum", "T. Mitchell"], "venue": "COLT, 1998.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Analyzing the effectiveness and applicability of co-training", "author": ["K. Nigam", "R. Ghani"], "venue": "CIKM, 2000.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2000}, {"title": "Multiview clustering with incomplete views", "author": ["A. Trivedi", "P. Rai", "H. Daum\u00e9 III", "S. DuVall"], "venue": "NIPS Workshop, 2010.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Multiple incomplete views clustering via weighted nonnegative matrix factorization with L2,1 regularization", "author": ["W. Shao", "L. He", "P.S. Yu"], "venue": "ECML PKDD, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Consensus clustering: A resampling-based method for class discovery and visualization of gene expression microarray data", "author": ["S. Monti", "P. Tamayo", "J. Mesirov", "T. Golub"], "venue": "Mach. Learn., 2003.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "Weighted Consensus Clustering", "author": ["T. Li", "C. Ding"], "venue": "SDM, 2008.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Consensus Clustering Algorithms: Comparison and Refinement", "author": ["A. Goder", "V. Filkov"], "venue": "9th Workshop on Algorithm Engineering and Experiments, 2008.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Bayesian consensus clustering.", "author": ["E.F. Lock", "D.B. Dunson"], "venue": "Bioinformatics, vol. 29,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Multiple view clustering [1]\u2013[3] aims to enhance clustering performance by integrating different views.", "startOffset": 25, "endOffset": 28}, {"referenceID": 2, "context": "Multiple view clustering [1]\u2013[3] aims to enhance clustering performance by integrating different views.", "startOffset": 29, "endOffset": 32}, {"referenceID": 0, "context": "Multi-view clustering [1], [4], [5] aims to utilize the multiple representations of instances in different features spaces to get better clustering performance.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "Multi-view clustering [1], [4], [5] aims to utilize the multiple representations of instances in different features spaces to get better clustering performance.", "startOffset": 27, "endOffset": 30}, {"referenceID": 4, "context": "Multi-view clustering [1], [4], [5] aims to utilize the multiple representations of instances in different features spaces to get better clustering performance.", "startOffset": 32, "endOffset": 35}, {"referenceID": 5, "context": "Although there are some previous studies on dealing with multiple incomplete view clustering [6]\u2013[9], none of them are suitable for multi-source multi-view scenario.", "startOffset": 93, "endOffset": 96}, {"referenceID": 7, "context": "Although there are some previous studies on dealing with multiple incomplete view clustering [6]\u2013[9], none of them are suitable for multi-source multi-view scenario.", "startOffset": 97, "endOffset": 100}, {"referenceID": 2, "context": "To perform spectral clustering for a single view i in source k, as shown in [3], [10], [11], we only need to solve the following optimization problem for the normalized graph Laplacian Li :", "startOffset": 76, "endOffset": 79}, {"referenceID": 8, "context": "To perform spectral clustering for a single view i in source k, as shown in [3], [10], [11], we only need to solve the following optimization problem for the normalized graph Laplacian Li :", "startOffset": 81, "endOffset": 85}, {"referenceID": 9, "context": "To perform spectral clustering for a single view i in source k, as shown in [3], [10], [11], we only need to solve the following optimization problem for the normalized graph Laplacian Li :", "startOffset": 87, "endOffset": 91}, {"referenceID": 2, "context": "Similar to the regularization in [3], we define the discrepancy/dissimilarity between two latent feature matrices as:", "startOffset": 33, "endOffset": 36}, {"referenceID": 10, "context": "instance mapping is really challenging and usually additional information is required to infer such anchor link [12], [13].", "startOffset": 112, "endOffset": 116}, {"referenceID": 11, "context": "instance mapping is really challenging and usually additional information is required to infer such anchor link [12], [13].", "startOffset": 118, "endOffset": 122}, {"referenceID": 9, "context": "According to [11], the solution U i is given by the top-ck eigenvectors of this modified Laplacian.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "\u2022 Sym-NMF Symmetric non-negative matrix factorization is proposed in [14] as a general framework for clustering.", "startOffset": 69, "endOffset": 73}, {"referenceID": 13, "context": "\u2022 MultiNMF: MultiNMF is one of the state-of-art multiview clustering methods based on joint nonnegative matrix factorization [15].", "startOffset": 125, "endOffset": 129}, {"referenceID": 2, "context": "\u2022 CoReg: CoReg is the centroid based multi-view clustering method proposed in [3].", "startOffset": 78, "endOffset": 81}, {"referenceID": 14, "context": "\u2022 English-Translations: This data contains two sources, the original Reuters news documents written in English, and the machine translations in other four languages (French, German, Spanish and Italian) in 6 topics [16].", "startOffset": 215, "endOffset": 219}, {"referenceID": 2, "context": "Multi-view learning [3], [4], [17], [18], is proposed to learn from instances which have multiple representations in different feature space.", "startOffset": 20, "endOffset": 23}, {"referenceID": 3, "context": "Multi-view learning [3], [4], [17], [18], is proposed to learn from instances which have multiple representations in different feature space.", "startOffset": 25, "endOffset": 28}, {"referenceID": 15, "context": "Multi-view learning [3], [4], [17], [18], is proposed to learn from instances which have multiple representations in different feature space.", "startOffset": 30, "endOffset": 34}, {"referenceID": 16, "context": "Multi-view learning [3], [4], [17], [18], is proposed to learn from instances which have multiple representations in different feature space.", "startOffset": 36, "endOffset": 40}, {"referenceID": 0, "context": "For example, [1] developed and stud-", "startOffset": 13, "endOffset": 16}, {"referenceID": 2, "context": "[3], [5] are among the first works proposed to solve clustering problem via spectral projection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[3], [5] are among the first works proposed to solve clustering problem via spectral projection.", "startOffset": 5, "endOffset": 8}, {"referenceID": 13, "context": "[15] proposed to solve multi-view clustering by joint non-negative matrix factorization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6], [7], [19], [20] are among the first works to solve the multi-view clustering with partial/incomplete views.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[6], [7], [19], [20] are among the first works to solve the multi-view clustering with partial/incomplete views.", "startOffset": 5, "endOffset": 8}, {"referenceID": 17, "context": "[6], [7], [19], [20] are among the first works to solve the multi-view clustering with partial/incomplete views.", "startOffset": 10, "endOffset": 14}, {"referenceID": 18, "context": "[6], [7], [19], [20] are among the first works to solve the multi-view clustering with partial/incomplete views.", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "Consensus clustering [21], [22] is also related to the proposed MMC framework.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "Consensus clustering [21], [22] is also related to the proposed MMC framework.", "startOffset": 27, "endOffset": 31}, {"referenceID": 21, "context": "[23] gives a report about consensus clustering algorithms comparison and refinement.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] proposes a bayesian consensus clustering method.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "With the advance of technology, entities can be observed in multiple views. Multiple views containing different types of features can be used for clustering. Although multi-view clustering has been successfully applied in many applications, the previous methods usually assume the complete instance mapping between different views. In many real-world applications, information can be gathered from multiple sources, while each source can contain multiple views, which are more cohesive for learning. The views under the same source are usually fully mapped, but they can be very heterogeneous. Moreover, the mappings between different sources are usually incomplete and partially observed, which makes it more difficult to integrate all the views across different sources. In this paper, we propose MMC (Multisource Multi-view Clustering), which is a framework based on collective spectral clustering with a discrepancy penalty across sources, to tackle these challenges. MMC has several advantages compared with other existing methods. First, MMC can deal with incomplete mapping between sources. Second, it considers the disagreements between sources while treating views in the same source as a cohesive set. Third, MMC also tries to infer the instance similarities across sources to enhance the clustering performance. Extensive experiments conducted on real-world data demonstrate the effectiveness of the proposed approach.", "creator": "LaTeX with hyperref package"}}}