{"id": "1604.04315", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Apr-2016", "title": "Moving Beyond the Turing Test with the Allen AI Science Challenge", "abstract": "Given recent successes in AI (e.g., AlphaGo's victory against Lee Sedol in the game of GO), it's become increasingly important to assess: how close are AI systems to human-level intelligence? This paper describes the Allen AI Science Challenge---an approach towards that goal which led to a unique Kaggle Competition, its results, the lessons learned, and our next steps.", "histories": [["v1", "Thu, 14 Apr 2016 22:43:30 GMT  (78kb)", "http://arxiv.org/abs/1604.04315v1", "6 pages"], ["v2", "Tue, 17 May 2016 18:47:00 GMT  (79kb)", "http://arxiv.org/abs/1604.04315v2", "6 pages"], ["v3", "Wed, 22 Feb 2017 20:02:46 GMT  (233kb)", "http://arxiv.org/abs/1604.04315v3", "7 pages"]], "COMMENTS": "6 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["carissa schoenick", "peter clark", "oyvind tafjord", "peter turney", "oren etzioni"], "accepted": false, "id": "1604.04315"}, "pdf": {"name": "1604.04315.pdf", "metadata": {"source": "CRF", "title": "Moving Beyond the Turing Test with the Allen AI Science Challenge", "authors": ["Carissa Schoenick", "Peter Clark", "Oyvind Tafjord", "Peter Turney", "Oren Etzioni"], "emails": [], "sections": [{"heading": "Moving Beyond the Turing Test with the Allen AI Science Challenge", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Carissa Schoenick, Peter Clark, Oyvind Tafjord, Peter Turney, Oren Etzioni", "text": "Given recent successes in AI (e.g. AlphaGo's victory over Lee Sedol in the game GO), it is increasingly important to assess how close AI systems are to human intelligence."}], "references": [{"title": "Software tricks people into thinking it is human", "author": ["J. Aron"], "venue": "New Scientist (Issue", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "The Plan to Replace the Turing Test with a \u2018Turing Olympics", "author": ["V. Turk"], "venue": "Motherboard", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "My Computer is an Honor Student - But how Intelligent is it? Standardized Tests as a Measure of AI", "author": ["P. Clark", "O. Etzioni"], "venue": "In AI Magazine", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Message Understanding Conference-6: A Brief History", "author": ["R. Grishman", "B. Sundheim"], "venue": "In COLING (Vol", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "Eds)Proc. 24th Text REtrieval Conference (TREC 2015), Publication SP 500- 319, NIST (http://trec.nist.gov", "author": ["E. Voorhees", "A. Ellis"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Information Extraction over Structured Data: Question Answering with Freebase", "author": ["X. Yao", "B. Van Durme"], "venue": "(pp. 956-966),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Semantic Parsing on Freebase from Question-Answer Pairs", "author": ["J. Berant", "A. Chou", "R. Frostig", "P. Liang"], "venue": "In EMNLP (Vol. 2,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Open question answering over curated and extracted knowledge bases", "author": ["A. Fader", "L. Zettlemoyer", "O. Etzioni"], "venue": "Proc 20th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining (pp. 1156-1165)", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Making the World's Data Computable", "author": ["S. Wolfram"], "venue": "Proc. Wolfram Data Summit,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "True Knowledge: The Natural Language Question Answering Wikipedia for Facts", "author": ["J. Simmons"], "venue": "Semantic Focus,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Natural Language Annotations for Question Answering", "author": ["B. Katz", "G. Borchardt", "S. Felshin"], "venue": "Proc 19th Int FLAIRS Conference (FLAIRS", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Current systems have revealed just how gameable this assessment of AI can be, as some chatbots have improved in recent years to the point where one could argue a few of them could pass the Turing test [1][2].", "startOffset": 204, "endOffset": 207}, {"referenceID": 1, "context": "So if the Turing test is readily subverted, and the game-playing approach is limited, what other, richer ways can we use to successfully measure the progress of AI technology as it continues to expand and evolve? Rather than a single test, cognitive scientist Gary Marcus of NYU and others recently proposed the notion of series of tests, a Turing Olympics of sorts, that could assess the full gamut of AI from robotics to NLP [3][4].", "startOffset": 430, "endOffset": 433}, {"referenceID": 2, "context": "Among the assessments proposed, Peter Clark and Oren Etzioni from the Allen Institute of Artificial Intelligence (AI2) are advocating a more multifaceted, meaningful approach: give an AI system a standardized test, such as a science exam [5].", "startOffset": 238, "endOffset": 241}, {"referenceID": 3, "context": "Question-answering systems developed for the MUC (message understanding) conferences [6] and TREC (text retrieval) conferences [7] focused on retrieving answers from text, the former from newswire articles and the latter from various large corpora such as the Web, microblogs, and clinical data.", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "Question-answering systems developed for the MUC (message understanding) conferences [6] and TREC (text retrieval) conferences [7] focused on retrieving answers from text, the former from newswire articles and the latter from various large corpora such as the Web, microblogs, and clinical data.", "startOffset": 127, "endOffset": 130}, {"referenceID": 5, "context": ", \"In which city was Bill Clinton born?\" from FreeBase [8,9,10].", "startOffset": 55, "endOffset": 63}, {"referenceID": 6, "context": ", \"In which city was Bill Clinton born?\" from FreeBase [8,9,10].", "startOffset": 55, "endOffset": 63}, {"referenceID": 7, "context": ", \"In which city was Bill Clinton born?\" from FreeBase [8,9,10].", "startOffset": 55, "endOffset": 63}, {"referenceID": 8, "context": "There are a few systems that attempt some form of reasoning: Wolfram Alpha [11] answers mathematical questions, providing they are stated either equationally or with relatively simple English; Evi [12] is able to combine facts together to answer simple questions (e.", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "There are a few systems that attempt some form of reasoning: Wolfram Alpha [11] answers mathematical questions, providing they are stated either equationally or with relatively simple English; Evi [12] is able to combine facts together to answer simple questions (e.", "startOffset": 197, "endOffset": 201}, {"referenceID": 10, "context": ", Who is older, Barack or Michelle Obama?); and START [13] will similarly answer simple inference questions using Web-based databases (e.", "startOffset": 54, "endOffset": 58}], "year": 2016, "abstractText": "The famous Turing test developed by Alan Turing in 1950 proposes that if a system can exhibit question-answering behavior that is indistinguishable from that of a human during a conversation, that system could be considered intelligent. As the field of artificial intelligence grows, this approach to evaluating a system has become less and less appropriate or meaningful. Current systems have revealed just how gameable this assessment of AI can be, as some chatbots have improved in recent years to the point where one could argue a few of them could pass the Turing test [1][2]. As The New York Times\u2019 John Markoff puts it, \u201cthe Turing test is a test of human gullibility.\u201d", "creator": "Word"}}}