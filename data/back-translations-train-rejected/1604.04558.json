{"id": "1604.04558", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2016", "title": "Accessing accurate documents by mining auxiliary document information", "abstract": "Earlier techniques of text mining included algorithms like k-means, Naive Bayes, SVM which classify and cluster the text document for mining relevant information about the documents. The need for improving the mining techniques has us searching for techniques using the available algorithms. This paper proposes one technique which uses the auxiliary information that is present inside the text documents to improve the mining. This auxiliary information can be a description to the content. This information can be either useful or completely useless for mining. The user should assess the worth of the auxiliary information before considering this technique for text mining. In this paper, a combination of classical clustering algorithms is used to mine the datasets. The algorithm runs in two stages which carry out mining at different levels of abstraction. The clustered documents would then be classified based on the necessary groups. The proposed technique is aimed at improved results of document clustering.", "histories": [["v1", "Fri, 15 Apr 2016 16:27:38 GMT  (891kb,D)", "http://arxiv.org/abs/1604.04558v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.LG", "authors": ["jinju joby", "jyothi korra"], "accepted": false, "id": "1604.04558"}, "pdf": {"name": "1604.04558.pdf", "metadata": {"source": "CRF", "title": "Accessing accurate documents by mining auxiliary document information", "authors": ["Jinju Joby"], "emails": ["jyothi.korra@christuniversity.in"], "sections": [{"heading": "1 Introduction", "text": "Researchers have used basic mining algorithms and techniques such as K-tools, agglomerative hierarchical clustering, and the like to find the best text-mining techniques. [2] The combinations of techniques have also set a pretty impressive precedent in data mining, such as split-K-tools [1]. The commonly used cluster techniques such as Scatter / Collect have been useful in understanding how cluster techniques operate in a real-life scenario of the web world [2]. The available tools for text mining are helpful as most of them are open source and have a wide range of options to work with. Some of the commercially available tools such as SPSS are common at Data Miners [3]. Apart from all these advances, research is on an ever-growing thirst for better ways to overcome the data-mining difficulties."}, {"heading": "2 Related Work", "text": "That is why it has come to this, \"he told the German Press Agency."}, {"heading": "3 DOCUMENT CLUSTERING WITH AUXILARY INFORMATION", "text": "The documents used in the clustering process should contain all the auxiliary information; the second part of the proposed method, as described in Section IV, would be used on the basis of the auxiliary information; the first stage of clustering requires the documents to be clustered first using K-Means algorithms; the similarity between the documents is determined by cosinal similarity; the cluster centering is updated based on the similarity values; and now, in order to improve the clustering process, we need to remove the noisy attributes that are useless for clustering; this can be done by calculating the Gini index of attributes in the documents; the set of useful attributes would be used for clustering to refine the clustering process; now the attributes and the document clusters have been selected; now the proposed model would have to combine both attributes to find the final clusters of attributes in the documents."}, {"heading": "4 PROPOSED METHOD", "text": "In this section, we discuss the proposed method for designing a cluster and classification technology for quickly retrieving documents from a large data set. The entire process has been broken down to better understand the approach."}, {"heading": "4.1 PreprocessingDocuments", "text": "Documents collected from the World Wide Web or repositories need not always have the same formatting, and even if the auxiliary information is known but not incorporated into the document itself, this should be done. Auxiliary features should be distinguished from the rest of the content by appending a special character before it, such as a $or #. Thus, the algorithm can distinguish between the actual content of the document and the auxiliary information, which is important because different parts of the designed algorithm are used separately for the content and auxiliary information. It is also well studied that information on web pages is viewed in the order of the word position [15]."}, {"heading": "4.2 Process Flow", "text": "The process of clustering extends over the years to the present day, in which most people are able to enter the world in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which"}, {"heading": "4.3 Document Classification", "text": "In order to classify the clusters, we need to know the type of documents that are present in each cluster, and the accuracy of the classification is checked using a crowdsourcing approach [16]. Documents that are bundled into a single cluster must contain the maximum number of common attributes, because the clustering was only carried out on the basis of the most relevant attributes. Thus, if the comparison is made between all the attributes in the cluster, the type of majority documents could be obtained, which can also mean that the same cluster can be classified in many respects depending on the attributes available. One way of classification is to find the most frequently repeated attribute in the cluster and name the cluster by the attribute. Another way of clustering is to calculate the presence of all attributes in the cluster and the cluster is named after the attribute whose presence would have the highest value."}, {"heading": "5 EXPERIMENTAL RESULTS", "text": "The algorithm is implemented in a system that takes input as a data set and output in two stages. Correctly bundled document set also contains the classified clusters based on the highest attribute presence. Table I specifies the details of the bundled documents and the cosinal similarity values after processing the data set by the entire algorithm. The above documents also have the attribute list as previously in Section IV. The attributes would be useful to filter out the unnecessary steps of processing by removing the unnecessary and useless attributes. Thus, the refined set of attributes would only be allowed for further clustering of the documents. Thus, the retrieval process will be better compared to the basic cluster algorithms and techniques. This cluster would contain the content and attribute-based documents that would generate the most accurate documents for the query submitted by the user. This is the goal of the proposed algorithm."}, {"heading": "6 CONCLUSION AND FUTURE WORK", "text": "The proposed method is aimed at retrieving and accessing documents from a large data set using the auxiliary characteristics. The usual clustering process uses only the content in the documents to cluster. This paper suggests an approach to do the same, but by refining the clustering process using the auxiliary characteristics. Auxiliary characteristics such as author details, paper details and weblogs would be considered auxiliary characteristics. After clustering, classification can be done by a side step, with the most prominent attribute considered to be the class of the cluster. This paper suggests this method to overcome the problem of maintaining and handling the large data sets we have to deal with."}], "references": [{"title": "A comparison of document clustering techniques", "author": ["M. Steinbach", "G. Karypis", "V. Kumar"], "venue": "KDD workshop on text mining, vol. 400, no. 1. Boston, 2000, pp. 525\u2013526.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Scatter/gather: A cluster-based approach to browsing large document collections", "author": ["D.R. Cutting", "D.R. Karger", "J.O. Pedersen", "J.W. Tukey"], "venue": "Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1992, pp. 318\u2013329.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1992}, {"title": "Commercially available data mining tools used in the economic environment", "author": ["M. Andronie", "D. Crisan"], "venue": "Database Systems Journal, vol. 1, no. 2, pp. 45\u201354, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Comparative analysis of bayes and lazy classification algorithms", "author": ["S. Vijayarani", "M. Muthulakshmi"], "venue": "International Journal of Advanced Research in Computer and Communication Engineering, vol. 2, no. 8, pp. 3118\u20133124, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "On the algorithmics and applications of a mixed-norm based kernel learning formulation", "author": ["S.N. Jagarlapudi", "D. G", "R. S", "C. Bhattacharyya", "A. Ben-tal", "R.K.r."], "venue": "pp. 844\u2013852, 2009. [Online]. Available: http://papers.nips.cc/paper/ 3880-on-the-algorithmics-and-applications-of-a-mixed-norm-based-kernel-learning-formulation.pdf", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Controlled sparsity kernel learning", "author": ["D. Govindaraj", "S. Raman", "S. Menon", "C. Bhattacharyya"], "venue": "CoRR, vol. abs/1401.0116, 2014. [Online]. Available: http://arxiv.org/abs/1401.0116", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Sparse classifier design based on the shapley value", "author": ["P. Ravipally", "D. Govindaraj"], "venue": "Proceedings of the World Congress on Engineering, vol. 1, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Hierarchical clustering algorithms for document datasets", "author": ["Y. Zhao", "G. Karypis", "U. Fayyad"], "venue": "Data mining and knowledge discovery, vol. 10, no. 2, pp. 141\u2013168, 2005.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "A system to filter unwanted messages from osn user walls", "author": ["M. Vanetti", "E. Binaghi", "E. Ferrari", "B. Carminati", "M. Carullo"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 25, no. 2, pp. 285\u2013 297, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "On the merits of building categorization systems by supervised clustering", "author": ["C.C. Aggarwal", "S.C. Gates", "P.S. Yu"], "venue": "Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1999, pp. 352\u2013356.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "A review on meta information based text data clustering.", "author": ["M.M.V. Upasani", "R.C. Samant"], "venue": "International Journal of Computer Science and Information Technologies,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Text clustering and classification on the use of side information", "author": ["S.S. Raut", "V. Maral"], "venue": "International Journal of Science and Research (IJSR), vol. 3, no. 10, 2014.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Application of active appearance model to automatic face replacement", "author": ["D. Govindaraj"], "venue": "Journal of Applied Statistics, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Modeling attractiveness and multiple clicks in sponsored search results", "author": ["D. Govindaraj", "T. Wang", "S.V.N. Vishwanathan"], "venue": "CoRR, vol. abs/1401.0255, 2014. [Online]. Available: http://arxiv.org/abs/1401.0255", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Moneybee: Towards enabling a ubiquitous, efficient, and easy-to-use mobile crowdsourcing service in the emerging market", "author": ["D. Govindaraj", "N.K.V.M.", "A. Nandi", "G. Narlikar", "V. Poosala"], "venue": "Bell Labs Technical Journal, vol. 15, no. 4, pp. 79\u201392, 2011. [Online]. Available: http://dx.doi.org/10.1002/bltj.20473 8", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "The combinations of the techniques also have made quite an impressive mark in data mining like bisect-K-means [1].", "startOffset": 110, "endOffset": 113}, {"referenceID": 1, "context": "The commonly used clustering techniques like scatter/gather has been beneficial to understand how clustering happens in a real web world scenario [2].", "startOffset": 146, "endOffset": 149}, {"referenceID": 2, "context": "Some of the commercially available tools like SPSS are common to data miners [3].", "startOffset": 77, "endOffset": 80}, {"referenceID": 3, "context": "The documents which are to be clustered are collected from a source which would be the World Wide Web or a repository which contains the different documents all in the same format [4][5].", "startOffset": 180, "endOffset": 183}, {"referenceID": 7, "context": "The algorithms for text clustering and classification like Nave Bayes, K-means, and SVM with kernerls [6, 7, 8, ?] have been used to mine textual data [9].", "startOffset": 151, "endOffset": 154}, {"referenceID": 8, "context": "Nave Bayes theorem was previously used to develop a system which detects the offensive content on the World Wide Web [10].", "startOffset": 117, "endOffset": 121}, {"referenceID": 0, "context": "The content based clustering requires an elaborate use of techniques along with K-means in order for the proposed methods to produce efficient results [1][11].", "startOffset": 151, "endOffset": 154}, {"referenceID": 9, "context": "The content based clustering requires an elaborate use of techniques along with K-means in order for the proposed methods to produce efficient results [1][11].", "startOffset": 154, "endOffset": 158}, {"referenceID": 10, "context": "The different techniques that are used for clustering and classification were summarized by various authors [12][13][?].", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "The different techniques that are used for clustering and classification were summarized by various authors [12][13][?].", "startOffset": 112, "endOffset": 116}, {"referenceID": 0, "context": "The bisecting K- means also produces results of clustered documents that are as good as those developed by using the agglomerative hierarchical clustering[1].", "startOffset": 154, "endOffset": 157}, {"referenceID": 12, "context": "K-means is also applied after reducing the dimensions using PCA[14].", "startOffset": 63, "endOffset": 67}, {"referenceID": 13, "context": "It is also well studied that information in web page is viewed in the order of position of words[15].", "startOffset": 96, "endOffset": 100}, {"referenceID": 14, "context": "Classification accuracy is verified using crowdsourcing approach [16].", "startOffset": 65, "endOffset": 69}], "year": 2016, "abstractText": "Earlier techniques of text mining included algorithms like k-means, Nave Bayes, SVM which classify and cluster the text document for mining relevant information about the documents. The need for improving the mining techniques has us searching for techniques using the available algorithms. This paper proposes one technique which uses the auxiliary information that is present inside the text documents to improve the mining. This auxiliary information can be a description to the content. This information can be either useful or completely useless for mining. The user should assess the worth of the auxiliary information before considering this technique for text mining. In this paper, a combination of classical clustering algorithms is used to mine the datasets. The algorithm runs in two stages which carry out mining at different levels of abstraction. The clustered documents would then be classified based on the necessary groups. The proposed technique is aimed at improved results of document clustering.", "creator": "LaTeX with hyperref package"}}}