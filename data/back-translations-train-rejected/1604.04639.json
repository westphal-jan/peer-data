{"id": "1604.04639", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2016", "title": "ModelWizard: Toward Interactive Model Construction", "abstract": "Data scientists engage in model construction to discover machine learning models that well explain a dataset, in terms of predictiveness, understandability and generalization across domains. Questions such as \"what if we model common cause Z\" and \"what if Y's dependence on X reverses\" inspire many candidate models to consider and compare, yet current tools emphasize constructing a final model all at once.", "histories": [["v1", "Fri, 15 Apr 2016 20:43:20 GMT  (1957kb,D)", "http://arxiv.org/abs/1604.04639v1", "Master's Thesis"]], "COMMENTS": "Master's Thesis", "reviews": [], "SUBJECTS": "cs.PL cs.LG", "authors": ["dylan hutchison"], "accepted": false, "id": "1604.04639"}, "pdf": {"name": "1604.04639.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "MODELWIZARD: TOWARD INTERACTIVE MODEL BUILDING STRUCTIONby Dylan Hutchison"}, {"heading": "A THESIS", "text": "In the Faculty of Stevens Institute of Technology, the requirements for the degree of MASTER OF SCIENCE - COMPUTER SCIENCEDylan Hutchison, Candidate ADVISORY COMMITTEEDavid Naumann, Advisor DatePhilippos Mordohai, Reader DateSTEVENS INSTITUTE OF TECHNOLOGY Castle Point on HudsonHoboken, NJ 07030 2015ar Xiv: 160 4.04 639v 1 [cs.P L] 15 Apr 201 6c \u00a9 2015, Dylan Hutchison. All rights reserved."}, {"heading": "Acknowledgments", "text": "I am grateful to David Naumann and Philippos Mordohai for their travel support and discussions that stimulate the growth of ModelWizard between programming languages and machine learning; Claudio Russo and Nicolas Rolland for their dives into bittersweet mathematical theory and pragmatic engineering; Matthew Smith for validating real-world ecological data and enthusiastic patience with software from the development phase. Andy Gordon, our intern and beyond, is allowed to open our office whiteboards, yes, the whiteboards of our minds that are so tentatively advertised yet so rich in energy and maturity for the public. Together, our moods will change the world one piece at a time.v Table of contents iiiiiiAckledgments iList of Figures ixList of Code Listings x"}, {"heading": "1 Introduction 1", "text": "1.1 Data Science as Model Construction 1 1.2 Prelude Example: Freefall in ModelWizard 41.2.1 Model Selection Matters: Overfitting and Consistency 9 1.2.2 Bayesian Inference 10 1.2.3 Interactive Model Construction 131.3 Probabilistic Programming 141.3.1 Tabular and Infer.NET 151.4 ModelWizard: Interactive Model Construction for Tabular 151.4.1 Concurrent Refining Data and Model 16 1.4.2 Composable Model Primitives 17 1.4.3 Safety in Model Construction 181.5 This Outline 18"}, {"heading": "2 ModelWizard Language 19", "text": "2.1 Types: State, Operation and Safety 19vi2.1.1 Definition of \"valid\" states 20 2.1.2 ValidState and ValidOp Types 23 2.1.3 OpMonad: ValidOp Computation Expression 242.2 Escape to F #: GetState 26 2.3 Machine Learning Base Models 26 2.4 Input of Data, Tables as Nominal Column Domains 282.4.1 Type Inference 302.5 Coupling Columns 312.5.1 Continuous Coupling: Noise Regression 31 2.5.2 Discrete Coupling: Index 32 2.5.3 Accounting: Ordering Tables and Columns 352.6 Latent Columns 35 2.7 Excel, Inference and Extended Operations 36"}, {"heading": "3 Applications 38", "text": "3.1 Small Model Search: Discrete Bayesian Networks 38 3.2 Derived Model Family: Naive Bayes 42 3.3 Hybrid Model: Internet Facility Sales 453.3.1 ExactInfer and Exact: Functional Dependencies 46 3.3.2 \"Preprocessing\" during Modeling 493.4 Recommendation for Evaluating User Movies 513.4.1 InfernoDB: Schema-Derived Cluster Models 51 3.4.2 Inferno Operation with Cluster Setting 53 3.4.3 Hyperparameter Sweeps Over the Number of Clusters 55 3.4.4 Missing Data Performance 56 3.4.5 Alternatives 58vii"}, {"heading": "4 Discussion 61", "text": "4.1 Addressing Big Data Challenges 61 4.2 Extending Model Security to Model Inferability 64 4.3 Extending to Usable Interactivity 65 4.4 Interactive Theorems Proving Analogy 67 4.5 Conclusions 68Appendices 69A OpMonad Translation 69 B ModelWizard API of Primitive and Derived Operations 70Bibliography 72viiList of Tables1.1 Apple in Freefall Dataset 2 1.2 Apple in Freefall Dataset, with \"missing value\" lines 5ixList of Figuressions 1.1 Apple Freefall Linear and Quadratic Regression 72.1 Tabular Conjugate Distributions 27 2.2 Factor Graph of CDiscrete (N = 2) Uncertain Bayesian Network 38 3.2 Intermediate States during Execution of Figure 3.3 Slease 3 Sleases 39 3.3 Initial State: Data and Scheme before Naive Baye Bayes result Code after Listing 3.2 Listing 3.3 Figure Planets 3.3 Planets 3.4 3.4 3.4 3.4"}, {"heading": "1.1 Data Science as Model Construction", "text": "In fact, most of them are able to survive on their own."}, {"heading": "1.2 Prelude Example: Freefall in ModelWizard", "text": "This year is the highest in the history of the country."}, {"heading": "1.2.1 Model Selection Matters: Overfitting and Consistency", "text": "Formally, we say that a model misses if it performs better on a training dataset, but performs worse on the distribution of all possible datasets than an alternative model [Mit97]. Apple Freefall models, for example, would clearly miss if their sound precision is too high. They would predict accurate distributions on their training dataset that do not predict well on non-training datasets.6 Model comparison methods can be another source of overmatch. We strive to compare models in a way that does not favor specialized, excessive models. Fortunately, for the Apple Freefall example, model comparison is closer to model comparison through the Akaike Information Criterion (Sto77), which is a desirable model complexity penalty [Boz87] that penalizes models with a greater degree of freedom."}, {"heading": "1.2.2 Bayesian Inference", "text": "It is a question of the extent to which it is at all possible for a country in which it is a country in which it is not a country but a country in which it is a country, a country in which it is not a country but a country in which it is a country, a country in which it is not a country, a country in which it is not a country, but a country in which it is a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a"}, {"heading": "1.2.3 Interactive Model Construction", "text": "In Section 1.2, we interactively build our quadratic regression model by building other models such as linear regression and comparing them, while naturally positioning them by asking questions about the apple dataset. In this way, of course, modelling fits in with the scientific method. To illustrate the benefits of interactivity, we envision two other extremes of modelling: manual and automated.14 Scientists pursuing a strategy of manual model construction take years to study a scenario well enough to become an expert and build a good model. However, the approach works at high labor costs, the fruits of which tend to be one-off special models that are applicable to a single problem. Scientists applying an automated exploration strategy by using algorithms that spend good families face traceability problems when trying to search through the space of all models. For example, [CG01a] O (n5) complexity models that seek out a small subspace of all possible models within the family of discrete networks."}, {"heading": "1.3 Probabilistic Programming", "text": "In probabilistic programming, machine learning models take the form of programs. Users write code that scans data points, effectively defining a probability distribution over possible data points. The model specified as a program gains power from programming language constructs, such as functional abstraction and control flow through iteration and conditions. Compilers use probabilistic program code at the highest level to synthesize inference codes. See [GHNR14], [DRK13], and [Goo13] for various variants of the Introduction to probabilistic programming. One success story that shows potential benefits for probabilistic programming is the creation of a seismic monitoring model to detect nuclear tests for the United Nations Comprehensive Nuclear Test Ban Treaty (CTBTO) Preparatory Commission. One of the CTBTO models has code on the order of 28,000 lines in C [Fis13]. This model was rewritten in the probabilistic language BLOG 14 and delivers a similar code to BLOG 14."}, {"heading": "1.3.1 Tabular and Infer.NET", "text": "Tabular is a probabilistic programming language in which models consist of probabilistic annotations on database schemas written within tables [GGR + 14, GRS + 15]. Tabular's motivation is the idea that data scientists would find it easier and more intuitive to specify their model by marking the schema of their dataset rather than specifying their model in a language independent of their dataset. Data scientists need an understanding of the primitives of Tabular, which are designed to be easy to read given their background in statistics and probability calculation. The Tabular Compiler compiles tabular models into Infer.NET probability programs [MWGK12], which can then be run in an Infer.NET Inference engine to infer posterior distributions and answers. Infer.NET supports variable message transmission, expectation propagation, and Gibbs sampling, all of which are available from tabular."}, {"heading": "1.4 ModelWizard: Interactive Model Construction for Tabular", "text": "ModelWizard is a domain-specific language embedded in F # for the interactive creation of tabular models. Users write scripts in ModelWizard that construct tabular models gradually, progressing from an initial \"do nothing\" Tabular model to an inference-ready tabular model. ModelWizard is inspired by the difficulty of writing tabular models, just like Tabular by the difficulty of writing Infer.NET models. ModelWizard's goal is to reduce the time it takes the user to create a tabular model from scratch. We are particularly interested in the case where the user does not know what the final model is and is still exploring the space of models. In this thesis, we present the design and implementation of ModelWizard as an embedded DSL, along with case studies in the application of modelWizard. The following sections highlight the main features of the ModelWizard design:"}, {"heading": "1.4.1 Concurrently Refining Data and Model", "text": "The operations of ModelWizard modify both the model of a data set under construction and the data set itself, which differs from the traditional \"pre-processing\" approach in the machine learning and data mining literature to perform all dataset-modifying operations prior to creating a model. Operations in ModelWizard that traditionally occur during the pre-processing of a changing column type, creating new tables with unique values, mapping values to refer to another table with a foreign key relationship, and capturing functional dependencies by moving data between tables, are an important step in the normalization of tables. Other operations we envision are numerical transformations such as square rooting, complete normalization of the table, data compression by taking major components, and outlier detection and purification, to name a few."}, {"heading": "1.4.2 Composable Model Primitives", "text": "Instead of constructing complicated machine learning models at once, we construct models step by step through sequences of primitive operations. Let's look at primitives as building blocks and F # code as adhesive. Putting together primitives and F # cements higher levels, derivative operations that we imagine as columns and walls. The beauty of derivative operations is that we abstract them and treat them as a reusable unique piece by forgetting the bricks and adhesives that make them up. We construct the most powerful models, machine learning castles, in fact, by composing all available operations to the design of F #. We find that the ModelWizard's primitive operations naturally capture common machine learning paradigms that, when composed into derivative models, provide easy access to many model families, such as clusters and naive bayes. Creating models as compositions gives us an understanding of how the box works, and how the computational models can be reconstructed to make it work."}, {"heading": "1.4.3 Safety in Model Construction", "text": "Tabular has typing rules relating to the domains of the columns and distributions to ensure that the probable annotations of a schema are meaningful and that the data actually matches the commented schema. A state consisting of a record plus a tabular model is valid, provided it does not contain naming conflicts, is well written, its schema and data comply with asserted relational properties such as primary / foreign keys, and there are no cyclic references. Users who develop models directly can easily construct invalid states. By contrast, ModelWizard ensures that only valid states can be constructed, and throws exceptions when an operation cannot construct a valid state."}, {"heading": "1.5 Thesis Outline", "text": "Chapter 2 introduces the syntax and design of the ModelWizard language. We will cover the core types and OpMonad, the operation builder of the ModelWizard, followed by a tour of the operations grouped by topic. See Appendix B for a concise ModelWizard operation API.Chapter 3 begins with simple model construction on small datasets and advances to advanced modeling on real data. We will cover Bayes networks, Naive Bayes classifiers, a hybrid model with functional dependencies and clusters for collaborative filtering. Readers seeking further intuition can skip Chapter 2 to see the examples of Chapter 3. Chapter 4 closes with the presentation of desirable extensions and the discussion of adapting the Model Wizard to the data science world. 19Chapter 2 ModelWizard LanguageWe will illustrate the language syntax and design of the ModelWizard, a domain-specific language embedded in # F in this chapter."}, {"heading": "2.1 Types: State, Operation and Safety", "text": "We call the dataset Data and the Tabular model schema. type TableName = string type ColumnName = string type DataTable = {tablename: TableName; colnames: ColumnName []; data: System.IComparable [,]} type Data = DataTable list type schema = / /... type State = schema * Data type StateOp < 'R > = (State - >' R * State) Data is a relative thin wrapper around an in-memory array of tables. A tablehas a named array of column names and a two-dimensional data array, 1 of1The System.IComparable [,] type on Data indicates that data values have a total order. \"Do not think deep into the total ordering; it is a pragmatic requirement that makes working with F # libraries."}, {"heading": "2.1.1 Defining \u201cValid\u201d States", "text": "This year it is more than ever before."}, {"heading": "2.1.2 ValidState and ValidOp Types", "text": "< < < < < < / p > ValidStates is part of an F # signature file whose purpose is to declare the types as an F # library implementation file. < p > The constructor of ValidStates is missing from the signature file, there is no direct way to construct ValidStates except by other methods that handle ValidStates in a controlled manner to maintain state validation. unwrapVS enables de-construction: retrieving encapsulated state from a ValidState. type ValidState / / / Constructor hidden! val unwrapVS: ValidState ValidState - > State UNSAFE-ValidState: Scheme * > ValidState24For development convenience and expert users, we include a functionUNSAFE ValidState."}, {"heading": "2.1.3 OpMonad: ValidOp Computation Expression", "text": "OpMonad is an F # computation expression class to create an intuitive syntax = > R > > unit = > ValidOps into a compound, derived ValidOp. As required for a proper monad, OpMonad respects the monad laws of left and right identity and association [Wad92, Section 2.10]. Code Listing 2.1 lists selected type signatures25type Opnatures25type OpMonad = member Bind: ValidOp < 'R - > ValidOp < N > member Return:' N > member Return Vnatures25type Opnatures25type Vind = member Bind # member Bind: ValidOp < \"R > member Zero: unit - > ValidOp & ltOp < unit > member Combine Combine Combine: ValidOp < unit > member Combine Componation <\""}, {"heading": "2.2 Escape to F#: GetState", "text": "GetState associates ModelWizard operations with F # code by returning a copy of the current schema and data of an executing operation and exposing it to the F # code. Operations can then inspect column names, types, and models, as well as their underlying data. Almost every derivative operation includes a call to GetState. There is no corresponding WriteState operation except via UNSAFE operations. Such an operation would allow a user to write derivative operations to simply create an invalid operation, destroying OpMonad's guarantees."}, {"heading": "2.3 Machine Learning Base Models", "text": "Both have conjugate priors: gamma on the precision of a Gaussian and discrete distribution model, another Gaussian on the mean of a Gaussian and another Gaussian on the mean of a Gaussian and Dirichlet on the probability vector of a discrete. Conjugate priors allow conclusions to be drawn about the meaning of a Gaussian and discrete distribution parameter. Tabular represents Gaussian and discrete conjugate distributions resulting from the col-umn markup CGaussian and CDiscrete themselves. Figure 2.1 illustrates the significance of markup as a method to draw from their represented probability distributions. N and MeanPrec are hyperparameters that can be specified in tabular model referencing. This \"discrete\" thesis refers to a categorical distribution, also known as a generalized Bernoulli distribution."}, {"heading": "2.4 Typing Data, Tables as Nominal Column Domains", "text": "The domain of upto (N) is the integer [0, N \u2212 1]. You can imagine a bool type like upto (2). The domain of link (T) is all rows of Table T. We change the column types by the operations TypeUpto, TypeReal, and 29TypeNominal. These operations are checked so that they do not set an inappropriate type on a column, and they may only act on unmodeled input columns. For example, TypeReal will check the data to make sure that the data of the target column is really real when there is a chance the data cannot be if the conversion of type string as opposed to type Indique. TypeUpto and TypeLink act similarly. TypeInt is also implemented, but not used in the API as no machine learning models."}, {"heading": "2.4.1 Type Inference", "text": "We can create TypeInfer, a derivative operation that derives the type of a column from its data. We design TypeInfer to first apply a heuristic that columns with less than 5% unique values are likely to be nominal columns because they have a significantly high degree of redundancy. For example, the data {1, 1, 1, 0, 0, 0} are nominal rather than continuous, with 0 and 1 indicating the presence or absence of a label or property. Users can call TypeReal to override this heuristic. If a column contains more than 5% unique values, TypeInfer will enter the input column as int, then as real if the data contains a non-integer, and then as nominal value as final resort.We expand TypeInfer to automatically add all the input columns of a table by the derivative operation TypeInfera Table in the simplified version of Table 31. Show the Implementation."}, {"heading": "2.5 Coupling Columns", "text": "The two previous sections introduce how to type columns and place basic machine learning models on a column independent of all other columns. We now look at coupling models of columns in such a way that one column depends on the other."}, {"heading": "2.5.1 Continuous Coupling: Noisy Regression", "text": "In fact, it is a reactionary act capable of blackmailing itself."}, {"heading": "2.5.2 Discrete Coupling: Index", "text": "In fact, it is a purely reactionary project, which is about putting people's interests at the centre, not putting them at the centre."}, {"heading": "2.5.3 Bookkeeping: Reordering Tables and Columns", "text": "With the power of the LinReg, QuadReg, and Index coupling operations to create dependencies between columns, we run the risk of creating cyclic dependencies: one column from another that transitively depends on the first. Cyclic dependencies are unpronounceable in tables; columns may only refer to columns declared above them in a tabular model. In other words, the overall model must fit into a directed acyclic graph. We protect ourselves from cyclic dependencies by checking the set of columns on which acolumn depends at runtime. There are three scenarios. If a dependency can be created without changing the column order, it is done. If a dependency can be created that requires a change in the column order, then a ReorderColumns operation is called internally. If a dependency cannot be created due to cyclic dependencies (sometimes with many columns), then an exception can be made."}, {"heading": "2.6 Latent Columns", "text": "A common modeling paradigm is to create latent columns that are not present in the original dataset, in addition to the concrete columns that are provided with data values. Latent columns derived from concrete columns free the user from intermediate states of probable modeling 36 and often increase the intelligibility of the model. For example, latent columns within the function tables of LinReg and QuadReg increase their interpretative capability by delimiting the addition of noise from regression. NewColumn is an operation that treats an UptoColumn or a LinkColumn. Section 3.4 demonstrates UptoColumn by creating new cluster columns for tables. The number of clusters is given as an argument for UptoColumn. We consider these columns as output in Figure 3.9, as we treat new columns as concrete columns with all the missing datas.Section 3.3 demonstrates LinkColumn in the ExactInfer operation, which links domain columns with table ranges to determine the exact columns."}, {"heading": "2.7 Excel, Inference and Advanced Operations", "text": "ModelWizard reads data from an Excel workbook data model using bindings in the.NET Framework API. Fortunately, the Excel data model includes types on columns forced by the Excel processing model. Therefore, ModelWizard relies on the type of column specified by Excel by using an UNSAFE ValidState operation when creating a state directly from an Excel workbook. Writing data is similar except that the data is first written into a user-defined Excel table and then added to the data model contained therein. Tabular models are read directly from tables and written in tables. Inference operations call up the tabular compiler. We implement them by calling GetState, Converting ModelWizard data and schema into table data and schema, and executing the table compiler to create an Infer.NET probability program to create the tabular compiler. We implement them by calling GetState, Consistent, Consisting data and schema in table data and schema, and executing an Inferen.NET probability program to create a table from an Excel workbook."}, {"heading": "3.1 Small Model Search: Discrete Bayesian Networks", "text": "This year it is more than ever before in the history of the city."}, {"heading": "3.2 Derived Model Family: Naive Bayes", "text": "This year it is more than ever before."}, {"heading": "3.3 Hybrid Model: Internet Plant Sales", "text": "We now turn to a real-world example: modeling Internet plant sales. We use more advanced pre-processing to capture functional dependencies, in combination with the Naive Bayes model of the previous section. Figure 3.5 shows a few lines from a data set acquired by staff at the Royal Botanic Gardens in Kew UK interested in predicting wild plants: whether a sale is a wild plant or a plant growing in a greenhouse. Predicting whether a plant is wild or reproducing is a key step in identifying illegal plant sales. Perhaps more important than predicting how strongly other columns affect wild plants, including sales price, country of sale, crop protection priority and status on the CITES list of endangered plant species. The database literature [Dat90] establishes a functional dependence (FD) between domain columns and a domain column."}, {"heading": "3.3.1 ExactInfer and Exact: Functional Dependencies", "text": "In fact, we are able to set out in search of new paths that will lead us into the future."}, {"heading": "3.3.2 \u201cPre-processing\u201d during Modeling", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "3.4 User-Movie-Rating Recommendation", "text": "For another application in the real world, we turn to film recommendations as popularized by the Netflix challenge [BL07]. We show how to build a general cluster model using a ModelWizard script and evaluate its predictive power. Specifically, we compare Singh and Graepel's application of InfernoDB to movie recommendations, as in their first example, which runs on synthetic user-movie rating data [SG12, SG13]. Our data is identical to Singh and Graepel's synthetic dataset, consisting of a table of users with attributes of gender and age, a table of movies with attributes of category and year, and a table of ratings with a rating of 0 to 10 and links to a user and movie. The dataset is small, comprising two movie genres, 20 users, 30 movies, and 25 ratings. Figure 3.7 illustrates a few lines."}, {"heading": "3.4.1 InfernoDB: Schema-Derived Clustering Models", "text": "Singh and Graepel introduce the concept of automatic generation of machine learning models. Each series has a distribution via a database, including the types of columns in tables and foreign key relationships between tables. The type of a column determines its base distribution: Real rated columns have a Gaussian distribution and discrete (link) columns have a discrete distribution. We replace the Bernoulli distribution used by Singh and Graepel with equivalent Discrete22Recall that we use discrete as a synonym for a categorical distribution. 52Distributions of dimension two. Each table has a number of clusters. Tables without external links (\"Leaf Tables\") have a fixed number of clusters that have been hand-selected as the number of clusters is a crucial hyperparameter. Tables with external connections (\"Body Tables\") have a number of clusters that are similar to the product of linked tables."}, {"heading": "3.4.2 Inferno Operation with Cluster Setting", "text": "In fact, most of us will be able to play by the rules that we have set ourselves, \"he said in an interview with\" Welt am Sonntag \":\" We have to play by the rules that we have set ourselves. \""}, {"heading": "3.4.3 Hyperparameter Sweeps over Number of Clusters", "text": "We use the resulting cluster number-change functions of Inferno to find the optimal numbers of clusters by hyperparameter verification. We model our algorithm as an iterative coordinate descent as follows: Let userk and titlek be the number of clusters for the user and the title table, respectively. Initialize userk, titlek: = 4 (from Inferno).2 Hold down titlek and calculate the best scoring column between 1 and 6 by runningcross validation 6 times and compare the scores. Hold userk fixed and calculate the best scoring titlek between 1 and 6 times and compare the scores."}, {"heading": "3.4.4 Performance on Missing Data", "text": "To assess how well our ModelWizard implementation captures the concept behind InfernoDB, we create graphs of the same shape as Figure 3 in [SG13]. Graphs 5758show model performance in predicting different columns with different numbers of randomly selected held values. In contrast to the procedure of the previous section to find the optimal number of clusters, we provide values from all unlinked columns: age and gender of a user, category and year of a movie and rating. There are 125 data values to keep. Figure 3.10 shows the performance of the model derived from Inferno using the calculated optimal number of clusters (that is, optimal for predicting ratings).For each number of held data on the x-axis, we plot five independent rounds of prediction that many held values will be maintained. Each round may have different held values, and for each version we calculate RSE."}, {"heading": "3.4.5 Alternatives", "text": "Matrix factorization is a popular alternative to cluster models for recommendation systems. In matrix factorization, each user and film has a hidden d-dimensional vector where each dimension can be considered a feature. Compatibility between users 560 and movies is determined by the inner product of their feature vectors, resulting in a real number that is shifted to the average rating. Characteristics of the same character (in one dimension of the vector) contribute to a higher rating, and opposing characteristics contribute to a lower rating. Other models in the literature that should be considered fall into the category of cooperative filtration; see [BHK98] for an overview. Another alternative is to consider rating as an ordinary variable rather than an oral variable. As in Section 3.3 of the Internet application for plant sales, it is a matter of ordering ratings and deriving and effectively discrediting their latent thresholds."}, {"heading": "4.1 Addressing Big Data\u2019s Challenges", "text": "This year, it has come to the point where it can only take a year for a solution to be found and a solution to be found."}, {"heading": "4.2 Extending Model Safety to Model Inferability", "text": "ModelWizard's ValidState, ValidOp, and OpMonad constructs guarantee a basic level of model security: Each model constructed by ModelWizard has a valid tabular counterpart and passes tabular type verification. Is it possible to extend model security to guarantee that models constructed by ModelWizard are derivable, i.e. that they can be executed by the back-end inference machine to generate rear distributions of parameters and missing values? Such a strong guarantee would allow data scientists to freely conjure models using the available range of operations (taking into account types, so as not to throw exceptions) without worrying whether the model they constructed is running. The short answer is with great difficulty. Providing inference guarantees is inherently specific to the choice of the inference machine. Formal proof requires modeling the syntax and semantics of a specific program to prove that a specific subversion is a semantic."}, {"heading": "4.3 Extending to Usable Interactivity", "text": "In fact, most of them are able to survive themselves if they do not put themselves in a position to survive themselves, and they are not able to survive themselves. Most of them are able to put themselves in a position to put themselves in a position to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position to survive, to put themselves in a position to survive, to put themselves in a position to put themselves in a position to survive."}, {"heading": "4.4 Interactive Theorem Proving Analogy", "text": "Both benefit from interactivity as a happy medium between two extremes. Proving theorems manually on pencil and paper requires expert knowledge and training to navigate the space of all possible proofs and formalize one that proves the theorem. The approach works like manual modeling, but with high labor costs and sometimes requires years of study in the field of proof. Automated testing of theorems requires powerful algorithms. For example, the automated SMT solver Z3 [DMB08] is successful for simple theorems, but will fail due to the size of all the proofs in complex theorems. Automated modeling similarly fails in an unrestricted model space. We strive to use the design of interactive theorem proofs as inspiration for interactive modeling. Imagine operations as model construction tactics, lower ones as model discrete, the code-writing tactic Backletics [like Isabelammer] and higher tactic Backletics."}, {"heading": "4.5 Conclusion", "text": "Probabilistic programs provide a universal space for creating machine learning models for a dataset. ModelWizard represents a new way of constructing machine learning models, focusing on iterative construction one-on-one with model exploration, rather than the traditional specification of a probabilistic program that is created entirely at once. Our primary contribution is to lay the groundwork for an interactive framework that is applicable to any language and inference engine to look at data transformations and machine learning models in the sense of composable building blocks that we call operations glued together by program code (F # in our case), while simultaneously realizing areas of preprocessing, manual analysis, automated analysis, and modeling itself. We realize these areas in naturally familiar program structures such as conditional, iteration, and procedural abstraction, along with possibilities for classic programming languages such as statistical analysis, tactical analysis, and compiler optimization."}, {"heading": "A OpMonad Translation", "text": "As a demonstration of how let!, do! and other monadic syntax desugars into vanilla F # code, we present a simplified version of the derived operation TypeInferTable on the target table tmain, followed by its translation into an F # quote evaluating a ValidOp < unit > value unit, which includes calls to calculation expression functions defined in Code Listing 2.1 and bold in the code below. OPM {let! schema = GetSchemalet table = getSchemaTableByName schema \"tmain\" for col in table.columns do / / infern each column'sdo! TypeInferColumn \"tmain\" col.name} / type in tmainQuotations.Explt; ValidOp < unit > = Call (Some (Value) (Blt1), Oparda gad), < Valay, [Lambda (unitVar Call, Value) < (Expquotation Value < < < < Expquotation Value < < < ValidOp <) < (Expect Value)"}, {"heading": "B ModelWizard API of Primitive and Derived Operations", "text": "< < < < < < < < < / p > > > / p > / p > / p > / p > / p > / p > / p > / p > / p > / pnp.pnpnp.pnpnp.pnpnp.pnnp.pnpnp.pnp.np.n.p.n.p.n.p.n.p.n.p.n.p.n.p.n.n.p.n.p.n.p.n.p.p.p.n.p.n.p.n.p.n.p.n.p.n.p.n.n.p.n.n.p.n.n.p.n.n.p.n.n.p.n.p.n.n.p.n.p.n.n.p.n.p.n.p.n.p.n.p.p.n.p.n.p.p.n.p.n.p.p.n.p.n.p.n.p.n.p.p.n.p.p.n.p.n.p.n.p.p.n.p.p.n.p.p.n.n.p.p.n.p.n.p.p.p.n.n.p.n.p.p.n.p.p.n.n.p.p.n.p.n.p.p.n.n.p.n.p.p.p.n.n.p.n.n.p.p.p.p.p.n.n.p.n.n.n.p.p.n.p.n.p.n.p.p.n.n.p.n.n.p.n.p.n.p.n.n.p.p.n.n.n.p.p.n.p.n.p.p.n..p..p..n....p.p.n..p.p.n..p."}], "references": [{"title": "Proof general: A generic tool for proof development", "author": ["David Aspinall"], "venue": "In Tools and Algorithms for the Construction and Analysis of Systems,", "citeRegEx": "Aspinall.,? \\Q2000\\E", "shortCiteRegEx": "Aspinall.", "year": 2000}, {"title": "BayesDB: querying the probable implications of tabular data", "author": ["Jay Baxter"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "Baxter.,? \\Q2014\\E", "shortCiteRegEx": "Baxter.", "year": 2014}, {"title": "Generative or discriminative: Getting the best of both worlds. Bayesian statistics 8: proceedings of the eighth Valencia International Meeting", "author": ["JM Bernardo", "MJ Bayarri", "JO Berger", "AP Dawid", "D Heckerman", "AFM Smith", "M West"], "venue": null, "citeRegEx": "Bernardo et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bernardo et al\\.", "year": 2006}, {"title": "Interactive theorem proving and program development: Coq\u2019Art: the calculus of inductive constructions", "author": ["Yves Bertot", "Pierre Cast\u00e9ran"], "venue": "springer,", "citeRegEx": "Bertot and Cast\u00e9ran.,? \\Q2004\\E", "shortCiteRegEx": "Bertot and Cast\u00e9ran.", "year": 2004}, {"title": "Empirical analysis of predictive algorithms for collaborative filtering", "author": ["John S Breese", "David Heckerman", "Carl Kadie"], "venue": "In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "Breese et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Breese et al\\.", "year": 1998}, {"title": "Variational methods for the dirichlet process", "author": ["David M Blei", "Michael I Jordan"], "venue": "In Proceedings of the twenty-first international conference on Machine learning,", "citeRegEx": "Blei and Jordan.,? \\Q2004\\E", "shortCiteRegEx": "Blei and Jordan.", "year": 2004}, {"title": "The netflix prize", "author": ["James Bennett", "Stan Lanning"], "venue": "In Proceedings of KDD cup and workshop,", "citeRegEx": "Bennett and Lanning.,? \\Q2007\\E", "shortCiteRegEx": "Bennett and Lanning.", "year": 2007}, {"title": "Automatic database normalization and primary key generation", "author": ["Amir Hassan Bahmani", "Mahmoud Naghibzadeh", "Behnam Bahmani"], "venue": "In Electrical and Computer Engineering,", "citeRegEx": "Bahmani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bahmani et al\\.", "year": 2008}, {"title": "Model selection and Akaike\u2019s information criterion (AIC): The general theory and its analytical extensions", "author": ["Hamparsum Bozdogan"], "venue": null, "citeRegEx": "Bozdogan.,? \\Q1987\\E", "shortCiteRegEx": "Bozdogan.", "year": 1987}, {"title": "Operations for learning with graphical models", "author": ["Wray L Buntine"], "venue": "arXiv preprint cs/9412102,", "citeRegEx": "Buntine.,? \\Q1994\\E", "shortCiteRegEx": "Buntine.", "year": 1994}, {"title": "Learning bayesian belief network classifiers: Algorithms and system", "author": ["Jie Cheng", "Russell Greiner"], "venue": "Advances in Artificial Intelligence,", "citeRegEx": "Cheng and Greiner.,? \\Q2001\\E", "shortCiteRegEx": "Cheng and Greiner.", "year": 2001}, {"title": "Learning bayesian belief network classifiers: Algorithms and system", "author": ["Jie Cheng", "Russell Greiner"], "venue": "In Advances in Artificial Intelligence,", "citeRegEx": "Cheng and Greiner.,? \\Q2001\\E", "shortCiteRegEx": "Cheng and Greiner.", "year": 2001}, {"title": "An introduction to database systems, volume 7. Addison-wesley", "author": ["Christopher John Date"], "venue": null, "citeRegEx": "Date.,? \\Q1990\\E", "shortCiteRegEx": "Date.", "year": 1990}, {"title": "The BigDawg architecture and reference implementation", "author": ["Jennie Duggan", "Aaron Elmore", "Tim Kraska", "Sam Madden", "Tim Mattson", "Michael Stonebraker"], "venue": "New England Database Summit,", "citeRegEx": "Duggan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Duggan et al\\.", "year": 2015}, {"title": "Mining database structure; or, how to build a data quality browser", "author": ["Tamraparni Dasu", "Theodore Johnson", "S. Muthukrishnan", "Vladislav Shkapenyuk"], "venue": "In Proceedings of the 2002 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Dasu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dasu et al\\.", "year": 2002}, {"title": "An efficient smt solver. In Tools and Algorithms for the Construction and Analysis of Systems, pages 337\u2013340", "author": ["Leonardo De Moura", "Nikolaj Bj\u00f8rner. Z"], "venue": null, "citeRegEx": "Moura and Z3,? \\Q2008\\E", "shortCiteRegEx": "Moura and Z3", "year": 2008}, {"title": "Probabilistic programming concepts", "author": ["Luc De Raedt", "Angelika Kimmig"], "venue": "arXiv preprint arXiv:1312.4328,", "citeRegEx": "Raedt and Kimmig.,? \\Q2013\\E", "shortCiteRegEx": "Raedt and Kimmig.", "year": 2013}, {"title": "Big dataconceptual modeling to the rescue", "author": ["David W. Embley", "Stephen W. Liddle"], "venue": "Conceptual Modeling,", "citeRegEx": "Embley and Liddle.,? \\Q2013\\E", "shortCiteRegEx": "Embley and Liddle.", "year": 2013}, {"title": "Probabilistic programming for advancing machine learning (PPAML) program kick-off", "author": ["Kathleen Fisher"], "venue": "Online at http: //ppaml.galois.com/wiki/attachment/wiki/Presentations/ PPAMLKickoffOverviewSlides.pdf?format=raw,", "citeRegEx": "Fisher.,? \\Q2013\\E", "shortCiteRegEx": "Fisher.", "year": 2013}, {"title": "Comprehensible classification models: A position paper", "author": ["Alex A. Freitas"], "venue": "SIGKDD Explor. Newsl.,", "citeRegEx": "Freitas.,? \\Q2014\\E", "shortCiteRegEx": "Freitas.", "year": 2014}, {"title": "Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper)", "author": ["Andrew Gelman"], "venue": "Bayesian Anal., 1(3):515\u2013534,", "citeRegEx": "Gelman.,? \\Q2006\\E", "shortCiteRegEx": "Gelman.", "year": 2006}, {"title": "Tabular: a schema-driven probabilistic programming language", "author": ["Andrew D. Gordon", "Thore Graepel", "Nicolas Rolland", "Claudio V. Russo", "Johannes Borgstr\u00f6m", "John Guiver"], "venue": "In POPL,", "citeRegEx": "Gordon et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 2014}, {"title": "Probabilistic programming", "author": ["Andrew D Gordon", "Thomas A Henzinger", "Aditya V Nori", "Sriram K Rajamani"], "venue": "In International Conference on Software Engineering (ICSE, FOSE track),", "citeRegEx": "Gordon et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 2014}, {"title": "Data management in cloud environments: Nosql and newsql data stores", "author": ["Katarina Grolinger", "Wilson A Higashino", "Abhinav Tiwari", "Miriam AM Capretz"], "venue": "Journal of Cloud Computing: Advances, Systems and Applications,", "citeRegEx": "Grolinger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Grolinger et al\\.", "year": 2013}, {"title": "The principles and practice of probabilistic programming", "author": ["Noah D Goodman"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "Goodman.,? \\Q2013\\E", "shortCiteRegEx": "Goodman.", "year": 2013}, {"title": "An agenda for probabilistic programming: Usable, portable, and ubiquitous. In ISAT/DARPA workshop on \u201cProbabilistic Programming: Democratizing Machine Learning,", "author": ["Andrew D. Gordon"], "venue": null, "citeRegEx": "Gordon.,? \\Q2013\\E", "shortCiteRegEx": "Gordon.", "year": 2013}, {"title": "Probabilistic programs as spreadsheet queries", "author": ["Andrew D. Gordon", "Claudio Russo", "Marcin Szymczak", "Johannes Borgstrm", "Nicolas Rolland", "Thore Graepel", "Daniel Tarlow"], "venue": "Programming Languages and Systems,", "citeRegEx": "Gordon et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 2015}, {"title": "Basic bayesian methods", "author": ["Mark E. Glickman", "David A. van Dyk"], "venue": "Topics in Biostatistics,", "citeRegEx": "Glickman and Dyk.,? \\Q2007\\E", "shortCiteRegEx": "Glickman and Dyk.", "year": 2007}, {"title": "Bayesian model averaging: a tutorial", "author": ["Jennifer A Hoeting", "David Madigan", "Adrian E Raftery", "Chris T Volinsky"], "venue": "Statistical science,", "citeRegEx": "Hoeting et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Hoeting et al\\.", "year": 1999}, {"title": "Scalable discovery of unique column combinations", "author": ["Arvid Heise", "Jorge-Arnulfo Quian\u00e9-Ruiz", "Ziawasch Abedjan", "Anja Jentzsch", "Felix Naumann"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Heise et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heise et al\\.", "year": 2013}, {"title": "Model selection error rates in nonparametric and parametric model comparisons", "author": ["Yongsung Joo", "Martin T Wells", "George Casella"], "venue": "In Borrowing Strength: Theory Powering Applications\u2013A Festschrift", "citeRegEx": "Joo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Joo et al\\.", "year": 2010}, {"title": "Associative arrays: Unified mathematics for spreadsheets, databases, matrices, and graphs", "author": ["Jeremy Kepner", "Julian Chaidez", "Vijay Gadepally", "Hayden Jansen"], "venue": "In New England Database Summit,", "citeRegEx": "Kepner et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kepner et al\\.", "year": 2015}, {"title": "Aleatory or epistemic? does it matter", "author": ["Armen Der Kiureghian", "Ove Ditlevsen"], "venue": "Structural Safety,", "citeRegEx": "Kiureghian and Ditlevsen.,? \\Q2009\\E", "shortCiteRegEx": "Kiureghian and Ditlevsen.", "year": 2009}, {"title": "The discovery of structural form", "author": ["Charles Kemp", "Joshua B. Tenenbaum"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Kemp and Tenenbaum.,? \\Q2008\\E", "shortCiteRegEx": "Kemp and Tenenbaum.", "year": 2008}, {"title": "Causal reasoning with causal models", "author": ["Kevin B. Korb", "Charles R. Twardy", "Toby Handfield", "Graham Oppy"], "venue": "Technical report,", "citeRegEx": "Korb et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Korb et al\\.", "year": 2005}, {"title": "A probabilistic programming approach to naive bayes text classification", "author": ["Danilo Lucena", "Gustavo Brito", "Andrei Formiga", "Joao Pessoa-PBBrazil"], "venue": "In 2nd Brazilian Conference on Intelligent Systems,", "citeRegEx": "Lucena et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lucena et al\\.", "year": 2013}, {"title": "Computing: A vision for data science", "author": ["Chris A. Mattmann"], "venue": null, "citeRegEx": "Mattmann.,? \\Q2013\\E", "shortCiteRegEx": "Mattmann.", "year": 2013}, {"title": "Support the data enthusiast: Challenges for next-generation data-analysis systems", "author": ["Kristi Morton", "Magdalena Balazinska", "Dan Grossman", "Jock Mackinlay"], "venue": "Proc. VLDB Endow.,", "citeRegEx": "Morton et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Morton et al\\.", "year": 2014}, {"title": "An introduction to graphical models. A Brief Introduction to Graphical Models and", "author": ["Kevin Murphy"], "venue": "Bayesian Networks,", "citeRegEx": "Murphy.,? \\Q2001\\E", "shortCiteRegEx": "Murphy.", "year": 2001}, {"title": "An efficient mcmc sampler for probabilistic programs", "author": ["Aditya V Nori", "Chung-Kil Hur", "Sriram K Rajamani", "Selva Samuel"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI)", "citeRegEx": "Nori et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nori et al\\.", "year": 2014}, {"title": "The sql++ semi-structured data model and query language: A capabilities survey of sql-on-hadoop, nosql and newsql databases", "author": ["Kian Win Ong", "Yannis Papakonstantinou", "Romain Vernoux"], "venue": "arXiv preprint arXiv:1405.3631,", "citeRegEx": "Ong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ong et al\\.", "year": 2014}, {"title": "Three years of experience with sledgehammer, a practical link between automatic and interactive theorem provers", "author": ["Lawrence C Paulson", "Jasmin Christian Blanchette"], "venue": "In PAAR@ IJCAR,", "citeRegEx": "Paulson and Blanchette.,? \\Q2010\\E", "shortCiteRegEx": "Paulson and Blanchette.", "year": 2010}, {"title": "Syntax matters: Writing abstract computations in F", "author": ["Tomas Petricek", "Don Syme"], "venue": "Pre-proceedings of TFP (Trends in Functional Programming),", "citeRegEx": "Petricek and Syme.,? \\Q2012\\E", "shortCiteRegEx": "Petricek and Syme.", "year": 2012}, {"title": "Potter\u2019s wheel: An interactive data cleaning system", "author": ["Vijayshankar Raman", "Joseph M Hellerstein"], "venue": "In VLDB,", "citeRegEx": "Raman and Hellerstein.,? \\Q2001\\E", "shortCiteRegEx": "Raman and Hellerstein.", "year": 2001}, {"title": "Unifying logic and probability", "author": ["Stuart Russell"], "venue": "Recent developments,", "citeRegEx": "Russell.,? \\Q2014\\E", "shortCiteRegEx": "Russell.", "year": 2014}, {"title": "Data curation at scale: The data tamer system", "author": ["Michael Stonebraker", "Daniel Bruckner", "Ihab F Ilyas", "George Beskales", "Mitch Cherniack", "Stanley B Zdonik", "Alexander Pagan", "Shan Xu"], "venue": "In CIDR,", "citeRegEx": "Stonebraker et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Stonebraker et al\\.", "year": 2013}, {"title": "Compiling relational database schemata into probabilistic graphical models", "author": ["Sameer Singh", "Thore Graepel"], "venue": "CoRR, abs/1212.0967,", "citeRegEx": "Singh and Graepel.,? \\Q2012\\E", "shortCiteRegEx": "Singh and Graepel.", "year": 2012}, {"title": "Automated probabilistic modeling for relational data", "author": ["Sameer Singh", "Thore Graepel"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,", "citeRegEx": "Singh and Graepel.,? \\Q2013\\E", "shortCiteRegEx": "Singh and Graepel.", "year": 2013}, {"title": "Linear model selection by cross-validation", "author": ["Jun Shao"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Shao.,? \\Q1993\\E", "shortCiteRegEx": "Shao.", "year": 1993}, {"title": "An asymptotic equivalence of choice of model by crossvalidation and Akaike\u2019s criterion", "author": ["Mervyn Stone"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Stone.,? \\Q1977\\E", "shortCiteRegEx": "Stone.", "year": 1977}, {"title": "Dirichlet process. In Encyclopedia of machine learning, pages 280\u2013287", "author": ["Yee Whye Teh"], "venue": null, "citeRegEx": "Teh.,? \\Q2010\\E", "shortCiteRegEx": "Teh.", "year": 2010}, {"title": "A Dictionary of Statistics", "author": ["G. Upton", "I. Cook"], "venue": "Oxford Paperback Reference. OUP Oxford,", "citeRegEx": "Upton and Cook.,? \\Q2008\\E", "shortCiteRegEx": "Upton and Cook.", "year": 2008}], "referenceMentions": [], "year": 2016, "abstractText": "iii", "creator": "LaTeX with hyperref package"}}}