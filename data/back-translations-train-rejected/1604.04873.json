{"id": "1604.04873", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Apr-2016", "title": "From Incremental Meaning to Semantic Unit (phrase by phrase)", "abstract": "This paper describes an experimental approach to Detection of Minimal Semantic Units and their Meaning (DiMSUM), explored within the framework of SemEval 2016 Task 10. The approach is primarily based on a combination of word embeddings and parserbased features, and employs unidirectional incremental computation of compositional embeddings for multiword expressions.", "histories": [["v1", "Sun, 17 Apr 2016 14:07:34 GMT  (330kb,D)", "http://arxiv.org/abs/1604.04873v1", "7 pages, 1 figure, International Workshop on Semantic Evaluation (SemEval-2016)"]], "COMMENTS": "7 pages, 1 figure, International Workshop on Semantic Evaluation (SemEval-2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["andreas scherbakov", "ekaterina vylomova", "fei liu", "timothy baldwin"], "accepted": false, "id": "1604.04873"}, "pdf": {"name": "1604.04873.pdf", "metadata": {"source": "CRF", "title": "VectorWeavers at SemEval-2016 Task 10: From Incremental Meaning to Semantic Unit (phrase by phrase)", "authors": ["Andreas Scherbakov", "Ekaterina Vylomova", "Fei Liu", "Timothy Baldwin"], "emails": ["andreas@softwareengineer.pro,", "evylomova@gmail.com,", "fliu3@student.unimelb.edu.au,", "tb@ldwin.net"], "sections": [{"heading": "1 Motivation", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Overview", "text": "The overall architecture of our system is shown in Figure 1. The neural network consists of three blocks: (1) an incremental vector (recurrence) for a candidate MWE; (2) a two-layer perceptron for a meaningful classification; and (3) a (slightly wider) two-layer vector for an incremental perception for a MWE classification. An incremental vector produced by the first block is used as the source of feature vectors of each of the latter block.The incremental vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector vector of each of the latter of the latter of the last block of the last block."}, {"heading": "3 Learning", "text": "As mentioned briefly above, our method looks at n-word expressions gradually, starting with individual words."}, {"heading": "3.1 MWE boundary", "text": "The system learns a single scalar output value of + 1 for each extension of (n \u2212 1) word prefixes to an n-word MWE (either complete or incomplete), where n \u2265 2. In this way, each n-word expression ultimately yields n \u2212 1 incremental positive samples. Furthermore, for each word, whether it is a standalone word or a member of the MWE, a \u2212 1 value (i.e. a negative sample) is selected for its (unobserved) extension to an MWE with a random word. Such a random word is selected in the same sentence for the L-words that are not involved in the same MWE with the current word. 1During the learning process (and accordingly, we limit L to 9 words and also limit the probability of each word selection to < 0.25 (by using sample processing for L < 4) to avoid possible distortions in the distribution of inter-word offsets."}, {"heading": "3.2 Senses", "text": "We learn one sense per complete n-word expression, including n = 1. We have one unique output per sense, including \"unknown\" (total of 42 in the DiMSUM dataset), factoring in the error in mapping the senses by the number of senses to compensate for the backpropagation of two perceptrons to the incremental vector calculator."}, {"heading": "4 Prediction", "text": "We use a greedy method of predicting MWE in a text. An outer loop iterates through all words in a sentence, selects each word (which has not yet been consumed by some previously predicted MWE) as the keyword of a possible new MWE and restarts the incremental vector calculation. An inner loop iterates through (up to L) remaining words in the sentence after the current header. Each time, the probability that such a second word is a continuation of the MWE is evaluated. As soon as a new MWE or an MWE extension is predicted, it consumes the right word and designates it as the next word of the MWE; the incremental vector is updated with the new MWE member each time. Such a method can create a deep stack of nested MWE's with gaps, but we limit the depth to match the DiMSUM data format."}, {"heading": "5 Features", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Word Embeddings", "text": "We used a publicly available, pre-trained CBOW word2vec model with 300-dimensional word vectors based on the Google News corpus. Words outside the vocabulary are represented with zero-filled vectors. We use the following search strategy when looking up a word in the word2vec dictionary (until the first successful search yields the final embedding): 2.1. strip off the leading \"#\" and \"@\" 2. if the word is a number, then replace it with \"NUM\" 3. write the word in lowercase letters 4. lemmatized (optional) 5. remove all non-alpha characters 6. embed the word associated with the word or, if there is no match, return a zero vector."}, {"heading": "5.2 Word Hash Sum", "text": "We produce a 64-dimensional + 1 / \u2212 1 hash sum vector for words where the embed vector is unknown; a zero vector has been provided for words found (somehow) in the Google News WEMB database. 2We have tried to reduce the rate of unknown words by means of easy spell checking (a simple replacement of a character and then selecting the most likely word according to its frequency classification), but it did not seem to be effective as the number of incorrectly predicted words was greater than the number of correctly predicted ones, especially due to the absence of a large number of frequent words (\"stop words\") in the Google News vectors DB. Therefore, a more sophisticated system would be needed to correct typos. Only alphabetical characters were counted in the hash sum."}, {"heading": "5.3 Word Distance features", "text": "Table 1 shows distance-based attributes between the words. We used a parser prediction file created for the source code to evaluate a hierarchical distance between two candidate words. Hierarchical distance means the maximum of two edge counts linking two predefined words to the next common clause. For example, two sibling nodes have a hierarchical distance value of one, as does a phrase header and its directly dependent word (this case is indicated by a specific feature). We used TurboParser v.2.0.0 (Martins and Almeida, 2014) and trained it on a Penn TreeBank data collection (some conversions were required to match the part of the language tag set used in the DiMSUM task)."}, {"heading": "5.4 Heuristic word features", "text": "The complete list of the different word characteristics (capitalization, punctuation, search success, etc.) is shown in Table 2."}, {"heading": "6 Results", "text": "The system configuration used as the official run for the SemEval 2016 task was parameterized as follows: Wide Layer 1 in MWE prediction perceptron = 1024 nodes; hash sum size = 16bit, calculated for both known and unknown words, using all characters in a word (Alpha + Non-Alpha); amean vector of word embeddings over the sentence was added as an additional feature; distance features are provided to the composed vector evaluator (as shown in Figure 1 with the dashed line); a confidence level of \u2212 0.15 was applied to the MWE perceptron when predicting a MWE prefix with two words (but not when extended to the third and next word, which encourages an MWE to start); the entire DiMSUM train set was used to train the system. Table 3 shows the results measured with the MSUM dictionary are also important attributes of the IR, as well as the WM short attributes of the source, which are a key WSUM short note to the IR."}, {"heading": "7 Findings & Conclusions", "text": "The system captures supersenses fairly well (considering the large number of senses, the small size of training data, and the ambiguity in the assignments of meaning), but there are often harsh miscalculations likely caused by the lack of global sense of coherence in EMBs (Qu et al., 2015), and it suffers from a lack of (other than MWE-related) context information in cases of ambiguity. Improving context awareness may be the most obvious next step. Unsurprisingly, the most common supersenses have the best memory, up to 80% for V.STATIVE. The mean recall value for sensory perceptions is about 50-60%, and there are senses (such as N.WEATHER) that are never correctly predicted. Exceptions are N.ATTRIBUTE, N.LOCATION, and V.CHANGE, where the recall is less than 30%, although they are relatively common."}], "references": [{"title": "Kyunghyun Cho", "author": ["Dzmitry Bahdanau"], "venue": "and Yoshua Bengio.", "citeRegEx": "Bahdanau et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Chris Dyer", "author": ["Trevor Cohn", "Cong Duy Vu Hoang", "Ekaterina Vymolova", "Kaisheng Yao"], "venue": "and Gholamreza Haffari.", "citeRegEx": "Cohn et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Semi-supervised training for the averaged perceptron pos tagger", "author": ["Haji\u010d", "Jan Raab", "Miroslav Spousta"], "venue": "In Proceedings of the 12th Conference of the European Chapter", "citeRegEx": "Spoustov\u00e1 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Spoustov\u00e1 et al\\.", "year": 2009}, {"title": "Priberam: A turbo semantic parser with second order features", "author": ["Martins", "Almeida2014] Andr\u00e9 FT Martins", "Mariana SC Almeida"], "venue": "In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Martins et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Wen-tau Yih", "Geoffrey Zweig"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguis-", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Nathan Schneider", "author": ["Lizhen Qu", "Gabriela Ferraro", "Liyuan Zhou", "Weiwei Hou"], "venue": "and Timothy Baldwin.", "citeRegEx": "Qu et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Paul Cook", "author": ["Bahar Salehi"], "venue": "and Timothy Baldwin.", "citeRegEx": "Salehi et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Kemal Oflazer", "author": ["Nathan Schneider", "Behrang Mohit"], "venue": "and Noah A Smith.", "citeRegEx": "Schneider et al.2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Christopher D Manning", "author": ["Richard Socher"], "venue": "and Andrew Y Ng.", "citeRegEx": "Socher et al.2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Chris Manning", "author": ["Richard Socher", "Cliff C Lin"], "venue": "and Andrew Y Ng.", "citeRegEx": "Socher et al.2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Recursive Deep Learning for Natural Language Processing and Computer Vision", "author": ["Richard Socher"], "venue": "Ph.D. thesis,", "citeRegEx": "Socher.,? \\Q2014\\E", "shortCiteRegEx": "Socher.", "year": 2014}, {"title": "Oriol Vinyals", "author": ["Ilya Sutskever"], "venue": "and Quoc V Le.", "citeRegEx": "Sutskever et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Trevor Cohn", "author": ["Ekaterina Vylomova", "Laura Rimell"], "venue": "and Timothy Baldwin.", "citeRegEx": "Vylomova et al.2015", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [], "year": 2016, "abstractText": "This paper describes an experimental approach to Detection of Minimal Semantic Units and their Meaning (DiMSUM), explored within the framework of SemEval\u201916 Task 10. The approach is primarily based on a combination of word embeddings and parserbased features, and employs unidirectional incremental computation of compositional embeddings for multiword expressions.", "creator": "LaTeX with hyperref package"}}}