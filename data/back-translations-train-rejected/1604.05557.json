{"id": "1604.05557", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2016", "title": "AGI and Reflexivity", "abstract": "We define a property of intelligent systems, which we call Reflexivity. In human beings, it is one aspect of consciousness, and an element of deliberation. We propose a conjecture, that this property is conditioned by a topological property of the processes which implement this reflexivity. These processes may be symbolic, or non symbolic e.g. connexionnist. An architecture which implements reflexivity may be based on the interaction of one or several modules of deep learning, which may be specialized or not, and interconnected in a relevant way. A necessary condition of reflexivity is the existence of recurrence in its processes, we will examine in which cases this condition may be sufficient. We will then examine how this topology and this property make possible the expression of a second property, the deliberation. In a final paragraph, we propose an evaluation of intelligent systems, based on the fulfillment of all or some of these properties.", "histories": [["v1", "Fri, 15 Apr 2016 19:39:54 GMT  (634kb)", "http://arxiv.org/abs/1604.05557v1", "submitted to ECAI-2016"], ["v2", "Wed, 20 Apr 2016 18:48:02 GMT  (343kb)", "http://arxiv.org/abs/1604.05557v2", "submitted to ECAI-2016"], ["v3", "Thu, 28 Apr 2016 18:49:12 GMT  (277kb)", "http://arxiv.org/abs/1604.05557v3", "submitted to ECAI-2016"]], "COMMENTS": "submitted to ECAI-2016", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pascal faudemay"], "accepted": false, "id": "1604.05557"}, "pdf": {"name": "1604.05557.pdf", "metadata": {"source": "CRF", "title": "AGI and reflexivity", "authors": ["Pascal Faudemay"], "emails": [], "sections": [{"heading": null, "text": "We suggest an assumption that this property is conditioned by a topological property of the processes implementing this reflexivity, which may be symbolic or non-symbolic emotions, such as the existence of artificial sentences in their processes. An architecture implementing reflexivity may be based on the interaction of one or more modules of deep learning, which may or may not be specialized, and are interconnected in a relevant way. A necessary condition of reflexivity is the existence of reflexivity in their processes, in which we will investigate in which cases this condition may be sufficient. We will then investigate how this topology and this property enable the expression of a second property, reflexivity. In a final paragraph, we propose an evaluation of intelligent systems based on the fulfillment of all or some of these certainties. INTRODUCTION1.1. The goal of general intelligence is superior intelligence."}, {"heading": "1. DELIBERATION", "text": "It is the fact that the system sentences based on those it has already produced, through reflexive processes, to produce such sentences and decide which sentences to include among them, it can move toward the external world.So it is a level of meta-inference that can be implemented through a deep learning system, or through a symbolic process, for example, derived from one of the existing pre-AGI projects.We will assume that the consultation is done through a neural subsystem, related to B, which receives as input the productions of the previously defined reflexive system, and produces as output a flow of sentences (or general files) or actions through which it communicates with its environment. In this scheme we have: IN the input unit, of one character (one byte, or possibly two bytes, if we want complex Unicode characters) - 3 -A0.. One: a systolic vector A and B: two recursive neurons."}, {"heading": "2. MODALITIES", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "3. ARCHITECTURE", "text": "The architecture of the intelligent system we are looking at here is characterized by a first level of n memory cells, resulting in a 1D systolic network into which the user enters one character after the other. This network may be connected to a stack of n registers with n characters each. Operations on this stack will be a subset of the actions of the system.The n cells of the first layer will be connected to jmax layers of h (j) neurons and form a recursive network.The output of layer jmax includes, first, the k actions of the system and, second, an output of c characters. Both elements form the feedback loop of the system and will be connected to its input layer, in addition to the set contained in the first n memory cells. The relevance of the coupling of this unit with another equivalent recurring unit according to the scheme of paragraph 3 shall allow for a certain degree of reasoning. It will be the subject of further experiments."}, {"heading": "4. INITIALIZATIONS", "text": "Initialization takes place through the choice of a global architecture among the few previously presented variants, and the meta-parameters such as the number of neurons per layer, the number of neurons per layer and cognitive area, the projections between cognitive areas, the initial synaptic weights. The functions that reflect the bias depending on the level of the different emotions will also be part of the initializations. We assume that when the list of connections is defined, the initial weights are drawn according to a simple law that is yet to be defined. It is possible to develop these meta parameters by using an evolutionary program. However, this leads to two questions: First, the choice of a success criterion of a set of parameters, such a criterion is necessary to guide the evolutionary program."}, {"heading": "5. EXPERIMENTATION", "text": "An implementation of the system in Python is planned for the next few months, it will use Theano libraries and should be implemented first in an OS X environment with relatively low computing power, then in a CUDA or OpenCL environment on a Mac Pro with a D700 graphics card (more than 4000 GPU cores), the possibility of implementing some of the initial development and experimentation on Ubuntu is also being considered as an alternative solution, and the goal of the experiment will be to develop a system that should be able to learn the basics of text available from Wikipedia and the Internet and participate in a process of query and answer, the system should learn the concepts and values associated with multiple authors, and be able to take them into account in order to evaluate questions and answers. We believe that this consideration of the discussion partner model is indispensable for masterful learning of the outside world."}, {"heading": "6. REFLEXIVITY EVALUATION.", "text": "We believe that the proposed architecture is minimal in order to achieve a perceptible degree of reflexivity. Let us remember that our goal is not to realize a \"conscious\" system, but to simulate some characteristics of human cognitive systems and some superior animals (primates, mammals, some birds...) or perhaps some simpler animals (Drosophila, honeybee). [9, 12] We propose the following conjectures: conjecture 1."}, {"heading": "A necessary condition for a neuron network to implement a reflexive system is that it should possess the properties described in paragraph 2.", "text": "Guess 2."}, {"heading": "A sufficient condition for an AGI to be a complete reflexive autonomous system is that it would possess all the properties", "text": "Note that an AGI can be a complete reflective system without being an autonomous one. We should also emphasize the fact that, in our opinion, the state of conjecture 2 is sufficient but not necessary. We will need to refine the analysis and experiment to achieve necessary and sufficient conditions. We will provide a reflectivity index that evaluates the satisfaction of the conditions set forth in paragraphs 2 to 4.14 to determine the degree to which an intelligent system is reflective. It will be possible to compare this index with subjective assessments of system intelligence, such as those resulting from turing tests or other measures of the effectiveness of an AGI. The composition of the reflectivity index will be the subject of further research.Conjection3. The properties of a fully reflective AGI or a fully autonomous AGI can be either with a neural system or with a partial or symbolic system that implements such a system that does not seem to disturb us with a symbolic system."}, {"heading": "7. CONCLUSION", "text": "In this paper, we have proposed various conjectures about the properties of a neural network, or possibly a symbolic architecture, in order to implement a reflective and advisory system and possibly a reflective and autonomous system. In the coming months, we intend to experiment with a neural architecture that exhibits these characteristics; the neural network that is implemented will not exceed the cardinality of the neural system of a Drosophila or possibly of a honeybee, i.e. cardinalities between 30 k and a million neurons, and a number of weights between 30 and 10 billion, or more likely no more than a billion weights.However, with a certain topology, this system should be applicable to problems that interest people, such as summarizing Wikipedia pages or participating in a query and response system."}, {"heading": "ACKNOWLEDGEMENTS", "text": "The author thanks Jean-Fran\u00e7ois Perrot and Francis Wolinski for their useful comments."}], "references": [{"title": "B", "author": ["S.S. Adams", "I. Arel", "J. Bach", "R. Coop", "R. Furlan"], "venue": "Goertzel, et al., Mapping the Landscape of Human-Level Artificial General Intelligence, AI Magazine, Spring", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "A cognitive theory of consciousness", "author": ["B. Baar"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1993}, {"title": "Modeling Motivation in MicroPsi2, in Artificial General Intelligence", "author": ["J. Bach"], "venue": "Proceedings 8th International Conference,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Our Final Invention: Artificial Intelligence and the End of the Human Era, Thomas Dunne Books", "author": ["J. Barrat"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Facing Up the Problem of Consciousness", "author": ["D.J. Chalmers"], "venue": "Journal of Consciousness Studies,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Consciousness and the Brain: Deciphering How the Brain Codes our Thoughts", "author": ["S. Dehaene"], "venue": "Penguin Books,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Behavioral Responses to a Repetitive Visual Threat Stimulus Express a Persistent State of Defensive Arousal in Drosophila", "author": ["W.T. Gibson"], "venue": "Current Biology,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Artificial General Intelligence: Concept, State of the Art, and Future Prospects", "author": ["B. Goertzel"], "venue": "Journal of Artificial General Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Reconnaissance des visages : l'ordinateur devrait imiter... les abeilles (in French) 2-2-2009, in www.futura-sciences.com", "author": ["J.-L. Goudet"], "venue": "consulte\u0301 le 20-5-2015", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Transcendence looks at the implications of artificial intelligence. But are we taking AI seriously enough ", "author": ["S. Hawking"], "venue": "The Independent,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets, Facebook AI Research, arXiv:1503.01007v4 [cs.NE] 1 Jun 2015", "author": ["A. Joulin", "T. Mikolov"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "The Unreasonable Effectiveness of Recurrent Neural Networks, in Andrej", "author": ["A. Karpathy"], "venue": "Karpathy blog,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Neural RandomAccess Machines, Google, arXiv1511.06392v2 [cs.LG", "author": ["K. Kurach", "M. Andrychowicz", "I. Sutskever"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "L\u2019apprentissage profond, cours au Coll\u00e8ge de France, chaire", "author": ["Y. Le Cun"], "venue": "Informatique et Sciences Nume\u0301riques,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "A new three-dimensional model for emotions and monoamine neuro-transmitters, Med", "author": ["H. L\u00f6vheim"], "venue": "Hypotheses,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Making Robots Conscious of their Mental States, Stanford", "author": ["J. McCarthy"], "venue": "http://wwwformal.stanford.edu/jmc/ published in Machine Intelligence", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Awareness and Understanding in Computer Programs, a Review of \u201cShadows of the Mind", "author": ["J. McCarthy"], "venue": "by Roger Penrose, Psyche,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1995}, {"title": "The Emotion Machine (Commonsense thinking, artificial intelligence and the future of the human mind)", "author": ["M. Minsky"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Recurrent Models of Visual Attention, Google DeepMind, arXiv:1406.6247v1 [cs.LG", "author": ["V. Mnih", "N. Hees", "A. Graves", "K. Kavukcuoglu"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Les abeilles, bonnes physionomistes", "author": ["J.-Y. Nau"], "venue": "Slate,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "The Emperor\u2019s New Mind, Oxford Univ", "author": ["R. Penrose"], "venue": "Press, Oxford, UK,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1989}, {"title": "J", "author": ["A. Potapov"], "venue": "Bieger, editors, Artificial General Intelligence, 8 Int\u2019l Conference, AGI", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Creating Human Level AI by Educating a Child Machine, in The Convergence of Machine and Biological Intelligence", "author": ["R. Reddy"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Using Stories to Teach Human Values to Artificial Agents, Georgia", "author": ["M.O. Riedl", "B. Harrison"], "venue": "Institute of Technology,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Deep Learning In Neural Networks, an Overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "A peine lanc\u00e9e, une intelligence artificielle de Microsoft d\u00e9rape sur Twitter, Le Monde.fr", "author": ["M. Tual"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Grammar as a Foreign Language, Google, arXiv:1412.7449v3 [cs.CL", "author": ["Vinyls Oriol", "Kaiser Lukasz", "Koo Terry", "Petrov Slav", "Sutskever Ilya", "Hinton Geoffrey"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Motivation Management in AGI Systems, Temple University, Philadelphia, USA, Proceedings of AGI-12, Oxford, UK, December 2012", "author": ["P. Wang"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Analogy in a General Purpose Reasoning System", "author": ["P. Wang"], "venue": "Cognitive Systems Research,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}, {"title": "Artificial Intelligence as a Positive and Negative Factor in Global Risk, in Global Catastrophic Risks, edited by Nick Bostr\u00f6m and Milan M \u0106ircovi\u0107", "author": ["E. Yudkowzky"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Creating Friendly AI 1.0 : The Analysis and Design of Benevolent Goal Architectures, The Singularity Institute, San Francisco", "author": ["E. Yudkowsky"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2001}, {"title": "Complex Value Systems In Friendly AI, Artificial General Intelligence 4 International Conference, AGI 2011, USA", "author": ["E. Yudkowsky"], "venue": "Proceedings, in LNCS", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "General Intelligence and Seed AI-Creating Complete Minds Capable of Open-Ended Self-Improvement", "author": ["E. Yudkowsky"], "venue": "Research report, MIRI,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2001}, {"title": "I", "author": ["W. Zaremba"], "venue": "Sutskever, Reinforcement Learning Neural Turing Machines (revised), Facebook AI Research & Google Brain, submitted to ICLR", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "An AGI may also designate a prototype of an Artificial General Intelligence, more or less close to the goals of this field [4, 11, 33].", "startOffset": 123, "endOffset": 134}, {"referenceID": 28, "context": "An AGI may also designate a prototype of an Artificial General Intelligence, more or less close to the goals of this field [4, 11, 33].", "startOffset": 123, "endOffset": 134}, {"referenceID": 32, "context": "It may also be a seed AGI (or Baby AGI), with a limited initial knowledge or even intelligence, but a good learning capability [38].", "startOffset": 127, "endOffset": 131}, {"referenceID": 13, "context": "An intelligent system implemented by a neural network [18] is reflexive if it has the following properties :", "startOffset": 54, "endOffset": 58}, {"referenceID": 11, "context": "The properties displayed by equations (1) to (4) define the network as a recurrent neural network (RNN) [16, 18].", "startOffset": 104, "endOffset": 112}, {"referenceID": 13, "context": "The properties displayed by equations (1) to (4) define the network as a recurrent neural network (RNN) [16, 18].", "startOffset": 104, "endOffset": 112}, {"referenceID": 11, "context": "(Andrej Karpathy,2015, [16]).", "startOffset": 23, "endOffset": 27}, {"referenceID": 10, "context": "These external memories do not necessarily need to be limited to a register stack [15, 17].", "startOffset": 82, "endOffset": 90}, {"referenceID": 12, "context": "These external memories do not necessarily need to be limited to a register stack [15, 17].", "startOffset": 82, "endOffset": 90}, {"referenceID": 5, "context": "Perceptions and states of consciousness which are accompanied by a more intense emotion, are more memorized than those accompanied by a less intense emotion [8, 20, 22].", "startOffset": 157, "endOffset": 168}, {"referenceID": 15, "context": "Perceptions and states of consciousness which are accompanied by a more intense emotion, are more memorized than those accompanied by a less intense emotion [8, 20, 22].", "startOffset": 157, "endOffset": 168}, {"referenceID": 17, "context": "Perceptions and states of consciousness which are accompanied by a more intense emotion, are more memorized than those accompanied by a less intense emotion [8, 20, 22].", "startOffset": 157, "endOffset": 168}, {"referenceID": 14, "context": "L\u00f6vheim [19] proposes a representation of emotions by a cube, as a function of the presence or absence of three neuromediators, dopamin, noradrenalin and serotonin, which have a specially important role.", "startOffset": 8, "endOffset": 12}, {"referenceID": 6, "context": "Indeed, the neuromediators which are present in humans are also present in mammals, and fear or even anxiety can also be observed, even in drosophila [9].", "startOffset": 150, "endOffset": 153}, {"referenceID": 17, "context": "- 4 several emotions [22].", "startOffset": 21, "endOffset": 25}, {"referenceID": 28, "context": "For examples of approximate inference and of blending in symbolic or partially symbolic architectures, the reader may refer to the works of projects like NARS or OpenCog [11, 33].", "startOffset": 170, "endOffset": 178}, {"referenceID": 24, "context": "The interest of a neuronal approach for AGI is underlined by the works of Schmidhuber [29].", "startOffset": 86, "endOffset": 90}, {"referenceID": 3, "context": "There would often be a risk that the system would escape the control of its designer, as people do not necessarily understand the reasoning which can be made by the system, when it is implemented with a neuronal architecture, or even with a symbolic one [5, 6, 13, 32, 37].", "startOffset": 254, "endOffset": 272}, {"referenceID": 9, "context": "There would often be a risk that the system would escape the control of its designer, as people do not necessarily understand the reasoning which can be made by the system, when it is implemented with a neuronal architecture, or even with a symbolic one [5, 6, 13, 32, 37].", "startOffset": 254, "endOffset": 272}, {"referenceID": 27, "context": "There would often be a risk that the system would escape the control of its designer, as people do not necessarily understand the reasoning which can be made by the system, when it is implemented with a neuronal architecture, or even with a symbolic one [5, 6, 13, 32, 37].", "startOffset": 254, "endOffset": 272}, {"referenceID": 31, "context": "There would often be a risk that the system would escape the control of its designer, as people do not necessarily understand the reasoning which can be made by the system, when it is implemented with a neuronal architecture, or even with a symbolic one [5, 6, 13, 32, 37].", "startOffset": 254, "endOffset": 272}, {"referenceID": 2, "context": "In a very interesting approach, Joscha Bach [3, 4] proposes to derive at any time the goals of an AGI from a set of needs, which include the needs of existence (access to calculation means, energy, cooling,.", "startOffset": 44, "endOffset": 50}, {"referenceID": 30, "context": "This theory may enable AGI designers to escape to the various problems of a direct goals definition [36].", "startOffset": 100, "endOffset": 104}, {"referenceID": 18, "context": ", if the system has a vision capability, with some part in high definition, and some part in low definition, the informations of the low definition part will enable the system to focus the high definition part within the vision field [23].", "startOffset": 234, "endOffset": 238}, {"referenceID": 11, "context": "An example of this property is given by Andrej Karpathy [16], for the access to hand-written characters which are spread on a page, by using a convolutive neural network with a size which is independent of the size of the page.", "startOffset": 56, "endOffset": 60}, {"referenceID": 25, "context": "We may consider that if there had been an imprinting mechanism or an image of third parties in Tay, the intelligent system experimented by Microsoft on Twitter, this system would have identified the discourse of hostile third parties or of people with values opposed to those of its group or designers, and would have limited it to these third parties [30].", "startOffset": 352, "endOffset": 356}, {"referenceID": 10, "context": "These interfaces may enable an access to sets of registers, stacks, or random access memory [15, 17, 38].", "startOffset": 92, "endOffset": 104}, {"referenceID": 12, "context": "These interfaces may enable an access to sets of registers, stacks, or random access memory [15, 17, 38].", "startOffset": 92, "endOffset": 104}, {"referenceID": 32, "context": "These interfaces may enable an access to sets of registers, stacks, or random access memory [15, 17, 38].", "startOffset": 92, "endOffset": 104}, {"referenceID": 29, "context": "Secondly, Eliezer Yudkowsky stresses the risk, if an AGI is defined by an evolutionary program, that it would escape to the control of its designers [35, 36].", "startOffset": 149, "endOffset": 157}, {"referenceID": 30, "context": "Secondly, Eliezer Yudkowsky stresses the risk, if an AGI is defined by an evolutionary program, that it would escape to the control of its designers [35, 36].", "startOffset": 149, "endOffset": 157}, {"referenceID": 8, "context": "It might not be the case for cardinalities about or above one million neurons, comparable to very evolved insects like the honey bee, which can recognize faces and have complex social behavior [12].", "startOffset": 193, "endOffset": 197}, {"referenceID": 6, "context": "), or maybe of some simpler animals (drosophila, honeybee) [9, 12].", "startOffset": 59, "endOffset": 66}, {"referenceID": 8, "context": "), or maybe of some simpler animals (drosophila, honeybee) [9, 12].", "startOffset": 59, "endOffset": 66}], "year": 2016, "abstractText": "We define a property of intelligent systems, which we call Reflexivity. In human beings it is one aspect of consciousness, and an element of deliberation. We propose a conjecture, that this property is conditioned by a topological property of the processes which implement this reflexivity. These processes may be symbolic, or non symbolic e.g. connexionnist. An architecture which implements reflexivity may be based on the interaction of one or several modules of deep learning, which may be specialized or not, and interconnected in a relevant way. A necessary condition of reflexivity is the existence of recurrence in its processes, we will examine in which cases this condition may be sufficient. We will then examine how this topology and this property make possible the expression of a second property, the deliberation. In a final paragraph, we propose an evaluation of intelligent systems, based on the fulfillment of all or some of these properties.", "creator": "Microsoft\u00ae Word 2016"}}}