{"id": "1604.08095", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2016", "title": "Accent Classification with Phonetic Vowel Representation", "abstract": "Previous accent classification research focused mainly on detecting accents with pure acoustic information without recognizing accented speech. This work combines phonetic knowledge such as vowels with acoustic information to build Guassian Mixture Model (GMM) classifier with Perceptual Linear Predictive (PLP) features, optimized by Hetroscedastic Linear Discriminant Analysis (HLDA). With input about 20-second accented speech, this system achieves classification rate of 51% on a 7-way classification system focusing on the major types of accents in English, which is competitive to the state-of-the-art results in this field.", "histories": [["v1", "Wed, 24 Feb 2016 02:50:44 GMT  (779kb,D)", "http://arxiv.org/abs/1604.08095v1", "Asian Conference on Pattern Recognition (ACPR) 2015"]], "COMMENTS": "Asian Conference on Pattern Recognition (ACPR) 2015", "reviews": [], "SUBJECTS": "cs.SD cs.CL", "authors": ["zhenhao ge", "yingyi tan", "aravind ganapathiraju"], "accepted": false, "id": "1604.08095"}, "pdf": {"name": "1604.08095.pdf", "metadata": {"source": "CRF", "title": "Accent Classification with Phonetic Vowel Representation", "authors": ["Zhenhao Ge", "Yingyi Tan", "Aravind Ganapathiraju"], "emails": ["aravind.ganapathiraju}@inin.com"], "sections": [{"heading": "1. Introduction", "text": "Improving voice recognition for accented speakers is becoming increasingly important as companies become stronger. However, handling calls is still a major challenge for companies specializing in voice recognition services. It requires accurate and efficient accentuation of the algorithm that can identify the accent of the call in a short time."}, {"heading": "2. Data Preparation", "text": "The database used here for the development of accent classifiers is a foreign word from English (FAE).It was originally collected by the Center for Language and Language Learning (CSLU) at Oregon Health & Science University (OHSU).It contains 4925 sentences over 20 seconds, of which 23 types of accents.We group them into 7 regional accents and one type of accent in each group has been selected to develop a 7-way accent classifier, including Arabic (AR), Brazilian (FR), German (GE), Hindi (HI), Mandarin (MA) and Russian (RU).1 provides a summary of these accents with the number of utterances in the FAE corpus."}, {"heading": "3. Vowel Representation", "text": "Inspired by the work of Minematsu et al. [13] and Suzuki et al. [15], where they measured the overall structure of the speaker's loudspeaker space, one can obtain some kind of accent-adapted characteristics by extracting vowels from the speaker room and using them to identify accents. For each accented version of a target language, such as English, it is assumed that the characteristics of the five basic vowels are relatively constant in the feature space. In Fig. 2, the first two feature dimensions are taken to illustrate the position of five vowels in accentuated and unaccentuated (standard) languages [13]. The center in each pentagon is the weighted average of five vowels based on their position in the feature space and the frequency of occurrence in the corpus. By placing the pentagon of the standard and accentuated language in the overlapped pentagon in the lower part of the appendix."}, {"heading": "4. Baseline with Pure Acoustic Information", "text": "As mentioned in paragraph 1, the system of baseline accent classification is implemented with GMM classifiers, whereby the PLP function is optimized on a discriminatory basis. It is a generalization of the LDA that allows characteristics to have different deviations in different feature dimensions. Here, we briefly describe the key components of GMM, LDA and HLDA and then discuss the implementation and results of the baseline."}, {"heading": "4.1. GMM Classifer", "text": "Motivated by the method of modeling the attributes of the speakers using Gaussian Mixture Models (GMMs) is in [6], here we use GMMs to model the attributes of the accents. Gaussian Mixture density models the characteristic distribution of each accent as a weighted sum of multiple Gaussian distributions. Given series feature x in M \u00b7 K attribute matrix X, where M attribute dimension and K is the number of attribute vectors, in the probability of x can asp (x) = N = 1 Wibi (x), (3) where N is the number of mixing components p, andbi (x) is the number of attribute vectors p."}, {"heading": "4.2. LDA and HLDA", "text": "Compared to Principles Component Analysis (PCA), which transforms data into intrinsic space and maintains data dimensions with greater variation [5], Linear Discriminant Analysis (LDA) reduces dimensions by mapping the data into a subspace while maximizing discriminatory information. Suppose there were K = K's number of M-dimensional data vectors xk in the S-classes, where Ks is the number of vectors in class s. Let's consider the global mean across all classes as K K k xk and the local ratios for each class s as the definition of dimensions."}, {"heading": "4.3. Results for Baseline", "text": "The diagram of 7-way accent classification based on pure acoustic information is used in Figure 4. PLPHLDA features with context size 1 and reduced dimension 20. Context factor is used to duplicate features for potential performance enhancement. For example, context size 1 extends the original feature frame by concatenating 1 left and 1 right frame. Both the GMM classifier and the enhanced GMM-HLDA classifier have been trained with features of various accent types of 256 Gaussian mixtures. These parameters, including the order of GMM, feature dimensions in PLP and HLDA, and context size, have been optimized with the development kit. Performance on the test kit achieves 40% and 46% accuracy with the help of GMM classifier and GMMHLDA classifier."}, {"heading": "5. Improved with Vowel Representation", "text": "To construct the classifier with vowel representation, instead of directly measuring the vowel change from standard speech to emphasis, the same vowels of different accent types are formed as separate GMMs; instead of using only the basic 5 vowels described in Sec. 3, Tab. 2, the vowels in Arpabet vowels aa ah ao aw ay eh er are used. Example father fast sun hot how my red bird vowel ey ih iy ow oy uh uw example say big meet boy book foodsame concept and all 15 vowels listed in Arpabet aa ah aw ay eh er. Example father fast sun hot how my red bird vowels ey ih iy ow oy oy uw example say big boy meet foodsame concept is and all 15 vowels listed in Arpabet [16] are used in Tab. 2."}, {"heading": "5.1. Phoneme Alignment and Recognition", "text": "In system development, with the partially internal transcriptions of the speech of 7 main accents, a dictionary is created that is needed for the phoneme alignment with HVite in HTK. Fig. 5 demonstrates the process of dictionary preparation and phoneme alignment for FAE. The dictionary file is a list of word-pronunciation pairs in HTK format that can be obtained through the process of word collection, word-to-pronunciation conversion with an in-house lexicon tester and the creation of HTK dictionaries. In the phoneme alignment, the HTK configuration file, the HMM model definition and the fatigue list are all trained with Fisher corpus. In the system test, since no transcription is available, functions that correspond with vowels are found, accentuated language with HTK and only a subset of recognized vowels with a certain degree of trust are defined on the basis of log-probability."}, {"heading": "5.2. Results for Improved Classifier", "text": "Here, 39-dimensional PLP features with MVNs are used in the implementation of accent classification. After training GMMs on separate vowels, GMMs with 7 vowels are selected for this accent. Overall classification accuracy is 50.9%, which is 4.5% improvement over the HLDA-trained GMM classifier. Tab. 3 compares the performance of all three methods. The combination of classifier and characteristics includes a) GMMs with PLP, trained per accent; b) GMMs with HDLA (20 dimensions with context size 1, optimized for 39-dimensional PLP), trained per accent; and c) GMMs with HLDA, trained per accent and per vowel. Accuracy is obtained from accentuated speech over 20-second duration and is competitive compared to 39-dimensional PLP), trained per accent; and c) GMMs with HLDA, trained per accent and accent."}, {"heading": "6. Summary and Future Work", "text": "This paper demonstrates the improvement of classification accuracy through HLDA feature optimization and vowels extracted from accented language for the development of GMM classifiers. There are at least several areas that can be addressed for further improvements. Firstly, more complex classifiers such as deep neural network classifiers [9, 7] can also be used for accent classification [11]. Secondly, because the data for each accent is very limited, a universal classifier based on Restricted Boltzmann Machine (RBM) can be researched instead of traditional GMMs for each accent [11]. RBM is trained on data from all accents, with the ability to deviate with different accents. Thirdly, accent clustering based on specific distance measurements such as Bhattacharyya distance [1] can also be used to pre-classify accents into multiple clusters, which can potentially help narrow the scope of search and improve all accents with equal classification patterns."}], "references": [{"title": "On a measure of divergence between two multinomial populations", "author": ["A. Bhattacharyya"], "venue": "Sankhya\u0304: The Indian Journal of Statistics (1933-1960),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1946}, {"title": "An empirical study of automatic accent classification", "author": ["G. Choueiter", "G. Zweig", "P. Nguyen"], "venue": "In ICASSP", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "PLP and RASTA (and MFCC, and inversion) in MATLAB. http://labrosa.ee.columbia.edu/ matlab/rastamat", "author": ["D. Ellis"], "venue": "Ac essed 2015-07-01", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Mispronunciation detection for language learning and speech recognition adaptation", "author": ["Z. Ge"], "venue": "Ph.D. dissertation, Purdue University West Lafayette,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Pca method for automated detection of mispronounced words. In SPIE Defense, Security, and Sensing, pages 80581D\u201380581D", "author": ["Z. Ge", "S.R. Sharma", "M.J. Smith"], "venue": "International Society for Optics and Photonics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "PCA/LDA approach for text-independent speaker recognition", "author": ["Z. Ge", "S.R. Sharma", "M.J. Smith"], "venue": "In Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Sleep stages classification using neural networks with multi-channel neural data", "author": ["Z. Ge", "Y. Sun"], "venue": "In Brain Informatics and Health,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "A method for silence removal and segmentation of speech signals, implemented in matlab", "author": ["T. Giannakopoulos"], "venue": "University of Athens, Athens,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A.-r. Mohamed", "G. Hinton"], "venue": "In ICASSP. IEEE,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Investigation of silicon auditory models and generalization of linear discriminant analysis for improved speech recognition", "author": ["N. Kumar", "A.G. Andreou"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "Acoustic adaptation and accent identification in the ICSI MR and FAE corpora", "author": ["J. Mac\u00edas-Guarasa"], "venue": "In ICSI Meeting slides,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Yet another acoustic representation of speech sounds", "author": ["N. Minematsu"], "venue": "In ICASSP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "A novel approach to detecting non-native speakers and their native language", "author": ["M.K. Omar", "J. Pelecanos"], "venue": "In ICASSP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Improved structure-based automatic estimation of pronunciation proficiency", "author": ["M. Suzuki", "L. Dean", "N. Minematsu", "K. Hirose"], "venue": "Proc. SLaTE,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}], "referenceMentions": [{"referenceID": 1, "context": "achieved 32% classification rate on 23-way classification of accented English [2], using methods such as Maximum Mutual Information (MMI) training and Gaussian tokenization.", "startOffset": 78, "endOffset": 81}, {"referenceID": 1, "context": "used Support Vector Machine (SVM) classifier integrated with Universal Background Model (UBM) and claimed they outperformed the results in [2] by 75.", "startOffset": 139, "endOffset": 142}, {"referenceID": 12, "context": "3% relatively [14].", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "Another work in [12] reported classification rates of 73% and 58.", "startOffset": 16, "endOffset": 20}, {"referenceID": 1, "context": "With the partial transcription of the database for 7 major types of accents, which is absent in [2] and [12], the vowels are extracted and with these phonetic information, the classification rate of 7-way classification is improved from 46% to 51%, compared with the baseline.", "startOffset": 96, "endOffset": 99}, {"referenceID": 10, "context": "With the partial transcription of the database for 7 major types of accents, which is absent in [2] and [12], the vowels are extracted and with these phonetic information, the classification rate of 7-way classification is improved from 46% to 51%, compared with the baseline.", "startOffset": 104, "endOffset": 108}, {"referenceID": 3, "context": "This work was initiated during the first author\u2019s internship at Interactive Intelligence [4].", "startOffset": 89, "endOffset": 92}, {"referenceID": 7, "context": "Data from these accents were then preprocessed with silence removal by thresholding on its short-time energy rate and spectral centroids, using method in [8].", "startOffset": 154, "endOffset": 157}, {"referenceID": 2, "context": "The silence-removed data of the selected accents were then converted to 39-dimensional PLP features [3].", "startOffset": 100, "endOffset": 103}, {"referenceID": 11, "context": "[13] and Suzuki et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15], where they measured the overall structure of the speaker\u2019s phonetic space, one type of accent-adapted features can be obtained by extracting vowels from speech and use them to identify accents.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "2, the first two feature dimensions are taken to illustrate the position of five vowels in accented and non-accented (standard) languages [13].", "startOffset": 138, "endOffset": 142}, {"referenceID": 0, "context": "2, the Bhattacharyya distances [1] between each pair of corresponding vowels and their angles can be computed and stored in a vector.", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "Motivated by the method of modeling attributes of speakers using Gaussian Mixture Models (GMMs) in [6], here we use GMMs to model the attributes of accents.", "startOffset": 99, "endOffset": 102}, {"referenceID": 4, "context": "Compared with Principle Component Analysis (PCA), which transforms data into eigenspace and preserves the data dimensions with larger variation [5], Linear Discriminant Analysis (LDA) reduces dimensions by mapping data into a subspace while maximizing the discriminative information.", "startOffset": 144, "endOffset": 147}, {"referenceID": 9, "context": "This work uses Kumar\u2019s method [10] to generalize LDA to HLDA using Maximum Likelihood Estimation (MLE) on Gaussian distributions.", "startOffset": 30, "endOffset": 34}, {"referenceID": 1, "context": "The accuracy is obtained from accented speech about 20-second duration, and is competitive compared with the state-of-art results in [2], [14] and [12].", "startOffset": 133, "endOffset": 136}, {"referenceID": 12, "context": "The accuracy is obtained from accented speech about 20-second duration, and is competitive compared with the state-of-art results in [2], [14] and [12].", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "The accuracy is obtained from accented speech about 20-second duration, and is competitive compared with the state-of-art results in [2], [14] and [12].", "startOffset": 147, "endOffset": 151}, {"referenceID": 8, "context": "First, more sophisticated classifiers such as deep neural network classifier [9, 7] may also be used for accent classification.", "startOffset": 77, "endOffset": 83}, {"referenceID": 6, "context": "First, more sophisticated classifiers such as deep neural network classifier [9, 7] may also be used for accent classification.", "startOffset": 77, "endOffset": 83}, {"referenceID": 0, "context": "Third, accent clustering based on certain distance measurements, such as Bhattacharyya distance [1] can also be used to pre-classify accents into several clusters, which may potentially help narrow down the search scope and improve the classification accuracy.", "startOffset": 96, "endOffset": 99}], "year": 2016, "abstractText": "Previous accent classification research focused mainly on detecting accents with pure acoustic information without recognizing accented speech. This work combines phonetic knowledge such as vowels with acoustic information to build Guassian Mixture Model (GMM) classifier with Perceptual Linear Predictive (PLP) features, optimized by Hetroscedastic Linear Discriminant Analysis (HLDA). With input about 20-second accented speech, this system achieves classification rate of 51% on a 7-way classification system focusing on the major types of accents in English, which is competitive to the state-of-the-art results in this field.", "creator": "LaTeX with hyperref package"}}}