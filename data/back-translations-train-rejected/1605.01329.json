{"id": "1605.01329", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-May-2016", "title": "Single Channel Speech Enhancement Using Outlier Detection", "abstract": "Distortion of the underlying speech is a common problem for single-channel speech enhancement algorithms, and hinders such methods from being used more extensively. A dictionary based speech enhancement method that emphasizes preserving the underlying speech is proposed. Spectral patches of clean speech are sampled and clustered to train a dictionary. Given a noisy speech spectral patch, the best matching dictionary entry is selected and used to estimate the noise power at each time-frequency bin. The noise estimation step is formulated as an outlier detection problem, where the noise at each bin is assumed present only if it is an outlier to the corresponding bin of the best matching dictionary entry. This framework assigns higher priority in removing spectral elements that strongly deviate from a typical spoken unit stored in the trained dictionary. Even without the aid of a separate noise model, this method can achieve significant noise reduction for various non-stationary noises, while effectively preserving the underlying speech in more challenging noisy environments.", "histories": [["v1", "Wed, 4 May 2016 16:16:12 GMT  (611kb,D)", "http://arxiv.org/abs/1605.01329v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["eunjoon cho", "bowon lee", "ronald schafer", "bernard widrow"], "accepted": false, "id": "1605.01329"}, "pdf": {"name": "1605.01329.pdf", "metadata": {"source": "CRF", "title": "SINGLE CHANNEL SPEECH ENHANCEMENT USING OUTLIER DETECTION", "authors": ["Eunjoon Cho", "Bowon Lee", "Ronald Schafer", "Bernard Widrow"], "emails": [], "sections": [{"heading": null, "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "2.1. Dictionary training", "text": "Considering a clean speech set, x (n), the Magnitude Square Transform (STFT) is calculated to estimate the power. Magnitude Square STFT can be called | Xm (k) | 2, where k is the Discrete Fourier Transform (DFT) Frequency bin and m is the Frame Index. | Xm (k) | 2 is normalized so that the average power of a time-frequency waste bin over a training set is 1. The normalized spectrum is called | X (k), A \u00b7 Xm (k) | 2, where A is the normalization constant. The purpose of this stage is to compensate for the amplitude difference of the recordings by different loudspeakers. However, this standardization only corrects the scalar multiplication of the loudspeaker inputs and does not necessarily correct the differences in perceived volume or filtering effects."}, {"heading": "2.2. Speech enhancement using the outlier framework", "text": "It is the only way we can think of when we go on a search to find the best response, and one sentence refers to a sample from the TIMIT database, since it is also used for the clusters that provide the training data. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (a) It is the best response in the TIMIT database. (b) It is the best response in the TIMIT database. (b) It is the best response in the IMIT database. (b) It is the best response in the IMIT. (b) It is the best response in the IMIT database. (b) It is the best in the IMIT. (b) It is the best response in the IMIT. (b) It is in the IMIT."}], "references": [{"title": "Noise power spectral density estimation based on optimal smoothing and minimum statistics", "author": ["Rainer Martin"], "venue": "Speech and Audio Processing, IEEE Transactions on, vol. 9, no. 5, pp. 504\u2013512, 2001.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "Noise spectrum estimation in adverse environments: Improved minima controlled recursive averaging", "author": ["Israel Cohen"], "venue": "Speech and Audio Processing, IEEE Transactions on, vol. 11, no. 5, pp. 466\u2013475, 2003.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Unbiased mmse-based noise power estimation with low complexity and low tracking delay", "author": ["Timo Gerkmann", "Richard C Hendriks"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 20, no. 4, pp. 1383\u20131393, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator", "author": ["Yariv Ephraim", "David Malah"], "venue": "Acoustics, Speech and Signal Processing, IEEE Transactions on, vol. 32, no. 6, pp. 1109\u2013 1121, 1984.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1984}, {"title": "Speech enhancement based on a priori signal to noise estimation", "author": ["Pascal Scalart"], "venue": "Acoustics, Speech, and Signal Processing, 1996. ICASSP-96. Conference Proceedings., 1996 IEEE International Conference on. IEEE, 1996, vol. 2, pp. 629\u2013632.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "Codebook driven short-term predictor parameter estimation for speech enhancement", "author": ["Sriram Srinivasan", "Jonas Samuelsson", "W Bastiaan Kleijn"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 14, no. 1, pp. 163\u2013176, 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Model-based monaural source separation using a vector-quantized phase-vocoder representation", "author": ["Daniel PW Ellis", "Ron J Weiss"], "venue": "Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on. IEEE, 2006, vol. 5, pp. V\u2013V.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "A corpus-based approach to speech enhancement from nonstationary noise", "author": ["Ji Ming", "Ramji Srinivasan", "Danny Crookes"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 19, no. 4, pp. 822\u2013836, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Speech enhancement by online non-negative spectrogram decomposition in non-stationary noise environments", "author": ["Zhiyao Duan", "Gautham J Mysore", "Paris Smaragdis"], "venue": "INTERSPEECH, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech enhancement using generative dictionary learning", "author": ["Christian D Sigg", "Tomas Dikk", "Joachim M Buhmann"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 20, no. 6, pp. 1698\u2013 1712, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "A new metric for vq-based speech enhancement and separation", "author": ["Mads Gr\u00e6sb\u00f8ll Christensen", "Pejman Mowlaee"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 4764\u20134767.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Convolutive speech bases and their application to supervised speech separation", "author": ["Paris Smaragdis"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 15, no. 1, pp. 1\u201312, 2007.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "A nonnegative approach to semi-supervised separation of speech from noise with the use of temporal dynamics", "author": ["Gautham J Mysore", "Paris Smaragdis"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 17\u201320.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Exploiting speech structure for noise estimation in single channel speech enhancement", "author": ["Eunjoon Cho"], "venue": "Ph.D. thesis, Stanford University,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "An evaluation of noise power spectral density estimation algorithms in adverse acoustic environments", "author": ["Jalal Taghia", "N Mohammadiha", "Jinqiu Sang", "V Bouse", "R Martin"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 4640\u20134643.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Darpa timit acoustic-phonetic continous speech corpus cd-rom. nist speech disc 1-1.1", "author": ["John S Garofolo", "Lori F Lamel", "William M Fisher", "Jonathon G Fiscus", "David S Pallett"], "venue": "NASA STI/Recon Technical Report N, vol. 93, pp. 27403, 1993.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1993}, {"title": "A study of complexity and quality of speech waveform coders", "author": ["JM Tribolet", "P Noll", "B McDermott", "R Crochiere"], "venue": "Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP\u201978. IEEE, 1978, vol. 3, pp. 586\u2013590.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1978}, {"title": "Speech enhancement: theory and practice", "author": ["Philipos C Loizou"], "venue": "CRC press,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Noise estimation methods [1, 2, 3] apply different criteria on when to update the noise, and are typically used to compute the spectral gain for speech enhancement algorithms [4, 5].", "startOffset": 25, "endOffset": 34}, {"referenceID": 1, "context": "Noise estimation methods [1, 2, 3] apply different criteria on when to update the noise, and are typically used to compute the spectral gain for speech enhancement algorithms [4, 5].", "startOffset": 25, "endOffset": 34}, {"referenceID": 2, "context": "Noise estimation methods [1, 2, 3] apply different criteria on when to update the noise, and are typically used to compute the spectral gain for speech enhancement algorithms [4, 5].", "startOffset": 25, "endOffset": 34}, {"referenceID": 3, "context": "Noise estimation methods [1, 2, 3] apply different criteria on when to update the noise, and are typically used to compute the spectral gain for speech enhancement algorithms [4, 5].", "startOffset": 175, "endOffset": 181}, {"referenceID": 4, "context": "Noise estimation methods [1, 2, 3] apply different criteria on when to update the noise, and are typically used to compute the spectral gain for speech enhancement algorithms [4, 5].", "startOffset": 175, "endOffset": 181}, {"referenceID": 5, "context": "noisy environments [6, 7, 8, 9, 10].", "startOffset": 19, "endOffset": 35}, {"referenceID": 6, "context": "noisy environments [6, 7, 8, 9, 10].", "startOffset": 19, "endOffset": 35}, {"referenceID": 7, "context": "noisy environments [6, 7, 8, 9, 10].", "startOffset": 19, "endOffset": 35}, {"referenceID": 8, "context": "noisy environments [6, 7, 8, 9, 10].", "startOffset": 19, "endOffset": 35}, {"referenceID": 9, "context": "noisy environments [6, 7, 8, 9, 10].", "startOffset": 19, "endOffset": 35}, {"referenceID": 5, "context": "Parametric models capture the sources in a compact representation by training the coefficients of a model [6, 8].", "startOffset": 106, "endOffset": 112}, {"referenceID": 7, "context": "Parametric models capture the sources in a compact representation by training the coefficients of a model [6, 8].", "startOffset": 106, "endOffset": 112}, {"referenceID": 6, "context": "Non-parametric models learn representations of the sources directly from the spectrum, and are trained using vector quantization (VQ) [7, 11], non-negative matrix factorization (NMF) and its probabilistic counterparts [12, 9], and variants of singular value decomposition (SVD) [10].", "startOffset": 134, "endOffset": 141}, {"referenceID": 10, "context": "Non-parametric models learn representations of the sources directly from the spectrum, and are trained using vector quantization (VQ) [7, 11], non-negative matrix factorization (NMF) and its probabilistic counterparts [12, 9], and variants of singular value decomposition (SVD) [10].", "startOffset": 134, "endOffset": 141}, {"referenceID": 11, "context": "Non-parametric models learn representations of the sources directly from the spectrum, and are trained using vector quantization (VQ) [7, 11], non-negative matrix factorization (NMF) and its probabilistic counterparts [12, 9], and variants of singular value decomposition (SVD) [10].", "startOffset": 218, "endOffset": 225}, {"referenceID": 8, "context": "Non-parametric models learn representations of the sources directly from the spectrum, and are trained using vector quantization (VQ) [7, 11], non-negative matrix factorization (NMF) and its probabilistic counterparts [12, 9], and variants of singular value decomposition (SVD) [10].", "startOffset": 218, "endOffset": 225}, {"referenceID": 9, "context": "Non-parametric models learn representations of the sources directly from the spectrum, and are trained using vector quantization (VQ) [7, 11], non-negative matrix factorization (NMF) and its probabilistic counterparts [12, 9], and variants of singular value decomposition (SVD) [10].", "startOffset": 278, "endOffset": 282}, {"referenceID": 5, "context": "However, these methods often rely on a separate noise model [6, 10, 9, 11], which limits the algorithms to work in environments that have been previously trained on.", "startOffset": 60, "endOffset": 74}, {"referenceID": 9, "context": "However, these methods often rely on a separate noise model [6, 10, 9, 11], which limits the algorithms to work in environments that have been previously trained on.", "startOffset": 60, "endOffset": 74}, {"referenceID": 8, "context": "However, these methods often rely on a separate noise model [6, 10, 9, 11], which limits the algorithms to work in environments that have been previously trained on.", "startOffset": 60, "endOffset": 74}, {"referenceID": 10, "context": "However, these methods often rely on a separate noise model [6, 10, 9, 11], which limits the algorithms to work in environments that have been previously trained on.", "startOffset": 60, "endOffset": 74}, {"referenceID": 11, "context": "For offline enhancement, semi-supervised NMF [12, 13] provides a solution to enhace without a separate noise model.", "startOffset": 45, "endOffset": 53}, {"referenceID": 12, "context": "For offline enhancement, semi-supervised NMF [12, 13] provides a solution to enhace without a separate noise model.", "startOffset": 45, "endOffset": 53}, {"referenceID": 13, "context": "The Mel or Bark scale can also be used to center the filter bands such that the lower frequencies are emphasized [14].", "startOffset": 113, "endOffset": 117}, {"referenceID": 6, "context": "However, as shown in [7], a VQ representation of the speech spectrum is, by itself, insufficient to capture all the subtle nuances of the underlying speech.", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "One distribution commonly used for speech enhancement [4] is to model Fourier Transform coefficients using a complex Gaussian distribution.", "startOffset": 54, "endOffset": 57}, {"referenceID": 6, "context": "The first algorithm is based on Ellis\u2019s method [7] where a VQ representation of the speech is used to quantize the noisy speech.", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "The second algorithm is the MMSE noise estimation algorithm by Gerkmann used with an a-priori SNR estimated Wiener filter [3].", "startOffset": 122, "endOffset": 125}, {"referenceID": 14, "context": "However, given that the MMSE algorithm has recently shown to be one of the more effective methods for single channel speech enhancement [15], we compare it here to highlight some of the more challenging situations a speech enhancement system can encounter.", "startOffset": 136, "endOffset": 140}, {"referenceID": 15, "context": "To train the speech dictionary, 10,000 patches were sampled from randomly selected sentences in the training section of the TIMIT speech database [16].", "startOffset": 146, "endOffset": 150}, {"referenceID": 13, "context": "The effect of these parameters are analyzed in [14].", "startOffset": 47, "endOffset": 51}, {"referenceID": 8, "context": "In the literature, a longer analysis window is often used [9, 10] such that the harmonics are better defined.", "startOffset": 58, "endOffset": 65}, {"referenceID": 9, "context": "In the literature, a longer analysis window is often used [9, 10] such that the harmonics are better defined.", "startOffset": 58, "endOffset": 65}, {"referenceID": 16, "context": "The frequency-weighted segmental SNR (fwSegSNR) [18] is another measure known to highly correlate with subjective mean opinion scores (MOS) [19].", "startOffset": 48, "endOffset": 52}, {"referenceID": 17, "context": "The frequency-weighted segmental SNR (fwSegSNR) [18] is another measure known to highly correlate with subjective mean opinion scores (MOS) [19].", "startOffset": 140, "endOffset": 144}], "year": 2016, "abstractText": "Distortion of the underlying speech is a common problem for single-channel speech enhancement algorithms, and hinders such methods from being used more extensively. A dictionary based speech enhancement method that emphasizes preserving the underlying speech is proposed. Spectral patches of clean speech are sampled and clustered to train a dictionary. Given a noisy speech spectral patch, the best matching dictionary entry is selected and used to estimate the noise power at each time-frequency bin. The noise estimation step is formulated as an outlier detection problem, where the noise at each bin is assumed present only if it is an outlier to the corresponding bin of the best matching dictionary entry. This framework assigns higher priority in removing spectral elements that strongly deviate from a typical spoken unit stored in the trained dictionary. Even without the aid of a separate noise model, this method can achieve significant noise reduction for various non-stationary noises, while effectively preserving the underlying speech in more challenging noisy environments.", "creator": "LaTeX with hyperref package"}}}