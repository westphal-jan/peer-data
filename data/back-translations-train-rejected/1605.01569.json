{"id": "1605.01569", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2016", "title": "Classification of Human Whole-Body Motion using Hidden Markov Models", "abstract": "Human motion plays an important role in many fields. Large databases exist that store and make available recordings of human motions. However, annotating each motion with multiple labels is a cumbersome and error-prone process. This bachelor's thesis presents different approaches to solve the multi-label classification problem using Hidden Markov Models (HMMs). First, different features that can be directly obtained from the raw data are introduced. Next, additional features are derived to improve classification performance. These features are then used to perform the multi-label classification using two different approaches. The first approach simply transforms the multi-label problem into a multi-class problem. The second, novel approach solves the same problem without the need to construct a transformation by predicting the labels directly from the likelihood scores. The second approach scales linearly with the number of labels whereas the first approach is subject to combinatorial explosion. All aspects of the classification process are evaluated on a data set that consists of 454 motions. System 1 achieves an accuracy of 98.02% and system 2 an accuracy of 93.39% on the test set.", "histories": [["v1", "Thu, 5 May 2016 12:38:18 GMT  (7242kb,D)", "http://arxiv.org/abs/1605.01569v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["matthias plappert"], "accepted": false, "id": "1605.01569"}, "pdf": {"name": "1605.01569.pdf", "metadata": {"source": "META", "title": "Classification of Human Whole-Body Motion using Hidden Markov Models", "authors": ["Matthias Plappert"], "emails": [], "sections": [{"heading": null, "text": "KIT - University of the State of Baden-W\u00fcrttemberg and National Research Center of the Helmholtz Association www.kit.eduKarlsruhe Institute of TechnologyClassification of Human Whole-BodyMotion using Hidden Markov ModelsBachelor's Thesis ofMatthias PlappertAt the Department of Informatics and Robotics (IAR) High Perfomance Humanoid Technologies Lab (H2T) Primary Judge: Prof. Dr.-Ing. Tamim Asfour Secondary Speaker: Prof. Dr.-Ing. R\u00fcdiger DillmannAdvisor: Dipl.-Ing. Christian ManderyDuration: May 1st, 2015 - August 31th, 2015ar X iv."}, {"heading": "1 Introduction 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Related Work 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Basics 5", "text": "3.1 Motion Capture..................................................................................................................."}, {"heading": "4 Features 13", "text": "4.1 Representation of marketers......................................................................................................................................................................................................................................................................................................................"}, {"heading": "5 Classification 21", "text": "For this purpose the powers of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders of commanders"}, {"heading": "6 Evaluation 29", "text": "In the second half of the year, the number of deaths in the US will rise to more than 2,000."}, {"heading": "1 Introduction", "text": "This year it is so far that it will only be a matter of time before an agreement is reached."}, {"heading": "2 Related Work", "text": "There is a promising idea to use human motion as an intuitive method of guiding and programming machines, an approach commonly referred to as Programming by Demonstration (PbD). [DRE + 00, BCDS08] In PbD, a human instructor teaches a machine how to complete a given task by completing the task and tries to complete the task by imitating what it perceives. Human motion can also be used to gain a better understanding of how different parts of the human body work together to complete a task or goal. For example, it is observed how a human responds to the balance of perturbations that can potentially be used to transfer this knowledge to bifurcated humanoid robots. [MBJA15] Because motion plays a key role in humanoid robotics."}, {"heading": "3 Basics", "text": "The classification of human whole-body movements requires primarily motion data. Therefore, this chapter begins with a short discussion of motion recording (Section 3.1) and the Master Motor Map as a framework for motion representation (Section 3.2). Section 3.3 provides an overview of the KIT whole-body motion database, which plays an important role in this work as it stores all motion data and also provides structures for motion labeling. In Section 3.4, Hidden Markov models are presented with which movements are learned and recognized in this thesis. Finally, an extension of HMMs, Factorial Hidden Markov Models, is discussed (Section 3.5)."}, {"heading": "3.1 Motion Capture", "text": "The motion recording system VICON MX can be used to record motion data. To this end, each camera has a ring of LEDs surrounding its lens, which emit light in the infrared spectrum, which is then reflected by the markers. Each camera records this reflected light and (depending on the mode of operation) transmits the 2D coordinates of the markers. The final 3D coordinates for each marker are calculated by triangulation using the data from each camera [vic].The movements are recorded by eight stationary and two portable VICON T10 cameras. Each camera records at a sampling rate of 100 Hz. A total of 56 markers are applied to the human body, as shown in Figure 3.1.All recorded motion data is stored in C3D format. The C3D format is a binary format, e.g. using data from public spaces, which are referred to as 3D markers."}, {"heading": "3.2 Master Motor Map", "text": "This year, it is only a matter of time before that happens, until that happens, until an agreement is reached."}, {"heading": "3.3 KIT Whole-Body Human Motion Database", "text": "KIT-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO-WTO."}, {"heading": "3.4 Hidden Markov Models", "text": "The question of how it could come to this is not only a question of the way it is, but also a question of the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about the way it is about"}, {"heading": "3.5 Factorial Hidden Markov Models", "text": "A sever limitation of HMMs is that they cannot represent a lot of information about the history of a time sequence. (Factorally hidden Markov models (FHMMs) are a generalization of HMMs and therefore provide a way to overcome this limitation. For example, the representation of 30 bit history information requires 230 hidden states in a standard HMM, whereas a FHMM can represent the same information with only 30 binary state variables. (1) The discussion in this section is based on the work of Ghahramani et al. [GJ97].In a FHMM, the current state is generalized by representing the state by a collection of M state variables: zt = (z) t. z (3.7), where each state is variable z (m)."}, {"heading": "4 Features", "text": "As already mentioned in Section 3.1, movements can be recorded using a motion capture system based on optical markers. The following section discusses different approaches to depicting such movements and describes possible features by which they can be detected and classified in later chapters."}, {"heading": "4.1 Marker Representation", "text": "A natural and obvious way to represent the recorded data is in three-dimensional Cartesian space. For each time sample t, the system records the position of each marker n: r (n) t = (x (n) t, y (n) t, z (n) t) R3. (4.1) A complete motion or observation sequence O is then represented by all marker positions for all sampled time steps. One way to write this is to \"unroll\" all marker positions for a given time step t into the tenth row of an observation matrix: Cartesian = x (1) 1 y (1) 1 z (1) 1. x (N) 1 z (N) 2 y (N) 2 y (N) 2 z (N) 2.......... mark (1) T z (1) T."}, {"heading": "4.2 Joint Angle Representation", "text": "This is achieved by mapping the position of physical markers on virtual markers on a reference model while maintaining the constraints of the reference model. [MBJA15] The optimization problem is minimized by reimplementing the subplex algorithm by varying the subject's pose (as defined by its position and rotation in space). [MBJA15]. Figure 4.2 shows the kinematics and shows the position and labels of all joints. Some joints have multiple degrees of freedom (DoF). Take, for example, the lower neck of the body (BLN) joint that has 3 DoF (to convince yourself that this is actually the case, shake your head from shoulder to shoulder)."}, {"heading": "4.3 Derived Features", "text": "It is an obvious extension to calculate the velocities and accelerations of all characteristics describing positions in the Cartesian coordinate space. However, given that velocity is the first subject of the position and acceleration, the first derivative of velocity is the first derivative of velocity, both properties are easy to calculate by approximating the respective derivatives: vt = rt \u2212 12 \u2206 t and at = vt + 1 \u2212 1 (4.11), where v denotes velocity, an acceleration and \u2206 t is the time difference between two consecutive examples (assumed to be equidistant across all samples). Normalization works similarly to Equation 4.8, but normalizes each sample with the current pose of the respective segment instead of the normalization of each sample with the original root. An interesting modification of velocities and accelerations is to reduce them to easy scalable values."}, {"heading": "4.4 Smoothing", "text": "For example, noise is introduced during the recording process. In addition, an approximation of the derivative to calculate velocities and accelerations can amplify errors and inaccuracies in the recorded data. To reduce the effects of these interferences, smoothing is used. A signal can be smoothed with a variety of different filters. For a more complete discussion see [Sim12]. In this paper, only one simple filter is briefly discussed: the moving average or sliding window filter. In such a filter of length W, the mean of the surrounding W points is used instead of the single data point: x-t = 1W + 1W / 2 \u2211 j = \u2212 W / 2 xt + j, (4,14) where xt denotes a (potentially multi-dimensional) data point at a given time, step t and x-t is the smoothed version of it. Including future samples into the average avoids the introduction of a time delay in the signal."}, {"heading": "4.5 Scaling", "text": "s take, for example, the joint angles and root position from the previous sections. The joint angles are physically limited to a very narrow range of values, while the root position can potentially become very large if the subject travels a large distance from the initial position. It should be evident from this example that the characteristics are on very different scales. This scale difference becomes a problem when k-mean clustering is used to initialize the emission distribution parameters of an HMM. If the data is distributed on very different scales across dimensions, k-mean will not find clusters that match the data properly, because the same distance measurement across dimensions is minimized. This, in turn, results in poor estimates of the emission distribution parameters that result in vanishing probabilities and numerical instabilities during the inference. To counteract this, scaling will consist of scaling the same characteristics, because each one corresponds very effectively to the strategy \u2212 that the characteristics are very specific to the 1.1."}, {"heading": "5 Classification", "text": "In the first section, the general concepts of the Hidden Markov models presented in Chapter 3.2 are discussed in concrete terms in the case of motion detection. In motion detection, the goal is to encode a motion into a Hidden Markov model and calculate a measure that describes how likely an unknown movement is under the model. In the second section, motion detection is extended to multi-class classification. In contrast to motion detection, the goal is now to assign an unknown movement exactly one class out of a (potentially large) set of possible classes. Finally, methods for performing a multi-class classification are introduced. In contrast to multi-class classification, an unknown movement can have many labels that it assigns to several classes. To avoid confusion and highlight the distinction between multi-class classification (in which each movement assigns a class) and multi-class classification (in which each movement is assigned to several classes)."}, {"heading": "5.1 Motion Recognition", "text": "Hidden Markov Models are a popular choice for encoding human whole body movements [TYS + 06, KTN07a, KTN08]. This section describes some characteristics of HMMs in detail and discusses characteristics and problems that are particularly relevant when it comes to movements."}, {"heading": "5.1.1 Emission Distribution", "text": "Remember that the emission distribution models the observed data. As in this case movements are observed and all previously discussed characteristics are continuous, the emission distribution must also be continuous. Typically, a Gaussian distribution or a mixture model is used to model this case [KTN08]. Since this work uses a multivariate Gaussian distribution, the following discussion focuses on this distribution. A multivariate Gaussian distribution or normal distribution is then defined by two parameters: its middle vector, its middle vector, its covariance matrix, where D is the dimension of the characteristic vector. (5.1) The probability density function (pdf) is then determined by f (x) = | \u03a3 | \u2212 1 2 (2\u03c0) -D 2 exp (\u2212 12 (x \u2212 \u00b5) T \u03a3 \u2212 1 (x \u2212 \u00b5) T \u03a3 \u2212 1 (x \u2212 \u00b5) T \u03a3 \u2212 1 (x \u2212 \u00b5)))."}, {"heading": "5.1.2 Topologies", "text": "An important property of a Hidden-Markov model is that it uses hidden states. Transition probabilities between the K states are given by the transition matrix A [0,1] K \u00b7 K, while \u03c0 [0,1] K defines the initial probabilities for each state. By restricting the transition matrix (and consequently the initial probabilities), various topologies can be realized, which can easily be set to zero by initializing the transition matrix and the initial probabilities with some entries. During the training, all probabilities that were originally set to zero [Rab89] remain. If the transition matrix is not restricted, a transition from any state to any other state can occur. Such a HMM is usually called completely connected or ergodic. Another popular topology is the classification of human whole-body movements using Hidden-Markov models. Page 22, chapter 5. Classification is linktopology or bakistopology."}, {"heading": "5.1.3 Parameter Initialization", "text": "An interesting problem that arises is the initialization of the values of the transition matrix and the start probabilities, as well as the means and covariance matrices of the emission distributions. As the Tree-Welch algorithm does not necessarily converge to a global maximum, but to a local one (see chapter 3.2), a correct initial estimate is important to increase the chances of finding the global maximum during the training. According to [Rab89], the initial probabilities and the transition matrix can either be initialized randomly (while maintaining the limitation that the respective probabilities must add up to one) or uniformly estimated. Note that the limitations imposed by the topology selection must also be observed. Initializing the mean vectors and covariance matrices of the emission distribution is more complicated. While a random initialization is possible, it is advantageous to perform an initial estimate of the underlying cluster distribution."}, {"heading": "5.1.4 Training and Recognition", "text": "After deciding on the hyperparameters of the model (i.e. the number of states, the topology and the initialization method for the parameters of the model), the model can be trained. HMM formation is efficiently performed using the tree-welch algorithm [BPSW70]: for each training sequence O, the parameters of the model are updated by the first calculation of the expected probability taking into account the current parameters (expectation step) and then the parameters are updated in such a way that the expected quantity from the expectation step is maximized (maximization step O). If performed iteratively, the probability limit p is maximized, the E- and M-steps are repeated until convergence or until a fixed number of iterations have been performed. Numerical instabilities are a frequent problem when using the tree-welch algorithm. This is due to the fact that the probabilities during the forward or reverse fit can become extremely small."}, {"heading": "5.1.5 Extension to Factorial Hidden Markov Models", "text": "The concepts discussed above apply equally to factorial Hidden Markov models. However, three additional considerations are already of interest: the number of Markov chains as an additional hyperparameter, efficient formation of the FHMM and calculation of probability in the framework of the model. First, the number of chains is an important hyperparameter, since it directly controls the complexity of the time series that a FHMM ModelsPage 24 can represent. However, it is also about the cost of increasing the computational complexity of both training and evaluation in the face of an unknown observation sequence (see Classification of Human Whole-Body Motion using Hidden Markov ModelsPage 24 chapter 5). Usually, only a few chains are used in literature. [KTN08] For example, only two chains are used in their work."}, {"heading": "5.2 Single-Label Classification", "text": "In the previous chapter, motion detection was discussed, and this discussion is now extended to a classification problem. In a classification problem, an unknown observation sequence, in this case a motion, must be assigned to a finite set of classes. Suppose, for example, that the set of classes is executed, jumping and kicking. The goal is then to find the right label for an unknown movement by making a prediction. Classification is correct when y = p. Figure 5.2 provides an overview of the classification process. This process is used during this work, not just for a single label classification. If only a single label is assigned to a movement, classification is straightforward. Instead of using words, y is encoded by natural numbers where each number corresponds to a class: y {1,., M}, (5,12) where M is the number of classes to be detected."}, {"heading": "5.3 Multi-Label Classification", "text": "Let us now extend the classification problem to a problem where multiple labels can be assigned to a movement, which can be motivated by the reference to the Motion Description Tree (see chapter 3.3): a movement is specified by the leaf nodes of the tree, e.g. (1) locomotion \u2192 two-footed \u2192 walking, (2) speed \u2192 fast, (3) direction \u2192 left, (4) disturbance \u2192 result, and (5) disturbance \u2192 source \u2192 passive. It should be obvious from this example that most movements cannot be adequately described by a single class. However, if a movement can have multiple labels, the simple classification described by Eq.5.13 no longer works, as it only calculates the only label with the highest possible probability. To get around this problem, two different approaches can be identified: problem conversion using the power-set method or the use of more advanced decision-makers. In the latter case, the decision-maker must really deal with the multi-loading method either by using the binance classification 11."}, {"heading": "5.3.1 Power Set Method", "text": "A first attempt to solve this problem is to treat any possible combination of labels simply as a single class. Formally, if L is the set of all labels, the set of labels is calculated as the set of labels: L-P (L) = {U | U L}\\ / 0. (5.14) When each element in L-L is then assigned to a natural number, the problem with multiple labels has been transformed into a problem with only one label, meaning that Equation 5.13 can be used to predict the labeling method with the highest probability. As the labeling method represents multiple labels, reversing the conversion after the classification step solves the problem with multiple labels using the approach to labeling already discussed. In the literature, this idea is commonly referred to as the method of labeling method [BLSB04, RPHF11]."}, {"heading": "5.3.2 Binary Relevance Method", "text": "The question that arises is to what extent it is actually a matter of a manner in which it concerns the terms that relate to the terminology and the terminology of the individual terms. (...) The question is to what extent the terminology of the individual terms is different in the individual terms levels. (...) The question is to what extent the terminology of the individual terms levels differs in the individual terms levels. (...) The question is to what extent the terms levels are different in the terms levels of the individual terms levels. (...) The question is to what extent the terms levels differ in the terms levels of the individual terms levels differ in the terms levels of the individual terms levels. (...) The question is to what extent the term levels are used in the terms levels of the individual terms levels, in the terms levels of the individual terms levels, in the terms levels. (...) The question is to what extent the terms levels differ in the individual terms levels, in the terms levels of the individual terms levels."}, {"heading": "5.3.3 Modified Algorithms", "text": "Some learning algorithms have been modified to support multi-label classification \"out of the box.\" In such a case, multi-label classification is simple: similar to the previous approaches, the probabilities under each model are calculated for each of the N training motions and the probability vectors x (1),.., x (N) (compare Equation 5.17). Unlike the binary relevance method, the classifier can now be trained on the entire label vector y instead of training individual classifiers on the individual classes. This potentially allows the learning algorithm to find patterns between probabilities and classes, as the correlation between classes can now also be taken into account. In this case, the decision maker is simply a classifier who is able to learn multi-label classification. Several algorithms exist that have been adopted for the multi-label problem."}, {"heading": "6 Evaluation", "text": "The evaluation of the previously discussed concepts is a challenge. This is due to the fact that a large number of system parameters can be identified: a number of characteristics must be selected, the hyperparameters of the Hidden Markov models must be selected, a comparison between FHMMs and HMMs is necessary, and a variety of different classifiers that perform the mapping of probabilities to final designations are available, which may also have many hyperparameters that require fine-tuning. It should be clear that the simultaneous evaluation of all these DoFs is impossible due to the large number of combinations. Instead, the problem is divided into smaller problems that are individually evaluated and optimized, only a small subset of the best parameter selections is then used for the next problem, and so on. The structure of this chapter is based on this idea: To get started, a brief overview of the tools used and developed for this work is given. The next section describes the evaluation data used."}, {"heading": "6.1 Tools", "text": "It is not the first time that such a project has come under criticism, but it is also not the first time that such a project has come under criticism. It is the second time that such a project has come under criticism. It is the second time that such a project has come under criticism. It is the second time that such a project has come under criticism. It is the third time that such a project has come under criticism. It is the third time that such a project has come under criticism. It is the third time that such a project has come under criticism."}, {"heading": "6.2 Dataset", "text": "The raw positions of the motion markers were stored in a C3D file. Each movement was contrasted with the KIT6https: / / github.com / hmmlearn 7https: / / github.com / hmmlearn / hhmcsaseSection 6.2: Dataset page 31h8 marker set with 56 markers at well defined locations and a sampling rate of 100 Hz. The C3D files are converted to the MMM reference model."}, {"heading": "6.3 Feature Selection", "text": "This year, it has reached the point where it will be able to reeenimn itself."}, {"heading": "6.4 Hidden Markov Models", "text": "As discussed in Chapter 5.1, Hidden Markov models can be used for motion detection. However, as mentioned in Chapter 5.1.3, correct initialization is a crucial step before training. Furthermore, a comparison between the performance of HMMs and FHMMs is useful. FHMMs have another important hyperparameter, the number of chains. During this section, the experimental setup from the previous section was re-used to select the characteristics. Specifically, the same data set was used. To make the results comparable between this and the previous section, the same permutation was used to mix the data set. In this section, triple cross-validation was applied with 49 HMMs, one for each class. Each HMM was trained for 10 iterations. The best feature from the previous section was used during the following experiments: root _ pos, root _ extreties, root _ pos _ rotric _ results, one for each class."}, {"heading": "6.4.1 Hyperparameters", "text": "In the web search, any possible combination of hyperparameters is used to train a model on the training data set, which is then evaluated on the test data set. A measurement quantity is calculated per combination and the best combination is selected. However, such a search is feasible in this case, since only two different hyperparameters are evaluated. In theory, any natural number can be used for the number of states and innumerable different topologies. In practice, however, it is useful to limit the number of states K to 5 to 20 states when human movements are recognized [KTN07a, KTN08]. In this evaluation, a topology of the states of states of states of states of states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the states of the topology of the assignment of the states of the topology of the assignment of the states of the topology of the states of the topology of the states of the topology of the topology of the states of the topology of the topology of the assignment of the states of the topology of the topology of the assignment of the assignment of the states of the states of the topology of the states of the topology of the states of the topology of the topology of the topology of the assignment of the states of the assignment of the states of the states of the states of the topology of the topology of the topology of the assignment of the states of the states of the states of the topology of the states of the states of the topology of the states of the topology of the topology of the assignment of the states of the states of the states of the topology of the states of the states of the states of the topology of the assignment of the states of the states of the states of the states of the states of the topology of the"}, {"heading": "6.4.2 Parameter Initialization", "text": "It is a case in which it is about the question of whether it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, and in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way in which it is about a way, in which it is about a way and in which it is about which it is about a way and in which it is about a way in which it is about a way, and in which it is about which it is about which it is about which it is about a way and in which it is about which it is about which it is about a way and in which it is about which it is about which it is about which it is about a way and in which it is about which it is about which it is about a way and in which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which is about which it is about which it is about which it is about which it is about which it is"}, {"heading": "6.4.3 Factorial Hidden Markov Models", "text": "Factorial Hidden Markov models are an important extension of HMMs when it comes to movement. However, this benefit comes at the expense of calculating more expensive than regular HMMs. Therefore, it makes sense to take into account not only the value that FHMMs achieve, but also the time it takes to train and evaluate them. In the course of this evaluation, a total of 4 different models were evaluated: \u2022 regular HMM with 5 states, \u2022 FHMM with 5 states and 2 chains, \u2022 FHMM with 5 states and 3 chains and \u2022 FHMM with 5 states and 4 chainsThe FHMMs were trained using the sequential training algorithm (see chapter 5.1.5). Each chain was trained for 10 tree-welch iterations. The emission parameters of the subsequent chains were initialized using the residual error, whereby MMM mean approach was already discussed. All other parameters were set to the default values as defined above."}, {"heading": "6.5 Decision Makers", "text": "Vnlrrlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "6.5.1 Logistic Regression", "text": "The reader is referred to other papers (e.g. [B + 06]) in order to have a full discussion. In this paper, the Logistic Regression Implementation in Scikit Learning with the Liblinar Solver can be found. Since Logistic Regression is a rather simple model, the only hyperparameters that are taken into account in this paper are those that control the regularization. Specifically, Logistic Regression can be used with the L1 or L2 regularization. Regularization is essentially an additional term in the cost function that penalizes large weights to avoid revision. The difference between L1 and L2 regularization lies in the way the penalty is calculated."}, {"heading": "6.5.2 Support Vector Machine", "text": "In fact, the majority of people who are able to see themselves in a position to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "6.5.3 Decision Tree", "text": "In this case, the leaves of the tree represent the classes and the inner nodes represent an input variable. Branches between the nodes represent decisions based on the input variables. However, a decision tree can then be traversed from the root while a decision has to be made at each node (e.g. if the input variable x is greater than a threshold follows the left branch; follow the right branch otherwise) until a leaf node is reached. Learning such a model is done by dividing the training samples at each node. The relevant attribute and threshold to make this decision are selected using a criterion, e.g. the maximum information gain. This process is then repeated recursively for each child until all samples belong to the same class (in this case, the node turns into a leaf)."}, {"heading": "6.5.4 Random Forest", "text": "The last classifier discussed here is called Random Forest [Bre01]. A Random Forest is already a so-called ensemble classifier: This means that it uses multiple, potentially weak, classifiers internally and combines their predictions into a final prediction. However, random forests do this by using multiple decision trees internally, and the final prediction is then calculated by a majority vote on the prediction of each tree. To avoid ending up with almost identical trees, randomness is introduced during the training. Specifically, this is achieved by two factors: Bootstrapping [Efr79] is used to match trees on newly sampled training examples, and Decision Trees is not selected, but randomizes this process by taking only a random subset of available features into account."}, {"heading": "6.6 Classification Systems", "text": "iSe rf\u00fc ide rf\u00fc ide rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc die rf\u00fc"}, {"heading": "6.6.1 Power Set System", "text": "Since 54 different combinations can be identified in the data set (see Section 6.2), a total of 54 such replacement labels were used. Similarly, 54 HMMs or FHMMs (depending on the configuration) were trained, and the classification was then carried out by selecting the model under which the unknown movement was most likely to occur. The 20 best results measured by their F1 rating are listed in Table 6.9. Classification of Human Whole-Body Motion with Hidden Markov ModelsF1 scores, precision and callbacks were averaged across all classes. Averaging is not necessary for overall accuracy as this measure already considers all classes malled. A first conclusion that can be drawn from the data is that the overall performance of the system.The best configuration was achieved with an F1 score that is very accurate."}, {"heading": "6.6.2 Multi-Label System", "text": "Most of them are able to play by the rules that they play by the rules."}, {"heading": "6.6.3 Comparison", "text": "Both systems did not benefit significantly from the use of FHMMs. Furthermore, features 2, 4, 5 and 6 proved to be good choices for both systems; the choice of topology and number of states did not have a significant impact on performance, although the left-right topology achieved better results in the multi-label system; the power-set system achieved an F1 score of 0.9742, while the multi-label system reached 0.9662; a more significant difference can be seen in overall accuracy: 0.9802 was the best value for the power-set system, whereas the multi-label system reached 0.9339. Interestingly, the F1 scores are relatively similar, whereas there is a noticeable difference in overall accuracy. An explanation for these results is that the power-set system is less likely to make an error because only one label is selected at a time. As most labels are properly recognized, the overall accuracy is very high."}, {"heading": "7 Conclusion", "text": "eiD rf\u00fc ide rf\u00fc ide rf\u00fc rf\u00fc rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rf"}], "references": [{"title": "Toward an unified representation for imitation of human motion on humanoids", "author": ["Pedram Azad", "Tamim Asfour", "R\u00fcdiger Dillmann"], "venue": "In Robotics and Automation,", "citeRegEx": "Azad et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Azad et al\\.", "year": 2007}, {"title": "ARMAR-III: An integrated humanoid platform for sensory-motor control", "author": ["Tamim Asfour", "Kristian Regenstein", "Pedram Azad", "Joachim Schr\u00f6der", "Alexander Bierbaum", "Niko Vahrenkamp", "R\u00fcdiger Dillmann"], "venue": "In Humanoid Robots,", "citeRegEx": "Asfour et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Asfour et al\\.", "year": 2006}, {"title": "Pattern Recognition and Machine Learning, volume 4. springer", "author": ["Christopher M Bishop"], "venue": "New York,", "citeRegEx": "Bishop,? \\Q2006\\E", "shortCiteRegEx": "Bishop", "year": 2006}, {"title": "Anthropometric data for describing the kinematics of the human", "author": ["Bryan Buchholz", "Thomas J Armstrong", "Steven A Goldstein"], "venue": "hand. Ergonomics,", "citeRegEx": "Buchholz et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Buchholz et al\\.", "year": 1992}, {"title": "Continuous speech recognition via centisecond acoustic states", "author": ["Raimo Bakis"], "venue": "The Journal of the Acoustical Society of America,", "citeRegEx": "Bakis.,? \\Q1976\\E", "shortCiteRegEx": "Bakis.", "year": 1976}, {"title": "Learning from and about others: Towards using imitation to bootstrap the social understanding of others by robots", "author": ["Cynthia Breazeal", "Daphna Buchsbaum", "Jesse Gray", "David Gatenby", "Bruce Blumberg"], "venue": "Artificial life,", "citeRegEx": "Breazeal et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Breazeal et al\\.", "year": 2005}, {"title": "Robot programming by demonstration", "author": ["Aude Billard", "Sylvain Calinon", "R\u00fcdiger Dillmann", "Stefan Schaal"], "venue": "In Springer handbook of robotics,", "citeRegEx": "Billard et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Billard et al\\.", "year": 2008}, {"title": "An inequality with applications to statistical estimation for probabilistic functions of markov processes and to a model for ecology", "author": ["Leonard E Baum", "John Alonzo Eagon"], "venue": "Bull. Amer. Math. Soc,", "citeRegEx": "Baum and Eagon,? \\Q1967\\E", "shortCiteRegEx": "Baum and Eagon", "year": 1967}, {"title": "Classification and regression trees", "author": ["Leo Breiman", "Jerome Friedman", "Charles J Stone", "Richard A Olshen"], "venue": "CRC press,", "citeRegEx": "Breiman et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Breiman et al\\.", "year": 1984}, {"title": "Learning multilabel scene classification", "author": ["Matthew R Boutell", "Jiebo Luo", "Xipeng Shen", "Christopher M Brown"], "venue": "Pattern recognition,", "citeRegEx": "Boutell et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Boutell et al\\.", "year": 2004}, {"title": "Effects of supportive hand contact on reactive postural control during support perturbations", "author": ["Jan Babi\u010d", "Tadej Petri\u010d", "Luka Peternel", "Nejc \u0160arabon"], "venue": "Gait & posture,", "citeRegEx": "Babi\u010d et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Babi\u010d et al\\.", "year": 2014}, {"title": "A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains", "author": ["Leonard E Baum", "Ted Petrie", "George Soules", "Norman Weiss"], "venue": "The annals of mathematical statistics,", "citeRegEx": "Baum et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Baum et al\\.", "year": 1970}, {"title": "Growth transformations for functions on manifolds", "author": ["Leonard E Baum", "George R Sell"], "venue": "Pacific J. Math,", "citeRegEx": "Baum and Sell,? \\Q1968\\E", "shortCiteRegEx": "Baum and Sell", "year": 1968}, {"title": "On learning, representing, and generalizing a task in a humanoid robot. Systems, Man, and Cybernetics, Part B: Cybernetics", "author": ["Sylvain Calinon", "Florent Guenter", "Aude Billard"], "venue": "IEEE Transactions on,", "citeRegEx": "Calinon et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Calinon et al\\.", "year": 2007}, {"title": "Introduction to robotics: mechanics and control, volume 3", "author": ["John J Craig"], "venue": "Pearson Prentice Hall Upper Saddle River,", "citeRegEx": "Craig.,? \\Q2005\\E", "shortCiteRegEx": "Craig.", "year": 2005}, {"title": "Learning robot behaviour and skills based on human demonstration and advice: the machine learning paradigm", "author": ["R\u00fcdiger Dillmann", "Oliver Rogalla", "Markus Ehrenmann", "R Zollner", "Monica Bordegoni"], "venue": "In ROBOTICS RESEARCH-INTERNATIONAL SYMPOSIUM-,", "citeRegEx": "Dillmann et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Dillmann et al\\.", "year": 2000}, {"title": "Hidden Markov models: estimation and control, volume 29", "author": ["Robert J Elliott", "Lakhdar Aggoun", "John B Moore"], "venue": "Springer Science & Business Media,", "citeRegEx": "Elliott et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Elliott et al\\.", "year": 2008}, {"title": "Bootstrap methods: another look at the jackknife", "author": ["Bradley Efron"], "venue": "The annals of Statistics,", "citeRegEx": "Efron.,? \\Q1979\\E", "shortCiteRegEx": "Efron.", "year": 1979}, {"title": "Liblinear: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "An introduction to variable and feature selection", "author": ["Isabelle Guyon", "Andr\u00e9 Elisseeff"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Guyon and Elisseeff.,? \\Q2003\\E", "shortCiteRegEx": "Guyon and Elisseeff.", "year": 2003}, {"title": "Factorial hidden markov models", "author": ["Zoubin Ghahramani", "Michael I Jordan"], "venue": "Machine learning,", "citeRegEx": "Ghahramani and Jordan.,? \\Q1997\\E", "shortCiteRegEx": "Ghahramani and Jordan.", "year": 1997}, {"title": "A class of wasserstein metrics for probability distributions", "author": ["Clark R Givens", "Rae Michael Shortt"], "venue": "Michigan Math. J,", "citeRegEx": "Givens and Shortt,? \\Q1984\\E", "shortCiteRegEx": "Givens and Shortt", "year": 1984}, {"title": "Spoken language processing: A guide to theory, algorithm, and system development", "author": ["Xuedong Huang", "Alex Acero", "Hsiao-Wuen Hon", "Raj Reddy"], "venue": null, "citeRegEx": "Huang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2001}, {"title": "Scholkopf. Support vector machines", "author": ["Marti A. Hearst", "Susan T Dumais", "Edgar Osman", "John Platt", "Bernhard"], "venue": "Intelligent Systems and their Applications,", "citeRegEx": "Hearst et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Hearst et al\\.", "year": 1998}, {"title": "Motion imitation and recognition using parametric hidden markov models", "author": ["Dennis Herzog", "AleNs Ude", "Volker Kr\u00fcger"], "venue": "In Humanoid Robots,", "citeRegEx": "Herzog et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Herzog et al\\.", "year": 2008}, {"title": "Feature subset selection by bayesian network-based optimization", "author": ["I\u00f1aki Inza", "Pedro Larra\u00f1aga", "Ram\u00f3n Etxeberria", "Basilio Sierra"], "venue": "Artificial intelligence,", "citeRegEx": "Inza et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Inza et al\\.", "year": 2000}, {"title": "Factorial hidden markov models and the generalized backfitting algorithm", "author": ["Robert A Jacobs", "Wenxin Jiang", "Martin A Tanner"], "venue": "Neural computation,", "citeRegEx": "Jacobs et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Jacobs et al\\.", "year": 2002}, {"title": "On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes", "author": ["A Jordan"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Jordan.,? \\Q2002\\E", "shortCiteRegEx": "Jordan.", "year": 2002}, {"title": "Learning actions from observations", "author": ["Volker Kr\u00fcger", "Dennis L Herzog", "Sanmohan Baby", "Ales Ude", "Danica Kragic"], "venue": "Robotics & Automation Magazine, IEEE,", "citeRegEx": "Kr\u00fcger et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kr\u00fcger et al\\.", "year": 2010}, {"title": "An efficient k-means clustering algorithm: Analysis and implementation", "author": ["Tapas Kanungo", "David M Mount", "Nathan S Netanyahu", "Christine D Piatko", "Ruth Silverman", "Angela Y Wu"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Kanungo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kanungo et al\\.", "year": 2002}, {"title": "Incremental learning of full body motion primitives and their sequencing through human motion observation", "author": ["Dana Kuli\u0107", "Christian Ott", "Dongheui Lee", "Junichi Ishikawa", "Yoshihiko Nakamura"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "Kuli\u0107 et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kuli\u0107 et al\\.", "year": 2011}, {"title": "Incremental on-line hierarchical clustering of whole body motion patterns", "author": ["Dana Kuli\u0107", "Wataru Takano", "Yoshihiko Nakamura"], "venue": "In Robot and Human interactive Communication,", "citeRegEx": "Kuli\u0107 et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kuli\u0107 et al\\.", "year": 2007}, {"title": "Representability of human motions by factorial hidden markov models", "author": ["Dana Kuli\u0107", "Wataru Takano", "Yoshihiko Nakamura"], "venue": "In Intelligent Robots and Systems,", "citeRegEx": "Kuli\u0107 et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kuli\u0107 et al\\.", "year": 2007}, {"title": "Incremental learning, clustering and hierarchy formation of whole body motion patterns using adaptive hidden markov chains", "author": ["Dana Kuli\u0107", "Wataru Takano", "Yoshihiko Nakamura"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "Kuli\u0107 et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kuli\u0107 et al\\.", "year": 2008}, {"title": "Numerically stable hidden markov model implementation", "author": ["Tobias P Mann"], "venue": "An HMM scaling tutorial,", "citeRegEx": "Mann.,? \\Q2006\\E", "shortCiteRegEx": "Mann.", "year": 2006}, {"title": "Analyzing wholebody pose transitions in multi-contact motions", "author": ["Christian Mandery", "J\u00falia Borr\u00e0s", "Mirjam J\u00f6chner", "Tamim Asfour"], "venue": "arXiv preprint arXiv:1507.08799,", "citeRegEx": "Mandery et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mandery et al\\.", "year": 2015}, {"title": "The kit whole-body human motion database", "author": ["Christian Mandery", "\u00d6mer Terlemez", "Martin Do", "Nikolaus Vahrenkamp", "Tamim Asfour"], "venue": "In IEEE International Conference on Robotics and Automation (ICRA), Seattle, USA,(submitted),", "citeRegEx": "Mandery et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mandery et al\\.", "year": 2015}, {"title": "Learning from demonstration and adaptation of biped locomotion", "author": ["Jun Nakanishi", "Jun Morimoto", "Gen Endo", "Gordon Cheng", "Stefan Schaal", "Mitsuo Kawato"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "Nakanishi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Nakanishi et al\\.", "year": 2004}, {"title": "Open-end human\u2013robot interaction from the dynamical systems perspective: mutual adaptation and incremental learning", "author": ["Tetsuya Ogata", "Shigeki Sugano", "Jun Tani"], "venue": "Advanced Robotics,", "citeRegEx": "Ogata et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ogata et al\\.", "year": 2005}, {"title": "Angular momentum primitives for human walking: biomechanics and control", "author": ["Mako Popovic", "Amy Englehart"], "venue": "In Intelligent Robots and Systems,", "citeRegEx": "Popovic and Englehart.,? \\Q2004\\E", "shortCiteRegEx": "Popovic and Englehart.", "year": 2004}, {"title": "Scikit-learn: Machine learning in python", "author": ["Fabian Pedregosa", "Ga\u00ebl Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Pedregosa et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2011}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["Lawrence R Rabiner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Rabiner.,? \\Q1989\\E", "shortCiteRegEx": "Rabiner.", "year": 1989}, {"title": "Classifier chains for multilabel classification", "author": ["Jesse Read", "Bernhard Pfahringer", "Geoff Holmes", "Eibe Frank"], "venue": "Machine learning,", "citeRegEx": "Read et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Read et al\\.", "year": 2011}, {"title": "Smoothing methods in statistics", "author": ["Jeffrey S Simonoff"], "venue": "Springer Science & Business Media,", "citeRegEx": "Simonoff.,? \\Q2012\\E", "shortCiteRegEx": "Simonoff.", "year": 2012}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["Jasper Snoek", "Hugo Larochelle", "Ryan P Adams"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Boostexter: A boosting-based system for text categorization", "author": ["Robert E Schapire", "Yoram Singer"], "venue": "Machine learning,", "citeRegEx": "Schapire and Singer.,? \\Q2000\\E", "shortCiteRegEx": "Schapire and Singer.", "year": 2000}, {"title": "On the stratification of multi-label data", "author": ["Konstantinos Sechidis", "Grigorios Tsoumakas", "Ioannis Vlahavas"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Sechidis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sechidis et al\\.", "year": 2011}, {"title": "Factored conditional restricted boltzmann machines for modeling motion style", "author": ["Graham W Taylor", "Geoffrey E Hinton"], "venue": "In Proceedings of the 26th annual international conference on machine learning,", "citeRegEx": "Taylor and Hinton.,? \\Q2009\\E", "shortCiteRegEx": "Taylor and Hinton.", "year": 2009}, {"title": "Correlated space formation for human whole-body motion primitives and descriptive word labels", "author": ["Wataru Takano", "Seiya Hamano", "Yoshihiko Nakamura"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "Takano et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Takano et al\\.", "year": 2015}, {"title": "Modeling human motion using binary latent variables", "author": ["Graham W Taylor", "Geoffrey E Hinton", "Sam T Roweis"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Taylor et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Taylor et al\\.", "year": 2006}, {"title": "Organization of behavioral knowledge from extraction of temporal-spatial features of human whole body motions", "author": ["Wataru Takano", "Hirotaka Imagawa", "Dana Kuli\u0107", "Yoshihiko Nakamura"], "venue": "In Biomedical Robotics and Biomechatronics (BioRob),", "citeRegEx": "Takano et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Takano et al\\.", "year": 2010}, {"title": "Construction of a space of motion labels from their mapping to full-body motion symbols", "author": ["Wataru Takano", "Yoshihiko Nakamura"], "venue": "Advanced Robotics,", "citeRegEx": "Takano and Nakamura.,? \\Q2015\\E", "shortCiteRegEx": "Takano and Nakamura.", "year": 2015}, {"title": "Statistical mutual conversion between whole body motion primitives and linguistic sentences for human motions", "author": ["Wataru Takano", "Yoshihiko Nakamura"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "Takano and Nakamura.,? \\Q2015\\E", "shortCiteRegEx": "Takano and Nakamura.", "year": 2015}, {"title": "Master Motor Map (MMM)\u2013framework and toolkit for capturing, representing, and reproducing human motion on humanoid robots", "author": ["\u00d6mer Terlemez", "Stefan Ulbrich", "Christian Mandery", "Martin Do", "Nikolaus Vahrenkamp", "Tamim Asfour"], "venue": "In Humanoid Robots (Humanoids),", "citeRegEx": "Terlemez et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Terlemez et al\\.", "year": 2014}, {"title": "Primitive Communication based on Motion Recognition and Generation with Hierarchical Mimesis Model", "author": ["Wataru Takano", "Katsu Yamane", "Tomomichi Sugihara", "Kou Yamamoto", "Yoshihiko Nakamura"], "venue": "In Robotics and Automation,", "citeRegEx": "Takano et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Takano et al\\.", "year": 2006}, {"title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm", "author": ["Andrew J Viterbi"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Viterbi.,? \\Q1967\\E", "shortCiteRegEx": "Viterbi.", "year": 1967}, {"title": "Decision trees for hierarchical multi-label classification", "author": ["Celine Vens", "Jan Struyf", "Leander Schietgat", "Sa\u0161o D\u017eeroski", "Hendrik Blockeel"], "venue": "Machine Learning,", "citeRegEx": "Vens et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vens et al\\.", "year": 2008}, {"title": "Parametric hidden markov models for gesture recognition", "author": ["Andrew D Wilson", "Aaron F Bobick"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Wilson and Bobick.,? \\Q1999\\E", "shortCiteRegEx": "Wilson and Bobick.", "year": 1999}, {"title": "Biomechanics of Human Movement", "author": ["David A Winter"], "venue": "Wiley New York,", "citeRegEx": "Winter.,? \\Q1979\\E", "shortCiteRegEx": "Winter.", "year": 1979}, {"title": "Biomechanics and motor control of human movement", "author": ["David A Winter"], "venue": null, "citeRegEx": "Winter.,? \\Q2009\\E", "shortCiteRegEx": "Winter.", "year": 2009}, {"title": "Human motion database with a binary tree and node transition graphs", "author": ["K. Yamane", "Y. Yamaguchi", "Y. Nakamura"], "venue": "In Proceedings of Robotics: Science and Systems,", "citeRegEx": "Yamane et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yamane et al\\.", "year": 2009}, {"title": "Ml-knn: A lazy learning approach to multi-label learning", "author": ["Min-Ling Zhang", "Zhi-Hua Zhou"], "venue": "Pattern recognition,", "citeRegEx": "Zhang and Zhou.,? \\Q2007\\E", "shortCiteRegEx": "Zhang and Zhou.", "year": 2007}], "referenceMentions": [], "year": 2016, "abstractText": null, "creator": "LaTeX with hyperref package"}}}