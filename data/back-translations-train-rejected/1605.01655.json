{"id": "1605.01655", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2016", "title": "Stance and Sentiment in Tweets", "abstract": "We can often detect from a person's utterances whether he/she is in favor of or against a given target entity -- their stance towards the target. However, a person may express the same stance towards a target by using negative or positive language. Here for the first time we present a dataset of tweet--target pairs annotated for both stance and sentiment. The targets may or may not be referred to in the tweets, and they may or may not be the target of opinion in the tweets. Partitions of this dataset were used as training and test sets in a SemEval-2016 shared task competition. We propose a simple stance detection system that outperforms submissions from all 19 teams that participated in the shared task. Additionally, access to both stance and sentiment annotations allows us to explore several research questions. We show that while knowing the sentiment expressed by a tweet is beneficial for stance classification, it alone is not sufficient. Finally, we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification.", "histories": [["v1", "Thu, 5 May 2016 17:07:54 GMT  (444kb,D)", "http://arxiv.org/abs/1605.01655v1", "22 pages"]], "COMMENTS": "22 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["saif m mohammad", "parinaz sobhani", "svetlana kiritchenko"], "accepted": false, "id": "1605.01655"}, "pdf": {"name": "1605.01655.pdf", "metadata": {"source": "CRF", "title": "Stance and Sentiment in Tweets", "authors": ["Saif M. Mohammad", "Parinaz Sobhani", "Svetlana Kiritchenko"], "emails": [], "sections": [{"heading": null, "text": "0 Attitude and Mood in TweetsSaif M. Mohammad, National Research Council Canada Parinaz Sobhani, University of Ottawa Svetlana Kiritchenko, National Research Council CanadaWe can often tell from a person's comments whether they are for or against a particular target unit - their attitude towards the target. However, a person can express the same attitude towards a target by using negative or positive language. Here, for the first time, we present a dataset of tweet-target pairs that are commented on for both attitude and mood. Targets may or may not be addressed in the tweets, and they may be the target of opinion in the tweets. Divides of this dataset have been used as training and test sets in a SemEval 2016 shared task competition. We propose a simple substance detection system that outperforms the submissions of all 19 teams that participated in the joint task."}, {"heading": "1. INTRODUCTION", "text": "The target can be a person, an organization, a government policy, a movement, a product, etc. For example, one can conclude from Barack Obama's speeches that he is in favor of stricter gun laws in the United States. Similarly, people often express themselves toward different audiences through posts on online forums, blogs, Twitter, Instagram, etc. However, most work focuses on congressional debates [Thomas et al. 2006] or debates in online forums [Somasundaran and Wiebe 2010; Anand et al. 2011; Walker et al. 2012a; Hasan and Ng 2013]."}, {"heading": "2. A DATASET FOR STANCE FROM TWEETS", "text": "We will now present how we compiled a series of tweets and objectives for the position comments (Section 2.1) and how we compiled questionnaires and crowdsourcing for the position comments (Section 2.2). An analysis of the position comments is presented in Section 4."}, {"heading": "2.1. Selecting the Tweet\u2013Target Pairs", "text": "Our goal was to create a relatively hard case for the recognition of dataset with the following characteristics: 1: The tweet and the target are generally understood by a large number of people in the US. (Thedata was eventually commented on for the position of respondents living in the US.) 2: There must be a significant amount of data for the three tweets that remove tweets: \"favor,\" \"against,\" and \"nei-ther.\" 2http: / / alt.qcri.org / semeval2016 / task6 / http: / www.saifmohammad.com / StanceDataset.htmACM Transactions on Embedded Computing Systems, Vol. 0, No. 0, Article 0, Release Date: 2016.3: Apart from tweets that explicitly mention the target, the dataset should include a significant number of tweets that express their opinion towards the target without mentioning it by name."}, {"heading": "2.2. Stance Annotation", "text": "The instructions given to commenters to determine the stance are shown below that supporting the tweet supports the goal. \u2022 The second question is whether the goal of the opinion in the tweet is the same as the stated goal of interest: \u2022 We can conclude from the tweet that the tweet does not support the goal of the tweet itself. \u2022 The second question is whether the goal of the opinion in the tweet is the same as the goal of interest: \u2022 We can conclude from the tweet that the tweet supports the goal. \u2022 This could happen for any reason shown below: - the tweet is explicitly in support of the goal - the tweet is most likely that the stance of the tweet or the outlook of the goal is true. \u2022 We can conclude from the tweet that the tweet supports the goal. - the tweet is explicitly in support of the goal - the tweet is support for something / someone pursuing the goal from which we can deduce that we support the goal."}, {"heading": "3. LABELING THE STANCE SET FOR SENTIMENT", "text": "A key research question aims to address the extent to which mood correlates with posture. To this end, we commented on the same terms described above for sensation in a separate comment by commenters. We followed a procedure for comments on CrowdFlower similar to the one described above, but now we only have the tweet (not a target).This is problematic because it can lead to different comments by commenters for the4http: / / www.crowdflower.com. The general interpretation of text should be labeled as positive, negative or neutral down to the individual comments."}, {"heading": "4. PROPERTIES OF THE STANCE DATASET", "text": "All commented tweets were not sorted by their timestamps, and the first 70% of tweets formed the training group and the last 30% formed the test group. Table II shows the number and distribution of instances in the stance dataset.Table III shows the distribution of responses to question 2 (whether the opinion is expressed directly about the stated goal).Note that the percentage of \"opinion versus others\" varies in different target groups from 27% to 46%. Table IV shows the distribution of instances according to the goal of the opinion for the \"favor\" and \"against\" viewpoint labels. Note that, as in Example 3, in a number of tweets from which we can deduce unfavorable attitude toward a goal, the goal of the opinion is someone / something other than the goal (about 26.5%).Manual review of the data also revealed that the goal is not directly mentioned, and yet the attitude toward the goal was determined by the observers."}, {"heading": "5. A COMMON TEXT CLASSIFICATION FRAMEWORK FOR STANCE AND SENTIMENT", "text": "In the past, the most useful characteristics for sentiment analysis have been found to be word and character diagrams and sentiment lexicon, while others such as negative characteristics, part-of-speech characteristics and punctuation have a smaller impact [Wilson et al. 2013; Kiritchenko et al. 2014a; Rosenthal et al. 2015]. These characteristics can also be useful in classifying individual characteristics, but it is unclear which characteristics will be more useful (and to what extent). Now that we have a dataset for both attitude and mood, we create a common text classification system (common learning frameworks and common characteristics) and apply it to the Stance Dataset for both sentiment classes. The words and concepts used in tweets that correspond to the three positive positions are not expected to generalize across the goals."}, {"heading": "6. RESULTS OBTAINED BY AUTOMATIC SYSTEMS", "text": "In this section, we will focus on systems that use only the provided training data and existing resources such as sentiment lexicographs. In Section 7, we will conduct experiments with systems that also use unlabeled (or pseudo-labeled) tweets."}, {"heading": "6.1. Results for Stance Classification", "text": "In fact, most people who are able to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves and to support others, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves, to help themselves and to help themselves."}, {"heading": "6.2. Results for Sentiment Classification", "text": "Table VIII shows F scores obtained by various automatic systems on the mood labels of the mood test. Note that the text classification system achieves significantly higher scores in predicting the mood than in predicting the mood level. Here, too, a classifier trained solely with n-gram characteristics achieves significantly higher results than baselines (II.a.). In contrast to the task with the mood lexicon function, however, the mood lexicon characteristics achieve significant further improvements (II.d). Adding POS and coding characteristics beyond n-gram characteristics leads to modest gains (II.b. and I.c.). Nevertheless, a classifier trained with all characteristics (II.d.) outperforms the classifier trained only with n-gram characteristics and mood characteristics (II.d.), not better from Table IX shows the performance of the mood unit compared to the mood unit (SVM)."}, {"heading": "7. STANCE CLASSIFICATION USING ADDITIONAL UNLABELED TWEETS", "text": "Classification results can usually be improved by using more data in addition to the training set. In the following subsections, we will examine two such approaches when used for position classification: Remote monitoring and word embedding."}, {"heading": "7.1. Distant Supervision", "text": "It is a method of supervised text classification in which training data is automatically generated using certain indicators contained in the text. [2009] extracted keywords that ended with emoticons \":)\" and \":\" (\"Next, ACM transactions on Embedded Computing Systems, Vol. 0, Article 0, Release Date: 2016.emoticons were removed from tweets and the remaining parts of tweets were marked as positive or negative, depending on whether they were originally\":) \"or\": \"(,\" or. \"Central aspect of the accuracy of these sentiment labels is the idea that emoticons often redundantly refer to the information already present in the tweet, i.e. a tweet that ends with a\". \"Emoticons that are likely to convey positive feelings even without the emoticons. Mohammad [2012] and Kunneman et al."}, {"heading": "7.2. Word Embeddings", "text": "Word embeddings are low-dimensional real-rated vectors used to represent words in the vocabulary [Bengio et al. 2001]. (The \"low\" dimensionality is relative to the vocabulary size, and using a few hundred dimensions is common.) A number of different language modeling techniques have been proposed to generate word embeddings, all of which require only a large body of text (e.g., [Collobert and Weston 2008; Mnih and Hinton 2009]). Word embeddings have been successfully used as features in a number of tasks, including sensitivity analysis [Tang et al. 2014] and named entity recognition [Turian et al. 2010]. Here we examine the use of large collections of tweets to generate word embeddings as additional features for word classification. We are investigating whether they lead to further improvements over the results achieved by the best system configuration discussed in Section 6 - SVM."}, {"heading": "8. RELATED WORK", "text": "In the work of Somasundaran and Wiebe [2010], a lexicon for recognizing argumentation expressions was created and then used to identify arguments, which, along with sensory expressions and their objectives, were used as features in a monitored learning experience to classify the posts. Anand et al. [2011] used a rules-based classification system with multiple features such as unigrams, bigrams, punctuality marks, syntactic dependencies, and the dialogical structure of the posts. [2011] it used a rules-based classification system with multiple features such as unigrams, punctuation, and distinction. [2014] it investigated the problem of recognizing documents by using two sets of features purporting to represent language."}, {"heading": "9. CONCLUSIONS AND FUTURE WORK", "text": "We presented the first set of tweets that were commented on for both attitudes toward given goals and polarity of language; the tweets are also commented on for whether the opinion is expressed toward the given goal or toward another entity; partitions of the default commented data created as part of this project were used as training and testing kits in a recent position recognition competition submitted by 19 teams; we proposed a simple but effective standpoint recognition system that scored an F score (70.3) higher than that obtained by the more complex, more powerful target system in the competition; we used a linear SVM classifier that utilizes word and character diagrams, and sentiment characteristics derived from available sentiment lexicon and word embedding characteristics drawn from additional unlabeled data; and we presented a detailed analysis of the data set and conducted multiple experiments to find out the attitudes and interactions between them."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Colin Cherry and Xiaodan Zhu for their helpful discussions. The second author of this paper was supported by the Natural Sciences and Engineering Research Council of Canada under the CREATE program."}], "references": [{"title": "Cats rule and dogs drool!: Classifying stance in online debate", "author": ["Pranav Anand", "Marilyn Walker", "Rob Abbott", "Jean E. Fox Tree", "Robeson Bowmani", "Michael Minor."], "venue": "Proceedings of the Workshop on Computational Approaches to Subjectivity and Sentiment Analysis. 1\u20139.", "citeRegEx": "Anand et al\\.,? 2011", "shortCiteRegEx": "Anand et al\\.", "year": 2011}, {"title": "A survey of paraphrasing and textual entailment methods", "author": ["Ion Androutsopoulos", "Prodromos Malakasiotis."], "venue": "Journal of Artificial Intelligence Research (2010), 135\u2013187.", "citeRegEx": "Androutsopoulos and Malakasiotis.,? 2010", "shortCiteRegEx": "Androutsopoulos and Malakasiotis.", "year": 2010}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "Rejean Ducharme", "Pascal Vincent."], "venue": "Advances in Neural Information Processing Systems.", "citeRegEx": "Bengio et al\\.,? 2001", "shortCiteRegEx": "Bengio et al\\.", "year": 2001}, {"title": "The seventh PASCAL recognizing textual entailment challenge", "author": ["Luisa Bentivogli", "Peter Clark", "Ido Dagan", "Hoa Dang", "Danilo Giampiccolo."], "venue": "Proceedings of Text Analysis Conference.", "citeRegEx": "Bentivogli et al\\.,? 2011", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2011}, {"title": "On Using Twitter to Monitor Political Sentiment and Predict Election Results", "author": ["Adam Bermingham", "Alan Smeaton."], "venue": "Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology. Chiang Mai, Thailand, 2\u201310.", "citeRegEx": "Bermingham and Smeaton.,? 2011", "shortCiteRegEx": "Bermingham and Smeaton.", "year": 2011}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston."], "venue": "Proceedings of the International Conference on Machine Learning. 160\u2013167.", "citeRegEx": "Collobert and Weston.,? 2008", "shortCiteRegEx": "Collobert and Weston.", "year": 2008}, {"title": "Predicting the Political Alignment of Twitter Users", "author": ["Michael Conover", "Bruno Gon\u00e7alves", "Jacob Ratkiewicz", "Alessandro Flammini", "Filippo Menczer."], "venue": "Proceedings of the IEEE International Conference on Privacy, Security, Risk, and Trust. 192\u2013199.", "citeRegEx": "Conover et al\\.,? 2011a", "shortCiteRegEx": "Conover et al\\.", "year": 2011}, {"title": "Political Polarization on Twitter", "author": ["Michael Conover", "Jacob Ratkiewicz", "Matthew R. Francisco", "Bruno Gon\u00e7alves", "Filippo Menczer", "Alessandro Flammini."], "venue": "Proceedings of the International AAAI Conference on Weblogs and Social Media. 89\u201396.", "citeRegEx": "Conover et al\\.,? 2011b", "shortCiteRegEx": "Conover et al\\.", "year": 2011}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["Mark Craven", "Johan Kumlien."], "venue": "Proceedings of the Conference on Intelligent Systems for Molecular Biology. 77\u201386.", "citeRegEx": "Craven and Kumlien.,? 1999", "shortCiteRegEx": "Craven and Kumlien.", "year": 1999}, {"title": "Probabilistic textual entailment: Generic applied modeling of language variability", "author": ["Ido Dagan", "Oren Glickman."], "venue": "PASCAL workshop on Text Understanding and Mining. 26\u201329.", "citeRegEx": "Dagan and Glickman.,? 2004", "shortCiteRegEx": "Dagan and Glickman.", "year": 2004}, {"title": "Recognizing textual entailment: Models and applications", "author": ["Ido Dagan", "Dan Roth", "Mark Sammons", "Fabio Massimo Zanzotto."], "venue": "Morgan & Claypool Publishers.", "citeRegEx": "Dagan et al\\.,? 2013", "shortCiteRegEx": "Dagan et al\\.", "year": 2013}, {"title": "Joint inference and disambiguation of implicit sentiments via implicature constraints", "author": ["Lingjia Deng", "Janyce Wiebe", "Yoonjung Choi."], "venue": "Proceedings of the International Conference on Computational Linguistics. 79\u201388.", "citeRegEx": "Deng et al\\.,? 2014", "shortCiteRegEx": "Deng et al\\.", "year": 2014}, {"title": "What does Twitter have to say about ideology", "author": ["Sarah Djemili", "Julien Longhi", "Claudia Marinica", "Dimitris Kotzinos", "Georges-Elia Sarfati."], "venue": "Proceedings of the Natural Language Processing for Computer-Mediated Communication/Social Media-Pre-conference workshop at Konvens.", "citeRegEx": "Djemili et al\\.,? 2014", "shortCiteRegEx": "Djemili et al\\.", "year": 2014}, {"title": "The joint student response analysis and recognizing textual entailment challenge: making sense of student responses in educational applications", "author": ["Myroslava O. Dzikovska", "Rodney D. Nielsen", "Claudia Leacock."], "venue": "Language Resources and Evaluation 50 (2016), 67\u201393. Issue 1.", "citeRegEx": "Dzikovska et al\\.,? 2016", "shortCiteRegEx": "Dzikovska et al\\.", "year": 2016}, {"title": "Automated Classification of Stance in Student Essays: An Approach Using Stance Target Information and the Wikipedia Link-Based Measure", "author": ["Adam Faulkner."], "venue": "Proceedings of the Flairs Conference.", "citeRegEx": "Faulkner.,? 2014", "shortCiteRegEx": "Faulkner.", "year": 2014}, {"title": "Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments", "author": ["Kevin Gimpel", "Nathan Schneider", "Brendan O\u2019Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A. Smith"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "Twitter Sentiment Classification using Distant Supervision", "author": ["Alec Go", "Richa Bhayani", "Lei Huang."], "venue": "Technical Report. Stanford University.", "citeRegEx": "Go et al\\.,? 2009", "shortCiteRegEx": "Go et al\\.", "year": 2009}, {"title": "Computing Political Preference Among Twitter Followers", "author": ["Jennifer Golbeck", "Derek Hansen."], "venue": "Proceedings of the Conference on Human Factors in Computing Systems. New York, NY, 1105\u20131108.", "citeRegEx": "Golbeck and Hansen.,? 2011", "shortCiteRegEx": "Golbeck and Hansen.", "year": 2011}, {"title": "Stance classification of ideological debates: Data, models, features, and constraints", "author": ["Kazi Saidul Hasan", "Vincent Ng."], "venue": "Proceedings of the International Joint Conference on Natural Language Processing. 1348\u20131356.", "citeRegEx": "Hasan and Ng.,? 2013", "shortCiteRegEx": "Hasan and Ng.", "year": 2013}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 168\u2013177.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Topic classification of blog posts using distant supervision", "author": ["Stephanie D. Husby", "Denilson Barbosa."], "venue": "Proceedings of the Workshop on Semantic Analysis in Social Media. 28\u201336.", "citeRegEx": "Husby and Barbosa.,? 2012", "shortCiteRegEx": "Husby and Barbosa.", "year": 2012}, {"title": "Taking sides: User classification for informal online political discourse", "author": ["Yoshikiyo Kato", "Sadao Kurohashi", "Kentaro Inui", "Robert Malouf", "Tony Mullen."], "venue": "Internet Research 18, 2 (2008), 177\u2013190.", "citeRegEx": "Kato et al\\.,? 2008", "shortCiteRegEx": "Kato et al\\.", "year": 2008}, {"title": "NRC-Canada-2014: Detecting aspects and sentiment in customer reviews", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu", "Colin Cherry", "Saif M. Mohammad."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. Dublin, Ireland.", "citeRegEx": "Kiritchenko et al\\.,? 2014b", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "Sentiment Analysis of Short Informal Texts", "author": ["Svetlana Kiritchenko", "Xiaodan Zhu", "Saif M. Mohammad."], "venue": "Journal of Artificial Intelligence Research 50 (2014), 723\u2013762.", "citeRegEx": "Kiritchenko et al\\.,? 2014a", "shortCiteRegEx": "Kiritchenko et al\\.", "year": 2014}, {"title": "The (un)predictability of emotional hashtags in Twitter", "author": ["Florian Kunneman", "Christine Liebrecht", "Antal van den Bosch."], "venue": "Proceedings of the Workshop on Language Analysis for Social Media. 26\u201334.", "citeRegEx": "Kunneman et al\\.,? 2014", "shortCiteRegEx": "Kunneman et al\\.", "year": 2014}, {"title": "A user-centric model of voting intention from social media", "author": ["Vasileios Lampos", "Daniel Preotiuc-Pietro", "Trevor Cohn."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics. 993\u20131003.", "citeRegEx": "Lampos et al\\.,? 2013", "shortCiteRegEx": "Lampos et al\\.", "year": 2013}, {"title": "Which side are you on? Identifying perspectives at the document and sentence levels", "author": ["Wei-Hao Lin", "Theresa Wilson", "Janyce Wiebe", "Alexander Hauptmann."], "venue": "Proceedings of the Conference on Computational Natural Language Learning. 109\u2013116.", "citeRegEx": "Lin et al\\.,? 2006", "shortCiteRegEx": "Lin et al\\.", "year": 2006}, {"title": "Sentiment Analysis: Mining Opinions, Sentiments, and Emotions", "author": ["Bing Liu."], "venue": "Cambridge University Press.", "citeRegEx": "Liu.,? 2015", "shortCiteRegEx": "Liu.", "year": 2015}, {"title": "A Survey of Opinion Mining and Sentiment Analysis", "author": ["Bing Liu", "Lei Zhang."], "venue": "Mining Text Data, Charu C. Aggarwal and ChengXiang Zhai (Eds.). Springer, 415\u2013463.", "citeRegEx": "Liu and Zhang.,? 2012", "shortCiteRegEx": "Liu and Zhang.", "year": 2012}, {"title": "Bridging social media via distant supervision", "author": ["Walid Magdy", "Hassan Sajjad", "Tarek El-Ganainy", "Fabrizio Sebastiani."], "venue": "Social Network Analysis and Mining 5, 1 (2015), 1\u201312.", "citeRegEx": "Magdy et al\\.,? 2015", "shortCiteRegEx": "Magdy et al\\.", "year": 2015}, {"title": "SemEval-2014 Task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli."], "venue": "Proceedings of the International Workshop on Semantic Evaluation.", "citeRegEx": "Marelli et al\\.,? 2014", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Automatic Detection of Political Opinions in Tweets", "author": ["Diana Maynard", "Adam Funk."], "venue": "Proceedings of the ESWC Workshop on the Semantic Web. 88\u201399.", "citeRegEx": "Maynard and Funk.,? 2011", "shortCiteRegEx": "Maynard and Funk.", "year": 2011}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems. 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. 1003\u20131011.", "citeRegEx": "Mintz et al\\.,? 2009", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "A scalable hierarchical distributed language model", "author": ["Andriy Mnih", "Geoffrey E. Hinton."], "venue": "Advances in Neural Information Processing Systems. 1081\u20131088.", "citeRegEx": "Mnih and Hinton.,? 2009", "shortCiteRegEx": "Mnih and Hinton.", "year": 2009}, {"title": "Emotional Tweets", "author": ["Saif M. Mohammad."], "venue": "Proceedings of the Joint Conference on Lexical and Computational Semantics. Montr\u00e9al, Canada, 246\u2013255.", "citeRegEx": "Mohammad.,? 2012", "shortCiteRegEx": "Mohammad.", "year": 2012}, {"title": "Sentiment Analysis: Detecting Valence, Emotions, and Other Affectual States from Text", "author": ["Saif M Mohammad."], "venue": "(2015).", "citeRegEx": "Mohammad.,? 2015", "shortCiteRegEx": "Mohammad.", "year": 2015}, {"title": "A Practical Guide to Sentiment Annotation: Challenges and Solutions", "author": ["Saif M. Mohammad."], "venue": "Proceedings of the Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis.", "citeRegEx": "Mohammad.,? 2016", "shortCiteRegEx": "Mohammad.", "year": 2016}, {"title": "Semeval-2016 Task 6: Detecting Stance in Tweets", "author": ["Saif M. Mohammad", "Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. San Diego, California.", "citeRegEx": "Mohammad et al\\.,? 2016", "shortCiteRegEx": "Mohammad et al\\.", "year": 2016}, {"title": "NRC-Canada: Building the State-ofthe-Art in Sentiment Analysis of Tweets", "author": ["Saif M. Mohammad", "Svetlana Kiritchenko", "Xiaodan Zhu."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. Atlanta, Georgia, USA.", "citeRegEx": "Mohammad et al\\.,? 2013", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon", "author": ["Saif M. Mohammad", "Peter D. Turney."], "venue": "Proceedings of the Workshop on Computational Approaches to Analysis and Generation of Emotion in Text. 26\u201334.", "citeRegEx": "Mohammad and Turney.,? 2010", "shortCiteRegEx": "Mohammad and Turney.", "year": 2010}, {"title": "Sentiment, emotion, purpose, and style in electoral tweets", "author": ["Saif M. Mohammad", "Xiaodan Zhu", "Svetlana Kiritchenko", "Joel Martin."], "venue": "Information Processing and Management 51 (2015), 480\u2013499.", "citeRegEx": "Mohammad et al\\.,? 2015", "shortCiteRegEx": "Mohammad et al\\.", "year": 2015}, {"title": "Opinion mining and sentiment analysis", "author": ["Bo Pang", "Lillian Lee."], "venue": "Foundations and Trends in Information Retrieval 2, 1\u20132 (2008), 1\u2013135.", "citeRegEx": "Pang and Lee.,? 2008", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "Grounded Semantic Parsing for Complex Knowledge Extraction", "author": ["Ankur P. Parikh", "Hoifung Poon", "Kristina Toutanova."], "venue": "Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Parikh et al\\.,? 2015", "shortCiteRegEx": "Parikh et al\\.", "year": 2015}, {"title": "SemEval-2015 Task 12: Aspect based sentiment analysis", "author": ["Maria Pontiki", "Dimitrios Galanis", "Haris Papageogiou", "Suresh Manandhar", "Ion Androutsopoulos."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. Denver, Colorado.", "citeRegEx": "Pontiki et al\\.,? 2015", "shortCiteRegEx": "Pontiki et al\\.", "year": 2015}, {"title": "SemEval-2014 Task 4: Aspect Based Sentiment Analysis", "author": ["Maria Pontiki", "Dimitrios Galanis", "John Pavlopoulos", "Harris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. Dublin, Ireland.", "citeRegEx": "Pontiki et al\\.,? 2014", "shortCiteRegEx": "Pontiki et al\\.", "year": 2014}, {"title": "Identifying Users with Opposing Opinions in Twitter Debates", "author": ["Ashwin Rajadesingan", "Huan Liu."], "venue": "Proceedings of the Conference on Social Computing, Behavioral-Cultural Modeling and Prediction. Washington, DC, USA, 153\u2013160.", "citeRegEx": "Rajadesingan and Liu.,? 2014", "shortCiteRegEx": "Rajadesingan and Liu.", "year": 2014}, {"title": "Linguistic Models for Analyzing and Detecting Biased Language", "author": ["Marta Recasens", "Cristian Danescu-Niculescu-Mizil", "Dan Jurafsky."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics. 1650\u20131659.", "citeRegEx": "Recasens et al\\.,? 2013", "shortCiteRegEx": "Recasens et al\\.", "year": 2013}, {"title": "Event Extraction Using Distant Supervision", "author": ["Kevin Reschke", "Martin Jankowiak", "Mihai Surdeanu", "Christopher D. Manning", "Daniel Jurafsky"], "venue": "In Proceedings of the International Conference on Language Resources and Evaluation", "citeRegEx": "Reschke et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reschke et al\\.", "year": 2014}, {"title": "Named entity recognition in tweets: an experimental study", "author": ["Alan Ritter", "Sam Clark", "Mausam", "Oren Etzioni."], "venue": "Proceedings of EMNLP. Edinburgh, Scotland, 1524\u20131534.", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "SemEval-2015 Task 10: Sentiment analysis in Twitter", "author": ["Sara Rosenthal", "Preslav Nakov", "Svetlana Kiritchenko", "Saif M. Mohammad", "Alan Ritter", "Veselin Stoyanov."], "venue": "Proceedings of the International Workshop on Semantic Evaluations.", "citeRegEx": "Rosenthal et al\\.,? 2015", "shortCiteRegEx": "Rosenthal et al\\.", "year": 2015}, {"title": "From Argumentation Mining to Stance Classification", "author": ["Parinaz Sobhani", "Diana Inkpen", "Stan Matwin."], "venue": "Proceedings of the Workshop on Argumentation Mining. Denver, Colorado, USA, 67\u201377.", "citeRegEx": "Sobhani et al\\.,? 2015", "shortCiteRegEx": "Sobhani et al\\.", "year": 2015}, {"title": "Recognizing stances in ideological on-line debates", "author": ["Swapna Somasundaran", "Janyce Wiebe."], "venue": "Proceedings of the NAACL HLT 2010 Workshop CAAGET. 116\u2013124.", "citeRegEx": "Somasundaran and Wiebe.,? 2010", "shortCiteRegEx": "Somasundaran and Wiebe.", "year": 2010}, {"title": "Learning sentiment-specific word embedding for Twitter sentiment classification", "author": ["Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics. 1555\u20131565.", "citeRegEx": "Tang et al\\.,? 2014", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts", "author": ["Matt Thomas", "Bo Pang", "Lillian Lee."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. 327\u2013335.", "citeRegEx": "Thomas et al\\.,? 2006", "shortCiteRegEx": "Thomas et al\\.", "year": 2006}, {"title": "Election Forecasts With Twitter: How 140 Characters Reflect the Political Landscape", "author": ["Andranik Tumasjan", "Timm O. Sprenger", "Philipp G. Sandner", "Isabell M. Welpe."], "venue": "Social Science Computer Review 29, 4 (2010), 402\u2013418.", "citeRegEx": "Tumasjan et al\\.,? 2010", "shortCiteRegEx": "Tumasjan et al\\.", "year": 2010}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Joseph Turian", "Lev Ratinov", "Yoshua Bengio."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics. 384\u2013394.", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews", "author": ["Peter D. Turney."], "venue": "Proceedings of the Association for Computational Linguistics. 417\u2013424.", "citeRegEx": "Turney.,? 2002", "shortCiteRegEx": "Turney.", "year": 2002}, {"title": "Stance classification using dialogic properties of persuasion", "author": ["Marilyn A. Walker", "Pranav Anand", "Robert Abbott", "Ricky Grant."], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 592\u2013596.", "citeRegEx": "Walker et al\\.,? 2012a", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "A Corpus for Research on Deliberation and Debate", "author": ["Marilyn A. Walker", "Jean E. Fox Tree", "Pranav Anand", "Rob Abbott", "Joseph King."], "venue": "Proceedings of the International Conference on Language Resources and Evaluation. 812\u2013817.", "citeRegEx": "Walker et al\\.,? 2012b", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "SemEval-2013 Task 2: Sentiment Analysis in Twitter", "author": ["Theresa Wilson", "Zornitsa Kozareva", "Preslav Nakov", "Sara Rosenthal", "Veselin Stoyanov", "Alan Ritter."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. Atlanta, USA.", "citeRegEx": "Wilson et al\\.,? 2013", "shortCiteRegEx": "Wilson et al\\.", "year": 2013}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann."], "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing. Vancouver, British Columbia, Canada, 347\u2013354.", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Shedding (a thousand points of) light on biased language", "author": ["Tae Yano", "Philip Resnik", "Noah A Smith."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon\u2019s Mechanical Turk. 152\u2013158.", "citeRegEx": "Yano et al\\.,? 2010", "shortCiteRegEx": "Yano et al\\.", "year": 2010}, {"title": "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection", "author": ["Guido Zarrella", "Amy Marsh."], "venue": "Proceedings of the International Workshop on Semantic Evaluation. San Diego, California.", "citeRegEx": "Zarrella and Marsh.,? 2016", "shortCiteRegEx": "Zarrella and Marsh.", "year": 2016}], "referenceMentions": [{"referenceID": 54, "context": "However, most work focuses on congressional debates [Thomas et al. 2006] or debates in online forums [Somasundaran and Wiebe 2010; Anand et al.", "startOffset": 52, "endOffset": 72}, {"referenceID": 0, "context": "2006] or debates in online forums [Somasundaran and Wiebe 2010; Anand et al. 2011; Walker et al. 2012a; Hasan and Ng 2013].", "startOffset": 34, "endOffset": 122}, {"referenceID": 58, "context": "2006] or debates in online forums [Somasundaran and Wiebe 2010; Anand et al. 2011; Walker et al. 2012a; Hasan and Ng 2013].", "startOffset": 34, "endOffset": 122}, {"referenceID": 38, "context": "(3) Organized a Shared Task Competition on Stance: Partitions of this stance-annotated data were used as training and test sets in the SemEval-2016 shared task competition, Task #6: Detecting Stance from Tweets [Mohammad et al. 2016].", "startOffset": 211, "endOffset": 233}, {"referenceID": 60, "context": "Past work has shown that the most useful features for sentiment analysis are word and character n-grams and sentiment lexicons, whereas others such as negation features, part-of-speech features, and punctuation have a smaller impact [Wilson et al. 2013; Mohammad et al. 2013; Kiritchenko et al. 2014a; Rosenthal et al. 2015].", "startOffset": 233, "endOffset": 324}, {"referenceID": 39, "context": "Past work has shown that the most useful features for sentiment analysis are word and character n-grams and sentiment lexicons, whereas others such as negation features, part-of-speech features, and punctuation have a smaller impact [Wilson et al. 2013; Mohammad et al. 2013; Kiritchenko et al. 2014a; Rosenthal et al. 2015].", "startOffset": 233, "endOffset": 324}, {"referenceID": 23, "context": "Past work has shown that the most useful features for sentiment analysis are word and character n-grams and sentiment lexicons, whereas others such as negation features, part-of-speech features, and punctuation have a smaller impact [Wilson et al. 2013; Mohammad et al. 2013; Kiritchenko et al. 2014a; Rosenthal et al. 2015].", "startOffset": 233, "endOffset": 324}, {"referenceID": 50, "context": "Past work has shown that the most useful features for sentiment analysis are word and character n-grams and sentiment lexicons, whereas others such as negation features, part-of-speech features, and punctuation have a smaller impact [Wilson et al. 2013; Mohammad et al. 2013; Kiritchenko et al. 2014a; Rosenthal et al. 2015].", "startOffset": 233, "endOffset": 324}, {"referenceID": 23, "context": "8 Positive and negative language tend to have sufficient amount of commonality regardless of topic of discussion, and hence sentiment analysis systems traditionally learn a single model from all of the training data [Liu 2015; Kiritchenko et al. 2014a; Rosenthal et al. 2015].", "startOffset": 216, "endOffset": 275}, {"referenceID": 50, "context": "8 Positive and negative language tend to have sufficient amount of commonality regardless of topic of discussion, and hence sentiment analysis systems traditionally learn a single model from all of the training data [Liu 2015; Kiritchenko et al. 2014a; Rosenthal et al. 2015].", "startOffset": 216, "endOffset": 275}, {"referenceID": 15, "context": "Tweets are tokenized and part-of-speech tagged with the CMU Twitter NLP tool [Gimpel et al. 2011].", "startOffset": 77, "endOffset": 97}, {"referenceID": 61, "context": "): The sentiment lexicon features are derived from three manually created lexicons: NRC Emotion Lexicon [Mohammad and Turney 2010], Hu and Liu Lexicon [Hu and Liu 2004], and MPQA Subjectivity Lexicon [Wilson et al. 2005], and two automatically created, tweet-specific, lexicons: NRC Hashtag Sentiment and NRC Emoticon (a.", "startOffset": 200, "endOffset": 220}, {"referenceID": 23, "context": "Sentiment140) [Kiritchenko et al. 2014a]; \u2022 target: presence/absence of the target of interest in the tweet;9 \u2022 POS: the number of occurrences of each part-of-speech tag (POS); \u2022 encodings (enc.", "startOffset": 14, "endOffset": 40}, {"referenceID": 60, "context": "10A similar metric was used in the past for sentiment analysis\u2014SemEval 2013 Task 2 [Wilson et al. 2013].", "startOffset": 83, "endOffset": 103}, {"referenceID": 16, "context": "For example, Go et al. [2009] extracted tweets that ended with emoticons \u2018:)\u2019 and \u2018:(\u2019.", "startOffset": 13, "endOffset": 30}, {"referenceID": 34, "context": "Mohammad [2012] and Kunneman et al.", "startOffset": 0, "endOffset": 16}, {"referenceID": 24, "context": "Mohammad [2012] and Kunneman et al. [2014] tested a similar hypothesis for emotions conveyed by hashtags at the end of a tweet and the rest of the tweet.", "startOffset": 20, "endOffset": 43}, {"referenceID": 55, "context": "17Turney [2002] and Kiritchenko et al.", "startOffset": 2, "endOffset": 16}, {"referenceID": 22, "context": "17Turney [2002] and Kiritchenko et al. [2014a] used similar measures for word\u2013sentiment associations.", "startOffset": 20, "endOffset": 47}, {"referenceID": 2, "context": "Word embeddings are low-dimensional real-valued vectors used to represent words in the vocabulary [Bengio et al. 2001].", "startOffset": 98, "endOffset": 118}, {"referenceID": 53, "context": "Word embeddings have been successfully used as features in a number of tasks including sentiment analysis [Tang et al. 2014] and named entity recognition [Turian et al.", "startOffset": 106, "endOffset": 124}, {"referenceID": 56, "context": "2014] and named entity recognition [Turian et al. 2010].", "startOffset": 35, "endOffset": 55}, {"referenceID": 32, "context": "We derive 100-dimensional word vectors using Word2Vec Skip-gram model [Mikolov et al. 2013] trained over the Domain Corpus (the window size was set to 10, and the minimum count to 2).", "startOffset": 70, "endOffset": 91}, {"referenceID": 59, "context": "com [Somasundaran and Wiebe 2010; Walker et al. 2012b; Hasan and Ng 2013].", "startOffset": 4, "endOffset": 73}, {"referenceID": 60, "context": "Sentiment Analysis and Opinion Mining There is a vast amount of work in sentiment analysis of tweets, and we refer the reader to surveys [Pang and Lee 2008; Liu and Zhang 2012; Mohammad 2015] and proceedings of recent shared task competitions [Wilson et al. 2013; Rosenthal et al. 2015].", "startOffset": 243, "endOffset": 286}, {"referenceID": 50, "context": "Sentiment Analysis and Opinion Mining There is a vast amount of work in sentiment analysis of tweets, and we refer the reader to surveys [Pang and Lee 2008; Liu and Zhang 2012; Mohammad 2015] and proceedings of recent shared task competitions [Wilson et al. 2013; Rosenthal et al. 2015].", "startOffset": 243, "endOffset": 286}, {"referenceID": 44, "context": "We refer the reader to SemEval proceedings for related work on ABSA [Pontiki et al. 2015; Pontiki et al. 2014].", "startOffset": 68, "endOffset": 110}, {"referenceID": 45, "context": "We refer the reader to SemEval proceedings for related work on ABSA [Pontiki et al. 2015; Pontiki et al. 2014].", "startOffset": 68, "endOffset": 110}, {"referenceID": 41, "context": "There has been considerable interest in analyzing political tweets towards detecting sentiment, emotion, and purpose in electoral tweets [Mohammad et al. 2015], determining political alignment of tweeters [Golbeck and Hansen 2011; Conover et al.", "startOffset": 137, "endOffset": 159}, {"referenceID": 6, "context": "2015], determining political alignment of tweeters [Golbeck and Hansen 2011; Conover et al. 2011a], identifying contentious issues and political opinions [Maynard and Funk 2011], detecting the amount of polarization in the electorate [Conover et al.", "startOffset": 51, "endOffset": 98}, {"referenceID": 7, "context": "2011a], identifying contentious issues and political opinions [Maynard and Funk 2011], detecting the amount of polarization in the electorate [Conover et al. 2011b], and even predicting the voting intentions or outcome of elections [Tumasjan et al.", "startOffset": 142, "endOffset": 164}, {"referenceID": 55, "context": "2011b], and even predicting the voting intentions or outcome of elections [Tumasjan et al. 2010; Bermingham and Smeaton 2011; Lampos et al. 2013].", "startOffset": 74, "endOffset": 145}, {"referenceID": 25, "context": "2011b], and even predicting the voting intentions or outcome of elections [Tumasjan et al. 2010; Bermingham and Smeaton 2011; Lampos et al. 2013].", "startOffset": 74, "endOffset": 145}, {"referenceID": 47, "context": "There are other subtasks in opinion mining related to stance classification, such as biased language detection [Recasens et al. 2013; Yano et al. 2010], perspective identification [Lin et al.", "startOffset": 111, "endOffset": 151}, {"referenceID": 62, "context": "There are other subtasks in opinion mining related to stance classification, such as biased language detection [Recasens et al. 2013; Yano et al. 2010], perspective identification [Lin et al.", "startOffset": 111, "endOffset": 151}, {"referenceID": 26, "context": "2010], perspective identification [Lin et al. 2006] and user classification based on their views [Kato et al.", "startOffset": 34, "endOffset": 51}, {"referenceID": 21, "context": "2006] and user classification based on their views [Kato et al. 2008].", "startOffset": 51, "endOffset": 69}, {"referenceID": 26, "context": "Perspective identification was defined as the subjective evaluation of points of view [Lin et al. 2006].", "startOffset": 86, "endOffset": 103}, {"referenceID": 22, "context": "In work by Somasundaran and Wiebe [2010], a lexicon for detecting argument trigger expressions was created and subsequently leveraged to identify arguments.", "startOffset": 11, "endOffset": 41}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts.", "startOffset": 0, "endOffset": 20}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language.", "startOffset": 0, "endOffset": 294}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language.", "startOffset": 0, "endOffset": 311}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language. Sobhani et al. [2015] extracted arguments used in online news comments to detect stance.", "startOffset": 0, "endOffset": 504}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language. Sobhani et al. [2015] extracted arguments used in online news comments to detect stance. Djemili et al. [2014] use a set of rules based on the syntax and discourse structure of the tweet to identify tweets that contain stance.", "startOffset": 0, "endOffset": 593}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language. Sobhani et al. [2015] extracted arguments used in online news comments to detect stance. Djemili et al. [2014] use a set of rules based on the syntax and discourse structure of the tweet to identify tweets that contain stance. Rajadesingan and Liu [2014] determine stance at user-level based on the assumption that if several users retweet one pair of tweets about a controversial topic, it is likely that they support the same side of a debate.", "startOffset": 0, "endOffset": 737}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language. Sobhani et al. [2015] extracted arguments used in online news comments to detect stance. Djemili et al. [2014] use a set of rules based on the syntax and discourse structure of the tweet to identify tweets that contain stance. Rajadesingan and Liu [2014] determine stance at user-level based on the assumption that if several users retweet one pair of tweets about a controversial topic, it is likely that they support the same side of a debate. Existing datasets for stance detection were created from online debate forums like 4forums.com and createdebates.com [Somasundaran and Wiebe 2010; Walker et al. 2012b; Hasan and Ng 2013]. The majority of these debates are two-sided, and the data labels are often provided by the authors of the posts. Topics of these debates are mostly related to ideological controversial issues such as gay rights and abortion. Sentiment Analysis and Opinion Mining There is a vast amount of work in sentiment analysis of tweets, and we refer the reader to surveys [Pang and Lee 2008; Liu and Zhang 2012; Mohammad 2015] and proceedings of recent shared task competitions [Wilson et al. 2013; Rosenthal et al. 2015]. Closely-related is the area of aspect based sentiment analysis (ABSA), where the goal is to determine sentiment towards aspects of a product such as speed of processor and screen resolution of a cell phone. We refer the reader to SemEval proceedings for related work on ABSA [Pontiki et al. 2015; Pontiki et al. 2014]. Mohammad et al. [2013] and Kiritchenko et al.", "startOffset": 0, "endOffset": 1971}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language. Sobhani et al. [2015] extracted arguments used in online news comments to detect stance. Djemili et al. [2014] use a set of rules based on the syntax and discourse structure of the tweet to identify tweets that contain stance. Rajadesingan and Liu [2014] determine stance at user-level based on the assumption that if several users retweet one pair of tweets about a controversial topic, it is likely that they support the same side of a debate. Existing datasets for stance detection were created from online debate forums like 4forums.com and createdebates.com [Somasundaran and Wiebe 2010; Walker et al. 2012b; Hasan and Ng 2013]. The majority of these debates are two-sided, and the data labels are often provided by the authors of the posts. Topics of these debates are mostly related to ideological controversial issues such as gay rights and abortion. Sentiment Analysis and Opinion Mining There is a vast amount of work in sentiment analysis of tweets, and we refer the reader to surveys [Pang and Lee 2008; Liu and Zhang 2012; Mohammad 2015] and proceedings of recent shared task competitions [Wilson et al. 2013; Rosenthal et al. 2015]. Closely-related is the area of aspect based sentiment analysis (ABSA), where the goal is to determine sentiment towards aspects of a product such as speed of processor and screen resolution of a cell phone. We refer the reader to SemEval proceedings for related work on ABSA [Pontiki et al. 2015; Pontiki et al. 2014]. Mohammad et al. [2013] and Kiritchenko et al. [2014b] came first in the 2013 Sentiment in Twitter and 2014 SemEval ABSA shared tasks.", "startOffset": 0, "endOffset": 2002}, {"referenceID": 0, "context": "Anand et al. [2011] deployed a rule-based classifier with several features such as unigrams, bigrams, punctuation marks, syntactic dependencies and the dialogic structure of the posts. The dialogic relations of agreements and disagreements between posts were exploited by Walker et al. [2012a]. Faulkner [2014] investigated the problem of detecting document-level stance in student essays by making use of two sets of features that are supposed to represent stance-taking language. Sobhani et al. [2015] extracted arguments used in online news comments to detect stance. Djemili et al. [2014] use a set of rules based on the syntax and discourse structure of the tweet to identify tweets that contain stance. Rajadesingan and Liu [2014] determine stance at user-level based on the assumption that if several users retweet one pair of tweets about a controversial topic, it is likely that they support the same side of a debate. Existing datasets for stance detection were created from online debate forums like 4forums.com and createdebates.com [Somasundaran and Wiebe 2010; Walker et al. 2012b; Hasan and Ng 2013]. The majority of these debates are two-sided, and the data labels are often provided by the authors of the posts. Topics of these debates are mostly related to ideological controversial issues such as gay rights and abortion. Sentiment Analysis and Opinion Mining There is a vast amount of work in sentiment analysis of tweets, and we refer the reader to surveys [Pang and Lee 2008; Liu and Zhang 2012; Mohammad 2015] and proceedings of recent shared task competitions [Wilson et al. 2013; Rosenthal et al. 2015]. Closely-related is the area of aspect based sentiment analysis (ABSA), where the goal is to determine sentiment towards aspects of a product such as speed of processor and screen resolution of a cell phone. We refer the reader to SemEval proceedings for related work on ABSA [Pontiki et al. 2015; Pontiki et al. 2014]. Mohammad et al. [2013] and Kiritchenko et al. [2014b] came first in the 2013 Sentiment in Twitter and 2014 SemEval ABSA shared tasks. We use most of the features they use in our classifier. There has been considerable interest in analyzing political tweets towards detecting sentiment, emotion, and purpose in electoral tweets [Mohammad et al. 2015], determining political alignment of tweeters [Golbeck and Hansen 2011; Conover et al. 2011a], identifying contentious issues and political opinions [Maynard and Funk 2011], detecting the amount of polarization in the electorate [Conover et al. 2011b], and even predicting the voting intentions or outcome of elections [Tumasjan et al. 2010; Bermingham and Smeaton 2011; Lampos et al. 2013]. There are other subtasks in opinion mining related to stance classification, such as biased language detection [Recasens et al. 2013; Yano et al. 2010], perspective identification [Lin et al. 2006] and user classification based on their views [Kato et al. 2008]. Perspective identification was defined as the subjective evaluation of points of view [Lin et al. 2006]. Deng et al. [2014] suggested an unsupervised framework to detect implicit sentiment by inference over explicit sentiments and events that positively or negatively affect the theme.", "startOffset": 0, "endOffset": 3076}, {"referenceID": 10, "context": "It has received a lot of attention in the past decade, and we refer the reader to surveys [Androutsopoulos and Malakasiotis 2010; Dagan et al. 2013] and proceedings of recent challenges on recognizing textual entailment [Bentivogli et al.", "startOffset": 90, "endOffset": 148}, {"referenceID": 3, "context": "2013] and proceedings of recent challenges on recognizing textual entailment [Bentivogli et al. 2011; Marelli et al. 2014; Dzikovska et al. 2016].", "startOffset": 77, "endOffset": 145}, {"referenceID": 30, "context": "2013] and proceedings of recent challenges on recognizing textual entailment [Bentivogli et al. 2011; Marelli et al. 2014; Dzikovska et al. 2016].", "startOffset": 77, "endOffset": 145}, {"referenceID": 13, "context": "2013] and proceedings of recent challenges on recognizing textual entailment [Bentivogli et al. 2011; Marelli et al. 2014; Dzikovska et al. 2016].", "startOffset": 77, "endOffset": 145}, {"referenceID": 33, "context": "This approach is widely used in automatic relation extraction, where information about pairs of related entities can be acquired from external knowledge sources such as Freebase or Wikipedia [Craven and Kumlien 1999; Mintz et al. 2009].", "startOffset": 191, "endOffset": 235}, {"referenceID": 16, "context": "In sentiment and emotion analysis, weakly labeled data can be accumulated by using sentiment clues provided by the authors of the text\u2013clues like emoticons and hashtags [Go et al. 2009; Mohammad 2012].", "startOffset": 169, "endOffset": 200}, {"referenceID": 29, "context": "Recently, distant supervision has been applied to topic classification [Husby and Barbosa 2012; Magdy et al. 2015], named entity recognition [Ritter et al.", "startOffset": 71, "endOffset": 114}, {"referenceID": 49, "context": "2015], named entity recognition [Ritter et al. 2011], event extraction [Reschke et al.", "startOffset": 32, "endOffset": 52}, {"referenceID": 48, "context": "2011], event extraction [Reschke et al. 2014], and semantic parsing [Parikh et al.", "startOffset": 24, "endOffset": 45}, {"referenceID": 43, "context": "2014], and semantic parsing [Parikh et al. 2015].", "startOffset": 28, "endOffset": 48}], "year": 2016, "abstractText": "We can often detect from a person\u2019s utterances whether he/she is in favor of or against a given target entity\u2014 their stance towards the target. However, a person may express the same stance towards a target by using negative or positive language. Here for the first time we present a dataset of tweet\u2013target pairs annotated for both stance and sentiment. The targets may or may not be referred to in the tweets, and they may or may not be the target of opinion in the tweets. Partitions of this dataset were used as training and test sets in a SemEval-2016 shared task competition. We propose a simple stance detection system that outperforms submissions from all 19 teams that participated in the shared task. Additionally, access to both stance and sentiment annotations allows us to explore several research questions. We show that while knowing the sentiment expressed by a tweet is beneficial for stance classification, it alone is not sufficient. Finally, we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification.", "creator": "LaTeX with hyperref package"}}}