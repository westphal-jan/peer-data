{"id": "1605.01681", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2016", "title": "Brain Emotional Learning-Based Prediction Model (For Long-Term Chaotic Prediction Applications)", "abstract": "This study suggests a new prediction model for chaotic time series inspired by the brain emotional learning of mammals. We describe the structure and function of this model, which is referred to as BELPM (Brain Emotional Learning-Based Prediction Model). Structurally, the model mimics the connection between the regions of the limbic system, and functionally it uses weighted k nearest neighbors to imitate the roles of those regions. The learning algorithm of BELPM is defined using steepest descent (SD) and the least square estimator (LSE). Two benchmark chaotic time series, Lorenz and Henon, have been used to evaluate the performance of BELPM. The obtained results have been compared with those of other prediction methods. The results show that BELPM has the capability to achieve a reasonable accuracy for long-term prediction of chaotic time series, using a limited amount of training data and a reasonably low computational time.", "histories": [["v1", "Thu, 5 May 2016 18:29:56 GMT  (928kb)", "http://arxiv.org/abs/1605.01681v1", "14 pages, 11 figures"]], "COMMENTS": "14 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mahboobeh parsapoor"], "accepted": false, "id": "1605.01681"}, "pdf": {"name": "1605.01681.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "In fact, it is the case that most people who are able to determine for themselves what they want and what they want to do, and that they have to do it in order to assert their interests. (...) In fact, it is the case that people are able to assert their interests. (...) In fact, it is the case that people who are able to assert their interests are not able to assert their interests. (...) In fact, it is the case that people who are able to assert their interests are not able to assert their interests. (...) In fact, it is the case that they are not willing to assert their interests. (...)"}, {"heading": "II. BACKGROUND", "text": "One of the most challenging topics in machine learning research is the development of high generalization algorithms to accurately predict chaotic systems. Recently, bioinspired models, especially emotion-based learning models [6], [8], [10], [12] - [14], have shown acceptable generalization capabilities in modelling and predicting the chaotic behavior of dynamic systems. In fact, this ability is achieved in emotion-based learning models by integrating machine learning algorithms with the computer model of emotional learning. In the following, we explain how emotional learning can be modelled as a computer-based tool and how it can be integrated with learning algorithms."}, {"heading": "A. Related Works in Modeling Emotional Learning", "text": "Since 1988, emotions and emotional processing have been active research topics for neuroscientists and psychologists. Great efforts have been made to analyze emotional behavior and describe emotions on the basis of various hypotheses, such as psychological, neurobiological, philosophical and learning hypotheses. These hypotheses, which have contributed to current computer-based models of emotional processing [18], have imitated certain aspects of emotional learning and can be classified on the basis of their basic theories and applications. For example, a computer-based model based on the central theory [19], [20] (which explains how a primary evaluation of emotional stimuli constitutes emotional experience) is called a computational model of emotional learning and mimics the associative learning aspect of emotional processing [18], which is based on fear conditioning [19], [20] Emotional processing has also been described using various anatomical structures: \"MacLean's limbic Schalbionic System, Cannanographic Structure 21 and Paper21\" on the first]."}, {"heading": "1) Anatomical Structure of Emotional Learning", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. Most of them are able to survive themselves, and most of them are not able to survive themselves. Most of them are able to survive themselves, and most of them are able to survive themselves. Most of them are able to survive themselves, and most of them are able to survive themselves."}, {"heading": "2) Emotion-Inspired Computational Models", "text": "In fact, most of them are able to survive on their own, without being able to survive on their own."}, {"heading": "B. A Brief Overview of the Data- Driven Methods", "text": "In fact, most of them are able to survive on their own if they do not put themselves in a position to survive on their own."}, {"heading": "A. Architecture of BELPM", "text": "In fact, the fact is that most of them will be able to move to another world, in which they are able to move, and in which they will be able to move to another world, in which they are able to move, in which they are in."}, {"heading": "B. Learning Algorithms of BELPM", "text": "The learning parameters are the weights (1 2 3w, w, w, etc.) and the parameters of the core functions (whether or not). As already mentioned, the learning algorithm of BELPM is divided into two phases: the first learning phase and the second learning phase. Each of them uses different learning rules to adjust the learning parameters. (1) First learning phase: In the first learning phase, a hybrid learning algorithm [3] is used, which is a combination of SD and LSE, to update the learning parameters of AMYG (e.g., a, a, 2w and 1 3w, w) and ORBI (o, 1 o, 2, wb)."}, {"heading": "IV. CASE STUDIES: CHAOTIC TIME SERIES", "text": "In order to allow a careful comparison with other methods, we used different datasets with different initialized points and sizes of training samples. In addition, we used two error measures: the normalized mean square error (NMSE) and the mean square error (MSE), as indicated in (39), (40), to evaluate the performance of the predictive models and provide results comparable to other studies. N2j jj 1 N 2j jj 1\u044b (y y y y) NMSE (y y y) (39) N 2j j j 11 \u0441MSE (y) N (40) Where y and y refer to the observed values and / or the desired targets. The parameter y is the average of the desired targets. For all experiments, a simple cross-validation was chosen; the number of samples in a one-time cross-validation corresponded to the size of the test data."}, {"heading": "A. Lorenz Time Series", "text": "The suggestions mentioned are primarily capable of establishing themselves in the region, both in the region and in the region in which they are located."}, {"heading": "B. Henon Time Series", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "V. DISCUSSION AND CONCLUSION", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}], "references": [{"title": "Nonlinear System Identification:From classicical Approches to Neural Networks and Fuzzy Models. Berlin, Germany", "author": ["O. Nelles"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Neural Networks: A Comperhensive Foundation.Upper Saddle River, NJ:Prentice Hall, 2 ed", "author": ["S. Haykin"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Neuro-Fuzzy and Soft Computing: A computational approach to Learning and Machine Intelligence.Upper Saddle River, NJ", "author": ["R. Jang", "C. Sun", "E. Mizutani"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1997}, {"title": "Time Series Prediction and Neural Networks", "author": ["R.J. Frank", "N. Davey", "S.P. Hunt"], "venue": "J. Intell Robot Syst., vol. 31, no. 1-3, pp. 91-103, 2001.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Predicting Chaotic Time Series Using Neuraland Neurofuzzy Models A Comparative Study", "author": ["A. Golipour", "B.N.Araabi.", "C. Lucas"], "venue": "J. Neural. Process Lett., vol. 24, no. 3, pp. 217-239, 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Neuro-fuzzy models, BELRFS and LoLiMoT, for prediction of chaotic time series", "author": ["M M. Parsapoor", "U. Bilstrup"], "venue": "Proc. IEEE Int. Conf. INISTA., pp.1-5, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Introducing BELBIC: brain emotional learning based intelligent controller", "author": ["C. Lucas", "D. Shahmirzadi", "N. Sheikholeslami"], "venue": "J. INTELL. AUTOM. SOFT. COMPUT., vol. 10, no. 1, pp. 11-22, 2004.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Enhancing the performance of neurofuzzy predictors by emotional learning algorithm", "author": ["C. Lucas", "A. Abbaspour", "A. Gholipour", "B. Nadjar Araabi", "M. Fatourechi"], "venue": "J. Informatica (Slovenia)., vol. 27, no. 2 pp.165\u2013174, 2003.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning based brain emotional intelligence as a new aspect for development of an alarm system", "author": ["T. Babaie", "R. Karimizandi", "C. Lucas"], "venue": "J. Soft Computing., vol. 9, issue 9, pp.857-873, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Reinforcement _recurrent fuzzy rule based system based on brain emotional learning structure to predict the complexity dynamic system", "author": ["M. Parsapoor", "C. Lucas", "S. Setayeshi"], "venue": "Proc. IEEE Int. Conf. ICDIM, , pp.25-32, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Brain Emotional Learning Based Fuzzy Inference System (BELFIS) for Solar Activity Forecasting", "author": ["M. Parsapoor", "U. Bilstrup"], "venue": "Proc. IEEE Int. Conf. ICTAI 2012, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Chaotic Time Series Prediction Using Brain Emotional Learning Based Recurrent Fuzzy System (BELRFS)", "author": ["M. Parsapoor", "U. Bilstrup"], "venue": "to be published in International Journal of Reasoning-based Intelligent Systems, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Prediction the price of Virtual Supply Chain Management with using emotional methods", "author": ["M. Parsapoor"], "venue": "M.S. thesis, Dept. Computer. Eng., Science and research Branch, IAU., Tehran, Iran,2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Application of emotional learning fuzzy inference systems and locally linear neuro-fuzzy models for prediction and simulation in dynamic systems", "author": ["M. Abdollahzade", "A. Miranian", "S. Faraji"], "venue": "Proc. IEEE Int. Joint Conf. Fuzzy Syst., pp. 1\u20138,2012", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Supervised brain emotional learning", "author": ["E. Lotfi", "M.R. Akbarzadeh-T"], "venue": "Proc. IJCNN, pp.1-6, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Emotional controller (BELBIC) based DTC for encoderless Synchronous Reluctance Motor drives", "author": ["H", "A. Zarchi", "E. Daryabeigi", "G.R. A .Markadeh", "J. Soltani"], "venue": "Proc. Int. Conf. PEDSTC, pp.478-483 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Emotional Circuits and Computational Neuroscience", "author": ["J.M.Fellous", "J.L.Armony", "J.E. LeDoux"], "venue": "The Handbook of Brain Theory and Neural Networks, The MIT Press, Cambridge, MA, 2003.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "How the Brain Processes Emotional Information", "author": ["J.L. Armony", "J.E. LeDoux"], "venue": "J. Ann. N. Y. Acad., no. 821, pp. 259-270, 1997.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "The Imbalanced Brain: From Normal Behavior To Schizophrenia", "author": ["S. Grossberg"], "venue": "J. Biol. Psychiatry., vol. 48, no. 2, pp. 81-98, 2000.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2000}, {"title": "The emotional brain", "author": ["T.Dalgleish"], "venue": "J. NAT REV NEUROSCI., vol. 5, no. 7, pp. 583\u2013589, 2004.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "Color and Contrast Sensitivity in the Lateral Geniculate Body and Primary Visual Cortex of the Macaque Monkey", "author": ["D.H. Hubel", "M.S. Livingstone"], "venue": "J., Neuroscience. vol. 10, no.7, pp. 2223-2237, 1990.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1990}, {"title": "The Neural Basis of Perception and Movement, Principles of Neural Science", "author": ["J.P. Kelly"], "venue": "London: Prentice Hall. 1991.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1991}, {"title": "Cytoarchitectonic mapping of the human amygdala, hippocampal region and entorhinal cortex : intersubject variability and probability maps", "author": ["K. Amunts.", "O. Kedo.", "M. Kindler.", "P. Pieperhoff.", "H. Mohlberg.", "N. Shah.", "U. Habel.", "F. Schneider.", "K. Zilles."], "venue": "J. Anatomy and Embryology., vol. 21, no. 5-6, pp. 343-352, 2005.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "Amygdala Response to Facial Expressions Reflects Emotional Learning", "author": ["C.I. Hooker.", "L.T. Germine.", "R.T. Knight.", "M.D. Esposito."], "venue": "Neuroscience. J., vol. 26, no.35, pp. 8915-8930, Aug. 2006.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2006}, {"title": "Primate Orbitofrontal Cortex and Adaptive Behavior,\u2019", "author": ["AC. Robert"], "venue": "J. TRENDS. COGN. SCI,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "The orbitofrontal cortex: linking reward to hedonic experience", "author": ["M.L. Kringelbach."], "venue": "J., Nat. Rev. Neurosci., vol. 6, pp. 691-702,2005.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "The Brain and Emotion by Edmund T. Rolls", "author": ["A.G. Phillips."], "venue": "J. TRENDS. COGN. SCI., vol. 3, pp. 281-282, 1999.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1999}, {"title": "Schultz.,\u201cThe Mysterios of Orbitofrontal Cortex. Foreword", "author": ["W.C. Cavada"], "venue": "Cereb Cortex,\u2019\u2019, J. Cerebr. Cortex. vol. 10,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2000}, {"title": "Constracting Roles of Basolateral Amygdala and Orbitofrontal Cortex in Impulsive Choice", "author": ["C.A. Winstanley", "D.E.H. Theobald", "R.N. Cardinal", "T.W. Robbins"], "venue": "J. Neurosci., vol. 24, no. 20, pp. 4718-4722, 2004.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "The functional neuroanatomy of the human orbitofrontal cortex: evidence from neuroimaging and neuropsychology", "author": ["M.L. Kringelbach", "E.T. Rolls"], "venue": "J., Prog. Neurobiol, vol. 72, pp. 341\u2013372, 2004.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2004}, {"title": "Emotion-Based Decision and Learning Using Associative Memory and Statistical Estimation", "author": ["B.D. Damas", "L. Cust\u00f3dio"], "venue": "J. Informatica (Slovenia), vol. 27, no. 2, pp. 145-156, 2004.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}, {"title": "When Robots Weep: Emotional Memories and Decision-Making", "author": ["J.D. Vel\u00e1squez."], "venue": "Proc. Conf. on Artifitial Intelligence, pp.70-75. 1997.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1997}, {"title": "Emotional behaviour: A resourcemanagement approach", "author": ["S.H. Zadeh", "S.B. Shouraki", "R R. Halavati"], "venue": "J. Adaptive Behaviour, vol. 14, pp. 357-380, 2006.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2006}, {"title": "Multiple Emotion-Based Agents Using an Extension of DARE Architecture", "author": ["M. Ma\u00e7\u00e3s", "L. Cust\u00f3dio"], "venue": "J. Informatica (Slovenia), vol. 27, no. 2, pp. 185-196, 2004.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2004}, {"title": "Lucas,\"Emotional controller (BELBIC) for electric drives \u2014 A review,", "author": ["E. Daryabeigi", "C.G.R.A. Markadeh"], "venue": "in Proc. Annual Conference on IEEE Industrial Electronics,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2010}, {"title": "Applying Brain Emotional Learning Algorithm for Multivariable Control of HVAC Systems,", "author": ["N. Sheikholeslami", "D. Shahmirzadi", "E. Semsar", "C. Lucas"], "venue": "J. INTELL. FUZZY", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2005}, {"title": "Roshanian,\"Aerospace Launch Vehicle Control: An Intelligent Adaptive Approach", "author": ["A.R. Mehrabian", "J.C. Lucas"], "venue": "J. Aerosp. Sci. Technol.,vol.10,pp", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2006}, {"title": "Intelligent Modeling and Control of Washing Machines Using LLNF Modeling and Modified BELBIC", "author": ["R.M. Milasi", "C. Lucas", "B.N. Araabi"], "venue": "Proc. Int. Conf. Control and Automation., pp.812-817, 2005,.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2005}, {"title": "Brain emotional learning based intelligent controller for stepper motor trajectory tracking", "author": ["A.M. Yazdani1", "S. Buyamin1", "S. Mahmoudzadeh2", "Z. Ibrahim1", "M.F. Rahmat1."], "venue": "J. IJPS., vol. 7, no. 15, pp. 2364- 2386, 2012.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2012}, {"title": "Emotional Learning as a New Tool for Development of Agent-based System", "author": ["M. Fatourechi", "C. Lucas", "A.K. Sedigh"], "venue": "J. Informatica (Slovenia), vol. 27, no. 2, pp.137-144., 2004.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning Behavior-selection in a Multigoal Robot Task", "author": ["S.C. Gadanho", "L. Cust\u00f3dio"], "venue": "J. Informatica (Slovenia), vol. 27, no. 2, pp. 175-184, 2003.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2003}, {"title": "A dynamic associative memory system by adopting amygdala model", "author": ["T. Kuremoto", "K.T. Ohta", "M. Kobayashi", "Obayashi"], "venue": "J. AROB, vol.13, pp.478\u2013482, 2009.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2009}, {"title": "A functional model of limbic system of brain", "author": ["T. Kuremoto", "T. Ohta", "K.K. Kobayashi", "M. Obayashi"], "venue": "Proc. Int. Conf. Brain informatics, pp.135-146, 2009.,.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2009}, {"title": "Recursive Bayesian recurrent neural networks for time-series modeling", "author": ["D. Mirikitani", "N. Nikolaev"], "venue": "IEEE Trans. Neural Netw., vol. 21, no. 2, pp. 262\u2013274, Feb. 2010.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2010}, {"title": "Input variables selection using mutual information for neuro fuzzy modeling with the application to time series forecasting", "author": ["M.M.R. Yousefi", "M. Mirmomeni", "C. Lucas"], "venue": "Proc. Int. Joint Conf. Neural Netw., pp. 1121\u20131126, 2007.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2007}, {"title": "Time-series prediction using a local linear wavelet neural network", "author": ["Y. Chen", "B. Yang", "J. Dong"], "venue": "J. Neurocomputing, vol. 69, nos. 4\u20136, pp. 449\u2013465, 2006.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2006}, {"title": "Time series prediction using support vector machines: A survey", "author": ["N.I. Sapankevych", "R. Sankar"], "venue": "IEEE Comput. Intell. Mag., vol. 4, no. 2, pp. 24\u201338, May 2009.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2009}, {"title": "Chaotic time series prediction based on a novel robust echo state network", "author": ["D. Li", "M. Han", "J. Wang"], "venue": "IEEE Trans. Neural Netw Learn. Syst., vol. 23, no. 5, pp. 787\u2013799, May 2012.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2012}, {"title": "Weighted k-Nearest-Neighbor Techniques and Ordinal Classification,", "author": ["S. Hechenbichler"], "venue": "Discussion Paper 399,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2004}, {"title": "P.Indyk, Nearest-Neighbor Methods in Learning and Vision:Theory and Practice", "author": ["G. Shakhnarovich", "T. Darrell"], "venue": null, "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2006}, {"title": "Extracting the main patterns of natural time series for long-term neurofuzzy prediction", "author": ["A.Gholipour", "C.Luca", "B.N.Araabi", "M.Mirmomeni", "M.Shafiee"], "venue": "J. Neural Computing & Applications., vol. 16, Issue, 4-5, pp. 383-393, 2007", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2007}, {"title": "Chaotic time series prediction with residual analysis method using hybrid Elman\u2013NARX neural networks", "author": ["M. Ardalani-Farsa", "S S. Zolfaghari"], "venue": "J. Neurocomputing, vol.73, issues 13\u201315, pp.2540-2553, 2010.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2010}, {"title": "Chaotic Time Series Prediction Based on Evolving Recurrent Neural Networks", "author": ["M. Qian-Li", "Z. Qi-lun", "P. Hong", "Z. Tan-Wei", "X. Li-Qiang"], "venue": "Proc. Int. Conf. Machine Learning and Cybernetics (ICMLC.2007), vol.6,no.,pp.3496,3500, 2007.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2007}, {"title": "Cooperative coevolution of elman recurrent neural networks for chaotic time series prediction,\u2019\u2019J", "author": ["R. Chandra", "M. Zhang"], "venue": "Neurocomputing, vol. 86,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2012}, {"title": "Nonlinear time series modeling and prediction using functional weights wavelet neural network-based statedependent AR model", "author": ["G. Inoussa", "H. Peng", "J. Wu"], "venue": "J. Neurocomputing Journal, vol. 86, pp. 59- 74,2012.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2012}, {"title": "Developing a Local Least-Squares Support Vector Machines-Based Neuro-Fuzzy Model for Nonlinear and Chaotic Time Series Prediction", "author": ["A. Miranian", "M. Abdollahzade"], "venue": "IEEE Trans. Neural Netw, vol.24, no.2, pp. 207-218, 2013.", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2013}, {"title": "Recursive Bayesian Recurrent Neural Networks for Time-Series Modeling,", "author": ["D.T. Mirikitani", "N. Nikolaev"], "venue": "IEEE Trans. Neural Netw, vol.21,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Well-known data-driven methodologies such as neural networks and neuro-fuzzy models have shown reasonable accuracy in the nonlinear prediction of chaotic time series [1].", "startOffset": 166, "endOffset": 169}, {"referenceID": 1, "context": "According to the VapnikChervonenkis (VC) theory [2], a sufficient size of training samples for achieving arbitrary prediction accuracy is proportional to the number of the models\u2019 learning parameters.", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": ", the number of training samples, chaos degree, embedding dimension, and the horizon of prediction) [1]\u2013[5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": ", the number of training samples, chaos degree, embedding dimension, and the horizon of prediction) [1]\u2013[5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 5, "context": "The model aims at continuing the recent studies that have suggested computational models of emotional processing for control and prediction applications [6]-[16].", "startOffset": 153, "endOffset": 156}, {"referenceID": 15, "context": "The model aims at continuing the recent studies that have suggested computational models of emotional processing for control and prediction applications [6]-[16].", "startOffset": 157, "endOffset": 161}, {"referenceID": 2, "context": "Adaptive-Network-Based Fuzzy Inference System (ANFIS) [3], MultiLayer Perceptron (MLP) Network [1], [2], Radial Bias Function (RBF) Networks [1], [2], and Local Linear Neuro-Fuzzy (LLNF) Models [1]).", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "Adaptive-Network-Based Fuzzy Inference System (ANFIS) [3], MultiLayer Perceptron (MLP) Network [1], [2], Radial Bias Function (RBF) Networks [1], [2], and Local Linear Neuro-Fuzzy (LLNF) Models [1]).", "startOffset": 95, "endOffset": 98}, {"referenceID": 1, "context": "Adaptive-Network-Based Fuzzy Inference System (ANFIS) [3], MultiLayer Perceptron (MLP) Network [1], [2], Radial Bias Function (RBF) Networks [1], [2], and Local Linear Neuro-Fuzzy (LLNF) Models [1]).", "startOffset": 100, "endOffset": 103}, {"referenceID": 0, "context": "Adaptive-Network-Based Fuzzy Inference System (ANFIS) [3], MultiLayer Perceptron (MLP) Network [1], [2], Radial Bias Function (RBF) Networks [1], [2], and Local Linear Neuro-Fuzzy (LLNF) Models [1]).", "startOffset": 141, "endOffset": 144}, {"referenceID": 1, "context": "Adaptive-Network-Based Fuzzy Inference System (ANFIS) [3], MultiLayer Perceptron (MLP) Network [1], [2], Radial Bias Function (RBF) Networks [1], [2], and Local Linear Neuro-Fuzzy (LLNF) Models [1]).", "startOffset": 146, "endOffset": 149}, {"referenceID": 0, "context": "Adaptive-Network-Based Fuzzy Inference System (ANFIS) [3], MultiLayer Perceptron (MLP) Network [1], [2], Radial Bias Function (RBF) Networks [1], [2], and Local Linear Neuro-Fuzzy (LLNF) Models [1]).", "startOffset": 194, "endOffset": 197}, {"referenceID": 5, "context": "Recently, bioinspired models, in particular, emotion-based learning models [6], [8], [10], [12]-[14], have shown acceptable generalization capability in modeling and predicting the chaotic behavior of dynamic systems.", "startOffset": 75, "endOffset": 78}, {"referenceID": 7, "context": "Recently, bioinspired models, in particular, emotion-based learning models [6], [8], [10], [12]-[14], have shown acceptable generalization capability in modeling and predicting the chaotic behavior of dynamic systems.", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "Recently, bioinspired models, in particular, emotion-based learning models [6], [8], [10], [12]-[14], have shown acceptable generalization capability in modeling and predicting the chaotic behavior of dynamic systems.", "startOffset": 85, "endOffset": 89}, {"referenceID": 11, "context": "Recently, bioinspired models, in particular, emotion-based learning models [6], [8], [10], [12]-[14], have shown acceptable generalization capability in modeling and predicting the chaotic behavior of dynamic systems.", "startOffset": 91, "endOffset": 95}, {"referenceID": 13, "context": "Recently, bioinspired models, in particular, emotion-based learning models [6], [8], [10], [12]-[14], have shown acceptable generalization capability in modeling and predicting the chaotic behavior of dynamic systems.", "startOffset": 96, "endOffset": 100}, {"referenceID": 17, "context": "These hypotheses that have contributed to the present computer-based models of emotional processing [18], have imitated certain aspects of emotional learning, and can be classified on the basis of their fundamental theories and applications.", "startOffset": 100, "endOffset": 104}, {"referenceID": 17, "context": "For example, a computer-based model that is based on the central theory [18] (i.", "startOffset": 72, "endOffset": 76}, {"referenceID": 17, "context": ", which explains how a primary evaluation of emotional stimuli forms emotional experiences) is called a computational model of emotional learning and imitates the associative learning aspect of emotional processing [18] that is based on fear conditioning [19], [ 20].", "startOffset": 215, "endOffset": 219}, {"referenceID": 18, "context": ", which explains how a primary evaluation of emotional stimuli forms emotional experiences) is called a computational model of emotional learning and imitates the associative learning aspect of emotional processing [18] that is based on fear conditioning [19], [ 20].", "startOffset": 255, "endOffset": 259}, {"referenceID": 19, "context": ", which explains how a primary evaluation of emotional stimuli forms emotional experiences) is called a computational model of emotional learning and imitates the associative learning aspect of emotional processing [18] that is based on fear conditioning [19], [ 20].", "startOffset": 261, "endOffset": 266}, {"referenceID": 22, "context": ", determining the effective values of stimuli [22]-[28].", "startOffset": 51, "endOffset": 55}, {"referenceID": 22, "context": "It then passes the generated signals to the amygdala and sensory cortex [28].", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "The thalamus includes different parts that process the emotional stimuli separately [27].", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "The sensory cortex distributes its output signals between the amygdala and orbitofrontal region [18]-[21], [27].", "startOffset": 96, "endOffset": 100}, {"referenceID": 21, "context": "The sensory cortex distributes its output signals between the amygdala and orbitofrontal region [18]-[21], [27].", "startOffset": 107, "endOffset": 111}, {"referenceID": 17, "context": "c) Amygdala is the central part of the limbic system of mammals and has a principal role in emotional learning [18][26].", "startOffset": 111, "endOffset": 115}, {"referenceID": 20, "context": "c) Amygdala is the central part of the limbic system of mammals and has a principal role in emotional learning [18][26].", "startOffset": 115, "endOffset": 119}, {"referenceID": 20, "context": "It has connections to the thalamus, orbitofrontal cortex, and hypothalamus [25], [26].", "startOffset": 81, "endOffset": 85}, {"referenceID": 23, "context": "During emotional learning, the amygdala participates in reacting to emotional stimuli, storing emotional responses [29], evaluating positive and negative reinforcement [30], learning the association between unconditioned and conditioned stimuli [19], [20], [31], predicting the association between stimuli and future reinforcement [31], and forming an association between neutral stimuli and emotionally charged stimuli [30].", "startOffset": 115, "endOffset": 119}, {"referenceID": 18, "context": "During emotional learning, the amygdala participates in reacting to emotional stimuli, storing emotional responses [29], evaluating positive and negative reinforcement [30], learning the association between unconditioned and conditioned stimuli [19], [20], [31], predicting the association between stimuli and future reinforcement [31], and forming an association between neutral stimuli and emotionally charged stimuli [30].", "startOffset": 245, "endOffset": 249}, {"referenceID": 19, "context": "During emotional learning, the amygdala participates in reacting to emotional stimuli, storing emotional responses [29], evaluating positive and negative reinforcement [30], learning the association between unconditioned and conditioned stimuli [19], [20], [31], predicting the association between stimuli and future reinforcement [31], and forming an association between neutral stimuli and emotionally charged stimuli [30].", "startOffset": 251, "endOffset": 255}, {"referenceID": 16, "context": "The diagram shows the pattern of fear conditioning, which needs to be clarified [17].", "startOffset": 80, "endOffset": 84}, {"referenceID": 17, "context": "The basolateral part has the bidirectional link to the insular cortex and orbital cortex [18], [20], [21], [25], [26] and performs the main role in mediating memory consolidation [32] and providing the primary response, and is divided into three parts: the lateral, basal, and accessory basal [25], [29].", "startOffset": 89, "endOffset": 93}, {"referenceID": 19, "context": "The basolateral part has the bidirectional link to the insular cortex and orbital cortex [18], [20], [21], [25], [26] and performs the main role in mediating memory consolidation [32] and providing the primary response, and is divided into three parts: the lateral, basal, and accessory basal [25], [29].", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "The basolateral part has the bidirectional link to the insular cortex and orbital cortex [18], [20], [21], [25], [26] and performs the main role in mediating memory consolidation [32] and providing the primary response, and is divided into three parts: the lateral, basal, and accessory basal [25], [29].", "startOffset": 113, "endOffset": 117}, {"referenceID": 24, "context": "The basolateral part has the bidirectional link to the insular cortex and orbital cortex [18], [20], [21], [25], [26] and performs the main role in mediating memory consolidation [32] and providing the primary response, and is divided into three parts: the lateral, basal, and accessory basal [25], [29].", "startOffset": 179, "endOffset": 183}, {"referenceID": 23, "context": "The basolateral part has the bidirectional link to the insular cortex and orbital cortex [18], [20], [21], [25], [26] and performs the main role in mediating memory consolidation [32] and providing the primary response, and is divided into three parts: the lateral, basal, and accessory basal [25], [29].", "startOffset": 299, "endOffset": 303}, {"referenceID": 19, "context": "The basal and accessory basal parts participate in mediating the contextual conditioning [20], [25].", "startOffset": 89, "endOffset": 93}, {"referenceID": 20, "context": "The centeromedial part, which is the main output for the basaloteral part [26], is divided into the central and medial parts [18], [20], [25], [26].", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "The centeromedial part, which is the main output for the basaloteral part [26], is divided into the central and medial parts [18], [20], [25], [26].", "startOffset": 125, "endOffset": 129}, {"referenceID": 19, "context": "The centeromedial part, which is the main output for the basaloteral part [26], is divided into the central and medial parts [18], [20], [25], [26].", "startOffset": 131, "endOffset": 135}, {"referenceID": 20, "context": "The centeromedial part, which is the main output for the basaloteral part [26], is divided into the central and medial parts [18], [20], [25], [26].", "startOffset": 143, "endOffset": 147}, {"referenceID": 20, "context": "It is responsible for the hormonal aspects of emotional reactions [25] or for mediating the expression of the emotional responses [25], [26].", "startOffset": 136, "endOffset": 140}, {"referenceID": 17, "context": "It also evaluates and corrects reward and punishment [18]-[21], [33][37], selects goals, makes decisions for a quick response to punishment [18], [23], [25]-[36], and prevents inappropriate responses of the amygdala.", "startOffset": 53, "endOffset": 57}, {"referenceID": 25, "context": "It also evaluates and corrects reward and punishment [18]-[21], [33][37], selects goals, makes decisions for a quick response to punishment [18], [23], [25]-[36], and prevents inappropriate responses of the amygdala.", "startOffset": 64, "endOffset": 68}, {"referenceID": 29, "context": "It also evaluates and corrects reward and punishment [18]-[21], [33][37], selects goals, makes decisions for a quick response to punishment [18], [23], [25]-[36], and prevents inappropriate responses of the amygdala.", "startOffset": 68, "endOffset": 72}, {"referenceID": 17, "context": "It also evaluates and corrects reward and punishment [18]-[21], [33][37], selects goals, makes decisions for a quick response to punishment [18], [23], [25]-[36], and prevents inappropriate responses of the amygdala.", "startOffset": 140, "endOffset": 144}, {"referenceID": 28, "context": "It also evaluates and corrects reward and punishment [18]-[21], [33][37], selects goals, makes decisions for a quick response to punishment [18], [23], [25]-[36], and prevents inappropriate responses of the amygdala.", "startOffset": 157, "endOffset": 161}, {"referenceID": 29, "context": "The medial part forms and memorizes reinforcement\u2013stimulus association, and also has role in providing responses and monitoring them, whereas the lateral part evaluates the response and provides punishment [37].", "startOffset": 206, "endOffset": 210}, {"referenceID": 30, "context": "It was applied for simulating artificial soccer playing [38], and its results were fairly good.", "startOffset": 56, "endOffset": 60}, {"referenceID": 31, "context": "The Cathexis model [39] was another emotional agent developed that reacted to an environment by imitating an emotional decision-making process in humans.", "startOffset": 19, "endOffset": 23}, {"referenceID": 32, "context": "The model of the mind [40] was developed as a modular artificial agent to generate emotional behavior for making decisions.", "startOffset": 22, "endOffset": 26}, {"referenceID": 33, "context": "An agent architecture that was called Emotionbased Robotic Agent Development (in reverse order, DARE) was developed on the basis of the somatic marker theory; it was tested in a multi-agent system and showed ability in modeling social and emotional behavior [41].", "startOffset": 258, "endOffset": 262}, {"referenceID": 6, "context": "b) Emotion-based controller: The first practical implementation of an emotion-based controller is BELBIC (Brain Emotional Learning-Based Intelligent Controller) [7].", "startOffset": 161, "endOffset": 164}, {"referenceID": 6, "context": "It was developed on the basis of Moren and Balkenius computational model [7], [23], [42].", "startOffset": 73, "endOffset": 76}, {"referenceID": 34, "context": "It was developed on the basis of Moren and Balkenius computational model [7], [23], [42].", "startOffset": 84, "endOffset": 88}, {"referenceID": 35, "context": "The BELBIC has been successfully employed for a number of applications: controlling heating and air conditioning [43] of aerospace launch vehicles [44], intelligent washing machines [45], and trajectory tracking of stepper motor [46].", "startOffset": 113, "endOffset": 117}, {"referenceID": 36, "context": "The BELBIC has been successfully employed for a number of applications: controlling heating and air conditioning [43] of aerospace launch vehicles [44], intelligent washing machines [45], and trajectory tracking of stepper motor [46].", "startOffset": 147, "endOffset": 151}, {"referenceID": 37, "context": "The BELBIC has been successfully employed for a number of applications: controlling heating and air conditioning [43] of aerospace launch vehicles [44], intelligent washing machines [45], and trajectory tracking of stepper motor [46].", "startOffset": 182, "endOffset": 186}, {"referenceID": 38, "context": "The BELBIC has been successfully employed for a number of applications: controlling heating and air conditioning [43] of aerospace launch vehicles [44], intelligent washing machines [45], and trajectory tracking of stepper motor [46].", "startOffset": 229, "endOffset": 233}, {"referenceID": 39, "context": "Another emotionbased intelligent controller is a neuro-fuzzy controller [47], which was integrated with emotion-based performance measurement to tune the parameters of the controller.", "startOffset": 72, "endOffset": 76}, {"referenceID": 40, "context": "Application of an emotion-based controller robotics was proposed in [48], which is an interesting example of applying emotional concepts in robotic applications and imitated the reinforcement learning aspect of emotional processing.", "startOffset": 68, "endOffset": 72}, {"referenceID": 6, "context": "Specifically, the BELBIC has been proven to outperform others in terms of simplicity, reliability, and stability [7], [39]-[42].", "startOffset": 113, "endOffset": 116}, {"referenceID": 31, "context": "Specifically, the BELBIC has been proven to outperform others in terms of simplicity, reliability, and stability [7], [39]-[42].", "startOffset": 118, "endOffset": 122}, {"referenceID": 34, "context": "Specifically, the BELBIC has been proven to outperform others in terms of simplicity, reliability, and stability [7], [39]-[42].", "startOffset": 123, "endOffset": 127}, {"referenceID": 41, "context": "Hippocampus-neocortex and amygdala hippocampus model have been proposed as neural network models [49], [50].", "startOffset": 97, "endOffset": 101}, {"referenceID": 42, "context": "Hippocampus-neocortex and amygdala hippocampus model have been proposed as neural network models [49], [50].", "startOffset": 103, "endOffset": 107}, {"referenceID": 5, "context": "Several emotionbased prediction models [6], [8]-[15] have been developed to model the complex systems.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "Several emotionbased prediction models [6], [8]-[15] have been developed to model the complex systems.", "startOffset": 44, "endOffset": 47}, {"referenceID": 14, "context": "Several emotionbased prediction models [6], [8]-[15] have been developed to model the complex systems.", "startOffset": 48, "endOffset": 52}, {"referenceID": 8, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 43, "endOffset": 46}, {"referenceID": 5, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 79, "endOffset": 82}, {"referenceID": 9, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 84, "endOffset": 88}, {"referenceID": 10, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 90, "endOffset": 94}, {"referenceID": 12, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 101, "endOffset": 105}, {"referenceID": 5, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 156, "endOffset": 159}, {"referenceID": 7, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 161, "endOffset": 164}, {"referenceID": 13, "context": ", auroral electrojec (AE) index prediction [9], solar activity prediction [6], [8], [10], [11]-[13], [14], and financial and chaotic time series prediction [6], [8]-[14].", "startOffset": 165, "endOffset": 169}, {"referenceID": 0, "context": ", Lorenz, Henon, Mackey-Glass, Ikeda) [1]-[15], [51]-[55].", "startOffset": 38, "endOffset": 41}, {"referenceID": 14, "context": ", Lorenz, Henon, Mackey-Glass, Ikeda) [1]-[15], [51]-[55].", "startOffset": 42, "endOffset": 46}, {"referenceID": 43, "context": ", Lorenz, Henon, Mackey-Glass, Ikeda) [1]-[15], [51]-[55].", "startOffset": 48, "endOffset": 52}, {"referenceID": 47, "context": ", Lorenz, Henon, Mackey-Glass, Ikeda) [1]-[15], [51]-[55].", "startOffset": 53, "endOffset": 57}, {"referenceID": 0, "context": "2) Generalization Regression Neural Network (GRNN) [1] differs from BELPM in its number of neurons (i.", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "4) Local Linear Neuro Fuzzy Models (LLNF) and BELPM can both be considered as types of \u201clocal modeling\u201d [2] algorithms.", "startOffset": 104, "endOffset": 107}, {"referenceID": 1, "context": "5) Modular neural network is a combination of several modules with different inputs [2] without any connection with others.", "startOffset": 84, "endOffset": 87}, {"referenceID": 0, "context": "6) Hybrid structures that are defined in [1], differ from BELPM in receiving the input data.", "startOffset": 41, "endOffset": 44}, {"referenceID": 48, "context": "calculated by using the W-kNN algorithm [56]:", "startOffset": 40, "endOffset": 44}, {"referenceID": 48, "context": "Any arbitrary function that holds the following properties given can be considered as the kernel function [56],[57 ]: 1) For all d , K( d ) 0 .", "startOffset": 106, "endOffset": 110}, {"referenceID": 49, "context": "Any arbitrary function that holds the following properties given can be considered as the kernel function [56],[57 ]: 1) For all d , K( d ) 0 .", "startOffset": 111, "endOffset": 116}, {"referenceID": 48, "context": "output, test r [56],[57].", "startOffset": 15, "endOffset": 19}, {"referenceID": 49, "context": "output, test r [56],[57].", "startOffset": 20, "endOffset": 24}, {"referenceID": 2, "context": "The first layer consists of a k nodes (\u201cadaptive or square\u201d [3] nodes)", "startOffset": 60, "endOffset": 63}, {"referenceID": 2, "context": "In the following, we explain how the BELPM uses the combination of two learning methods: the SD [3] and LSE to learn the input\u2013output mapping (the stimulus\u2013response association).", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "1) First learning phase: At the first learning phase, a hybrid learning algorithm [3] that is a combination of SD and LSE is used to update the learning parameters of AMYG (e.", "startOffset": 82, "endOffset": 85}, {"referenceID": 0, "context": "equal to [1,-1,0].", "startOffset": 9, "endOffset": 17}, {"referenceID": 4, "context": "Lorenz Time Series The Lorenz time series [5], [9], [58] was chosen as the first test, given by using (41) and (42).", "startOffset": 42, "endOffset": 45}, {"referenceID": 8, "context": "Lorenz Time Series The Lorenz time series [5], [9], [58] was chosen as the first test, given by using (41) and (42).", "startOffset": 47, "endOffset": 50}, {"referenceID": 50, "context": "Lorenz Time Series The Lorenz time series [5], [9], [58] was chosen as the first test, given by using (41) and (42).", "startOffset": 52, "endOffset": 56}, {"referenceID": 4, "context": "01 s [5], [9], [58], and the embedded dimension is selected as three.", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "01 s [5], [9], [58], and the embedded dimension is selected as three.", "startOffset": 10, "endOffset": 13}, {"referenceID": 50, "context": "01 s [5], [9], [58], and the embedded dimension is selected as three.", "startOffset": 15, "endOffset": 19}, {"referenceID": 50, "context": "4867 [58] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 50, "context": "1682 [58] 0.", "startOffset": 5, "endOffset": 9}, {"referenceID": 51, "context": "The data-driven models are: Nonlinear Autoregressive model with eXogenous input (Hybrid NARX-Elman RNN) [59], Evolving Recurrent Neural Networks (ERNN) [60], Radial Basis Function (RBF), multilayer perceptron (MLP) [5], Support Vector Regression (SVR), Tapped Delay Line Multilayer Perceptron (TDL-MLP), Distributed Local Experts based on Vector_Quantization using Information Theoretic learning (DLE-VQIT) [61], Cooperative Coevolution of Elman Recurrent Neural Networks (CCRNN) [62], Functional Weights Wavelet Neural Network-based state-dependent AutoRegressive (FWWNN-AR) [63], Recurrent Neural Network trained with Real-time Recurrent Learning (RNNRTRL), Recurrent Neural Network trained with the secondorder Extended Kalman Filter (RNN-EKF), Recurrent Neural Network trained with the algorithm and BackPropagation Through Time (BPTT), feedforward Multi layer Perceptron trained with the Bayesian Levenberg\u2013Marquardt (MLP-BLM), and recursive second-order training of Recurrent Neural Networks via a Recursive Bayesian Levenberg\u2013Marquardt (RBLM-RNN) algorithm [65].", "startOffset": 104, "endOffset": 108}, {"referenceID": 52, "context": "The data-driven models are: Nonlinear Autoregressive model with eXogenous input (Hybrid NARX-Elman RNN) [59], Evolving Recurrent Neural Networks (ERNN) [60], Radial Basis Function (RBF), multilayer perceptron (MLP) [5], Support Vector Regression (SVR), Tapped Delay Line Multilayer Perceptron (TDL-MLP), Distributed Local Experts based on Vector_Quantization using Information Theoretic learning (DLE-VQIT) [61], Cooperative Coevolution of Elman Recurrent Neural Networks (CCRNN) [62], Functional Weights Wavelet Neural Network-based state-dependent AutoRegressive (FWWNN-AR) [63], Recurrent Neural Network trained with Real-time Recurrent Learning (RNNRTRL), Recurrent Neural Network trained with the secondorder Extended Kalman Filter (RNN-EKF), Recurrent Neural Network trained with the algorithm and BackPropagation Through Time (BPTT), feedforward Multi layer Perceptron trained with the Bayesian Levenberg\u2013Marquardt (MLP-BLM), and recursive second-order training of Recurrent Neural Networks via a Recursive Bayesian Levenberg\u2013Marquardt (RBLM-RNN) algorithm [65].", "startOffset": 152, "endOffset": 156}, {"referenceID": 4, "context": "The data-driven models are: Nonlinear Autoregressive model with eXogenous input (Hybrid NARX-Elman RNN) [59], Evolving Recurrent Neural Networks (ERNN) [60], Radial Basis Function (RBF), multilayer perceptron (MLP) [5], Support Vector Regression (SVR), Tapped Delay Line Multilayer Perceptron (TDL-MLP), Distributed Local Experts based on Vector_Quantization using Information Theoretic learning (DLE-VQIT) [61], Cooperative Coevolution of Elman Recurrent Neural Networks (CCRNN) [62], Functional Weights Wavelet Neural Network-based state-dependent AutoRegressive (FWWNN-AR) [63], Recurrent Neural Network trained with Real-time Recurrent Learning (RNNRTRL), Recurrent Neural Network trained with the secondorder Extended Kalman Filter (RNN-EKF), Recurrent Neural Network trained with the algorithm and BackPropagation Through Time (BPTT), feedforward Multi layer Perceptron trained with the Bayesian Levenberg\u2013Marquardt (MLP-BLM), and recursive second-order training of Recurrent Neural Networks via a Recursive Bayesian Levenberg\u2013Marquardt (RBLM-RNN) algorithm [65].", "startOffset": 215, "endOffset": 218}, {"referenceID": 53, "context": "The data-driven models are: Nonlinear Autoregressive model with eXogenous input (Hybrid NARX-Elman RNN) [59], Evolving Recurrent Neural Networks (ERNN) [60], Radial Basis Function (RBF), multilayer perceptron (MLP) [5], Support Vector Regression (SVR), Tapped Delay Line Multilayer Perceptron (TDL-MLP), Distributed Local Experts based on Vector_Quantization using Information Theoretic learning (DLE-VQIT) [61], Cooperative Coevolution of Elman Recurrent Neural Networks (CCRNN) [62], Functional Weights Wavelet Neural Network-based state-dependent AutoRegressive (FWWNN-AR) [63], Recurrent Neural Network trained with Real-time Recurrent Learning (RNNRTRL), Recurrent Neural Network trained with the secondorder Extended Kalman Filter (RNN-EKF), Recurrent Neural Network trained with the algorithm and BackPropagation Through Time (BPTT), feedforward Multi layer Perceptron trained with the Bayesian Levenberg\u2013Marquardt (MLP-BLM), and recursive second-order training of Recurrent Neural Networks via a Recursive Bayesian Levenberg\u2013Marquardt (RBLM-RNN) algorithm [65].", "startOffset": 480, "endOffset": 484}, {"referenceID": 54, "context": "The data-driven models are: Nonlinear Autoregressive model with eXogenous input (Hybrid NARX-Elman RNN) [59], Evolving Recurrent Neural Networks (ERNN) [60], Radial Basis Function (RBF), multilayer perceptron (MLP) [5], Support Vector Regression (SVR), Tapped Delay Line Multilayer Perceptron (TDL-MLP), Distributed Local Experts based on Vector_Quantization using Information Theoretic learning (DLE-VQIT) [61], Cooperative Coevolution of Elman Recurrent Neural Networks (CCRNN) [62], Functional Weights Wavelet Neural Network-based state-dependent AutoRegressive (FWWNN-AR) [63], Recurrent Neural Network trained with Real-time Recurrent Learning (RNNRTRL), Recurrent Neural Network trained with the secondorder Extended Kalman Filter (RNN-EKF), Recurrent Neural Network trained with the algorithm and BackPropagation Through Time (BPTT), feedforward Multi layer Perceptron trained with the Bayesian Levenberg\u2013Marquardt (MLP-BLM), and recursive second-order training of Recurrent Neural Networks via a Recursive Bayesian Levenberg\u2013Marquardt (RBLM-RNN) algorithm [65].", "startOffset": 576, "endOffset": 580}, {"referenceID": 56, "context": "The data-driven models are: Nonlinear Autoregressive model with eXogenous input (Hybrid NARX-Elman RNN) [59], Evolving Recurrent Neural Networks (ERNN) [60], Radial Basis Function (RBF), multilayer perceptron (MLP) [5], Support Vector Regression (SVR), Tapped Delay Line Multilayer Perceptron (TDL-MLP), Distributed Local Experts based on Vector_Quantization using Information Theoretic learning (DLE-VQIT) [61], Cooperative Coevolution of Elman Recurrent Neural Networks (CCRNN) [62], Functional Weights Wavelet Neural Network-based state-dependent AutoRegressive (FWWNN-AR) [63], Recurrent Neural Network trained with Real-time Recurrent Learning (RNNRTRL), Recurrent Neural Network trained with the secondorder Extended Kalman Filter (RNN-EKF), Recurrent Neural Network trained with the algorithm and BackPropagation Through Time (BPTT), feedforward Multi layer Perceptron trained with the Bayesian Levenberg\u2013Marquardt (MLP-BLM), and recursive second-order training of Recurrent Neural Networks via a Recursive Bayesian Levenberg\u2013Marquardt (RBLM-RNN) algorithm [65].", "startOffset": 1064, "endOffset": 1068}, {"referenceID": 4, "context": "01s [5], [58] and three, respectively.", "startOffset": 4, "endOffset": 7}, {"referenceID": 50, "context": "01s [5], [58] and three, respectively.", "startOffset": 9, "endOffset": 13}, {"referenceID": 54, "context": "FWWNN[63] 9.", "startOffset": 5, "endOffset": 9}, {"referenceID": 51, "context": "8e-15 1500,1000 NN+AR, 1 step noiseless NARX[59] 1.", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "9e-10 1500,1000 AR, 1 step noiseless BELRFS[12] 4.", "startOffset": 43, "endOffset": 47}, {"referenceID": 52, "context": "9e-10 1500,1000 NF+BEL, 1 step noiseless ERNN[60] 9.", "startOffset": 45, "endOffset": 49}, {"referenceID": 4, "context": "9e-10 1500,1000 NN, 1 step noiseless RBF[5] 1.", "startOffset": 40, "endOffset": 43}, {"referenceID": 4, "context": "4e-9 1500,1000 NN, 1 step noiseless MLP[5] 5.", "startOffset": 39, "endOffset": 42}, {"referenceID": 55, "context": "6e-4 ---------, 1 step noiseless LSSVMs[64] 6.", "startOffset": 39, "endOffset": 43}, {"referenceID": 56, "context": "01 RBLMRNN[65] 9.", "startOffset": 10, "endOffset": 14}, {"referenceID": 53, "context": "CCRNN [62] 7.", "startOffset": 6, "endOffset": 10}, {"referenceID": 55, "context": "7e-4 500,500 NN,2 step noiseless LLNF[64] 2.", "startOffset": 37, "endOffset": 41}, {"referenceID": 56, "context": "05 MLP_BLM[65] 8.", "startOffset": 10, "endOffset": 14}, {"referenceID": 56, "context": "05 MLP_EKF[65] 1.", "startOffset": 10, "endOffset": 14}, {"referenceID": 56, "context": "05 RNNRTRL[65] 1.", "startOffset": 10, "endOffset": 14}, {"referenceID": 56, "context": "RNN-BPTT[65] 1.", "startOffset": 8, "endOffset": 12}, {"referenceID": 56, "context": "05 RNN-EKF[65] 1.", "startOffset": 10, "endOffset": 14}, {"referenceID": 4, "context": "3315 RBF[5] 0.", "startOffset": 8, "endOffset": 11}, {"referenceID": 4, "context": "0872 42 neuron ------LoLiMoT[5] 0.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "0590[5] 0.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "RBF[5] 1.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "4e-9 1500,1000 NN, 1 step noiseless MLP[5] 5.", "startOffset": 39, "endOffset": 42}, {"referenceID": 55, "context": "001 LSSVMs[64] 4.", "startOffset": 10, "endOffset": 14}, {"referenceID": 56, "context": "05 RBLMRNN[65] 6.", "startOffset": 10, "endOffset": 14}, {"referenceID": 56, "context": "RNN-EKF[65] 8.", "startOffset": 7, "endOffset": 11}, {"referenceID": 56, "context": "05 MLP-BLM[65] 8.", "startOffset": 10, "endOffset": 14}, {"referenceID": 56, "context": "01 RNN-BPTT[65] 1.", "startOffset": 11, "endOffset": 15}, {"referenceID": 56, "context": "05 RNNRTRL[65] 1.", "startOffset": 10, "endOffset": 14}, {"referenceID": 39, "context": "improvements in the model would be made on the basis of kdTree data structure [47] to address \u201cthe curse of dimensionality\u201d [1] problem and decrease the computational time complexity of BELPM.", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "improvements in the model would be made on the basis of kdTree data structure [47] to address \u201cthe curse of dimensionality\u201d [1] problem and decrease the computational time complexity of BELPM.", "startOffset": 124, "endOffset": 127}], "year": 2016, "abstractText": "Abstract\u2014 This study suggests a new prediction model for chaotic time series inspired by the brain emotional learning of mammals. We describe the structure and function of this model, which is referred to as BELPM (Brain Emotional LearningBased Prediction Model). Structurally, the model mimics the connection between the regions of the limbic system, and functionally it uses weighted k nearest neighbors to imitate the roles of those regions. The learning algorithm of BELPM is defined using steepest descent (SD) and the least square estimator (LSE). Two benchmark chaotic time series, Lorenz and Henon, have been used to evaluate the performance of BELPM. The obtained results have been compared with those of other prediction methods. The results show that BELPM has the capability to achieve a reasonable accuracy for long-term prediction of chaotic time series, using a limited amount of training data and a reasonably low computational time.", "creator": "Microsoft\u00ae Word 2010"}}}