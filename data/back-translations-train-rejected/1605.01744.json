{"id": "1605.01744", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2016", "title": "Improving Automated Patent Claim Parsing: Dataset, System, and Experiments", "abstract": "Off-the-shelf natural language processing software performs poorly when parsing patent claims owing to their use of irregular language relative to the corpora built from news articles and the web typically utilized to train this software. Stopping short of the extensive and expensive process of accumulating a large enough dataset to completely retrain parsers for patent claims, a method of adapting existing natural language processing software towards patent claims via forced part of speech tag correction is proposed. An Amazon Mechanical Turk collection campaign organized to generate a public corpus to train such an improved claim parsing system is discussed, identifying lessons learned during the campaign that can be of use in future NLP dataset collection campaigns with AMT. Experiments utilizing this corpus and other patent claim sets measure the parsing performance improvement garnered via the claim parsing system. Finally, the utility of the improved claim parsing system within other patent processing applications is demonstrated via experiments showing improved automated patent subject classification when the new claim parsing system is utilized to generate the features.", "histories": [["v1", "Thu, 5 May 2016 20:11:57 GMT  (1291kb,D)", "http://arxiv.org/abs/1605.01744v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mengke hu", "david cinciruk", "john maclaren walsh"], "accepted": false, "id": "1605.01744"}, "pdf": {"name": "1605.01744.pdf", "metadata": {"source": "CRF", "title": "Improving Automated Patent Claim Parsing: Dataset, System, and Experiments", "authors": ["Mengke Hu", "John MacLaren Walsh"], "emails": [], "sections": [{"heading": null, "text": "Improving Automated Patent Claim Parsing: Dataset, System, and ExperimentsMengke Hu, David Cinciruk, and John MacLaren Walsh Dept. of Elec. & Comp. Eng., Drexel University, Philadelphia, PAOff-the-shelf Natural Language Processing Software performs poorly when parsing patent claims because it uses an irregular language relative to the corporations normally used from news articles and the Web to create this software. It is proposed to break the extensive and costly process of amassing a sufficiently large data set to fully re-train parsers for patent claims, a method of adapting existing natural language processing software to patent claims using a forced portion of language tag correction."}, {"heading": "1. Introduction", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a region and in which it is a country."}, {"heading": "2. Dataset Collection via Amazon Mechanical Turk", "text": "In fact, the fact is that most of them will be able to show themselves, that they are able to assert themselves, that they are able to assert themselves, and that they are able to assert themselves."}, {"heading": "2.1 Three Initial Tag Collection Campaigns", "text": "This year, most of them were able to get used to the work, while most of them were able to do their jobs."}, {"heading": "2.2 A Fourth Campaign with an Improved User Interface", "text": "It was clear that we needed to raise the response rate to a remote level to satisfy the vulnerable portion of users who only had their responses to accidental errors."}, {"heading": "2.3 Lessons Learned about Collecting POS Tags with AMT", "text": "Several valuable conclusions regarding the collection of natural language processing data with Amazon Mechanical Turk can indeed be summarized in key statistics by campaigns 1-4. When considering the design of HITs for curating, it is important to first consider the objectives of the participants. Of course, the applicant wants a large number of high-quality comments that he has collected as quickly as possible, and at a low cost. In turn, the applicants are motivated by a combination of factors that are as much as possible, but also have an interest in the task that he is attracting."}, {"heading": "2.4 Curation of the Dataset", "text": "Once the accepted HIT responses had been collected, of course, further curating was required to get the data into a form in which they could be used to train a system for parsing claims. Data from the first three campaigns required the greatest amount of curating, since the answers were free-format text and could therefore easily be corrupted with accidental extra spaces or carriage returns in the middle of words, or the query could completely not match. Furthermore, it was necessary to get the text responses into a form that could be used with standard machine learning paradigms, to identify the position of each tagged term (previously supposedly marked with a verb) within the segment, as well as to filter out the corrected / confirmed tag for it. After processing the answers with software that brought the query into line with the answers, and manually setting some of the answers that were detected by the software as faulty in the table, we were easily identified by the software as the number of tags, but were likely to be curated by the software as the number of the Pronez."}, {"heading": "3. Automatic Parts of Speech Tag Fixer", "text": "With the corpus of correct POS tags collected from our AMT campaign in hand, our focus shifted to developing a system that provides natural language processing features from the claims presented in Figure 4. This system combines the ordinary Stanford NLP parser with a POS tag corrector trained by machine learning. After an initial run of the ordinary Stanford NLP parser, the tag corrector determines whether the tags of the words referred to as verbs are correct or not, and if not, changes them to nouns, adjectives, or adverb tags. In our prototype system, this tag corrector is the concatenation of a simple rule-based corrector that corrects the most common tagging errors in patent claims, listed in Table 3, followed by a curated record of the previous section of the supported theme, which may be repeated by the first stage of the NLP, but the second stage of the initial NLP is repeated several times as an additional LP."}, {"heading": "3.1 Training an Automatic Tag Corrector", "text": "Subsequently, verb triplicates centered around the verbs-in-question are sorted into the question of whether the supposed verbs-in-question, i.e. the terms originally designated as verbs by the unmodified Stanford parsers, were designated as nouns, adjectives, adjectives, adjectives, or actually verbs by the Turks. As the verbs collected from the previous section are contained only in the order of hundreds of thousands of terms, many terms that need to be tagged by the system are designated as nouns."}, {"heading": "4. Experimental Validation: Improved Claim NLP", "text": "In this section, we want to confirm that the natural language processing system described and trained in the previous section leads to improved parsing of claims over existing, unmodified natural language processing software, and measures the improvements achieved. Two methods of validation are offered: the first and simplest approach simply compares the output of the automatic tag corrector to the tags of the verbs in question on the rest of the curated AMT tag record that has not yet been used to train the tag corrector, and then measures the percentage of tags that the automatic tag corrector corrects correctly; the second approach forms snippets from the original Stanford parser, sets of tags forced by the AMT results, and the output sets of the automatic tag corrector, measuring the difference between them using standard NLP metrics."}, {"heading": "4.1 Comparing POS Tags", "text": "We tested our system using our data curated according to the work in Section 2.4. In this experiment, we used only the data from the last iteration of our AMT campaign, as we noticed that the answers were more accurate; one-third of the data was used for training and two-thirds for testing. A total of 113,995 words originally marked as verbs were used for training purposes in the experiment with 39,097 and 74,898 were used for testing purposes. Assuming that the AMT data was true, our system had only a 9.17% error in determining the true tag, as in Table 4. For comparison with the automatic corrector, two systems were used - the original Stanford POS Tagger and the pure rule-based corrector used in the first step of our system (where the rules are listed in Table 3). In both cases, the SVM-based corrector significantly outperformed both systems."}, {"heading": "4.2 Comparing Parse Trees", "text": "In fact, the fact is that most of them are able to move to another world, in which they are able to move, rather than immerse themselves in another world, in which they are able, in which they are able, in which they are able, in which they are able to move, in which they are able to change the world, in which they are able to change the world, in which they are able to change the world in which they are in."}, {"heading": "5. Experimental Validation: Improved Patent Subject Classification", "text": "The experiments in the previous section have provided evidence to support the hypothesis that the extended patent claims NLP system trained from the collected AMT data set is more effective at parsing sentences from patent claims than the original unmodified grammar distributed with the Stanford NLP system. However, since there were no patent claims, only differences between the original parse trees and those generated with language parts generated by the automatic correction system and the AMT labels could be measured. However, the big differences that have been shown indicate an improvement, a better validation of the improved patent claims NLP system would show that the features it provides are useful in other patent processing systems.To show that our system is justified in this sense, a toy problem in the field of patent subject- subject- classification was created from the field of patent subject- subject- based on the performance of the StanOS, which is easily accessible only because our system has been created to the fixes in this sense."}, {"heading": "5.1 Background on Patent Subject Classification", "text": "The patent subject used by the U.S. Patent and Trademark Office has essentially evolved over the years. Patents submitted to the United States Patent and Trademark Office have historically been categorized by at least one of three different classification systems: the U.S. Patent Classification (USPC), the International Patent Classification (IPC) and the Cooporative Patent Classification (CPC). The USPC system was developed and maintained by the USPTO to classify patents registered with the Patent Office and to conduct a prior search (USPTO 2015). In an attempt to unify the classification of international patents between different patent offices, a system was developed and maintained."}, {"heading": "5.2 Experimental Setup", "text": "While a full-fledged patent subject classification experiment on scale is far beyond this scope of this article, the goal of this section is rather to show with a representative, but tiny, example that the new features that the article provides can improve patent subject classification. In particular, it has already been shown that dependency features can provide helpful information in performing subject classification. Our goal is to show that the improved patent claims NLP system provides dependencies that can provide a significant improvement in subject classification. To do this, a very simple patent subclass experiment was set up to keep the experiment small, but difficult, we selected two subclasses of the same parent class 714: error detection / correction and recovery of the USPC. As shown in Fig. 9, the two subclasses selected, 714 / 748: Request for Re-transmission and 763: Memory Access, are both refinements of the subclass."}, {"heading": "5.3 Experimental Results", "text": "An initial observation that makes this figure possible in line with common sense is that the information contained in claims is consistently more important than the information provided in the summary. However, more importantly, this figure shows that the improved NLP system reduces the error rate from 5.974% to 4.695% in multiple contexts. Indeed, a system composed of claim trigrams alone can achieve an error rate of 3.699%, and when these features are supplemented with those of the language model provided with the unmodified Stanford NLP, the error rate actually deteriorates to 3.99%, while the LP produced from claim trigrams alone has an error rate of 3.699%, while the claim dependencies built from the improved claim NLP system can be increased by 2.97%, while the error rate of the NLP features created from these features can be increased by 3.7%."}, {"heading": "6. Conclusion", "text": "Since they describe the legal scope of an invention, patent claims are arguably the most important section of a patent for many patent processing problems. Natural language processing properties built from these claims could potentially be useful for software that helps people in multiple stages of patent processing. However, claims are not written in the same style of English that appears in news articles and on the Internet, and therefore the language model provided with off-the-shelf natural language processing software is not well suited for claims. However, given a tree of patent claims annotations from which to develop a completely new language model for patent claims would be an expensive and exhaustive exercise that would be difficult to find. Motivated by the observation that much of the difficulty in parsing claims lies in incorrectly identifying verbs, this paper proposed an alternative way to adapt the NLP software to claim language by simply providing the POS towers of the alleged data system, and in particular by describing the subsequent collection of Amazon tags."}], "references": [{"title": "Toward a More Rational Patent Search Paradigm", "author": ["H. Kristine"], "venue": "PaIR", "citeRegEx": "Kristine,? \\Q2008\\E", "shortCiteRegEx": "Kristine", "year": 2008}, {"title": "Lci-insa linguistic experiment for clef-ip classification track", "author": ["Beney", "others2010]Beney", "Jean"], "venue": "CLEF-IP", "citeRegEx": "Beney et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Beney et al\\.", "year": 2010}, {"title": "Hierarchical document categorization with support vector machines", "author": ["Cai", "Hofmann2004]Cai", "Lijuan", "Thomas Hofmann"], "venue": "In Proceedings of the thirteenth ACM international conference on Information and knowledge management,", "citeRegEx": "Cai et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2004}, {"title": "Creating speech and language data with Amazon\u2019s Mechanical Turk. In Creating speech and language data with Amazon\u2019s", "author": ["Callison-Burch", "Dredze2010]Callison-Burch", "Chris", "Mark Dredze"], "venue": null, "citeRegEx": "Callison.Burch et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2010}, {"title": "A three-phase method for patent classification", "author": ["Chen", "Chang2012]Chen", "Yen-Liang", "Yuan-Che Chang"], "venue": "Information Processing & Management,", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Svmtorch: Support vector machines for large-scale regression problems", "author": ["Collobert", "Bengio", "Williamson2001]Collobert", "Ronan", "Samy Bengio", "C. Williamson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2001}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["De Marneffe", "MacCartney", "M Manning2006]De Marneffe", "Bill MacCartney", "C Manning"], "venue": "In Proceedings of the 5th International Conference on Language Resources and Evaluation,", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Combining semantics and statistics for patent classification", "author": ["Derieux et al.2010]Derieux", "Franck", "Mihaela Bobeica", "Delphine Pois", "Jean-Pierre Raysz"], "venue": null, "citeRegEx": "al.2010.Derieux et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al.2010.Derieux et al\\.", "year": 2010}, {"title": "Text Representations for Patent Classification", "author": ["D\u2019hondt et al.2013]D\u2019hondt", "Eva", "Suzan Verberne", "Cornelis Koster", "Lou Boves"], "venue": "Association for Computational Linguistics,", "citeRegEx": "al.2013.D.hondt et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al.2013.D.hondt et al\\.", "year": 2013}, {"title": "Automated Categorization in the International Patent Classification", "author": ["C.J. Fall et al.2003]Fall", "A. T\u00f6rcsv\u00f3ri", "K. Benzineb", "G. Karetka"], "venue": "Newsletter ACM SIGIR Forum,", "citeRegEx": "al.2003.Fall et al\\.,? \\Q2003\\E", "shortCiteRegEx": "al.2003.Fall et al\\.", "year": 2003}, {"title": "2016. Part of speech tag datasets for patent claims. http://www.ece.drexel.edu/walsh/aspitrg/Release1.0.zip", "author": ["Hu", "Cinciruk", "Walsh2016]Hu", "Mengke", "David Cinciruk", "John MacLauren Walsh"], "venue": null, "citeRegEx": "Hu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2016}, {"title": "Speech and Language Processing", "author": ["Jurafsky", "Martin2008]Jurafsky", "Daniel", "James H. Martin"], "venue": null, "citeRegEx": "Jurafsky et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Jurafsky et al\\.", "year": 2008}, {"title": "Accurate unlexicalized parsing", "author": ["Klein", "Manning2003]Klein", "Dan", "Christopher D Manning"], "venue": "In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume", "citeRegEx": "Klein et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2003}, {"title": "Some issues in the automatic classification of us patents", "author": ["Larkey1997]Larkey", "Leah"], "venue": "Workshop on Learning for Text Categorization", "citeRegEx": "Larkey1997.Larkey and Leah.,? \\Q1997\\E", "shortCiteRegEx": "Larkey1997.Larkey and Leah.", "year": 1997}, {"title": "A patent search and classification system", "author": ["S. Leah"], "venue": "In Proceedings of the fourth ACM conference on Digital libraries,", "citeRegEx": "Leah,? \\Q1999\\E", "shortCiteRegEx": "Leah", "year": 1999}, {"title": "The Status of Retrieval Evaluation in the Patent Domain", "author": ["Lupu2011]Lupu", "Mihai"], "venue": "PaIR", "citeRegEx": "Lupu2011.Lupu and Mihai.,? \\Q2011\\E", "shortCiteRegEx": "Lupu2011.Lupu and Mihai.", "year": 2011}, {"title": "Foundations of Statistical Natural Language Processing. The MIT Press, 1st edition edition", "author": ["Manning", "Sch\u00fctze1999]Manning", "Christopher D", "Hinrich Sch\u00fctze"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Manning et al\\.", "year": 1999}, {"title": "Efficient estimation of word representations in vector space", "author": ["Mikolov et al.2013]Mikolov", "Tomas", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In International Conference on Learning Representations", "citeRegEx": "al.2013.Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al.2013.Mikolov et al\\.", "year": 2013}, {"title": "Using Dependency Relations for Text Classification", "author": ["Nastase", "Shirabad", "Caropreso2006]Nastase", "Vivi", "Jelber Sayyad Shirabad", "Maria Fernanda Caropreso"], "venue": "In Canadian AI 2006 (poster)", "citeRegEx": "Nastase et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nastase et al\\.", "year": 2006}, {"title": "Patent Claim Decomposition for Improved Information Extraction", "author": ["Parapatics", "Dittenbach2009]Parapatics", "Peter", "Michael Dittenbach"], "venue": "PaIR", "citeRegEx": "Parapatics et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Parapatics et al\\.", "year": 2009}, {"title": "Crowdsourcing for Grammatical Error Correction", "author": ["Pavlick", "Yan", "Callison-Burch2014]Pavlick", "Ellie", "Rui Yan", "Chris Callison-Burch"], "venue": "In CSCW Companion \u201914 Proceedings of the companion publication of the 17th ACM conference on Computer supported cooperative work & social computing,", "citeRegEx": "Pavlick et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pavlick et al\\.", "year": 2014}, {"title": "CLEF-IP 2011: Retrieval in the Intellectual Property Domain", "author": ["Piroi et al.2011]Piroi", "Florina", "Mihai Lupu", "Allan Hanbury", "Veronika Zenz"], "venue": null, "citeRegEx": "al.2011.Piroi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al.2011.Piroi et al\\.", "year": 2011}, {"title": "Ranking annotators for crowdsourced labeling tasks", "author": ["Raykar", "Yu2011]Raykar", "Vikas C", "Shipeng Yu"], "venue": null, "citeRegEx": "Raykar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Raykar et al\\.", "year": 2011}, {"title": "Kernel-based learning of hierarchical multilabel classification models", "author": ["Rousu et al.2006]Rousu", "Juho", "Craig Saunders", "Sandor Szedmak", "John Shawe-Taylor"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "al.2006.Rousu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al.2006.Rousu et al\\.", "year": 2006}, {"title": "Cross-validation optimization for large scale hierarchical classification kernel methods", "author": ["Seeger2006]Seeger", "Matthias"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Seeger2006.Seeger and Matthias.,? \\Q2006\\E", "shortCiteRegEx": "Seeger2006.Seeger and Matthias.", "year": 2006}, {"title": "Utility data annotation with Amazon Mechanical Turk", "author": ["Sorokin", "Forsyth2008]Sorokin", "Alexander", "David Forsyth"], "venue": "In Computer Vision and Pattern Recognition Workshops", "citeRegEx": "Sorokin et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sorokin et al\\.", "year": 2008}, {"title": "Experiment with a hierarchical text categorization method on the wipo-alpha patent collection", "author": ["Tikk", "Bir\u00f32003]Tikk", "Domonkos", "Gy\u00f6rgy Bir\u00f3"], "venue": "In Uncertainty Modeling and Analysis,", "citeRegEx": "Tikk et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Tikk et al\\.", "year": 2003}, {"title": "Quality Control for Comparison Microtasks", "author": ["Venetis", "Garcia-Molina2012]Venetis", "Petros", "Hector Garcia-Molina"], "venue": "CrowdKDD", "citeRegEx": "Venetis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Venetis et al\\.", "year": 2012}, {"title": "Patent classification experiments with the linguistic classification system lcs in clef-ip", "author": ["Verberne", "D\u2019hondt2011]Verberne", "Suzan", "Eva D\u2019hondt"], "venue": "CLEF-IP", "citeRegEx": "Verberne et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Verberne et al\\.", "year": 2011}, {"title": "Quantifying the Challenges in Parsing Patent Claims", "author": ["Verberne", "D\u2019hondt", "Oostdijk2010]Verberne", "Suzan", "Eva D\u2019hondt", "Nelleke Oostdijk"], "venue": "In 1st International Workshop on Advances in Patent Information Retrieval (AsPIRe", "citeRegEx": "Verberne et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Verberne et al\\.", "year": 2010}], "referenceMentions": [], "year": 2016, "abstractText": "claims trigrams trigrams dependencies AMT-trained fixed dependencies 3.699% 4.697% 5.974% 18.18% 3.99% 2.797% 3.696% 2.597% 3.297% FEATURES (TFIDFs of) SVM Classifier's Error Rate DATASET", "creator": "LaTeX with hyperref package"}}}