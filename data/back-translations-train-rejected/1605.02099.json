{"id": "1605.02099", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-May-2016", "title": "Some Simulation Results for Emphatic Temporal-Difference Learning Algorithms", "abstract": "This is a companion note to our recent study of the weak convergence properties of constrained emphatic temporal-difference learning (ETD) algorithms from a theoretic perspective. It supplements the latter analysis with simulation results and illustrates the behavior of some of the ETD algorithms using three example problems.", "histories": [["v1", "Fri, 6 May 2016 20:52:26 GMT  (7632kb,D)", "http://arxiv.org/abs/1605.02099v1", "A companion note to the article arxiv:1511.07471; 30 pages; 34 figures, best viewed on screen"]], "COMMENTS": "A companion note to the article arxiv:1511.07471; 30 pages; 34 figures, best viewed on screen", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["huizhen yu"], "accepted": false, "id": "1605.02099"}, "pdf": {"name": "1605.02099.pdf", "metadata": {"source": "CRF", "title": "Some Simulation Results for Emphatic Temporal-Difference Learning Algorithms\u2217", "authors": ["Huizhen Yu"], "emails": ["(janey.hzyu@gmail.com)."], "sections": [{"heading": null, "text": ""}, {"heading": "1 About this Note 2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Two Test Problems 2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Simulation Results for the Constant-stepsize Case 6", "text": "3.1 Problem I........................................................................................................................"}, {"heading": "4 Simulation Results for the Diminishing-stepsize Case 18", "text": "4.1 Problem I......................................................................................................................."}, {"heading": "5 Mountain Car 23", "text": "5.1 Experimental setup..................................................................................................................................................................................................................................................................."}, {"heading": "2 ETD Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 About this Note", "text": "This is a side effect of our recent study on the weak convergence properties of limited ETD algorithms from a theoretical perspective [3]. Our goal is to supplement this theoretical analysis with simulation results and illustrate the behavior of some of the ETD algorithms using examples. We will look at three test problems: two small net-like problems and then the larger problem with the mountain bike. In terms of algorithms, we will focus on the two variant algorithms [3] (given by like-minded people) and (3,4) each in Section 3.2 of [3], as well as their disturbed versions for the constant case (given by like-minded people) in Section 3.3 of like-minded people."}, {"heading": "2 Two Test Problems", "text": "For these two problems, it is easier to describe the system dynamics directly in relation to the state transition probabilities (without explicitly dealing with actions), which is what we will do below. (Readers who wish to explicitly select the scope of action may interpret any state transition in our description as being caused by a certain action that will surely lead to that particular transition.) Problem I has 6 states. Let P\u03c0 and P\u03c0o be the state transition probability matrices under the target policy and behavioral policy \u03c0o, respectively. These transition matrices are of P\u03c0 = 0 0 0 0 0 0 0 0 0 0 0.9 0 0.1 0 0.2 0 0.3 0.5 0.3 0 0 0.1 0 0.1 0 0.1 0 0.90.9 0 0 0.0 0.1 0 0 0 0 0 0 0.1 0 0.1 0 0.1 0 0.0 0.0."}, {"heading": "4 ETD Experiments", "text": "The discount factor is \u03b3 = 0.9 for all states. The interest weights and \u03bb parameters are set so that they (s) = 0 (s) = 4 (s) = 1 for all states. As for the characteristics, we can use the next three figures to illustrate the behavior of traces. (Readers interested only in the behavior of the occurring ETD algorithms, we can skip this part and go directly to the following sections.) Generally, by identifying certain cycle patterns in the transition graphs, we can conclude whether the behavior of the occurring iterates will be unlimited over time. [2, Section 3.1] Figure 2 shows a few examples of such cycles in Figure 2. The left figure in Figure 2 is a cycle of two states in which we are almost certain."}, {"heading": "6 ETD Experiments", "text": "This type of behavior suggests that it is better to apply the biased limited ETD algorithms rather than the unbiased (limited or unbiased) ones in practice, because if large-scale traces occur in successive iterations, they can result in large-scale changes in the bias of bias in a short period of time, if little constraints are placed on the size of the change \u03b8t + 1 \u2212 \u03b8t with each iteration. Therefore, in practice, despite their superior asymptotic convergence characteristics, the unbiased ETD algorithms tend to be fragile. As the biased algorithms take measures to prevent such abrupt changes in the default settings: for example, variant I separates the traces, and variant II truncates the steps of the bias of the bias. Since the fractions of the large-scale traces are small, these small separations, with appropriate pricing, can only have a small change in the threshold of S3."}, {"heading": "3 Simulation Results for the Constant-stepsize Case", "text": "In this section, we show simulation results of the distorted ETD algorithms with a constant increment for the two test problems described in the previous section. In addition to the two distorted algorithms, variant I and variant II, we will also show results for the distorted versions of these two variants. Our focus will be on the behavior of several consecutive \u03b8 iterates and the behavior of a path of \u03b8 iterates or their averaged iterates below different increments. In the experiments described below, the radius parameter rB for limiting these iterates is set so that rB = 100 (well above the threshold required by [3, Lemma 2.1], which is calculated to be rB > 7.04 for problem I and rB > 5.20 for problem II."}, {"heading": "3.1 Problem I", "text": "The experiments below compare the behavior of the different algorithms in problem I, for four different step variables: \u03b1 = 0.01, 0.001, 0.0005. Firstly, we have 4 independent runs of both variant I and variant II. Each run lasted for 6 x 105 iterations, in which the same state path is used entirely by both algorithms for all four step variables. We have performed the same experiments for the disturbed versions of the two variants. To illustrate the steady state behavior, we have used only the last 4 x 105 iterations of each run to obtain the statistics of several consecutive iterations, which are shown in Figures 6-9 below. Before explaining these numbers, let us first show an exemplary path of a single run (more trajectories of the iterations will be shown later). In Figure 5, the standardized distances to the iterations are listed."}, {"heading": "8 ETD Experiments", "text": "While the three dashed lines correspond to the results from the other three runs, we show more trajectories from the individual runs. The smaller the number of steps, the smaller the neighborhood of \u03b8 * within which an iteration path spends most of the time. Figures 8-9: We repeated the same experiments for the disturbed versions of variants I and II. The results are shown in Figures 8-9, and they show a similar behavior of the multiple successive iterations generated by these disturbed algorithms. (As in the previous case in the figures, the continuous lines for each color correspond to the results from one of the four runs, and the dashed lines in the other three runs.) These simulation results can be compared with the claims in 3.8 of [3]."}, {"heading": "10 ETD Experiments", "text": "Algorithms may be affected by the noise caused by the disturbance (cf. Remark 3.2 at the end of Section 3.3 of [3]), and the undisturbed algorithms may be suitable for practical purposes (cf. Remark 4.1 at the end of Section 4.3 in [3]).Figure 12: In this experiment, we compare the transient behavior of the variable algorithms for the four stage variables using a single pass of 105 iterations. All algorithms proceed from the same initial condition and no part of the pass is discarded. ELSTD is also used for comparison: the linear equations formed by ELSTD are solved every 500 iterations to produce the ELSTD curve shown in the figure. ELSTD can be seen to converge rapidly. With a large step size \u03b1 = 0.01, variants I and II also make rapid initial progress before starting in a relatively large neighborhood."}, {"heading": "12 ETD Experiments", "text": "Figure 13 shows the normalized distances between the average iterations and the original iterations generated in the later part of a pass for four different step variables. To reduce temporary effects in particular and to focus on the behavior in the stationary state, we first performed all the algorithms for 3 x 105 iterations with the step size 0.0005 and then continued the run for a further 106 iterations with the four different step variables indicated in the figure. The averaged iterations shown in the uppermost row of the figure are generated from these later 106 iterations of the pass. It is evident that the behavior of the iterations overall is similar to what we observed in the previous experiments."}, {"heading": "3.2 Problem II", "text": "We repeated for problem II the same experiments we performed for problem I. All algorithms are tested for five step sizes: \u03b1 = 0.0005, 0.0002, 0.00005, 0.0000002. First, we have 4 independent passes of variants I and II and their disrupted versions. Each run has 11 \u00d7 105 iterations, and the last 8 \u00d7 105 iterations are used to obtain the statistics of several successive iterations, shown in Figures 15-18, to show the plant behavior of the algorithms. Further details are as follows. Figure 14: This figure shows a sample track from a single run. The figure shows the standardized distances to the iterates generated by the four algorithms for the smallest step size of these algorithms."}, {"heading": "14 ETD Experiments", "text": ""}, {"heading": "16 ETD Experiments", "text": "Figures 19-20: In these two figures, we plotted for each algorithm and each number of steps the normalized distances to \u03b8 \u0445 a trajectory of averaged iterations \u03b8 \u03b1t and original iterations \u03b8 \u03b1 t using the data from one of the sequences of the previous four figures. Our observations from these results are the same as those from Figures 10-11 in the case of Problem I: (i) The averaged iterations perform better than \u03b8 \u03b1 t because they can vary less and approach a smaller neighborhood of Medicare. (ii) The undisturbed algorithms do not appear to have any disadvantages compared to the disturbed algorithms for the same increment. (17)"}, {"heading": "18 ETD Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 Simulation Results for the Diminishing-stepsize Case", "text": "In this section, we illustrate the behavior of variant I and variant II with reduced increment for the two test problems. As in the previous case, we set the radius parameter rB = 100 and use the component-wise truncation function \u0430 K with K = 50 in the two variant algorithms. In order to visualize the behavior of \u03b8 iterates and the behavior of several successive iterates, we will plot their normalized distances to the desired ETD solution as before. Given the close connection between the case with constant increment and the case with reduced increment, and in view of what we have already observed in the first case, the results from the present part of the experiments, about which we will report in the following, turn out as expected."}, {"heading": "4.1 Problem I", "text": "In the first experiment, we used five step size sequences, which decrease at different velocities \u03b2, \u03b1t = \u03b2 = 1200 + (0.1 t) \u03b2 for \u03b2 (0.3, 0.5, 0.7, 0.9, 1).We executed the two algorithms with these five step size rules simultaneously for 6 \u00d7 105 iterations, using a common state curve. The results are shown in Figure 22. ELSTD (modified as in Section 3) is also used for comparison: the linear equations formed by ELSTD are solved every 500 iterations to produce the ELSTD curve in the figure.19The top row of Figure 22 shows the normalized distances of the averaged iterates and the bottom line shows the normalized distances of the iterates, which are determined only for the first half of the pass in order to have a close-up view of the transient behavior."}, {"heading": "20 ETD Experiments", "text": "In words, the x-axis represents approximately a continuous time line (cf. [3, section 3.1]), and the x-component of a fixed curve corresponds to the sum of the increments up to one iteration, while the y-component of the curve corresponds to the normalized distance of that iteration. The entire curve is plotted on the left side of each figure, with a close-up of the lower error shown on the right. To give a rough indication of the values of the decreasing increment itself, we color the segments of the fixed curves in different colors according to the order of magnitude in each segment as follows: the first step 0.003 (black), the second step (0.003] (violet, 0.002] (violet), the second step (brown, 0.001), the third step (blue), the third step (blue)."}, {"heading": "4.2 Problem II", "text": "Similar to the previous subsection, in the first experiment for problem II we used five sequences of increments, which decrease with different velocities \u03b2: \u03b1t = 12000 + (0.1 t) \u03b2 for \u03b2 iterations {0.3, 0.5, 0.7, 0.9, 1}. We used the two algorithms with these five step size rules simultaneously for 8 x 105 iterations, using a common state curve. The results are also included for comparison in Figure 25. ELSTD (modified as in section 3): The linear equations formed by ELSTD are solved every 500 iterations to produce the ELSTD curve in the figure. The top line of Figure 22 shows the normalized distances of the averaged iterates over the entire run, and the bottom line shows the normalized distances of the iterates only for the first half of the run, in order to have a close-up view of the transient behavior."}, {"heading": "22 ETD Experiments", "text": "In the next experiment, we performed 10 independent runs with 1.6 x 106 iterations each for the two variant algorithms, using two step size rules: \u03b1t = 12000 + (10 t) \u03b2 for \u03b2 = 0.7 and \u03b1t = 12000 + (4000 t) \u03b2 for \u03b2 = 0.5. As before, we chose these step size rules to ensure that the step size becomes small enough in the further course (at t = 1.6 x 106, \u03b1t is about 10 \u2212 5 in both cases of \u03b2) The simulation results are plotted in Figure 26 and Figure 27 for \u03b2 = 0.7 and \u03b2 = 0.5, respectively. The graphic objects in these figures have the same significance as those in Figure 23-24 for problem I, so we will describe these objects only briefly. In Figure 26-27, we are plotted in solid lines, the normalized deviations (to profiles) of the items from one of the 10 runs. The x-axis represents a continuous time line, solid sections and a curve of 0000m (0000m)."}, {"heading": "5 Mountain Car", "text": "In this last series of experiments, we test the restricted ETD against a larger problem constructed from the mountain car problem [1]. Mountain car has continuous state and action space. As such, it is indeed beyond the finite space model considered in [3], so the convergence theories it proves for the restricted ETD do not extend to the mountain car problem. Nevertheless, we have observed empirically in our experiments that the restricted ETD behaves well, and in this section we report some of these simulation results for variant I with constant step size. (Variant II behaves similarly, but with a larger variant for this problem.)"}, {"heading": "5.1 Experimental Setup", "text": "We take the dynamics of the mountain car problem. The goal is to drive an underpowered car up a steep hill. A state consists of the position p and the speed v of the car, whose values are limited as p [\u2212 1,2, 0.5] and v [\u2212 0.07, 0.07]. Position 0.5 corresponds to the desired mountain summit target, while position \u2212 \u03c0 / 6 corresponds to the bottom of the valley."}, {"heading": "24 ETD Experiments", "text": "Three measures are available: {back, coast, forward}, denoted by {\u2212 1, 0, 1}, respectively. In naming the measures taken in due course and in naming the measures taken in due course, the dynamics of the car are defined as asvt + 1 = [\u2212 0.07, 0.07] (vt + 0.001 At \u2212 0.0025 cos (3pt)), pt + 1 = [\u2212 1.2, 0.5] (pt + + 1) (pt + vt + 1) (unless the dynamics of the car are asvt + 1 = \u2212 1.2, the speed is reset to zero: vt + 1 = 0. Before the target p = 0.5 is reached, the rewards are only dependent on the measures taken and are expressed by r (\u2212 1) = 1.5, r (1) = \u2212 1, and r (0) = 0. Once the target p = 0.5 is reached, the car enters a worthless final state."}, {"heading": "26 ETD Experiments", "text": "(p \u2032, v \u2032) described in step (2) above. This defines the importance of scanning weights \u03c0 (s, a) / \u03c0o (s, a) for the limited ETD algorithms in the experiments. It is worth noting that in the mathematical framework of non-political learning, we do not have to restrict behavioral policy as a physically feasible policy. In fact, this would restrict the use of non-political learning methods in solving target problems such as mountain cars, since in such problems it may be tantamount to solving the problem itself to finding a policy that is capable of reaching the target state. By defining behavioral policy more broadly, non-political learning methods can be applied to solving target problems, at least in the context in which the system dynamics of the problems can be simulated. Algorithmic parameters: We will show only results for variant I with a constant step size, as already mentioned. The following algorithmic parameters will be applied to all of us in all of the experiments in which we have a constant weight of 104 = 0.5; we will apply them to all of the problems; we will have a constant weight of 0.5 = 0.5."}, {"heading": "5.2 Simulation Results", "text": "First experiment: In the first experiment, we roughly divide the position (and velocity) interval into 7 (and 6) partial intervals to form 42 rectangular schemes covering the space [\u2212 1.2, 0.5) \u00d7 [\u2212 0.07, 0.07]. In each region, we approach the velocity interval of (cos (3p), v); therefore, the total approximation is piececessarily linear in (cos (3p), v). Specifically, to divide the position interval [\u2212 1.2, 0.5) and the velocity interval of [\u2212 0.07, 0.07] we use the points given in the two vectors below as averages: position: (\u2212 0.9 \u2212 0.7 \u2212 0.5 \u2212 0.3), velocity: (0.3), velocity: (0.05 \u2212 0.05)."}, {"heading": "28 ETD Experiments", "text": "The states in each region are treated as an aggregated state in the discredited model \u2212 \u2212 \u2212 1 \u2212 -1 \u2212 -2 Seen transition frequencies between the aggregated states for the target policy.These frequencies are considered transition probabilities in the discredited model, and the rewards per stage for the model are similarly defined.The Bellman equation for the discredited model is then used to define transition frequencies between the aggregated states (constant over each aggregated state).Figure 31 shows the 3D view and contour map of the resulting approximation, which can be compared with the estimated v\u03c0 representation.Figure 32: In this experiment, a rough coding scheme is used to generate 78 regions."}, {"heading": "30 ETD Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Reinforcement Learning", "author": ["R.S. Sutton", "A.G. Barto"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Least squares temporal difference methods: An analysis under general conditions", "author": ["H. Yu"], "venue": "SIAM J. Control Optim.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Weak convergence properties of constrained emphatic temporal-difference learning with constant and slowly diminishing stepsize. http://arxiv.org/abs/1511.07471", "author": ["H. Yu"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}], "referenceMentions": [{"referenceID": 2, "context": "2 ETD Experiments 1 About this Note This is a companion note to our recent study of the weak convergence properties of constrained ETD algorithms from a theoretical perspective [3].", "startOffset": 177, "endOffset": 180}, {"referenceID": 2, "context": "As to the algorithms, we will focus on the two variant algorithms in [3] (given by Eqs.", "startOffset": 69, "endOffset": 72}, {"referenceID": 2, "context": "2 of [3]), as well as their perturbed versions for the constant-stepsize case (given by Eq.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "3 of [3]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "2 of [3]), but they are more robust than the unbiased algorithms in practice, as we will also explain later in Section 2 of this note.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "We use these results in particular to demonstrate some of the convergence properties proved in [3], and to show that the algorithms are well-behaved despite the high variance issue in offpolicy learning.", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "We will thus use the notation given in [3] without redefining it here.", "startOffset": 39, "endOffset": 42}, {"referenceID": 2, "context": "(Please see the paper [3] for important prior works on TD and ETD learning.", "startOffset": 22, "endOffset": 25}, {"referenceID": 2, "context": "2) in [3]) is taken to be the componentwise truncation, \u03c8K(x) = min{K,max{\u2212K,x}}, for K = 50.", "startOffset": 6, "endOffset": 9}, {"referenceID": 2, "context": "6(i) of [3].", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "8 of [3].", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "3 of [3]), and the unperturbed algorithms may be adequate for practical purposes (cf.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "3 in [3]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "1 of [3]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "6(i) of [3] for Variants I and II, and with the assertions in Theorem 3.", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "8 of [3] for the perturbed versions of these two variants.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "3 of [3] for Variants I and II with diminishing stepsizes.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "3 of [3] for the two variant algorithms with diminishing stepsizes.", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "5 Mountain Car In this last set of experiments we test constrained ETD on a larger problem constructed from the Mountain Car problem [1].", "startOffset": 133, "endOffset": 136}, {"referenceID": 2, "context": "As such it is actually beyond the finite-space model considered in [3], so the convergence theorems we proved therein for constrained ETD do not extend to the Mountain Car problem.", "startOffset": 67, "endOffset": 70}, {"referenceID": 0, "context": "More experiments: In the subsequent experiments we ran Variant I with features generated by tile-coding [1].", "startOffset": 104, "endOffset": 107}], "year": 2016, "abstractText": "This is a companion note to our recent study of the weak convergence properties of constrained emphatic temporal-difference learning (ETD) algorithms from a theoretic perspective. It supplements the latter analysis with simulation results and illustrates the behavior of some of the ETD algorithms using three example problems.", "creator": "LaTeX with hyperref package"}}}