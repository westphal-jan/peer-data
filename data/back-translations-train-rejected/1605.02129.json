{"id": "1605.02129", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2016", "title": "Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot task", "abstract": "The Dialog State Tracking Challenge 4 (DSTC 4) proposes several pilot tasks. In this paper, we focus on the spoken language understanding pilot task, which consists of tagging a given utterance with speech acts and semantic slots. We compare different classifiers: the best system obtains 0.52 and 0.67 F1-scores on the test set for speech act recognition for the tourist and the guide respectively, and 0.52 F1-score for semantic tagging for both the guide and the tourist.", "histories": [["v1", "Sat, 7 May 2016 01:55:51 GMT  (68kb)", "http://arxiv.org/abs/1605.02129v1", "Paper accepted at IWSDS 2016"]], "COMMENTS": "Paper accepted at IWSDS 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["franck dernoncourt", "ji young lee", "trung h bui", "hung h bui"], "accepted": false, "id": "1605.02129"}, "pdf": {"name": "1605.02129.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Franck Dernoncourt", "Ji Young Lee", "Trung H. Bui", "Hung H. Bui"], "emails": ["francky@mit.edu", "jjylee@mit.edu", "bui@adobe.com", "hubui@adobe.com"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.02 129v 1 [cs.C L] 7M ay2 016paper, we focus on the pilot task of language comprehension, which is to mark a given utterance with speech acts and semantic slots. We compare different classifiers: the best system receives 0.52 or 0.67 F1 points on the test set for language character recognition for the tourist or tourist guide and 0.52 F1 points for semantic marking for both the guide and the tourist."}, {"heading": "1 Speech act recognition", "text": "In the training and development sets, each utterance is commented with a speech act. A speech act consists of zero, one or two speech act categories. Each speech act category has zero, one or two speech act attributes in its turn. There are 4 speech act categories and 22 speech act attributes. [6] and [7] provide further details on the task. The main approaches to this task are presented in [15, 1, 17, 5, 16, 19, 10, 3]. We submitted 5 systems. Systems 3 and 5 were the most powerful. System 3 is based on a support engine (SVM) to recognize the speech file: The features are the 5000 most common unigrams, bigrams, trigrams, and a binary feature that indicates whether the current speaker is different from the speaker in the last utterance. To take into account the history, each feature is compressed for both the current and the previous utterance."}, {"heading": "2 Semantic tagging", "text": "Semantic tagging is the second goal of the SLU pilot task. A tagged unit consists of one or more words. A tag contains one of 8 main categories and can contain a subcategory, a relative modifier, and a from-to-modifier. Ontology contains the list of subcategories, relative modifiers, and from-to-modifiers present in each main category. [6] and [7] provide further details of the task. The most important approaches to this task are presented in [8, 9, 14, 12, 18, 4, 11, 2]. Our semantic tagging system is based on conditional random fields (CRFs) implemented by the CRFsuite library [13] and uses the following characteristics, which are calculated on 7 consecutive words (the current word, the 3 previous words, and the 3 following words): Upper and lower case uniforms are insensitive to the CRFsuite library [13], and use the following characteristics, which are computed on 7 consecutive words (the current word, the 3 previous words, and the 3 following words) to summarize the word, whether the last word of the first word is a single word, whether the last word of the first word, if it is a single word, if the first word of the first word of the first word, if it is a single word, whether the semantic tagging is a single word of the first word, whether the semantic tagging is the second letter of the last word of the first word of the SLU pilot task."}], "references": [{"title": "Automatic dialog act segmentation and classification in multiparty meetings", "author": ["J. Ang", "Y. Liu", "E. Shriberg"], "venue": "In ICASSP", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Use of kernel deep convex networks and end-to-end learning for spoken language understanding", "author": ["L. Deng", "G. Tur", "X. He", "D. Hakkani-Tur"], "venue": "In Spoken Language Technology Workshop (SLT), 2012 IEEE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Machine learning techniques in dialogue act recognition", "author": ["M. Fi\u0161el"], "venue": "Eesti Rakenduslingvistika U\u0308hingu aastaraamat,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Joint semantic utterance classification and slot filling with recursive neural networks", "author": ["D. Guo", "G. Tur", "W.-t. Yih", "G. Zweig"], "venue": "In Spoken Language Technology Workshop (SLT),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Dialog act tagging using graphical models", "author": ["G. Ji", "J. Bilmes"], "venue": "In ICASSP", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "The Fourth Dialog State Tracking Challenge", "author": ["S. Kim", "L.F. D\u2019Haro", "R.E. Banchs", "J. Williams", "M. Henderson"], "venue": "In Proceedings of the 7th International Workshop on Spoken Dialogue Systems (IWSDS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Chunking with support vector machines. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, pages 1\u20138", "author": ["T. Kudo", "Y. Matsumoto"], "venue": "Association for Computational Linguistics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F.C. Pereira"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Tagging of speech acts and dialogue games in spanish call home", "author": ["L. Levin", "K. Ries", "A. Thyme-Gobbel", "A. Lavie"], "venue": "In Workshop: Towards Standards and Tools for Discourse Tagging,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "Using recurrent neural networks for slot filling in spoken language understanding", "author": ["G. Mesnil", "Y. Dauphin", "K. Yao", "Y. Bengio", "L. Deng", "D. Hakkani-Tur", "X. He", "L. Heck", "G. Tur", "D. Yu"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding", "author": ["G. Mesnil", "X. He", "L. Deng", "Y. Bengio"], "venue": "In INTERSPEECH,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "CRFsuite: a fast implementation of Conditional Random Fields (CRFs)", "author": ["N. Okazaki"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Generative and discriminative algorithms for spoken language understanding", "author": ["C. Raymond", "G. Riccardi"], "venue": "In INTERSPEECH,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Hmm and neural network based speech act detection", "author": ["K. Ries"], "venue": "In Acoustics, Speech, and Signal Processing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Flsa: Extending latent semantic analysis with features for dialogue act classification", "author": ["R. Serafin", "B. Di Eugenio"], "venue": "In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Dialogue act modeling for automatic tagging and recognition of conversational speech", "author": ["A. Stolcke", "K. Ries", "N. Coccaro", "E. Shriberg", "R. Bates", "D. Jurafsky", "P. Taylor", "R. Martin", "C. Van Ess-Dykema", "M. Meteer"], "venue": "Computational linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2000}, {"title": "Spoken language understanding using long short-term memory neural networks", "author": ["K. Yao", "B. Peng", "Y. Zhang", "D. Yu", "G. Zweig", "Y. Shi"], "venue": "In Spoken Language Technology Workshop (SLT), 2014 IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Toward joint segmentation and classification of dialog acts in multiparty meetings", "author": ["M. Zimmermann", "Y. Liu", "E. Shriberg", "A. Stolcke"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}], "referenceMentions": [{"referenceID": 5, "context": "[6] and [7] give further details on the task.", "startOffset": 8, "endOffset": 11}, {"referenceID": 13, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 0, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 15, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 4, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 14, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 17, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 8, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 2, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 5, "context": "[6] and [7] give further details on the task.", "startOffset": 8, "endOffset": 11}, {"referenceID": 6, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 7, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 12, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 10, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 16, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 3, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 9, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 1, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 11, "context": "Our semantic tagging system is based on conditional random fields (CRFs) implemented by the CRFsuite library [13] and uses the following features computed on 7 consecutive words (the current word, the 3 previous words, and the 3 following words): case-insensitive unigrams, the last 3 characters of the word, whether the first letter of the word is an uppercase, whether all the letters of the word are uppercases, whether the word contains a digit, the coarse-grained part-of-speech of the word, and the fine-grained part-of-speech of the word.", "startOffset": 109, "endOffset": 113}], "year": 2016, "abstractText": "The Dialog State Tracking Challenge 4 (DSTC 4) proposes several pilot tasks. In this paper, we focus on the spoken language understanding pilot task, which consists of tagging a given utterance with speech acts and semantic slots. We compare different classifiers: the best system obtains 0.52 and 0.67 F1-scores on the test set for speech act recognition for the tourist and the guide respectively, and 0.52 F1-score for semantic tagging for both the guide and the tourist. 1 Speech act recognition Recognizing the speech acts of the current utterance is one of the two goals of the spoken language understanding pilot task. In the training and development sets, each utterance is annotated with one speech act. One speech act is composed of zero, one or two speech act categories. Each speech act category has in turn zero, one or two speech act attributes. There are 4 speech act categories, and 22 speech act attributes. [6] and [7] give further details on the task. The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3]. We submitted 5 systems. Systems 3 and 5 were the best performing ones. System 3 is based on a support vector machine (SVM) classifier to recognize the speech acts: the features are the 5000 most common unigrams, bigrams, trigrams, as well as a binary feature indicating whether the current speaker is different from the speaker in the last utterance. To account for the history, each feature is computed for both the current and the previous utterance. Two SVM classifiers were trained: one for each speaker. The kernel function as well as the penalty parameter of the error term were both optimized with 5-fold cross-validation. System 5 is similar, but with logistic regression as the classifier; moreover, it uses one single speaker-independent model instead of one model per speaker, as it slightly improves the results on the development set. Systems 3 and 5 assume that each utterance contains exactly one speech act category and one speech act attribute: they are therefore multiclass, monolabel classifiers, with 88 possible classes (4 speech act categories\u00d722 speech act attributes). Franck Dernoncourt Adobe Research, San Jose, CA, USA and MIT, Cambridge, MA, USA e-mail: francky@mit.edu Ji Young Lee Massachusetts Institute of Technology, Cambridge, MA, USA e-mail: jjylee@mit.edu Trung H. Bui Adobe Research, San Jose, CA, USA e-mail: bui@adobe.com Hung H. Bui Adobe Research, San Jose, CA, USA e-mail: hubui@adobe.com", "creator": "LaTeX with hyperref package"}}}