{"id": "1605.02196", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2016", "title": "All Weather Perception: Joint Data Association, Tracking, and Classification for Autonomous Ground Vehicles", "abstract": "A novel probabilistic perception algorithm is presented as a real-time joint solution to data association, object tracking, and object classification for an autonomous ground vehicle in all-weather conditions. The presented algorithm extends a Rao-Blackwellized Particle Filter originally built with a particle filter for data association and a Kalman filter for multi-object tracking (Miller et al. 2011a) to now also include multiple model tracking for classification. Additionally a state-of-the-art vision detection algorithm that includes heading information for autonomous ground vehicle (AGV) applications was implemented. Cornell's AGV from the DARPA Urban Challenge was upgraded and used to experimentally examine if and how state-of-the-art vision algorithms can complement or replace lidar and radar sensors. Sensor and algorithm performance in adverse weather and lighting conditions is tested. Experimental evaluation demonstrates robust all-weather data association, tracking, and classification where camera, lidar, and radar sensors complement each other inside the joint probabilistic perception algorithm.", "histories": [["v1", "Sat, 7 May 2016 14:36:34 GMT  (8390kb,D)", "http://arxiv.org/abs/1605.02196v1", "35 pages, 21 figures, 14 tables"]], "COMMENTS": "35 pages, 21 figures, 14 tables", "reviews": [], "SUBJECTS": "cs.SY cs.CV cs.LG cs.RO", "authors": ["peter radecki", "mark campbell", "kevin matzen"], "accepted": false, "id": "1605.02196"}, "pdf": {"name": "1605.02196.pdf", "metadata": {"source": "CRF", "title": "All Weather Perception: Joint Data Association, Tracking, and Classification for Autonomous Ground Vehicles", "authors": ["Peter Radecki", "Mark Campbell", "Kevin Matzen"], "emails": ["ppr27@cornell.edu,", "mc288@cornell.edu,", "kmatzen@cs.cornell.edu"], "sections": [{"heading": null, "text": "A novel probabilistic perception algorithm is presented as a common real-time solution for data association, object tracking and object classification for an autonomous ground vehicle in all weather conditions.The presented algorithm extends a Rao-Blackwellized Particle Filter originally built with a particle filter for data tracking and a Kalman filter for multi-object tracking (Miller et al., 2011a) and now also includes the tracking of multiple models for classification. In addition, a state-of-the-art vision recognition algorithm was implemented that provides direction information for autonomous ground vehicle applications (AGV).Cornell's AGV from the DARPA Urban Challenge was updated and used experimentally to investigate whether and how advanced vision algorithms can complement or replace lidar and radar sensors. Sensor and algorithm performance in adverse weather and light conditions is tested. Experimental evaluation demonstrates a robust data classification, all-weather tracking, and light tracking together."}, {"heading": "1 Introduction", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "2 Joint Probabilistic Formulation", "text": "Before a full Bayesian formulation for common data association, tracking, and classification is derived, a brief example is given to show how measurements fed into a tracker can be used to correctly classify the object solely on the basis of dynamics without sensor-specific meta-information about the shape, size, color, or type of the object. Kinematics-based classification methods that correspond to the dynamic model of an object with measured data points typically require access to residuals (innovations) for measurement updates and covariances of a Kalman filter (KF) or particle filter (PF). Building on the short classification example, a full Bayesian formulation is then developed that extends the combined data association and tracking of RBPF (Miller et al., 2011a)."}, {"heading": "2.1 Joint Classification and Tracking \u2013 Derivation and Example", "text": "In contemporary literature, the uncertainty in relation to the systematics of image processing typically depends on the way in which this kind of measurement is to be found in the real world and in the real world in the real world. (\"The way in which it is to be seen in the real world and in the real world.\" (\"The way in which it is to be seen in the real world and in the real world in the real world.\") The way in which it is to be seen in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world, in the real world in the real world, in the real world in the real world, and in the real world in the real world in the real world, in the real world in the real world, in the real world in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world in the real world, in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world, and in the real world in the real world in the real world in the real world, and in the real world"}, {"heading": "2.2 Joint Data Association, Tracking, and Classification", "text": "This year, it is more than ever before until it is able to retaliate."}, {"heading": "2.3 Classification with Multiple Hypothesis", "text": "As a result, however, the angular direction of the measurement would require a bi-modal distribution with a main peak along the front and rear directions of the car. Furthermore, the propagation of the position dynamics is coupled to both the heading and the ground velocity, so that a large covariance of the heading causes the overall position of the filter and the velocity estimates are uncertain and degraded. There are several options for handling multimodal distributions, such as Gaussian Sum Filters (et al., 2012) or Miller Parameters for future measurements."}, {"heading": "3 Experimental Hardware, Sensors, and Sensor Processing", "text": "There is only one way to describe it. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him. There is only one way to describe him."}, {"heading": "3.1 Vision-based Detection", "text": "In fact, it is a way in which people are able to determine for themselves what they want and what they want."}, {"heading": "3.2 Lidar Segmentation", "text": "Clusters must contain at least seven points and have at least one point that exceeds both cluster thresholds and whose maximum size is less than 15 m (the maximum typical length of a bus) are considered \"stable\" clusters and are passed on to the common perception algorithm. Clusters must contain at least seven points and have at least one point that exceeds both cluster thresholds and whose maximum size is less than 15 m (the maximum typical length of a bus).The resulting clusters are classified as \"car-sized.\" Clustering is implemented through the extension of Laplacian of Gaussians (LoG).Cluster filtering is normally used in image processing for lidar processing. Laplacian filters are derived filters that are applied to images to find an image."}, {"heading": "4 Simulation and Experimental Results", "text": "Kalman filter conclusions on object classification are demonstrated both in the Monte Carlo simulation and in experimental data by running a filter bank on object-measured data. Next, the experimental part uses data collected with a low-precision portable GPS unit from pedestrians, cyclists, cars and bus objects crossing the Cornell campus. Next, the common data associations, tracking and classification algorithms are evaluated by Skynet - Cornell's AGV input from the DUC. Repeatable scenarios of crossing events have been performed under multiple weather conditions and recorded with camera \"C,\" lidar \"L- and radar\" R sensors. Quantitative evaluations have been performed in follow-up analysis with the reduced sensor sets L + R and C + R, as well as complete sensor sets + C to evaluate whether cameras can replace AGL, sensor + C + L for applications."}, {"heading": "4.1 Monte Carlo Simulations: Joint Tracking-Classification", "text": "Monte Carlo simulations were performed to evaluate the classification performance of two categories, person and cyclist, with the truth data generated by a dynamic function exactly matching the dynamics (KF modelled dynamic functions).Synthetic tracks with a length of 50 seconds, sampled at 1Hz, were generated by the dynamic functions modelled at KF. Motion was generated from randomly selected initial conditions and process noises; synthetic measurements were generated by adding Gaussian measurement sounds to the synthetic tracks. Measuring noise was randomly drawn per track within the MC truth simulation; each track is considered an MC iteration. Measurements from each of these tracks were then performed by both KFs and classified based on the highest Produc2 probability. Both filters are initialized by matching the initial position of the first position measurement and the initial speed of the DOC vector tangendered, with the second tangential line between the first and second tangential line."}, {"heading": "4.2 Experimental Results: Joint Tracking-Classification", "text": "Experiments to investigate joint tracking and classification were conducted by building CF models with four classifications: pedestrian, cyclist, car and bus. A low accuracy hand-held GPS with 1.1 meter standard deviation of errors recorded position data from each object. Part of the data was used to estimate the process noise parameters for each class. Classification performance was analyzed on the remaining data to show that an accurate classification can only be achieved with GPS position measurements of the objects. All data was collected in Ithaca, NY around the campus of Cornell University and the Ithaca Commons. Euler integration is used to predict the model of continuous time obstacle dynamics at 1Hz intervals. GPS data were collected with a Locosys GT-31 handheld unit at 1Hz frequency and recorded in NMEA-GGA set format, which was about 18 cm quantization error in Ithaca, NY. Measurement noise for the sensor was collected with a stationary sensor, or was classified by a sensor, or a 1.2 unit."}, {"heading": "4.3 Experimental Data Collection", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "4.4 Particle Count Selection for Joint Data Association, Tracking, and Classification", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "4.5 Controlled Experiments: Sensor Sets in Joint Data Association, Tracking, and Classification", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "4.6 Controlled Experiments: Weather Conditions in Joint Data Association, Tracking, and Classification", "text": "In fact, the fact is that most of them will be able to move, to move and to move."}, {"heading": "4.7 Urban Driving Experiments: Qualitative Discussion of Performance in Weather Conditions", "text": "This year, it has come to the point where there is only one occasion when there is a scandal, and that is when there is a scandal."}, {"heading": "5 Conclusion", "text": "A novel system for detecting sensory impressions and sensitivities that are able to be present is influenced by a multitude of factors that are able to unfold, both able and able to unfold."}, {"heading": "Acknowledgments", "text": "The authors thank Trimble for providing the Omnnistar HP DGPS correction service, NVIDIA for providing a GTX980 GPU, Kevin Wyffels for revealing discussions on classification formulation, and You Won Park for designing the Ladybug3 camera mount."}], "references": [{"title": "Korean Competition Shows Weather Still a Challenge for Autonomous", "author": ["E. Ackerman"], "venue": null, "citeRegEx": "Ackerman,? \\Q2014\\E", "shortCiteRegEx": "Ackerman", "year": 2014}, {"title": "Pedestrian detection with a large-field-of-view deep", "author": ["A. autonomous-cars. Angelova", "A. Krizhevsky", "V. Vanhoucke"], "venue": null, "citeRegEx": "Angelova et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Angelova et al\\.", "year": 2015}, {"title": "Estimation with Applications to Tracking", "author": ["Y. Bar-Shalom", "X.R. Li", "T. Kirubarajan"], "venue": "Robotics and Automation (ICRA),", "citeRegEx": "Bar.Shalom et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bar.Shalom et al\\.", "year": 2015}, {"title": "Learning complexity-aware cascades for deep pedestrian", "author": ["Navigation. John Wiley", "Sons", "Z. Inc. Cai", "M.J. Saberian", "N. Vasconcelos"], "venue": null, "citeRegEx": "Wiley et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wiley et al\\.", "year": 2015}, {"title": "Histograms of oriented gradients for human detection", "author": ["detection. CoRR", "N. abs/1507.05348. Dalal", "B. Triggs"], "venue": null, "citeRegEx": "CoRR et al\\.,? \\Q2005\\E", "shortCiteRegEx": "CoRR et al\\.", "year": 2005}, {"title": "A Tutorial Survey of Architectures, Algorithms, and Applications", "author": ["L. Deng"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Object detection with discrimi", "author": ["P. Felzenszwalb", "R. Girshick", "D. McAllester", "D. Ramanan"], "venue": "Object Classes (VOC) Challenge. International Journal of Computer Vision (IJCV),", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2010}, {"title": "A Short Introduction to Boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Journal of Japanese Society", "citeRegEx": "Freund and Schapire,? \\Q1999\\E", "shortCiteRegEx": "Freund and Schapire", "year": 1999}, {"title": "A Guide to LIDAR Data Acquisition and Processing for the Forests", "author": ["D. Gatziolis", "Andersen", "H.-E"], "venue": "Artificial Intelligence,", "citeRegEx": "Gatziolis et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gatziolis et al\\.", "year": 2008}, {"title": "Vision meets Robotics: The KITTI Dataset", "author": ["A. Geiger", "P. Lenz", "C. Stiller", "R. Urtasun"], "venue": "Forest Service Pacific Northwest", "citeRegEx": "Geiger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Geiger et al\\.", "year": 2013}, {"title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conference on.", "citeRegEx": "Girshick et al\\.,? 2014", "shortCiteRegEx": "Girshick et al\\.", "year": 2014}, {"title": "Discriminatively Trained Deformable Part Models, Release 5", "author": ["R.B. Girshick", "P.F. Felzenszwalb", "D. McAllester"], "venue": "http://people.cs.uchicago.edu/ rbg/latent-release5/.", "citeRegEx": "Girshick et al\\.,? 2012", "shortCiteRegEx": "Girshick et al\\.", "year": 2012}, {"title": "Deep Residual Learning for Image Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "http://arxiv.org/pdf/1512.03385v1.pdf.", "citeRegEx": "He et al\\.,? 2015", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "A probabilistic framework for car detection in images using context and scale", "author": ["D. Held", "J. Levinson", "S. Thrun"], "venue": "Robotics and Automation (ICRA), 2012 IEEE International Conference on, pages 1628\u20131634.", "citeRegEx": "Held et al\\.,? 2012", "shortCiteRegEx": "Held et al\\.", "year": 2012}, {"title": "Precision tracking with sparse 3D and dense color 2D data", "author": ["D. Held", "J. Levinson", "S. Thrun"], "venue": "Robotics and Automation (ICRA), 2013 IEEE International Conference on, pages 1138\u20131145.", "citeRegEx": "Held et al\\.,? 2013", "shortCiteRegEx": "Held et al\\.", "year": 2013}, {"title": "Combining 3D Shape, Color, and Motion for Robust Anytime Tracking", "author": ["D. Held", "J. Levinson", "S. Thrun", "S. Savarese"], "venue": "Proceedings of Robotics: Science and Systems, Berkeley, USA.", "citeRegEx": "Held et al\\.,? 2014", "shortCiteRegEx": "Held et al\\.", "year": 2014}, {"title": "Drive PX", "author": ["J.S. Huang"], "venue": "Consumer Electronics Show. http://www.nvidia.com/object/drivepx.html.", "citeRegEx": "Huang,? 2015", "shortCiteRegEx": "Huang", "year": 2015}, {"title": "Reconstruction of rigid body models from motion distorted laser range data using optical flow", "author": ["E. Ilg", "R. Kuummerle", "W. Burgard", "T. Brox"], "venue": "Robotics and Automation (ICRA), 2014 IEEE International Conference on, pages 4627\u20134632.", "citeRegEx": "Ilg et al\\.,? 2014", "shortCiteRegEx": "Ilg et al\\.", "year": 2014}, {"title": "On Real-Time LIDAR Data Segmentation and Classification", "author": ["D. Korchev", "S. Cheng", "Y. Owechko", "K. Kim"], "venue": "Proceedings of Image Processing, Computer Vision, & Pattern Recognition ICPV.", "citeRegEx": "Korchev et al\\.,? 2013", "shortCiteRegEx": "Korchev et al\\.", "year": 2013}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS: Neural Information Processing Systems, Lake Tahoe, Nevada.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "NYC3DCars: A Dataset of 3D Vehicles in Geographic Context", "author": ["K. Matzen", "N. Snavely"], "venue": "Proc. Int. Conf. on Computer Vision.", "citeRegEx": "Matzen and Snavely,? 2013", "shortCiteRegEx": "Matzen and Snavely", "year": 2013}, {"title": "Sensitivity Analysis of a Tightly-Coupled GPS/INS System for Autonomous Navigation", "author": ["I. Miller", "M. Campbell"], "venue": "Aerospace and Electronic Systems, IEEE Transactions on, 48(2):1115\u20131135.", "citeRegEx": "Miller and Campbell,? 2012", "shortCiteRegEx": "Miller and Campbell", "year": 2012}, {"title": "Efficient Unbiased Tracking of Multiple Dynamic Obstacles Under Large Viewpoint Changes", "author": ["I. Miller", "M. Campbell", "D. Huttenlocher"], "venue": "Robotics, IEEE Transactions on, 27(1):29\u201346.", "citeRegEx": "Miller et al\\.,? 2011a", "shortCiteRegEx": "Miller et al\\.", "year": 2011}, {"title": "Map-aided localization in sparse global positioning system environments using vision and particle filtering", "author": ["I. Miller", "M. Campbell", "D. Huttenlocher"], "venue": "Journal of Field Robotics, 28(5):619\u2013643.", "citeRegEx": "Miller et al\\.,? 2011b", "shortCiteRegEx": "Miller et al\\.", "year": 2011}, {"title": "Team Cornell\u2019s Skynet: Robust perception and planning in an urban environment", "author": ["I. Miller", "M. Campbell", "D. Huttenlocher", "Kline", "F.-R.", "A. Nathan", "S. Lupashin", "J. Catlin", "B. Schimpf", "P. Moran", "N. Zych", "E. Garcia", "M. Kurdziel", "H. Fujishima"], "venue": "Journal of Field Robotics, 25(8):493\u2013527.", "citeRegEx": "Miller et al\\.,? 2008", "shortCiteRegEx": "Miller et al\\.", "year": 2008}, {"title": "Tracking and classification of dynamic obstacles using laser range finder and vision", "author": ["G. Monteiro", "C. Premebida", "P. Peixoto", "U. Nunes"], "venue": "Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).", "citeRegEx": "Monteiro et al\\.,? 2006", "shortCiteRegEx": "Monteiro et al\\.", "year": 2006}, {"title": "Preliminary Statement of Policy Concerning Automated Vehicles", "author": ["NHTSA"], "venue": "National Highway Traffic Safety Administration.", "citeRegEx": "NHTSA,? 2014", "shortCiteRegEx": "NHTSA", "year": 2014}, {"title": "Kalman Filtering Techniques for Radar Tracking", "author": ["K.V. Ramachandra"], "venue": "Marcel Dekker, Inc.", "citeRegEx": "Ramachandra,? 2000", "shortCiteRegEx": "Ramachandra", "year": 2000}, {"title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "author": ["S. Ren", "K. He", "R. Girshick", "J. Sun"], "venue": "Neural Information Processing Systems (NIPS). Microsoft Research. http://arxiv.org/pdf/1506.01497v2.pdf.", "citeRegEx": "Ren et al\\.,? 2015", "shortCiteRegEx": "Ren et al\\.", "year": 2015}, {"title": "On target classification using kinematic data", "author": ["B. Ristic", "N. Gordon", "A. Bessell"], "venue": "Information Fusion, 5:15\u201321.", "citeRegEx": "Ristic et al\\.,? 2004", "shortCiteRegEx": "Ristic et al\\.", "year": 2004}, {"title": "Nvidia Wants to Build the Robocar\u2019s Brain", "author": ["P.E. Ross"], "venue": "IEEE Spectrum, Cars that Think Website. http://spectrum.ieee.org/cars-that-think/transportation/self-driving/nvidia-wants-to-buildthe-robocars-brain.", "citeRegEx": "Ross,? 2015", "shortCiteRegEx": "Ross", "year": 2015}, {"title": "30Hz Object Detection with DPM V5", "author": ["M.A. Sadeghi", "D. Forsyth"], "venue": "Fleet, D., Pajdla, T., Schiele, B., and Tuytelaars, T., editors, Computer Vision \u2013 ECCV 2014, volume 8689 of Lecture Notes in Computer Science, pages 65\u201379. Springer International Publishing.", "citeRegEx": "Sadeghi and Forsyth,? 2014", "shortCiteRegEx": "Sadeghi and Forsyth", "year": 2014}, {"title": "Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems - J3016", "author": ["SAE"], "venue": "Society of Automotive Engineers: On-Road Automated Vehicle Standards Committee.", "citeRegEx": "SAE,? 2013", "shortCiteRegEx": "SAE", "year": 2013}, {"title": "Posterior representation with a multi-modal likelihood using the gaussian sum filter for localization in a known map", "author": ["J.R. Schoenberg", "M. Campbell", "I. Miller"], "venue": "Journal of Field Robotics, 29(2):240\u2013257.", "citeRegEx": "Schoenberg et al\\.,? 2012", "shortCiteRegEx": "Schoenberg et al\\.", "year": 2012}, {"title": "Programmable automotive headlights", "author": ["R. Tamburo", "E. Nurvitadhi", "A. Chugh", "M. Chen", "A. Rowe", "T. Kanade", "S. Narasimhan"], "venue": "European Conference of Computer Vision (ECCV), volume 8692 of Lecture Notes in Computer Science, pages 750\u2013765. Springer International Publishing.", "citeRegEx": "Tamburo et al\\.,? 2014", "shortCiteRegEx": "Tamburo et al\\.", "year": 2014}, {"title": "Towards 3D object recognition via classification of arbitrary object tracks", "author": ["A. Teichman", "J. Levinson", "S. Thrun"], "venue": "Robotics and Automation (ICRA), 2011 IEEE International Conference on, pages 4034\u20134041.", "citeRegEx": "Teichman et al\\.,? 2011", "shortCiteRegEx": "Teichman et al\\.", "year": 2011}, {"title": "Practical object recognition in autonomous driving and beyond", "author": ["A. Teichman", "S. Thrun"], "venue": "Advanced Robotics and its Social Impacts (ARSO), 2011 IEEE Workshop on, pages 35\u201338.", "citeRegEx": "Teichman and Thrun,? 2011", "shortCiteRegEx": "Teichman and Thrun", "year": 2011}, {"title": "Probabilistic Robotics", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": "The MIT Press.", "citeRegEx": "Thrun et al\\.,? 2006", "shortCiteRegEx": "Thrun et al\\.", "year": 2006}, {"title": "The Google Self-Driving Car Project", "author": ["C. Urmson"], "venue": "Technical report, Google Inc.", "citeRegEx": "Urmson,? 2011", "shortCiteRegEx": "Urmson", "year": 2011}, {"title": "Let the Robot Drive The Autonomous Car of the Future is Here", "author": ["T. Vanderbilt"], "venue": "Wired Magazine. http://www.wired.com/2012/01/ff autonomouscars/.", "citeRegEx": "Vanderbilt,? 2012", "shortCiteRegEx": "Vanderbilt", "year": 2012}, {"title": "The Gaussian Mixture Probability Hypothesis Density Filter", "author": ["B. Vo", "W. Ma"], "venue": "IEEE: Transactions Signal Processing, 54(11):4091\u20134104. 35", "citeRegEx": "Vo and Ma,? 2006", "shortCiteRegEx": "Vo and Ma", "year": 2006}], "referenceMentions": [{"referenceID": 22, "context": "The presented algorithm extends a Rao-Blackwellized Particle Filter originally built with a particle filter for data association and a Kalman filter for multi-object tracking (Miller et al., 2011a) to now also include multiple model tracking for classification.", "startOffset": 175, "endOffset": 197}, {"referenceID": 26, "context": "Both the NHTSA (NHTSA, 2014) and SAE (SAE, 2013) have published roadmaps for the future development of autonomous vehicles and have posed the Holy Grail of \u201cLevel 4 or 5\u201d as full autonomy in any environment and situation.", "startOffset": 15, "endOffset": 28}, {"referenceID": 32, "context": "Both the NHTSA (NHTSA, 2014) and SAE (SAE, 2013) have published roadmaps for the future development of autonomous vehicles and have posed the Holy Grail of \u201cLevel 4 or 5\u201d as full autonomy in any environment and situation.", "startOffset": 37, "endOffset": 48}, {"referenceID": 0, "context": "At the 2014 Future Automobile Technology Competition in South Korea, rain fell the morning of the second day of testing (Ackerman, 2014).", "startOffset": 120, "endOffset": 136}, {"referenceID": 19, "context": ", 2010a), and (3) deep learning methods that learn a rich hierarchy of low-level to high-level features from data with little to no manual engineering of the model structure (Krizhevsky et al., 2012), (Girshick et al.", "startOffset": 174, "endOffset": 199}, {"referenceID": 10, "context": ", 2012), (Girshick et al., 2014), (Girshick, 2015), (Ren et al.", "startOffset": 9, "endOffset": 32}, {"referenceID": 28, "context": ", 2014), (Girshick, 2015), (Ren et al., 2015), and (He et al.", "startOffset": 27, "endOffset": 45}, {"referenceID": 12, "context": ", 2015), and (He et al., 2015).", "startOffset": 13, "endOffset": 30}, {"referenceID": 18, "context": ", 2011) and (Korchev et al., 2013).", "startOffset": 12, "endOffset": 34}, {"referenceID": 14, "context": "Aligning point-clouds with iterated closest point methods has been shown to improve tracking performance of obstacles\u2019 absolute ground speed, an inherently noisy parameter when estimated as a derivative of position in a parametric filter (Held et al., 2013).", "startOffset": 238, "endOffset": 257}, {"referenceID": 13, "context": "Further advancements have demonstrated real-time performance of DPM vision detection methods (Held et al., 2012) and (Sadeghi and Forsyth, 2014), and hardware advances in embedded computing have shown deep learning classification running on rugged mobile platforms (Huang, 2015).", "startOffset": 93, "endOffset": 112}, {"referenceID": 31, "context": ", 2012) and (Sadeghi and Forsyth, 2014), and hardware advances in embedded computing have shown deep learning classification running on rugged mobile platforms (Huang, 2015).", "startOffset": 12, "endOffset": 39}, {"referenceID": 16, "context": ", 2012) and (Sadeghi and Forsyth, 2014), and hardware advances in embedded computing have shown deep learning classification running on rugged mobile platforms (Huang, 2015).", "startOffset": 160, "endOffset": 173}, {"referenceID": 36, "context": "(Teichman and Thrun, 2011) stated that full joint solutions to this perception problem are intractable to formulate or compute.", "startOffset": 0, "endOffset": 26}, {"referenceID": 35, "context": "Many advanced techniques recently published have evaluated performance of some of these components in isolation from others in the overall perception pipeline (Teichman et al., 2011), (Ilg et al.", "startOffset": 159, "endOffset": 182}, {"referenceID": 17, "context": ", 2011), (Ilg et al., 2014), (Held et al.", "startOffset": 9, "endOffset": 27}, {"referenceID": 15, "context": ", 2014), (Held et al., 2014).", "startOffset": 9, "endOffset": 28}, {"referenceID": 36, "context": "Examples include: improved tracking and classification algorithms that ignored any segmentation or data association errors (Teichman and Thrun, 2011), performed evaluations on very limited types of scenarios such as tracking a large number of stationary cars or a small number of dynamic objects (Held et al.", "startOffset": 123, "endOffset": 149}, {"referenceID": 14, "context": "Examples include: improved tracking and classification algorithms that ignored any segmentation or data association errors (Teichman and Thrun, 2011), performed evaluations on very limited types of scenarios such as tracking a large number of stationary cars or a small number of dynamic objects (Held et al., 2013), simply lacked access to large public-domain accurately labeled", "startOffset": 296, "endOffset": 315}, {"referenceID": 18, "context": "urban data sets available to quantitatively evaluate performance (Korchev et al., 2013), or handled classification separately after combining data association and tracking (Miller et al.", "startOffset": 65, "endOffset": 87}, {"referenceID": 22, "context": ", 2013), or handled classification separately after combining data association and tracking (Miller et al., 2011a).", "startOffset": 92, "endOffset": 114}, {"referenceID": 37, "context": "A corresponding philosophical question arises in robotics literature (Thrun et al., 2006) regarding the importance of actually modeling the dynamics of all possible object classifications if the inputs are truly unknown.", "startOffset": 69, "endOffset": 89}, {"referenceID": 38, "context": "Google, for example, heavily utilizes background subtraction for lidar sensor processing, subtracting sensor returns from a prebuilt 3D static environmental map to identify moving obstacles (Urmson, 2011).", "startOffset": 190, "endOffset": 204}, {"referenceID": 39, "context": ", 2014) and (Vanderbilt, 2012).", "startOffset": 12, "endOffset": 30}, {"referenceID": 29, "context": "Such multiple model tracking has been shown beneficial for tracking airplanes in turning and straight flight (Ristic et al., 2004) but is novel for classification of terrestrial objects in urban vehicular environments.", "startOffset": 109, "endOffset": 130}, {"referenceID": 22, "context": "This paper utilizes Skynet, Cornell\u2019s autonomous 2007 Chevrolet Tahoe from the DUC, and builds upon (Miller et al., 2011a) to extend joint data association and tracking to include classification; relaxations allowing computational feasibility come from a Rao-Blackwellized Particle Filter (RBPF), multiple hypothesis modeling, and carefully managing measurements in forward-pass parametric filters.", "startOffset": 100, "endOffset": 122}, {"referenceID": 22, "context": "By building upon the brief classification example, a full Bayesian formulation is then developed that extends the combined data association and tracking RBPF from (Miller et al., 2011a).", "startOffset": 163, "endOffset": 185}, {"referenceID": 25, "context": "Similar work has been done by (Monteiro et al., 2006) to combine a KF with extra sensor information such as imagery data to infer object classification.", "startOffset": 30, "endOffset": 53}, {"referenceID": 7, "context": "Alternative approaches known as boosting methods have combined banks of weak classifiers to infer object classification; AdaBoost is one of the most popular (Freund and Schapire, 1999).", "startOffset": 157, "endOffset": 184}, {"referenceID": 27, "context": "where ex1 , and ex2 correspond to the acceleration process noise in the East and North Cartesian directions, respectively, similar to that presented in (Ramachandra, 2000).", "startOffset": 152, "endOffset": 171}, {"referenceID": 22, "context": "In (Miller et al., 2011a) a joint solution for measurement association and object tracking is presented as a RaoBlackwellized Particle Filter which solves p(Ak, Ok|Zk), where capital letters with k subscripts represent the set\u2019s history until time k.", "startOffset": 3, "endOffset": 25}, {"referenceID": 40, "context": "Some general filtering methods such as the Gaussian Mixture Probability Hypothesis Density Filter (Vo and Ma, 2006) exist which could estimate joint densities over different variables, but in general, no closed form solutions exist, and computational requirements for an exact filter would grow exponentially through time and would be impractical.", "startOffset": 98, "endOffset": 115}, {"referenceID": 22, "context": "Miller showed how the infeasible problem can be made feasible by using factorization and sampling techniques (Miller et al., 2011a).", "startOffset": 109, "endOffset": 131}, {"referenceID": 40, "context": "In (Vo and Ma, 2006) this same splitting was implemented via a Rao-Blackwellized Particle Filter (RBPF).", "startOffset": 3, "endOffset": 20}, {"referenceID": 40, "context": "For the sake of brevity, a full derivation of particle likelihood formulations including birth and death likelihoods and resampling procedures has been omitted; (Vo and Ma, 2006) and (Miller et al.", "startOffset": 161, "endOffset": 178}, {"referenceID": 22, "context": "For the sake of brevity, a full derivation of particle likelihood formulations including birth and death likelihoods and resampling procedures has been omitted; (Vo and Ma, 2006) and (Miller et al., 2011a) both present thorough summaries.", "startOffset": 183, "endOffset": 205}, {"referenceID": 7, "context": "The formulation included here natively supports sensor-specific output of object classification along with weak classifiers typically used in a boosting framework (Freund and Schapire, 1999).", "startOffset": 163, "endOffset": 190}, {"referenceID": 20, "context": "Vision-based car detections provide vehicle heading in addition to locating the vehicle\u2019s bounding box within the scene (Matzen and Snavely, 2013).", "startOffset": 120, "endOffset": 146}, {"referenceID": 33, "context": "Multiple options exist for handling multi-modal distributions, such as Gaussian Sum Filters (Schoenberg et al., 2012) or Particle Filters (Miller et al.", "startOffset": 92, "endOffset": 117}, {"referenceID": 23, "context": ", 2012) or Particle Filters (Miller et al., 2011b).", "startOffset": 28, "endOffset": 50}, {"referenceID": 24, "context": "Experiments in this paper utilize Cornell\u2019s DUC entry vehicle, a 2007 Chevy Tahoe dubbed Skynet (Miller et al., 2008).", "startOffset": 96, "endOffset": 117}, {"referenceID": 24, "context": "Hardware upgrades since the DUC (Miller et al., 2008) include a Point Grey Ladybug3 360 degree field-of-view spherical camera, external waterproofing of all sensor mounts and wiring, and upgrading of on-board computing and storage rack-mount servers.", "startOffset": 32, "endOffset": 53}, {"referenceID": 21, "context": "A pose estimator described in (Miller and Campbell, 2012) combines sensor measurements to utilize strengths of each sensor and diversity to generate a robust attitude and position estimation solution.", "startOffset": 30, "endOffset": 57}, {"referenceID": 24, "context": "The following sections detail raw sensor processing, developed since the DUC (Miller et al., 2008) and (Miller et al.", "startOffset": 77, "endOffset": 98}, {"referenceID": 22, "context": ", 2008) and (Miller et al., 2011a), to detect vehicles and people with the Ladybug camera and to process lidar returns for person-sized and car-sized clusters.", "startOffset": 12, "endOffset": 34}, {"referenceID": 13, "context": "Recent studies have shown improved detection and classification rates for cars (Held et al., 2012) and pedestrians (Angelova et al.", "startOffset": 79, "endOffset": 98}, {"referenceID": 1, "context": ", 2012) and pedestrians (Angelova et al., 2015), (Cai et al.", "startOffset": 24, "endOffset": 47}, {"referenceID": 20, "context": "The car detector was first introduced in (Matzen and Snavely, 2013).", "startOffset": 41, "endOffset": 67}, {"referenceID": 9, "context": ", 2010) \u2013 an Internet dataset with 2D bounding box annotations, KITTI (Geiger et al., 2013) \u2013 an autonomous vehicle dataset with 3D bounding box and orientation annotations fitted to lidar point clouds, and NYC3DCars (Matzen and Snavely, 2013) \u2013 an Internet dataset with 3D bounding box and orientation annotations built by estimating scene geometry and asking annotators to place 3D models in the reconstructed scene.", "startOffset": 70, "endOffset": 91}, {"referenceID": 20, "context": ", 2013) \u2013 an autonomous vehicle dataset with 3D bounding box and orientation annotations fitted to lidar point clouds, and NYC3DCars (Matzen and Snavely, 2013) \u2013 an Internet dataset with 3D bounding box and orientation annotations built by estimating scene geometry and asking annotators to place 3D models in the reconstructed scene.", "startOffset": 133, "endOffset": 159}, {"referenceID": 11, "context": "The detector from (Girshick et al., 2012) is used for person detections.", "startOffset": 18, "endOffset": 41}, {"referenceID": 24, "context": "Car-sized clustering was unchanged from the DUC as described in (Miller et al., 2008).", "startOffset": 64, "endOffset": 85}, {"referenceID": 0, "context": "This condition most closely resembled the conditions on the second day of the KAIST competition that resulted in two autonomous vehicles crashing (Ackerman, 2014).", "startOffset": 146, "endOffset": 162}, {"referenceID": 22, "context": "In Miller\u2019s original RBPF (Miller et al., 2011a), multiple hypotheses helped model ambiguity associated with data association.", "startOffset": 26, "endOffset": 48}, {"referenceID": 22, "context": "For configuration 1, joint association and tracking, in accordance with (Miller et al., 2011a), increasing particle count from 1 to 4 improves performance; performance plateaus at 8 particles.", "startOffset": 72, "endOffset": 94}, {"referenceID": 31, "context": "Recent developments such as (Sadeghi and Forsyth, 2014), (Angelova et al.", "startOffset": 28, "endOffset": 55}, {"referenceID": 1, "context": "Recent developments such as (Sadeghi and Forsyth, 2014), (Angelova et al., 2015), and (Cai et al.", "startOffset": 57, "endOffset": 80}, {"referenceID": 39, "context": ", 2014), (Vanderbilt, 2012), precipitation generally did not affect radars in a noticeable way in the experiments.", "startOffset": 9, "endOffset": 27}, {"referenceID": 30, "context": "It has been reported (Ross, 2015) that radar can have problems with shiny and reflective glass or objects, but this was not observed in Skynet recorded data.", "startOffset": 21, "endOffset": 33}, {"referenceID": 34, "context": "Extending tracking of precipitation (Tamburo et al., 2014) with classification to categorize various weather phenomenon could improve individual sensor performance or perception system performance.", "startOffset": 36, "endOffset": 58}], "year": 2016, "abstractText": "A novel probabilistic perception algorithm is presented as a real-time joint solution to data association, object tracking, and object classification for an autonomous ground vehicle in all-weather conditions. The presented algorithm extends a Rao-Blackwellized Particle Filter originally built with a particle filter for data association and a Kalman filter for multi-object tracking (Miller et al., 2011a) to now also include multiple model tracking for classification. Additionally a state-of-the-art vision detection algorithm that includes heading information for autonomous ground vehicle (AGV) applications was implemented. Cornell\u2019s AGV from the DARPA Urban Challenge was upgraded and used to experimentally examine if and how state-of-the-art vision algorithms can complement or replace lidar and radar sensors. Sensor and algorithm performance in adverse weather and lighting conditions is tested. Experimental evaluation demonstrates robust all-weather data association, tracking, and classification where camera, lidar, and radar sensors complement each other inside the joint probabilistic perception algorithm.", "creator": "LaTeX with hyperref package"}}}