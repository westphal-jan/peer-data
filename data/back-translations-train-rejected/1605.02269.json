{"id": "1605.02269", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2016", "title": "Predicting Performance on MOOC Assessments using Multi-Regression Models", "abstract": "The past few years has seen the rapid growth of data min- ing approaches for the analysis of data obtained from Mas- sive Open Online Courses (MOOCs). The objectives of this study are to develop approaches to predict the scores a stu- dent may achieve on a given grade-related assessment based on information, considered as prior performance or prior ac- tivity in the course. We develop a personalized linear mul- tiple regression (PLMR) model to predict the grade for a student, prior to attempting the assessment activity. The developed model is real-time and tracks the participation of a student within a MOOC (via click-stream server logs) and predicts the performance of a student on the next as- sessment within the course offering. We perform a com- prehensive set of experiments on data obtained from three openEdX MOOCs via a Stanford University initiative. Our experimental results show the promise of the proposed ap- proach in comparison to baseline approaches and also helps in identification of key features that are associated with the study habits and learning behaviors of students.", "histories": [["v1", "Sun, 8 May 2016 04:00:31 GMT  (664kb,D)", "http://arxiv.org/abs/1605.02269v1", "8 pages, 7 figures"]], "COMMENTS": "8 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.CY cs.LG", "authors": ["zhiyun ren", "huzefa rangwala", "aditya johri"], "accepted": false, "id": "1605.02269"}, "pdf": {"name": "1605.02269.pdf", "metadata": {"source": "CRF", "title": "Predicting Performance on MOOC Assessments using Multi-Regression Models", "authors": ["Zhiyun Ren", "George Mason", "Huzefa Rangwala", "Aditya Johri"], "emails": ["zen4@masonlive.gmu.edu", "rangwala@cs.gmu.edu", "johri@gmu.edu"], "sections": [{"heading": null, "text": "Keywords Personalized linear multi-regression models, MOOC, performance prediction"}, {"heading": "1. INTRODUCTION", "text": "Since its inception, Massive Open Online Courses (MOOCs) have aimed at providing online learning on a variety of topics for a large number of participants around the world. Due to the low cost (mostly zero) and the lack of entry barriers (e.g., requirements or qualification requirements) for participants, a large number of students may enroll in MOOCs, but only a small fraction of them keep themselves engaged in the learning materials and participate in the various activities associated with the course offerings, such as watching the video lectures, studying the materials, completing the various quiz and homework-based assessments. Given this high mapping rate and the potential of MOOCs to deliver low-cost but high-quality education, several researchers have associated the server logs with these MOOCs to determine the factors associated with students who drop out of their education. Several predictive methods have been developed to predict when a MOOCs will emerge."}, {"heading": "2. RELATED WORK", "text": "Several researchers have focused on analyzing educational data (including MOOCs) in an effort to understand the characteristics of learning behavior and student motivation within this educational model. [13] Boyer et. al. [2] focus on the problem of stop-out prediction within MOOCs; by developing a series of processes that use information from previous courses and the previous weeks of the current course. Brinton et. al. [3] developed an approach to predict whether a student answers a question correctly at the first attempt using clickstream information and social learning networks. Kennedy et al. [9] analyzed the relationship between a student's prior knowledge and performance at the end of the MOOC."}, {"heading": "3. METHODS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Personal Linear Multi-Regression Models", "text": "We train a personalized linear multi-regression model (PLMR) [5] to predict student performance within a MOOC. Specifically, the grade g, a is predicted for a student in an assessment activity a as follows: g, a = bs + p t sWfsa = bs + l \u2211 d = 1 (ps, d nF \u2211 k = 1 fsa, kwd, k), (1) where bs is the bias term for students s, fsa is the characteristic vector of interaction between students s and activity a. The characteristics extracted from the MOOC server protocols are described in the next paragraph. nF is the length of fsa indicating the dimension of our feature space. l is the number of linear regression models, W is the coefficient matrix of dimensions l \u00d7 nF containing the coefficients of linear regression models, and is a vector of the length that holds the different regression models within the students."}, {"heading": "3.2 Feature Description", "text": "In fact, most of them will be able to orient themselves in a different direction than the direction in which they are moving."}, {"heading": "4. EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets", "text": "This year, it will be able to research the aforementioned hreeisrcnlrVo in order to reactivate and reactivate it."}, {"heading": "4.3 Data Partition", "text": "We divide the students for StLearn and StMed into two groups: the group of students who do all the required homework, and the group of students who do little homework, so we can take into account the different motivations and expectations of the students who sign up for a MOOC. For example, students who want to study in a MOOC can watch videos for a long time and not do the homework. Students who want a diploma may not pay as much to watch the videos, but focus on the results of the homework. We call the first group \"Partial Homework Group\" and the second group \"All Homework Group.\" We evaluate our models against the two groups for the AllStMed and AllStLearn datasets. Specifically, we name the four groups of students as AllStMed, AllStLearn, PartialStMed and PartialStLearn based on their group and MOOC classs.For the IntroCN course, both the intermediate and final exams are available."}, {"heading": "4.4 Evaluation Metrics", "text": "StMed and IntroCN courses have continuous scores for a homework or exam that are scaled from 0 to 1. However, the homework score in the StLearn course is binary and indicates whether the student answers a question correctly or incorrectly. In StLearn, we use a logistical loss and formulate a classification problem instead of the regression problem as in the StMed and IntroCN courses. To evaluate the performance of our approach, we use the mean of the quadratic error (RMSE) as the measure of choice for the regression problem. For the classification problem, we use accuracy and the F1 score (harmonious mean of precision and memory), which is known as the appropriate metric for unbalanced datasets."}, {"heading": "4.5 Comparative Approaches.", "text": "In this paper, we compare the performance of our proposed methods with two different competing starting methods. 1. Average grade of previous homework. We calculate the mean of a student's previous homework to predict their future performance, and are called Meanscore. We use this method to compare our prediction results on StMed.2. KT-IDEM [12]. KT-IDEM is a modified version of the original CCTC model. By adding an \"item\" to each question node, the model assigns a different probability of \"slip\" and \"rate\" to each question due to uneven difficulty. Since this model can only predict a binary value, we use this model to compare our prediction results on StLearn."}, {"heading": "5. RESULTS AND DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Assessment Prediction Results", "text": "This year, it has come to the point where there is only one person who is able to take care of another person who is able to take care of another person."}, {"heading": "7. REFERENCES", "text": "[1] Ryan SJd Baker, Albert T Corbett, and VincentAleven. Improving contextual models of guessing and slipping with a truncated training set. Human-Computer Interaction Institute, page 17, 2008. [2] Sebastien Boyer and Kalyan Justin Veeramachaneni. Transfer learning for predictive models in massive open online courses. In Artificial Intelligence in Education, pages 54-63. Knowledge Tracing: Modeling the acquisition of procedural knowledge. User modeling and user-adapted interaction, 4 (4): 253-278, 1994. [5] Asmaa Elbadrawy, Scott Studham, and George Karypis."}], "references": [{"title": "Improving contextual models of guessing and slipping with a truncated training", "author": ["Ryan SJd Baker", "Albert T Corbett", "Vincent Aleven"], "venue": "set. Human-Computer Interaction Institute,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Transfer learning for predictive models in massive open online courses", "author": ["Sebastien Boyer", "Kalyan Veeramachaneni"], "venue": "In Artificial Intelligence in Education,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Mooc performance prediction via clickstream data and social learning networks", "author": ["Christopher G Brinton", "Mung Chiang"], "venue": "To appear,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Knowledge tracing: Modeling the acquisition of procedural knowledge", "author": ["Albert T Corbett", "John R Anderson"], "venue": "User modeling and user-adapted interaction,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "Personalized multi-regression models for predicting students performance in course activities", "author": ["Asmaa Elbadrawy", "Scott Studham", "George Karypis"], "venue": "UMN CS 14-011,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Predictors of retention and achievement in a massive open online course", "author": ["Jeffrey A Greene", "Christopher A Oswald", "Jeffrey Pomerantz"], "venue": "American Educational Research Journal,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "The utilization of data analysis techniques in predicting student performance in massive open online courses (moocs)", "author": ["Glyn Hughes", "Chelsea Dobbins"], "venue": "Research and Practice in Technology Enhanced Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Predicting mooc performance with week 1 behavior", "author": ["Suhang Jiang", "Adrienne Williams", "Katerina Schenke", "Mark Warschauer", "Diane O\u2019dowd"], "venue": "In Educational Data", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Predicting success: how learners\u2019 prior knowledge, skills and activities predict mooc performance", "author": ["Gregor Kennedy", "Carleton Coffrin", "Paula de Barba", "Linda Corrin"], "venue": "In Proceedings of the Fifth International Conference on Learning Analytics And Knowledge,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Learners expectations and motivations using content analysis in a mooc", "author": ["Daniel FO Onah", "Jane Sinclair"], "venue": "In EdMedia 2015-World Conference on Educational Media and Technology,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Adapting bayesian knowledge tracing to a massive open online course in edx", "author": ["Zachary Pardos", "Yoav Bergner", "Daniel Seaton", "David Pritchard"], "venue": "In Educational Data", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Kt-idem: Introducing item difficulty to the knowledge tracing model", "author": ["Zachary A Pardos", "Neil T Heffernan"], "venue": "In User Modeling, Adaption and Personalization,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Educational data mining: A survey and a data mining-based analysis of recent works", "author": ["Alejandro Pe\u00f1a-Ayala"], "venue": "Expert systems with applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Analysing and predicting recurrent interactions among learners during online discussions in a mooc", "author": ["Ayse Saliha Sunar", "Nor Aniza Abdullah", "Susan White", "Hugh C Davis"], "venue": "Proceedings of the 11th International Conference on Knowledge Management,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1996}, {"title": "Smartgpa: how smartphones can assess and predict academic performance of college students", "author": ["Rui Wang", "Gabriella Harari", "Peilin Hao", "Xia Zhou", "Andrew T Campbell"], "venue": "In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Beyond prediction: First steps toward automatic intervention in mooc student stopout", "author": ["Jacob Whitehill", "Joseph Jay Williams", "Glenn Lopez", "Cody Austun Coleman", "Justin Reich"], "venue": "Available at SSRN 2611750,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Turn on, tune in, drop out: Anticipating student dropouts in massive open online courses", "author": ["Diyi Yang", "Tanmay Sinha", "David Adamson", "Carolyn Penstein Rose"], "venue": "In Proceedings of the 2013 NIPS Data-Driven Education Workshop,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Early prediction of student dropout and performance in moocs using higher granularity temporal information", "author": ["Cheng Ye", "Gautam Biswas"], "venue": "Journal of Learning Analytics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Behavior prediction in moocs using higher granularity temporal information", "author": ["Cheng Ye", "John S Kinnebrew", "Gautam Biswas", "Brent J Evans", "Douglas H Fisher", "Gayathri Narasimham", "Katherine A Brady"], "venue": "In Proceedings of the Second", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}], "referenceMentions": [{"referenceID": 5, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 6, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 7, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 16, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 17, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 18, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 19, "context": "Several predictive methods have been developed to predict when a participant will drop out from a MOOC [6, 7, 8, 17, 18, 19, 20].", "startOffset": 103, "endOffset": 128}, {"referenceID": 9, "context": "Participants enroll in a MOOC sometimes to learn a subset of topics within the curriculum, sometimes to earn degree certificates for future career promotion or college credit, social experience or/and exploration of free online education [10].", "startOffset": 238, "endOffset": 242}, {"referenceID": 5, "context": "Students with similar motivation have different learning outcomes from a MOOC based on the number of invested hours, prior education background, knowledge and skills [6].", "startOffset": 166, "endOffset": 169}, {"referenceID": 4, "context": "This approach was previously studied within the context of predicting a student\u2019s performance based on graded activities within a traditional university course with data extracted from a learning management system (Moodle) [5].", "startOffset": 223, "endOffset": 226}, {"referenceID": 0, "context": "al [1] have presented systems that can adapt based on predictions of future student performance, and they were able to incorporate interventions, which were effective in improving student experiences within Intelligent Tutoring Systems (ITS).", "startOffset": 3, "endOffset": 6}, {"referenceID": 12, "context": "Several researchers have focused on the analysis of education data (including MOOCs), in an effort to understand the characteristics of student learning behaviors and motivation within this education model [13].", "startOffset": 206, "endOffset": 210}, {"referenceID": 1, "context": "[2] focus on the stopout prediction problem within MOOCs; by designing a set of processes using information from previous courses and the previous weeks of the current course.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] developed an approach to predict if a student answers a question correct on the first attempt via clickstream information and social learning networks.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] analyzed the relationship between a student\u2019s prior knowledge on end-of-MOOC performance.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "[14] developed an approach to predict the possible interactions between peers participating in a MOOC.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Most similar to our proposed work, Bayesian Knowledge Tracing (BKT) [12] has been adapted to predict whether a student can get a MOOC assessment correct or not.", "startOffset": 68, "endOffset": 72}, {"referenceID": 3, "context": "BKT was first developed [4] for modeling the evolving knowledge states of students monitored within Intelligent Tutoring Systems (ITS).", "startOffset": 24, "endOffset": 27}, {"referenceID": 10, "context": "By identifying the challenges associated with modeling MOOC data, the IDEM approach and extensions that involve splitting questions into several sub-parts and incorporating resource (knowledge) information [11] are considered state-of-the-art MOOC assessment prediction approaches and referred as KT-IDEM.", "startOffset": 206, "endOffset": 210}, {"referenceID": 15, "context": "[16] performed a study to predict student\u2019s performance by capturing data relevant to study habits and learning behaviors from their smartphones.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] proposed the use of personalized linear multi-regression models to predict student performance in a traditional university by extracting data from course management systems (Moodle).", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "We train a personalized linear multi-regression (PLMR) model [5] to predict student performance within a MOOC.", "startOffset": 61, "endOffset": 64}, {"referenceID": 4, "context": "l is the number of linear regression models, W is the coefficient matrix of dimensions l \u00d7 nF that holds the coefficients of the l linear regression models, and ps is a vector of length l that holds the memberships of student s within the l different regression models [5].", "startOffset": 269, "endOffset": 272}, {"referenceID": 14, "context": "Using lasso [15], we solve the following optimization problem:", "startOffset": 12, "endOffset": 16}, {"referenceID": 11, "context": "KT-IDEM [12].", "startOffset": 8, "endOffset": 12}], "year": 2016, "abstractText": "The past few years has seen the rapid growth of data mining approaches for the analysis of data obtained from Massive Open Online Courses (MOOCs). The objectives of this study are to develop approaches to predict the scores a student may achieve on a given grade-related assessment based on information, considered as prior performance or prior activity in the course. We develop a personalized linear multiple regression (PLMR) model to predict the grade for a student, prior to attempting the assessment activity. The developed model is real-time and tracks the participation of a student within a MOOC (via click-stream server logs) and predicts the performance of a student on the next assessment within the course offering. We perform a comprehensive set of experiments on data obtained from three openEdX MOOCs via a Stanford University initiative. Our experimental results show the promise of the proposed approach in comparison to baseline approaches and also helps in identification of key features that are associated with the study habits and learning behaviors of students.", "creator": "LaTeX with hyperref package"}}}