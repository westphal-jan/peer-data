{"id": "1605.02442", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2016", "title": "Machine Learning Techniques with Ontology for Subjective Answer Evaluation", "abstract": "Computerized Evaluation of English Essays is performed using Machine learning techniques like Latent Semantic Analysis (LSA), Generalized LSA, Bilingual Evaluation Understudy and Maximum Entropy. Ontology, a concept map of domain knowledge, can enhance the performance of these techniques. Use of Ontology makes the evaluation process holistic as presence of keywords, synonyms, the right word combination and coverage of concepts can be checked. In this paper, the above mentioned techniques are implemented both with and without Ontology and tested on common input data consisting of technical answers of Computer Science. Domain Ontology of Computer Graphics is designed and developed. The software used for implementation includes Java Programming Language and tools such as MATLAB, Prot\\'eg\\'e, etc. Ten questions from Computer Graphics with sixty answers for each question are used for testing. The results are analyzed and it is concluded that the results are more accurate with use of Ontology.", "histories": [["v1", "Mon, 9 May 2016 07:14:52 GMT  (1013kb)", "http://arxiv.org/abs/1605.02442v1", "11 pages, 5 figures, journal,this http URL2016"]], "COMMENTS": "11 pages, 5 figures, journal,this http URL2016", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.IR", "authors": ["m syamala devi", "himani mittal"], "accepted": false, "id": "1605.02442"}, "pdf": {"name": "1605.02442.pdf", "metadata": {"source": "CRF", "title": "MACHINE LEARNING TECHNIQUES WITH ONTOLOGY FOR SUBJECTIVE ANSWER EVALUATION", "authors": ["M. Syamala Devi", "Himani Mittal"], "emails": [], "sections": [{"heading": null, "text": "DOI: 10.5121 / ijnlc.2016.5201 1Computerized Evaluation of English Essays is done using Machine Learning Techniques such as Latent Semantic Analysis (LSA), Generalized LSA, Bilingual Evaluation Understudy and Maximum Entropy. Ontology, a concept map of domain knowledge, can increase the performance of these techniques. Using ontology makes the evaluation process holistic, since keywords, synonyms, the correct word combination and the coverage of concepts can be verified. In this essay, the above techniques are implemented with or without ontology and tested on common input data consisting of technical answers of computer science. Domain Ontology of Computer Graphics is designed and developed. The software for implementation includes Java Programming Language and tools such as MATLAB, Prot\u00e9g\u00e9, etc. Ten questions from Computer Graphics with sixty answers are used for each question to test."}, {"heading": "1. INTRODUCTION", "text": "The manual system for evaluating the subjective answers for technical subjects involves a lot of time and effort of the evaluator. Carrying out the evaluation by computers with intelligent techniques ensures uniformity of marking, since the same inference mechanism is used for all students. Subjective answers are evaluated on the basis of content and spellings. For technical subjects, the emphasis is more on content. If standard keywords are found in the student's answer, the answer is correct. However, we cannot mark the answers simply by counting the number of keywords. A holistic approach is required, which can be evaluated on the basis of not only keyword presence, but also the semantic relationship between words and concepts. Multiple machine learning methods exist that attempt to capture the latent relationship between words. The techniques explored in this paper - latent semantic analysis (LSA), latent semantic semantic analysis (GLSA), maximum max. entropy (entropy study) and bial evaluation."}, {"heading": "2. REVIEW OF RELATED WORK", "text": "Research to evaluate subjective responses with computers has been underway for more than a decade."}, {"heading": "3. APPLICATION OF MACHINE LEARNING TECHNIQUES TO SUBJECTIVE EVALUATION WITHOUT ONTOLOGY", "text": "The aforementioned suggestions from the period around 1900 to 1900 gained new significance in the years around 1900 and around 1900 to 1900."}, {"heading": "4. APPLICATION OF MACHINE LEARNING TECHNIQUES TO SUBJECTIVE EVALUATION WITH ONTOLOGY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. DESIGN OF ONTOLOGY", "text": "The domain Ontology of Computer Graphics is prepared using the subject predicate object representation. The following components of ontology are defined: 1) Classes: Sentences, collections, concepts and object types. For example, the main class is Computer _ Graphics. Then Computer _ Graphics has computer graphics applications, Computer _ Graphics _ Systems, types _ of _ media, etc. Then the further classification of each as in Figure-1. 2) Individuals: The classes have instances or objects as in Firgure-2. For example, the image processing class has individuals such as color coding, improvement _ image quality, improvement _ shading, machine _ perception and rearrangement _ image parts. The instances then have additional properties. 3) Attributes: The classes and individuals have properties as in Figure-3. Some of the attributes identified are: isDefinedBy, use, technique, purpose, standard, creation _ image parts."}, {"heading": "4.2. USAGE OF ONTOLOGY", "text": "When the students \"answers to the question are to be evaluated, the details of the concept are extracted from ontology. The level of detail depends on the type of question, as in Table-2. If short questions are to be answered, then the directly related information is extracted. If longer questions are to be answered, more details are extracted. After the information is extracted from ontology, a multi-hash map is created by collecting all words that correspond to the same concept. This multi-hash map is then used for evaluation. In addition to retrieving the concept information from ontology, the relationship or similarity between the concepts is also retrieved. If the concepts have a path between each other, the length of such a path is calculated. Combining the ontology with the techniques mentioned in Section 3 is done using the design shown in Figure 5. After pre-processing of the words, the model response and the students\" answers decide as input. Ontology is extracted for the concept that is used on the basis of this question as an answer between the different models and the ontology."}, {"heading": "4.3. MODIFICATION TO EXISTING TECHNIQUES", "text": "The following steps are performed for each technique discussed in Section-3: The technique takes as input a multi-hash map of ontology concepts, the distance between concepts, the model response and the students \"responses. First, the sentences in the model response are bundled using ontology concepts and merged with the ontology map using the eligible machine learning technique. Then, the updated multi-hash map is used to find a correlation between each concept and the students\" response using the same machine learning technique. The total number of concepts with positive correlation to the students \"responses (q) is multiplied by the distance between the main concept and the current concept. Then, this value is divided by the total number of concepts in multi-hash card to generate a definitive scale. Along with the techniques mentioned in the above section, another technique is applied with the ontology, the word-weight of the word response is then divided by the weight of the word in each word."}, {"heading": "5. IMPLEMENTATION", "text": "The LSA technique is implemented in the Java programming language and in MatLab. Searching for synonyms is done with WordNet [25]; [26]. The GLSA implementation is done by adding n-grams to the LSA package. All programming and extension tools used are the same as in LSA. BLEU is implemented in the Java programming language. The Java-based Maximum Entropy package is freely available at http: / / maxent.sourceforge.net. The characteristics and functionality of this package are understood and it is used for evaluation. The wordweight technique is implemented in Java. Details of the tools and techniques for implementation are in Table 3. Subject Specific Ontology has been implemented for a field of computer science - Computer Graphics. The RDF format used for ontology and the Onqache tool are used in ontology to integrate the ontology."}, {"heading": "6. TESTING AND RESULTS", "text": "There is no standard database for the evaluation of subjective answers. Therefore, the database was created over a period of time by conducting class tests. All techniques (as implemented above) for the evaluation of answers were tested using this common database. The database consists of ten different questions with approximately sixty answers for each question in the field of computer graphics. Grades are generated for each student's answer using the techniques with and without ontology. Table 4 contains the correlations between humanly assigned scores and machine-generated scores using each technique."}, {"heading": "7. ANALYSIS OF RESULTS", "text": "This section analyzes the results of each technique. Table-4 clearly shows that BLEU and LSA provide consistent performance with and without ontology. With ontology, maximum entropy shows a lot of improvements. LSA and GLSA both overrate when keywords or phrases are repeated many times. BLEU technology is a medium-term technique and cannot capture the relationship between words. MaxEnt cannot identify the divergent essays. BLEU identifies contradictory essays. Comparing NGRAM-1,2,3 with LSA, since they represent theoretical improvements over LSA, does not yield better results than LSA. In fact, they provide minimal performance. Using n-gram size 1,2,3 yields almost the same results. Thus, increasing the size of n-gram does not give better performance. With the use of ontology, all techniques are OBLEU, OLSA, ONG < 1, 2, 3 > and OMAX as good as original techniques."}, {"heading": "8. CONCLUSION AND SCOPE FOR FUTURE WORK", "text": "The techniques discussed and implemented in this essay show a high correlation (up to 90 percent) with human performance. This is due to the fact that human evaluation is largely influenced by the length of the response. The use of ontology verifies the presence of keywords, synonyms, the correct word context and the coverage of all concepts. It is concluded that the use of ML techniques with ontology delivers satisfactory results on the basis of a holistic evaluation. This work can be improved by the use of expanded ontology, which includes the presence of keywords, synonyms, the correct word context and the coverage of all concepts. \"One comes to the conclusion that the use of ML techniques with ontology delivers satisfactory results on the basis of holistic evaluation. This work can be carried out by the use of expanded ontology including the concepts OOOOOOOOOOOOOOOOOOOOOOOOOOOEUEUEUEUEUEUOBLUL BLUL, and the use of advanced ontology."}, {"heading": "9. REFERENCES", "text": "[1] B. Rujiang and L. Junhua, \"Improving the Classification of Documents with Semantic Characteristics,\" 2nd Int. Symp. 41 April. Electron. Commer. Secur. ISECS 2009, vol. 1, pp. 640-643, 2009. [2] P. D. Turney and P. Pantel. \"From Frequency to Meaning: Vector Space Models of Semantics.\" J.Artif. p. 10, pp. 295-308, 2003. [4] T. K. Landauer, P. W. Foltz and D. Laham. \"An Introduction to Latent Semantic Analysis.\" DiscourseProcess., vol. 25, no. 2, pp. 259-284, 1998."}], "references": [{"title": "Improving documents classification with semantic features", "author": ["B. Rujiang", "L. Junhua"], "venue": "2nd Int. Symp. Electron. Commer. Secur. ISECS 2009, vol. 1, pp. 640\u2013643, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["P.D. Turney", "P. Pantel"], "venue": "J. Artif. Intell. Res., vol. 37, pp. 141\u2013188, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Automatic Essay Assessment", "author": ["T.K. Landauer"], "venue": "Assess. Educ. Princ. Policy Pract., vol. 10, no. 3, pp. 295\u2013308, 2003.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "An introduction to latent semantic analysis", "author": ["T.K. Landauer", "P.W. Foltz", "D. Laham"], "venue": "Discourse Process., vol. 25, no. 2\u20133, pp. 259\u2013284, 1998.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "An introduction to latent semantic analysis", "author": ["T.K. Landauer", "P.W. Foltz"], "venue": "Discourse Process., no. April 2012, pp. 37\u201341, 2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "The measurement of textual coherence with latent semantic analysis", "author": ["P.W. Foltz", "W. Kintsch", "T.K. Landauer"], "venue": "Discourse Process., vol. 25, no. 2\u20133, pp. 285\u2013307, 1998.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "Latent Semantic Analysis for Text-Based", "author": ["P.W. Foltz"], "venue": "Behav. Res. Methods, Instruments Comput., vol. 28, no. 2, pp. 197\u2013202, 1996.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1996}, {"title": "Comparison of dimension reduction methods for automated essay grading", "author": ["T. Kakkonen", "N. Myller", "E. Sutinen", "J. Timonen"], "venue": "Educ. Technol. Soc., vol. 11, no. 3, pp. 275\u2013288, 2008.  International Journal on Natural Language Computing (IJNLC) Vol. 5, No.2, April 2016 11", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Latent Dirichlet Allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res., vol. 3, no. 4\u20135, pp. 993\u20131022, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic latent semantic indexing", "author": ["T. Hofmann"], "venue": "Sigir, pp. 50\u201357, 1999.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Automated Essay Scoring Using Generalized", "author": ["M. Islam"], "venue": "Proceesings of 13th International Conference on Computer and Information Technology (ICCIT 2010), 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Automated essay scoring using Bayes\u2019 theorem", "author": ["L. Rudner", "T. Liang"], "venue": "J. Technol. Learn. ..., vol. 1, no. 2, 2002.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Automated essay scoring using the KNN algorithm", "author": ["L. Bin", "L. Jun", "Y. Jian-Min", "Z. Qiao-Ming"], "venue": "Proc. - Int. Conf. Comput. Sci. Softw. Eng. CSSE 2008, vol. 1, pp. 735\u2013738, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "C-rater: Automated scoring of short-answer questions", "author": ["C. Leacock", "M. Chodorow"], "venue": "Comput. Hum., vol. 37, no. 4, pp. 389\u2013405, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Using a MaxEnt classifier for the automatic content scoring of free-text responses", "author": ["J.Z. Sukkarieh"], "venue": "AIP Conf. Proc., vol. 1305, pp. 41\u201348, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Automating Model Building in c-rater", "author": ["J. Sukkarieh", "S. Stoyanchev"], "venue": "Proc. 2009 Work. ..., no. August, pp. 61\u201369, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Automated scoring using a hybrid feature identification technique", "author": ["J. Burstein", "K. Kukich", "S. Wolff", "C. Lu", "M. Chodorow", "L. Braden-Harder", "M.D. Harris"], "venue": "Proc. 17th Int. Conf. Comput. Linguist. -, vol. 1, p. 206, 1998.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Bridging gaps in computerised assessment of texts", "author": ["D. Callear", "J. Jerrams-Smith", "V. Soh"], "venue": "Proc. - IEEE Int. Conf. Adv. Learn. Technol. ICALT 2001, pp. 139\u2013140, 2001.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2001}, {"title": "Automatic Assessment of Students \u2019 free-text Answers underpinned by the Combination of a B LEU -inspired algorithm and Latent Semantic Analysis", "author": ["P. Diana", "A. Gliozzo", "C. Strapparava", "E. Alfonseca", "P. Rodr", "B. Magnini"], "venue": "Mach. Transl., 2005.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "The automatic assessment of free text answers using a modified BLEU algorithm", "author": ["F. Noorbehbahani", "a. a. Kardan"], "venue": "Comput. Educ., vol. 56, no. 2, pp. 337\u2013345, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Text categorization based on combination of modified back propagation neural network and latent semantic analysis", "author": ["W. Wang", "B. Yu"], "venue": "Neural Comput. Appl., vol. 18, no. 8, pp. 875\u2013881, 2009.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Analysis of a Vector Space Model , Latent Semantic Indexing and Formal Concept Analysis for Information Retrieval", "author": ["C.A. Kumar", "M. Radvansky", "J. Annapurna"], "venue": "vol. 12, no. 1, pp. 34\u2013 48, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Indexing by Latent Semantic Analysis", "author": ["S. Deerwester", "S.T. Dumais", "G.W. Furnas", "T.K. Landauer", "R. Harshman"], "venue": "Journal of the American Society for Information Science,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1990}, {"title": "WordNet: a lexical database for English,", "author": ["A. G"], "venue": "Commun. ACM,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1995}, {"title": "Java Libraries for Accessing the Princeton Wordnet: Comparison and Evaluation.,", "author": ["M.A. Finlayson"], "venue": "Proc. 7th Int. Glob. WordNet Conf.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}], "referenceMentions": [{"referenceID": 22, "context": "Latent Semantic Analysis (LSA) technique, proposed by Deerwester [23], is used to establish similarity between two contents.", "startOffset": 65, "endOffset": 69}, {"referenceID": 2, "context": "Intelligent Essay Assessor (IEA) tool uses LSA [3-7] for subjective evaluation of English essays.", "startOffset": 47, "endOffset": 52}, {"referenceID": 3, "context": "Intelligent Essay Assessor (IEA) tool uses LSA [3-7] for subjective evaluation of English essays.", "startOffset": 47, "endOffset": 52}, {"referenceID": 4, "context": "Intelligent Essay Assessor (IEA) tool uses LSA [3-7] for subjective evaluation of English essays.", "startOffset": 47, "endOffset": 52}, {"referenceID": 5, "context": "Intelligent Essay Assessor (IEA) tool uses LSA [3-7] for subjective evaluation of English essays.", "startOffset": 47, "endOffset": 52}, {"referenceID": 6, "context": "Intelligent Essay Assessor (IEA) tool uses LSA [3-7] for subjective evaluation of English essays.", "startOffset": 47, "endOffset": 52}, {"referenceID": 18, "context": "Diana Perez [19-20] developed a tool-Atenea, using hybrid of LSA and BiLingual Evaluation Understudy (BLEU).", "startOffset": 12, "endOffset": 19}, {"referenceID": 19, "context": "Diana Perez [19-20] developed a tool-Atenea, using hybrid of LSA and BiLingual Evaluation Understudy (BLEU).", "startOffset": 12, "endOffset": 19}, {"referenceID": 16, "context": "Electronic Essay Rater (E-Rater) [17] uses Natural Language Processing techniques to evaluate sentence structure.", "startOffset": 33, "endOffset": 37}, {"referenceID": 10, "context": "Generalized Latent Semantic Analysis (GLSA) [11] extends LSA.", "startOffset": 44, "endOffset": 48}, {"referenceID": 13, "context": "C-rater [14-16] uses Maximum Entropy technique (MaxEnt).", "startOffset": 8, "endOffset": 15}, {"referenceID": 14, "context": "C-rater [14-16] uses Maximum Entropy technique (MaxEnt).", "startOffset": 8, "endOffset": 15}, {"referenceID": 15, "context": "C-rater [14-16] uses Maximum Entropy technique (MaxEnt).", "startOffset": 8, "endOffset": 15}, {"referenceID": 0, "context": "The application of Ontology to document classification is discussed in [1].", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "Turney [2] discusses three approaches to document", "startOffset": 7, "endOffset": 10}, {"referenceID": 8, "context": "3 representation in natural language processing- term document vector (tdv), word context vector (wcv) as used in [9] and pair pattern vector (ppv).", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "2003 Landauer Inteliigent Essay Assessor Latent Semantic Processing 59-88% [3],[4]\u2013[7]", "startOffset": 75, "endOffset": 78}, {"referenceID": 3, "context": "2003 Landauer Inteliigent Essay Assessor Latent Semantic Processing 59-88% [3],[4]\u2013[7]", "startOffset": 79, "endOffset": 82}, {"referenceID": 6, "context": "2003 Landauer Inteliigent Essay Assessor Latent Semantic Processing 59-88% [3],[4]\u2013[7]", "startOffset": 83, "endOffset": 86}, {"referenceID": 7, "context": "2008 Kakkonen Automatic essay Assessor LSA, Probabilistic LSA, Latent Dirichlet Allocation LSA better than rest [8],[9], [10]", "startOffset": 112, "endOffset": 115}, {"referenceID": 8, "context": "2008 Kakkonen Automatic essay Assessor LSA, Probabilistic LSA, Latent Dirichlet Allocation LSA better than rest [8],[9], [10]", "startOffset": 116, "endOffset": 119}, {"referenceID": 9, "context": "2008 Kakkonen Automatic essay Assessor LSA, Probabilistic LSA, Latent Dirichlet Allocation LSA better than rest [8],[9], [10]", "startOffset": 121, "endOffset": 125}, {"referenceID": 10, "context": "2010 Islam Generalized Latent Semantic Analysis 86-96% [11]", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "2002 Rudner Betsy Bays Theorem 80% [12]", "startOffset": 35, "endOffset": 39}, {"referenceID": 12, "context": "2008 Li bin K-Nearest Neighbor 76% [13]", "startOffset": 35, "endOffset": 39}, {"referenceID": 13, "context": "2012 Sukkarieh C-rater Maximum Entropy 80% [14]\u2013[16]", "startOffset": 43, "endOffset": 47}, {"referenceID": 15, "context": "2012 Sukkarieh C-rater Maximum Entropy 80% [14]\u2013[16]", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "1998 Burstein E-rater Hybrid of features 84-94% [17]", "startOffset": 48, "endOffset": 52}, {"referenceID": 17, "context": "2001 Callear Automated Text Marker Conceptual Dependency None [18]", "startOffset": 62, "endOffset": 66}, {"referenceID": 18, "context": "2005 Perez Atenea BiLingual Evaluation Understudy, LSA 50% [19], [20]", "startOffset": 59, "endOffset": 63}, {"referenceID": 19, "context": "2005 Perez Atenea BiLingual Evaluation Understudy, LSA 50% [19], [20]", "startOffset": 65, "endOffset": 69}, {"referenceID": 20, "context": "[21]", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "20082012 Ontology Based Methods Applied to Information Retrieval Only [1][2][22]", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "20082012 Ontology Based Methods Applied to Information Retrieval Only [1][2][22]", "startOffset": 73, "endOffset": 76}, {"referenceID": 21, "context": "20082012 Ontology Based Methods Applied to Information Retrieval Only [1][2][22]", "startOffset": 76, "endOffset": 80}, {"referenceID": 0, "context": "The output is a similarity measure in the range of [0, 1], where a value of 0 indicates no similarity and 1 indicates high similarity.", "startOffset": 51, "endOffset": 57}, {"referenceID": 23, "context": "Synonym Search is done using WordNet [25];[26].", "startOffset": 37, "endOffset": 41}, {"referenceID": 24, "context": "Synonym Search is done using WordNet [25];[26].", "startOffset": 42, "endOffset": 46}], "year": 2016, "abstractText": "Computerized Evaluation of English Essays is performed using Machine learning techniques like Latent Semantic Analysis (LSA), Generalized LSA, Bilingual Evaluation Understudy and Maximum Entropy. Ontology, a concept map of domain knowledge, can enhance the performance of these techniques. Use of Ontology makes the evaluation process holistic as presence of keywords, synonyms, the right word combination and coverage of concepts can be checked. In this paper, the above mentioned techniques are implemented both with and without Ontology and tested on common input data consisting of technical answers of Computer Science. Domain Ontology of Computer Graphics is designed and developed. The software used for implementation includes Java Programming Language and tools such as MATLAB, Prot\u00e9g\u00e9, etc. Ten questions from Computer Graphics with sixty answers for each question are used for testing. The results are analyzed and it is concluded that the results are more accurate with use of Ontology.", "creator": "PScript5.dll Version 5.2.2"}}}