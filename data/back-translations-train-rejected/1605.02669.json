{"id": "1605.02669", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2016", "title": "The GPU-based Parallel Ant Colony System", "abstract": "The Ant Colony System (ACS) is, next to Ant Colony Optimization (ACO) and the MAX-MIN Ant System (MMAS), one of the most efficient metaheuristic algorithms inspired by the behavior of ants. In this article we present three novel parallel versions of the ACS for the graphics processing units (GPUs). To the best of our knowledge, this is the first such work on the ACS which shares many key elements of the ACO and the MMAS, but differences in the process of building solutions and updating the pheromone trails make obtaining an efficient parallel version for the GPUs a difficult task. The proposed parallel versions of the ACS differ mainly in their implementations of the pheromone memory. The first two use the standard pheromone matrix, and the third uses a novel selective pheromone memory. Computational experiments conducted on several Travelling Salesman Problem (TSP) instances of sizes ranging from 198 to 2392 cities showed that the parallel ACS on Nvidia Kepler GK104 GPU (1536 CUDA cores) is able to obtain a speedup up to 24.29x vs the sequential ACS running on a single core of Intel Xeon E5-2670 CPU. The parallel ACS with the selective pheromone memory achieved speedups up to 16.85x, but in most cases the obtained solutions were of significantly better quality than for the sequential ACS.", "histories": [["v1", "Mon, 9 May 2016 17:41:37 GMT  (391kb,D)", "http://arxiv.org/abs/1605.02669v1", null], ["v2", "Fri, 5 May 2017 10:43:58 GMT  (391kb,D)", "http://arxiv.org/abs/1605.02669v2", null]], "reviews": [], "SUBJECTS": "cs.DC cs.AI", "authors": ["rafa{\\l} skinderowicz"], "accepted": false, "id": "1605.02669"}, "pdf": {"name": "1605.02669.pdf", "metadata": {"source": "CRF", "title": "The GPU-based Parallel Ant Colony System", "authors": ["Rafa\u0142 Skinderowicza"], "emails": [], "sections": [{"heading": null, "text": "The Ant Colony System (ACS), along with Ant Colony Optimization (ACO) and the MAX-MIN Ant System (MMAS), is one of the most efficient metaheuristic algorithms inspired by the behavior of ants. In this article, we present three novel parallel versions of ACS for graphics processor units (GPUs). To our knowledge, this is the first such work on ACS that has many key elements in common with ACO and MMAS, but differences in the process of building solutions and updating pheromone tracks make obtaining an efficient parallel version for the GPUs a difficult task. The proposed parallel versions of ACS differ mainly in their implementations of pheromone memory. The first two use the standard pheromone matrix, and the third uses a novel selective pheromone memory. Computational experiments that differ on several issues, mainly in their TSP implementions."}, {"heading": "1. Introduction", "text": "The possibility of using e-cigarettes (GPU) for general experiments (GPU) has been increasingly pushed to the fore in recent years."}, {"heading": "2. Related work", "text": "In fact, most of them are able to survive on their own, and that they are able to survive on their own by going in search of their own identity. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...)"}, {"heading": "2.1. Characteristics of GPU computing", "text": "The use of GPUs for general purposes requires consideration of the significant differences between the GPU and the CPU architectures [19], which are designed to achieve fast processing of a single instruction stream (or more in the case of multi-core chips), and are equipped with multi-level cachemories up to a few megabytes per core, all designed to hide global memory latencies and maximize the use of available computing power."}, {"heading": "3. Ant Colony System", "text": "It is NP-hard, but has a relatively simple definition that allows one to focus on the proposed algorithms, but the conclusions drawn should be useful in the context of other problems that can be solved by the ACS. In the TSP, the salesman has to visit each city from a given set exactly once and return to the starting city, taking into account that the journey between any cities is associated with a predetermined cost factor. The solution to the problem is a route with the minimum total cost. TSP can be achieved by using a full graph G = (V, A), where V = {1, n}."}, {"heading": "12 end", "text": "The complexity of the algorithm corresponds to O (# Iterations \u00b7 # Ants \u00b7 # Nodes 2), since the number of iterations required to select the next node (line 8) is in the order of O (# Nodes). It is often assumed that # ants = O (# Nodes), that is, the complexity of the algorithm O (# Iterations \u00b7 # Nodes3). The pseudo-code for the procedure of the next node selection according to formulas (1) and (2) is represented in Fig. 3. First, a node is selected from the candidate set containing the closest neighbors (lines 5-9) of the current node. Depending on the value of parameter q0, the selection is made in a deterministic manner (line 13) or randomly with the probability defined by formula (2). If all nodes in the candidate set are already part of the solution, the next node (line 18) is selected from the remaining line."}, {"heading": "3.1. Parallel ACS for the GPU", "text": "In designing the algorithms presented in this paper, we were guided by the conclusions and comments presented in the literature on the parallel ACO and the MMAS for the GPU. However, efficient implementation of the ACS for the GPU requires taking into account the significant differences between the ACO and the MMAS. Based on the results and conclusions presented in [5, 8, 10], among others, we applied a model of parallelization in which each ant corresponds to a single thread block. Stream processors (cores) in modern GPUs are grouped into so-called warps that operate in SIMT mode (single statement, multiple threads) [34], which means that all threads in the chain block execute the same statement at the same time. In the case of Nvidia GPUs, the chain size is typically 32. Any divergence (branch) in the control flow between threads in a given chain statement should not be a chain statement."}, {"heading": "3.1.1. Pseudo-random proportional rule", "text": "rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu the rfu"}, {"heading": "3.1.2. Pheromone update", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able, in which they are able to integrate themselves, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "3.2. Selective pheromone memory", "text": "In fact, the fact is that most of them will be able to move to another world, in which they will be able to move to another world, in which they will be able to integrate, in which they will be able to move, in which they will be able to find themselves."}, {"heading": "4. Experiments", "text": "The experiments consist of several parts: we started with a focus on parallel ACS implementation by using the standard pheromone matrix for the GPU, then a performance-oriented study of the parameter values, and ended with a focus on parallel ACS with selective pheromone memory."}, {"heading": "4.1. Parallel vs sequential ACS", "text": "The first part of the experiments was focused on the performance of the ACS algorithm on the GPU. Three versions of the ACS algorithm were considered; the first, labeled ACS-SEQ, was the reference sequential implementation of the ACS in the C language by Thomas St\u00fctzle [27]; the second version was the aforementioned ACS-GPU, which represents a parallel version of the ACS for the GPU; it is a version in which the process of solution construction by ants comes closest to the sequential version of the ACS; the third version, ACS-GPU-Alt, is an alternative implementation of the ACS for the GPU, in which the main emphasis is placed on performance. In this version, the complete solution will be performed in a single kernel execution and pheromone memory updates without the use of atomic instructions, such as CAS.The algorithms were implemented in version + UDA (6.5)."}, {"heading": "4.2. Limiting the number of local pheromone updates", "text": "To better investigate the effects of the observed phenomena, the ACS GPU Alt was performed with a limited number of local pheromone updates. Specifically, the local pheromone update was performed for each k-edge selected by an ant. However, the following values of k were used: 1, 2, 8, and 16. Table 4 shows the mean times of solution construction depending on the period of local pheromone updates. The relative acceleration of values is also shown, the shorter the updates, the higher the acceleration of solutions. This confirms previous observations that the time spent performing local pheromone updates has a significant effect on algorithm runtime; for example, k = 16 and instance pcb442, a speedup of 21.9, the acceleration of 4x."}, {"heading": "4.3. Manipulating the number of ants", "text": "An interesting problem is that the number of ants m in both runtime and quality of parallel ACS for the GPU. To measure this effect, the number of ants m and the total number of solutions to be built must be set and measured. It is worth noting that the ant forms a complete solution to the problem, i.e. the number of ants m and the total number of mentioned solutions is b, then the number of algorithm iterations is."}, {"heading": "4.4. Parallel ACS with a selective pheromone memory", "text": "This year, it has reached the point where there is only one person who is able to establish himself in the region."}, {"heading": "5. Summary", "text": "In fact, it is in such a way that one will be able to enter another world, in which one can enter another world, in which one is able to discover another world, in which one is able to explore another world, in which one is able to explore another world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create another world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create a new world, in which one is able to create a new world, a new world, a new world, in which one is able to create a new world, a new world, a new world, a new world, a new world, a new, a new world, a new, a new world, a new, a new world, a new, a new world, a new, a new, a new world, a new, a new, a new world, a new, a new, a new world, a new, a new, a new world, a new, a new, a new, a new world, a new, a new, a new, a new world, a new, a new, a new, a new world, a new, a new, a new, a new, a new world, a new, a new, a new, a new world, a new, a new, a new, a new world, a new, a new, a new, a new, a new world, a new, a new, a new, a new, a new world, a new, a new, a new, a new, a new, a new world, a new, a new, a new, a new, a new, a new, a new world, a new, a new, a new, a new, a new, a new, a new world, a new, a new, a new, a new, a new, a new, a new world, a new, a new, a new, a new, a new, a world, a new, a new, a new, a new, a new"}, {"heading": "5.1. Further research", "text": "As part of further research, the algorithm should be tested by using a newer generation of GPUs running simultaneously on multiple GPUs. Perhaps running simultaneous cores can be used to speed up computation for multiple ants and multiple colonies. [3] It would also be interesting to see how convergence of the algorithm changes when using a local search, such as 3-opt, as illustrated in [10]. Marco Marco has partially supported this research by PL-Grid Infrastructure. [1] NVIDIA: CUDA C Programming Guide. http: / docs.nvidia.com / cuda-c-programming-guide /. Access: 2014-06-18. [2] Hongtao Bai, Dantong OuYang, Ximing Li, Lili He, and Haihong Andy Yu."}], "references": [{"title": "Max-min ant system on gpu with cuda", "author": ["Hongtao Bai", "Dantong OuYang", "Ximing Li", "Lili He", "Haihong Yu"], "venue": "In Innovative Computing, Information and Control (ICICIC),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "High performance evaluation of evolutionary-mined association rules on gpus", "author": ["Alberto Cano", "Jos\u00e9 Mar\u00eda Luna", "Sebasti\u00e1n Ventura"], "venue": "The Journal of Supercomputing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Parallel multi-objective ant programming for classification using GPUs", "author": ["Alberto Cano", "Juan Luis Olmo", "Sebasti\u00e1n Ventura"], "venue": "J. Parallel Distrib. Comput.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Enhancing data parallelism for ant colony optimization on gpus", "author": ["Jos\u00e9 M. Cecilia", "Jos\u00e9 M. Garc\u00eda", "Andy Nisbet", "Martyn Amos", "Manuel Ujaldon"], "venue": "J. Parallel Distrib. Comput.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "A uav path planning with parallel aco algorithm on cuda platform", "author": ["U. Cekmez", "M. Ozsiginan", "O.K. Sahingoz"], "venue": "In Unmanned Aircraft Systems (ICUAS),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "A parallel ant colony algorithm on massively parallel processors and its convergence analysis for the travelling salesman problem", "author": ["Ling Chen", "Hai-Ying Sun", "Shu Wang"], "venue": "Inf. Sci.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Candidate set parallelization strategies for ant colony optimization on the GPU", "author": ["Laurence Dawson", "Iain A. Stewart"], "venue": "Algorithms and Architectures for Parallel Processing - 13th International Conference,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Improving ant colony optimization performance on the GPU using CUDA", "author": ["Laurence Dawson", "Iain A. Stewart"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Parallel ant colony optimization on graphics processing units", "author": ["Audrey Delevacq", "Pierre Delisle", "Marc Gravel", "Micha\u00ebl Krajecki"], "venue": "J. Parallel Distrib. Comput.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Ant colony system: a cooperative learning approach to the traveling salesman problem", "author": ["Marco Dorigo", "Luca Maria Gambardella"], "venue": "IEEE Trans. Evolutionary Computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Ant system: optimization by a colony of cooperating agents", "author": ["Marco Dorigo", "Vittorio Maniezzo", "Alberto Colorni"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Ant colony optimization", "author": ["Marco Dorigo", "Thomas St\u00fctzle"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "GPU accelerated nature inspired methods for modelling large scale bi-directional pedestrian movement", "author": ["Sankha Baran Dutta", "Robert D. McLeod", "Marcia R. Friesen"], "venue": "In 2014 IEEE International Parallel & Distributed Processing Symposium Workshops,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "A CUDA based solution to the multidimensional knapsack problem using the ant colony optimization", "author": ["Henrique Fingler", "Edson Norberto C\u00e1ceres", "Henrique Mongelli", "Siang W. Song"], "venue": "Proceedings of the International Conference on Computational Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "A population based approach for ACO", "author": ["Michael Guntsch", "Martin Middendorf"], "venue": "editors, Applications of Evolutionary Computing, EvoWorkshops 2002: EvoCOP,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Exploiting memory access patterns to improve memory performance in data-parallel architectures", "author": ["Byunghyun Jang", "Dana Schaa", "Perhaad Mistry", "David R. Kaeli"], "venue": "IEEE Trans. Parallel Distrib. Syst.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Nature-inspired meta-heuristics on modern gpus: State of the art and brief survey of selected algorithms", "author": ["Pavel Kr\u00f6mer", "Jan Platos", "V\u00e1clav Sn\u00e1sel"], "venue": "International Journal of Parallel Programming,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Debunking the 100x GPU vs. CPU myth: an evaluation of throughput computing on CPU and GPU", "author": ["Victor W. Lee", "Changkyu Kim", "Jatin Chhugani", "Michael Deisher", "Daehyun Kim", "Anthony D. Nguyen", "Nadathur Satish", "Mikhail Smelyanskiy", "Srinivas Chennupaty", "Per Hammarlund", "Ronak Singhal", "Pradeep Dubey"], "venue": "37th International Symposium on Computer Architecture (ISCA", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "A survey on parallel ant colony optimization", "author": ["Mart\u00edn Pedemonte", "Sergio Nesmachnow", "H\u00e9ctor Cancela"], "venue": "Appl. Soft Comput.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Candidate set strategies for ant colony optimisation", "author": ["Marcus Randall", "James Montgomery"], "venue": "Ant Algorithms, Third International Workshop,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2002}, {"title": "Gpu computing in discrete optimization. part ii: Survey focused on routing problems", "author": ["Christian Schulz", "Geir Hasle", "Andr\u00e9 R Brodtkorb", "Trond R Hagen"], "venue": "EURO Journal on Transportation and Logistics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Ant colony system with selective pheromone memory for TSP", "author": ["Rafa\u0142 Skinderowicz"], "venue": "Computational Collective Intelligence. Technologies and Applications - 4th International Conference,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Ant colony system with selective pheromone memory for SOP", "author": ["Rafa\u0142 Skinderowicz"], "venue": "Computational Collective Intelligence. Technologies and Applications - 5th International Conference,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "A survey on gpu-based implementation of swarm intelligence", "author": ["Y. Tan", "K. Ding"], "venue": "IEEE Transactions on,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Ant colony optimization - public software. http://iridia.ulb.ac.be/~mdorigo/ACO/aco-code/ public-software.html", "author": ["St\u00fctzle Thomas"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "cook. the traveling salesman problem: A computational study, princeton university", "author": ["robert e. bixby", "vasek chv\u00e1tal", "william j"], "venue": "press, princeton,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "An analysis of communication policies for homogeneous multi-colony ACO algorithms", "author": ["Colin Twomey", "Thomas St\u00fctzle", "Marco Dorigo", "Max Manfrin", "Mauro Birattari"], "venue": "Inf. Sci.,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "An efficient GPU implementation of ant colony optimization for the traveling salesman problem", "author": ["Akihiro Uchida", "Yasuaki Ito", "Koji Nakano"], "venue": "In ICNC,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Accelerating ant colony optimisation for the travelling salesman problem on the gpu", "author": ["Akihiro Uchida", "Yasuaki Ito", "Koji Nakano"], "venue": "International Journal of Parallel, Emergent and Distributed Systems,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Using CUDA GPU to accelerate the ant colony optimization algorithm", "author": ["Kai-Cheng Wei", "Chao-Chin Wu", "Chien-Ju Wu"], "venue": "International Conference on Parallel and Distributed Computing, Applications and Technologies,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "GPU-Accelerated Ant Colony Optimization", "author": ["Robin M. Weiss"], "venue": "GPU Computing Gems Emerald Edition, Applications of GPU Computing Series,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "The cuda handbook: A comprehensive guide to gpu programming", "author": ["Nicholas Wilt"], "venue": "Pearson Education,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2013}, {"title": "An efficient implementation of ant colony optimization on GPU for the satisfiability problem", "author": ["Hassan A. Youness", "Aziza Ibraheim", "Mohammed Moness", "Muhammad Osama"], "venue": "23rd Euromicro International Conference on Parallel,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}], "referenceMentions": [{"referenceID": 31, "context": "GPUs offer attractive performance to energy consumption and the cost of purchase ratio, and allow to perform many types of computations more quickly while maintaining the same cost in relation to the CPUs [34].", "startOffset": 205, "endOffset": 209}, {"referenceID": 17, "context": "At the same time, the number of high latency operations should be minimized, particularly involving global memory access [19].", "startOffset": 121, "endOffset": 125}, {"referenceID": 11, "context": "Good examples of efficient metaheuristic algorithms are algorithms inspired by the foraging behavior of ants, including the Ant Colony Algorithm (ACO), the Ant Colony System (ACS) and the MAX-MIN Ant System (MMAS) [13].", "startOffset": 214, "endOffset": 218}, {"referenceID": 18, "context": "Similarly to other metaheuristic algorithms, ant colony algorithms are computationally demanding, therefore much research effort was put into developing efficient parallel versions for multi-processor computers [20].", "startOffset": 211, "endOffset": 215}, {"referenceID": 8, "context": "To the best of our knowledge, this is the first such work, although GPU versions of some ant colony algorithms, including the ACO and the MMAS, were proposed in the literature [10, 20].", "startOffset": 176, "endOffset": 184}, {"referenceID": 18, "context": "To the best of our knowledge, this is the first such work, although GPU versions of some ant colony algorithms, including the ACO and the MMAS, were proposed in the literature [10, 20].", "startOffset": 176, "endOffset": 184}, {"referenceID": 21, "context": "We also present a third parallel version of the ACS which includes a new version of the selective pheromone memory as inspired by an earlier work [23, 24].", "startOffset": 146, "endOffset": 154}, {"referenceID": 22, "context": "We also present a third parallel version of the ACS which includes a new version of the selective pheromone memory as inspired by an earlier work [23, 24].", "startOffset": 146, "endOffset": 154}, {"referenceID": 18, "context": "An extensive overview of the different approaches to parallelization of ant algorithms can be found in [20].", "startOffset": 103, "endOffset": 107}, {"referenceID": 18, "context": "Most of the parallel ACO versions dedicated to the CPU apply the multi-colony approach [20].", "startOffset": 87, "endOffset": 91}, {"referenceID": 26, "context": "In [29], a comparison can be found of the various communication topologies (policies) on the convergence of the MMAS algorithm solving the TSP.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "[7], in which proof of the convergence (at infinity) of the parallel ACO is given.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] proposed an efficient parallel (GPU) version of the ACO for the TSP in which an efficient parallelization scheme (data-parallel) was applied of the solution construction process.", "startOffset": 0, "endOffset": 3}, {"referenceID": 28, "context": "[31] proposed a GPU version of the Ant System (AS) for the TSP.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] studied a parallel implementation of the MMAS for the TSP on the GPU.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "In [32], based on the algorithm presented by Cecilia et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "[5], Wei et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 32, "context": "[35], the parallel MMAS for the Satisfiability Problem (SAT) was presented.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "The parallel ACO for the GPU to accelerate bi-directional pedestrian movement simulation was described in [14].", "startOffset": 106, "endOffset": 110}, {"referenceID": 2, "context": "[4] presented Parallel multi-objective Ant Programming for the classification algorithm using GPUs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "Not without significance is the fact that the authors implemented the algorithm in Java rather than in C, which suggests that the sequential version could be sped up, thus resulting in smaller relative speedup values [19].", "startOffset": 217, "endOffset": 221}, {"referenceID": 30, "context": "The classification task was also addressed in [33], in which a parallel version of the AntMiner algorithm for the GPU was about 100x faster than the sequential version.", "startOffset": 46, "endOffset": 50}, {"referenceID": 13, "context": "[15] used the GPU to accelerate calculations of the ACO for the knapsack problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[2] to speedup the MMAS using the GPUs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6] to solve the path planning problem of an Unmanned Aerial Vehicle (UAV).", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "A survey of recent advances in applying the GPUs to speedup other metaheuristic algorithms can be found in [18, 22, 26].", "startOffset": 107, "endOffset": 119}, {"referenceID": 20, "context": "A survey of recent advances in applying the GPUs to speedup other metaheuristic algorithms can be found in [18, 22, 26].", "startOffset": 107, "endOffset": 119}, {"referenceID": 23, "context": "A survey of recent advances in applying the GPUs to speedup other metaheuristic algorithms can be found in [18, 22, 26].", "startOffset": 107, "endOffset": 119}, {"referenceID": 6, "context": "In this paper we present an approach based on the solutions proposed in [8, 9, 10, 30], which use a single colony with a single pheromone memory matrix.", "startOffset": 72, "endOffset": 86}, {"referenceID": 7, "context": "In this paper we present an approach based on the solutions proposed in [8, 9, 10, 30], which use a single colony with a single pheromone memory matrix.", "startOffset": 72, "endOffset": 86}, {"referenceID": 8, "context": "In this paper we present an approach based on the solutions proposed in [8, 9, 10, 30], which use a single colony with a single pheromone memory matrix.", "startOffset": 72, "endOffset": 86}, {"referenceID": 27, "context": "In this paper we present an approach based on the solutions proposed in [8, 9, 10, 30], which use a single colony with a single pheromone memory matrix.", "startOffset": 72, "endOffset": 86}, {"referenceID": 18, "context": "According to the classification given in [20], this is a coarse-grained master-slave approach.", "startOffset": 41, "endOffset": 45}, {"referenceID": 17, "context": "Characteristics of GPU computing The use of graphics processors for general purpose computing requires taking into account the significant differences between the GPU and CPU architectures [19].", "startOffset": 189, "endOffset": 193}, {"referenceID": 15, "context": "The long delays, often at an order of hundreds of cycles, in accessing the global (main) memory are one of the main obstacles to efficient parallel computations on GPUs [17, 19].", "startOffset": 169, "endOffset": 177}, {"referenceID": 17, "context": "The long delays, often at an order of hundreds of cycles, in accessing the global (main) memory are one of the main obstacles to efficient parallel computations on GPUs [17, 19].", "startOffset": 169, "endOffset": 177}, {"referenceID": 17, "context": "Summarizing, a large number of the GPU processing elements allows to obtain high speedups, provided that the computations are largely independent and enough data is transferred in time [19].", "startOffset": 185, "endOffset": 189}, {"referenceID": 25, "context": "The Travelling Salesman Problem (TSP) is one of the most often studied combinatorial optimization problems [28].", "startOffset": 107, "endOffset": 111}, {"referenceID": 9, "context": "The TSP was one of the first problems used to test the performance of algorithms as inspired by the behavior of ants, including the Ant System and its enhanced version - the Ant Colony System [11, 12].", "startOffset": 192, "endOffset": 200}, {"referenceID": 10, "context": "The TSP was one of the first problems used to test the performance of algorithms as inspired by the behavior of ants, including the Ant System and its enhanced version - the Ant Colony System [11, 12].", "startOffset": 192, "endOffset": 200}, {"referenceID": 10, "context": "2 derived from the Ant System [12].", "startOffset": 30, "endOffset": 34}, {"referenceID": 9, "context": "In the second case we can talk about exploration of the solution space [11].", "startOffset": 71, "endOffset": 75}, {"referenceID": 9, "context": "The size of the candidate set, cl, is typically 10 to 25 [11, 13].", "startOffset": 57, "endOffset": 65}, {"referenceID": 11, "context": "The size of the candidate set, cl, is typically 10 to 25 [11, 13].", "startOffset": 57, "endOffset": 65}, {"referenceID": 19, "context": "It is worth mentioning that Randall and Montgomery [21] proposed dynamic update schemes for candidate sets for the TSP and the Quadratic Assignment Problem.", "startOffset": 51, "endOffset": 55}, {"referenceID": 11, "context": "The global pheromone update places emphasis on exploitation of the search space around the best solutions found to date, hence improving the convergence of the algorithm [13].", "startOffset": 170, "endOffset": 174}, {"referenceID": 3, "context": "Based on the results and conclusions presented, among others, in [5, 8, 10], we applied a model of parallelization in which each ant corresponds to a single thread block.", "startOffset": 65, "endOffset": 75}, {"referenceID": 6, "context": "Based on the results and conclusions presented, among others, in [5, 8, 10], we applied a model of parallelization in which each ant corresponds to a single thread block.", "startOffset": 65, "endOffset": 75}, {"referenceID": 8, "context": "Based on the results and conclusions presented, among others, in [5, 8, 10], we applied a model of parallelization in which each ant corresponds to a single thread block.", "startOffset": 65, "endOffset": 75}, {"referenceID": 31, "context": "The stream processors (cores) in modern GPUs are grouped into so-called warps working in the SIMT mode (single instruction, multiple threads) [34].", "startOffset": 142, "endOffset": 146}, {"referenceID": 3, "context": "This is one of the reasons why the task parallelism model with a single ant per thread is not well suited for the GPU [5].", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "Following [8], we used the value cl = 32.", "startOffset": 10, "endOffset": 13}, {"referenceID": 31, "context": "These instructions give the threads access to values stored in the registers of other threads in the warp without the usage of shared memory [34].", "startOffset": 141, "endOffset": 145}, {"referenceID": 3, "context": "I-Roulette proposed in [5].", "startOffset": 23, "endOffset": 26}, {"referenceID": 6, "context": "results presented in [8].", "startOffset": 21, "endOffset": 24}, {"referenceID": 31, "context": "changes made in the global memory by one thread are immediately visible to the other threads and appear in the order they were made [34].", "startOffset": 132, "endOffset": 136}, {"referenceID": 21, "context": "Selective pheromone memory Based on our earlier ideas [23, 24], we developed a parallel version of the ACS for the GPU in which the pheromone matrix was replaced with a selective pheromone memory of a smaller size.", "startOffset": 54, "endOffset": 62}, {"referenceID": 22, "context": "Selective pheromone memory Based on our earlier ideas [23, 24], we developed a parallel version of the ACS for the GPU in which the pheromone matrix was replaced with a selective pheromone memory of a smaller size.", "startOffset": 54, "endOffset": 62}, {"referenceID": 21, "context": "In the previous work [23, 24], a slightly different selective pheromone memory model was proposed in", "startOffset": 21, "endOffset": 29}, {"referenceID": 22, "context": "In the previous work [23, 24], a slightly different selective pheromone memory model was proposed in", "startOffset": 21, "endOffset": 29}, {"referenceID": 21, "context": "Previous studies have shown that it is enough to remember only a small number of pheromone trail values to obtain good quality results [23, 24].", "startOffset": 135, "endOffset": 143}, {"referenceID": 22, "context": "Previous studies have shown that it is enough to remember only a small number of pheromone trail values to obtain good quality results [23, 24].", "startOffset": 135, "endOffset": 143}, {"referenceID": 14, "context": "This is largely consistent with the observations of the convergence of PopulationBased ACO (PACO), in which the pheromone matrix is defined on the basis of a population of solutions, often of a very small size [16].", "startOffset": 210, "endOffset": 214}, {"referenceID": 24, "context": "The first, labeled ACS-SEQ, was the reference sequential implementation of the ACS in C language by Thomas St\u00fctzle [27].", "startOffset": 115, "endOffset": 119}, {"referenceID": 8, "context": "[10] that a reliable evaluation of a parallel algorithm should take into account the time (speedup) as well as the quality of the results.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "The speedup values were calculated in relation to the sequential implementation of the ACS algorithm from the ACOTSP software by St\u00fctzle [27].", "startOffset": 137, "endOffset": 141}, {"referenceID": 6, "context": "A similar solution was adopted in the literature [8, 9] in order to make the comparisons more reliable and reproducible.", "startOffset": 49, "endOffset": 55}, {"referenceID": 7, "context": "A similar solution was adopted in the literature [8, 9] in order to make the comparisons more reliable and reproducible.", "startOffset": 49, "endOffset": 55}, {"referenceID": 17, "context": "The sequential version takes advantage of only a single CPU core, which makes the GPU vs CPU comparison not entirely fair, as was pointed out in [19], however, such a convention was adopted in most of the articles on the parallel GPU versions of the ACO and MMAS algorithms as presented in the literature, including [5, 10].", "startOffset": 145, "endOffset": 149}, {"referenceID": 3, "context": "The sequential version takes advantage of only a single CPU core, which makes the GPU vs CPU comparison not entirely fair, as was pointed out in [19], however, such a convention was adopted in most of the articles on the parallel GPU versions of the ACO and MMAS algorithms as presented in the literature, including [5, 10].", "startOffset": 316, "endOffset": 323}, {"referenceID": 8, "context": "The sequential version takes advantage of only a single CPU core, which makes the GPU vs CPU comparison not entirely fair, as was pointed out in [19], however, such a convention was adopted in most of the articles on the parallel GPU versions of the ACO and MMAS algorithms as presented in the literature, including [5, 10].", "startOffset": 316, "endOffset": 323}, {"referenceID": 3, "context": "It is worth recalling that in the previous experiments we used the number of ants m equal to the size of the TSP instance solved, as is often recommended in the literature [5, 8, 10, 13].", "startOffset": 172, "endOffset": 186}, {"referenceID": 6, "context": "It is worth recalling that in the previous experiments we used the number of ants m equal to the size of the TSP instance solved, as is often recommended in the literature [5, 8, 10, 13].", "startOffset": 172, "endOffset": 186}, {"referenceID": 8, "context": "It is worth recalling that in the previous experiments we used the number of ants m equal to the size of the TSP instance solved, as is often recommended in the literature [5, 8, 10, 13].", "startOffset": 172, "endOffset": 186}, {"referenceID": 11, "context": "It is worth recalling that in the previous experiments we used the number of ants m equal to the size of the TSP instance solved, as is often recommended in the literature [5, 8, 10, 13].", "startOffset": 172, "endOffset": 186}, {"referenceID": 17, "context": "The smallest number of ants was set to 128 because in order to make good use of the hundreds (in our case 1536) of GPU CUDA cores, the number of active threads should be large [19, 34].", "startOffset": 176, "endOffset": 184}, {"referenceID": 31, "context": "The smallest number of ants was set to 128 because in order to make good use of the hundreds (in our case 1536) of GPU CUDA cores, the number of active threads should be large [19, 34].", "startOffset": 176, "endOffset": 184}, {"referenceID": 8, "context": "The quality of the results could be significantly improved if a local search heuristic was applied [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 24, "context": "All three algorithms were implemented by using the Nvidia CUDA framework and experimentally compared with the reference sequential implementation (ACOTSP) by Thomas St\u00fctzle [27].", "startOffset": 173, "endOffset": 177}, {"referenceID": 1, "context": "Perhaps concurrent kernels execution may be used to speed up even further the computation for multiple ants and multiple colonies [3].", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "3-Opt, as presented in [10].", "startOffset": 23, "endOffset": 27}, {"referenceID": 0, "context": "[2] Hongtao Bai, Dantong OuYang, Ximing Li, Lili He, and Haihong Yu.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[3] Alberto Cano, Jos\u00e9 Mar\u00eda Luna, and Sebasti\u00e1n Ventura.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] Alberto Cano, Juan Luis Olmo, and Sebasti\u00e1n Ventura.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] Jos\u00e9 M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6] U.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] Ling Chen, Hai-Ying Sun, and Shu Wang.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] Laurence Dawson and Iain A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] Laurence Dawson and Iain A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] Audrey Delevacq, Pierre Delisle, Marc Gravel, and Micha\u00ebl Krajecki.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] Marco Dorigo and Luca Maria Gambardella.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] Marco Dorigo, Vittorio Maniezzo, and Alberto Colorni.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] Marco Dorigo and Thomas St\u00fctzle.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] Sankha Baran Dutta, Robert D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] Henrique Fingler, Edson Norberto C\u00e1ceres, Henrique Mongelli, and Siang W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] Michael Guntsch and Martin Middendorf.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] Byunghyun Jang, Dana Schaa, Perhaad Mistry, and David R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] Pavel Kr\u00f6mer, Jan Platos, and V\u00e1clav Sn\u00e1sel.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] Victor W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] Mart\u00edn Pedemonte, Sergio Nesmachnow, and H\u00e9ctor Cancela.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21] Marcus Randall and James Montgomery.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[22] Christian Schulz, Geir Hasle, Andr\u00e9 R Brodtkorb, and Trond R Hagen.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] Rafa\u0142 Skinderowicz.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] Rafa\u0142 Skinderowicz.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[26] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] St\u00fctzle Thomas.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[28] Michael Trick.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[29] Colin Twomey, Thomas St\u00fctzle, Marco Dorigo, Max Manfrin, and Mauro Birattari.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[30] Akihiro Uchida, Yasuaki Ito, and Koji Nakano.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[31] Akihiro Uchida, Yasuaki Ito, and Koji Nakano.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[32] Kai-Cheng Wei, Chao-Chin Wu, and Chien-Ju Wu.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[33] Robin M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[34] Nicholas Wilt.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[35] Hassan A.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "The Ant Colony System (ACS) is, next to Ant Colony Optimization (ACO) and the MAX-MIN Ant System (MMAS), one of the most efficient metaheuristic algorithms inspired by the behavior of ants. In this article we present three novel parallel versions of the ACS for the graphics processing units (GPUs). To the best of our knowledge, this is the first such work on the ACS which shares many key elements of the ACO and the MMAS, but differences in the process of building solutions and updating the pheromone trails make obtaining an efficient parallel version for the GPUs a difficult task. The proposed parallel versions of the ACS differ mainly in their implementations of the pheromone memory. The first two use the standard pheromone matrix, and the third uses a novel selective pheromone memory. Computational experiments conducted on several Travelling Salesman Problem (TSP) instances of sizes ranging from 198 to 2392 cities showed that the parallel ACS on Nvidia Kepler GK104 GPU (1536 CUDA cores) is able to obtain a speedup up to 24.29x vs the sequential ACS running on a single core of Intel Xeon E5-2670 CPU. The parallel ACS with the selective pheromone memory achieved speedups up to 16.85x, but in most cases the obtained solutions were of significantly better quality than for the sequential ACS.", "creator": "LaTeX with hyperref package"}}}