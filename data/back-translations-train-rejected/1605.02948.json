{"id": "1605.02948", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2016", "title": "Different approaches for identifying important concepts in probabilistic biomedical text summarization", "abstract": "Many biomedical researchers and clinicians are faced with the information overload problem. Attaining desirable information from the ever-increasing body of knowledge is a difficult task without using automatic text summarization tools that help them to acquire the intended information in shorter time and with less effort. Although many text summarization methods have been proposed, developing domain-specific methods for the biomedical texts is a challenging task. In this paper, we propose a biomedical text summarization method, based on concept extraction technique and a novel sentence classification approach. We incorporate domain knowledge by utilizing the UMLS knowledge source and the na\\\"ive Bayes classifier to build our text summarizer. Unlike many existing methods, the system learns to classify the sentences without the need for training data, and selects them for the summary according to the distribution of essential concepts within the original text. We show that the use of critical concepts to represent the sentences as vectors of features, and classifying the sentences based on the distribution of those concepts, will improve the performance of automatic summarization. An extensive evaluation is performed on a collection of scientific articles in biomedical domain. The results show that our proposed method outperforms several well-known research-based, commercial and baseline summarizers according to the most commonly used ROUGE evaluation metrics.", "histories": [["v1", "Tue, 10 May 2016 11:33:33 GMT  (573kb)", "http://arxiv.org/abs/1605.02948v1", null], ["v2", "Sat, 10 Sep 2016 16:02:32 GMT  (2274kb)", "http://arxiv.org/abs/1605.02948v2", null], ["v3", "Tue, 30 May 2017 14:37:31 GMT  (2297kb)", "http://arxiv.org/abs/1605.02948v3", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["milad moradi", "nasser ghadiri"], "accepted": false, "id": "1605.02948"}, "pdf": {"name": "1605.02948.pdf", "metadata": {"source": "CRF", "title": "A Bayesian Approach to Biomedical Text Summarization", "authors": ["Milad Moradi", "Nasser Ghadiri"], "emails": ["milad.moradi@ec.iut.ac.ir,", "nghadiri@cc.iut.ac.ir", "nghadiri@gmail.com"], "sections": [{"heading": null, "text": "A Bayesian Approach to Biomedical Text SummarizationMilad Moradi, Nasser Ghadiri1Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, IranE-mail: milad.moradi @ ec.iut.ac.ir, nghadiri @ cc.iut.irAbstract - Many biomedical researchers and clinicians face the problem of information overload. Developing domain-specific methods for biomedical texts is a difficult task without using automatic text aggregation tools that help them obtain the intended information in a shorter time and with less effort. Although many text aggregation methods have been proposed, developing domain-specific methods for biomedical texts is a challenging task. In this paper, we propose a biomedical text aggregation that includes the concept extraction method and novel sentence classification."}, {"heading": "1. Introduction", "text": "This year, as never before in the history of a country where it is a country, where it is a country, where it is a country, where it is a country, where it is a country, where it is a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country,"}, {"heading": "2. Background and related work", "text": "Early work on the automatic summary of texts dates back to the 1950s and 1960s, with the pioneering work of Luhn [18] and Edmundson [19]. However, most progress in this field has occurred in the last two decades. Manuscipt 4 26 April 2016There are some well-known methods of summary, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24], and HITS [25], to which the research community has made much reference over the past two decades. In recent years, much work in text summary has been done using Natural Language Processing (NLP), clusters, machine learning, statistical and graphical methods."}, {"heading": "2.1. Types of summarization", "text": "Text summary methods can be divided into abstract and extractive approaches [1, 26]. An abstract summariser uses NLP methods to process and analyze the input text, then derives from it and produces a new version. On the other hand, an extractive summariser selects the most representative units (paragraphs, sentences, phrases) from the original text and merges them in a shorter form. A further classification of text summaries distinguishes single-document and multi-document inputs [1, 2]. A further classification of summary methods results in the summary that is the result of the condensation of just one document. In contrast, a multi-document summariser receives a cluster of essays and delivers a single summary as the result of extracting the most representative content from the input documents. A further classification of summary methods is based on the user's requirements: generic versus user-oriented summarizers (also known as query-focus sumizers)."}, {"heading": "2.2. Concept extraction from biomedical text", "text": "In the biomedical domain, there are several knowledge sources such as MeSH, SNOMED, GO, OMIM, UWDA, and NCBI taxonomy that can be used in knowledge-intensive data and information processing tasks, as well as word processing tasks related to the biomedical domain. These knowledge sources, along with over 100 controlled vocabulary, classification systems, and additional information sources, have been unified into the Unified Medical Language System (UMLS) [15] by the National Library of Medicine. UMLS comprises three main components: the specialist Lexicon, the metathesaurus, and the Semantic Network.The Specialist Lexicon [28] is a lexicographic information database intended to be used in NLP systems. It contains common English words and biomedical vocabularies."}, {"heading": "2.3. Summarization in the biomedical domain", "text": "In fact, most of them are able to survive themselves if they don't put themselves in a position to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are not able to survive themselves."}, {"heading": "3. The proposed method", "text": "Our proposed summary scheme consists of a pre-processing phase and a classification phase. In the pre-processing stage, the input document is mapped to UMLS concepts and prepared for a further stage. In the classification phase, the sentences, which are presented as vectors of characteristics, are divided into summary and non-summary classes using the naive Bayes classification method. One of the main components of our summary process is the naive Bayes classifier. We begin this section with a brief review of the naive Bayes classification method and then explain in detail our proposed biomedical summary process."}, {"heading": "3.1. The na\u00efve Bayes classifier", "text": "The na\u00efve Bayes [16] is an easy-to-construct and robust classification. It is known as a proven data mining algorithm [44]. Based on this method, the training phase, and the actual classification, is carried out efficiently. There is no need to design complicated iterative parameter estimates. Generally, Bayesian classifier is defined on the basis of Eq. 1 below. In the classification, where C and X are random variables, they refer to the observation of class C and instance X, respectively. X is a vector that contains the values of the characteristics, the posterior probability of observing class X. In the classification, it could be interpreted as the probability that class X is in class C, and is what the classification is trying to determine."}, {"heading": "3.2. Summarization Method", "text": "This year it is more than ever before."}, {"heading": "3.2.4. Preparing sentences for classification", "text": "There are some sentences in which none of the important concepts appear. Thus, the value of all the characters for these sentences would be wrong, and they are discarded for this step and also for the next steps. In this step, each remaining sentence must be represented as a vector of the characters. In the order of the sentences appearing in the original document, each sentence has a number, and the number of sentences is assigned to the corresponding vector of the characters. We refer to the vector of the remaining sentences, which must be represented as a vector of the characters."}, {"heading": "3.2.5. Sentence classification using na\u00efve Bayes", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "3.2.6. Creating the summary", "text": "The last step is the summary. It is determined which sentences should be selected to create the final summary. Sentences with the corresponding sentence vector, which is classified as yes, are added to the summary. Sentences are arranged in the same order as they appear in the primary document. Finally, the figures and tables in the main document referred to in the summary are added to complete the summary process."}, {"heading": "3.3. Evaluation methodology", "text": "The evaluation methods of summary systems can be divided into two broad categories: intrinsic and extrinsic [49]. For intrinsic evaluation, the quality of the summaries produced is assessed on the basis of certain criteria such as accuracy, relevance, comprehensibility and readability, which can be represented by two main characteristics: informativeness and coherence. In intrinsic evaluation, the summaries produced are evaluated by comparison with a gold standard or a human rating. In extrinsic evaluation, the impact of a summary system on the performance of a specific information search task is assessed. Extrinsic evaluation could be performed on the basis of measures such as decision accuracy, success rate and time-to-completion."}, {"heading": "3.3.1. Evaluation corpus", "text": "The most common way to evaluate the summaries generated by an automatic table of contents (also called system or peer summaries) is to compare them with manually generated summaries (also called model or reference summaries).The metric of such an evaluation method is the similarity between the content of system and model summaries. The more content is shared between the system and model summaries, the better the system summary will be adopted. Obtaining the manually generated summaries for biomedical documents is a demanding and time-consuming task since they must be written by human experts. Moreover, the human-generated model summaries as of April 17, 2016 are highly manusceptible. To the authors \"knowledge, there is no corpus of model summaries for biomedical documents. However, most scientific papers have a summary that is normally considered a model summary for evaluation. To evaluate our proposed method, we will randomly select from a biomedical collection and we will use a bidical one to evaluate the scientific one."}, {"heading": "3.3.2. Evaluation metrics: ROUGE", "text": "As mentioned earlier, in GE's intrinsic evaluation of summary methods, two properties are considered as a measure of summary quality: coherence and informativity. Coherence is a property used to measure the readability and cohesion of the summary. Informativity is a feature used to represent how much information from the original text is provided by the summary [51]. Despite progress in evaluating the coherence and readability of automatic summaries [52-54], this evaluation approach is still very preliminary, and the research community has not yet adopted a standard-readability approach. On the other hand, advances in automatic evaluation of informativeness are more impressive [55, 56], and the research community has moved toward a standard approach for this evaluation. For performance evaluation, in terms of the informativeness of automatic summaries, we use the RecallOriented Understudy for Gisting Evaluation (ROUGE) package."}, {"heading": "3.3.3. System configuration", "text": "In this subsection, we describe the first and preliminary set of experiments that determine the best system configuration. In Section 3.3.4, we define the second round of experiments that compare our proposed method with other summaries. We conducted a series of preliminary experiments to determine the optimal value for the threshold that comes with recognizing the important concepts for feature selection (Section 3.2.2). A possible selection for the value of this parameter could be calculated using Equation 5 that we selected for evaluation. We evaluated the performance of our summing method among two other possible choices for the value of this parameter. The other two choices could be calculated using (11) and (12) as follows: =! \"# $(11) =!\" # + \"() #!\" The results of our summing method from U! \"In our preliminary experiments, we also evaluated the effects of coefficients and on the performance of our summarized system."}, {"heading": "3.3.4. Comparison with other summarizers", "text": "In fact, most of them will be able to play by the rules that they need for their policies to achieve their goals."}, {"heading": "4. Results and discussion", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "4.2. Evaluation results", "text": "To evaluate the performance of our summary method, we compare the ROUGE values obtained by our method with the ROUGE values of the other six summarizers. Other summarizers, as described in Section 3.3.4, are SUMMA, SweSum, BioChain, Microsoft AutoSummarze, Lead Baseline, and Random Baseline. For each summarizer, the system summaries were compared with the model summaries provided by the ROUGE toolkit, and each summarizer was assigned four different values. ROUGE values for all summarizers are shown in Manuscipt 22 April 26, 2016 Table 2. It can be observed that the naive Bayes summarics summarizer reports are higher than the other summarizer values and baselines. The naive Bayes summarizer summarics are significant with respect to all summarizers."}, {"heading": "5. Conclusion", "text": "This paper proposes a novel biomedical text summary based on the naive Bayes classification. Our method extracts biomedical concepts within the UMLS document and identifies the key concepts to show the main themes of the text. The key concepts identified are then used as characteristics to classify the sentences as a summary rather than a summary. There is no need for the formation of data, and the naive Bayes classifiers estimate the previous and subsequent probabilities based on the distribution of important concepts within the original document. Furthermore, a useful indication is given that the distribution of important concepts must take place within the source text. The proposed method was based on the summary of a collection of 80 scientific biomedical papers selected from the online library."}], "references": [{"title": "Text summarization in the biomedical domain: a systematic review of recent research", "author": ["R. Mishra", "J. Bian", "M. Fiszman", "C.R. Weir", "S. Jonnalagadda", "J. Mostafa"], "venue": "Journal of biomedical informatics, vol. 52, pp. 457-467, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Summarization from medical documents: a survey", "author": ["S. Afantenos", "V. Karkaletsis", "P. Stamatopoulos"], "venue": "Artificial intelligence in medicine, vol. 33, pp. 157-177, 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Application of text mining in the biomedical domain", "author": ["W.W. Fleuren", "W. Alkema"], "venue": "Methods, vol. 74, pp. 97-106, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "The use of domain-specific concepts in biomedical text summarization", "author": ["L.H. Reeve", "H. Han", "A.D. Brooks"], "venue": "Information Processing & Management, vol. 43, pp. 1765-1776, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Text summarization using Wikipedia", "author": ["Y. Sankarasubramaniam", "K. Ramanathan", "S. Ghosh"], "venue": "Information Processing & Management, vol. 50, pp. 443-461, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "A semantic graph-based approach to biomedical summarisation", "author": ["L. Plaza", "A. D\u00edaz", "P. Gerv\u00e1s"], "venue": "Artificial intelligence in medicine, vol. 53, pp. 1-14, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic summarization of MEDLINE citations for evidence-based medical treatment: A topic-oriented evaluation", "author": ["M. Fiszman", "D. Demner-Fushman", "H. Kilicoglu", "T.C. Rindflesch"], "venue": "Journal of biomedical informatics, vol. 42, pp. 801- 813, 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "BioChain: lexical chaining methods for biomedical text summarization", "author": ["L. Reeve", "H. Han", "A.D. Brooks"], "venue": "Proceedings of the 2006 ACM symposium on Applied computing, 2006, pp. 180-184.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Concept frequency distribution in biomedical text summarization", "author": ["L.H. Reeve", "H. Han", "S.V. Nagori", "J.C. Yang", "T.A. Schwimmer", "A.D. Brooks"], "venue": "Proceedings of the 15th ACM international conference on Information and knowledge management, 2006, pp. 604-611.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "A trainable document summarizer", "author": ["J. Kupiec", "J. Pedersen", "F. Chen"], "venue": "Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, 1995, pp. 68-73.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1995}, {"title": "Automatic text summarization using a machine learning approach", "author": ["J.L. Neto", "A.A. Freitas", "C.A. Kaestner"], "venue": "Advances in Artificial Intelligence, ed: Springer, 2002, pp. 205-215.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Applying regression models to query-focused multi-document summarization", "author": ["Y. Ouyang", "W. Li", "S. Li", "Q. Lu"], "venue": "Information Processing & Management, vol. 47, pp. 227-237, 2011.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic extraction and learning of keyphrases from scientific articles", "author": ["Y. HaCohen-Kerner", "Z. Gross", "A. Masa"], "venue": "Computational Linguistics and Intelligent Text Processing, ed: Springer, 2005, pp. 657-669.  Manuscipt  24  26 April 2016", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "The unified medical language system (umls) project", "author": ["S.J. Nelson", "T. Powell", "B. Humphreys"], "venue": "Encyclopedia of library and information science, pp. 369-378, 2002.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Generative and discriminative classifiers: naive Bayes and logistic regression, 2005", "author": ["T. Mitchell"], "venue": "Manuscript available at <http://www.cs. cm. edu/~ tom/NewChapters.html>.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 0}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["C.-Y. Lin"], "venue": "Text summarization branches out: Proceedings of the ACL-04 workshop, 2004.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "The automatic creation of literature abstracts", "author": ["H.P. Luhn"], "venue": "IBM Journal of research and development, vol. 2, pp. 159- 165, 1958.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1958}, {"title": "New methods in automatic extracting", "author": ["H.P. Edmundson"], "venue": "Journal of the ACM (JACM), vol. 16, pp. 264-285, 1969.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1969}, {"title": "Centroid-based summarization of multiple documents", "author": ["D.R. Radev", "H. Jing", "M. Sty\u015b", "D. Tam"], "venue": "Information Processing & Management, vol. 40, pp. 919-938, 2004.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "The use of MMR, diversity-based reranking for reordering documents and producing summaries", "author": ["J. Carbonell", "J. Goldstein"], "venue": "Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, 1998, pp. 335-336.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1998}, {"title": "LexRank: Graph-based lexical centrality as salience in text summarization", "author": ["G. Erkan", "D.R. Radev"], "venue": "Journal of Artificial Intelligence Research, pp. 457-479, 2004.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "The PageRank citation ranking: bringing order to the web", "author": ["L. Page", "S. Brin", "R. Motwani", "T. Winograd"], "venue": "1999.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "TextRank: Bringing order into texts", "author": ["R. Mihalcea", "P. Tarau"], "venue": "2004.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2004}, {"title": "Authoritative sources in a hyperlinked environment", "author": ["J.M. Kleinberg"], "venue": "Journal of the ACM (JACM), vol. 46, pp. 604- 632, 1999.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1999}, {"title": "A survey of text summarization extractive techniques", "author": ["V. Gupta", "G.S. Lehal"], "venue": "Journal of Emerging Technologies in Web Intelligence, vol. 2, pp. 258-268, 2010.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "MCMR: Maximum coverage and minimum redundant text summarization model", "author": ["R.M. Alguliev", "R.M. Aliguliyev", "M.S. Hajirahimova", "C.A. Mehdiyev"], "venue": "Expert Systems with Applications, vol. 38, pp. 14514-14522, 2011.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}, {"title": "Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program", "author": ["A.R. Aronson"], "venue": "Proceedings of the AMIA Symposium, 2001, p. 17.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2001}, {"title": "Using lexical chains for text summarization", "author": ["R. Barzilay", "M. Elhadad"], "venue": "Advances in automatic text summarization, pp. 111-121, 1999.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1999}, {"title": "Using domain knowledge for text summarization in medical domain", "author": ["K. Sarkar"], "venue": "International Journal of Recent Trends in Engineering, vol. 1, pp. 200-205, 2009.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2009}, {"title": "Comparison of automatic summarisation methods for clinical free text notes", "author": ["H. Moen", "L.-M. Peltonen", "J. Heimonen", "A. Airola", "T. Pahikkala", "T. Salakoski"], "venue": "Artificial Intelligence in Medicine, 2016.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2016}, {"title": "Comparing different knowledge sources for the automatic summarization of biomedical literature", "author": ["L. Plaza"], "venue": "Journal of biomedical informatics, vol. 52, pp. 319-328, 2014.  Manuscipt  25  26 April 2016", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "Abstraction summarization for managing the biomedical research literature", "author": ["M. Fiszman", "T.C. Rindflesch", "H. Kilicoglu"], "venue": "Proceedings of the HLT-NAACL workshop on computational lexical semantics, 2004, pp. 76-83.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2004}, {"title": "The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text", "author": ["T.C. Rindflesch", "M. Fiszman"], "venue": "Journal of biomedical informatics, vol. 36, pp. 462- 477, 2003.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2003}, {"title": "Text summarization as a decision support aid", "author": ["T.E. Workman", "M. Fiszman", "J.F. Hurdle"], "venue": "BMC medical informatics and decision making, vol. 12, p. 41, 2012.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "Degree centrality for semantic abstraction summarization of therapeutic studies", "author": ["H. Zhang", "M. Fiszman", "D. Shin", "C.M. Miller", "G. Rosemblat", "T.C. Rindflesch"], "venue": "Journal of biomedical informatics, vol. 44, pp. 830-838, 2011.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "Clustering cliques for graph-based summarization of the biomedical research literature", "author": ["H. Zhang", "M. Fiszman", "D. Shin", "B. Wilkowski", "T.C. Rindflesch"], "venue": "BMC bioinformatics, vol. 14, p. 1, 2013.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "A robust and adaptable summarization tool", "author": ["H. Saggion"], "venue": "Traitement Automatique des Langues, vol. 49, 2008.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2008}, {"title": "Swesum: A text summerizer for swedish: KTH", "author": ["H. Dalianis"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2000}, {"title": "Top 10 algorithms in data mining", "author": ["X. Wu", "V. Kumar", "J.R. Quinlan", "J. Ghosh", "Q. Yang", "H. Motoda"], "venue": "Knowledge and information systems, vol. 14, pp. 1-37, 2008.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2008}, {"title": "Data mining and predictive analytics", "author": ["D.T. Larose", "C.D. Larose"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2015}, {"title": "National library of medicine", "author": ["M.J. Shooshan SE", "Aronson AR"], "venue": "Technical report. Ambiguity in the UMLS Metathesaurus; 2009 Edition,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2009}, {"title": "Resolving ambiguity in biomedical text to improve summarization", "author": ["L. Plaza", "M. Stevenson", "A. D\u00edaz"], "venue": "Information Processing & Management, vol. 48, pp. 755-766, 2012.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2012}, {"title": "Word sense disambiguation by selecting the best semantic type based on Journal Descriptor Indexing: Preliminary experiment", "author": ["S.M. Humphrey", "W.J. Rogers", "H. Kilicoglu", "D. Demner\u2010Fushman", "T.C. Rindflesch"], "venue": "Journal of the American Society for Information Science and Technology, vol. 57, pp. 96-113, 2006.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2006}, {"title": "Evaluating natural language processing systems: An analysis and review", "author": ["K.S. Jones", "J.R. Galliers"], "venue": "vol. 1083: Springer Science & Business Media,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1995}, {"title": "Looking for a few good metrics: Automatic summarization evaluation-how many samples are enough", "author": ["C.-Y. Lin"], "venue": "NTCIR, 2004.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2004}, {"title": "Summarization evaluation: An overview", "author": ["I. Mani"], "venue": "2001.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2001}, {"title": "Automatic evaluation of linguistic quality in multi-document summarization", "author": ["E. Pitler", "A. Louis", "A. Nenkova"], "venue": "Proceedings of the 48th annual meeting of the Association for Computational Linguistics, 2010, pp. 544-554.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2010}, {"title": "Revisiting readability: A unified framework for predicting text quality", "author": ["E. Pitler", "A. Nenkova"], "venue": "Proceedings of the conference on empirical methods in natural language processing, 2008, pp. 186-195.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2008}, {"title": "Quantitative evaluation of grammaticality of summaries", "author": ["R. Vadlapudi", "R. Katragadda"], "venue": "Computational Linguistics and Intelligent Text Processing, ed: Springer, 2010, pp. 736-747.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2010}, {"title": "Summarization evaluation using transformed basic elements", "author": ["S. Tratz", "E. Hovy"], "venue": "Proceedings TAC, 2008.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2008}, {"title": "Summarization system evaluation revisited: Ngram graphs", "author": ["G. Giannakopoulos", "V. Karkaletsis", "G. Vouros", "P. Stamatopoulos"], "venue": "ACM Transactions on Speech and Language Processing (TSLP), vol. 5, p. 5, 2008.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2008}, {"title": "The Oxford handbook of computational linguistics", "author": ["R. Mitkov"], "venue": null, "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Biomedical information available for researchers and clinicians is accessible from a variety of sources such as scientific literature databases, Electronic Health Record (EHR) systems, web documents, e-mailed reports and multimedia documents [1, 2].", "startOffset": 242, "endOffset": 248}, {"referenceID": 1, "context": "Biomedical information available for researchers and clinicians is accessible from a variety of sources such as scientific literature databases, Electronic Health Record (EHR) systems, web documents, e-mailed reports and multimedia documents [1, 2].", "startOffset": 242, "endOffset": 248}, {"referenceID": 2, "context": "It is widely used as a rich source for assessing the new comers in a particular field, gathering information for constructing research hypotheses and collecting information for interpretation of experimental results [3].", "startOffset": 216, "endOffset": 219}, {"referenceID": 1, "context": "Required information must be accessed easily at the right time, and in the most appropriate form [2].", "startOffset": 97, "endOffset": 100}, {"referenceID": 3, "context": "Automatic text summarization is a promising approach to overcome the information overload, by reducing the amount of text that must be read [5].", "startOffset": 140, "endOffset": 143}, {"referenceID": 0, "context": "It can be used to obtain the gist efficiently on a topic of interest [1].", "startOffset": 69, "endOffset": 72}, {"referenceID": 4, "context": "A good summary of text must have two main properties: it needs to be short, and it should preserve valuable information of source text [6].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "In other words, they are designed as general-purpose tools [7].", "startOffset": 59, "endOffset": 62}, {"referenceID": 5, "context": "The characteristics of biomedical domain raise the need to analyze the source text at a conceptual level and to employ domain knowledge in summarization process [7].", "startOffset": 161, "endOffset": 164}, {"referenceID": 5, "context": "This is required to extract a rich representation of source text [7-10].", "startOffset": 65, "endOffset": 71}, {"referenceID": 6, "context": "This is required to extract a rich representation of source text [7-10].", "startOffset": 65, "endOffset": 71}, {"referenceID": 7, "context": "This is required to extract a rich representation of source text [7-10].", "startOffset": 65, "endOffset": 71}, {"referenceID": 8, "context": "This is required to extract a rich representation of source text [7-10].", "startOffset": 65, "endOffset": 71}, {"referenceID": 9, "context": "Some of the summarization systems have been proposed based on classification methods [11-14].", "startOffset": 85, "endOffset": 92}, {"referenceID": 10, "context": "Some of the summarization systems have been proposed based on classification methods [11-14].", "startOffset": 85, "endOffset": 92}, {"referenceID": 11, "context": "Some of the summarization systems have been proposed based on classification methods [11-14].", "startOffset": 85, "endOffset": 92}, {"referenceID": 12, "context": "Some of the summarization systems have been proposed based on classification methods [11-14].", "startOffset": 85, "endOffset": 92}, {"referenceID": 13, "context": "In our proposed method, biomedical concepts are extracted from input text by utilizing the UMLS [15], an important and well-known knowledge source in biomedical sciences, maintained by the US National Library of Medicine.", "startOffset": 96, "endOffset": 100}, {"referenceID": 14, "context": "We use the na\u00efve Bayes classifier [16] to label the sentences as summary or nonsummary.", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "The results demonstrate that our method performs better than similar research-oriented, commercial competitors and baseline methods in terms of the most commonly used ROUGE evaluation metrics [17].", "startOffset": 192, "endOffset": 196}, {"referenceID": 16, "context": "Early work on automatic text summarization dates back to the 1950s and 1960s with the pioneering work of Luhn [18] and Edmundson [19].", "startOffset": 110, "endOffset": 114}, {"referenceID": 17, "context": "Early work on automatic text summarization dates back to the 1950s and 1960s with the pioneering work of Luhn [18] and Edmundson [19].", "startOffset": 129, "endOffset": 133}, {"referenceID": 18, "context": "Manuscipt 4 26 April 2016 There are some well-known summarization methods, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24] and HITS [25], widely referenced by the research community in the last two decades.", "startOffset": 88, "endOffset": 92}, {"referenceID": 19, "context": "Manuscipt 4 26 April 2016 There are some well-known summarization methods, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24] and HITS [25], widely referenced by the research community in the last two decades.", "startOffset": 98, "endOffset": 102}, {"referenceID": 20, "context": "Manuscipt 4 26 April 2016 There are some well-known summarization methods, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24] and HITS [25], widely referenced by the research community in the last two decades.", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "Manuscipt 4 26 April 2016 There are some well-known summarization methods, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24] and HITS [25], widely referenced by the research community in the last two decades.", "startOffset": 127, "endOffset": 131}, {"referenceID": 22, "context": "Manuscipt 4 26 April 2016 There are some well-known summarization methods, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24] and HITS [25], widely referenced by the research community in the last two decades.", "startOffset": 142, "endOffset": 146}, {"referenceID": 23, "context": "Manuscipt 4 26 April 2016 There are some well-known summarization methods, such as MEAD [20], MMR [21], LexRank [22], PageRank [23], TextRank [24] and HITS [25], widely referenced by the research community in the last two decades.", "startOffset": 156, "endOffset": 160}, {"referenceID": 0, "context": "Text summarization methods can be divided into abstractive and extractive approaches [1, 26].", "startOffset": 85, "endOffset": 92}, {"referenceID": 24, "context": "Text summarization methods can be divided into abstractive and extractive approaches [1, 26].", "startOffset": 85, "endOffset": 92}, {"referenceID": 0, "context": "Another classification of text summarization differentiates single-document and multi-document inputs [1, 2].", "startOffset": 102, "endOffset": 108}, {"referenceID": 1, "context": "Another classification of text summarization differentiates single-document and multi-document inputs [1, 2].", "startOffset": 102, "endOffset": 108}, {"referenceID": 0, "context": "user-oriented (also known as query-focused summarizers) [1, 2, 27].", "startOffset": 56, "endOffset": 66}, {"referenceID": 1, "context": "user-oriented (also known as query-focused summarizers) [1, 2, 27].", "startOffset": 56, "endOffset": 66}, {"referenceID": 25, "context": "user-oriented (also known as query-focused summarizers) [1, 2, 27].", "startOffset": 56, "endOffset": 66}, {"referenceID": 13, "context": "These knowledge sources along with over 100 controlled vocabularies, classification systems, and additional information sources have been unified into the Unified Medical Language System (UMLS) [15] by the National Library of Medicine.", "startOffset": 194, "endOffset": 198}, {"referenceID": 26, "context": "For mapping biomedical text to the UMLS Metathesaurus concepts (known as automated concept annotation), the MetaMap program [31, 32] has been developed by the National Library of Medicine.", "startOffset": 124, "endOffset": 132}, {"referenceID": 1, "context": "These methods are reviewed in a survey of early work [2] and in a systematic review of recently published research [1].", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "These methods are reviewed in a survey of early work [2] and in a systematic review of recently published research [1].", "startOffset": 115, "endOffset": 118}, {"referenceID": 7, "context": "[9] applied the method of lexical chaining [33] to biomedical text, but they used concepts rather than terms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 27, "context": "[9] applied the method of lexical chaining [33] to biomedical text, but they used concepts rather than terms.", "startOffset": 43, "endOffset": 47}, {"referenceID": 8, "context": "FreqDist [10] is a context-sensitive approach, proposed to score the sentences according to a frequency distribution model, along with the ability to remove information redundancy.", "startOffset": 9, "endOffset": 13}, {"referenceID": 3, "context": "[5] combine the BioChain and the FreqDist and propose a hybrid method.", "startOffset": 0, "endOffset": 3}, {"referenceID": 28, "context": "In a feature-based method [34], in addition to commonly used traditional features, a vocabulary of cue terms and phrases unique to the medical domain is identified and is used as domain knowledge.", "startOffset": 26, "endOffset": 30}, {"referenceID": 5, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 29, "context": "[35] present several text summarization methods for summarizing clinical notes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[36], in terms of the quality of the automatically generated summaries.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[37] present a multi-document semantic abstraction summarization system for MEDLINE citations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "Their system relies on the semantic predications extracted by SemRep [38], a parser based on linguistic analysis and domain knowledge contained in the UMLS.", "startOffset": 69, "endOffset": 73}, {"referenceID": 6, "context": "[8] extend the semantic abstraction summarization system [37] for evidence-based medical treatment.", "startOffset": 0, "endOffset": 3}, {"referenceID": 31, "context": "[8] extend the semantic abstraction summarization system [37] for evidence-based medical treatment.", "startOffset": 57, "endOffset": 61}, {"referenceID": 31, "context": "Two other abstractive summarizers based on semantic abstraction summarization system [37] are proposed by Workman et al.", "startOffset": 85, "endOffset": 89}, {"referenceID": 33, "context": "[39] and Zhang et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[40].", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "An abstractive graph-based clustering method [41] is presented for automatic identification of themes in multi-document summarization.", "startOffset": 45, "endOffset": 49}, {"referenceID": 36, "context": "Unlike domain-independent summarization methods such as SUMMA [42] and SweSum [43], our proposed method utilizes domain knowledge and analyzes the source text at a conceptual level.", "startOffset": 62, "endOffset": 66}, {"referenceID": 37, "context": "Unlike domain-independent summarization methods such as SUMMA [42] and SweSum [43], our proposed method utilizes domain knowledge and analyzes the source text at a conceptual level.", "startOffset": 78, "endOffset": 82}, {"referenceID": 14, "context": "The na\u00efve Bayes [16] is an easy to build and robust classifier.", "startOffset": 16, "endOffset": 20}, {"referenceID": 38, "context": "It is known as a proven data mining algorithm [44].", "startOffset": 46, "endOffset": 50}, {"referenceID": 39, "context": "The Posterior Odds Ratio shows a measure of the strength of evidence in favor of a particular classification compared to another method [45].", "startOffset": 136, "endOffset": 140}, {"referenceID": 40, "context": "When the MetaMap is faced with lexical ambiguity, it often fails to specify a unique mapping for a given phrase [46].", "startOffset": 112, "endOffset": 116}, {"referenceID": 41, "context": "This behavior occurs because some words may have multiple meanings, and each meaning depends on the context in which it appears [47].", "startOffset": 128, "endOffset": 132}, {"referenceID": 42, "context": "-y flag, it uses the Journal Descriptor Indexing (JDI) algorithm [48] to resolve Metathesaurus ambiguity.", "startOffset": 65, "endOffset": 69}, {"referenceID": 41, "context": "It has been shown in [47] that the All Mappings is relatively an appropriate Word Sense Disambiguation (WSD) strategy for concept identification.", "startOffset": 21, "endOffset": 25}, {"referenceID": 5, "context": "These semantic types have been identified empirically by [7], including functional concept, qualitative concept,", "startOffset": 57, "endOffset": 60}, {"referenceID": 43, "context": "The evaluation methods of summarization systems could be divided into two broad categories: Intrinsic and Extrinsic [49].", "startOffset": 116, "endOffset": 120}, {"referenceID": 44, "context": "According to [50], the size of evaluation corpus is large enough to allow the results of the assessment to be significant.", "startOffset": 13, "endOffset": 17}, {"referenceID": 45, "context": "Informativeness is a feature for representing how much information from the original text is provided by the summary [51].", "startOffset": 117, "endOffset": 121}, {"referenceID": 46, "context": "In spite of advances in evaluating the coherence and readability of automatic summaries [52-54], this evaluation approach is still very preliminary, and the research community has not adopted any standard readability assessment approach yet.", "startOffset": 88, "endOffset": 95}, {"referenceID": 47, "context": "In spite of advances in evaluating the coherence and readability of automatic summaries [52-54], this evaluation approach is still very preliminary, and the research community has not adopted any standard readability assessment approach yet.", "startOffset": 88, "endOffset": 95}, {"referenceID": 48, "context": "In spite of advances in evaluating the coherence and readability of automatic summaries [52-54], this evaluation approach is still very preliminary, and the research community has not adopted any standard readability assessment approach yet.", "startOffset": 88, "endOffset": 95}, {"referenceID": 49, "context": "On the other hand, advances in automatic evaluation of informativeness are more impressive [55, 56], and the research community has agreed upon a standard approach for this evaluation approach.", "startOffset": 91, "endOffset": 99}, {"referenceID": 50, "context": "On the other hand, advances in automatic evaluation of informativeness are more impressive [55, 56], and the research community has agreed upon a standard approach for this evaluation approach.", "startOffset": 91, "endOffset": 99}, {"referenceID": 15, "context": "For performance evaluation, in terms of the informativeness of automatic summaries, we used the RecallOriented Understudy for Gisting Evaluation (ROUGE) package [17].", "startOffset": 161, "endOffset": 165}, {"referenceID": 15, "context": "In spite of its simplicity, ROUGE has shown high correlation with the human judges [17].", "startOffset": 83, "endOffset": 87}, {"referenceID": 51, "context": "The choice of 30% as the compression rate is based on a well-accepted de facto standard that says the size of a summary should be between 15% and 35% of the size of original text [57].", "startOffset": 179, "endOffset": 183}, {"referenceID": 36, "context": "\u2022 SUMMA: SUMMA [42] is a popular research summarizer and is available for public usage.", "startOffset": 15, "endOffset": 19}, {"referenceID": 37, "context": "\u2022 SweSum: SweSum [43] is a multi-lingual summarizer with its text summarization for English, Danish, Norwegian and Swedish considered to be state-of-the-art and for Persian, French, German, Spanish and Greek is in a prototype state.", "startOffset": 17, "endOffset": 21}, {"referenceID": 7, "context": "\u2022 BioChain: BioChain [9] is a biomedical summarizer that uses an NLP method, named Lexical Chaining, for summarization.", "startOffset": 21, "endOffset": 24}], "year": 2016, "abstractText": "Many biomedical researchers and clinicians are faced with the information overload problem. Attaining desirable information from the ever-increasing body of knowledge is a difficult task without using automatic text summarization tools that help them to acquire the intended information in shorter time and with less effort. Although many text summarization methods have been proposed, developing domain-specific methods for the biomedical texts is a challenging task. In this paper, we propose a biomedical text summarization method, based on concept extraction technique and a novel sentence classification approach. We incorporate domain knowledge by utilizing the UMLS knowledge source and the na\u00efve Bayes classifier to build our text summarizer. Unlike many existing methods, the system learns to classify the sentences without the need for training data, and selects them for the summary according to the distribution of essential concepts within the original text. We show that the use of critical concepts to represent the sentences as vectors of features, and classifying the sentences based on the distribution of those concepts, will improve the performance of automatic summarization. An extensive evaluation is performed on a collection of scientific articles in biomedical domain. The results show that our proposed method outperforms several well-known research-based, commercial and baseline summarizers according to the most commonly used ROUGE evaluation metrics. Keywords\u2015Biomedical text summarization; Data mining; Na\u00efve Bayes; Concept extraction; UMLS; Domain knowledge; Sentence classification; 1 Corresponding author. Address: Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran. Phone : +98-31-3391-9058, Fax: +98-31-3391-2450, Alternate email: nghadiri@gmail.com", "creator": "PDFCreator 2.3.0.103"}}}