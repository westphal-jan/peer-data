{"id": "1605.03284", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2016", "title": "Machine Comprehension Based on Learning to Rank", "abstract": "Machine comprehension plays an essential role in NLP and has been widely explored with dataset like MCTest. However, this dataset is too simple and too small for learning true reasoning abilities. \\cite{hermann2015teaching} therefore release a large scale news article dataset and propose a deep LSTM reader system for machine comprehension. However, the training process is expensive. We therefore try feature-engineered approach with semantics on the new dataset to see how traditional machine learning technique and semantics can help with machine comprehension. Meanwhile, our proposed L2R reader system achieves good performance with efficiency and less training data.", "histories": [["v1", "Wed, 11 May 2016 05:05:05 GMT  (947kb,D)", "http://arxiv.org/abs/1605.03284v1", "9 pages"], ["v2", "Fri, 13 May 2016 01:06:09 GMT  (947kb,D)", "http://arxiv.org/abs/1605.03284v2", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tian tian", "yuezhang li"], "accepted": false, "id": "1605.03284"}, "pdf": {"name": "1605.03284.pdf", "metadata": {"source": "CRF", "title": "Machine Comprehension Based on Learning to Rank", "authors": ["Tian Tian", "Yuezhang Li"], "emails": ["yuezhanl@andrew.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "In the meantime, as the central objective in NLP, research has been carried out using a variety of methods. Based on the published data set MCTest (Richardson et al., 2013), a lexical matching-based method is proposed (Smith et al., 2015), which applies linguistic characteristics to address this problem. However, this method delves deeply into the properties of the data set and cannot be generalized well to other data sets. This problem is also associated with the discourse model introduced in (Narasimhan and Barzilay, 2015), which examines causal, temporal and explanatory relationships between two sentences that do not scale well."}, {"heading": "2 Task and Datasets", "text": "This section gives a brief introduction to the task and the dataset that was recently released for this task."}, {"heading": "2.1 Formal Task Description", "text": "This task requires answering a cloze-style question based on understanding a context document that accompanies the question. Along with each question and document, it also provides the correct answer to the question and a list of candidate answers. This can be formalized as follows: The training data consists of tuples (d, q, a, A), where d is a context document for answering the question q, a is the correct answer to the question q, A defines a set of candidate answers to the question, and a a."}, {"heading": "2.2 Datasets", "text": "The dataset (Hermann et al., 2015) we used in this task was constructed from news articles from the CNN and Daily Mail websites; the contextual document of the dataset comes from the main part of the news article, while the question consists of a first sentence summarizing the news article. Specifically, the question is constructed by replacing the said company with a placeholder, e.g. \"@ placeholder and @ placeholder welcome son @ placeholder\" is a question defined in the dataset. In addition, we use the anonymized version as shown in Figure 2 to eliminate the influence of background knowledge. Therefore, we need to use the context to answer the question, and these two corporations really measure readability. The basic statistics from CNN and Daily Mail of the dataset are summarized in Table 1."}, {"heading": "3 Related Work", "text": "Machine understanding is generally focused on MCTest (Richardson et al., 2013), and due to the limitation of data size, the state of the art is mainly based on traditional machine learning techniques. For example, (Wang and McAllester, 2015) a maximum margin learning framework was proposed that combines features on syntax, co-references, frame semantics and word embedding, thereby substantially improving the problem of answering MCTest questions. Although a parallel hierarchical model based on neural networks was recently proposed (Trischler et al., 2016) and this method surpasses previous functional approaches, it has an argument limitation that reasoning can only be achieved by stringing together important sentences. Their experiment proves that MCTest is too simple to learn true reasoning, and is also too small for this purpose. Taking into account the limitations of the MCTest dataset (al Hermann et Mail, 2015), we can find a comprehensive explanation of the MCTest database for CNN, and thus provide an explanation of the MCMail."}, {"heading": "4 Model \u2013 Learning to Rank (L2R) Reader", "text": "Our model consists of learning the order of precedence of algorithms, attributes and semantics. As shown in Figure 1, we receive a document along with a list of queries in which the placeholder is filled with different units from the list of candidate responses. We then obtain multiple attributes for each unit (i.e. candidate response) through a feature extractor. In combination with the correct response, we use a learning algorithm for ranking (i.e. L2R in Figure 1) to train a ranking model. Based on the ranking model, we create rankings for new invisible data sets whose attributes are extracted using feature extractor; from the ranking list, we select the company with the highest score as the predicted answer to the question."}, {"heading": "4.1 Learning to Rank", "text": "The ranking is applied in Information Retrieval (IR) and Natural Language Processing (NLP). Generally, it is defined as follows: In a query, the ranking algorithm generates a list of candidate documents with results (Hang, 2011). In this task, we select the company with the highest score in response to the question. At this point, we introduce three different types of learning to evaluate algorithms that may be helpful in the task. Pointwise: In the pointwise approach, the ranking algorithm is converted into problems, including classification and regression, to derive a score for each pair of documents and queries (Hang, 2011). This approach ignores the group structure of the ranking and does not apply it to this task. In the pairewise approach, the ranking algorithm is converted into problems of pairewise classification or pairwise regression (Hang, 2011)."}, {"heading": "4.2 Features", "text": "We will examine four types of characteristics in this task: we will start with the frequency of the entity in both document and cloze questions. Then we will try word spacing characteristics with different window size settings. We will also examine syntactic and semantics characteristics to see how they affect model performance."}, {"heading": "4.2.1 Frequency", "text": "The frequency is examined on the basis of a baseline of (Hermann et al., 2015). We simply count the number of entities in the candidate list that appear in the document and in the question, then the count works as the frequency attribute of the entity. If this entity does not appear in the question or in the document, we assign a value of 0. The idea behind this is that important entities are usually mentioned several times in news articles, and the cloze-style question deals with such entities."}, {"heading": "4.2.2 Word Distance", "text": "We examine word removal from three aspects - word alignment, nBOW, and word spacing (WMD) (Kusner et al., 2015).Word Alignment (WA): For word alignment, we first look at the situation shown in Figure 2. After Figure 2, we first replace the \"@ placeholder\" with a unit in the candidate list and search the document to find a matching sentence that contains that unit. Then, we align these two units and set the position index to 0. Starting from this index, words that are on the left have a negative index, while words that are on the right have a positive index. With the defined index, we align the same words of these two sentences and calculate the difference between the word indexes. In the case of words that are not aligned, a penalty is given. Finally, the score captures some word information of the question and document records that are on the right with a positive index."}, {"heading": "4.2.3 Syntactic Features", "text": "In this task, we consider syntactical characteristics such as part-of-speech (POS) tags and dependency sparsing.POS tags: Similar to the word alignment defined in Section 4.2.2, we consider the alignment of POS tags as a syntactic feature. Specifically, we transform words using NLTK1 into POS tags and use the same technology as word alignment to detect the dissimilarity of two sentences. Dependency parsing: When two sentences describe the same event, it is likely that they overlap (Wang and McAllester, 2015). Therefore, we include the dependency sparing to gather such information. To be more precise, we use Stanford Parsing2 to obtain dependencies of a sentence that are represented as multiple triples, such as (s, t, arc), e.g. (entity, has, nsubj), where s is the source word and t the target word. Then, this dependency-based similarity is evaluated from d = d = d = d = qd, d = qd =, qd =, this question = qd = = qt = qd =."}, {"heading": "4.2.4 Semantic Features", "text": "In addition to the word embedding used in WMD in Section 4.2.2, we use the SEMAFOR Frame Semantic (FS) parser (Das et al., 2014) to extract some semantic characteristics. Figure 4 gives an example of the SEMAFOR Semantic Parser. In this example, five frames are identified, e.g. 1http: / / www.nltk.org / 2http: / / nlp.stanford.edu / software / stanford-dependencies.shtmlThe word \"says\" is a target that evokes a semantic frame called STATEMENT. Each frame has its own frame elements, e.g. the STATEMENT frame has frame elements of Message and Speaker. Properties from these parsers have proven useful for the machine understanding task (Wang and McAllester, 2015). We expect the document set containing the answer to intersect with the question and answer to be corrected for the elements referred to in a fragment."}, {"heading": "4.3 Semantics", "text": "In this project, we use semantics in aspects of weapons of mass destruction, frame semantic (FS) and koreference. In weapons of mass destruction, we use word embedding to capture the semantics of the word level, and FS helps us capture the semantics of the sentence level. Korean reference is applied to identity chains of mentions within and between sentences for data preprocessing. In particular, word embedding (Mikolov et al., 2013) projects words into a low-dimensional space and similarity of vectors can capture some word similarities in semantics. For example, the word \"Paris\" is close to \"and not\" France \"and vec (\" Paris \") is closest to Vec (\" Berlin \") - Vetik (\" Germany \") + vec (\" France \") semanity.\""}, {"heading": "5 Evaluation", "text": "We evaluate the L2R reading system by comparing it with the baselines of (Hermann et al., 2015). In addition, we present system performance using various learning-to-rank algorithms, on the basis of which we select RankSVM and LamdaMART as ranking algorithms for model training. In addition, we evaluate the contribution of individual features to system performance for the final feature decision. Based on the final results, we analyze the impact of integrating semantics into the system from Korean references, word embedding and frame semantics. Afterwards, we perform semantic analyses to see how the system can be improved in the future."}, {"heading": "5.1 Experimental Results", "text": "Final results: Table 5.1 shows the best performance of our model and some baselines. Our L2R3http: / / stanfordnlp.github.io / CoreNLP / model finally combines all three types of spacing and semantic characteristics of the frame described in Section 4.2. Our L2R reader exceeds the LSTM-based models proposed in (Hermann et al., 2015) on the CNN dataset and achieves competitive results on the Daily Mail dataset. Different L2R algorithms: Table 4 shows the performance of different learning to rank algorithms by using the same features. Model parameters are matched to the validation set. We found that RankSVM and LambdaMART are two best L2R algorithms for this task. RankSVM performs best on the CNN dataset, while LambdaMART performs best on the Daily Mail dataset."}, {"heading": "5.2 Semantics Analysis", "text": "We also test the performance of our semantic components, which are co-references, word embeddings and frame semantics. Table 7 shows the results of adding co-references, removing word movers and deleting frame antiques. Experimental results show that the co-referencing system does not improve our system and even harms performance, possibly because the co-referencing system (Stanford CoNLP) we use in our system does not perform well when sentences are complicated. We can also conclude from the results that the word embedding and frame semantics components play a crucial role in our system, although the performance of the individual features of frame semantics is quite low."}, {"heading": "5.3 Error Analysis", "text": "In order to give insight into the performance of our system and to show future research directions, we analyze the errors our system has made. We found that many queries require a text summary, event detection, background knowledge and conclusions. We also found an error on the CNN dataset (see Figure 6). We perform some detailed analysis as follows. Figure 6 shows an example of an incorrect answer in the gold standard dataset. It is clear from the query that the correct answer should be holist0, not holist6. Our model successfully gets the correct answer. The error in the dataset could be due to the process of generating the datasets. Figure 7 shows an example of a high-level text summary. The phrases \"within 10 minutes\" and \"nudge\" do not appear in the document, but it is a high-level summary of the document. Therefore, our model lacks the ability to obtain the correct response in such a situation. Figure 8 shows an example of a clock request appearing in the document several times during the request of an event."}, {"heading": "6 Conclusion", "text": "We explored the new task of Cloze-style reading comprehension and developed an L2R reading system to provide a solution. We integrate semantics such as word embedding, frame semantics and correlation resolution into our system and show that they can greatly improve our model performance. We find that our model is poor in terms of high-level text summary, event detection and deduction by error analysis. We will explore how we can solve these kinds of problems in the future by using semantics."}], "references": [{"title": "Learning to rank using gradient descent", "author": ["Burges et al.2005] Chris Burges", "Tal Shaked", "Erin Renshaw", "Ari Lazier", "Matt Deeds", "Nicole Hamilton", "Greg Hullender"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Burges et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Burges et al\\.", "year": 2005}, {"title": "From ranknet to lambdarank to lambdamart: An overview", "author": ["Christopher JC Burges"], "venue": null, "citeRegEx": "Burges.,? \\Q2010\\E", "shortCiteRegEx": "Burges.", "year": 2010}, {"title": "Learning to rank: from pairwise approach to listwise approach", "author": ["Cao et al.2007] Zhe Cao", "Tao Qin", "Tie-Yan Liu", "MingFeng Tsai", "Hang Li"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Cao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2007}, {"title": "An efficient boosting algorithm for combining preferences", "author": ["Freund et al.2003] Yoav Freund", "Raj Iyer", "Robert E Schapire", "Yoram Singer"], "venue": "The Journal of machine learning research,", "citeRegEx": "Freund et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Freund et al\\.", "year": 2003}, {"title": "A short introduction to learning to rank", "author": ["LI Hang"], "venue": "IEICE TRANSACTIONS on Information and Systems,", "citeRegEx": "Hang.,? \\Q2011\\E", "shortCiteRegEx": "Hang.", "year": 2011}, {"title": "Large margin rank boundaries for ordinal regression", "author": ["Thore Graepel", "Klaus Obermayer"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Herbrich et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Herbrich et al\\.", "year": 1999}, {"title": "Teaching machines to read and comprehend", "author": ["Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "From word embeddings to document distances", "author": ["Kusner et al.2015] Matt Kusner", "Yu Sun", "Nicholas Kolkin", "Kilian Q Weinberger"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Kusner et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kusner et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Machine comprehension with discourse relations", "author": ["Narasimhan", "Barzilay2015] Karthik Narasimhan", "Regina Barzilay"], "venue": "In 53rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Narasimhan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Mctest: A challenge dataset for the open-domain machine comprehension of text", "author": ["Christopher JC Burges", "Erin Renshaw"], "venue": "In EMNLP,", "citeRegEx": "Richardson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "Learning answerentailing structures for machine comprehension", "author": ["Avinava Dubey", "Eric P Xing", "Matthew Richardson"], "venue": "In Proceedings of ACL", "citeRegEx": "Sachan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sachan et al\\.", "year": 2015}, {"title": "A strong lexical matching method for the machine comprehension test", "author": ["Smith et al.2015] Ellery Smith", "Nicola Greco", "Matko Bo\u0161njak", "Andreas Vlachos"], "venue": null, "citeRegEx": "Smith et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2015}, {"title": "Cloze procedure: a new tool for measuring readability", "author": ["Wilson L Taylor"], "venue": "Journalism and Mass Communication", "citeRegEx": "Taylor.,? \\Q1953\\E", "shortCiteRegEx": "Taylor.", "year": 1953}, {"title": "A parallel-hierarchical model for machine comprehension on sparse data", "author": ["Zheng Ye", "Xingdi Yuan", "Jing He", "Phillip Bachman", "Kaheer Suleman"], "venue": "arXiv preprint arXiv:1603.08884", "citeRegEx": "Trischler et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Trischler et al\\.", "year": 2016}, {"title": "Adarank: a boosting algorithm for information retrieval", "author": ["Xu", "Li2007] Jun Xu", "Hang Li"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Xu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 6, "context": "(Hermann et al., 2015) therefore release a large scale news article dataset and propose a deep LSTM reader system for machine comprehension.", "startOffset": 0, "endOffset": 22}, {"referenceID": 10, "context": "Based on the released dataset MCTest (Richardson et al., 2013), a lexical matching based method is proposed (Smith et al.", "startOffset": 37, "endOffset": 62}, {"referenceID": 12, "context": ", 2013), a lexical matching based method is proposed (Smith et al., 2015).", "startOffset": 53, "endOffset": 73}, {"referenceID": 11, "context": "Meanwhile, (Sachan et al., 2015) applied similar loss function, modeling machine comprehension as textual entailment and solved the problem by constructing latent answer-entailing structure with an accuracy of 67.", "startOffset": 11, "endOffset": 32}, {"referenceID": 6, "context": "Therefore, our work is based on a much larger news article dataset created by (Hermann et al., 2015).", "startOffset": 78, "endOffset": 100}, {"referenceID": 13, "context": "questions generally generated by removing a phrase from a sentence (Taylor, 1953).", "startOffset": 67, "endOffset": 81}, {"referenceID": 6, "context": "Since the questions can be formed from a short summary of the document with condensed form of paraphrase, the dataset is suitable for testing machine comprehension (Hermann et al., 2015).", "startOffset": 164, "endOffset": 186}, {"referenceID": 6, "context": "Opposed to the deep LSTM (Hermann et al., 2015) that computes the answer based on context information of documents, it is more efficient and does not require much data to reach good performance.", "startOffset": 25, "endOffset": 47}, {"referenceID": 6, "context": "The dataset (Hermann et al., 2015) we used in this task were constructed from news article from CNN and Daily Mail websites.", "startOffset": 12, "endOffset": 34}, {"referenceID": 10, "context": "Machine comprehension generally concentrates on MCTest (Richardson et al., 2013) and due to the limitation of data size, the state of the arts are mainly based on traditional machine learning techniques.", "startOffset": 55, "endOffset": 80}, {"referenceID": 14, "context": "Although recently (Trischler et al., 2016) proposed a parallel-hierarchical model based", "startOffset": 18, "endOffset": 42}, {"referenceID": 6, "context": "Considering the limitations of MCTest dataset, (Hermann et al., 2015) provides a large scale supervised reading comprehension dataset collected from the CNN and Daily Mail websites.", "startOffset": 47, "endOffset": 69}, {"referenceID": 6, "context": "With this dataset, (Hermann et al., 2015) propose a deep LSTM reader that achieves an accuracy of 63.", "startOffset": 19, "endOffset": 41}, {"referenceID": 4, "context": "Generally, it is defined as follows: given a query, the ranking algorithm will generate a list of candidate documents with scores (Hang, 2011).", "startOffset": 130, "endOffset": 142}, {"referenceID": 4, "context": "Pointwise: In the pointwise approach, the ranking algorithm is transformed into problems including classification and regression to derive a score for every pair of document and query (Hang, 2011).", "startOffset": 184, "endOffset": 196}, {"referenceID": 4, "context": "Pairwise: In the pairewise approach, the ranking algorithm is transformed into problems of pairewise classification or pairwise regression (Hang, 2011).", "startOffset": 139, "endOffset": 151}, {"referenceID": 0, "context": "We try approaches including RankNet (Burges et al., 2005), RankBoost (Freund et al.", "startOffset": 36, "endOffset": 57}, {"referenceID": 3, "context": ", 2005), RankBoost (Freund et al., 2003), RankSVM (Herbrich et al.", "startOffset": 19, "endOffset": 40}, {"referenceID": 5, "context": ", 2003), RankSVM (Herbrich et al., 1999), MART and LambdaMART (Burges, 2010)", "startOffset": 17, "endOffset": 40}, {"referenceID": 1, "context": ", 1999), MART and LambdaMART (Burges, 2010)", "startOffset": 29, "endOffset": 43}, {"referenceID": 4, "context": "Listwise: In the listwise approach, the ranking problem is addressed by taking the ranking list as instances in both learning and prediction process (Hang, 2011).", "startOffset": 149, "endOffset": 161}, {"referenceID": 2, "context": "It maintains the group structure and we employ the following listwise approaches: ListNet (Cao et al., 2007), AdaRank (Xu and Li, 2007), Coordinate Ascent.", "startOffset": 90, "endOffset": 108}, {"referenceID": 6, "context": "Frequency is explored based on one baseline of (Hermann et al., 2015).", "startOffset": 47, "endOffset": 69}, {"referenceID": 7, "context": "We investigate word distance from three aspects \u2013 word alignment, nBOW, and word mover\u2019s distance (WMD) (Kusner et al., 2015).", "startOffset": 104, "endOffset": 125}, {"referenceID": 7, "context": "Word Mover\u2019s distance (WMD): The WMD (Kusner et al., 2015) measures the dissimilarity between two text documents using the minimal distance that the embedded words of one document need to move to the embedded words of another document.", "startOffset": 37, "endOffset": 58}, {"referenceID": 8, "context": "Here, we apply WMD into two sentences after using Mikolov\u2019s word2vec (Mikolov et al., 2013) to convert words of sentences to embeddings.", "startOffset": 69, "endOffset": 91}, {"referenceID": 8, "context": "Specifically, word embeddings (Mikolov et al., 2013) project words into a low-dimensional space and similarity of vectors can capture some word similarity on semantics.", "startOffset": 30, "endOffset": 52}, {"referenceID": 8, "context": "Based on the word embedding given by (Mikolov et al., 2013), the WMD can align semantically similar words together using distance measure, for example, it is much cheaper to transform \u201cIllinois\u201d into \u201cChicago\u201d than \u201cJapan\u201d into \u201cChicago\u201d.", "startOffset": 37, "endOffset": 59}, {"referenceID": 6, "context": "We evaluate the L2R reader system by comparing with the baselines of (Hermann et al., 2015).", "startOffset": 69, "endOffset": 91}, {"referenceID": 6, "context": "Our L2R Reader outperforms LSTM-based models proposed in (Hermann et al., 2015) on the CNN dataset and achieves competitive results on the Daily Mail dataset.", "startOffset": 57, "endOffset": 79}], "year": 2017, "abstractText": "Machine comprehension plays an essential role in NLP and has been widely explored with dataset like MCTest. However, this dataset is too simple and too small for learning true reasoning abilities. (Hermann et al., 2015) therefore release a large scale news article dataset and propose a deep LSTM reader system for machine comprehension. However, the training process is expensive. We therefore try feature-engineered approach with semantics on the new dataset to see how traditional machine learning technique and semantics can help with machine comprehension. Meanwhile, our proposed L2R reader system achieves good performance with efficiency and less training data.", "creator": "LaTeX with hyperref package"}}}