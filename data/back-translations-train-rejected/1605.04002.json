{"id": "1605.04002", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2016", "title": "Which Learning Algorithms Can Generalize Identity-Based Rules to Novel Inputs?", "abstract": "We propose a novel framework for the analysis of learning algorithms that allows us to say when such algorithms can and cannot generalize certain patterns from training data to test data. In particular we focus on situations where the rule that must be learned concerns two components of a stimulus being identical. We call such a basis for discrimination an identity-based rule. Identity-based rules have proven to be difficult or impossible for certain types of learning algorithms to acquire from limited datasets. This is in contrast to human behaviour on similar tasks. Here we provide a framework for rigorously establishing which learning algorithms will fail at generalizing identity-based rules to novel stimuli. We use this framework to show that such algorithms are unable to generalize identity-based rules to novel inputs unless trained on virtually all possible inputs. We demonstrate these results computationally with a multilayer feedforward neural network.", "histories": [["v1", "Thu, 12 May 2016 22:42:48 GMT  (164kb,D)", "http://arxiv.org/abs/1605.04002v1", "6 pages, accepted abstract at COGSCI 2016"]], "COMMENTS": "6 pages, accepted abstract at COGSCI 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["paul tupper", "bobak shahriari"], "accepted": false, "id": "1605.04002"}, "pdf": {"name": "1605.04002.pdf", "metadata": {"source": "CRF", "title": "Which Learning Algorithms Can Generalize Identity-Based Rules to Novel Inputs?", "authors": ["Paul Tupper", "Bobak Shahriari"], "emails": ["(pft3@sfu.ca)", "(bshahr@cs.ubc.ca)"], "sections": [{"heading": "Introduction", "text": "In fact, the fact is that most of them are able to assert themselves, that they are able to survive on their own."}, {"heading": "Formal Definitions", "text": "We consider a set of W, which we call W, as a set of words that contain all well-shaped inputs > > AA; < < A > 1) We emphasize that we are in linguis ar class 1: 160 5.04 002v 1 [cs.C L] 12 May 201 6tic case W in fact both words that are good (grammatical) and words that are bad (ungrammatical). (D) What follows is that we find words that we find in the set of all two letters in which the letters are taken from the English alphabet, such as AA or MG.We define the training data D to be a collection of word rating pairs & ltw, r > CC is a word in W and r is a number that is interpreted as rating."}, {"heading": "Identity-Based Rules", "text": "We now use the above result to show that certain algorithms cannot learn identity-based rules if they are not trained on words that contain practically all the letters in the alphabet. That is, the algorithm cannot extend identity-based rules to words that contain letters that it has not been explicitly trained on. This is in sharp contrast to human learners who are able to generalize identity-based rules (in the phonological context, for example) to segments that they have not previously met (Berent et al., 2002).For example, we return to the example at the beginning of the work: W is the sentence of all words that consist of two letters. We specify that grammatical words are those that consist of two identical letters and that all other words are ungrammatic. Let's say we want the algorithm to learn this grammar, but train it on data that do not contain words that will contain the letters that will be able to correct the Y and Z algorithms under the conditions of the grammar."}, {"heading": "Randomized Algorithms", "text": "Many learning algorithms use randomness at some point in their operation. It may be either in the calculation that the input data for the parameters p (for example, in what order the input words are used) is taken from the parameters and a new input word to a word value s in the map. In the first case, p = A (D) is a random function of D; in the second case, s = f (p, w) is a random function of p and w. In both cases, this results in L (D, w) being an expectation for all fixed D and w.Under these conditions, it is unlikely that the inventory of the form described above will persist. Instead, we now define the inventory of L under \u03c3 to beEL (D), \u03c3 (w) = EL (D, w), where E means expectation. (If X is a random variable, EX is roughly what we would get if we take the average of a large number of samples of EL."}, {"heading": "Experiments", "text": "We demonstrate the consequences of our theorems in a computational experiment in which we use a deep neural network to learn the grammar described in our Introduction. Networks are trained on the basis of data in which two-letter words with two identical letters are good and two-letter words with two different letters are bad. The network is then asked to evaluate new words containing segments it has not seen in the training set. Randomness occurs in different places in the training of these networks and so Theorem 2 is the relevant result in this case. Consequently, we do not compare individual training sessions of the network on the novel stimuli. For each novel stimulus, we train the network several times and take the average value over all training sessions. It is these values that are compared between the stimuli."}, {"heading": "Task and Dataset", "text": "Before discussing the learners of the neural network who were tested, we describe the data set and the task they needed. As before, our set of words W consisted of all two letter words with letters running from A to Z. The training set consisted of the 24 words AA, BB,..., XX paired with grading1, along with 48 randomly generated words with non-matching segments from list A,.... X, each with grading 0.In order to evaluate the learner's ability to generalize new entries, we tested it after the training with the words YY, ZZ, XY, YZ, XZ, ZY, where X, A, B,... were randomly selected. For each student, the experiment was independently repeated 40 times with various random sets."}, {"heading": "Neural Network Learners", "text": "We tested our theoretical insights on the most popular model of machine learning literature today: the artificial neural network: the words were fed into the neural network simply by concatenating the two 26-bit codes of their letters; we experimented with many different architectures ranging from one to three hidden layers and from 256 to 1024 units per layer, with tanh nonlinearities prevalent for all hidden units; we trained the models by backward propagation using an iterative quasi-newton gradient descent algorithm called the limited memory method Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) with a maximum of 100 iterations; both the neural network and its optimization are implemented in torches (Collobert, Bengio, & Marie'thoz, 2002)."}, {"heading": "Results", "text": "We present the results in the case that each hidden layer has 256 units, because the results for more units per hidden layer are similar. In Figure 1, for local coding, we plot the average score that the neural network gives for each of the above test words for 1, 2 and 3 hidden layers. In addition, the averaged training values are shown in the two upper bars of each panel. If you look at the top graph in the figure, which shows the results for a hidden layer, the words YY and ZZ get values of about 0.3 as opposed to the score of close to 1 for the well-shaped input AA. The networks are unable to determine that YY and ZZ are grammatical. Similarly, the other test words with different segments and with segments Y or Z show values ranging from about 0.3 to 0.5. The networks are unable to distinguish between grammatical and ungrammatic words in this case."}, {"heading": "Discussion", "text": "That connectionist networks are unable to generalize what is sometimes referred to as \"algebraic\" rules to novel inputs is not a new observation (Marcus, 2003; Berent, 2012).Our contribution was to formally describe and prove this phenomenon. Moreover, our results and computer experiments confirm that deep learning in the form of the ability to form connectionist networks with multiple hidden layers does not overcome these limitations alone."}, {"heading": "Acknowledgments", "text": "The authors thank Nilima Nigam for comments on an earlier draft of this manuscript. PT was supported by an NSERC Discovery Grant, a Research Accelerator Supplement and a Tier II Canada Research Chair. BS was supported by an NSERC Discovery Grant."}], "references": [{"title": "The phonological mind", "author": ["I. Berent"], "venue": null, "citeRegEx": "Berent,? \\Q2012\\E", "shortCiteRegEx": "Berent", "year": 2012}, {"title": "The scope of linguistic generalizations: evidence from Hebrew word formation", "author": ["I. Berent", "G.F. Marcus", "J. Shimron", "A.I. Gafos"], "venue": "Cognition, 83(2),", "citeRegEx": "Berent et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Berent et al\\.", "year": 2002}, {"title": "Modeling OCPplace in Amharic with the Maximum Entropy phonotactic learner", "author": ["R. Colavin", "R. Levy", "S. Rose"], "venue": "In Proceedings volume of the 46th meeting of the Chicago Linguistics Society", "citeRegEx": "Colavin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Colavin et al\\.", "year": 2010}, {"title": "Torch: a modular machine learning software library", "author": ["R. Collobert", "S. Bengio", "J. Mari\u00e9thoz"], "venue": "Technical Report IDIAP-RR", "citeRegEx": "Collobert et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2002}, {"title": "Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks, 3361(10)", "author": ["Y. LeCun", "Y. Bengio"], "venue": null, "citeRegEx": "LeCun and Bengio,? \\Q1995\\E", "shortCiteRegEx": "LeCun and Bengio", "year": 1995}, {"title": "Idempotency and chain shifts", "author": ["G. Magri"], "venue": "Proceedings of WCCFL 33: the 33rd annual West Coast Conference in Formal Linguistics. Cascadilla Proceedings Project", "citeRegEx": "Magri,? \\Q2015\\E", "shortCiteRegEx": "Magri", "year": 2015}, {"title": "The algebraic mind: Integrating connectionism and cognitive science", "author": ["G.F. Marcus"], "venue": null, "citeRegEx": "Marcus,? \\Q2003\\E", "shortCiteRegEx": "Marcus", "year": 2003}, {"title": "Parallel distributed processing (Vol", "author": ["D.E. Rumelhart", "J.L. McClelland"], "venue": null, "citeRegEx": "Rumelhart and McClelland,? \\Q1988\\E", "shortCiteRegEx": "Rumelhart and McClelland", "year": 1988}], "referenceMentions": [{"referenceID": 6, "context": "Such algorithms are unable to generalize \u201coutside the training space\u201d (Marcus, 2003), or \u201cdo not instantiate variables\u201d (Berent, 2012).", "startOffset": 70, "endOffset": 84}, {"referenceID": 0, "context": "Such algorithms are unable to generalize \u201coutside the training space\u201d (Marcus, 2003), or \u201cdo not instantiate variables\u201d (Berent, 2012).", "startOffset": 120, "endOffset": 134}, {"referenceID": 5, "context": "For one thing, most phonological maps satisfy \u03c3(\u03c3(x)) = \u03c3(x) for all x (also known as idempotency (Magri, 2015)).", "startOffset": 98, "endOffset": 111}, {"referenceID": 1, "context": "This is in sharp contrast to human learners who are able to generalize identify-based rules (in the phonological context, for example) to segments they have not encountered before(Berent et al., 2002).", "startOffset": 179, "endOffset": 200}, {"referenceID": 6, "context": "This poor performance is perhaps not surprising for the localist encoding, as observed by Marcus (Marcus, 2003): in the localist encoding, introducing new segments correspond to activating new input units that were never active during training, and therefore whose weights never changed from their random initializations.", "startOffset": 97, "endOffset": 111}, {"referenceID": 6, "context": "That connectionist networks are unable to generalize what are sometimes called \u201calgebraic\u201d rules to novel inputs is not a new observation (Marcus, 2003; Berent, 2012).", "startOffset": 138, "endOffset": 166}, {"referenceID": 0, "context": "That connectionist networks are unable to generalize what are sometimes called \u201calgebraic\u201d rules to novel inputs is not a new observation (Marcus, 2003; Berent, 2012).", "startOffset": 138, "endOffset": 166}], "year": 2016, "abstractText": "We propose a novel framework for the analysis of learning algorithms that allows us to say when such algorithms can and cannot generalize certain patterns from training data to test data. In particular we focus on situations where the rule that must be learned concerns two components of a stimulus being identical. We call such a basis for discrimination an identitybased rule. Identity-based rules have proven to be difficult or impossible for certain types of learning algorithms to acquire from limited datasets. This is in contrast to human behaviour on similar tasks. Here we provide a framework for rigorously establishing which learning algorithms will fail at generalizing identity-based rules to novel stimuli. We use this framework to show that such algorithms are unable to generalize identitybased rules to novel inputs unless trained on virtually all possible inputs. We demonstrate these results computationally with a multilayer feedforward neural network.", "creator": "TeX"}}}