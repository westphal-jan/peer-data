{"id": "1605.04122", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2016", "title": "Natural Language Semantics and Computability", "abstract": "This paper is a reflexion on the computability of natural language semantics. It does not contain a new model or new results in the formal semantics of natural language: it is rather a computational analysis of the logical models and algorithms currently used in natural language semantics, defined as the mapping of a statement to logical formulas - formulas, because a statement can be ambiguous. We argue that as long as possible world semantics is left out, one can compute the semantic representation(s) of a given statement, including aspects of lexical meaning. We also discuss the algorithmic complexity of this process.", "histories": [["v1", "Fri, 13 May 2016 10:46:22 GMT  (37kb,D)", "http://arxiv.org/abs/1605.04122v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.CC", "authors": ["richard moot", "christian retor\\'e"], "accepted": false, "id": "1605.04122"}, "pdf": {"name": "1605.04122.pdf", "metadata": {"source": "CRF", "title": "Natural Language Semantics and Computability", "authors": ["Richard Moot", "Christian Retor\u00e9"], "emails": [], "sections": [{"heading": null, "text": "In the second half of the last decade, when we have to deal with the question of what the future of humanity is like, what the future of humanity is like, what the future of humanity is like, what the future of humanity is like, what the future of humanity is like, what the future of humanity is like, what the future of humanity is like, what the future is like, what the future of humanity is like, what the future is like, what the future is like, what the future is like, what the future is like, what the future is like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like, what the future is going to be like like like like like, what the future is going to be like like like like like like like like like like like like like like like like like like like, what is going to be like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like like, like like like like like like like, like like like like like like like like like like, like like like like like, like like like like like like like like like like like like, like like like like like, like, like like like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like, like,"}, {"heading": "1 Computational semantics a\u0300 la Montague", "text": "We first introduce the general algorithm that assigns logical formulas to sentences, and return to lexical semantics in Section 2. The first step is to compute a syntactical analysis that is sufficiently comprehensive and detailed to allow the calculation of semantics (in the form of logical formulas); the second step is to include the lexical lambda terms and reduce the obtained lambda term - this step may include the selection of some Lambda terms from the lexicon that resolve the type differences."}, {"heading": "1.1 Categorial syntax", "text": "To express the process of assigning a sentence to its semantic interpretation (s) in the form of logical formulas, we start with a categorical grammar. This is not strictly necessary: Montague (1974) used a context-free grammar (extended by a mechanism for the scope of the quantifier), but if you read between the lines, he converts the phrase structure in some places into a categorical derivative so that, according to Moot & Retore (2012), we apply a categorical analysis directly. Although richer variations of categorical grammars are possible and are used in practice, here we give an example with Lambek grammars and briefly comment on the variants later. Categories are freely generated from a series of base categories, for example np (noun phrase), n (common noun), S (sentence), by two binary operators:\\ and /: A\\ B and B / A are categories that form a sequence."}, {"heading": "1.2 From syntactic derivation to typed linear lambda terms", "text": "The categorical derivatives, which represent a correct subset of derivatives in multiplicative intuitionist linear logic, correspond (simply typed) to linear lambda terms. This makes the connection to Montague grammar particularly transparent. (Syntactic type): Characteristic by the set of entities (or individuals) and by the type of propositionnp (these can be either true or false, hence the name t has the following mapping of syntactic categories to semantic / logical types. (Syntactic type): a proposition is a propositionnp (this can be either true or false, hence the name t is an entity n = a subset of syntactic / logical types. (Syntactic type): (A\\ B): (B / A): a proposition is a proposition that easily extends to all syntactic categories."}, {"heading": "2 Adding sorts, coercions, and uniform operations", "text": "Montague (as Frege) used only one type for entities: e. But it is much better to have many species to block the interpretation of some sentences: (1) * The table barked. (2) The dog barked. (3)? The sergeant barked. As dictionaries say, you can say of animals, usually of dogs. The first is correctly rejected: you get a barking dog \u2192 t (the table) artifact and dog 6 = artifact. However, we have to activate the last example bark. (the sergeant) human and in this case we use coercive means (Bassac et al. 2010, Retore \u0301 2014): the lexical entry for the verb \"barked,\" which applies only to the type of \"dogs,\" provides a compulsion c: the dog from \"human\" to \"dog.\""}, {"heading": "3 Complexity of the syntax", "text": "In fact, it is the case that most of them are in a position to move into a different world, in which they are able to move, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they are able to move, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they are able to"}, {"heading": "4 Complexity of the semantics", "text": "The complexity of the syntax discussed in the previous section would explain why even na\u00efve implementations of normalization are only taken into consideration. Whether unreduced lambda terms appear as the meaning of a sentence is very complex, but essentially due to the possibility of recursive copies. Despite this prohibition of the complexity of the worst period, normalization does not seem to be a bottleneck in calculating the meaning for practical applications (Schwichtenberg 1982), largely due to the possibility of recursive copies. Is there a deeper reason for this? We believe that the semantics of natural language uses a limited fragment of the lambda calculation, soft lambda calculation. This calculation limits recursive copying and has been shown to accurately characterize the complexity class P (Lafont 2004, Baillot & Mogbil 2004). This would explain why even naive implementations of normalization work well in practice."}, {"heading": "5 Conclusion", "text": "It is somewhat surprising that, contrary to the well-developed theory of algorithmic complexity of parsing work (less useful is that little is known about semantic analysis, although computer-aided semantics is an active field, since the recurring conferences with the same title show as well as the number of natural language processing applications. In this essay we simply presented remarks on the computational capability and complexity of this process. The good news is that semantics (at least defined as a set of logical formulas) is actually predictable. This was known, but only implicit: Montague gave a series of instructions to calculate the formula (and interpret it in a model), but he never showed that the calculation of such a logical formula (s): - the process he defines stops with a normal Lambda terms of typology (t), - eta-long normal Lambda terms with constants that are either logical connections or constants of a higher order."}], "references": [{"title": "Soft lambda-calculus: a language for polynomial time computation, in \u2018Foundations of software science and computation structures", "author": ["P. Baillot", "V. Mogbil"], "venue": null, "citeRegEx": "Baillot and Mogbil,? \\Q2004\\E", "shortCiteRegEx": "Baillot and Mogbil", "year": 2004}, {"title": "Towards a type-theoretical account of lexical semantics", "author": ["C. Bassac", "B. Mery", "C. Retor\u00e9"], "venue": "Journal of Logic, Language and Information", "citeRegEx": "Bassac et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bassac et al\\.", "year": 2010}, {"title": "Widecoverage semantic representation from a CCG parser, in \u2018Proceedings of COLING2004", "author": ["J. Bos", "S. Clark", "M. Steedman", "J.R. Curran", "J. Hockenmaier"], "venue": null, "citeRegEx": "Bos et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bos et al\\.", "year": 2004}, {"title": "Mathematical linguistics and proof theory", "author": ["W. Buszkowski"], "venue": "eds, \u2018Handbook of Logic and Language\u2019, Elsevier,", "citeRegEx": "Buszkowski,? \\Q1997\\E", "shortCiteRegEx": "Buszkowski", "year": 1997}, {"title": "Quantification and scoping: A deductive account, in \u2018The Proceedings of the 13th West Coast Conference on Formal Linguistics", "author": ["B. Carpenter"], "venue": null, "citeRegEx": "Carpenter,? \\Q1994\\E", "shortCiteRegEx": "Carpenter", "year": 1994}, {"title": "Natural language inference in Coq", "author": ["S. Chatzikyriakidis", "Z. Luo"], "venue": "Journal of Logic, Language and Information", "citeRegEx": "Chatzikyriakidis and Luo,? \\Q2014\\E", "shortCiteRegEx": "Chatzikyriakidis and Luo", "year": 2014}, {"title": "A formulation of the simple theory of types", "author": ["A. Church"], "venue": "Journal of Symbolic Logic", "citeRegEx": "Church,? \\Q1940\\E", "shortCiteRegEx": "Church", "year": 1940}, {"title": "Montague\u2019s Semantic Theory and Transformational Grammar, PhD thesis, University of Massachusetts", "author": ["R. Cooper"], "venue": null, "citeRegEx": "Cooper,? \\Q1975\\E", "shortCiteRegEx": "Cooper", "year": 1975}, {"title": "Cours de s\u00e9mantique: Introduction, Armand Colin", "author": ["F. Corblin"], "venue": null, "citeRegEx": "Corblin,? \\Q2013\\E", "shortCiteRegEx": "Corblin", "year": 2013}, {"title": "Formal Investigations of Underspecified Representations, PhD thesis, King\u2019s College, University of London", "author": ["C. Ebert"], "venue": null, "citeRegEx": "Ebert,? \\Q2005\\E", "shortCiteRegEx": "Ebert", "year": 2005}, {"title": "Expressiveness and complexity in underspecified semantics", "author": ["C. Fox", "S. Lappin"], "venue": "Linguistic Analysis", "citeRegEx": "Fox and Lappin,? \\Q2010\\E", "shortCiteRegEx": "Fox and Lappin", "year": 2010}, {"title": "On the theoretical and practical complexity of TAG parsers, in \u2018Proceedings of Formal Grammar (FG 2006)", "author": ["C. G\u00f3mez-Rodr\u0131\u0301guez", "M.A. Alonso", "M. Vilares"], "venue": null, "citeRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.,? \\Q2006\\E", "shortCiteRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.", "year": 2006}, {"title": "The (dis)organization of the grammar: 25 years", "author": ["P. Jacobson"], "venue": "Linguistics and Philosophy", "citeRegEx": "Jacobson,? \\Q2002\\E", "shortCiteRegEx": "Jacobson", "year": 2002}, {"title": "Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions?, in \u2018Natural Language Parsing", "author": ["A. Joshi"], "venue": null, "citeRegEx": "Joshi,? \\Q1985\\E", "shortCiteRegEx": "Joshi", "year": 1985}, {"title": "Survey of the State of the Art in Human Language Technology", "author": ["A. Joshi"], "venue": "Parsing techniques,", "citeRegEx": "Joshi,? \\Q1997\\E", "shortCiteRegEx": "Joshi", "year": 1997}, {"title": "Soft linear logic and polynomial time", "author": ["Y. Lafont"], "venue": "Theoretical Computer Science", "citeRegEx": "Lafont,? \\Q2004\\E", "shortCiteRegEx": "Lafont", "year": 2004}, {"title": "Cognitive Grammar \u2014 A Basic Introduction", "author": ["R. Langacker"], "venue": null, "citeRegEx": "Langacker,? \\Q2008\\E", "shortCiteRegEx": "Langacker", "year": 2008}, {"title": "Higher-order logical inference with compositional semantics, in \u2018Proceedings of EMNLP", "author": ["K. Mineshima", "P. Mart\u0131nez-G\u00f3mez", "Y. Miyao", "D. Bekki"], "venue": null, "citeRegEx": "Mineshima et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mineshima et al\\.", "year": 2015}, {"title": "The proper treatment of quantification in ordinary English, in R. Thomason, ed., \u2018Formal Philosophy", "author": ["R. Montague"], "venue": null, "citeRegEx": "Montague,? \\Q1974\\E", "shortCiteRegEx": "Montague", "year": 1974}, {"title": "Categorial type logics", "author": ["M. Moortgat"], "venue": "Elsevier/MIT Press,", "citeRegEx": "Moortgat,? \\Q1997\\E", "shortCiteRegEx": "Moortgat", "year": 1997}, {"title": "Proof Nets for Linguistic Analysis", "author": ["R. Moot"], "venue": "PhD thesis,", "citeRegEx": "Moot,? \\Q2002\\E", "shortCiteRegEx": "Moot", "year": 2002}, {"title": "Filtering axiom links for proof nets", "author": ["R. Moot"], "venue": null, "citeRegEx": "Moot,? \\Q2007\\E", "shortCiteRegEx": "Moot", "year": 2007}, {"title": "Wide-coverage French syntax and semantics using Grail, in \u2018Proceedings of Traitement Automatique des Langues Naturelles (TALN)", "author": ["R. Moot"], "venue": null, "citeRegEx": "Moot,? \\Q2010\\E", "shortCiteRegEx": "Moot", "year": 2010}, {"title": "Linear one: A theorem prover for first-order linear logic\u2019, https://github.com/RichardMoot/LinearOne", "author": ["R. Moot"], "venue": null, "citeRegEx": "Moot,? \\Q2015\\E", "shortCiteRegEx": "Moot", "year": 2015}, {"title": "Linguistic applications of first order multiplicative linear logic", "author": ["R. Moot", "M. Piazza"], "venue": "Journal of Logic, Language and Information", "citeRegEx": "Moot and Piazza,? \\Q2001\\E", "shortCiteRegEx": "Moot and Piazza", "year": 2001}, {"title": "The Logic of Categorial Grammars: A Deductive Account of Natural Language Syntax and Semantics, Springer", "author": ["R. Moot", "C. Retor\u00e9"], "venue": null, "citeRegEx": "Moot and Retor\u00e9,? \\Q2012\\E", "shortCiteRegEx": "Moot and Retor\u00e9", "year": 2012}, {"title": "Computational coverage of TLG: The Montague test, in \u2018Proceedings", "author": ["G. Morrill", "O. Valent\u0131\u0301n"], "venue": "CSSP 2015 Le onzie\u0300me Colloque de Syntaxe et Se\u0301mantique a\u0300 Paris\u2019,", "citeRegEx": "Morrill and Valent\u0131\u0301n,? \\Q2015\\E", "shortCiteRegEx": "Morrill and Valent\u0131\u0301n", "year": 2015}, {"title": "The displacement calculus", "author": ["G. Morrill", "O. Valent\u0131\u0301n", "M. Fadda"], "venue": "Journal of Logic, Language and Information", "citeRegEx": "Morrill et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Morrill et al\\.", "year": 2011}, {"title": "Lambek grammars are context free, in \u2018Proceedings of Logic in Computer Science", "author": ["M. Pentus"], "venue": null, "citeRegEx": "Pentus,? \\Q1995\\E", "shortCiteRegEx": "Pentus", "year": 1995}, {"title": "A polynomial-time algorithm for Lambek grammars of bounded order", "author": ["M. Pentus"], "venue": "Linguistic Analysis", "citeRegEx": "Pentus,? \\Q2010\\E", "shortCiteRegEx": "Pentus", "year": 2010}, {"title": "The Language Instinct", "author": ["S. Pinker"], "venue": "Penguin Science", "citeRegEx": "Pinker,? \\Q1994\\E", "shortCiteRegEx": "Pinker", "year": 1994}, {"title": "The Montagovian Generative Lexicon", "author": ["C. Retor\u00e9"], "venue": null, "citeRegEx": "Retor\u00e9,? \\Q2014\\E", "shortCiteRegEx": "Retor\u00e9", "year": 2014}, {"title": "Practical experiments in parsing using tree adjoining grammars, in \u2018Proceeding of TAG+ 5", "author": ["A. Sarkar"], "venue": null, "citeRegEx": "Sarkar,? \\Q2000\\E", "shortCiteRegEx": "Sarkar", "year": 2000}, {"title": "Product-free Lambek calculus is NP-complete, in \u2018Symposium on Logical Foundations of Computer Science (LFCS) 2009", "author": ["Y. Savateev"], "venue": null, "citeRegEx": "Savateev,? \\Q2009\\E", "shortCiteRegEx": "Savateev", "year": 2009}, {"title": "Complexity of normalization in the pure typed lambdacalculus, in \u2018The L", "author": ["H. Schwichtenberg"], "venue": "E. J. Brouwer Centenary Symposium\u2019,", "citeRegEx": "Schwichtenberg,? \\Q1982\\E", "shortCiteRegEx": "Schwichtenberg", "year": 1982}, {"title": "Evidence against the context-freeness of natural language", "author": ["S. Shieber"], "venue": "Linguistics & Philosophy", "citeRegEx": "Shieber,? \\Q1985\\E", "shortCiteRegEx": "Shieber", "year": 1985}, {"title": "Computing machinery and intelligence", "author": ["A. Turing"], "venue": "Mind", "citeRegEx": "Turing,? \\Q1950\\E", "shortCiteRegEx": "Turing", "year": 1950}], "referenceMentions": [{"referenceID": 36, "context": "In the well-known Turing test for artificial intelligence, a human interrogator needs to decide, via a question answering session with two terminals, which of his two interlocutors is a man and which is a machine (Turing 1950).", "startOffset": 213, "endOffset": 226}, {"referenceID": 27, "context": "Actually there are two different views of this cognitive and computational view: one view, promoted by authors such as Pinker (1994), claims that there is a specific cognitive function for language, a \u201clanguage module\u201d in the mind, while others, like Langacker (2008), think that our language faculty is just our general cognitive abilities applied to language.", "startOffset": 119, "endOffset": 133}, {"referenceID": 15, "context": "Actually there are two different views of this cognitive and computational view: one view, promoted by authors such as Pinker (1994), claims that there is a specific cognitive function for language, a \u201clanguage module\u201d in the mind, while others, like Langacker (2008), think that our language faculty is just our general cognitive abilities applied to language.", "startOffset": 251, "endOffset": 268}, {"referenceID": 8, "context": "And, as argued by Corblin (2013), if someone is given a few sentences on a sheet of paper without any further information, he starts imagining situations, may infer other statements from what he reads, .", "startOffset": 18, "endOffset": 33}, {"referenceID": 8, "context": "And, as argued by Corblin (2013), if someone is given a few sentences on a sheet of paper without any further information, he starts imagining situations, may infer other statements from what he reads, . . . , and such thoughts are the semantics of the sentence. \u2013 The linguistic tradition initiated by Montague (1974) lacks some coherence regarding computability.", "startOffset": 18, "endOffset": 319}, {"referenceID": 18, "context": "This is not strictly necessary: Montague (1974) used a context free grammar (augmented with a mechanism for quantifier scope), but if one reads between the lines, at some points he converts the phrase structure into a categorial derivation, so we shall, following Moot & Retor\u00e9 (2012), directly use a categorial analysis.", "startOffset": 32, "endOffset": 48}, {"referenceID": 18, "context": "This is not strictly necessary: Montague (1974) used a context free grammar (augmented with a mechanism for quantifier scope), but if one reads between the lines, at some points he converts the phrase structure into a categorial derivation, so we shall, following Moot & Retor\u00e9 (2012), directly use a categorial analysis.", "startOffset": 32, "endOffset": 285}, {"referenceID": 6, "context": "As observed by Church (1940), the simply typed lambda calculus with two types e and t is enough to express higher order logic, provided one introduces constants for the logical connectives and quantifiers, that is a constants \u201c\u2203\u201d and \u201c\u2200\u201d of type (e\u2192 t)\u2192 t, and constants \u201c\u2227\u201d, \u201c\u2228\u201d et \u201c\u21d2\u201d of type t\u2192 (t\u2192 t).", "startOffset": 15, "endOffset": 29}, {"referenceID": 33, "context": "Perhaps surprisingly, the simple product-free version of the Lambek calculus we have used for our examples is already NP-complete (Savateev 2009).", "startOffset": 130, "endOffset": 145}, {"referenceID": 29, "context": "We know that once we bound the order of formulas in the lexicon of our grammars to be less than a fixed n, parsing becomes polynomial for any choice of n (Pentus 2010)6.", "startOffset": 154, "endOffset": 167}, {"referenceID": 33, "context": "The NP-completeness proof of Savateev (2009) uses a reduction from SAT, where a SAT problem with c clauses and v variables produces a Lambek grammar of order 3+4c, with (2c+1)(3v+1) atomic formulas.", "startOffset": 29, "endOffset": 45}, {"referenceID": 28, "context": "Even though the Lambek calculus is a nice and simple system, we know that the Lambek calculus generates only context-free languages (Pentus 1995), and there is good evidence that at least some constructions in natural language require a slightly larger class of languages (Shieber 1985).", "startOffset": 132, "endOffset": 145}, {"referenceID": 35, "context": "Even though the Lambek calculus is a nice and simple system, we know that the Lambek calculus generates only context-free languages (Pentus 1995), and there is good evidence that at least some constructions in natural language require a slightly larger class of languages (Shieber 1985).", "startOffset": 272, "endOffset": 286}, {"referenceID": 13, "context": "One influential proposal for such a larger class of languages are the mildly context-sensitive languages (Joshi 1985), characterised as follows.", "startOffset": 105, "endOffset": 117}, {"referenceID": 28, "context": "6 For the algorithm of Pentus (2010), the order appears as an exponent in the worst-case complexity: for a grammar of order n there is a multiplicative factor of 25(n+1).", "startOffset": 23, "endOffset": 37}, {"referenceID": 19, "context": "Though Moot (2002) shows that multimodal categorial grammars generate exactly the contextsensitive languages, Buszkowski (1997) underlines the difficulty of adapting the result of Pentus (1995) to extensions of the Lambek calculus8.", "startOffset": 7, "endOffset": 19}, {"referenceID": 3, "context": "Though Moot (2002) shows that multimodal categorial grammars generate exactly the contextsensitive languages, Buszkowski (1997) underlines the difficulty of adapting the result of Pentus (1995) to extensions of the Lambek calculus8.", "startOffset": 110, "endOffset": 128}, {"referenceID": 3, "context": "Though Moot (2002) shows that multimodal categorial grammars generate exactly the contextsensitive languages, Buszkowski (1997) underlines the difficulty of adapting the result of Pentus (1995) to extensions of the Lambek calculus8.", "startOffset": 110, "endOffset": 194}, {"referenceID": 18, "context": "Although the standard notion of complexity for categorial grammars is the complexity deciding whether or not a proof exists, formal semanticists, at least since Montague (1974), want their formalisms to generate all and only the correct readings for a sentence: we are not only interested in whether or not a proof exists but, since different natural deduction proofs correspond to different readings, also in what the different proofs of a sentence are9.", "startOffset": 161, "endOffset": 177}, {"referenceID": 19, "context": "Extensions/variations of the Lambek calculus \u2014 which include multimodal categorial grammars (Moortgat 1997), the Displacement calculus (Morrill et al.", "startOffset": 92, "endOffset": 107}, {"referenceID": 27, "context": "Extensions/variations of the Lambek calculus \u2014 which include multimodal categorial grammars (Moortgat 1997), the Displacement calculus (Morrill et al. 2011) and firstorder linear logic (Moot & Piazza 2001) \u2014 solve both the problems of formal language theory and the problems of the syntax-semantics interface.", "startOffset": 135, "endOffset": 156}, {"referenceID": 4, "context": "Carpenter (1994) gives many examples of the advantages of this logical approach to scope, notably its interaction with other semantic phenomena like negation and coordination.", "startOffset": 0, "endOffset": 17}, {"referenceID": 20, "context": "Though these modern calculi solve the problems with the Lambek calculus, they do so without excessively increasing the computational complexity of the formalism: multimodal categorial grammars are PSPACE complete (Moot 2002), whereas most other extensions are NP-complete, like the Lambek calculus.", "startOffset": 213, "endOffset": 224}, {"referenceID": 7, "context": "Cooper storage, (Cooper 1975)), or 2) an underspecification mechanism for representing quantifier scope (Fox & Lappin 2010).", "startOffset": 16, "endOffset": 29}, {"referenceID": 7, "context": "For case 1 (Cooper 1975), a single syntactic structure is converted into up to n! semantic readings, whereas for case 2, though we represent all possible readings in a single structure, even deciding whether the given sentence has a semantic reading at all becomes NP-complete (Fox & Lappin 2010), hence we simply shift the NP-completeness from the syntax to the syntax-semantics interface11.", "startOffset": 11, "endOffset": 24}, {"referenceID": 9, "context": "11 In addition, Ebert (2005) argues that underspecification languages are not expressive enough", "startOffset": 16, "endOffset": 29}, {"referenceID": 21, "context": "It is rather easy to set up a categorial grammar parser in such a way that it produces underspecified representations in time proportional to n2 (Moot 2007).", "startOffset": 145, "endOffset": 156}, {"referenceID": 4, "context": "We believe, following Carpenter (1994) and Jacobson (2002), that giving an integrated account of the various aspects of the syntax-semantics interface is the most promising path.", "startOffset": 22, "endOffset": 39}, {"referenceID": 4, "context": "We believe, following Carpenter (1994) and Jacobson (2002), that giving an integrated account of the various aspects of the syntax-semantics interface is the most promising path.", "startOffset": 22, "endOffset": 59}, {"referenceID": 34, "context": "Even in the standard, simply typed Montagovian framework, normalizing lambda terms is known to be of non-elementary complexity (Schwichtenberg 1982), essentially due to the possibility of recursive copying.", "startOffset": 127, "endOffset": 148}, {"referenceID": 15, "context": "However, the system of Lafont (2004) includes second-order quantifiers hence reduction stays polynomial once coercions have been chosen.", "startOffset": 23, "endOffset": 37}, {"referenceID": 6, "context": "\u2013 the process he defined stops with a normal lambda terms of type proposition (t), \u2013 eta-long normal lambda terms with constants being either logical connectives or constants of a first (or higher order) logical language are in bijective correspondence with formulas of this logical language (this is more or less clear in the work of Church (1940) on simple type theory).", "startOffset": 335, "endOffset": 349}, {"referenceID": 34, "context": "\u2013 the complexity of the whole process has a known complexity class, in particular the beta-reduction steps which was only discovered years after his death (Schwichtenberg 1982).", "startOffset": 155, "endOffset": 176}], "year": 2016, "abstractText": "This paper is a reflexion on the computability of natural language semantics. It does not contain a new model or new results in the formal semantics of natural language: it is rather a computational analysis of the logical models and algorithms currently used in natural language semantics, defined as the mapping of a statement to logical formulas \u2014 formulas, because a statement can be ambiguous. We argue that as long as possible world semantics is left out, one can compute the semantic representation(s) of a given statement, including aspects of lexical meaning. We also discuss the algorithmic complexity of this process.", "creator": "TeX"}}}