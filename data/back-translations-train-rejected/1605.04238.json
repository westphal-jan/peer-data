{"id": "1605.04238", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2016", "title": "Semantic Spaces", "abstract": "Any natural language can be considered as a tool for producing large databases (consisting of texts, written, or discursive). This tool for its description in turn requires other large databases (dictionaries, grammars etc.). Nowadays, the notion of database is associated with computer processing and computer memory. However, a natural language resides also in human brains and functions in human communication, from interpersonal to intergenerational one. We discuss in this survey/research paper mathematical, in particular geometric, constructions, which help to bridge these two worlds. In particular, in this paper we consider the Vector Space Model of semantics based on frequency matrices, as used in Natural Language Processing. We investigate underlying geometries, formulated in terms of Grassmannians, projective spaces, and flag varieties. We formulate the relation between vector space models and semantic spaces based on semic axes in terms of projectability of subvarieties in Grassmannians and projective spaces. We interpret Latent Semantics as a geometric flow on Grassmannians. We also discuss how to formulate G\\\"ardenfors' notion of \"meeting of minds\" in our geometric setting.", "histories": [["v1", "Fri, 13 May 2016 16:25:38 GMT  (112kb)", "http://arxiv.org/abs/1605.04238v1", "32 pages, TeX, 1 eps figure"]], "COMMENTS": "32 pages, TeX, 1 eps figure", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yuri manin", "matilde marcolli"], "accepted": false, "id": "1605.04238"}, "pdf": {"name": "1605.04238.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Yuri I. Manin", "Matilde Marcolli"], "emails": [], "sections": [{"heading": null, "text": "A system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system, a system,"}, {"heading": "2. Vector Space Models of semantics", "text": "This year it will be able to mention the aforementioned brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated csrteBnlrc\u00fce."}, {"heading": "3. Projective Spaces and Flag Varieties", "text": "We describe here two variants of the construction aimed at a more explicit encoding than the fact that a linguistic text has an ordered linear structure, which is crucial for its semantic interpretation. We propose two modifications of the geometry described above, which better encode this fact. It is based on a text divided into contexts, as a collection of points that determine a path in a projective space, rather than as a single point in a grassmannian. The second is in relation to points in a flag variety.3.1. Here again, we consider the case in which we have some fixed large vocabularies of size M = # D, which contain at least all the words in the given text T. We also subdivide the text into contexts, as before, but we do not necessarily assume that the total number of contexts is less than M."}, {"heading": "4. From Lexemes to Semantic Dictionaries", "text": "We are looking at a setting in which one cannot directly identify the corresponding categories, but nevertheless can achieve a meaningful distinction. \"We are starting from a\" semantic dictionary \"that we share. (a) We are starting from a\" semantic dictionary \"in which lexems are summarized. (a) We are looking at the nature of the question we are looking at to what extent the information contained in the semantic vectors is still contained in the semantic vocabularies as correct information when it is led to a quotient that corresponds to identification by semantic categories. (b) We are assuming that the sense tags are not assigned, so that one can directly identify the corresponding semantic categories, but still achieve a meaningful distinction.\""}, {"heading": "5. Geodesically convex neighborhoods and semantic spaces", "text": "In the utopia of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, of utopia, utopia, of utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, utopia, ut"}, {"heading": "5.2. Geodesically convex neighborhoods, C\u030cech complexes, and neural", "text": "This year, it has come to the point where it will be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be to be able to be able to be able to be able to be to be to be able to be to be able to be able to be to be able to be to be able to be to be to be able to be to be to be able to be able to be able to be to be able to be to be to be to be to be able to be to be able to be to be to be able to be to be to be to be to be able to be to be to be able to be to be to be to be to be to be able to be to be to be able to be able to be able to be to be to be to be able to be to be to be to be to be to be able to be to be to be to be to be to be able to be to be to be to be to be to be to be to be able to be to be to be to be to be able to be to be to be to be to be to be to be able to be to be to be to be to be to be to be to be to be able to be to be to be to be to be to be to be able to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be"}, {"heading": "6. Spectral decompositions and Riccati flows", "text": "It is known that this causes problems in measuring the semantic similarity with the usual cosmic method (see [TuPa10]), since the method easily assigns words that do not occur together, even though they are semantically related to each other. To work around this problem, a dimensional reduction can be performed on the basis of a singular value decomposition (SVD), which represents the semantic matrix P as a product in which U and V are related to each other, and M \u00b7 M and a N \u00b7 N unitary matrix is a N \u00b7 M matrix with the singular values, rank r equal to the rank of the original semantic matrix. 6.2. The technique known as \"latent semantics.\""}, {"heading": "7. Relation to Ga\u0308rdenfors\u2019 \u201cmeeting of minds\u201d", "text": "In our attitude, the geometry of the spaces is not dictated by external categories. [Ga \ufffd fors] has developed an approach to semantic spaces based on the metaphor \"meeting of spirits\" (see [Ga \ufffd 13]) and on models of \"conceptual spaces\" developed in [Ga \ufffd 00]. The main idea is that meaning arises in communication (see Section 5.1 of [Ga \ufffd 14]). Communication is modeled in relation to a division of this domain determined by the transmitter and a number of points in the received domain, and the common understanding is achieved by constructing a voronoi partition, the two sections 5.4.1 of [Ga \ufffd 14]."}, {"heading": "8. Semantic vectors, Zipf\u2019s law, and Kolmogorov complexity", "text": "This year it has come to the point that it has never come as far as this year."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Any natural language can be considered as a tool for producing<lb>large databases (consisting of texts, written, or discursive). This tool for its descrip-<lb>tion in turn requires other large databases (dictionaries, grammars etc.). Nowadays,<lb>the notion of database is associated with computer processing and computer mem-<lb>ory. However, a natural language resides also in human brains and functions in<lb>human communication, from interpersonal to intergenerational one. We discuss in<lb>this survey/research paper mathematical, in particular geometric, constructions,<lb>which help to bridge these two worlds. In particular, in this paper we consider the<lb>Vector Space Model of semantics based on frequency matrices, as used in Natural<lb>Language Processing. We investigate underlying geometries, formulated in terms<lb>of Grassmannians, projective spaces, and flag varieties. We formulate the relation<lb>between vector space models and semantic spaces based on semic axes in terms of<lb>projectability of subvarieties in Grassmannians and projective spaces. We interpret<lb>Latent Semantics as a geometric flow on Grassmannians. We also discuss how to<lb>formulate G\u00e4rdenfors\u2019 notion of \u201cmeeting of minds\u201d in our geometric setting. O INTERIOR DO EXTERIOR DO INTERIOR Pascal Mercier<lb>\u201cNachtzug nach Lissabon\u201d", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}