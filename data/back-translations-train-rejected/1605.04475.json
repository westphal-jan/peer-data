{"id": "1605.04475", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2016", "title": "Capturing divergence in dependency trees to improve syntactic projection", "abstract": "Obtaining syntactic parses is a crucial part of many NLP pipelines. However, most of the world's languages do not have large amounts of syntactically annotated corpora available for building parsers. Syntactic projection techniques attempt to address this issue by using parallel corpora consisting of resource-poor and resource-rich language pairs, taking advantage of a parser for the resource-rich language and word alignment between the languages to project the parses onto the data for the resource-poor language. These projection methods can suffer, however, when the two languages are divergent. In this paper, we investigate the possibility of using small, parallel, annotated corpora to automatically detect divergent structural patterns between two languages. These patterns can then be used to improve structural projection algorithms, allowing for better performing NLP tools for resource-poor languages, in particular those that may not have large amounts of annotated data necessary for traditional, fully-supervised methods. While this detection process is not exhaustive, we demonstrate that common patterns of divergence can be identified automatically without prior knowledge of a given language pair, and the patterns can be used to improve performance of projection algorithms.", "histories": [["v1", "Sat, 14 May 2016 22:11:07 GMT  (864kb,D)", "http://arxiv.org/abs/1605.04475v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ryan georgi", "fei xia", "william d lewis"], "accepted": false, "id": "1605.04475"}, "pdf": {"name": "1605.04475.pdf", "metadata": {"source": "CRF", "title": "Measuring Divergence in Dependency Trees to Improve Projection Algorithms", "authors": ["Ryan Georgi", "Fei Xia", "William D. Lewis"], "emails": ["rgeorgi@uw.edu", "fxia@uw.edu", "wilewis@microsoft.com"], "sections": [{"heading": null, "text": "Keywords Multilingualism \u00b7 Translation Divergence \u00b7 Syntactic ProjectionR. Georgi F. Xia University of Washington Department of Linguistics Box 354340 Seattle, WA 98195-4340 Tel.: + 1 (206) 543-2046 Fax: + 1 (206) 685-7978 Email: rgeorgi @ uw.edu Email: fxia @ uw.eduW. D. Lewis Microsoft Research, Bldg 99 14820 NE 36th St, Redmond, WA 98052-6399 Email: wilewis @ microsoft.comar Xiv: 160 5.04 475v 1 [cs.C L] 14 May 201 6"}, {"heading": "1 Introduction", "text": "When it comes to resources for natural language processing, a small handful of languages account for the vast majority of available resources. Of the resources listed on the LRE map (Calzolari et al., 2012), 30% of all recorded resources are in English, and 62% of all resources are accounted for by the ten languages with the most resources. A wide range of tools is available for these resource-rich languages because the time and effort required to annotate resources for these languages makes it possible to build state-of-the-art systems that use monitored and semi-monitored methods. The availability of such resources is the result of a major investment over many years on a linguistic basis. As the creation of high-quality annotations is expensive and labor-intensive, the vast majority of languages lack such resources and powerful NLP tools. To address this problem, recent studies (Lewis and Xia, 2008; Benajiba and Zitouni, 2010; Georgi, 2012; and Bitgi, 2012) are sufficient."}, {"heading": "2 Background", "text": "This year, it has reached the stage where it will be able to put itself at the forefront in order to pave the way for the future."}, {"heading": "3 Methodology", "text": "In our approach to the automatic detection of different structures between the languages, which we are first able to measure the number of trees, which we are able to hide in a position, and which are able to hide themselves in a position, in which they are able, in which they are able, in which they are able to hide themselves in a position, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they are in which they are able, in which they are able, in which they are in which they are able, in which they are able, in which they are able, in which they are in which they are able, in which they are in which they are able, in which they are in which they are able, in which they are in which they are able, in which they are able, in which they are able, in which they are in which they are in which they are in which they are able, in which they are able, in which they are in which they are able, in which they are in which they are able, in which they are in which they are in which they are able, in which they are in which they are able, in which they are in which they are in which they are in which they are able, in which they are in which they are able, in which they are in which they are in which they are able, in which they are in which they are able, in which they are in which they are in which they are in which they are in which they are in which they are"}, {"heading": "O1 \u2013 Remove", "text": "As shown in Figure 5 (a), the removal of node l is achieved by removing the connection between node l and its parent, j, and adding connections between the parent and the children of the remote node. This result of this operation looks like this in Figure 5 (a) by using the relationship children, which maps a word to the set of all its children in the tree. 1 Algorithm: Remove (w, T) Input: T = {(wi, wj)... (wm, wn)}; / / Input treeInput: w; / / Word to remove. Output: T \u2032; / / Modified tree 2 begin 3 T \u2032 = T \u2212 {(w, wi) | wi = Parent (w, T)} / / Remove edge between w and parent wi4 \u2212 (wj, w) | w = Parent (wj, T)} / Remove edges for parent (w, T)."}, {"heading": "O2 \u2013 Merge", "text": "The merge process is used when a node and some or all of its children in one tree are aligned to the same node in the other tree as shown in Figure 4 (b). The parent node j and child l are merged into a merged node, as indicated in Figure 5 (b) by l + j, and the children of l become children of the new node l + j. The result is in Figure 5 (b).1 Algorithm: Merge (wc, wp, T) Input: T = {(wi, wj). (wm, wn)}; / / Input treeInput: wc; / / Child word to merge. Input: wp; / / Parent word to merge.Output: T \u2032; / / Modified tree 2 begin 3 T \u2032 = T \u2212 {(wi, wp)} 4 \u2212 {(wi, wc) | wc = Parent (wi, T} Child and wc. \""}, {"heading": "O3 \u2013 Swap", "text": "The swap operation is used when two nodes in a tree are aligned to two nodes in the other tree. / / The swap operation is used when two nodes in a tree are aligned to two nodes in the other tree. / / The swap operation can be used to handle certain types of deviations such as demotional and promotional deviations. / The swap operation is described in more detail in \u00a7 3.4.Figure 5 (c) how the swap operation takes place by degrading the swap nodes l and j-node 1, the former parent will be degraded and its attachment to its children will be maintained, and its children will become siblings of the node. / / / The results of this swap operation can be seen in Figure 5 (c)."}, {"heading": "4 Experiments", "text": "This year it is more than ever before in the history of the city."}, {"heading": "5 Discussion of Results", "text": "In fact, it is the case that one is able to put oneself at the top of society in the way that one puts oneself at the top of society."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we have shown that this method can be used to detect similarities between languages at the course level, as well as to serve as a general measure of the similarity between dependency corpora. Finally, we have shown that the use of these detection methods has potential for improving projection algorithms with little or no expert involvement. This work further shows that there is still much room for improvement in existing projection methods. In future work, we plan to explore further ways to learn rules for post-processing in projected trees, such as the correct correction of 1-to-many alignments and methods for re-attaching spontaneous words in the foreign language. In future work, we also plan to investigate how labeled dependency margins can play a role in describing divergences between languages, and how they could be statistically better corrected."}], "references": [{"title": "Enhancing mention detection using projection via aligned corpora", "author": ["Yassine Benajiba", "Imed Zitouni"], "venue": "In 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Benajiba and Zitouni.,? \\Q2010\\E", "shortCiteRegEx": "Benajiba and Zitouni.", "year": 2010}, {"title": "A multi-representational and multilayered treebank for Hindi/Urdu. In The Third Linguistic Annotation Workshop (The LAW III) in conjunction with ACL/IJCNLP", "author": ["Rajesh Bhatt", "Bhuvana Narasimhan", "Martha Palmer", "Owen Rambow", "Dipti Misra Sharma", "Fei Xia"], "venue": null, "citeRegEx": "Bhatt et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bhatt et al\\.", "year": 2009}, {"title": "A statistical approach to machine translation", "author": ["Peter F Brown", "John Cocke", "Stephen A Della Pietra", "Vincent J Della Pietra", "Fredrick Jelinek", "John D Lafferty", "Robert L Mercer", "Paul S Roossin"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1990}, {"title": "The LRE Map. Harmonising Community Descriptions of Resources", "author": ["Nicoletta Calzolari", "Riccardo Del Gratta", "Gil Francopoulo", "Joseph Mariani", "Francesco Rubino", "Irene Russo", "Claudia Soria"], "venue": "In LREC (International Conference on Language Resources and Evaluation),", "citeRegEx": "Calzolari et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Calzolari et al\\.", "year": 2012}, {"title": "Head-driven statistical models for natural language parsing", "author": ["Michael Collins"], "venue": "PhD thesis, University of Pennsylvania,", "citeRegEx": "Collins.,? \\Q1999\\E", "shortCiteRegEx": "Collins.", "year": 1999}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["Marie-Catherine de Marneffe", "Bill MacCartney", "Christopher D Manning"], "venue": "In Proceedings of LREC", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Machine translation divergences: a formal description and proposed solution", "author": ["Bonnie Jean Dorr"], "venue": "Computational Linguistics,", "citeRegEx": "Dorr.,? \\Q1994\\E", "shortCiteRegEx": "Dorr.", "year": 1994}, {"title": "Evaluating translational correspondence using annotation projection", "author": ["Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Okan Kolak"], "venue": "In Proceedings of ACL", "citeRegEx": "Hwa et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Hwa et al\\.", "year": 2002}, {"title": "Bootstrapping parsers via syntactic projection across parallel texts", "author": ["Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak"], "venue": "Natural Language Engineering,", "citeRegEx": "Hwa et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hwa et al\\.", "year": 2004}, {"title": "ODIN: A model for adapting and enriching legacy infrastructure", "author": ["William D Lewis"], "venue": "In e-Science", "citeRegEx": "Lewis.,? \\Q2006\\E", "shortCiteRegEx": "Lewis.", "year": 2006}, {"title": "Automatically identifying computationally relevant typological features", "author": ["William D Lewis", "Fei Xia"], "venue": "In Proceedings of IJCNLP", "citeRegEx": "Lewis and Xia.,? \\Q2008\\E", "shortCiteRegEx": "Lewis and Xia.", "year": 2008}, {"title": "A universal part-of-speech tagset", "author": ["Slav Petrov", "Dipanjan Das", "Ryan McDonald"], "venue": "In Proceedings of LREC,", "citeRegEx": "Petrov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "SMULTRON (version 3.0) \u2014 The Stockholm MULtilingual parallel TReebank, 2010. URL http://www.cl.uzh.ch/research/paralleltreebanks/ smultron_en.html. An English-French-German-Spanish-Swedish parallel treebank with sub-sentential alignments", "author": ["Martin Volk", "Anne G\u00f6hring", "Torsten Marek", "Yvonne Samuelsson"], "venue": null, "citeRegEx": "Volk et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Volk et al\\.", "year": 2010}, {"title": "Multilingual structural projection across interlinear text", "author": ["Fei Xia", "William D Lewis"], "venue": "In Human Language Technologies:", "citeRegEx": "Xia and Lewis.,? \\Q2007\\E", "shortCiteRegEx": "Xia and Lewis.", "year": 2007}, {"title": "Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora", "author": ["David Yarowsky", "Grace Ngai"], "venue": "In Proceedings of NAACL, Stroudsburg, PA,", "citeRegEx": "Yarowsky and Ngai.,? \\Q2001\\E", "shortCiteRegEx": "Yarowsky and Ngai.", "year": 2001}], "referenceMentions": [{"referenceID": 3, "context": "Out of the resources listed by the LRE Map (Calzolari et al., 2012), English accounts for 30% of all recorded resources, and the ten most resourced languages for 62% of all resources.", "startOffset": 43, "endOffset": 67}, {"referenceID": 10, "context": "To address this issue, recent studies (Lewis and Xia, 2008; Benajiba and Zitouni, 2010; Georgi et al., 2012) have proposed to take advantage of bitext and resources for resource-rich languages; that is, use tools for resource-rich languages to process one side of bitext (the resource-rich language) and project the information to the other side of bitext (the resource-poor language) via word alignments.", "startOffset": 38, "endOffset": 108}, {"referenceID": 0, "context": "To address this issue, recent studies (Lewis and Xia, 2008; Benajiba and Zitouni, 2010; Georgi et al., 2012) have proposed to take advantage of bitext and resources for resource-rich languages; that is, use tools for resource-rich languages to process one side of bitext (the resource-rich language) and project the information to the other side of bitext (the resource-poor language) via word alignments.", "startOffset": 38, "endOffset": 108}, {"referenceID": 12, "context": "3 Simple but frequent example of 1-to-many German\u2013English alignment found in the Sophie\u2019s World portion of the SMULTRON corpus (Volk et al., 2010).", "startOffset": 127, "endOffset": 146}, {"referenceID": 2, "context": "Here, the authors used IBM Model 3 (Brown et al., 1990) to align large parallel corpora between English\u2013Chinese and English\u2013French.", "startOffset": 35, "endOffset": 55}, {"referenceID": 13, "context": "Some of the initial research on the subject of projecting word-level annotation from one language to another was published in Yarowsky and Ngai (2001). Here, the authors used IBM Model 3 (Brown et al.", "startOffset": 126, "endOffset": 151}, {"referenceID": 12, "context": "3 shows a very simple but common case of conflation in the SMULTRON corpus (Volk et al., 2010) where a single German word aligns to multiple English words.", "startOffset": 75, "endOffset": 94}, {"referenceID": 11, "context": "In this case, using a universal tagset such as those presented by Petrov et al. (2012) could help alleviate the problem, but for more complex cases, learning the pattern would be more critical.", "startOffset": 66, "endOffset": 87}, {"referenceID": 9, "context": "In Xia and Lewis (2007), enriched IGT data for 7 language pairs was created using this augmented alignment and structural projection, then handcorrected to create gold standards with minimal expert intervention.", "startOffset": 11, "endOffset": 24}, {"referenceID": 9, "context": "In Xia and Lewis (2007), enriched IGT data for 7 language pairs was created using this augmented alignment and structural projection, then handcorrected to create gold standards with minimal expert intervention. They showed the potential for using IGT as a resource for languages for which finding resources would otherwise be extremely difficult or impossible to obtain. We will use this data for the current work. A breakdown of the language pairs can be seen in \u00a74.1. Lewis and Xia (2008) used projected phrase structures to determine the basic word order for 97 languages using a database of IGT instances.", "startOffset": 11, "endOffset": 492}, {"referenceID": 6, "context": "\u2019s Direct Correspondence Assumption (DCA) describes the assumption made for projection, Dorr (1994) makes a deeper analysis of divergence in languages.", "startOffset": 88, "endOffset": 100}, {"referenceID": 6, "context": "4 Relationship to Dorr (1994)", "startOffset": 18, "endOffset": 30}, {"referenceID": 6, "context": "6 An example of promotional divergence from Dorr (1994). The reverse in parent-child relation is handled by the Swap operation.", "startOffset": 44, "endOffset": 56}, {"referenceID": 7, "context": "Using the techniques described above, and following Hwa et al. (2004), we can find post-processing rules automatically.", "startOffset": 52, "endOffset": 70}, {"referenceID": 12, "context": "The corpora used are the SMULTRON treebank (Volk et al., 2010), the guideline sentences in IGT form from the Hindi treebank (Bhatt et al.", "startOffset": 43, "endOffset": 62}, {"referenceID": 1, "context": ", 2010), the guideline sentences in IGT form from the Hindi treebank (Bhatt et al., 2009), and several sets of IGT data as used in (Xia and Lewis, 2007).", "startOffset": 69, "endOffset": 89}, {"referenceID": 13, "context": ", 2009), and several sets of IGT data as used in (Xia and Lewis, 2007).", "startOffset": 49, "endOffset": 70}, {"referenceID": 4, "context": "The English side of the phrase structures do not contain edge labels and are instead converted to dependency trees using a head percolation table (Collins, 1999).", "startOffset": 146, "endOffset": 161}, {"referenceID": 1, "context": ", 2010), the guideline sentences in IGT form from the Hindi treebank (Bhatt et al., 2009), and several sets of IGT data as used in (Xia and Lewis, 2007). The statistics of the corpora are shown in Table 1. Ten of the language pairs use English as one side of the language, while the eleventh uses the pair of German and Swedish from the SMULTRON corpus. In the SMULTRON Treebank, the German and Swedish phrase trees are marked for head children, allowing for the automatic extraction of dependency trees. The English side of the phrase structures do not contain edge labels and are instead converted to dependency trees using a head percolation table (Collins, 1999). From the Hindi Treebank guidelines, we extracted example sentences in the form of IGT (i.e., Hindi sentences, English gloss, and English translation) and the Hindi dependency structures manually created by the guideline designers. We obtained dependency structures for the English translation by running the Stanford dependency parser de Marneffe et al. (2006) and then we hand corrected the structures.", "startOffset": 70, "endOffset": 1029}, {"referenceID": 1, "context": ", 2010), the guideline sentences in IGT form from the Hindi treebank (Bhatt et al., 2009), and several sets of IGT data as used in (Xia and Lewis, 2007). The statistics of the corpora are shown in Table 1. Ten of the language pairs use English as one side of the language, while the eleventh uses the pair of German and Swedish from the SMULTRON corpus. In the SMULTRON Treebank, the German and Swedish phrase trees are marked for head children, allowing for the automatic extraction of dependency trees. The English side of the phrase structures do not contain edge labels and are instead converted to dependency trees using a head percolation table (Collins, 1999). From the Hindi Treebank guidelines, we extracted example sentences in the form of IGT (i.e., Hindi sentences, English gloss, and English translation) and the Hindi dependency structures manually created by the guideline designers. We obtained dependency structures for the English translation by running the Stanford dependency parser de Marneffe et al. (2006) and then we hand corrected the structures. Word alignment is initially derived from the IGT instances using heuristic alignment following Xia and Lewis (2007), and later hand-corrected.", "startOffset": 70, "endOffset": 1188}, {"referenceID": 1, "context": ", 2010), the guideline sentences in IGT form from the Hindi treebank (Bhatt et al., 2009), and several sets of IGT data as used in (Xia and Lewis, 2007). The statistics of the corpora are shown in Table 1. Ten of the language pairs use English as one side of the language, while the eleventh uses the pair of German and Swedish from the SMULTRON corpus. In the SMULTRON Treebank, the German and Swedish phrase trees are marked for head children, allowing for the automatic extraction of dependency trees. The English side of the phrase structures do not contain edge labels and are instead converted to dependency trees using a head percolation table (Collins, 1999). From the Hindi Treebank guidelines, we extracted example sentences in the form of IGT (i.e., Hindi sentences, English gloss, and English translation) and the Hindi dependency structures manually created by the guideline designers. We obtained dependency structures for the English translation by running the Stanford dependency parser de Marneffe et al. (2006) and then we hand corrected the structures. Word alignment is initially derived from the IGT instances using heuristic alignment following Xia and Lewis (2007), and later hand-corrected. The IGT data from Xia and Lewis (2007) was obtained in the manually corrected dependency forms described in \u00a72.", "startOffset": 70, "endOffset": 1254}, {"referenceID": 9, "context": "While the size of the data sets used here are very small, and the ODIN IGT data may be biased towards illustrative purposes (described as the \u201cIGT Bias\u201d in Xia and Lewis (2007)), it would appear that these results illustrate that the match detection is capable of two interesting corpus analyses.", "startOffset": 164, "endOffset": 177}, {"referenceID": 14, "context": "While this example focuses only on the easily correctable swap operation, the success here suggests that a similar analysis of the merge operations could be used to correct the 1-to-many projections from English onto other languages that Yarowsky and Ngai (2001) cited as problematic.", "startOffset": 238, "endOffset": 263}, {"referenceID": 9, "context": "Creating dependency annotation on a small set of data from a source like ODIN (Lewis, 2006) can get a lot of mileage with a small amount of investment.", "startOffset": 78, "endOffset": 91}], "year": 2016, "abstractText": "Obtaining syntactic parses is a crucial part of many NLP pipelines. However, most of the world\u2019s languages do not have large amounts of syntactically annotated corpora available for building parsers. Syntactic projection techniques attempt to address this issue by using parallel corpora consisting of resource-poor and resource-rich language pairs, taking advantage of a parser for the resource-rich language and word alignment between the languages to project the parses onto the data for the resource-poor language. These projection methods can suffer, however, when the two languages are divergent. In this paper, we investigate the possibility of using small, parallel, annotated corpora to automatically detect divergent structural patterns between two languages. These patterns can then be used to improve structural projection algorithms, allowing for better performing NLP tools for resource-poor languages, in particular those that may not have large amounts of annotated data necessary for traditional, fully-supervised methods. While this detection process is not exhaustive, we demonstrate that common patterns of divergence can be identified automatically without prior knowledge of a given language pair, and the patterns can be used to improve performance of projection algorithms.", "creator": "LaTeX with hyperref package"}}}