{"id": "1605.04515", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2016", "title": "Machine Translation Evaluation: A Survey", "abstract": "This paper introduces the state-of-the-art MT evaluation survey that contains both manual and automatic evaluation methods. The traditional human evaluation criteria mainly include the intelligibility, fidelity, fluency, adequacy, comprehension, and informativeness. We classify the automatic evaluation methods into two categories, including lexical similarity and linguistic features application. The lexical similarity methods contain edit distance, precision, recall, and word order, etc. The linguistic features can be divided into syntactic features and semantic features. Subsequently, we also introduce the evaluation methods for MT evaluation and the recent quality estimation tasks for MT.", "histories": [["v1", "Sun, 15 May 2016 09:41:00 GMT  (565kb)", "https://arxiv.org/abs/1605.04515v1", "14 pages, 21 formula"], ["v2", "Wed, 18 May 2016 18:38:02 GMT  (567kb)", "http://arxiv.org/abs/1605.04515v2", "14 pages, 21 formula"], ["v3", "Thu, 19 May 2016 16:12:34 GMT  (570kb)", "http://arxiv.org/abs/1605.04515v3", "some revision of the mathematical symbols and recent literature work in the content, and edit of references"], ["v4", "Mon, 23 May 2016 15:48:19 GMT  (643kb)", "http://arxiv.org/abs/1605.04515v4", "We added some further revision of the content, with introducation of previous MT evaluation related survey works from some european MT and language technology projects; fixed some mising references in paraphrase section"], ["v5", "Wed, 25 May 2016 10:30:16 GMT  (649kb)", "http://arxiv.org/abs/1605.04515v5", "We gave more intro information in the abstract about the content structure, the content layout, to make it easier for researchers understand the paper in the first moment. and we add some literature about deep learning for MT and evaluation"], ["v6", "Sun, 19 Jun 2016 12:28:58 GMT  (656kb)", "http://arxiv.org/abs/1605.04515v6", "We gave more intro information in the abstract about the content structure, the content layout, to make it easier for researchers understand the paper in the first moment. and we add some literature about deep learning for MT and evaluation, some literature about task-based MT evaluation"], ["v7", "Tue, 10 Oct 2017 14:04:07 GMT  (1610kb,D)", "http://arxiv.org/abs/1605.04515v7", "We add two presentation figures about Human MT Evaluation, and Automatic MT Evaluation, to make it clear for readers to find the whole structure of the paper. Add some advanced works of MT Evaluation, e.g. Neural models"]], "COMMENTS": "14 pages, 21 formula", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["aaron li-feng han", "derek fai wong"], "accepted": false, "id": "1605.04515"}, "pdf": {"name": "1605.04515.pdf", "metadata": {"source": "CRF", "title": "Machine Translation Evaluation Resources and Methods: A Survey", "authors": ["Lifeng Han", "Derek F. Wong", "Lidia S. Chao"], "emails": ["lifeng.han@adaptcentre.ie", "derekfw@umac.mo", "lidiasc@umac.mo"], "sections": [{"heading": null, "text": "This paper differs from the existing work (Dorr et al., 2009; EuroMatrix, 2007) in several aspects, in that it presents some recent developments in MT benchmarks, the different classifications from manual to automatic benchmarks, the introduction of newer MT QE tasks, and the concise design of the content. We hope that this work will help MTresearchers easily pick up some metrics that are best suited to their specific MT model development, and help MT valuers to get a general overview of how MT valuation research has evolved."}, {"heading": "1 Introduction", "text": "Machine translation (MT) began as early as the 1950s (Weaver, 1955), and gained rapid development since the 1990s (Marin, o et al., 2006) due to the development of computer memory and computing power and the widespread multilingual and bilingual corpora. However, there is much important work in MT areas, for some to mention by the time IBM Watson research group (Brown et al., 1993) developed five statistical MT models and the ways to estimate the parameters in the bilingual translation corpora models; (Koehn et al., 2003) proposed statistical phrase models based on the MT model; Och (Och, 2003) presented Minimum Error Rate Training (MERT) for log-linear statistical machine translation models; (Koehn and Monz, 2005) performed a shared task to build statistical machine translation (SMT) systems for four European language pairs; (Chiang) proposed a hierarchical formulation (2005)."}, {"heading": "2 Human Evaluation Methods", "text": "In this section, traditional human evaluation methods and advanced methods are presented, as shown in Fig. 1."}, {"heading": "2.1 Traditional Human Assessment", "text": "In fact, most people are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "3 Automatic Evaluation Metric", "text": "In fact, most of them are able to survive themselves, and they are able to survive themselves, \"he said in an interview with The New York Times, in which he addressed the\" New York Times \"and the\" New York Times. \""}, {"heading": "3.2 Linguistic Features", "text": "Although some of the above-mentioned metrics take linguistic information into account, e.g. semantic information synonyms and information contained in METEOR, lexical similarity methods focus mainly on the exact matches of interface words in output translation. The advantages of lexical similarity-based metrics are that they work well in capturing translation quality (Lo et al., 2012), and they are very fast and cost-effective. On the other hand, there are also some weaknesses, for example, syntactic information is rarely taken into account, and the underlying assumption that a good translation is one that shares the same lexical decisions as reference translations are semantically unwarranted. Lexical similarity does not adequately reflect similarity in meaning. Translation measures reflecting similarity in meaning must be based on similarity in the semantic structure of language, not mere xlecal similarity."}, {"heading": "3.3 DL for MTE", "text": "There are researchers who use DL- and NNs models for MTE that are promising for further research. For example, (Guzma \u0301 n et al., 2015; Guzmn et al., 2017) neural networks for MTE used paired modeling to select the best hypotheses translation by comparing candidate translation with reference and integrating syntactical and semantic information into NNs. (Gupta et al., 2015b) suggested LSTM networks based on dense vectors to perform MTE. While (Ma et al., 2016) developed a new metric based on bidirectional LSTM that resembles the work of (Guzma \u0301 n et al., 2015) but is less complex by allowing the evaluation of individual hypotheses based on references rather than on pairwise situations."}, {"heading": "4 Evaluating the MT Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Statistical Significance", "text": "To investigate this problem, Koehn, 2004, is conducting research on the statistical significance test for machine translation evaluation, the bootstrap resampling method used to calculate statistical significance intervals for valuation metrics on small sets of tests. Statistical significance usually refers to two different terms, one of which is the p-value, the probability that the observed data will occur randomly in a particular null hypothesis, and the other is the \"type I error rate\" of a statistical hypotheses test, also known as \"false positive,\" which is measured with the probability of a false rejection of a given null hypothesis in favor of a second alternative hypothesis (Hald, 1998)."}, {"heading": "4.2 Evaluating Human Judgment", "text": "s kappa coefficient of agreement is one of the commonly used evaluation methods (Cohen, 1960). For the problem of nominal agreement between two judges, there are two relevant quantities p0 and St. The factor p0 is the proportion of units in which the judges agreed, and PC is the proportion of units for which a coincidence is expected. K is simply the proportion of randomly expected discrepancies that do not occur, or alternatively the proportion of agreement after a random agreement has been excluded from consideration: k = p0 \u2212 pc 1 \u2212 pc (14), where p0 \u2212 pc represents the proportion of cases in which a coincidence of coincidence occurs and represents the count of the coefficient (Landis and Koch, 1977)."}, {"heading": "4.3 Correlating Manual and Automatic Score", "text": "In this section, we present three correlation coefficient algorithms commonly used by recent WMT workshops to measure the proximity of automatic assessment and manual assessments; the choice of the correlation coefficient depends on whether the scores or ranking schemes are used (Montgomery and Runger, 2003)."}, {"heading": "4.3.3 Kendall\u2019s \u03c4", "text": "Kendall's \u03c4 (Kendall, 1938) has been used in recent years for the correlation between automatic order and reference order (Callison-Burch et al., 2010; Callison-Burch et al., 2011; Callison-Burch et al., 2012). It is defined as: \u03c4 = number of concordant pairs \u2212 number of discordant pairstotal pairs (18) The latest version of Kendall's \u03c4 is introduced (Kendall and Gibbons, 1990). (Lebanon and Lafferty, 2002) provide a review of Kendall's \u03c4 that shows its application in calculating how much the system orders differ from the reference order. More specifically (Lapata, 2003) suggests the use of Kendall's \u03c4, a measure of ranking correlation that estimates the distance between a system-generated and a human-generated gold standard order."}, {"heading": "4.4 Metrics Comparison Works", "text": "There are some researchers who have done some work on comparing different types of metrics. For example (Callison-Burch et al., 2006b; Callison-Burch et al., 2007b; Lavie, 2013) it was mentioned that BLEU, by qualitative analysis of some standard data sets, cannot reflect well the performance of MT systems in many situations, i.e. a higher BLEU value cannot ensure better translation results. Furthermore, there are some recently developed metrics that can work much better than traditional ones, especially in demanding sentence-level assessment, although they are not yet popular, such as nLEPOR and SentBLEU-Moses (Graham et al., 2015; Graham and Liu, 2016). Such comparisons will help MT researchers to select suitable metrics for their specific tasks."}, {"heading": "5 Advanced Quality Estimation", "text": "In recent years, some MT evaluation methods have been proposed that do not use the manually provided gold reference values, which are usually referred to as \"Quality Estimation (QE).\" \u2212 si Some of the related work has already been mentioned in earlier sections. \u2212 si MT's latest quality evaluation tasks can be found from WMT12 to WMT15 (CallisonBurch et al., 2012; Bojar et al., 2013; Bojar et al., 2014; Bojar et al., 2015). They have defined a new evaluation metric that offers some advantages over traditional ranking metrics. DeltaAvg, the designed criterion, assumes that with each entry, the reference test set is associated with a number representing its extrinsic value. Given these values, its metric does not require an explicit reference ranking, as the Spearman ranking does."}, {"heading": "6 Discussion and Conclusion", "text": "This year, it has come to the point where it has never come as far as this year, where it has come so far, until it has come so far that it has never come as far as this year."}, {"heading": "7 Perspective", "text": "In this section, we will mention several aspects that are useful and will attract a lot of attention for the further development of the MT evaluation field.First, lexical similarity and linguistic characteristics are important. Since natural languages are expressive and ambiguous at different levels (Gime \u0301 nez and Ma \u0301 rquez, 2007), lexical similarity metrics limit their scope to the lexical dimension and are not sufficient to ensure that two sentences convey the same meaning or not. For example, research by (Callison-Burch et al., 2006a) and (Koehn and Monz, 2006b) reports that lexical similarity metrics tend to favor automatic statistical translation systems. If the rated systems belong to different types that include rule-based, human-assisted and statistical systems, then lexical similarity metrics, such as EU, will not be important to the inconsistency between the results provided by the human evaluators."}, {"heading": "8 Aknowledgement", "text": "Author Han is supported by the ADAPT Centre for Digital Content Technology under the SFI Research Centres Programme (Grant 13 / RC / 2106) and co-financed by the European Regional Development Fund. Han thanks NWO VICI under Grant No. 277-89-002 of the Netherlands and the Research Committee of the University of Macau (Grant No. MYRG2015-00175-FST and MYRG2015-00188FST) and the Science and Technology Development Fund of Macau (Grant No. 057 / 2014 / A). Author Han thanks Prof. Dr. Qun Liu, Prof. Dr. Khalil Sima'an of ILLC / UvA Amsterdam and Dr. Ying Shi."}], "references": [{"title": "A re-examination of machine learning approaches for sentence-level mt evaluation", "author": ["Albrecht", "Hwa2007] J. Albrecht", "R. Hwa"], "venue": "In The Proceedings of the 45th Annual Meeting of the ACL,", "citeRegEx": "Albrecht et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Albrecht et al\\.", "year": 2007}, {"title": "A survey of paraphrasing and textual entailment methods", "author": ["Androutsopoulos", "Prodromos Malakasiotis"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Androutsopoulos et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Androutsopoulos et al\\.", "year": 2010}, {"title": "Computers and Translation: A translator\u2019s guide-Chap8 Why translation is difficult for computers", "author": ["D. Arnold"], "venue": "Benjamins Translation Library", "citeRegEx": "Arnold.,? \\Q2003\\E", "shortCiteRegEx": "Arnold.", "year": 2003}, {"title": "Evaluate with confidence estimation: Machine ranking of translation outputs using grammatical features", "author": ["Maja Popovic", "David Vilar", "Aljoscha Burchardt"], "venue": "Proceedings of WMT", "citeRegEx": "Avramidis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Avramidis et al\\.", "year": 2011}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Meteor: An automatic metric for mt evaluation with improved correlation with human judgments", "author": ["Banerjee", "Lavie2005] Satanjeev Banerjee", "Alon Lavie"], "venue": "In Proceedings of the ACL", "citeRegEx": "Banerjee et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2005}, {"title": "Evaluation metrics for generation", "author": ["Owen Rambow", "Steven Whittaker"], "venue": "In Proceedings of INLG", "citeRegEx": "Bangalore et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Bangalore et al\\.", "year": 2000}, {"title": "Learning to paraphrase: an unsupervised approach using multiple-sequence alignment", "author": ["Barzilayand", "Lee2003] Regina Barzilayand", "Lillian Lee"], "venue": "In Proceedings NAACL", "citeRegEx": "Barzilayand et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Barzilayand et al\\.", "year": 2003}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Brown et al.1993] Peter F Brown", "Vincent J Della Pietra", "Stephen A Della Pietra", "Robert L Mercer"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Black box features for the wmt 2012 quality estimation shared task", "author": ["Christian Buck"], "venue": "In Proceedings of WMT", "citeRegEx": "Buck.,? \\Q2012\\E", "shortCiteRegEx": "Buck.", "year": 2012}, {"title": "Improved statistical machine translation using paraphrases", "author": ["Philipp Koehn", "Miles Osborne"], "venue": "In Proceedings of HLT-NAACL", "citeRegEx": "Callison.Burch et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2006}, {"title": "Reevaluating the role of bleu in machine translation research", "author": ["Miles Osborne", "Philipp Koehn"], "venue": "In Proceedings of EACL,", "citeRegEx": "Callison.Burch et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2006}, {"title": "meta-) evaluation of machine translation", "author": ["Cameron Fordyce", "Philipp Koehn", "Christof Monz", "Josh Schroeder"], "venue": "In Proceedings of WMT", "citeRegEx": "Callison.Burch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2007}, {"title": "meta-) evaluation of machine translation", "author": ["Cameron Fordyce", "Philipp Koehn", "Christof Monz", "Josh Schroeder"], "venue": "In Proceedings of the Second Workshop on Statistical Machine Translation,", "citeRegEx": "Callison.Burch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2007}, {"title": "Further meta-evaluation of machine translation", "author": ["Cameron Fordyce", "Philipp Koehn", "Christof Monz", "Josh Schroeder"], "venue": "In Proceedings of WMT", "citeRegEx": "Callison.Burch et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2008}, {"title": "Findings of the 2009 workshop on statistical machine translation", "author": ["Philipp Koehn", "Christof Monz", "Josh Schroeder"], "venue": "In Proceedings of the 4th WMT", "citeRegEx": "Callison.Burch et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2009}, {"title": "Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation", "author": ["Philipp Koehn", "Christof Monz", "Kay Peterson", "Mark Przybocki", "Omar F. Zaridan"], "venue": null, "citeRegEx": "Callison.Burch et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2010}, {"title": "Recent advances in example-based machine translation", "author": ["Carl", "Way2003] Michael Carl", "Andy Way"], "venue": null, "citeRegEx": "Carl et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Carl et al\\.", "year": 2003}, {"title": "An experiment in evaluating the quality of translation", "author": ["John B. Carroll"], "venue": "Mechanical Translation and Computational Linguistics,", "citeRegEx": "Carroll.,? \\Q1966\\E", "shortCiteRegEx": "Carroll.", "year": 1966}, {"title": "Port: a precision-order-recall mt evaluation metric for tuning", "author": ["Chen et al.2012] Boxing Chen", "Roland Kuhn", "Samuel Larkin"], "venue": "In Proceedings of the ACL", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "A hierarchical phrase-based model for statistical machine translation", "author": ["David Chiang"], "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Chiang.,? \\Q2005\\E", "shortCiteRegEx": "Chiang.", "year": 2005}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches. CoRR, abs/1409.1259", "author": ["Cho et al.2014] KyungHyun Cho", "Bart van Merrienboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Good applications for crummy machine translation", "author": ["Church", "Hovy1991] Kenneth Church", "Eduard Hovy"], "venue": "In Proceedings of the Natural Language Processing Systems Evaluation Workshop", "citeRegEx": "Church et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Church et al\\.", "year": 1991}, {"title": "A coefficient of agreement for nominal scales", "author": ["Jasob Cohen"], "venue": "Educational and Psychological Measurement,", "citeRegEx": "Cohen.,? \\Q1960\\E", "shortCiteRegEx": "Cohen.", "year": 1960}, {"title": "Verta: Linguistic features in mt evaluation", "author": ["Jordi Atserias", "Victoria Arranz", "Irene Castell\u00f3n"], "venue": "In LREC,", "citeRegEx": "Comelles et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Comelles et al\\.", "year": 2012}, {"title": "Probabilistic textual entailment: Generic applied modeling of language variability. In Learning Methods for Text Understanding and Mining workshop", "author": ["Dagan", "Glickman2004] Ido Dagan", "Oren Glickman"], "venue": null, "citeRegEx": "Dagan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 2004}, {"title": "The pascal recognising textual entailment challenge", "author": ["Dagan et al.2006] Ido Dagan", "Oren Glickman", "Bernardo Magnini"], "venue": "Machine Learning Challenges:LNCS,", "citeRegEx": "Dagan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 2006}, {"title": "Tesla at wmt2011: Translation evaluation and tunable metric", "author": ["Chang Liu", "Hwee Tou Ng"], "venue": "In Proceedings of WMT", "citeRegEx": "Dahlmeier et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dahlmeier et al\\.", "year": 2011}, {"title": "Automatic evaluation of machine translation quality using n-gram co-occurrence statistics", "author": ["George Doddington"], "venue": "In HLT Proceedings", "citeRegEx": "Doddington.,? \\Q2002\\E", "shortCiteRegEx": "Doddington.", "year": 2002}, {"title": "Part 5: Machine translation evaluation", "author": ["Dorr et al.2009] Bonnie Dorr", "Matt Snover", "etc. Nitin Madnani"], "venue": "In Bonnie Dorr edited DARPA GALE program report", "citeRegEx": "Dorr et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dorr et al\\.", "year": 2009}, {"title": "Task-based evaluation for machine translation", "author": ["John S. White", "Kathryn B. Taylor"], "venue": "In Proceedings of MT Summit", "citeRegEx": "Doyon et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Doyon et al\\.", "year": 1999}, {"title": "Automatic evaluation method for machine translation using noun-phrase chunking", "author": ["Echizen-ya", "Araki2010] H. Echizen-ya", "K. Araki"], "venue": "In Proceedings of the ACL", "citeRegEx": "Echizen.ya et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Echizen.ya et al\\.", "year": 2010}, {"title": "Overview of the iwslt 2005 evaluation campaign", "author": ["Eck", "Hori2005] Matthias Eck", "Chiori Hori"], "venue": "In In proceeding of International Workshop on Spoken Language Translation (IWSLT)", "citeRegEx": "Eck et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Eck et al\\.", "year": 2005}, {"title": "Overview of the iwslt 2011 evaluation campaign", "author": ["Luisa Bentivogli", "Michael Paul", "Sebastian St\u00fcker"], "venue": "In In proceeding of International Workshop on Spoken Language Translation (IWSLT)", "citeRegEx": "Federico et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Federico et al\\.", "year": 2011}, {"title": "Measuring word alignment quality for statistical machine translation", "author": ["Fraser", "Marcu2007] Alexander Fraser", "Daniel Marcu"], "venue": null, "citeRegEx": "Fraser et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Fraser et al\\.", "year": 2007}, {"title": "Sentence-level mt evaluation without reference translations beyond language modelling", "author": ["Gamon et al.2005] Michael Gamon", "Anthony Aue", "Martine Smets"], "venue": "In Proceedings of EAMT,", "citeRegEx": "Gamon et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gamon et al\\.", "year": 2005}, {"title": "Factoring synchronous grammars by sorting", "author": ["Gildea et al.2006] Daniel Gildea", "Giorgio Satta", "Hao Zhang"], "venue": "In Proceedings of ACL", "citeRegEx": "Gildea et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2006}, {"title": "A smorgasbord of features for automatic mt evaluation", "author": ["Gim\u00e9ne", "M\u00e1rquez2008] Jes\u00fas Gim\u00e9ne", "Ll\u00fais M\u00e1rquez"], "venue": "In Proceedings of WMT,", "citeRegEx": "Gim\u00e9ne et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gim\u00e9ne et al\\.", "year": 2008}, {"title": "Linguistic features for automatic evaluation of heterogenous mt systems", "author": ["Gim\u00e9nez", "M\u00e1rquez2007] Jes\u00fas Gim\u00e9nez", "Ll\u00fais M\u00e1rquez"], "venue": "In Proceedings of WMT", "citeRegEx": "Gim\u00e9nez et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gim\u00e9nez et al\\.", "year": 2007}, {"title": "Achieving accurate conclusions in evaluation of automatic machine translation metrics", "author": ["Graham", "Liu2016] Yvette Graham", "Qun Liu"], "venue": "In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association", "citeRegEx": "Graham et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Graham et al\\.", "year": 2016}, {"title": "Accurate evaluation of segment-level machine translation metrics", "author": ["Graham et al.2015] Yvette Graham", "Timothy Baldwin", "Nitika Mathur"], "venue": "In NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association", "citeRegEx": "Graham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Graham et al\\.", "year": 2015}, {"title": "Named entity recognition in query", "author": ["Guo et al.2009] Jiafeng Guo", "Gu Xu", "Xueqi Cheng", "Hang Li"], "venue": "In Proceeding of SIGIR", "citeRegEx": "Guo et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2009}, {"title": "2015a. Machine translation evaluation using recurrent neural networks", "author": ["Gupta et al.2015a] Rohit Gupta", "Constantin Orasan", "Josef van Genabith"], "venue": "In Proceedings of the Tenth Workshop on Statistical Machine Translation,", "citeRegEx": "Gupta et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2015}, {"title": "2015b. Reval: A simple and effective machine translation evaluation metric based on recurrent neural networks", "author": ["Gupta et al.2015b] Rohit Gupta", "Constantin Orasan", "Josef van Genabith"], "venue": "In Proceedings of the 2015 Conference on Emperical Methods", "citeRegEx": "Gupta et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2015}, {"title": "Pairwise neural machine translation evaluation", "author": ["Shafiq Joty", "Llu\u0131\u0301s M\u00e0rquez", "Preslav Nakov"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and The 7th Interna-", "citeRegEx": "Guzm\u00e1n et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guzm\u00e1n et al\\.", "year": 2015}, {"title": "Machine translation evaluation with neural networks. Comput. Speech Lang., 45(C):180\u2013200, September", "author": ["Shafiq Joty", "Llus Mrquez", "Preslav Nakov"], "venue": null, "citeRegEx": "Guzmn et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Guzmn et al\\.", "year": 2017}, {"title": "A History of Mathematical Statistics from 1750 to 1930", "author": ["Anders Hald"], "venue": null, "citeRegEx": "Hald.,? \\Q1998\\E", "shortCiteRegEx": "Hald.", "year": 1998}, {"title": "A robust evaluation metric for machine translation with augmented factors", "author": ["Derek Fai Wong", "Lidia Sam Chao"], "venue": "Proceedings of COLING", "citeRegEx": "Han et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Han et al\\.", "year": 2012}, {"title": "Phrase tagset mapping for french and english treebanks and its application in machine translation evaluation", "author": ["Derek Fai Wong", "Lidia Sam Chao", "Liangeye He", "Shuo Li", "Ling Zhu"], "venue": null, "citeRegEx": "Han et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Han et al\\.", "year": 2013}, {"title": "A description of tunable machine translation evaluation systems in wmt13 metrics task", "author": ["Derek Fai Wong", "Lidia Sam Chao", "Yi Lu", "Liangye He", "Yiming Wang", "Jiaji Zhou"], "venue": "Proceedings of WMT,", "citeRegEx": "Han et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Han et al\\.", "year": 2013}, {"title": "Unsupervised quality estimation model for english to german translation and its application in extensive supervised evaluation", "author": ["Derek Fai Wong", "Lidia Sam Chao", "Liangeye He", "Yi Lu"], "venue": null, "citeRegEx": "Han et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Han et al\\.", "year": 2014}, {"title": "LEPOR: An Augmented Machine Translation Evaluation Metric", "author": ["Lifeng Han"], "venue": "Ph.D. thesis,", "citeRegEx": "Han.,? \\Q2014\\E", "shortCiteRegEx": "Han.", "year": 2014}, {"title": "Improving statistical machine translation using shallow linguistic knowledge", "author": ["Andrew Finch", "Yutaka Sasaki"], "venue": "Computer Speech and Language,", "citeRegEx": "Hwang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hwang et al\\.", "year": 2007}, {"title": "Rank Correlation Methods", "author": ["Kendall", "Gibbons1990] Maurice G. Kendall", "Jean Dickinson Gibbons"], "venue": null, "citeRegEx": "Kendall et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Kendall et al\\.", "year": 1990}, {"title": "A new measure of rank correlation", "author": ["Maurice G. Kendall"], "venue": null, "citeRegEx": "Kendall.,? \\Q1938\\E", "shortCiteRegEx": "Kendall.", "year": 1938}, {"title": "Syntax-based reordering for statistical machine translation", "author": ["Khalilov", "Fonollosa2011] Maxim Khalilov", "Jos\u00e9 A.R. Fonollosa"], "venue": "Computer Speech and Language,", "citeRegEx": "Khalilov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Khalilov et al\\.", "year": 2011}, {"title": "Femti: Creating and using a framework for mt evaluation", "author": ["King et al.2003] Marrgaret King", "Andrei PopescuBelis", "Eduard Hovy"], "venue": "In Proceedings of the Machine Translation Summit IX", "citeRegEx": "King et al\\.,? \\Q2003\\E", "shortCiteRegEx": "King et al\\.", "year": 2003}, {"title": "Statistical machine translation, November 24. US Patent 7,624,005", "author": ["Koehn", "Knight2009] Philipp Koehn", "Kevin Knight"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2009}, {"title": "Shared task: Statistical machine translation between european languages", "author": ["Koehn", "Monz2005] Philipp Koehn", "Christof Monz"], "venue": "In Proceedings of the ACL Workshop on Building and Using Parallel Texts", "citeRegEx": "Koehn et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2005}, {"title": "Manual and automatic evaluation of machine translation between european languages", "author": ["Koehn", "Monz2006a] Philipp Koehn", "Christof Monz"], "venue": "In Proceedings on the Workshop on Statistical Machine Translation,", "citeRegEx": "Koehn et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2006}, {"title": "Manual and automatic evaluation of machine translation between european languages", "author": ["Koehn", "Monz2006b] Philipp Koehn", "Christof Monz"], "venue": "In Proceedings of WMT", "citeRegEx": "Koehn et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2006}, {"title": "Statistical phrase-based translation", "author": ["Koehn et al.2003] Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["Herbst."], "venue": "Proceedings of ACL.", "citeRegEx": "Herbst.,? 2007a", "shortCiteRegEx": "Herbst.", "year": 2007}, {"title": "Moses: Open source toolkit", "author": ["Koehn et al.2007b] Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Statistical significance tests for machine translation evaluation", "author": ["Philipp Koehn"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Koehn.,? \\Q2004\\E", "shortCiteRegEx": "Koehn.", "year": 2004}, {"title": "Statistical Machine Translation", "author": ["Philipp Koehn"], "venue": null, "citeRegEx": "Koehn.,? \\Q2010\\E", "shortCiteRegEx": "Koehn.", "year": 2010}, {"title": "The measurement of observer agreement for categorical data", "author": ["Landis", "Koch1977] J. Richard Landis", "Gary G. Koch"], "venue": null, "citeRegEx": "Landis et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Landis et al\\.", "year": 1977}, {"title": "Task-based mt evaluation: From who/when/where extraction to event understanding", "author": ["Laoudi et al.2006] Jamal Laoudi", "Ra R. Tate", "Clare R. Voss"], "venue": "In in Proceedings of LREC06,", "citeRegEx": "Laoudi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Laoudi et al\\.", "year": 2006}, {"title": "Probabilistic text structuring: Experiments with sentence ordering", "author": ["Mirella Lapata"], "venue": "In Proceedings of ACL", "citeRegEx": "Lapata.,? \\Q2003\\E", "shortCiteRegEx": "Lapata.", "year": 2003}, {"title": "Automated metrics for mt evaluation", "author": ["Alon Lavie"], "venue": "Machine Translation,", "citeRegEx": "Lavie.,? \\Q2013\\E", "shortCiteRegEx": "Lavie.", "year": 2013}, {"title": "Combining rankings using conditional probability models on permutations", "author": ["Lebanon", "Lafferty2002] Guy Lebanon", "John Lafferty"], "venue": "In Proceeding of the ICML", "citeRegEx": "Lebanon et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Lebanon et al\\.", "year": 2002}, {"title": "Edit distances with block movements and error rate confidence estimates", "author": ["Leusch", "Ney2009] Gregor Leusch", "Hermann Ney"], "venue": "Machine Translation,", "citeRegEx": "Leusch et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Leusch et al\\.", "year": 2009}, {"title": "Phrase-based evaluation for machine translation", "author": ["Li et al.2012] Liang You Li", "Zheng Xian Gong", "Guo Dong Zhou"], "venue": "In Proceedings of COLING,", "citeRegEx": "Li et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Li et al\\.", "year": 2012}, {"title": "Results of the 2005 nist machine translation evaluation", "author": ["A. LI"], "venue": "In Proceedings of WMT", "citeRegEx": "LI.,? \\Q2005\\E", "shortCiteRegEx": "LI.", "year": 2005}, {"title": "Automatic evaluation of summaries using n-gram co-occurrence statistics", "author": ["Lin", "Hovy2003] Chin-Yew Lin", "E.H. Hovy"], "venue": "In Proceedings NAACL", "citeRegEx": "Lin et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2003}, {"title": "Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics", "author": ["Lin", "Och2004] Chin-Yew Lin", "Franz Josef Och"], "venue": "In Proceedings of ACL", "citeRegEx": "Lin et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2004}, {"title": "Syntactic features for evaluation of machine translation. In Proceedingsof theACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization", "author": ["Liu", "Gildea2005] Ding Liu", "Daniel Gildea"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2005}, {"title": "Better evaluation metrics lead to better machine translation", "author": ["Chang Liu", "Daniel Dahlmeier", "Hwee Tou Ng"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Liu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2011}, {"title": "Meant: An inexpensive, high- accuracy, semiautomatic metric for evaluating translation utility based on semantic roles", "author": ["Lo", "Wu2011a] Chi Kiu Lo", "Dekai Wu"], "venue": "Proceedings of ACL", "citeRegEx": "Lo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lo et al\\.", "year": 2011}, {"title": "Structured vs. flat semantic role representations for machine translation evaluation", "author": ["Lo", "Wu2011b] Chi Kiu Lo", "Dekai Wu"], "venue": "In Proceedings of the 5th Workshop on Syntax and Structure in StatisticalTranslation (SSST-5)", "citeRegEx": "Lo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lo et al\\.", "year": 2011}, {"title": "Fully automatic semantic mt evaluation", "author": ["Lo et al.2012] Chi Kiu Lo", "Anand Karthik Turmuluru", "Dekai Wu"], "venue": "In Proceedings of WMT", "citeRegEx": "Lo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lo et al\\.", "year": 2012}, {"title": "Maxsd: A neural machine translation evaluation metric optimized by maximizing similarity", "author": ["Ma et al.2016] Qingsong Ma", "Fandong Meng", "Daqi Zheng", "Mingxuan Wang", "Yvette Graham", "Wenbin Jiang", "Qun Liu"], "venue": null, "citeRegEx": "Ma et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2016}, {"title": "Muc-7 evaluation of ie technology: Overview of results", "author": ["Marsh", "Perzanowski1998] Elaine Marsh", "Dennis Perzanowski"], "venue": "In Proceedingsof Message Understanding Conference (MUC-7)", "citeRegEx": "Marsh et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Marsh et al\\.", "year": 1998}, {"title": "Paraphrasing using given and new information in a question-answer system", "author": ["Kathleen R. McKeown"], "venue": "In Proceedings of ACL", "citeRegEx": "McKeown.,? \\Q1979\\E", "shortCiteRegEx": "McKeown.", "year": 1979}, {"title": "Microsoft research treelet translation system: Naacl 2006 europarl evaluation", "author": ["Menezes et al.2006] Arul Menezes", "Kristina Toutanova", "Chris Quirk"], "venue": "In Proceedings of WMT", "citeRegEx": "Menezes et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Menezes et al\\.", "year": 2006}, {"title": "Microsoft research treelet translation system: Naacl 2006 europarl evaluation", "author": ["Meteer", "Shaked1988] Marie Meteer", "Varda Shaked"], "venue": "In Proceedings of COLING", "citeRegEx": "Meteer et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Meteer et al\\.", "year": 1988}, {"title": "Wordnet: an on-line lexical database", "author": ["G.A. Miller", "R. Beckwith", "C. Fellbaum", "D. Gross", "K.J. Miller"], "venue": null, "citeRegEx": "Miller et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Miller et al\\.", "year": 1990}, {"title": "Applied statistics and probability for engineers", "author": ["Montgomery", "George C. Runger"], "venue": null, "citeRegEx": "Montgomery et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Montgomery et al\\.", "year": 2003}, {"title": "Unobtrusive methods for low-cost manual assessment of machine translation", "author": ["Moran", "Lewis2012] John Moran", "David Lewis"], "venue": "Tralogy I [Online], Session", "citeRegEx": "Moran et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Moran et al\\.", "year": 2012}, {"title": "automatic evaluation of machine translation quality", "author": ["L. Mrquez"], "venue": "Dialogue 2013 invited talk,", "citeRegEx": "Mrquez.,? \\Q2013\\E", "shortCiteRegEx": "Mrquez.", "year": 2013}, {"title": "Minimum error rate training for statistical machine translation", "author": ["Franz Josef Och"], "venue": "In Proceedings of ACL", "citeRegEx": "Och.,? \\Q2003\\E", "shortCiteRegEx": "Och.", "year": 2003}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei Jing Zhu"], "venue": "In Proceedings of ACL", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Erating machine translation", "author": ["Joel Tetreault ans Nitin Madnani", "Martin Chodorow"], "venue": "In Proceedings of WMT", "citeRegEx": "Parton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Parton et al\\.", "year": 2011}, {"title": "Overview of the iwslt 2010 evaluation campaign", "author": ["Paul et al.2010] Michael Paul", "Marcello Federico", "Sebastian St\u00fcker"], "venue": "In Proceeding of IWSLT", "citeRegEx": "Paul et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Paul et al\\.", "year": 2010}, {"title": "Overview of the iwslt 2009 evaluation campaign", "author": ["M. Paul"], "venue": "In Proceeding of IWSLT", "citeRegEx": "Paul.,? \\Q2009\\E", "shortCiteRegEx": "Paul.", "year": 2009}, {"title": "On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling", "author": ["Karl Pearson"], "venue": null, "citeRegEx": "Pearson.,? \\Q1900\\E", "shortCiteRegEx": "Pearson.", "year": 1900}, {"title": "Evaluation without references: Ibm1 scores as evaluation metrics", "author": ["Popovi\u0107 et al.2011] Maja Popovi\u0107", "David Vilar", "Eleftherios Avramidis", "Aljoscha Burchardt"], "venue": "In Proceedings of WMT", "citeRegEx": "Popovi\u0107 et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Popovi\u0107 et al\\.", "year": 2011}, {"title": "Word error rates: Decomposition over pos classes and applications for error analysis", "author": ["Popovic", "Ney2007] M. Popovic", "Hermann Ney"], "venue": "In Proceedings of WMT", "citeRegEx": "Popovic et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Popovic et al\\.", "year": 2007}, {"title": "Evaluating text-type suitability for machine translation a case study on an english-danish system", "author": ["Nancy Underwood", "Bradley Music", "Anne Neville"], "venue": "In Proceeding LREC", "citeRegEx": "Povlsen et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Povlsen et al\\.", "year": 1998}, {"title": "this sentence is wrong.\u201d detecting errors in machine-translated sentences", "author": ["David Langlois", "Kamel Sm\u00e4ili"], "venue": "Machine Translation,", "citeRegEx": "Raybaud et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Raybaud et al\\.", "year": 2011}, {"title": "Inferring shallow-transfer machine translation rules from small parallel corpora", "author": ["S\u00e1nchez-Mart\u0301inez", "Forcada2009] F. S\u00e1nchezMart\u0301inez", "M.L. Forcada"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "S\u00e1nchez.Mart\u0301inez et al\\.,? \\Q2009\\E", "shortCiteRegEx": "S\u00e1nchez.Mart\u0301inez et al\\.", "year": 2009}, {"title": "A study of translation edit rate with targeted human annotation", "author": ["Bonnie J. Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul"], "venue": "In Proceeding of AMTA", "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "Regression and ranking based optimisation for sentence level mt evaluation", "author": ["Song", "Cohn2011] Xingyi Song", "Trevor Cohn"], "venue": "In Proceedings of WMT", "citeRegEx": "Song et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Song et al\\.", "year": 2011}, {"title": "Combining confidence estimation and reference-based metrics for segment-level mt evaluation. In The Ninth Conference of the Association for Machine Translation in the Americas (AMTA)", "author": ["Specia", "Gim\u00e9nez2010] L. Specia", "J. Gim\u00e9nez"], "venue": null, "citeRegEx": "Specia et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Specia et al\\.", "year": 2010}, {"title": "Predicting machine translation adequacy", "author": ["Specia et al.2011] Lucia Specia", "Naheh Hajlaoui", "Catalina Hallett", "Wilker Aziz"], "venue": "In Machine Translation Summit XIII", "citeRegEx": "Specia et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Specia et al\\.", "year": 2011}, {"title": "A new quantitative quality measure for machine translation systems", "author": ["Su et al.1992] Keh-Yih Su", "Wu Ming-Wen", "Chang Jing-Shin"], "venue": "In Proceeding of COLING", "citeRegEx": "Su et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Su et al\\.", "year": 1992}, {"title": "Accelerated dp based search for statistical translation", "author": ["Stephan Vogel", "Hermann Ney", "Arkaitz Zubiaga", "Hassan Sawaf"], "venue": "In Proceeding of EUROSPEECH", "citeRegEx": "Tillmann et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Tillmann et al\\.", "year": 1997}, {"title": "Evaluation of machine translation and its evaluation", "author": ["Luke Shea", "I Dan Melamed"], "venue": null, "citeRegEx": "Turian et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2006}, {"title": "Task-based evaluation of machine translation (mt) engines: Measuring how well people extract who, when, where-type elements in mt output", "author": ["Voss", "Tate2006] Clare R. Voss", "Ra R. Tate"], "venue": "Proceedings of 11th Annual Conference of the Euro-", "citeRegEx": "Voss et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Voss et al\\.", "year": 2006}, {"title": "Translation. Machine Translation of Languages: Fourteen Essays", "author": ["Warren Weaver"], "venue": null, "citeRegEx": "Weaver.,? \\Q1955\\E", "shortCiteRegEx": "Weaver.", "year": 1955}, {"title": "A task-oriented evaluation metric for machine translation", "author": ["White", "Taylor1998] John S. White", "Kathryn B. Taylor"], "venue": "In Proceeding LREC", "citeRegEx": "White et al\\.,? \\Q1998\\E", "shortCiteRegEx": "White et al\\.", "year": 1998}, {"title": "The arpa mt evaluation methodologies: Evolution, lessons, and future approaches", "author": ["White et al.1994] John S. White", "Theresa O\u2019 Connell", "Francis O\u2019 Mara"], "venue": "In Proceeding of AMTA", "citeRegEx": "White et al\\.,? \\Q1994\\E", "shortCiteRegEx": "White et al\\.", "year": 1994}, {"title": "Neural-based machine translation for medical text domain. based on european medicines agency leaflet texts", "author": ["Wolk", "Marasek2015] Krzysztof Wolk", "Krzysztof Marasek"], "venue": "Procedia Computer Science,", "citeRegEx": "Wolk et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wolk et al\\.", "year": 2015}, {"title": "Atec: automatic evaluation of machine translation via word choice and word order", "author": ["Wong", "yu Kit2009] Billy Wong", "Chun yu Kit"], "venue": "Machine Translation,", "citeRegEx": "Wong et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wong et al\\.", "year": 2009}, {"title": "RED: A reference dependency based MT evaluation metric", "author": ["Yu et al.2014] Hui Yu", "Xiaofeng Wu", "Jun Xie", "Wenbin Jiang", "Qun Liu", "Shouxun Lin"], "venue": "COLING", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}, {"title": "Deep neural networks in machine translation: An overview", "author": ["Zhang", "Zong2015] Jiajun Zhang", "Chengqing Zong"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 29, "context": "This paper differs from the existing works (Dorr et al., 2009; EuroMatrix, 2007) from several aspects, by introducing some recent development of MT evaluation measures, the different classifications from manual to automatic evaluation measures, the introduction of recent QE tasks of MT, and the concise construction of the content.", "startOffset": 43, "endOffset": 80}, {"referenceID": 109, "context": "Machine translation (MT) began as early as in the 1950s (Weaver, 1955) , and gained a rapid development since the 1990s (Mari\u00f1o et al.", "startOffset": 56, "endOffset": 70}, {"referenceID": 8, "context": "There are many important works in MT areas, for some to mention by time, IBM Watson research group (Brown et al., 1993) designed five statistical MT models and the ways of how to estimate the parame-", "startOffset": 99, "endOffset": 119}, {"referenceID": 61, "context": "ters in the models given the bilingual translation corpora; (Koehn et al., 2003) proposed statistical phrase-based MT model; Och (Och, 2003) presented Minimum Error Rate Training (MERT) for log-linear statistical machine translation models; (Koehn and Monz, 2005) introduced a Shared task of building statistical machine translation (SMT) systems for four European language pairs; (Chiang, 2005) proposed a hierarchical phrase-based SMT model that is learned from a bitext with-", "startOffset": 60, "endOffset": 80}, {"referenceID": 90, "context": ", 2003) proposed statistical phrase-based MT model; Och (Och, 2003) presented Minimum Error Rate Training (MERT) for log-linear statistical machine translation models; (Koehn and Monz, 2005) introduced a Shared task of building statistical machine translation (SMT) systems for four European language pairs; (Chiang, 2005) proposed a hierarchical phrase-based SMT model that is learned from a bitext with-", "startOffset": 56, "endOffset": 67}, {"referenceID": 20, "context": ", 2003) proposed statistical phrase-based MT model; Och (Och, 2003) presented Minimum Error Rate Training (MERT) for log-linear statistical machine translation models; (Koehn and Monz, 2005) introduced a Shared task of building statistical machine translation (SMT) systems for four European language pairs; (Chiang, 2005) proposed a hierarchical phrase-based SMT model that is learned from a bitext with-", "startOffset": 308, "endOffset": 322}, {"referenceID": 84, "context": "out syntactic information; (Menezes et al., 2006) introduced a syntactically informed phrasal SMT system for English-to-Spanish translation using a phrase translation model, which was based on global reordering and dependency tree; (Koehn et al.", "startOffset": 27, "endOffset": 49}, {"referenceID": 52, "context": ", 2007b) developed an open source SMT software toolkit Moses; (Hwang et al., 2007) utilized the shallow linguistic knowledge to improve word alignment and language model quality be-", "startOffset": 62, "endOffset": 82}, {"referenceID": 4, "context": "With the fast development of Deep Learning (DL), MT research has evolved from rule-based models to example based models, statistical models, hybrid models, and recent years\u2019 Neural models (Nirenburg, 1989; Carl and Way, 2003; Koehn and Knight, 2009; Bahdanau et al., 2014), such as the attention mechanism models, coverage models, multi-modal and multilingual MT models.", "startOffset": 188, "endOffset": 272}, {"referenceID": 21, "context": "mance through two steps recurrent neural network (RNN) of encoder and decoder (Cho et al., 2014; Bahdanau et al., 2014; Wolk and Marasek, 2015).", "startOffset": 78, "endOffset": 143}, {"referenceID": 4, "context": "mance through two steps recurrent neural network (RNN) of encoder and decoder (Cho et al., 2014; Bahdanau et al., 2014; Wolk and Marasek, 2015).", "startOffset": 78, "endOffset": 143}, {"referenceID": 2, "context": "content in the same way (Arnold, 2003).", "startOffset": 24, "endOffset": 38}, {"referenceID": 73, "context": "One of them was the NIST open machine translation Evaluation series (OpenMT), which were very prestigious evaluation campaigns from 2001 to 2009 (LI, 2005).", "startOffset": 145, "endOffset": 155}, {"referenceID": 18, "context": "They include the intelligibility and fidelity used by the automatic language processing advisory committee (ALPAC) (Carroll, 1966).", "startOffset": 115, "endOffset": 130}, {"referenceID": 111, "context": "1991) in MT evaluation campaigns (White et al., 1994).", "startOffset": 33, "endOffset": 53}, {"referenceID": 6, "context": "(Bangalore et al., 2000) conduct a research developing accuracy into several kinds including simple string accuracy, generation string accuracy, and two corresponding tree-based accuracies.", "startOffset": 0, "endOffset": 24}, {"referenceID": 6, "context": "(Bangalore et al., 2000) conduct a research developing accuracy into several kinds including simple string accuracy, generation string accuracy, and two corresponding tree-based accuracies.Reeder (2004) shows the correlation between fluency and the number of words it takes to distinguish between human translation and machine translation.", "startOffset": 1, "endOffset": 203}, {"referenceID": 104, "context": "(Specia et al., 2011) conduct a study of the", "startOffset": 0, "endOffset": 21}, {"referenceID": 30, "context": "A brief introduction of task-based MT evaluation work was shown in their later work (Doyon et al., 1999).", "startOffset": 84, "endOffset": 104}, {"referenceID": 67, "context": "They extend the work later into event understanding in (Laoudi et al., 2006).", "startOffset": 55, "endOffset": 76}, {"referenceID": 56, "context": "(King et al., 2003) extend a large range of manual evaluation methods for MT systems, which, in", "startOffset": 0, "endOffset": 19}, {"referenceID": 101, "context": "One example of a metric that is designed in such a manner is the human translation error rate (HTER) (Snover et al., 2006), based on the number of editing steps, computing the editing steps between an automatic translation and a reference translation.", "startOffset": 101, "endOffset": 122}, {"referenceID": 47, "context": "There are usually two ways to offer the human reference translation, either offering one single reference or offering multiple references for a single source sentence (Lin and Och, 2004; Han et al., 2012).", "startOffset": 167, "endOffset": 204}, {"referenceID": 105, "context": "By calculating the minimum number of editing steps to transform output to reference, (Su et al., 1992) introduce the word error rate (WER) metric into MT evaluation.", "startOffset": 85, "endOffset": 102}, {"referenceID": 106, "context": "To address this problem, the position-independent word error rate (PER) (Tillmann et al., 1997) is designed to ignore word order when matching output and reference.", "startOffset": 72, "endOffset": 95}, {"referenceID": 101, "context": "In this light, (Snover et al., 2006) design the translation edit rate (TER) metric that adds block movement (jumping action) as", "startOffset": 15, "endOffset": 36}, {"referenceID": 91, "context": "The widely used evaluation metric BLEU (Papineni et al., 2002) is based on the degree of ngram overlapping between the strings of words produced by the machine and the human translation references at the corpus level.", "startOffset": 39, "endOffset": 62}, {"referenceID": 28, "context": "To weight more heavily those n-grams that are more informative, (Doddington, 2002) proposes the NIST metric with the information weight added.", "startOffset": 64, "endOffset": 82}, {"referenceID": 107, "context": "(Turian et al., 2006) conducted experiments to examine how standard measures such as precision and recall and F-measure can be applied for evaluation of MT and showed the comparisons of these standard measures with some existing alternative evaluation measures.", "startOffset": 0, "endOffset": 21}, {"referenceID": 19, "context": "Combining the precision, order, and recall information together, (Chen et al., 2012) develop an automatic evaluation metric PORT that is initially for the tuning of the MT systems to output higher quality translation.", "startOffset": 65, "endOffset": 84}, {"referenceID": 47, "context": "Another evaluation metric LEPOR (Han et al., 2012; Han et al., 2014) is proposed as the combination of many evaluation factors including n-gram based word order penalty in addition to precision, recall, and sentence-length penalty.", "startOffset": 32, "endOffset": 68}, {"referenceID": 50, "context": "Another evaluation metric LEPOR (Han et al., 2012; Han et al., 2014) is proposed as the combination of many evaluation factors including n-gram based word order penalty in addition to precision, recall, and sentence-length penalty.", "startOffset": 32, "endOffset": 68}, {"referenceID": 80, "context": "The advantages of the metrics based on lexical similarity are that they perform well in capturing the translation fluency (Lo et al., 2012), and they are very fast and low cost.", "startOffset": 122, "endOffset": 139}, {"referenceID": 96, "context": "Using the IBM model one, (Popovi\u0107 et al., 2011) evaluate the translation quality by calculating the similarity scores of source and target (translated) sentence without using reference translation, based on the morphemes, 4-gram POS and lexicon probabilities.", "startOffset": 25, "endOffset": 47}, {"referenceID": 27, "context": "(Dahlmeier et al., 2011) develop the evaluation metrics TESLA, combining the synonyms of bilingual phrase tables and POS information in the matching task.", "startOffset": 0, "endOffset": 24}, {"referenceID": 50, "context": "Other similar works using POS information include (Gim\u00e9nez and M\u00e1rquez, 2007; Popovic and Ney, 2007; Han et al., 2014).", "startOffset": 50, "endOffset": 118}, {"referenceID": 98, "context": "To measure a MT system\u2019s performance in translating new text-types, such as in what ways the system itself could be extended to deal with new text-types, (Povlsen et al., 1998) perform a research work focusing on the study of Englishto-Danish machine-translation system.", "startOffset": 154, "endOffset": 176}, {"referenceID": 3, "context": "Assuming that the similar grammatical structures should occur on both source and translations, (Avramidis et al., 2011) perform the evaluation on source (German) and target (English) sentence employing the features of sentence length ratio, unknown words, phrase numbers including noun phrase, verb phrase and prepositional phrase.", "startOffset": 95, "endOffset": 119}, {"referenceID": 72, "context": "Other similar works using the phrase similarity include the (Li et al., 2012)", "startOffset": 60, "endOffset": 77}, {"referenceID": 80, "context": "Other works that using syntactic information into the evaluation include (Lo and Wu, 2011a) and (Lo et al., 2012) that use an automatic shallow parser and RED metric (Yu et al.", "startOffset": 96, "endOffset": 113}, {"referenceID": 114, "context": ", 2012) that use an automatic shallow parser and RED metric (Yu et al., 2014) that applies dependency tree, etc.", "startOffset": 60, "endOffset": 77}, {"referenceID": 41, "context": "sify atomic elements in the text into different entity categories (Marsh and Perzanowski, 1998; Guo et al., 2009).", "startOffset": 66, "endOffset": 113}, {"referenceID": 9, "context": "In the quality estimation of machine translation task of WMT 2012, (Buck, 2012) introduces the features including named entity, in addition to discriminative word lexicon, neural networks, back off behavior (Raybaud et al.", "startOffset": 67, "endOffset": 79}, {"referenceID": 99, "context": "In the quality estimation of machine translation task of WMT 2012, (Buck, 2012) introduces the features including named entity, in addition to discriminative word lexicon, neural networks, back off behavior (Raybaud et al., 2011) and edit distance, etc.", "startOffset": 207, "endOffset": 229}, {"referenceID": 86, "context": "One of the widely used synonym database in NLP literature is the WordNet (Miller et al., 1990), which is an English lexical database grouping English words into sets of synonyms.", "startOffset": 73, "endOffset": 94}, {"referenceID": 26, "context": "Instead of the pure logical or mathematical entailment, the textual entailment in natural language processing (NLP) is usually performed with a relaxed or loose definition (Dagan et al., 2006).", "startOffset": 172, "endOffset": 192}, {"referenceID": 25, "context": "Instead of the pure logical or mathematical entailment, the textual entailment in natural language processing (NLP) is usually performed with a relaxed or loose definition (Dagan et al., 2006). For instance, according to text fragment TB, if it can be inferred that the text fragment TA is most likely to be true then the relationship TB \u21d2 TA also establishes. That the relation is directive also means that the inverse inference (TA\u21d2 TB) is not ensured to be true (Dagan and Glickman, 2004). Recently, Castillo and Estrella (2012) present a new approach for MT evaluation based on the task of \u201cSemantic Textual Similarity\u201d.", "startOffset": 173, "endOffset": 532}, {"referenceID": 83, "context": "Further knowledge of paraphrase from the aspect of linguistics is introduced in the works of (McKeown, 1979; Meteer and Shaked, 1988; Barzilayand and Lee, 2003).", "startOffset": 93, "endOffset": 160}, {"referenceID": 101, "context": "(Snover et al., 2006) describe a new evaluation", "startOffset": 0, "endOffset": 21}, {"referenceID": 80, "context": "Furthermore, instead of using uniform weights, (Lo et al., 2012) weight the different types of semantic roles according to their relative importance to the adequate preservation of meaning, which is empiri-", "startOffset": 47, "endOffset": 64}, {"referenceID": 35, "context": "(Gamon et al., 2005) propose LMSVM, language-model, support vector machine, method investigating the possibility of evaluating", "startOffset": 0, "endOffset": 20}, {"referenceID": 36, "context": "In the latest version, they extended the permutation-tree (Gildea et al., 2006) into permutation-forests model (Stanojevi\u0107 and Sima\u2019an, 2014b), and showed stable good perfor-", "startOffset": 58, "endOffset": 79}, {"referenceID": 44, "context": "For instances, (Guzm\u00e1n et al., 2015; Guzmn et al., 2017) used neural networks for MTE for pair wise modeling to choose best hypothesis translation by comparing candidate translations with reference, integrating syntactic and semantic information into NNs.", "startOffset": 15, "endOffset": 56}, {"referenceID": 45, "context": "For instances, (Guzm\u00e1n et al., 2015; Guzmn et al., 2017) used neural networks for MTE for pair wise modeling to choose best hypothesis translation by comparing candidate translations with reference, integrating syntactic and semantic information into NNs.", "startOffset": 15, "endOffset": 56}, {"referenceID": 81, "context": "While (Ma et al., 2016) designed a new metric based on bi-directional LSTM, which is similar with the work of (Guzm\u00e1n et al.", "startOffset": 6, "endOffset": 23}, {"referenceID": 44, "context": ", 2016) designed a new metric based on bi-directional LSTM, which is similar with the work of (Guzm\u00e1n et al., 2015) but with less complexity by allowing the evaluation of single hypothesis with reference, instead of pairwise situation.", "startOffset": 94, "endOffset": 115}, {"referenceID": 64, "context": "If different MT systems produce translations with different qualities on a data set, how can we ensure that they indeed own different system quality? To explore this problem, (Koehn, 2004) performs a research work on the statistical significance test for machine translation evaluation.", "startOffset": 175, "endOffset": 188}, {"referenceID": 46, "context": "of a second alternative hypothesis (Hald, 1998).", "startOffset": 35, "endOffset": 47}, {"referenceID": 95, "context": "Pearson\u2019s correlation coefficient (Pearson, 1900) is commonly represented by the Greek letter \u03c1.", "startOffset": 34, "endOffset": 49}, {"referenceID": 14, "context": "is another algorithm to measure the correlations of automatic evaluation and manual judges, especially in recent years (Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011).", "startOffset": 119, "endOffset": 235}, {"referenceID": 15, "context": "is another algorithm to measure the correlations of automatic evaluation and manual judges, especially in recent years (Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011).", "startOffset": 119, "endOffset": 235}, {"referenceID": 16, "context": "is another algorithm to measure the correlations of automatic evaluation and manual judges, especially in recent years (Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011).", "startOffset": 119, "endOffset": 235}, {"referenceID": 54, "context": "Kendall\u2019s \u03c4 (Kendall, 1938) has been used in recent years for the correlation between automatic order and reference order (Callison-Burch et al.", "startOffset": 12, "endOffset": 27}, {"referenceID": 16, "context": "Kendall\u2019s \u03c4 (Kendall, 1938) has been used in recent years for the correlation between automatic order and reference order (Callison-Burch et al., 2010; Callison-Burch et al., 2011; Callison-Burch et al., 2012).", "startOffset": 122, "endOffset": 209}, {"referenceID": 68, "context": "More concretely, (Lapata, 2003) proposes the use of Kendall\u2019s \u03c4 , a measure of rank correlation, estimating the distance between", "startOffset": 17, "endOffset": 31}, {"referenceID": 69, "context": "For example, (Callison-Burch et al., 2006b; Callison-Burch et al., 2007b; Lavie, 2013) mentioned that, through some qualitative analysis on", "startOffset": 13, "endOffset": 86}, {"referenceID": 40, "context": "much better than the traditional ones especially on the challenging sentence-level evaluation, though they are not popular yet such as nLEPOR and SentBLEU-Moses (Graham et al., 2015; Graham and Liu, 2016).", "startOffset": 161, "endOffset": 204}, {"referenceID": 65, "context": "Furthermore, the automatic evaluation metrics tend to ignore the relevance of words (Koehn, 2010), for instance, the name entities and core concepts are more important than punctuations and determiners but most automatic evaluation metrics put the same weight on each word of the sentences.", "startOffset": 84, "endOffset": 97}, {"referenceID": 92, "context": "For instance, what is the meaning of -16094 score by the MTeRater metric (Parton et al., 2011) or 1.", "startOffset": 73, "endOffset": 94}, {"referenceID": 47, "context": "find one interesting metric family LEPOR and hLEPOR (Han et al., 2012; Han, 2014) that can give a somehow meaningful score for a somehow recognized good translation, e.", "startOffset": 52, "endOffset": 81}, {"referenceID": 51, "context": "find one interesting metric family LEPOR and hLEPOR (Han et al., 2012; Han, 2014) that can give a somehow meaningful score for a somehow recognized good translation, e.", "startOffset": 52, "endOffset": 81}, {"referenceID": 65, "context": "mance towards metric;meaningful, score should give intuitive interpretation of translation quality;consistent, repeated use of metric should give same results;correct, metric must rank better systems higher as mentioned in (Koehn, 2010), of which the low cost, tunable and consistent characteristics are easily achieved by the metric developers, but the rest two goals (meaningful and correct) are usually the challenges in front of the NLP researchers.", "startOffset": 223, "endOffset": 236}, {"referenceID": 29, "context": "For instance, in the DARPA GALE report (Dorr et al., 2009), researchers first introduced the automatic", "startOffset": 39, "endOffset": 58}, {"referenceID": 89, "context": "Mrquez (Mrquez, 2013) introduced the Asiya online interface developed by their institute for MT output error analysis, where they also briefly mentioned the MT evaluation developments of", "startOffset": 7, "endOffset": 21}], "year": 2017, "abstractText": "We introduce the Machine Translation (MT) evaluation survey that contains both manual and automatic evaluation methods. The traditional human evaluation criteria mainly include the intelligibility, fidelity, fluency, adequacy, comprehension, and informativeness. The advanced human assessments include task-oriented measures, post-editing, segment ranking, and extended criteriea, etc. We classify the automatic evaluation methods into two categories, including lexical similarity scenario and linguistic features application. The lexical similarity methods contain edit distance, precision, recall, F-measure, and word order. The linguistic features can be divided into syntactic features and semantic features respectively. The syntactic features include part of speech tag, phrase types and sentence structures, and the semantic features include named entity, synonyms, textual entailment, paraphrase, semantic roles, and language models. The deep learning models for evaluation are very newly proposed. Subsequently, we also introduce the evaluation methods for MT evaluation including different correlation scores, and the recent quality estimation (QE) tasks for MT. This paper differs from the existing works (Dorr et al., 2009; EuroMatrix, 2007) from several aspects, by introducing some recent development of MT evaluation measures, the different classifications from manual to automatic evaluation measures, the introduction of recent QE tasks of MT, and the concise construction of the content. We hope this work will be helpful for MT researchers to easily pick up some metrics that are best suitable for their specific MT model development, and help MT evaluation researchers to get a general clue of how MT evaluation research developed. Furthermore, hopefully, this work can also shine some light on other evaluation tasks, except for translation, of NLP fields. 1", "creator": "LaTeX with hyperref package"}}}