{"id": "1605.04614", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2016", "title": "DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple's iOS, OS X and tvOS developed in Metal and Swift", "abstract": "In this paper we present DeepLearningKit - an open source framework that supports using pretrained deep learning models (convolutional neural networks) for iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to utilize the GPU efficiently and Swift for integration with applications, e.g. iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS X desktop applications. The goal is to support using deep learning models trained with popular frameworks such as Caffe, Torch, TensorFlow, Theano, Pylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time required to train Deep Learning models we suggest an App Store like model to distribute and download pretrained and reusable Deep Learning models.", "histories": [["v1", "Sun, 15 May 2016 23:19:48 GMT  (3390kb,D)", "http://arxiv.org/abs/1605.04614v1", "9 pages, 12 figures, open source documentation and code at deeplearningkit.org and github.com/deeplearningkit"]], "COMMENTS": "9 pages, 12 figures, open source documentation and code at deeplearningkit.org and github.com/deeplearningkit", "reviews": [], "SUBJECTS": "cs.LG cs.DC cs.NE", "authors": ["amund tveit", "torbj{\\o}rn morland", "thomas brox r{\\o}st"], "accepted": false, "id": "1605.04614"}, "pdf": {"name": "1605.04614.pdf", "metadata": {"source": "CRF", "title": "DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple\u2019s iOS, OS X and tvOS developed in Metal and Swift", "authors": ["Amund Tveit", "Torbj\u00f8rn Morland"], "emails": ["opensource@deeplearningkit.org"], "sections": [{"heading": "1 GPU Accelerated Deep Learning Library", "text": "The Metal programming language is the most efficient way to use the GPU on Apple's iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7]. This paper gives a brief overview of a deep learning library based on Metal and Swift called DeepLearningKit, in particular parts of Convolutionary Neural Network Operators for the GPU. DeepLearningKit supports On-Deep Learning on Apple's iOS, OS X and tvOS.DeepLearningKit currently has shader functions for Convolutionary Neural Networks implemented in metal and parallelized for the GPU. Operators include: Convolution, Pooling, Rectifier Layer and Softmax. In terms of the supported Deep Learning model, it has support for Min Lin's Caffe-trained Network [8] (NIN - trained on CIFAR-10, CIF100-Net and ImageNet)."}, {"heading": "1.1 Experiences with PowerVR G6430/GT7600 on iPhone 5S/6S", "text": "The performance of the DeepLearningKit Deep Learning, which ranges from the iPhone 5S (with PowerVR G6430 according to The iPhone 5S Review (AnandTech)) to the iPhone 6S (with PowerVR GT7600 according to Apple iPhone 6S Plus vs. Samsung Galaxy S6 Edge +), has an order of magnitude of improved performance. The computation time for performing a 20-layer deep Convolutionary Neural Network Model * http: / / DeepLearningKit.orgar Xiv: 160 5.04 614v 1 [cs.L G] 15 Mfor image recognition went from about 2 seconds to less than 100 milliseconds. The network we used was a NIN network trained on CIFAR-10. Based on XCode profiles, we suspect that the metal computation drivers for the GPU were not finely tuned, so that with tools of lower levels (e.g. for OpenCL / Vulcan SPIR-V) the performance of the GU could be significantly increased by 100 seconds (or 0.03 seconds)."}, {"heading": "1.2 Effort needed to port from Metal/Swift to OpenCL/Vulkan Compute SPIR-V", "text": "The code needed to set up and execute deep learning on the GPU, load / store data and set up the deep learning pipeline (revolutionary neural network) is executed in Swift (for easy app integration on iOS, OS X and tvOS), but can be moved to a selection language (e.g. Java on Android or C + + / C on other devices).The Swift API for setting up metal is similar to the corresponding OpenCL C API as shown in Figure 2.The deep learning GPU code (e.g. shader functions with folding calculations, etc.) is written in metal, a language that is a subset of C + + -11, and also has its own (relatively few) additions compared to C + + 11. Porting the metcode GPU code to OpenCL should be relatively straightforward, as OpenCL is also a subset of C + +, for example see Figures 3 and 4 for a rectifier function written in both metal and CL."}, {"heading": "1.3 Roadmap for Deep Learning for OpenCL/Vulkan (or Metal)", "text": "Here is a brief overview of the things we are working on or which we are using on our roadmap.1. Use FFT-based folding - with precalculated folding filters [13, 14] 2. use lower resolution on floating points - to increase performance and support larger models (currently 32-bit float or complex numbers are used - i.e. 2x32 bits per complex number to prepare for FFT-based folding) [15, 16] 3. avoid copying memory between CPU and GPU more than necessary [17] 4. add support for other types of pre-formed networks than deep Convolutionary Neural Networks, e.g. recurring neural networks [18, 19] 5. consider more in-place calculations to save memory, i.e., support larger models. Try larger portions of metal API wrt memory layout, thread groups to increase performance (this refers to 1 network, 20, 21, 7., 24.) but nevertheless, use smaller networks for students."}, {"heading": "2 App Store for Deep Learning Models", "text": "Given the immense asymmetry in the time it takes to learn a deep learning model to use it (e.g. to do image recognition), it makes perfect sense to build a large repository of upstream models that can be used multiple times. As there are several popular tools used to learn deep learning models (e.g. Caffe, Torch, Theano, DeepLearning4J, PyLearn and Nervana), we are working to support upstream models in an app store for deep learning models (currently we primarily work with Caffe CNN models).The tweet in Figure 10 shows how much energy is needed to educate a deep learning model (per night)."}, {"heading": "3 Deep Learning Model Importer", "text": "Importing deep learning models into the model app store requires the support of the most important deep learning tools. The most commonly used in research are Torch and Caffe, and DeepLearningKit currently supports the conversion of trained caffe models into JSON (i.e. ready to be uploaded to the app store) and the import into Swift / Metal (or OpenCL / Volcano with port) for the mobile app. To get support for importing Constitutional Neural Networks from other tools, it may be necessary to have an intimate look into the tools, but since Constitutional Neural Networks are quite similar by nature, complexity and effort for creating importers are not daunting. To propose and support standards - e.g. for 1. Deep learning network descriptions (i.e. entering into the training phase) 2. Entering data formats (images, text, input, etc.) Dekan Learning modules may facilitate the use of these in training networks for longer periods of time."}, {"heading": "4 Conclusion", "text": "Performed a presentation of DeepLearningKit GPU-accelerated Deep Learning for Metal / Swift and presented a guide on how to port / customize it to OpenCL / Vulkan SPIR-V."}], "references": [{"title": "Working with Metal - Overview", "author": ["Jeremy Sandmel"], "venue": "Apple WWDC, published online - https: //developer.apple.com/videos/wwdc/2014/,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Working with Metal - Fundamentals", "author": ["Richard Schreyer", "Aaftab Munshi"], "venue": "Apple WWDC, published online - https://developer.apple.com/videos/wwdc/2014/,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Working with Metal - Advanced", "author": ["Gokhan Avkarogullari", "Aaftab Munshi", "Serhat Tekin"], "venue": "Apple WWDC, published online - https://developer.apple.com/videos/wwdc/2014/,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "GPGPU Performance of Swift/Metal vs Accelerate on iPhone 6/5S, iPad Air and iPad Mini", "author": ["Amund Tveit"], "venue": "Memkite, published online http://memkite.com/blog/2014/12/18/ gpgpu-performance-of-swiftmetal-vs-accelerate-on-iphone-6-5s-ipad-air-and-ipad-mini/,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "What\u2019s New in Metal, Part 1. Apple WWDC, published online - https://developer", "author": ["Rav Dhiraj"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "What\u2019s New in Metal", "author": ["Dan Omachi", "Anna Tikhonova"], "venue": "Part 2. Apple WWDC, published online https://developer.apple.com/videos/wwdc/2015/,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["James Bergstra", "Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio"], "venue": "In Proceedings of the Python for Scientific Computing Conference (SciPy),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Deep Learning for Speech Recognition. published online http://memkite.com/ blog/2015/02/11/deep-learning-for-speech-recognition", "author": ["Amund Tveit"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Deep Learning for Natural Language Processing. published online http://memkite", "author": ["Amund Tveit"], "venue": "com/blog/2015/01/29/deep-learning-for-natural-language-processing/,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Fast convolutional nets with fbfft: A GPU performance evaluation", "author": ["Nicolas Vasilache", "Jeff Johnson", "Micha\u00ebl Mathieu", "Soumith Chintala", "Serkan Piantino", "Yann LeCun"], "venue": "CoRR, abs/1412.7580,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Deep learning with limited numerical precision", "author": ["Suyog Gupta", "Ankur Agrawal", "Kailash Gopalakrishnan", "Pritish Narayanan"], "venue": "CoRR, abs/1502.02551,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Why are Eight Bits Enough for Deep Neural Networks?  published online http://petewarden.com/2015/05/23/ why-are-eight-bits-enough-for-deep-neural-networks", "author": ["Pete Warden"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Example of Sharing Memory Between GPU and CPU with Swift and Metal for iOS8", "author": ["Amund Tveit"], "venue": "Memkite, published online http://memkite.com/blog/2014/12/30/ example-of-sharing-memory-between-gpu-and-cpu-with-swift-and-metal-for-ios8,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Deeplearning.University - Bibliographies from Lisa Labs (Yoshua Bengio\u2019s Lab).  published online http://memkite.com/blog/2015/04/17/ deeplearning-university-bibliographies-from-lisa-labs-yoshua-bengios-lab", "author": ["Amund Tveit"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 1, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 2, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 3, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 104, "endOffset": 116}, {"referenceID": 4, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 136, "endOffset": 145}, {"referenceID": 5, "context": "The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7].", "startOffset": 136, "endOffset": 145}, {"referenceID": 6, "context": "We also have preliminary support running Theano[9] trained LeNet (trained on MNIST digit classification dataset).", "startOffset": 47, "endOffset": 50}, {"referenceID": 7, "context": "g speech recognition[10] or natural language processing[11].", "startOffset": 20, "endOffset": 24}, {"referenceID": 8, "context": "g speech recognition[10] or natural language processing[11].", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "use FFT-based convolution - with precalculated convolution filters [13, 14]", "startOffset": 67, "endOffset": 75}, {"referenceID": 10, "context": "2x32 bit per complex number to prepare for FFT-based convolution) [15, 16] 3.", "startOffset": 66, "endOffset": 74}, {"referenceID": 11, "context": "2x32 bit per complex number to prepare for FFT-based convolution) [15, 16] 3.", "startOffset": 66, "endOffset": 74}, {"referenceID": 12, "context": "avoid copying memory between CPU and GPU more than needed [17] 4.", "startOffset": 58, "endOffset": 62}, {"referenceID": 13, "context": "recurring neural networks[18, 19] 5.", "startOffset": 25, "endOffset": 33}], "year": 2016, "abstractText": "In this paper we present DeepLearningKit an open source framework that supports using pretrained deep learning models (convolutional neural networks) for iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to utilize the GPU efficiently and Swift for integration with applications, e.g. iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS X desktop applications. The goal is to support using deep learning models trained with popular frameworks such as Caffe, Torch, TensorFlow, Theano, Pylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time required to train Deep Learning models we suggest an App Store like model to distribute and download pretrained and reusable Deep Learning models. 1 GPU Accelerated Deep Learning Library The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7]. This paper gives a brief overview of a Metal and Swift based Deep Learning library named DeepLearningKit, in particular parts of Metal convolutional neural network operators for the GPU. DeepLearningKit supports on-device Deep Learning on Apple\u2019s iOS, OS X and tvOS. DeepLearningKit currently has shader functions for convolutional neural networks implemented in Metal and parallelized for the GPU, operators include: convolution, pooling, rectifier layer and softmax. In terms of deep learning model supported it has support for Min Lin\u2019s Caffe-trained Network In Network[8] (NIN trained on CIFAR-10, CIFAR-100 and ImageNet data sets). We also have preliminary support running Theano[9] trained LeNet (trained on MNIST digit classification dataset). The reason we have chosen NIN is that the network is small compared to other deep convolutional neural networks, but at the same time provide very high classification accuracy on images, e.g. better than AlexNet. GoogleLeNet (winner of Imagenet 2014) uses a similar approach as NIN[?]. NIN can perhaps also be used in non-image domains, e.g speech recognition[10] or natural language processing[11]. In particular one could attempt to adapt Zhang and Lecun\u2019s encoding and 1D convolutional operators in \u201cText Understanding from Scratch\u201d[12] and use it with NIN. 1.1 Experiences with PowerVR G6430/GT7600 on iPhone 5S/6S The performance of DeepLearningKit Deep Learning going from iPhone 5S (with PowerVR G6430 according to The iPhone 5S Review (AnandTech)) to iPhone 6S (with PowerVR GT7600 according to Apple iPhone 6S Plus vs. Samsung Galaxy S6 Edge+) we got 1 order of magnitude in improved performance. Calculation time to run through a 20 layer deep convolutional neural network model \u2217http://DeepLearningKit.org 1 ar X iv :1 60 5. 04 61 4v 1 [ cs .L G ] 1 5 M ay 2 01 6", "creator": "LaTeX with hyperref package"}}}