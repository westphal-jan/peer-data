{"id": "1605.04652", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "Fast and Accurate Performance Analysis of LTE Radio Access Networks", "abstract": "An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy.", "histories": [["v1", "Mon, 16 May 2016 05:31:01 GMT  (1047kb,D)", "https://arxiv.org/abs/1605.04652v1", null], ["v2", "Tue, 17 May 2016 20:00:59 GMT  (333kb,D)", "http://arxiv.org/abs/1605.04652v2", null]], "reviews": [], "SUBJECTS": "cs.DC cs.LG cs.NI", "authors": ["anand padmanabha iyer", "ion stoica", "mosharaf chowdhury", "li erran li"], "accepted": false, "id": "1605.04652"}, "pdf": {"name": "1605.04652.pdf", "metadata": {"source": "META", "title": "Fast and Accurate Performance Analysis of LTE Radio Access Networks", "authors": ["Anand Padmanabha", "Li Erran Li"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we examine this trade-off in the context of a specific domain, the Cellular Radio Access Networks (RAN). Our choice of this area is influenced by its similarities with several other domains that produce real-time data, our access to a large live dataset and its real-time work and dimensionality, which makes it a natural solution for a popular analytics technique, machine learning (ML). We find that the trade-off can be resolved with latency accuracy by two broad, generic techniques: intelligent data grouping and task formulations that use domain characteristics. Building on this, we present CellScope, a system that addresses this challenge by applying domain-specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. This goal is achieved through three techniques: feature engineering to transform raw data into effective functions, a PCA-inspired similarity metric that covers multiple geographic modes of similarity."}, {"heading": "1 Introduction", "text": "This year, we have reached a point where it can only take one year to reach an agreement."}, {"heading": "2 Background and Motivation", "text": "This section briefly discusses mobile networks, focusing on the LTE network architecture, protocol procedures, and measurement data, and then motivating the problem."}, {"heading": "2.1 LTE Network Primer", "text": "In this context, it should be noted that the solution to the problem is not a purely formal solution, but a purely formal solution, which involves finding a solution that meets the needs of each individual."}, {"heading": "2.2 RAN Troubleshooting Today", "text": "Current RAN network monitoring depends on aggregated Key Performance Indicators (KPIs) at the cell level. Existing practice is to use power counters to derive these KPIs. Derived KPIs are then aggregated by domain experts, aggregated over specific predefined time frames. Based on domain knowledge and operational experience, these KPIs are used to determine whether Service Level Agreements (SLAs) are being complied with. For example, an operator may have designed the network to have no more than 0.5% call failures in a 10-minute window. If a KPI that is being monitored exceeds an alarm is triggered and a ticket is created, this ticket is then processed by experts who often examine the cause of the problem manually. Multiple commercial solutions exist [3-5, 16] thereof 1Some of the most important physical layer parameters useful for diagnosis are described in Table 1, where our measurement data set consists of nearly 400 pieces of additional data."}, {"heading": "2.3 Need for Domain Specific Approach", "text": "We are now discussing the difficulties in applying machine learning to solve the RAN performance analysis problem, thus motivating the need for a new domain-specific solution."}, {"heading": "2.3.1 Ineffectiveness of Global Modelling", "text": "A common solution for applying ML to a dataset is to treat the dataset as one unit and build a model of the entire data. However, base stations on a mobile network have different characteristics, making the use of a global model ineffective. To illustrate this problem, we conducted an experiment where the goal was to build a model for network call failures. First, we run a decision-making algorithm to obtain a single model for the network. At the other extreme of this approach, training one model per base station. Figure 2a shows the results of this experiment, where data collected over a period of one hour was used to ensure that there was enough data for the algorithms to achieve statistically significant results."}, {"heading": "2.3.2 Latency/Accuracy Issues with Local Models", "text": "It is natural to consider one model per Base Unit as the definitive solution to this problem. However, this approach also has problems. Due to differences in the properties of the Base Units, the amount of data they collect varies, so they cannot generate enough data at small intervals to achieve valid results. To demonstrate this, we are conducting an experiment with two different algorithms to collect data over different latencies; the first algorithm (Alg 1) builds a connection error classification model, while the second (Alg 2) builds a regression model to predict and explain throughput anomalies. The results of this experiment are presented in Figure 2c. The behavior of the first algorithm is obvious; as it receives more data, its accuracy improves due to the slow variability of the underlying causes of disturbances."}, {"heading": "2.3.3 Need for Model Updates", "text": "To illustrate this, we repeated the experiment in which we created one call failure decision tree model per Base Unit. However, instead of training and testing on portions of the same data set, we train on one hour's worth of data and apply it to the next hour. Figure 2a shows that the accuracy of an obsolete model decreases by 12%. Therefore, it is important to keep the model fresh by incorporating learning from the incoming data while removing historical knowledge. Such gliding updates of ML models in a general environment are difficult because they need to be retrained from the ground up. Additionally, mobile networks consist of several thousand base stations, a number that increases with increasing user demand and the ease of providing small cells. Therefore, one approach per Base Unit requires the creation, maintenance and updating of a huge set of models (e.g. our network consisted of over 13,000 base stations)."}, {"heading": "2.3.4 Why not Spatial/Spatio-Temporal Partitioning?", "text": "The obvious solution to combat this trade-off is to intelligently combine data from multiple Base Stations. It is intuitive to consider this a spatial partitioning problem, since Base Stations are geographically separated in the real world. Thus, a space partitioner that combines data from Base Stations within a geographical region must be able to provide good results. Unfortunately, this is not the case, and we will use a simple example to motivate this. Consider two Base Stations, one in the center of Times Square in New York and the other one mile away in a residential area. Using a spatial partitioning scheme that divides the space into equally large levels would probably result in a combination of data from these Base Stations. However, this is not desirable as the properties of these Base Stations are located in the center of Times Square in New York and the other mile away in a residential area. We illustrate this using the Drop Experiment. Figure 2a shows the performance of a model of a nearby spatial data we combine in the same area."}, {"heading": "3.1 Problem Statement", "text": "The ultimate goal of CellScope is to enable fast and accurate RAN performance diagnosis by resolving the trade-off between the latency of data acquisition and the accuracy achieved; the main difficulty arises from the fundamental trade-off between insufficient data to build accurate enough models in short periods of time and waiting for enough data, resulting in outdated results that are impossible to resolve in a general environment. In addition, we must support efficient modifications of the learned models to take into account the temporal nature of our environment to avoid data durability."}, {"heading": "3.2 Architectural Overview", "text": "Figure 3 shows the overall architecture of CellScope, which has the following key components: Input data: CellScope uses owner data that is readily available on cellular networks (\u00a7 2.1). Base stations collect tracks independently and send them to the associated MME. Records, if necessary (users move, the MME merges records, thus generating tracks at multiple base stations) and uploads them to a data center.4 Feature Engineering: Next, CellScope uses domain knowledge to transform the raw data and constructs a set of features that allow learning (e.g. calculating interference rates). We also use log details and algorithms (e.g. link fit) in the physical layer. 3In our measurements, a base station is used in a very popular spot that includes more than 300 UEs and carries uplink and downlink traffic several times compared to another base station that serves only one mile."}, {"heading": "4 Resolving Latency-Accuracy Trade-off", "text": "In this section, we present how CellScope uses domain-specific machine learning to mitigate the trade-off between latency and accuracy. First, we discuss a high-level overview of RAN-specific feature engineering that processes the data for learning (\u00a7 4.1). Next, we describe the MTL formulation of CellScope (\u00a7 4.2) and discuss how we can build fast, precise and incremental models. Finally, we explain how CellScope achieves a grouping that captures commonalities between base stations using a novel PCA-based partitioner (\u00a7 4.3). Finally, we summarize our approach in \u00a7 4.4."}, {"heading": "4.1 Feature Engineering", "text": "Feature engineering, the process of transforming raw data into a set of features that can be used effectively by machine learning algorithms, is a fundamental component of ML applications [51]. Usually performed by domain experts, it is often the first step in applying learning techniques. Owner traces contain several hundred fields that are associated with LTE networking methods. Unfortunately, many of these fields are not suitable for modeling in its current form. Multiple fields are collected in a format that uses a compact representation. For example, block error rates must be calculated across multiple datasets to take time into account. Moreover, these datasets are not self-contained and several datasets need to be analyzed to create a feature for a particular procedure. In \u00a7 7, we describe many of the specific feature engineering that helped CellScope uncover network problems."}, {"heading": "4.2 Multi-Task Learning", "text": "The trade-off between latency and accuracy makes it difficult to achieve both low latency and high accuracy in applied machine learning tasks (\u00a7 2). The ideal case scenario in CellScope is if there is infinite amounts of data with no latency available per Base Unit. In this scenario, we would have a learning task for each Base Unit that produces a model with the best possible achievable accuracy. In reality, our setting has several tasks, each with its own data. However, each task does not have enough data to produce models with acceptable accuracy within a given latency budget. This makes our setting an ideal candidate for Multi-Task Learning (MTL), a pioneering field of research in machine learning. The key idea behind MTL is to learn from other tasks by weakly coupling their parameters so that the statistical efficiency of many tasks can be increased [9, 10, 17, 44]. In particular, if we are interested in bs( 2) bsx (1) form (x), x (x is a basis for x, x."}, {"heading": "4.2.1 CellScope\u2019s MTL Formulation", "text": "To address the difficulty in applying MTL due to the violation of the task dependency assumption in RANs, we can use domain-specific characteristics. Although independent learning tasks (learning per Base Unit) are not correlated, they have a specific non-random structure. However, the performance characteristics of nearby Base Units have been affected by similar underlying characteristics. However, we assume that each group divides its own learning tasks into groups of dependent tasks to which MTL can be applied. MTL in the face of dependency violation has been studied in the recent past [20, 25]."}, {"heading": "4.2.2 Hybrid Modeling for Fast Model Updates", "text": "The estimation of the model in eq. (3) could be presented as \"1 regulated loss minimization problem\" (45), where L (h: fbs), y) is a non-negative loss function consisting of parameters for a particular Base Unit and must therefore capture the error in the prediction for it in the group, and \u03bb > 0 is a regulation parameter scaling the penalty R (x: fbs) for the Base Unit. However, since the Base Units are grouped into correlated task clusters, we can combine the features used for each Base Unit into a common common model fc and a specific Base Unit."}, {"heading": "4.2.3 Anomaly Detection Using Concept Drift", "text": "A common use case of learning tasks for RAN performance analysis is the detection of anomalies. For example, an operator might be interested in learning when there is a sudden increase in call declines. At the simplest level, it is easy to answer this question by simply monitoring the number of calls declines at each base station. However, a simple answer to such questions is rarely useful. If there is a sudden increase in call declines, then it is useful to understand whether the problem affects an entire region and its cause. [19] Our MTL approach and the ability to perform rapid incremental learning provide a better solution for detecting and diagnosing anomalies. Concept drift is a term used to describe the phenomenon where the underlying distribution of training data for a machine learning model changes [19]. CellScope uses this to detect anomalies as concept drift and quickly test any existing data for it, as we can only detect a minor technical problem while a larger one can be detected."}, {"heading": "4.3 Data Grouping for MTL", "text": "After discussing the MTL formulation of CellScope, we now turn to the question of how CellScope achieves an efficient grouping of cellular data sets that enables accurate learning. Our data partitioning is based on Principal Component Analysis (PCA), a widely used technique in multivariate analysis [32]. PCA uses an orthogonal coordinate transformation to map a given set of points into a new coordinate space. Each of the new subspaces is commonly referred to as the main component. As the coordinate space is equal or smaller than the original, PCA is used for dimensionality reduction. [28] In their pioneering work, Lakhina et.al. [28] demonstrated the usefulness of PCA for detecting network anomalies. They observed that it is possible to determine normal behavior and abnormal (abnormal) behavior using PCA - the main components explain most of the normal behavior while the remaining areas are captured by the anomalies."}, {"heading": "4.3.1 Notation", "text": "Since traces of the carrier level are continuously collected, we consider a buffer of carriers as a measurement matrix A. Therefore, A consists of m carrier data sets, each with n observed parameters, which make them a m \u00b7 n time series matrix. It should be noted that n is in the order of a few hundred fields, while m can be much higher depending on the length of the buffer interval. We force n to be specified in our setting - each measurement matrix must contain n columns. To make this matrix usable for PCA analysis, we adjust the columns so that they have an average of zero. By applying PCA to each measurement matrix A, we can obtain a set of k main components, ordered by the amount of data variance they capture."}, {"heading": "4.3.2 PCA Similarity", "text": "It is intuitive to recognize that many measurement matrices can be formed on the basis of different criteria. Suppose we are interested in determining whether two measurement matrices are similar. One way to achieve this is to compare the main components of the two matrices. Krzanowski [27] describes such a similarity factor. Consider two matrices A and B with the same number of columns, but not rows. The similarity factor between A and B is defined as: SF = track (LM \u2032 ML \u2032) = k \u2211 i = 1k \u0445 j = 1 cos2 \u03b8i jwo L, M are the first k major components of A and B, and successi j is the angle between the ith component of A and the jth component of B. Thus, the similarity factor takes into account all combinations of k components of both matrices."}, {"heading": "4.3.3 CellScope\u2019s Similarity Metric", "text": "The similarity in our setting bears a slightly different term: We do not want a strict similarity between the measurement components, but only need similarity between the corresponding main components. This ensures that algorithms capture the underlying main influences and trends in observation sets that are not exactly similar. Unfortunately, SF does not meet our requirements; therefore, we propose a simpler measurement variable. Let's look at two measurement matrices A and B as before, where A is of size mA \u00b7 n and B is of size mB \u00b7 n. By applying PCA to the matrices, we can obtain k main components by means of a heuristics. We get the first k components, which capture 95% of the variance. From the PCA, we obtain the resulting weight vector or load, which is a n \u00b7 k matrix: for each major component in k, the load describes the weight of the original n characteristics. Intuitively, this can be regarded as a rough measurement of the influence of n characteristics on the main component ellope."}, {"heading": "4.3.4 Using Similarity Metric for Partitioning", "text": "First, we group the beams into measurement matrices by separating them according to the cell on which the beam originated, based on our observation that the cell is the lowest level at which an anomaly would manifest itself. Then, we create a graph G (V, E) in which the vertices are the individual measurement matrices of the cells. If the SFCellScope is below a threshold between them, an edge is drawn between two matrices. To calculate SFCellScope, we simply use the geographic distance between the cells as weight. Once the graph is created, we run connected components on that graph to obtain the partitions. Using the linked component algorithm is not fundamental, but it is also possible to use a cluster algorithm instead. For example, a k-mean cluster algorithm that could use SFCellScope to merge clusters would yield similar results."}, {"heading": "4.3.5 Managing Partitions Over Time", "text": "An important consideration is the management and handling of group changes over time. In order to detect group changes, it is necessary to establish correspondence between groups over time intervals. Once this correspondence is established, the hybrid CellScope model facilitates adaptation to changes. Due to the division of our model into common and base station specific components, small changes to the group do not affect the common model. In these cases, we can simply boot the new base station with the common model and then start learning specific features. On the other hand, if there are significant changes to a group, the common model may no longer be valid, which can easily be determined by concept drift. In such cases, the offline model could be rebuilt."}, {"heading": "4.4 Summary", "text": "We will now summarize how CellScope resolves the fundamental trade-off between latency and accuracy. To cope with the fact5suggestions for performing geographically weighted PCA (GW-PCA), there is [21], but they are not applicable, since they assume a smooth-fading bandwidth function of the user. 6A similarity measure for multivariate time series is proposed in [48], but it is not applicable due to its stricter form and dependence on finding the correct eigenvector matrices to extend the Frobenius norm. Grouped = DStream.groupBySimilarityAndWindow (WindowDuration, slideDuration) reduced = DStream.reduceBySimilarityAndWindow (funityAndDuration, Durdeducation), Durdeductive.AndBydow Durdeducation, Duration, Durdeductive.Anddeducation ()"}, {"heading": "5 Implementation", "text": "We have implemented CellScope on Spark [49], a Big Data Cluster Computing Framework. In this section we describe its API, which shows our similarities-based grouping based on PCA (\u00a7 5.1) and implementation details for the hybrid offline online MTL models (\u00a7 5.2)."}, {"heading": "5.1 Data Grouping API", "text": "The CellScope Grouping API is based on Spark Streaming [50] because the data is continuously arriving and we need to work with that data in a streaming manner. Spark Streaming already provides support for window functions on data streams, so we expanded the window functionality by adding three APIs in the listing 1. In this section, we use the words grouping and partitioning interchangeable.Both APIs use the DStream abstraction provided by Spark Streaming. The groupingBySimilarityAndWindow takes the buffered data from the duration of the last window, applies the similarity metric to generate output sets of grouped data (multiple DStreams) per slide duration. The reduction BySimilarityAndWindow allows an additional user-defined associative reduction on the grouped data sets. Finally, it also provides a JoinBySimilarityAndWindow that connects multiple streams by similarity."}, {"heading": "5.2 Hybrid MTL Modeling", "text": "We use Spark's machine learning library MLlib [41] to implement our hybrid MTL model. MLlib includes the implementation of many distributed learning algorithms. In order to harness the many existing algorithms in Mllib, we implemented our multi-task learning hybrid model as an ensemble method [13]. By definition, ensemble methods use several learning algorithms to achieve better performance. Given such methods, it is easy to implement our hybrid online offline model; the common features can be integrated as a static model and the per base station model can be a separate input. We modified the MLlib implementation of the Gradient Boosted Tree (GBT) [18] model, an ensemble of decision trees. This implementation supports both classification and regression, and uses internally stochastic methods. Our online modification model allows us to add additional window enrichment to the result, which is supported by our online modeling."}, {"heading": "6 Evaluation", "text": "We have evaluated CellScope through a series of experiments with real cellular traces from an active LTE network in a large geographical area. Our results are summarized below: \u2022 CellScope's similarity-based grouping alone provides up to 10% improvement in accuracy compared to the best case of spatial distribution systems. \u2022 With MTL, CellScope's accuracy improvements range from 2.5 x to 4.4 x across different capture latencies. \u2022 Our hybrid online offline model is capable of reducing model update times up to 4.8 x and learning changes online without losing accuracy. We discuss these results in detail in the rest of this section. Evaluation setting: Due to the sensitive nature of our data set, our evaluation environment consists of a private cluster of 20 computers. Each machine consists of 4 CPUs, 32 GB of memory and a 200 GB magnetic disk."}, {"heading": "6.1 Benefits of Similarity Based Grouping", "text": "Exactly what we are talking about. Exactly what we are talking about. Exactly what we are talking about. Exactly what we are talking about. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly. Exactly.................... Exactly...................... Exactly.............."}, {"heading": "6.2 Benefits of MTL", "text": "Next, we describe the advantages of using MTL by CellScope. To do this, we repeat the experiment before and apply MTL to the grouped data to see if the accuracy is confirmed compared to the previous approach of a single model per group. Figure 4a shows the results. MTL's ability to learn and improve models from the data of other similar base stations leads to an increase in accuracy. Compared to the advantages of grouping, we see a 6% improvement in the connection drop diagnostic experiment and 16.2% in the throughput prediction experiment. The greater benefit in the latter lies in the ability of CellScope to capture individual characteristics of the base station. This ability is not so crucial in the former respect, as the individual characteristics vary only to a limited extent compared to those of the grouping."}, {"heading": "6.3 Combined Benefits of Grouping and MTL", "text": "We are now evaluating the combined benefits of grouping and MTL, taking into account different latencies in data acquisition. At this point, we are interested in evaluating how CellScope handles the latency compromise. To this end, we are conducting the same classification and regression experiments, but with different latencies instead of one. We are showing the results of the classification experiment in Fig. 4c and the regression experiment in Fig. 4d, which compares the accuracy of CellScope with that of a base station model. If the ability to collect data at individual base stations is limited, CellScope can use our MTL formulation to combine data from multiple base stations and create tailor-made models to improve accuracy. CellScope benefits range up to 2.5 x in the classification experiment, up to 4.4 x in the regression experiment, and lower latencies are extremely likely due to low latencies in the classification experiment."}, {"heading": "6.4 Hybrid model benefits", "text": "In fact, it is not that we are in a position to manoeuvre ourselves into the impasse in which we find ourselves."}, {"heading": "7.1 Analyzing Call Drop Performance", "text": "With the conversion to the transmission of voice data over the data network (VoLTE), this measurement value has gained even more importance. In this section, we describe how we used CellScope for the analysis of case performance."}, {"heading": "7.1.1 Feature Engineering", "text": "As shown in Fig. 5a, areas with RSRP < \u2212 130 dBm have a very high probability of connection drop. Downlink interference For downlink interference, we consider two measurements: RSRQ and downlink CQI. RSRQ is only reported if the UE is required to cede. CQI is available independently of handoffs. In Fig. 5b and Fig. 5c, we see that the distributions do not match. To show the difference between these two distributions, we have converted them to the common SINR. To convert CQI, we use the CQI to the SINR table. For RSRQ, we use the formula derived in [35], SINR = 1112RSRSRRQ \u2212 \u03c1."}, {"heading": "7.1.2 Decision Tree Model for Connection Drops", "text": "We then used CellScope to train a decision tree to explain the causes of disconnection. One of the learned trees is shown in Fig. 6b. As we can see, the tree first classifies the crashes using uplink SINR and then uses RSRQ when available. We confirmed with experts that the model matches their experiences. Uplink SINR is more unpredictable, as the fault comes from participants associated with adjacent base stations, while downlink interference comes from adjacent base stations. CellScope's models achieved an overall accuracy of 92.1%, whereas neither one model per base station nor a global model could accurately identify uplink SINR as the cause and achieved an accuracy of less than 80%."}, {"heading": "7.1.3 Detecting Cell KPI Change False Positives Using Concept Drift and Incremental Learning", "text": "One interesting application of CellScope's hybrid model is the detection of false positive KPI changes. As previously explained, state-of-the-art systems for detecting performance problems monitor KPIs and raise the alarm when thresholds are exceeded. A major problem with these systems is that the alarms are triggered even for known causes, but operators cannot confirm this without conducting manual research that leads to wasted time and effort. This problem can be solved if known causes can be filtered out before the alarm is triggered. We illustrate this by the fall rate. To do this, we use CellScope to gradually apply the decision tree to a week of data in 10-minute interval windows. We used this window because it closely matches an interval that is normally used by operators to monitor fall rates. In each window, we predict the number of falls with our technology. The predicted falls are explainable because we know exactly why these falls happened."}, {"heading": "7.2 Throughput Performance Analysis", "text": "Our traces provide information that allows us to calculate RLC throughput as truth. We want to use physical layer and MAC sublayer information to model how far the actual RLC throughput is from the predicted throughput, which helps us understand the factors that contribute to throughput."}, {"heading": "7.2.1 Feature Engineering", "text": "SINR Estimation Base stations have two antennas and are capable of running MIMO spatial multiplexing (two streams) or transmitting diversity. For both transmissions, each UE specifies its two broadband CQIs. We use the CQI to SINR mapping table, which is used by the Base Station Scheduler to convert CQI to SINR. For transmission diversity, we convert the two CQIs into a single SINR. First, we convert both CQIs to SINR, then we calculate the two spectrum efficiencies (bits / sec / Hz) using the Shannon capacity. We calculate the two spectrum efficiencies and convert them back to SINR. We then add a 3dB transmission diversity increase to achieve the final SINR. For spatial multiplexing, we convert the two CINRIs into two CINRs."}, {"heading": "7.2.2 Regression Model: Bearer-Level Throughput", "text": "The predicted throughput due to the diversity of transmission is calculated as follows. t putRLCdiv = (1.0 \u2212 \u03b2MAC) \u00b7 0.9 \u00b7 (1 \u2212 0.29) \u00b7 180 \u00b7 PRBdiv \u00b7 log2 (1 + SINRdiv) / T xTimedivPRBdiv denotes the total transmission time to derive the final RLC penetration. Likewise, we cannot calculate the predicted throughput due to the spatial multiplexing."}, {"heading": "8 Discussion", "text": "We have presented a system that resolves the fundamental trade-off between latency and accuracy in the context of mobile network analysis. Now, we are discussing the usability and universality of our solution.Applicability and impact: In several areas, it is common to use research prototypes on a live system to close the loop. Unfortunately, mobile networks are extremely powerful systems and therefore it is difficult to deploy our system. Nevertheless, our results have been useful for the operator to fix several problems in his network. Furthermore, in the course of this experience, we have been able to identify many problems with the data (missing fields, corruption, incorrect values, etc.) and propose new areas that can be added for a better diagnostic.Generality: Our solutions can be divided into two general techniques that are applicable to many other areas: the partitioning of the data according to the underlying cause on which the analysis is to be performed; and the application of domain-specific formulations to the analytical approach. It is important to note that ML is not applicable to the underlying cause of the solution, but to many other areas of the technology that are more specific to ML."}, {"heading": "9 Related Work", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "10 Conclusion and Future Work", "text": "While several areas can benefit from analyzing the data collected in real time, the practicality of these analyses is hampered by a fundamental trade-off between the latency of data acquisition and the accuracy of the analysis. In this paper, we examined this trade-off in the context of a specific domain use case, performance analysis in cellular RANs. To resolve this trade-off by applying a domain-specific formulation of MTL, CellScope first converted raw data into revealing features. To effectively apply MTL, CellScope proposed a novel PCA-inspired similarity metric that groups data from geographically close base stations that share common features. Finally, it includes a hybrid online offline model for efficient model updates. We built CellScope on Apache Spark and evaluated it against real data showing accuracy improvements ranging from 2.5 to 4.4 Mx over ML."}, {"heading": "Acknowledgments", "text": "This research is supported in part by the NSF CISE Expeditions Award CCF-1139158, the DOE Award SN10040 DE-SC0012463, and the DARPA XData Award FA8750-12-2-0331, as well as gifts from Amazon Web Services, Google, IBM, SAP, The Thomas and Stacey Siebel Foundation, Apple Inc., Arimo, Blue Goji, Bosch, Cisco, Cray, Cloudera, Ericsson, Facebook, Fujitsu, HP, Huawei, Intel, Microsoft, Pivotal, Samsung, Schlumberger, Splunk, State Farm, and VMware."}], "references": [{"title": "Netprints: diagnosing home network misconfigurations using shared knowledge", "author": ["B. AGGARWAL", "R. BHAGWAN", "T. DAS", "S. ESWARAN", "V.N. PADMANABHAN", "G.M. VOELKER"], "venue": "In Proceedings of the 6th USENIX symposium on Networked systems design and implementation (Berkeley, CA,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "9900 wireless network guardian", "author": ["ALCATEL LUCENT"], "venue": "http://www.alcatel-lucent.com/products/ 9900-wireless-network-guardian", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "9959 network performance optimizer", "author": ["ALCATEL LUCENT"], "venue": "http://www.alcatel-lucent.com/products/ 9959-network-performance-optimizer", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Alcatel-Lucent motive big network analytics for service creation", "author": ["ALCATEL LUCENT"], "venue": "http://resources. alcatel-lucent.com/?cid=170795", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Motive big network analytics", "author": ["ALCATEL LUCENT"], "venue": "http://www.alcatel-lucent.com/solutions/ motive-big-network-analytics", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards highly reliable enterprise network services via inference of multi-level dependencies", "author": ["P. BAHL", "R. CHANDRA", "A. GREENBERG", "S. KANDULA", "D.A. MALTZ", "M. ZHANG"], "venue": "In Proceedings of the 2007 Conference on Applications,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Learning of model parameters for fault diagnosis in wireless networks", "author": ["R. BARCO", "V. WILLE", "L. D\u00cdEZ", "M. TORIL"], "venue": "Wirel. Netw. 16,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "A model of inductive bias learning", "author": ["J. BAXTER"], "venue": "J. Artif. Int. Res", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Multitask learning: A knowledge-based source of inductive bias", "author": ["R. CARUANA"], "venue": "In Proceedings of the Tenth International Conference on Machine Learning", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1993}, {"title": "Correlating instrumentation data to system states: A building block for automated diagnosis and control", "author": ["I. COHEN", "M. GOLDSZMIDT", "T. KELLY", "J. SYMONS", "J.S. CHASE"], "venue": "In Proceedings of the 6th Conference on Symposium on Opearting Systems Design & Implementation", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Gigascope: a stream database for network applications", "author": ["C. CRANOR", "T. JOHNSON", "O. SPATASCHEK", "V. SHKAPENYUK"], "venue": "In Proceedings of the 2003 ACM SIGMOD international conference on Management of data (New York, NY, USA,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Ensemble methods in machine learning", "author": ["T.G. DIETTERICH"], "venue": "In Multiple classifier systems. Springer,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "Regularized multi\u2013task learning", "author": ["T. EVGENIOU", "M. PONTIL"], "venue": "In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (New York, NY, USA,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["J.H. FRIEDMAN"], "venue": "Annals of statistics", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "A survey on concept drift adaptation", "author": ["J.A. GAMA", "I. \u017dLIOBAIT\u0116", "A. BIFET", "M. PECHENIZKIY", "A. BOUCHACHIA"], "venue": "ACM Comput. Surv. 46,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Robust multi-task feature learning", "author": ["P. GONG", "J. YE", "C. ZHANG"], "venue": "In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (New York, NY, USA,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Geographically weighted principal components analysis", "author": ["P. HARRIS", "C. BRUNSDON", "M. CHARLTON"], "venue": "International Journal of Geographical Information Science 25,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Tiresias: Online anomaly detection for hierarchical operational network data", "author": ["HONG", "C.-Y", "M. CAESAR", "N. DUFFIELD", "J. WANG"], "venue": "In Proceedings of the 2012 IEEE 32Nd International Conference on Distributed Computing Systems (Washington, DC,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Celliq : Real-time cellular network analytics at scale", "author": ["A. IYER", "L.E. LI", "I. STOICA"], "venue": "In 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Automated rule-based diagnosis through a distributed monitor system", "author": ["G. KHANNA", "M. YU CHENG", "P. VARADHARAJAN", "S. BAGCHI", "M.P. CORREIA", "P.J. VER\u00cdSSIMO"], "venue": "IEEE Trans. Dependable Secur. Comput", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Tree-guided group lasso for multi-task regression with structured sparsity", "author": ["S. KIM", "E.P. XING"], "venue": "Intenational Conference on Machine Learning (ICML)", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Mlbase: A distributed machine-learning system", "author": ["T. KRASKA", "A. TALWALKAR", "J.C. DUCHI", "R. GRIFFITH", "M.J. FRANKLIN", "M.I. JORDAN"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Between-groups comparison of principal components", "author": ["W. KRZANOWSKI"], "venue": "Journal of the American Statistical Association 74,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1979}, {"title": "Diagnosing network-wide traffic anomalies", "author": ["A. LAKHINA", "M. CROVELLA", "C. DIOT"], "venue": "In Proceedings of the 2004 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (New York, NY, USA,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2004}, {"title": "AND STRASS- NER, J. A model-based approach to adding autonomic capabilities to network fault management system", "author": ["Y. LIU", "J. ZHANG", "M. JIANG", "D. RAYMER"], "venue": "In Network Operations and Management Symposium,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Machine learning: a probabilistic perspective", "author": ["K.P. MURPHY"], "venue": "MIT press,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "A divide-andconquer method for scalable robust multitask learning", "author": ["PAN Y", "XIA R", "YIN J", "LIU"], "venue": "Neural Networks and Learning Systems, IEEE Transactions on 26,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "On lines and planes of closest fit to systems of points in space", "author": ["K. PEARSON"], "venue": "Philosophical Magazine 2,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1901}, {"title": "Operational fault detection in cellular wireless basestations", "author": ["RAO S"], "venue": "IEEE Trans. on Netw. and Serv. Manag. 3,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}, {"title": "AND MOUFTAH, H. 4g network technologies for mobile telecommunications", "author": ["A.M. SAFWAT"], "venue": "Network, IEEE 19,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2005}, {"title": "Mobility parameter planning for 3GPP LTE: Basic concepts and intra-layer mobility. www.lteexpert.com/lte_ mobility_wp1_10June2013.pdf", "author": ["J. SALO"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "LTE: the UMTS long term evolution", "author": ["S. SESIA", "I. TOUFIK", "M. BAKER"], "venue": "Wiley Online Library,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "Understanding the impact of network dynamics on mobile video user engagement", "author": ["M.Z. SHAFIQ", "J. ERMAN", "L. JI", "A.X. LIU", "J. PANG", "J. WANG"], "venue": "In The 2014 ACM International Conference on Measurement and Modeling of Computer Systems (New York, NY, USA,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "A first look at cellular network performance during crowded events", "author": ["M.Z. SHAFIQ", "L. JI", "A.X. LIU", "J. PANG", "S. VENKATARA- MAN", "J. WANG"], "venue": "In Proceedings of the ACM SIGMETRICS/International Conference on Measurement and Modeling of Computer Systems (New York, NY, USA,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "Stochastic methods for l1-regularized loss minimization", "author": ["S. SHALEV-SHWARTZ", "A. TEWARI"], "venue": "J. Mach. Learn. Res", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "3G wireless networks", "author": ["C. SMITH"], "venue": "McGraw-Hill, Inc.,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2006}, {"title": "MLI: an API for distributed machine learning", "author": ["E.R. SPARKS", "A. TALWALKAR", "V. SMITH", "J. KOTTALAM", "X. PAN", "J.E. GONZALEZ", "M.J. FRANKLIN", "M.I. JORDAN", "T. KRASKA"], "venue": "IEEE 13th International Conference on Data Mining, Dallas, TX, USA, December", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2013}, {"title": "Using big data for more dependability: A cellular network tale", "author": ["N. THEERA-AMPORNPUNT", "S. BAGCHI", "K.R. JOSHI", "R.K. PANTA"], "venue": "In Proceedings of the 9th Workshop on Hot Topics in Dependable Systems (New York, NY, USA,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2013}, {"title": "Is learning the n-th thing any easier than learning the first", "author": ["S. THRUN"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1996}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. TIBSHIRANI"], "venue": "Journal of the Royal Statistical Society, Series B", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1994}, {"title": "Automatic misconfiguration troubleshooting with peerpressure", "author": ["H.J. WANG", "J.C. PLATT", "Y. CHEN", "R. ZHANG", "WANG", "Y.-M"], "venue": "In Proceedings of the 6th Conference on Symposium on Opearting Systems Design & Implementation - Volume 6 (Berkeley, CA,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2004}, {"title": "Argus: End-to-end service anomaly detection and localization from an isp\u2019s point of view", "author": ["H. YAN", "A. FLAVEL", "Z. GE", "A. GERBER", "D. MASSEY", "C. PAPADOPOULOS", "H. SHAH", "J. YATES"], "venue": "In INFOCOM,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2012}, {"title": "A pca-based similarity measure for multivariate time series", "author": ["K. YANG", "C. SHAHABI"], "venue": "In Proceedings of the 2nd ACM International Workshop on Multimedia Databases (New York, NY, USA,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2004}, {"title": "Resilient distributed datasets: a fault-tolerant abstraction for in-memory cluster computing", "author": ["M. ZAHARIA", "M. CHOWDHURY", "T. DAS", "A. DAVE", "J. MA", "M. MCCAULEY", "M.J. FRANKLIN", "S. SHENKER", "I. STOICA"], "venue": "In Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation (Berkeley, CA,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "Discretized streams: Fault-tolerant streaming computation at scale", "author": ["M. ZAHARIA", "T. DAS", "H. LI", "T. HUNTER", "S. SHENKER", "I. STOICA"], "venue": "In Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles (New York, NY, USA,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2013}, {"title": "Materialization optimizations for feature selection workloads", "author": ["C. ZHANG", "A. KUMAR", "R\u00c9"], "venue": "In Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data (New York, NY, USA,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2014}, {"title": "Failure diagnosis using decision trees", "author": ["A.X. ZHENG", "J. LLOYD", "E. BREWER"], "venue": "In Proceedings of the First International Conference on Autonomic Computing (Washington, DC, USA,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2004}], "referenceMentions": [{"referenceID": 29, "context": "While RAN technologies have seen tremendous improvements over the past decade [34, 36, 40], performance problems are still prevalent [38].", "startOffset": 78, "endOffset": 90}, {"referenceID": 31, "context": "While RAN technologies have seen tremendous improvements over the past decade [34, 36, 40], performance problems are still prevalent [38].", "startOffset": 78, "endOffset": 90}, {"referenceID": 35, "context": "While RAN technologies have seen tremendous improvements over the past decade [34, 36, 40], performance problems are still prevalent [38].", "startOffset": 78, "endOffset": 90}, {"referenceID": 33, "context": "While RAN technologies have seen tremendous improvements over the past decade [34, 36, 40], performance problems are still prevalent [38].", "startOffset": 133, "endOffset": 137}, {"referenceID": 32, "context": "Factors impacting RAN performance include user mobility, skewed traffic pattern, interference, lack of coverage, unoptimized configuration parameters, inefficient algorithms, equipment failures, software bugs and protocol errors [37].", "startOffset": 229, "endOffset": 233}, {"referenceID": 0, "context": "Although some of these factors are present in traditional networks and troubleshooting these networks has received considerable attention in the literature [2, 7, 11, 46, 52], RAN performance diagnosis brings out a unique challenge: the performance of multiple base stations exhibit complex temporal and spatial interdependencies due to the shared radio access media and user mobility.", "startOffset": 156, "endOffset": 174}, {"referenceID": 5, "context": "Although some of these factors are present in traditional networks and troubleshooting these networks has received considerable attention in the literature [2, 7, 11, 46, 52], RAN performance diagnosis brings out a unique challenge: the performance of multiple base stations exhibit complex temporal and spatial interdependencies due to the shared radio access media and user mobility.", "startOffset": 156, "endOffset": 174}, {"referenceID": 9, "context": "Although some of these factors are present in traditional networks and troubleshooting these networks has received considerable attention in the literature [2, 7, 11, 46, 52], RAN performance diagnosis brings out a unique challenge: the performance of multiple base stations exhibit complex temporal and spatial interdependencies due to the shared radio access media and user mobility.", "startOffset": 156, "endOffset": 174}, {"referenceID": 40, "context": "Although some of these factors are present in traditional networks and troubleshooting these networks has received considerable attention in the literature [2, 7, 11, 46, 52], RAN performance diagnosis brings out a unique challenge: the performance of multiple base stations exhibit complex temporal and spatial interdependencies due to the shared radio access media and user mobility.", "startOffset": 156, "endOffset": 174}, {"referenceID": 46, "context": "Although some of these factors are present in traditional networks and troubleshooting these networks has received considerable attention in the literature [2, 7, 11, 46, 52], RAN performance diagnosis brings out a unique challenge: the performance of multiple base stations exhibit complex temporal and spatial interdependencies due to the shared radio access media and user mobility.", "startOffset": 156, "endOffset": 174}, {"referenceID": 2, "context": "Existing systems [4, 16] for detecting performance problems rely on monitoring aggregate metrics, such as connection drop rate and throughput per cell, over minuteslong time windows.", "startOffset": 17, "endOffset": 24}, {"referenceID": 19, "context": "However, the sheer volume of the data and its high dimensionality make the troubleshooting using human experts and traditional rule-based systems very hard, if not infeasible [24].", "startOffset": 175, "endOffset": 179}, {"referenceID": 25, "context": "In this paper, we consider one natural alternative to these approaches that has been used recently to troubleshoot other complex systems with considerable success: machine learning (ML) [30].", "startOffset": 186, "endOffset": 190}, {"referenceID": 8, "context": "More specifically, CellScope applies Multi-task Learning (MTL) [10, 44], a stateof-the-art machine learning approach, to RAN troubleshooting.", "startOffset": 63, "endOffset": 71}, {"referenceID": 38, "context": "More specifically, CellScope applies Multi-task Learning (MTL) [10, 44], a stateof-the-art machine learning approach, to RAN troubleshooting.", "startOffset": 63, "endOffset": 71}, {"referenceID": 14, "context": "Finally, in this approach, finding anomalies is equivalent to detecting concept drift [19].", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": "To demonstrate the effectiveness of our proposal, we have built CellScope on Spark [26, 41, 49].", "startOffset": 83, "endOffset": 95}, {"referenceID": 36, "context": "To demonstrate the effectiveness of our proposal, we have built CellScope on Spark [26, 41, 49].", "startOffset": 83, "endOffset": 95}, {"referenceID": 43, "context": "To demonstrate the effectiveness of our proposal, we have built CellScope on Spark [26, 41, 49].", "startOffset": 83, "endOffset": 95}, {"referenceID": 1, "context": "Several commercial solutions exists [3\u20135, 16] that", "startOffset": 36, "endOffset": 45}, {"referenceID": 2, "context": "Several commercial solutions exists [3\u20135, 16] that", "startOffset": 36, "endOffset": 45}, {"referenceID": 3, "context": "Several commercial solutions exists [3\u20135, 16] that", "startOffset": 36, "endOffset": 45}, {"referenceID": 45, "context": "Feature engineering, the process of transforming the raw input data to a set of features that can be effectively utilized by machine learning algorithms, is a fundamental part of ML applications [51].", "startOffset": 195, "endOffset": 199}, {"referenceID": 7, "context": "boosted [9, 10, 17, 44].", "startOffset": 8, "endOffset": 23}, {"referenceID": 8, "context": "boosted [9, 10, 17, 44].", "startOffset": 8, "endOffset": 23}, {"referenceID": 12, "context": "boosted [9, 10, 17, 44].", "startOffset": 8, "endOffset": 23}, {"referenceID": 38, "context": "boosted [9, 10, 17, 44].", "startOffset": 8, "endOffset": 23}, {"referenceID": 15, "context": "MTL in the face of dependency violation has been studied in the machine learning literature in the recent past [20, 25].", "startOffset": 111, "endOffset": 119}, {"referenceID": 20, "context": "MTL in the face of dependency violation has been studied in the machine learning literature in the recent past [20, 25].", "startOffset": 111, "endOffset": 119}, {"referenceID": 26, "context": "Scalable application of MTL in a general setting is an active area of research in machine learning [31], so we turn to problem-specific optimizations to address this challenge.", "startOffset": 99, "endOffset": 103}, {"referenceID": 39, "context": "(3) could be posed as an `1 regularized loss minimization problem [45]:", "startOffset": 66, "endOffset": 70}, {"referenceID": 34, "context": "Furthermore, the choice of our learning functions lets us apply stochastic methods [39] which can be efficiently parallelized.", "startOffset": 83, "endOffset": 87}, {"referenceID": 14, "context": "Concept drift is a term used to refer the phenomenon where the underlying distribution of the training data for a machine learning model changes [19].", "startOffset": 145, "endOffset": 149}, {"referenceID": 27, "context": "Our data partitioning is based on Principal Component Analysis (PCA), a widely used technique in multivariate analysis [32].", "startOffset": 119, "endOffset": 123}, {"referenceID": 23, "context": "[28] showed the usefulness of PCA for network anomaly detection.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Krzanowski [27] describes such a Similarity Factor (SF).", "startOffset": 11, "endOffset": 15}, {"referenceID": 16, "context": "5Proposals for conducting geographically weighted PCA (GW-PCA) exist [21], but they are not applicable since they assume a smooth decaying user provided bandwidth function.", "startOffset": 69, "endOffset": 73}, {"referenceID": 42, "context": "6A similarity measure for multivariate time series is proposed in [48], but it is not applicable due to its stricter form and dependence on finding the right eigenvector matrices to extend the Frobenius norm.", "startOffset": 66, "endOffset": 70}, {"referenceID": 43, "context": "We have implemented CellScope on top of Spark [49], a big data cluster computing framework.", "startOffset": 46, "endOffset": 50}, {"referenceID": 44, "context": "CellScope\u2019s grouping API is built on Spark Streaming [50], since the data arrives continuously, and we need to operate on this data in a streaming fashion.", "startOffset": 53, "endOffset": 57}, {"referenceID": 36, "context": "We use Spark\u2019s machine learning library, MLlib [41] for implementing our hybrid MTL model.", "startOffset": 47, "endOffset": 51}, {"referenceID": 11, "context": "To leverage the many pre-existing algorithms in Mllib, we implemented our multi-task learning hybrid model as an ensemble method [13].", "startOffset": 129, "endOffset": 133}, {"referenceID": 13, "context": "We modified the MLlib implementation of Gradient Boosted Tree (GBT) [18] model, an ensemble of decision trees.", "startOffset": 68, "endOffset": 72}, {"referenceID": 18, "context": "The second (Spatial 2) uses a sophisticated space-filling curve based approach [23] that could create dynamically size partitions.", "startOffset": 79, "endOffset": 83}, {"referenceID": 30, "context": "For RSRQ, we use the formula derived in [35], SINR = 1 1 12RSRQ\u2212\u03c1 .", "startOffset": 40, "endOffset": 44}, {"referenceID": 1, "context": "Cellular network monitoring and troubleshooting A number of existing cellular network monitoring and diagnosis systems exist [3, 4, 12, 16].", "startOffset": 125, "endOffset": 139}, {"referenceID": 2, "context": "Cellular network monitoring and troubleshooting A number of existing cellular network monitoring and diagnosis systems exist [3, 4, 12, 16].", "startOffset": 125, "endOffset": 139}, {"referenceID": 10, "context": "Cellular network monitoring and troubleshooting A number of existing cellular network monitoring and diagnosis systems exist [3, 4, 12, 16].", "startOffset": 125, "endOffset": 139}, {"referenceID": 10, "context": "AT&T GigaScope [12] and Alcatel-Lucent Wireless Network Guardian (WNG) [3] generates per IP flow records and monitors many performance metrics such as aggregate per-cell TCP throughput, delay and loss.", "startOffset": 15, "endOffset": 19}, {"referenceID": 1, "context": "AT&T GigaScope [12] and Alcatel-Lucent Wireless Network Guardian (WNG) [3] generates per IP flow records and monitors many performance metrics such as aggregate per-cell TCP throughput, delay and loss.", "startOffset": 71, "endOffset": 74}, {"referenceID": 2, "context": "Systems targeting RAN [4, 16] typically monitor aggregate KPIs and per-bearer records separately.", "startOffset": 22, "endOffset": 29}, {"referenceID": 4, "context": "One recent commercial cellular network analytics system [6] adopted the Hadoop big data processing framework.", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "Since it is built on top of WNG [3], it does not have visibility into RANs.", "startOffset": 32, "endOffset": 35}, {"referenceID": 6, "context": "Modelling and diagnosis techniques: Diagnosing problems in cellular networks has been explored in the literature in various forms [8, 22, 29, 33, 43], where the focus of the work has either been detecting faults or finding the root cause of failures.", "startOffset": 130, "endOffset": 149}, {"referenceID": 17, "context": "Modelling and diagnosis techniques: Diagnosing problems in cellular networks has been explored in the literature in various forms [8, 22, 29, 33, 43], where the focus of the work has either been detecting faults or finding the root cause of failures.", "startOffset": 130, "endOffset": 149}, {"referenceID": 24, "context": "Modelling and diagnosis techniques: Diagnosing problems in cellular networks has been explored in the literature in various forms [8, 22, 29, 33, 43], where the focus of the work has either been detecting faults or finding the root cause of failures.", "startOffset": 130, "endOffset": 149}, {"referenceID": 28, "context": "Modelling and diagnosis techniques: Diagnosing problems in cellular networks has been explored in the literature in various forms [8, 22, 29, 33, 43], where the focus of the work has either been detecting faults or finding the root cause of failures.", "startOffset": 130, "endOffset": 149}, {"referenceID": 37, "context": "Modelling and diagnosis techniques: Diagnosing problems in cellular networks has been explored in the literature in various forms [8, 22, 29, 33, 43], where the focus of the work has either been detecting faults or finding the root cause of failures.", "startOffset": 130, "endOffset": 149}, {"referenceID": 6, "context": "A probabilistic system for auto-diagnosing faults in RAN is presented in [8].", "startOffset": 73, "endOffset": 76}, {"referenceID": 17, "context": "An automated approach to locating anomalous events on hierarchical operational networks was proposed in [22] based on hierarchical heavy hitter based anomaly detection.", "startOffset": 104, "endOffset": 108}, {"referenceID": 24, "context": "Adding autonomous capabilities to alarm based fault detection is discussed in [29].", "startOffset": 78, "endOffset": 82}, {"referenceID": 28, "context": "[33] looks at detecting call connection faults due to load imbalances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "In [47], a technique to detect and localize anomalies from an ISP point of view is proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 37, "context": "Finally, [43] discusses the use of ML tools in predicting call drops and its duration.", "startOffset": 9, "endOffset": 13}, {"referenceID": 7, "context": "Multi-Task Learning: MTL builds on the idea that related tasks can learn from each other to achieve better statistical efficiency [9, 10, 17, 44].", "startOffset": 130, "endOffset": 145}, {"referenceID": 8, "context": "Multi-Task Learning: MTL builds on the idea that related tasks can learn from each other to achieve better statistical efficiency [9, 10, 17, 44].", "startOffset": 130, "endOffset": 145}, {"referenceID": 12, "context": "Multi-Task Learning: MTL builds on the idea that related tasks can learn from each other to achieve better statistical efficiency [9, 10, 17, 44].", "startOffset": 130, "endOffset": 145}, {"referenceID": 38, "context": "Multi-Task Learning: MTL builds on the idea that related tasks can learn from each other to achieve better statistical efficiency [9, 10, 17, 44].", "startOffset": 130, "endOffset": 145}, {"referenceID": 15, "context": "Since the assumption of task relatedness do not hold in many scenarios, techniques to automatically cluster tasks have been explored in the past [20, 25].", "startOffset": 145, "endOffset": 153}, {"referenceID": 20, "context": "Since the assumption of task relatedness do not hold in many scenarios, techniques to automatically cluster tasks have been explored in the past [20, 25].", "startOffset": 145, "endOffset": 153}], "year": 2016, "abstractText": "An increasing amount of analytics is performed on data that is procured in a real-time fashion to make real-time decisions. Such tasks include simple reporting on streams to sophisticated model building. However, the practicality of such analyses are impeded in several domains because they are faced with a fundamental trade-off between data collection latency and analysis accuracy. In this paper, we study this trade-off in the context of a specific domain, Cellular Radio Access Networks (RAN). Our choice of this domain is influenced by its commonalities with several other domains that produce real-time data, our access to a large live dataset, and their real-time nature and dimensionality which makes it a natural fit for a popular analysis technique, machine learning (ML). We find that the latency accuracy trade-off can be resolved using two broad, general techniques: intelligent data grouping and task formulations that leverage domain characteristics. Based on this, we present CellScope, a system that addresses this challenge by applying a domain specific formulation and application of Multi-task Learning (MTL) to RAN performance analysis. It achieves this goal using three techniques: feature engineering to transform raw data into effective features, a PCA inspired similarity metric to group data from geographically nearby base stations sharing performance commonalities, and a hybrid online-offline model for efficient model updates. Our evaluation of CellScope shows that its accuracy improvements over direct application of ML range from 2.5\u00d7 to 4.4\u00d7 while reducing the model update overhead by up to 4.8\u00d7. We have also used CellScope to analyze a live LTE consisting of over 2 million subscribers for a period of over 10 months, where it uncovered several problems and insights, some of them previously unknown.", "creator": "LaTeX with hyperref package"}}}