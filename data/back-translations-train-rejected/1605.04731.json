{"id": "1605.04731", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "CNN based texture synthesize with Semantic segment", "abstract": "Deep learning algorithm display powerful ability in Computer Vision area, in recent year, the CNN has been applied to solve problems in the subarea of Image-generating, which has been widely applied in areas such as photo editing, image design, computer animation, real-time rendering for large scale of scenes and for visual effects in movies. However in the texture synthesize procedure. The state-of-art CNN can not capture the spatial location of texture in image, lead to significant distortion after texture synthesize, we propose a new way to generating-image by adding the semantic segment step with deep learning algorithm as Pre-Processing and analyze the outcome.", "histories": [["v1", "Mon, 16 May 2016 11:24:03 GMT  (556kb)", "http://arxiv.org/abs/1605.04731v1", "7 pages, 4 figures. arXiv admin note: text overlap witharXiv:1505.07376,arXiv:1604.04339,arXiv:1602.07188by other authors"]], "COMMENTS": "7 pages, 4 figures. arXiv admin note: text overlap witharXiv:1505.07376,arXiv:1604.04339,arXiv:1602.07188by other authors", "reviews": [], "SUBJECTS": "cs.CV cs.GR cs.LG", "authors": ["xianye liang", "bocheng zhuo", "peijie li", "liangju he"], "accepted": false, "id": "1605.04731"}, "pdf": {"name": "1605.04731.pdf", "metadata": {"source": "CRF", "title": "CNN based texture synthesize with Semantic segment", "authors": ["Xianye Liang", "Bocheng Zhuo", "Peijie Li", "Liangju He"], "emails": [], "sections": [{"heading": null, "text": "has been applied to solve problems in the sub-area of image generation that are common in areas such as image editing, image design, computer animation, real-time rendering for large scenes and for visual effects in movies. However, in texture synthesis, the state-of-the-art CNN cannot capture the physical position of the texture in the image, resulting in significant distortions after texture synthesis. We propose a new way of image generation by adding the semantic segment step with the deep learning algorithm as pre-processing and analyzing the result."}, {"heading": "1. Introduction", "text": "Over the past three years, however, we have pushed the performance of computer vision systems onto a wide range of high-level problems, including image classification (Krizhevsky et al., 2014), fine-grained categorization (Zhanget [3] et al., 2014; Simonyan & Zisserman [5] et al., Papandreou et al., 2014), fine-grained categorization (Zhanget) et al., among others. (Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs) The way CNN's model simulates human beings in image processing."}], "references": [{"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Proc. IEEE,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Untangling local and global deformations in deep convolutional networks for image classification and sliding window detection", "author": ["G. Papandreou", "I. Kokkinos", "Savalle", "P.-A"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Clonal mosaic model for the synthesis of mammalian coat patterns", "author": ["M Walter", "A Fournier"], "venue": "Proc of Graphics Interface. Vancouver: BC Press,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Filters, random fields and maximum entropy (frame)", "author": ["S.C. Zhu", "Y. Wu", "D. Mumford"], "venue": "International Journal of Computer Vision,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "A parametric texture modelbased on joint statistics of comple x wavelet coefficients", "author": ["J. PORTILLA", "E.P. SIMONCELLI"], "venue": "InternationalJournal of Computer Vision 40,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Image quilting for texture synthesis and transfer", "author": ["Efros", "Alexei A", "Freeman", "William T"], "venue": "Conference on Computer Graphics & Interactive", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In: NIPS. pp", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "A neural algorithm of artistic style", "author": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Wierstra"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks[J", "author": ["Alex J. Champandard"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected CRFs", "author": ["L. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A. Yuille"], "venue": "Proc. Int. Conf. Learn. Representations, 2015.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Han.Learning Deconvolution Network for Semantic Segmentation", "author": ["Hyeonwoo Noh", "Seunghoon Hong", "Bohyung"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Conditional Random Fields as Recurrent Neural Networks", "author": ["Shuai Zheng", "Sadeep Jayasumana", "Bernardino Romera-Paredes", "Vibhav Vineet", "Zhizhong Su", "Dalong Du", "Chang Huang", "Philip H.S. Torr"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "ImageNet Large Scale Visual Rcognition Challenge 2012 (ILSVRC 2012)", "author": ["J. Deng", "A. Berg", "S. Satheesh", "H. Su", "A. Khosla", "L. Fei-Fei"], "venue": "2012.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Proc.IEEE Conf. Comp. Vis. Patt. Recogn.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Directional Texture Transfer", "author": ["H. Lee", "S. Seo", "S. Ryoo", "K. Yoon"], "venue": "In Proc. 8th International Symposium on Non-Photorealistic Animation and Rendering,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Separating style and content with bilinear models", "author": ["J.B. Tenenbaum", "W.T. Freeman"], "venue": "Neural computation", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "Introduction Convolutional Neural Networks was first applied in document recognition and Le-net 5 achieve much higher recognition precision than other recognition algorithm [1].", "startOffset": 173, "endOffset": 176}, {"referenceID": 1, "context": "The development of deep learning is quite exciting in recent years, particular in computer vision area, Over the past three years DCNNs have pushed the performance of computer vision systems to soaring heights on a broad array of high-level problems, including image classification(Krizhevsky[2] et al.", "startOffset": 292, "endOffset": 295}, {"referenceID": 2, "context": ", 2013; Sermanet[3] et al.", "startOffset": 16, "endOffset": 19}, {"referenceID": 3, "context": ", 2013; Simonyan & Zisserman[4], 2014; Szegedy[5] et al.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": ", 2014), fine-grained categorization (Zhanget[6] al.", "startOffset": 45, "endOffset": 48}, {"referenceID": 5, "context": "Walter and Fournier [8] synthesis mammalian coat patterns based on cell division and cell-to-cell interactions.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "[9] model texture as a Markov Random Field and use Gibbs sampling for synthesis.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Portilla\u548c Simoncelli [10] propose a model combine all sort of wavelet features and their coefficients, it was considered to be the state of art model in texture synthesis.", "startOffset": 21, "endOffset": 25}, {"referenceID": 8, "context": "Efros [11] convert an input image into a specific stylization, through extract patterns as texture patches from existing artworks and proved to be a success in synthesizing in painting.", "startOffset": 6, "endOffset": 10}, {"referenceID": 9, "context": "Recently, generative models based on deep neural networks have shown exciting new perspectives for image synthesis [12,13,14,15].", "startOffset": 115, "endOffset": 128}, {"referenceID": 10, "context": "Recently, generative models based on deep neural networks have shown exciting new perspectives for image synthesis [12,13,14,15].", "startOffset": 115, "endOffset": 128}, {"referenceID": 11, "context": "Recently, generative models based on deep neural networks have shown exciting new perspectives for image synthesis [12,13,14,15].", "startOffset": 115, "endOffset": 128}, {"referenceID": 12, "context": "Recently, generative models based on deep neural networks have shown exciting new perspectives for image synthesis [12,13,14,15].", "startOffset": 115, "endOffset": 128}, {"referenceID": 13, "context": "some of the recently proposed approaches to this task are based on the fully convolutional network(FCN) [16] trained end-to-end, pixels-to-pixels which is efficient and at the same time has achieved the state-of-the-art performance.", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": ", the DeepLab [17], deconvNet[18]and CRF-RNN[8].", "startOffset": 14, "endOffset": 18}, {"referenceID": 15, "context": ", the DeepLab [17], deconvNet[18]and CRF-RNN[8].", "startOffset": 29, "endOffset": 33}, {"referenceID": 5, "context": ", the DeepLab [17], deconvNet[18]and CRF-RNN[8].", "startOffset": 44, "endOffset": 47}, {"referenceID": 16, "context": "One key reason for the success of these methods is that they are based on rich features learned from the very large ImageNet [19] dataset, often in the form of a 16-layer VGGNet [20].", "startOffset": 125, "endOffset": 129}, {"referenceID": 17, "context": "One key reason for the success of these methods is that they are based on rich features learned from the very large ImageNet [19] dataset, often in the form of a 16-layer VGGNet [20].", "startOffset": 178, "endOffset": 182}, {"referenceID": 18, "context": ", the ResNet [21, 22].", "startOffset": 13, "endOffset": 21}, {"referenceID": 12, "context": "The model comprises a fully convolutional network stage (used the FCN-8s architecture of [15], which provides unary potentials to the CRF.", "startOffset": 89, "endOffset": 93}, {"referenceID": 10, "context": "after extract the forward and backward image, we use the method in [13] to match the texture from style set.", "startOffset": 67, "endOffset": 71}, {"referenceID": 1, "context": "We compare AlexNet [2], GoogLeNet [5], andVGG-19, with AlexNet performing similarly to GoogLeNet and VGG-16 similarly to VGG-19.", "startOffset": 19, "endOffset": 22}, {"referenceID": 19, "context": "The gradients of El, and thus the gradient of Loss(x, y), with respect to the pixels y can be readily computed using standard error back-propagation [23].", "startOffset": 149, "endOffset": 153}, {"referenceID": 20, "context": "Therefore, in spite of the large complexity of the model, texture generation can be done in reasonable time using GPUs and performance-optimised toolboxes for training deep neural networks [24].", "startOffset": 189, "endOffset": 193}, {"referenceID": 0, "context": "Reference [1]LeCun, Y.", "startOffset": 10, "endOffset": 13}, {"referenceID": 1, "context": "[2]Krizhevsky, A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3]Sermanet, P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4]Simonyan, K.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6]Papandreou, G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[8]M Walter, A Fournier.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[9]S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[10]PORTILLA, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[11]Efros , Alexei A, Freeman, William T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Conference on Computer Graphics & Interactive Techniques2001:341-346 [12]Goodfellow, I.", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "[13]Gatys, L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "06576,2015 [14]Gregor, K.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "04623,2015 [15] Alex J.", "startOffset": 11, "endOffset": 15}, {"referenceID": 13, "context": "[16]Long, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[17] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[18] Hyeonwoo Noh, Seunghoon Hong, Bohyung Han.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[19]Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du,", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "03240,2015 [20] J.", "startOffset": 11, "endOffset": 15}, {"referenceID": 18, "context": "[21] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[23] Lee, H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[24] Tenenbaum, J.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "Deep learning algorithm display powerful ability in Computer Vision area, in recent year, the CNN has been applied to solve problems in the subarea of Image-generating, which has been widely applied in areas such as photo editing, image design, computer animation, real-time rendering for large scale of scenes and for visual effects in movies. However in the texture synthesize procedure. The state-of-art CNN can not capture the spatial location of texture in image, lead to significant distortion after texture synthesize, we propose a new way to generating-image by adding the semantic segment step with deep learning algorithm as Pre-Processing and analyze the outcome.", "creator": "Microsoft\u00ae Word 2016"}}}