{"id": "1605.04800", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing", "abstract": "This paper describes the submission of the AMU (Adam Mickiewicz University) team to the Automatic Post-Editing (APE) task of WMT 2016. We explore the application of neural translation models to the APE problem and achieve good results by treating different models as components in a log-linear model, allowing for multiple inputs (the MT-output and the source) that are decoded to the same target language (post-edited translations). A simple string-matching penalty integrated within the log-linear model can be used to control for higher faithfulness with regard to the to-be-corrected machine translation input. Our submission outperforms the uncorrected baseline on the unseen test set by -3.2% TER and +5.5% BLEU.", "histories": [["v1", "Mon, 16 May 2016 15:15:05 GMT  (25kb)", "https://arxiv.org/abs/1605.04800v1", null], ["v2", "Thu, 23 Jun 2016 13:15:50 GMT  (25kb)", "http://arxiv.org/abs/1605.04800v2", "Submission to the WMT 2016 shared task on Automatic Post-Editing"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["marcin junczys-dowmunt", "roman grundkiewicz"], "accepted": false, "id": "1605.04800"}, "pdf": {"name": "1605.04800.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["junczys@amu.edu.pl", "romang@amu.edu.pl"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.04 800v 2 [cs.C L] 23 Jun 2016"}, {"heading": "1 Introduction", "text": "This paper describes the submission of the AMU team (Adam Mickiewicz University) to the Automatic Post-Processing (APE) task of WMT 2016. Following the APE joint task of WMT 2015 (Bojar et al., 2015), the aim is to test methods for correcting errors caused by an unknown machine translation system in a black box scenario. Organizers provide training data with human post-processing, some of which are automated using TER (Snover et al., 2006) and BLEU (Papineni et al., 2002) and some of which are performed manually. We examine the application of neural translation models to the APE task and examine a number of aspects that appear to lead to good results: \u2022 Creation of artificial post-processing data that can be used to train the neural models; \u2022 Log-linear combination of monolingual and bilingual models in a narrower manner and to control the automatic addition of task-specific characteristics;"}, {"heading": "2 Related work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Post-Editing", "text": "State-of-the-art APE systems follow a monolingual approach first proposed by Simard et al. (2007), which developed a phrase-based SMT system based on the output of machine translations and their post-edited versions. Be \u0301 chara et al. (2011) proposed a \"source-context-aware\" variant of this approach: Automatically generated word alignments are used to create a new source language consisting of linked MT output and source token pairs. Including source-language information in this form is useful to improve automatic post-editing results (Be \u0301 chara et al., 2012; Chatterjee et al., 2015b). The quality of word alignments plays an important role in these methods, such as Pal et al. (2015). A number of techniques have been developed to improve PB-SMT-based APE systems, e.g. approaches based on filter-based and terraced techniques."}, {"heading": "2.2 Neural machine translation", "text": "We limit our description to the recently popular encoder decoder models based on relapsing neural networks (RNN), an LSTM-based encoder decoder model introduced by Sutskever et al. (2014), where the source set is encoded into a single continuous vector, the final state of the source set state.Bahdanau et al. (2015) extended this simple concept to include bidirectional source sets (Cho et al., 2014) and the so-called soft attention model. The novelty of this approach and its improved performance compared to Sutskever et al. (2014) are based on the reduced dependence on the source set embedding, which required all the information required for translation into a single sentence."}, {"heading": "3 Data and data preparation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Used corpora", "text": "We have used the following resources: 1. The official training and development data of the APE Shared Task Organizer, consisting of 12,000 training triplets 2 and 1,000 development triplets. In this essay, we report on our results for the 1,000 sets of development data and selected results for the invisible test data provided by the clients. 2. The domain-specific bilingual English-German training data permitted during the WMT-16 Shared Task for IT Domain Translation. 3. All other parallel bilingual English-German data permitted during the WMT-16 news translation task. 4. The monolingual Common Crawl corpus German permitted for the WMT-16 news translation and IT translation tasks."}, {"heading": "3.2 Pre- and post-processing", "text": "The provided triplets have already been symbolized, the tokenization scheme seems to correspond to the Moses tokenizer with no escaped special characters (Koehn et al., 2007), so we reapply the escaping. All other data is symbolized with the Moses tokenizer with default settings per language. We trust the data with the Moses truecaser. To deal with the limited ability of neural translation models to process words outside the vocabulary, we divide tokens into subword units, Sennrich et al. (2015b). Subword units were learned with a modified version of the byte pair that processes the sequence algorithm's encryption (BPE) (Gage, 1994).1An accepted ACL 2016 paper is expected to appear: Santanu Pal, Sudip Kumar Naskar, Mihaela Vela Vela Vela and Josef van Genabith."}, {"heading": "4 Artificial post-editing data", "text": "The post-processing data provided is orders of magnitude too small to train our neural models, and even with domain-internal training data from the IT translation task, we quickly see overfitting effects for a first English-German translation system. Inspired by Sennrich et al. (2015a) - which uses backtranslated monolingual data to enrich bilingual training corpus - we have decided to create artificial training triplets."}, {"heading": "4.1 Bootstrapping monolingual data", "text": "We have filtered the corpus for \"well-shaped\" lines starting with a large Unicode letter and ending with a sentence. We require the line to contain at least 30 Unicode letters. \u2022 The corpus has been pre-processed as described above, including subword units that can have a positive effect on crossword filtering by allowing unknown words to be evaluated. \u2022 Next, we have created an internal trigram language model (Heafield et al., 2013) from the German post-processing data and German IT task data, as well as a similarly large outdomain language model from the Common Crawl data. \u2022 We have calculated entropy values for the first billion lines of the corpus according to the bilingual models. \u2022 We have sorted the corpus by increasing the crossword spaces and maintaining the first 10 million entries for the translation of the first 100 million lines of the translation."}, {"heading": "4.2 Round-trip translation", "text": "For the next step, two phrase-based translation models, English-German and German-English, were created using the permissible parallel training data of the IT task. Word alignments were calculated using Fast-Align (Dyer et al., 2013), the dynamic suffix array (Germann, 2015) holds the translation model. The top 10% of the bootstrapped monolingual data was used for language modeling in the case of the English-German model, for the German-English translation system the language model was created only by the target page of the parallel in-domain group. 3In order to be able to translate these 10 million sentences quickly (twice), we applied small batch sizes and cubepruning pop limits of about 100 and completed the translation of the return journey in about 24 hours.To translate these 10 million sentences quickly (twice), we revised the data retrospectively, translating the source data into three-dimensional data."}, {"heading": "4.3 Filtering for TER", "text": "We hope that a round trip translation process will result in literal translations that are more or less similar to post-processed triplets, where the distance between MT output and post-processed text 3 These models were not meant to be state-of-the-art quality systems. Our main goal was to create them within a few hours. While TER scores only take into account the two German-language parts of the triplets, it seems reasonable that filtering for better German couples automatically leads to a higher quality of the intermediate English part by trying to mimic the TER statistics of the provided APE training corpus. While TER scores only take into account the two linguistic parts of the triplets, it seems reasonable that filtering for better German pairs automatically leads to a higher quality of the intermediate English part. To achieve this, we represented each triplet in the APE training data as a vector of the elementary TER statistics."}, {"heading": "5 Experiments", "text": "Analogous to the two predominant approaches described in Section 2.1, we examine methods that are purely monolingual, as well as a simple method of incorporating source language information in a more natural way than is the case with phrase-based machine translation.The neural machine translation systems studied in this thesis are attention-oriented encoder models (Bahdanau et al., 2015) trained with Nematus4. We used size 80 minibatches, a maximum sentence length of 50, size 500 word embedding, and size 1024 hidden layers. Models were trained with 4https: / / github.com / rsennrich / nematusAdadelta (Zeiler, 2012), reshuffling the corpus between epochs."}, {"heading": "5.1 MT-output to post-editing", "text": "We started training the monolingual MT-PE model with the MT and PE data from the larger artificial triplet corpus (round-trip.n10), which was trained for four days and stored one model every 10,000 mini-batches. In the monolingual task, rapid convergence was observed and we switched to fine-tuning after the 300,000 iteration, using a mixture of the provided training data and the smaller Round-trip.n1 corpus. The initial post-processing data was skimmed 20 times and used Round-trip.n1.This resulted in the performance jump shown in Figure 1 (mt \u00b2 pe, blue). Training was continued and stopped for another 100,000 iterations as overfit effects became evident. Training directly with the smaller training data without the initial training on Round-trip.n10 led to an even earlier overfitting.The input \u2192 pe in Table 2 contains the results of the monolingual model on the base group, extending well beyond the development line."}, {"heading": "5.2 Source to post-editing", "text": "We proceed similarly with the English-German NMT training. When fine-tuning with the smaller body with oversampled post-processing data, we also add all domain-internal parallel training data from the IT task, about 200,000 records. Fine-tuning results in a much larger jump than in the monolingual case, but the overall performance of the NMT system is still weaker than the uncorrected MT baseline. In the monolingual case, we evaluate the monolingual model (src \u2192 pe) and an ensemble5https: / / github.com / emjotde / amunmt (src \u2192 pe \u00d7 4) of the four best models of a training run. The src \u2192 pe \u00d7 4 system is not able to beat the MT baseline, but the overall ensemble is significantly better than the single model."}, {"heading": "5.3 Log-linear combinations and tuning", "text": "AmuNMT can be configured to accept different inputs to different members of a model ensemble, as long as the vocabulary of the target language is the same. Therefore, we can build a decoder that uses both the German MT output and the English source set as parallel input and produces post-edited German as output. As the input set essentially becomes a language model for an NMT model, this can be achieved without much effort. Theoretically, an unlimited number of inputs can be combined in this way without the need for specialized multiple input viewing processes (Zoph and Knight, 2016).6 In NMT ensembles, homogeneous models are typically weighted equally. Here, we combine different models and the same weighting does not work. Instead, we treat each ensemble component as a feature in a traditional log-linear model and perform weighting as parameter tuning with BatchMira (Cherry and Foster, 2012) using AmuT and NMT precompatible and can be predefined by 0.0."}, {"heading": "5.4 Enforcing faithfulness", "text": "We extend AmuNMT with a simple post-processing penalty (PEP). To ensure that the system is relatively conservative - i.e., the correction process does not introduce too much new material - every word in the output of the system that was not seen in its input is punished with a penalty of -1. During decoding, this is efficiently implemented as a matrix of dimensional size \u00d7 target vocabulary size, assigning 0 values to all columns that correspond to the source words, all other words \u2212 1. This feature can then be used as if it were a different encoder-decoder model and aligned with the same procedure as described above. PEP introduces a precision-like bias into the decoding process and is a simple means to enforce some fidelity to the input via string matching, which is not as easy to achieve within the encoder-decoder framework as described above."}, {"heading": "6 Final results and conclusions", "text": "We have submitted the results of the last system (mt \u2192 pe \u00d7 4 / src \u2192 pe \u00d7 4 / pep) as our final proposal for the APE Shared Task, and mt \u2192 pe \u00d7 4 as a contrastive system. Table 3 contains the results of the invisible test set for our two systems (in bold) and the best system of all the other submitting teams, as reported by the task organizers (for further details and manually assessed results - which were not yet available at the time of writing - see the joint task summary).The results are sorted by TER from the best to the worst. For our best system, we see improvements of -3.2% TER and + 5.5% BLEU over unprocessed Baseline 1 (uncorrected MT) and -1.5% TER and + 1.5% BLEU over our contrastive system. The organizers also provide results for a standard phase-based Moses configuration (baseline 2) that barely meet the EU baseline (-1% TER, + 1.4%)."}, {"heading": "7 Acknowledgements", "text": "This work is partly funded by the Polish National Science Centre (grant number 2014 / 15 / N / ST6 / 02330)."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Proceedings of the International Conference on Learning Representations,", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Statistical post-editing for a statistical MT system", "author": ["Yanjun Ma", "Josef van Genabith"], "venue": "In Proceedings of the 13th Machine Translation Summit,", "citeRegEx": "B\u00e9chara et al\\.,? \\Q2011\\E", "shortCiteRegEx": "B\u00e9chara et al\\.", "year": 2011}, {"title": "An evaluation of statistical post-editing systems applied to RBMT and SMT systems", "author": ["Rapha\u00ebl Rubino", "Yifan He", "Yanjun Ma", "Josef van Genabith"], "venue": "In Proceedings of COLING", "citeRegEx": "B\u00e9chara et al\\.,? \\Q2012\\E", "shortCiteRegEx": "B\u00e9chara et al\\.", "year": 2012}, {"title": "Findings of the 2015 Workshop on Statistical Machine Translation", "author": ["Turchi."], "venue": "Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 1\u201346, Lisbon, Portugal. Association for Computational Linguistics.", "citeRegEx": "Turchi.,? 2015", "shortCiteRegEx": "Turchi.", "year": 2015}, {"title": "The FBK participation in the WMT15 automatic post-editing shared task", "author": ["Marco Turchi", "Matteo Negri"], "venue": "In Proceedings of the Tenth Workshop on Statistical Machine Translation,", "citeRegEx": "Chatterjee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chatterjee et al\\.", "year": 2015}, {"title": "Exploring the planet of the APEs: a comparative study of state-of-the-art methods for MT automatic post-editing", "author": ["Marion Weller", "Matteo Negri", "Marco Turchi"], "venue": "In Proceedings of the 53rd Annual", "citeRegEx": "Chatterjee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chatterjee et al\\.", "year": 2015}, {"title": "Batch tuning strategies for statistical machine translation", "author": ["Cherry", "Foster2012] Colin Cherry", "George Foster"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Cherry et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cherry et al\\.", "year": 2012}, {"title": "Learning phrase representations using RNN encoder\u2013decoder for statistical machine translation", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A simple, fast, and effective reparameterization of IBM model 2", "author": ["Dyer et al.2013] Chris Dyer", "Victor Chahuneau", "Noah A. Smith"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association", "citeRegEx": "Dyer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2013}, {"title": "A new algorithm for data compression", "author": ["Philip Gage"], "venue": "The C Users Journal,", "citeRegEx": "Gage.,? \\Q1994\\E", "shortCiteRegEx": "Gage.", "year": 1994}, {"title": "Sampling phrase tables for the Moses statistical machine translation system", "author": ["Ulrich Germann"], "venue": "Prague Bulletin of Mathematical Linguistics,", "citeRegEx": "Germann.,? \\Q2015\\E", "shortCiteRegEx": "Germann.", "year": 2015}, {"title": "Scalable modified Kneser-Ney language model estimation", "author": ["Ivan Pouzyrevsky", "Jonathan H. Clark", "Philipp Koehn"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Heafield et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heafield et al\\.", "year": 2013}, {"title": "Moses: Open source toolkit", "author": ["Koehn et al.2007] Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Intelligent selection of language model training data", "author": ["Moore", "Lewis2010] Robert C. Moore", "William Lewis"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Moore et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2010}, {"title": "USAAR-SAPE: An English\u2013Spanish statistical automatic post-editing system", "author": ["Pal et al.2015] Santanu Pal", "Mihaela Vela", "Sudip Kumar Naskar", "Josef van Genabith"], "venue": null, "citeRegEx": "Pal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pal et al\\.", "year": 2015}, {"title": "BLEU: A method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th Annual Meeting on Association", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Improving neural machine translation models with monolingual data", "author": ["Barry Haddow", "Alexandra Birch"], "venue": "arXiv preprint arXiv:1511.06709", "citeRegEx": "Sennrich et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sennrich et al\\.", "year": 2015}, {"title": "Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909", "author": ["Barry Haddow", "Alexandra Birch"], "venue": null, "citeRegEx": "Sennrich et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sennrich et al\\.", "year": 2015}, {"title": "Statistical phrase-based post-editing", "author": ["Simard et al.2007] Michel Simard", "Cyril Goutte", "Pierre Isabelle"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Simard et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Simard et al\\.", "year": 2007}, {"title": "A study of translation edit rate with targeted human annotation", "author": ["Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul"], "venue": "In Proceedings of Association for Machine Translation in the Americas,", "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "Sequence to sequence learning with neural networks", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": "In Advances in Neural Information Processing Systems 27: 28th Annual Conference on Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Why predicting post-edition is so hard? failure analysis of LIMSI submission to the APE shared task", "author": ["Nicolas P\u00e9cheux", "Fran\u00e7ois Yvon"], "venue": "In Proceedings of the Tenth Workshop on Statistical Ma-", "citeRegEx": "Wisniewski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wisniewski et al\\.", "year": 2015}, {"title": "ADADELTA: an adaptive learning rate method", "author": ["Matthew D. Zeiler"], "venue": "arXiv preprint arXiv:1212.5701", "citeRegEx": "Zeiler.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler.", "year": 2012}, {"title": "Multi-source neural translation", "author": ["Zoph", "Knight2016] Barret Zoph", "Kevin Knight"], "venue": "arXiv preprint arXiv:1601.00710", "citeRegEx": "Zoph et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zoph et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 19, "context": "The organizers provide training data with human post-edits, evaluation is carried out partautomatically using TER (Snover et al., 2006) and BLEU (Papineni et al.", "startOffset": 114, "endOffset": 135}, {"referenceID": 15, "context": ", 2006) and BLEU (Papineni et al., 2002), and part-manually.", "startOffset": 17, "endOffset": 40}, {"referenceID": 2, "context": "The inclusion of source-language information in that form is shown to be useful to improve the automatic post-editing results (B\u00e9chara et al., 2012; Chatterjee et al., 2015b).", "startOffset": 126, "endOffset": 174}, {"referenceID": 14, "context": "State-of-the-art APE systems follow a monolingual approach firstly proposed by Simard et al. (2007) who trained a phrase-based SMT system on machine translation output and its post-edited versions.", "startOffset": 79, "endOffset": 100}, {"referenceID": 1, "context": "B\u00e9chara et al. (2011) proposed a \u201csource-context aware\u201d variant of this approach: automatically created word alignments are used to create a new source language which consists of joined MT-output and source token pairs.", "startOffset": 0, "endOffset": 22}, {"referenceID": 14, "context": "important role for this methods, as shown for instance by Pal et al. (2015).", "startOffset": 58, "endOffset": 76}, {"referenceID": 4, "context": "Chatterjee et al. (2015a) propose a pipeline where", "startOffset": 0, "endOffset": 26}, {"referenceID": 21, "context": "Other popular approaches rely on rulebased components (Wisniewski et al., 2015; B\u00e9chara et al., 2012) which we do not discuss here.", "startOffset": 54, "endOffset": 101}, {"referenceID": 2, "context": "Other popular approaches rely on rulebased components (Wisniewski et al., 2015; B\u00e9chara et al., 2012) which we do not discuss here.", "startOffset": 54, "endOffset": 101}, {"referenceID": 20, "context": "An LSTM-based encoder-decoder model was introduced by Sutskever et al. (2014). Here the source sentence is encoded into a single continuous vector, the final state of the source LSTMRNN.", "startOffset": 54, "endOffset": 78}, {"referenceID": 7, "context": "(2015) extended this simple concept with bidirectional source RNNs (Cho et al., 2014) and the so-called soft-", "startOffset": 67, "endOffset": 85}, {"referenceID": 20, "context": "The novelty of this approach and its improved performance compared to Sutskever et al. (2014) came from the reduced reliance on the source sentence embedding which had to convey all information required for trans-", "startOffset": 70, "endOffset": 94}, {"referenceID": 0, "context": "the reader to Bahdanau et al. (2015) for a detailed description of the discussed models.", "startOffset": 14, "endOffset": 37}, {"referenceID": 12, "context": "The provided triplets have already been tokenized, the tokenization scheme seems to correspond to the Moses (Koehn et al., 2007) tokenizer without escaped special characters, so we re-apply escaping.", "startOffset": 108, "endOffset": 128}, {"referenceID": 16, "context": "To deal with the limited ability of neural translation models to handle out-of-vocabulary words we split tokens into subword units, following Sennrich et al. (2015b). Subword units were learned using a mod-", "startOffset": 142, "endOffset": 166}, {"referenceID": 9, "context": "ified version of the byte pair encoding (BPE) compression algorithm (Gage, 1994).", "startOffset": 68, "endOffset": 80}, {"referenceID": 16, "context": "Inspired by Sennrich et al. (2015a) \u2014 who use backtranslated monolingual data to enrich bilingual training corpora \u2014 we decided to create artificial training triplets.", "startOffset": 12, "endOffset": 36}, {"referenceID": 11, "context": "\u2022 Next, we built an in-domain trigram language model (Heafield et al., 2013) from the German post-editing training data and the German IT-task data, and a similarly sized outof-domain language model from the Common Crawl data.", "startOffset": 53, "endOffset": 76}, {"referenceID": 8, "context": "Word-alignments were computed with fast-align (Dyer et al., 2013), the dynamic-suffix array (Germann, 2015) holds the translation model.", "startOffset": 46, "endOffset": 65}, {"referenceID": 10, "context": ", 2013), the dynamic-suffix array (Germann, 2015) holds the translation model.", "startOffset": 34, "endOffset": 49}, {"referenceID": 0, "context": "decoder models (Bahdanau et al., 2015), which have been trained with Nematus4.", "startOffset": 15, "endOffset": 38}, {"referenceID": 22, "context": "Adadelta (Zeiler, 2012), reshuffling the corpus between epochs.", "startOffset": 9, "endOffset": 23}], "year": 2016, "abstractText": "This paper describes the submission of the AMU (Adam Mickiewicz University) team to the Automatic Post-Editing (APE) task of WMT 2016. We explore the application of neural translation models to the APE problem and achieve good results by treating different models as components in a log-linear model, allowing for multiple inputs (the MT-output and the source) that are decoded to the same target language (post-edited translations). A simple string-matching penalty integrated within the log-linear model is used to control for higher faithfulness with regard to the raw machine translation output. To overcome the problem of too little training data, we generate large amounts of artificial data. Our submission improves over the uncorrected baseline on the unseen test set by -3.2% TER and +5.5% BLEU and outperforms any other system submitted to the shared-task by a large margin.", "creator": "LaTeX with hyperref package"}}}