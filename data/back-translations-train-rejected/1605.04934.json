{"id": "1605.04934", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "Self-Reflective Risk-Aware Artificial Cognitive Modeling for Robot Response to Human Behaviors", "abstract": "In order for cooperative robots (\"co-robots\") to respond to human behaviors accurately and efficiently in human-robot collaboration, interpretation of human actions, awareness of new situations, and appropriate decision making are all crucial abilities for co-robots. For this purpose, the human behaviors should be interpreted by co-robots in the same manner as human peers. To address this issue, a novel interpretability indicator is introduced so that robot actions are appropriate to the current human behaviors. In addition, the complete consideration of all potential situations of a robot's environment is nearly impossible in real-world applications, making it difficult for the co-robot to act appropriately and safely in new scenarios. This is true even when the pretrained model is highly accurate in a known situation. For effective and safe teaming with humans, we introduce a new generalizability indicator that allows a co-robot to self-reflect and reason about when an observation falls outside the co-robot's learned model. Based on topic modeling and two novel indicators, we propose a new Self-reflective Risk-aware Artificial Cognitive (SRAC) model. The co-robots are able to consider action risks and identify new situations so that better decisions can be made. Experiments both using real-world datasets and on physical robots suggest that our SRAC model significantly outperforms the traditional methodology and enables better decision making in response to human activities.", "histories": [["v1", "Mon, 16 May 2016 20:22:30 GMT  (2629kb,D)", "http://arxiv.org/abs/1605.04934v1", "40 pages"]], "COMMENTS": "40 pages", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["fei han", "christopher reardon", "lynne e parker", "hao zhang"], "accepted": false, "id": "1605.04934"}, "pdf": {"name": "1605.04934.pdf", "metadata": {"source": "CRF", "title": "Self-Reflective Risk-Aware Artificial Cognitive Modeling for Robot Response to Human Behaviors", "authors": ["Fei Hana", "Christopher Reardonb", "Lynne E. Parkerb", "Hao Zhanga"], "emails": ["fhan@mines.edu", "creardon@utk.edu", "leparker@utk.edu", "hzhang@mines.edu"], "sections": [{"heading": null, "text": "In order for cooperative robots (\"co-robots\") to respond accurately and efficiently to human behavior, co-robots \"human behaviors should be interpreted in the same way as human colleagues. To solve this problem, a novel interpretation indicator is introduced, so that robot actions are appropriate to current human behavior. In addition, full consideration of all potential situations in the robot environment in real-world applications is almost impossible, making it difficult for the co-robot to act appropriately and safely in new scenarios, even if the pre-trained model is highly precise in a known situation. For effective and safe play with humans, we introduce a new generalization indicator that allows a co-robot to reflect on itself and think about when an observation occurs outside the learned model of the co-robot."}, {"heading": "1. Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2. Related Work", "text": "In this section, we provide an overview of a variety of methods related to our proposed SRAC cognitive model for human-robot teams, including human activity detection, theme models, and artificial cognitive modeling."}, {"heading": "2.1. Human Activity Recognition", "text": "We focus on the commonly used sequential and space-time volume methods [15]. A comprehensive review of the various aspects of the recognition of human activity (HAR) is presented in [15] and [16]. A popular sequential method is the use of centric trajectories to identify human activity in visual data, but in which a human being is presented as a single point indicating the location of a human being. Chen and Yang represented a person with only one point to derive gait characteristics for pedestrian recognition [17]. Ge et al. extracted footpaths from the video to automatically detect small groups of people traveling together [18]. These methods can avoid the influence of human phenomena such as clothing and wearing, but are unable to detect activities involving various relative body movements. Another sequential method relies on human shapes, including human contours and silhouettes. Singalet extracted data contours and use the different contours of these contours."}, {"heading": "2.2. Topic Models and Evaluation", "text": "Zhao et al. integrated Bayesian learning into an undirected theme model and proposed a \"relevance topic model\" for unstructured detection of social group activity [27]. A semi-latent theme model, trained in a supervised manner, was introduced in [28] and used to classify activities in videos. Zhang and Parker used theme models to classify activities in 3D point clouds of color depth cameras on mobile robots [12]. Topical models were also widely used to detect human activities in streaming data. [29] The use of theme models was explored to detect daily activity patterns in portable sensor data. An unverified theme model was proposed in [30] to detect daily routines of streaming location and proximity data. Taking into account temporal and / or object-related relative information, AR's ability is underestimated."}, {"heading": "2.3. Artificial Cognitive Modeling", "text": "Artificial cognition has its origins in cybernetics with the intention of creating a science of the mind based on logic [1]. Among other cognitive paradigms, cognitivism has undoubtedly prevailed so far [2]. Within the cognitive paradigm, several cognitive architectures have been developed, including Soar [6], ACT-R [3] (and its extensions ACT-R / E [4], ACT-R [5], etc.), C4 [7] and architectures for robotics [8], which are relatively independent of application [37]. However, since architectures represent the mechanism of cognition, they lack the relevant information for using this mechanism, and they must be supplied with knowledge to perform a specific task. The combination of a cognitive architecture and a certain knowledge that is interactive is generally referred to as a cognitive model."}, {"heading": "3. Topic Modeling for Artificial Cognition", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Cognitive Architecture Overview", "text": "The proposed SRAC model is inspired by the cognitive architecture of the C4 [7]. The model shown in Figure 1 is divided into four modules for its functionality: \u2022 Sensory and Perception: Visual Cameras observe the environment. Subsequently, the perception system builds a BoW representation of raw data that can be processed by theme models. \u2022 Probabilistic Thinking: Theme models are applied to reason about human activities that are trained offline and used online. \u2022 Decision-making: The training kit is provided as a precursor that encodes a history of sensory information. This module uses the proposed indicators to select theme models that better reflect the human perspective and to discover new activities online. \u2022 Decision-making: Robot action risk is estimated based on theme models and evaluation and a reaction robot action is selected that minimizes this risk. \u2022 Navigation and motor system: The selected robot action is performed in response to human activities."}, {"heading": "3.2. Topic Modeling", "text": "The latent dirichlet allocation (LDA) [51], which has shown promising activity detection performance in our previous work (12], is applied in the SRAC model. In the light of a series of observations {w}, LDA models each of the K activities as a multinomial distribution of all possible visual words in the dictionary D. This distribution is parameterized by enabling the latent activity assignment z. By using the visual words to link observations and activities, the topic of the word is generated by the activity. LDA also represents each word as a collection of visual words and assumes that each word is associated with a latent activity assignment z. By applying the visual models linking observations and activities, the LDA models w are generated as a multinomial distribution of the activities being parameterized."}, {"heading": "4. Interpretability and Generalizability", "text": "In order to improve artificial cognitive modelling, we present two new indicators in this section and discuss their relationship, which form the core of the self-reflection module in Fig. 1."}, {"heading": "4.1. Interpretability Indicator", "text": "We observe that accuracy is not an appropriate evaluation metric for robot decision-making, as it only takes into account the most likely category of human activity and disregards the others. In order to use the category distribution, which contains much richer information, the interpretability indicator referred to by II is introduced. II is able to encode how well the subject modeling corresponds to common sense. Like the accuracy metric, II is an extrinsic metric, which means that it requires a basic truth to calculate. II is formally defined as: Definition 1 (interpretability indicator). Given the observation w with the basic truth and the distribution of the basic truth is g, like the basic truth about K 2 categories, let us state the basic truth."}, {"heading": "4.2. Generalizability Indicator", "text": "An artificial cognitive model requires the critical ability to recognize new situations and to be aware that the knowledge learned is less applicable (Pvwp = 1).To this end, we propose the Generalization Indicator (IG), an intrinsic metric that does not require a basic truth to calculate and thus can be used online. Introducing IG is inspired by perplexity metrics (also known as the Hero Out probability), which evaluates the generalization ability of a topic on a fraction of held instances using cross-validation [54] or invisible observations [55].Perplexity is defined as the log probability of words in an observation [32]. Since different observations may contain a different number of visual words, we calculate the Per-Visual-Word Perplexity (Pvwp). Mathematically, the topic modelM and an observation is defined as follows: Pvw (Pvwp)."}, {"heading": "4.3. Indicator Relationship", "text": "While the indicator of interpretability interprets human activity distributions in a way similar to human thinking, the indicator of generalisability gives a co-robot the ability to self-reflect. We summarize their relationship in cases where a training set is exhaustive (i.e. the training includes all possible categories) and non-exhaustive (i.e., new human behavior occurs during the test) as follows: Observation (relationship of IG and II): LetWtrain is the training data set used to train a theme model, and II and IG are the interpretability and generalizability indicators of the model. \u2022 IfWtrain is exhaustive, then IG \u2192 1 and II is generally independent of IG. \u2022 IfWtrain is not exhaustive, then IG takes values much smaller than 1; II also takes small values and is moderately correlated to IG.model, if the model can lead to better recognition performance."}, {"heading": "5. Self-Reflective Risk-Aware Decision Making", "text": "Another contribution of this research is a decision framework, which is able to integrate the activity category distribution of robots, i.e. IG self-reflection (activated by the indicators) and co-robot action risks, which are realized in the decision-making module. (Our new, self-reflective, risk-conscious decision algorithm is defined in algorithm 2. In view of the independent action of the robot, a risk is determined, which can be expected during the period when the robot takes a specific action. (.) The response to observed human activity zj is defined as the level of inconvenience, interference or damage, which may occur during the period when the robot performs a specific action. (.) S} in response to observed human activity zj,."}, {"heading": "6. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Datasets and Visual Features", "text": "We use three benchmark datasets to evaluate our cognitive model in relation to HAR tasks, which are widely used in the Machine Vision Dataset [57], the KTH Activity Dataset [58], and the UTK Activity Dataset [12]. Illustrative examples from each activity category are presented in Fig. In our experiments, we apply different types of visual attributes to encrypt these datasets."}, {"heading": "6.2. Activity Recognition", "text": "We first evaluate the ability of the SRAC model to detect the interpretation possibilities of indicator II when the training plan is exhaustive. In this experiment, each data set is divided into disjunctural parameters, then the interpretation ability of the subject is calculated on the basis of the training set, and no new human activities are included. This training process is repeated five times to obtain reliable results."}, {"heading": "6.3. Knowledge Discovery", "text": "In fact, it is the case that most people are able to survive themselves, and that they are able to survive themselves, \"he told the German Press Agency.\" I don't think they are able to survive themselves, \"he said.\" But I think they will be able to survive themselves. \"He added,\" I don't think they will be able to survive themselves. \"He added,\" I don't think they will be able to survive themselves. \"He added,\" I don't think they are able to survive themselves. \""}, {"heading": "6.4. Relationship of IG and II", "text": "This means that we first check the correlation between II and IG. Furthermore, we examine other relationships between II and IG, such as the probability that II \u2264 IG. Unfortunately, while we are able to validate this relationship in cases where IG requires small values to analyze the relationship between IG and II when test cases are fully represented by the training model, we cannot use the non-exhaustive setup in Section 6.3 to validate this relationship in cases where IG takes small values. This is because the basic truth cannot be assigned to the distances associated with novel activities to calculate II, since these activities only exist in the test phase and are not presented in our model. Inspired by the method used to generate synthetic data in Section 6.3, we assume a semi-exhaustive device by replacing certain words in each test instance with visual words from novel activities."}, {"heading": "6.5. Decision Making", "text": "We evaluate our SRAC model of decision-making with a Turtlebot 2 robot in a human follow-up task, which is important in many human robot teaming applications. In this task, a robot follower must decide at what distance to follow the human being. We are interested in three human behaviors: \"walking\" in a straight line, \"turning\" and \"falling,\" which are shown in Figure 9. With perfect perception and reasoning, i.e., a robot always interprets human activities perfectly, we assume that it is far away from the human when it walks in a straight line (so as not to interrupt the human)."}, {"heading": "7. Conclusion", "text": "In this paper, we construct an artificial cognitive model that provides co-robots with both accurate perception and new information-gathering capabilities, enabling safe, reliable robot decision-making for HAR tasks in human-robot interaction applications.The proposed SRAC model utilizes subject modeling, which is unsupervised and allows the discovery of new knowledge without being in training. Furthermore, subject modeling is also capable of treating activity estimates as distribution and taking into account risks for any action response, which is beneficial to the decision-making ability of the system. To ensure the ability to accurately interpret human activity, we define a new interpretation indicator (II) and demonstrate its ability to interpret category distribution in a similar way to humans. Indicator II is applied to recognized clusters in known activity categories and selects the best interpreted model to ensure the ability to find knowledge (we have a novel generator)."}, {"heading": "Appendix A. Proof of II \u2019s Properties (Proposition 1)", "text": "If k = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K (K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K = K"}, {"heading": "Appendix B. Proof of the Relationship between II and IA (Proposition 2)", "text": "The accuracy metric IA indicates whether the detection result y (w) corresponds to the soil truth g. Formally, IA is defined as follows: IA (y (w), g) = l (y (w) = g). (B.1) With this definition, we prove that IA is a special case of our II indicator in definition 1, if \u03b81 = 1.0, \u03b82 =.. = \u03b8K = 0, and k = 1 or k = K.In view of the normalizing constants a = 2 and b = 1, if \u03b81 = 1.0, success2 =. = \u03b8K = 0, and k = 1 (i.e., the detection result y (w) corresponds to the soil truth g), we get: Is (\u03b8s, 1) = 1a (K \u2212 1 + 0) when we look at the case, and vice versa: Is (K \u2212 1)."}], "references": [{"title": "Understanding Origins", "author": ["F.J. Varela", "J. Dupuy"], "venue": "Kluwer Academic Publishers", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1992}, {"title": "A survey of artificial cognitive systems: Implications for the autonomous development of mental capabilities in computational agents", "author": ["D. Vernon", "G. Metta", "G. Sandini"], "venue": "IEEE Transactions on Evolutionary Computation 11 (2) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "ACT: A simple theory of complex cognition", "author": ["J.R. Anderson"], "venue": "American Psychologist 51 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "ACT- R/E: An embodied cognitive architecture for human-robot interaction", "author": ["G. Trafton", "L. Hiatt", "A. Harrison", "F. Tamborello", "S. Khemlani", "A. Schultz"], "venue": "Journal of Human-Robot Interaction 2 (1) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "ACT-R\u03a6: A cognitive architecture with physiology and affect", "author": ["C.L. Dancy"], "venue": "Biologically Inspired Cognitive Architectures 6 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "The Soar cognitive architecture", "author": ["J. Laird"], "venue": "MIT Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "A layered brain architecture for synthetic creatures", "author": ["D. Isla", "R. Burke", "M. Downie", "B. Blumberg"], "venue": "in: International Joint Conferences on Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "A cognitive architecture for a humanoid robot: a first approach", "author": ["C. Burghart", "R. Mikut", "R. Stiefelhagen", "T. Asfour", "H. Holzapfel", "P. Steinhaus", "R. Dillmann"], "venue": "in: IEEE-RAS International Conference on Humanoid Robots", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "The challenge of complexity for cognitive systems", "author": ["U. Schmid", "M. Ragni", "C. Gonzalez", "J. Funke"], "venue": "Cognitive Systems Research 12 (3-4) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning hierarchical invariant spatiotemporal features for action recognition with independent subspace analysis", "author": ["Q.V. Le", "W.Y. Zou", "S.Y. Yeung", "A.Y. Ng"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "FREAK: Fast retina keypoint", "author": ["A. Alahi", "R. Ortiz", "P. Vandergheynst"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "L", "author": ["H. Zhang"], "venue": "E. Parker, 4-dimensional local spatio-temporal features for human activity recognition., in: IEEE/RSJ International Conference on Intelligent Robots and Systems", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Autonomous adaptive exploration using realtime online spatiotemporal topic modeling", "author": ["Y. Girdhar", "P. Giguere", "G. Dudek"], "venue": "International Journal of Robotics Research 33 (4) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised learning of human action categories using spatial-temporal words", "author": ["J.C. Niebles", "H. Wang", "L. Fei-Fei"], "venue": "International Journal of Computer Vision 79 (3) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Human activity analysis: A review", "author": ["J. Aggarwal", "M. Ryoo"], "venue": "ACM Computing Surveys 43 (3) ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Video-based human behavior understanding: a survey", "author": ["P.V.K. Borges", "N. Conci", "A. Cavallaro"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 23 (11) ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Extraction method of gait feature based on human centroid trajectory", "author": ["X. Chen", "T. Yang"], "venue": "in: Computer Engineering and Networking", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Vision-based analysis of small groups in pedestrian crowds", "author": ["W. Ge", "R.T. Collins", "R.B. Ruback"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 34 (5) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Human activity recognition based on silhouette directionality", "author": ["M. Singh", "A. Basu", "M. Mandal"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology 18 (9) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Silhouette-based human action recognition using SAX-Shapes", "author": ["I.N. Junejo", "K.N. Junejo", "Z. Al Aghbari"], "venue": "The Visual Computer 30 (3) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Bio-inspired predictive orientation decomposition of skeleton trajectories for real-time human activity prediction", "author": ["H. Zhang", "L.E. Parker"], "venue": "in: IEEE International Conference on Robotics and Automation", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["D.G. Lowe"], "venue": "International Journal of Computer Vision 60 (2) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "Action recognition via local descriptors and holistic features", "author": ["X. Sun", "M.Y. Chen", "A. Hauptmann"], "venue": "in: IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Real-time activity recognition by discerning qualitative relationships between randomly chosen visual features", "author": ["A. Behera", "A.G. Cohn", "D.C. Hogg"], "venue": "in: British Machine Vision Conference", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing human actions: A local SVM approach", "author": ["C. Schuldt", "I. Laptev", "B. Caputo"], "venue": "in: International Conference on Pattern Recognition", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "Behavior recognition via sparse spatio-temporal features", "author": ["P. Doll\u00e1r", "V. Rabaud", "G. Cottrell", "S. Belongie"], "venue": "in: IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Relevance topic model for unstructured social group activity recognition", "author": ["F. Zhao", "Y. Huang", "L. Wang", "T. Tan"], "venue": "in: Advances in Neural Information Processing Systems", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Human action recognition by semilatent topic models", "author": ["Y. Wang", "G. Mori"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 31 (10) ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Discovery of activity patterns using topic models", "author": ["T. Huynh", "M. Fritz", "B. Schiele"], "venue": "in: International Conference on Ubiquitous Computing", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Discovering routines from large-scale human locations using probabilistic topic models", "author": ["K. Farrahi", "D. Gatica-Perez"], "venue": "ACM Transactions on Intelligent Systems and Technology 2 (1) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Temporal and object relations in plan and activity recognition for robots using topic models", "author": ["R.G. Freedman", "H.-T. Jung", "S. Zilberstein"], "venue": "in: AAAI Fall Symposium Series", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Evaluation methods for topic models", "author": ["H. Wallach", "I. Murray", "R. Salakhutdinov", "D. Mimno"], "venue": "in: International Conference on Machine Learning", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "LDA-based document models for ad-hoc retrieval", "author": ["X. Wei", "W.B. Croft"], "venue": "in: Interational Conference on Research and Development in Information Retrieval", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}, {"title": "Reading tea leaves: How humans interpret topic models", "author": ["J. Chang", "J. Boyd-Graber", "S. Gerrish", "C. Wang", "D. Blei"], "venue": "in: Neural Information Processing Systems", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2009}, {"title": "Automatic evaluation of topic coherence", "author": ["D. Newman", "J.H. Lau", "K. Grieser", "T. Baldwin"], "venue": "in: Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Probabilistic topic models", "author": ["D.M. Blei"], "venue": "Communications of the ACM 55 (4) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "Introduction to this special issue on cognitive architectures and human-computer interaction", "author": ["W.D. Gray", "R.M. Young", "S.S. Kirschenbaum"], "venue": "Human-Computer Interaction 12 (4) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1997}, {"title": "Integrating perceptual and cognitive modeling for adaptive and intelligent human-computer interaction", "author": ["Z. Duric", "W. Gray", "R. Heishman", "F. Li", "A. Rosenfeld", "M. Schoelles", "C. Schunn", "H. Wechsler"], "venue": "Proceedings of the IEEE 90 (7) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2002}, {"title": "EFAA: a companion emerges from integrating a layered cognitive architecture", "author": ["S. Lall\u00e9e", "V. Vouloutsi", "S. Wierenga", "U. Pattacini", "P. Verschure"], "venue": "in: ACM/IEEE International Conference on Human-robot Interaction", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2014}, {"title": "J", "author": ["P.E. Baxter"], "venue": "de Greeff, T. Belpaeme, Cognitive architecture for human\u2013robot interaction: towards behavioural alignment, Biologically Inspired Cognitive Architectures 6 ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "C-HMAX: Artificial cognitive model inspired by the color vision mechanism of the human brain", "author": ["B. Yang", "L. Zhou", "Z. Deng"], "venue": "Tsinghua Science and Technology 18 (1) ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "ACT-CV: Bridging the gap between cognitive models and the outer world", "author": ["M. Halbr\u00fcgge"], "venue": "Grundlagen und anwendungen der mensch-maschine-interaktion ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Steps toward a cognitive vision system", "author": ["H.-H. Nagel"], "venue": "AI Magine 25 (2) ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2004}, {"title": "Interactive scene prediction for automotive applications", "author": ["A. Lawitzky", "D. Althoff", "C.F. Passenberg", "G. Tanzmeister", "D. Wollherr", "M. Buss"], "venue": "in: Intelligent Vehicles Symposium", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2013}, {"title": "Things that see: Context-aware multi-modal interaction", "author": ["J.L. Crowley"], "venue": "in: Cognitive Vision Systems,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2006}, {"title": "Learning situation models in a smart home", "author": ["O. Brdiczka", "J.L. Crowley", "P. Reignier"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 39 (1) ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic models of cognitive development: Towards a rational constructivist approach to the study of learning and development", "author": ["F. Xu", "T.L. Griffiths"], "venue": "Cognition 120 ", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2011}, {"title": "Dynamic decision networks for decisionmaking in self-adaptive systems: A case study", "author": ["N. Bencomo", "A. Belaggoun", "V. Issarny"], "venue": "in: International Symposium on Software Engineering for Adaptive and Self-Managing Systems", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "Dynamic Bayesian networks for vehicle classification in video", "author": ["M. Kafai", "B. Bhanu"], "venue": "IEEE Transactions on Industrial Informatics 8 (1) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic models of cognition: where next", "author": ["N. Chater", "J.B. Tenenbaum", "A. Yuille"], "venue": "Trends in Cognitive Sciences 10 (7) ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2006}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "Journal of Machine Learning Research 3 ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2003}, {"title": "Finding scientific topics", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "in: National Academy of Sciences", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2004}, {"title": "Fast collapsed Gibbs sampling for latent dirichlet allocation", "author": ["I. Porteous", "D. Newman", "A. Ihler", "A. Asuncion", "P. Smyth", "M. Welling"], "venue": "in: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2008}, {"title": "Improving topic evaluation using conceptual knowledge", "author": ["C.C. Musat", "J. Velcin", "S. Trausan-Matu", "M.-A. Rizoiu"], "venue": "in: International Joint Conference on Artificial Intelligence", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2011}, {"title": "Correlated topic models", "author": ["D. Blei", "J. Lafferty"], "venue": "in: Neural Information Processing Systems", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2006}, {"title": "Bayesian nonexhaustive learning for online discovery and modeling of emerging classes", "author": ["M. Dundar", "F. Akova", "A. Qi", "B. Rajwa"], "venue": "in: International Conference on Machine Learning", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2012}, {"title": "Actions as space-time shapes", "author": ["L. Gorelick", "M. Blank", "E. Shechtman", "M. Irani", "R. Basri"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 29 (12) ", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2007}, {"title": "On space-time interest points", "author": ["I. Laptev"], "venue": "International Journal of Computer Vision 64 (2-3) ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Artificial cognition has its origin in cybernetics; its intention is to create a science of mind based on logic [1].", "startOffset": 112, "endOffset": 115}, {"referenceID": 1, "context": "Among other mechanisms, cognitivism is a most widely used cognitive paradigm [2].", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "Several cognitive architectures were developed within this paradigm, including ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), Soar [6], C4 [7], and architectures for robotics [8].", "startOffset": 85, "endOffset": 88}, {"referenceID": 3, "context": "Several cognitive architectures were developed within this paradigm, including ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), Soar [6], C4 [7], and architectures for robotics [8].", "startOffset": 117, "endOffset": 120}, {"referenceID": 4, "context": "Several cognitive architectures were developed within this paradigm, including ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), Soar [6], C4 [7], and architectures for robotics [8].", "startOffset": 129, "endOffset": 132}, {"referenceID": 5, "context": "Several cognitive architectures were developed within this paradigm, including ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), Soar [6], C4 [7], and architectures for robotics [8].", "startOffset": 145, "endOffset": 148}, {"referenceID": 6, "context": "Several cognitive architectures were developed within this paradigm, including ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), Soar [6], C4 [7], and architectures for robotics [8].", "startOffset": 153, "endOffset": 156}, {"referenceID": 7, "context": "Several cognitive architectures were developed within this paradigm, including ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), Soar [6], C4 [7], and architectures for robotics [8].", "startOffset": 189, "endOffset": 192}, {"referenceID": 1, "context": "The combination of the cognitive architecture and components is usually referred to as a cognitive model [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 8, "context": ", perception, under significant uncertainty in a complex environment [9].", "startOffset": 69, "endOffset": 72}, {"referenceID": 9, "context": "This perception uncertainty is addressed in this work using the bag-of-visual-words (BoW) representation based on local spatio-temporal features, which has previously shown promising performance [10, 11, 12].", "startOffset": 195, "endOffset": 207}, {"referenceID": 10, "context": "This perception uncertainty is addressed in this work using the bag-of-visual-words (BoW) representation based on local spatio-temporal features, which has previously shown promising performance [10, 11, 12].", "startOffset": 195, "endOffset": 207}, {"referenceID": 11, "context": "This perception uncertainty is addressed in this work using the bag-of-visual-words (BoW) representation based on local spatio-temporal features, which has previously shown promising performance [10, 11, 12].", "startOffset": 195, "endOffset": 207}, {"referenceID": 11, "context": "In recent years, topic modeling has attracted increasing attention in human behavior discovery and recognition due to its ability to generate a distribution over activities of interest, and its promising performance using BoW representations in robotics applications [12, 13].", "startOffset": 267, "endOffset": 275}, {"referenceID": 12, "context": "In recent years, topic modeling has attracted increasing attention in human behavior discovery and recognition due to its ability to generate a distribution over activities of interest, and its promising performance using BoW representations in robotics applications [12, 13].", "startOffset": 267, "endOffset": 275}, {"referenceID": 13, "context": "Traditional activity recognition systems typically use accuracy as a performance metric [14].", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "We focus our review on the commonly used sequential and space-time volume methods [15].", "startOffset": 82, "endOffset": 86}, {"referenceID": 14, "context": "A comprehensive review of different aspects of human activity recognition (HAR) is presented in [15] and [16].", "startOffset": 96, "endOffset": 100}, {"referenceID": 15, "context": "A comprehensive review of different aspects of human activity recognition (HAR) is presented in [15] and [16].", "startOffset": 105, "endOffset": 109}, {"referenceID": 16, "context": "Chen and Yang represented a human with just a point to derive the gait features for the pedestrian detection [17].", "startOffset": 109, "endOffset": 113}, {"referenceID": 17, "context": "extracted pedestrian trajectories from video to automatically detect small groups of people traveling together [18].", "startOffset": 111, "endOffset": 115}, {"referenceID": 18, "context": "extracted directional vectors from the silhouette contours and utilize the distinct data distribution of these vectors in a vector space for activity recognition [19].", "startOffset": 162, "endOffset": 166}, {"referenceID": 19, "context": "transformed silhouettes of a human from every frame into time-series, then each of these time series is converted into the symbolic vector to represent actions [20].", "startOffset": 160, "endOffset": 164}, {"referenceID": 20, "context": "Zhang and Parker implemented a bio-inspired predictive orientation decomposition (BIPOD) to construct representations of people from skeleton trajectories for the activity recognition and prediction, where the human body is decomposed into five body parts [21].", "startOffset": 256, "endOffset": 260}, {"referenceID": 21, "context": "A large number of HAR methods are based on SIFT features [22] and its extensions [23].", "startOffset": 57, "endOffset": 61}, {"referenceID": 22, "context": "A large number of HAR methods are based on SIFT features [22] and its extensions [23].", "startOffset": 81, "endOffset": 85}, {"referenceID": 23, "context": "proposed a random forest that unifies randomization, discriminative relationships mining and a Markov temporal structure for real-time activity recognition with SIFT features [24].", "startOffset": 175, "endOffset": 179}, {"referenceID": 24, "context": "STIP features were introduced in [25] and SVMs were applied to classify human activities.", "startOffset": 33, "endOffset": 37}, {"referenceID": 25, "context": "used separable filters in spatial and temporal dimensions to extract features for HAR [26].", "startOffset": 86, "endOffset": 90}, {"referenceID": 11, "context": "Four-dimensional features were also introduced in [12] to combine depth information to classify human activities.", "startOffset": 50, "endOffset": 54}, {"referenceID": 26, "context": "incorporated Bayesian learning into an undirected topic model and proposed a \u201drelevance topic model\u201d for the unstructured social group activity recognition [27].", "startOffset": 156, "endOffset": 160}, {"referenceID": 27, "context": "A semi-latent topic model trained in a supervised fashion was introduced in [28] and used to classify activities in videos.", "startOffset": 76, "endOffset": 80}, {"referenceID": 11, "context": "Zhang and Parker adopted topic models to classify activities in 3D point clouds from color-depth cameras on mobile robots [12].", "startOffset": 122, "endOffset": 126}, {"referenceID": 28, "context": "The use of topic models was explored in [29] to discover daily activity patterns in wearable sensor data.", "startOffset": 40, "endOffset": 44}, {"referenceID": 29, "context": "An unsupervised topic model was proposed in [30] to detect daily routines from streaming location and proximity data.", "startOffset": 44, "endOffset": 48}, {"referenceID": 30, "context": "explored a new method using topic models for both plan recognition and activity recognition objective [31].", "startOffset": 102, "endOffset": 106}, {"referenceID": 31, "context": ", computing the probability of held-out documents to evaluate generalization ability [32]) or extrinsic methods that rely on external tasks, (e.", "startOffset": 85, "endOffset": 89}, {"referenceID": 32, "context": ", information retrieval [33]).", "startOffset": 24, "endOffset": 28}, {"referenceID": 33, "context": "demonstrated that the probability of held-out documents is not always a good indicator of human judgment [34].", "startOffset": 105, "endOffset": 109}, {"referenceID": 34, "context": "showed that metrics based on word co-occurrence statistics are able to predict human evaluations of topic quality [35].", "startOffset": 114, "endOffset": 118}, {"referenceID": 35, "context": "As recently pointed out by Blei [36], topic model evaluation is an essential research topic.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "Artificial cognition has its origin in cybernetics with the intention to create a science of mind based on logic [1].", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "Among other cognitive paradigms, cognitivism has undoubtedly been predominant to date [2].", "startOffset": 86, "endOffset": 89}, {"referenceID": 5, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 107, "endOffset": 110}, {"referenceID": 3, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 151, "endOffset": 154}, {"referenceID": 6, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 165, "endOffset": 168}, {"referenceID": 7, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 201, "endOffset": 204}, {"referenceID": 36, "context": "Within the cognitivism paradigm, several cognitive architectures were developed, including Soar [6], ACT-R [3] (and its extensions ACT-R/E [4], ACT-R\u03a6 [5], etc), C4 [7], and architectures for robotics [8], which are relatively independent of applications [37].", "startOffset": 255, "endOffset": 259}, {"referenceID": 1, "context": "The combination of a cognitive architecture and a particular knowledge set is generally referred to as a cognitive model [2].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "The knowledge incorporated in cognitive models is typically determined by human designers [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 37, "context": "For example, cognitive modeling was adopted in [38, 39, 40] to construct intelligent human-machine interaction systems.", "startOffset": 47, "endOffset": 59}, {"referenceID": 38, "context": "For example, cognitive modeling was adopted in [38, 39, 40] to construct intelligent human-machine interaction systems.", "startOffset": 47, "endOffset": 59}, {"referenceID": 39, "context": "For example, cognitive modeling was adopted in [38, 39, 40] to construct intelligent human-machine interaction systems.", "startOffset": 47, "endOffset": 59}, {"referenceID": 40, "context": "Cognitive perception systems were also used to recognize traffic signs [41, 42], interpret traffic behaviors [43, 44], and recognize human activities [45, 46].", "startOffset": 71, "endOffset": 79}, {"referenceID": 41, "context": "Cognitive perception systems were also used to recognize traffic signs [41, 42], interpret traffic behaviors [43, 44], and recognize human activities [45, 46].", "startOffset": 71, "endOffset": 79}, {"referenceID": 42, "context": "Cognitive perception systems were also used to recognize traffic signs [41, 42], interpret traffic behaviors [43, 44], and recognize human activities [45, 46].", "startOffset": 109, "endOffset": 117}, {"referenceID": 43, "context": "Cognitive perception systems were also used to recognize traffic signs [41, 42], interpret traffic behaviors [43, 44], and recognize human activities [45, 46].", "startOffset": 109, "endOffset": 117}, {"referenceID": 44, "context": "Cognitive perception systems were also used to recognize traffic signs [41, 42], interpret traffic behaviors [43, 44], and recognize human activities [45, 46].", "startOffset": 150, "endOffset": 158}, {"referenceID": 45, "context": "Cognitive perception systems were also used to recognize traffic signs [41, 42], interpret traffic behaviors [43, 44], and recognize human activities [45, 46].", "startOffset": 150, "endOffset": 158}, {"referenceID": 46, "context": "Over the last decade, probabilistic models of cognition, as an alternative of deterministic cognitive models, have attracted more attention in cognitive development [47].", "startOffset": 165, "endOffset": 169}, {"referenceID": 47, "context": "For example, an adaptive remote data mirroring system was proposed applying dynamic decision networks in [48].", "startOffset": 105, "endOffset": 109}, {"referenceID": 48, "context": "Another cognitive model was introduced in [49] to apply dynamic Bayesian networks for vehicle classification.", "startOffset": 42, "endOffset": 46}, {"referenceID": 49, "context": "Probabilistic models have also been widely used for learning and reasoning in cognitive modeling [50].", "startOffset": 97, "endOffset": 101}, {"referenceID": 6, "context": "The proposed SRAC model is inspired by the C4 cognitive architecture [7].", "startOffset": 69, "endOffset": 72}, {"referenceID": 50, "context": "Latent Dirichlet Allocation (LDA) [51], which showed promising activity recognition performance in our prior work [12], is applied in the SRAC model.", "startOffset": 34, "endOffset": 38}, {"referenceID": 11, "context": "Latent Dirichlet Allocation (LDA) [51], which showed promising activity recognition performance in our prior work [12], is applied in the SRAC model.", "startOffset": 114, "endOffset": 118}, {"referenceID": 50, "context": "However, exact parameter estimation is intractable in general [51].", "startOffset": 62, "endOffset": 66}, {"referenceID": 51, "context": "Our model applies Gibbs sampling [52] to compute the per-observation activity distribution \u03b8, based on two considerations: 1) This sampling-based method is generally accurate, since it asymptotically approaches the correct distribution [53], and 2) This method can be used to intrinsically evaluate topic model\u2019s performance [32], thereby providing a consistent method to infer, learn, and evaluate topic models.", "startOffset": 33, "endOffset": 37}, {"referenceID": 52, "context": "Our model applies Gibbs sampling [52] to compute the per-observation activity distribution \u03b8, based on two considerations: 1) This sampling-based method is generally accurate, since it asymptotically approaches the correct distribution [53], and 2) This method can be used to intrinsically evaluate topic model\u2019s performance [32], thereby providing a consistent method to infer, learn, and evaluate topic models.", "startOffset": 236, "endOffset": 240}, {"referenceID": 31, "context": "Our model applies Gibbs sampling [52] to compute the per-observation activity distribution \u03b8, based on two considerations: 1) This sampling-based method is generally accurate, since it asymptotically approaches the correct distribution [53], and 2) This method can be used to intrinsically evaluate topic model\u2019s performance [32], thereby providing a consistent method to infer, learn, and evaluate topic models.", "startOffset": 325, "endOffset": 329}, {"referenceID": 50, "context": "The indicator II is defined over the per-observation category proportion \u03b8, which takes values in the (K\u22121)-simplex [51].", "startOffset": 116, "endOffset": 120}, {"referenceID": 0, "context": "\u2200\u03b8s, II(\u03b8s, k) \u2208 [0, 1].", "startOffset": 17, "endOffset": 23}, {"referenceID": 53, "context": "The introduction of IG is inspired by the perplexity metric (also referred to as heldout likelihood), which evaluates a topic model\u2019s generalization ability on a fraction of held-out instances using cross-validation [54] or unseen observations [55].", "startOffset": 216, "endOffset": 220}, {"referenceID": 54, "context": "The introduction of IG is inspired by the perplexity metric (also referred to as heldout likelihood), which evaluates a topic model\u2019s generalization ability on a fraction of held-out instances using cross-validation [54] or unseen observations [55].", "startOffset": 244, "endOffset": 248}, {"referenceID": 31, "context": "The perplexity is defined as the log-likelihood of words in an observation [32].", "startOffset": 75, "endOffset": 79}, {"referenceID": 31, "context": "The left-to-right algorithm, presented in Algorithm 1, is used to estimate Pvwp, which is an accurate and efficient Gibbs sampling method to estimate perplexity [32].", "startOffset": 161, "endOffset": 165}, {"referenceID": 55, "context": "The training set is defined as exhaustive when it contains instances from all categories that can possibly be observed in the testing phase [56].", "startOffset": 140, "endOffset": 144}, {"referenceID": 0, "context": "Low risk [1,30] Unsatisfied with the robot\u2019s performance.", "startOffset": 9, "endOffset": 15}, {"referenceID": 29, "context": "Low risk [1,30] Unsatisfied with the robot\u2019s performance.", "startOffset": 9, "endOffset": 15}, {"referenceID": 30, "context": "Medium risk [31,60] Annoyed or upset by the robot\u2019s actions.", "startOffset": 12, "endOffset": 19}, {"referenceID": 56, "context": "activity dataset [57], the KTH activity dataset [58], and the UTK 3D activity dataset [12].", "startOffset": 17, "endOffset": 21}, {"referenceID": 57, "context": "activity dataset [57], the KTH activity dataset [58], and the UTK 3D activity dataset [12].", "startOffset": 48, "endOffset": 52}, {"referenceID": 11, "context": "activity dataset [57], the KTH activity dataset [58], and the UTK 3D activity dataset [12].", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": ", the Weizmann and KTH datasets), we use two different features: scale-invariant feature transform (SIFT) features [22] and space-time interest points (STIP) features [58].", "startOffset": 115, "endOffset": 119}, {"referenceID": 57, "context": ", the Weizmann and KTH datasets), we use two different features: scale-invariant feature transform (SIFT) features [22] and space-time interest points (STIP) features [58].", "startOffset": 167, "endOffset": 171}, {"referenceID": 11, "context": ", the UTK dataset), we use the 4-dimensional local spatio-temporal features (4D-LSTF) [12].", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": "sirable characteristics including invariance to transformation, rotation and scale, and robustness to partial occlusion [22].", "startOffset": 120, "endOffset": 124}, {"referenceID": 21, "context": "We employ the algorithm and implementation in [22] to detect and describe SIFT features.", "startOffset": 46, "endOffset": 50}, {"referenceID": 57, "context": "To encode time information, we also apply STIP along with the histogram of oriented gradients (HOG) and histogram of optical flow (HOF) descriptors [58].", "startOffset": 148, "endOffset": 152}, {"referenceID": 11, "context": "Previous work has demonstrated that local features incorporating both depth and color information can greatly improve recognition accuracy [12].", "startOffset": 139, "endOffset": 143}, {"referenceID": 11, "context": "Therefore, for the 3D UTK dataset we use 4D-LSTF [12] features, which are highly robust and distinct and are generated using both color and depth videos.", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "Thus, \u2200\u03b8, II(\u03b8s, k) \u2208 [0, 1] holds.", "startOffset": 22, "endOffset": 28}], "year": 2016, "abstractText": "In order for cooperative robots (\u201cco-robots\u201d) to respond to human behaviors accurately and efficiently in human-robot collaboration, interpretation of human actions, awareness of new situations, and appropriate decision making are all crucial abilities for corobots. For this purpose, the human behaviors should be interpreted by co-robots in the same manner as human peers. To address this issue, a novel interpretability indicator is introduced so that robot actions are appropriate to the current human behaviors. In addition, the complete consideration of all potential situations of a robot\u2019s environment is nearly impossible in real-world applications, making it difficult for the co-robot to act appropriately and safely in new scenarios. This is true even when the pretrained model is highly accurate in a known situation. For effective and safe teaming with humans, we introduce a new generalizability indicator that allows a co-robot to self-reflect and reason about when an observation falls outside the co-robot\u2019s learned model. Based on topic modeling and two novel indicators, we propose a new Self-reflective Risk-aware Artificial Cognitive (SRAC) model. The co-robots are able to consider action risks and identify new situations so that better decisions can be made. Experiments both using real-world datasets and on physical robots suggest that our SRAC model significantly outperforms the traditional methodology and enables better decision making in response to human activities. Email addresses: fhan@mines.edu (Fei Han), creardon@utk.edu (Christopher Reardon), leparker@utk.edu (Lynne E. Parker), hzhang@mines.edu (Hao Zhang) May 18, 2016 ar X iv :1 60 5. 04 93 4v 1 [ cs .R O ] 1 6 M ay 2 01 6", "creator": "LaTeX with hyperref package"}}}