{"id": "1605.05368", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2016", "title": "Deep Action Sequence Learning for Causal Shape Transformation", "abstract": "Deep learning (DL) became the method of choice in recent years for solving problems ranging from object recognition and speech recognition to robotic perception and human disease prediction. In this paper, we present a hybrid architecture of convolutional neural networks (CNN) and stacked autoencoders (SAE) to learn a sequence of actions that nonlinearly transforms an input shape or distribution into a target shape or distribution with the same support. While such a framework can be useful in a variety of problems such as robotic path planning, sequential decision-making in games and identifying material processing pathways to achieve desired microstructures, this paper focuses on controlling fluid deformations in a microfluidic channel by deliberately placing a sequence of pillars, which has a significant impact on manufacturing for biomedical and textile applications where highly targeted shapes are desired. We propose an architecture which simultaneously predicts the intermediate shape lying in the nonlinear transformation pathway between the undeformed and desired flow shape, then learns the causal action--the single pillar which results in the deformation of the flow--one at a time. The learning of stage-wise transformations provides deep insights into the physical flow deformation. Results show that under the current framework, our model is able to predict a sequence of pillars that reconstructs the flow shape which highly resembles the desired shape.", "histories": [["v1", "Tue, 17 May 2016 21:07:18 GMT  (1072kb)", "http://arxiv.org/abs/1605.05368v1", null], ["v2", "Fri, 20 May 2016 02:01:37 GMT  (1071kb)", "http://arxiv.org/abs/1605.05368v2", "Submitted to NIPS2016. Differences: All vspaces removed and all figures in full size"], ["v3", "Tue, 8 Nov 2016 20:48:47 GMT  (1459kb)", "http://arxiv.org/abs/1605.05368v3", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["kin gwn lore", "daniel stoecklein", "michael davies", "baskar ganapathysubramanian", "soumik sarkar"], "accepted": false, "id": "1605.05368"}, "pdf": {"name": "1605.05368.pdf", "metadata": {"source": "CRF", "title": "Deep Action Sequence Learning for Causal Shape Transformation", "authors": ["Kin Gwn Lore"], "emails": ["kglore@iastate.edu", "stoeckd@iastate.edu", "mdavies@iastate.edu", "baskarg@iastate.edu", "soumiks@iastate.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.05 36"}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Problem setup", "text": "In this section we describe the structure of the problem, previous work and our proposed architecture in solving the inverse design problem."}, {"heading": "2.1 Flow sculpting", "text": "The shape of a fluid flow can be controlled by deliberately introducing obstacles within the fluid channel in the form of micro-arrows, where the arrangement of the pillars in a sequence gradually contributes to the deformation of the flow form (see Figure 1). We are interested in the reverse problem - predicting the configurations of the pillars in a desired flow form. To address this problem, class indices are assigned to the pillars with different specifications. For example, a column at position 0.0 with a diameter of 0.375 is assigned an index of 1, while another column at position 0.125 and diameter 0.375 is assigned an index of 2. Diameters and position values are presented as ratios in relation to the channel size and locations, so that they are dimensionless sizes to allow the scalability of the fluid channel. Index assignment is made by a finite combination of column positions and diameters achieved by discretizing the construction space (there is a possible acid class in 32)."}, {"heading": "2.2 Simultaneous multi-class classification (SMC)", "text": "Simultaneous multi-class classification is a method proposed in [7] for solving a similar problem. Instead of solving a single classification problem, the model solves a partial problem for each column based on the parameters learned by CNN. This formulation requires a minor modification of the loss function: For column sequences with length np, the loss function to be minimized for a data set D is the negative log probability defined as follows: Total number of logs (\u03b8 = {W, b}, D) = \u2212 np \u2211 j = 1 | D | \u2211 i = 0 [log (P (Y = y (i) | x (i), W, b)] jwo D denotes the training set, while D denotes the model parameters with W as weight and b for the bias. y is the predicted column index, whereas x is the provided image of the flow form. The total loss is calculated by adding the individual sequences to the number of losses for each column, while the number of new columns is different in each method."}, {"heading": "2.3 Pillar prediction network (PPN)", "text": "In fact, most of them are able to survive on their own, without having to orient themselves in a different direction."}, {"heading": "2.5 The integrated pipeline (PPN+ITN)", "text": "With the clearly described roles of PPN and ITN, we can now integrate both networks into one integrated pipeline. A circuit diagram is shown in Fig. 5. At the very beginning, ITN will guess a candidate for the bridging flow form, which will then be considered a temporary target form and associated with the undeformed form placed on the left with a cushion. The concatenated input is delivered to the PPN to predict the first column causing the deformation, and then added to the originally empty sequence, resulting in a sequence of length 1. The current form is regenerated with the updated one-column sequence and replaces the left part of the input image for the next PPN iteration to obtain the second column index. The process repeats itself as \"Level A\" (with the bridging form serving as a temporary target) until the current shape of the bridging form is sufficiently similar or reaches an iteration limit."}, {"heading": "3 Results and discussions", "text": "In this section, we will first present the evaluation metrics used in the study, and then show the results that CNN-SMC compares to our method using PPN and the PPN + ITN hybrid architecture."}, {"heading": "3.1 Performance evaluation metrics", "text": "In order to quantify the effectiveness of both approaches, we evaluated the pixel match rate (PMR) on 20 target flow forms and calculated corresponding statistics. The PMR defined in [7] is calculated as follows: PMR = 1 \u2212 | | p \u2212 p | 1 | p | where p is the target image vector, p \u00b2 is the predicted image vector, and | p | denotes the number of elements in the vector (i.e. the total number of pixels in the image).As a supplementary metric, the Structural Similarities Index (SSIM) [21] is used to compare how structurally similar the regenerated flow form patterns are (from the predicted sequence) to the target flow shape. SSIM examines the change in image structure and contains pixel interdependencies. SSIM is expressed as follows: 2x SSIM (2 \u00b5x) and the regenerated flow form images are different (from the predicted sequence to the target flow shape)."}, {"heading": "3.2 Predicting sequences with PPN and ITN", "text": "In all of our tests, the target flow shape is generated from a 10-column sequence that is sufficiently complex. Figure 6 shows four exemplary target shapes where performance consists only of PPN (without bridging) and PPN + ITN (with bridging). In most cases, the pure PPN formulation results in column sequences that result in flow shapes that do not come as close to the target shape as the use of PPN + ITN. This is the case in cases C and D in Figure 6. On the other hand, using the bridging shape as a temporary target has shown a big improvement in prediction performance. In addition, we see that most shapes correspond to both the bridging shape and the target in the PPN + ITN formulation. In realistic applications, the sequence can be stored and post-processed in memory to remove the redundant columns and thus generate a shorter sequence that can increase the financial savings during the manufacturing process."}, {"heading": "3.3 Comparison with CNN-SMC", "text": "20 random comparison of the performance of CNN-SMC, and our methods PPN and PPN + ITN are shown in Figure 7 and in Table 1. The reconstructed flow shapes from the predicted sequences are shown in Figure 8. Both in Figure 7 (a) and in Figure 7 (b), PMR and SSIM for PPN and PPN + ITN are significantly higher than the CNN-SMC approach. We observe that the predicted sequence for CNN-SMC can result in a completely dissimilar shape for some target flow shapes (e.g. Figure 2, 19, 20). In some cases (e.g. Figure 14, 15, 16), PPN fared better than the hybrid PN + ITN model. However, PPN + ITN is consistently better than the PPN-pure architecture in terms of both PMR and SSIM. This shows that a bridging shape generally helps to generate sequences that generate complex flow shapes."}, {"heading": "4 Conclusions and future work", "text": "This paper proposes a deep learning-based approach to learning a sequence of actions that execute the desired transformation via input, with potentially major implications for innovation in manufacturing processes, materials science, biomedical applications, decision planning, and more. In the paper, we focused specifically on the development of microfluidic channels for flow modelling. We demonstrated that the creative integration of DL-based tools can solve the problem of inverse fluid and achieve the required design accuracy while speeding up the design process compared to tedious and faulty design. Together, the generation of training data and hierarchical feature extraction processes prove to be very useful for a scalable design tool. Current efforts focus primarily on optimizing the tool chain (e.g. recursive ITN) as well as tailored solutions for specific applications such as manufacturing and biology."}], "references": [{"title": "Classification using discriminative restricted boltzmann machines", "author": ["Hugo Larochelle", "Yoshua Bengio"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Deep neural networks for acoustic modeling in speech recognition", "author": ["Geoffrey E. Hinton", "Li Deng", "Dong Yu", "George E. Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N. Sainath", "Brian Kingsbury"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Occlusion edge detection in rgb-d frames using deep convolutional networks", "author": ["Soumik Sarkar", "Vivek Venugopalan", "Kishore Reddy", "Michael Giering", "Julian Ryde", "Navdeep Jaitly"], "venue": "Proceedings of IEEE High Performance Exterme Computing Conference,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Indoor semantic segmentation using depth information", "author": ["Camille Couprie", "Cl\u00e9ment Farabet", "Laurent Najman", "Yann LeCun"], "venue": "arXiv preprint arXiv:1301.3572,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Multimodal learning with deep boltzmann machines", "author": ["Nitish Srivastava", "Ruslan R Salakhutdinov"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Early detection of combustion instability by neural-symbolic analysis on hi-speed video", "author": ["Soumalya Sarkar", "Kin Gwn Lore", "Soumik Sarkar"], "venue": "In Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches (CoCo@ NIPS", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Hierarchical feature extraction for efficient design of microfluidic flow patterns", "author": ["Kin Gwn Lore", "Daniel Stoecklein", "Michael Davies", "Baskar Ganapathysubramanian", "Soumik Sarkar"], "venue": "In Proceedings of The 1st International Workshop on \u201cFeature Extraction: Modern Questions and Challenges\u201d,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Deep value of information estimators for collaborative human-machine information gathering", "author": ["Kin Gwn Lore", "Nicholas Sweet", "Kundan Kumar", "Nisar Ahmed", "Soumik Sarkar"], "venue": "International Conference on Cyber-physical Systems (ICCPS). Vienna,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Deep learning of the tissue-regulated splicing", "author": ["Michael K.K. Leung", "Hui Y. Xiong", "Leo J. Lee", "Brendan J. Frey"], "venue": "code. Bioinformatics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Mitosis detection in breast cancer histology images with deep neural networks. In Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI", "author": ["Dan C. Cire\u015fan", "Alessandro Giusti", "Luca M. Gambardella", "J\u00fcrgen Schmidhuber"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Engineering fluid flow using sequenced microstructures", "author": ["Hamed Amini", "Elodie Sollier", "Mahdokht Masaeli", "Yu Xie", "Baskar Ganapathysubramanian", "Howard A. Stone", "Dino Di Carlo"], "venue": "Nature Communications,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Optimization of micropillar sequences for fluid flow sculpting", "author": ["Daniel Stoecklein", "Chueh-Yu Wu", "Donghyuk Kim", "Dino Di Carlo", "Baskar Ganapathysubramanian"], "venue": "Physics of Fluids,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Application of machine learning algorithms to flow modeling and optimization", "author": ["S.D. M\u00fcller", "M. Milano", "Petros Koumoutsakos"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Closed-loop turbulence control using machine learning", "author": ["Thomas Duriez", "Vladimir Parezanovi\u0107", "Laurent Cordier", "Bernd R Noack", "Jo\u00ebl Delville", "Jean- Paul Bonnet", "Marc Segond", "Markus Abel"], "venue": "arXiv preprint arXiv:1404.4589,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Artificial neural networks approach for solving stokes problem", "author": ["Modjtaba Baymani", "Asghar Kerayechian", "Sohrab Effati"], "venue": "Applied Mathematics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "The role of neural networks in fluid mechanics and heat transfer", "author": ["S. Ashforth-Frost", "V.N. Fontama", "K. Jambunathan", "S.L. Hartle"], "venue": "In Instrumentation and Measurement Technology Conference,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "Recurrent neural network based language model", "author": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In INTERSPEECH,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Spatial transformer networks", "author": ["Max Jaderberg", "Karen Simonyan", "Andrew Zisserman"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Pascal Vincent", "Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Image quality assessment: from error visibility to structural similarity", "author": ["Zhou Wang", "Alan Conrad Bovik", "Hamid Rahim Sheikh", "Eero P Simoncelli"], "venue": "Image Processing, IEEE Transactions on,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction Hierarchical feature extraction using deep neural networks has been very successful in accomplishing various tasks such as objection recognition [1], speech recognition [2], scene understand-", "startOffset": 160, "endOffset": 163}, {"referenceID": 1, "context": "1 Introduction Hierarchical feature extraction using deep neural networks has been very successful in accomplishing various tasks such as objection recognition [1], speech recognition [2], scene understand-", "startOffset": 184, "endOffset": 187}, {"referenceID": 2, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 4, "endOffset": 10}, {"referenceID": 3, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 4, "endOffset": 10}, {"referenceID": 4, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 38, "endOffset": 41}, {"referenceID": 5, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 55, "endOffset": 58}, {"referenceID": 6, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 79, "endOffset": 82}, {"referenceID": 7, "context": "ing [3, 4], multi-modal sensor fusion [5], prognostics [6], engineering design [7] and policy reward learning [8].", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "In addition, the field of biology has taken a huge interest in using deep learning (DL) methods for relating DNA variants to diseases [9] and detecting mitosis from cancer histology images [10].", "startOffset": 134, "endOffset": 137}, {"referenceID": 9, "context": "In addition, the field of biology has taken a huge interest in using deep learning (DL) methods for relating DNA variants to diseases [9] and detecting mitosis from cancer histology images [10].", "startOffset": 189, "endOffset": 193}, {"referenceID": 10, "context": "Using microchannels populated with a set of pillars, the pillars can individually deform a flow to achieve the final desired shape [11].", "startOffset": 131, "endOffset": 135}, {"referenceID": 11, "context": "Although works have been done to frame this inverse problem as an unconstrained optimization problem [12], they are invariable time-consuming.", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 13, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 14, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 15, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 57, "endOffset": 64}, {"referenceID": 6, "context": "While many methods are used to solve the forward problem [13\u201316], only a limited amount of effort has been done in solving the inverse problem [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 16, "context": "Recurrent neural network (RNN)-like architectures [17] are deemed unsuitable because the elements in the output vector are generally independent of each other, unlike words in a sentence.", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "A related concept is the spatial transformer network [18] where the localization network outputs geometrical transformation parameters; however we desire an exact class attributed to an arbitrary transformation function.", "startOffset": 53, "endOffset": 57}, {"referenceID": 6, "context": "Authors in [7] predicted the sequence of pillars which deforms into the target flow shape in a joint manner, although the resultant sequence is constrained in length and do not provide sufficient insight on the interplay between pillars causing the deformation.", "startOffset": 11, "endOffset": 14}, {"referenceID": 18, "context": "An integrated hierachical feature extraction approach using deep autoencoders (DAE) [19] with convolutional neural networks (CNN) [20] is proposed to capture multi-scale patterns of a deformed fluid flow to generate the associated sequence resulting in the deformation.", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "An integrated hierachical feature extraction approach using deep autoencoders (DAE) [19] with convolutional neural networks (CNN) [20] is proposed to capture multi-scale patterns of a deformed fluid flow to generate the associated sequence resulting in the deformation.", "startOffset": 130, "endOffset": 134}, {"referenceID": 6, "context": "Simultaneous multi-class classification is a method proposed in [7] to solve a similar problem.", "startOffset": 64, "endOffset": 67}, {"referenceID": 6, "context": "The PMR, defined in [7], is computed as follows: PMR = 1\u2212 ||p\u2212 p\u0302||1 |p| where p is the target image vector, p\u0302 is the predicted image vector, and |p| denotes the number of elements in the vector (i.", "startOffset": 20, "endOffset": 23}, {"referenceID": 20, "context": "As a supplementary metric, the structural similarity index (SSIM) [21] is used to compare how structurally similar are the regenerated flow shape images (from predicted sequence) to the target flow shape.", "startOffset": 66, "endOffset": 70}], "year": 2017, "abstractText": "Deep learning (DL) became the method of choice in recent years for solving problems ranging from object recognition and speech recognition to robotic perception and human disease prediction. In this paper, we present a hybrid architecture of convolutional neural networks (CNN) and stacked autoencoders (SAE) to learn a sequence of actions that nonlinearly transforms an input shape or distribution into a target shape or distribution with the same support. While such a framework can be useful in a variety of problems such as robotic path planning, sequential decision-making in games and identifying material processing pathways to achieve desired microstructures, this paper focuses on controlling fluid deformations in a microfluidic channel by deliberately placing a sequence of pillars, which has a significant impact on manufacturing for biomedical and textile applications where highly targeted shapes are desired. We propose an architecture which simultaneously predicts the intermediate shape lying in the nonlinear transformation pathway between the undeformed and desired flow shape, then learns the causal action\u2013the single pillar which results in the deformation of the flow\u2013one at a time. The learning of stage-wise transformations provides deep insights into the physical flow deformation. Results show that under the current framework, our model is able to predict a sequence of pillars that reconstructs the flow shape which highly resembles the desired shape.", "creator": "LaTeX with hyperref package"}}}