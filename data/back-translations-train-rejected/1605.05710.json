{"id": "1605.05710", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-May-2016", "title": "Active Learning On Weighted Graphs Using Adaptive And Non-adaptive Approaches", "abstract": "This paper studies graph-based active learning, where the goal is to reconstruct a binary signal defined on the nodes of a weighted graph, by sampling it on a small subset of the nodes. A new sampling algorithm is proposed, which sequentially selects the graph nodes to be sampled, based on an aggressive search for the boundary of the signal over the graph. The algorithm generalizes a recent method for sampling nodes in unweighted graphs. The generalization improves the sampling performance using the information gained from the available graph weights. An analysis of the number of samples required by the proposed algorithm is provided, and the gain over the unweighted method is further demonstrated in simulations. Additionally, the proposed method is compared with an alternative state of-the-art method, which is based on the graph's spectral properties. It is shown that the proposed method significantly outperforms the spectral sampling method, if the signal needs to be predicted with high accuracy. On the other hand, if a higher level of inaccuracy is tolerable, then the spectral method outperforms the proposed aggressive search method. Consequently, we propose a hybrid method, which is shown to combine the advantages of both approaches.", "histories": [["v1", "Wed, 18 May 2016 19:21:22 GMT  (620kb,D)", "http://arxiv.org/abs/1605.05710v1", "In ICASSP 2016"]], "COMMENTS": "In ICASSP 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["eyal en gad", "akshay gadde", "a salman avestimehr", "antonio ortega"], "accepted": false, "id": "1605.05710"}, "pdf": {"name": "1605.05710.pdf", "metadata": {"source": "CRF", "title": "ACTIVE LEARNING ON WEIGHTED GRAPHS USING ADAPTIVE AND NON-ADAPTIVE APPROACHES", "authors": ["Eyal En Gad", "Akshay Gadde", "A. Salman Avestimehr", "Antonio Ortega"], "emails": [], "sections": [{"heading": null, "text": "Index terms - active learning on graphs, adaptive and non-adaptive sampling of graph signals, sampling of complexity"}, {"heading": "1. INTRODUCTION", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "2. S2 ALGORITHM FOR WEIGHTED GRAPHS", "text": "The S2 algorithm was proposed in [2] for unweighted graphs. In this section we describe the principle of the algorithm and generalize the algorithm to weighted graphs. In the next section we analyze the query complexity of the generalized algorithm."}, {"heading": "2.1. Original S2 Algorithm", "text": "The goal of the algorithm is to find the signal f. To do this, the algorithm works by finding the edges that connect opposite labeled nodes. These edges are called cut edges, and together, the set of cut edges is called cut edges. The algorithm incrementally identifies the cut, on the grounds that once the entire cut is identified, the signal is fully restored. To find the cut, the algorithm receives a copy of the graph G, and each time it tries a node that was previously sampled, it removes the newly discovered cut edges from the graph copy. In this way, the remaining graph copy contains only the undetected portion of the cut, and the algorithm can more easily focus on the discovery of those edges. The main idea of the algorithm is to search for a pair of opposite labeled nodes, and then the remaining intersections are removed from the graph copy."}, {"heading": "2.2. Generalization for Weighted Graphs", "text": "The S2 is intended only for the unweighted graphs. As many learning scenarios provide a weighted graph, we expand the algorithm to use the additional available information by modifying the unweighted S2 algorithms."}, {"heading": "3. ANALYSIS OF THE WEIGHTED S2 ALGORITHM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Notation", "text": "Note that f divides the vertices of G into a collection of interconnected components with identically labeled vertices. Let V1, V2,.., Vk be these k-connected components. Note that the first node that S2 queries in each Vi collection is often queried randomly, not by a query in two halves. Define \u03b2, min 1 \u2264 i \u2264 k | Vi | n. If \u03b2 is small, more random queries are required in S2. Let C be the set of intersections in G. The length of the shortest intersection in G is Fig. 2: The interval of interest is at least halved after two queries. Identify by lcut. Let the set of nodes divide an edge with at least one opposite labeled node. The nodes in B are called boundary nodes in G."}, {"heading": "3.2. Cut Clustering", "text": "For nodes x, y, V, dG (x, y) must be the length of the shortest path connecting x and y in G. Let e1 = {x1, y1} and e2 = {x2, y2} be a pair of cut edges inG, so that f (x1) = f (x2) and f (y1) = f (y2) are removed. Definie\u03b4 (e1, e2) = d G \u2212 C (x1, x2) + d G \u2212 C (y1, y2) + max {le1, le2}, where G \u2212 C is the graph G where all cut edges are removed. Let Hr = (C, E) be the meta graph whose nodes are the cut edges of G, and {e, e \u00b2)."}, {"heading": "3.3. Query Complexity", "text": "Theorem 1. Suppose that a graph G = (V, E) and a signal f are such that the induced intersection C m has components with cut clusters. Then, for each > 0, the weighted S2 becomes with probability at least 1 \u2212 if the cut edge is at least 1 \u2212 if the cut edge has at least 2 log2 (ln lcut) log2 (ln lcut) log2 (l / lcut) log2 (l / lcut) log2 (l / lcut) log2 (l / lcut) log2 (l / lcut) log2 (l / lcut) log2 (l / lcut) log2) log2 (lcut) log2 (l / lcut) logarithmic in (l / lcut), where l is the length of the path between the nodes. We show this fact in the following lemma.Lemma 2. The cutting edge of the length lcut lcut lcut lcut lcut lcut lcut lcut lcut lcut lcut lcut."}, {"heading": "4. EXPERIMENTS", "text": "In fact, most people are able to recognize themselves and understand what they are doing to change the world."}, {"heading": "5. CONCLUSIONS", "text": "The paper generalizes the S2 algorithm in the case of weighted graphs, analyzes the sample complexity of the generalized algorithm, and demonstrates the gain over the unweighted version by simulation. Further experiments identify the range of tolerable reconstruction error in which the S2 algorithms exceed a diagram frequency-based global approach. A hybrid approach is proposed, which has the advantages of both methods. It remains open to analytically characterize the gain of the weighted S2 method over the unweighted version. Another interesting way for future work is to provide a performance analysis for the spectral sampling method, which can suggest an optimal switching criterion for the hybrid method."}, {"heading": "6. REFERENCES", "text": "[1] Burr Settles, \"Active learning literature survey,\" Computer Sciences Technical Report 1648, University of Wisconsin - Madison, 2010. [2] Gautam Dasarathy, Robert Nowak, and Xiaojin Zhu, \"S2: An efficient graph based active learning algorithm with application to nonparametric classification,\" Journal of Machine Learning Research, vol. 40, pp. 1-20, 2015. [3] Xiaojin Zhu, John Lafferty, and Zoubin Ghahramani, \"Combining active learning and semi-supervised learning using gaussian fields and harmonic functions,\" in ICML 2003 workshop on the continuum from labeled to unlabeled data in machine learning and data mining, 2003, pp."}], "references": [{"title": "Active learning literature survey", "author": ["Burr Settles"], "venue": "Computer Sciences Technical Report 1648, University of Wisconsin\u2013 Madison, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "S: An efficient graph based active learning algorithm with application to nonparametric classification", "author": ["Gautam Dasarathy", "Robert Nowak", "Xiaojin Zhu"], "venue": "Journal of Machine Learning Research, vol. 40, pp. 1\u201320, 2015.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Combining active learning and semi-supervised learning using gaussian fields and harmonic functions", "author": ["Xiaojin Zhu", "John Lafferty", "Zoubin Ghahramani"], "venue": "ICML 2003 workshop on the continuum from labeled to unlabeled data in machine learning and data mining, 2003, pp. 58\u201365.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Towards a sampling theorem for signals on arbitrary graphs", "author": ["A. Anis", "A. Gadde", "A. Ortega"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), IEEE International Conference on, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "A variance minimization criterion to active learning on graphs", "author": ["M. Ji", "J. Han"], "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS), 2012, vol. 22, pp. 556\u2013 564.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Active semi-supervised learning using submodular functions", "author": ["Andrew Guillory", "Jeff Bilmes"], "venue": "Proceedings of 27th Conference on Uncertainty in Artificial Intelligence, 2011, pp. 274\u2013282.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Balancing exploration and exploitation: A new algorithm for active machine learning", "author": ["Thomas Osugi", "Deng Kim", "Stephen Scott"], "venue": "Data Mining, Fifth IEEE International Conference on. IEEE, 2005, pp. 8\u2013pp.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Active semi-supervised learning using sampling theory for graph signals", "author": ["A. Gadde", "A. Anis", "A. Ortega"], "venue": "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2014, pp. 492\u2013501.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Localized iterative methods for interpolation in graph structured data", "author": ["S.K. Narang", "A. Gadde", "E. Sanou", "A. Ortega"], "venue": "Signal and Information Processing (GlobalSIP), IEEE Global Conference on, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Active learning is an effective way to minimize the cost of labeling in such scenarios [1].", "startOffset": 87, "endOffset": 90}, {"referenceID": 1, "context": "The methods with this approach [2, 3] sample nodes sequentially, i.", "startOffset": 31, "endOffset": 37}, {"referenceID": 2, "context": "The methods with this approach [2, 3] sample nodes sequentially, i.", "startOffset": 31, "endOffset": 37}, {"referenceID": 3, "context": "The second approach [4, 5, 6], in contrast, utilizes global properties of the graph in order to identify the most informative nodes, and sample them all at once.", "startOffset": 20, "endOffset": 29}, {"referenceID": 4, "context": "The second approach [4, 5, 6], in contrast, utilizes global properties of the graph in order to identify the most informative nodes, and sample them all at once.", "startOffset": 20, "endOffset": 29}, {"referenceID": 5, "context": "The second approach [4, 5, 6], in contrast, utilizes global properties of the graph in order to identify the most informative nodes, and sample them all at once.", "startOffset": 20, "endOffset": 29}, {"referenceID": 6, "context": "It is also possible to combine the two approaches, for example, as in [7].", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "The weighted S algorithm is a generalization of a recently proposed algorithm called S [2], which is defined only for the case of unweighted edges.", "startOffset": 87, "endOffset": 90}, {"referenceID": 3, "context": "We further compare the sampling complexity of the weighted S algorithm with an alternative state-of-the-art method called the cutoff maximization method [4].", "startOffset": 153, "endOffset": 156}, {"referenceID": 7, "context": "Unlike the S methods, which aim for a complete recovery of the signal by aggressively searching for the boundary nodes, the cutoff maximization method is focused only on providing a good approximation of the signal by ensuring that the unsampled nodes are well-connected to the sampled nodes [8].", "startOffset": 292, "endOffset": 295}, {"referenceID": 6, "context": "Motivated by the second observation, we propose a hybrid approach (similar in spirit to [7]) which samples the first few nodes ar X iv :1 60 5.", "startOffset": 88, "endOffset": 91}, {"referenceID": 1, "context": "The S algorithm was proposed in [2] for unweighted graphs.", "startOffset": 32, "endOffset": 35}, {"referenceID": 8, "context": "Several such label completion algorithms are known, such as the POCS method in [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 1, "context": "The S algorithm in [2] is defined only for unweighted graphs.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "The random sampling phase follows the same argument as in [2], which gives the term log(1/(\u03b2 )) log(1/(1\u2212\u03b2)) .", "startOffset": 58, "endOffset": 61}, {"referenceID": 7, "context": "Each document i is represented by a 3000 dimensional vector xi whose elements are the tf-idf statistics of the 3000 most frequent words in the dataset [8].", "startOffset": 151, "endOffset": 154}, {"referenceID": 1, "context": "We compare the performance of the following active learning methods: (1) unweighted S method [2] with graph G, (2) weighted S method with dissimilarity graph Gd, (3) cutoff maximization method [8] with similarity graph Gw and (4) a hybrid approach combining cutoff maximization and weighted S method.", "startOffset": 93, "endOffset": 96}, {"referenceID": 7, "context": "We compare the performance of the following active learning methods: (1) unweighted S method [2] with graph G, (2) weighted S method with dissimilarity graph Gd, (3) cutoff maximization method [8] with similarity graph Gw and (4) a hybrid approach combining cutoff maximization and weighted S method.", "startOffset": 193, "endOffset": 196}, {"referenceID": 7, "context": "After the nodes selected by each method have been sampled, we reconstruct the unknown label signal using the approximate POCS based bandlimited reconstruction scheme [8] to get the soft labels.", "startOffset": 166, "endOffset": 169}], "year": 2016, "abstractText": "This paper studies graph-based active learning, where the goal is to reconstruct a binary signal defined on the nodes of a weighted graph, by sampling it on a small subset of the nodes. A new sampling algorithm is proposed, which sequentially selects the graph nodes to be sampled, based on an aggressive search for the boundary of the signal over the graph. The algorithm generalizes a recent method for sampling nodes in unweighted graphs. The generalization improves the sampling performance using the information gained from the available graph weights. An analysis of the number of samples required by the proposed algorithm is provided, and the gain over the unweighted method is further demonstrated in simulations. Additionally, the proposed method is compared with an alternative stateof-the-art method, which is based on the graph\u2019s spectral properties. It is shown that the proposed method significantly outperforms the spectral sampling method, if the signal needs to be predicted with high accuracy. On the other hand, if a higher level of inaccuracy is tolerable, then the spectral method outperforms the proposed aggressive search method. Consequently, we propose a hybrid method, which is shown to combine the advantages of both approaches.", "creator": "LaTeX with hyperref package"}}}