{"id": "1605.06296", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2016", "title": "On the Robustness of Decision Tree Learning under Label Noise", "abstract": "In most practical problems of classifier learning, the training data suffers from the label noise. Hence, it is important to understand how robust is a learning algorithm to such label noise. Experimentally, Decision trees have been found to be more robust against label noise than SVM and logistic regression. This paper presents some theoretical results to show that decision tree algorithms are robust to symmetric label noise under the assumption of large sample size. We also present some sample complexity results for this robustness. Through extensive simulations we illustrate this robustness.", "histories": [["v1", "Fri, 20 May 2016 11:31:26 GMT  (32kb)", "https://arxiv.org/abs/1605.06296v1", null], ["v2", "Fri, 26 Aug 2016 08:58:06 GMT  (58kb)", "http://arxiv.org/abs/1605.06296v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["aritra ghosh", "naresh manwani", "p s sastry"], "accepted": false, "id": "1605.06296"}, "pdf": {"name": "1605.06296.pdf", "metadata": {"source": "CRF", "title": "On the Robustness of Decision Tree Learning under Label Noise", "authors": ["Aritra Ghosh", "Naresh Manwani"], "emails": ["aritraghosh.iem@gmail.com", "nareshmanwani@gmail.com", "sastry@ee.iisc.ernet.in"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.06 296v 2 [cs.L G] 2Keywords: robust learning, decision trees, label noise"}, {"heading": "1. Introduction", "text": "In fact, it is in such a way that most of us are able to move into a different world, in which they are able to move, and in which they are able to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live"}, {"heading": "2. Label Noise and Decision Tree Robustness", "text": "In this paper we consider only binary decision trees for binary classification. We use the same idea of noise tolerance as in (Manwani and Sastry, 2013; van Rooyen et al., 2015)."}, {"heading": "2.1. Label Noise", "text": "Let S = {(x1, yx1), (x2, yx2),.., (xN, yxN), (X \u00b7 Y) N be the ideal noise-free data drawn iid from a fixed but unknown distribution D over X \u00b7 Y. The learning algorithm has no access to these data. The loud training data given to the algorithm are S\u03b7 = {(xi, y-xi), i = 1, \u00b7 \u00b7 \u00b7, N}, where y-xi = yxi with probability (1 \u2212 \u03b7xi) and y-xi = \u2212 yxi with probability throuxi. As notation, yx denotes its \"true\" identifier for each x, while y-x denotes the loud identifier. Thus, throux denotes the loud identifier = Pr [yx 6 = y-xi = \u2212 yxi with probability throuxi."}, {"heading": "2.2. Criteria for Learning Split Rule at a Node of Decision Trees", "text": "Most decision tree learning algorithms grow the tree top-down, starting with all the training data at the root node q. At each node, the algorithm selects a column rule to optimize a criterion and uses this column rule to divide the data into the left and right children of that node; then the same process is applied recursively to the children's nodes until the node meets the criterion of becoming a leaf. Let F designate a series of column rules. Suppose a column rule f, F at a node v, sends a fraction of the samples to the left child vl and the remaining fraction (1 \u2212 a) to the right child vr."}, {"heading": "2.3. Noise Tolerance of Decision Tree", "text": "A decision tree learned with loud markings in the training data should have the same test error (in a noise-free test set) as the tree learned with noise-free training data. One way to achieve such robustness is if the decision tree learning algorithm learns the same tree in the presence of label noise as it would learn with noise-free data.1 Since label noise is random, the tree learned would also be random. Therefore, we say that the learning method is robust if, in1. Keeping things simple, we do not consider pruning the tree. The limit as a unit of measurement of tree size goes to infinity, the algorithm learns the same tree with silent training data. We then argue that this implies that we learn the same tree (with a high probability) that we learn the same tree (with a sufficient number of samples)."}, {"heading": "3. Theoretical Results", "text": "The robustness of learning decision trees requires the robustness of the split criterion on each non-leaf knot and the robustness of the label rule on each leaf knot. We consider each of these criteria in turn."}, {"heading": "3.1. Robustness Of Split Rules", "text": "It is therefore not as if it is a matter of a distraction, but a distraction that refers to a distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the deflection from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the deflection from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the distraction from the"}, {"heading": "3.2. Robustness of Labeling Rule at Leaf Nodes", "text": "Next, we consider the robustness of the criterion of assigning a class name to a leaf node. A popular approach is majority decision on the leaf node. We prove that majority decisions are robust against symmetrical label noise in the sense that (in the large sample size) the percentage of positive examples would be more than label noise if the percentage of positive examples was higher in the silent data. (b) We also show that it can be robust against uneven label noise if all dots on the leaf node belong to one class in the noiseless data.ProofLet p and q = 1 \u2212 p are the percentage of positive and negative samples on the leaf node v. (a) Under symmetrical label noise, the relevant fractions are also robust if all dots on the leaf node belong to one class in the noiseless data.ProofLet p and q = 1 \u2212 p are the fraction of positive and negative samples on the leaf node (v.)."}, {"heading": "3.3. Robustness of Decision Tree Learning Under Symmetric Label Noise : Large Sample Analysis", "text": "We have proven that some of the popular splinter criteria are noise tolerant. What we have shown is that the splinter rule that maximizes the criterion among noise-free samples is the same as the one that maximizes the value of the criterion under symmetrical brand name noise (under large sample limits). This means that under large sample assumptions, the same splinter rule would be learned at each node, regardless of whether the markers are from noise-free data or from noise-free data. (Here, for simplicity's sake, we assume that there is a unique splinter rule that maximizes the criterion at each node. Otherwise, we need a predetermined rule to break ties. 2Our result for node labeling implies that under large sample assumptions, a node would get the same label under loud or noise-free data. To conclude that we will need to learn the same leaf when the sample number is determined by a tree, we have to choose the sample for a node the number of nodes."}, {"heading": "3.4. Sample Complexity under Noise", "text": "An interesting question, therefore, is how large the sample size should be so that our assertions about robustness can be held with a high probability. Under symmetrical marking noise with p < 0.5, the majority vote will not fail with the probability, at least not if n \u2265 2\u03c12 (1 \u2212 2\u03b7) 2 ln (1\u043c), whereas the difference between the fraction of positive and negative samples is in noise-free fall. 2. Here, we assume that the xi at the node is the same in the loud and noise-free cases, which are the same at root. If we detect the same fraction of positive and negative samples in noise-free fall in both cases, then the samples in the loud and noise-free cases would be the same."}, {"heading": "3.5. Noise Robustness in Random Forest", "text": "A Random Forest (Breiman, 2001) is a collection of randomized tree classifiers. We place the set of trees as gn = {gn (x, \u03c01), \u00b7 \u00b7 \u00b7 \u00b7, gn (x, \u03c0m)}. If we select these tree classifiers as random, random tree classifiers for prediction, we can designate these classifiers as pure random forest classifiers. In a purely random forest classifier, the tree division does not depend on the class identifiers. At each step, a node is randomly selected and a trait is selected for partition."}, {"heading": "4. Empirical Illustration", "text": "In this section we demonstrate our robustness results for learning decision trees and random forests. We also present results with SVM. Although SVM has not proven robust even under symmetric label noise, its sensitivity to noise differs greatly (Long and Servedio, 2010; Nettleton et al., 2010; Manwani and Sastry, 2013; van Rooyen et al., 2015). We also provide results on sample complexity for robust learning of decision trees and random forests."}, {"heading": "4.1. Dataset Description", "text": "We used four synthetic 2D datasets. Details are given below. (Here n denotes the total number of samples, p +, p \u2212 represents the conditional density of the class, and U (A) the uniform distribution over set A. \u2022 Dataset 1: Checker Board 2by2 Pattern: Data evenly over [0, 2] \u00d7 [0, 2] and a class region containing ([0, 1] \u00d7 [0, 1]) * ([1, 2] \u00d7 [1, 2]) and n = 30000 \u2022 Dataset 2: Checker Board 4by4 Pattern: Extension of the above to a 4 x 4 grid. \u2022 Dataset 3: Imbalance Linear Data. p + = U ([0, 0.5] \u00d7 [0, 1] and p \u2212 = U (0.5, 1] \u00d7 [0, 1])) \u00b7 Previous probabilities of the classes are 0.9 & 0.1 and n = 40,000. \u2022 Dataset 4: Imbalance Linear Data and Linetric."}, {"heading": "4.2. Experimental Setup", "text": "We used the implementation of the decision tree in the Scikit Learn library (Pedregosa et al., 2011). We present the results only with the impurity-based classifier of the decision tree. (We observed that decision trees perform similarly using two rules and a misclassification rate.) For the Random Forest classifier (RF), we use the Scikit Learn library. The number of trees in the Random Forest was set to 100. For the SVM, we used the libsvm package (Chang and Lin, 2011). In Section 4.3, we present the results to illustrate sample complexity for robust learning, where size and size of leaf nodes are varied. In Section 4.4, we compare the accuracy of learning decision trees, random forests, and SVM, for which the following setup is used. Minimum leaf size is the only parameter used in random forests and data sets limited to 250 data sets (for decision trees, for example, for 250 data sets)."}, {"heading": "4.3. Effect of sample size on robustness of learning", "text": "Here we discuss the sensitivity of learning decision trees (under labeling noise) to sample size. We present experimental results on test accuracy for different sample sizes using the 2by2 checkerboard data. To investigate the effect of sample size in leaf nodes, we select a leaf sample size and learn decision tree and random forest with different noise levels. (The size of the training set is set at 20000) We do this for a number of selections for leaf sample size. Test accuracy in all of these cases is shown in Figure 1 (a) as the minimum sample size is required for the majority rule to be correct with high probability. A sample size of 50 leaves seems sufficient to take into account even 30% noise."}, {"heading": "4.4. Comparison of accuracies of learnt classifiers", "text": "The average test accuracy and standard deviation (over 10 runs) on different data sets at different noise levels are shown in Table 1 for synthetic data sets and in Table 2 for UCI data sets. In Table 2 we also show the dimension of feature vectors (d), the number of positive and negative samples in the data (n +, n \u2212). For synthetic data sets, sample sizes are large and therefore we expect good robustness. As shown in Table 1, decision tree, random forest and SVM all have similar accuracies. However, the accuracies of SVM data sets are much worse than those of decision trees and random forest. For example, the accuracies of decision trees and random forest continue to be 99% even at 40% noise, while those of SVM data sets fall to about 90% and 80%."}, {"heading": "5. Conclusion", "text": "In this paper, we investigated the robustness of learning decision trees under label noise. In many current applications, one has to pay attention to label noise in the training data. Therefore, it is very desirable to have learning algorithms that are not affected by label noise. Since most contamination-based top-down decision tree algorithms learn split rules based on fractions of positive and negative samples at a node, one can expect them to have somersaults. We have proven that decision tree algorithms based on impurities due to impurities or misclassifications, and the dual control algorithm are all robust to symmetrical label noise. We have shown that with large sample acceptance and high probability, the same tree would learn with noise-free data as with loud data. We also provided some sample complexity results for robustness. Through extensive empirical research, we have demonstrated that robust learning of decision trees and decimal light is very popular in many application scenarios."}, {"heading": "Appendix A. Sample Complexity Bounds", "text": "The proof [of lemmas 7] Let n + and n \u2212 denounce positive and negative samples at the node. (note n = n + n \u2212) Let us # positive and negative samples at the node (note n + n \u2212) # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}], "references": [{"title": "Classification and Regression Trees", "author": ["L. Breiman", "J. Friedman", "R. Olshen", "C. Stone"], "venue": null, "citeRegEx": "Breiman et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Breiman et al\\.", "year": 1984}, {"title": "Identifying mislabeled training data", "author": ["Carla E. Brodley", "Mark A. Friedl"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Brodley and Friedl.,? \\Q1999\\E", "shortCiteRegEx": "Brodley and Friedl.", "year": 1999}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Analysis of learning from positive and unlabeled data", "author": ["Marthinus C du Plessis", "Gang Niu", "Masashi Sugiyama"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Plessis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Plessis et al\\.", "year": 2014}, {"title": "Classification in the presence of label noise: a survey", "author": ["Ben\u00f4\u0131t Fr\u00e9nay", "Michel Verleysen"], "venue": "Neural Networks and Learning Systems, IEEE Transactions on,", "citeRegEx": "Fr\u00e9nay and Verleysen.,? \\Q2014\\E", "shortCiteRegEx": "Fr\u00e9nay and Verleysen.", "year": 2014}, {"title": "Making risk minimization tolerant to label", "author": ["Aritra Ghosh", "Naresh Manwani", "PS Sastry"], "venue": "noise. Neurocomputing,", "citeRegEx": "Ghosh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ghosh et al\\.", "year": 2015}, {"title": "The elements of statistical learning: data mining, inference and prediction", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome Friedman", "James Franklin"], "venue": "The Mathematical Intelligencer,", "citeRegEx": "Hastie et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2005}, {"title": "A fast, bottom-up decision tree pruning algorithm with near-optimal generalization", "author": ["Michael J Kearns", "Yishay Mansour"], "venue": "In ICML,", "citeRegEx": "Kearns and Mansour.,? \\Q1998\\E", "shortCiteRegEx": "Kearns and Mansour.", "year": 1998}, {"title": "Random classification noise defeats all convex potential boosters", "author": ["Philip M Long", "Rocco A Servedio"], "venue": "Machine Learning,", "citeRegEx": "Long and Servedio.,? \\Q2010\\E", "shortCiteRegEx": "Long and Servedio.", "year": 2010}, {"title": "Generalization bounds for decision trees", "author": ["Yishay Mansour", "David A McAllester"], "venue": "In COLT,", "citeRegEx": "Mansour and McAllester.,? \\Q2000\\E", "shortCiteRegEx": "Mansour and McAllester.", "year": 2000}, {"title": "Noise tolerance under risk minimization", "author": ["Naresh Manwani", "PS Sastry"], "venue": "Cybernetics, IEEE Transactions on,", "citeRegEx": "Manwani and Sastry.,? \\Q2013\\E", "shortCiteRegEx": "Manwani and Sastry.", "year": 2013}, {"title": "Learning with noisy labels", "author": ["Nagarajan Natarajan", "Inderjit S Dhillon", "Pradeep K Ravikumar", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Natarajan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Natarajan et al\\.", "year": 2013}, {"title": "A study of the effect of different types of noise on the precision of supervised learning techniques", "author": ["David F Nettleton", "Albert Orriols-Puig", "Albert Fornells"], "venue": "Artificial intelligence review,", "citeRegEx": "Nettleton et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nettleton et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 4, "context": "Thus, learning classifiers in the presence of label noise is an important problem (Fr\u00e9nay and Verleysen, 2014).", "startOffset": 82, "endOffset": 110}, {"referenceID": 6, "context": "It is generally accepted that among all the classification methods, decision tree is probably closest to \u2018off-the-shelf\u2019 method which has all the desirable properties including robustness to outliers (Hastie et al., 2005).", "startOffset": 200, "endOffset": 221}, {"referenceID": 9, "context": "While there are many results about generalization bounds for decision trees (Mansour and McAllester, 2000; Kearns and Mansour, 1998), not many theoretical results are known about the robustness of decision tree learning in presence of label noise.", "startOffset": 76, "endOffset": 132}, {"referenceID": 7, "context": "While there are many results about generalization bounds for decision trees (Mansour and McAllester, 2000; Kearns and Mansour, 1998), not many theoretical results are known about the robustness of decision tree learning in presence of label noise.", "startOffset": 76, "endOffset": 132}, {"referenceID": 1, "context": "the training data increases size of the learnt tree; detecting and removing noisy examples improves the learnt tree (Brodley and Friedl, 1999).", "startOffset": 116, "endOffset": 142}, {"referenceID": 10, "context": "Another result is that some of the standard convex losses are not robust to symmetric label noise while the 0-1 loss is (Manwani and Sastry, 2013).", "startOffset": 120, "endOffset": 146}, {"referenceID": 5, "context": "A general sufficient condition on the loss function for risk minimization to be robust is derived in (Ghosh et al., 2015).", "startOffset": 101, "endOffset": 121}, {"referenceID": 11, "context": "Robust risk minimization strategies under the so called class-conditional (or asymmetric) label noise are also proposed (Natarajan et al., 2013; Scott et al., 2013).", "startOffset": 120, "endOffset": 164}, {"referenceID": 5, "context": "Some sufficient conditions for robustness of risk minimization under 0-1 loss, ramp loss and sigmoid loss when the training data is corrupted with most general non-uniform label noise are also presented in (Ghosh et al., 2015).", "startOffset": 206, "endOffset": 226}, {"referenceID": 1, "context": "the training data increases size of the learnt tree; detecting and removing noisy examples improves the learnt tree (Brodley and Friedl, 1999). Recently, Nettleton et al. (2010) empirically studied robustness of different classifiers under label noise.", "startOffset": 117, "endOffset": 178}, {"referenceID": 1, "context": "the training data increases size of the learnt tree; detecting and removing noisy examples improves the learnt tree (Brodley and Friedl, 1999). Recently, Nettleton et al. (2010) empirically studied robustness of different classifiers under label noise. While decision tree learning is better than SVM or logistic regression in terms of robustness to label noise, it is also seen that naive Bayes is more robust than decision trees. In this paper, we present a theoretical study of such robustness properties of decision trees. Recently, many analytical results are reported on robust learning of classifiers, using the framework of risk minimization. The robustness or noise tolerance of risk minimization depends on the loss function used. Long and Servedio (2010) proved that any convex potential loss is not robust to uniform or symmetric label noise.", "startOffset": 117, "endOffset": 766}, {"referenceID": 1, "context": "the training data increases size of the learnt tree; detecting and removing noisy examples improves the learnt tree (Brodley and Friedl, 1999). Recently, Nettleton et al. (2010) empirically studied robustness of different classifiers under label noise. While decision tree learning is better than SVM or logistic regression in terms of robustness to label noise, it is also seen that naive Bayes is more robust than decision trees. In this paper, we present a theoretical study of such robustness properties of decision trees. Recently, many analytical results are reported on robust learning of classifiers, using the framework of risk minimization. The robustness or noise tolerance of risk minimization depends on the loss function used. Long and Servedio (2010) proved that any convex potential loss is not robust to uniform or symmetric label noise. Another result is that some of the standard convex losses are not robust to symmetric label noise while the 0-1 loss is (Manwani and Sastry, 2013). It is noted by du Plessis et al. (2014) that convex surrogates losses are not good for learning from positive and unlabeled data.", "startOffset": 117, "endOffset": 1043}, {"referenceID": 10, "context": "We use the same notion of noise tolerance as in (Manwani and Sastry, 2013; van Rooyen et al., 2015).", "startOffset": 48, "endOffset": 99}, {"referenceID": 0, "context": "Then the gini impurity is defined by GGini = 2pq (Breiman et al., 1984); entropy based impurity is defined as GEntropy = \u2212p log p\u2212 q log q (Quinlan, 1986); and misclassification impurity is defined as GMC = min{p, q}.", "startOffset": 49, "endOffset": 71}, {"referenceID": 0, "context": "Then the gini impurity is defined by GGini = 2pq (Breiman et al., 1984); entropy based impurity is defined as GEntropy = \u2212p log p\u2212 q log q (Quinlan, 1986); and misclassification impurity is defined as GMC = min{p, q}. Often the criterion C is called the gain. Hence, we also use gainGini(f) to refer to C(f) when G is GGini and similarly for other impurity measures. A split criterion different from impurity is twoing rule, first proposed by Breiman et al. (1984). Consider a split rule f at a node v.", "startOffset": 50, "endOffset": 465}, {"referenceID": 11, "context": "In the risk minimization framework, class conditional noise can be taken care when the noise rates are known (or can be estimated) (Natarajan et al., 2013; Scott et al., 2013; Ghosh et al., 2015).", "startOffset": 131, "endOffset": 195}, {"referenceID": 5, "context": "In the risk minimization framework, class conditional noise can be taken care when the noise rates are known (or can be estimated) (Natarajan et al., 2013; Scott et al., 2013; Ghosh et al., 2015).", "startOffset": 131, "endOffset": 195}, {"referenceID": 6, "context": "If pairwise correlation of each trees is \u03c1 and variance is \u03c32 for each tree, then random forest, consisting N trees, has variance, (Hastie et al., 2005)", "startOffset": 131, "endOffset": 152}, {"referenceID": 8, "context": "While, SVM has been proved to be non-robust even under symmetric label noise, its sensitivity towards noise widely varies (Long and Servedio, 2010; Nettleton et al., 2010; Manwani and Sastry, 2013; van Rooyen et al., 2015).", "startOffset": 122, "endOffset": 222}, {"referenceID": 12, "context": "While, SVM has been proved to be non-robust even under symmetric label noise, its sensitivity towards noise widely varies (Long and Servedio, 2010; Nettleton et al., 2010; Manwani and Sastry, 2013; van Rooyen et al., 2015).", "startOffset": 122, "endOffset": 222}, {"referenceID": 10, "context": "While, SVM has been proved to be non-robust even under symmetric label noise, its sensitivity towards noise widely varies (Long and Servedio, 2010; Nettleton et al., 2010; Manwani and Sastry, 2013; van Rooyen et al., 2015).", "startOffset": 122, "endOffset": 222}, {"referenceID": 2, "context": "For SVM we used libsvm package (Chang and Lin, 2011).", "startOffset": 31, "endOffset": 52}], "year": 2016, "abstractText": "In most practical problems of classifier learning, the training data suffers from the label noise. Hence, it is important to understand how robust is a learning algorithm to such label noise. This paper presents some theoretical analysis to show that many popular decision tree algorithms are robust to symmetric label noise under large sample size. We also present some sample complexity results which provide some bounds on the sample size for the robustness to hold with a high probability. Through extensive simulations we illustrate this robustness.", "creator": "LaTeX with hyperref package"}}}