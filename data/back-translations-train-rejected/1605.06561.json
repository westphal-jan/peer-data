{"id": "1605.06561", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2016", "title": "DynaNewton - Accelerating Newton's Method for Machine Learning", "abstract": "Newton's method is a fundamental technique in optimization with quadratic convergence within a neighborhood around the optimum. However reaching this neighborhood is often slow and dominates the computational costs. We exploit two properties specific to empirical risk minimization problems to accelerate Newton's method, namely, subsampling training data and increasing strong convexity through regularization. We propose a novel continuation method, where we define a family of objectives over increasing sample sizes and with decreasing regularization strength. Solutions on this path are tracked such that the minimizer of the previous objective is guaranteed to be within the quadratic convergence region of the next objective to be optimized. Thereby every Newton iteration is guaranteed to achieve super-linear contractions with regard to the chosen objective, which becomes a moving target. We provide a theoretical analysis that motivates our algorithm, called DynaNewton, and characterizes its speed of convergence. Experiments on a wide range of data sets and problems consistently confirm the predicted computational savings.", "histories": [["v1", "Fri, 20 May 2016 23:46:58 GMT  (901kb,D)", "http://arxiv.org/abs/1605.06561v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hadi daneshmand", "aurelien lucchi", "thomas hofmann"], "accepted": false, "id": "1605.06561"}, "pdf": {"name": "1605.06561.pdf", "metadata": {"source": "CRF", "title": "DYNANEWTON Accelerating Newton\u2019s Method for Machine Learning", "authors": ["Hadi Daneshmand", "Aurelien Lucchi", "Thomas Hofmann"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In machine learning we often fix a function class with the parameters x-Rd, define a non-negative family of loss functions, a regulator, and then aim to minimize a regulated sample loss via training data S, fS\u03bd (x). (1) Based on theories such as the Tikhonov regulation or structural risk minimization, we know that we can control the expected risk of minimizer x-Rate f-Rate. (2) Avoid over-adjustment by choosing the regulation strength in a reasonable manner. (3) We focus on Newton's method for optimization, the square convergence rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-the-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-rate-"}, {"heading": "2 Related work", "text": "This is achieved by re-examining samples and storing their progression techniques to reduce the variance of future updating policies. Although these methods achieve rapid convergence on empirical risk, they do not explicitly consider the expected risk, which has been separately examined in the literature on learning theory. It is usually analyzed using uniform convergence limits that take the generic form. [5] ES [sup x x x x x x] S [x) - Ez\u03c6z (x) - [n) - and the expectation is via a random sample S of size n. H is a bond that depends on n, usually by a ratio n / d where d is the capacity of the F (e.g. VC dimension).1The recent work of the 8] strategy of empirical risk can be used simultaneously."}, {"heading": "3 Adaptive Newton Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Newton\u2019s Method", "text": "Suppose that we have a \"strongly convex\" function f: Rd \u2192 R, which we want to minimize using solutions x = Rd. A Newton step defines the incrementality as4x = \u2212 \u2212 1 f (x) \u2212 1 f (x), x f (x) + 4x (3) An equivalent method for defining Newton increments without the need to invert the Hessian incrementality is implicit as a solution to the linearized optimality condition f (x + 4x). \u2212 1 f (x). Newton's method implicitly converts to the optimal solution x: = arg min f (x) in a finite number of steps. The rate of convergence is characterized by two different phases depending on the distance to x. The first phase is a vaporized phase with slow convergence, while the second phase has square convergence and a number of steps is triggered."}, {"heading": "3.2 Continuation Method", "text": "We study the 2-parametric family of regulated empirical risk functions defined by smooth and convex, non-negative loss functions \u03c6z and relative to a complete sample S \u0445 = (z1,.., zN). We use the definitions in Equation (1) and think that fS\u03bd is indexed just like n = | S |, where S = (z1,.., zn) consists of the first n samples of S \u0445. The canonical regulator we are looking at is: B (x) = 12 \u0445 x 2 and we will sometimes use commonly used heuristics to focus on a simpler 1-parametric family. We want to implement the abstract procedure described in Algorithm 1, in which we either pre-generate a sequence of problems ft (x) or construct alternatively (\u00b5t, mt) greedily in a data-adaptive manner."}, {"heading": "3.3 Reducing Regularization Strength", "text": "Let us first assume that we solve S and this problem: = \u00b5t \u2212 1. We are looking for the range of possible solution: = \u00b5t \u2264 \u00b5, for which we can guarantee the condition in Eq. (7). Lemma 1. Let us find this solution (\u00b7) = 12% \u00b7 2, x \u0445 \u00b5: = arg minx f\u00b5 (x), and B\u00b5: = 2%%%%% x \u0432. 2. In each such case we have this problem (1 \u2212 1 \u00b2) = \u2212 1 2 (\u221a B2\u00b5 + 4B\u00b5 \u2212 B\u00b5)))) = \u21d2 (x \u0445). After the optimum condition of the first order for x \u00b2 we have this problem f0 (x \u00b2) = \u2212 \u00b5\u00b5; therefore we can find a solution for the following: - f0 (x \u0445) = f0% of the solution - 2% of the solution."}, {"heading": "3.4 Increasing Sample Size", "text": "We now generalize our analysis to the case in which we also increase the sample size. The basic challenge is that we have to limit the gradient standard contributions, which proceed from new data points, upwards. Intuitively, this depends on the generalizability of the current iteration.Tagma 3. Suppose f has continuous gradients with constant L. Let us specify a given nsample, which we divide into S0 = (z1,., zm) and S1 = (zm + 1,., zn), where m \u2264 n is arbitrary. Define x: = arg minx fS0 (x). With a high probability of S0, it is that ES1 root fS (x-1,."}, {"heading": "3.5 Data-Adaptive Algorithm", "text": "The above analysis is largely data independent and contains only a few constants: L, \u03a6, proportionality constants that include H and \u00b5. (Therefore, it leads to geometric rates that can be very conservative.) We will now show a data adaptive strategy that - even with small approximation errors - maximizes sample size and, equivalent, maximizes regulation strength within the desired range. (First, it should be noted that we can easily calculate the gradient based on an increased sample. Denote S = (z1,., zn) and S0 = (z1,., zm), m. (Define x) n. (arg) f S0 \u00b5 f S0 \u00b5 (x), p. (x), n."}, {"heading": "4 Experiments", "text": "Datasets We apply \"2-regulated logistic regression to a set of 4 datasets of different sizes and dimensions summarized in Table 1. We use 90% of the data points as a training set and the remaining 10% as a test set.Compared to standard baselines We compare DYNANEWTON (cf. Algorithm 2) with Newton's method and - as a competitive SGD variant - with SAGA. We have used a step size of 1 L for SAGA as suggested in previous work [10, 14]. The results shown in Figure 2 show significant speeds compared to Newton's method. DYNANEWTON also exceeds the SAGA value and obtains a very accurate solution after less than 6 epochs on all datasets. We also evaluate the solution quality based on the expected risk and provide the full results of this evaluation in the appendix."}, {"heading": "3. COVTYPE 4. SUSY", "text": "We observed empirically that the data adaptive method chooses a value of \u03b1 \u2248 12, which explains why the non-adaptive approach achieves a similar - but slightly worse - performance with \u03b1 = 12. Meaning of the initialization point We investigate the role of the initialization point for the convergence of Newton's method and DYNANEWTON. The results shown in Figure 4 show that bad initialization points (i.e. far from optimum) significantly slow down the convergence of Newton's method, as they require more steps to enter the ball of square convergence. In comparison, a bad initialization does not significantly affect DYNANEWTON."}, {"heading": "5 Conclusion", "text": "We proposed a continuation method variant of the Newton method that dynamically adjusts the sample size and regularization strength so that each partial problem provides a starting point that lies within the square convergence region of the subsequent optimization problem. We provided a theoretical analysis that characterizes the conditions required for proper transfer, and also developed a data adaptive strategy for discrediting the solution path. Our empirical results show significant acceleration across a wide range of data sets with respect to both empirical and expected risks. In particular, the rate of convergence in the latter is transversatile and often approaches optimal solutions in approximately two effective epochs. All results appear to be in good agreement with our theory and its predictions. In the appendix, we provide further empirical evidence showing that our results relate to non-exact Newton methods such as the L-FGS analysis, which is of particular interest for the implementation of significant FGS networks."}, {"heading": "Acknowledgments", "text": "We would like to thank Aryan Mokhtari for the helpful discussions about Newton's method."}, {"heading": "A Appendix", "text": "n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n.. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n.. n. n. n. n. n. n. n. n. n. n. n. n. n. n. n.. n. n. n. n.. n... n. n.. n. n.. n. n....... n.. n. n..... n.. n. n..... n... n.... n.. n..... n. n. n.... n.......... n..... n..... n... n........ n... n...... n.... n... n...... n..... n.. n. n.... n........."}, {"heading": "3. COVTYPE 4. SUSY", "text": "The analysis we developed assumes that we perform a single Newton step instead of 6, which guarantees convergence to numerical precision (see Section 9.5 in [7]). As shown in Figure 7, the effect of the resulting approximate solution is almost negligible. A.5 BFGSOne shortcoming of the Newton method is that it requires the solution of a linear equation system involving the Hessen matrix, which can be impractical for large and high-dimensional datasets. Approximate variants, known as quasi-Newton methods [11], were therefore developed, such as the popular BFGS or its limited memory version L-BFGS [17]. Quasi-Newton methods such as the BFGS do not require the calculation of the Hessian matrix, but construct a successive gap between the GS function, which we effectively quantify by QS."}, {"heading": "3. COVTYPE 4. SUSY", "text": "The results shown in Figure 8 show significant increases compared to L-BFGS. We also examine the performance of DYNALBFGS in the formation of a Convolutionary Neural Network consisting of two convex and merging layers with a fully connected layer. We refer the results to the standard MNIST dataset in Figure 9. Although our analysis does not cover non-convex functions, we do observe significant increases."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Newton\u2019s method is a fundamental technique in optimization with quadratic con-<lb>vergence within a neighborhood around the optimum. However reaching this<lb>neighborhood is often slow and dominates the computational costs. We exploit<lb>two properties specific to empirical risk minimization problems to accelerate New-<lb>ton\u2019s method, namely, subsampling training data and increasing strong convexity<lb>through regularization. We propose a novel continuation method, where we define<lb>a family of objectives over increasing sample sizes and with decreasing regular-<lb>ization strength. Solutions on this path are tracked such that the minimizer of the<lb>previous objective is guaranteed to be within the quadratic convergence region<lb>of the next objective to be optimized. Thereby every Newton iteration is guar-<lb>anteed to achieve super-linear contractions with regard to the chosen objective,<lb>which becomes a moving target. We provide a theoretical analysis that motivates<lb>our algorithm, called DYNANEWTON, and characterizes its speed of convergence.<lb>Experiments on a wide range of data sets and problems consistently confirm the<lb>predicted computational savings.", "creator": "LaTeX with hyperref package"}}}