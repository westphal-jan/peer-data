{"id": "1605.06693", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-May-2016", "title": "Efficient Document Indexing Using Pivot Tree", "abstract": "We present a novel method for efficiently searching top-k neighbors for documents represented in high dimensional space of terms based on the cosine similarity. Mostly, documents are stored as bag-of-words tf-idf representation. One of the most used ways of computing similarity between a pair of documents is cosine similarity between the vector representations, but cosine similarity is not a metric distance measure as it doesn't follow triangle inequality, therefore most metric searching methods can not be applied directly. We propose an efficient method for indexing documents using a pivot tree that leads to efficient retrieval. We also study the relation between precision and efficiency for the proposed method and compare it with a state of the art in the area of document searching based on inner product.", "histories": [["v1", "Sat, 21 May 2016 19:55:03 GMT  (76kb,D)", "http://arxiv.org/abs/1605.06693v1", "6 Pages, 2 Figures"]], "COMMENTS": "6 Pages, 2 Figures", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["gaurav singh", "benjamin piwowarski"], "accepted": false, "id": "1605.06693"}, "pdf": {"name": "1605.06693.pdf", "metadata": {"source": "CRF", "title": "Efficient Document Indexing Using Pivot Tree", "authors": ["Gaurav Singh", "Benjamin Piwowarski"], "emails": ["gaurav.singh.15@ucl.ac.uk", "benjamin.piwowarski@lip6.fr"], "sections": [{"heading": "1 Introduction and Related Work", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "2 Proposed Method", "text": "We observe experimentally that the following relation applies to each given query q-Rv, where v is the vocabulary size, projector S-Rv-V, document d-Rv and orthogonal projector S-Rv-vqT d-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i."}, {"heading": "2.1 Updating the Projector", "text": "We construct the base Bn for the subspace spanned by the vectors (pivot points) p1,..., pn in the descending path to the node Np by the root of the tree. Bn = PnAn with Pn = (p1... pn) If we allow pn + 1 to be the new vector, which is then added to the subspace, we have the new base Bn + 1: Bn + 1 = (Bn x), so that: x = y-y with y = (Id \u2212 BnB \u2020 n) pn + 1We can get a projection vector (y) orthogonal to Bn by using the relation: \u0394\u0442 y-y-y-pn + 1-2 \u2212 (PnB \u2020 npn + 1) 2 = (Id \u2212 BnB \u2020 2 + 1) pn + 1 (Pn + 1) (pn \u00b2)."}, {"heading": "2.2 Updating the Similarity", "text": "We calculate the value for all documents (D) rooted in the subtree of the node Np. Each node of the rotary tree contains max (B) and min (B), where Dp is the set of all documents rooted in the subtree of the node Np."}, {"heading": "2.3 Algorithm", "text": "In this section, we describe the algorithm we use to construct the Pivot Tree. Then, we describe an algorithm to search the Pivot Tree based on a given query. 1. Algorithm SelectPivot (Data S) SelectPivot (Data S) Select some random Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot-Pivot."}, {"heading": "MakeSplit(Data S, Pivot p)", "text": "A \u2190 {s-S: A-DT pn + 1-2 > c-B \u2190 S / A-yield (A, B) 3. Algorithm UpdateProjections (Data Dl, Pivot p, A)"}, {"heading": "UpdateProjections((Data D, Pivot p, A)", "text": "Di.Projections \u2190 update (Tue, p, A) \u0445Di-D; # Using eqn. 54. Algorithm BuildTree (Data S)"}, {"heading": "BuildTree(Data S)", "text": "Input \u2190 S Output \u2190 Tree T T.S \u2190 S T.min \u2190 min (S.Projections) T.max \u2190 max (S.Projections) if (| S | \u2264 No) return TT.p \u2190 SelectPivot (Data S) Dl, Dr \u2190 MakeSplit (T.S, T.p) # Using eqn. 4 T.A \u2190 UpdateA (pivot p) # Using eqn. 4 T.P \u2190 UpdateP (pivot p) # Using eqn 7. Dl.Projections \u2190 UpdateProjections (Data Dl, Pivot p, T.A) T.left \u2190 BuildTree (Data Dl) T.right \u2190 BuildTree (Data Dr) return T5. Algorithm SearchTree (Query S, Tree T)"}, {"heading": "SearchTree(Query S, Tree T)", "text": "Input \u2190 Query S, Tree T Output \u2190 Document Set D Bl \u2190 ComputeBound (Tree T.left, Query q) # with eqn 2 Br \u2190 ComputeBound (Tree T.right, Query q) # with eqn 2 # getLast: Returns the element with the least resemblance to Query if (Bl \u2265 getLast (Queue))) searchL = True if (Br \u2265 getLast (Queue) searchR = Trueif (searchL and! searchR) if (Bl > Br) queue \u2190 SearchTree (Query S, T.left) elsequeue \u2190 SearchTree (Query S, T.right) else if (searchL and! searchR) queue \u2190 SearchTree (Query S, T.chR) else if (! searchL and searchR) e \u2190 SearchTree (Query S, T.chR) searchr"}, {"heading": "3 Experimentation and Results", "text": "In this section, we present experimental results for the proposed method based on the MTA (Maximized Trace Approach) versus the state-of-the-art MIP (Maximum Inner Product) evaluation method. Precision against plums is determined for both assessments by artificially reducing the binding, the reduction in the binding results in more plums but less precision. We can see in Figure 1 that MTA outperforms MIP both in terms of ranking (measured by spearman distance) and in terms of precision for different values of plums [9]."}], "references": [{"title": "Clustering for metric and nonmetric distance measures", "author": ["Marcel R Ackermann", "Johannes Bl\u00f6mer", "Christian Sohler"], "venue": "ACM Transactions on Algorithms (TALG),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Non-metric biometric clustering", "author": ["Glenn Becker", "Mark Potts"], "venue": "In Biometrics Symposium,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Searching in metric spaces", "author": ["Edgar Ch\u00e1vez", "Gonzalo Navarro", "Ricardo Baeza-Yates", "Jos\u00e9 Luis Marroq\u00fa\u0131n"], "venue": "ACM Comput. Surv.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Efficient similarity search in nonmetric spaces with local constant embedding", "author": ["Lei Chen", "Xiang Lian"], "venue": "IEEE Trans. on Knowl. and Data Eng.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Fastmap: A fast algorithm for indexing, datamining and visualization of traditional and multimedia datasets", "author": ["Christos Faloutsos", "King-Ip Lin"], "venue": "SIGMOD Rec.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1995}, {"title": "Cluster-preserving embedding of proteins", "author": ["Hristescu Gabriela", "Farach Martin"], "venue": "Technical report,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Properties of embedding methods for similarity searching in metric spaces", "author": ["G.R. Hjaltason", "H. Samet"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Maximum inner-product search using cone trees", "author": ["Parikshit Ram", "Alexander G. Gray"], "venue": "In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Going metric: Denoising pairwise data", "author": ["Volker Roth", "Julian Laub", "Joachim M Buhmann", "Klaus-Robert M\u00fcller"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Foundations of Multidimensional and Metric Data Structures (The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling)", "author": ["Hanan Samet"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Optimal multi-step k-nearest neighbor search", "author": ["Thomas Seidl", "Hans-Peter Kriegel"], "venue": "In Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}, {"title": "An index structure for data mining and clustering", "author": ["Xiong Wang", "Jason T.L. Wang", "King ip Lin", "Dennis Shasha", "Bruce A. Shapiro", "Kaizhong Zhang"], "venue": "Knowledge and Information Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "Similarity Search: The Metric Space Approach", "author": ["Pavel Zezula", "Giuseppe Amato", "Vlastislav Dohnal", "Michal Batko"], "venue": "Springer Publishing Company, Incorporated,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}], "referenceMentions": [{"referenceID": 2, "context": "A number of methods have been developed in the past to search metric spaces[4, 11, 14], most metric spaces can be search efficiently using the triangle inequality.", "startOffset": 75, "endOffset": 86}, {"referenceID": 9, "context": "A number of methods have been developed in the past to search metric spaces[4, 11, 14], most metric spaces can be search efficiently using the triangle inequality.", "startOffset": 75, "endOffset": 86}, {"referenceID": 12, "context": "A number of methods have been developed in the past to search metric spaces[4, 11, 14], most metric spaces can be search efficiently using the triangle inequality.", "startOffset": 75, "endOffset": 86}, {"referenceID": 10, "context": "[12, 8] discuss the use of range queries and kNN in metric space.", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[12, 8] discuss the use of range queries and kNN in metric space.", "startOffset": 0, "endOffset": 7}, {"referenceID": 3, "context": "There are certain embedding methods which perform exact conversion[5] ar X iv :1 60 5.", "startOffset": 66, "endOffset": 69}, {"referenceID": 3, "context": "In the case of exact embedding methods, the most prominent is LCE[5], which tried to divide objects into groups and then adds a small local constant to all pairwise distances within a group to make them follow triangle inequality.", "startOffset": 65, "endOffset": 68}, {"referenceID": 4, "context": "A number of other approximate embedding techniques like Fastmap[6], Metric Map[13], and Sparse Map[7] exist, but the only exact method with no false dismissals are LCE and CSE[10] [3] presented a non-metric clustering method based on distances to the socalled fiduciary templates (some selected random objects from the set).", "startOffset": 63, "endOffset": 66}, {"referenceID": 11, "context": "A number of other approximate embedding techniques like Fastmap[6], Metric Map[13], and Sparse Map[7] exist, but the only exact method with no false dismissals are LCE and CSE[10] [3] presented a non-metric clustering method based on distances to the socalled fiduciary templates (some selected random objects from the set).", "startOffset": 78, "endOffset": 82}, {"referenceID": 5, "context": "A number of other approximate embedding techniques like Fastmap[6], Metric Map[13], and Sparse Map[7] exist, but the only exact method with no false dismissals are LCE and CSE[10] [3] presented a non-metric clustering method based on distances to the socalled fiduciary templates (some selected random objects from the set).", "startOffset": 98, "endOffset": 101}, {"referenceID": 8, "context": "A number of other approximate embedding techniques like Fastmap[6], Metric Map[13], and Sparse Map[7] exist, but the only exact method with no false dismissals are LCE and CSE[10] [3] presented a non-metric clustering method based on distances to the socalled fiduciary templates (some selected random objects from the set).", "startOffset": 175, "endOffset": 179}, {"referenceID": 1, "context": "A number of other approximate embedding techniques like Fastmap[6], Metric Map[13], and Sparse Map[7] exist, but the only exact method with no false dismissals are LCE and CSE[10] [3] presented a non-metric clustering method based on distances to the socalled fiduciary templates (some selected random objects from the set).", "startOffset": 180, "endOffset": 183}, {"referenceID": 0, "context": "[1] proposed a k-median clustering algorithm for nonmetric functions (specifically, the Kullback-Leibler divergence) that computes a(1 + )\u2212 approximation of the k-median problem.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Recently [9] published maximum inner product based appraoch for querying documents.", "startOffset": 9, "endOffset": 12}, {"referenceID": 7, "context": "We can see in Figure 1 that MTA outperforms MIP[9] in terms of both ranking (as measured by spearman distance) and precision for different values of prunes.", "startOffset": 47, "endOffset": 50}], "year": 2016, "abstractText": "We present a novel method for efficiently searching top-k neighbors for documents represented in high dimensional space of terms based on the cosine similarity. Mostly, documents are stored as bagof-words tf-idf representation. One of the most used ways of computing similarity between a pair of documents is cosine similarity between the vector representations, but cosine similarity is not a metric distance measure as it doesn\u2019t follow triangle inequality, therefore most metric searching methods can not be applied directly. We propose an efficient method for indexing documents using a pivot tree that leads to efficient retrieval. We also study the relation between precision and efficiency for the proposed method and compare it with a state of the art in the area of document searching based on inner product.", "creator": "TeX"}}}